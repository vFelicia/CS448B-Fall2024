With timestamps:

00:00 - hello and welcome i'm your code monkey
00:02 - and here let's learn one of the more
00:04 - basic tasks related to machine learning
00:06 - let's teach the machine how to drive a
00:07 - car this is a classic example and it's
00:09 - pretty easy to do when working with
00:11 - unity ml agents
00:12 - i cover the complete getting start guide
00:14 - in another video so go watch that if
00:16 - you're not familiar with the toolkit
00:17 - machine learning in unity is actually
00:19 - very simple and easy to use once you
00:21 - understand the basics
00:22 - there's a link in the description for
00:23 - the entire machine learning playlist now
00:25 - here we want to teach the ai to drive a
00:27 - car
00:28 - for that we first need a car controller
00:29 - so here i have a very simple one
00:31 - i can move it with the arrow keys and
00:33 - works pretty much exactly like you would
00:34 - expect just a very basic car controller
00:37 - now how this is implemented isn't
00:39 - important for training the ai
00:40 - all that matters is that we have some
00:42 - way that we can interact with this
00:43 - controller by setting forward and
00:45 - turning amounts
00:46 - in this case i have this symbol function
00:48 - set the inputs where i can set the for
00:49 - the mount and turn them out
00:50 - so the ai won't work on any car
00:52 - controller you want to use doesn't have
00:54 - to be this specific one all it needs is
00:56 - to expose a function where the ai can
00:57 - take these actions
00:59 - in order to get our final ai we're first
01:01 - going to teach to drive it in a simple
01:02 - track just doing some left turns
01:04 - then we're going to teach it on a track
01:06 - where the some right turns
01:08 - and then finally we're going to train it
01:09 - on a much more complex track
01:11 - but before we look at the training let's
01:13 - first think of the big picture of what
01:15 - it is that we need for the ai to drive a
01:17 - car
01:17 - so i've got a car here and the goal is
01:20 - for the car to go all the way around the
01:21 - track
01:22 - so think about what information does the
01:23 - ai need in order to achieve this goal
01:26 - well first it needs to know where the
01:28 - track is so we can tell it that by
01:30 - essentially placing some invisible walls
01:31 - on each side of the track and firing
01:33 - some raycasts
01:34 - so just place a bunch of walls all
01:36 - alongside the track and this way the
01:38 - ai won't be able to tell where there's a
01:39 - wall and where there isn't so it will
01:41 - learn what's around it so it can learn
01:43 - to stay away from the walls
01:44 - and then we also need to tell the ai
01:46 - that it's actually making progress
01:47 - so for that there are some invisible
01:49 - checkpoints placed around the track
01:51 - so i can make them a bit visible and yep
01:53 - there they go all the checkpoints
01:55 - so every time the ai goes through one
01:57 - checkpoint it receives a reward
01:58 - as usual when it comes to machine
02:00 - learning the tricky part isn't really on
02:02 - the code
02:02 - that part is very easy as you saw in the
02:04 - getting started video
02:06 - the tricky part is making a good
02:07 - training environment
02:09 - so this is why before you start writing
02:11 - any code you should stop and think about
02:13 - what does the ai need to know
02:14 - just like we did right now so over here
02:16 - i have a brain that i trained previously
02:18 - as you can see it follows correctly
02:20 - alongside the track and goes through all
02:22 - the checkpoints and goes all the way
02:23 - around it
02:24 - so it works on this one with just left
02:26 - turns it also works on this one with
02:28 - right turns there you go they all keep
02:29 - going at it
02:30 - and it also works on this much more
02:32 - complex strap there you go they start in
02:34 - there they go through they manage to go
02:36 - through that turn through that turn
02:37 - then over here this complex one yep
02:39 - there you go they succeed and they keep
02:41 - going all the way
02:42 - the ai isn't completely perfect there
02:43 - are still some times where they hit the
02:45 - invisible walls
02:46 - but the model is working so the solution
02:48 - to fix all that is simply much more
02:49 - training
02:50 - so that's the setup that i've got i have
02:53 - a simple nice car model that i grabbed
02:55 - from a racing asset pack
02:56 - there's a link if you want to grab it on
02:58 - the car object i have a simple
03:00 - collider a rigid body and a car driver
03:02 - script
03:03 - so these are the components for the car
03:05 - controller to work like i said you can
03:06 - use any car controller you want so don't
03:08 - worry about these specific components
03:10 - so those handle the car and then over
03:12 - here i have all the machine learning
03:14 - components
03:14 - so in here is the car driver agent the
03:16 - behavior parameters and the
03:18 - decision requester so these are the
03:20 - standard machine learning components i
03:21 - cover them in detail in the getting
03:23 - started video
03:24 - the one big difference here is over here
03:26 - on the decision requester
03:28 - i'm requesting a decision on every step
03:30 - rather than default which would be on
03:31 - every five steps
03:32 - i'm requesting it on every single one
03:34 - because the car drives pretty fast so it
03:36 - does need to make a decision quite often
03:38 - now the one new thing here is this
03:40 - component the array perception sensor
03:42 - so this is a default ml agent's
03:44 - component what it does is it
03:46 - automatically handles firing some
03:47 - raycasts
03:48 - and adding them to the observations it
03:50 - also has a nice editor script so we can
03:52 - see it over here in the editor in action
03:54 - so if i move the car yep there you go
03:56 - you can see it happening you can see as
03:58 - it collides
03:59 - so this is the information that the ai
04:00 - won't receive for the parameters here
04:02 - you can play around with how many rays
04:04 - per direction so there you go right here
04:05 - we have three so one two three and one
04:07 - down the center
04:08 - so you can increase as many as you want
04:10 - then you've got the max rate degree so
04:12 - right now the maximum is just 70
04:14 - degrees in there but if you want you can
04:15 - make it go 360.
04:17 - then the sphere cast radius so that's
04:18 - the size of the sphere
04:20 - so this isn't actually a raycast rather
04:22 - than sphere cast
04:23 - so this is helpful if the object you're
04:24 - trying to detect with raycast is quite
04:26 - tiny
04:27 - so just increase the size of the sphere
04:28 - cast like that
04:30 - then you can also define a length so
04:32 - this is how far the raycast will go
04:34 - so naturally needs to be big enough in
04:36 - order to actually detect the objects in
04:38 - front of it
04:39 - then we also have a start and end
04:41 - vertical offsets
04:42 - so here for example the object the
04:44 - origin is right down there but i don't
04:45 - want it to start firing
04:47 - right from the floor since that i put it
04:49 - on a vertical offset of one so it starts
04:50 - one unit above
04:51 - then you can also have the n vertical
04:53 - offset so for example you could put this
04:54 - one to go down and there you go all the
04:56 - raycasts go down
04:58 - so for example if you want to teach the
04:59 - machine to avoid falling off the map you
05:01 - would simply add this
05:02 - make it start higher and then lower okay
05:05 - so those are the basics then you have
05:07 - the
05:07 - layer mask so this is what layers the
05:09 - rays won't collide against
05:11 - and once again you need to think like a
05:12 - machine like we did a while ago
05:14 - so in order for the ai to learn how to
05:16 - drive it needs to know about the walls
05:17 - as well as the checkpoints so that's
05:19 - exactly what i said here
05:20 - by using this layer mask the rays will
05:22 - only collide with these layers
05:24 - so for example i've got a car here and
05:26 - as you can see this second car
05:27 - is right in front there you go the array
05:30 - goes through it but it doesn't collide
05:31 - with that one since that one is not on
05:33 - the walls or checkpoints layer
05:34 - then we also have the detectable tags so
05:37 - this is how the ai knows what object it
05:39 - hits
05:40 - so they are based on the game object
05:41 - tags right in here so as you can see on
05:43 - the wall
05:44 - they've got the wall tag as well as the
05:45 - one layer and the checkpoint the same
05:47 - thing same thing
05:48 - so with this sensor the ai now knows if
05:50 - it hits something at what distance that
05:52 - object is
05:53 - and what type of object it is so with
05:55 - this the ai has knowledge that there's a
05:56 - wall over here onto this side at this
05:58 - distance and knows that it's a wall and
06:00 - right in front it knows that there's a
06:02 - checkpoint at this distance
06:03 - i mean again the ai really only works
06:05 - with numbers so it doesn't really
06:06 - understand what is a checkpoint and what
06:08 - is a wall
06:09 - but over time it will learn to increase
06:11 - the distance from this object type
06:12 - and decrease distance towards this
06:14 - object type so as you can see the setup
06:16 - is very simple
06:17 - the only new thing compared to what i
06:19 - covered in the getting started video is
06:20 - really just a sensor
06:22 - now let's look at the agent code and by
06:24 - the way if you find the video helpful
06:26 - consider subscribing and hitting the
06:27 - like button
06:28 - it really helps out the channel here it
06:30 - is it's a pretty simple script as you
06:32 - can see it's less than 100 lines long
06:34 - the tricky part is really only on the
06:36 - training setup and not on the code
06:38 - itself
06:38 - so here on start i'm just listening to
06:40 - the track checkpoints
06:42 - so this is the script that handles when
06:43 - the car goes through a checkpoint
06:45 - i cover this checkpoint system in detail
06:47 - in another video
06:48 - then over here it's very simple if it
06:49 - goes through the correct checkpoint gets
06:51 - a positive reward and through the wrong
06:52 - checkpoint gets a negative reward
06:54 - then down here on our episode begin we
06:56 - just place the car on start with a bit
06:58 - of randomness
06:59 - we make it point the same forward as the
07:01 - spawn position
07:02 - we reset the checkpoints and we stop the
07:04 - car driver then over here for the
07:06 - observations
07:07 - as we saw we use the sensor and that one
07:09 - automatically handles most of them
07:11 - over here i just have an extra one for
07:13 - the dot product between the transform
07:15 - forward and the checkpoint forward
07:16 - so with this the i should learn to face
07:18 - the same direction as the checkpoint
07:20 - and then we have the actions and for
07:22 - actions we really just have two of them
07:24 - so just forward and turn and that one is
07:26 - handled by discrete actions
07:28 - so we've got accelerate brake slash
07:31 - reverse and don't move
07:32 - and also turn right turn left and don't
07:35 - turn then after coming up with the
07:36 - tournament for mount i just send that
07:38 - over to the car driver again it doesn't
07:40 - matter what car controller i'm using
07:42 - here it can be anything as long as
07:44 - i can make it work with these two types
07:45 - of inputs then for the heuristics very
07:47 - basic just using the arrow keys
07:49 - and then down here we've got the
07:50 - collisions here on the uncollision enter
07:53 - so when a collision first happens when
07:54 - it first hits a wall i'm giving it a
07:56 - rather large negative reward
07:58 - and then on the collision say which is
08:00 - triggered for every physics update that
08:02 - the collision is happening for that one
08:04 - i give it a small reward
08:05 - so with this i'm trying to encourage the
08:07 - ai to keep off the walls because before
08:09 - i added this
08:09 - the i was essentially just sliding along
08:11 - the wall and that's it there's nothing
08:13 - else so as you can see it's a very
08:14 - simple script
08:15 - the code is all very basic the training
08:17 - setup is really the only tricky part
08:19 - so i just placed all the tracks placed
08:20 - all the checkpoints alongside it as well
08:22 - as all the walls
08:23 - and again the only thing that matters is
08:25 - really just the physics system
08:26 - so here i can easily make the walls
08:28 - invisible and everything still works
08:30 - perfectly
08:31 - then for the checkpoints themselves i'm
08:32 - using the checkpoint system that i
08:34 - covered in detail in another video
08:36 - it handles the logic for ensuring that
08:38 - each car is passing through the correct
08:39 - checkpoint
08:40 - now here it is important not to place
08:42 - them too far apart
08:43 - so they should be relatively evenly
08:45 - spaced and have
08:46 - a bunch more on the turns you have to
08:48 - remember that the ai really only knows
08:50 - it did something good when it gets a
08:51 - reward
08:52 - so adding more rewards on complex turns
08:54 - does make it helpful
08:56 - so for example here i have quite a lot
08:58 - of checkpoints in order to make sure
08:59 - that it learns how to do this really
09:00 - complex turn
09:01 - okay now we can try training it just
09:03 - like this so here it is just using
09:05 - reinforcement learning and it's trying
09:07 - to learn
09:08 - right away you've seen that they
09:09 - actually start going backwards instead
09:11 - of forwards
09:12 - the reason is because i made the
09:13 - breaking speed long's moving forward is
09:14 - pretty fast
09:15 - so if he tries a bunch of random actions
09:17 - then he just ends up going backwards
09:19 - now the one big change that i made since
09:21 - my first attempt at this project was
09:22 - with regards to the walls
09:24 - first i made the ai and lose instantly
09:26 - when they touch the walls
09:27 - that makes logical sense but it also
09:29 - made it so that every episode was very
09:31 - short so it was hard for the
09:32 - ai to actually randomly try moving
09:34 - forward and getting the first reward so
09:36 - i just made the wall solid
09:38 - and disable the ending of the episode as
09:40 - i said the tricky part is really the
09:41 - training setup and your goal is to help
09:43 - your ai learn by any means necessary
09:45 - so you start by teaching it the simplest
09:47 - example possible and then over time you
09:49 - can make the training scenario more
09:50 - difficult so with this it's just doing
09:52 - normal reinforcement training
09:53 - so as you can see even after some time
09:55 - it still hasn't figured out that the
09:57 - obvious thing is to go forward
09:59 - so that's just basic reinforcement
10:01 - training but like i covered in the
10:03 - last video we can use the awesome power
10:04 - of imitation learning
10:06 - if you haven't seen it yet go watch that
10:07 - video it's really a very powerful tool
10:09 - for that i have some demos here that i
10:11 - prepared previously
10:12 - essentially i just went through the
10:14 - track a bunch of times and recorded it
10:15 - so over here got 4 000 steps
10:18 - going through eight episodes with a nice
10:20 - mean reward so i recorded it for the
10:22 - left turn track and the one for the
10:23 - right turn track
10:24 - then on the config file just enable it
10:26 - to use the demos by enabling both gale
10:28 - and behavioral cloning
10:30 - and for starters i want the agent to
10:32 - learn how to behave excel like the demos
10:34 - so leave the strength of both of these
10:36 - close to one and for the extrinsic
10:38 - rewards we can now leave it at just 0.1
10:40 - so let's see with imitation learning how
10:42 - much faster it learns and for the first
10:44 - attempt for some reason it sounds dry is
10:46 - going backwards
10:47 - but afterwards it does start to learn
10:49 - from the demos and there you go right
10:50 - away it instantly learns to go forwards
10:52 - now obviously it's still getting stuck
10:54 - so it still hasn't learned but in just
10:56 - pretty much just
10:57 - a couple of steps then it already
10:58 - learned quite a lot more than just with
11:00 - reinforcement learning
11:01 - so as you can see imitation and learning
11:03 - is really very powerful
11:04 - in order to enable it it's really very
11:06 - simple you just had a bunch of things
11:08 - over here on the config
11:10 - and there you go they automatically
11:11 - start using it so here you can see a
11:13 - handful of them have already managed to
11:15 - go through the first turn go through
11:16 - there and these ones manage to go and
11:18 - look at that one
11:19 - okay so that's what i did i first used
11:20 - the demo on this track and trained it
11:22 - enough
11:23 - so that they'll learn how to achieve
11:24 - this so trained it using
11:26 - bc gale and reinforcement learning then
11:29 - when it learned this track
11:31 - i set it to training on this second
11:32 - track i used a different demo
11:35 - i lowered the strength on the imitation
11:37 - learning components
11:38 - and increased a bit on the extrinsic
11:40 - rewards and then when it learned how to
11:42 - go through this track
11:43 - then i set it to train on all five
11:45 - tracks and just let it go
11:46 - using only reinforcement learning so
11:48 - here i have a brain that i've trained
11:50 - for about five million steps
11:52 - and right away you can see all of them
11:53 - go so there they go on this track and
11:56 - they also go successfully on this track
11:58 - and then down here on the complex track
11:59 - yep look at that they go through that
12:01 - turn
12:01 - and this come like certain down poor
12:02 - thing got stuck but most of them
12:04 - actually go through
12:05 - they come into that one and they do nice
12:07 - turn and there they go
12:09 - so here you can see just how powerful
12:10 - this is if for example you have a game
12:12 - where you want to support custom player
12:14 - tracks
12:15 - you would just make a handful of pieces
12:17 - all of them with built-in walls and
12:18 - checkpoints and you'll let the player
12:20 - create any track shape you want
12:21 - then the cars would still be able to
12:23 - race through any track custom made by
12:25 - the player
12:26 - you would simply include a trained brain
12:27 - model where you would train it for
12:29 - something like 50 million steps
12:31 - and the agent would perfectly follow any
12:32 - track with any shape
12:34 - alright so there you have it yet another
12:36 - excellent use case for using machine
12:37 - learning and another example of how easy
12:39 - it is to use ml agency in unity
12:42 - check the phone playlist linked in the
12:43 - description where i'm adding all of my
12:45 - machine learning videos
12:46 - as always you can download the project
12:47 - files and utilities from
12:48 - unitycodemonkey.com
12:49 - this video is made possible thanks to
12:51 - these awesome supporters
12:52 - go to patreon.com unitycodemonkey to get
12:55 - some perks and help keep the videos free
12:57 - for everyone
12:58 - if you found this video helpful consider
13:00 - liking and subscribing post any
13:01 - questions have any comments and i'll see
13:02 - you next time
13:08 - [Music]
13:12 - you

Cleaned transcript:

hello and welcome i'm your code monkey and here let's learn one of the more basic tasks related to machine learning let's teach the machine how to drive a car this is a classic example and it's pretty easy to do when working with unity ml agents i cover the complete getting start guide in another video so go watch that if you're not familiar with the toolkit machine learning in unity is actually very simple and easy to use once you understand the basics there's a link in the description for the entire machine learning playlist now here we want to teach the ai to drive a car for that we first need a car controller so here i have a very simple one i can move it with the arrow keys and works pretty much exactly like you would expect just a very basic car controller now how this is implemented isn't important for training the ai all that matters is that we have some way that we can interact with this controller by setting forward and turning amounts in this case i have this symbol function set the inputs where i can set the for the mount and turn them out so the ai won't work on any car controller you want to use doesn't have to be this specific one all it needs is to expose a function where the ai can take these actions in order to get our final ai we're first going to teach to drive it in a simple track just doing some left turns then we're going to teach it on a track where the some right turns and then finally we're going to train it on a much more complex track but before we look at the training let's first think of the big picture of what it is that we need for the ai to drive a car so i've got a car here and the goal is for the car to go all the way around the track so think about what information does the ai need in order to achieve this goal well first it needs to know where the track is so we can tell it that by essentially placing some invisible walls on each side of the track and firing some raycasts so just place a bunch of walls all alongside the track and this way the ai won't be able to tell where there's a wall and where there isn't so it will learn what's around it so it can learn to stay away from the walls and then we also need to tell the ai that it's actually making progress so for that there are some invisible checkpoints placed around the track so i can make them a bit visible and yep there they go all the checkpoints so every time the ai goes through one checkpoint it receives a reward as usual when it comes to machine learning the tricky part isn't really on the code that part is very easy as you saw in the getting started video the tricky part is making a good training environment so this is why before you start writing any code you should stop and think about what does the ai need to know just like we did right now so over here i have a brain that i trained previously as you can see it follows correctly alongside the track and goes through all the checkpoints and goes all the way around it so it works on this one with just left turns it also works on this one with right turns there you go they all keep going at it and it also works on this much more complex strap there you go they start in there they go through they manage to go through that turn through that turn then over here this complex one yep there you go they succeed and they keep going all the way the ai isn't completely perfect there are still some times where they hit the invisible walls but the model is working so the solution to fix all that is simply much more training so that's the setup that i've got i have a simple nice car model that i grabbed from a racing asset pack there's a link if you want to grab it on the car object i have a simple collider a rigid body and a car driver script so these are the components for the car controller to work like i said you can use any car controller you want so don't worry about these specific components so those handle the car and then over here i have all the machine learning components so in here is the car driver agent the behavior parameters and the decision requester so these are the standard machine learning components i cover them in detail in the getting started video the one big difference here is over here on the decision requester i'm requesting a decision on every step rather than default which would be on every five steps i'm requesting it on every single one because the car drives pretty fast so it does need to make a decision quite often now the one new thing here is this component the array perception sensor so this is a default ml agent's component what it does is it automatically handles firing some raycasts and adding them to the observations it also has a nice editor script so we can see it over here in the editor in action so if i move the car yep there you go you can see it happening you can see as it collides so this is the information that the ai won't receive for the parameters here you can play around with how many rays per direction so there you go right here we have three so one two three and one down the center so you can increase as many as you want then you've got the max rate degree so right now the maximum is just 70 degrees in there but if you want you can make it go 360. then the sphere cast radius so that's the size of the sphere so this isn't actually a raycast rather than sphere cast so this is helpful if the object you're trying to detect with raycast is quite tiny so just increase the size of the sphere cast like that then you can also define a length so this is how far the raycast will go so naturally needs to be big enough in order to actually detect the objects in front of it then we also have a start and end vertical offsets so here for example the object the origin is right down there but i don't want it to start firing right from the floor since that i put it on a vertical offset of one so it starts one unit above then you can also have the n vertical offset so for example you could put this one to go down and there you go all the raycasts go down so for example if you want to teach the machine to avoid falling off the map you would simply add this make it start higher and then lower okay so those are the basics then you have the layer mask so this is what layers the rays won't collide against and once again you need to think like a machine like we did a while ago so in order for the ai to learn how to drive it needs to know about the walls as well as the checkpoints so that's exactly what i said here by using this layer mask the rays will only collide with these layers so for example i've got a car here and as you can see this second car is right in front there you go the array goes through it but it doesn't collide with that one since that one is not on the walls or checkpoints layer then we also have the detectable tags so this is how the ai knows what object it hits so they are based on the game object tags right in here so as you can see on the wall they've got the wall tag as well as the one layer and the checkpoint the same thing same thing so with this sensor the ai now knows if it hits something at what distance that object is and what type of object it is so with this the ai has knowledge that there's a wall over here onto this side at this distance and knows that it's a wall and right in front it knows that there's a checkpoint at this distance i mean again the ai really only works with numbers so it doesn't really understand what is a checkpoint and what is a wall but over time it will learn to increase the distance from this object type and decrease distance towards this object type so as you can see the setup is very simple the only new thing compared to what i covered in the getting started video is really just a sensor now let's look at the agent code and by the way if you find the video helpful consider subscribing and hitting the like button it really helps out the channel here it is it's a pretty simple script as you can see it's less than 100 lines long the tricky part is really only on the training setup and not on the code itself so here on start i'm just listening to the track checkpoints so this is the script that handles when the car goes through a checkpoint i cover this checkpoint system in detail in another video then over here it's very simple if it goes through the correct checkpoint gets a positive reward and through the wrong checkpoint gets a negative reward then down here on our episode begin we just place the car on start with a bit of randomness we make it point the same forward as the spawn position we reset the checkpoints and we stop the car driver then over here for the observations as we saw we use the sensor and that one automatically handles most of them over here i just have an extra one for the dot product between the transform forward and the checkpoint forward so with this the i should learn to face the same direction as the checkpoint and then we have the actions and for actions we really just have two of them so just forward and turn and that one is handled by discrete actions so we've got accelerate brake slash reverse and don't move and also turn right turn left and don't turn then after coming up with the tournament for mount i just send that over to the car driver again it doesn't matter what car controller i'm using here it can be anything as long as i can make it work with these two types of inputs then for the heuristics very basic just using the arrow keys and then down here we've got the collisions here on the uncollision enter so when a collision first happens when it first hits a wall i'm giving it a rather large negative reward and then on the collision say which is triggered for every physics update that the collision is happening for that one i give it a small reward so with this i'm trying to encourage the ai to keep off the walls because before i added this the i was essentially just sliding along the wall and that's it there's nothing else so as you can see it's a very simple script the code is all very basic the training setup is really the only tricky part so i just placed all the tracks placed all the checkpoints alongside it as well as all the walls and again the only thing that matters is really just the physics system so here i can easily make the walls invisible and everything still works perfectly then for the checkpoints themselves i'm using the checkpoint system that i covered in detail in another video it handles the logic for ensuring that each car is passing through the correct checkpoint now here it is important not to place them too far apart so they should be relatively evenly spaced and have a bunch more on the turns you have to remember that the ai really only knows it did something good when it gets a reward so adding more rewards on complex turns does make it helpful so for example here i have quite a lot of checkpoints in order to make sure that it learns how to do this really complex turn okay now we can try training it just like this so here it is just using reinforcement learning and it's trying to learn right away you've seen that they actually start going backwards instead of forwards the reason is because i made the breaking speed long's moving forward is pretty fast so if he tries a bunch of random actions then he just ends up going backwards now the one big change that i made since my first attempt at this project was with regards to the walls first i made the ai and lose instantly when they touch the walls that makes logical sense but it also made it so that every episode was very short so it was hard for the ai to actually randomly try moving forward and getting the first reward so i just made the wall solid and disable the ending of the episode as i said the tricky part is really the training setup and your goal is to help your ai learn by any means necessary so you start by teaching it the simplest example possible and then over time you can make the training scenario more difficult so with this it's just doing normal reinforcement training so as you can see even after some time it still hasn't figured out that the obvious thing is to go forward so that's just basic reinforcement training but like i covered in the last video we can use the awesome power of imitation learning if you haven't seen it yet go watch that video it's really a very powerful tool for that i have some demos here that i prepared previously essentially i just went through the track a bunch of times and recorded it so over here got 4 000 steps going through eight episodes with a nice mean reward so i recorded it for the left turn track and the one for the right turn track then on the config file just enable it to use the demos by enabling both gale and behavioral cloning and for starters i want the agent to learn how to behave excel like the demos so leave the strength of both of these close to one and for the extrinsic rewards we can now leave it at just 0.1 so let's see with imitation learning how much faster it learns and for the first attempt for some reason it sounds dry is going backwards but afterwards it does start to learn from the demos and there you go right away it instantly learns to go forwards now obviously it's still getting stuck so it still hasn't learned but in just pretty much just a couple of steps then it already learned quite a lot more than just with reinforcement learning so as you can see imitation and learning is really very powerful in order to enable it it's really very simple you just had a bunch of things over here on the config and there you go they automatically start using it so here you can see a handful of them have already managed to go through the first turn go through there and these ones manage to go and look at that one okay so that's what i did i first used the demo on this track and trained it enough so that they'll learn how to achieve this so trained it using bc gale and reinforcement learning then when it learned this track i set it to training on this second track i used a different demo i lowered the strength on the imitation learning components and increased a bit on the extrinsic rewards and then when it learned how to go through this track then i set it to train on all five tracks and just let it go using only reinforcement learning so here i have a brain that i've trained for about five million steps and right away you can see all of them go so there they go on this track and they also go successfully on this track and then down here on the complex track yep look at that they go through that turn and this come like certain down poor thing got stuck but most of them actually go through they come into that one and they do nice turn and there they go so here you can see just how powerful this is if for example you have a game where you want to support custom player tracks you would just make a handful of pieces all of them with builtin walls and checkpoints and you'll let the player create any track shape you want then the cars would still be able to race through any track custom made by the player you would simply include a trained brain model where you would train it for something like 50 million steps and the agent would perfectly follow any track with any shape alright so there you have it yet another excellent use case for using machine learning and another example of how easy it is to use ml agency in unity check the phone playlist linked in the description where i'm adding all of my machine learning videos as always you can download the project files and utilities from unitycodemonkey.com this video is made possible thanks to these awesome supporters go to patreon.com unitycodemonkey to get some perks and help keep the videos free for everyone if you found this video helpful consider liking and subscribing post any questions have any comments and i'll see you next time you
