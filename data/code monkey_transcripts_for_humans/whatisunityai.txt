With timestamps:

00:00 - hello and welcome I'm your cut monkey
00:01 - and earlier this week I made a video
00:04 - doing a quick recap on the unity GDC
00:06 - roadmap Tonk which covered what is
00:08 - coming with the engine in the near
00:09 - future however one very important thing
00:11 - that was mysteriously absent from the
00:12 - road map but was announced on that very
00:14 - same night was Yin Tai it was somewhat
00:17 - quietly announced just on Twitter the
00:19 - YouTube video is still enlisted which
00:20 - means it's not public now I say
00:22 - announcement but it really is just a
00:23 - teaser really nothing in terms of
00:25 - concrete details and because that the
00:27 - response was pretty negative a handful
00:29 - of people are excited most are skeptical
00:31 - or really just very negative and that's
00:33 - not really without reason AI is a very
00:36 - sensitive topic that can be done either
00:37 - in a positive or negative way and in
00:40 - this case we just how limited this
00:41 - teaser is and how it doesn't really have
00:43 - any details on anything I don't blame
00:45 - people for having a negative reaction
00:47 - however like I mentioned in the GDC
00:49 - video Unity invited me over there and I
00:51 - attended a private tunnel where I got
00:52 - the chance to take a look at behind the
00:54 - scenes and I saw the current state of a
00:56 - bunch of AI tools they are working on
00:57 - that talk was very much behind and then
00:59 - EA so I'm not allowed to talk about
01:01 - specifics but still I can talk about
01:03 - some things you can also sign up to
01:05 - their AI beta if you want to learn more
01:06 - I've signed up myself so here I'm going
01:08 - to cover three common questions that I
01:10 - saw as a response to the announcement
01:11 - and just AI in general so first is Unity
01:14 - announcing something quickly just to
01:16 - please investors which will then be
01:17 - dropped secondly are they doing AI
01:19 - ethically or carelessly and thirdly is
01:21 - Unity considering consent and legal
01:23 - issues in the data sets they are using
01:25 - those are very very important questions
01:27 - and the unity team had answers to all of
01:29 - them but before those I actually had a
01:30 - question of my own I asked them why
01:32 - announces quietly overnight instead of
01:34 - doing the roadmap talk it seems like
01:36 - this should really be present on the
01:37 - roadmap and the answer that I got has to
01:39 - do with how they are researching tons of
01:41 - things and they already have quite a lot
01:42 - working but there's a huge difference
01:44 - between making a quick working prototype
01:46 - and building a proper production ready
01:48 - tune so they have essentially learned
01:50 - the lesson from dots where they showcase
01:52 - it right away in the very very early
01:53 - stages and then a bunch of people were
01:55 - regularly upset when many years came and
01:57 - went and dots was constantly stuck in
01:59 - development so they learned from that
02:01 - and now they want to make sure they only
02:03 - show something concrete when they are
02:04 - very confident they have an actual
02:06 - reusable product and not really just a
02:08 - proof of concept that is why they did
02:10 - not make a Big Splash in the roadmap and
02:11 - also why the teaser announcement is
02:13 - extremely vague without any clear
02:14 - details they don't want to over promise
02:16 - until they know for certainly exactly
02:18 - what they can deliver although actually
02:19 - they have already shown one AI tool in
02:22 - the last unite they showed a tool that
02:24 - uses Ai and machine learning to easily
02:26 - position and animate some characters as
02:28 - you move a hand the tool uses AI to
02:30 - figure out where the rest of the body
02:31 - should be this really speeds up the
02:33 - opposing process so you don't have to
02:35 - move each bone individually then that
02:37 - same tune can be used for animations so
02:39 - as you add some keyframes it uses AI to
02:41 - figure out the position of every limb at
02:43 - every frame in a natural way and it can
02:45 - also do some post matching where you
02:47 - give it a picture and then it positions
02:48 - the character in that exact same pose
02:50 - this is one of the several demos that we
02:52 - saw in that privatonk with this you can
02:53 - also see how they are researching tons
02:55 - of areas so they're not just making a
02:57 - quick Chachi PT clone or a clone of
02:59 - stable diffusion and it's actually kind
03:01 - of funny to see the difference in the
03:02 - reactions that talk which showcase an
03:04 - actual tool in action is from a very
03:06 - very positive comments whereas the
03:08 - general AI announcement that has no
03:10 - details that one is almost entirely
03:11 - negative honestly I see this as a
03:13 - positive because it tells you that
03:14 - people are upset when there are no
03:15 - details but become much more positive
03:17 - when they actually see how AI might help
03:19 - them for me as someone with no animation
03:21 - skills I can definitely see this tune
03:22 - being very useful also lots of people
03:24 - were either very excited or very angry
03:26 - when kjiro posted about his AI command
03:29 - tool this actually demonstrates the
03:30 - exact same thing that the AI team was
03:32 - talking about like cager himself
03:33 - mentioned in the FAQ this is just a
03:35 - proof of concept This is Not Practical
03:37 - there is a huge difference between a
03:39 - research proof of concept and a proper
03:41 - usable production ready tool so those
03:43 - are the reasons why they quietly made
03:44 - this announcement instead of making a
03:46 - Big Splash in the official roadmap okay
03:48 - so now let's see those three common
03:49 - questions that I saw for example the
03:51 - first question several people posted a
03:53 - comment saying something like oh they're
03:54 - just announcing this because AI is the
03:56 - big hype right now so they're announcing
03:58 - it just for the investors and they're
04:00 - going going to drop it soon that is a
04:02 - very valid concern and it's actually the
04:03 - very first thing that I asked the AI
04:05 - team the answer is no this is not a
04:06 - knee-jerk reaction to Chachi PT or
04:09 - mid-journey or anything like that they
04:10 - pointed out how Unity has been working
04:12 - with AI for many years now their ml
04:15 - agents package has been around for
04:16 - several years and I've even used it
04:18 - myself to build some interesting things
04:19 - alongside the mligence packages project
04:22 - Barracuda this is their lightweight
04:24 - cross-platform inference engine which is
04:26 - what actually runs in neural networks
04:28 - this is extremely important to make sure
04:29 - you can run machine learning on all the
04:31 - platforms that Unity supports again this
04:33 - package has been in custom development
04:35 - since 2018 and beyond that they made a
04:37 - blog post in 2018 covering their guiding
04:39 - principles which I'm going to cover in a
04:40 - bit so with regards to this question is
04:42 - this just the next shiny thing that UNT
04:44 - is chasing just to jump on the AI hype
04:47 - bandwagon in order to police investors
04:48 - the answer to that is no clearly this
04:51 - area of AI and machine learning this is
04:53 - something they have been researching for
04:54 - a long time which showcase just how
04:55 - serious they are about it another
04:57 - question and the issue people have with
04:58 - AI is with regards to app ethics and
05:01 - again for this they already publicly
05:02 - posted their guiding principles all the
05:04 - way back in 2018 their guiding
05:06 - principles are be unbiased be
05:08 - accountable be fair be responsible be
05:12 - honest and be trustworthy these are
05:14 - their guiding principles as established
05:16 - back in 2018 in that private talks the
05:18 - team told me their principles nowadays
05:20 - are still the same as they were before
05:21 - meaning they're focused on making AI the
05:23 - right way they're not trying to
05:25 - eliminate developers or jobs they're not
05:27 - trying to screw anyone by scripping
05:29 - their dad without consent instead
05:30 - they're trying to do it the right way by
05:32 - giving you tools to help you make your
05:33 - games better and faster since AI is
05:36 - moving really quickly they're also
05:37 - paying close attention to the rules and
05:38 - regulations as this space changes
05:40 - another extremely important question is
05:42 - with regards to data sets plenty of
05:44 - people don't like how all of these AI
05:46 - tools just scrape the entire internet
05:47 - without consent chances are if you've
05:49 - ever drawn an image and published it on
05:51 - the internet that it was used to train
05:52 - stable diffusion or perhaps if you've
05:54 - ever posted something on stack Overflow
05:56 - chances are Chachi PT read about it and
05:58 - learned from it this is a a very tricky
06:00 - subject should the AI tools be allowed
06:03 - to learn from any public Source or
06:04 - should they require consent first that's
06:06 - not just a moral issue but in legal one
06:08 - as well is it legal to train a model on
06:11 - copyrighted materials there are already
06:13 - several lawsuits currently ongoing and
06:15 - right now no one knows which way the
06:17 - chords are on the side right now it's
06:18 - certainly complete unknown and if game
06:20 - development is your job you definitely
06:22 - don't want to be dependent on data known
06:24 - and potentially become exposed to legal
06:26 - problems in the future there are already
06:27 - some reports that various Studios have
06:29 - forbidden the use of AI tools simply
06:31 - because it is not clear how it works
06:33 - legally those Studios absolutely do want
06:35 - to use AI to improve their productivity
06:37 - but not at the cost of exposing them to
06:39 - legal action The Entity team said that
06:41 - this is something they take very
06:42 - seriously Unity does not want people
06:45 - that use the engine to be exposed to any
06:47 - kind of legal liability because of
06:48 - copyright questions related to the
06:50 - original data set so that means in order
06:52 - to do it right they need to gather the
06:53 - data sets properly and with consent this
06:55 - is another part of the reason why they
06:57 - didn't announce anything specific
06:58 - because these two homes are built on
07:00 - data massive amounts of data and if
07:02 - you're doing things the right way either
07:03 - you need to get consent or you need to
07:05 - build all that data yourself as you can
07:07 - imagine for something like an AI mocap
07:09 - tool it takes quite a bit of time and
07:10 - money to generate all of the thousands
07:12 - of hours of mocap data that you need in
07:14 - order to make the tune work for me this
07:15 - showcase is just how committed they are
07:17 - to doing Aid right way with consent and
07:19 - without exposing you the developer to
07:21 - any legal liability since Unity is
07:23 - working on building an entire data set
07:24 - that they themselves own they can then
07:26 - build tools and know for certain there
07:28 - are no legal issues as for what are the
07:30 - tones themselves like I said what I saw
07:32 - is under NDA so I can't reveal any
07:34 - specifics on what I saw but they've
07:35 - already probably shown that talk in
07:37 - unite where they showcase AI driven
07:39 - posing AI animation and post-matching
07:41 - from an image another AI tool they've
07:43 - shown many times is called kinematica
07:45 - which is an AI driven animation system
07:47 - now they actually pause development on
07:49 - this dual until that animation is fully
07:51 - stable which might happen sometime later
07:53 - this year so perhaps kinematica won't be
07:55 - back next year beyond that you can look
07:57 - at the General State of AI and assume
07:59 - Unity is researching of those areas like
08:01 - for example kijirusum where a chatbot
08:03 - can interact directly with unity of
08:05 - course using AI to generate all kinds of
08:07 - textures this is something that already
08:09 - exist you don't think stopping them from
08:11 - releasing something like this right now
08:12 - is simply the need for building their
08:13 - own data set from scratch Nvidia has
08:15 - already announced a text to 3D tool that
08:18 - one would definitely be extremely useful
08:19 - to game devs there are already some
08:21 - tunes on the accessor they use AI for
08:23 - terrain generation and placing objects
08:25 - with regards to code Microsoft recently
08:27 - announced GitHub co-pilot X which seems
08:29 - really impressive it allows you to
08:31 - generate documentation ask questions
08:33 - based on your code base write code with
08:34 - voice and so on so you can probably
08:36 - assume Unity is researching all kinds of
08:38 - use case related to AI but at the same
08:40 - time like I mentioned in the beginning
08:41 - there's a huge difference between a
08:43 - proof of concept and a proper usable
08:44 - production ready tool so it remains to
08:46 - be seen how many of these possible use
08:48 - cases they can turn into proper tools oh
08:50 - no I can definitely understand the
08:51 - skepticism and negativity that people
08:53 - had in reaction to this extremely bare
08:55 - bone Caesar I get that but what I saw
08:57 - behind closed doors really puts my mind
08:59 - at these that they are doing this the
09:01 - right way and actively trying to avoid
09:03 - all of the negative pitfalls of AI
09:04 - hopefully in the coming months as the
09:06 - Apparently announced more and more on
09:07 - this topic people will see how AI might
09:09 - help them make better games faster which
09:11 - will then generate a more positive
09:12 - sentiment if you want to learn more you
09:14 - can sign up to their AI beta I've signed
09:17 - up myself and I'm very much looking
09:18 - forward to seeing what the future brings
09:19 - alright hope that's useful check out
09:22 - these videos to learn some more thanks
09:24 - to these awesome patreon supporters for
09:25 - making these videos possible thank you
09:27 - for watching and I'll see you next time
09:30 - [Music]

Cleaned transcript:

hello and welcome I'm your cut monkey and earlier this week I made a video doing a quick recap on the unity GDC roadmap Tonk which covered what is coming with the engine in the near future however one very important thing that was mysteriously absent from the road map but was announced on that very same night was Yin Tai it was somewhat quietly announced just on Twitter the YouTube video is still enlisted which means it's not public now I say announcement but it really is just a teaser really nothing in terms of concrete details and because that the response was pretty negative a handful of people are excited most are skeptical or really just very negative and that's not really without reason AI is a very sensitive topic that can be done either in a positive or negative way and in this case we just how limited this teaser is and how it doesn't really have any details on anything I don't blame people for having a negative reaction however like I mentioned in the GDC video Unity invited me over there and I attended a private tunnel where I got the chance to take a look at behind the scenes and I saw the current state of a bunch of AI tools they are working on that talk was very much behind and then EA so I'm not allowed to talk about specifics but still I can talk about some things you can also sign up to their AI beta if you want to learn more I've signed up myself so here I'm going to cover three common questions that I saw as a response to the announcement and just AI in general so first is Unity announcing something quickly just to please investors which will then be dropped secondly are they doing AI ethically or carelessly and thirdly is Unity considering consent and legal issues in the data sets they are using those are very very important questions and the unity team had answers to all of them but before those I actually had a question of my own I asked them why announces quietly overnight instead of doing the roadmap talk it seems like this should really be present on the roadmap and the answer that I got has to do with how they are researching tons of things and they already have quite a lot working but there's a huge difference between making a quick working prototype and building a proper production ready tune so they have essentially learned the lesson from dots where they showcase it right away in the very very early stages and then a bunch of people were regularly upset when many years came and went and dots was constantly stuck in development so they learned from that and now they want to make sure they only show something concrete when they are very confident they have an actual reusable product and not really just a proof of concept that is why they did not make a Big Splash in the roadmap and also why the teaser announcement is extremely vague without any clear details they don't want to over promise until they know for certainly exactly what they can deliver although actually they have already shown one AI tool in the last unite they showed a tool that uses Ai and machine learning to easily position and animate some characters as you move a hand the tool uses AI to figure out where the rest of the body should be this really speeds up the opposing process so you don't have to move each bone individually then that same tune can be used for animations so as you add some keyframes it uses AI to figure out the position of every limb at every frame in a natural way and it can also do some post matching where you give it a picture and then it positions the character in that exact same pose this is one of the several demos that we saw in that privatonk with this you can also see how they are researching tons of areas so they're not just making a quick Chachi PT clone or a clone of stable diffusion and it's actually kind of funny to see the difference in the reactions that talk which showcase an actual tool in action is from a very very positive comments whereas the general AI announcement that has no details that one is almost entirely negative honestly I see this as a positive because it tells you that people are upset when there are no details but become much more positive when they actually see how AI might help them for me as someone with no animation skills I can definitely see this tune being very useful also lots of people were either very excited or very angry when kjiro posted about his AI command tool this actually demonstrates the exact same thing that the AI team was talking about like cager himself mentioned in the FAQ this is just a proof of concept This is Not Practical there is a huge difference between a research proof of concept and a proper usable production ready tool so those are the reasons why they quietly made this announcement instead of making a Big Splash in the official roadmap okay so now let's see those three common questions that I saw for example the first question several people posted a comment saying something like oh they're just announcing this because AI is the big hype right now so they're announcing it just for the investors and they're going going to drop it soon that is a very valid concern and it's actually the very first thing that I asked the AI team the answer is no this is not a kneejerk reaction to Chachi PT or midjourney or anything like that they pointed out how Unity has been working with AI for many years now their ml agents package has been around for several years and I've even used it myself to build some interesting things alongside the mligence packages project Barracuda this is their lightweight crossplatform inference engine which is what actually runs in neural networks this is extremely important to make sure you can run machine learning on all the platforms that Unity supports again this package has been in custom development since 2018 and beyond that they made a blog post in 2018 covering their guiding principles which I'm going to cover in a bit so with regards to this question is this just the next shiny thing that UNT is chasing just to jump on the AI hype bandwagon in order to police investors the answer to that is no clearly this area of AI and machine learning this is something they have been researching for a long time which showcase just how serious they are about it another question and the issue people have with AI is with regards to app ethics and again for this they already publicly posted their guiding principles all the way back in 2018 their guiding principles are be unbiased be accountable be fair be responsible be honest and be trustworthy these are their guiding principles as established back in 2018 in that private talks the team told me their principles nowadays are still the same as they were before meaning they're focused on making AI the right way they're not trying to eliminate developers or jobs they're not trying to screw anyone by scripping their dad without consent instead they're trying to do it the right way by giving you tools to help you make your games better and faster since AI is moving really quickly they're also paying close attention to the rules and regulations as this space changes another extremely important question is with regards to data sets plenty of people don't like how all of these AI tools just scrape the entire internet without consent chances are if you've ever drawn an image and published it on the internet that it was used to train stable diffusion or perhaps if you've ever posted something on stack Overflow chances are Chachi PT read about it and learned from it this is a a very tricky subject should the AI tools be allowed to learn from any public Source or should they require consent first that's not just a moral issue but in legal one as well is it legal to train a model on copyrighted materials there are already several lawsuits currently ongoing and right now no one knows which way the chords are on the side right now it's certainly complete unknown and if game development is your job you definitely don't want to be dependent on data known and potentially become exposed to legal problems in the future there are already some reports that various Studios have forbidden the use of AI tools simply because it is not clear how it works legally those Studios absolutely do want to use AI to improve their productivity but not at the cost of exposing them to legal action The Entity team said that this is something they take very seriously Unity does not want people that use the engine to be exposed to any kind of legal liability because of copyright questions related to the original data set so that means in order to do it right they need to gather the data sets properly and with consent this is another part of the reason why they didn't announce anything specific because these two homes are built on data massive amounts of data and if you're doing things the right way either you need to get consent or you need to build all that data yourself as you can imagine for something like an AI mocap tool it takes quite a bit of time and money to generate all of the thousands of hours of mocap data that you need in order to make the tune work for me this showcase is just how committed they are to doing Aid right way with consent and without exposing you the developer to any legal liability since Unity is working on building an entire data set that they themselves own they can then build tools and know for certain there are no legal issues as for what are the tones themselves like I said what I saw is under NDA so I can't reveal any specifics on what I saw but they've already probably shown that talk in unite where they showcase AI driven posing AI animation and postmatching from an image another AI tool they've shown many times is called kinematica which is an AI driven animation system now they actually pause development on this dual until that animation is fully stable which might happen sometime later this year so perhaps kinematica won't be back next year beyond that you can look at the General State of AI and assume Unity is researching of those areas like for example kijirusum where a chatbot can interact directly with unity of course using AI to generate all kinds of textures this is something that already exist you don't think stopping them from releasing something like this right now is simply the need for building their own data set from scratch Nvidia has already announced a text to 3D tool that one would definitely be extremely useful to game devs there are already some tunes on the accessor they use AI for terrain generation and placing objects with regards to code Microsoft recently announced GitHub copilot X which seems really impressive it allows you to generate documentation ask questions based on your code base write code with voice and so on so you can probably assume Unity is researching all kinds of use case related to AI but at the same time like I mentioned in the beginning there's a huge difference between a proof of concept and a proper usable production ready tool so it remains to be seen how many of these possible use cases they can turn into proper tools oh no I can definitely understand the skepticism and negativity that people had in reaction to this extremely bare bone Caesar I get that but what I saw behind closed doors really puts my mind at these that they are doing this the right way and actively trying to avoid all of the negative pitfalls of AI hopefully in the coming months as the Apparently announced more and more on this topic people will see how AI might help them make better games faster which will then generate a more positive sentiment if you want to learn more you can sign up to their AI beta I've signed up myself and I'm very much looking forward to seeing what the future brings alright hope that's useful check out these videos to learn some more thanks to these awesome patreon supporters for making these videos possible thank you for watching and I'll see you next time
