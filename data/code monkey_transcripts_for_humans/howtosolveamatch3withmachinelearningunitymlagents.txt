With timestamps:

00:00 - hello and welcome i'm your code monkey
00:02 - so a while ago i made this simple match
00:04 - 3 game
00:04 - it's got the basic design you would
00:06 - expect i even made a video showcasing
00:08 - how i made this in just under 6 hours
00:10 - then i also used this game as an example
00:13 - for how to use game simulation to play
00:14 - your game in the cloud
00:16 - and for that i created the bot using
00:17 - some classic ai to play the game
00:19 - the bot is simple and not very smart but
00:21 - it does work and now here
00:23 - let's implement some ai using machine
00:25 - learning to teach you how to play a
00:26 - match 3 game
00:27 - the one huge benefit of using machine
00:29 - learning as opposed to classic ai
00:31 - is that after implementing it once we
00:33 - can easily modify our game and add extra
00:35 - features without having to change much
00:37 - on the ai
00:38 - if we were to add some special skill
00:39 - like for example an explosion when
00:41 - matching four in a row
00:42 - then we would need to explicitly add
00:44 - that to the classic ai
00:46 - but when using machine learning we just
00:48 - need to run training some more
00:49 - so using machine learning ai is
00:51 - excellent for a game that is constantly
00:53 - updating
00:53 - in the end we will see how easy the ai
00:56 - will learn how to play after adding a
00:57 - new feature
00:58 - and making a super intelligent ai is
01:00 - also great for giving the player a hint
01:02 - when they're stuck
01:03 - you can just ask the ai to make a
01:04 - decision and then you would show that
01:06 - move to the player
01:07 - this video is sponsored by unity so i've
01:10 - already covered the basics for ml agents
01:12 - and machine learning in unity in another
01:14 - video
01:14 - go watch that one to learn how the
01:16 - toolkit works if you know those basics
01:18 - you should be able to follow everything
01:20 - here
01:21 - so we're going to implement machine
01:22 - learning using the official ml agents
01:24 - match 3 extension i'm using the game
01:26 - that i have here as an example but the
01:28 - process for adding it to any match 3
01:30 - game will be very similar and quite
01:31 - simple thanks to how the extension is
01:33 - set up
01:34 - as long as you have some events and some
01:35 - simple functions in your match 3 class
01:37 - then this will work with any kind of
01:39 - game you really just need to write
01:41 - one script which handles the connection
01:42 - between your custom match 3 scripts any
01:44 - match during the extensions and
01:46 - everything works
01:47 - you can get the official match 3
01:48 - extension from the ml legends github
01:50 - repo
01:51 - there's a link in the description to
01:52 - install the extensions you can open up
01:54 - the package manager
01:55 - click on the plus icon to add a package
01:57 - from git and then you paste in the link
01:59 - that you see on the documentation
02:01 - okay so in those extensions you have
02:03 - essentially three elements that make it
02:04 - up
02:05 - you have a board a actuator and a sensor
02:08 - the only one that we really need to work
02:10 - with is just the board
02:11 - this is an abstract class that we're
02:13 - going to implement naturally this
02:14 - represents the board or the play area
02:17 - and it contains the number of rows and
02:18 - columns as well as the number of cell
02:20 - types and any special types that your
02:22 - game has
02:23 - then we just have a whole bunch of
02:24 - functions that we're going to need to
02:25 - implement which is how we interact with
02:27 - the board
02:27 - so this is the only class that we're
02:29 - going to need to interact with then we
02:31 - have the
02:31 - sensor and actuator both those have two
02:34 - classes
02:35 - so you have the class that actually
02:36 - implements the logic and then
02:38 - also the components which is what you
02:40 - attach into your game objects which in
02:42 - turn all they do
02:43 - is construct the actual underlying class
02:45 - the sensor is what generates
02:47 - observations for the ai based on the
02:48 - state of the board
02:49 - and the actuator is what takes actions
02:51 - on the board and finally you also have a
02:53 - move which is just a simple struct
02:55 - so it represents an in-game move where
02:57 - you swap a position towards a certain
02:58 - direction so for example swap the cell
03:00 - on zero zero with direction on right to
03:02 - swap with one zero
03:03 - so as i said all you really need to
03:05 - worry about is just implementing the
03:06 - abstract board
03:07 - everything else just interacts with that
03:09 - one so let's do just that
03:11 - over here on my scripts folder i'm going
03:12 - to create a new c sharp script
03:14 - name this my match 3 ml agents board
03:17 - and create a new game object to run it
03:20 - so just attach it and let's open
03:22 - so as i said this class will connect the
03:24 - machine learning side with
03:25 - your match 3 class so let's begin by
03:28 - just adding a field for that one
03:30 - so in my case my main one is called just
03:33 - match three
03:35 - and in this case i'm going to make it as
03:37 - a serialized field so i can easily set
03:39 - it in the editor
03:40 - so here in the editor i've got the field
03:41 - and just drag it on there okay
03:43 - now here we're going to add our using so
03:45 - we're going to add using
03:50 - unity.mlagents.extensions.match3
03:52 - and instead of extending just modern
03:54 - behavior we're going to extend
03:55 - our abstract board okay now we need to
03:58 - implement all of this you can use visual
04:00 - studio to really help you out
04:02 - so just implement the abstract class so
04:04 - just with this default implementation
04:06 - let's just hit save and go back into the
04:08 - editor
04:09 - okay the code compiles and now we can
04:10 - see the public fields on the abstract
04:12 - board
04:13 - so we've got the rows columns special
04:15 - types and cell types
04:17 - so these are poly films so if you want
04:19 - you can set them directly over here in
04:20 - the editor
04:22 - or in my case the way that i set up my
04:24 - mastery game is all of that data is on a
04:26 - scriptable object so i'm going to grab
04:27 - it and set it directly in my code
04:29 - by the way if you find the video helpful
04:31 - please hit the like button
04:32 - it's a tiny thing but it really does
04:33 - help thanks so in my particular
04:35 - implementation i have this simple
04:37 - scriptable object that defines every
04:39 - single level
04:40 - and in there i've got a list of all the
04:42 - gem types that are possible
04:44 - as well as the width and height and so
04:45 - on again depending on how you set up
04:47 - your
04:48 - match 3 game this is going to be
04:49 - different but it's going to be roughly
04:50 - the same thing
04:51 - so in here i just make a private void
04:53 - awake and on awake i'm going to set all
04:55 - those fields
04:56 - so first up these the columns which in
04:58 - my case i named it width and height
05:05 - next up is the cell types this is the
05:08 - number of colors or shapes that you have
05:10 - in your level
05:11 - so in my case each level object has a
05:13 - list of all the gems
05:15 - and then the final thing you need to set
05:17 - is the number of special types
05:19 - so for example if you've got some
05:21 - special gems that cause some explosions
05:23 - or destruction online or something so
05:24 - anything that is different from the base
05:26 - cell types that's what you would input
05:28 - in here
05:29 - in my case i made two different level
05:31 - types so one of them is hitting the
05:32 - score
05:33 - and the other one is destroying some
05:34 - class nodes so for my normal score type
05:36 - i don't have any special
05:38 - types and on my glass levels i do have
05:40 - the glass as a special cell type
05:46 - so in my case if my level is of type
05:48 - score so there's nothing special so i
05:49 - just have a zero
05:50 - and if not then it's going to be a glass
05:52 - level so it is going to be
05:54 - one on the special type again if you
05:56 - have multiple special types then
05:58 - obviously you would put a different
05:59 - number
05:59 - okay so that's the basics we just set up
06:01 - all of our public fields
06:03 - now down here we see all the functions
06:05 - that we actually need to implement
06:06 - and if you want some help on how these
06:08 - should be implemented you can just go
06:10 - into the main abstract board class and
06:12 - over here you've got tons of comments to
06:13 - tell you exactly what each of them
06:15 - should do
06:15 - so for example over here on the get cell
06:17 - type this one returns the color or
06:20 - shape or whatever type of the piece at a
06:22 - given row and cone
06:23 - so this will be an int that will be
06:25 - between zero and the number of types
06:27 - that you gave
06:28 - so for example if you've got a match
06:29 - three with let's say just squares and
06:31 - circles
06:32 - then you would put on the number of cell
06:34 - types you would put two so you got
06:35 - squares and circles two types
06:36 - and in here if it was a square then you
06:38 - would return zero
06:40 - and if it was a circle you'd return one
06:42 - so you convert your types into simple
06:44 - integer values
06:44 - so over here the way that i implemented
06:46 - things
06:52 - so i asked my custom match free class to
06:55 - give me the gem type and then i simply
06:56 - return an integer that refers to that
06:58 - gem type
06:59 - okay that's pretty much it for the get
07:00 - sound type then for the special type
07:03 - as it says here this is pretty much
07:04 - exactly the same thing but regarding
07:06 - special types
07:07 - so in my case the only special type is
07:09 - if it is in case in class or not
07:14 - so in my case i can ask my class if a
07:16 - specific position is in case in the last
07:18 - if so return one if not return zero next
07:20 - up for the is move valid
07:22 - so this one checks if a particular move
07:24 - is valid for the game
07:25 - meaning that it tests if this move would
07:27 - result in a match if so it is valid and
07:29 - can be swapped
07:30 - and you can inspect the struct on the
07:32 - move to see how it is set up
07:34 - so you've got essentially a row and cone
07:36 - then you've got a direction for the swap
07:38 - so for example zero zero swapping to the
07:40 - right and you would test that
07:41 - so again i'm going to implement it in my
07:43 - particular case
07:51 - okay so in my match 3 class i've got a
07:53 - function to ask if two grid positions
07:55 - can be swapped so we start
07:57 - x and y compared with an n x and y
08:00 - that's if that can be swapped so i go
08:02 - into the move and the move also has a
08:03 - really nice function
08:04 - that returns the other cell so again for
08:07 - example if the move was zero zero swap
08:08 - to the right
08:09 - then calling other cell would give you
08:11 - the position one zero
08:13 - so just ask that do that and there you
08:14 - go that one is implement and finally we
08:16 - have the make move function
08:18 - so this one is supposed to actually make
08:19 - the move so you can see over here on the
08:21 - abstract it instructs the game to make
08:23 - the actual given move
08:24 - and then returns through if the move was
08:26 - made however look at this note which is
08:28 - that during training a move that was
08:30 - invalid
08:30 - may still be requested so if it happens
08:32 - you need to handle that
08:34 - so let's implement this
08:42 - all right so that's it pretty much the
08:44 - same logic as for asking if the move is
08:45 - valid
08:46 - and if it is then i can do this move so
08:48 - i just swap those positions if not then
08:49 - i can do it
08:50 - okay so that's pretty much it with this
08:52 - we have our abstract board
08:54 - fully implemented so now this class acts
08:56 - as a link between the built-in sensor
08:58 - and
08:59 - actuator and our custom mastery class so
09:01 - speaking of that let's add those two
09:03 - over here on our ml agents we currently
09:05 - have our board
09:06 - now in order to run machine learning we
09:08 - need an agent so let's add the standard
09:10 - just search for the agent component
09:12 - and there you go there's the standard
09:14 - agent and it automatically adds the
09:16 - behavior parameters so here give it a
09:17 - name so just
09:19 - just something like match three agent
09:21 - then we're also going to add the
09:22 - built-in components
09:24 - so let's add the match 3 sensor
09:26 - component
09:27 - and also the actuator so match 3
09:29 - actuator component
09:31 - again these are from the official
09:32 - extensions we didn't touch these at all
09:34 - and now this sensor and this actuator is
09:37 - going to work in conjunction with the
09:38 - agent
09:39 - and all of them are going to tall to our
09:41 - custom match three board
09:43 - which in turn interfaces with the rest
09:44 - of our code with our custom classes
09:46 - alright so we're almost ready for
09:48 - training one more thing is needed for
09:50 - the agent which is to request a decision
09:52 - now usually we would add here the
09:54 - decision requester script
09:56 - so this one is great for constantly
09:57 - requesting decisions however this game
10:00 - is turn based so we should manually
10:01 - request decisions the way the game works
10:03 - is the board is ready and it waits for
10:05 - the player to make a move
10:06 - then the algorithm looks for all the
10:08 - matches spawns some more gems and
10:09 - finally goes back to waiting for the
10:11 - player
10:11 - so we only want to take an action and
10:13 - request a decision when the board is on
10:15 - that state
10:15 - so in my case i have a class that fires
10:18 - off some events
10:19 - so when it is waiting for the user so
10:21 - let's listen to this event to request a
10:23 - decision
10:24 - so just go there and subscribe to that
10:28 - event
10:29 - when the event happens we go into the
10:31 - agent and request decision so
10:32 - let's grab our agent
10:36 - and the agent class is in the normal ml
10:39 - agents
10:41 - okay we've got the standard built-in
10:42 - agent class
10:44 - and then here we just go into the agent
10:45 - and request a decision
10:48 - okay that's it the decision is taken
10:50 - care of now we need one more very
10:52 - important thing which is adding some
10:54 - rewards
10:54 - now in my match three game i have two
10:57 - goal types one is based on score and the
10:59 - other one based on destroying all the
11:00 - class in a level
11:01 - if it is score based then we can give it
11:03 - a reward every time the sum is destroyed
11:05 - just like the score
11:06 - and if it is a glass level then we give
11:07 - it a reward only every time the glass is
11:10 - destroyed
11:10 - then with regards to rewards we also
11:12 - need to handle multiple
11:14 - episodes so for the score going we can
11:15 - set a limited number of moves
11:17 - and then when the moves are over we end
11:19 - the episode and for the class the
11:21 - episode ends when the class is on gone
11:23 - okay so let's see that now again when i
11:25 - implemented my custom mastery class i
11:27 - made a whole bunch of very useful events
11:29 - so for the score i can listen to this
11:31 - event when a jam grid position is
11:32 - destroyed
11:33 - and for the glass i got this one when
11:35 - the glass is destroyed so thanks to how
11:37 - i set up this class with some really
11:38 - nice events it's going to be super
11:40 - simple to add
11:45 - so when a gem grid position is destroyed
11:47 - if it is a score goal type
11:49 - if so then just go into the agent now
11:51 - the reward same thing over here one can
11:53 - let's destroy it if it is
11:54 - then we add roar and naturally the
11:56 - rewards need to be in the same format as
11:58 - your actual play rewards
12:00 - so if you have something like a bonus
12:01 - score for matching four in a row then
12:03 - you would also apply a bonus reward for
12:04 - that
12:05 - here i'm only adding the same reward for
12:07 - every gem that is destroyed just because
12:08 - this demo is very simple
12:10 - and now if it is a glasgow we also want
12:12 - the ai to learn to destroy the glass
12:14 - in as few turns as possible so let's
12:17 - also give it a negative reward on every
12:19 - move
12:22 - so when a move is used if we are on the
12:24 - last type then we're giving it a
12:26 - negative reward
12:27 - for the score type we don't need that
12:28 - since the score will always have a fixed
12:30 - number of moves
12:31 - so that one by default it will already
12:33 - try to achieve the maximum score within
12:35 - the same moves
12:36 - so with this we have all of our rewards
12:38 - nicely designed
12:39 - the next thing is handling the episode
12:41 - end now again i also got another very
12:44 - useful event
12:45 - so this one is when out of moves so very
12:47 - simple when there are no more moves we
12:49 - just listen to that event and end the
12:50 - episode
12:52 - we just go into the agent and call and
12:55 - episode
12:56 - then in order to play all over again a
12:58 - very simple way is just to reload the
12:59 - current scene
13:04 - so here just using the standard scene
13:06 - manager to load the current scene
13:08 - so we do that when we run our moves and
13:09 - then also when we have a win which is
13:11 - going to happen on the
13:12 - last levels
13:15 - all right so that should do it again how
13:18 - easy this is to implement is going to
13:19 - depend
13:20 - on how you implemented your original
13:21 - metric class in my case i already made
13:24 - all these very useful events so adding
13:26 - this one on top was extremely easy
13:28 - now before we train we should test with
13:30 - heuristics to make sure that everything
13:32 - is indeed working
13:33 - now for handling heuristics is actually
13:35 - extremely simple the built-in match 3
13:37 - actuator already has a really nice
13:39 - toggle to force heuristics
13:40 - so to use it we just really need to take
13:42 - this and now it will be using the
13:44 - default heuristics so we should be able
13:45 - to test
13:46 - okay we can now test so just make sure
13:48 - everything is set up exalt like this
13:50 - so we made our board we implemented all
13:52 - these films are set dynamically so we
13:54 - don't need to set them in here
13:55 - then we've got our normal behavior
13:57 - parameters actually here we can
13:59 - set the space size to zero since all of
14:02 - the observations are handled by the
14:03 - sensor component
14:04 - okay everything else looks pretty good
14:06 - so we got the agent the center
14:08 - the actuator and we are forcing
14:09 - heuristics okay so we can now finally
14:11 - hit play and test
14:13 - and when you do you might see this very
14:15 - weird error
14:16 - it's something to do with the action
14:17 - mask this is a weird error related to
14:20 - how the sensor and the actuator
14:22 - initialize
14:23 - if you do see this error then a simple
14:25 - solution is just load up a different
14:27 - scene doesn't matter which one
14:28 - so just go to a different scene and go
14:30 - back into your scene
14:32 - and without touching anything if you run
14:34 - now it should be working
14:35 - and if right away everything is indeed
14:36 - working i'm not touching anything and
14:38 - the code is automatically using
14:39 - heuristics to find
14:40 - a random valid move now let's just
14:42 - verify that the level is resetting
14:44 - correctly
14:45 - so just wait until it runs out of moves
14:48 - so just one more move zero
14:50 - and if there you go as you saw it
14:52 - automatically finished level and you
14:53 - reload the current one
14:55 - all right so everything is good and we
14:56 - can now start training now for training
14:58 - again
14:59 - don't forget go up here and disable
15:01 - force heuristic
15:02 - and now let's run training normally here
15:04 - is the config file i will be using
15:06 - this is included in the official github
15:08 - repo my only change here was really just
15:10 - putting the summary frequency
15:12 - to 100 just for now just for testing and
15:14 - also changing the behavior name to match
15:16 - the one on the behavior parameters
15:17 - component
15:18 - and here's my command line
15:23 - so just use the config and run training
15:25 - again if you're not familiar with these
15:27 - commands go watch the getting start
15:28 - video
15:29 - in there i cover in detail all of this
15:31 - the config the commands and so on
15:32 - so with this we're ready to start
15:34 - training
15:37 - and there you go we're listening and yep
15:39 - training is now running so you can see
15:40 - everything is constantly going through
15:41 - the moves constantly you'll lose and so
15:43 - on
15:45 - alright so we see everything training
15:47 - everything going and we can start to see
15:48 - our results
15:56 - all right so training is working that's
15:57 - awesome now one thing though which is
15:59 - like this we're only training one
16:01 - instance of the game
16:02 - this is going to be quite a bit slow so
16:04 - ideally we always want to run training
16:06 - in parallel
16:07 - so let's do it just like it did when
16:09 - training the flippy bird agent which is
16:11 - to make a proper build and use that for
16:12 - training
16:13 - the first thing we need is to make a
16:14 - build so let's go into our build
16:16 - settings make sure you include the scene
16:18 - in the build
16:18 - then you can also set it as a server
16:20 - build which will not waste resources on
16:22 - rendering
16:23 - so just go ahead and make a regular
16:24 - build just make sure that it starts
16:26 - playing automatically
16:32 - okay i've got my standard build here we
16:33 - can even double click to make sure that
16:35 - everything is working
16:37 - and there it is running without any
16:39 - visuals okay
16:43 - so here's our command using the same
16:45 - config going into the
16:47 - environment parameter going inside of
16:48 - our path running our executable
16:50 - then for the number of environments so
16:52 - this will depend on your machine
16:54 - in my case eight is my maximum then the
16:56 - same run id and in this case resume
16:59 - again i covered training using builds in
17:01 - detail in the flappy bird video so go
17:02 - watch that if you want to learn more
17:04 - so if we just go ahead and run this and
17:06 - yep there it is we've got all of our
17:08 - instances running and yep they are all
17:10 - training
17:10 - we can verify by looking in the task
17:12 - manager and yep over here we see we have
17:14 - our command line
17:15 - with all of our eight instances all
17:18 - right so that's really it
17:19 - now our ai is indeed training with eight
17:21 - instances in parallel
17:22 - so that's left is just don't let it
17:24 - train for a little bit alright so i have
17:26 - a brain that i trained for about one
17:27 - hour and it's already very good
17:29 - here are the graphs in tensorboard so
17:31 - the one thing
17:32 - is that each brain needs to be trained
17:34 - separately so i've got a brain that was
17:36 - trained for the score goal
17:38 - and another one here that was trained
17:39 - for the glasgow so as you can see this
17:41 - one learned quite quickly actually
17:43 - and the glass ai did take a bit longer i
17:45 - trained it in total for four hours
17:48 - it had a strange crash right down the
17:49 - middle but as you can see just
17:51 - continuously
17:52 - getting improvement for the training
17:54 - scenarios like you saw the score goal
17:56 - has the unlimited number of moves they
17:57 - always got 100 moves and they try to
17:59 - reach as much score as possible
18:01 - so that is why the episode length is
18:02 - always the same because it's always 100
18:04 - moves
18:04 - and the score is constantly increasing
18:06 - and for the glass goal what i did was
18:08 - made some code to place 10 random cells
18:10 - in casing the glass
18:12 - and then also gave it a negative reward
18:14 - for every move so it learned to destroy
18:15 - as quickly as possible
18:16 - and as you can see over here on the
18:18 - episode length yeah constantly going
18:19 - down
18:20 - all right so that's the results for
18:21 - training now let's run the ai's and see
18:23 - first here is the score ai so let's see
18:25 - how much score it gets
18:29 - okay got a total of twelve thousand nine
18:31 - hundred let's run again
18:35 - okay got ten thousand five hundred
18:40 - and now it got 17 000. all right now i'm
18:43 - going to try to play myself
18:44 - so here i am let's see if i can beat it
18:50 - okay i got 8 600.
18:57 - and 6900
19:03 - and 8700 now i'm definitely not a pro
19:06 - match 3 player or anything but you can
19:08 - see how in just one hour of training the
19:10 - eye is already doing much better than me
19:12 - so now let's swap it out for the one
19:14 - with the glass brain
19:16 - here's the ai making its moves
19:21 - and it got it with 91 moves left now
19:23 - let's see how i do
19:29 - all right look at that i actually beat
19:30 - the ai on the second one and with that
19:32 - we have made an ai that use machine
19:34 - learning to play a match 3 game
19:36 - now as i mentioned in the beginning the
19:37 - huge benefit when compared with classic
19:39 - ai is that we don't need to change much
19:41 - every time we add a new feature for
19:43 - example i add an
19:44 - extra feature that causes an explosion
19:46 - whenever i match four in a row
19:48 - so here if i swap this one i'm going to
19:49 - match four in a row and all of these are
19:51 - going to explode
19:52 - so swap and if there you go all of them
19:54 - go on so with that i implement the brand
19:56 - new mechanic
19:57 - and now if i was working with classic ai
19:59 - i would have to explicitly add that new
20:01 - logic onto my bot
20:02 - however here when working with machine
20:04 - learning i really don't have to do
20:05 - anything
20:06 - all of the core components are exactly
20:08 - the same so i just have to go and run
20:09 - training some more
20:10 - and the ai will learn that if it matches
20:12 - four in a row it won't cause an
20:13 - explosion that gives it more points
20:15 - you can either run training some more
20:17 - completely from scratch or you can use
20:19 - the parameter initialize from to
20:20 - continue training from the previous
20:22 - model which will make it learn the new
20:23 - behavior very quickly
20:24 - so that's the awesome power of machine
20:26 - learning and you can see how useful it
20:28 - is when you've got a game that is in
20:29 - constant development
20:30 - alright awesome now as you saw all i
20:32 - needed to do was implement the abstract
20:34 - board and everything worked perfectly
20:36 - with my custom mastery class
20:38 - so if you have your own match 3 game
20:40 - it's very easy to implement this so go
20:41 - ahead and give it a try
20:43 - all right hope that's useful check out
20:44 - these videos to learn some more
20:46 - thanks to these awesome patreon
20:48 - supporters for making these videos
20:49 - possible
20:50 - thank you for watching and i'll see you
20:51 - next time

Cleaned transcript:

hello and welcome i'm your code monkey so a while ago i made this simple match 3 game it's got the basic design you would expect i even made a video showcasing how i made this in just under 6 hours then i also used this game as an example for how to use game simulation to play your game in the cloud and for that i created the bot using some classic ai to play the game the bot is simple and not very smart but it does work and now here let's implement some ai using machine learning to teach you how to play a match 3 game the one huge benefit of using machine learning as opposed to classic ai is that after implementing it once we can easily modify our game and add extra features without having to change much on the ai if we were to add some special skill like for example an explosion when matching four in a row then we would need to explicitly add that to the classic ai but when using machine learning we just need to run training some more so using machine learning ai is excellent for a game that is constantly updating in the end we will see how easy the ai will learn how to play after adding a new feature and making a super intelligent ai is also great for giving the player a hint when they're stuck you can just ask the ai to make a decision and then you would show that move to the player this video is sponsored by unity so i've already covered the basics for ml agents and machine learning in unity in another video go watch that one to learn how the toolkit works if you know those basics you should be able to follow everything here so we're going to implement machine learning using the official ml agents match 3 extension i'm using the game that i have here as an example but the process for adding it to any match 3 game will be very similar and quite simple thanks to how the extension is set up as long as you have some events and some simple functions in your match 3 class then this will work with any kind of game you really just need to write one script which handles the connection between your custom match 3 scripts any match during the extensions and everything works you can get the official match 3 extension from the ml legends github repo there's a link in the description to install the extensions you can open up the package manager click on the plus icon to add a package from git and then you paste in the link that you see on the documentation okay so in those extensions you have essentially three elements that make it up you have a board a actuator and a sensor the only one that we really need to work with is just the board this is an abstract class that we're going to implement naturally this represents the board or the play area and it contains the number of rows and columns as well as the number of cell types and any special types that your game has then we just have a whole bunch of functions that we're going to need to implement which is how we interact with the board so this is the only class that we're going to need to interact with then we have the sensor and actuator both those have two classes so you have the class that actually implements the logic and then also the components which is what you attach into your game objects which in turn all they do is construct the actual underlying class the sensor is what generates observations for the ai based on the state of the board and the actuator is what takes actions on the board and finally you also have a move which is just a simple struct so it represents an ingame move where you swap a position towards a certain direction so for example swap the cell on zero zero with direction on right to swap with one zero so as i said all you really need to worry about is just implementing the abstract board everything else just interacts with that one so let's do just that over here on my scripts folder i'm going to create a new c sharp script name this my match 3 ml agents board and create a new game object to run it so just attach it and let's open so as i said this class will connect the machine learning side with your match 3 class so let's begin by just adding a field for that one so in my case my main one is called just match three and in this case i'm going to make it as a serialized field so i can easily set it in the editor so here in the editor i've got the field and just drag it on there okay now here we're going to add our using so we're going to add using unity.mlagents.extensions.match3 and instead of extending just modern behavior we're going to extend our abstract board okay now we need to implement all of this you can use visual studio to really help you out so just implement the abstract class so just with this default implementation let's just hit save and go back into the editor okay the code compiles and now we can see the public fields on the abstract board so we've got the rows columns special types and cell types so these are poly films so if you want you can set them directly over here in the editor or in my case the way that i set up my mastery game is all of that data is on a scriptable object so i'm going to grab it and set it directly in my code by the way if you find the video helpful please hit the like button it's a tiny thing but it really does help thanks so in my particular implementation i have this simple scriptable object that defines every single level and in there i've got a list of all the gem types that are possible as well as the width and height and so on again depending on how you set up your match 3 game this is going to be different but it's going to be roughly the same thing so in here i just make a private void awake and on awake i'm going to set all those fields so first up these the columns which in my case i named it width and height next up is the cell types this is the number of colors or shapes that you have in your level so in my case each level object has a list of all the gems and then the final thing you need to set is the number of special types so for example if you've got some special gems that cause some explosions or destruction online or something so anything that is different from the base cell types that's what you would input in here in my case i made two different level types so one of them is hitting the score and the other one is destroying some class nodes so for my normal score type i don't have any special types and on my glass levels i do have the glass as a special cell type so in my case if my level is of type score so there's nothing special so i just have a zero and if not then it's going to be a glass level so it is going to be one on the special type again if you have multiple special types then obviously you would put a different number okay so that's the basics we just set up all of our public fields now down here we see all the functions that we actually need to implement and if you want some help on how these should be implemented you can just go into the main abstract board class and over here you've got tons of comments to tell you exactly what each of them should do so for example over here on the get cell type this one returns the color or shape or whatever type of the piece at a given row and cone so this will be an int that will be between zero and the number of types that you gave so for example if you've got a match three with let's say just squares and circles then you would put on the number of cell types you would put two so you got squares and circles two types and in here if it was a square then you would return zero and if it was a circle you'd return one so you convert your types into simple integer values so over here the way that i implemented things so i asked my custom match free class to give me the gem type and then i simply return an integer that refers to that gem type okay that's pretty much it for the get sound type then for the special type as it says here this is pretty much exactly the same thing but regarding special types so in my case the only special type is if it is in case in class or not so in my case i can ask my class if a specific position is in case in the last if so return one if not return zero next up for the is move valid so this one checks if a particular move is valid for the game meaning that it tests if this move would result in a match if so it is valid and can be swapped and you can inspect the struct on the move to see how it is set up so you've got essentially a row and cone then you've got a direction for the swap so for example zero zero swapping to the right and you would test that so again i'm going to implement it in my particular case okay so in my match 3 class i've got a function to ask if two grid positions can be swapped so we start x and y compared with an n x and y that's if that can be swapped so i go into the move and the move also has a really nice function that returns the other cell so again for example if the move was zero zero swap to the right then calling other cell would give you the position one zero so just ask that do that and there you go that one is implement and finally we have the make move function so this one is supposed to actually make the move so you can see over here on the abstract it instructs the game to make the actual given move and then returns through if the move was made however look at this note which is that during training a move that was invalid may still be requested so if it happens you need to handle that so let's implement this all right so that's it pretty much the same logic as for asking if the move is valid and if it is then i can do this move so i just swap those positions if not then i can do it okay so that's pretty much it with this we have our abstract board fully implemented so now this class acts as a link between the builtin sensor and actuator and our custom mastery class so speaking of that let's add those two over here on our ml agents we currently have our board now in order to run machine learning we need an agent so let's add the standard just search for the agent component and there you go there's the standard agent and it automatically adds the behavior parameters so here give it a name so just just something like match three agent then we're also going to add the builtin components so let's add the match 3 sensor component and also the actuator so match 3 actuator component again these are from the official extensions we didn't touch these at all and now this sensor and this actuator is going to work in conjunction with the agent and all of them are going to tall to our custom match three board which in turn interfaces with the rest of our code with our custom classes alright so we're almost ready for training one more thing is needed for the agent which is to request a decision now usually we would add here the decision requester script so this one is great for constantly requesting decisions however this game is turn based so we should manually request decisions the way the game works is the board is ready and it waits for the player to make a move then the algorithm looks for all the matches spawns some more gems and finally goes back to waiting for the player so we only want to take an action and request a decision when the board is on that state so in my case i have a class that fires off some events so when it is waiting for the user so let's listen to this event to request a decision so just go there and subscribe to that event when the event happens we go into the agent and request decision so let's grab our agent and the agent class is in the normal ml agents okay we've got the standard builtin agent class and then here we just go into the agent and request a decision okay that's it the decision is taken care of now we need one more very important thing which is adding some rewards now in my match three game i have two goal types one is based on score and the other one based on destroying all the class in a level if it is score based then we can give it a reward every time the sum is destroyed just like the score and if it is a glass level then we give it a reward only every time the glass is destroyed then with regards to rewards we also need to handle multiple episodes so for the score going we can set a limited number of moves and then when the moves are over we end the episode and for the class the episode ends when the class is on gone okay so let's see that now again when i implemented my custom mastery class i made a whole bunch of very useful events so for the score i can listen to this event when a jam grid position is destroyed and for the glass i got this one when the glass is destroyed so thanks to how i set up this class with some really nice events it's going to be super simple to add so when a gem grid position is destroyed if it is a score goal type if so then just go into the agent now the reward same thing over here one can let's destroy it if it is then we add roar and naturally the rewards need to be in the same format as your actual play rewards so if you have something like a bonus score for matching four in a row then you would also apply a bonus reward for that here i'm only adding the same reward for every gem that is destroyed just because this demo is very simple and now if it is a glasgow we also want the ai to learn to destroy the glass in as few turns as possible so let's also give it a negative reward on every move so when a move is used if we are on the last type then we're giving it a negative reward for the score type we don't need that since the score will always have a fixed number of moves so that one by default it will already try to achieve the maximum score within the same moves so with this we have all of our rewards nicely designed the next thing is handling the episode end now again i also got another very useful event so this one is when out of moves so very simple when there are no more moves we just listen to that event and end the episode we just go into the agent and call and episode then in order to play all over again a very simple way is just to reload the current scene so here just using the standard scene manager to load the current scene so we do that when we run our moves and then also when we have a win which is going to happen on the last levels all right so that should do it again how easy this is to implement is going to depend on how you implemented your original metric class in my case i already made all these very useful events so adding this one on top was extremely easy now before we train we should test with heuristics to make sure that everything is indeed working now for handling heuristics is actually extremely simple the builtin match 3 actuator already has a really nice toggle to force heuristics so to use it we just really need to take this and now it will be using the default heuristics so we should be able to test okay we can now test so just make sure everything is set up exalt like this so we made our board we implemented all these films are set dynamically so we don't need to set them in here then we've got our normal behavior parameters actually here we can set the space size to zero since all of the observations are handled by the sensor component okay everything else looks pretty good so we got the agent the center the actuator and we are forcing heuristics okay so we can now finally hit play and test and when you do you might see this very weird error it's something to do with the action mask this is a weird error related to how the sensor and the actuator initialize if you do see this error then a simple solution is just load up a different scene doesn't matter which one so just go to a different scene and go back into your scene and without touching anything if you run now it should be working and if right away everything is indeed working i'm not touching anything and the code is automatically using heuristics to find a random valid move now let's just verify that the level is resetting correctly so just wait until it runs out of moves so just one more move zero and if there you go as you saw it automatically finished level and you reload the current one all right so everything is good and we can now start training now for training again don't forget go up here and disable force heuristic and now let's run training normally here is the config file i will be using this is included in the official github repo my only change here was really just putting the summary frequency to 100 just for now just for testing and also changing the behavior name to match the one on the behavior parameters component and here's my command line so just use the config and run training again if you're not familiar with these commands go watch the getting start video in there i cover in detail all of this the config the commands and so on so with this we're ready to start training and there you go we're listening and yep training is now running so you can see everything is constantly going through the moves constantly you'll lose and so on alright so we see everything training everything going and we can start to see our results all right so training is working that's awesome now one thing though which is like this we're only training one instance of the game this is going to be quite a bit slow so ideally we always want to run training in parallel so let's do it just like it did when training the flippy bird agent which is to make a proper build and use that for training the first thing we need is to make a build so let's go into our build settings make sure you include the scene in the build then you can also set it as a server build which will not waste resources on rendering so just go ahead and make a regular build just make sure that it starts playing automatically okay i've got my standard build here we can even double click to make sure that everything is working and there it is running without any visuals okay so here's our command using the same config going into the environment parameter going inside of our path running our executable then for the number of environments so this will depend on your machine in my case eight is my maximum then the same run id and in this case resume again i covered training using builds in detail in the flappy bird video so go watch that if you want to learn more so if we just go ahead and run this and yep there it is we've got all of our instances running and yep they are all training we can verify by looking in the task manager and yep over here we see we have our command line with all of our eight instances all right so that's really it now our ai is indeed training with eight instances in parallel so that's left is just don't let it train for a little bit alright so i have a brain that i trained for about one hour and it's already very good here are the graphs in tensorboard so the one thing is that each brain needs to be trained separately so i've got a brain that was trained for the score goal and another one here that was trained for the glasgow so as you can see this one learned quite quickly actually and the glass ai did take a bit longer i trained it in total for four hours it had a strange crash right down the middle but as you can see just continuously getting improvement for the training scenarios like you saw the score goal has the unlimited number of moves they always got 100 moves and they try to reach as much score as possible so that is why the episode length is always the same because it's always 100 moves and the score is constantly increasing and for the glass goal what i did was made some code to place 10 random cells in casing the glass and then also gave it a negative reward for every move so it learned to destroy as quickly as possible and as you can see over here on the episode length yeah constantly going down all right so that's the results for training now let's run the ai's and see first here is the score ai so let's see how much score it gets okay got a total of twelve thousand nine hundred let's run again okay got ten thousand five hundred and now it got 17 000. all right now i'm going to try to play myself so here i am let's see if i can beat it okay i got 8 600. and 6900 and 8700 now i'm definitely not a pro match 3 player or anything but you can see how in just one hour of training the eye is already doing much better than me so now let's swap it out for the one with the glass brain here's the ai making its moves and it got it with 91 moves left now let's see how i do all right look at that i actually beat the ai on the second one and with that we have made an ai that use machine learning to play a match 3 game now as i mentioned in the beginning the huge benefit when compared with classic ai is that we don't need to change much every time we add a new feature for example i add an extra feature that causes an explosion whenever i match four in a row so here if i swap this one i'm going to match four in a row and all of these are going to explode so swap and if there you go all of them go on so with that i implement the brand new mechanic and now if i was working with classic ai i would have to explicitly add that new logic onto my bot however here when working with machine learning i really don't have to do anything all of the core components are exactly the same so i just have to go and run training some more and the ai will learn that if it matches four in a row it won't cause an explosion that gives it more points you can either run training some more completely from scratch or you can use the parameter initialize from to continue training from the previous model which will make it learn the new behavior very quickly so that's the awesome power of machine learning and you can see how useful it is when you've got a game that is in constant development alright awesome now as you saw all i needed to do was implement the abstract board and everything worked perfectly with my custom mastery class so if you have your own match 3 game it's very easy to implement this so go ahead and give it a try all right hope that's useful check out these videos to learn some more thanks to these awesome patreon supporters for making these videos possible thank you for watching and i'll see you next time
