00:00 - hey you in this video we are going to be
00:03 - doing web scraping with Python using
00:07 - libraries like beautifulsoup and request
00:11 - this is something that is very useful
00:14 - whether you are a beginner or a
00:17 - professional developer these are
00:19 - essential skills that almost every
00:22 - person needs so let's get started it's
00:25 - gonna be a fun little project and this
00:27 - was inspired by data quest io it's not a
00:30 - sponsored video or anything but I looked
00:32 - at one of their tutorials and they're
00:33 - doing a weather forecast I was like hey
00:35 - we should also just do that weather
00:38 - forecast except we're gonna be doing it
00:41 - for a lake that's where I live so we're
00:44 - gonna go to forecast dot weather.gov so
00:48 - that's number one let me zoom in here so
00:50 - you guys can see very clearly and I'm
00:52 - gonna type in Los Angeles will hit go
00:56 - and this is what pops up so what we're
00:59 - trying to do here is we want to pull
01:01 - this data that we want to put it into an
01:03 - Excel spreadsheet we you could also put
01:06 - it in pandas dataframe if you know what
01:08 - that is but most people know what an
01:10 - Excel spreadsheet is or what a CSV file
01:13 - is so that's essentially what we're
01:15 - going to be doing and we're gonna be
01:17 - doing web scraping here it's a pretty
01:19 - cool thing to learn how to do so let's
01:21 - jump right into it first of all for
01:23 - really basic stuff you know you have to
01:25 - know basic HTML we're not gonna cover
01:27 - too much of HTML or CSS in this video
01:31 - but you know for example if I write an
01:34 - h2 tag I have a code pen open here so I
01:37 - can just show how HTML works if I do h2
01:40 - and I say hey guys like that him I do
01:43 - this it'll type in hey guys knife I do
01:46 - h6 tag right it'll make it smaller so
01:51 - these are H a.m. this is HTML
01:53 - this is basics very very basic basic use
01:57 - of it and now what we're gonna do is
01:59 - because I'm on Chrome
02:01 - we're gonna hit inspect here and dive
02:03 - deep using the chrome dev tools it's a
02:06 - very powerful way to learn the structure
02:08 - of the website that you want to scrape
02:11 - you want to abuse this tool
02:14 - okay use this tool a lot the chrome dev
02:16 - tools so now I'm gonna hover over and
02:18 - essentially what I want to do is I want
02:20 - to be able to get this week's forecast
02:22 - so I want to be able to find out what
02:25 - the weather is tonight Sunday Sunday
02:27 - night Monday and you know I also want to
02:30 - get the descriptions of it and I want to
02:32 - get what's the low and what's the high
02:35 - be able to put it in my Excel
02:37 - spreadsheet so let's do it so first of
02:41 - all I want you to click this button over
02:43 - here okay
02:43 - the shortcut for this is command shift C
02:46 - on a Mac or you can just come over here
02:48 - click this allows you to highlight over
02:51 - each thing and then it tells you what
02:54 - element it is of HTML or CSS file so he
02:59 - goes okay this is an image element as
03:01 - you can see it says I am g dot you know
03:04 - something so that dot pull left is a CSV
03:08 - clasp or sorry CSS class so let's go
03:11 - over here and check this out so it looks
03:15 - like we have a container here but this
03:18 - has an ID we have a div here and this
03:20 - has the ID of seven-day forecast body
03:25 - which is very good which is exactly what
03:28 - we need to leverage here so let's go
03:30 - ahead and use this because we know that
03:33 - once we have access to this we will have
03:36 - access to essentially everything else
03:38 - that's within this div so let's go to
03:42 - our code now you're gonna need a few
03:45 - modules installed and I'm not gonna walk
03:48 - through the full process of installing
03:50 - them because again those could turn into
03:53 - their own videos so let's go here and
03:57 - first of all we you need to install pip
04:00 - install beautiful soup 4 so that's step
04:06 - one another thing you're gonna need is
04:08 - pip install requests that's how you're
04:10 - gonna make HTTP requests to the websites
04:12 - and then you want to install the last
04:16 - one which is pandas all right because
04:19 - I've already installed them for me it
04:21 - says requirement already satisfied for
04:24 - you it's gonna take you through the
04:25 - installation process if you run into
04:27 - errors with installation process look up
04:30 - how to overcome them then once you solve
04:32 - it come back to this tutorial so once
04:35 - this is installed let's start writing
04:36 - some code so first of all we're gonna do
04:38 - important requests and I'm gonna also
04:41 - say from bs4 import beautiful soup like
04:46 - that alright and now essentially what I
04:49 - want to do is request this URL so I'm
04:53 - just gonna copy this URL right here I'll
04:56 - go here and I'll say this page is equal
05:00 - to request dot get and then I'll pop in
05:05 - that URL right there we'll also create a
05:08 - soup object out of that page so that
05:11 - requests thing that we just got we're
05:14 - gonna use that to create a beautiful
05:16 - soup object and what's beautiful soup
05:17 - allows you to do is makes the web
05:20 - scraping of the page really really easy
05:22 - it gives you nice structures it's able
05:25 - to find classes it's able to find
05:28 - paragraph tags it's able to find headers
05:31 - and it understands CSS and it
05:34 - understands HTML so it makes your life a
05:36 - lot easier that's why we're using
05:38 - beautifulsoup
05:39 - so let's go here in soup and go
05:41 - beautiful soup alright and we'll say
05:47 - page dot content and then we will say
05:52 - and we'll give it HTML parser okay so
05:55 - it'll note that it's HTML and so it
05:58 - needs to parse it as an HTML page
06:01 - alright and if I print this we should
06:06 - see something pretty weird so I'm gonna
06:09 - run this piece of code I'm gonna go here
06:11 - hit run all right so it says couldn't
06:16 - find a tree builder the features you
06:17 - requested HTML parser do you need to
06:19 - install a parser library Oh yep HTML dot
06:29 - parser not a - parser so we have now
06:35 - let's try it again
06:36 - we will run the code ok so looks like it
06:40 - worked and as you can see the soup
06:43 - object is all of the HTML code that's on
06:47 - that page it's pretty much the source
06:49 - code of that page so if I go and I
06:53 - right-click and I go I go view page
06:56 - source it's essentially this whole thing
07:02 - alright so it has access to all of it
07:05 - but what's cool is that I can do things
07:07 - like that find all and I can go find all
07:12 - of like the a tags you know find all a
07:15 - tags for example and if I run it it's
07:19 - essentially finding all of the links so
07:21 - it's finding the n-o a a.gov link that's
07:25 - there it's finding the weather.gov link
07:30 - that's on that page it's finding the
07:31 - Commerce gov link that's on that page so
07:36 - these all these links is able to find
07:39 - them right if I do not find images or if
07:43 - I do not find all you know short
07:47 - descriptions it'll find those as well so
07:51 - that's what's cool about beautiful soup
07:54 - makes your life really easy so let's go
07:56 - ahead and what we're gonna do is we're
07:58 - gonna create a variable that has this
08:04 - entire div stored inside of it that way
08:07 - we'll have access to this this div is
08:09 - what I'm talking about we'll have access
08:10 - to that div at all times so let's go to
08:13 - our code here and I'll say week is equal
08:19 - to soup dot find and we'll give it the
08:22 - ID in the ID what is the ID here the ID
08:26 - is seven-day forecast body so because I
08:30 - don't want to make a mistake I'm gonna
08:32 - click here
08:32 - once I click here you can see at the
08:34 - bottom it's highlighted this line I'll
08:37 - go to the ID
08:38 - and I'll double-click I will copy this
08:41 - I'll come back in here paste it so I'll
08:44 - make sure that this way there are no
08:46 - spelling errors as a programmer I know
08:50 - sometimes you want to do things quick
08:51 - and just type it out but the reason why
08:54 - you want to paste is not so you're
08:55 - faster but the real reason why you want
08:58 - to copy paste as much as you can is so
09:01 - you're accurate and you don't make
09:02 - mistakes that's why I took the time to
09:05 - copy it even if it was small like it was
09:08 - three letters I would still copy and
09:10 - paste because it has happened to me so
09:12 - many times that I'll make like a tiny
09:14 - little mistake like the one I made up
09:16 - here with HTML dot parser where I wrote
09:18 - a - here alright so we have this access
09:27 - to this week let's first of all print it
09:29 - out let's see what it shows us so we'll
09:32 - run our code alright so basically now
09:36 - what it's doing is showing us everything
09:39 - that's inside of that div that's all
09:43 - it's doing that's all it's showing us
09:45 - okay now it's not showing us the entire
09:48 - HTML page anymore it's just showing us
09:50 - that that's all we want anyways we need
09:52 - we just need access to that one div so
09:55 - what do we do next well now what we want
09:58 - to do is we want to access all of those
10:00 - objects or items whatever you want to
10:02 - call it we'll just call them items so
10:05 - I'm calling so I'm calling I this item
10:09 - number one what I'm highlighting here
10:11 - this is gonna be item number two this is
10:13 - gonna be item number three item for item
10:15 - five six seven eight nine you get the
10:18 - idea okay so if you notice each of the
10:24 - each of these is a list item okay so in
10:31 - HTML a list item has a tag of Li and an
10:35 - unordered list item has a tag of UL so
10:40 - you can see it says li here and how we
10:44 - can access all of these by either using
10:46 - the tag li or we can use the class four
10:52 - last tombstone so let's say week dot
10:57 - find all and let's just try Li and let's
11:02 - see what it gives us maybe we'll run
11:05 - into an error maybe we won't let's find
11:08 - out so when I hit Li actually let's
11:12 - comment this line out all right so when
11:18 - I hit a lie I get a lot of things okay
11:23 - and now let's actually do instead of a
11:27 - lie what we'll do is we'll say that find
11:30 - all and we'll say look for a class
11:33 - instead of that Li tag so we're gonna go
11:35 - class and the tricky thing in
11:38 - beautifulsoup is you can't just say the
11:40 - argument s class because that's means
11:42 - something special in Python so you get a
11:44 - new class underscore like that so your
11:48 - class is equal to and then we'll say
11:52 - tombstone actually we'll copy it so we
11:56 - don't make a mistake
11:57 - so I'll click here and I'll go forecast
12:00 - tombstone and we'll paste it just like
12:02 - that all right
12:09 - actually maybe that there's a better
12:12 - thing that we can do so let's go alright
12:20 - so we have a div actually that contains
12:23 - all of these items I miss this div so
12:27 - this div actually contains it's a
12:29 - tombstone container so it actually
12:32 - contains the the blue part is what it
12:37 - contains right so you can see that it
12:38 - contains the where it says Sunday it
12:41 - also contains the image it also looks
12:43 - like it contains the description where
12:45 - it says chance showers and it also
12:47 - contains the temperature whether it's a
12:50 - low or a high
12:52 - so let's actually access the tombstone
12:54 - container class all right so we're gonna
12:58 - go class and instead we're gonna say
13:01 - we're gonna go tombstone container if it
13:04 - lets me highlight it it's kind of tricky
13:05 - to highlight
13:06 - it's pretty secret well let's just click
13:11 - here and then let's dig a little deeper
13:15 - and this is the tombstone container
13:18 - right there so we're gonna say get all
13:21 - of those guys okay and we're gonna say
13:30 - get all of those guys okay so let's go
13:33 - boom boom do that and close this out and
13:43 - this we will call items okay
13:50 - this will call items and then we'll also
13:55 - print items so let's run this code now
13:58 - all right so you can see we have a list
14:01 - and each item in that list is
14:05 - essentially one tombstone container so
14:13 - let's say that I get item zero in that
14:16 - list the first item index it by zero I
14:19 - get one tombstone container so what is
14:24 - that it has the period name which is
14:27 - tonight if I go here you can see it
14:30 - right there it says tonight the next
14:32 - thing I should see is this if I hover
14:35 - over here this is the notice the
14:38 - paragraph tag and the CSS class here is
14:41 - period name so when I go here I see
14:44 - class period name is tonight when I go
14:49 - here the class here is short description
14:51 - short - des C and it should say slight
14:55 - chance showers and when I go to my code
15:00 - here so this is the image alt tag let's
15:03 - ignore that let's look for the thing
15:08 - that we're searching for the short
15:09 - description one alright so the short
15:12 - description here says slight chance
15:14 - right that's what we were looking for
15:17 - and slight chance showers
15:20 - and then we also have the temperature
15:23 - class all right which is this one right
15:28 - over here so that's that's what each
15:33 - item is right so each item in that list
15:35 - will give you man it's been kind of
15:39 - annoying because you cancel it's hard to
15:41 - select that
15:42 - but each item is essentially that
15:44 - tombstone container class this guy right
15:47 - over here
15:51 - okay tombstone container boom boom
15:56 - tombstone container the second one all
15:59 - right so now that we have that what
16:01 - we're gonna do is now we'll find what we
16:06 - want to do is get all of the period
16:10 - names so where it's us tonight where
16:12 - it's a Sunday Sunday night we want to
16:14 - get all of those period names and be
16:16 - able to put it in one column then we
16:20 - want to be able to take all of the short
16:23 - descriptions and put it in a description
16:26 - column and lastly we want to be able to
16:29 - take all of the temperatures and put
16:32 - them in a temperature column so each of
16:35 - them is gonna have their own columns so
16:39 - let's go ahead and do that so what I
16:43 - will do here is I'll say for items 0
16:50 - let's first of all just get that items
16:54 - period name so I'll do class equals I
17:02 - remember the class name was period so
17:05 - I'm gonna just put that and first of all
17:09 - let's just print this guy and let's see
17:11 - what we get we will comment this out so
17:16 - when I print this out I get back this P
17:19 - tag but what I really want is the text
17:22 - the text that's in between the tags so
17:26 - what I can actually do is because it's a
17:28 - beautiful soup object I can just go and
17:32 - do get tagged
17:34 - like that and run this and when I run it
17:37 - gives me the text that says tonight now
17:40 - I can copy this line paste it and
17:43 - essentially just go and change the class
17:45 - name here to the next class which is
17:48 - short description so I'll do short
17:53 - description like that and get its class
17:55 - I'll run it and now it should said
17:57 - tonight and slight chance showers which
18:00 - is what it says right there and then
18:03 - last thing I want is temp so I'm just
18:06 - gonna call it by the temp class not temp
18:08 - low because this is temp hi this is temp
18:10 - high so we're just gonna get by the more
18:13 - general name so it works for every
18:15 - single tombstone container and we'll go
18:20 - here and we will simply say temperature
18:24 - like that and when I run it you will see
18:27 - that I get back those three things so
18:30 - now that I'm able to access all of those
18:32 - three things from the first tombstone
18:34 - container now it's very simple I just
18:37 - have to collect all of them in a list
18:43 - and then just run a for loop right to be
18:50 - able to access any of them so let's just
18:53 - go ahead and put them on all oh sorry
18:57 - it's already in the items list so items
19:01 - list already has them right now I'm only
19:03 - accessing the zeroth one which is in
19:06 - human language the first one now all I
19:09 - need to do is write a for loop that goes
19:11 - through all of all of those items what
19:17 - we're gonna use is list comprehension
19:20 - because that's cool so here's what I'm
19:24 - gonna demonstrate period underscore
19:26 - names is equal to and I'm gonna say item
19:30 - for item in items except what I want to
19:38 - do to this item is I want to not find
19:41 - its class and make sure that the class
19:45 - says period
19:47 - and then I also want to get its text
19:51 - alright so I'm gonna find oh you made a
19:57 - mistake here just didn't write the equal
19:59 - sign that should work now alright so
20:02 - this is a list comprehension that
20:06 - essentially says hey for each item in
20:10 - items as you loop through it just do
20:13 - this to it and I'll essentially get me
20:16 - back the period name now what I'll do is
20:18 - I'll print period names so you can see
20:21 - what it is it's right here this line and
20:25 - right all it did was loop through and
20:28 - just collect period names that's what we
20:30 - want okay so that's done now the second
20:36 - one we're gonna write is gonna be short
20:40 - description so we'll do short
20:41 - descriptions and we're gonna say item
20:47 - dot fine
20:48 - so it's essentially gonna be the same
20:50 - thing right so what I can do is I can
20:52 - just copy this guy come over here and
20:55 - paste it paste it move it up and then
21:04 - about a Bambaataa boom and we'll come
21:08 - here and instead of that we'll say a
21:10 - short description and then I'll copy
21:12 - paste this and I'll come here and I'll
21:15 - say temperature and I'll change this to
21:19 - temperatures all right so all of these
21:24 - now get us everything that we want I'll
21:27 - print these out as well for you so you
21:30 - can see what's going on all right
21:36 - I'll run this and you can see now we
21:38 - have three lists with what we want and
21:41 - that's exactly what we needed and now
21:45 - I'm gonna show you something really cool
21:47 - initially what my instinct was was to
21:51 - write it to a CSV file well you have to
21:54 - do a little bit of coding for that it
21:56 - takes some time it takes some stack
21:57 - overflowing it's kind of obnoxious there
22:00 - is a beautifully elegant and easy way to
22:04 - actually write this to a CSV file and
22:07 - also to do data analytics with it using
22:10 - pandas so let's use pandas here and it
22:14 - makes it so easy to turn this data into
22:16 - a table that you can then actually use
22:19 - manipulate and do stuff with so let's do
22:22 - that let's go up at the top and remember
22:25 - at the start I told you install pandas
22:27 - so now what we're gonna do is we're
22:29 - gonna go here and install pandas I
22:32 - believe P becomes before R so let's do
22:36 - it like this
22:37 - pandas as PD and now what we're gonna
22:41 - say is we're gonna say weather stuff is
22:44 - equal to pandas dot data frame and what
22:50 - data frame takes is actually a
22:52 - dictionary right and we are going to say
22:59 - period so the column is gonna be called
23:02 - period and the values of it are gonna be
23:05 - period names so it's gonna be this list
23:08 - that we made here and then the idea is
23:11 - essentially the same we're just gonna
23:13 - repeat that same process and we're gonna
23:15 - say the next one is gonna be short
23:18 - descriptions are just going to be open
23:24 - comma goes here gonna be short
23:26 - descriptions okay and then lastly we
23:31 - have temperatures which are just going
23:36 - to be temperatures oops comma make sure
23:41 - you have all the commas in the right
23:42 - place all right that is essentially the
23:47 - dictionary
23:54 - that's a much better way to actually
23:56 - write the dictionary so yeah that's the
23:59 - dictionary we got our data frame we put
24:03 - our column names these are the values
24:07 - that go in that column so that entire
24:10 - list is just gonna go there the entire
24:13 - list of short descriptions is gonna go
24:15 - under the short descriptions column the
24:17 - entire list of temperatures is gonna go
24:20 - under the temperatures column and one
24:21 - little trick I'm going to show you guys
24:22 - is you can put a comma here it won't
24:24 - give you a syntax error and it's just a
24:26 - good habit to get into because then when
24:28 - if you ever go back to that dictionary
24:30 - add more things you'll never run into an
24:32 - error so just a good code hygiene and if
24:37 - we print this out now let's see what
24:40 - this might look like so let's print this
24:42 - out so you can see that pandas actually
24:45 - turns us into a really I'll comments all
24:48 - the other print statements out now
24:49 - because we don't need them anymore and
24:54 - you can see what it does is it turns it
24:56 - into this beautiful looking table which
24:59 - you can now take a look at and do stuff
25:01 - with and you know figure out the means
25:04 - and figure out the averages and all that
25:06 - kind of nerdy stuff but we're not gonna
25:09 - get too much into that because that will
25:10 - be a whole nother video with pandas our
25:13 - job is not to use do that we are just
25:17 - learning how to do web scraping and to
25:19 - make this data useful the last cool
25:21 - thing I want to show you that makes it
25:23 - all super useful really handy trick is
25:26 - this awesome feature that panda has so I
25:29 - can just do weather stuff dot to
25:32 - underscore CSV all right it has this
25:37 - beautiful thing you can do which is just
25:42 - called dot to CSV and then just give it
25:46 - a CSV name so we're gonna call it let's
25:49 - call it weather dot CSV and I'm gonna
25:53 - save I'm gonna run this and right when I
25:56 - run it I get the CSV file over here
25:59 - which looks like this but let's take a
26:01 - look at what it looks like in our
26:02 - computer so we will go here
26:06 - and I will hit that and boom look at
26:13 - that it's looking super nice super fresh
26:16 - and you can see the entire data table
26:19 - right there I can also open it up in
26:22 - Excel if I want to let's zoom in a
26:26 - little bit so you can see it right and
26:32 - you can see we have our column called
26:35 - period with all of this data we have
26:38 - short descriptions with all of this data
26:39 - temperatures all of this data so that's
26:42 - so freaking cool right we just created a
26:44 - CSV file from scraping the internet
26:48 - scraping something online now you can
26:51 - just take that URL and pop something
26:53 - else in and they'll also work so for
26:55 - example forget Los Angeles weather maybe
27:01 - we can look at the weather of say
27:03 - Chicago so let's type in Chicago here
27:07 - and we will hit go hazardous weather
27:12 - outlook Wow wind advisory in effect so
27:16 - that's pretty scary huh so let's go
27:21 - let's copy this and for you it might
27:25 - look different right because you might
27:26 - be doing this video at following
27:28 - tutorial at another time so I'm gonna go
27:30 - here I'm gonna paste the new URL alright
27:39 - i pasted the new URL here and now let's
27:45 - run this code and we're gonna go take a
27:48 - look at our csv file now don't save and
27:55 - view will be three hundred percent and
28:01 - take a look at this now the data is
28:05 - completely different
28:06 - right now it's the Chicago's temperature
28:10 - so if you were making a web app you
28:12 - could use web scraping to use somebody
28:16 - else's website to dynamically generate
28:18 - stuff on your
28:20 - on website pretty powerful stuff all
28:25 - right hopefully you have enjoyed this
28:27 - tutorial that is all I had for you today
28:29 - but I do want to say that we have
28:30 - something very special coming up so
28:32 - again if you are a beginner or you are a
28:36 - working professional developer we have a
28:40 - new program coming out for you called
28:42 - how to automate stuff with Python so
28:45 - whether you're looking to land your
28:46 - first job and ace your interview or you
28:50 - are looking to get promoted at your
28:51 - current job or maybe you're trying to
28:53 - become a freelancer who kicks ass this
28:57 - brand new course will give you all of
28:59 - the essential skills that you need to
29:01 - make that happen this is something new
29:04 - that we're working on is gonna be coming
29:06 - out soon but in the description below we
29:10 - have the link to the page for the course
29:13 - how to automate stuff with Python and it
29:16 - will go deep dive into these things and
29:19 - much more all you need to do is just pop
29:21 - in your email below I will also send you
29:24 - a free gift once you put in your email
29:27 - below as well as once the course is out
29:30 - you will be the first one to know so go
29:33 - ahead pop it in your email below thank
29:36 - you so much for watching this video if
29:38 - you liked the video give it a like if
29:41 - you enjoyed this and you want to keep
29:43 - seeing the new tutorials that are gonna
29:45 - be coming out and make sure you
29:47 - subscribe to the channel with that said
29:49 - thank you so much for watching as always
29:51 - this is Kazi I love your face and I'll
29:55 - see you in the next video
30:01 - [Music]
30:07 - [Music]
30:15 - [Music]