00:00 - In our previous lesson, we talked about
level order traversal of binary tree
00:04 - which is basically breadth-first
traversal. Now in this lesson we are
00:08 - going to discuss
00:09 - these three depth-first algorithms
pre-order,
00:12 - in-order and postorder. I have drawn a
binary tree here
00:16 - datatype filled in the nodes is
character now as we had discussed in
00:20 - earlier lessons,
00:21 - in depth-first traversal of binary tree
if we go in one direction
00:26 - then we visit all the nodes in that
direction or in other words
00:30 - we visit the complete sub-tree in that direction
00:33 - and then only we go in other direction.
In this example tree that i have drawn here
00:38 - if I'm at 'root' and I'm going left
00:42 - then I'll visit all the nodes in this
left subtree
00:45 - and then only I can go right and once
again
00:49 - when I'll go right I'll visit all the nodes in
this right subtree
00:53 - if you can see in this approach we are
reducing the problem in a
00:56 - self-similar
00:57 - or recursive mannner, we can say that in total
01:00 - visiting all the nodes in the tree is
visiting the 'root' node
01:04 - visiting the left subtree and visiting
the right subtree
01:08 - remember by visiting a node we mean
reading or processing the data in that node
01:12 - and by visiting
01:14 - a subtree we mean visiting all the
nodes in the subtree
01:18 - in-depth first strategy relative order of
visiting the left subtree, right subtree
01:23 - and the root
01:24 - can be different, for example we can
first visit the right subtree
01:28 - then the root and then the left subtree
or we can first visit
01:32 - the root and then left subtree and
then the right subtree
01:35 - conventionally left subtree is always
visited before right subtree
01:39 - we this constraint we will have three
permutations, we can first visit the root
01:44 - and then the left subtree and then the
right subtree and such a traversal will
01:48 - be called
01:49 - preorder traversal or we can first
visit the left subtree
01:53 - then the root and then the right
subtree and such a traversal will be
01:57 - called
01:57 - in-order traversal and we can also go
02:00 - left-right and then root and such a
traversal will be called
02:04 - post order traversal, left and right
subtree will be visited recursively
02:09 - in same manner as the original tree, so
in pre-order
02:13 - once again for the subtrees we will go
root, left and then right
02:18 - in in-order will keep going left, 
root and then right.
02:21 - The actual implementation of these algorithms
02:25 - really easy and intuitive let's first
see
02:28 - code for preorder traversal. I first
written the algorithm in 
02:33 - words here, in preorder traversal
we first need to visit the root and then
02:37 - left subtree and then the right subtree
02:39 - now I want to write a function that
should take pointer
02:42 - or reference to root node as argument
and print data in all the nodes
02:47 - in pre-order let's say visiting a node
for us is printing the data in that node
02:52 - in C or C++ my method signature
will look something like this:
02:56 - this function will take address of the 
root node as argument,
03:00 - argument type is pointer to Node. I'll
define node as a structure
03:05 - with three fields like this, data type
in this definition is character
03:10 - and there are two fields to store the addresses of left and right children
 
55
00:03:15,349 --> 00:03:20,609
now in pre-order function I'll first
visit or print the data in root node
03:20 - and now i'll make a recursive call to
visit the left subtree
03:24 - I have made a recursive call here and to this call I'm passing
03:27 - address of the left child of my current
root because
03:31 - left child will be the root of left
subtree
03:34 - and I'll have another call like this to
visit the right subtree
03:38 - there is one more thing that we need to
add in this function and we will be done
03:43 - we cannot go into recursion infinitely,
we need to have
03:47 - a base condition where we should exit if
a tree or a subtree is empty or
03:52 - in other words for any call if root is
null
03:56 - we can return or exit. Now with this much
of code I'm done with my pre-order
04:01 - function.
04:02 - this will work fine in C or C++
04:05 - actually in C make sure you right
struct space node
04:09 - instead of righting just 'node', rest of
the things are fine
04:14 - it will be good to visualize
this recursion so let's now quickly see
04:18 - how this pre-order function will work if
this example tree
04:22 - that I'm showing in right here is pass
to it
04:25 - I'll redraw this tree and show it like
this
04:29 - hear I'm depicting node as a structure
with three fields
04:33 - let's say the leftmost cell here is to
store the address of left child
04:37 - the cell in middle is to store the data
and the right
04:41 - most cell is to store the address of
right child
04:46 - Now let's assume some addresses for
these nodes, let's say the root node 
04:50 - is at address 200
04:52 - and I'll assume some random addresses
for other notes as well
04:56 - and now I can fill in left and right
fields for each node
05:02 - and as we know the identity of tree
that we always keep with us
05:07 - is reference or address of the root node
05:10 - this is what we pass to all the
functions, in our implementation we often
05:14 - use
05:15 - a variable of type pointer to node named
root
05:19 - to store the address of root node,
we can name this variable
05:22 - anything, we can name this variable root
or we can name this variable
05:26 - rootPtr but this is just a pointer
05:29 - this particular block that I'm showing here
is for pointer to node
05:33 - and all these rectangles with three cells are
05:36 - nodes, this is how things are organized
in memory
05:41 - now for this tree, let say we are making a
call to this pre-order function
05:45 - I'll make a call to pre-order passing it
address 200
05:49 - for this call root is not null so
we will not return at first line in
05:53 - this function
05:55 - we will go ahead and print the data in
this node
05:58 - at address 200. I'll write output for all
print statements here
06:03 - and now this function will make a recursive
call
06:06 - execution of this particular function
call will pause,
06:09 - it will resume only after this recursive
call pre-order(150) finishes
06:14 - this second call is to visit this
left subtree
06:18 - this call pre-order(150) is to visit this
left subtree,
06:22 - address of the left child of node at 200
is 150
06:26 - once again for this call root is not
null,
06:29 - so we will go ahead and print the data, data
in node at
06:32 - 150 is D and now once again there will
be a recursive call
06:38 - with this call pre-order 400. We are saying that
we are going to visit this subtree
06:43 - once again we will print the data and
make another recursive call
06:47 - now we have made a call to visit this
particular subtree with just one node
06:51 - for this call we will print the data and
now for node at 250 address of
06:55 - left child is zero or null we will make
a call
06:59 - pre-order(0) but for this call
we will simply return
07:03 - because the address in this variable 
root will be
07:06 - null. We have hit the base condition for
our recursion
07:09 - call to pre-order(0) will finish and
preorder(250) will
07:14 - resume. Now in this particular function
call will make another call
07:18 - for right subtree for node at 250, even
the right child is null
07:22 - we will have another recursive call
passing address 0 but this once again
07:25 - simply will return
07:27 - and now call to pre-order(250) will
finish and call to pre-order(400) will
07:32 - resume.
07:33 - Now in call to pre-order(400) we will 
make another recursive call
07:36 - to pre-order(180) with this call 
pre-order(180),
07:40 - we are visiting this particular subtree
with just one node
07:43 - for this call first we will print the
data and then we will make a recursive call to
07:47 - pre-order(0)
07:48 - now pre-order(0) will simply return
and then we will have another call to 
07:52 - pre-order(0)
07:53 - for right child of 180, the recursion
will go on like this
07:57 - there's one thing that I want to talk
about you that's happening in this whole
08:01 - process
08:02 - even though we are not using any extra
memory explicitly
08:05 - in our function because of the recursion
we are growing the function call stack
08:11 - we have discussed memory management a
number of times in our earlier lessons
08:15 - you can check description of this video
for link to one of those lessons.
08:19 - As we know for each function call we
allocate some amount of memory
08:23 - in what we call stack section of
applications memory
08:26 - and this allocated memory is 
reclaimed when the function call finishes
08:30 - at this stage of execution of my recursion
for this example my call stack
08:34 - will look something like this:
I'm writing P as
08:38 - shortcut for pre-order because I'm
short of space here let's say we made a
08:41 - call to pre-order passing it address 200
from main function,
08:45 - main function will be at bottom of stack
at any time
08:48 - only the call at top of stack will be
executing
08:51 - and all other calls will be paused, call
stack keeps growing and shrinking during
08:55 - execution of a program
08:57 - because memory is allocated for a new
function call
09:00 - and its reclaimed when a function
call finishes
09:04 - so even though we are not using any
extra memory explicitly here
09:08 - we are using memory implicitly in the call
stack
09:11 - so space complexity which is measure of
09:14 - rate of growth of extra memory used with
input
09:17 - will depend upon the maximum amount of
extra memory used
09:20 - in the call stack. I'll talk about space
complexity once more
09:24 - later for now let's come back to this
recursion that I was executing
09:28 - called to this pre-order(0) will finish
and pre-order(180) will resume
09:32 - memory allocated for execution of
pre-order(0) will be reclaimed
09:36 - now for pre-order(180) both recursive
calls have finished
09:39 - so this guy will also finish even for 
pre-order(400) both calls have finished
09:44 - so pre-order(150) will resume.
09:48 - Now this guy will make a recursive call
to pre-order function passing it address
09:51 - 450
09:53 - address of its right child, memory in
the stack will be allocated for
09:57 - execution of
09:58 - pre-order(450). Now in this call we will
first print the data
10:03 - and then we will make two recursive
calls to pre-order passing
10:06 - address 'zero' each time because for this
node at 450
10:10 - both children are null, both calls will
simply return
10:13 - and then pre-order(450) will finish and now
pre-order(150) will also be done
10:19 - if you can see the call stack will grow
on till we reach 
10:22 - a leaf node, a node with no children and
then it will start shrinking
10:26 - again maximum growth of call stack to do
this recursion will depend upon
10:31 - maximum depth or height of the tree.
We can say that extra space used will be
10:36 - proportional to
10:38 - height of the tree or in other words
space complexity of this algorithm
10:43 - is O(h), where h is height
of the tree.
10:47 - Okay coming back to the recursion we are done 
with pre-order(150) so pre-order(200)
10:52 - will
10:52 - resume and now we will make a call to
visit
10:55 - this particular subtree, in this call
we will print J
10:59 - and then we will make a call passing
address 60
11:03 - so now we are visiting this particular
subtree, here we will first print
11:07 - "G" and then this guy will make a call
to pre-order(0)
11:11 - which will simply return and then there
will be another call
11:15 - to pre-order(500) here we will print "I" 
 
187
00:11:19,160 --> 00:11:22,610
and then we will two recursive calls
passing address 'zero'
11:22 - every time because node at 500 is a leaf
node
11:25 - with no children after this guy finishes
pre-order(60) will resume,
11:29 - now this guy will also finish and pre-order(350)
will resume
11:33 - and now we will have a call to pre-order(700)
which once again is a leaf node,
11:38 - so "K" which is data in this node will
be printed
11:41 - and then we will two calls passing
address 'zero' which will simply return.
11:46 - Now at this stage all these calls can
finish, we are done visiting all the nodes
11:50 - finally we will return back to the
caller of pre-order(200)
11:54 - which probably would be the main
function
11:58 - so this is preorder traversal for you I
hope you got how this recursion works,
12:02 - code for in-order and post-order will
be very similar
12:05 - in in-order traversal my base case will
be the same
12:09 - so I'll say if root is null then return or 
exit
12:13 - if root is not null I first need to
visit the left subtree
12:17 - I'm visiting the left subtree with this
recursive call
12:20 - then I need to visit the root so now
I'm writing this printf statement to
12:24 - print the data
12:25 - and now I can visit the right subtree so
this second recursive call,
12:29 - and this is my in-order function, 
in-order traversal of this example tree
12:35 - that I have drawn here
12:36 - will be this. This particular binary trees
actually
12:39 - also a binary search tree and in-order
traversal of a binary search tree
12:44 - would give us elements in the tree in
sorted order. Okay let's now write
12:49 - code for
12:49 - post-order. For this function once
again the base case will be the same
12:53 - so I'll say if root is null, return or
exit
12:56 - if root is not null. I first need to
visit the left subtree
13:00 - so I have made this recursive call, then the
right subtree
13:04 - so I'll have this another recursive call
and now I can visit the root node
13:08 - post-order traversal for this example
13:11 - tree will be this. So this is pre-order,
in-order and post-order for you
13:17 - you can check the description of this
video for link to all the source code.
13:21 - Let's now quickly talk about time and
space complexity of these algorithms.
13:25 - Time complexity of all these three
algorithms
13:29 - is O(n), if you could see
13:33 - then there was one function call
corresponding to each node
13:37 - where we were actually visiting that node,
where we were actually printing
13:41 - the data in that node
13:42 - so running time should actually be
proportional to number of nodes
13:45 - there's a better formal and mathematical
way of proving that
13:48 - time complexity of these algorithms
is O(n), you can check the
13:52 - description of this video for link to that
13:54 - space complexity as we had discussed
earlier will be O(h),
13:58 - where h is height of the tree, height of a
tree in worst-case will be
14:03 - (n-1) so in worst-case space complexity
of these algorithms
14:08 - can be O(n) and in best or average
case
14:12 - height of the tree will be O(log n)
14:15 - so we can say that
in best or average case
14:18 - space complexity will be O(log n). 
14:22 - I'll stop here now. In coming lessons we will
solve some problems on binary tree.
14:27 - Thanks for Watching.