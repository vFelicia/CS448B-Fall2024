hey what's going on everybody it's you bro hope you're doing well and in this video i'm going to describe the very basics of big o notation in well computer science so sit back relax and enjoy the show oh yeah big o notation so a common phrase used with big o notation is how code slows as data grows it describes the performance of an algorithm as the amount of data increases and really this notation is machine independent what we're really focusing on is the number of steps to complete an algorithm because some machines are going to run certain algorithms faster than others and three we tend to ignore smaller operations if we had some task that took n plus one we would just reduce it to just n because that plus one really isn't going to make a difference so here's a few examples of big o notation we have o of one o of n o of log n and o of n squared and n is really just the amount of data that we're passing in it's a variable like x what we're focusing on is the performance of an algorithm as the amount of data increases and n is a representation of the amount of data that we're passing in here's a more concrete example i have a function named addup we will add up to a certain number depending on what we pass in as an argument the for loop within here will iterate once up to whatever number that m is add i to sum then return it what if n was a large number like a million well it's going to take just above a million steps to complete this function this function is said to have a runtime complexity of oh then linear time as the amount of data increases it's going to increase the amount of steps linearly or proportionally now another way in which we could write the same function is to take sum equals n times n plus 1 divided by 2. we will get the exact same sum so if n was let's say a million this is still only going to take a couple steps three steps not a million steps so this function is going to have a runtime complexity of o of the input size doesn't matter the amount of data that we have really doesn't matter it's going to be completed in the same amount of steps so this function is way better than this previous one three steps is better than a million steps and the reason that this isn't o of three because this takes three steps is that we really don't care about smaller operations in the grand scheme of things they really won't make much of a difference so we would just shorten this and say that this is of one constant time the input size doesn't matter here's a graph that i made to represent the different runtime complexities we have data on the xaxis represented by n so data will increase as we go more to the right and we have time on the yaxis i did add an asterisk next to time because some of these times can vary depending on what machine you're using so these can vary another way to look at this is number of steps so as we increase on the yaxis these algorithms are going to perform with increasingly more time they're going to get slower so let's begin with of one constant time anything that has a runtime complexity of o of 1 will take the same amount of time regardless of the data size a few examples would include the random access of an element within an array and inserting at the beginning of a linked list so o of one is extremely fast next we have o of log n also known as logarithmic time one example is binary search we haven't talked about this yet we'll talk about a few of these algorithms in future videos but anything that has a runtime complexity of o of log n will actually take i don't want to say less and less time but increasingly less time to complete so as the data size increases this algorithm is going to be more and more efficient compared to the early stages with a small data set of n is also known as linear time as the amount of data increases the time it takes to complete something will increase proportionally linearly that would include looping through the elements in an array and searching through a linked list next we have o of n log n also known as quasilinear time this would include a quick sort merge sort and heap sort we'll talk about these concepts in future videos so for the most part this is very similar to linear time unless we're working with a large data set then anything using o of n log n is going to start to slow down when we work with larger data sets hence this curve here then we have o of n squared also known as quadratic time a few examples would include insertion sort selection sort and bubble sort as the amount of data increases it's going to take increasingly more and more time to complete anything that has a runtime complexity of o of n squared so just to compare linear time and quadratic time with linear time if our data set was a thousand if n equals a thousand it's going to take a thousand steps they're proportional they're linear but if we were using quadratic time if n was a thousand then a thousand squared would be a million so if our data set was a thousand if we're using quadratic time it's going to take a million steps then way more than linear time so quadratic time is extremely slow with large data sets but in the case of a small data set it could actually be faster as you can see by the graph here and lastly we have o of n factorial also known as factorial time and one place where this is used is with the traveling salesman problem which i might discuss in a future video so this is extremely slow so if i had to give a letter grade to each of these runtime complexities when working with large data sets with constant time this would be an a like an a plus logarithmic time would be a b it's pretty good linear time is c it's okay quasilinear time is a d it's just barely passing quadratic time would be an f and factorial time well you get expelled from school although some of these runtime complexities are actually faster when working with a smaller data set so keep that in mind well that's the very basics of bigo notation it's notation used to describe the performance of an algorithm as the amount of data increases so if you can give this video a thumbs up drop a random comment down below and well that's big o notation in computer science