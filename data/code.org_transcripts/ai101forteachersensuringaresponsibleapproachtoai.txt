00:00 - [Music]
00:07 - hi welcome to session four of AI 101 for
00:11 - teachers professional learning Series so
00:14 - far we have been focusing mostly on the
00:16 - benefits of AI which might be leaving
00:18 - some of you with some important
00:20 - questions like wait a minute I've heard
00:23 - that sometimes AI can make mistakes or
00:26 - even provide biased
00:28 - responses how do I ensure I'm using AI
00:31 - responsibly and
00:33 - thoughtfully what can I do to ensure I'm
00:37 - preparing my students to think
00:38 - critically about these new
00:40 - technologies these are all valid and
00:43 - important things to consider as you
00:45 - think about how you will approach AI in
00:47 - education let's dig into some of these
00:49 - [Music]
00:57 - topics hi I'm Danny I'm a former middle
01:00 - school and high school math computer
01:02 - science and engineering teacher I now
01:05 - work at code.org on our product team
01:07 - helping to develop the website that
01:09 - students and teachers use today we're
01:12 - here joined by Katrina to talk about AI
01:15 - we know that AI has been on many
01:17 - teachers minds and we're excited to dive
01:19 - into this topic today with Katrina could
01:21 - you introduce yourself hi I'm Katrina I
01:24 - am an elementary school special
01:26 - education teacher so could you tell us a
01:28 - little bit about how a relates to your
01:30 - work as an elementary school teacher AI
01:32 - is a really exciting tool but I am
01:36 - worried about how it relates to students
01:38 - and its use in the education setting
01:40 - what are some things you're excited
01:41 - about I think that AI can be really
01:44 - useful to help me when writing reports
01:47 - or when generating test questions or
01:50 - assignments for the students to work on
01:53 - um there's a lot of potential there so
01:55 - you said you had some concerns what are
01:57 - those concerns well I am worried about
01:59 - student priv privacy and how their data
02:01 - could be used by different AI tools and
02:04 - also about how AI could be used in the
02:06 - classroom and whether or not um the
02:09 - information that it provides would be
02:11 - accurate for students and also um how
02:15 - students might use it to help them with
02:17 - things like essay writing or homework
02:19 - are there ways you think you can
02:20 - leverage AI as a special education
02:22 - teacher um I do think that it could be
02:25 - really useful when helping to do things
02:27 - like write IEP goals um but with that I
02:30 - have concerns as well because IEPs are
02:34 - obviously very specific to each student
02:36 - and I wouldn't want to provide any
02:39 - personally identifying information to
02:41 - the AI tools I do think it can be really
02:44 - helpful with differentiation um I teach
02:48 - students who are at all different levels
02:49 - so for instance if I'm reviewing aition
02:53 - I can ask AI to help me write questions
02:57 - for my students who are at a lower level
02:59 - maybe add adding numbers between 1 and
03:00 - 10 but also my students who are more
03:03 - advanced in adding multi-digit numbers
03:05 - Danny I was wondering if you could give
03:07 - me advice so if I'm using AI to help me
03:12 - um come up with a reading passage at
03:14 - differentiated levels for my students
03:16 - about for instance the Revolutionary War
03:19 - how can I make sure that the information
03:21 - that it gives me for my students to read
03:24 - is actually accurate you really are
03:26 - going to have to be the expert we
03:28 - already think you know we know that
03:29 - teachers are the experts and you're
03:31 - going to have to rely on your knowledge
03:33 - to check what the AI tool is giving you
03:37 - to make sure that it is accurate so you
03:39 - can't just take what the I tool
03:41 - generates and hand it to students you're
03:43 - going to have to read it yourself and
03:44 - make sure that you believe what it's
03:46 - saying and maybe check other sources to
03:48 - make sure it matches what you find there
03:50 - as well Danny as somebody who works in
03:52 - educational technology and for a company
03:55 - that creates some of these AI tools what
03:58 - are your thoughts about the safety of
04:01 - using AI in a K12 classroom in terms of
04:04 - when we develop tools we work really
04:06 - hard to ensure their safety before they
04:09 - ever see a classroom so we're going to
04:11 - do a lot of rigorous testing to make
04:13 - sure that they're safe and they're
04:16 - producing factual information and
04:19 - they're reliable um that they're going
04:21 - to give the same result repeatedly and
04:25 - then we work hard to then pilot in a
04:28 - classroom make making sure that we do it
04:31 - with a small set so we can see what is
04:33 - happening and be really Hands-On we also
04:36 - always make sure that when we're
04:37 - developing tools that teachers have
04:40 - access to deciding what they want in
04:42 - their classroom and how it's used and
04:43 - then being able to monitor what is
04:45 - happening what are your thoughts on the
04:48 - future of AI where would you like to see
04:49 - it go if you could talk to you know
04:52 - creators of AI Technologies what would
04:54 - you want for your classroom well as a
04:57 - special education teacher I have a few
04:59 - students who are non-speaking and they
05:01 - use AAC devices to help them communicate
05:04 - um and I'm curious about how those AAC
05:08 - devices could be integrated with AI to
05:11 - give those non-speaking students or
05:14 - really any non-speaking individual a way
05:16 - to communicate their
05:18 - [Music]
05:23 - thoughts the potential for AI to help
05:25 - Society is enormous it's something that
05:27 - is influencing a lot of very important
05:29 - decisions about real humans and their
05:32 - lives it could be used in education to
05:34 - be more of an equalizer between people
05:36 - it could be used in healthcare to
05:37 - develop new drugs it could be used in
05:39 - science to develop new technologies and
05:42 - like any technology its application will
05:44 - depend on how it is utilized and at the
05:47 - same time we need to think about the
05:49 - risks that are associated with doing
05:50 - that the consequences are
05:52 - huge hi everyone I hope you're all as
05:55 - excited as we are to dive back into the
05:57 - fascinating world of AI my name is is
05:59 - Michelle and I'm a former High School
06:01 - science and computer science teacher I
06:03 - now work as a member of the professional
06:04 - learning team at code.org today we're
06:07 - going to discuss how you can ensure a
06:09 - responsible approach to AI in education
06:12 - Educators and administrators have valid
06:14 - concerns when considering whether or not
06:17 - AI Technologies are right for their
06:18 - classrooms some top concerns include the
06:21 - following data
06:23 - privacy how can my students and I use AI
06:26 - Tools in a way that protects our data
06:28 - and how do I know when a tool tool is
06:30 - safe enough to use with my students
06:32 - misinformation and AI fiction how can my
06:36 - students and I use AI effectively when
06:38 - it can be wrong algorithmic bias how can
06:42 - my students and I recognize AI bias and
06:44 - how can I teach my students to think
06:46 - critically about that bias throughout
06:49 - this video we will address each of these
06:50 - concerns and equip you with clear
06:52 - effective strategies you can use to
06:54 - mitigate risks for your students and for
06:58 - yourself
07:05 - it is really important that
07:07 - technologists kind of have this Mantra
07:09 - of ensuring that their Innovation is
07:12 - ethical and is beneficial to everyone in
07:16 - society machine learning requires a lot
07:18 - of true information to be provided to it
07:21 - in order to ultimately uh deliver a
07:24 - utility this information might be very
07:26 - sensitive to us it might be health
07:28 - related it might be Financial it might
07:30 - be very very
07:32 - personal we need to put checks and
07:35 - controls in place like with any
07:38 - technology that it's utilized to benefit
07:42 - us and that it is done with accordance
07:44 - to the law there's lot of gain from
07:47 - involving yourself in really
07:49 - understanding the details of how this
07:52 - technology
07:54 - Works given that it's so impactful given
07:57 - that it is something that will influence
07:59 - inuence your life and the life of
08:01 - everyone that you love AI systems
08:03 - process vast amounts of personal data
08:05 - consider a chess playing AI as an
08:07 - example rather than programming a set of
08:09 - steps that the computer should follow
08:11 - such as always start with the move
08:13 - Knight to F3 the computer analyzes
08:15 - millions of chess games to create its
08:17 - own patterns or algorithm that allow it
08:20 - to make the best moves in novel
08:22 - situations a large data set of millions
08:25 - of games is necessary for the computer
08:27 - to develop its own style of play now
08:29 - instead of Chess let's consider another
08:31 - example a video recommender algorithm
08:34 - how does an app recommend videos it
08:37 - constantly analyzes each person's
08:39 - interactions with the app monitoring how
08:41 - long you watch a video whether you
08:43 - comment on it or like it and More in
08:45 - order to learn your preferences the
08:47 - algorithm must process your data plus
08:50 - the data of everyone else using the app
08:52 - people tend to have different personal
08:54 - thresholds for what data they are and
08:56 - aren't comfortable sharing with AI
08:58 - systems individuals should have the
09:00 - autonomy to decide whether their data is
09:02 - collected for use in AI systems and
09:05 - companies should provide users with
09:06 - clear information about their data
09:08 - collection
09:09 - practices companies recognize the
09:11 - financial value of user data and often
09:14 - view it as an asset that can be
09:16 - monetized furthermore data protection
09:18 - regulations generally lag behind
09:21 - industry advancements for these reasons
09:23 - staying informed about how individual AI
09:26 - tools are using your data and advocating
09:28 - for privacy protect for your students
09:30 - are crucially important the introduction
09:33 - of AI tools and educational institutions
09:35 - presents nuanced challenges especially
09:37 - concerning data privacy often students
09:40 - find themselves with limited agency in
09:42 - choosing whether or not to use AI or
09:44 - edtech tools as decisions typically fall
09:47 - under institutional mandates emerging
09:49 - data intensive AI platforms may not
09:52 - always meet regulatory standards such as
09:54 - the US's family educational rights and
09:56 - Privacy Act furpa and children's online
09:59 - privacy protection act Capa or other
10:01 - International privacy protections making
10:04 - their integration into educational
10:05 - settings challenging especially for
10:08 - tools targeting users younger than 18
10:10 - parental consent becomes imperative
10:12 - unless these platforms were explicitly
10:14 - designed for educational use while it's
10:17 - Paramount for teachers to instill a
10:18 - thorough understanding of data privacy
10:21 - it's equally important to ensure that
10:22 - students don't feel overwhelmed or
10:24 - powerless though the broader control of
10:26 - personal data might seem elusive
10:29 - students should be equipped with the
10:30 - knowledge to make informed decisions
10:32 - about the data they can control
10:34 - promoting both awareness and
10:36 - [Music]
10:41 - empowerment the learns to take a text
10:44 - description and generate completely new
10:46 - images nobody has ever seen
10:49 - before or to alter existing
10:53 - images the same approach can also be
10:55 - used for
10:58 - videos
11:00 - now this raises multiple questions is
11:03 - the AI really learning creativity and
11:06 - Imagination on the one hand if you look
11:08 - at art and video created by AI it can be
11:11 - beautiful original and amazing on the
11:15 - other hand the AI only learns this by
11:18 - doing math at the pixel level while
11:21 - studying creations made by people is
11:24 - that really creativity another question
11:27 - is the issue of copyright I learns by
11:29 - studying the creations of others and the
11:33 - original creators may want to say in
11:35 - this of course when humans learn to
11:37 - create they also study creations made by
11:40 - others so the legal questions here are
11:43 - not simple we're still in the very early
11:47 - days of teaching AI how to create new
11:49 - types of media today AI can generate
11:52 - photos and videos soon you would also
11:55 - learn to create music my heart on with
11:59 - and 3D worlds this will have an
12:01 - incredible impact on all aspects of
12:04 - society especially in entertainment not
12:07 - just movies and music but also games
12:10 - think about all the information you've
12:12 - posted online over the years like family
12:13 - photos blog posts classroom websites and
12:16 - product reviews generative AI tools
12:19 - those that create new text code and
12:21 - images are typically trained on human
12:23 - Works possibly including some of the
12:24 - content you've contributed to the
12:26 - internet many AI tools also use the
12:28 - content users create within their
12:30 - platforms to enhance their own
12:32 - capabilities for example at present chat
12:35 - gbt and Bard use your conversations as
12:38 - training data by default we mentioned
12:40 - before that people have different
12:42 - personal boundaries around data privacy
12:44 - that holds true when it comes to
12:46 - generative AI
12:47 - too however many communities whose
12:50 - livelihoods depend on generating content
12:52 - like artists programmers and authors
12:55 - have objected to the use of their work
12:57 - to train AI tools since our students are
13:00 - artists programmers and authors too it's
13:02 - important to develop their skills as
13:04 - informed users of these AI tools so they
13:07 - can craft their own stance on data
13:10 - [Music]
13:14 - ownership AI tools Built For Education
13:17 - often have specific guardrails in place
13:19 - to promote safe student interactions and
13:22 - responsible stewardship of student data
13:24 - for example an AI chat bot Built For
13:26 - Education might limit the number of
13:28 - messages per day that a student can sent
13:31 - make a student's chat history visible to
13:33 - Educators or parents or proactively
13:35 - monitor a student's messages for
13:37 - inappropriate content an AI used in
13:39 - education should comply with furpa Capa
13:42 - and other Regional regulations when
13:45 - evaluating an AI tool to see if it is
13:47 - appropriate for use in your school
13:48 - environment first check to see if it was
13:50 - developed for use in education which can
13:52 - be a shorthand for understanding its
13:54 - safety
13:55 - standards look for first party help
13:58 - articles or guides available about the
13:59 - tool that explains safety and privacy
14:02 - features scan its privacy policy for
14:04 - passages that mention School use furpa
14:07 - and Capa you can also search Common
14:09 - Sense media's privacy program for a
14:12 - thorough privacy review of many online
14:14 - tools including chat GPT if you want to
14:17 - stress test an AI tool yourself get in
14:19 - the mindset of a mischievous teenager
14:21 - and see if you can break it how is this
14:24 - mitigated we can't ensure that all
14:26 - technologies that your students use have
14:28 - been optimize to protect their privacy
14:30 - here are some concrete strategies for
14:32 - keeping data private seek local
14:35 - guidance regulations around AI tools are
14:38 - constantly changing ask administrators
14:41 - or District leaders for guidance on AI
14:43 - tools such as guidelines or a white list
14:46 - search for any state and local laws that
14:48 - may affect the use of AI Tools in
14:50 - education scan the privacy policy don't
14:53 - be intimidated by all the legal language
14:56 - take a glance through with some help
14:58 - from control r f search for school use
15:00 - furpa CA and look for the age
15:03 - restrictions or required parental
15:05 - permissions check to see what types of
15:07 - data are collected and whether the data
15:09 - is sold to third parties if the policy
15:12 - doesn't address School use furpa or COA
15:15 - or if student data is sold you may want
15:17 - to consult your school's it department
15:19 - for more help adjust privacy settings
15:23 - most tools will offer some privacy
15:24 - setting such as disabling tracking or
15:26 - data storage before using a tool explore
15:29 - these options and use them to enhance
15:31 - privacy share these options with your
15:34 - students Empower your students it's
15:37 - crucial that students have a genuine
15:39 - Choice when using AI tools inform them
15:41 - about what the tools do and the Privacy
15:43 - implications show them a summary of the
15:46 - privacy policy and let them decide how
15:48 - they want to use the tool don't share
15:50 - personally identifying information a
15:53 - simple rule of thumb for sharing
15:55 - information is the anonymous Forum test
15:58 - if students wouldn't feel comfortable
15:59 - sharing something on an anonymous online
16:02 - platform such as Reddit or ciora they
16:04 - shouldn't share it with AI chat Bots
16:06 - like chat
16:07 - TBT don't forget that files may also
16:10 - contain personally identifying
16:11 - information and should be reviewed
16:13 - before uploading by keeping these points
16:15 - in mind we can help students navigate
16:17 - the world of AI while ensuring their
16:19 - privacy is respected let's take a quick
16:21 - look at how you might evaluate a tool
16:23 - like K Migo First let's check the Con
16:26 - Academy privacy policy right off the B
16:28 - there's a section about school use that
16:30 - mentions furpa and Capa compliance which
16:33 - helps us understand that the tool is
16:35 - intended for use in an educational
16:36 - environment it has sections that
16:38 - explicitly mention the use of the
16:40 - service for those under 18 and under 13
16:44 - second we'll look for first party help
16:46 - articles that explain the tool in a bit
16:48 - more detail we can see in this article
16:50 - that students are informed about the
16:52 - moderation of the tool that interaction
16:54 - is limited and that there are other
16:56 - safeguards in place it's also clear from
16:58 - a glance at the help articles that
17:00 - parents can turn off access to kigo and
17:02 - that some of the articles are directed
17:04 - at
17:05 - Learners let's conduct the same research
17:07 - for chat GPT first we'll scan the
17:09 - privacy policy for open AI you can see
17:12 - that the policy doesn't mention furpa
17:14 - Capa or School use so we can tell that
17:16 - the tool wasn't intended for use in an
17:18 - educational environment if we search for
17:21 - age restrictions the policy tells us
17:23 - that chat PT isn't designed for users
17:25 - under 13 and that users under 18 must
17:28 - have parental consent scanning the help
17:30 - articles for chat GPT there are clearly
17:33 - data control settings that we can turn
17:35 - on or off and ways to report harmful
17:38 - content however there aren't any
17:39 - articles directed at Learners or that
17:41 - mention parental or teacher controls now
17:44 - it's time for you to practice pause the
17:46 - video and examine the privacy policy of
17:48 - a site you use regularly with your
17:50 - [Music]
17:55 - students a large language model can
17:58 - produce unbelievable results that seem
18:00 - like magic but because it's not actually
18:03 - magic it can often get things wrong and
18:07 - when you get things wrong people ask
18:09 - does a large language model have actual
18:13 - intelligence discussions about AI often
18:16 - spark philosophical debates about the
18:18 - meaning of
18:19 - intelligence some argue that a neuron
18:22 - Network producing words using
18:25 - probabilities doesn't have real
18:27 - intelligence but what isn't under debate
18:30 - is that large language models produce
18:32 - amazing results with applications in
18:35 - many fields this technology is already
18:38 - being used to create apps and websites
18:42 - help produce movies and video games and
18:45 - even discover new drugs the rapid
18:48 - acceleration of AI will have enormous
18:50 - impacts on society and it's important
18:53 - for everybody to understand this
18:55 - technology misinformation is a problem
18:58 - and pmic to the internet not something
19:00 - created by AI just as you might have
19:02 - taught students to be skeptical of
19:04 - content on Wikipedia you'll need to help
19:06 - students understand that the information
19:08 - produced by AI isn't always correct
19:10 - healthy skepticism is a great mindset
19:12 - for your students to practice as they
19:14 - begin to encounter more and more
19:15 - information on the internet at home in
19:18 - school and in the workforce sometimes AI
19:20 - systems can confidently produce text
19:22 - that sounds very real but is actually
19:24 - not true while the type of information
19:27 - is often called the h ation we'll use
19:29 - the more inclusive term AI fiction in
19:31 - this video AI fictions happen because
19:34 - large language models were designed to
19:35 - mimic human language not be 100% factual
19:39 - they're language models not knowledge
19:41 - models while language does contain a lot
19:44 - of knowledge it can also contain
19:46 - incorrect information AI systems also
19:49 - don't have a true understanding of what
19:51 - they're saying like humans do so they
19:53 - often can't tell when they're making a
19:55 - mistake which means that these AI system
19:58 - systems communicate as though they're
20:00 - certain about their responses even if
20:02 - they're wrong why is this important well
20:05 - some people might use these madeup
20:06 - stories to spread false information on
20:09 - purpose others might come across these
20:11 - AI fictions by accident and think
20:13 - they're true this can be a problem
20:16 - especially now because with AI fake news
20:19 - stories and images can be created much
20:21 - faster and in larger amounts than before
20:24 - in the online world there's always been
20:26 - misinformation but with AI this
20:28 - information is now easier and faster to
20:31 - create AI fictions have already found
20:33 - their way into legal briefs and
20:34 - scientific papers and since AI mixes
20:37 - both right and wrong information it's
20:39 - important to double check anything you
20:41 - read or hear especially if it sounds a
20:43 - bit off or
20:45 - unbelievable students while eager to use
20:48 - AI tools might not be equipped to
20:50 - differentiate between factual
20:51 - information and AI generated fictions
20:54 - the introduction of AI in schools
20:56 - necessitates a recommitment to to
20:58 - bolstering digital literacy skills
21:00 - ensuring students critically evaluate
21:02 - the authenticity and relevance of the
21:04 - information they consume here are some
21:06 - concrete strategies for combating
21:08 - misinformation exercise healthy
21:11 - skepticism be cautious when asking large
21:14 - language models for factual information
21:16 - especially if that information is
21:18 - obscure reprompt is necessary if
21:21 - something sounds off when prompting a
21:22 - large language model prompt it again to
21:24 - re-evaluate for example by asking are
21:27 - you sure about blank
21:29 - emphasize digital
21:31 - literacy practice digital literacy
21:33 - skills with your students like
21:35 - corroborating information checking for
21:37 - bias in the author's Viewpoint and
21:39 - evaluating The credibility of online
21:41 - sources get creative with assignments
21:44 - give students assignments that ask them
21:46 - to debunk large language models outputs
21:49 - or Define the types of prompts that most
21:50 - often lead to AI
21:52 - fictions use a variety of tools use
21:55 - search engines and large language models
21:57 - to complement each other's strengths and
22:00 - weaknesses search engines can help with
22:02 - factchecking and finding citable sources
22:04 - while AI tools can help summarize and
22:07 - brainstorm so what we're going to do now
22:09 - is we're going to try out a common
22:10 - prompt type that can lead to
22:12 - misinformation this one is asking for
22:14 - quotes from a book to back up a claim in
22:17 - general asking large language models to
22:19 - site sources can be problematic so
22:22 - Katrina what type of books do you like
22:24 - to read I like to read all types of
22:27 - books but my favorite book is Pride and
22:29 - Prejudice awesome so what we're going to
22:31 - do is we're going to prompt our large
22:33 - language model we're going to ask it to
22:36 - list five reasons why Elizabeth Darcy
22:40 - liked Mr Wickham we're going to ask the
22:42 - model to use quotes from the book to
22:44 - back up your reasons we'll see what
22:56 - happens
23:09 - so what it's telling us is seems like
23:12 - you're referring to Pride and Prejudice
23:13 - by Jane Austin that's correct right that
23:16 - is correct U then it says however there
23:18 - isn't any clear evidence in the book
23:20 - that Elizabeth Darcy formerly Elizabeth
23:22 - Bennett like Mr Wickham is that
23:26 - true well in the end of the book she
23:30 - does not like Mr Wickham but there is a
23:32 - substantial portion of the book where
23:34 - she is um quite interested in him oh so
23:40 - it's not accurate here so let's try repr
23:43 - prompting and see if we can get chat gbt
23:46 - to correct itself okay so ask it but
23:49 - doesn't she initially grow to like Mr
23:51 - Wickham before she was aware about how
23:53 - he treated Mr Darcy she believes at
23:56 - first that Darcy treated him him
24:13 - poorly
24:15 - so it corrects itself so it says that it
24:18 - apologizes for the confusion that we're
24:20 - correct um Elizabeth Bennett initially
24:23 - had a favorable impression of Mr Wickham
24:26 - before learning the truth of his
24:27 - character and his actions and then it
24:29 - gives some quotes and you know it lists
24:32 - reasons here Charming manner friendly
24:34 - nature it gives the chapters this looks
24:37 - great to me what do you think as The
24:39 - Pride and Prejudice expert well here for
24:42 - quote number one that is a quote from
24:44 - the book about Mr Wickam and Elizabeth
24:47 - but it says it's from chapter 3 and
24:49 - actually it's from chapter 18 oh so it
24:52 - just has the chapter number wrong yeah
24:53 - but it is a correct quote and then quote
24:56 - number two is actually a quote that Mr
24:59 - Darcy says about Mr Wickham when he
25:02 - explains to Elizabeth um Mr Wickham's
25:05 - faults now so that doesn't really
25:07 - support our point at all here does it no
25:10 - that would not support Elizabeth's
25:13 - interest in Mr Wickham and then if we
25:15 - look at number four we see this is
25:17 - actually a quote from after Elizabeth
25:20 - learns of Mr Wickham's deceit and um the
25:23 - shame she feels for herself so this is
25:25 - not a quote that supports
25:28 - Elizabeth's liking of Mr
25:31 - Wickham that's some great examples of
25:33 - how chat GPT was able to produce an
25:36 - output that looked legitimate but
25:38 - actually had a lot of fictions now it's
25:41 - your turn to try pause the video open
25:43 - chat GPT or another large language model
25:45 - of your choice prop the large language
25:47 - model on a subject you know well fact
25:49 - check the output and see if you can find
25:51 - your own examples of AI
25:53 - [Music]
25:56 - fiction
26:00 - I think ethics becomes more important as
26:02 - something becomes more impactful and as
26:04 - AI becomes more impactful the more that
26:06 - we have to think about the ethics of
26:11 - AI artificial intelligence is ultimately
26:13 - built by human
26:15 - beings human beings can have very
26:18 - diverse motives for why they make
26:20 - something unfortunately there's a huge
26:23 - difference between those that are
26:25 - involved in creating these systems and
26:27 - those that are impacted by these
26:29 - systems so what we really want to think
26:31 - about long term is where is the society
26:33 - we want to get to and how is technology
26:36 - going to help enable
26:38 - that if we think about that in the long
26:40 - term we have a better chance of getting
26:42 - there than if we just try to develop the
26:44 - technology and then see what
26:48 - happens AI systems can sometimes produce
26:51 - unfair or discriminatory results this
26:54 - often arises from biases in the data
26:56 - that they're trained on or the way their
26:58 - algorithms are designed this phenomenon
27:01 - is known as algorithmic bias in
27:03 - artificial intelligence it represents
27:05 - the consistent and repeatable errors
27:08 - made by a computer system leading to
27:10 - unjust outcomes like favoring one group
27:12 - over another however the term bias isn't
27:15 - limited to distinctions like race gender
27:18 - or age broadly speaking bias is a more
27:21 - general term that reflects situations
27:22 - where an AI system consistently airs in
27:25 - a particular direction causing skewed
27:28 - conclusions these biases can emerge due
27:30 - to various factors such as design
27:32 - processes pre-existing prejudices
27:35 - embedded in the training data or even
27:37 - the interpretation of the results by
27:39 - those utilizing the AI for instance if a
27:42 - facial recognition system is trained
27:44 - predominantly on images of people from
27:46 - One ethnic group it may perform poorly
27:48 - on people from other ethnic groups
27:51 - moreover when algorithms trained on bias
27:53 - data are employed in real world
27:55 - applications they can perpetually uate
27:57 - inequities and create adverse outcomes
28:01 - understanding this concept is crucial as
28:02 - AI continues to play an increasingly
28:05 - integral role in various aspects of Our
28:07 - Lives from job applications to credit
28:09 - approvals from healthc care Diagnostics
28:11 - to personalized education these systems
28:14 - if left unchecked can inadvertently
28:16 - deepen existing disparities and hinder
28:19 - the objective of a just Society let's
28:21 - take a look at some prominent examples
28:23 - of algorithmic bias as a result of a
28:26 - facial recognition positive a black
28:28 - woman was wrongfully accused of a
28:30 - carjacking in Detroit facial recognition
28:33 - systems have performed poorly on the
28:35 - faces of people of color and even
28:37 - seemingly small error rates can still
28:39 - have a negative impact on a substantial
28:41 - number of individuals chat GPT has been
28:44 - found to exhibit a left-leaning bias
28:47 - likely in part because of the
28:48 - demographics of the people who trained
28:49 - the system to construct helpful
28:52 - prompts programs used to detect AI are
28:54 - more likely to flag writing from
28:56 - non-native English speakers as AI
28:59 - generated Common Sense Media recently
29:01 - found that in YouTube videos watched by
29:04 - kids eight and younger 62% feature no
29:06 - black indigenous or people of color
29:08 - characters at all while in another 10%
29:11 - of videos black indigenous or people of
29:13 - color characters were portrayed in
29:15 - Shallow ways while it's impossible to
29:17 - understand the extent to which the AI
29:19 - recommendation system was responsible
29:21 - for this outcome we do know it's
29:23 - responsible for 70% of all watch time on
29:26 - YouTube pause the video here and search
29:28 - for your own example of algorithmic bias
29:30 - in AI supported Technologies the problem
29:33 - is that with real world data there's
29:36 - often information in there that you
29:38 - didn't intend to be in there but is
29:40 - captured because of the bias in the data
29:42 - collection
29:43 - process so if you're building an AI to
29:46 - determine who gets a home loan or who
29:48 - should be charged with a crime it could
29:51 - definitely Bubble Up the racial biases
29:53 - that humans and our current Society
29:56 - already does
30:01 - a lot of what it means to build less
30:02 - harmful AI is really uh systems that are
30:06 - including the perspectives of those that
30:08 - are most vulnerable or most marginalized
30:10 - most likely to be hurt by the deployment
30:12 - of that
30:13 - system in many ways I've worried that
30:15 - the people who are particularly
30:17 - vulnerable to eii are the people who are
30:19 - already underprivileged in many
30:23 - [Music]
30:25 - respects most people in the world world
30:27 - just have ai applied to them rather than
30:30 - playing an active role in guiding what
30:32 - AI gets applied
30:34 - to everybody you know has a computer in
30:37 - their
30:38 - pocket that's young people old people
30:41 - rich people poor people to me that's
30:44 - actually quite exciting from a
30:47 - democratization of Technology
30:50 - perspective means that AI powerful as it
30:53 - is could theoretically be in everybody's
30:56 - Pockets benefiting
30:58 - everybody We should strive to make sure
31:00 - that things that provide value for
31:02 - society can be reached to
31:07 - anybody how do we give a greater voice
31:10 - to the people who are being impacted by
31:12 - AI to in turn be able to turn around and
31:15 - impact how AI is used for
31:19 - them every time when you looking at a
31:21 - new problem you have an opportunity to
31:24 - change the world sometimes we succeed
31:26 - sometimes we don't but we always
31:29 - try it's really critically important
31:32 - that we have as many diverse
31:33 - perspectives as possible influencing the
31:36 - development of AI we need the
31:38 - participation of more women more people
31:40 - of color to provide a different
31:42 - perspective and a different lens on
31:44 - which problems matter and how we should
31:46 - approach these
31:48 - problems now that we've taken a look at
31:51 - where algorithmic bias can emerge in
31:53 - real world context let's examine some
31:56 - guiding principles for teach teaching
31:57 - about bias in your
31:58 - classroom AI technology is nearly
32:01 - everywhere remember the old phrase
32:03 - there's an app for that today it's more
32:05 - like there's an AI for that artificial
32:08 - intelligence is an umbrella term
32:10 - encompassing machine learning and deep
32:12 - learning these techniques are applied in
32:14 - almost every sector you can think of do
32:18 - stay true to your passion and subject
32:20 - area find examples of both potentially
32:22 - harmful Ai and helpful AI in that space
32:26 - don't assume AI can do everything even
32:29 - if it's widespread the errors and biases
32:31 - are widespread too assume someone in the
32:34 - room is a data point depending on the
32:36 - age level various case studies of AI
32:38 - bias may come up these can include
32:40 - racial discrimination legal inequity
32:43 - housing insecurity gender discrimination
32:45 - social media manipulation misinformation
32:48 - education ACCESS food insecurity and so
32:51 - on teach us if you are speaking directly
32:53 - to someone affected by the issue as it
32:56 - may even be the case
32:57 - do speak with compassion and a Solutions
33:00 - oriented approach don't make jokes Tolen
33:03 - the mood don't treat the data like it's
33:05 - objective or detached don't treat
33:08 - outliers as useless data points don't
33:10 - use shock value data sources can be
33:13 - biased the problems we try to solve and
33:15 - the data we use to solve them can be
33:18 - narrow-minded for example trying to
33:20 - extrapolate instructional
33:21 - recommendations from one school's data
33:23 - likely won't translate using health
33:25 - costs as a proxim for how sick someone
33:28 - is discounts all the people who don't go
33:30 - to the doctor even though they are sick
33:32 - because they can't afford it data is not
33:34 - always ethically sourced and the right
33:36 - questions aren't always asked sometimes
33:39 - the problem itself is one that we
33:41 - shouldn't be trying to solve like how to
33:43 - predict someone's gender race criminal
33:46 - potential or sexuality from a photo do
33:51 - consider where the data comes from and
33:53 - how it was collected do look for whether
33:55 - it was ethically sourced do look for the
33:57 - year it was collected and the context of
34:00 - the time don't assume you always need
34:03 - more data you might need different data
34:06 - don't assume all problems are worth
34:08 - solving in the first place show
34:10 - Solutions no one wants to feel like
34:12 - their future is doomed you don't I don't
34:14 - your students don't we Thrive off hope
34:17 - for each case of algorithmic bias there
34:19 - are some solutions that have already
34:20 - worked and an opportunity to brainstorm
34:22 - possible solutions for the future do
34:25 - provide links to organ organizations
34:27 - working to solve issues of bias and
34:29 - algorithmic harm do be honest that
34:31 - mistakes will happen and that it takes
34:33 - bravery and accountability to tackle
34:36 - them don't assume that all solutions are
34:39 - technical fixes or magic aha algorithms
34:42 - Solutions are often cultural or policy
34:44 - driven don't imply all the problems have
34:46 - already been fixed and won't be
34:48 - represented in another similar context
34:51 - let's dive deeper return to the example
34:53 - of algorithmic bias that you explored
34:55 - earlier how how might those principles
34:57 - impact how you would approach leading a
34:59 - discussion about this issue with your
35:01 - students this session on ensuring a
35:03 - responsible approach to AI has been
35:05 - Illuminating we examine critical issues
35:08 - like privacy concerns misinformation and
35:10 - algorithmic bias underscoring the
35:13 - pressing challenges that come with the
35:15 - rapid advancements in AI
35:17 - technology however it's essential to
35:19 - remember that technology at its core is
35:22 - a tool the responsibility is on us its
35:25 - users and developers to guide ai's
35:27 - Direction by fostering open dialogues
35:29 - like the one we had today and working
35:31 - collaboratively we can ensure that AI
35:33 - serves Humanity ethically effectively
35:36 - and responsibly the conversation does
35:38 - not end here we challenge you to go back
35:40 - to your school and continue these
35:41 - conversations with your colleagues
35:43 - perhaps you might even establish data
35:45 - privacy policies with your school level
35:47 - teams or share successes and challenges
35:50 - related to discussing algorithmic bias
35:52 - with your students the future is bright
35:55 - and with our Collective Comm commitment
35:57 - we can harness ai's potential while
35:59 - safeguarding our shared values and
36:03 - principles AI certainly does have its
36:05 - benefits and also its pitfalls we hope
36:08 - that the information presented in this
36:10 - session will help you to navigate this
36:12 - new world with confidence the next step
36:15 - in our journey is to consider how you
36:17 - might bring AI into your classroom join
36:20 - us in session five where we focus on
36:23 - teaching about AI evaluating and
36:26 - utilizing ing AI Educational Tools and
36:29 - leveraging AI for student assessment
36:31 - this session will be a blend of theory
36:34 - practical examples and resources all
36:37 - intended to help you navigate the Ever
36:39 - Changing landscape of AI and education
36:42 - visit the ai101 for teers website at
36:45 - code.org
36:46 - ai101 to sign up for Early Access and to
36:50 - explore additional resources from
36:51 - code.org ETS IST and Con Academy thanks
36:55 - for joining us