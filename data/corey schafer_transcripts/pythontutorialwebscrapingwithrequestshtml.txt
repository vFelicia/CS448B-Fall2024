00:00 - hey there how's it going everybody in
00:01 - this video we're gonna be learning how
00:02 - to scrape websites using the requests
00:04 - HTML library now I've done a video on
00:07 - web scraping before using beautifulsoup
00:09 - which is one of the more popular tools
00:10 - out there but request hTML is a newer
00:12 - project written by Kenneth writes and
00:15 - he's the same person who wrote the
00:16 - request library and he has a history of
00:18 - writing libraries that are easy to use
00:20 - and pretty intuitive so I figured we'd
00:22 - give this library a look to see how we
00:24 - can scrape some web data now if you
00:26 - don't know what it means to scrape
00:27 - websites basically this means parsing
00:30 - the content from a website and pulling
00:32 - out exactly what you want so for example
00:34 - maybe you want to pull down some
00:35 - headlines from a new site or grab some
00:38 - scores from a sports site or monitor
00:40 - some prices in an online store or the
00:43 - stock market or anything like that
00:45 - so to show you an example of this let's
00:47 - take a look at the finished product that
00:48 - we'll be building in this video and then
00:50 - we'll actually learn how to build it now
00:52 - this is going to be very similar to the
00:53 - script that we built in the beautiful
00:55 - soup video but also I'm going to show
00:57 - how we can do some more advanced parsing
00:58 - such as grabbing dynamic data generated
01:01 - by JavaScript and how to make
01:02 - asynchronous requests and things like
01:04 - that so if I go over here to my personal
01:07 - website I have a home page that has a
01:10 - post of my most recent videos and every
01:12 - post that I have has a title with this
01:14 - big heading tag here and then I have
01:17 - some text of the summary of the video so
01:20 - a description of the video and then I
01:22 - have the embedded YouTube video here so
01:24 - let's say that we wanted to write a
01:26 - scraper that would go out and grab this
01:28 - information so we wanted to grab the
01:30 - post titles the summaries and the links
01:33 - to the videos and we just wanted to
01:34 - ignore all this other stuff here so to
01:37 - show you what this would look like let
01:38 - me run the finish script that we'll be
01:39 - writing in this video so that you can
01:41 - you know see what something like this
01:43 - can do and what it's capable of and then
01:45 - we'll actually learn how to build it so
01:48 - I have a script here if I'm just going
01:50 - to run this it's a CMS underscore scrape
01:53 - pie so if I run that script with Python
01:56 - then you can see that it went out to my
01:59 - website and pulled down a bunch of
02:00 - information from my homepage so these
02:02 - are the latest videos that I have and it
02:05 - grabbed the title here and it grabbed
02:08 - the description and it also grabbed the
02:10 - link to the YouTube video
02:13 - now not only did it print this
02:16 - information out here within the terminal
02:18 - but if I go to the directory where this
02:22 - script lives then it also created this
02:25 - CSV file here so if I open up the CSV
02:29 - file I'm on a Mac so this is going to
02:31 - open this in numbers by default yours
02:35 - might open in Excel if you're on Windows
02:37 - but we can see that it pulled down this
02:39 - information within a CSV file too so we
02:41 - have the headlines the summaries and
02:43 - then the video link over here now we
02:46 - could reformat this here a little bit to
02:50 - be a little bit better so I will set the
02:54 - column here to 300 point instead and
02:58 - then I'll also turn on word wrap so turn
03:01 - that on ok and now that's a little bit
03:02 - easier to read there so this is what you
03:05 - can do with a script to scrape websites
03:06 - like this now if we were to try to parse
03:08 - this information with Python alone then
03:10 - we'd probably run into a lot of issues
03:12 - but luckily we have libraries like
03:15 - python HTML that makes parsing out all
03:17 - this information a lot easier to do so
03:19 - let's go ahead and get started and see
03:21 - how to do this so first we need to
03:23 - install request HTML so I'm going to
03:26 - pull my terminal back up here
03:28 - now we can do this with a simple pip
03:30 - install it's just pip install and that
03:33 - is request
03:34 - - HTML now I already have mine installed
03:37 - here but yours would install there and
03:39 - once we have that installed let's look
03:41 - at a very basic example to get us
03:43 - started and then we'll work up from
03:45 - there now you don't have to be extremely
03:47 - familiar with HTML in order to scrape
03:49 - websites but it definitely helps
03:51 - basically hTML is structured in a way
03:53 - where all of the information is
03:55 - contained within certain tags so if
03:57 - you're familiar with you know XML then
03:59 - it's very similar to that so I have an
04:02 - extremely simple example here a basic
04:05 - HTML file and I have one open here in my
04:08 - browser and we can see that this small
04:10 - example here just has one big header
04:13 - that says test website and then we have
04:15 - two large links here for article 1 and
04:19 - article 2 and then we have a summary
04:21 - underneath for both of those articles
04:23 - and then we also have a footer down here
04:27 - and also I have something that says this
04:28 - text is generated by JavaScript so this
04:31 - is how you're probably used to seeing
04:33 - browsers display HTML but in the
04:35 - background the source code looks a bit
04:37 - different so let me switch over to the
04:39 - HTML code of this simple website here to
04:43 - see what this looks like
04:44 - so I have this open in sublime text I'm
04:47 - going to make this half screen here and
04:49 - actually let me make this website a
04:51 - little smaller here so that we can see a
04:53 - bit more of this HTML so we can see how
04:56 - this is structured here so we have these
04:59 - tags throughout our documents so there
05:01 - are opening tags which are surrounded by
05:03 - these brackets here so for example if I
05:07 - look at the head then we can see that
05:09 - these angled brackets this is the
05:11 - opening tag and the closing tag is the
05:15 - same thing except it has a forged slash
05:18 - here right after this so this is the
05:20 - opening head tag and this is the closing
05:22 - head tag and these tags can also be
05:24 - nested so if we want to find our article
05:26 - headlines in our article summary
05:28 - summaries then we can look down here in
05:31 - the body tag and within the body tag we
05:34 - have our test website heading here and
05:38 - then we have a div tag right below this
05:41 - and that div tag has a class of article
05:44 - and those classes are mainly used for
05:47 - CSS styling and can also be used within
05:49 - JavaScript to identify specific elements
05:52 - so within that div tag with the class of
05:55 - article we have our article information
05:57 - so we have an h2 tag here which is the
06:01 - heading of our article and within that
06:03 - h2 tag we have an anchor tag which is a
06:07 - link so this is a link to article 1 HTML
06:10 - with the text of article 1 headline and
06:12 - then below that we just have the
06:14 - paragraph tag with the summary of our
06:16 - article so we can see how the structure
06:18 - of these websites can look confusing but
06:21 - when you dig down a bit and actually
06:23 - look at the structure then the structure
06:25 - usually repeats so for example with our
06:28 - second article here it has exactly the
06:31 - same structure as the one above it so we
06:34 - have a div with a class of article
06:35 - heading two and this one goes to article
06:39 - two dot HTML with an article
06:40 - to headline as the text and then below
06:43 - that we have a paragraph tag and a
06:45 - summary for article two so these are
06:48 - very similar here we have our article
06:50 - one div here in our article two div here
06:52 - so let's use this very simple example to
06:55 - see how we can parse out information
06:56 - using requests HTML so let's say that we
06:59 - wanted to parse out the article
07:01 - headlines and also the summaries for our
07:04 - website and nothing else just the
07:06 - article headlines and the summaries so
07:07 - in this example it's just going to be
07:09 - article one headline and it's summary
07:12 - text and then the article two headline
07:14 - and it's summary text so I'm going to
07:17 - open up a blank file here and I just
07:19 - called this file our HTML
07:22 - - demo and now we can parse the HTML
07:24 - within this script now we can parse HTML
07:27 - in multiple ways so we can either use an
07:30 - HTML session to go out and pull HTML
07:32 - from a website and we'll see how to do
07:34 - that in just a minute but we can also
07:36 - just parse HTML directly and that's so I
07:39 - have it saved as a file on my machine so
07:42 - that's what we're going to do right now
07:43 - so for now we're just going to parse
07:46 - this simple dot HTML file and that file
07:48 - is located in the same directory as this
07:51 - script so if you'd like to download this
07:53 - simple dot HTML file to follow along
07:55 - then I'll leave a link to this code in
07:57 - the description section below okay so
07:59 - now let's go ahead and open this file
08:00 - and pass it into request HTML now first
08:03 - we're going to want to import the HTML
08:05 - class perm request HTML so at the top
08:07 - here I'll just say from requests
08:10 - underscore HTML so that's an underscore
08:13 - whenever we pip installed it it was a
08:15 - dash but when we're actually using the
08:17 - module it's an underscore and now we can
08:19 - say import HTML okay and now let's open
08:22 - the HTML file and pass the contents of
08:25 - that file into the HTML class so we'll
08:28 - say with open and this file was called
08:31 - simple dot HTML and that's what this
08:35 - site is over here and this is saved this
08:38 - HTML file is saved in the same directory
08:40 - as my as my demo here okay so now I can
08:44 - open that as HTML file and within this
08:49 - with block here I'll say source is equal
08:53 - to html5
08:55 - dot read so we're grabbing the contents
08:58 - from that file and now let's pass that
09:00 - into the HTML class so I'll say hTML is
09:02 - equal to HTML and hTML is equal to this
09:08 - source which is the contents of that
09:11 - HTML file now if working with files is
09:13 - new to you and you want to know more
09:15 - about how we opened and read the
09:16 - contents of that HTML file then I do
09:18 - have a video that goes into a lot
09:20 - further detail on working with files so
09:22 - I'll leave a link to that video in the
09:23 - description section below if any of you
09:25 - would like to learn more about that ok
09:27 - so now we have an instance of this HTML
09:30 - object here so first of all we can
09:33 - access the HTML of this object just by
09:36 - printing out the HTML attribute so I'll
09:40 - just say print HTML dot HTML so this is
09:44 - the HTML attribute of this instance that
09:46 - we just created here so if I save that
09:49 - and run it then I'll make this a little
09:52 - larger here we can see that we have all
09:54 - of the HTML from that simple web site
09:57 - now if we just wanted the text from the
10:00 - HTML without the tags then we can use
10:02 - the text attribute so I'll say print
10:05 - HTML dot text if I save that and run it
10:08 - then we can see that now we just have
10:09 - the text of the website with the tags
10:12 - taken out now dynamically generated data
10:15 - comes out a bit weird at the bottom here
10:17 - if we look at this this is the text from
10:20 - our website that is showing up here that
10:23 - says this text is generated by
10:24 - JavaScript now we're going to take a
10:27 - look at that further in just a bit but
10:29 - let's not worry about it right now okay
10:32 - so now let's find out how we can parse
10:34 - out that information that we want from
10:36 - this HTML so let's say that we wanted to
10:38 - grab the title of our HTML page so if I
10:42 - look at the title tag of this HTML up
10:45 - here at the top then we should get this
10:49 - here where it says test - a sample
10:51 - website so in order to get the title we
10:55 - can simply do something like this so I'm
10:58 - going to say match is equal to and I'm
11:00 - gonna do HTML dot find and with this
11:04 - fine method we just want to find title
11:07 - ok and now
11:08 - can print out that match so if I save
11:13 - that and run it then we can see that it
11:15 - prints out this list of elements here
11:17 - now I'm not sure how many people are
11:18 - familiar with CSS selectors but those
11:21 - are how you specify what you want to
11:23 - find and I like that a lot because it's
11:26 - something that a lot of developers might
11:28 - already be familiar with so this right
11:31 - here what we passed in the find is the
11:33 - CSS selector that we would use to find
11:36 - that title and when we print it out that
11:38 - match it gives us this list of elements
11:40 - and this list only has one element so
11:43 - that's probably our matched title so
11:45 - instead of printing out the whole list
11:47 - let's instead print out that only that
11:50 - first element so I'm going to print out
11:52 - match and access that zero index there
11:56 - to print out the first one and I will
11:58 - run that and now I just have this
12:02 - element and with these elements we have
12:04 - access to a lot of the same attributes
12:06 - and methods that we had before so we
12:08 - could find additional elements within
12:09 - here if this were nested we can view the
12:12 - HTML or we can simply view the text so
12:15 - if I wanted the HTML then I could just
12:18 - say print the HTML of that element if I
12:22 - save that and run it then we can see
12:24 - that we get the HTML of that title tag
12:27 - and if we only wanted this text without
12:29 - the HTML tags then we can use text
12:32 - instead so instead of printing HTML I'll
12:34 - print text save that and run it and we
12:37 - get the title of our website now instead
12:40 - of accessing that first element of that
12:42 - matched list we can instead just tell
12:44 - our find method that we only want the
12:47 - first match and it will just return that
12:49 - first match instead of a list so instead
12:52 - of accessing at this zero index here I'm
12:55 - just going to remove that and instead in
12:58 - our fine method I'm just going to say
13:01 - first is equal to true and now that
13:04 - match won't be a list of elements it'll
13:06 - just be the first element that gets
13:07 - found with that search so if I save that
13:10 - and run it then you can see that we get
13:12 - the exact same thing now like I said the
13:14 - find method it uses CSS selectors so if
13:17 - we wanted to get an element by a certain
13:20 - ID then we can use the pounce
13:22 - so for example if we wanted to grab the
13:24 - div with the ID of footer then I could
13:28 - simply say pound sign footer and now
13:32 - it's going to return the element that
13:34 - has the ID of footer so if I save that
13:37 - and run it then we can see that we get
13:39 - that footer information okay so now
13:41 - let's see how we get those article
13:43 - headlines and summaries from our HTML
13:45 - now most of the time you aren't going to
13:47 - want to look through all of the HTML of
13:49 - the page because with larger sites it
13:52 - can definitely just be a mess of code so
13:55 - a nice little trick if we go back to our
13:57 - browser here and I'm going to make this
14:00 - just a little bit larger for a second
14:02 - now in order to dig down into the HTML
14:04 - and find exactly where our article
14:06 - headline and summary is I'm using the
14:09 - Chrome browser here but other browsers
14:10 - have this feature as well but we can
14:12 - just right click on what we want so I'm
14:15 - going to right click on that headline
14:16 - and now I'm going to click on inspect
14:20 - and that will allow us to inspect this
14:22 - element so this inspection popped up
14:25 - here on the right side let me see if I
14:27 - can make this text a little bit larger
14:30 - here so that we can see so now we can
14:32 - see that we have all of our HTML here
14:34 - but the one that's highlighted is the
14:36 - one that we right clicked and inspected
14:38 - so we can see whenever I hover over this
14:40 - it actually highlights that in the
14:42 - browser so if I hover over the h2 then
14:45 - it shows me all of the h2 if I hover
14:47 - over the article it shows me all of the
14:49 - article and so on so if I go to the body
14:52 - then it highlights everything so this is
14:54 - a nice way to narrow down exactly what
14:57 - it is you're looking for so like we saw
14:59 - before our article headlines are within
15:01 - a div with a class of article and then
15:04 - we have an h2 tag and then an anchor tag
15:07 - so first let's grab the article div so
15:10 - I'm going to go back I'm going to close
15:11 - this and go back to the HTML or the
15:15 - scraper here and now instead of match
15:18 - I'm going to call this article instead
15:21 - and now and in the find method here I'm
15:26 - going to find a div with a class of
15:30 - articles so to do that you can say div
15:31 - dot article and if you're familiar with
15:35 - CSS selectors
15:36 - how we would find that with CSS
15:38 - selectors as well so if I save that and
15:40 - run it then we can see that I grabbed
15:43 - the first div with the class article and
15:46 - printed out its text and we can see that
15:48 - it gives us the headline and the summary
15:50 - within that div so now we have that
15:53 - first article we can just search this
15:56 - element just like we searched the entire
15:58 - HTML object so let's say I wanted to
16:01 - access the headline and the summary
16:03 - individually so to do that we can simply
16:06 - say I'm going to overwrite that part
16:08 - there I'm gonna say headline is equal to
16:11 - and now we're going to use this article
16:13 - and I'll say article dot find and within
16:17 - the article I want to find the h2 and
16:20 - I'll also say first is equal to true
16:23 - here and now I'm going to copy this line
16:26 - and paste it in below and I'm also going
16:30 - to grab the summary so the summary is
16:32 - the article dot find and we want to find
16:35 - the first paragraph tag so now let's
16:38 - print those out individually so I will
16:40 - print out let me give some space here so
16:45 - I will print out that headline and I
16:47 - will also print out the summary so if I
16:51 - save that and run it then you can see
16:53 - that we have those matched elements if I
16:55 - just wanted the text then I could either
16:58 - say headline text here or I could even
17:01 - just add it on to the end of my query
17:02 - here so I'll say dot text after that
17:05 - find dot text after that find save that
17:08 - and run it and now we can see we got the
17:10 - article one headline and the summary for
17:12 - article 1 okay so now that we have this
17:15 - information from one article we can most
17:18 - likely reuse this to parse the
17:19 - information from all of the articles so
17:21 - let me change the first search here to
17:24 - where I'm finding all of the divs with
17:26 - the class of article 2 not just return
17:29 - the first one so I will rename this here
17:33 - I want to say articles is equal to HTML
17:36 - dot fine
17:36 - div dot article I'm going to take away
17:38 - that first equals true so now that
17:41 - should return a list of articles so now
17:44 - let's loop over those articles and reuse
17:46 - the same same code that we had before to
17:48 - access the headline
17:49 - and the summary so right underneath here
17:52 - I'm just gonna say for article in
17:55 - articles and then we will use this same
18:01 - code here to find the headline and the
18:05 - summary so let me spread that out a
18:08 - little bit and let me save this and run
18:10 - it and now we can see that we have the
18:14 - headline and the summary for both of
18:16 - those articles instead of just the first
18:19 - one now if I those are bunched together
18:21 - if I put a just blank print here then
18:23 - it'll spread those out a bit and now we
18:25 - can see we have those spread out okay so
18:28 - now we got the headline and the summary
18:30 - for every article in our simple HTML
18:33 - file here so that's good so we're
18:35 - starting to see how this would be useful
18:36 - for getting information from websites so
18:39 - now let's do something similar but with
18:41 - an actual website so I have my personal
18:44 - website pulled up here in the browser
18:46 - that we saw before let me make this a
18:48 - little larger here
18:49 - and like I said I have a list of posts
18:51 - here and all of these posts have a title
18:54 - a summary and then an embedded video so
18:57 - let's say that we wanted to write a
18:59 - script that would go out and grab those
19:01 - titles and summaries and links to those
19:04 - videos so first things first we're going
19:06 - to need to import a different class from
19:09 - request HTML when we're grabbing data
19:12 - from a URL we need to use something like
19:14 - an HTML session so let me make this a
19:18 - little larger here and up at the top
19:21 - instead of just importing HTML I'm also
19:23 - going to import HTML session ok and now
19:27 - let's get the source code from my
19:29 - website so I'm just going to comment out
19:32 - this with open that we have here before
19:35 - because I'm going to do one more thing
19:36 - with this file later and now I'm just
19:38 - going to overwrite everything that we
19:40 - had previously
19:41 - so now to get the source from my website
19:46 - I'm going to say session is equal to
19:48 - HTML session and now I can say R is
19:52 - equal to that'll be for response I'm
19:56 - gonna say session dot get and I want to
19:59 - get the home page of my website so I
20:03 - will just
20:03 - copy that and paste that in there so
20:05 - that uses the request library to get a
20:07 - response from our website and this our
20:10 - variable is going to be the response
20:12 - object now if you are familiar with the
20:15 - request library then you can pretty much
20:16 - use this like you would use a response
20:18 - from that request library so we could
20:21 - check the status code we could get the
20:23 - content and bytes get the content and
20:25 - Unicode all kinds of different stuff now
20:27 - if you'd like to see more of what you
20:28 - can and do with the request library
20:30 - itself then you can watch my video where
20:32 - I go into more detail about these
20:34 - request and response objects so I'll
20:36 - leave a link to that video in the
20:37 - description section below if anyone is
20:39 - interested but what we're interested in
20:41 - for this video is the HTML attribute so
20:44 - I'm going to print our dot HTML if I
20:50 - save that and run it then when I printed
20:52 - that out that HTML attribute gives us
20:56 - access to the HTML object for that
20:59 - website so that HTML object is just like
21:02 - the HTML object that we interacted with
21:05 - just a second ago it's just the same as
21:07 - a setting this HTML equals HTML with the
21:12 - source so we can use that to find what
21:14 - we're looking for on my website so just
21:16 - like before let's start off by grabbing
21:18 - one videos information first and then
21:21 - we'll loop through those to get the
21:23 - information for all of the videos so to
21:25 - grab the first headline and snip it
21:28 - let's inspect my website and see what
21:30 - the structure looks like so I'm going to
21:32 - go ahead and enlarge this here so just
21:35 - like I did in the simple example I'm
21:37 - going to right click on this headline
21:39 - and then go to inspect and now we can
21:43 - see here our article headline is in an
21:46 - h2 tag with a class of entry title okay
21:50 - so that's how we're going to find that
21:53 - if I right-click on the description here
21:55 - and inspect that then we can see that
21:59 - this is a paragraph tag inside of a div
22:02 - with the class entry content now both
22:05 - the heading and the summary are both
22:08 - inside of this article tag here so this
22:13 - article tag is for one post so if I
22:16 - hover over that
22:17 - then you can see it just highlights that
22:19 - first post but not the second one if I
22:21 - hover over the second one then it
22:22 - highlights that post so first let's just
22:25 - grab that entire first article that
22:28 - contains all of the information and that
22:30 - we want so to grab that first article in
22:33 - the source code let me go back to our
22:36 - script here we can simply just say I'm
22:39 - going to overwrite this print statement
22:41 - here I'm gonna say article is equal to
22:44 - RR dot HTML dot fine and we are going to
22:49 - find that article tag and I just want
22:52 - the first one for now while we're
22:54 - messing with this so I will say first is
22:57 - equal to true and now I can print out
22:59 - that article dot HTML so I'll save that
23:03 - and run it okay and this gives us all of
23:06 - the HTML of that first article now I've
23:09 - actually liked using this library more
23:12 - than beautifulsoup but there was one
23:13 - thing I liked about beautiful soup that
23:15 - I haven't been able to find in this
23:17 - library and that's some sort of pretty
23:19 - Phi or a pretty print method now I don't
23:22 - think that this library has anything
23:25 - that will print this HTML out nice and
23:27 - neat but if it can do that and I've
23:29 - somehow missed it then just let me know
23:31 - in the comment section below because I
23:32 - think that would be some good
23:33 - functionality so this isn't the neatest
23:35 - HTML here but if we read through this
23:38 - then we will be able to see that it's
23:40 - the HTML from that first article so just
23:43 - to see this a bit better I will go ahead
23:45 - and format this so that we can read it I
23:48 - have an online format err pulled up here
23:51 - in my browser and I'm just going to use
23:53 - this to pretty up our HTML so I'm going
23:55 - to paste that into the HTML input part
23:58 - and then click on beautify and you can
24:00 - see that over here it formats it nicely
24:02 - so now I'm going to copy that prettied
24:08 - up HTML and paste this in here to
24:12 - sublime and also let me set the syntax
24:16 - as HTML okay so now we have our pretty
24:20 - printed HTML okay so now that we have
24:22 - the HTML for this article now we can
24:24 - figure out how we want to grab what we
24:26 - want to grab so we want to grab the
24:29 - headline summary and you two
24:31 - video link from this article here so
24:33 - let's start with the title so like I
24:36 - said before this is in this h2 tag with
24:38 - the class of entry title and then we
24:41 - have this link here and the link this is
24:44 - a little long here actually this would
24:46 - probably be more readable if I turn on
24:49 - word rap okay
24:51 - but we can see that this is the link
24:54 - here and the text of that link is the
24:57 - article headline and actually this link
24:59 - has its own class so that makes it a
25:01 - little easier on us it says entry title
25:03 - link so let's just grab the text of that
25:07 - class so I'm going to go back to our
25:09 - script here and now instead of printing
25:12 - out that article dot HTML I'm going to
25:15 - use it to find our headline so I'm going
25:17 - to say headline is equal to article dot
25:20 - find and within that article we want to
25:24 - find a class of entry I can actually
25:27 - just go back to the HTML here so I don't
25:29 - screw it up entry title link I will copy
25:32 - that and paste that in and we just want
25:36 - to grab the first result
25:37 - so we'll say first is equal to true and
25:40 - we just want to grab the text from that
25:44 - match so now if I print out headline if
25:48 - I save that and run it then we can see
25:51 - that we got the first headline from the
25:52 - first post okay so now that we got the
25:55 - title of my latest post now let's get
25:58 - the summary text for that post so let's
26:01 - go back to the HTML for our article here
26:04 - and let me scroll down until I see what
26:07 - looks like the description and this is
26:09 - it right here
26:11 - so our summary text is within this
26:13 - paragraph tag and that paragraph is
26:15 - inside of a div with a class of entry
26:19 - content so I'm going to copy that
26:21 - and now back in our scraper let's just
26:27 - copy this here and paste this in and
26:30 - instead I'm going to call this summary
26:34 - and that summary is going to be if I
26:37 - copy that entry content it is going to
26:40 - be a class of entry content and then it
26:44 - is the paragraph tag within entry
26:48 - content so now if I save that and run it
26:51 - that now we have our headline here and
26:55 - then right below this it's a bit bunched
26:57 - together but this is the description of
26:59 - that first post now again the syntax
27:02 - that we're using inside of this find
27:04 - method is the same syntax that you would
27:06 - use in CSS so if you're not familiar
27:08 - with how that works then that's where
27:10 - that comes from
27:11 - okay so lastly we need to get the link
27:13 - to the video for that post now this one
27:16 - is going to be a little more difficult
27:18 - but I wanted to show you this because
27:19 - sometimes parsing information can be a
27:22 - bit ugly and require you to take several
27:24 - steps before getting your final desired
27:27 - result so if we look back at the HTML of
27:30 - the article then let's see if we can
27:33 - find where this video is so it's
27:36 - actually down here within this iframe
27:40 - this is that embedded video here so let
27:43 - me just grab the HTML of that iframe so
27:45 - that we can see just that so back in the
27:48 - scraper here I'm going to say let's say
27:51 - I'll just call this vid underscore
27:52 - source is equal to article dot fine I'll
27:57 - just copy that from above we want to
27:59 - find the iframe within that article and
28:02 - I will say first is equal to true and
28:06 - now I'm going to print the vid source
28:11 - dot HTML and I'm going to copy or I'm
28:14 - going to comment out these other print
28:16 - statements for now so I'm going to save
28:18 - that and run it okay so this is the HTML
28:21 - for our embedded video so if we inspect
28:24 - this iframe here if we look at the
28:27 - source attribute here this source is has
28:31 - a link to the embedded version of the
28:33 - video but it's not a direct link to the
28:36 - video itself we can see it goes to
28:38 - youtube.com forward slash embed forward
28:42 - slash this video ID here and then it has
28:44 - a long URL after that but if you know
28:47 - how YouTube videos work they all have an
28:50 - ID for the video and the ID for this
28:52 - video is right here it's everything
28:55 - before this question mark
28:58 - so the question mark in a URL specifies
29:00 - where the parameters start so it's not
29:03 - actually part of the ID so with that ID
29:05 - we can create a link to the video
29:07 - ourselves so we need to parse that ID
29:10 - from that URL so first we need to grab
29:13 - that URL from the iframe which is in the
29:16 - source attribute so this is pretty
29:18 - simple to do so instead of using this
29:21 - HTML of this vid source element here we
29:25 - can instead access the attribute by
29:27 - saying vid source dot attrs for
29:31 - attribute so if I run that then we get a
29:36 - dictionary of the attributes for that
29:38 - iframe element so to grab the source we
29:41 - can just access that like any other
29:45 - Python dictionary so I'm just going to
29:48 - access the source key of that dictionary
29:52 - so now I'll run that and now we can see
29:56 - we get that youtube link and now we can
29:58 - see that that gives us the entire
29:59 - YouTube URL for that embedded video so
30:03 - I'm going to move the attributes and
30:07 - source key up on the previous line here
30:10 - so that we have our URL in a single
30:14 - variable so what I mean by that I'm just
30:15 - going to cut out the dot attributes and
30:18 - the source there and I'm going to just
30:21 - put that up here on the previous line so
30:24 - this vid source variable is equal to
30:27 - this link here so if I run this we
30:29 - should just get the same result okay so
30:31 - now that we have this URL we're gonna
30:33 - have to parse this URL string to grab
30:35 - the ID of that video and we'll break
30:38 - this up into several lines so first we
30:40 - can see that our video ID which is right
30:43 - here comes directly after a forward
30:46 - slash so let's split our string based on
30:50 - forward slashes so I'm going to comment
30:54 - out actually I'll just remove that print
30:56 - statement there and I'll say vid
30:58 - underscore ID is equal to vid source dot
31:03 - split and we're going to split our URL
31:07 - on forge slashes and now I can print
31:12 - this vid ID so if I save that and run it
31:16 - then now we have a list of values from
31:20 - our string that we're split onto that
31:23 - Ford slash now if you've never used the
31:25 - split method on a string basically like
31:28 - I said it just splits the string into a
31:30 - list of values based on the character
31:32 - that you specify so now we can see that
31:35 - our URL is broken into several parts
31:37 - based on where the forward slashes were
31:39 - so if we look at the items of our list
31:42 - here we're looking for our video ID
31:44 - which is right here
31:45 - so which index is that located in so
31:49 - this is the zero index here 0 1 2 3 4 so
31:54 - that is within the 4th index of this
31:57 - list so let's specify that we only want
32:00 - the 4th index of that list so right
32:03 - after the split I'm just going to access
32:05 - the 4th index there save that and run it
32:09 - and now we have just that video ID with
32:14 - the other URL parameters but we still
32:17 - don't have the ID itself so like I said
32:19 - before the question mark specifies where
32:22 - the parameters for the URL begin and the
32:24 - video ID is before that so if we do
32:27 - another split on the question mark then
32:29 - it should separate those out so I'll go
32:32 - to a new line so that we aren't making
32:35 - this one too complicated and I will just
32:39 - say vid ID is equal to vid ID dot split
32:43 - and we want to split this value on a
32:47 - question mark so I will split that and
32:51 - if I run that now then we can see that
32:54 - now we have two items it's split by our
32:57 - video ID and then the second value in
33:01 - our list here is all of the URL
33:03 - parameters but we don't care about those
33:05 - parameters we just want the video ID so
33:07 - we want to grab that first element of
33:10 - the list which is at index 0 so I'll put
33:13 - an index of 0 there save that and run it
33:15 - and now we have our video ID okay so I
33:18 - know that that was a lot of parsing but
33:20 - sometimes you know website source code
33:22 - just doesn't have the information that
33:24 - you want in the most accessible way
33:26 - so I wanted to show you how you might go
33:28 - about getting the data that you want
33:29 - okay so now that we have that YouTube ID
33:33 - now we can create our own YouTube link
33:36 - using that video ID so the way that
33:38 - YouTube links are formatted are like
33:41 - this let me make this a little smaller
33:44 - here so that we have some more room so
33:46 - I'm going to remove that print statement
33:48 - there and now I'm going to say YouTube
33:51 - link is equal to and I'm just going to
33:55 - make this an F string so the way that
33:57 - YouTube links to videos is like this so
34:00 - we can do HTTP colon forward slash
34:03 - forward slash youtube.com forward slash
34:06 - watch and now for our YouTube parameters
34:10 - we want a question mark v is equal to
34:13 - and now V is going to be equal to the
34:15 - video ID so since we're using an F
34:19 - string we can just put that in there now
34:22 - I'm using f strings to format the string
34:23 - but those are only available in Python 3
34:26 - 6 and above if you're using an older
34:28 - version of Python then you can use the
34:30 - format method and I have a separate
34:32 - video on both F strings and formatted
34:34 - strings if anyone needs to see how to do
34:36 - that so I'll leave a link to those
34:38 - videos in the description section below
34:40 - so if I print out that youtube link that
34:44 - we just created now we can see that we
34:47 - have a link here that should go to our
34:50 - video so if I copy this and paste it
34:54 - into my browser then it should open up
34:56 - that video in the browser okay let me
35:00 - pause that okay so we can see that it
35:02 - opened up that video in the browser
35:04 - using that link that we created okay so
35:06 - that's perfect so now we've scraped all
35:08 - of the information that we want from
35:10 - that first article so just like in our
35:13 - earlier example now that we've got that
35:15 - information for one article now we can
35:18 - loop over all of the articles and get
35:19 - that information for all of them so to
35:22 - do this I will just come up here to the
35:26 - top where we found that first article
35:27 - and instead I'm going to call this
35:29 - articles and take out this first equals
35:32 - to true because we don't just want the
35:34 - first article now we want all of them
35:36 - and now we can say
35:39 - for article in articles and we can reuse
35:44 - all of the same logic that we used
35:46 - before but we'll just put it inside of
35:50 - that for loop so now for each article
35:53 - that we found we are parsing out the
35:55 - headline and let me print that out
35:58 - we are parsing out the summary and I
36:00 - will uncomment out that print statement
36:02 - and then we're doing all of this parsing
36:04 - here to also grab a youtube link so now
36:08 - and also let me put a blank print
36:11 - statement here at the bottom so that we
36:14 - have some separation between these
36:15 - articles okay so now if I run this then
36:19 - we should be able to scroll up here okay
36:21 - so now we have all of that information
36:23 - this is the first article here here's
36:26 - the headline here is the description and
36:28 - here is the youtube link and it should
36:30 - do this for every one of the articles on
36:33 - the site or at least on the home page
36:35 - okay so that's good but sometimes you're
36:37 - going to run into situations where you
36:40 - might be missing some data and if that
36:42 - happens then it could break your script
36:45 - to scrape the website now maybe you're
36:47 - pulling down a list of items and one is
36:49 - missing an image or you know something
36:52 - that you thought would be there so to
36:53 - show what this looks like I'm going to
36:54 - go to one of my older posts that doesn't
36:56 - have a YouTube video associated with it
36:58 - and see what happens
37:00 - so blog posts from a long time ago don't
37:03 - have videos so if I go back here let's
37:07 - say I'm going to close down the
37:09 - inspection now I think on let's say I
37:12 - think it's like page 14 or so of my
37:15 - website let me go to page 14 here so if
37:20 - I scroll down here a little bit okay so
37:22 - I have an old post here from 2014 where
37:26 - I made a doll bed for my niece and just
37:28 - wrote you know a quick article about how
37:30 - I threw that together but the post
37:32 - doesn't have a YouTube video associated
37:34 - with it and there are a few more of my
37:36 - old posts like this as well so let's see
37:38 - what happens if I try to scrape page 14
37:42 - here of my website so I'm going to copy
37:45 - this URL and go back to our script and
37:49 - the website that we're getting I'm going
37:52 - to paste in
37:53 - and that now we're gonna try to scrape
37:54 - page 14 so I'm going to save that and
37:58 - run it and if I do that
38:01 - if I scroll up here we can see that it
38:03 - got the headline and summary and link
38:06 - for the first post on that page but for
38:08 - the doll bed post we have a trace back
38:12 - here and it's saying that it can't
38:15 - actually be at access the attributes of
38:17 - the vid source and that's to be expected
38:19 - because there is no video in that post
38:21 - so when we try to access the attributes
38:24 - of that video then it's not going to
38:25 - have a value and it's going to throw an
38:27 - error so to fix this we can just put in
38:29 - a try except block that will check for
38:32 - errors and if it does you know run into
38:34 - an error parsing a video then it will
38:36 - just skip that part of the post so to do
38:39 - this I'm going to make my output a
38:42 - little smaller there so to do this I'm
38:45 - just going to create a try except block
38:47 - where we are trying to parse out the
38:51 - video and in the try section of this I'm
38:54 - going to take all of our code that
38:56 - parses the video and creates the link
38:58 - and I'm going to paste that into the try
39:01 - section of the try block and for the
39:05 - exception if it runs into an exception
39:07 - then I'm just going to say that the
39:10 - youtube link is going to be equal to
39:13 - none now again if you're unfamiliar with
39:15 - try/except blocks and would like to see
39:17 - a more detailed video about that concept
39:19 - then I do have a video specifically on
39:21 - that so I'll leave a link to that video
39:23 - in the description section below if
39:25 - anyone would like to learn more about
39:26 - that ok so now if I rerun this same code
39:32 - from before if I look at the output now
39:35 - then whenever it gets to the post
39:38 - without a video then we can see that it
39:41 - just prints none instead and then it
39:44 - moves on to the other posts now that
39:47 - didn't print a summary either and the
39:49 - reason for that is because the first
39:51 - paragraph of that post is an image
39:54 - instead of the summary so you know we're
39:57 - not going to mess with that
40:00 - so instead let me go back to the home
40:03 - page and rerun that code
40:07 - it's still working okay and the code is
40:11 - still working for our homepage as well
40:12 - okay so now that we've scraped the
40:14 - information that we wanted you can save
40:16 - this in any way that you'd like right
40:18 - now we're just printing this out to our
40:20 - terminal here and maybe that's fine for
40:23 - you but you can also save this to a file
40:25 - or a CSV or whatever you'd like so for
40:29 - example real quick let's say that we
40:30 - wanted to scrape this page and save it
40:32 - to a CSV file so we've already done the
40:35 - hard part of getting the information
40:36 - that we want so to save it to a CSV file
40:39 - we could simply come up here to the top
40:42 - and I'll say import CSV and then here
40:46 - towards the top of our file before our
40:49 - for loop we can just open up a CSV file
40:54 - now I'm not gonna go into as much detail
40:56 - here but we could use a context manager
40:59 - here but the way that this is currently
41:01 - set up I think it's just a little bit
41:02 - quicker and easier to just open up the
41:04 - file directly so I'm gonna say CSV file
41:07 - is equal to open and I'm going to open a
41:11 - new file I'm just going to call this CMS
41:13 - underscore scrape dot CSV and we want to
41:17 - open this in write mode and now we can
41:19 - write some header lines to set up our
41:21 - CSV file so I'm gonna say CSV underscore
41:25 - writer is equal to CS v dot writer and
41:30 - we want to pass in that CSV file and now
41:35 - we can write our header lines into our
41:37 - CSV file so basically what we're going
41:40 - to be putting into the CSV so I'm going
41:42 - to say CSV writer dot right row and we
41:46 - want to pass in a list of what we want
41:49 - to write so first we're going to write
41:50 - the headline second we're going to write
41:52 - the summary and third we're gonna write
41:55 - the video that's all the information
41:58 - that we posted from those posts or that
42:00 - we parse from those posts sorry now
42:02 - again I'm not going into as much detail
42:03 - here but if you've never worked with CSV
42:06 - files before and don't know exactly
42:07 - what's going on here then I do have a
42:10 - separate video that goes into deeper
42:12 - detail into CSV files so I'll also be
42:15 - sure to put a link to that video in the
42:16 - description section below as well but
42:19 - for now now within our four
42:22 - where we're getting our scraped
42:23 - information let's just write that
42:25 - information to our CSV file so at the
42:27 - very bottom of our loop I'm going to
42:30 - copy this CSV writer here at the very
42:32 - bottom of our loop I'm going to say CSV
42:37 - underscore writer dot write row and we
42:41 - want to write the headline and the
42:45 - summary and the YouTube underscore link
42:49 - okay and lastly here on the outside let
42:53 - me close the output there so we can see
42:55 - a little bit better lastly since we
42:58 - didn't use a context manager for the CSV
43:01 - file we need to close our file at the
43:03 - end of the script so I'm going to say
43:05 - CSV underscore file dot close ok so now
43:09 - whenever we run our script it should
43:10 - create a CSV file so let me go back to
43:15 - my Finder window here and this is the
43:17 - CSV file that I created at the very
43:19 - beginning of the video to show you what
43:21 - our final product would look like let me
43:23 - erase that and delete that and now let
43:26 - me run our script that we just wrote so
43:29 - that is running it printed out all this
43:31 - information in the terminal but also if
43:34 - I open finder back up then we can see
43:37 - that that CSV file was created again so
43:41 - this is the old one here let me close
43:43 - that down and this is the new one that
43:47 - we just created so again let me format
43:50 - this a little better here I will put the
43:52 - columns to be size of 300 and put the
43:57 - word wrap 1 so now we can see that we
43:59 - have all of that data that we scraped
44:02 - available here in a spreadsheet so now
44:05 - it's a bit easier to read all of that
44:07 - information that we pulled down so
44:10 - that's kind of cool that we wrote a
44:11 - script to go out to that website parse
44:13 - out all of that information and save it
44:15 - to this CSV file
44:17 - so this would be extremely useful for a
44:19 - data collection or putting together
44:20 - reports or whatever whatever it is that
44:23 - you need ok so everything that we've
44:25 - done in this video so far is stuff that
44:27 - we also did in the beautiful soup video
44:29 - but let me show you a couple of extra
44:31 - things that we can do with request HTML
44:33 - that we didn't do with
44:35 - sooo so first of all it's a common thing
44:38 - to just want to get all of the links on
44:41 - a site so perhaps you're writing a
44:43 - crawler and want to visit each page on a
44:46 - site or something like that
44:47 - well that's so common that there's
44:49 - actually a links attribute in the HTML
44:52 - object that has a set of all the links
44:55 - on a page so let's go back to our script
44:58 - here and see what this would look like
45:00 - now I'm going to close out our output
45:03 - there I'm just going to comment
45:05 - everything out here and also I'm going
45:09 - to comment out our CSV stuff I'm just
45:12 - going to work with this website data for
45:18 - now so let me paste that in okay so like
45:21 - I was saying it's so common to want to
45:23 - just get all of the links on a website
45:24 - that HTML or that request HTML makes
45:27 - this very easy for us so to do this I
45:30 - can simply print our dot HTML dot links
45:34 - so if I save that and run it then this
45:38 - gives us a set of all the links on a
45:40 - website now this is a bit difficult to
45:43 - read so you can actually loop over that
45:45 - as well
45:45 - so I could say for link in our dot HTML
45:51 - that links and for every link we can
45:56 - just print out that link so if I save
45:59 - that and run it then we can see that now
46:01 - this prints out those links in a bit
46:04 - easier to read now I don't think that I
46:06 - have any relative links on my page but
46:09 - if you do have relative links and want
46:11 - to instead get absolute URL for your
46:13 - links then instead of using links here
46:15 - you could use absolute links so absolute
46:19 - underscore links if I save that and run
46:22 - it this is pretty much going to look the
46:24 - same but if you have relative links then
46:27 - it prints out the absolute path for
46:30 - those links instead of the relative path
46:31 - now another really cool feature with
46:33 - request HTML is the ability to grab text
46:36 - that's dynamically generated by
46:38 - JavaScript now I don't think something
46:41 - like beautifulsoup has a way to do this
46:43 - out of the box so let's take a look at
46:45 - an example so if you remember that first
46:47 - HTML file that I had say
46:49 - my machine had some text that was
46:51 - dynamically created with JavaScript so
46:54 - let's go back and take a look at that
46:55 - again so I'm gonna open up the HTML and
46:58 - I will also open that up in the browser
47:02 - as well so let me resize this so we can
47:07 - see here at the bottom of the page it
47:08 - says this is text generated by
47:10 - JavaScript so if I look in my browser
47:14 - and inspect this text so let's see what
47:18 - this looks like then it just looks like
47:21 - text and a paragraph tag within the
47:24 - footer whenever I actually inspect that
47:26 - in the browser but if we actually look
47:28 - at this in the HTML let me make this a
47:31 - bit larger here so that we can see if we
47:33 - actually look at this in the HTML then
47:36 - we can see here's our entire footer here
47:39 - we don't actually have that text in our
47:43 - footer but I have some JavaScript here
47:46 - at the bottom of the page that adds that
47:49 - text to the footer but the page actually
47:51 - has to render and run that JavaScript
47:53 - before the text gets added to the footer
47:55 - so usually libraries have trouble
47:57 - getting dynamic data like this but we
48:00 - can do this with request HTML so first
48:03 - let's look at the result before we
48:05 - render the page so I'm going to make
48:07 - this large again and go back to our
48:10 - scraper here and I'm going to uncomment
48:12 - out the part where we were working with
48:14 - that simple
48:15 - HTML document and I'm just going to
48:17 - comment out everything beneath it so let
48:20 - me put in some blank lines here so we
48:22 - have some space so like I was saying
48:24 - let's look at the result that we get
48:25 - before the page is rendered so I'm gonna
48:28 - say match is equal to HTML dot find and
48:32 - I'm going to find the footer and I will
48:38 - say first is equal to true and now I'm
48:41 - going to print that match dot HTML so
48:46 - let me save that and run it and if we
48:49 - run that then we can see that the
48:50 - dynamic text isn't included in our
48:53 - response here but if we want to render
48:55 - the page in order to get the dynamic
48:57 - data then as simple as coming up here
49:00 - underneath the HTML
49:02 - here and just simply saying HTML dot
49:05 - render so now the first time that you
49:09 - run this it might need to download a few
49:11 - things from chromium in order to use
49:13 - this functionality so don't worry if you
49:16 - see it downloading some stuff here but
49:18 - I'm going to run this and I've already
49:20 - run this command once on my machine so
49:22 - it doesn't need to go out and download
49:24 - anything but you might see yours
49:26 - downloading something at this point but
49:28 - once it's downloaded and you rerun it
49:30 - then we can see that the text generated
49:33 - by JavaScript is now included here in
49:35 - our footer so I think it's really cool
49:37 - that HTML or that request HTML allows us
49:41 - to do this out of the box okay now the
49:43 - last thing that I want to show you with
49:44 - this library is its ability to do
49:46 - asynchronous requests now if you don't
49:48 - know the difference between synchronous
49:50 - and asynchronous basically when you make
49:53 - a synchronous request you have to wait
49:55 - until we get a response back before we
49:58 - continue on with our script but when we
50:00 - make an asynchronous request we can move
50:02 - one and do other stuff in our script
50:04 - while we wait on the response so I have
50:07 - another file pulled up here and I'm
50:10 - going to show you both a synchronous
50:12 - version and an asynchronous version of
50:14 - getting responses from a certain website
50:17 - so let's look at the synchronous version
50:20 - first and we can time this so here I
50:23 - have a script that goes and does some
50:25 - synchronous requests to some websites so
50:28 - the website that I'm using for this test
50:30 - is called HTTP bin org and it was
50:33 - written by the same person who wrote the
50:35 - requests and requests HTML libraries so
50:38 - it's a cool website that allows you to
50:40 - test different requests and responses
50:41 - and for this example I'm going to use a
50:43 - route that simulates a delayed response
50:46 - depending on the number that we pass
50:48 - into the URL so in this synchronous
50:50 - version we're just going to these URLs
50:52 - and printing out the results so we're
50:54 - going to a route that is going to be
50:56 - delayed by one second here another route
51:00 - that's going to be delayed by two
51:01 - seconds and a third route that is going
51:03 - to be delayed by three seconds and I'm
51:06 - starting a timer before the first
51:08 - website and then getting the time after
51:10 - all of the websites have printed their
51:12 - responses to see how long that took now
51:15 - since this is running
51:17 - it's going to go make the first request
51:19 - and wait for a response then make the
51:21 - second request and wait for a response
51:23 - and then make the third request and wait
51:25 - for the response so we can imagine that
51:27 - this should probably take a little over
51:29 - six seconds since one plus two plus
51:32 - three is equal to six and those are all
51:35 - of our delays so if I run this then we
51:39 - can see that we got the first website
51:40 - back now the second and now the third
51:44 - and it tells us that it took about six
51:46 - point six seconds so that's about what
51:48 - we would expect okay so now let's take a
51:50 - look at the asynchronous version of this
51:53 - same test so I have this different file
51:56 - open here called async snippets so we
51:58 - can see that there is a bit more code
52:01 - here but let's look through this here so
52:04 - first we're importing async HTML session
52:08 - and then towards the middle of our
52:10 - script here we're creating an async
52:13 - function for each website that we want
52:16 - to visit and I'm not going to go into
52:18 - async code in this video that topic
52:21 - probably requires several videos just on
52:23 - its own but within these async functions
52:26 - we're saying a wait and then returning
52:29 - and then getting these URLs so if I
52:32 - scroll down here a little bit then we
52:35 - have this line here results is equal to
52:38 - asynchronous section sex session dot run
52:41 - and we are running all three of these
52:43 - async functions here get delay 1 get
52:46 - delay to get delay 3 so that is going to
52:48 - go and get the responses from all of
52:50 - those sites but it's going to do this
52:52 - asynchronously which means that as it's
52:55 - waiting on one response it's going to go
52:57 - ahead and move on and try to get a
52:59 - response from the next one and once it
53:01 - has responses from all of those we're
53:03 - looping over the responses right here
53:06 - and printing out those results so in
53:09 - this case we're just printing out the
53:11 - URLs and then we are ending the timer
53:14 - here and printing out how long it took
53:17 - in total so in this case we can imagine
53:19 - that the execution time is going to be
53:21 - around 3 seconds because when it makes
53:24 - the request with a one-second delay it's
53:27 - going to move on to the next without
53:28 - waiting for a response like it
53:30 - synchronously so basically it will make
53:32 - requests for all of them around the same
53:35 - time and then manage results as they
53:37 - come in
53:38 - and since our longest requests should
53:40 - take only about three seconds then
53:42 - that's how long it should take us to get
53:44 - some results back so if we run this then
53:48 - let me wait for the results here okay so
53:51 - we can see that it took just a little
53:53 - over three seconds so that's about half
53:55 - of the time that it took to run
53:57 - synchronously so if you have a lot of
53:59 - websites to parse then doing it a sink
54:02 - or so they could save you a ton of time
54:04 - so if you can imagine you had to crawl
54:06 - you know ten different api's that took
54:08 - three seconds each to compute a response
54:11 - then if you did that synchronously then
54:13 - that could take over 30 seconds but if
54:15 - you did a synchronously then it would
54:17 - take around three seconds so it's
54:19 - definitely something to think about if
54:21 - you're doing something like that okay so
54:23 - I think that is going to do it for this
54:24 - video hopefully now you have a pretty
54:26 - good idea for how you can go out and
54:28 - scrape information from websites now one
54:31 - thing I do want to mention is that if
54:33 - you want data from a large website like
54:36 - Twitter or Facebook or YouTube or
54:38 - something like that
54:39 - then it may be beneficial for you to see
54:40 - whether or not they have a public API so
54:43 - public api's allow those sites to serve
54:46 - up data to you in a more efficient way
54:48 - and sometimes they don't appreciate it
54:50 - if you try to scrape their data manually
54:52 - they'd rather you use an API instead but
54:56 - it's usually those larger websites that
54:58 - have public api's like that so if you
55:00 - want data from a smaller website then
55:02 - you'll usually have to do something like
55:03 - we did here now I also want to point out
55:05 - that you should be considerate when
55:07 - scraping websites computer programs
55:09 - allow us to send a lot of requests very
55:11 - quickly so be aware that you might be
55:14 - bogging down someone's server if you
55:15 - aren't careful so try to keep that in
55:17 - mind so you know after this tutorial try
55:20 - not to go out and Hammer my website with
55:22 - a ton of different requests through your
55:24 - program and that goes for other websites
55:26 - as well and some websites will even
55:28 - monitor if they're getting hit quickly
55:30 - and can block your program or IP address
55:32 - if you're hitting them too fast some
55:35 - websites will actually try to block BOTS
55:36 - completely and but that's another good
55:38 - thing about request HTML is that it
55:40 - spoofs a user agent for us to make it
55:43 - seem like a
55:44 - real web browser so it's hard for people
55:46 - to tell that you're using a program in
55:48 - this case okay but other than that if
55:50 - anyone has any questions about what
55:51 - we've covered in this video then feel
55:53 - free to ask in the comment section below
55:54 - and I'll do my best to answer those and
55:56 - if you enjoyed these tutorials and would
55:57 - like to support them then there are
55:59 - several ways you can do that the easiest
56:00 - ways is something like the video and
56:02 - give it a thumbs up and also it's a huge
56:03 - help to share these videos with anyone
56:05 - who you think would find them useful and
56:06 - if you have the means you can contribute
56:08 - through patreon and there's a link to
56:09 - that page into the scripts in section
56:10 - below be sure to subscribe for future
56:12 - videos and thank you all for watching
56:24 - you