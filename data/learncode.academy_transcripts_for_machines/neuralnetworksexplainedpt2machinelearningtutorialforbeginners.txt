in the last video i showed you a presentation on how a neural network works and what's going on underneath the hood so to kind of help illustrate it in a different way we're going to do a reallife training scenario here and we're going to actually do a ton of console logging and output to actually help you see what it's doing to the real data that we're training so i've gone ahead and hacked brain.js and added tons of console logging that should really help us understand what it's doing to our training data and then if you've been following the examples we've done in the past videos all of which will be in the description then you'll really understand this this is very simple what we're doing we're creating a neural network and we're training it with one piece of data and we're only doing one training iteration which of course is silly in real life because normally we'd have tons of training data and 20 000 or so iterations but we don't want to do that because that'd be just log bonanza so we're gonna go ahead train this one piece of data one time and let's show you what happens so there we go i've gone ahead and run it and let me scroll back through my logs yes this is all a mess and before i start going through this i'm going to take the final log output and put it in a gist and add it to the description here because if you step through this it actually is really really helpful this is doing things like this actually helped me understand how neural networks work when i was learning them so what we've done is we've ta we've started training it says hey here's our training data we have basically one piece of data and it's got an input and an output so let's go ahead and run input set 0 which is this whole thing right here we only have one piece one input set and so then we're going to look at our neural network hey layer two which is this layer right here layer number two it has three nodes layer three has two nodes so layer two has three nodes let's start with node zero so we're gonna calculate this node then calculate this node then calculate this node and then we're gonna move on to these calculate this calculate this so let's start with node zero hey look we've initialized it with a bias there's our bias and we've also initialized weights for each of our input values so zero has been given a weight and dimension one has been given weight so dimension zero which happens to be zero has been given this weight and that so we're going to calculate the node value which is zero times this one times this number we're going to add those two calculations together and then add our bias as well and we end up with a value for that node but we're not done yet then we're going to run that through the sigmoid function because our neural network by default with brain will use the sigmoid function and there we go that is the value for our node node one is done boom let's go start with node two which i'm actually calling node one there uh node zero node one and now node one we're gonna do the exact same thing different biases different weights same values same input values zero and one now we're going to go on to node two same thing new bias new weights same input values of zero one you can see we have all of our sigmoid output values done so now let's move on to layer three layer three has two nodes two output layers for our neural network so there we go we have our biases and look we have three inputs now because we have three of those middle hidden layers here's those outputs you can see 0.45 0.47 and 0.459 for example node number 3 has 0.459 there's that number so that's our input to the next layer and we're going to multiply those by the weights we're going to sigmoid them and now our two output nodes have a final value so there's our final value let's go ahead and calculate the error the delta uh and then we're going to go ahead and back propagate and we're gonna go make some adjustments to the weights here's our weight adjustment formula it's our learning rate times the delta times the value of the current weight and we're also going to add the momentum plus the prior change that we made which is going to be zero right now because we didn't make a prior change in the last step so this is basically just doing that for step number one this is gonna output to zero so then we're going to go ahead and make an adjusted change point zero zero two we've modified our weight for this layer we've modified the weight and we've modified our bias as well down here we've adjusted the bias by that much so we adjusted our bias we adjusted our weight let's go down to the next layer and let's go down to the next layer we've adjusted all of our biases and our weights we're ready for the next iteration so let's go change this now let's run two iterations and let's look at what happens on iteration number two it's going to look exactly the same except for the weights and the biases are all going to be different the weights have changed the biases have changed ever so slightly because our our learning rate is 0.03 we don't want to make these brash guesses and say oh you showed me one piece of data one time well now i know exactly what the answer is um if you'll notice now our momentum times change has changed a little bit since we had a prior change value we actually have a little bit of momentum right now so last iterations change value is going to slightly affect this iterations change value basically if this number was on its way down we're going to make sure it keeps it wants to go down at least a little bit and so that's basically how that works that is two iterations on one piece of data and if we were to then go ahead and change this let's go ahead and give it two pieces of data let's say that equates to a one and a one well now we're gonna do four complete loops let me scroll up here pardon with me we're gonna do four loops through our neural network we're going to say hey we're training we have two pieces of data here and so we're doing two iterations so it's going to take these two values put them in the inputs run them through the neural network then it's going to take these two input values input sets run them through the neural network that's training iteration one and then it's going to take all of them and run it through training iteration two again and we're going to keep doing those iterations until we've either reached the desired error level or the desired count of iterations when we're done here i can console log once we have a trained network i can console log let's stringify this because it's going to be json we're going to json stringifynet.2json so i'm going to output the json of what i have here and i'm going to stringify that so it's easy to see so when our train network is done this is actually what we've come up with we have some sizes here we can see our sizes are two three two you can change this in the options but that's what it shows and then here's our layers our final train network has biases and weights for all of our different layers biases and weights you can see that we used a sigmoid activation function which is the default and then these were our training options and our default error threshold there we go we've trained a neural network and this right here this json object is our trained neural network we can now take two pieces of input without knowing the output run it through this network and the output should work i say should because clearly this is just made up data and we only did two iterations so that's how a neural network works hopefully you're comfortable now looking at a diagram like this and understanding what's actually going on how it's calculating really complex outcomes from from data that would be hard to predict otherwise neural networks are awesome they're tons of fun getting to them the documentation for brain.js is great it's really easy to pick different activation functions to change the amount of hidden layers in your network play around with it have fun with some data sets that are available online and have a great day you