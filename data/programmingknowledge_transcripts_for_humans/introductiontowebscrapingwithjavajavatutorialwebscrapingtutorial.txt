With timestamps:

00:02 - hi guys in this tutorial I'm going to
00:05 - show you how to scrape website with Java
00:07 - you will need the basic understanding of
00:09 - the Java language maven and a web
00:11 - browser as an example I will show you
00:15 - how to script Craigslist search page and
00:17 - export the results into a JSON array I'm
00:21 - going to search for an iPhone 8 and see
00:24 - what happens here we have a huge list of
00:28 - results and as you can see there are
00:30 - several parameters in the URL this is
00:34 - the request that we are going to
00:35 - reproduce in our java code you can see
00:39 - the the HTML code for a specific item
00:41 - with a right click on an element and
00:44 - then inspect all these items are list
00:47 - elements with a class result row you
00:51 - move your mouse on a Dom element chrome
00:53 - will highlight this element on the page
00:55 - it's a real nice feature to visualize
00:58 - how the basis structure if we expand the
01:01 - inner HTML of an item we can see the
01:04 - HTML code for the price title etc these
01:08 - are the information that we are going to
01:10 - extract with our code now let's create a
01:13 - new project and add some dependencies to
01:16 - our bomb that XML we will use HTML unit
01:20 - which is a headless browser for Java the
01:23 - headless browser is basically a browser
01:25 - without any graphical interface we can
01:27 - control HTML unit with our Java code and
01:30 - since it doesn't need any graphic
01:32 - interface it can also be run on the
01:34 - server you can do many things with HTML
01:38 - units such as making HTTP requests
01:41 - selecting Dom elements submitting forms
01:44 - executing JavaScript or manipulating
01:46 - cookies the next thing we'll need is the
01:49 - jackson library to convert java object
01:52 - to json format i've created an item
01:55 - class to store Craigslist results it's a
01:58 - really basic class with three fields the
02:01 - title the price and the URL i could have
02:05 - added many more fields like the location
02:07 - the image level the item description but
02:11 - for this example this will be enough
02:13 - i've created a simple class
02:15 - called scraper with a main entry point
02:18 - we will need an HTTP client to perform
02:21 - the initial request htmlunit
02:24 - provides an HTTP client called web
02:27 - client we can set some options such as
02:30 - enabling JavaScript enabling CSS or
02:34 - setting up proxy and lots of other
02:36 - options as you can see then we will need
02:40 - to search around that you can copy from
02:42 - your browser address bar
02:53 - now we have to create an HTML object to
02:56 - receive the content and tell our client
02:59 - to go to the search URL and then I just
03:03 - print the HTML code and receive from the
03:05 - server into the console
03:15 - I'm going to run this code again in
03:18 - debug mode to show you some interesting
03:20 - methods I'm selecting every items on the
03:24 - page with an XPath expression XPath is a
03:27 - query language for selecting HTML nodes
03:31 - I'm not going to teach you XPath in this
03:33 - video but you will find lots of
03:35 - information about it in my book or
03:37 - elsewhere online the first XPath
03:41 - expression we are going to use is the
03:44 - one we saw earlier this one we need to
03:48 - use the get by XPath method on our HTML
03:51 - page object it will return a list of all
03:55 - the elements matching this expression if
03:58 - you want to get only one element you'll
04:01 - need to use get first by expect as you
04:05 - can see it returns the 120 items that
04:09 - are on the result page the first thing
04:14 - we need is a list of HTML elements to
04:17 - store every items on the result page we
04:22 - have to check if this thesis committee
04:24 - then we iterate through this list and
04:27 - for each elements we will extract the
04:30 - title URL and price the URL and the
04:35 - title are inside an anchor element as
04:38 - you can see here the XPath expression is
04:42 - easy it's an anchor located just after P
04:45 - elements with a class result info
04:52 - same thing for the price located in
04:56 - spend tag with a class result price it's
05:01 - possible that an item doesn't have any
05:03 - price so we have to check this and then
05:07 - we can create an item object and set all
05:10 - the properties
05:16 - for the price we have to get rid of the
05:19 - dollar sign since it's a big decimal and
05:22 - we can now use the Jackson library to
05:25 - convert our item objects to adjacent
05:27 - string and print it
05:34 - thanks for watching this video I hope
05:36 - you guys enjoyed this tutorial if you
05:38 - want to learn more about this subject
05:40 - you can check out my book the Java web
05:43 - scraping handbook you can find the link
05:45 - in the description I also have a blog
05:47 - where I wrote many parts about web
05:49 - scraping with Java don't hesitate to
05:52 - give me some feedback in the comments
05:53 - see you soon for the next tutorial

Cleaned transcript:

hi guys in this tutorial I'm going to show you how to scrape website with Java you will need the basic understanding of the Java language maven and a web browser as an example I will show you how to script Craigslist search page and export the results into a JSON array I'm going to search for an iPhone 8 and see what happens here we have a huge list of results and as you can see there are several parameters in the URL this is the request that we are going to reproduce in our java code you can see the the HTML code for a specific item with a right click on an element and then inspect all these items are list elements with a class result row you move your mouse on a Dom element chrome will highlight this element on the page it's a real nice feature to visualize how the basis structure if we expand the inner HTML of an item we can see the HTML code for the price title etc these are the information that we are going to extract with our code now let's create a new project and add some dependencies to our bomb that XML we will use HTML unit which is a headless browser for Java the headless browser is basically a browser without any graphical interface we can control HTML unit with our Java code and since it doesn't need any graphic interface it can also be run on the server you can do many things with HTML units such as making HTTP requests selecting Dom elements submitting forms executing JavaScript or manipulating cookies the next thing we'll need is the jackson library to convert java object to json format i've created an item class to store Craigslist results it's a really basic class with three fields the title the price and the URL i could have added many more fields like the location the image level the item description but for this example this will be enough i've created a simple class called scraper with a main entry point we will need an HTTP client to perform the initial request htmlunit provides an HTTP client called web client we can set some options such as enabling JavaScript enabling CSS or setting up proxy and lots of other options as you can see then we will need to search around that you can copy from your browser address bar now we have to create an HTML object to receive the content and tell our client to go to the search URL and then I just print the HTML code and receive from the server into the console I'm going to run this code again in debug mode to show you some interesting methods I'm selecting every items on the page with an XPath expression XPath is a query language for selecting HTML nodes I'm not going to teach you XPath in this video but you will find lots of information about it in my book or elsewhere online the first XPath expression we are going to use is the one we saw earlier this one we need to use the get by XPath method on our HTML page object it will return a list of all the elements matching this expression if you want to get only one element you'll need to use get first by expect as you can see it returns the 120 items that are on the result page the first thing we need is a list of HTML elements to store every items on the result page we have to check if this thesis committee then we iterate through this list and for each elements we will extract the title URL and price the URL and the title are inside an anchor element as you can see here the XPath expression is easy it's an anchor located just after P elements with a class result info same thing for the price located in spend tag with a class result price it's possible that an item doesn't have any price so we have to check this and then we can create an item object and set all the properties for the price we have to get rid of the dollar sign since it's a big decimal and we can now use the Jackson library to convert our item objects to adjacent string and print it thanks for watching this video I hope you guys enjoyed this tutorial if you want to learn more about this subject you can check out my book the Java web scraping handbook you can find the link in the description I also have a blog where I wrote many parts about web scraping with Java don't hesitate to give me some feedback in the comments see you soon for the next tutorial
