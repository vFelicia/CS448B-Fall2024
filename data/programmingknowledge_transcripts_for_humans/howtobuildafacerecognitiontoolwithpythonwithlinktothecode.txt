With timestamps:

00:00 - in this video we are going to do a new
00:02 - machine learning project that is real
00:03 - time facial recognition so let me give
00:06 - you a brief overview that what is the
00:08 - output of the project then we will move
00:10 - to the roadmap that what we are going to
00:12 - do step by step okay so the output of
00:14 - the project is like this we will open up
00:16 - a laptops camera camera or webcam and a
00:20 - colored box
00:21 - uh will surround our face and our name
00:24 - will do that in the box so basically our
00:26 - laptop will recognize our face that who
00:30 - we are in partners of a name so let me
00:32 - just give you an example of that
00:35 - yeah so I've just run my test sample and
00:38 - this is my phase as you can see
00:48 - so basically our camera is recognizing
00:51 - that what is my name and what is the
00:53 - name associated that with that face okay
00:55 - so this is a real-time face recognition
00:58 - whichever system is doing so let us see
01:00 - that how we will proceed to just project
01:03 - so let me give you a road now of this
01:05 - that what we are going to do step by
01:07 - step so basically first we are gonna We
01:10 - Are Gonna feed our video that like we
01:13 - should open our camera and we should
01:15 - record that what phase is in front of
01:17 - the camera right so
01:19 - I have made several separates a snippet
01:23 - of video record it is just to check that
01:25 - whether the camera is working or not so
01:28 - by this code we can check that our
01:30 - camera is working or not
01:33 - um don't be stressed out I will explain
01:34 - each time of the code step by step I'm
01:37 - just sitting the roadmap right now okay
01:38 - so this is about just checking this this
01:42 - code stick that whether our camera is
01:44 - working or not okay so this is a real
01:48 - test and after this
01:51 - okay so after this we are gonna We Are
01:54 - Gonna collect our phase data so
01:57 - basically in this snippet uh this the
02:00 - function of this code is like this this
02:03 - code opens up a camera and uh asks ask
02:06 - ourselves to write our name okay so if I
02:09 - play this sample so it is asking my name
02:13 - so I will enter my name here and after
02:15 - that
02:16 - when I enter Then camera will open and
02:18 - it will start recording my face it will
02:21 - start uh memorizing my face and will put
02:25 - each and every data in an array okay I
02:28 - will explain this entire thing step by
02:30 - step I'm just like giving an overview
02:33 - overview right now okay so it this code
02:36 - recognizes uh this code basically
02:39 - collects our facial facial data and
02:41 - stores it in an array and that array is
02:44 - useful recognition afterwards so after
02:46 - collecting our facial data
02:48 - we will run this code this is basically
02:52 - facial recognition Okay so after
02:55 - collecting our data we will store that
02:58 - data in another area and we will start
03:00 - another live streaming I mean we will
03:03 - start our camera again and it will match
03:06 - that this current phase matches with the
03:09 - previous array and it Maps down the name
03:12 - of the person with that signal okay
03:15 - so basically first step is data data
03:18 - collection over faces and then after
03:20 - that you will do a face evaluation and
03:23 - we will use basically k-means algorithm
03:25 - in this and a classifier that is hard
03:28 - casket classifier okay so this is a
03:31 - brief overview of the project that what
03:33 - we are going to do and now I'm gonna
03:35 - explain you okay so before deeping uh so
03:39 - because before diving into the project
03:42 - let us first see that what is hard
03:44 - casket classifier okay after explaining
03:47 - this Hardcastle classifier I will
03:49 - explain you each and every lines on the
03:50 - code that but we have done step by step
03:52 - okay
04:00 - features line features and many or other
04:03 - features so basic purpose of Hawk asset
04:06 - classifier is it detects each and every
04:09 - feature of our face okay so this is a
04:11 - box it moves in every direction in the
04:14 - in the entire image and it just collects
04:18 - the data that varies our eyes where is
04:20 - our nose I'll show you the animation
04:22 - that how it works before that list you
04:25 - can just see on this website that how uh
04:28 - what is the basic documentation of
04:29 - Hardcastle classical
04:31 - um after this I will show you the
04:33 - animation of this okay so I've done the
04:35 - basic of this so if I enter my image
04:39 - here and the Hardcastle classifier will
04:41 - basically uh classify that where is our
04:45 - eyes and where is our face located in
04:47 - that that entire image okay so as you
04:50 - can see that here is my face and these
04:52 - are my eyes so this simple code which
04:55 - uses hard casket player has just
04:57 - recognized that where are my eyes and
05:00 - where is my face in the entire image
05:02 - okay so now let us see that uh this
05:05 - anyway hard gasket animation
05:09 - foreign
05:13 - classifier is just moving in the entire
05:15 - image and it is just classifying that
05:18 - where is our face and where are the
05:20 - other components of the face so as you
05:23 - can see that uh The Edge features uh
05:25 - line features and the other features of
05:27 - the casket classifier just checking that
05:31 - where are the main features of our face
05:34 - okay so it is traversing the whole image
05:36 - by increasing the size so just see the
05:39 - animation
05:45 - I've increased the size of the uh the
05:47 - speed of the video to 5.5 X so you can
05:50 - see clearly
05:53 - okay so this is how hard cast can
05:55 - classifier works okay
05:58 - so I hope that you will get and you have
06:00 - got a basic idea of that how and
06:03 - Hardcastle classifier works so in this
06:06 - video in this project we are we will be
06:08 - using that hard casket classifier to
06:11 - detect our facial components and after
06:14 - detecting that storing that face into an
06:16 - array mapping that with the name of the
06:19 - person and just recognizing that again
06:21 - by our key means algorithm okay so
06:24 - before that before starting data
06:27 - correction let us check that whether
06:29 - your camera is working or not okay so by
06:33 - this code we will just take that whether
06:35 - our camera is working yes or no okay so
06:39 - let me just explain you this code
06:40 - so this code starting with like we will
06:43 - import CB2 like we will we are importing
06:45 - opencv library and by this cap is equal
06:49 - to CB2 let me just
06:51 - zoom in zoom in okay so second line that
06:54 - cap is CV dot video capture it means
06:57 - that just open our webcam okay so this
07:01 - Line opens up a webcam and
07:03 - this Loop just tells that if our webcam
07:07 - is reading our image
07:10 - then just continue and if it is false
07:14 - then move out of the loop okay so it
07:18 - shows like a video frame it uh okay so
07:21 - let me just open the camera
07:24 - I'm playing this
07:26 - and
07:40 - so as you can see that our camera has
07:42 - been opened and after that this camera
07:46 - name just uh the name of a camera is
07:48 - frame as okay as you can as you have
07:51 - just seen before and after this I have
07:55 - entered this logic that if I press q q
07:59 - as the key if I press the key Cube then
08:02 - it uh breaks the camera and closes the
08:05 - window and the camera will not be closed
08:08 - by the simple uh closing function it
08:12 - will be only closed if you enter queue
08:13 - okay so this is a logic which I entered
08:16 - and I will explain you the purpose of
08:18 - that why I have entered this okay and
08:21 - this is a key pressed this line simply
08:23 - means that uh
08:25 - if our currently pressed key matches
08:28 - with this key or not
08:30 - this is that's it and I will explain
08:32 - this in the meaning of this line later
08:34 - in this project when we are doing data
08:36 - collection
08:37 - okay I will explain the logic behind
08:39 - this that why I am bitwise why I have
08:43 - used bid base and here with ux FM okay
08:47 - so for right now you have to just
08:49 - understand that we have just opened the
08:52 - camera and just checked that if return
08:54 - is equal to false then we will just
08:56 - continue and if our camera is reading
08:58 - then we will just move
09:00 - to move forward and just show the camera
09:04 - that and to stick that with the camera
09:06 - is open or not and we'll just uh close
09:08 - that camera by pressing the Key Queue
09:11 - okay and after that we will release our
09:14 - camera tapped or at least if when we
09:17 - break out of the loop then we just uh
09:20 - the ease of a camera by this line This
09:23 - Means closing the camera and by this it
09:26 - means you're destroying all windows
09:27 - means
09:29 - um
09:29 - disabling all the cookies that has been
09:32 - formed by opening the captain and
09:34 - deleting all the data which has been
09:36 - captured in the back memory okay so this
09:39 - is basically a video Read we are just
09:42 - checking that our camera is reading the
09:44 - video or not
09:45 - okay so I hope that you have got a clear
09:48 - idea that what is this okay so after
09:52 - that we'll do facial data collection we
09:55 - have covered this video Read part like
09:57 - we are just thinking that how video is
09:59 - being readed from your webcam of the
10:01 - laptop or computer and how it has been
10:04 - processed and how it is the video has
10:07 - been stopping so in today's video we're
10:09 - gonna see that how the laptop camera or
10:13 - webcam is reading your face data and
10:16 - storing it in an array to like detect
10:19 - further okay
10:21 - so this file phase data consists that
10:24 - how a phase data is being storing in the
10:28 - memory of computer and we will process
10:30 - it later when we are doing phase
10:32 - detection using knot Okay so
10:36 - so let's get started about it so I will
10:39 - explain you line by line that what each
10:41 - line is doing
10:42 - so so let's get started
10:45 - so first we import two libraries like
10:48 - opencv and numpy Library opencv2 like
10:51 - read the camera feed or open the camera
10:53 - and numpy has basic array operations and
10:57 - some more operations okay so by this
10:59 - line we are just reading we are just
11:00 - opening our webcam and
11:03 - um in this variable cap our webcam has
11:06 - been storing the data is being storing
11:08 - in this cap okay so after that we are
11:11 - using like in previous video I've shown
11:13 - you a hard casket classifier that that
11:15 - is classifying the facial components of
11:18 - the face okay so we have just imported
11:21 - this hard casket classifier in this
11:23 - variable and
11:25 - like this is the location of our gasket
11:28 - classifier so before starting the
11:30 - project uh just see here it is in my D
11:33 - folder D drive and this folder
11:39 - uh we will just download this from the
11:42 - internet it is easily available on
11:44 - GitHub so just download it or I'll give
11:46 - the link in the description okay we do
11:50 - have to store this hard casket file in
11:52 - this directory only so like
11:56 - just wait a second
11:58 - so in my data in my D drive I have a
12:01 - folder called face immigration project
12:03 - and in this folder I have this file hard
12:07 - casket classifier file okay this is hard
12:10 - casket frontal face
12:12 - so you have to just download This by
12:14 - only and this is the mainly classifier
12:17 - we are going to use here so
12:20 - we have just imported this classify here
12:22 - in this variable so let's move forward
12:26 - this script variable just means that uh
12:29 - it I will experience this later when we
12:31 - are just using the script variable here
12:33 - for now just ignore it and in this space
12:37 - data array this is basically a list in
12:40 - which we will be storing each phase data
12:43 - okay so don't be confused you will get
12:46 - clear understanding later when we are
12:49 - proceeding towards it and this data set
12:51 - path is Page data set so this means that
12:56 - the faces which we are storing has to be
12:58 - downloaded or has to be stored in the
13:01 - computer's membrane okay so like if I
13:03 - open my camera and store my face
13:06 - so my computer has to download that face
13:09 - and store that file in a particular
13:11 - folder right so I have just created this
13:14 - folder here so
13:17 - so as you can see that in my D drive
13:19 - I've created a folder field data set by
13:21 - this line okay and this phase data set
13:24 - contains all the files that has been
13:27 - deleted through my camera so if I open
13:29 - it I have just
13:33 - um I have just recorded my face and
13:35 - given my name to this like anything and
13:39 - this uh every data of my camera feed is
13:43 - stored in this data folder in this
13:45 - folder Okay so
13:48 - let's move forward so um so like when we
13:51 - open our camera then we will enter our
13:54 - name there as I just shown you in the
13:56 - previous video when we open the camera
13:58 - we enter our name and after that video
14:01 - starts recording and our face is
14:04 - starting getting recognized and feeding
14:06 - the camera Okay so
14:09 - or we are just giving the input that
14:11 - when we open the camera
14:13 - just enter our name and index and in the
14:17 - console uh this dialog box will appear
14:20 - in where we have to enter our name don't
14:23 - worry I will just when I will just play
14:25 - this video like when I play this code
14:27 - then you will see that but this line is
14:29 - actually doing here in the console
14:31 - okay
14:33 - okay so let us just now uh play it once
14:37 - so when we play this file then this cons
14:40 - in this console you can see that here it
14:42 - is coming like enter your name like
14:45 - enter the name of person so when I write
14:47 - my name here like this and press enter
14:49 - Then the camera will open okay so as of
14:52 - now I'm just stopping this program we
14:54 - will do this later okay so I've just
14:57 - shown you that what how it is being
14:59 - appeared in the console
15:01 - okay so let us move further so now we
15:05 - are opening our camera and we will store
15:07 - our data field now okay so in in a while
15:10 - loop which is always true we are just
15:13 - doing this code so let me just explain
15:14 - that what we are doing here
15:16 - okay so this red comma frame is equal to
15:20 - Capital it means that red is basically a
15:22 - Boolean variable which just check that
15:24 - camera is open or not and frame
15:26 - basically captures uh as a variable
15:29 - where we are defining our camera Okay so
15:33 - and here we are just checking that if
15:36 - the camera is not open then just
15:37 - continue and don't do this iteration and
15:41 - this lines means that we are just
15:44 - converting our uh like initially we will
15:48 - be having a colorful image like we all
15:50 - are colorful right so initially our
15:52 - images are RGB image
15:55 - and in Python we just like RGB like we
15:58 - like we let BGR instead of RGB every
16:00 - time so in this line we are converting
16:04 - our
16:05 - RGB image to a grayscale image okay and
16:09 - to convert that we use this type of
16:12 - syntax like CV2 dot CVT color
16:16 - and frame which is storing your camera
16:19 - feed and CV2 dot color BGR to create BGR
16:24 - to gray means we are converting pgr like
16:27 - R it means RGB we are converting RGB to
16:31 - grayscale take it so this is a syntax
16:35 - so our gray so initially we are having
16:38 - frame in this Frame we are we are having
16:41 - a colorful image and now in this gray
16:44 - frame we will have we will be having a
16:46 - gray scale image okay so grayscale we
16:49 - have converted it to graysk limit
16:51 - because in KN and Quantum it is much
16:53 - easier to like understand a grayscale
16:56 - image and do the algorithm like do the
16:59 - functionalities and Grace Kelly which it
17:01 - is much easier than a colorful image and
17:03 - it doesn't affect the output output is
17:05 - much better in grayscale okay so when we
17:09 - are processing rescue okay so let us
17:11 - move forward
17:13 - and this line like phase is equal to
17:16 - face Cascade dot detect multiscale
17:19 - okay so I will I'm explaining the
17:21 - parameter that is used here so this is a
17:24 - three frame that is we just created here
17:27 - and this is a scaling Factor this is the
17:30 - number of neighbors okay so let me just
17:34 - give a comment here like
17:39 - premium
17:41 - parameters are frame name scaling Factor
17:48 - and number of Neighbors
17:51 - that we defined by K and just we write
17:57 - number of
18:01 - number of tables okay so uh number of
18:04 - neighbors is basically used in KN and
18:06 - Gotham if you don't know that clear then
18:08 - Quantum for now just keep this line I
18:11 - will explain the each and every
18:12 - functionality of scaling Factor K and
18:16 - the whole functionality of this line
18:17 - later when we IMB I will be explaining
18:20 - the KL algorithm because you will get a
18:22 - clear understanding pin Okay so
18:25 - so uh just let me give you a quick
18:27 - overview overview that what is the
18:29 - scaling Factor so initially if our image
18:31 - size if we scale down our image to 1
18:34 - then if we are doing 1.3 then simply
18:37 - means that we are just shrinking our
18:39 - image to 30 percent don't worry I will
18:42 - just explain you this step later when we
18:44 - are doing k n in algorithm so for now
18:46 - let us move further so in this line we
18:49 - are just checking that it faces length
18:51 - equal equal to 0 like if this
18:55 - um
18:56 - if this space is equal equal to 0 then
18:59 - just continue we don't have any phase
19:00 - here okay
19:02 - so as of now just understand that this
19:05 - line like this function just returns you
19:07 - the coordinates of the face captured
19:09 - like if I open the camera and the camera
19:12 - will capture my face then this function
19:14 - will return the coordinates of my face
19:17 - like top left top right bottom left
19:20 - bottom right okay so all the coordinates
19:22 - will be returned by this function to
19:25 - this faces variable okay so this so This
19:28 - lines this function is only doing this
19:30 - this is just telling the coordinates of
19:32 - faces to us okay okay so let me explain
19:36 - you that what actually
19:37 - returning us and what type of
19:39 - coordinates are they okay so just let me
19:42 - open my Notepad
19:46 - okay so this function like this function
19:49 - so let me just select uh
19:54 - okay so that's function like paste
19:56 - casket dot detect multiscale which is uh
19:59 - this variable faces just means that this
20:04 - faces is a list
20:05 - and this list is storing the coordinates
20:08 - of the face so if I draw here like
20:10 - different draw stitches like like if
20:13 - this is the person here
20:21 - [Music]
20:23 - okay so these both are faces Okay so
20:28 - these are the top coordinates like XY is
20:31 - the top coordinates of the faces and
20:32 - this is the width
20:34 - this is the height
20:36 - okay so a box it returns like this
20:40 - detect multi scale returns a block to
20:43 - you I delete it as a box in which we
20:46 - have the top left and
20:49 - we have the top left coordinates of x y
20:52 - and the height is H
20:55 - and the width is W okay so this function
20:59 - just returns
21:01 - X this function returns x y w and z
21:06 - so the W and H
21:09 - x y w n h okay so these are the
21:12 - coordinates and by this W and H we can
21:14 - just calculate it what are what can be
21:16 - these coordinates like this can be like
21:18 - X Plus H and the and pi plus W right
21:23 - like you can just calculate it by adding
21:25 - W and H in X and Y so we can get this
21:28 - these and this coordinate also so this
21:31 - function is just returning as the
21:32 - coordinates so that
21:34 - we can just make a box into the field
21:38 - around the face okay that's it about
21:41 - this latest
21:44 - okay so now let us see that the further
21:46 - code so this line like faces is sorted
21:50 - faces key Lambda X2 into X3 so what is
21:54 - it is doing so it is just arranging your
21:57 - faces like if you have multiple faces in
21:59 - the video field like if I show my face
22:01 - my sister's face my brother says
22:10 - in increasing or decreasing water as per
22:13 - our need okay so what we are doing here
22:15 - is we are passing a function name sorted
22:19 - and we are just using using a laptop
22:21 - option okay so in this uh this time
22:24 - being that we are passing our faces list
22:27 - here like in this basis list
22:31 - we have a x y h and W coordinates uh
22:36 - numbers okay and we pass this list here
22:39 - and we are just calculating so this
22:42 - means that
22:45 - okay so like faces wishes like if your
22:48 - faces
22:49 - then faces contains a list of
22:52 - X by
22:54 - W and H
22:57 - okay so it is zero Index this is bar
23:00 - Index this is three index okay so the
23:03 - area of image is what area of any image
23:06 - is
23:07 - weight into height okay
23:10 - you get into height and good thing to
23:13 - hide basically here is faces
23:16 - two
23:18 - into faces three okay this is width into
23:22 - height and this is basically area
23:24 - and the image which has larger area will
23:28 - obviously come first if we are sorting
23:30 - it in a decreasing order and if the area
23:32 - is less then it will come first in uh
23:35 - the sorted order if we are sorting it in
23:38 - an ascending order right so this so in
23:41 - this here so Lambda X is just
23:44 - representing our faces
23:46 - and we are just using the Lambda
23:49 - function here if you don't like what is
23:50 - Lambda function so that like just get a
23:53 - quick overview by seeing the documents
23:56 - okay so X is representing this faces and
24:01 - X2 into X3 basically is area of image
24:04 - area of the face or the area of the box
24:06 - which has been made okay and reverse is
24:09 - equal to True means which we are just
24:12 - arranging this in a descending order
24:14 - like we are sorting it in a descending
24:16 - order right so and these like if we are
24:20 - having faces like this first faces this
24:23 - second phase is this third phase is like
24:25 - small phase then big face and small
24:28 - piece and these all faces will be sorted
24:30 - in a descending order like first welcome
24:32 - big and small and then small this one
24:35 - okay so in this way we sort our faces
24:39 - and every data will be stored in this
24:44 - in this variable okay
24:46 - so I hope that you get a clear
24:48 - understanding of what we are actually
24:49 - doing here and now just forget this line
24:53 - as of now so now we are just we will
24:56 - just hydrate to the every phases and we
25:00 - will restore every face in our data
25:03 - so now we are we are just alternating in
25:05 - our faces again so uh let us see that we
25:09 - are starting a for Loop here and four
25:12 - Loop is going till end okay and this x y
25:15 - w h is are the coordinates of the face
25:19 - so face and faces means that it is like
25:23 - this is Phase One this is phase two this
25:26 - is phase three this is phase four like
25:28 - these are the faces and the coordinates
25:30 - of each and every phase will come in
25:33 - this x y w and H variables okay as we
25:36 - iterate over every faces then the uh
25:39 - coordinates of every face will come in X
25:42 - by W and H okay and this offset simply
25:45 - means that we are providing a padding so
25:48 - if we have done HTML before before you
25:51 - might know that what is padding what is
25:53 - margin so padding is basically a
26:01 - so if we are having our face here this
26:03 - is our face then this Gap is basically
26:06 - padding okay so this Gap is padding
26:10 - sorry about handwriting uh actually pen
26:13 - is quite cold here okay so if you are
26:15 - having a face here like
26:18 - and this is covered in a box then this
26:22 - box is having a padding of file okay so
26:26 - this length is basically five or five
26:28 - card
26:29 - okay so we are just given the padding of
26:31 - five to like uh show a clear user
26:34 - interface okay
26:37 - so as before we are just having this uh
26:40 - this box as outer box which is at which
26:43 - we are having the coordinates x y and
26:46 - everything so now here we are just
26:48 - extracting the face section so this line
26:51 - is basically extracting the section of a
26:54 - face so it is subtracting the offset so
26:58 - basically it is subtracting the padding
27:00 - and it is just uh calculating a
27:03 - particular section of a face initially
27:06 - this was padding and now we are
27:07 - discovering the particular section of
27:09 - the face okay and after that like you
27:12 - will see you can understand this easily
27:14 - like we are just subtracting offset from
27:17 - length from top and bottom and
27:20 - subtracting from left and right okay we
27:23 - are just subtracting over starting and
27:25 - just getting the section of Face by this
27:27 - line okay just go through it once and by
27:31 - this space selection we are just
27:32 - reselling a phase 200 cross 100 image
27:36 - okay so I hope that you understand it
27:39 - and now this skip so this skip just
27:43 - means that when we start recording our
27:45 - face then after every second our skip
27:49 - after every second or after
27:51 - hydration this tip will increment okay
27:54 - like we have recorded one first page
27:57 - second phase third phase like a
27:59 - particular uh time frame of the face is
28:02 - being recorded by this script by the
28:05 - script okay so after every 10 space like
28:09 - when I started the recording when I
28:11 - started recording my face so I record it
28:13 - at first second second third second
28:16 - fourth second I'm recording my face and
28:19 - every second okay so when I read the
28:21 - 10th second of camera I will just do a
28:25 - skip operation okay and after every 10th
28:30 - phase I will be recording this 10th
28:32 - phase into my array
28:34 - okay I'll be recording each 10th
28:37 - iterated face in my array so that I
28:40 - don't have many faces in my array and I
28:42 - have a good feeling and a good video
28:44 - feed like recognize later
28:49 - so as you can see that like after each
28:51 - 10th
28:53 - in titration I'm just appending my face
28:56 - into the phase data and sprinting the
28:59 - length of face that's it like
29:01 - understanding this line this line simply
29:03 - means that we are just creating a
29:05 - rectangular box
29:06 - towards our frame like frame is
29:08 - basically a section of frame a section
29:10 - of face which we are having and this
29:13 - these are the coordinates like top left
29:16 - top left coordinates and these are the
29:18 - bottom right coordinates we pass this
29:21 - these parameters at the color of the box
29:23 - which we have to display okay so this is
29:26 - RGB red green and blue so basically we
29:30 - have given green to its full number and
29:33 - red in blue to zero zero so basically a
29:36 - green color box will uh will appear out
29:39 - of your face okay so like let me show
29:42 - you that
29:43 - so so when I when I will open my camera
29:46 - so what will happen like
29:48 - a camera will open like this
29:51 - it will be a frame and my face will be
29:53 - here like I will be standing or sitting
29:56 - here and a green color box will appear
29:59 - around my face like or down the section
30:01 - of face a green color box will appear
30:04 - okay and
30:06 - by this like this is basically RGB I
30:10 - have given 0 to r0 to Blue and 255 to
30:13 - Green 255 is the maximum number that's
30:16 - why a green color box will appear if I
30:18 - give like 255
30:21 - 0 0 then a red color box will appear
30:24 - around my face red color box will appear
30:27 - so this is simply your this line is
30:29 - simply creating a rectangular box which
30:31 - will appear around this Frame frame is
30:34 - basically uh this stream Okay so
30:39 - and but this this will just show the
30:42 - frame
30:43 - like it is understandable and this uh
30:46 - this is like that if we have if a webcam
30:50 - is open then if we place an EQ
30:53 - if we press Q then the webcam will just
30:55 - switch off like I will explain the
30:58 - function of this later so let us move
31:00 - forward about things as of now
31:04 - so now after when we have stored our
31:06 - faces then after that we will we are we
31:09 - will be having a list of faces like we
31:11 - are having a list of Faces in which
31:13 - faces are faces data are stored okay so
31:16 - now to implement a KB is algorithm here
31:19 - we have to implement
31:20 - foreign
31:25 - works best in some scenarios and the
31:28 - compilation power is pretty much higher
31:31 - than list okay so we will convert our
31:34 - list so face data is basically list now
31:37 - we will convert this list to one numpy
31:40 - array by this function by NP dot array
31:44 - phase data error we are basically
31:47 - converting our space
31:49 - this is a list here as of now we will we
31:52 - are converting this to a numpy array
31:54 - okay so to have a faster computation and
31:57 - to better fit in again after converting
32:01 - it to a numpy array we will just reshape
32:03 - it okay so reshaping is a basic like
32:07 - basic concept
32:08 - you would know it and if you don't know
32:10 - like what is reshaping I would say that
32:12 - just look at the documentation like what
32:15 - it is doing
32:17 - and after this reshaping we are just
32:20 - printing our face not shape face data
32:22 - shape like whatever like what is the
32:25 - shape of the face as of now
32:27 - after that we are just saving our data
32:30 - in
32:31 - our folder which we have just made
32:34 - like this let me explain you this so
32:36 - this data set path is basically the D
32:39 - drive path which I have just uh stated
32:41 - earlier so
32:44 - so basically this this is a data set
32:46 - path and now we are the story cover like
32:51 - current data into this folder okay so to
32:54 - store our data in this folder what we
32:56 - are doing is like we are just saving our
32:58 - current data data paths file name in
33:01 - Phase data okay so file name is
33:03 - basically this
33:04 - uh when we are entering our name the
33:07 - name is stored in this file name okay so
33:10 - now just see that what we have done we
33:13 - have saved our data set plus file name
33:15 - and phase data and so if we print this
33:19 - it will be like data set like let me
33:22 - just show you if we print this what will
33:24 - happen if
33:25 - so now when we print it like it will
33:27 - come like this if the folder name is my
33:30 - data if data is my folder named in it
33:33 - and my file name is if I write my my
33:35 - name like arbit
33:39 - and extension is basically Dot npy
33:44 - because we storing this so this will be
33:47 - our
33:48 - location or Source where we are
33:50 - storybook current data okay so this this
33:54 - perfect dot npy will contain all the
33:57 - faces all the my phase data which is
33:59 - being stored in the camera feed and we
34:01 - will use this data to recognize and pass
34:04 - this data in our KN inverter
34:07 - [Music]
34:14 - webcam and this lens is just destroying
34:17 - all the windows which have been created
34:19 - by the camera like basically the frames
34:21 - which have been created here okay so
34:23 - this is the basically everything about
34:25 - is data reading and data collection so
34:29 - now we will see that how we can
34:31 - recognize the data by using algorithm
34:35 - so this is the basically the order of
34:37 - the face recognition and here I've
34:40 - implemented a Kalin algorithm that what
34:43 - the algorithm is doing okay so I will
34:45 - explain line by line that every like
34:47 - what every line of function is doing
34:49 - I'll explain everything and uh if you
34:52 - have any confusion like if you don't
34:54 - want to make KN and algorithm from
34:56 - scratch like here in this video I've
34:58 - made the this algorithm from scratch you
35:01 - can also use inbuilt Library like in
35:03 - inbuilt library comes it just works in
35:07 - simple one line and here I've used like
35:10 - two very lines here to implement it from
35:13 - scratch okay so you can use like direct
35:15 - Library function also and you can also
35:18 - like implement it from scratch
35:21 - okay so don't worry about that we'll
35:22 - just discuss everything you
35:24 - okay so before starting like a face
35:27 - recognition
35:29 - give you a quick overview that what is
35:32 - scale and got them doing
35:34 - okay so now let's see this
35:36 - okay so now let me give you an example
35:38 - of like what is Karen in a very very
35:41 - simplest way and I will show you that
35:43 - how our gains can be implemented in this
35:45 - project also okay so let us see that so
35:48 - if we are having a suppose we are having
35:52 - suppose I will give you a small example
35:54 - before like we are having a class one
35:57 - here so let me just
35:59 - so
36:02 - it is a it is my class one
36:06 - [Music]
36:07 - okay
36:10 - and I am just just like to change my
36:13 - color and
36:15 - this is my class too
36:20 - class 2.
36:27 - and in between this class one and class
36:29 - two I have a person here
36:32 - like suppose this is me
36:35 - now I have to like go to class one or
36:37 - class two and we have to find that this
36:40 - one belong to which class Like This one
36:43 - belongs to this class or this class we
36:45 - don't know as of now so what we do is we
36:48 - will find distance of current point with
36:51 - all the points and find the nearest
36:53 - point to this Green Point okay we find
36:57 - distance to every point and we'll check
36:59 - that what is the average nearest
37:00 - distance we have so suppose if
37:05 - so what we do is we find distance of
37:08 - this screen percent to every person of
37:11 - the class and we will find the top K
37:13 - persons like suppose we find distance to
37:16 - every every person in the class and
37:18 - after that finding we just categorize
37:20 - the top five percent like if we write K
37:23 - is equal to 5 then these five people are
37:26 - the nearest people to this like if a is
37:29 - equal to 5 then this three people like
37:31 - this this this three people of plasma
37:34 - and these two people of class two are
37:36 - the nearest people to this green Okay so
37:41 - a is equal to 5 simply means that these
37:44 - five peoples are the nearest K people to
37:47 - this cream color
37:49 - this green person
37:51 - okay now there are three persons of
37:54 - class one and two persons of class two
37:56 - this simply means that the we will just
38:00 - check that at which class we have the
38:03 - most number of uh nearest neighbors okay
38:06 - so this class one has the most number of
38:09 - nearest neighbors to this green green
38:11 - person okay so as class one has three
38:14 - neighbors class two has two nearest
38:16 - table so obviously we will categorize
38:18 - our this green person to class one
38:20 - because these are more nearest neighbors
38:23 - as compared to plus two okay so here
38:26 - class class one wins
38:29 - so basically this point belongs to class
38:32 - one is it is a basic overview like what
38:34 - is k n and I will explain this in this
38:37 - further videos like by giving more
38:39 - detailed examples to explain you the
38:41 - complete like how to take facial data
38:43 - and store into a numpy array and also
38:47 - shown in the basic quick overview that
38:49 - what is KN and algorithm and in today's
38:52 - video we're going to see that how Kanan
38:55 - algorithm can be implemented here and
38:57 - why should we implemented here okay so
38:59 - like
39:01 - like in this project we are like
39:03 - recognize recognizing our face with this
39:07 - but this is not the only way there are
39:10 - many other other algorithms like uh
39:13 - convolution neural networks and like
39:15 - many other things by which we can like
39:19 - recognizable face so this is what this
39:22 - is one of the method came in by which we
39:24 - recognize so let me give you example
39:27 - that how kerin can be implemented here
39:29 - so just see this
39:31 - so suppose that it is my graph and
39:35 - suppose I have stored the data of five
39:39 - people like uh four people I have state
39:42 - I have recorded the data of four people
39:44 - four of my friends and one of one it's
39:47 - me one is me and uh other three are my
39:50 - friends okay
39:52 - and total is I have four people okay one
39:56 - is one is me and three are friends so
39:59 - just let's see that suppose this is my
40:02 - this is me uh
40:05 - this is these are my face chords like
40:07 - artists I have just told you that I am
40:10 - recording my faces after every 10th
40:13 - iteration in uh and
40:15 - it will depend like when the number of
40:19 - the number of minutes or seconds or
40:21 - hours I will open my camera it my face
40:24 - will be get recorded and and due to that
40:27 - I have I will be having number of faces
40:30 - like if I open my camera for 10 minutes
40:31 - then I will be having a lot of faces
40:33 - recorded if I open my camera for one
40:36 - minute then I'll be having only six
40:38 - spaces recorded because the my faces are
40:41 - recording after every 10 seconds okay it
40:44 - is just a overview example so suppose I
40:47 - am I am I am having like my six faces
40:51 - and every friend of mine is having six
40:53 - faces story okay so this is person one
40:57 - and these are the faces of person one
40:59 - and let me change the color
41:03 - this is like this is me and suppose this
41:07 - is my friend face
41:10 - okay this is my friend's face
41:13 - and like like friend one
41:16 - and this is me
41:18 - and suppose
41:21 - time having one more friend stays told
41:26 - okay so this is my friend's three phase
41:28 - like a second frame face and
41:42 - this is these are the faces of my friend
41:44 - three okay and now I am just like these
41:48 - are just these are stored in my data
41:49 - these all pieces are stored in my data
41:52 - and now I open my camera feed to
41:54 - recognize and use gain in algorithm now
41:57 - so suppose I open my camera and I open
42:01 - up my camera like my camera face has
42:04 - been opened and a random person comes in
42:06 - the camera like it is none of us so it
42:09 - will not match with any of them and it
42:11 - will just simply cannot recognize okay
42:13 - so if I if I open my camera and I show
42:17 - my face to it like I show my face to it
42:20 - and it will recognize my face as like
42:24 - this so how it is happening so if I open
42:26 - my camera my face will come here like
42:29 - this is my camera and my face will come
42:31 - here so now my face will calculate the
42:34 - distance from every spatial data
42:37 - okay so I have to tell you that I have
42:40 - used hard casket classifier so my heart
42:42 - ask a class where I am just calculating
42:44 - my difference between faces okay so I
42:49 - will calculate the difference my of my
42:51 - face every other face is told okay
42:54 - while every other face is told I will
42:57 - calculate the difference between wire
42:58 - phase and other faces okay
43:01 - like every faces
43:03 - okay and I will just calculate like if I
43:06 - take K as 3 then
43:10 - I will just get the three nearest
43:12 - Neighbors
43:14 - three nearest Neighbors and
43:18 - obviously I will be having the least
43:20 - favorite facial difference with me only
43:23 - if I am wearing in the front of the
43:25 - camera then I will be having the least
43:27 - facial defense with me only okay so by
43:30 - this algorithm we can just state that I
43:34 - am having like
43:36 - this space means this is me and if if it
43:40 - recognize that this phase means a bit
43:42 - like my name is arpit so it will just
43:45 - recognize it and show my name on the box
43:48 - like don't be confused I will explain
43:51 - everything step by step after like
43:53 - moving into the cold so let us get
43:56 - started about that
43:58 - okay so let us get further like
44:00 - explaining that what is going down here
44:02 - so in this record phase organization
44:04 - file what we have done is we have just
44:06 - imported imported our numpy library
44:09 - opencv and Os Library here okay so this
44:13 - is the code of k n algorithm and if you
44:17 - don't know like mathematics okay and
44:20 - Wortham then I prefer you that like just
44:23 - read the documentation or just see it
44:25 - any video just see any video at or see
44:28 - any code and try to implement it by own
44:31 - by role okay if you try to implement it
44:33 - by own you will get a clear clear
44:35 - understanding that what this is doing in
44:38 - actual I have explained you like like
44:40 - what are the Logics which has been done
44:43 - and these Logics are simply coded here
44:45 - okay like sorting on the basis of this
44:49 - and frequency of each level finding them
44:51 - back frequency I've just explained you
44:53 - everything about this you have to just
44:54 - understand like what code is doing so I
44:57 - add this is basically your distance like
45:01 - this point distance from this is
45:03 - basically euclidean distance which is
45:07 - a
45:08 - x 1 minus X2 whole square plus y1 minus
45:12 - y 2 whole Square so this is basically
45:14 - euclidean distance you might know this
45:16 - as everyone has started this in school
45:18 - so here the euclidean distance is been
45:22 - calculated and here is a basic logic of
45:25 - k n so I
45:27 - like
45:29 - give the task to you and to find that
45:32 - what this game is actually doing so I
45:34 - have explained the logic just go through
45:37 - it once and understand that which and
45:39 - what is this k n code is doing if you
45:42 - don't understand this write in the
45:43 - comment box like I will explain
45:44 - everything about that and make another
45:46 - video Kaylin if you don't understand but
45:48 - this is very logical thing I will
45:49 - explain the logic just go through this
45:51 - cold ones and understand that what it is
45:54 - doing
45:54 - okay this is quite simple so like like
45:57 - uh so now let's move to our main logic
45:59 - that how to recognize that using
46:01 - inverter
46:03 - so I have just changed my IDE because uh
46:06 - previously I was having spider ID that's
46:08 - come that comes from anaconda and now I
46:11 - have an ID of python so it doesn't
46:15 - affect our code and so let's start it so
46:19 - like in the previous video we have seen
46:21 - that like uh all the things like paste
46:24 - data connection video camera on like how
46:27 - to how to do that please recognition
46:29 - Okay all of that and now like we have to
46:32 - do like the last practical part of it
46:34 - like we have to recognize our face after
46:36 - after loading and loading the data of
46:40 - the faces right like I will open my
46:42 - webcam and I will upload my data like I
46:44 - will start the webcam and my camera feed
46:47 - will constantly and consecutively uh
46:50 - load my data okay and after that like my
46:53 - facial data will be stored in a number
46:55 - array and in prediction I will use that
46:58 - number array for in my KN and algorithm
47:01 - to predict my new phase okay
47:04 - but
47:05 - but so basic overview that like in your
47:07 - family just record the faces of four or
47:09 - five people and after that in the data
47:12 - collection we got that and while the
47:14 - data recognition just one person coming
47:17 - the camera or multiple persons and a
47:20 - label will be come at around your face
47:22 - and a box will come I will show you that
47:24 - later okay
47:26 - so till then just see here so this is
47:29 - our face organization code okay so like
47:32 - we have done this
47:33 - [Music]
47:35 - previous data collection and like
47:38 - everything we have done till in the
47:40 - later the earlier classes as this is a
47:43 - Hardcastle classifier
47:44 - which we have used for detecting the
47:46 - facial components and now like let us
47:49 - see our face recognition file so
47:52 - basically like we have like now like we
47:56 - have discussed k n Gotham in the under
47:58 - glass like how our base is detected in
48:01 - the bunch of many cases okay so like
48:04 - this is my kenil algorithm I have not
48:07 - used a library function rather than I
48:09 - have coded it from scratch okay like I
48:11 - will show you later like I also told you
48:13 - to study the scaling code by yourself so
48:16 - basically it is nothing just calculating
48:18 - the euclidean distance and just
48:20 - calculating that which phase is the
48:21 - nearest face to the point of convergence
48:25 - like two of a new phase how many
48:27 - previous spaces are near tools okay so
48:30 - like like that thing is done here like I
48:33 - have also given comments and this you
48:35 - can read that okay and like I will share
48:38 - this code I will share the data
48:39 - repository so that you can read the code
48:42 - and understand it and run it in your
48:44 - computer okay and as of now let me just
48:49 - unhide the scale code
48:51 - foreign it
48:57 - okay so I have just minimized my k n
48:59 - code so let us see now like what further
49:01 - things are done in this in this part so
49:04 - like initially like while we while I
49:06 - have to recognize my face so before that
49:09 - like basic steps has to be done as we
49:11 - have done in previous classes like okay
49:13 - so like we have to first open the camera
49:16 - like when we open the camera then only
49:19 - we can like put our face in front of it
49:21 - right so first we open our camera by CV2
49:24 - dot video capture Zero by this we are
49:27 - opening our webcam like this opencv
49:30 - function video capture and by this you
49:33 - open a webcam and like with c and I have
49:36 - stored my webcam in this cap variable so
49:39 - cap will contain my webcam okay my video
49:42 - feed basically and after that like I
49:45 - have called my classifier that is
49:46 - Hardcastle classifier and the function
49:48 - to call our classifier in is Cascade
49:51 - classifier okay and there are multiple
49:54 - classifier like hard casket class
49:55 - frontal face classifier is only used for
49:58 - like uh
50:01 - and there are multiple classifiers like
50:04 - which are which are used for detection
50:06 - the number plate of the car or a person
50:08 - is the tender of person or many things
50:10 - so there are like a lot of classifiers
50:13 - which I've already been made so we have
50:14 - used Hardcastle classifier to to
50:17 - classify a particular part of the faces
50:19 - okay and after that after that the
50:21 - series data set paths so initial like in
50:25 - previous video we have seen that
50:26 - whenever we are we are capturing our
50:29 - face then we are storing that phase in a
50:31 - particular data file okay so uh just see
50:34 - here face data collection
50:36 - here we have stored our face
50:39 - um I think you
50:42 - just see here like we have stored our
50:44 - face in this data set path okay and this
50:49 - data set path is basically this folder
50:52 - now like when I show you this folder so
50:55 - just see here I think this is a folder
50:58 - okay
51:02 - uh just see this okay so this is a
51:05 - folder that is like my like this is my
51:08 - folder basically which contains my all
51:10 - the files python files and this is my
51:12 - face data set folder in which all the
51:14 - faces like whatever the name I've given
51:17 - in the data collection is being written
51:19 - here in the dot npy format so if I open
51:22 - this like face data
51:25 - then you can see that when I was
51:27 - printing it then I was printing in such
51:29 - a way like
51:30 - dot format data set path plus file name
51:33 - plus dot np1 okay so you can see that
51:37 - like it is my data set path space data
51:40 - and data set nay and uh file name is
51:43 - this like
51:48 - it is my name and this is a file name
51:51 - and Dot npysa extension okay so like
51:54 - dismiss store data and now I have to use
51:56 - this data so like in
51:59 - basic organization I have uh I will be
52:03 - using my this facial data for the
52:05 - recognition part okay and
52:09 - this is a normal arrays by which we are
52:11 - just calculating our facial data like
52:13 - with where we are storing your data and
52:16 - label are the the name of the data like
52:18 - what is the label like currently and
52:20 - class I like I have made two new
52:22 - variables here class ID and names so
52:24 - class ID will be basically labels for
52:26 - every q and file okay and names are like
52:29 - we are mapping a particular name with a
52:31 - particular data file okay and now let us
52:35 - see like how to do data preparation okay
52:38 - so like just see this line just see this
52:41 - Loop for FX in OS Dot
52:45 - I always do it list directory data set
52:48 - path so basically OS is a another
52:52 - library in Python which is used to for
52:55 - interaction with our operating system OS
52:57 - basically means operating system okay so
53:00 - here you can see that like I have also
53:02 - imported this OS file OS Library
53:04 - basically and now I'm using that so by
53:08 - this OS dot list dire it means list
53:11 - directory and data set path so this this
53:15 - line is basically looping in by this
53:18 - folder okay this is my folder face data
53:21 - set and here my
53:25 - like this Loop is this line is iterating
53:29 - over this uh folder okay so every file
53:33 - like every file which is present here
53:34 - will be in the FX like we will be
53:37 - iterating over every file and like in
53:39 - this line FX dot with end width it is
53:42 - just finding that which file ends with
53:45 - this extension dot npy so basically if I
53:49 - made some new file here like if I made a
53:51 - new folder here
53:52 - suppose new folder and
53:55 - suppose I make
53:58 - a word doc here okay so like I have made
54:01 - a new folder and a Word document dot
54:03 - word doc so basically if these folders
54:06 - are present in my file so I have to just
54:08 - find the dot mpy files okay
54:12 - so with if f x dot ends with DOT mpy I
54:18 - am finding just only dot mpy files where
54:20 - my data are stored okay where the
54:23 - different faces data are stored and
54:25 - responding those files Okay and like you
54:28 - see names
54:30 - bracket class ID is equal to f x colon
54:34 - minus one so I hope that you remember
54:36 - the slicing operator we have discussed
54:38 - in previous class also like if it is a
54:40 - slicing operator so basically
54:44 - just see this we are we are taking all
54:47 - the waiting all the characters
54:49 - uh except the last four okay so last
54:53 - order basically this dot npy are the
54:56 - last four indices right and
55:00 - everything before dot npy is our name so
55:03 - basically this names class ID contains
55:06 - our name basically okay and here we are
55:09 - just loading our data and appending this
55:12 - particular name and data item in my face
55:15 - data array okay so phase data array is
55:19 - this so we are just appending every data
55:21 - data in this page face data area okay
55:25 - and now you see that
55:28 - now we are making a particular Target
55:30 - variable like like suppose we have five
55:33 - persons person number one two zero five
55:35 - and these five person are the family
55:37 - members okay and now like we have to
55:39 - make a particular array a particular
55:41 - scale down array with that five percent
55:43 - okay so just see that like we have to
55:46 - meet different Target and scores at so
55:48 - initially my class ID is zero so like
55:51 - the series line so basically like we
55:53 - have Target variables for different
55:54 - phases like we have stored over facial
55:56 - data and now we are just simplifying
55:57 - that data into Target variables okay so
56:00 - Target are nothing just a simple array
56:02 - okay so basically what we are doing is
56:04 - like initially like we are having
56:06 - classes like initial class is 0 and
56:09 - after that like VR will be increment
56:10 - incrementing our class ID with every
56:13 - iteration so a particular class ID is
56:16 - associated with every phase data okay
56:19 - initially my class ID is zero and now
56:21 - you see this like I have got my day uh
56:25 - data item and I'm just taking the shape
56:28 - of the data item like the length of my
56:30 - data items data items are basically the
56:32 - number of times our face has been stored
56:34 - okay so like I'm just calculating the
56:37 - length of the data item and like
56:39 - converting that
56:40 - into an array of ones so I'll be forming
56:45 - a area of ones with the length of the
56:49 - day diet okay the size will be length of
56:52 - the data item and I am multiplying it by
56:54 - class ID so my class ID is 0 so when 0
56:57 - is Multiplied with then one uh npt once
57:00 - it will become an array of zeros okay so
57:03 - this will be my target number one
57:05 - after that like I will increase my class
57:07 - ID I'll increment it I'll store the
57:09 - Target in the labels area and I will
57:12 - just move to the next iteration after
57:15 - that I will go to my second phase okay
57:17 - and what I will do is like I will get
57:20 - another data item I will tell you the
57:22 - size of the data item because I'm having
57:24 - a different person now and I will
57:27 - convert
57:29 - array of once and the size of that array
57:32 - will be data item size okay and I will
57:36 - multiply that by class ID so whenever an
57:39 - area of once is Multiplied with class ID
57:41 - which is one so it will become the same
57:44 - area again so that will be my target
57:46 - number two and similarly when I class ID
57:48 - are being incremented so basically like
57:51 - when class had equal to when 2 is
57:53 - multiplied by array of ones then it will
57:56 - become an array of two okay the basic
57:58 - difference is that the size of this
58:00 - these all the target arrays are
58:02 - different okay based on a particular
58:05 - faces the size of errors are different
58:06 - and the number of the areas are
58:08 - difference okay so that's how like we
58:11 - are just modifying the facial data into
58:13 - Target variables and storing all the
58:16 - data in this labels so labels is also an
58:19 - array we are just storing all the
58:21 - different phase data and labels
58:23 - now and now we are just printing that
58:25 - data like the word or the phase data we
58:28 - have what are the face labels we have
58:30 - all that simple stuff and just combining
58:33 - that into like NP or concatenate base
58:36 - data and phase labels space data is the
58:39 - phase data and phase labels are the
58:41 - labels of the faces associated with that
58:43 - okay and now just see that
58:46 - like we have printed that stuff and now
58:49 - it is my font this line doesn't care as
58:52 - of now and now just see that like
58:55 - like this this line
59:04 - okay so now I just read that like um
59:10 - so now like we have like stored our
59:13 - facial data like we have extracted our
59:15 - data from the data set and we have
59:17 - stored that data okay now like we have
59:20 - to implement table like we have to call
59:22 - our K9 function and we are we have to
59:24 - make a box around our face so what will
59:27 - happen is that when you store your face
59:29 - data Okay and like one part is storing
59:32 - over phase data in Phase data dot py
59:35 - file and now like when we are
59:36 - recognizing it like open your camera and
59:38 - play this file your camera will be open
59:40 - and then you will show your face in
59:42 - front of the camera a box will become
59:45 - around your face and your name will be
59:48 - written above that box okay suppose uh
59:51 - if I show you this
60:07 - so we'll just just see this suppose like
60:10 - we are having a face like this and like
60:12 - what what will happen is like when I
60:14 - open my webcam suppose this is my webcam
60:17 - okay this this whole screen is my webcam
60:20 - and this is my face like I'm having neck
60:22 - also and like so
60:26 - okay like rest of the body and a face so
60:30 - basically whatever algorithm will do is
60:32 - like when you open up a camera then a
60:34 - colored box will be covered on your face
60:37 - which will be like this which will cover
60:40 - only our face part okay like
60:45 - okay so a square box will be formed
60:48 - around our face and our name will become
60:50 - here at the top okay so our like our
60:55 - algorithm will do that so like this is
60:57 - our webcam and this is me or anything or
61:00 - you and a particular green color box
61:03 - will be covered on this and this is due
61:04 - to this Hardcastle classifier which is
61:06 - like uh defining our face basically and
61:10 - our name will be written over that so
61:12 - let me just show you that code
61:14 - so
61:16 - basically like
61:18 - like we are just doing the same thing
61:20 - again which we have seen earlier also
61:23 - like we will start a loop an infinite
61:25 - Loop which will be recording our camera
61:27 - so we will start our camera by Capital
61:29 - read and this is the rate and frame will
61:32 - basically have be having our camera
61:34 - variables like webcam variables return
61:37 - is basically like telling us that
61:38 - whether the camera is on or off okay
61:40 - frame is basically our main camera
61:43 - pinning which will be used okay so first
61:45 - like we have just converted our image to
61:48 - a grayscale image okay like whatever the
61:50 - video we are having we have just
61:52 - converted that into a gray scale video
61:54 - and after that like we are done same
61:56 - thing like we have just detect multi
61:59 - scale and these are the scaling factor
62:00 - and the number of neighbors like we have
62:03 - seen all this part in earlier video also
62:05 - okay
62:07 - just get over the here so this basis
62:10 - will basically contain our coordinates
62:12 - of the faces like X by W and H so
62:17 - basically uh if I change the thing so
62:19 - this this this top left corner will
62:23 - contain the will having the point number
62:25 - X and Y sorry I don't have the mouse so
62:27 - I'm starting like this so X and Y are
62:29 - the coordinates and this is our width
62:33 - and this is our height basically okay so
62:37 - basically our
62:39 - this function will give us the X Y width
62:42 - and height so that that all will be
62:45 - stored in in the face array okay and now
62:48 - like we are just starting a loop okay so
62:50 - like in the new Loop we are having a
62:52 - face and with a phase we are having the
62:55 - coordinates and these coordinates are
62:56 - stored are got from the space okay
63:00 - so this space is basically the one phase
63:02 - on which we are iterating
63:06 - and everything this is same just we are
63:08 - just cutting the part of the
63:10 - camera frame and just converting that to
63:13 - 100 cross hundred frame size and now
63:15 - just see this out is equal to k n
63:19 - we are calling our function just see
63:21 - just concentrate here we are calling our
63:24 - function k n and now like train train
63:26 - set and phase section flatten
63:34 - which we are carrying over from the past
63:36 - time and phase section dot platter means
63:39 - like we have defined this earlier also
63:41 - like we are having a phase section just
63:43 - here
63:44 - we are having a phase section basically
63:46 - the camera frame which is just uh
63:49 - captured in our face so we're just
63:51 - flattening that to convert that into a
63:53 - array okay of one column in multiple
63:56 - rows we are just starting that because
63:58 - in k n our parameter should be a
64:01 - flattened array only array of one call
64:03 - okay so our train set we have that we
64:06 - have our new phase which is we are just
64:09 - passing the two parameters
64:11 - and this will give us the output output
64:14 - will be that phase a training set we
64:17 - have trained and space section is the
64:20 - section we got here so it will basically
64:22 - guess the output that which frame we are
64:25 - having correctly so trains that we got
64:27 - from data paste data okay all the phase
64:31 - data we have so it will just iterate our
64:33 - every data and just apply our k n
64:36 - algorithm on that
64:37 - okay which is having a training set and
64:40 - a test set okay on the base of that it
64:42 - will give us the prediction which is
64:44 - this
64:45 - and it will tell us that which point it
64:48 - belongs to okay it's like if we have
64:50 - this
64:52 - um
64:58 - basically like this is a stuff like if
65:00 - you are having a face in between so it
65:02 - will just tell us that which face does
65:05 - our page belong to from this rest of the
65:07 - five faces basically okay and now like
65:10 - we have done that like we got the output
65:12 - base from here and now we we have to
65:15 - make a box around the face and a text on
65:20 - the face basically okay so see we do dot
65:22 - rectangle dot rectangle is a function
65:24 - which is used to make a shape by opencv
65:27 - so what we are doing is just we are
65:29 - passing a frame the coordinates the top
65:32 - left coordinates and the bottom right
65:34 - coordinates okay top left x y and bottom
65:38 - right are X Plus will be y plus h we are
65:40 - passing the coordinates okay and it will
65:43 - make a face around it will make a
65:45 - rectangle in these coordinates and this
65:47 - is the color and this is the width the
65:51 - width of the Box color is 255 25 which
65:55 - this is basically BGR colored okay three
65:57 - blue green red
65:59 - okay like if I do zero here and if I do
66:02 - Z 0 L so BGR means b g and r
66:07 - so if my B and gr 0 and my R is 255 it
66:12 - will make a box of
66:14 - a red color okay and if I make this like
66:19 - if I make this two multiple here
66:21 - so it will make a green color box okay
66:23 - this is just a color color format and
66:27 - now like to put a text like here like we
66:30 - write a function CO2 to Output text and
66:32 - it will just uh put a text here and this
66:35 - is the font of the text and this is the
66:38 - and this is the coordinates where I have
66:40 - to put my text
66:41 - and this is my color of the text like
66:44 - pgr format B is 255 so my text will be
66:47 - of blue color okay and this is a bit
66:50 - okay and similarly like that we are just
66:52 - putting everything and now like we are
66:54 - just displaying our face
66:56 - okay like we are just showing our camera
66:58 - feed and all of that okay and after that
67:03 - everything just be a make a function
67:05 - like if I press a Key Queue so my
67:07 - function will be end there and I can
67:09 - close my webcam and my webcam will not
67:12 - be closed
67:13 - buy anything except pressing Q okay and
67:17 - now like after all everything we just
67:19 - will just destroy the window and close
67:21 - the program that's all okay like this is
67:25 - a project of face recognition and I hope
67:27 - that like this is a very beginner level
67:29 - project
67:30 - in machine learning okay it's like I
67:33 - hope that this will this will be clear
67:34 - to all of you and
67:37 - just write the let's just give the
67:39 - comment below that how like
67:42 - like um how much do you like this
67:44 - playlist of this project okay and
67:47 - okay so let's end this video now okay
67:50 - bye

Cleaned transcript:

in this video we are going to do a new machine learning project that is real time facial recognition so let me give you a brief overview that what is the output of the project then we will move to the roadmap that what we are going to do step by step okay so the output of the project is like this we will open up a laptops camera camera or webcam and a colored box uh will surround our face and our name will do that in the box so basically our laptop will recognize our face that who we are in partners of a name so let me just give you an example of that yeah so I've just run my test sample and this is my phase as you can see so basically our camera is recognizing that what is my name and what is the name associated that with that face okay so this is a realtime face recognition whichever system is doing so let us see that how we will proceed to just project so let me give you a road now of this that what we are going to do step by step so basically first we are gonna We Are Gonna feed our video that like we should open our camera and we should record that what phase is in front of the camera right so I have made several separates a snippet of video record it is just to check that whether the camera is working or not so by this code we can check that our camera is working or not um don't be stressed out I will explain each time of the code step by step I'm just sitting the roadmap right now okay so this is about just checking this this code stick that whether our camera is working or not okay so this is a real test and after this okay so after this we are gonna We Are Gonna collect our phase data so basically in this snippet uh this the function of this code is like this this code opens up a camera and uh asks ask ourselves to write our name okay so if I play this sample so it is asking my name so I will enter my name here and after that when I enter Then camera will open and it will start recording my face it will start uh memorizing my face and will put each and every data in an array okay I will explain this entire thing step by step I'm just like giving an overview overview right now okay so it this code recognizes uh this code basically collects our facial facial data and stores it in an array and that array is useful recognition afterwards so after collecting our facial data we will run this code this is basically facial recognition Okay so after collecting our data we will store that data in another area and we will start another live streaming I mean we will start our camera again and it will match that this current phase matches with the previous array and it Maps down the name of the person with that signal okay so basically first step is data data collection over faces and then after that you will do a face evaluation and we will use basically kmeans algorithm in this and a classifier that is hard casket classifier okay so this is a brief overview of the project that what we are going to do and now I'm gonna explain you okay so before deeping uh so because before diving into the project let us first see that what is hard casket classifier okay after explaining this Hardcastle classifier I will explain you each and every lines on the code that but we have done step by step okay features line features and many or other features so basic purpose of Hawk asset classifier is it detects each and every feature of our face okay so this is a box it moves in every direction in the in the entire image and it just collects the data that varies our eyes where is our nose I'll show you the animation that how it works before that list you can just see on this website that how uh what is the basic documentation of Hardcastle classical um after this I will show you the animation of this okay so I've done the basic of this so if I enter my image here and the Hardcastle classifier will basically uh classify that where is our eyes and where is our face located in that that entire image okay so as you can see that here is my face and these are my eyes so this simple code which uses hard casket player has just recognized that where are my eyes and where is my face in the entire image okay so now let us see that uh this anyway hard gasket animation foreign classifier is just moving in the entire image and it is just classifying that where is our face and where are the other components of the face so as you can see that uh The Edge features uh line features and the other features of the casket classifier just checking that where are the main features of our face okay so it is traversing the whole image by increasing the size so just see the animation I've increased the size of the uh the speed of the video to 5.5 X so you can see clearly okay so this is how hard cast can classifier works okay so I hope that you will get and you have got a basic idea of that how and Hardcastle classifier works so in this video in this project we are we will be using that hard casket classifier to detect our facial components and after detecting that storing that face into an array mapping that with the name of the person and just recognizing that again by our key means algorithm okay so before that before starting data correction let us check that whether your camera is working or not okay so by this code we will just take that whether our camera is working yes or no okay so let me just explain you this code so this code starting with like we will import CB2 like we will we are importing opencv library and by this cap is equal to CB2 let me just zoom in zoom in okay so second line that cap is CV dot video capture it means that just open our webcam okay so this Line opens up a webcam and this Loop just tells that if our webcam is reading our image then just continue and if it is false then move out of the loop okay so it shows like a video frame it uh okay so let me just open the camera I'm playing this and so as you can see that our camera has been opened and after that this camera name just uh the name of a camera is frame as okay as you can as you have just seen before and after this I have entered this logic that if I press q q as the key if I press the key Cube then it uh breaks the camera and closes the window and the camera will not be closed by the simple uh closing function it will be only closed if you enter queue okay so this is a logic which I entered and I will explain you the purpose of that why I have entered this okay and this is a key pressed this line simply means that uh if our currently pressed key matches with this key or not this is that's it and I will explain this in the meaning of this line later in this project when we are doing data collection okay I will explain the logic behind this that why I am bitwise why I have used bid base and here with ux FM okay so for right now you have to just understand that we have just opened the camera and just checked that if return is equal to false then we will just continue and if our camera is reading then we will just move to move forward and just show the camera that and to stick that with the camera is open or not and we'll just uh close that camera by pressing the Key Queue okay and after that we will release our camera tapped or at least if when we break out of the loop then we just uh the ease of a camera by this line This Means closing the camera and by this it means you're destroying all windows means um disabling all the cookies that has been formed by opening the captain and deleting all the data which has been captured in the back memory okay so this is basically a video Read we are just checking that our camera is reading the video or not okay so I hope that you have got a clear idea that what is this okay so after that we'll do facial data collection we have covered this video Read part like we are just thinking that how video is being readed from your webcam of the laptop or computer and how it has been processed and how it is the video has been stopping so in today's video we're gonna see that how the laptop camera or webcam is reading your face data and storing it in an array to like detect further okay so this file phase data consists that how a phase data is being storing in the memory of computer and we will process it later when we are doing phase detection using knot Okay so so let's get started about it so I will explain you line by line that what each line is doing so so let's get started so first we import two libraries like opencv and numpy Library opencv2 like read the camera feed or open the camera and numpy has basic array operations and some more operations okay so by this line we are just reading we are just opening our webcam and um in this variable cap our webcam has been storing the data is being storing in this cap okay so after that we are using like in previous video I've shown you a hard casket classifier that that is classifying the facial components of the face okay so we have just imported this hard casket classifier in this variable and like this is the location of our gasket classifier so before starting the project uh just see here it is in my D folder D drive and this folder uh we will just download this from the internet it is easily available on GitHub so just download it or I'll give the link in the description okay we do have to store this hard casket file in this directory only so like just wait a second so in my data in my D drive I have a folder called face immigration project and in this folder I have this file hard casket classifier file okay this is hard casket frontal face so you have to just download This by only and this is the mainly classifier we are going to use here so we have just imported this classify here in this variable so let's move forward this script variable just means that uh it I will experience this later when we are just using the script variable here for now just ignore it and in this space data array this is basically a list in which we will be storing each phase data okay so don't be confused you will get clear understanding later when we are proceeding towards it and this data set path is Page data set so this means that the faces which we are storing has to be downloaded or has to be stored in the computer's membrane okay so like if I open my camera and store my face so my computer has to download that face and store that file in a particular folder right so I have just created this folder here so so as you can see that in my D drive I've created a folder field data set by this line okay and this phase data set contains all the files that has been deleted through my camera so if I open it I have just um I have just recorded my face and given my name to this like anything and this uh every data of my camera feed is stored in this data folder in this folder Okay so let's move forward so um so like when we open our camera then we will enter our name there as I just shown you in the previous video when we open the camera we enter our name and after that video starts recording and our face is starting getting recognized and feeding the camera Okay so or we are just giving the input that when we open the camera just enter our name and index and in the console uh this dialog box will appear in where we have to enter our name don't worry I will just when I will just play this video like when I play this code then you will see that but this line is actually doing here in the console okay okay so let us just now uh play it once so when we play this file then this cons in this console you can see that here it is coming like enter your name like enter the name of person so when I write my name here like this and press enter Then the camera will open okay so as of now I'm just stopping this program we will do this later okay so I've just shown you that what how it is being appeared in the console okay so let us move further so now we are opening our camera and we will store our data field now okay so in in a while loop which is always true we are just doing this code so let me just explain that what we are doing here okay so this red comma frame is equal to Capital it means that red is basically a Boolean variable which just check that camera is open or not and frame basically captures uh as a variable where we are defining our camera Okay so and here we are just checking that if the camera is not open then just continue and don't do this iteration and this lines means that we are just converting our uh like initially we will be having a colorful image like we all are colorful right so initially our images are RGB image and in Python we just like RGB like we like we let BGR instead of RGB every time so in this line we are converting our RGB image to a grayscale image okay and to convert that we use this type of syntax like CV2 dot CVT color and frame which is storing your camera feed and CV2 dot color BGR to create BGR to gray means we are converting pgr like R it means RGB we are converting RGB to grayscale take it so this is a syntax so our gray so initially we are having frame in this Frame we are we are having a colorful image and now in this gray frame we will have we will be having a gray scale image okay so grayscale we have converted it to graysk limit because in KN and Quantum it is much easier to like understand a grayscale image and do the algorithm like do the functionalities and Grace Kelly which it is much easier than a colorful image and it doesn't affect the output output is much better in grayscale okay so when we are processing rescue okay so let us move forward and this line like phase is equal to face Cascade dot detect multiscale okay so I will I'm explaining the parameter that is used here so this is a three frame that is we just created here and this is a scaling Factor this is the number of neighbors okay so let me just give a comment here like premium parameters are frame name scaling Factor and number of Neighbors that we defined by K and just we write number of number of tables okay so uh number of neighbors is basically used in KN and Gotham if you don't know that clear then Quantum for now just keep this line I will explain the each and every functionality of scaling Factor K and the whole functionality of this line later when we IMB I will be explaining the KL algorithm because you will get a clear understanding pin Okay so so uh just let me give you a quick overview overview that what is the scaling Factor so initially if our image size if we scale down our image to 1 then if we are doing 1.3 then simply means that we are just shrinking our image to 30 percent don't worry I will just explain you this step later when we are doing k n in algorithm so for now let us move further so in this line we are just checking that it faces length equal equal to 0 like if this um if this space is equal equal to 0 then just continue we don't have any phase here okay so as of now just understand that this line like this function just returns you the coordinates of the face captured like if I open the camera and the camera will capture my face then this function will return the coordinates of my face like top left top right bottom left bottom right okay so all the coordinates will be returned by this function to this faces variable okay so this so This lines this function is only doing this this is just telling the coordinates of faces to us okay okay so let me explain you that what actually returning us and what type of coordinates are they okay so just let me open my Notepad okay so this function like this function so let me just select uh okay so that's function like paste casket dot detect multiscale which is uh this variable faces just means that this faces is a list and this list is storing the coordinates of the face so if I draw here like different draw stitches like like if this is the person here okay so these both are faces Okay so these are the top coordinates like XY is the top coordinates of the faces and this is the width this is the height okay so a box it returns like this detect multi scale returns a block to you I delete it as a box in which we have the top left and we have the top left coordinates of x y and the height is H and the width is W okay so this function just returns X this function returns x y w and z so the W and H x y w n h okay so these are the coordinates and by this W and H we can just calculate it what are what can be these coordinates like this can be like X Plus H and the and pi plus W right like you can just calculate it by adding W and H in X and Y so we can get this these and this coordinate also so this function is just returning as the coordinates so that we can just make a box into the field around the face okay that's it about this latest okay so now let us see that the further code so this line like faces is sorted faces key Lambda X2 into X3 so what is it is doing so it is just arranging your faces like if you have multiple faces in the video field like if I show my face my sister's face my brother says in increasing or decreasing water as per our need okay so what we are doing here is we are passing a function name sorted and we are just using using a laptop option okay so in this uh this time being that we are passing our faces list here like in this basis list we have a x y h and W coordinates uh numbers okay and we pass this list here and we are just calculating so this means that okay so like faces wishes like if your faces then faces contains a list of X by W and H okay so it is zero Index this is bar Index this is three index okay so the area of image is what area of any image is weight into height okay you get into height and good thing to hide basically here is faces two into faces three okay this is width into height and this is basically area and the image which has larger area will obviously come first if we are sorting it in a decreasing order and if the area is less then it will come first in uh the sorted order if we are sorting it in an ascending order right so this so in this here so Lambda X is just representing our faces and we are just using the Lambda function here if you don't like what is Lambda function so that like just get a quick overview by seeing the documents okay so X is representing this faces and X2 into X3 basically is area of image area of the face or the area of the box which has been made okay and reverse is equal to True means which we are just arranging this in a descending order like we are sorting it in a descending order right so and these like if we are having faces like this first faces this second phase is this third phase is like small phase then big face and small piece and these all faces will be sorted in a descending order like first welcome big and small and then small this one okay so in this way we sort our faces and every data will be stored in this in this variable okay so I hope that you get a clear understanding of what we are actually doing here and now just forget this line as of now so now we are just we will just hydrate to the every phases and we will restore every face in our data so now we are we are just alternating in our faces again so uh let us see that we are starting a for Loop here and four Loop is going till end okay and this x y w h is are the coordinates of the face so face and faces means that it is like this is Phase One this is phase two this is phase three this is phase four like these are the faces and the coordinates of each and every phase will come in this x y w and H variables okay as we iterate over every faces then the uh coordinates of every face will come in X by W and H okay and this offset simply means that we are providing a padding so if we have done HTML before before you might know that what is padding what is margin so padding is basically a so if we are having our face here this is our face then this Gap is basically padding okay so this Gap is padding sorry about handwriting uh actually pen is quite cold here okay so if you are having a face here like and this is covered in a box then this box is having a padding of file okay so this length is basically five or five card okay so we are just given the padding of five to like uh show a clear user interface okay so as before we are just having this uh this box as outer box which is at which we are having the coordinates x y and everything so now here we are just extracting the face section so this line is basically extracting the section of a face so it is subtracting the offset so basically it is subtracting the padding and it is just uh calculating a particular section of a face initially this was padding and now we are discovering the particular section of the face okay and after that like you will see you can understand this easily like we are just subtracting offset from length from top and bottom and subtracting from left and right okay we are just subtracting over starting and just getting the section of Face by this line okay just go through it once and by this space selection we are just reselling a phase 200 cross 100 image okay so I hope that you understand it and now this skip so this skip just means that when we start recording our face then after every second our skip after every second or after hydration this tip will increment okay like we have recorded one first page second phase third phase like a particular uh time frame of the face is being recorded by this script by the script okay so after every 10 space like when I started the recording when I started recording my face so I record it at first second second third second fourth second I'm recording my face and every second okay so when I read the 10th second of camera I will just do a skip operation okay and after every 10th phase I will be recording this 10th phase into my array okay I'll be recording each 10th iterated face in my array so that I don't have many faces in my array and I have a good feeling and a good video feed like recognize later so as you can see that like after each 10th in titration I'm just appending my face into the phase data and sprinting the length of face that's it like understanding this line this line simply means that we are just creating a rectangular box towards our frame like frame is basically a section of frame a section of face which we are having and this these are the coordinates like top left top left coordinates and these are the bottom right coordinates we pass this these parameters at the color of the box which we have to display okay so this is RGB red green and blue so basically we have given green to its full number and red in blue to zero zero so basically a green color box will uh will appear out of your face okay so like let me show you that so so when I when I will open my camera so what will happen like a camera will open like this it will be a frame and my face will be here like I will be standing or sitting here and a green color box will appear around my face like or down the section of face a green color box will appear okay and by this like this is basically RGB I have given 0 to r0 to Blue and 255 to Green 255 is the maximum number that's why a green color box will appear if I give like 255 0 0 then a red color box will appear around my face red color box will appear so this is simply your this line is simply creating a rectangular box which will appear around this Frame frame is basically uh this stream Okay so and but this this will just show the frame like it is understandable and this uh this is like that if we have if a webcam is open then if we place an EQ if we press Q then the webcam will just switch off like I will explain the function of this later so let us move forward about things as of now so now after when we have stored our faces then after that we will we are we will be having a list of faces like we are having a list of Faces in which faces are faces data are stored okay so now to implement a KB is algorithm here we have to implement foreign works best in some scenarios and the compilation power is pretty much higher than list okay so we will convert our list so face data is basically list now we will convert this list to one numpy array by this function by NP dot array phase data error we are basically converting our space this is a list here as of now we will we are converting this to a numpy array okay so to have a faster computation and to better fit in again after converting it to a numpy array we will just reshape it okay so reshaping is a basic like basic concept you would know it and if you don't know like what is reshaping I would say that just look at the documentation like what it is doing and after this reshaping we are just printing our face not shape face data shape like whatever like what is the shape of the face as of now after that we are just saving our data in our folder which we have just made like this let me explain you this so this data set path is basically the D drive path which I have just uh stated earlier so so basically this this is a data set path and now we are the story cover like current data into this folder okay so to store our data in this folder what we are doing is like we are just saving our current data data paths file name in Phase data okay so file name is basically this uh when we are entering our name the name is stored in this file name okay so now just see that what we have done we have saved our data set plus file name and phase data and so if we print this it will be like data set like let me just show you if we print this what will happen if so now when we print it like it will come like this if the folder name is my data if data is my folder named in it and my file name is if I write my my name like arbit and extension is basically Dot npy because we storing this so this will be our location or Source where we are storybook current data okay so this this perfect dot npy will contain all the faces all the my phase data which is being stored in the camera feed and we will use this data to recognize and pass this data in our KN inverter webcam and this lens is just destroying all the windows which have been created by the camera like basically the frames which have been created here okay so this is the basically everything about is data reading and data collection so now we will see that how we can recognize the data by using algorithm so this is the basically the order of the face recognition and here I've implemented a Kalin algorithm that what the algorithm is doing okay so I will explain line by line that every like what every line of function is doing I'll explain everything and uh if you have any confusion like if you don't want to make KN and algorithm from scratch like here in this video I've made the this algorithm from scratch you can also use inbuilt Library like in inbuilt library comes it just works in simple one line and here I've used like two very lines here to implement it from scratch okay so you can use like direct Library function also and you can also like implement it from scratch okay so don't worry about that we'll just discuss everything you okay so before starting like a face recognition give you a quick overview that what is scale and got them doing okay so now let's see this okay so now let me give you an example of like what is Karen in a very very simplest way and I will show you that how our gains can be implemented in this project also okay so let us see that so if we are having a suppose we are having suppose I will give you a small example before like we are having a class one here so let me just so it is a it is my class one okay and I am just just like to change my color and this is my class too class 2. and in between this class one and class two I have a person here like suppose this is me now I have to like go to class one or class two and we have to find that this one belong to which class Like This one belongs to this class or this class we don't know as of now so what we do is we will find distance of current point with all the points and find the nearest point to this Green Point okay we find distance to every point and we'll check that what is the average nearest distance we have so suppose if so what we do is we find distance of this screen percent to every person of the class and we will find the top K persons like suppose we find distance to every every person in the class and after that finding we just categorize the top five percent like if we write K is equal to 5 then these five people are the nearest people to this like if a is equal to 5 then this three people like this this this three people of plasma and these two people of class two are the nearest people to this green Okay so a is equal to 5 simply means that these five peoples are the nearest K people to this cream color this green person okay now there are three persons of class one and two persons of class two this simply means that the we will just check that at which class we have the most number of uh nearest neighbors okay so this class one has the most number of nearest neighbors to this green green person okay so as class one has three neighbors class two has two nearest table so obviously we will categorize our this green person to class one because these are more nearest neighbors as compared to plus two okay so here class class one wins so basically this point belongs to class one is it is a basic overview like what is k n and I will explain this in this further videos like by giving more detailed examples to explain you the complete like how to take facial data and store into a numpy array and also shown in the basic quick overview that what is KN and algorithm and in today's video we're going to see that how Kanan algorithm can be implemented here and why should we implemented here okay so like like in this project we are like recognize recognizing our face with this but this is not the only way there are many other other algorithms like uh convolution neural networks and like many other things by which we can like recognizable face so this is what this is one of the method came in by which we recognize so let me give you example that how kerin can be implemented here so just see this so suppose that it is my graph and suppose I have stored the data of five people like uh four people I have state I have recorded the data of four people four of my friends and one of one it's me one is me and uh other three are my friends okay and total is I have four people okay one is one is me and three are friends so just let's see that suppose this is my this is me uh this is these are my face chords like artists I have just told you that I am recording my faces after every 10th iteration in uh and it will depend like when the number of the number of minutes or seconds or hours I will open my camera it my face will be get recorded and and due to that I have I will be having number of faces like if I open my camera for 10 minutes then I will be having a lot of faces recorded if I open my camera for one minute then I'll be having only six spaces recorded because the my faces are recording after every 10 seconds okay it is just a overview example so suppose I am I am I am having like my six faces and every friend of mine is having six faces story okay so this is person one and these are the faces of person one and let me change the color this is like this is me and suppose this is my friend face okay this is my friend's face and like like friend one and this is me and suppose time having one more friend stays told okay so this is my friend's three phase like a second frame face and this is these are the faces of my friend three okay and now I am just like these are just these are stored in my data these all pieces are stored in my data and now I open my camera feed to recognize and use gain in algorithm now so suppose I open my camera and I open up my camera like my camera face has been opened and a random person comes in the camera like it is none of us so it will not match with any of them and it will just simply cannot recognize okay so if I if I open my camera and I show my face to it like I show my face to it and it will recognize my face as like this so how it is happening so if I open my camera my face will come here like this is my camera and my face will come here so now my face will calculate the distance from every spatial data okay so I have to tell you that I have used hard casket classifier so my heart ask a class where I am just calculating my difference between faces okay so I will calculate the difference my of my face every other face is told okay while every other face is told I will calculate the difference between wire phase and other faces okay like every faces okay and I will just calculate like if I take K as 3 then I will just get the three nearest Neighbors three nearest Neighbors and obviously I will be having the least favorite facial difference with me only if I am wearing in the front of the camera then I will be having the least facial defense with me only okay so by this algorithm we can just state that I am having like this space means this is me and if if it recognize that this phase means a bit like my name is arpit so it will just recognize it and show my name on the box like don't be confused I will explain everything step by step after like moving into the cold so let us get started about that okay so let us get further like explaining that what is going down here so in this record phase organization file what we have done is we have just imported imported our numpy library opencv and Os Library here okay so this is the code of k n algorithm and if you don't know like mathematics okay and Wortham then I prefer you that like just read the documentation or just see it any video just see any video at or see any code and try to implement it by own by role okay if you try to implement it by own you will get a clear clear understanding that what this is doing in actual I have explained you like like what are the Logics which has been done and these Logics are simply coded here okay like sorting on the basis of this and frequency of each level finding them back frequency I've just explained you everything about this you have to just understand like what code is doing so I add this is basically your distance like this point distance from this is basically euclidean distance which is a x 1 minus X2 whole square plus y1 minus y 2 whole Square so this is basically euclidean distance you might know this as everyone has started this in school so here the euclidean distance is been calculated and here is a basic logic of k n so I like give the task to you and to find that what this game is actually doing so I have explained the logic just go through it once and understand that which and what is this k n code is doing if you don't understand this write in the comment box like I will explain everything about that and make another video Kaylin if you don't understand but this is very logical thing I will explain the logic just go through this cold ones and understand that what it is doing okay this is quite simple so like like uh so now let's move to our main logic that how to recognize that using inverter so I have just changed my IDE because uh previously I was having spider ID that's come that comes from anaconda and now I have an ID of python so it doesn't affect our code and so let's start it so like in the previous video we have seen that like uh all the things like paste data connection video camera on like how to how to do that please recognition Okay all of that and now like we have to do like the last practical part of it like we have to recognize our face after after loading and loading the data of the faces right like I will open my webcam and I will upload my data like I will start the webcam and my camera feed will constantly and consecutively uh load my data okay and after that like my facial data will be stored in a number array and in prediction I will use that number array for in my KN and algorithm to predict my new phase okay but but so basic overview that like in your family just record the faces of four or five people and after that in the data collection we got that and while the data recognition just one person coming the camera or multiple persons and a label will be come at around your face and a box will come I will show you that later okay so till then just see here so this is our face organization code okay so like we have done this previous data collection and like everything we have done till in the later the earlier classes as this is a Hardcastle classifier which we have used for detecting the facial components and now like let us see our face recognition file so basically like we have like now like we have discussed k n Gotham in the under glass like how our base is detected in the bunch of many cases okay so like this is my kenil algorithm I have not used a library function rather than I have coded it from scratch okay like I will show you later like I also told you to study the scaling code by yourself so basically it is nothing just calculating the euclidean distance and just calculating that which phase is the nearest face to the point of convergence like two of a new phase how many previous spaces are near tools okay so like like that thing is done here like I have also given comments and this you can read that okay and like I will share this code I will share the data repository so that you can read the code and understand it and run it in your computer okay and as of now let me just unhide the scale code foreign it okay so I have just minimized my k n code so let us see now like what further things are done in this in this part so like initially like while we while I have to recognize my face so before that like basic steps has to be done as we have done in previous classes like okay so like we have to first open the camera like when we open the camera then only we can like put our face in front of it right so first we open our camera by CV2 dot video capture Zero by this we are opening our webcam like this opencv function video capture and by this you open a webcam and like with c and I have stored my webcam in this cap variable so cap will contain my webcam okay my video feed basically and after that like I have called my classifier that is Hardcastle classifier and the function to call our classifier in is Cascade classifier okay and there are multiple classifier like hard casket class frontal face classifier is only used for like uh and there are multiple classifiers like which are which are used for detection the number plate of the car or a person is the tender of person or many things so there are like a lot of classifiers which I've already been made so we have used Hardcastle classifier to to classify a particular part of the faces okay and after that after that the series data set paths so initial like in previous video we have seen that whenever we are we are capturing our face then we are storing that phase in a particular data file okay so uh just see here face data collection here we have stored our face um I think you just see here like we have stored our face in this data set path okay and this data set path is basically this folder now like when I show you this folder so just see here I think this is a folder okay uh just see this okay so this is a folder that is like my like this is my folder basically which contains my all the files python files and this is my face data set folder in which all the faces like whatever the name I've given in the data collection is being written here in the dot npy format so if I open this like face data then you can see that when I was printing it then I was printing in such a way like dot format data set path plus file name plus dot np1 okay so you can see that like it is my data set path space data and data set nay and uh file name is this like it is my name and this is a file name and Dot npysa extension okay so like dismiss store data and now I have to use this data so like in basic organization I have uh I will be using my this facial data for the recognition part okay and this is a normal arrays by which we are just calculating our facial data like with where we are storing your data and label are the the name of the data like what is the label like currently and class I like I have made two new variables here class ID and names so class ID will be basically labels for every q and file okay and names are like we are mapping a particular name with a particular data file okay and now let us see like how to do data preparation okay so like just see this line just see this Loop for FX in OS Dot I always do it list directory data set path so basically OS is a another library in Python which is used to for interaction with our operating system OS basically means operating system okay so here you can see that like I have also imported this OS file OS Library basically and now I'm using that so by this OS dot list dire it means list directory and data set path so this this line is basically looping in by this folder okay this is my folder face data set and here my like this Loop is this line is iterating over this uh folder okay so every file like every file which is present here will be in the FX like we will be iterating over every file and like in this line FX dot with end width it is just finding that which file ends with this extension dot npy so basically if I made some new file here like if I made a new folder here suppose new folder and suppose I make a word doc here okay so like I have made a new folder and a Word document dot word doc so basically if these folders are present in my file so I have to just find the dot mpy files okay so with if f x dot ends with DOT mpy I am finding just only dot mpy files where my data are stored okay where the different faces data are stored and responding those files Okay and like you see names bracket class ID is equal to f x colon minus one so I hope that you remember the slicing operator we have discussed in previous class also like if it is a slicing operator so basically just see this we are we are taking all the waiting all the characters uh except the last four okay so last order basically this dot npy are the last four indices right and everything before dot npy is our name so basically this names class ID contains our name basically okay and here we are just loading our data and appending this particular name and data item in my face data array okay so phase data array is this so we are just appending every data data in this page face data area okay and now you see that now we are making a particular Target variable like like suppose we have five persons person number one two zero five and these five person are the family members okay and now like we have to make a particular array a particular scale down array with that five percent okay so just see that like we have to meet different Target and scores at so initially my class ID is zero so like the series line so basically like we have Target variables for different phases like we have stored over facial data and now we are just simplifying that data into Target variables okay so Target are nothing just a simple array okay so basically what we are doing is like initially like we are having classes like initial class is 0 and after that like VR will be increment incrementing our class ID with every iteration so a particular class ID is associated with every phase data okay initially my class ID is zero and now you see this like I have got my day uh data item and I'm just taking the shape of the data item like the length of my data items data items are basically the number of times our face has been stored okay so like I'm just calculating the length of the data item and like converting that into an array of ones so I'll be forming a area of ones with the length of the day diet okay the size will be length of the data item and I am multiplying it by class ID so my class ID is 0 so when 0 is Multiplied with then one uh npt once it will become an array of zeros okay so this will be my target number one after that like I will increase my class ID I'll increment it I'll store the Target in the labels area and I will just move to the next iteration after that I will go to my second phase okay and what I will do is like I will get another data item I will tell you the size of the data item because I'm having a different person now and I will convert array of once and the size of that array will be data item size okay and I will multiply that by class ID so whenever an area of once is Multiplied with class ID which is one so it will become the same area again so that will be my target number two and similarly when I class ID are being incremented so basically like when class had equal to when 2 is multiplied by array of ones then it will become an array of two okay the basic difference is that the size of this these all the target arrays are different okay based on a particular faces the size of errors are different and the number of the areas are difference okay so that's how like we are just modifying the facial data into Target variables and storing all the data in this labels so labels is also an array we are just storing all the different phase data and labels now and now we are just printing that data like the word or the phase data we have what are the face labels we have all that simple stuff and just combining that into like NP or concatenate base data and phase labels space data is the phase data and phase labels are the labels of the faces associated with that okay and now just see that like we have printed that stuff and now it is my font this line doesn't care as of now and now just see that like like this this line okay so now I just read that like um so now like we have like stored our facial data like we have extracted our data from the data set and we have stored that data okay now like we have to implement table like we have to call our K9 function and we are we have to make a box around our face so what will happen is that when you store your face data Okay and like one part is storing over phase data in Phase data dot py file and now like when we are recognizing it like open your camera and play this file your camera will be open and then you will show your face in front of the camera a box will become around your face and your name will be written above that box okay suppose uh if I show you this so we'll just just see this suppose like we are having a face like this and like what what will happen is like when I open my webcam suppose this is my webcam okay this this whole screen is my webcam and this is my face like I'm having neck also and like so okay like rest of the body and a face so basically whatever algorithm will do is like when you open up a camera then a colored box will be covered on your face which will be like this which will cover only our face part okay like okay so a square box will be formed around our face and our name will become here at the top okay so our like our algorithm will do that so like this is our webcam and this is me or anything or you and a particular green color box will be covered on this and this is due to this Hardcastle classifier which is like uh defining our face basically and our name will be written over that so let me just show you that code so basically like like we are just doing the same thing again which we have seen earlier also like we will start a loop an infinite Loop which will be recording our camera so we will start our camera by Capital read and this is the rate and frame will basically have be having our camera variables like webcam variables return is basically like telling us that whether the camera is on or off okay frame is basically our main camera pinning which will be used okay so first like we have just converted our image to a grayscale image okay like whatever the video we are having we have just converted that into a gray scale video and after that like we are done same thing like we have just detect multi scale and these are the scaling factor and the number of neighbors like we have seen all this part in earlier video also okay just get over the here so this basis will basically contain our coordinates of the faces like X by W and H so basically uh if I change the thing so this this this top left corner will contain the will having the point number X and Y sorry I don't have the mouse so I'm starting like this so X and Y are the coordinates and this is our width and this is our height basically okay so basically our this function will give us the X Y width and height so that that all will be stored in in the face array okay and now like we are just starting a loop okay so like in the new Loop we are having a face and with a phase we are having the coordinates and these coordinates are stored are got from the space okay so this space is basically the one phase on which we are iterating and everything this is same just we are just cutting the part of the camera frame and just converting that to 100 cross hundred frame size and now just see this out is equal to k n we are calling our function just see just concentrate here we are calling our function k n and now like train train set and phase section flatten which we are carrying over from the past time and phase section dot platter means like we have defined this earlier also like we are having a phase section just here we are having a phase section basically the camera frame which is just uh captured in our face so we're just flattening that to convert that into a array okay of one column in multiple rows we are just starting that because in k n our parameter should be a flattened array only array of one call okay so our train set we have that we have our new phase which is we are just passing the two parameters and this will give us the output output will be that phase a training set we have trained and space section is the section we got here so it will basically guess the output that which frame we are having correctly so trains that we got from data paste data okay all the phase data we have so it will just iterate our every data and just apply our k n algorithm on that okay which is having a training set and a test set okay on the base of that it will give us the prediction which is this and it will tell us that which point it belongs to okay it's like if we have this um basically like this is a stuff like if you are having a face in between so it will just tell us that which face does our page belong to from this rest of the five faces basically okay and now like we have done that like we got the output base from here and now we we have to make a box around the face and a text on the face basically okay so see we do dot rectangle dot rectangle is a function which is used to make a shape by opencv so what we are doing is just we are passing a frame the coordinates the top left coordinates and the bottom right coordinates okay top left x y and bottom right are X Plus will be y plus h we are passing the coordinates okay and it will make a face around it will make a rectangle in these coordinates and this is the color and this is the width the width of the Box color is 255 25 which this is basically BGR colored okay three blue green red okay like if I do zero here and if I do Z 0 L so BGR means b g and r so if my B and gr 0 and my R is 255 it will make a box of a red color okay and if I make this like if I make this two multiple here so it will make a green color box okay this is just a color color format and now like to put a text like here like we write a function CO2 to Output text and it will just uh put a text here and this is the font of the text and this is the and this is the coordinates where I have to put my text and this is my color of the text like pgr format B is 255 so my text will be of blue color okay and this is a bit okay and similarly like that we are just putting everything and now like we are just displaying our face okay like we are just showing our camera feed and all of that okay and after that everything just be a make a function like if I press a Key Queue so my function will be end there and I can close my webcam and my webcam will not be closed buy anything except pressing Q okay and now like after all everything we just will just destroy the window and close the program that's all okay like this is a project of face recognition and I hope that like this is a very beginner level project in machine learning okay it's like I hope that this will this will be clear to all of you and just write the let's just give the comment below that how like like um how much do you like this playlist of this project okay and okay so let's end this video now okay bye
