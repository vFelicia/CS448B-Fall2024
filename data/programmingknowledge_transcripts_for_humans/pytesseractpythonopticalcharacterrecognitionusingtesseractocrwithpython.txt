With timestamps:

00:00 - in this video we'll talk about making a
00:02 - simple python optical character
00:04 - recognition
00:05 - script where we use uh pi test rack
00:08 - uh api over the google interest rate ocr
00:12 - engine
00:12 - to actually read text from images
00:15 - programmatically
00:16 - so in this video we will talk about what
00:19 - is
00:20 - ocr what are the applications of optical
00:22 - character recognition
00:24 - how can we actually build an ocr script
00:27 - where we can actually read image read
00:30 - text
00:31 - from images so let's get started
00:34 - so first let's have a very brief
00:36 - introduction about what ocr is
00:38 - so humans can understand the contents of
00:42 - an image simply by looking at it we
00:44 - perceive the text on the image
00:46 - as text and can read it so computers
00:49 - don't work the same way they need
00:50 - something more complete in an organized
00:52 - way to understand that
00:54 - so this is where optical character
00:55 - recognition comes into the picture
00:57 - whether it's recognition of car plates
00:59 - from a camera or handwritten documents
01:02 - that should be converted into
01:03 - additional copy this technique is very
01:05 - very very useful
01:07 - so in this video we will delve into the
01:10 - depth of
01:11 - optical character ignition and its
01:12 - application areas we'll also
01:14 - build a simple script and python that
01:16 - will help us detect characters
01:18 - from images and you can also build on
01:21 - top of this
01:21 - simple python script and build a web
01:24 - application out of it
01:26 - so what is ocr so optical character
01:29 - recognition involves detection of text
01:31 - content on images
01:32 - and translation of those images to
01:34 - encode a text
01:35 - that the computer can understand easily
01:38 - so how is this achieved uh
01:39 - so to us as i said uh text an image is
01:42 - easily
01:43 - discernable and we are always able to
01:45 - detect characters
01:46 - and read the text but for computers it's
01:49 - only a series of dots or pixels
01:52 - so the image is first scan and the text
01:54 - and the graphics
01:55 - uh elements are converted into something
01:57 - called as a bitmap
01:59 - which is basically a matrix of black and
02:01 - white dots
02:02 - then the image is pre-processed where
02:04 - the brightness and the contrast of them
02:07 - are enhanced
02:08 - to improve accuracy of process
02:12 - now the image split results identifying
02:14 - the areas of interest
02:16 - such as where the images or text are and
02:19 - this helps
02:19 - curve the extraction process the areas
02:22 - containing text can now be broken down
02:24 - into further lines
02:25 - worlds and characters and now the ocr
02:28 - engine
02:28 - or the software is able to match the
02:30 - characters through comparison and
02:32 - various ai algorithms
02:34 - the final result is the text in the
02:36 - image that we're given
02:38 - now uh be aware that the process may not
02:41 - be 100 accurate
02:42 - and it might need some human
02:44 - intervention to correct
02:46 - some elements that were not scanned
02:47 - correctly the error correction
02:50 - part can also be achieved using a
02:51 - dictionary or even an np
02:53 - natural language processing so
02:56 - let's see where we use ocr so ocr is
02:58 - very commonly used in airports to
03:00 - automate the process of pass protocol
03:01 - mission
03:02 - extraction from information out of it
03:05 - the other
03:06 - applications include automation of data
03:08 - entry processes
03:09 - detection and recognition of carbon
03:11 - outputs
03:13 - so in this video we'll use python
03:15 - tessraft or simply by tesseract
03:17 - library which is a wrapper for google's
03:20 - tesseract or cr engine
03:22 - so i chose to make this video with
03:24 - pydescript because it's completely open
03:26 - source
03:26 - and it's being developed and maintained
03:28 - by a giant that is google
03:31 - so now first we need to download by
03:34 - tesseract
03:35 - or install it so that we can start
03:37 - working with it so to install pi
03:39 - tesseract you can go to this website
03:41 - uh and just do a simple pip install
03:43 - python
03:44 - so let's do
03:54 - the next thing which we need to do is
03:56 - have opencv
03:57 - in our computer to work with images
03:59 - using python so for that we do a pip
04:01 - install opencv
04:10 - this might take some time since opencv
04:12 - is a very very big software
04:14 - but since i already have it it was done
04:17 - in like a few seconds
04:19 - so next thing is for let's start
04:21 - creating our
04:24 - script a python script and start writing
04:26 - the code
04:32 - this should take about a few seconds to
04:35 - build
04:36 - almost there
04:40 - now first before we jump on to writing
04:44 - our script first actually let's see
04:48 - which image will be actually be reading
04:50 - from
04:51 - or how do we which image do we actually
04:53 - choose to extract the characters from so
04:55 - i have this image.png here
04:58 - so basically we'll be actually reading
05:00 - the characters from this image so this
05:01 - image has a few words
05:03 - so we try to write a python script which
05:06 - can actually read
05:07 - all of this from the image directly or
05:09 - using pi tessraft or the tesseract of
05:11 - crg
05:13 - so let's start first we make an ocr.py
05:17 - file
05:19 - now we need to import a few things for
05:21 - suppose we need to import
05:22 - cv2
05:32 - and the next thing actually we don't
05:34 - need numpy for now
05:36 - the next thing which we need is import
05:38 - by
05:40 - yeah so first uh
05:43 - let's actually read the image that we
05:45 - have so using
05:46 - again uh opencv so we have image equal
05:49 - to
06:00 - and now let's actually write our code in
06:03 - a much readable format and actually
06:05 - fragment
06:06 - the parts of our function that we need
06:08 - to write
06:09 - so let's define a function called as ocr
06:13 - and this is going to be dealing with the
06:16 - image
06:17 - and actually run our entire
06:20 - api and give us back the text from the
06:22 - image so basically text
06:24 - equal to by tesseract dot
06:29 - image to spring
06:32 - and
06:38 - so as you can see it's pretty easy and
06:40 - straightforward to actually use pi
06:42 - tesseract where we just have to make a
06:44 - function called
06:45 - where the method is image to strength
06:47 - passing the image parameter
06:48 - which again returns a text which we
06:50 - return back to our standard output
06:53 - so now it is not so straightforward to
06:56 - actually
06:57 - write nocr using python this might
06:59 - actually give us the results but
07:01 - as i said the results are not 100
07:03 - accurate we need to do some
07:04 - pre-processing of our own
07:06 - to get the result that we want so let's
07:09 - do that processing now the first thing
07:11 - which we need to do
07:13 - is convert the image to grayscale so
07:15 - let's write the function for that
07:21 - image parameter and we return
07:28 - series
07:33 - [Music]
07:41 - so color
07:56 - okay
08:00 - next thing which we need to do is uh
08:02 - remove the noise from the image so some
08:04 - images might be distorted
08:06 - and might have if you have some pixels
08:08 - which are not
08:10 - the way they're supposed to be so for
08:11 - that we actually remove some noise in
08:13 - the image to make it a bit more
08:14 - sharp let's see how we do that
08:18 - nice again we're leaving functions all
08:21 - of these the code is much more readable
08:30 - [Music]
08:34 - again let's give it a comment so that we
08:36 - know what the function is
08:52 - something called as thresholding so we
08:55 - need to have
08:56 - a threshold basically which states that
08:59 - if
09:00 - the pixel value is about uh it's above
09:02 - the threshold then the pixel
09:04 - is black or white and if it's below the
09:06 - threshold then again it's either black
09:08 - or white
09:09 - it's the opposite of what it is above
09:11 - the threshold so in this way we have
09:13 - a very concrete black and white image
09:16 - and because that
09:17 - it is very easy for pythagoras to
09:19 - predict or to give us out
09:21 - the characters from the image so again
09:24 - let's comment it first
09:27 - folding
09:30 - function the shoulder
09:34 - image and this is a bit
09:37 - long function called let me just
09:40 - copy it and then get it here
09:44 - so again we have a threshold we
09:47 - threshold this again depending on
09:48 - structured binary from the threshold
09:50 - also
09:52 - you can read more about these two
09:53 - functions uh in description below there
09:56 - is information in the description about
09:57 - all of this what i'm doing
09:59 - and now that we have a few functions
10:01 - which can help allow us to actually
10:04 - you know preprocess the image and
10:06 - enhance our image properly
10:07 - let's write the code to actually call
10:09 - these functions image equal to
10:12 - get grayscale and g first we
10:15 - convert this to grayscale and the next
10:17 - thing which we need to do is
10:19 - threshold image equal to
10:22 - thresholding image and finally now that
10:25 - we have thresholded
10:26 - it i don't know so the next thing which
10:30 - we need to do is remove the noise or
10:32 - excess noise
10:33 - that the image might have nice
10:36 - ing and yeah we're good to go so now
10:39 - that we have
10:41 - uh done our preprocessed or image using
10:45 - a very simple opencv techniques which is
10:47 - just you know
10:48 - converting it to greyscale removing the
10:50 - noise and just thresholding it
10:52 - the last part here is to actually call
10:54 - our ocr
10:55 - code so let's call our ocr code
11:00 - and pass the enhanced image here
11:03 - and once when we print it hopefully we
11:06 - should get this
11:07 - rtr this is the output where the output
11:10 - says a pipeline approach to category
11:11 - condition
11:13 - so let's just check the code once again
11:16 - and make sure that everything here is
11:17 - right
11:21 - looks about right and now we can
11:25 - run our code and see whether we have the
11:29 - output that we actually mean
11:32 - ocr
11:35 - and yeah as you can see we have the
11:38 - exact output which the image had
11:40 - which was basically a python approach to
11:42 - character recognition
11:43 - and we were able to extract that
11:45 - information from the image
11:47 - using the python test rank api
11:51 - so let's just go through uh what we have
11:53 - done here
11:54 - uh you know
12:02 - which just converts or uses the api to
12:06 - convert image to string
12:07 - but before that we had done a bit of pin
12:10 - processing on our
12:10 - image so we covered it to grayscale
12:13 - thresholded it
12:14 - and then remove the noise and after the
12:17 - image has been pre-processed
12:18 - we then pass that image to the ocr code
12:20 - and then we get our desired output which
12:22 - is
12:24 - as you can see a python approach to that
12:26 - reaction so
12:28 - uh that is all that is it for the
12:29 - tutorial for pythag
12:31 - there will be much more interesting and
12:33 - complicated tutorials
12:35 - about pipeline in the future but for now
12:38 - that is it thank you for watching i'll
12:40 - see you in the next video bye

Cleaned transcript:

in this video we'll talk about making a simple python optical character recognition script where we use uh pi test rack uh api over the google interest rate ocr engine to actually read text from images programmatically so in this video we will talk about what is ocr what are the applications of optical character recognition how can we actually build an ocr script where we can actually read image read text from images so let's get started so first let's have a very brief introduction about what ocr is so humans can understand the contents of an image simply by looking at it we perceive the text on the image as text and can read it so computers don't work the same way they need something more complete in an organized way to understand that so this is where optical character recognition comes into the picture whether it's recognition of car plates from a camera or handwritten documents that should be converted into additional copy this technique is very very very useful so in this video we will delve into the depth of optical character ignition and its application areas we'll also build a simple script and python that will help us detect characters from images and you can also build on top of this simple python script and build a web application out of it so what is ocr so optical character recognition involves detection of text content on images and translation of those images to encode a text that the computer can understand easily so how is this achieved uh so to us as i said uh text an image is easily discernable and we are always able to detect characters and read the text but for computers it's only a series of dots or pixels so the image is first scan and the text and the graphics uh elements are converted into something called as a bitmap which is basically a matrix of black and white dots then the image is preprocessed where the brightness and the contrast of them are enhanced to improve accuracy of process now the image split results identifying the areas of interest such as where the images or text are and this helps curve the extraction process the areas containing text can now be broken down into further lines worlds and characters and now the ocr engine or the software is able to match the characters through comparison and various ai algorithms the final result is the text in the image that we're given now uh be aware that the process may not be 100 accurate and it might need some human intervention to correct some elements that were not scanned correctly the error correction part can also be achieved using a dictionary or even an np natural language processing so let's see where we use ocr so ocr is very commonly used in airports to automate the process of pass protocol mission extraction from information out of it the other applications include automation of data entry processes detection and recognition of carbon outputs so in this video we'll use python tessraft or simply by tesseract library which is a wrapper for google's tesseract or cr engine so i chose to make this video with pydescript because it's completely open source and it's being developed and maintained by a giant that is google so now first we need to download by tesseract or install it so that we can start working with it so to install pi tesseract you can go to this website uh and just do a simple pip install python so let's do the next thing which we need to do is have opencv in our computer to work with images using python so for that we do a pip install opencv this might take some time since opencv is a very very big software but since i already have it it was done in like a few seconds so next thing is for let's start creating our script a python script and start writing the code this should take about a few seconds to build almost there now first before we jump on to writing our script first actually let's see which image will be actually be reading from or how do we which image do we actually choose to extract the characters from so i have this image.png here so basically we'll be actually reading the characters from this image so this image has a few words so we try to write a python script which can actually read all of this from the image directly or using pi tessraft or the tesseract of crg so let's start first we make an ocr.py file now we need to import a few things for suppose we need to import cv2 and the next thing actually we don't need numpy for now the next thing which we need is import by yeah so first uh let's actually read the image that we have so using again uh opencv so we have image equal to and now let's actually write our code in a much readable format and actually fragment the parts of our function that we need to write so let's define a function called as ocr and this is going to be dealing with the image and actually run our entire api and give us back the text from the image so basically text equal to by tesseract dot image to spring and so as you can see it's pretty easy and straightforward to actually use pi tesseract where we just have to make a function called where the method is image to strength passing the image parameter which again returns a text which we return back to our standard output so now it is not so straightforward to actually write nocr using python this might actually give us the results but as i said the results are not 100 accurate we need to do some preprocessing of our own to get the result that we want so let's do that processing now the first thing which we need to do is convert the image to grayscale so let's write the function for that image parameter and we return series so color okay next thing which we need to do is uh remove the noise from the image so some images might be distorted and might have if you have some pixels which are not the way they're supposed to be so for that we actually remove some noise in the image to make it a bit more sharp let's see how we do that nice again we're leaving functions all of these the code is much more readable again let's give it a comment so that we know what the function is something called as thresholding so we need to have a threshold basically which states that if the pixel value is about uh it's above the threshold then the pixel is black or white and if it's below the threshold then again it's either black or white it's the opposite of what it is above the threshold so in this way we have a very concrete black and white image and because that it is very easy for pythagoras to predict or to give us out the characters from the image so again let's comment it first folding function the shoulder image and this is a bit long function called let me just copy it and then get it here so again we have a threshold we threshold this again depending on structured binary from the threshold also you can read more about these two functions uh in description below there is information in the description about all of this what i'm doing and now that we have a few functions which can help allow us to actually you know preprocess the image and enhance our image properly let's write the code to actually call these functions image equal to get grayscale and g first we convert this to grayscale and the next thing which we need to do is threshold image equal to thresholding image and finally now that we have thresholded it i don't know so the next thing which we need to do is remove the noise or excess noise that the image might have nice ing and yeah we're good to go so now that we have uh done our preprocessed or image using a very simple opencv techniques which is just you know converting it to greyscale removing the noise and just thresholding it the last part here is to actually call our ocr code so let's call our ocr code and pass the enhanced image here and once when we print it hopefully we should get this rtr this is the output where the output says a pipeline approach to category condition so let's just check the code once again and make sure that everything here is right looks about right and now we can run our code and see whether we have the output that we actually mean ocr and yeah as you can see we have the exact output which the image had which was basically a python approach to character recognition and we were able to extract that information from the image using the python test rank api so let's just go through uh what we have done here uh you know which just converts or uses the api to convert image to string but before that we had done a bit of pin processing on our image so we covered it to grayscale thresholded it and then remove the noise and after the image has been preprocessed we then pass that image to the ocr code and then we get our desired output which is as you can see a python approach to that reaction so uh that is all that is it for the tutorial for pythag there will be much more interesting and complicated tutorials about pipeline in the future but for now that is it thank you for watching i'll see you in the next video bye
