With timestamps:

00:07 - hi this video course is on learning
00:10 - computer vision with Python and OpenCV I
00:12 - hope you are really excited about this
00:14 - course I'm definitely sure at the end of
00:16 - this course you will gain enormous
00:18 - knowledge on computer vision and you
00:19 - will have a tool box with several image
00:21 - processing techniques ready this is
00:23 - Catherine completing my master's degree
00:25 - in computer vision I'm currently working
00:27 - as a data scientist in Texas USA I'm
00:30 - interested in medical imagery
00:31 - researching and robotics you can find me
00:33 - in my LinkedIn before getting started
00:35 - with open CV let's see the overview of
00:37 - this course in section 1 we will provide
00:40 - some insights and installation
00:42 - procedures of open CV Python which work
00:44 - great for image processing techniques
00:46 - and computer vision in section 2 we give
00:48 - the inside of working with images in
00:50 - frequency domain and helps in finding
00:52 - the edges in the image using image
00:54 - gradients and segmenting the image in
00:56 - section 3 we detect features from images
00:58 - and use it for detecting the objects in
01:00 - images for example in this section we
01:03 - will detect faces in the images using
01:05 - features captured from several positive
01:07 - or negative images in section 4 we will
01:09 - learn about getting started with videos
01:11 - and do the background subtraction and
01:13 - calculate the optical flow of the object
01:15 - in the video using different methods and
01:17 - finally track the object in the video
01:19 - using mean shift and cam shape basic
01:21 - Python programming numpy and matplotlib
01:23 - all the prerequisites of this course
01:25 - let's get scattered the different
01:28 - morphological operations are erosion
01:30 - dilation opening closing morphological
01:32 - gradient top-hat black hat and
01:35 - structuring elements the first one is
01:37 - erosion the pixels in the original image
01:39 - are considered as one only if the pixels
01:41 - under 2d convolutional kernel is one
01:43 - pixel near the boundaries are eroded
01:45 - based on the kernel size it is useful
01:48 - for removing white noises or detaching
01:50 - two connected objects the function is C
01:52 - V dot erode
01:53 - I have a spoiler alert for you we're
01:56 - going to see one more example on this
01:58 - morphological operations in image
02:00 - segmentation using watershed algorithm
02:02 - let's look into the code for erosion so
02:05 - here we have used CV dot erode
02:07 - when after erosion this is they eroded
02:09 - image and this erode method remote all
02:12 - the white noises in the input image
02:15 - the second one is dilation it is the
02:18 - opposite of illusion the result an image
02:20 - pixel element will be one if at least
02:23 - one pixel under 2d convolutional curl is
02:25 - one this in turn increases the white
02:27 - region of the image or increases the
02:30 - size of the foreground object a nice
02:32 - removal dilation is performed after
02:34 - erosion so for dilation we use the
02:36 - method called CV dot dilate let's look
02:39 - into the code here we use CB 2 to dilate
02:41 - what it exactly does is it increases the
02:43 - white region of the image so this is the
02:46 - input image and this is the dilated one
02:48 - later looks so different the third one
02:51 - is opening opening is otherwise known as
02:53 - erosion followed by dilation it removes
02:56 - the noise in the image so we use the
02:58 - function C V dot morphology X with a
03:01 - parameter CB dot mara underscore open
03:03 - let's look into the code so here in the
03:06 - code we use smartphone GX with the
03:08 - parameter more underscore open so how it
03:11 - exactly works is erosion followed by
03:13 - dilation so this is the input image this
03:15 - is the opening image the fourth one is
03:18 - closing closing is otherwise known as
03:20 - opposite of opening so here dilation
03:23 - followed by erosion so we use the open
03:26 - Seavey's method CV dot morphology X with
03:29 - math underscore closed as the parameter
03:31 - so like I said Mark Foley underscore X
03:34 - and Mark Fonda's are close so how it is
03:37 - different from opening years like in the
03:39 - closing image you can see more of white
03:40 - region and damage which means first
03:43 - we've performed the erosion operation
03:44 - and then we go for the dilation one v
03:48 - honest morphological gradient
03:50 - morphological gradient is nothing but
03:52 - the difference between the dilation and
03:53 - erosion of the image the resulting image
03:56 - will appear as the outline of the image
03:57 - let's look into the code so here we have
04:00 - morphology X that is like they've been
04:03 - using it for a long well I guess and
04:04 - with the parameter C B 2 dot morph
04:06 - underscore gradient is the thing so here
04:09 - is the input image and here is the
04:10 - difference between dilation and erosion
04:12 - operation in the image next one is top
04:15 - hat top hat is otherwise known as
04:16 - difference between the opening of an
04:18 - image and the original image let's look
04:20 - into the code ok so here we use morph
04:23 - underscore top hat parameter for
04:24 - morphology X method so here is the
04:26 - output what's happening here really
04:29 - like it calculates the difference
04:30 - between opening up an image in the
04:32 - original image the next one is black hat
04:34 - black hat is otherwise known as the
04:36 - difference between closing of an input
04:38 - image and the input image and we have a
04:40 - parameter more underscored black hat
04:41 - let's check the code so how black head
04:44 - works is like it calculates the closing
04:47 - of the image and then you have the input
04:49 - image so finally finding the difference
04:51 - between closing of the input image and
04:52 - the original image that's known as the
04:54 - black head operation so the last one is
04:56 - structuring element so getting
04:58 - structuring element function from OpenCV
05:00 - gives you the desired shape and size of
05:02 - the kernel so we can get more funders
05:04 - correct we can get more fun tasks or
05:06 - ellipse or cross or whatever the
05:09 - function you want like rect in the sense
05:11 - like it will give you the rect shape
05:12 - kernel generally in certain images the
05:15 - pixel values have skewed only on a
05:17 - certain range for example brighter
05:19 - images will have almost all the pixel
05:21 - intensities of brighter values that is
05:23 - around the range of 240 to 255 on the
05:27 - contrary an ideal image will have pixel
05:30 - intensity values from all regions of the
05:32 - image so I think this might have given
05:34 - you a good intuition about the pixel
05:36 - intensity distribution in images so in
05:39 - this case meaning the transformation
05:40 - function that takes the input pixels and
05:42 - returns the equalized output pixels so
05:45 - we're gonna use this function numpy dot
05:46 - histogram so for using that we need to
05:49 - flatten the image first let's look into
05:51 - the code now so here we use numpy dot
05:53 - histogram and I'm giving the flattened
05:56 - image as the input for a histogram so
05:58 - from the given example it is understood
06:00 - that pixels lie in the brighter region
06:02 - so we need to have a full spectrum to
06:04 - transform the image into a good one
06:06 - that's what histogram Equalization does
06:08 - so in this lumpy array usage we have a
06:11 - master rate for the mastery all
06:13 - operations are performed on the non
06:14 - master elements explaining mastery is
06:17 - beyond the scope of this video this
06:19 - method gives you a lookup table which
06:20 - helps him mapping the input pixels to
06:23 - the output pixels we can just apply
06:25 - transform on the image the practical use
06:27 - case of histogram equalization is in
06:29 - face recognition before feeding the face
06:31 - images for training histogram
06:33 - equalization is applied even if the
06:36 - image was a darker one equalization
06:38 - almost get the same result as that of a
06:40 - brighter image
06:40 - hence Equalization
06:42 - is used to make all the regions of the
06:44 - image with a better lighting condition
06:46 - the next one is histogram Equalization
06:48 - with OpenCV we can achieve the histogram
06:51 - equalization in a similar way some
06:53 - issues with histogram equalization ZAR
06:55 - that histogram considers the global
06:57 - contrast of the image so if we have very
06:59 - bright object in the image by applying
07:02 - equalization to the image we'll make the
07:03 - image lose the information the brighter
07:05 - region so for open CV based histogram
07:08 - equalization we use equalized hist let's
07:11 - look into the code now so I perform
07:13 - equalize historian here so this is the
07:15 - input image and this is the equalist
07:17 - histogram so if you try to plot the
07:19 - histogram you can find that the pixel
07:21 - intensity distribution will be in all
07:22 - regions so like a discussed before we
07:25 - can solve this problem using adaptive
07:26 - histogram Equalization some issues with
07:29 - histogram equalization or histograms
07:30 - consider the global contrast of the
07:32 - image so if you have a bright object in
07:34 - the image by applying equalization to
07:36 - the image will make the image lose
07:38 - information in the brighter area so we
07:40 - can solve this problem using adaptive
07:42 - histogram Equalization here we divide
07:44 - the image into tiles with a default size
07:46 - of 8 by 8 and OpenCV histogram
07:48 - equalization is applied on each of these
07:50 - blocks as usual if there is any noise in
07:53 - the image histogram equalization will
07:55 - amplify the noise to solve this problem
07:57 - again we can apply contrast limiting by
07:59 - default fall to use the contrast limit
08:01 - and open series if any histogram bin is
08:04 - above 40 those pixels are clipped and
08:06 - distributed uniformly to other bins
08:08 - prayer - histogram Equalization after
08:10 - Equalization to remove these artifacts
08:13 - and tile borders bilinear interpolation
08:14 - is applied yes background subtraction is
08:17 - a major pre-processing step for the
08:19 - video the first method is so we need to
08:22 - extract the moving foreground from the
08:23 - static background it's gonna be really
08:25 - easy if the image of the background is
08:27 - available the first method is background
08:29 - subtractor emoji this is a Gaussian
08:31 - mixture based background subtraction or
08:33 - a segmentation algorithm it used a
08:35 - method to model each background pixel by
08:37 - a mixture of K Gaussian distributions K
08:40 - value ranged from 3 to 5 the weights of
08:43 - the mixer represent the time stamp that
08:44 - each color stay in the video the
08:47 - probable colors are the media background
08:48 - colors which stay in the video longer
08:50 - and static for achieving this we need to
08:52 - create a background subtractor object
08:54 - using Create background subtractor
08:56 - emotion
08:56 - it has the parameters like number of
08:58 - Gaussian mixtures length of history M
09:00 - threshold etc you can play around with
09:02 - these parameters in the video let's look
09:04 - into the code so here in the code we are
09:06 - going to use the same user in both video
09:08 - sample let me run the code okay here is
09:11 - the thing the background is subtracted
09:13 - from the video the second method is
09:15 - background subtract emoji - this is a
09:17 - Gaussian mixture based background
09:18 - subtraction or a segmentation algorithm
09:20 - the most important feature here is that
09:22 - it selects the appropriate number of
09:24 - gaussian mixture for each pixel in the
09:26 - video also it provides adaptability for
09:29 - varying scenes and illumination let's
09:31 - look into the code in background
09:33 - subtractor emoji they have different
09:34 - parameters in emoji - we have an option
09:37 - of detecting shadow in the video if
09:38 - Didache shadow is equal to true then it
09:40 - detects and marks the shadow in the
09:42 - video
09:42 - shadows are marked in gray color one
09:44 - more important thing is it decreases the
09:46 - speed of the background subtraction
09:48 - let me run this code so it looks like
09:50 - better than emoji the last background
09:53 - subtractor method is background
09:54 - subtractor GMG this algorithm make use
09:57 - of statistical estimation of the image
09:58 - and per pixel bayesian segmentation but
10:01 - default in OpenCV it uses 120 frames for
10:04 - modeling the background and deploys
10:06 - basing inference for the probabilistic
10:08 - foreground estimation new observations
10:10 - are given more weights than the old to
10:12 - differentiate the illumination
10:13 - morphological operations like opening
10:15 - and closing which we discussed in the
10:17 - section 2 are used to remove the noise
10:19 - you can try to implement this yourself
10:21 - as a homework today

Cleaned transcript:

hi this video course is on learning computer vision with Python and OpenCV I hope you are really excited about this course I'm definitely sure at the end of this course you will gain enormous knowledge on computer vision and you will have a tool box with several image processing techniques ready this is Catherine completing my master's degree in computer vision I'm currently working as a data scientist in Texas USA I'm interested in medical imagery researching and robotics you can find me in my LinkedIn before getting started with open CV let's see the overview of this course in section 1 we will provide some insights and installation procedures of open CV Python which work great for image processing techniques and computer vision in section 2 we give the inside of working with images in frequency domain and helps in finding the edges in the image using image gradients and segmenting the image in section 3 we detect features from images and use it for detecting the objects in images for example in this section we will detect faces in the images using features captured from several positive or negative images in section 4 we will learn about getting started with videos and do the background subtraction and calculate the optical flow of the object in the video using different methods and finally track the object in the video using mean shift and cam shape basic Python programming numpy and matplotlib all the prerequisites of this course let's get scattered the different morphological operations are erosion dilation opening closing morphological gradient tophat black hat and structuring elements the first one is erosion the pixels in the original image are considered as one only if the pixels under 2d convolutional kernel is one pixel near the boundaries are eroded based on the kernel size it is useful for removing white noises or detaching two connected objects the function is C V dot erode I have a spoiler alert for you we're going to see one more example on this morphological operations in image segmentation using watershed algorithm let's look into the code for erosion so here we have used CV dot erode when after erosion this is they eroded image and this erode method remote all the white noises in the input image the second one is dilation it is the opposite of illusion the result an image pixel element will be one if at least one pixel under 2d convolutional curl is one this in turn increases the white region of the image or increases the size of the foreground object a nice removal dilation is performed after erosion so for dilation we use the method called CV dot dilate let's look into the code here we use CB 2 to dilate what it exactly does is it increases the white region of the image so this is the input image and this is the dilated one later looks so different the third one is opening opening is otherwise known as erosion followed by dilation it removes the noise in the image so we use the function C V dot morphology X with a parameter CB dot mara underscore open let's look into the code so here in the code we use smartphone GX with the parameter more underscore open so how it exactly works is erosion followed by dilation so this is the input image this is the opening image the fourth one is closing closing is otherwise known as opposite of opening so here dilation followed by erosion so we use the open Seavey's method CV dot morphology X with math underscore closed as the parameter so like I said Mark Foley underscore X and Mark Fonda's are close so how it is different from opening years like in the closing image you can see more of white region and damage which means first we've performed the erosion operation and then we go for the dilation one v honest morphological gradient morphological gradient is nothing but the difference between the dilation and erosion of the image the resulting image will appear as the outline of the image let's look into the code so here we have morphology X that is like they've been using it for a long well I guess and with the parameter C B 2 dot morph underscore gradient is the thing so here is the input image and here is the difference between dilation and erosion operation in the image next one is top hat top hat is otherwise known as difference between the opening of an image and the original image let's look into the code ok so here we use morph underscore top hat parameter for morphology X method so here is the output what's happening here really like it calculates the difference between opening up an image in the original image the next one is black hat black hat is otherwise known as the difference between closing of an input image and the input image and we have a parameter more underscored black hat let's check the code so how black head works is like it calculates the closing of the image and then you have the input image so finally finding the difference between closing of the input image and the original image that's known as the black head operation so the last one is structuring element so getting structuring element function from OpenCV gives you the desired shape and size of the kernel so we can get more funders correct we can get more fun tasks or ellipse or cross or whatever the function you want like rect in the sense like it will give you the rect shape kernel generally in certain images the pixel values have skewed only on a certain range for example brighter images will have almost all the pixel intensities of brighter values that is around the range of 240 to 255 on the contrary an ideal image will have pixel intensity values from all regions of the image so I think this might have given you a good intuition about the pixel intensity distribution in images so in this case meaning the transformation function that takes the input pixels and returns the equalized output pixels so we're gonna use this function numpy dot histogram so for using that we need to flatten the image first let's look into the code now so here we use numpy dot histogram and I'm giving the flattened image as the input for a histogram so from the given example it is understood that pixels lie in the brighter region so we need to have a full spectrum to transform the image into a good one that's what histogram Equalization does so in this lumpy array usage we have a master rate for the mastery all operations are performed on the non master elements explaining mastery is beyond the scope of this video this method gives you a lookup table which helps him mapping the input pixels to the output pixels we can just apply transform on the image the practical use case of histogram equalization is in face recognition before feeding the face images for training histogram equalization is applied even if the image was a darker one equalization almost get the same result as that of a brighter image hence Equalization is used to make all the regions of the image with a better lighting condition the next one is histogram Equalization with OpenCV we can achieve the histogram equalization in a similar way some issues with histogram equalization ZAR that histogram considers the global contrast of the image so if we have very bright object in the image by applying equalization to the image we'll make the image lose the information the brighter region so for open CV based histogram equalization we use equalized hist let's look into the code now so I perform equalize historian here so this is the input image and this is the equalist histogram so if you try to plot the histogram you can find that the pixel intensity distribution will be in all regions so like a discussed before we can solve this problem using adaptive histogram Equalization some issues with histogram equalization or histograms consider the global contrast of the image so if you have a bright object in the image by applying equalization to the image will make the image lose information in the brighter area so we can solve this problem using adaptive histogram Equalization here we divide the image into tiles with a default size of 8 by 8 and OpenCV histogram equalization is applied on each of these blocks as usual if there is any noise in the image histogram equalization will amplify the noise to solve this problem again we can apply contrast limiting by default fall to use the contrast limit and open series if any histogram bin is above 40 those pixels are clipped and distributed uniformly to other bins prayer histogram Equalization after Equalization to remove these artifacts and tile borders bilinear interpolation is applied yes background subtraction is a major preprocessing step for the video the first method is so we need to extract the moving foreground from the static background it's gonna be really easy if the image of the background is available the first method is background subtractor emoji this is a Gaussian mixture based background subtraction or a segmentation algorithm it used a method to model each background pixel by a mixture of K Gaussian distributions K value ranged from 3 to 5 the weights of the mixer represent the time stamp that each color stay in the video the probable colors are the media background colors which stay in the video longer and static for achieving this we need to create a background subtractor object using Create background subtractor emotion it has the parameters like number of Gaussian mixtures length of history M threshold etc you can play around with these parameters in the video let's look into the code so here in the code we are going to use the same user in both video sample let me run the code okay here is the thing the background is subtracted from the video the second method is background subtract emoji this is a Gaussian mixture based background subtraction or a segmentation algorithm the most important feature here is that it selects the appropriate number of gaussian mixture for each pixel in the video also it provides adaptability for varying scenes and illumination let's look into the code in background subtractor emoji they have different parameters in emoji we have an option of detecting shadow in the video if Didache shadow is equal to true then it detects and marks the shadow in the video shadows are marked in gray color one more important thing is it decreases the speed of the background subtraction let me run this code so it looks like better than emoji the last background subtractor method is background subtractor GMG this algorithm make use of statistical estimation of the image and per pixel bayesian segmentation but default in OpenCV it uses 120 frames for modeling the background and deploys basing inference for the probabilistic foreground estimation new observations are given more weights than the old to differentiate the illumination morphological operations like opening and closing which we discussed in the section 2 are used to remove the noise you can try to implement this yourself as a homework today
