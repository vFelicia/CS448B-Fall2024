hey welcome back everyone this is Ian bringing you the third video in this AI series with the New Boston in this video we're going to build upon what we created in the first two videos where we interacted with the gbt 3.5 turbo using open ai's chat completion API in the first video we just asked a question we hardcoded it and we got back an answer in the second video we actually got Dynamic input from our user whenever we ran our program and then we used that to ask a question of the model and we got back and answer again this time we are going to continue on that but we're going to have a back and forth continuous conversation with the model so let's go ahead and get into the code on the first couple lines of course we have our boiler plate importing whatever packages we need and setting our API key on the open AI library now we have an example of some potential inputs that we can provide here in this multiline Comet so we me being Ian uh you could put your name here if you wanted to we're going to ask uh we're just going to greet the model saying hi Grandma and then give me a suggestion on what to eat for lunch and then we're going to follow that up with what is the recipe for that so in between each of these queries we're going to have some responses from the model and you can see whenever we run the program how we actually get to have a back and forth conversation where the model actually remembers the previous thing that we told it for context it has a history of the conversation and it's able to respond accordingly so let's see how we're doing that down here on line 13 we have our messages list nothing new here except for instead of hardcoding a user roll object right after our system roll object we're going to do that dynamically inside of a w Loop which comes next but let's take a look at the system roll object that we have inside of the list of course the system roll object always needs to happen first before everything else one time and then after that we're just going to have a back and forth between user Ro and assistant role user role being what we input and then ass assistant role being what the model sends back back to us as a response to our request to the API so the system role is the same as what we did in the previous video where the content is set to you are sweet old helpful Grandma so we're going to be communicating with Grandma in this program and we have an infinite Loop here so while true and then we're going to gather the user text input using the input method in Python where the argument that we pass in here is just a string of e in colon space and that's just prompting us the user whoever running the program hey this is the part where you enter in the input for in this case Ian once we get that assigned to the variable then we're going to take it and we're going to inject it into this dictionary here which is the user roll object we're going to pass that into messages. append so it'll take the user roll object with the dynamic content that we just got from that input on the previous line and it'll append it to the end of our messages list so like I said previously we had it hardcoded system roll message and then after that the user roll message we're doing that now except the user roll message is getting appended dynamically and that's important because it happens inside of the W Loop now as we continue to have this continuous conversation with our model we can add new Dynamic input from us the user and additionally later on we're also going to include the responses from the model so let's take a look at what's next here here is the code that should not be new to you it's the same thing that we used in the previous two videos where we're actually making the request to the openai chat completion API so we're creating a new chat completion object and we're passing in the arguments of the model set to GPT 3.5 turbo the messages set to the current state of our messages list the temperature we're keeping it low around 0.5 so not a lot of creativity uh going on there and then the max tokens we like to have it around 1,024 for this use case but feel free to play around with it for whatever you're building so we get that response from the API and then we can Traverse into that object you've seen the object in our logs from the previous videos but essentially it has information about the chat completion when it was created the various choices available to you in this case there's always one choice un lets you tell it to have more which we're not and we're going to go into that First Choice get access to that message object and then pull the content string out of it that content string is going to be the textual response from our assistant role so from the API we're going to assign that to the granny response variable and then we're going to print that we're printing it so that we can keep track of the conversation in the console and see what the responses are from the API however we also need to include that in a assistant role object that we append to the end of our messages list so I know I said this twice already but we start out with our system role and then we have our user role now we're including our first assistant role object and then we're going to go back and forth user Ro assistant role for the remainder of however long we keep this program running for and that's how we keep the history of the conversation and keep providing context back to the API for each of our API calls in the future so here we have messages that's our messages list. aend this is just going to put this dictionary onto the end of the messages list the role is set to assistant and then the content is whatever the dynamic value is of that cont content string that we're getting back from the API response up here so again we assign that to Granny response we pass it in here we append it to the end of messages as an assistant roll object and now the loop is going to run over again and it's going to wait for us to provide further user input here and keep continue to repeat that process so that's it for the code really straightforward really simple let's go ahead and run it and see what happens so we'll go ahead and open up our terminal here we'll run python main.py with our virtual environment activated we're inside of the open AI example 03 continuous conversation folder and we're going to execute that main.py file using Python 3 so when we run that the first thing it does is it gets down to the user text input Ian which you see highlighted over here on the left and it's just prompting me for my input so I'm going to keep it simple hello Grandma now we wait for Grandma to respond short and sweet hello dear how can I help you today so that's perfectly in line with what we told the model how it was going to behave it's a helpful old grandma that checks out so now I can say can you please recommend something for lunch we got to say please because it's our grandma so we wait for a moment it comes back of course dear how about a comforting bowl of homemade chicken noodle soup it's nourishing and delicious or if you prefer something lighter a fresh salad with grilled chicken and mixed greens would be lovely what do you think so this is nice it's actually giving us options so let's go with the chicken noodle soup so I'll say I like the chicken noodle soup can you please provide a recipe for that so let's see if it can give us a recipe with the number of response tokens we've limited to in our Max tokens so the recipe might take a second to come back it's probably the the largest response thus far and sure enough there it is so if we take a look Grandma comes back with absolutely here's a simple recipe for homemade chicken noodle soup it gives us all the ingredients nice and organized in an unordered list then the instructions in an order list every single step that we need to do to create a delicious bowl of soup and at the very end a message there you go dear I hope you enjoy making and eating this comforting chicken noodle soup let me know if you need any more help so because we're inside of a infinite Loop when we finally decide that we want to exit out of here we just contrl C keyboard interrupt and that'll stop the program from running and that's it for having a continuous conversation with your GPT model inside of the chat completion API thanks a lot and we'll catch you all in the next video