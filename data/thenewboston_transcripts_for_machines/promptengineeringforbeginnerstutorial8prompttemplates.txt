hey what's up everybody welcome back this is Ian bringing you another video in this AI series with the New Boston so in today's video I'm going to show you some more cool stuff that we can do with prompt player specifically we're going to create something called a prompt template so prompt templates are kind of what they sound like we can create templates for our prompts there's more to it than that we're going to show you in this video but essentially you know when we're creating a prompt we can have like messages we can have our arguments to our API calls like the temperature and the max tokens and which model to use all that stuff can be predefined so that we can use it over and over again also there's a really powerful feature where we can inject variables into placeholder values using something called an FST string in Python and it's going to make it to where it's super easy for us to take a prepackage template modify it with just a couple little clicks and changes of our code so so let's go ahead and see what we can see over here on the dashboard interface and then take a look at it in our code so if you're logged in to prompt layer then you should be able to go up to registry at the top here you'll see all of your prompt templates I only have one and then you have a blue button here where you can create a new one so if we click on create a new one it defaults to the completions API we've been using the chat completions API so if you want to toggle that over you'll notice that the interface changes a little bit essentially it's going to give us the ability to create templates for the system Ro if we click new message we can create a template for the user Ro if we click it again we can do another one for the assistant role we can input the name of a function if we're doing function calls down here at the bottom where it says functions we can actually input the information about our functions if you aren't familiar with function calls we made a video for that previously so feel free to check that out down here for parameters we can set parameters for everything from our model name whether we're using three and a half turbo or we're using four or we're using CLA instead of open AI uh we can change the temperature the maximum tokens all these other parameters we can go in here and modify them that way we have like a preset defined template with the specific parameters that we use and we can just use that across our different programs we have metadata which is a feature specific to prompt layer so metadata just allows you to add additional meta information to your requests we also have tags you can go in here and add new tags so this makes it really easy for you to search through your different promt templates or your different requests that you made with prom templates we also have scoring for individual requests we'll talk more about scoring in a later video but lots of powerful stuff here now I'm not going to use the user role and I'm not going to use the assistant role I'm just going to use the system role over here so the title of course is important we'll just do something like assistant type I already have one called that so I'll make it two and then the system here is where we want to put in our actual template our actual text anyway now we're going to use the F string uh formatting which is just single curly brackets for our placeholder values you can see an example of that down here but you can drop down with this little carrot and you can choose Ginger 2 if you prefer Ginger 2 is going to give you the ability to use the Ginger 2 syntax which I believe is just double curly brackets instead of single curly brackets so whichever you prefer you can use that option there so here in the assistant you know the default is uh you are helpful assistant here in the system role now we can modify that to anything we want so we can say you are a helpful math assistant and then we can go a step further we can say you know you only answer math related questions uh so on and so forth we can direct it we can say hey if someone ask something that's not math related then you just don't answer them or you politely decline to answer and this will set the context for all of our interactions with the chat completion API now we can dynamically inject values into this text right here which is really powerful so we have math repeated twice here but also what if we want to change it to something else what if we want it to be a helpful coding assistant or a helpful theme park assistant or whatever it may be so we can actually change this using the curly bracket syntax so we'll select math and we'll do open close curly brackets and then we can put whatever variable name we want inside here so in this case I'm just going to call this one type and I'm going to borrow that and I'm going to go find where I have math again and I'm going to replace it and so now when we get over to our code and we're actually using this template we're just going to pass in a variable called type with whatever value we want it could be math it could be any of those other things we mentioned and it'll dynamically update the string before we pass it to our actual API call so this is going to be really powerful we're going to show you a practical example here in a moment uh you can go ahead and click create template down here and it'll add it to your registry now I already have one over my registry so I'm not going to use that one here you can see if I click on this it's similar to what we just had U helpful type assistant you only answer type related questions anything that isn't related to type will be poly declined and you will gently correct the user now if you go down here you can see the input variable is typed so it recog recn that that was the variable if we had more than one it would show us what other variables we had uh you can see the metadata the parameters your average score if you're using the scoring feature how much it cost to make this request you know how many times you've used this template uh the average latency for the use of this template and the requests that you made using it here's the actual requests and then all the information associated with them now being able to get this tracked over here uh we have to take a couple steps in our our code I'm going to show you exactly how to do that so the first thing we have to do is take it from here use it in our code and then in our code we take the responses and we link them back to our dashboard so pretty easy back and forth I'm going to show you everything in our Python program but I just want to show you how simple it is to be able to create prompt templates from the promp layer dashboard before we jump out of here I just want to show you that if you edit this template or any one of your templates and then you update it it's going to ask you to create a commit message this is very similar to like if you were using git or some type of Version Control it's just going to be a little comment that indicates to you you know which changes were made in this specific version so I'm going to cancel that head back over to my registry click on assistant type if I click on the versions you can see this little comment box down here it's got update Title for version two and it's got init commit for version one so you can see that those are the two changes and if you were to edit and update and add a new commit message you would get a new version this is is important because you don't have to create delete create anything like that a new prompt template every time you want to change a specific template you can just edit it update it and have a whole history of all the versions so if you want to toggle back and forth between different versions and see how each one performs you can do that we'll show you how to change between versions in your code so that should be everything with the basics of creating prompt templates over here in your prompt layer dashboard now let's head over to our code editor and I'll show you how we can get access to the prompt templates in our code all right here we are are in our code editor we're in our AI playground repository Link in the description below we're inside of the open AI examples folder the subfolder 07 prompt templates and then the file main.py so at the top here we just have our boiler plate we're just importing OS so that we can get our environment variable for our promp layer API key and then we're bringing in prompt layer we're setting the API key for prompt layer and then we're bringing in open AI now because we're layering prompt layer on top of open AI the way that we import open AI is that we actually bring it in from prompt layer so that's why we bring in prompt layer first and then open AI second now you'll notice the syntax is a little bit different for open AI we're now using this capital O Capital AI open a as opposed to the import openai that we used previously that's because we're using the newer version of the openai library and this is how it's done in the most recent version so open AI is equal to prompt layer. openai doop and then client is equal to openai open close parenthesis the client is what we're going to actually use to make the calls to the chat completions API we'll see that here in a minute okay so we have a comment here that says prompt templates are customizable prompt strings with placeholders for variables so if we go down we first want to bring in the entire template that we just created we called it assistant unor type so we can use prompt layer. promps doget pass in that name as a string and the resulting object that comes back will be assigned to this assistant unor type variable now it's going to have a lot more information than just that system roll message that we created but there is a way for us to easily Traverse down into this dictionary and pull out that template that we want to use in addition to the promp layer. promps doget with the string argument you can actually add a comma and then a keyword variable called version and set it equal to whichever version you want so that's what I mentioned a moment AG go if you have multiple versions and you want to use a specific version just pass that in to your prompts doget call and then you'll be able to use whichever version you specify all right so we have a variable called type and that's our placeholder variable that we want to inject something into in this case you could have multiple variables and you could store them in a dictionary called variables we only have one but just for the sake of showing you how you probably want to do it we'll go ahead and store the type type key in its current value of web development inside of this variable's dictionary you'll see how we use that here in a second so we need to go down inside of the assistant type dictionary and pull out the actual template so the template is the one you actually have multiple templates if you use multiple different roles like I mentioned you can use the user role the assistant role any number of those actually in this case we just used the system R and just like in our messages list where the system always comes first the system roll object that's the same format here so when we go down into assistant type there's going to be a messages key that's going to point to a list of message objects the first one the zeroth one is always going to be the system roll so we use bracket zero to get access to that object and then it has a key call Prompt and then that has a key called template and the template key is actually going to return to us the string with the curly bracket syntax for the type variable and then we're going to actually format that and inject web development down into it so now that we have the template assigned to assistant type template on the next line we're going to create a new variable called content and we're going to set it equal to the assistant type template variable and because it's a string we're going to call the format method on it and we're going to replace all of the instances of curly bracket type with web development the way that we do that is we call. format and then we pass in type is equal to web development now because we have a variable's dictionary and because the variable's dictionary could have more than one key value pair for example we could have another one here called name and that could be something like Jane we are going to use the double asterisk variable syntax and what this will do is it'll just take this dictionary take all of its key value Pairs and it'll pass them in here as keyword arguments pretty simple so if there's a key called type it'll pass it in like this and if we had another one called name it would pass it in like that now in this case we only have our type key so we'll leave that like that and then here just so we can make it Dynamic we'll go ahead and go back to the double asterisk variable syntax but that's what's happening behind the scenes with the syntax right here it's going to take that string and it's going to replace any instance of the curly bracket type with the word web development the resulting string is going to be assigned to the content variable and we're going to use that down here whenever we actually make a request to the chat completions API all right so let's take a look at this syntax right here it's pretty similar to what we've done in the past with some slight modifications so you'll know that we've already updated our Syntax for the open AI Library if you watched our previous video with those syntax changes but essentially instead of doing open a. chat completion. create we do client. chat. completions all lowercase doc create then we pass in our arguments so our model gbt 3 and2 Turbo in this case we're using the most recent release 1106 and then we have our messages list it always starts with the system roll and then it has the content normally we would hardcode this but now because we're pulling it from our prompt template and we've assigned it to this content variable we can pass in the variable here so this will be that text that we assigned over in the dashboard from prompt layer where we say you are a helpful blah blah assistant you only answer blah blah related questions yada yada and so in this case it's going to be a helpful web development assistant now when we run it here in a second I'll show you why this is powerful but it's really useful that we can just change it one time here and then it's going to change everywhere else in our template the next thing that we have here is return PL ID is equal to Boolean value of true we haven't seen this before this is a prompt layer feature and it's just saying hey return back to me a prompt layer ID now remember we're using open AI but we're using it with prompt layer layered on top of it and so we have some additional features and functionality and that's where this argument comes from so what's going to happen is instead of just getting back a response object with some stuff inside of it we're actually going to get back a tuple so a tuple is kind of like a list except it's immutable meaning it can't be changed and that's the main difference here is that it is an immutable list and in this case what we're going to get back is two things the first argument of our tupal is going to be the response object from the chat completion call and then the second one is going to be the ID the pl request ID that we asked it to return so we'll just say something random like 1 2 3 4 so we've got all of our information inside of the dictionary for the response to the chat comp completion call and then we've got the pl request ID now because we use this syntax response comma plore request uncore ID is equal to this API call and because this is our response the first thing gets assigned to the first variable response and the second thing gets assigned to the second variable plore request ID so now we can use these variables later on in our code so down here we're going to Traverse through the response we've done this previously where we have our choices we look at the first choice we go to the message object the message object is going to be for the assistant role and it's going to have a Content key which is going to be the string which is essentially the answer from the API to our question from our user role in this case we've hardcoded it here what is HTML so this is going to be the answer to that question so we're going to print that answer and we can see what the API is telling us back now mind you we also got that plore request ID we're going to use that that down here so that we can associate the request that we just made to the open a API with the prompt template that we used from prompt player so we say prompt layer. track. prompt it takes three arguments the first one is going to be the request ID and we assign that to the plore request ID that's the one that we got back right here and then the next one is the prompt name this is just the name of the prompt template that we used for the request in this case assistant underscore type and then the prompt input variables that's going to be set equal to our variables dictionary so we have our variables dictionary right here and of course we use assistant type here and we use the same name here if you want to put those into a variable so that you don't have to type it twice that might be a smart thing to do I haven't done that here but I would probably do that in a production application so the next thing we want to do is attach some meta information as key value pairs to our request so we can do that with prompt layer by doing promp layer. track metadata and it takes two arguments the first one is the request ID so again we pass in that plore requestor ID and the next thing is a argument called metadata set equal to a dictionary of key value pairs of any type of meta information that we want to include so this is just some madeup stuff that I have here you could put whatever you want anything that's relevant to the request that you want tracked all right so now that we've gone through the code let's go ahead and run it and see what the output is and then we can make some changes to it and see if it does what we want it to do so if we remember our variable type is web development and therefore our system role is set to a helpful web development assistant who only answers web development related questions our first question is what is HTML so if we run our code it should actually answer our question and sure enough it says HTML stands for hypertext markup language Etc so it's actually answering our question in a helpful way at the very end it says if you have any more specific questions about HTML feel free to ask great that's just what we expected it to do now if we change it to where it's no longer a web development assistant and let's just say you're a math assistant and we leave the hardcoded question from the user as what is HTML then we should expect for it to give us a different response so the response from the API is I'm here to assist with math related questions if you have any math queries feel free to ask and I'd be happy to help so this is showing us that it actually used our prompt template and it changed it to math and now because we told it you know if it's if you are asked any questions that are not related to whatever the type is in this case math then you won't answer them now the other question was answered because it was related to the type however there is some room for error here and this is where this kind of thing gets helpful because you can track which one of these prompts is working and which ones need to be tweaked and modified so if we go back here and we change type to English not English language or anything like that we just say English then there's a chance that it might misinterpret it and actually answer the question about HTML even though we meant you know you're like a English language Professor or something like that that's not what we explicitly said and sure enough you can see it actually answered the question about HTML even though we didn't tell it that it was a web development assistant so this is helpful because you can run these and you can track these and you can see which ones work and which ones need to be modified so that they get you the type of responses that you're expecting so before we go let's head back over here and if we look at assistant type on the left you can see all of your requests have updated in real time on the right you can see these have not updated in real time so let me refresh this page here we go so here we have this was a few seconds ago 2 minutes 2 minutes Etc and and you can see all of the different responses and when you Mouse over the type you can see this is the one for English you can see this is the one for Math and this is the one for web development now if you click on any one of these like we click on this one for example it's going to take us over here to this interface and now we can see which model we used we can see what the latency was how many tokens what the cost was we can open it in the playground we can see what the system prompt was what the initial user prompt was what the assistant prompt was we can check the metadata and this is where the metadata was attached to so remember that information I put you know client type is browser username is Ian that's all included here so that's it for using prompt templates with prompt layer again there's a lot more to be explored so feel free to check out the documentation or ask us questions in the comments below thanks a lot for tuning in and we will catch you all in the next video