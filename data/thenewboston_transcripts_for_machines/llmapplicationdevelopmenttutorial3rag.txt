all right everybody welcome back to another video and in this one we are going to be improving ya even more so in the last video we improved A's ability to answer very simple programming questions but then towards the end of the video we started thinking about the product from a more realistic point of view now putting ourselves in the user shoes whenever they're on this video page talking to the chatbot we know that they're not going to be asking strictly simple programming related questions I mean it's more realistic to believe that they may ask questions about I don't know maybe some people that they saw in the video or maybe questions about the source code in the video or maybe they're going to be asking questions to a about herself like um what llm are you using or what's your name or what is your purpose who knows what the user may type into this chat box now in order to give a the ability to answer these types of questions we need to give her some more intelligence some more information so now what we can do is in our template where do we start well let's go ahead and open up our existing template in the playground and let's go ahead and ask one of these questions so for example this is a question from Ian one of the ones that we're going to be uh using in this example and in here this is a prompt engineering tutorial that he made about image variation now in this this let me see if I can get that screenshot again okay so that's not that's not me this is me right here so he used my image in this video and by the way this is just the uh the variation of it but anyways the point of the story is let's imagine that a user is on this video and they ask who is the dude in this video well right now of course what we're looking at is basically A's brain and she doesn't know anything about any video she doesn't know she's going to be embedded on the New Boston uh website she doesn't know anything except for this right here and what is already in the llm all that information so of course that's not going to work also if we ask something like what is your name uh that's not going to work either and I'll show you guys the other um examples that we're going to try to figure out so this is a C++ tutorial if someone ask what's the return value of this video or maybe someone ask in this video what's the name of this class or maybe someone asked in this video what is printed out in this first Loop ya just doesn't have that information so now we have to ask ourselves what information does a need in order to be able to answer these types of questions well the first thing I can think that would really help her out are the transcripts from these vide videos so all of this text again she can't hear the audio but what we can do is we can take this video get the trans script from it basically convert it to text and then feed that text into IO now another kind of classification of questions that people ask a lot are about the source code in the video so if we could also provide I with the source code I think that would help a lot so what our plan is is in addition to this very basic system prompt what I want to do is I want to provide a with the transcript of the video and we'll say the transcript is going to go here and then I also want to provide the source code so let's just go ahead and see if these two things can answer some answer some of these simple questions and the first question that we will try to answer is who is the dude in this video of course the dude is me but I'll say this who is the dude in this video all right so before we convert this into a prompt template and add our variables right here what I want to do first is I just want to manually stick in a transcript in some source code here just to prove that this Theory can work and if I do provide a with this information then she could potentially spit out more accurate answers so for the transcript this is actually pretty interesting so open AI they actually have this model right here whisper one and what it can do is you can give it an MP4 video and you can upload it and it can return the transcript of the video so I have those four videos that I just showed you uh the first one was prompt engineering then Bucky C++ tutorial then my Java one then my intermediate Java one so what I'm going to do in this example is I'm just going to give it this video right here and I'll show you the transcript that it pops back out so this takes about like uh I don't know 15 seconds or so all right I think that was a little bit longer than 15 seconds but either way you can see what it returns is the text from the video and actually this is pretty good I went over it and uh was just doublechecking and it's pretty dang accurate but either way what I want to do first is I just want to plop this in where the transcript is going to be and then the other thing that I want to paste in which isn't going to help with this question specifically but just to kind of show you guys the template I'm going for in this video I want to paste in this source code as well so the source code for this is in this AI playground repo but for now I'm just going to take this and inject it right here now another thing that I I want to do is I want to update my prompt and let me just remove this sentence right here uh you are embedded on a website that helps uh people program through YouTube videos and this way I just want to give a some context of like where she is living in the universe basically so I want to say you're on a website so if someone says like hey something about the website or a video she doesn't get a little lost so now with this extra information I'm going to ask again who is the dude in the video because I know for effect uh let's see if I can find it yeah it says uh I probably recognize this person as Bucky so now let me go ahead and send this request and check it out all right so now we can see that I was indeed able to give the right answer that it was Bucky Roberts that's me and that information again came from the transcript in the video so from here what I want to do is of course go ahead and convert this to a prompt template now I can kind of just save the time here so in actually let me just do this maybe easier so I'm going to copy this entire system prompt and then I'm going to make a new template and I'll say a video and I'll paste this in for the system prompt however instead of hardcoding this transcript I'm just going to first of all change this to Ginger 2 and I'll say this is going to accept a transcript variable which I'm going to be uh pasting in basically right here and it's also going to accept a source code little snippet that I'm going to be pasting in right there and the last variable that we need just like before is we need the question from the user now there's another thing that I'm thinking through that may help and that is this kind of ignore this right now you remember earlier when actually I think this was the first video there or the second video and I said um what's the problem with this and I said something like VAR equals 3 and I was hoping to get back the answer that it's missing the variable name and it needs a semicolon however I was a little confused because she didn't understand that I was asking it from a JavaScript perspective she got confused and thought that I was writing python which admitted this does look more like python than JavaScript but either way I think another good thing to help clear up some of that confusion is if we pass in the topic of these videos to let her know hey we're talking about C++ or hey we're talking about a Java tutorial I just think that would be um better to give her more context or understanding of the problem so with that I will say this video topic and let's just call it video topic all right so now whenever I use this prompt template I'm going to have to give it four V variables the topic of the video the transcript the source code from the video and then of course the question which is going to come from the user of whatever the question is now the last thing I want to do is I just want to go ahead and set the parameters for this which you guys understood why I'm doing that from the last video and now I just want to save this so now we have this new prompt template now how do we test it well you guys already know this as well and also what I did before this video is I already made up this test right here and I also see that I named it topic instead of video topic so what I'm going to do is just edit my template real quick to rename this topic just so I can keep everything consistent okay so I'll go ahead and quickly talk about um these again there are only well how many questions do I have four different questions so the first one like I said is who is the person in this video this prompt engineering video and the answer should indeed be Bucky Roberts the second question I'm going to test a on is what is the return value of the main function from this video and this main function returns zero so that's why it's zero now in this one the Java programming video I said what is the name of the class in this video so the name of the class is indeed apples it's the only class in the video and for the last question I just say what words print out in the first Loop for the intermediate Java tutorial and this first Loop it prints out all the words that start with Fu so Funk and furry is the right answer so Funk and furry so now that we understand the basic test that we're going to use what I can do is I'm just going to go ahead and download that to a CSV and again this was called video specific questions so now I'm going to go ahead and create a new evaluation and I'll just name it video specific questions and now for the data set I'm just going to upload that data set that we you're just taking a look at video specific questions and for the name I'll just name it video specific questions data set nothing too fancy here and this is the data set that I want to use with these four questions so now I'm going to go ahead and select my data set and I'm going to go ahead and create my pipeline so now what I want to do is this I'm going to add another step and I'm going to be evaluating that prompt template that we just created and for this I'll just name it the llm response as well and for the prompt template we're actually going to be using that new one called I of video we'll just use the latest version and now here I just need to plug up basically all of these columns to say which template variables are they going to be connected to so the question is the question this is why I like naming my um column names the same as the variable name and the template because when you're evalua it's a piece of cake to kind of hook everything up the source code is going to go here and the topic is going to go there and there you go and since we already configured this prompt template to use I can show you University I of video it is already configured to use open AI 3.5 turbo that's why it's already spitting out these answers and there you go you can now see that with this extra context with this added information a is now able to answer this whole other slew of problems that she was unable to before so very cool and in fact just to kind of uh walk you guys through this architecture this is actually called a rag architecture what it basically means is before you send your prompt to the llm you're going to inject some additional information into it so to show you guys a more realistic example of how this would work in the real world what would happen is ya is going to be living on my server that's running the new boston.com and of course all of this data is going to be in some um database whether it's a thirdparty service or API basically this app needs to reach out to somewhere else to grab this extra data so let's just say that for the sake of Simplicity that the source code in all the transcripts for my video were just stored in my own database for the New Boston so what happens is whenever this question comes in is what is the name of the class in the video my app or a is basically going to say okay what video page are you on oh I see you're on Java 7 video or whatever so I'm going to go ahead and get the transcript for this video in the source code I'm going to inject it into those that prompt template where those two variables are as well as the topic of the video and then I'm going to send this this to the llm now the reason that this is called rag I really don't like the name of it but it stands for I believe retrieval augmented generation basically means you're retrieving some data you're augmenting or changing the prompt by adding it to it and then you're generating the response so retrieving data adding or augmenting and then generating the response now the reason I wanted to take some time and talk about this architecture specifically isn't because you know I didn't think you guys could figure out how to pull data from a database and inject it in your prom template but more so to focus on how we are evaluating this prom template because the way we evaluate it in the way we are going to use this in the real world are slightly different and there's a reason for this so we see here the real world usage is going to involve making an API call or basically doing something extra with some third party service to grab this information now in our evaluation we aren't doing that what we're doing is we're just taking the response data from whatever that API call would be and just hardcoding it into our data set right here now believe it or not I'll actually show you this cool feature with prom player so we don't have to do it this way in fact what we can do is we can make a custom API endpoint and whenever we give it a custom URL then what's going to happen is it's going to take all this data and throw it into that URL and we can basically structure a custom API endpoint to set it up and respond just like we would with our production data so it sounds like that may be kind of a better method for testing right like we want our test to simulate the production environment as much as we can so why don't we go with this method instead of hardcoding everything well there are pros and cons to each for one if we were to use I keep closing this thing and popping it back open but if we were to use the actual API service then for one thing it's going to be slower because instead of just reading the data from here we have to actually make some API call and get that data back another thing is that it's not going to be consistent so for example if our API ever changes and we say hey give me the transcript for this video one day and the next day we make a call and get different data back then our data set or our test is going to be changing so then the prompt template that we're testing it's not going to be giving consistent results because you're pretty much at the whim of whatever the API is returning and the last one is just error prone because if this service is ever down that means means that we can't evaluate our prompt template and we pretty much uh can't prove it anymore so of course those are the downsides of using this however it does have some benefits as well first of all if you're using the same response data for example if you have a test where you're testing on this one specific video and you're using this exact same transcript every time well instead of having that data in this cell in this cell in this cell well it will help minimize your data set because you know you basically don't have to store this you're just making a call for it and the other thing that it helps with is maintenance so for example let's say that you transcribed this video and this was the wrong transcript let's say there's just um I don't know it gave you an inaccurate transcript and then you're using that transcript in a bunch of other cells right here well if you updated the API to fix the results and it changed to give you those correct results you either one have to update this location this location this location everywhere you have it versus if you were just making an API call you would then get those correct results back so there's a lot of different tradeoffs on how you evaluate a prompt template using rag data properly there's no right or wrong method just understand that there are tradeoffs between either one now the very last thing I'm going to do before I let you guys go for this video is I'm actually going to do this for myself because I'm pretty lazy so what I want to do is I want to add another column here to basically be the same thing as that score column as before however like I said I'm lazy and I don't feel like going through each of these every time and doing zero Z one zero I mean I got stuff to do so I wish there was a better method well I already have the answer right here so I I know what the correct answers are however the problem with that is I just can't do something like a a quality comparison because the llm May respond with something that doesn't quite match this exact answer but it's still correct for example in here the llm responded with the question who is the person in the image with the person in the image is Bucky Roberts he is yada yada for educational content now I also would have accepted the person in the image is Bucky Roberts also it could have just said Bucky Roberts it could phrase it in a bunch of different ways and we just need to know is this the correct answer even though it may not be an exact match to this so what can we do for that well what we can do is hop back in here and we can create a new prompt template in general and I will say that this is called um a uh answer to to booing and in the system system prompt what I'm going to say is um you are an AI um assessment tool your job is to judge whether or not an answer is correct and I will say that um your response should be one word only true or false and then after this what I'm going to do is I'm first going to give it the original question and let make sure I Chang this to a ging 2 template and then after this in addition to giving a the question I'm going to say that this is the this is the provided answer and I'll say provide an answer and then I'll have another one for actual answer and I actually just want to change the order of these and the reason that I'm going to change the order of these is just because in my report I'm going to have the question as one of the earliest columns and then the actual answer is like the middle one and the provider one is going to be last just for uh like organization purposes so actually let me take this and I'll actually throw it into the user message right here all right so the last thing I want to do is I just want to set these parameters so I don't have to adjust the prompt template or excuse me the engine settings in the report and now let me go ahead and create this template beautiful so now that I have this prompt template that we're going to be able to feed in a question the provided answer and the actual answer and get back a Boolean now what we can do is use this instead of me to grade these answers so let me pop this open in a new tab and now in my video specific questions evaluation I'm going to add another step and this is going to be the prompt template that we just created so prompt template and I'll just say um uh uh assessment or I'll say booing now let's do assessment okay and then for this it is I answer to Boolean just use the latest version and now the actual answer is going to come from A's llm response this is how a responds now the question is just this original question actually let me change this around I got a little confused okay so the provided answer is going to be I response and the actual answer is going to come from the data set yeah I got this right so this is the question this is the actual answer and the provided answer is going to come from a she has to figure that out on her own so that's going to be the llm response so now let me go ahead and run this step and then we can see if my prompt template can assess these answers so is this answer acceptable for this and already it says no and this is not correct so let's go ahead and actually do this um we can do a little prompt engineering to fix this so I'm going to go ahead and run this full batch and give us some time and let's inspect the results of this so the first thing I was going to do is answer all these questions to the best of her ability and then what she's going to do is she's going to try to assess is this answer an acceptable answer given that this is the real answer now the first one she actually got it wrong she said that even though she got the question right the person in the image is Bucky Roberts um she says that no this is not a suitable answer for this answer which is Bucky Roberts and not true same thing with this the answer we were looking for is Apples she said the name of the class from the video is Apples but then when she assessed her answer to see if it was right or not she said no that's not the right answer I don't know why that's so funny to me but there are a couple things right now that I'm noticing now the very first thing is that I response to these they're just a bit wordy like I'm just looking for Bucky Roberts I don't need all this extra fluff I don't need all these extra sentences like just give me the answer in the shortest way you know how another thing is that these look like they're just wrong um even though this is a little bit wordy I should still be able to figure out that this is the right answer so I'm actually going to make two adjustments here the first one is to this template and the other one is to this template so first let's try to cut down on A's wordiness so in here University template uh this is a video I'm going to edit this and I'm going to say answer in as few words as possible okay now I'm going to update this and even though this is updated I don't want to run the evaluation again because I want to make a change to that assessment prom template before so I'm just going to go ahead and save this without kicking off the other uh evaluation or test and now the other change I wanted to make was this right here so this looks like it structured all right the only other thing that I want to change right here is I want to upgrade this from 3.5 turbo and I'll use four basically just a smarter uh model and now I'm going to update this and now after I do then this entire evaluation is like I'm good so those were all the changes I want to make now after this just go ahead and run this evaluation again which were my video specific questions going to confirm that and when I do we can go to the latest version which now has gp4 enabled and we can see if I does any better so the first thing I'm curious about okay so this change is good instead of you know all the extra text it looks like these are a lot shorter answers and yes look at this not only is A's response getting better more accurate less fluff but also her ability to assess these answers is getting better as well and this is pretty cool because half of these were pretty easy she got the exact same answer but half of these are different than the answer like the ideal answer this one says the person is Bucky Roberts or the person in the image rather than just the name and this one has quotes around the words and still she said true so yeah a lot of um information there I think this tutorial was a little bit longer than anticipated but that is pretty much how you would evaluate a prompt template using rag data and also having a prompt template assessment to save you a lot of clicking and manual assessing as well so I don't know what we're going to be doing in the next video but um I mean I is getting smarter and yeah I'm pretty excited looking forward to the next video so I'll see you guys then