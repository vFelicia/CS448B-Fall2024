hi welcome to session four of AI 101 for teachers professional learning Series so far we have been focusing mostly on the benefits of AI which might be leaving some of you with some important questions like wait a minute I've heard that sometimes AI can make mistakes or even provide biased responses how do I ensure I'm using AI responsibly and thoughtfully what can I do to ensure I'm preparing my students to think critically about these new technologies these are all valid and important things to consider as you think about how you will approach AI in education let's dig into some of these topics hi I'm Danny I'm a former middle school and high school math computer science and engineering teacher I now work at code.org on our product team helping to develop the website that students and teachers use today we're here joined by Katrina to talk about AI we know that AI has been on many teachers minds and we're excited to dive into this topic today with Katrina could you introduce yourself hi I'm Katrina I am an elementary school special education teacher so could you tell us a little bit about how a relates to your work as an elementary school teacher AI is a really exciting tool but I am worried about how it relates to students and its use in the education setting what are some things you're excited about I think that AI can be really useful to help me when writing reports or when generating test questions or assignments for the students to work on um there's a lot of potential there so you said you had some concerns what are those concerns well I am worried about student priv privacy and how their data could be used by different AI tools and also about how AI could be used in the classroom and whether or not um the information that it provides would be accurate for students and also um how students might use it to help them with things like essay writing or homework are there ways you think you can leverage AI as a special education teacher um I do think that it could be really useful when helping to do things like write IEP goals um but with that I have concerns as well because IEPs are obviously very specific to each student and I wouldn't want to provide any personally identifying information to the AI tools I do think it can be really helpful with differentiation um I teach students who are at all different levels so for instance if I'm reviewing aition I can ask AI to help me write questions for my students who are at a lower level maybe add adding numbers between 1 and 10 but also my students who are more advanced in adding multidigit numbers Danny I was wondering if you could give me advice so if I'm using AI to help me um come up with a reading passage at differentiated levels for my students about for instance the Revolutionary War how can I make sure that the information that it gives me for my students to read is actually accurate you really are going to have to be the expert we already think you know we know that teachers are the experts and you're going to have to rely on your knowledge to check what the AI tool is giving you to make sure that it is accurate so you can't just take what the I tool generates and hand it to students you're going to have to read it yourself and make sure that you believe what it's saying and maybe check other sources to make sure it matches what you find there as well Danny as somebody who works in educational technology and for a company that creates some of these AI tools what are your thoughts about the safety of using AI in a K12 classroom in terms of when we develop tools we work really hard to ensure their safety before they ever see a classroom so we're going to do a lot of rigorous testing to make sure that they're safe and they're producing factual information and they're reliable um that they're going to give the same result repeatedly and then we work hard to then pilot in a classroom make making sure that we do it with a small set so we can see what is happening and be really HandsOn we also always make sure that when we're developing tools that teachers have access to deciding what they want in their classroom and how it's used and then being able to monitor what is happening what are your thoughts on the future of AI where would you like to see it go if you could talk to you know creators of AI Technologies what would you want for your classroom well as a special education teacher I have a few students who are nonspeaking and they use AAC devices to help them communicate um and I'm curious about how those AAC devices could be integrated with AI to give those nonspeaking students or really any nonspeaking individual a way to communicate their thoughts the potential for AI to help Society is enormous it's something that is influencing a lot of very important decisions about real humans and their lives it could be used in education to be more of an equalizer between people it could be used in healthcare to develop new drugs it could be used in science to develop new technologies and like any technology its application will depend on how it is utilized and at the same time we need to think about the risks that are associated with doing that the consequences are huge hi everyone I hope you're all as excited as we are to dive back into the fascinating world of AI my name is is Michelle and I'm a former High School science and computer science teacher I now work as a member of the professional learning team at code.org today we're going to discuss how you can ensure a responsible approach to AI in education Educators and administrators have valid concerns when considering whether or not AI Technologies are right for their classrooms some top concerns include the following data privacy how can my students and I use AI Tools in a way that protects our data and how do I know when a tool tool is safe enough to use with my students misinformation and AI fiction how can my students and I use AI effectively when it can be wrong algorithmic bias how can my students and I recognize AI bias and how can I teach my students to think critically about that bias throughout this video we will address each of these concerns and equip you with clear effective strategies you can use to mitigate risks for your students and for yourself it is really important that technologists kind of have this Mantra of ensuring that their Innovation is ethical and is beneficial to everyone in society machine learning requires a lot of true information to be provided to it in order to ultimately uh deliver a utility this information might be very sensitive to us it might be health related it might be Financial it might be very very personal we need to put checks and controls in place like with any technology that it's utilized to benefit us and that it is done with accordance to the law there's lot of gain from involving yourself in really understanding the details of how this technology Works given that it's so impactful given that it is something that will influence inuence your life and the life of everyone that you love AI systems process vast amounts of personal data consider a chess playing AI as an example rather than programming a set of steps that the computer should follow such as always start with the move Knight to F3 the computer analyzes millions of chess games to create its own patterns or algorithm that allow it to make the best moves in novel situations a large data set of millions of games is necessary for the computer to develop its own style of play now instead of Chess let's consider another example a video recommender algorithm how does an app recommend videos it constantly analyzes each person's interactions with the app monitoring how long you watch a video whether you comment on it or like it and More in order to learn your preferences the algorithm must process your data plus the data of everyone else using the app people tend to have different personal thresholds for what data they are and aren't comfortable sharing with AI systems individuals should have the autonomy to decide whether their data is collected for use in AI systems and companies should provide users with clear information about their data collection practices companies recognize the financial value of user data and often view it as an asset that can be monetized furthermore data protection regulations generally lag behind industry advancements for these reasons staying informed about how individual AI tools are using your data and advocating for privacy protect for your students are crucially important the introduction of AI tools and educational institutions presents nuanced challenges especially concerning data privacy often students find themselves with limited agency in choosing whether or not to use AI or edtech tools as decisions typically fall under institutional mandates emerging data intensive AI platforms may not always meet regulatory standards such as the US's family educational rights and Privacy Act furpa and children's online privacy protection act Capa or other International privacy protections making their integration into educational settings challenging especially for tools targeting users younger than 18 parental consent becomes imperative unless these platforms were explicitly designed for educational use while it's Paramount for teachers to instill a thorough understanding of data privacy it's equally important to ensure that students don't feel overwhelmed or powerless though the broader control of personal data might seem elusive students should be equipped with the knowledge to make informed decisions about the data they can control promoting both awareness and empowerment the learns to take a text description and generate completely new images nobody has ever seen before or to alter existing images the same approach can also be used for videos now this raises multiple questions is the AI really learning creativity and Imagination on the one hand if you look at art and video created by AI it can be beautiful original and amazing on the other hand the AI only learns this by doing math at the pixel level while studying creations made by people is that really creativity another question is the issue of copyright I learns by studying the creations of others and the original creators may want to say in this of course when humans learn to create they also study creations made by others so the legal questions here are not simple we're still in the very early days of teaching AI how to create new types of media today AI can generate photos and videos soon you would also learn to create music my heart on with and 3D worlds this will have an incredible impact on all aspects of society especially in entertainment not just movies and music but also games think about all the information you've posted online over the years like family photos blog posts classroom websites and product reviews generative AI tools those that create new text code and images are typically trained on human Works possibly including some of the content you've contributed to the internet many AI tools also use the content users create within their platforms to enhance their own capabilities for example at present chat gbt and Bard use your conversations as training data by default we mentioned before that people have different personal boundaries around data privacy that holds true when it comes to generative AI too however many communities whose livelihoods depend on generating content like artists programmers and authors have objected to the use of their work to train AI tools since our students are artists programmers and authors too it's important to develop their skills as informed users of these AI tools so they can craft their own stance on data ownership AI tools Built For Education often have specific guardrails in place to promote safe student interactions and responsible stewardship of student data for example an AI chat bot Built For Education might limit the number of messages per day that a student can sent make a student's chat history visible to Educators or parents or proactively monitor a student's messages for inappropriate content an AI used in education should comply with furpa Capa and other Regional regulations when evaluating an AI tool to see if it is appropriate for use in your school environment first check to see if it was developed for use in education which can be a shorthand for understanding its safety standards look for first party help articles or guides available about the tool that explains safety and privacy features scan its privacy policy for passages that mention School use furpa and Capa you can also search Common Sense media's privacy program for a thorough privacy review of many online tools including chat GPT if you want to stress test an AI tool yourself get in the mindset of a mischievous teenager and see if you can break it how is this mitigated we can't ensure that all technologies that your students use have been optimize to protect their privacy here are some concrete strategies for keeping data private seek local guidance regulations around AI tools are constantly changing ask administrators or District leaders for guidance on AI tools such as guidelines or a white list search for any state and local laws that may affect the use of AI Tools in education scan the privacy policy don't be intimidated by all the legal language take a glance through with some help from control r f search for school use furpa CA and look for the age restrictions or required parental permissions check to see what types of data are collected and whether the data is sold to third parties if the policy doesn't address School use furpa or COA or if student data is sold you may want to consult your school's it department for more help adjust privacy settings most tools will offer some privacy setting such as disabling tracking or data storage before using a tool explore these options and use them to enhance privacy share these options with your students Empower your students it's crucial that students have a genuine Choice when using AI tools inform them about what the tools do and the Privacy implications show them a summary of the privacy policy and let them decide how they want to use the tool don't share personally identifying information a simple rule of thumb for sharing information is the anonymous Forum test if students wouldn't feel comfortable sharing something on an anonymous online platform such as Reddit or ciora they shouldn't share it with AI chat Bots like chat TBT don't forget that files may also contain personally identifying information and should be reviewed before uploading by keeping these points in mind we can help students navigate the world of AI while ensuring their privacy is respected let's take a quick look at how you might evaluate a tool like K Migo First let's check the Con Academy privacy policy right off the B there's a section about school use that mentions furpa and Capa compliance which helps us understand that the tool is intended for use in an educational environment it has sections that explicitly mention the use of the service for those under 18 and under 13 second we'll look for first party help articles that explain the tool in a bit more detail we can see in this article that students are informed about the moderation of the tool that interaction is limited and that there are other safeguards in place it's also clear from a glance at the help articles that parents can turn off access to kigo and that some of the articles are directed at Learners let's conduct the same research for chat GPT first we'll scan the privacy policy for open AI you can see that the policy doesn't mention furpa Capa or School use so we can tell that the tool wasn't intended for use in an educational environment if we search for age restrictions the policy tells us that chat PT isn't designed for users under 13 and that users under 18 must have parental consent scanning the help articles for chat GPT there are clearly data control settings that we can turn on or off and ways to report harmful content however there aren't any articles directed at Learners or that mention parental or teacher controls now it's time for you to practice pause the video and examine the privacy policy of a site you use regularly with your students a large language model can produce unbelievable results that seem like magic but because it's not actually magic it can often get things wrong and when you get things wrong people ask does a large language model have actual intelligence discussions about AI often spark philosophical debates about the meaning of intelligence some argue that a neuron Network producing words using probabilities doesn't have real intelligence but what isn't under debate is that large language models produce amazing results with applications in many fields this technology is already being used to create apps and websites help produce movies and video games and even discover new drugs the rapid acceleration of AI will have enormous impacts on society and it's important for everybody to understand this technology misinformation is a problem and pmic to the internet not something created by AI just as you might have taught students to be skeptical of content on Wikipedia you'll need to help students understand that the information produced by AI isn't always correct healthy skepticism is a great mindset for your students to practice as they begin to encounter more and more information on the internet at home in school and in the workforce sometimes AI systems can confidently produce text that sounds very real but is actually not true while the type of information is often called the h ation we'll use the more inclusive term AI fiction in this video AI fictions happen because large language models were designed to mimic human language not be 100% factual they're language models not knowledge models while language does contain a lot of knowledge it can also contain incorrect information AI systems also don't have a true understanding of what they're saying like humans do so they often can't tell when they're making a mistake which means that these AI system systems communicate as though they're certain about their responses even if they're wrong why is this important well some people might use these madeup stories to spread false information on purpose others might come across these AI fictions by accident and think they're true this can be a problem especially now because with AI fake news stories and images can be created much faster and in larger amounts than before in the online world there's always been misinformation but with AI this information is now easier and faster to create AI fictions have already found their way into legal briefs and scientific papers and since AI mixes both right and wrong information it's important to double check anything you read or hear especially if it sounds a bit off or unbelievable students while eager to use AI tools might not be equipped to differentiate between factual information and AI generated fictions the introduction of AI in schools necessitates a recommitment to to bolstering digital literacy skills ensuring students critically evaluate the authenticity and relevance of the information they consume here are some concrete strategies for combating misinformation exercise healthy skepticism be cautious when asking large language models for factual information especially if that information is obscure reprompt is necessary if something sounds off when prompting a large language model prompt it again to reevaluate for example by asking are you sure about blank emphasize digital literacy practice digital literacy skills with your students like corroborating information checking for bias in the author's Viewpoint and evaluating The credibility of online sources get creative with assignments give students assignments that ask them to debunk large language models outputs or Define the types of prompts that most often lead to AI fictions use a variety of tools use search engines and large language models to complement each other's strengths and weaknesses search engines can help with factchecking and finding citable sources while AI tools can help summarize and brainstorm so what we're going to do now is we're going to try out a common prompt type that can lead to misinformation this one is asking for quotes from a book to back up a claim in general asking large language models to site sources can be problematic so Katrina what type of books do you like to read I like to read all types of books but my favorite book is Pride and Prejudice awesome so what we're going to do is we're going to prompt our large language model we're going to ask it to list five reasons why Elizabeth Darcy liked Mr Wickham we're going to ask the model to use quotes from the book to back up your reasons we'll see what happens so what it's telling us is seems like you're referring to Pride and Prejudice by Jane Austin that's correct right that is correct U then it says however there isn't any clear evidence in the book that Elizabeth Darcy formerly Elizabeth Bennett like Mr Wickham is that true well in the end of the book she does not like Mr Wickham but there is a substantial portion of the book where she is um quite interested in him oh so it's not accurate here so let's try repr prompting and see if we can get chat gbt to correct itself okay so ask it but doesn't she initially grow to like Mr Wickham before she was aware about how he treated Mr Darcy she believes at first that Darcy treated him him poorly so it corrects itself so it says that it apologizes for the confusion that we're correct um Elizabeth Bennett initially had a favorable impression of Mr Wickham before learning the truth of his character and his actions and then it gives some quotes and you know it lists reasons here Charming manner friendly nature it gives the chapters this looks great to me what do you think as The Pride and Prejudice expert well here for quote number one that is a quote from the book about Mr Wickam and Elizabeth but it says it's from chapter 3 and actually it's from chapter 18 oh so it just has the chapter number wrong yeah but it is a correct quote and then quote number two is actually a quote that Mr Darcy says about Mr Wickham when he explains to Elizabeth um Mr Wickham's faults now so that doesn't really support our point at all here does it no that would not support Elizabeth's interest in Mr Wickham and then if we look at number four we see this is actually a quote from after Elizabeth learns of Mr Wickham's deceit and um the shame she feels for herself so this is not a quote that supports Elizabeth's liking of Mr Wickham that's some great examples of how chat GPT was able to produce an output that looked legitimate but actually had a lot of fictions now it's your turn to try pause the video open chat GPT or another large language model of your choice prop the large language model on a subject you know well fact check the output and see if you can find your own examples of AI fiction I think ethics becomes more important as something becomes more impactful and as AI becomes more impactful the more that we have to think about the ethics of AI artificial intelligence is ultimately built by human beings human beings can have very diverse motives for why they make something unfortunately there's a huge difference between those that are involved in creating these systems and those that are impacted by these systems so what we really want to think about long term is where is the society we want to get to and how is technology going to help enable that if we think about that in the long term we have a better chance of getting there than if we just try to develop the technology and then see what happens AI systems can sometimes produce unfair or discriminatory results this often arises from biases in the data that they're trained on or the way their algorithms are designed this phenomenon is known as algorithmic bias in artificial intelligence it represents the consistent and repeatable errors made by a computer system leading to unjust outcomes like favoring one group over another however the term bias isn't limited to distinctions like race gender or age broadly speaking bias is a more general term that reflects situations where an AI system consistently airs in a particular direction causing skewed conclusions these biases can emerge due to various factors such as design processes preexisting prejudices embedded in the training data or even the interpretation of the results by those utilizing the AI for instance if a facial recognition system is trained predominantly on images of people from One ethnic group it may perform poorly on people from other ethnic groups moreover when algorithms trained on bias data are employed in real world applications they can perpetually uate inequities and create adverse outcomes understanding this concept is crucial as AI continues to play an increasingly integral role in various aspects of Our Lives from job applications to credit approvals from healthc care Diagnostics to personalized education these systems if left unchecked can inadvertently deepen existing disparities and hinder the objective of a just Society let's take a look at some prominent examples of algorithmic bias as a result of a facial recognition positive a black woman was wrongfully accused of a carjacking in Detroit facial recognition systems have performed poorly on the faces of people of color and even seemingly small error rates can still have a negative impact on a substantial number of individuals chat GPT has been found to exhibit a leftleaning bias likely in part because of the demographics of the people who trained the system to construct helpful prompts programs used to detect AI are more likely to flag writing from nonnative English speakers as AI generated Common Sense Media recently found that in YouTube videos watched by kids eight and younger 62% feature no black indigenous or people of color characters at all while in another 10% of videos black indigenous or people of color characters were portrayed in Shallow ways while it's impossible to understand the extent to which the AI recommendation system was responsible for this outcome we do know it's responsible for 70% of all watch time on YouTube pause the video here and search for your own example of algorithmic bias in AI supported Technologies the problem is that with real world data there's often information in there that you didn't intend to be in there but is captured because of the bias in the data collection process so if you're building an AI to determine who gets a home loan or who should be charged with a crime it could definitely Bubble Up the racial biases that humans and our current Society already does a lot of what it means to build less harmful AI is really uh systems that are including the perspectives of those that are most vulnerable or most marginalized most likely to be hurt by the deployment of that system in many ways I've worried that the people who are particularly vulnerable to eii are the people who are already underprivileged in many respects most people in the world world just have ai applied to them rather than playing an active role in guiding what AI gets applied to everybody you know has a computer in their pocket that's young people old people rich people poor people to me that's actually quite exciting from a democratization of Technology perspective means that AI powerful as it is could theoretically be in everybody's Pockets benefiting everybody We should strive to make sure that things that provide value for society can be reached to anybody how do we give a greater voice to the people who are being impacted by AI to in turn be able to turn around and impact how AI is used for them every time when you looking at a new problem you have an opportunity to change the world sometimes we succeed sometimes we don't but we always try it's really critically important that we have as many diverse perspectives as possible influencing the development of AI we need the participation of more women more people of color to provide a different perspective and a different lens on which problems matter and how we should approach these problems now that we've taken a look at where algorithmic bias can emerge in real world context let's examine some guiding principles for teach teaching about bias in your classroom AI technology is nearly everywhere remember the old phrase there's an app for that today it's more like there's an AI for that artificial intelligence is an umbrella term encompassing machine learning and deep learning these techniques are applied in almost every sector you can think of do stay true to your passion and subject area find examples of both potentially harmful Ai and helpful AI in that space don't assume AI can do everything even if it's widespread the errors and biases are widespread too assume someone in the room is a data point depending on the age level various case studies of AI bias may come up these can include racial discrimination legal inequity housing insecurity gender discrimination social media manipulation misinformation education ACCESS food insecurity and so on teach us if you are speaking directly to someone affected by the issue as it may even be the case do speak with compassion and a Solutions oriented approach don't make jokes Tolen the mood don't treat the data like it's objective or detached don't treat outliers as useless data points don't use shock value data sources can be biased the problems we try to solve and the data we use to solve them can be narrowminded for example trying to extrapolate instructional recommendations from one school's data likely won't translate using health costs as a proxim for how sick someone is discounts all the people who don't go to the doctor even though they are sick because they can't afford it data is not always ethically sourced and the right questions aren't always asked sometimes the problem itself is one that we shouldn't be trying to solve like how to predict someone's gender race criminal potential or sexuality from a photo do consider where the data comes from and how it was collected do look for whether it was ethically sourced do look for the year it was collected and the context of the time don't assume you always need more data you might need different data don't assume all problems are worth solving in the first place show Solutions no one wants to feel like their future is doomed you don't I don't your students don't we Thrive off hope for each case of algorithmic bias there are some solutions that have already worked and an opportunity to brainstorm possible solutions for the future do provide links to organ organizations working to solve issues of bias and algorithmic harm do be honest that mistakes will happen and that it takes bravery and accountability to tackle them don't assume that all solutions are technical fixes or magic aha algorithms Solutions are often cultural or policy driven don't imply all the problems have already been fixed and won't be represented in another similar context let's dive deeper return to the example of algorithmic bias that you explored earlier how how might those principles impact how you would approach leading a discussion about this issue with your students this session on ensuring a responsible approach to AI has been Illuminating we examine critical issues like privacy concerns misinformation and algorithmic bias underscoring the pressing challenges that come with the rapid advancements in AI technology however it's essential to remember that technology at its core is a tool the responsibility is on us its users and developers to guide ai's Direction by fostering open dialogues like the one we had today and working collaboratively we can ensure that AI serves Humanity ethically effectively and responsibly the conversation does not end here we challenge you to go back to your school and continue these conversations with your colleagues perhaps you might even establish data privacy policies with your school level teams or share successes and challenges related to discussing algorithmic bias with your students the future is bright and with our Collective Comm commitment we can harness ai's potential while safeguarding our shared values and principles AI certainly does have its benefits and also its pitfalls we hope that the information presented in this session will help you to navigate this new world with confidence the next step in our journey is to consider how you might bring AI into your classroom join us in session five where we focus on teaching about AI evaluating and utilizing ing AI Educational Tools and leveraging AI for student assessment this session will be a blend of theory practical examples and resources all intended to help you navigate the Ever Changing landscape of AI and education visit the ai101 for teers website at code.org ai101 to sign up for Early Access and to explore additional resources from code.org ETS IST and Con Academy thanks for joining us