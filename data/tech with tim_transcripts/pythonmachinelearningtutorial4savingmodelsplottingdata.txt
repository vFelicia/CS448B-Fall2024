00:00 - hey guys and welcome to the fourth video
00:02 - in my machine learning with Python
00:05 - series and in today's video we are gonna
00:07 - be going over saving our models and how
00:10 - we can kind of plot data on a grid and
00:11 - actually visualize some of the stuff
00:13 - that we're doing so essentially what
00:14 - we're gonna do today is we're going to
00:15 - use the pickle knowledgeable that comes
00:17 - built into Python to save our models
00:20 - we're going to be creating multiple
00:21 - models and trying to save the best
00:23 - possible one to use in the future and
00:25 - then we're going to be plotting things
00:27 - like on a graph that we can kind of look
00:28 - at so yeah so let's go ahead and get
00:31 - started so the first thing we actually
00:32 - need to do is we need to import another
00:34 - module or install another module so you
00:36 - can see here I've got my tensor
00:38 - environment already loaded up and
00:39 - activated so again reminder you can
00:41 - activate and then whatever the name of
00:43 - your environment is and just hit enter
00:44 - I'm just doing this again in the little
00:46 - terminal in pycharm now what we need to
00:48 - install is we're just guys I hit install
00:51 - mat plot lib ok now this is just a
00:54 - library for doing like basic graphs and
00:57 - grids and stuff um so do that I already
00:59 - have it installed so I'm not gonna hit
01:00 - enter I'll take a second and I think
01:02 - that's actually the only module we need
01:03 - for today and in the future we probably
01:06 - won't have to install any more modules
01:08 - because I think we have most of them
01:09 - already now okay so we're gonna import
01:11 - matplotlib now so a matplotlib dot pi
01:15 - plot as pi plot that one is always a
01:20 - long import statement ok so import map
01:23 - plot lived up hi plot as pi plot and
01:25 - then we're going to import what he call
01:28 - it pickle and this should actually
01:30 - already be installed with your python if
01:31 - it's not for some reason to leave a
01:33 - comment down below or go to tech with
01:35 - him net and leave a thing on the forum
01:36 - again if you guys want to follow along
01:38 - with all the code here it's gonna be up
01:39 - on tech with tim net so go on there'll
01:41 - be a link in the description where you
01:43 - can see the text-based tutorial and all
01:44 - the code in the video and all that ok
01:46 - now we're actually going to import
01:48 - something from a plot lid so from matt
01:50 - plot lib import style like that and this
01:55 - is just cuz we're gonna change the style
01:56 - of our grid um now what should we do
01:59 - first I think what we're gonna do first
02:00 - is actually save our model and then
02:02 - it'll go into drawing some of this stuff
02:03 - ok so why would we want to save our
02:06 - model well you guys may have noticed
02:08 - already that in our case our model
02:10 - trains really
02:12 - like under a second is how long it takes
02:14 - to train so doesn't really make sense to
02:15 - save it in our instance because well
02:17 - it's so quick that it's training but on
02:20 - a lot of other models that are training
02:22 - off of like hundreds of thousands of
02:24 - pieces of data you don't want to have to
02:25 - retrain your model every time you're
02:27 - gonna use it and if you can find a model
02:30 - that has like a 90 something percent
02:31 - accuracy or like a very high accuracy
02:33 - you probably want to save that model as
02:35 - opposed to risking it in because you can
02:38 - see our model fluctuates between like
02:39 - eighty and ninety percent so essentially
02:41 - we'd want to save the highest-scoring
02:43 - model to use that on our future data
02:46 - sets right so the way that we can do
02:48 - this is really easy and it's using
02:50 - pickle so what we're gonna do is after
02:52 - we score and we fit in the model we can
02:54 - actually just literally just pickle it
02:56 - so we're gonna do is gonna say with open
02:59 - and in here we're just gonna name this
03:01 - whatever we want
03:01 - I'm gonna just name this student model
03:04 - okay dot pickle and then we're gonna
03:08 - open this in WB mode okay and this just
03:11 - who's gonna write the file for us
03:13 - essentially if it doesn't already exist
03:14 - and we're gonna open this as f now this
03:17 - is really easy and all you have to do to
03:18 - actually save this is you do pickle dump
03:21 - and then what you're gonna do is you're
03:23 - gonna put what we're dumping in this
03:24 - case linear which is our model and then
03:26 - into the file F okay so pickle dump
03:30 - linear F so this is essentially gonna
03:32 - save a pickle file for us in our
03:34 - directory and then we can open that and
03:36 - use that don't ask me how pickle works
03:39 - cuz I honestly can't tell you but all I
03:40 - know is it saves the model for us and
03:42 - yeah it works pretty well so now what
03:44 - we're gonna do is we need to read in our
03:46 - pickle right so read in our pickle file
03:49 - so to do this once we've created this
03:52 - file obviously which is gonna happen
03:53 - here we're just gonna say pickle and
03:56 - it'd probably be good if I spelled
03:57 - pickle right so pickle in you can name
03:59 - this whatever you want equals pickle dot
04:03 - load I believe yes the load and then
04:06 - we're just gonna take this so student
04:08 - model dot pickle and throw that in there
04:11 - okay and I think that might be it or no
04:16 - I think I actually am messing this up I
04:18 - think what we have to do is we have to
04:19 - open sorry and then let's do this
04:22 - student model dot pickle
04:24 - and then we're gonna open that in our B
04:28 - mode okay yes that looks correct let me
04:30 - just double check here and yes that is
04:33 - sorry that is how you do it now what we
04:35 - have to do is we can load this pickle
04:37 - into our linear model okay so we call it
04:39 - linear so we're going to say linear is
04:41 - equal to pickle dot load and then pickle
04:45 - again like that okay so now this is
04:47 - going to load our model into the
04:50 - variable called linear okay so what I'm
04:52 - gonna do now is I'm just gonna run this
04:54 - to generate the pickle file and then I'm
04:56 - actually gonna just delete all this and
04:57 - show you that this is actually working
04:59 - just by loading in the file and we don't
05:01 - we're not retraining every time okay so
05:03 - let's run this one and let it go through
05:07 - give it a second okay
05:09 - and now if we go here you can see we
05:12 - have a student model dot pickle file
05:14 - over here all right
05:15 - so now what I'm going to do is I'm just
05:16 - gonna comment out from here so one two
05:20 - three and we will go to one two three
05:23 - there so now all we're doing is we're
05:25 - just loading in our pickle you can see
05:27 - we're skipping the whole training
05:28 - process and the saving of the pickle and
05:30 - we'll just see if this works now okay so
05:33 - run this and you can see that we're
05:35 - getting no errors and everything is
05:37 - working just fine okay so yeah that is
05:40 - essentially how that works okay so now
05:43 - that we've saved our model I want to
05:45 - show you how we can save like a better
05:48 - version of our model so essentially what
05:50 - I want to do is I want to continue to
05:52 - keep what do you call it trying to save
05:55 - a model until we get a certain score so
05:58 - until we get like above 90 or above 95
06:00 - or something like that okay so the way
06:02 - that we can do this is really easy we're
06:04 - just gonna use a for loop or we could
06:06 - use a while loop actually but um what
06:08 - I'm gonna do is we need this extra X
06:10 - test okay so let's just do this I'm
06:12 - gonna type it out and then we'll kind of
06:14 - talk about what's happening so let's say
06:15 - for underscore cuz we don't actually
06:16 - care about this variable in range and
06:19 - then type whatever range you want I'm
06:22 - just gonna type like 30 and I'm gonna
06:24 - set a variable best up here and this is
06:26 - just gonna keep track of the best score
06:27 - we've gone so far okay and let's do that
06:31 - okay now what I'm gonna say is going to
06:33 - say if
06:34 - ACC which is our accuracy okay is
06:37 - greater than our current best score what
06:40 - we're gonna do is we're going to write
06:42 - to the file about new model that we've
06:44 - just trained okay because we did the
06:45 - linear model and then we fit it right
06:46 - and we're gonna set our best equal to
06:49 - ACC so now essentially we're only gonna
06:51 - save a new model if this current score
06:54 - for that model is better than any
06:56 - previous one that we've seen and we're
06:57 - gonna do this 30 times now you guys
07:00 - could technically do this like 10000
07:02 - times and it probably wouldn't take that
07:03 - long but for the purpose of the tutorial
07:05 - I'm just gonna do it 30 times if you
07:07 - guys can find a model that gets like 95%
07:09 - and you like messed with all these and
07:10 - stuff just let me know because that's I
07:12 - don't know that's kind of cool all right
07:13 - so we'll do that and what I'm gonna do
07:17 - is we'll just say we'll just print out
07:18 - the accuracy each time just so we get
07:20 - some kind of output so we can see what
07:21 - it looks like essentially all right and
07:23 - what we're also gonna do is I'm gonna
07:25 - take this and put it up here and I'll
07:27 - talk about why I'm doing this in just
07:29 - one sec okay so let's run the file and
07:31 - let's see what we get okay so you can
07:33 - see that happened like almost instantly
07:35 - and we can run through we can see here
07:37 - our highest accuracy was probably 95
07:39 - unless there was a higher one here so
07:41 - that would mean the model now that we're
07:43 - training off of would be that 95
07:45 - accuracy model okay so what we can do
07:49 - now is we actually get rid of this for
07:51 - loop just by simply commenting it out so
07:53 - we're not gonna be training any more
07:55 - models now unless we wanted to keep
07:56 - going and what we'll do here is we'll
07:58 - just load in the model that we just
08:00 - created and use that now the reason that
08:02 - I've redefined this up here is for this
08:06 - exact purpose so when we stopped like
08:08 - retraining the model then we still have
08:12 - this extra annexed sy train Y test
08:14 - because we do some stuff with that down
08:15 - here right and essentially you might be
08:17 - asking why are we getting different
08:19 - scores each time we run this model well
08:21 - that's because every time we do this
08:23 - like this test size equals 0.1 we're
08:25 - getting different training data right so
08:27 - you would think if we have the same
08:28 - training data the model would be the
08:30 - same every time but essentially since
08:32 - we're splitting this and 90% is going to
08:33 - one and 10% is going to the other it
08:35 - just randomly selects them so that our
08:37 - model is gonna be different each time
08:39 - because we're training off of different
08:41 - data right okay so now we have that this
08:44 - should be working but I've already ran
08:46 - this enough times you guys already know
08:47 - what this looks like so
08:48 - let's actually get into plottings things
08:50 - on a grid so we can see what they look
08:52 - like so we're gonna use matplotlib to do
08:54 - this and the first thing we're gonna do
08:56 - is I'm just gonna cut this in because
08:57 - it's kind of a weird name and I was you
08:59 - know to spell it but we're just gonna do
09:01 - style use and then ggplot okay
09:03 - essentially this is just gonna make our
09:05 - grid look like half-decent okay in
09:08 - matplotlib and then what we're gonna do
09:10 - is we're going to plot a few pieces of
09:12 - information so to plot our information
09:14 - what we're going to start off by doing
09:15 - is we're just gonna set up a scatter
09:17 - plot now we could do like a line graph
09:19 - Kanna or like a connected graph but
09:22 - there's a lot of points and they end up
09:23 - getting that kind of messy together and
09:24 - they don't connect ya proper way I tried
09:26 - this earlier so what we're gonna do is
09:28 - really use a scatter plot so essentially
09:29 - to do this we're gonna do pipe lot dot
09:32 - scatter and then we need to give an x
09:35 - and a y value so for our x value what
09:37 - we're actually gonna do here is a data
09:38 - and then what we're going to do for this
09:41 - is I'm gonna set a variable and I'm
09:42 - gonna say P equals and in this case I'm
09:44 - gonna do G 1 now P this is gonna be one
09:47 - of your attributes okay so you can pick
09:48 - G 1 G 2 study time failures absences so
09:51 - one of the features pretty well and then
09:54 - our Y value is always going to be the
09:56 - label which is going to be G 3 so we're
09:58 - in new data and then and here were just
10:01 - gonna type P so it's more like dynamic
10:02 - and we can just change it here and then
10:04 - what we're gonna do is read your data
10:05 - and what do you call it G 3 okay now
10:09 - what we're gonna do is we're just gonna
10:10 - set up some labels for our axes so we
10:13 - know what is once we escape pipe lot dot
10:15 - X label and our X label is gonna be P
10:18 - okay and then pipe lot dot Y label and
10:23 - this is gonna be what do you call it
10:25 - final grades and so G 3 I'm actually
10:27 - gonna say final grade because we already
10:29 - know what this represents now to show
10:31 - the grade will do pipe lot dot show and
10:34 - this is now essentially just gonna show
10:36 - us a grid so actually let's run this and
10:39 - see what we get so we still get the same
10:41 - output and now you can actually see what
10:43 - our data points look like so this is our
10:46 - grade ones like the first semester grade
10:48 - and this is the final grade and you can
10:50 - see the correlation between them now
10:53 - obviously we have some outliers out here
10:54 - but for a majority of them you can see
10:57 - like that a best foot line would look
10:58 - like something like that right like I
11:00 - was kind of demonstrating
11:01 - earlier in the last video now if we want
11:03 - to see the correlation between other
11:05 - features and our final grade what we
11:08 - only have to do is just change this so I
11:09 - could say put G 2 here instead and we
11:12 - should get something similar so we can
11:13 - see it just shifted over a little bit
11:15 - but it's similar data points now you
11:18 - guys may notice well you're like there's
11:19 - 600 students why is Emily showing this
11:21 - many points well essentially a lot of
11:23 - the points are overlapping so you can
11:24 - kind of see on some of them how they're
11:26 - not perfect circles but that's
11:28 - essentially why because the grade points
11:30 - were rounded to to be out of 20 so not
11:33 - like perfect percentages so that's why
11:35 - we're not seeing 600 points here we're
11:37 - only seeing like I don't know what like
11:38 - 100 or something so yeah so anyways we
11:41 - can also look at other ones with some
11:42 - other ones here study time failures
11:44 - absences and this is a good way to kind
11:46 - of see what correlation we're getting
11:48 - between different points right so for
11:50 - study time here you can see we're
11:53 - getting this very like linear line going
11:55 - up and I mean you guys can look here and
11:58 - see if study time really is affecting
12:00 - the final grade or not right so this is
12:02 - a good way to look at a graphical
12:04 - representation of all these things so
12:07 - failures so let's type this one in here
12:09 - and see what this looks like again very
12:11 - similar thing to what do you call it the
12:15 - study time sorry what am i saying here
12:18 - we can see that people with three
12:19 - failures typically had a lower grade
12:21 - than people with zero failures right so
12:24 - there is some kind of correlation here
12:26 - and that's what I'm trying to get at
12:27 - with this linear regression and then
12:28 - obviously for the last one we could do
12:30 - absences like this and see what this has
12:33 - to do with final grade if there's much
12:34 - correlation yep so again we see if
12:36 - someone had 78 absences typically their
12:39 - lower right so we can see kind of some
12:40 - correlation here right in how that works
12:43 - so anyways that is how you can kind of
12:46 - plot different points on a graph if
12:48 - you're using a scatterplot literally
12:49 - just pick like what two points from data
12:52 - you want to plot and then you can give
12:54 - an X label Y label show it and just use
12:56 - this style if you want it to look half
12:58 - decent so anyways that has been it for
13:00 - this video in the next video we're gonna
13:02 - be moving into classification algorithms
13:04 - so it's it's K nearest neighbors some of
13:06 - you may have heard of it before really
13:08 - interesting it's going to allow us to
13:09 - classify things into different kind of
13:11 - categories whereas this one was just
13:13 - giving us like some kind of
13:14 - linear prediction or number prediction
13:16 - so as always if you guys enjoyed the
13:18 - video please make sure you leave like
13:19 - all of the code is up on tech with Tim
13:21 - net and I will see you in the next video
13:23 - [Music]