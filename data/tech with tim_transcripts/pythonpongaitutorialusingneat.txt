00:02 - [Music]
00:08 - right now you are watching an ai that
00:10 - teaches itself how to play the game of
00:12 - pong now it's doing so using an
00:14 - algorithm called neat which stands for
00:15 - neural evolution of augmented topologies
00:18 - now in this video i'm going to explain
00:20 - to you how that algorithm works and then
00:22 - show you how to implement it into this
00:23 - game now although we will be focused on
00:26 - pong the techniques and strategies i
00:28 - show you in this video will work for
00:29 - pretty much any game so if you're
00:31 - interested in building ai and building
00:33 - ai for games in general then definitely
00:35 - watch through this video and i'm sure
00:36 - that you will learn a lot now i do want
00:38 - to mention that we're not going to code
00:40 - out pong from scratch like i did in kind
00:42 - of the last video of this where i coded
00:44 - a ai that played flappy bird i'll link
00:46 - that in the description by the way what
00:47 - i'm going to do is give you some
00:48 - starting code that has a functioning
00:50 - pong game and then we'll look at how we
00:52 - actually implement the neat algorithm
00:54 - and move the different paddles and well
00:56 - train in ai so with that said let's go
00:58 - ahead and get into the content after a
01:00 - quick word from our sponsor before we
01:02 - get started i need to thank appify for
01:04 - sponsoring this video appify lets you
01:07 - turn any website into an api and can
01:09 - automate anything you do manually in a
01:10 - web browser at scale with appify you can
01:13 - perform web scraping web automation web
01:16 - integration and more as a developer you
01:18 - can build your own custom scrapers using
01:20 - the appify sdk which is a fully featured
01:23 - nodejs library or you can use their
01:25 - python api client now if you do end up
01:27 - making a custom scraper or automation
01:30 - tool you can monetize your work by
01:31 - publishing your solution to the appify
01:33 - store and rent your software to earn
01:35 - passive income each month now if you
01:37 - don't want to write a scraper from
01:38 - scratch you can also fork the code of
01:40 - hundreds of pre-made tools in the appify
01:42 - store and modify it to your liking you
01:44 - can get started with appify today for
01:46 - free by clicking the link in the
01:48 - description and get a 5 us dollar credit
01:50 - every single month without even needing
01:52 - a credit card however if you do need to
01:54 - upgrade you can use the code tim20 for a
01:56 - 20 discount thanks again to appify for
01:59 - sponsoring this video now let's get into
02:01 - it so i want to get right into the code
02:03 - but i just need to mention that this
02:05 - video here is not designed for complete
02:06 - beginners so i'm going to assume that
02:08 - you have a solid understanding of python
02:11 - that you have some understanding of
02:12 - neural networks now if you don't don't
02:14 - worry i will leave some links in the
02:16 - description and some resources to help
02:17 - you so first of all if you don't
02:19 - understand python or maybe you're just
02:21 - kind of a beginner programmer you can
02:22 - check out my course it's called
02:24 - programmingexpert.io
02:25 - teaches you fundamental programming
02:27 - concepts mostly in python that'll be
02:29 - linked in the description you can also
02:31 - check out my neural networks for
02:32 - beginners tutorial series that's free
02:34 - that's on youtube if you just want to
02:36 - learn a little bit about neural networks
02:37 - before going through all of the content
02:39 - here with that said please do feel free
02:41 - to follow along you'll most likely be
02:43 - able to get a functioning ai you may
02:44 - just not understand everything that
02:46 - you're doing all right so now that we've
02:48 - talked about that i will also mention
02:49 - all the code for this video will be
02:51 - linked in the description as well as all
02:52 - of the documentation and research papers
02:54 - that i reference now i apologize for the
02:57 - long introduction let's actually get
02:59 - into the code and let's start creating
03:01 - this ai alright so on the right hand
03:02 - side of my screen here you can see that
03:04 - i actually have a finished version of
03:06 - this ai so the right hand side is the ai
03:08 - and i'm on the left hand side and this
03:10 - is going to be the goal for this video
03:11 - is to train the ai watch how it trains
03:13 - and kind of understand the genetic
03:15 - algorithm but then be able to actually
03:17 - play against the ai in a game of pong or
03:19 - to have two ais play against each other
03:21 - so that is the end goal just wanted to
03:23 - show that to you and now what we're
03:24 - going to do is just get into some setup
03:26 - steps here because as i mentioned we're
03:28 - not going to be coding out pong from
03:29 - scratch what we're going to do is start
03:31 - with an implementation of pong and then
03:34 - i'm going to show you how to implement
03:35 - the ai for it now if you do want to code
03:36 - pong from scratch i do have an entire
03:38 - tutorial on how to do that so i'll link
03:40 - that in the description but for now i
03:42 - want to get started with the starting
03:43 - code so what i'm actually going to do is
03:45 - just open up a new folder here in vs
03:46 - code and then walk through the setup
03:48 - steps with you so i've just opened up a
03:49 - new folder in vs code that's the editor
03:52 - i'm going to use for this video feel
03:53 - free to use whatever you want now i also
03:55 - have this github link open uh this will
03:57 - be in the description but this is what
03:59 - contains the starting code for this
04:01 - project and the implementation of pong
04:03 - that we'll use to train the ai with so
04:05 - go to this link again it's in the
04:06 - description and just copy it if you have
04:08 - git installed and if you don't have git
04:10 - installed then what you're going to want
04:12 - to do is just click on the download zip
04:14 - here by clicking on code so code
04:16 - download zip and then extract the zip
04:17 - folder and open up that zip folder but
04:20 - if you do have git then you can just
04:21 - copy the url and you can just clone the
04:23 - repository which is what i'm going to do
04:25 - so i'm going to go to vs code i have my
04:26 - terminal open and i'm just going to type
04:28 - in git clone and then paste the url here
04:31 - and that's going to give me all of those
04:32 - files inside of this directory now i'm
04:34 - just going to start walking you through
04:35 - how this code works then we'll build out
04:38 - kind of a basic implementation of the
04:40 - pong game so we can actually view it and
04:42 - kind of play the game ourselves then
04:44 - we'll start getting into writing the ai
04:46 - so the first thing that we do need to do
04:47 - is actually install a few modules so if
04:50 - you open up requirements.txt you'll see
04:52 - that we need neat python and pygame so
04:55 - if you know how to you can install just
04:57 - this txt file here or you can just go
04:59 - into your command prompt and type pip
05:01 - install and then the modules so the
05:03 - first one is going to be neat python and
05:06 - then after that it's going to be pi game
05:07 - now i already have them installed so
05:09 - you're going to see it says requirement
05:10 - already satisfied but you need both neat
05:12 - python and pygame for this video now for
05:15 - some reason that pip command didn't work
05:16 - for you try the pip3 command if that
05:19 - didn't work for you try python hyphen m
05:22 - pip and then install and then the two
05:24 - modules that are listed there and if
05:26 - that didn't work for you try python3 and
05:28 - if none of those work for you as always
05:29 - i'll put two videos on the screen that
05:31 - show you how to fix that command okay so
05:33 - now that we have that working let's just
05:35 - start having a look inside of this pong
05:37 - folder here because the pong folder it's
05:39 - actually a python package that contains
05:41 - everything you need to create pom so
05:44 - inside of here we have ball dot pi
05:46 - this simply implements the ball okay we
05:49 - have paddle this is one paddle we you
05:51 - know use two paddles in our pond game
05:53 - and we have game.pi which is the class
05:55 - that you're going to be interfacing with
05:57 - so inside of this file you can see that
05:58 - we have two main classes we have game
06:00 - information and we have game now the
06:03 - game information class is going to be
06:04 - returned to us or at least an instance
06:06 - of this class will be returned to us
06:08 - whenever we call the loop method of the
06:10 - game which i'll talk about in one second
06:11 - but it's just going to give us the game
06:13 - information right the number of hits the
06:14 - left paddle has the right paddle has
06:16 - then the score of both the left and the
06:18 - right paddle and the way the scoring
06:19 - works is that if you get the ball across
06:22 - the other player's side you get a point
06:23 - so if i'm the right paddle i hit it to
06:25 - the left side and they miss then the
06:26 - right paddle would get a point obviously
06:28 - we want to know all of this information
06:30 - so that we can understand which ai is
06:32 - performing better and we can train our
06:34 - ai using you know this data right that's
06:36 - what we want then we have the game class
06:38 - this is the main class that we're going
06:39 - to interface with you don't have to
06:41 - understand how the code inside of here
06:42 - works you just need to understand how
06:44 - you simulate the game using the class
06:46 - which i'm going to show you exactly how
06:48 - to do so the first thing we'll do here
06:50 - is initialize an instance
06:51 - and we do that by passing a window a
06:54 - window width and a window height okay
06:56 - pretty straightforward this is going to
06:57 - be a pi game window and then it will
06:59 - handle actually making the game for us
07:01 - we then have a bunch of private methods
07:03 - which we don't even have to look at
07:04 - because we're not going to interface
07:05 - with them
07:06 - and then we have draw now draw is going
07:09 - to actually draw the game for us you
07:10 - don't have to draw the game if you don't
07:11 - draw it you just won't see it so up to
07:13 - you if you want to draw it or not and
07:15 - you may not want to draw it because
07:16 - it'll be faster to actually train the ai
07:18 - if you're not constantly drawing
07:20 - then we have move paddle pretty easy but
07:22 - this allows us to move the left or the
07:24 - right paddle if we pass left true that
07:26 - means we're moving the left paddle if we
07:27 - pass left false we're moving the right
07:29 - paddle up true we're going to move
07:30 - whatever paddle up
07:32 - up false we're going to move it down
07:33 - right and then it will make sure that we
07:34 - actually can move it and it's going to
07:36 - return to us true if we were able to
07:38 - successfully move the paddle and false
07:40 - otherwise so if you're trying to move
07:41 - the paddle off the screen for example
07:43 - it's going to return false saying hey
07:45 - nope you cannot move there
07:46 - okay continuing
07:48 - we have loop this executes a single game
07:50 - loop so what you need to do here to
07:52 - actually run the game is create your own
07:54 - event loop which is just going to be a
07:56 - while loop essentially that's running
07:57 - that's constantly calling this method
07:59 - and then this method every frame is
08:02 - going to return to you the game info
08:04 - which is going to be the hits for the
08:05 - left and right paddle and then the score
08:07 - for the left and the right paddle so at
08:09 - every frame in the game you will know
08:10 - all of the information and you can do
08:12 - with it what you want inside of your
08:15 - main game loop you can decide when to
08:16 - end the game you can decide if you want
08:18 - to train another ai if you want to give
08:19 - an ai more points than another one we'll
08:21 - talk about that later on
08:23 - then we have reset pretty
08:24 - straightforward resets the entire game
08:26 - okay that's the game class that's really
08:28 - all the information you need to know and
08:30 - one last thing we have this init.pi file
08:32 - and this just says from.gameimportgame
08:35 - which means that when i import this pong
08:37 - i guess package is what we'll call it
08:39 - then i'm able to just directly import
08:41 - the game class and start working with it
08:43 - okay continuing we have config.txt this
08:46 - is what we're going to use for the
08:48 - configuration for our neat algorithm
08:50 - talk about all of this stuff when we
08:51 - actually implement neat don't worry
08:53 - about it too much right now
08:54 - then we have main.pi
08:56 - this is the finished code so if you just
08:58 - want to run the ai like you don't care
09:00 - to go through the tutorial then you can
09:01 - just run this file assuming you've
09:03 - installed the python and pi game
09:06 - but what i'm going to be doing in this
09:07 - video is essentially rewriting this file
09:09 - from scratch so we actually understand
09:10 - all of this stuff inside of here and
09:12 - then this header comment here is just
09:14 - one of the examples from neat that we
09:16 - kind of reference or that i've stolen
09:17 - some code from in this file right here
09:20 - okay
09:21 - so that is the gist of this starting
09:22 - code not overly complicated again you
09:25 - don't have to understand everything
09:26 - inside of here i just wanted to give you
09:28 - a brief explanation of what's going on
09:30 - so that when i start writing some code
09:31 - it makes a bit more sense so now let's
09:33 - actually implement a basic pong game so
09:36 - let's use that game class and just see
09:38 - how we can actually move the panel up
09:40 - and down and work with those different
09:41 - methods then we'll start writing out the
09:43 - ai so i'm going to create a file here
09:46 - and i'm going to call this
09:47 - tutorial.pi and inside of here i'm going
09:50 - to say imports i'm going to import pi
09:52 - game and then i'm going to say from and
09:54 - this is going to be pong
09:56 - import and then i'm going to import game
09:58 - now i can do this because pong which is
10:00 - the folder here is a package because it
10:02 - has the init.pi file inside of it that
10:04 - allows me to directly import anything
10:06 - that it imports and since it imports
10:08 - game i get game right here now make sure
10:11 - you put your tutorial.pi file inside of
10:13 - the neat python folder and that is not
10:16 - inside of the pong folder okay
10:18 - now that we have this we want to set up
10:20 - a pie game window the window is where
10:22 - we're going to draw all of this stuff
10:23 - and what we need to pass to the game
10:25 - class so i'm going to say window is
10:27 - equal to
10:29 - pygame.display.set underscore mode and
10:31 - then inside of here i have to pass a
10:33 - width and a height for the window so i'm
10:35 - just going to say width
10:36 - comma height is equal to and then we're
10:38 - going to go 700 500. now make sure that
10:41 - whatever the width and the height is
10:43 - that you set you're going to keep it the
10:44 - same when you're training the ai because
10:46 - if you change the width and the height
10:48 - it's going to affect how the ai performs
10:50 - so just make sure the width and the
10:51 - height you pick right now you're okay
10:53 - with and that you're not going to be
10:54 - changing in say the middle of training
10:56 - because if you were to change that's
10:57 - going to kind of mess everything up just
10:58 - wanted to note that so we'll pass width
11:01 - and height inside of here
11:02 - okay now that we have a window and a
11:04 - width and a height we can initialize the
11:06 - game class so i'm going to say game is
11:08 - equal to game and i'm going to pass my
11:10 - window my width and my height now you're
11:13 - about to see how easy it's going to be
11:14 - to run the game what i can do is create
11:16 - a while loop here so i can say while
11:18 - true for example although i really
11:20 - should just make a variable so i'll say
11:21 - run equals true
11:23 - and then while run and i'm going to say
11:25 - game
11:26 - dot loop
11:27 - and then game
11:29 - dot draw and then i'm going to say pi
11:31 - game dot display
11:33 - where is this here
11:34 - dot update
11:37 - and this will actually run the pi game
11:38 - for us that's literally all we need now
11:40 - i do need some way to quit this while
11:42 - loop i don't want an infinite loop so
11:43 - let's implement that but this is what i
11:45 - was talking about okay i'm going to say
11:46 - game.loop this is just going to
11:48 - constantly run the game loop for me
11:50 - inside of here i'm saying game.draw so
11:52 - it's going to draw it and then i'm
11:54 - updating my display just so i see
11:55 - everything if i don't update the display
11:56 - it's not actually going to show that
11:58 - it's being drawn however as i said we
12:00 - need some way to quit so what i'm going
12:01 - to do is say for
12:03 - event
12:04 - in pygame
12:06 - dot event dot get
12:08 - and i'm going to say if event dot type
12:11 - is equal to pi game dot quit so that
12:13 - means we hit the red x button on the pi
12:15 - game window which you'll see in a second
12:16 - then i just want to say run equals false
12:19 - and i'll just break out of the for loop
12:21 - like that
12:22 - okay and then down here we can just say
12:24 - pie game dot quit
12:26 - just make sure the window closes okay
12:28 - that's literally all we need to run the
12:29 - pong game and of course you need a way
12:30 - to move the paddles but let's run this
12:32 - right now and see if this is working
12:34 - okay so i'm going to bring up actually i
12:36 - don't need to bring up the console i can
12:37 - just click run
12:38 - and let's see
12:40 - and notice that we have the pawn game
12:42 - and there you go now it's going super
12:44 - fast right just because i haven't
12:46 - actually limited how fast the loop is
12:48 - running i'll show you how we can limit
12:49 - that but that's how you utilize the palm
12:51 - game and then if i want to move the
12:52 - paddle i would just need to use that
12:54 - paddle move method for now though i'll
12:56 - show you how we can limit the the speed
12:58 - so what we can do is create a clock
13:00 - let's say
13:01 - pygame.time.clock and then what i will
13:04 - do
13:05 - is go in here and say clock
13:07 - dot tick and you pass the maximum number
13:10 - of frames that you want to render per
13:12 - second so in this case i'm saying 60 so
13:14 - that means this while loop will be
13:15 - limited to running 60 times per second
13:18 - that's exactly what take does for us
13:19 - okay so you just put that inside the
13:21 - loop and it's gonna limit the time
13:23 - let's run this
13:24 - and then notice that now we get a ball
13:26 - moving at a reasonable speed okay and
13:28 - then it's drawing the score for us now a
13:30 - few other things that we can look at
13:31 - here when we draw
13:33 - we have the option to pass two things
13:36 - let's just go back here and i'll show
13:37 - you
13:38 - so looking at draw we have the option to
13:41 - pass draw score and draw hits so draw a
13:44 - score by default is true draw hits is
13:46 - false pretty straightforward what
13:47 - they're doing but if i don't want to
13:48 - draw the score i can pass this false and
13:50 - if i want to draw the number of hits i
13:52 - pass that is true so maybe we'll switch
13:53 - this and just say
13:55 - false and true and now rather than it
13:58 - showing us what the score is it's going
13:59 - to show us the combined number of hits
14:01 - between the two players okay so uh you
14:03 - know unfortunately they have not hit the
14:04 - ball yet now one small thing to note
14:06 - here as well is that you'll probably see
14:07 - that when the ball starts in the middle
14:09 - it's kind of random the direction that
14:11 - it's going that's intended so i have it
14:13 - so it's just randomly coming off at a
14:15 - slight angle so that the ai can't just
14:18 - say sit in the middle of the screen and
14:20 - constantly hit the ball it needs to
14:21 - actually learn to move towards the ball
14:23 - that's something i did in the game class
14:25 - that i want to mention anyways see the
14:26 - hits is being tracked up here that's all
14:28 - good we now pretty much understand how
14:30 - to use this class so last thing i'll do
14:32 - is show you how we can move the panel
14:34 - with the arrow keys and then we'll start
14:35 - building the ai
14:37 - so let's do the following let's say keys
14:40 - we want to get all the keys that the
14:42 - user has pressed we're going to say keys
14:43 - is equal to
14:45 - pygame.key.getunderscore and this is
14:46 - going to be pressed this will give us a
14:48 - list of all of the keys that the user
14:50 - has pressed so i can just check if
14:52 - they've pressed in this case let's go
14:53 - with the w and the s key and then i can
14:55 - move the panel accordingly so going to
14:57 - say if keys and i'm going to pass pie
15:00 - game dot k underscore and then the key i
15:02 - want to check is w
15:04 - so that's what i pass if you want to do
15:05 - a you would do a right if you want to do
15:08 - up it's actually k underscore up if you
15:10 - want down it's in all capitals k
15:12 - underscore down you can look those up
15:13 - from the pi game website but pretty
15:15 - straightforward and then what i will do
15:17 - is say game dot move paddle
15:19 - okay and then what paddle do we want to
15:21 - move want to move the left paddle so
15:23 - let's say left is equal to true and i
15:25 - want to move up when i'm pressing w so
15:26 - i'll say up
15:28 - equals trip okay and then we can copy
15:30 - this
15:32 - put this down here
15:33 - and now we'll say if key is pi game.k
15:36 - underscore s because well that's below w
15:38 - then we'll say left is true okay but up
15:40 - is going to be false
15:41 - nice now this will allow us to move the
15:43 - left paddle so let's run the code
15:47 - and let's see what we get and notice
15:48 - that if i move s and w i can now move
15:50 - the left paddle and if you wanted to you
15:52 - could implement maybe the up arrow keys
15:53 - for the right panel that's as easy as it
15:55 - is though and the last thing to look at
15:57 - is that if i do something like game info
16:00 - is equal to
16:01 - this
16:02 - i can print out for example the game
16:05 - info
16:06 - dot and then let's go left
16:09 - score and the game info dot right score
16:11 - so the game info class again it has left
16:13 - score right score left hits right hits
16:15 - so we'll use this data to figure out
16:17 - when we want to end the game and how
16:18 - well the players are doing i just want
16:20 - to show you that i can print this out
16:21 - and let's move the console up and notice
16:23 - we're constantly getting zero
16:25 - and let's let him score and then we're
16:27 - gonna get zero one right
16:29 - okay there you are
16:30 - nice so now that we have done all of
16:32 - that
16:33 - i wanna start building out the ai so to
16:35 - do that i want to make a class that's
16:38 - going to have a few different methods
16:39 - the first method may be something like
16:41 - train ai the other method may be test ai
16:43 - right i need a few different things and
16:45 - it just makes sense to put all this in a
16:46 - class so let's go ahead and do that so
16:48 - i'm just going to make a class here
16:50 - let's do it at the top and let's say
16:52 - class
16:53 - i'll call it pong game and then we'll
16:55 - define an init
16:57 - and in the init let me just move the mic
16:59 - a bit closer here we'll take in a window
17:02 - a width and a height and we'll
17:05 - initialize a game so what i'm going to
17:06 - do is say game here let's copy this
17:10 - is equal to that but we'll say self.game
17:13 - is equal to game window with height so
17:15 - now each pong game instance will have
17:18 - its own game and then inside of here i
17:20 - just want to grab the ball as well as
17:22 - the left and the right paddle from my
17:24 - game so if i go to game here
17:26 - you can see that in the init
17:28 - we have a left paddle right paddle and
17:31 - ball now i'm going to want the location
17:32 - of the ball location of the left and the
17:34 - right paddle when i'm actually designing
17:36 - the ai so i'm just going to get those
17:38 - things i'm going to say self dot left
17:41 - paddle is equal to self
17:44 - dot game dot left paddle
17:47 - and then self.right pal is equal to
17:49 - self.game.rightpaddle
17:50 - and then self.ball
17:53 - is equal to self.game.ball okay
17:55 - now that we have all of that let's make
17:57 - a method and let's just make this test
18:00 - ai
18:01 - and for now we're just going to take in
18:02 - self and i'm just going to run all of
18:04 - the code that i put right here just so
18:05 - that we're not wasting this code let's
18:07 - put all of it in here
18:08 - okay let's tab all of this forward and
18:11 - now we have a method that actually lets
18:12 - us test the game and then later on we'll
18:14 - make it so that we pass an ai here and
18:16 - that actually uses the ai to play
18:18 - against us okay there we go we already
18:20 - have our first method done
18:22 - nice so now that we've done all of that
18:23 - we need to talk about neat because we're
18:25 - going to start actually using neat to
18:27 - well train an ai and we need to
18:29 - understand how neat works and what that
18:31 - is so let me hop over the whiteboard
18:33 - we'll do a bit of an explanation then
18:34 - we'll start implementing it so i'm on
18:36 - the whiteboard and i'm going to start
18:37 - explaining to you neat now neat is
18:39 - neural evolution of augmented topologies
18:42 - and this is what's known as a genetic
18:43 - algorithm now a genetic algorithm takes
18:46 - inspiration from human history and
18:48 - natural selection and essentially
18:50 - produces multiple generations of what we
18:53 - call genomes now this is a little bit
18:55 - confusing i'm going to explain this more
18:56 - in depth but before i get to that i just
18:58 - want to give you a quick recap on neural
19:00 - networks and how you design a regular
19:03 - neural network because neat is kind of
19:04 - an advanced
19:06 - i don't even know what you would call it
19:07 - layer on top of neural networks so when
19:09 - we're designing a neural network what we
19:12 - want to do is we want to feed some
19:13 - inputs to it then we want to get some
19:15 - outputs now we need to determine how
19:16 - many inputs we're going to have and how
19:18 - many outputs and what inputs are going
19:20 - to make sense to feed to the neural
19:21 - network so we're talking about our pong
19:23 - game let's just draw this out here we
19:25 - have a left paddle a right paddle and a
19:28 - ball now there's all different types of
19:30 - inputs that we could feed to a neural
19:32 - network to try to get the paddle to move
19:34 - but the first thing we should probably
19:36 - determine is what do we want this neural
19:37 - network to tell us what is what is the
19:39 - output going to be well what we want the
19:42 - neural network to tell us is if we're
19:43 - talking about say the left paddle here
19:45 - is if we should move the paddle up
19:48 - down or if we should just keep the
19:49 - paddle in the same location that's
19:51 - really all we care about that's what we
19:52 - want to know from the network so that's
19:54 - what our output's going to be up down or
19:57 - stay still now to try to get the pile to
19:59 - go up down or to stay still what input
20:01 - should we feed the neural network well
20:03 - it's definitely going to need to know
20:04 - the location of the paddle right now in
20:07 - pi game the location is the top left
20:08 - hand corner so in this case we'll pass
20:11 - say the y of the paddle
20:13 - to the neural network now the reason i
20:15 - won't pass the x is because the x is
20:17 - going to be constant and you don't want
20:18 - to pass any constant values to a neural
20:20 - network it's just not necessary to do
20:22 - that so i don't need to pass the x
20:23 - because it's constant of the path let's
20:25 - not change okay so we pass the y of the
20:26 - paddle and then we want to know the
20:28 - location of the ball right that's going
20:29 - to be important so i'm going to pass the
20:32 - y of the ball
20:33 - okay so actually let's not just say p
20:35 - let's say y of ball
20:37 - and then i'll also pass the distance
20:40 - between the paddle and the ball since
20:42 - i'm not going to pass the x of the
20:43 - paddle i'll pass not just the x of the
20:46 - ball but i'll pass the distance between
20:48 - so it knows how close we're getting to
20:49 - right so i'll just say like this
20:51 - i'm standing for the distance between
20:53 - the paddle and the ball nice so those
20:55 - will be my three inputs to the neural
20:57 - network so let's clear the screen here
20:58 - and now let's draw a neural network
21:00 - that's going to have the inputs that we
21:01 - discussed and the outputs
21:03 - so in a neural network we have nodes
21:05 - right we're going to have our input
21:06 - layer which we'll draw in red
21:08 - and this first input we're going to say
21:10 - is going to be the y of the paddle the
21:13 - second input will be the y of the ball
21:16 - and then this will be the distance in x
21:19 - between the ball and the paddle
21:20 - okay and then we're going to have an
21:22 - output layer
21:23 - and for the output layer since there's
21:25 - three possible decisions that we want to
21:27 - make we're going to have three notes
21:28 - right and this first node will say okay
21:30 - we want to stay still this will say go
21:33 - up
21:34 - and this will stay go down and we'll
21:36 - have to interpret
21:37 - which node kind of represents what i'll
21:40 - talk about that later on but the point
21:42 - is we want three nodes because we have
21:43 - three possible decisions and so we can
21:46 - say something like whatever node has the
21:47 - highest value is the decision that we're
21:49 - going to take
21:50 - and then in between here because this is
21:52 - our input layer
21:53 - and this is our output layer we're going
21:55 - to have something called a hidden layer
21:57 - or multiple hidden layers
21:59 - so maybe i have something like two nodes
22:01 - in one hidden layer and then typically
22:03 - what we do is we connect every node
22:06 - from the input layer to the hidden layer
22:09 - okay
22:09 - and then every node from the hidden
22:11 - layer gets connected to every node from
22:14 - the output layer now it's not always the
22:16 - case
22:16 - sometimes we're missing connections or
22:18 - sometimes there's multiple connections
22:20 - all different types of things can happen
22:22 - but generally speaking we have our input
22:23 - layer we have hidden layers so in this
22:26 - case we just have one we could have
22:27 - multiple hidden layers we could have
22:29 - five nodes ten node as many nodes as we
22:30 - want in the hidden layers and then we
22:32 - have our output layer and what we wanna
22:34 - do is pass information it gets sent
22:36 - through the neural network and then we
22:38 - get some output and we don't really care
22:39 - how we get the output we just want to
22:41 - get the most accurate output we possibly
22:43 - can so that is kind of the brief on
22:45 - neural networks again i'm assuming you
22:47 - understand how neural networks work
22:48 - because i'm not going to explain kind of
22:50 - how the data is getting sent through
22:52 - here the main thing that i want to show
22:54 - you by looking at this diagram is that
22:55 - it's kind of random or it's kind of
22:57 - arbitrary the way that we're picking the
23:00 - internal architecture of our network
23:01 - right within this box that i'm drawing
23:04 - can really be anything i don't care
23:06 - what's in the middle of the neural
23:07 - network so long as the output based on
23:10 - my input is valid right that's really
23:11 - all i care about it can kind of just be
23:13 - an invisible black box what's inside of
23:15 - the neural network and for me to try to
23:17 - determine the number of nodes in each
23:19 - hidden layer how many hidden layers i
23:21 - should have that's a pretty difficult
23:22 - thing to do especially if we're trying
23:24 - to solve a task like training an ai to
23:26 - play a game where this isn't really a
23:28 - well-known task well maybe playing pong
23:30 - is but for any kind of general game or
23:32 - maybe a game you've made yourself
23:34 - there's not a good way to determine how
23:36 - many nodes in our hidden layer we should
23:38 - have as well as how many layers we
23:40 - should have we can you know try to guess
23:42 - but it's not going to be very easy to do
23:44 - that so the reason i keep saying this is
23:45 - because this architecture in the middle
23:47 - is really kind of the question mark this
23:49 - is what's going to determine really the
23:51 - performance of the neural network and
23:52 - that's something that's difficult for us
23:54 - to pick so rather than us deciding it
23:57 - we're going to get the neat algorithm to
23:59 - do that for us so let me zoom out a bit
24:00 - here
24:01 - just so that okay i move this up all
24:04 - right why is it not letting me zoom out
24:05 - okay you know what that's fine we'll
24:06 - just get off the screen i don't need it
24:08 - to be on the screen anymore what our
24:09 - neat algorithm is going to do is it's
24:12 - going to create a bunch of neural
24:13 - networks and these neural networks are
24:15 - going to start with kind of a predefined
24:18 - number of hidden layers a number of
24:19 - hidden nodes we'll decide that on our
24:22 - own and then there'll be some random
24:23 - mutations that are performed to these
24:25 - neural networks so we'll start with kind
24:26 - of a population here so let's say a
24:28 - population of however many neural
24:30 - networks we determine in this case let's
24:32 - say we start with 10 neural networks and
24:34 - these neural networks will all be
24:36 - slightly different and have some kind of
24:38 - minor changes made to them from the
24:41 - starting neural network that we define
24:42 - ourselves so maybe we say that we want
24:44 - to have the network that i said we want
24:46 - to have three input nodes we want to
24:48 - have two hidden nodes and we want to
24:50 - have three output nodes the number of
24:52 - input nodes and the number of output
24:53 - nodes is always going to stay the same
24:55 - no matter what but what's going to
24:57 - change is what's in the middle here the
24:58 - number of hidden nodes the number of
24:59 - connections and all of the parameters to
25:02 - the neural network that's what's going
25:03 - to be modified by the neat algorithm
25:06 - so we start with a population of 10
25:08 - neural networks and we're going to call
25:10 - these neural networks genomes okay and
25:12 - what we're going to do is we're going to
25:14 - take all of these genomes
25:16 - we're going to test them and we're going
25:18 - to determine what their fitness is now
25:20 - the fitness
25:22 - of a genome is essentially its score
25:24 - it's how well it performs right if we're
25:26 - talking about humans and natural
25:28 - selection which i'm going to get to in a
25:29 - second it would be how long do you
25:30 - survive right natural selection
25:32 - essentially states that over you know
25:34 - tens of thousands of years multiple
25:36 - generations of humans the ones that were
25:38 - the smartest the ones that were able to
25:40 - survive they bred together that created
25:43 - a smarter offspring and then that
25:44 - continued on and on and on and you'll
25:46 - oftentimes see memes and stuff about you
25:48 - know natural selection with the people
25:50 - of today that do very stupid things and
25:52 - end up you know potentially dying
25:54 - obviously that's a little bit dark we
25:55 - don't need to talk about that in here
25:56 - but the point of natural selection is
25:58 - that over tens of thousands of years
26:00 - you have a large population of people
26:02 - they all breed together they create
26:04 - offspring the best of those offspring
26:06 - are going to survive the worst are going
26:08 - to die off and that means that when you
26:10 - get to you know the year 2022 you have a
26:13 - set of humans who are all to some level
26:15 - better than the very first generation
26:18 - again depends on the metrics that you're
26:19 - using but that's what this algorithm is
26:21 - going to attempt to do so we take every
26:23 - single one of our genomes and we grade
26:25 - them we give them a fitness now the
26:26 - fitness is how well they perform our
26:28 - task so in this case when we're playing
26:30 - pong we need to come up with kind of a
26:31 - fitness function and a way to determine
26:34 - what the fitness is of every one of our
26:36 - ais now i'm simply going to use the
26:38 - number of times that the ai hits the
26:40 - ball that's going to be my fitness so if
26:42 - the ai misses the ball which is going to
26:44 - happen a lot at the very beginning it's
26:46 - going to get a fitness of zero but if
26:48 - the ai stays alive for a good amount of
26:49 - time
26:50 - and hits the ball a lot then it's going
26:52 - to get a high fitness
26:53 - that's as simple as it is for the
26:55 - fitness function so we go through we
26:56 - give them all fitness let's just say we
26:58 - have something like one seven three
27:00 - two zero uh three four ten
27:04 - twenty
27:05 - 21 whatever whatever the fitness values
27:07 - are and then what we're going to do
27:09 - is we're going to look at this
27:10 - population of genomes we're going to
27:12 - keep the best genomes that we have so
27:14 - maybe we keep like 21 20 10.
27:17 - uh maybe we keep seven as well we're
27:19 - going to discard some of the worst ones
27:21 - and then we're going to breed the best
27:23 - genomes together and move to the next
27:25 - generation and when i say breed what
27:28 - that really involves is looking at the
27:30 - architecture of each of these neural
27:32 - networks because remember each genome is
27:33 - really just a neural network and taking
27:36 - those properties and kind of merging
27:37 - them together in another new neural
27:39 - network so maybe one neural network has
27:41 - a layer with two nodes the other one has
27:42 - a layer with three maybe we then make a
27:44 - new network that has
27:46 - excuse me two hidden layers one with two
27:49 - nodes one with three nodes whatever the
27:51 - mutation is we make some changes and
27:52 - we're kind of breeding the best networks
27:54 - together and hoping to get a better
27:56 - offspring that's the concept so we take
27:58 - these let me zoom out here and then we
28:00 - move on this is what we call generation
28:03 - one okay
28:04 - and we move on and we make another
28:06 - generation of genomes that goes here so
28:08 - we have one two three four five six
28:11 - seven eight nine ten
28:12 - okay and then same thing with these
28:14 - genomes we take them we grade them on
28:16 - their fitness we keep the best ones we
28:18 - get rid of the worst ones and then we
28:19 - mutate the best ones together create
28:21 - some offspring and move on to the next
28:24 - generation and we continue this until
28:26 - eventually we get a genome or a neural
28:28 - network that meets our criteria
28:30 - for fitness so maybe once the fitness is
28:32 - 500
28:33 - 700 whatever it is we say okay we're
28:35 - done we have found an ai that is
28:37 - sufficiently good at the game of pong
28:39 - we're going to end the algorithm and we
28:40 - can then save that ai and use it in our
28:42 - game
28:43 - hopefully this makes a bit of sense
28:45 - all right so obviously i am giving a
28:48 - vast simplification to how the neat
28:49 - algorithm actually works people way
28:52 - smarter than me wrote the neat algorithm
28:54 - we're not going to write this algorithm
28:55 - we're just going to utilize it that's
28:56 - why we have the config file and we
28:58 - installed that module
28:59 - and neat does a lot more than what i'm
29:01 - explaining here it actually will keep
29:03 - different species of neural networks so
29:05 - what i mean by that is we'll group
29:08 - maybe you know like let's say these
29:11 - these and these together into three
29:13 - separate species and we'll try to make
29:15 - sure that through our different
29:16 - mutations we're keeping at least one or
29:19 - two
29:20 - genomes from each species so we don't
29:22 - have a species go extinct right and the
29:24 - reason we would do that is because there
29:26 - may be a species that's not very good
29:27 - right now but may have a promising
29:30 - architecture for later on now there's
29:32 - all kinds of other considerations like
29:34 - that like how long do you keep a genome
29:36 - that's not performing well if i have a
29:38 - species and i have one genome in there
29:40 - and it's not performing well for say 10
29:41 - generations is that sufficient for me to
29:43 - say okay i'm going to get rid of it
29:45 - i don't know all kinds of questions like
29:47 - that now there's also the ability to add
29:49 - random mutations to offspring and kind
29:51 - of children of other genomes so what may
29:54 - happen is you may take the best genome
29:56 - and rather than breeding it with another
29:57 - one you may just add a random mutation
29:59 - and a mutation may be
30:01 - disabling a connection or adding another
30:03 - node or slightly changing the weights
30:05 - and biases of the neural network there's
30:07 - all kinds of stuff that can go on and
30:09 - that's why it requires a lot of
30:10 - generations typically to train in
30:12 - artificial intelligence
30:14 - so we're going to start with a
30:15 - population of close to 50 uh genomes and
30:18 - then what we're going to do is run them
30:20 - through about 50 generations until we
30:22 - reach a genome or a neural network that
30:24 - plays the game of pong decently well
30:26 - okay so that's it for the explanation on
30:29 - neat uh hopefully that made a bit of
30:31 - sense now let's hop over the computer
30:33 - we'll start actually implementing this
30:35 - which won't take us too long and then
30:36 - we'll talk about the different
30:38 - strategies on actually testing the
30:40 - fitness because as you're going to
30:41 - notice here the fitness is the most
30:43 - important part we're going to keep the
30:45 - best get rid of the worst generally
30:46 - speaking and so we really need to make
30:48 - sure that we're judging these genomes
30:51 - properly and that we know which ones are
30:53 - the best by giving them the most
30:54 - accurate fitness okay with that said
30:57 - let's hop over to the computer so i'm
30:58 - back on the computer and i just want to
31:00 - spend a second telling you about some
31:01 - resources so first of all this is the
31:03 - neat paper this explains neat gives an
31:05 - overview of it some of the pros and cons
31:08 - and it's obviously going to be a way
31:09 - better explanation of how the algorithm
31:11 - works than what i could have just given
31:12 - you so please do have a read of this
31:14 - it's not super difficult to read it's
31:16 - only six pages long and it will really
31:18 - crystallize probably a lot of the
31:19 - questions or i guess just your
31:21 - understanding of the neat algorithm
31:23 - anyways that's the resources uh that's
31:24 - the resource sorry that's in the
31:26 - description and then continuing here i
31:28 - have this example from the neat
31:30 - documentation so neat python
31:32 - documentation this is one of the
31:34 - examples they provide and it talks about
31:36 - the fitness function running neat
31:37 - getting the results i'm not going to
31:39 - read this too you can feel free to read
31:40 - it on your own and then there's some
31:41 - example code a lot of the code we have
31:43 - is straight from here as well as a
31:46 - configuration file
31:47 - so this is the default configuration
31:49 - file for the example they're using which
31:51 - is the xor example
31:53 - again read this if you want to learn
31:54 - more about it but the configuration file
31:57 - that i have in the project that's
31:58 - already written for us is essentially
32:00 - the exact same as this with just a few
32:02 - minor changes so i will talk about what
32:04 - i've changed but if you want to
32:06 - understand what every single one of
32:07 - these like 70 lines means you can click
32:10 - on configuration file description and it
32:12 - shows you fitness criteria and fitness
32:14 - threshold like all of the different
32:16 - sections in this uh configuration file
32:18 - it talks about how you use them and what
32:20 - you can set them to so again i'm not
32:22 - going to spend the time reading this all
32:23 - out to you that's kind of what you can
32:24 - do on your own time you do not need to
32:27 - go in and touch anything if you don't
32:28 - want to but i know some of you are going
32:30 - to ask you know what does this do what
32:31 - does that do if that's the case please
32:33 - go here and read this it gives you
32:34 - really good explanations
32:36 - okay so now we're back here and we need
32:38 - to start working in this configuration
32:39 - file and understand a few of these
32:41 - important aspects so then we can use it
32:44 - for our neat algorithm so let's start
32:45 - going through this file here
32:47 - these are going to be the three most
32:48 - important things you want to have a look
32:50 - at so just pay attention here
32:51 - fitness criterion is telling us when we
32:54 - reach the fitness threshold essentially
32:56 - so it's kind of confusing the way i
32:58 - explain this but the fitness threshold
32:59 - is when we're going to stop the
33:00 - algorithm and if this is max that means
33:03 - that once we hit this value for at least
33:05 - one genome so once a single genome has a
33:07 - fitness of 400 or more then we're going
33:10 - to stop that's what max means now if i
33:12 - make this mean that means once i have
33:14 - all of my genomes having an average
33:16 - fitness of 400 i'm going to stop and if
33:18 - i make this min that means once the
33:21 - minimum of any genome that i have has a
33:23 - fitness of 400 then i stop so i want
33:25 - this to be max again once i find a
33:27 - single genome having a fitness at or
33:29 - above 400 we stop the algorithm and then
33:31 - we would return that genome and that
33:33 - would be our kind of ai right
33:35 - then population size that's what pop
33:36 - size stands for this is how many we want
33:38 - in our population i'm going to go with
33:40 - 50 and the way we're going to test this
33:42 - is that if you increase this it's going
33:44 - to exponentially increase how long it
33:46 - takes to run so already training this ai
33:48 - could take you know 20 minutes an hour
33:50 - could take a good amount of time
33:52 - depending on how long you run it for so
33:54 - if you make this larger it's going to
33:55 - take significantly longer so i'd
33:57 - recommend you keep it at around 50 but
33:59 - you can mess around with higher lower
34:00 - values i won't make a massive difference
34:03 - to the performance but the speed yes it
34:05 - will so i think 50 is like a good
34:06 - minimum to keep it at some of you may
34:08 - want to do it at like 100 or 150 but for
34:11 - now just go with 50. and by the way
34:12 - everything in this file please feel free
34:14 - to change it
34:15 - a lot of this is just the default that i
34:16 - took right from the neat website and
34:18 - i've just modified a few things
34:20 - so continuing i'm not going to explain a
34:23 - lot of these again you can read the
34:24 - documentation to see that but i want to
34:26 - go to default genome now the default
34:29 - genome we do need to modify a few things
34:30 - here because we need to say set the
34:32 - number of input layers and output layers
34:34 - and all that kind of stuff and we also
34:36 - change the activation function so i'm
34:38 - not going to necessarily explain what
34:39 - the activation function is but
34:41 - essentially what it does is it takes the
34:43 - result from a specific node and it just
34:46 - converts it to a different value so i
34:48 - run the result from a node through the
34:50 - activation function then i pass that
34:52 - value to the next node and this makes it
34:54 - so that our values are going to be
34:55 - within a specific range in this case
34:57 - i've changed the activation function
34:59 - from the default of sigmoid to u which
35:01 - is rectify linear unit and this function
35:04 - actually i have a photo of it right here
35:05 - i'll just pull it up uh this is the relu
35:07 - function uh
35:09 - okay of course you know you can see it
35:10 - on the right hand side of my screen it
35:12 - just makes it so the minimum value we
35:14 - possibly have is zero okay that's rel u
35:17 - uh sigmoid is a different function so
35:18 - i've changed these to value that's the
35:20 - only change i've made there
35:22 - here have not made any changes
35:24 - there's all these other things like okay
35:26 - what's the probability that we add a
35:28 - node or delete a node or all that and
35:30 - continuing where we really want to look
35:32 - at is
35:33 - where was it right here
35:35 - okay network parameters this is what we
35:37 - care about for right now so we need to
35:39 - make sure we change these and they will
35:40 - already be changed for you so the number
35:42 - of inputs is three and the number of
35:44 - outputs is three
35:46 - now the number of hidden is the number
35:47 - of hidden layers you wanna start with by
35:49 - default in this case i'm going with two
35:51 - however you could change this to one
35:53 - three whatever zero again it's kind of a
35:55 - random value that i've picked and this
35:57 - will change over time as the mutations
35:59 - are applied to the neural network so
36:00 - just go with three three
36:02 - you know you can mess with this make it
36:03 - one make it two make it three whatever
36:05 - i'm just gonna make it two for now okay
36:06 - so last thing to explain in this
36:08 - configuration file feed forward make
36:10 - sure this is true again it will be true
36:12 - for you but i've changed this from from
36:14 - false to true now what this means is
36:16 - that we're just going to get a regular
36:18 - neural network where we feed inputs and
36:20 - we get an output if you make this false
36:22 - you get something called a recurrent
36:23 - neural network which means the output of
36:25 - the previous call to the neural network
36:27 - is going to be an input to the next call
36:29 - and that is so you can kind of save
36:31 - information you can save like the
36:33 - history of the neural network if that
36:34 - makes sense we don't care about that
36:36 - here and if you do that you're going to
36:37 - get some weird results so just make this
36:39 - true and then initial connection full
36:41 - direct what this means is that we have
36:43 - directed connections between every
36:45 - single node so we have a fully connected
36:47 - nodes every node in the input layer is
36:49 - connected to every node in the hidden
36:50 - layer every node in the hidden layer
36:51 - every node in the output layer okay all
36:54 - right so now let's actually use the
36:56 - configuration file so to do that i'm
36:57 - going to say import neat and i'm also
37:00 - going to import os just because we need
37:03 - to find the path to the configuration
37:05 - file to load it then i'm going to come
37:07 - down here i'm going to say if underscore
37:08 - underscore name is equal to under
37:10 - squadron square main just making sure
37:12 - that we ran this file not that we
37:13 - imported it i am going to load the
37:15 - configuration file so i'm going to say
37:17 - that my local directory is equal
37:20 - to os.path
37:22 - dot der name and then under square
37:24 - underscore file under squad underscore
37:26 - with a lower case this is a special
37:28 - variable just gives you the current file
37:30 - i can get the directory name of it and
37:32 - then what i'm going to do is say that
37:34 - the config
37:36 - path is equal to os.path.join
37:40 - and i'm going to join the local
37:41 - directory with config.txt
37:44 - okay which is what we have right there
37:45 - now if you change the name of this
37:46 - you're going to have to change that but
37:48 - i assume most you're working with the
37:49 - starting code now that we have that
37:51 - we're going to say config is equal to
37:53 - neat dot
37:55 - config and actually let me just copy
37:57 - this in
37:58 - ah because it's going to be a bit easier
38:00 - than typing all this out okay
38:02 - then we're going to say neat dot default
38:03 - genome neat default reproduction neat
38:06 - defaults bc set neat default stagnation
38:09 - and then the configuration path
38:11 - not going to explain this too much
38:12 - essentially we're just passing the
38:14 - different properties from the
38:15 - configuration file that we want to use i
38:17 - mean you can read this if you want
38:19 - but these are the ones that we want to
38:20 - use right default genome default
38:21 - reproduction default species set default
38:23 - stagnation and so i need to make sure
38:25 - all of those are in my configuration
38:26 - file and they are and then lastly i pass
38:28 - my configuration path so now i've loaded
38:30 - the configuration file now we need the
38:32 - configuration file to actually create a
38:34 - neural network so that's what we had to
38:35 - load it okay now that we've loaded it
38:37 - what i want to do is i want to run the
38:40 - need algorithm so i'm going to make a
38:42 - function and say define
38:44 - run neat okay
38:46 - and this is just going to take in the
38:47 - config
38:48 - okay so here we can go
38:51 - say run neat
38:52 - and we can pass the config
38:54 - now inside of run neat i need to create
38:57 - kind of my
38:58 - meet runner i don't even know what you
39:00 - would necessarily call this i guess my
39:01 - neat population so i'm going to say p is
39:03 - equal to neat dot
39:05 - population and for the population i'm
39:08 - just going to pass the config okay
39:10 - so i'm initializing a population of
39:11 - genomes using the configuration file now
39:14 - that i've done that i'm going to add a
39:15 - few things to this that makes it so we
39:17 - get some output to our screen now all
39:19 - this code again is coming really right
39:21 - from the neat website so you can
39:22 - reference it there as well but i'm just
39:24 - going to say p dot add reporter and i'm
39:26 - going to say neat dot std out reporter
39:30 - and then i'm going to pass true here now
39:32 - this just means we're going to report
39:34 - data to the standard output so we'll
39:35 - actually see what generation we're on
39:37 - the best fitness the average fitness all
39:39 - that kind of stuff i'm then going to say
39:40 - stats is equal to neat dot and then this
39:43 - will be statistics reporter so
39:46 - let's write it like that inside of here
39:48 - we don't have to pass anything and i'm
39:50 - going to say p
39:51 - dot add reporter stats and then finally
39:54 - p dot add reporter and i'm going to add
39:56 - neat dot check pointer one now this is
39:59 - really important that you do this the
40:00 - check pointer is going to actually save
40:02 - a checkpoint after every x generations x
40:06 - being the number i passed here so i'm
40:07 - going to save one after every one
40:08 - generation now what this allows you to
40:10 - do is restart the algorithm from a
40:13 - checkpoint now you want this because it
40:14 - could take an hour two hours a day two
40:17 - days to run this depending on what you
40:18 - have in the config file so obviously you
40:20 - want to save your progress and be able
40:21 - to kind of restart and maybe train
40:23 - differently from a certain point in time
40:25 - so that's why we're checkpointing at
40:27 - every one you may want to checkpoint at
40:28 - every five generations whatever and to
40:31 - actually load from a checkpoint let me
40:33 - just copy this in
40:34 - what you would do is you would comment
40:36 - out this line and you would just put the
40:38 - name of the checkpoint that you want to
40:39 - load from okay
40:41 - pretty straightforward
40:42 - neat.checkpointer.restorecheckpoint
40:44 - checkpoint and then whatever the number
40:46 - is you'll see them being saved as we run
40:48 - this
40:48 - and then that's instead of the
40:50 - population but of course we don't have a
40:52 - checkpoint so we're not going to do that
40:53 - right now all right so now that i've
40:54 - done this i'm going to say p dot run i'm
40:56 - going to pass a function which i've yet
40:58 - to write called eval genomes and i'm
41:00 - going to pass the number of generations
41:02 - that i want to run this for at most now
41:04 - you can read what it's saying here we're
41:05 - passing what's called the fitness
41:06 - function the fitness function is going
41:08 - to take all of my genomes which are in
41:11 - the current population based on whatever
41:12 - generation it is and it's going to give
41:14 - them a fitness and then based on what
41:16 - their fitness is once that function is
41:18 - finished executing then the neat
41:20 - algorithm is going to perform its
41:22 - mutations and then it's going to go to
41:23 - the next generation and get the fitness
41:25 - for that so what i'm going to do is say
41:26 - define
41:28 - eval underscore genomes and i'm going to
41:31 - take inside of here my genomes which are
41:34 - the neural networks in the current
41:35 - population as well as my configuration
41:38 - file
41:39 - okay
41:40 - so let's just quickly talk about what we
41:42 - did we set up our population using the
41:44 - configuration file then we added the
41:46 - reporters and the check pointer just so
41:47 - we see some data on the screen and we're
41:49 - checkpointing at every one generation
41:52 - then we're saying p.run we're passing
41:54 - the function make sure you don't call
41:56 - the function just pass the name of the
41:57 - function it will automatically pass this
41:59 - data for us then the maximum number of
42:01 - generations we want to run for which is
42:03 - 50. now i can actually say winner is
42:05 - equal to p dot run
42:07 - and this will give me the best neural
42:08 - network or the one that hits the fitness
42:11 - threshold while running this so either
42:13 - we'll get to 50 generations and then
42:14 - whatever one has the best fitness will
42:16 - be the winner or if we hit one that or
42:18 - if we get one story that has 400 fitness
42:21 - or more it will be returned to us at
42:22 - whatever generation that occurs okay now
42:25 - we have eval genomes now
42:27 - inside of here what we need to do is we
42:29 - need to set a fitness for every one of
42:31 - our genomes and to do that we need to
42:33 - run them through the pong game all right
42:35 - so let me take a quick pause here and
42:36 - explain the thought process behind how
42:39 - we're going to train this ai because
42:40 - it's a little bit complicated but it is
42:42 - necessary to avoid getting kind of
42:44 - stagnation in training
42:46 - so there's a lot of ways that we could
42:47 - train a pong ai and the whole issue here
42:51 - is that this is a multiplayer game if
42:53 - this was a single player game no problem
42:55 - it'd be really easy to train because the
42:56 - environment's always the same right it's
42:58 - always the same single player
42:59 - environment so everything's consistent
43:01 - and we get a really fair fitness reading
43:03 - however in pong
43:04 - the performance of our player our ai
43:07 - depends on the performance of its
43:09 - opponent and so we need to find a fair
43:11 - way to train all of our ais by either
43:14 - playing them against say the same
43:15 - opponent or maybe each ai against every
43:17 - other ai there's a lot of different
43:19 - possible ways to go about doing this so
43:21 - the first approach you may think of is
43:22 - okay well let's train the ai against the
43:25 - same opponent every single time if we do
43:27 - that then we get a consistent fitness
43:28 - score that's correct but the issue is if
43:31 - we train against the same opponent we
43:32 - need to have a opponent that's as good
43:34 - as can possibly be right because if we
43:36 - have an opponent that's really bad we're
43:37 - going to get a false sense that our ai
43:39 - is good so we need an opponent that's as
43:41 - good as possible to really determine the
43:44 - fitness of our ai but the whole point of
43:46 - making the ai is to find a really good
43:48 - ai at playing pong so we don't have that
43:50 - available right unless we were to hard
43:52 - code something out which is definitely
43:54 - possible you could hard code this
43:55 - without actually making you know the
43:57 - neat ai for it but this is you know much
43:59 - neater much cooler so we're going to
44:00 - eliminate that approach because it
44:01 - doesn't make sense for us to kind of
44:02 - hard code out an opponent to play
44:04 - against the ai
44:06 - so the next approach is let's train the
44:08 - ai against itself now this is a
44:10 - reasonable approach to do this but
44:11 - what's going to happen if you train the
44:13 - ai against itself is that even though
44:14 - you're going to get a very fair fitness
44:16 - reading the ai is going to learn how to
44:18 - play only against itself it's not going
44:21 - to learn how to play against an opponent
44:23 - that makes seemingly random moves and if
44:25 - it's only learning how to play against
44:26 - itself even though it may look like it's
44:28 - going to be very good we have no idea
44:30 - what's going to happen if we put it
44:31 - against an opponent where it can't
44:33 - predict what the move of that opponent
44:34 - is going to be so we can't really go
44:37 - with that approach
44:38 - i mean we can try that but we're
44:40 - probably going to end up with ais that
44:41 - are really good against themselves and
44:43 - look amazing but then when they start
44:44 - playing against me or you they have no
44:46 - idea what to do
44:47 - so the last approach is we need to train
44:49 - each ai against each other so either i
44:52 - take pairs of ais maybe like ai 1 and
44:54 - ai2 and train them against each other
44:56 - and then get their fitness or i take
44:58 - each ai and i train against every single
45:00 - other ai and take kind of a
45:03 - sum of the fitness of all of those games
45:05 - now that's the approach that we're going
45:07 - to go with and the reason we're going
45:08 - with that approach is because again
45:10 - how good your ai is or how good the
45:13 - fitness is is dependent on its opponent
45:15 - so to make everything as fair as
45:16 - possible we want each ai
45:18 - to play against every other ai now that
45:20 - is going to take a long time but it's
45:22 - going to give us the most accurate
45:24 - fitness and actually end up being one of
45:26 - the quicker training routes so that's
45:27 - what i'm about to implement apologize
45:29 - for all this talking but again you got
45:31 - to understand the theory behind what
45:32 - we're doing and some of the potential
45:33 - problems that come up in a multiplayer
45:35 - game so let's try this now
45:37 - i'm going to again be kind of looking at
45:39 - my screen i don't have all this code
45:40 - memorized so if you see me looking over
45:42 - here that's what i'm doing i'm just
45:43 - referencing my code so the first thing
45:45 - i'm going to do
45:46 - is say width height is equal to 700 500
45:49 - because we need to set up a pi game
45:50 - window so we can pass it
45:52 - to this game instance or to the pong
45:55 - game instance where i'm actually going
45:56 - to write a method that will train the ai
45:58 - for us in kind of a similar way to how
46:00 - we were testing it so i'm going to say
46:02 - with height
46:03 - and then i'm going to say window is
46:05 - equal to
46:06 - pygame.display.window or dot sorry.set
46:09 - underscore mode
46:11 - and then width
46:12 - height okay
46:14 - and now that we passed width height
46:17 - what we can do is say for i comma and
46:20 - i'm going to say genome underscore id
46:24 - genome i think this is correct
46:27 - in and this is going to be enumerate
46:29 - genomes now let's go genome id1 and
46:32 - genome so first thing to understand here
46:34 - is that genomes is going to be a list of
46:36 - tuples where each tuple has the genome
46:38 - id as well as the actual genome object
46:41 - now remember i want each
46:43 - what do you call it genome to play
46:44 - against every other genome and so the
46:47 - reason i'm enumerating here is so that i
46:48 - can make sure we're not repeating games
46:50 - that you're going to see in a second so
46:51 - i'm going to say 4 and then this is
46:53 - going to be genome 2 or genome id2
46:57 - genome 2
46:58 - in and then this will be
47:01 - genomes at
47:03 - i plus 1 colon now i spell genome
47:07 - and then colon and then for now we're
47:09 - going to pass so this is kind of the
47:10 - setup of our for loop here we're saying
47:12 - 4i which is the index of each all of
47:14 - these genomes genomic d1 genome 1 in
47:17 - enumerate genomes and then we're saying
47:18 - 4 genome id2 genome 2 in genomes i plus
47:21 - 1 colon now the reason we need i plus 1
47:23 - colon is to make sure the same genomes
47:25 - don't play against each other multiple
47:27 - times
47:28 - they would be swapping on the left and
47:30 - right hand side but to avoid doing so
47:32 - many operations and to cut it by a
47:34 - significant amount i'm going to make
47:35 - this i plus 1 just so the same genome
47:37 - doesn't play against each other multiple
47:39 - times now the issue with i plus one is
47:41 - that eventually we're gonna get i being
47:44 - equal to the last index and then when i
47:45 - add one to it we're gonna get an index
47:47 - out of range error so i'm just gonna say
47:49 - if i is equal to the len of
47:52 - genomes minus one then break
47:55 - just so that we end okay
47:58 - hopefully that makes sense uh that just
47:59 - avoids having the index out of bounds
48:01 - error here okay so now inside of here
48:03 - what i want to do is i want to create a
48:06 - game
48:07 - and i want to test the two genomes
48:08 - against each other so i'm going to say
48:10 - game is equal to pong game
48:13 - and i'm going to pass my window my width
48:15 - and my height
48:17 - now before i do that
48:19 - if i can type properly here i'm just
48:22 - going to set up here
48:24 - i'm going to say genome 1
48:27 - dot fitness
48:29 - is equal to 0. now
48:31 - these genomes do not have a fitness
48:33 - attribute on them by default so the
48:35 - reason i'm doing this is so that later
48:37 - on i can add or subtract from the
48:39 - fitness as opposed to setting it because
48:41 - i'm going to be adding and subtracting
48:42 - to it multiple times
48:44 - again this all makes sense when i write
48:46 - more code but i'm saying genome 1.finish
48:48 - equals 0 and then down here in this next
48:50 - for loop i'm going to say genome 2
48:53 - dot fitness
48:54 - is equal to 0 if genome 2 dot fitness
49:00 - equals none
49:01 - else this is going to be genome 2.
49:03 - fitness now this is an inline if
49:04 - statement and the reason i'm writing
49:05 - this is because for my genome 2 i need
49:08 - to set its fitness equal to 0 when i
49:11 - first
49:12 - pick up this genome when this is the
49:14 - first genome that i'm having a look at
49:16 - now the issue is that i don't want to
49:17 - set its fitness to zero if the genome
49:20 - already has a fitness value from being
49:21 - ran multiple times so if we're looking
49:23 - at this i have genome one right and then
49:26 - this for loop is going to run every time
49:28 - that this for loop runs so on the next
49:30 - iteration of this for loop this for loop
49:32 - kind of restarts and i'm going to be
49:33 - looking at the same genome multiple
49:35 - times as the opponent to this genome so
49:37 - i don't want to set this genome's
49:39 - fitness equal to zero if it already has
49:42 - a fitness value but if it doesn't have a
49:43 - fitness value then i need to initialize
49:45 - its value and so that's why i'm writing
49:47 - this here
49:48 - hopefully that's all good
49:50 - and just to make sure i think this will
49:52 - be fine because this genome will only
49:54 - ever be encountered in this for loop
49:56 - yeah we should be good with that okay so
49:58 - now that we've set the fitness values uh
50:00 - we initialize our pawn game so game is
50:02 - equal to pawn game and then what i'm
50:04 - going to do is i'm going to train my ai
50:06 - so i'm just going to say game
50:08 - dot train underscore ai i need to pass
50:11 - to this genome one
50:13 - genome two
50:15 - and then the configuration file
50:17 - okay uh that's all we'll pass for right
50:19 - now and i'm gonna write this method on
50:21 - the game class and this game class will
50:24 - set the fitness for us okay so this is
50:26 - almost all we need in here we'll make a
50:28 - few slight changes but we're just going
50:30 - to train the ai so we pass genome 1
50:32 - genome 2 and then it will simulate the
50:34 - game between the two ais and set their
50:35 - fitness
50:36 - so now we're going to go up here and
50:39 - let's just write it from scratch i don't
50:40 - want to copy this i'm going to say
50:42 - define train ai
50:44 - and inside of here i'm going to take
50:46 - genome 1
50:48 - genome 2
50:49 - config and then i need to make sure i
50:51 - have self as well
50:52 - okay so self genome one genome two and
50:54 - config
50:55 - and then i need to run both of these
50:58 - genomes uh right and i need to pass my
51:01 - input to the neural networks get the
51:03 - output analyze the output and then make
51:05 - a move for my paddles so similar to what
51:07 - i've done up here i'm going to say run
51:10 - is equal to true i'm going to say
51:13 - wow run
51:14 - and then i'm going to say game so self
51:18 - dot game dot loop
51:20 - self.game
51:23 - and then pygame dot display dot update
51:27 - okay so now that we have this game loop
51:28 - set up similar to what i did here i'm
51:30 - just going to take this event loop and
51:32 - i'm going to say
51:34 - let's get into the right method here
51:37 - for event in pigeon.event.get i just
51:39 - need a way to quit right so i'm putting
51:40 - this in here just so i have a way to
51:42 - quit i'm going to say run equals false
51:43 - but i'm actually you know what i'm not
51:45 - going to say only false i'm just going
51:47 - to return
51:48 - false here and the reason i'm going to
51:50 - return false is because what's going to
51:51 - happen is we're going to constantly call
51:54 - from eval genomes
51:56 - this game right i'm going to constantly
51:58 - be creating a new game and constantly
52:00 - running it and so what happens is if i
52:02 - return false here then that's fine i end
52:05 - the current training but then i'm going
52:06 - to train again and again and again and i
52:08 - want when you click the x button to just
52:09 - completely exit the program so i'm going
52:11 - to say
52:13 - force underscore quit
52:15 - is equal to this
52:17 - and actually i'll say if force quit
52:20 - then quit okay
52:21 - and in fact i don't even know why i'm
52:23 - doing all this this seems a bit too
52:24 - complicated
52:25 - let's just do this
52:26 - let's go here and let's just say quit
52:29 - so if you hit this we just quit the
52:31 - entire program uh quit just completely
52:33 - ends the game okay say quit that's just
52:35 - going to end the program for us so i can
52:37 - avoid having to return values back and
52:38 - do all that stuff okay so now we have a
52:40 - way to exit we're looping we're drawing
52:43 - we're updating the display
52:44 - and what else do we need to do here well
52:46 - let's have a look at the game
52:47 - information so let's say game info is
52:50 - equal to self.game.loop and now that
52:52 - we've done that we need a way to
52:53 - actually move the two paddles using
52:55 - genome 1 and using genome 2.
52:57 - now what we can do is we can create
53:00 - neural networks for both of these
53:01 - genomes then pass inputs and get the
53:04 - output so i'm going to do that here i'm
53:06 - going to say net1 is equal to self
53:08 - actually it's not going to be self it's
53:10 - going to be neat dot nn dot feed forward
53:13 - network
53:14 - dot create
53:16 - i'm going to pass my genome
53:18 - and the configuration file
53:20 - okay so that's net 1
53:22 - and then net 2 is going to be the same
53:24 - but it's going to be with genome 2.
53:27 - now to use the networks what we need to
53:29 - do is say and we'll do this before we
53:32 - call the game info
53:34 - we're going to say net1
53:36 - dot activate and we're going to pass the
53:38 - inputs to the network so the inputs that
53:40 - we want is we want the y coordinate of
53:43 - the paddle we want the y coordinate of
53:46 - the ball and we want the distance in the
53:49 - x between the ball and the paddle now it
53:51 - doesn't matter the order that we pass
53:52 - them in so long as we pass them
53:54 - consistently in the same order so let's
53:56 - say output
53:57 - let's go output 1
54:00 - is equal to this
54:01 - and we'll pass self
54:03 - dot left paddle
54:05 - dot y it has a y attribute on it you can
54:07 - look at the paddle class if you want to
54:09 - see that then self
54:11 - dot ball dot y and again remember we
54:14 - have these up here so that's how i'm
54:15 - accessing them
54:16 - and then we want the absolute value of
54:19 - the self dot left paddle dot x
54:21 - minus
54:23 - the ball dot x okay so this is always
54:25 - going to be positive
54:26 - nice so that's what we have for output
54:28 - one
54:29 - and then we want output two so output
54:31 - two is going to be equal to this but
54:32 - it's gonna be net two and rather than
54:34 - left paddle is gonna be the right path
54:37 - okay and then that's ball.y and that is
54:40 - the right panel nice
54:42 - okay i think that's all good so this is
54:44 - going to give us an output now the
54:45 - output is just going to be the numeric
54:47 - values associated with the three output
54:49 - nodes in our neural network so we need
54:52 - to actually interpret that and we need
54:54 - to select the maximum value from those
54:57 - outputs now since i understand it's a
54:58 - little bit confusing let's just print
55:00 - them out for now and just have a look at
55:02 - what's happening so let's go
55:04 - output one
55:06 - output two
55:08 - now i also need some way to end the game
55:09 - here because i'm not ending the game in
55:11 - this game class i'm relying on whoever's
55:13 - using the game class to end it based on
55:15 - this info so i'm just going to put in a
55:17 - statement here and i'll do this at the
55:19 - bottom i'll say if and this is going to
55:22 - be game info dot left score is greater
55:25 - than or equal to 1
55:27 - or
55:28 - game info
55:30 - dot write score is greater than or equal
55:32 - to 1
55:33 - then i'm just going to break but before
55:36 - i break i need to set the fitness of my
55:38 - two genomes now i'm going to say
55:41 - actually it won't be self it's just
55:43 - going to be
55:45 - let's say genome one
55:49 - okay instead of doing that let's go
55:51 - define
55:52 - and this will be
55:55 - calculate fitness
55:57 - and we'll take in self genome one genome
55:59 - two sorry i was just contemplating how i
56:01 - want to do this uh but i want to do it
56:03 - in a method so i'm going to say self dot
56:05 - and then this will be calculate fitness
56:08 - and we'll pass genome one
56:10 - and genome two
56:12 - and actually we will pass the game info
56:14 - as well i guess we need that data in
56:15 - here just pass game info
56:18 - and then inside of here we'll we'll deal
56:19 - with what the fitness calculation should
56:21 - be okay so there's a lot going on here
56:22 - believe it or not we're actually almost
56:23 - done we just need to move the paddles
56:25 - but i want to kind of take a pause
56:27 - explain what i've done so far just so
56:29 - i'm not confusing you guys too badly
56:30 - then we'll run the code see what we're
56:32 - getting right now and then continue from
56:33 - there so let's go right to the beginning
56:36 - we have our local directory
56:38 - configuration path we essentially read
56:40 - the configuration file and then we pass
56:42 - that to our run need function we set up
56:45 - our population all of our reporters and
56:46 - all that and then we run the eval
56:49 - genomes function up to 50 times
56:51 - okay so we come here we set up a pi game
56:53 - window because we need that for our game
56:55 - and then we say 4i genome id1 genome 1.
56:59 - we actually don't care about the genome
57:00 - ids but we'll just leave them there in a
57:02 - numeric genomes and what this whole set
57:04 - of for loop is going to do here is it's
57:06 - going to run each genome here so each
57:08 - genome 1 against every other genome
57:11 - exactly one time and then the fitness
57:13 - for that is going to be the sum of
57:14 - whatever the fitnesses they get for
57:16 - every game
57:17 - okay
57:19 - then we set the fitness because we need
57:20 - to initialize an attribute
57:22 - we then go and loop through all of the
57:24 - other genomes
57:25 - set the fitness if they don't already
57:26 - have one set and then we train the ai
57:28 - okay
57:29 - genome one genome two config
57:31 - coming up here
57:33 - we set up our two neural networks based
57:34 - on our genomes
57:36 - we then run the game
57:37 - okay we have an event that just allows
57:39 - us to actually quit
57:40 - and then we get the output from both of
57:42 - our neural networks now we're going to
57:43 - use this output to move the paddles
57:45 - we're going to do that later we run the
57:47 - game loop which
57:49 - now that i'm thinking about it i guess
57:50 - we can run the game loop here that's
57:51 - fine and then we have self.game.draw so
57:54 - we just draw the game and then we update
57:56 - the display and then hear what i've done
57:58 - i didn't really explain this i'm
57:59 - essentially saying that if either paddle
58:01 - misses the ball once we're immediately
58:03 - going to end the game now the reason i'm
58:05 - doing this is because if the paddle
58:07 - misses the ball i don't want to keep
58:10 - running it like multiple times 50 times
58:12 - 100 times whatever because it's most
58:14 - likely going to miss almost every ball i
58:16 - want to be in a situation where as soon
58:18 - as it misses we just immediately move on
58:19 - to the next paddle and that way it
58:21 - doesn't get any higher fitness score and
58:23 - i just kind of stopped testing that one
58:25 - because it could take a long time just
58:28 - for it to continue to miss balls
58:30 - again i know it might be a little bit
58:31 - confusing but the score is telling me
58:33 - again how many times the ball has gone
58:35 - off the opposite person's side so if the
58:38 - left score is one or the right score is
58:39 - one that means either the left or the
58:41 - right paddle missed the ball and since
58:42 - they missed the ball then we're just
58:44 - going to stop
58:46 - calculate the fitness and then move on
58:48 - now the only issue with doing this here
58:50 - is that what's going to happen is that
58:52 - as soon as even your opponent misses the
58:54 - ball you're going to stop as well we're
58:56 - going to stop calculating your fitness
58:58 - as soon as you or your opponent misses
59:00 - the ball now this is a way for me to
59:02 - quickly train because if i don't do that
59:04 - again it's going to take way way longer
59:06 - to train like significantly longer so
59:08 - you could come up with other approaches
59:09 - and other fitness calculations
59:11 - this has worked for me this far that's
59:13 - why i'm doing this again feel free to
59:15 - change this as you please and then if
59:17 - that happens we're going to end so we're
59:18 - going to calculate the fitness and then
59:20 - break out of this loop
59:21 - and then kind of move on with life all
59:23 - right
59:24 - okay so let's run this so far let's just
59:26 - see if this is working you're not going
59:28 - to see kind of anything moving on the
59:29 - screen really because we're not actually
59:31 - moving the paddles but you will see in
59:33 - the console what our outputs are and
59:34 - you'll see what the need output is as
59:36 - well so let's
59:37 - close cmd let's run this
59:40 - and let's see what we get okay it says
59:42 - name ball is not defined
59:44 - self.ball.y oh i just put ball.x sorry
59:46 - guys let's make that fix so this is now
59:49 - self.ball
59:50 - and this is self as well scroll over so
59:52 - you can see okay
59:54 - nice okay so let's clear
59:56 - and run
59:58 - and see what we get now and there we go
59:59 - okay so we can see that we're getting a
60:01 - bunch of results let me close this we're
60:03 - getting a bunch of results here
60:05 - and what we're going to do is we're just
60:06 - going to take whatever the maximum value
60:08 - is of all of these things right so we'll
60:11 - treat the first column as staying still
60:13 - the second column or the second index as
60:16 - uh moving up and then the next one is
60:18 - moving down and as you can see right
60:20 - we're getting you know sometimes we're
60:21 - getting a bunch of different values
60:22 - sometimes we're just getting zero and
60:24 - these values will start to
60:25 - make more sense
60:27 - as the ai trains itself and gets better
60:29 - so to do that
60:31 - we're going to say
60:32 - let's go here
60:35 - result 1 or we'll say
60:37 - decision 1 is equal to and then this is
60:40 - going to be the maximum
60:44 - of output 1.
60:45 - we're going to index this so i'm going
60:47 - to say output 1
60:49 - dot index the max of output 1.
60:52 - this is going to give us the index so
60:54 - either zero one or two and we'll say
60:56 - zero stay still one is move up and two
60:59 - is move down hopefully that makes sense
61:00 - we're just getting the index of wherever
61:02 - the maximum value occurs from output one
61:04 - and then we'll say output two is equal
61:07 - to
61:08 - output two
61:10 - dot index
61:11 - the max
61:13 - of output two so now that we know sorry
61:15 - not output two
61:17 - decision two so now that we know the
61:18 - decision we can then write some if
61:20 - statements that say okay if this is a
61:22 - decision move here if this is a session
61:23 - move here
61:24 - so i can say if
61:26 - decision one is equal to zero
61:29 - then we just don't do anything right
61:30 - because we're staying still we can say l
61:32 - if
61:33 - decision is equal to one then we will
61:35 - say
61:36 - uh self
61:38 - dot game
61:39 - dot move paddle
61:41 - and we're gonna say left equals true
61:44 - because the uh net one is going to be
61:46 - our left paddle and then up
61:48 - equals true
61:50 - okay and then else we'll say self dot
61:53 - game dot move paddle
61:56 - left
61:56 - is equal to true and up is equal to
61:59 - false because that's moving down and
62:01 - we'll just copy the exact same thing
62:04 - and just tweak it a little bit
62:06 - so now this is going to be decision two
62:09 - decision two and then we just need to
62:11 - change left to be false because now this
62:12 - is the right pad
62:14 - okay
62:15 - so that's how we'll move the paddles and
62:16 - with that we've actually set up almost
62:18 - all the training for the ai other than
62:20 - the calculate fitness function which
62:21 - we'll do in a second but now
62:23 - if i clear this in rerun you should see
62:26 - that the paddles move right now they're
62:28 - not really doing very well for us but
62:29 - they are moving
62:31 - and yeah there you go so now the pedal
62:32 - is actually moving based on the neural
62:34 - network and once we start implementing
62:35 - the fitness and the different
62:36 - generations then you'll see that they'll
62:38 - slowly start to get better so let's
62:39 - close that i also want to change
62:41 - something here where it says draw
62:43 - so
62:44 - for the draw i'm going to say draw
62:47 - score is equal to false instead i want
62:49 - to draw the number of hits they have so
62:51 - i want to say draw hits
62:53 - is equal to true
62:55 - and just to show you that change let's
62:57 - run it
62:59 - and notice that now we just get this red
63:01 - thing being drawn that's telling us the
63:02 - number of combined hits between the left
63:04 - and the right paddle
63:05 - okay so now that we've done that all we
63:07 - need to do is implement the fitness once
63:09 - the fitness is implemented we're pretty
63:11 - much done with the code and we just need
63:12 - to wait for it to train and i'll show
63:13 - you how to save the best
63:15 - run tested all that stuff so to do this
63:18 - we're simply going to say
63:20 - genome one
63:22 - is equal to or sorry dot fitness
63:25 - is plus equal to this is going to be
63:27 - game info dot left hits like that and
63:30 - then i'm going to say genome 2
63:32 - dot fitness plus equals game info dot
63:36 - right hits so that's actually all we
63:37 - need for the fitness again we'll just
63:40 - add how many hits they had in the game
63:41 - and we're adding not setting if you set
63:43 - that's no good that means the only the
63:46 - last game they play is going to account
63:47 - for their fitness we care about every
63:49 - game they're playing because we're
63:50 - playing against every single ai now the
63:52 - only thing that we want to implement
63:54 - here is we want some way to essentially
63:56 - end a game when the hits get too large
63:59 - because you'll get to a point where you
64:00 - do have two perfect ais and when they're
64:02 - playing against each other they can play
64:03 - infinitely so we just want to make sure
64:05 - that
64:06 - the number of hits between them doesn't
64:08 - grow so large that we play too much
64:11 - right and that that biases our score so
64:14 - let's say and game info
64:17 - dot let's just go with left hits
64:20 - is greater than 50. sorry not not uh not
64:23 - and we're going to say
64:24 - or so essentially what this is saying is
64:27 - that if the player on the left gets 50
64:29 - hits or more or gets more than 50 hits
64:32 - then we're just going to stop because
64:33 - they'll still get a very high fitness
64:34 - score but we don't want them to play
64:36 - infinitely right again that's just going
64:38 - to make the training really long and
64:39 - that will actually give us an infinite
64:40 - loop
64:41 - now the reason why i'm not checking the
64:42 - right hits is because the right hits
64:44 - will always be
64:46 - either one more or one less than the
64:47 - left hits so there's no reason for me to
64:50 - check
64:50 - the right hits as well if the left hits
64:52 - is greater than 50 then the right hits
64:54 - will either be 50 or it will be 51 or it
64:57 - will be 49 or something like that right
64:58 - it's very similar so it doesn't really
64:59 - matter and the reason why that will be
65:01 - the case is because when the ball starts
65:03 - on the screen it will randomly start
65:05 - either on the left or the right hand
65:06 - side i don't know where it's going to
65:07 - start randomly left or right
65:10 - yeah hopefully that makes sense but
65:11 - that's why we're checking that okay so
65:13 - now that we've done that let's run this
65:15 - let's just see how it works for a
65:17 - generation or two and then i'll show you
65:18 - how we test it and how we save the best
65:20 - ai
65:21 - okay so let's go ahead and run the code
65:24 - all right so i've just let this run for
65:25 - a few generations and i'll just talk to
65:27 - you about some of the data we're getting
65:28 - here uh then we'll kind of look at the
65:30 - ai see how it's doing now on i guess
65:31 - generation four and um how we can
65:34 - actually test the ai as well so we have
65:36 - the average fitness of 4.0 actually not
65:38 - bad for the first generation that means
65:39 - at least some ais were hitting the ball
65:41 - right we have best fitness of 20 that
65:43 - means one ai through all of the
65:45 - different games that it played hit the
65:47 - ball a total of 20 times so played 49
65:49 - games and it would have missed the ball
65:51 - i was that 29 times and hit the ball 20
65:53 - times so not great but for the first
65:55 - generation we can live with that right
65:57 - then we have average adjusted fitness
65:58 - 0.347 mean genetic distance this is the
66:02 - i guess difference
66:04 - between the neural network architectures
66:07 - kind of hard to explain exactly what the
66:09 - magnitude means here but the larger the
66:11 - number the more different the the
66:13 - different neural networks are that you
66:14 - have
66:15 - then you have the population of 50
66:17 - members in two different species so
66:19 - species with id1 is here species with
66:21 - ids 2 is here tells you how long the
66:23 - species have existed and then the size
66:25 - there's 19 in species 1 31 in species 2
66:28 - and then we have a fitness of 20 and a
66:29 - fitness of 10. now that's the best
66:31 - fitness in this species and the best
66:34 - fitness in this species and then the
66:35 - adjusted fitness for that species okay
66:38 - coming here
66:40 - we have
66:41 - now 19 in species 1 31 in species 2
66:45 - fitnesses have now changed and the stag
66:47 - here is telling you the stagnation of
66:48 - the species so how long has it been
66:49 - stagnant for continuing we now come here
66:52 - and now the reason this is getting a one
66:54 - for stagnation is because its fitness
66:57 - score is less than it was last time so
66:58 - it's now being stagnant right based on
67:00 - the mutations that would have been done
67:02 - and you see that we've actually now
67:03 - moved some of these uh neural networks
67:06 - into the other species based on
67:08 - the architecture of the internal neural
67:11 - network okay
67:12 - and continuing we come here we're seeing
67:14 - the fitness is increasing the average
67:15 - fitness goes up best fitness 68 and you
67:18 - will notice that sometimes you will go
67:19 - down so you'll hit a generation where
67:21 - your fitness will drop drastically
67:24 - that's fine that does happen and again
67:25 - that's because we're adding random
67:27 - mutations we're doing changes and it's
67:29 - not always guaranteed to give us a
67:31 - better neural network we just hope it's
67:33 - going to do that now here we're at
67:34 - stagnation of three in the config file i
67:37 - believe we had 20
67:39 - as the extinct stagnation so once that
67:41 - hits 20 if there's more than two species
67:44 - then it will actually make this species
67:45 - go extinct because it's not been
67:47 - improving over a period of time right so
67:50 - all this different kind of stuff lots to
67:51 - learn lots to look at i'm by no means a
67:54 - pro here but i have figured out how to
67:55 - make a few ais using neat so obviously
67:58 - the tutorial now this is running and
68:00 - you'll notice that we're going to get a
68:01 - lot of low scores right but once in a
68:02 - while you will see kind of a decent
68:04 - rally and
68:06 - it's difficult to really tell how well
68:08 - you're doing based on just watching this
68:09 - because you only need one ai to perform
68:12 - well
68:13 - to really get a good ai right to get a
68:15 - good result out of this and that ai will
68:17 - play against every other ai and since
68:20 - all the other ais are going to be really
68:21 - bad what's going to happen is this ai
68:24 - will hit the ball every time then it
68:25 - will never be returned and so will look
68:27 - like the rallies are always short but
68:29 - that's just because the opponent of the
68:30 - really good ai can't return the ball
68:32 - right so there's all kinds of stuff like
68:34 - that to think about and this took me a
68:35 - few days kind of messing around with to
68:37 - really understand so this is running
68:40 - we'll leave it running for now and while
68:42 - it's running
68:43 - let's just work on actually how we would
68:45 - test the ai and a change or two that we
68:47 - could make here and then what you can do
68:49 - is you can stop it we can rerun the code
68:52 - and then we can return from the
68:53 - checkpoint that we were just at so we
68:55 - don't have to redo all of the training
68:57 - that we already did right because you're
68:58 - going to notice it takes a long time
68:59 - like the average generation i think is
69:01 - about two or three minutes long okay
69:03 - so if we want to train the ai uh or
69:05 - sorry test the and not train it we have
69:07 - test ai and what we're going to take in
69:09 - here is a genome
69:11 - which will just be the best ai right and
69:13 - then from the genome we will create a
69:16 - neural network and then we'll use the
69:17 - neural network to move the ai so we're
69:19 - just going to say net is equal to
69:22 - and then actually we'll need
69:25 - the config as well
69:27 - so we'll say net is equal to neat dot nn
69:29 - for neural network
69:31 - dot
69:32 - feed forward network
69:36 - genome
69:37 - config
69:38 - okay and now that we have the network
69:41 - let's use it inside of here so we're
69:43 - moving the left paddle let's just have
69:45 - the ai move the right paddle and then
69:47 - that's really all we need here i mean
69:48 - there we could implement some way to end
69:50 - the game but i'm not even really going
69:51 - to do that in the test ai because if you
69:53 - want to end the game you can just click
69:54 - the x button right and here rather than
69:56 - drawing the number of hits we'll draw
69:58 - the score and then we'll actually see
69:59 - how the ai is playing against the human
70:02 - and you'll notice that the ai will be
70:03 - unbeatable based on the way that i've
70:04 - coded this pawn came out so let's go
70:07 - here and let's now move the paddle
70:09 - so really what i can do is simply copy
70:11 - output 2 in decision 2 here
70:14 - and just paste that right here
70:16 - now we can just make this output rather
70:18 - than you know decision
70:20 - and change a few of these values here
70:21 - and net 2 will just be net
70:23 - but this will be right panel
70:25 - and i think that will be good yeah
70:26 - that's really all we need and i mean i
70:28 - could get rid of this if decision equals
70:30 - zero pass i'm just putting it there so
70:31 - it's explicit and we know that zero
70:33 - means that we're staying still so now
70:35 - that we've done that we now actually
70:36 - have something that will test the um
70:39 - uh what do you call it here sorry that
70:41 - we'll test the ai for us what i want to
70:43 - do instead of drawing the
70:46 - score or sorry instead of drawing the
70:48 - hits though is i want to draw the score
70:50 - so i'm going to say true false
70:52 - so this means we're going to draw the
70:54 - score
70:55 - not draw the hits
70:56 - and that's what we want when we're
70:57 - actually testing the ai out okay so i
70:59 - think that's good for test ai
71:02 - we have train ai
71:04 - now what we really need is some way to
71:06 - save this best ai now we're not going to
71:08 - get this best ai for a while we need to
71:10 - get to a score of 400 right or 50
71:12 - generations and obviously i'm not going
71:13 - to sit here and just you know wait for
71:15 - all this to finish before recording the
71:17 - rest of the video so we'll let it run
71:19 - but what i will do is show you that we
71:20 - can use a module called pickle to
71:22 - actually save the
71:24 - object right to save this neural network
71:27 - and then we can load that neural network
71:28 - in so rather than having to retrain this
71:31 - every time we just load the neural
71:33 - network that's really good at doing what
71:34 - it does use the neural network and then
71:36 - we're good to go so i'm going to say
71:38 - import pickle here
71:40 - okay this is built into python so you
71:42 - don't need to install this
71:44 - and we're just going to go down to right
71:46 - where the winner is i'm going to say
71:47 - with open
71:49 - and i'm going to say best dot pickle
71:52 - i'm going to open this in wb mode which
71:54 - stands for write bytes i'm going to open
71:56 - this as f
71:57 - then i'm going to say
71:59 - pickle.dump and i'm going to dump the
72:01 - winner into the file f that's as easy as
72:05 - it is to actually save the neural
72:06 - network so this gives you the best
72:08 - genome sorry not the neural network
72:09 - gives you the best genome so we're going
72:11 - to dump the genome into this pickled
72:13 - file so what pickle allows us to do is
72:15 - actually save an entire python object so
72:17 - that's what we're doing here so we'll
72:19 - open that but then what i can do now is
72:21 - i can write another function i can say
72:22 - define
72:24 - test ai okay i can just take in my
72:26 - config and then here
72:28 - we'll just open the pickle file so we'll
72:30 - say with
72:31 - open best.pickle in rb mode as f now
72:35 - we're going to say the winner is equal
72:36 - to pickle dot and rather than dump we're
72:39 - going to say load and we're just going
72:41 - to load the file so now that we have the
72:43 - winner genome what i'll do is i will
72:46 - just call my game so i'll say
72:48 - game is equal to pong game
72:51 - and then i will pass to this a window so
72:53 - let's just copy the window that we made
72:55 - here
72:56 - okay
72:57 - so let's paste that there
73:00 - so we'll say pong game we'll pass
73:02 - window width
73:04 - height
73:05 - and then we'll say game
73:07 - dot test ai
73:08 - and we'll just pass the winner that's
73:10 - all we need that will run the game for
73:11 - us now we can test the ai so what i can
73:13 - do is i can just after i run my need
73:15 - algorithm i can say test ai
73:18 - i can pass my config and then if i have
73:21 - the best.pickle file so as soon as this
73:23 - training is done what i'll do is i'll
73:25 - comment this out and now i'll just test
73:27 - the ai right right so rather than
73:29 - running the need algorithm we just test
73:31 - the ai and then we'll be good to go
73:33 - okay hopefully that makes sense uh let's
73:36 - go here and okay we just got a funny one
73:39 - there where they were both kind of stuck
73:40 - at the top of the screen just hitting it
73:41 - back and forth but we should notice
73:43 - there's been some pretty decent progress
73:44 - like at least when i'm looking at this
73:46 - right now it looks like a lot of them
73:47 - are rallying this is something that will
73:48 - happen uh it just it's gonna happen the
73:51 - way that i've coded this out it's
73:52 - possible for it to kind of go in that
73:53 - way but since the ball comes off at a
73:56 - random angle
73:57 - it should be rare that that's going to
73:59 - occur
74:00 - and of course if you're playing against
74:01 - the ai then you would be able to hit the
74:03 - ball in a way where you kind of get it
74:04 - off
74:05 - and so the two ais i guess are just uh
74:07 - they don't want to move and they're both
74:09 - staying at the bottom of the screen
74:10 - anyways i'm not going to watch this i
74:12 - have been looking at this like all day
74:13 - before filming this tutorial i'm going
74:15 - to close this and i'm just going to
74:16 - change the fitness threshold to be very
74:19 - small
74:20 - and then i'm going to take whatever the
74:21 - best ai is that we have and show you how
74:23 - we test it
74:24 - even though it's not going to be as good
74:26 - as you can get right and then obviously
74:27 - you guys know you can just train this
74:29 - for longer you'll get a better ai and
74:31 - then you can test that ai but i don't
74:32 - want to wait because it's going to take
74:33 - a really long time right like the
74:34 - average generation time 139 seconds so
74:37 - let's close this
74:39 - now all of our work is not lost we still
74:40 - have checkpoint seven so now what i'm
74:42 - going to do is restore from checkpoint
74:44 - seven
74:45 - right if i wanted to okay so restore
74:47 - from checkpoint seven
74:48 - and i will just actually we're gonna
74:51 - have an issue here i'll talk about what
74:53 - the problem's gonna be in one second but
74:54 - if we restore from checkpoint seven we
74:55 - can just keep training and we'll start
74:57 - start where we stopped off now the issue
75:00 - here is that
75:02 - the configuration file if i make a
75:04 - change now after i already started
75:06 - training and i resume from a checkpoint
75:08 - it's not going to take effect so what i
75:09 - wanted to do is i wanted to just change
75:11 - the fitness to be like 200 or 100 and
75:14 - just wait until we got that which would
75:15 - be a lot faster but since it's not going
75:17 - to take effect any change i make here
75:19 - since we're resuming from a checkpoint
75:21 - what i will do is i'll just make it so
75:24 - that whatever the best ai is of
75:26 - the next generation that we run is the
75:28 - one that we get and the way i'm going to
75:29 - do that is i'm going to change this to
75:30 - just run one generation so we'll resume
75:33 - from checkpoint seven and then we'll
75:34 - resume and then we'll run one generation
75:36 - and whatever we get from that generation
75:38 - will pickle right and then it should
75:41 - test the ai excuse me my voice is
75:43 - starting to go here and then we should
75:44 - just be able to play against it
75:47 - okay so let's clear
75:49 - and let's run
75:50 - and we'll wait for the one generation to
75:52 - finish once that's done i'll be right
75:54 - back and then we'll see how the best ai
75:56 - holds up against me alright so i just
75:58 - finished running the generation you can
76:00 - see bestop pico has been saved now what
76:02 - i've done is i've just commented out run
76:04 - neat and now i have test ai and i just
76:06 - made a small fix here uh in game dot
76:08 - test ai i need to pass config as well so
76:11 - winner and config this code will all be
76:13 - available from the description as well
76:14 - so don't worry if
76:15 - you're missing some of the fixes and
76:17 - then inside of my test ai function here
76:20 - i need to fix a few things so wherever i
76:22 - have game i just need to put self before
76:24 - it because when i copied this in it
76:26 - wasn't in a class i didn't self and then
76:29 - here where i have decision i need to
76:31 - change this from output two to be output
76:33 - and then here where i have game loop
76:36 - this needs to be self and this needs to
76:38 - be self as well so really anywhere there
76:39 - was game just put a self before it and
76:41 - then this was a small fix add output to
76:42 - it need to be output uh anyways let's
76:44 - run this now and again we're just going
76:47 - to be
76:47 - testing the ai so we're just calling
76:49 - this function and it should open best up
76:51 - pickle now i have no idea how well the
76:54 - ai's going to perform because we only
76:55 - ran it for seven generations okay you
76:57 - can see so i missed it looks like it's
76:59 - getting close okay it actually hit the
77:00 - ball that time
77:01 - and it's kind of a bit jittery but let's
77:03 - see how it does okay nice so it's
77:04 - actually working uh slightly right now
77:06 - again we only ran for seven generations
77:09 - it kind of glitched on that one it was
77:10 - weird it looked like it was going then
77:11 - it stopped moving
77:13 - but um if you run this for more
77:14 - generations you will get a perfect ai
77:16 - and i have had many perfect ais when i
77:18 - was kind of testing this beforehand
77:20 - so yeah with that said
77:22 - i think i'm going to end the video here
77:24 - now this was a lot to record i don't
77:26 - know how long the video will end up
77:27 - being because i have to edit a ton of
77:28 - stuff out but it's only almost three
77:30 - hours of me recording this so if you
77:31 - guys appreciated this please do leave a
77:33 - like subscribe to the channel i
77:35 - understand it's a little bit all over
77:36 - the place but something like this is
77:38 - difficult to film because it's hard to
77:40 - know
77:41 - when to either over explain or
77:42 - underexplain something and what the
77:44 - general competence of the audience is
77:46 - going to be because this is a
77:47 - complicated thing requires neural
77:49 - networks machine learning artificial
77:51 - intelligence advanced python code so
77:54 - there's a lot that i could have
77:55 - explained i could have made this video a
77:56 - lot longer anyways love to hear your
77:58 - feedback on it in the comments down
77:59 - below again please like subscribe i look
78:01 - forward to seeing you guys in another
78:03 - youtube video
78:06 - [Music]
78:12 - you