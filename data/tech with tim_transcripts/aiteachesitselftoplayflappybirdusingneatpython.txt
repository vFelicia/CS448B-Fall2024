00:00 - hey guys and welcome back so in today's
00:02 - video I want to show you a project I've
00:03 - been working on for the past couple days
00:05 - which is an AI teaching itself how to
00:07 - play flappy bird now I know I'm
00:08 - definitely not the first person to make
00:10 - this and I've taken a lot of inspiration
00:11 - from other youtubers like code bullet
00:13 - and seeing their videos and how they've
00:15 - tried to do this I took this as a
00:17 - challenge for myself trying to do this
00:19 - without looking at any of their code and
00:20 - you guys are gonna see how it turned out
00:22 - today so right now you're witnessing the
00:24 - AI train itself on how to play the game
00:26 - of flappy bird now the way that this
00:28 - works is that it starts off completely
00:30 - random having absolutely no idea what to
00:32 - do and how the game email operates and
00:34 - after many generations of slowly
00:37 - learning and slowly getting better it
00:39 - finally picks up on patterns and figures
00:41 - out what it can do to progress further
00:43 - in the level now this uses something
00:45 - called a genetic algorithm and the exact
00:47 - genetic algorithm I use is called neat
00:48 - now that stands for neuro evolution of
00:51 - augmenting topologies and we're gonna
00:52 - get into all those details later in the
00:54 - video and talk about exactly how it
00:56 - works but essentially after a few
00:58 - generations the AI starts to get
01:00 - exponentially better until eventually it
01:02 - reaches a point where it can't be beat
01:04 - and it can beat the level infinitely and
01:06 - keep going without ever hitting a pipe
01:08 - now to me this is super fascinating so
01:10 - I'm just gonna play a few clips and let
01:12 - you guys witness how this actually works
01:15 - [Music]
01:33 - so after about 13 generations you can
01:36 - see we've got a pretty good AI and
01:38 - chances are that this guy will be able
01:39 - to make it through the level infinitely
01:41 - without ever hitting a pipe now how does
01:44 - this work and how are we able to train
01:46 - an AI so quickly well that's what I'm
01:48 - gonna talk about now I'm gonna start
01:50 - explaining how this whole algorithm and
01:51 - everything works oh and after about an
01:54 - hour of running this program this is
01:56 - what the AI was able to accomplish a
01:57 - score of upwards of a thousand and I
01:59 - just ended up terminating the program at
02:01 - that point now before we can start to
02:03 - understand how the neat algorithm works
02:05 - we need to talk about neural networks
02:07 - now neural networks come in what we call
02:09 - layers and the first layer to talk about
02:10 - here is the input layer now the input
02:13 - layer is what is the information to our
02:15 - network it's what the network actually
02:17 - knows and what it sees you can almost
02:19 - think of it as the eyes of the AI now
02:22 - let's look at the frame on the right
02:23 - side of our screen here based on this
02:25 - frame we need some way in some pieces of
02:27 - information that we can feed to our
02:29 - neural network so that it knows what's
02:30 - going on now for me the three pieces of
02:33 - information I thought would be valuable
02:34 - is the position of the bird and the
02:36 - position of the two pipes or actually
02:38 - the distance between the bird the top
02:40 - pipe and the distance between the bird
02:41 - and the bottom pipe this way our AI has
02:44 - some idea where it is in the level and
02:46 - where the next pipes are that are coming
02:47 - up now once we have this input
02:49 - information we need some way to
02:51 - transport it into an output and this is
02:53 - where the output layer comes in now each
02:55 - neural network has both one input layer
02:56 - and one output layer and this output
02:58 - layer is gonna tell our AI what to do in
03:00 - our case we need to know whether we're
03:02 - gonna jump or not so we'll use one
03:05 - output neuron to represent the decision
03:06 - of jumping or not jumping and this is
03:09 - how we're gonna get our output from the
03:11 - neural network what we're gonna do is
03:13 - we're gonna give some values to our
03:14 - input so to our input neurons whatever
03:16 - those values are that we've decided then
03:18 - they're gonna pass that value somehow
03:20 - which I'm gonna talk about in a second
03:22 - to this output neuron and depending on
03:23 - the value of this output neuron we're
03:25 - either gonna jump or not jump alright so
03:28 - how do we pass these values well this is
03:30 - where we use something called
03:31 - connections and weights
03:33 - so essentially you know this very basic
03:35 - example each of our input neurons are
03:37 - gonna be connected to our output neuron
03:39 - using one connection so these lines that
03:41 - just showed up on the screen and each of
03:43 - these connections have what's called
03:45 - a weight now a weight is simply a number
03:47 - that represents how strong or how weak
03:49 - this connection is and these are the
03:52 - numbers that we're going to tweak to
03:53 - make our AI better or I guess make it
03:56 - worse in some cases so what we're going
03:58 - to do when we pass our values to our
04:00 - input neurons so our bird Y the top of
04:02 - the pipe and the bottom of the pipe is
04:04 - we're going to feed those through our
04:07 - neural network this is why it's called a
04:09 - feed-forward neural network they're
04:11 - going to have a weight applied to them
04:13 - and then they're gonna be passed to our
04:14 - output neuron where some more things can
04:16 - happen so we're gonna take what's called
04:18 - a weighted sum now weighted sum means
04:20 - we're gonna take each weight and
04:21 - multiply it by its corresponding input
04:23 - value so on input neuron 1 which is
04:26 - gonna be our bird Y position we're gonna
04:27 - take whatever that weight value is and
04:29 - multiply it by bird Y then we're gonna
04:31 - add it to whatever the distance between
04:33 - our bird and our pipe is multiplied by
04:37 - the next weight and so on and you can
04:39 - see that showing up right now now once
04:42 - that happens and we get those values at
04:44 - our output neuron we're going to apply
04:45 - two more operations to it and the first
04:47 - operation is something called a bias
04:49 - we're actually gonna add what's called a
04:51 - bias now a bias is simply a number that
04:54 - is going to allow us to kind of tweak
04:56 - our neural network in another way you
04:57 - can almost think of it as a y-intercept
05:00 - on a very basic graph this will just
05:02 - allow us to kind of move our network up
05:04 - and down a little bit and just shift it
05:06 - into the right position so these weights
05:08 - don't quite do the trick this bias
05:09 - should hopefully help us kind of adjust
05:12 - the network and and make it in the right
05:14 - dimensional space and I want to go too
05:15 - complicated with the math here so knees
05:17 - we're going to add this bias to our
05:19 - weighted sum and now we're going to
05:22 - apply what we call an activation
05:24 - function to this whole thing
05:26 - now this activation function simply
05:29 - allows us to get our value for this
05:30 - output neuron between two set numbers
05:33 - and this is really useful because it
05:34 - allows us to check whether or not you
05:36 - know and it's this number or its closest
05:38 - to this number so we know whether to
05:40 - jump or not to jump and in this case I'm
05:42 - using an activation function called tan
05:44 - H now there's tons of other ones you
05:46 - have sigmoid you have rel u you have all
05:48 - other kinds of activation functions but
05:50 - the tan h function is gonna squish
05:52 - whatever this value is in between the
05:54 - value of negative
05:56 - one and one so this is what the tan age
05:58 - function looks like you can see that the
06:00 - larger negative the number the closest
06:02 - negative the closer to negative one it's
06:04 - gonna be and the larger positive the
06:06 - number the closer to one it's gonna be
06:08 - and anything in between is kind of gonna
06:10 - be squished in between negative one and
06:12 - one and maybe kind of close to zero and
06:14 - that's the way that tan age works so
06:16 - based on this I'm actually able to now
06:18 - feed some values to my neural network
06:21 - get that output neuron see what it is
06:23 - and then compare that to whatever
06:25 - criteria I want so in this case I'm
06:28 - gonna say if this neural network has an
06:30 - output value of greater than 0.5 I'm
06:33 - gonna jump otherwise I'm not gonna jump
06:35 - and that's exactly what I've done in the
06:36 - code here to get this bird to actually
06:39 - move and to create this AF now you're
06:41 - probably wondering how we come up with
06:42 - these weights and biases and the answer
06:44 - is we don't we let the computer do it
06:47 - for us now what I've decided to use to
06:50 - do this is an algorithm called neat now
06:52 - there's lots of other ways to do this
06:53 - for a neural network but for a game like
06:54 - flappy bird this makes a lot of sense
06:56 - and you're gonna understand why after I
06:57 - explain it neat stands for a neuro
06:59 - evolution of augmenting topologies and
07:02 - essentially it's inspired on natural
07:04 - selection and natural selection is kind
07:07 - of a process of generations continually
07:09 - learning and getting better and better
07:11 - and better until eventually they get as
07:13 - good as they can get now that's exactly
07:15 - what we do here with our flappy birds as
07:17 - you guys have already seen through some
07:19 - of the simulations we're gonna start
07:21 - with an observation and that observation
07:22 - is we have no idea what the correct
07:25 - number for the weights and biases of our
07:27 - bird should be there's no way to kind of
07:29 - figure that out without doing tons of
07:31 - different tests so what we do is you say
07:33 - okay we don't know so we'll start by
07:35 - creating a population of birds and this
07:37 - population is gonna start off completely
07:40 - random and each population is going to
07:42 - consist of will a bird and a neural
07:44 - network that controls that bird now this
07:46 - neural network is gonna start with
07:47 - random weights and random biases and
07:49 - what we're gonna do is we're going to
07:50 - test all of these neural networks on our
07:53 - level or on our game and see how well
07:55 - they do we're going to evaluate what we
07:57 - call their fitness now fitness is
07:59 - different depending on what game you're
08:01 - playing in flappy bird the way that we
08:03 - determine how well a bird did is how far
08:05 - it progressed in the level you can do
08:07 - that in a few different ways but I've
08:08 - decided to just say
08:09 - every frame it moves forward without
08:11 - dying or without losing it gets another
08:14 - point and that's gonna be its fitness
08:15 - score so what we're gonna do is at the
08:17 - end of the simulation when all of our
08:19 - birds have died we're gonna see which
08:21 - one's performed the best in this set of
08:23 - population we're going to take those
08:25 - birds a certain percentage of them and
08:27 - we're gonna breed them and mutate them
08:29 - to create a brand new population of a
08:31 - hundred new birds and we're gonna get
08:33 - rid of all of the other birds that did
08:34 - poorly so now what we have is we have
08:37 - some offspring from the best birds from
08:39 - the last generation and we hope that
08:41 - these birds are gonna perform better
08:44 - than the previous generation because
08:46 - they come from the best of that previous
08:48 - generation now if you're interested in
08:50 - learning how neat actually breeds and
08:52 - mutates these neural networks that I
08:55 - have left a link down below to the
08:56 - original neat paper it's worth noting
08:58 - that I'm oversimplifying almost
09:00 - everything here so if you're interested
09:02 - in learning more about the technical and
09:03 - specific details I definitely recommend
09:05 - you check that out now this has been a
09:07 - little bit of a different video than
09:08 - what I usually do and if you guys like
09:10 - this style of presentation and of
09:11 - teaching definitely let me know in the
09:13 - comments down below because I can start
09:14 - implementing it more into the channel
09:16 - now with that being said this video is
09:18 - taking a crazy amount of time to make so
09:19 - I'd really appreciate it that if you
09:21 - enjoyed it and if you learned a little
09:22 - bit you hit the like button down below
09:24 - and even subscribe to the channel if
09:25 - you're not already with that being said
09:27 - I post all kinds of Python videos and
09:29 - this entire project was actually
09:30 - programmed using Python I used a module
09:33 - called PI game and a pipe Python module
09:35 - called neat Python which is actually how
09:37 - I did all of this AI and if you go ahead
09:40 - and look at the code down below using my
09:41 - github link there you'll see that this
09:43 - is actually pretty simple to do in that
09:45 - it's not crazy complicated there's a few
09:47 - things you have to tweak and mess with
09:49 - and it was a bit of a learning curve for
09:50 - me but if you're interesting getting
09:52 - into AI and kind of seeing how this
09:54 - works I will probably be making a
09:55 - tutorial about this in the future so
09:57 - make sure you're subscribed and stay
09:58 - tuned for that so finally if you guys
10:00 - enjoyed the video please please please
10:02 - hit the thumbs up button down below it
10:04 - really helps me out and even just leave
10:05 - a comment and let me know what you most
10:07 - like to bet or what you want to see in
10:08 - the future on the channel so with that
10:10 - being said go follow my Twitter go
10:12 - follow my Instagram join the discord and
10:14 - I will see you guys in another video