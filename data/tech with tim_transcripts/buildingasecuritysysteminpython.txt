00:00 - broke
00:17 - [Music]
00:43 - so I'm starting this video on a bit more
00:45 - of a depressed note than usual and
00:47 - that's because as you guys would have
00:48 - just seen a few hours ago my house was
00:51 - broken into now fortunately I did have
00:53 - my security system running the one that
00:55 - I built myself using python just last
00:57 - weekend so I was able to actually get
00:59 - all the video footage of the person who
01:01 - broke it now I will say they were
01:03 - extremely attractive young white male
01:05 - about 5 10 ripped super handsome so if
01:08 - you guys know who that is please leave a
01:10 - comment down below I've already reported
01:12 - it to the police and to the insurance
01:13 - but I wanted to make this video so that
01:15 - you guys don't run into the same problem
01:17 - where you have an extremely good looking
01:18 - robber breaking into your house so if
01:21 - you guys want to learn how to build a
01:22 - security system in Python make sure you
01:25 - watch this video I'm gonna go through
01:26 - the architecture I'm going to talk about
01:27 - the code and of course I'll leave all of
01:29 - the links in the description so that you
01:31 - guys can avoid this situation or at
01:33 - least catch someone if they do break
01:35 - into your house just like they broke
01:36 - into mine alright guys so all jokes
01:38 - aside I want to share with you a really
01:40 - great project that you guys can work on
01:42 - extend or even build from scratch which
01:44 - is a python security system the idea
01:47 - here is just to give you a quick
01:48 - overview of how it works talk about the
01:50 - architecture and give you a really great
01:52 - project that you can work on and
01:53 - especially add to your resume this is
01:55 - one I've been wanting to build for a
01:57 - long time but never got around to so
01:59 - fortunately I had a weekend to spare and
02:01 - I kind of coded this out in a few hours
02:02 - set all the different things up and I
02:04 - want to give you a quick demo of how it
02:05 - works and then talk about the
02:07 - architecture and the layout so you guys
02:08 - can go and build this yourself I promise
02:10 - it's a great project looks really really
02:12 - good on a resume especially because it's
02:14 - a real world use case so in front of me
02:17 - you can see here that I have my security
02:18 - system admin panel now this is just a
02:21 - really simple user interface that shows
02:23 - all of the videos that were recorded by
02:25 - this camera setup now I'll dive a bit
02:27 - more into the architecture later but
02:28 - essentially I have my MacBook just
02:30 - sitting down kind of in my main floor
02:32 - and I have it hooked up to a webcam
02:34 - that's on a tripod and that's kind of
02:36 - running most of the software which is
02:37 - recording all of this video now this is
02:39 - just running on a local web server on a
02:41 - react server here where I'm able to
02:43 - preview all the the videos and you can
02:44 - see I can click into like a video like
02:46 - this where I was just testing it out and
02:48 - we can play the video and you can see me
02:49 - kind of waving to the camera we can go
02:51 - full screen exit out of here go back and
02:54 - then I have the ability to disarm or arm
02:56 - the camera uh so I can actually see
02:58 - what's going on now additionally I
03:00 - actually set up notifications on my
03:01 - phone using twilio twilio I don't know
03:04 - how you pronounce it but you'll see I'll
03:06 - put this up on the screen I have a bunch
03:08 - of text message notifications I get
03:10 - every single time motion is detected on
03:12 - the camera now what I did here
03:13 - specifically is I made it so it only
03:15 - detected person motion that's because I
03:18 - have a cat my cat runs around like crazy
03:20 - and I didn't want to get a million text
03:22 - messages when my cat was just running in
03:24 - front of the camera so I ran a really
03:26 - simple machine learning model uh in
03:28 - something called opencv which I'm going
03:30 - to talk about in a second which actually
03:31 - just detected for people in the frame
03:33 - and as soon as someone left the frame
03:35 - for a certain amount of time it kind of
03:36 - captured that recording uploaded that
03:38 - recording and then allowed me to view
03:40 - that from this panel here now I've set
03:42 - up a few other things where I can kind
03:43 - of go through through some different
03:44 - date ranges you can see here when I was
03:46 - just testing this out I have some videos
03:47 - and that's kind of it in terms of the
03:50 - interface and the demo for this system I
03:52 - know it seems pretty simple but this is
03:54 - really cool you can extend this and you
03:56 - can add different types of motion you
03:58 - can have other kinds of events emails
04:00 - multiple cameras at the same time
04:02 - anyways let me get into the architecture
04:04 - here and talk to you a bit more about
04:05 - how this works so the way I actually
04:07 - started this project was just by
04:08 - creating a few design documents and kind
04:11 - of planning out what I wanted to build
04:12 - whenever you're working on a larger
04:14 - project like this it's usually worth The
04:16 - Upfront investment maybe an hour two
04:18 - hours to actually create a few basic
04:20 - design documents so you know what you're
04:21 - going to be building the different
04:22 - components you're going to have and how
04:24 - they're going to interact with each
04:25 - other so you can see here that I made a
04:27 - basic system diagram I made a sequence
04:29 - diagram and I even did a really quick
04:31 - user interface wireframe now a lot of
04:34 - you guys ask me how I build these
04:35 - documents and the tool that I use is
04:37 - actually called Miro now Miro is the
04:39 - sponsor of this video but it's
04:41 - completely free to use and it's a
04:43 - digital workspace where you can actually
04:44 - collaboratively work on different
04:46 - documentation for your various projects
04:48 - I use them personally just for system
04:50 - designs sequence diagrams all the stuff
04:52 - I just showed you but you can use it for
04:54 - practically anything and you can kind of
04:56 - connect with teammates so I've actually
04:57 - used this with my Discord team a few
04:59 - times and we're planning out some
05:00 - different projects we were going to work
05:02 - on anyways you guys can check them out
05:03 - from the link in the description but for
05:05 - now let me just show you the kind of
05:07 - diagrams I created using that tool for
05:09 - this project so you can see here that I
05:12 - wanted to just start by figuring out
05:13 - what different components we were going
05:15 - to have here so what I wanted to have
05:17 - originally was a Raspberry Pi or some
05:19 - kind of remote computer that wasn't my
05:21 - home machine here my big desktop I ended
05:23 - up just using my Mac because it was a
05:25 - little bit easier but originally it was
05:26 - going to be a Raspberry Pi I wanted to
05:28 - have a camera on that Raspberry Pi such
05:30 - as the webcam and then some person
05:32 - person detection sorry model right so
05:34 - some machine learning model that would
05:36 - actually detect if a person was run now
05:38 - for this I wanted to use Python so I
05:39 - kind of just put that in a little box
05:40 - now that was going to be connected to a
05:43 - flask API and this flask API I wanted to
05:46 - run on the actual kind of physical
05:48 - Hardware device so whatever was running
05:50 - the camera which in this case is kind of
05:52 - the Raspberry Pi anyways the flask API
05:54 - was going to be the main interface
05:56 - between the user interface notifications
05:58 - the cloud storage and all of that kind
06:00 - of stuff so I kind of put that in the
06:01 - middle here and then you can see that I
06:03 - have a Google Cloud object storage now
06:05 - this is where I wanted to actually store
06:07 - all of my videos so I ended up creating
06:09 - a bucket in Google cloud and that's
06:11 - where I dumped all the different video
06:12 - files so essentially the flask API is
06:15 - responsible for arming and disarming the
06:17 - camera saving and retrieving all of the
06:19 - videos and getting information about the
06:21 - video metadata which I'll show you in
06:23 - the sequence diagram in just a second
06:24 - Beyond there we have a user interface I
06:27 - wanted to build this in react with
06:28 - JavaScript so I kind of put those two
06:30 - little icons there and this would
06:31 - connect to the flask API and then that's
06:33 - how we would get the different URLs of
06:35 - the videos and control the camera right
06:37 - so arming it disarming it all of that's
06:39 - happening through this API lastly I
06:41 - wanted to have a notification system so
06:43 - whenever someone went in for another
06:44 - camera it would send me a text message
06:46 - so to do that I used twilio or yeah
06:49 - twilio I think that's how you say it and
06:50 - that's kind of connected to the API so
06:52 - whenever motion is detected from the
06:54 - camera goes to the API stores it in
06:56 - Google Cloud Storage notifies myself and
06:58 - then updates the UI and kind of shows
07:00 - the new video that was there so that's
07:02 - the whole system you can see that we
07:04 - have a few different components going on
07:05 - and it's a good idea even if it looks
07:07 - kind of rough and sketchy like mine does
07:09 - to just plan that out and see how those
07:11 - components are going to interact with
07:12 - each other so beyond that I have a
07:14 - sequence diagram now I'll dive into the
07:16 - code and show this to you guys in a
07:18 - second but you can see this is actually
07:19 - how all of the different systems are
07:21 - going to interact with each other in a
07:23 - specific order if you did any type of
07:25 - computer science degree you've probably
07:26 - seen a diagram like this before but it's
07:29 - really good for visualizing kind of
07:30 - what's going on and what is controlling
07:33 - what right so in this case we have UI
07:35 - our user interface so from the user
07:37 - interface we have really three main
07:38 - things we can do we can arm the camera
07:40 - disarm the camera view the video and
07:43 - that's pretty much it right so from the
07:45 - UI we send the armed command now we send
07:48 - that to the API and what the API does is
07:51 - then go and control the camera so
07:53 - whatever software is running the camera
07:54 - it starts the camera camera starts
07:56 - running and then at some point a person
07:58 - is detected in the camera frame some
08:00 - machine learning model going on there as
08:02 - soon as the person motion is detected it
08:04 - notifies the API the API then goes and
08:07 - saves the video in the Google cloud
08:09 - storage and then that storage is going
08:11 - to return the video metadata now from
08:13 - there we could use that data if we
08:15 - wanted to but this kind of little dotted
08:17 - line is just indicating hey something is
08:18 - coming back from the request or the call
08:20 - that you make so next once we get the
08:23 - video metadata or the URL then what we
08:25 - do is we send a notification so using
08:28 - the notification service which is twilio
08:30 - and then that returns to us the
08:31 - notification is set so at that point I
08:33 - could have added another little box
08:34 - saying user receives notification but
08:37 - you get the idea okay so that kind of
08:39 - just goes infinitely right that will
08:41 - continue to happen every time a new
08:43 - person is detected from there we have
08:45 - the disarm command now once the disarm
08:47 - command is ran that means we're going to
08:49 - stop running the camera or release that
08:50 - resource and then that's pretty much it
08:52 - for the camera until we decide to arm it
08:54 - again lastly from the UI we can view the
08:57 - video when we want to view the video we
08:58 - go to the API the API then retrieves any
09:01 - of the videos or video that we want to
09:03 - view returns that data and then returns
09:05 - that back to the user interface so
09:07 - hopefully you can see how this would be
09:08 - a helpful type of diagram but this is
09:10 - what I started with so I knew kind of
09:12 - the flow of my different commands and
09:14 - how the systems would interact with each
09:16 - other alright so lastly after that I did
09:18 - the user interface wireframe now I just
09:20 - spun this up so I had some idea what I
09:22 - wanted to actually create I didn't do
09:24 - the exact replica of this on the actual
09:27 - user interface that I built but you can
09:29 - see that I wanted to have some kind of
09:30 - title the ability to arm and disarm and
09:33 - then just show the different Logs with
09:34 - kind of a little thumbnail image and the
09:36 - ability to go between the different
09:37 - dates or the different pages of videos
09:39 - and then I wanted one other page here
09:41 - just as like a Details page to view the
09:43 - information about one individual video
09:45 - so there you go that is my design
09:46 - documentation now I'm going to get into
09:49 - the actual code here but I just want to
09:51 - show you kind of how I built this in
09:52 - Miro because a lot of you guys ask about
09:54 - this again it's completely free and it's
09:56 - super easy to kind of create the
09:57 - different components alright so I just
09:59 - signed into my mirror account here and
10:00 - you can see if I go to something like my
10:02 - sequence diagram here I will kind of pop
10:04 - this up which I actually just exported
10:06 - as a PDF now from here you can just grab
10:09 - the different components right I could
10:10 - copy and paste them and kind of move
10:11 - them around or I can just use some of
10:13 - the different components from their
10:15 - Library so what I actually did for this
10:16 - is I went over to shapes I went to all
10:21 - shapes and then you see that we have a
10:22 - few different options right it's got
10:23 - basic shapes flow chart call outs you
10:25 - can also go to more shapes and then you
10:27 - can select all the different ones you
10:29 - want now for most of you you're probably
10:30 - going to be interested in the uml uh
10:32 - shapes which are some of the ones that I
10:33 - used or things like data flow but you
10:36 - can see there's stuff related to Azure
10:37 - Cisco so this is kind of um what do you
10:40 - call it made in a way such that if
10:42 - you're a developer you're going to have
10:43 - access to a lot of pre-built components
10:45 - here to make it a lot easier to diagram
10:47 - your stuff out so I don't think I really
10:48 - need to show you much more than that but
10:50 - the point is that it's super easy to
10:52 - just go in here kind of drag all of the
10:54 - different components that you need need
10:55 - you can just make arrows and move them
10:57 - around and I found it pretty simple to
10:59 - set up the diagrams hence why I use this
11:01 - tool all right so now let's spend a few
11:03 - minutes diving into the code if you guys
11:05 - want this will be available in the link
11:06 - in the description from GitHub now
11:08 - there's a few things that you need to
11:09 - set up here if you want this to work
11:11 - which I'll explain here but if you just
11:13 - want the code and you want to search
11:14 - through yourself then just go to the
11:15 - link in the description you'll find the
11:16 - GitHub page so first of all we have a
11:19 - react front end I'm not going to really
11:20 - run through that front end there all
11:22 - I'll mention is that I just have a few
11:25 - different API calls that are happening
11:26 - from the front end so you can see I've
11:27 - just linked up the IP address of my kind
11:30 - of local server which is just running on
11:32 - my local network so this is the local IP
11:34 - address of my Mac which is running the
11:35 - camera and the API you can see that I
11:37 - start by just getting the status of the
11:39 - camera so if it's armed or not and then
11:41 - I have this kind of little fetch command
11:43 - here which will get me the videos within
11:45 - a certain day so from one day to another
11:47 - day that's how I set it up and then
11:49 - lastly I just have two little commands
11:51 - here two little endpoints disarm and arm
11:53 - two arm and disarm the camera and that's
11:55 - all that's really happening from the
11:57 - front end right interacting with that
11:58 - back end API so that's it for the front
12:00 - end in terms of the back end here I have
12:02 - my flask server super straightforward
12:04 - you can see I have my arm endpoint
12:06 - disarm get armed motion detected and
12:09 - then get logs now motion detected is
12:11 - what's going to be called from the
12:13 - actual camera thread and I'll talk about
12:15 - the threads in one second which will
12:17 - then send the notification to my phone
12:19 - saying hey someone was detected at the
12:22 - front door whatever the camera is that
12:24 - you want to name this okay and then get
12:26 - logs that's just gonna get the um what
12:28 - do you call it kind of different logs or
12:30 - videos sorry from the Google Cloud
12:33 - Storage now in order to separate things
12:35 - out here I created a notification script
12:37 - so this is just simply sending a
12:39 - notification to my text message I've got
12:41 - all this stuff set up in environment
12:42 - variables to my text message to my phone
12:45 - number sorry I've got storage here what
12:47 - storage is doing is uploading to the
12:49 - Google cloud storage and then it is
12:52 - getting all of the videos from the cloud
12:53 - storage within a certain date range so
12:55 - that's something you can do and then
12:57 - what I did here is I just set up some
12:59 - things that I actually encode the video
13:01 - before I upload it to Google Cloud using
13:03 - this ffmpj or whatever you call that
13:06 - simply so that I have the video in a
13:09 - format that the web browser can
13:11 - understand because by default the opencv
13:13 - recording format which is what I'm using
13:15 - for the camera it doesn't actually show
13:17 - up in a preview so I was getting some
13:18 - issues with that so I just had to
13:19 - actually use the software to encode or
13:22 - kind of transcode the video remove the
13:24 - old video get the new transcoded video
13:26 - and then upload that to Google Cloud
13:29 - not sure if that makes sense to you or
13:31 - not but after all of this is done now
13:33 - what I do is I send a request to the API
13:36 - that just says hey this is finished this
13:38 - is the URL of the video and the reason I
13:40 - need to do it that way is that I run all
13:42 - of this stuff in a separate thread and
13:45 - it needs to be in a separate thread
13:46 - because while this is running and
13:47 - uploading the video to Google Cloud I
13:49 - want my camera to still be working
13:51 - properly and be able to record video and
13:54 - detect people while I'm uploading
13:55 - potentially a very long video so what
13:57 - kind of happens is from the camera when
13:59 - motion is detected it then goes and does
14:01 - all of this kind of storage stuff here
14:03 - where it's handling the detection it
14:05 - then sends the request when it's
14:07 - finished back to the API and says hey
14:09 - we've just finished doing all of that
14:10 - and then it sends the notification and
14:12 - goes from there not sure if that makes
14:14 - sense or not but that's kind of what's
14:16 - going on here inside of storage lastly
14:18 - we have camera now this is where most of
14:21 - the complicated code is what I'm doing
14:23 - is I'm reading in a pre-trained model
14:25 - which simply detects a person I am then
14:28 - getting access to the camera so whatever
14:30 - the default camera device is in this
14:32 - case it would just be using your webcam
14:34 - you could also set up to use a external
14:36 - camera if you had that set up now inside
14:38 - of here we just have two methods arm and
14:40 - disarm which is what's being called by
14:42 - the API and again everything that you're
14:44 - running here needs to be inside of a
14:45 - separate thread so that your API can be
14:48 - handling any type of request that it's
14:49 - received while the camera is running in
14:51 - a completely separate thread and that's
14:53 - why we have that kind of communication
14:55 - with the API from the camera thread so
14:58 - that we can have data transmitting
15:00 - between the different threads without
15:02 - any complicated locks which I didn't
15:03 - want to set up this is a little bit
15:05 - Advanced if you're a complete beginner
15:07 - this might not make a ton of sense but
15:09 - what I'm doing is running every
15:10 - individual operation that is blocking in
15:13 - a separate thread so that we don't have
15:15 - the two threads conflicting with each
15:17 - other and while we're say uploading a
15:19 - video to Google we can't be recording
15:21 - someone on the camera or while we are
15:23 - recording we can't be receiving a new
15:25 - request from our API so we need to make
15:27 - sure we have these in separate threads
15:28 - so assume as we arm the camera assuming
15:31 - it's not already armed then we're going
15:32 - to create a new thread and run the
15:34 - camera thread otherwise we just dispose
15:36 - of the camera thread which happens right
15:38 - here inside of disarm so inside of run
15:40 - we have a few basic variables right if
15:42 - we've detected a person non-detected
15:44 - counter this is just so that we will
15:46 - keep recording even if the person steps
15:48 - in and out of the frame for a few
15:49 - seconds
15:50 - then we get access to the camera okay
15:52 - and we kind of go through here and we
15:55 - get access to the current frame from the
15:57 - camera we then use that frame to detect
16:00 - if a person is there so this is kind of
16:02 - detecting all the people that are inside
16:03 - of the frame and then drawing a box
16:05 - around them we're then saying if we've
16:07 - detected a person what we're going to do
16:10 - is start recording a video so we're
16:12 - going to actually take whatever this
16:13 - current frame is and we're going to save
16:14 - that into a video file and then as soon
16:17 - as we're no longer detecting a person
16:18 - what we're going to do is take that
16:20 - video and we're going to upload that to
16:22 - Google Cloud which is what happens here
16:24 - in the handle detection that's pretty
16:26 - much it but as soon as someone is
16:27 - detected we start saving a video locally
16:30 - on the computer then we upload that
16:32 - video to Google Cloud deleted from the
16:34 - computer and just continue the rest of
16:36 - the process so that is it for the back
16:39 - end I was gonna say if you do want to
16:41 - set this up then you need to create a
16:42 - credentials.json file with your Google
16:44 - Cloud project where you have a Google
16:47 - storage bucket created and you also need
16:49 - to go into this EnV file rename it to
16:52 - dot EnV and need to put in all of your
16:54 - twilio information to be able to send
16:56 - the notification that's about it
16:58 - everything else is in the readme file
17:00 - and I think with that said I'm going to
17:02 - wrap up the video here the point of this
17:04 - video is just to demonstrate a cool
17:06 - project that you guys can work on extend
17:08 - and build this is something I had a lot
17:10 - of fun making I think it's really cool
17:12 - it's actually useful if I wanted to
17:13 - leave this running 24 7 and I think it
17:16 - looks really great on a resume because
17:17 - it is a more unique project something
17:19 - that not everyone's building and that
17:21 - you legitimately could have a real use
17:23 - case for for example I was going to set
17:25 - this up near my cat feeder and I was
17:26 - going to record every time my cat went
17:28 - and got food and kind of track its
17:30 - eating schedule so that would have been
17:31 - another cool variation of this but I
17:33 - didn't want to wait the days and days to
17:34 - kind of accumulate all of that
17:36 - information anyways if you guys enjoyed
17:37 - make sure to leave a like subscribe to
17:39 - the channel and I will see you in
17:41 - another one remember to check out Miro
17:42 - the sponsor of this video if you want to
17:44 - create those design documents just like
17:46 - I did for this project
17:48 - [Music]