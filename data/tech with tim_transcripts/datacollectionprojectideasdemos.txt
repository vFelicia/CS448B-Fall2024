00:02 - [Music]
00:08 - in this video i'll share with you some
00:10 - cool and interesting web scraping and
00:12 - data collection project ideas now this
00:15 - video is meant to act as inspiration you
00:17 - may not build out all of the projects
00:19 - that i mentioned here but hopefully it
00:20 - gives you an idea for something that you
00:22 - could make or at minimum motivates you
00:24 - to go out there and work on some coding
00:26 - project now all the ideas that i have
00:28 - here are related to getting data in some
00:31 - format mostly scraping it from a website
00:33 - say like airbnb or a realtor website or
00:36 - something along those lines and in this
00:38 - video i'll actually show you a few
00:40 - simple demos of projects that i've built
00:42 - out that kind of fit the theme or the
00:44 - idea that i'm sharing with you so the
00:46 - last thing i'll mention here before we
00:47 - get into the ideas is that these ideas
00:50 - are language agnostic so you can really
00:52 - create these projects in any language
00:54 - technology framework that you like and
00:56 - specifically here i've done so in
00:58 - javascript using react and then i've
01:00 - just written some basic python scripts
01:02 - that actually output a graph or give us
01:04 - some data kind of in the console now all
01:06 - of the data that i'm getting for these
01:08 - projects is coming from a service called
01:10 - bright data so what i've done is i've
01:12 - set up some data collectors and these
01:14 - are things that will run directly on the
01:16 - bright data platform and then i'm able
01:18 - to access the data from these collectors
01:20 - from an api read them into my program
01:23 - and then use the data however i please
01:25 - now bright data has actually been kind
01:27 - enough to sponsor this video and we'll
01:28 - talk more about that later alright so
01:30 - let's go ahead and get started with
01:32 - project idea number one now this project
01:35 - has to do with travel and specifically
01:37 - accommodations so finding where you're
01:39 - gonna stay when you travel to some city
01:41 - or some destination for a certain period
01:43 - of time so i'll show you a demo in a
01:45 - second but the general idea here would
01:47 - be to make some type of application that
01:49 - allows you to put in some filters or
01:51 - criteria it's like a maximum price a
01:54 - number of nights that you're staying
01:56 - when you're checking in number of guests
01:58 - you're going to have with you the
01:59 - location obviously you're going to be
02:00 - traveling to and then have this site go
02:03 - and search or not this site have this
02:04 - application go and search multiple
02:07 - travel websites like booking.com airbnb
02:10 - expedia wherever else you'd look for
02:12 - hotels or accommodations find all of the
02:14 - results on those sites that match your
02:16 - criteria and then aggregate all of those
02:18 - in one place where you can look at them
02:20 - and sort them by price reviews go and
02:23 - click the link etc so let me show you a
02:25 - quick demo here of what i mean and what
02:27 - i've built out now this is a very simple
02:29 - slim bare bone version of what i
02:31 - described this only searches one website
02:34 - because i didn't want to spend a ton of
02:35 - time building this out i built a few of
02:37 - these projects for this video uh but
02:39 - what this does is look on airbnb for any
02:41 - listings that match the criteria of
02:43 - number of guests check-in checkout and
02:46 - the location and then aggregates them
02:48 - puts them all on one page with their
02:50 - title a little description the price for
02:52 - the total uh amount of the stay and then
02:55 - gives you a button here where you can
02:56 - actually view the listing and go in and
02:58 - see if it's right for you so again very
03:00 - simple you could obviously make this a
03:01 - lot more complicated but this is a quick
03:03 - demo right i can view the different
03:05 - listings on airbnb and it's showing them
03:07 - to me all on one page of course i can
03:09 - add booking.com i can add expedia and i
03:12 - can search anywhere else i want from now
03:13 - i'm just doing airbnb sorry so here i'm
03:16 - looking in toronto
03:17 - but if we want we can change this to say
03:19 - seattle let's say we want to check in
03:21 - maybe april 20th and we want to check
03:23 - out
03:24 - let's go april 27 so for a full week
03:26 - let's search this is going to take a
03:28 - second once it's done i'll be right back
03:30 - and then i'll describe to you how i
03:31 - actually collected this data all right
03:33 - so there we go we can see the data has
03:35 - loaded now the prices are a bit off just
03:37 - because i think i've kind of sliced
03:38 - these incorrectly uh this is really
03:41 - 1270 dollars obviously not 1.27 cents
03:45 - the the dot is kind of like a comma
03:47 - right but if i click in to this one here
03:49 - you can see we have our entire unit
03:51 - entire condo hosted by david it is one
03:54 - thousand two hundred and seventy dollars
03:56 - in total right as i was saying
03:58 - so there you go we can scroll down see
04:00 - all the other results that we have and
04:02 - if we had multiple websites of course we
04:04 - could say you know what website they
04:05 - were from so on and so forth anyways i
04:07 - want to show you how i'm actually
04:08 - getting this data because it is
04:10 - interesting how i'm grabbing this you
04:12 - can do this in many different ways but
04:14 - as i said i am using bright data and i'm
04:16 - using something called a data collector
04:18 - from bright data so these data
04:20 - collectors are really just tools that
04:22 - are hosted by bright data and they allow
04:24 - you to send them inputs so you can
04:26 - specify the inputs yourself or if it's a
04:27 - pre-built collector they'll just have
04:29 - some inputs you can use it will then go
04:31 - actually do the web scraping based on
04:33 - your inputs grab all of the data from
04:36 - the website or websites if you're doing
04:38 - multiple uh it will then send that data
04:40 - to you in whatever format you want so we
04:42 - can send it to an api endpoint you have
04:44 - using a web hook you can download a json
04:46 - file csv file really whatever you want
04:49 - however if you want to use these data
04:51 - collectors you do need to sign up for an
04:53 - account with bright data you can do that
04:55 - for free by clicking the link in the
04:56 - description and if you want some credit
04:58 - on your account just book a really quick
05:00 - demo it's like a few minute meeting with
05:02 - someone where you go through some
05:03 - compliance and kind of learn about the
05:04 - platform and then they'll give you 25
05:06 - dollars in free credit uh towards your
05:08 - bright data account which is more than
05:09 - enough to mess around with the
05:10 - collectors
05:12 - lastly if you don't want to use this in
05:13 - more of a business setting you're going
05:15 - to be downloading all kinds of data
05:17 - doing a bunch of web scraping you may
05:19 - want to actually make a deposit if you
05:21 - do that so you put your own money into
05:22 - this platform bright data will match
05:24 - that up to 250
05:26 - so totally up to you guys obviously it
05:28 - is cool i haven't paid any money for
05:30 - this i've been using it and now let me
05:32 - just give you a quick view at what the
05:34 - collector looks like so you can see if
05:36 - this is of interest to you or not so
05:38 - here i'm on bright data i just i'm going
05:40 - to go to data collecting platform you
05:42 - have data sets collectors i'm going to
05:44 - click on collectors uh i can close this
05:46 - and i have a few different collectors
05:48 - i've been working with here so one for
05:49 - youtube one for real estate data and
05:51 - then my airbnb one ignore the names this
05:54 - isn't really what i probably should name
05:55 - them but here if i click on this you can
05:57 - see my success rate average duration all
06:00 - of this kind of stuff and if i go in
06:01 - here and go to advanced actions i can
06:05 - actually edit the code so this is a
06:06 - custom web scraper that i wrote that
06:09 - goes to airbnb.com and it grabs me the
06:12 - descriptions the images the total prices
06:14 - and the titles from that website so i
06:16 - can preview that by clicking this link
06:18 - and then it will go and grab the data
06:20 - takes a second so we don't necessarily
06:22 - have to look through all of this but
06:23 - what's interesting is if i go back here
06:25 - i can actually click here and i can
06:27 - start this by an api call or i can start
06:30 - it manually so i can run this in
06:31 - multiple ways like i can just run it
06:33 - from the website and see the results or
06:35 - i can go to initiate by api and then i
06:37 - have an api call that i can do where i
06:40 - send an api token obviously i'm not
06:42 - going to leak that to you guys and then
06:43 - it will return my data in whatever way i
06:46 - set up so if i go back here to
06:47 - collectors i go to airbnb and i go to my
06:50 - delivery preferences
06:52 - you can see that i want my data in json
06:54 - format and i want it from a web hook so
06:56 - i put in where i want this to be sent
06:58 - and then once the data is collected it
07:00 - sends that to the web hook so to quickly
07:03 - summarize how this works here i set up a
07:05 - data collector on bright data set up my
07:07 - inputs i then trigger this collector to
07:09 - start running by an api call so i do
07:12 - that from my back end then once the data
07:15 - is finished being collected it sends
07:17 - that data to this url which is just the
07:19 - back end of my application
07:21 - in a json format i then take that data
07:24 - and display it on the front so that's
07:26 - what's going on i'll lastly just show
07:28 - you here if we go to collectors and i
07:30 - try to make a new collector there's a
07:31 - bunch of pre-built ones you don't have
07:33 - to make one like i did but you can if
07:35 - you want to for like youtube walmart
07:37 - twitter tick tock instagram so on and so
07:40 - forth so obviously this is great there's
07:41 - a bunch of pre-built options here you
07:43 - can customize these pre-built options or
07:45 - alternatively if you want to make one
07:47 - from scratch you can code it from
07:49 - scratch or you can use the bright data
07:50 - chrome extension so if i go to a site
07:53 - say like walmart so just go to walmart
07:54 - here
07:55 - and go to the site okay hopefully it's
07:57 - going to load properly you can see my
07:59 - bright data extension opens up just
08:00 - because i have it loaded i can close it
08:02 - over here just a chrome extension and
08:04 - from here what i can do is select stuff
08:06 - that i want to be scraped from this
08:08 - website so if i want to scrape like all
08:10 - these images for example i select them i
08:12 - can go to multi and hit collect and then
08:15 - say okay i want to grab all these
08:16 - different images and then it will create
08:18 - a field over here with all of the images
08:20 - that i have and i can view the json
08:22 - which would give me the urls to all of
08:24 - these images so really easy to pick the
08:26 - different data that you want and
08:27 - obviously you can choose it in a dynamic
08:29 - way sorry so if you were looking at like
08:31 - a search page or results then you'd grab
08:34 - like the top 10 results or all of the
08:36 - titles or all of the prices really
08:38 - whatever data it is that you want
08:40 - anyways that's all i have for you for
08:41 - bright data i just wanted to demo how
08:43 - i'm getting the data here because that's
08:45 - not really obvious in a lot of the
08:46 - projects obviously you don't have to use
08:48 - this there's all kinds of other ways to
08:50 - do this however if you are going to be
08:51 - scraping large amounts of data this is
08:54 - one of the more efficient ways to go
08:55 - about it and these tools are just really
08:57 - easy to use so if you want to check them
08:58 - out link in the description that said
09:00 - though let's go to idea number two so
09:02 - moving on the next project idea i have
09:04 - has to do with real estate now there's
09:06 - all kinds of things you can do with real
09:08 - estate data obviously real estate is
09:10 - very hot right now at least where i live
09:12 - in canada the market is absolutely
09:14 - absurd and people are just buying
09:16 - properties uh like there's no tomorrow
09:18 - even though the price is drastically
09:20 - increasing anyways in terms of some
09:22 - specific ideas here within real estate
09:24 - of course you're going to be grabbing a
09:25 - bunch of data you could grab data about
09:27 - a specific property you could grab data
09:29 - about a specific area or kind of general
09:32 - geographic region maybe you do something
09:35 - like set up a profile or kind of a
09:37 - filtering criteria for your ideal
09:39 - property and then scrape a bunch of
09:41 - different websites and return to
09:42 - yourself results that match that
09:44 - criteria maybe your investor you're
09:46 - looking for something that's a certain
09:47 - size certain area certain price again
09:50 - you could kind of plug all that stuff in
09:52 - and then find a property that matches
09:54 - that again i know this stuff exists you
09:56 - can find websites that do this for you
09:58 - but you guys are programmers you're
09:59 - looking for programming ideas related to
10:01 - web scraping and that's what i have for
10:03 - you now of course if you were a business
10:04 - it would definitely be useful to have a
10:06 - ton of real estate data that you could
10:08 - look through train machine learning
10:09 - models on all of that kind of stuff and
10:12 - well you can scrape that grab that data
10:14 - and use it now what i've done here for
10:16 - this demo is quite simple all i've done
10:18 - is looked at the information about a
10:20 - single property so the web scraper or
10:23 - kind of collector that i'm using for
10:24 - bright data allows me to send an
10:26 - unlimited number of addresses and then
10:28 - goes looks at all of those addresses and
10:30 - grabs all of the data about those
10:32 - properties and returns that to me now
10:35 - what i'm doing specifically here is i'm
10:37 - looking at the estimated value of a
10:39 - single property over five years and then
10:41 - graphing that so we can have a look at
10:44 - so kind of just a random idea i guess i
10:46 - came up with related to real estate but
10:47 - if i run the demo that i have here
10:50 - you can see that it gives me the chart
10:52 - of the estimated value or price of a
10:55 - property over the last five years now
10:58 - first of all this is kind of just
10:59 - shocking right when you look at a
11:00 - five-year chart of real estate almost
11:02 - everything at least where i live canada
11:04 - even in kind of u.s is up by at least a
11:06 - hundred percent uh kind of wild that in
11:08 - 2017 something to be worth 140 grand and
11:11 - now it's close to 300 thousand dollars
11:14 - anyways just a basic matplotlib program
11:16 - i set up here to make this graph if
11:18 - there was multiple properties that i was
11:20 - searching for then it would graph all of
11:21 - those but i just have one right now
11:23 - because that's the simplest and if i go
11:25 - to my data.json file which is all of the
11:27 - data about this property you can see
11:29 - that i'm getting all this stuff uh like
11:31 - we get rent estimation the estimate uh
11:34 - five year history of the value of the
11:36 - property which is what i'm graphing the
11:37 - size and square footage number of
11:39 - bedrooms bathrooms address a current
11:41 - value symbol right like all this data
11:45 - and of course you guys can find
11:46 - something meaningful to do with that so
11:48 - that was kind of project idea number two
11:50 - something related to real estate grab
11:52 - some housing prices grab the average
11:54 - prices do some type of graph have some
11:56 - user interface for it or really just
11:58 - send yourself links maybe an email with
12:00 - properties that are going to be
12:01 - appealing to you and again you can run
12:03 - this scraper every four hours every one
12:06 - day every week however you'd like to do
12:08 - it and yeah there you go that is my
12:10 - project idea number two all right so now
12:12 - we're moving on to project idea number
12:14 - three now this one has to do with
12:16 - youtube channels but let me get a bit
12:18 - more specific here and give you some
12:19 - context so i have a programming course
12:21 - called programmingexpert.io check it out
12:23 - from the link in the description anyways
12:25 - for that course we do paid uh marketing
12:28 - advertising we target specific youtube
12:30 - channels specific uh keywords on google
12:33 - whatever you do for like a traditional
12:34 - marketing campaign we do that for
12:36 - programming expert as well now we have
12:38 - channels that we know that we would
12:39 - target right like my channel there's
12:40 - probably ads on it for programming
12:42 - expert however there's other channels on
12:45 - youtube that would meet kind of a
12:46 - general criteria that we just don't know
12:48 - about so i thought it would be a cool
12:49 - idea to kind of come up with a program
12:52 - that would search youtube for channels
12:54 - that met a specific criteria i'll tell
12:56 - you what the criteria is i guess in a
12:58 - second or how we kind of specify that
13:00 - and then give us a list of all of those
13:02 - channels as well as information about
13:04 - the channel like when it was started
13:06 - number of views number of videos a
13:08 - number of subscribers all of that kind
13:10 - of stuff so to give you a general sense
13:12 - of what i'm talking about here uh the
13:14 - program essentially what it does is it
13:16 - goes to youtube now let me just open up
13:19 - a tab here that has youtube so it goes
13:21 - to youtube it searches in some terms so
13:23 - something like let's say a learn to code
13:26 - you pick the the query you wanted to
13:27 - type in in this case maybe something
13:29 - like learn to code and then goes through
13:30 - every single channel here that has
13:32 - posted a video so we go to like cs dojo
13:35 - for example
13:36 - click on the about page it then reads
13:38 - the description of this gets the stats
13:41 - of the channel and then returns that now
13:44 - if the description contains some certain
13:46 - keywords so i think i did something like
13:47 - programming coding software engineering
13:50 - code um like i just specified some
13:52 - random keywords essentially
13:54 - then it returns to me that channel as
13:56 - well as information about that channel
13:58 - and that then is kind of a potential
13:59 - candidate that we would do like a paid
14:02 - advertisement on hopefully that makes a
14:04 - bit of sense but i wanted to come up
14:05 - with like a legitimate use case and this
14:08 - is one right finding youtube channels
14:09 - that we could target with ads that meet
14:11 - a certain criteria so i've done it in
14:13 - the coding space but of course you could
14:14 - do this in in any other space as well
14:16 - anyways if i go here and i run kind of
14:18 - the demo you can see that it gives me
14:20 - all of the channels that meet the
14:22 - criteria sorted by subscribers so i have
14:24 - code with harry uh programming with mosh
14:26 - csdojo programming knowledge so on and
14:29 - so forth you guys probably know most of
14:31 - the channels that are on this list we
14:32 - have of course this great one tech with
14:34 - tim almost had a million subscribers
14:36 - help me out hit that subscribe button
14:38 - anyways you get the point right it's
14:40 - giving me this list now this is just
14:42 - displaying the data that i already had
14:43 - because i don't want to run the scraper
14:44 - from scratch but if we go to data you
14:46 - can see there's a bunch of information
14:48 - about every channel right i'm just
14:50 - displaying a subset but we have you know
14:52 - all of the different tags for the
14:54 - channel
14:55 - we have the urls for the channel we have
14:58 - um
14:59 - what else would be here
15:01 - uh like number of views channel name
15:04 - url yeah contact email stuff like that
15:07 - so actually contact email could be
15:08 - useful as well if they have one then you
15:10 - could reach out to the contact email or
15:12 - send a you know email list or
15:14 - send an email blast all the channels
15:16 - whatever i'm just trying to come up with
15:17 - some examples of stuff you could do with
15:19 - something like this
15:20 - so hopefully that is helpful and i don't
15:23 - know somewhat maybe inspiring it gives
15:25 - you an idea of something to do but just
15:27 - to run this one more time with some
15:28 - fresh data
15:29 - if i go here and i click on run
15:32 - you can see that i can enter a query so
15:34 - maybe i enter a query some of like
15:36 - robotics and then the keywords that i
15:39 - put in here determine if the channel is
15:40 - going to be relevant or not and the
15:42 - keywords again we're searching for in
15:44 - the channel description so i could
15:45 - search for something
15:47 - in robotics i don't know like tech
15:49 - um
15:50 - i don't know let's go with programming
15:52 - we could go with robot
15:54 - whatever pick whatever terms you want
15:56 - and then what happens here is it
15:57 - constantly pulls the um what do you call
16:00 - it the data collector endpoint to see if
16:02 - the data is ready to be retrieved once
16:04 - it is it that displays all the data and
16:06 - downloads it now this does take a minute
16:08 - because you have to go through and
16:09 - search every single channel go to the
16:11 - about page so i'm not going to wait for
16:12 - this to finish but you get the point
16:14 - that was project number three alright so
16:17 - moving on now to my fourth and final web
16:19 - scraping project idea and this one has
16:22 - to do with ecommerce now i did not make
16:24 - a demo for this because i already did
16:26 - three demos before and i was pretty
16:28 - tired from writing all of those so i'm
16:30 - just going to give you a few kind of
16:31 - general ideas here so in the e-commerce
16:34 - i guess section you could be a consumer
16:37 - or you could be a business right if you
16:38 - were a consumer and you're working on a
16:40 - project here maybe you'll do something
16:42 - like compare the price of toothpaste or
16:44 - any general item at maybe a walmart a
16:47 - target a shopper's drug mart a
16:48 - convenience store any other places that
16:50 - you may shop at maybe you'll look at the
16:52 - history of prices of a specific item
16:55 - over time like you'll track that
16:57 - maybe you do something like see if an
16:58 - item is in stock at a certain store if
17:00 - it's something that is frequently out of
17:02 - stock like a graphics card or a computer
17:04 - component maybe even something like a
17:06 - new car i think there's a lot of issues
17:08 - with new cars recently at least that's
17:10 - kind of what i've heard and been seeing
17:12 - but you get the point right there's all
17:13 - kinds of stuff you could do where you're
17:14 - searching for products
17:16 - looking for the availability of products
17:18 - checking the stock maybe you just want a
17:19 - general dashboard that gives you like
17:21 - the reviews on products all kinds of
17:23 - stuff you can write now from a business
17:25 - perspective you're probably more
17:26 - interested in collecting more data where
17:28 - you can kind of analyze your competitors
17:30 - you can see what's selling where how
17:33 - many reviews certain items have maybe
17:35 - you're into drop shipping and there's
17:36 - some specific data that you're
17:38 - constantly looking at and that would be
17:39 - helpful to kind of aggregate and bring
17:41 - in one place maybe you build yourself a
17:43 - really general dashboard that web scrape
17:45 - some information from different sites
17:47 - that you're constantly checking there's
17:48 - all kinds of stuff you can do right so i
17:50 - just wanted to rattle off a few ideas
17:52 - here and hopefully get you thinking
17:53 - about some stuff you might want to do in
17:55 - e-commerce now in case this is helpful
17:57 - uh bright data does have a bunch of
17:59 - pre-built collectors here for e-commerce
18:01 - so there's stuff like ebay aliexpress
18:03 - amazon.com.ca
18:05 - uh the indian one costco uh you know
18:08 - flick flipkart whatever all these things
18:11 - i actually haven't even heard of
18:13 - etsy
18:14 - you get what i mean right there's all
18:15 - kinds of websites that you can look
18:16 - through now the great thing with these
18:18 - collectors is that you can use multiple
18:19 - of them at the same time so you can
18:21 - trigger you know the wayfarer walmart
18:22 - target uh and i don't know let's go ebay
18:25 - collector to all start running at the
18:26 - same time and then as they finish you
18:28 - can collect all the data aggregate that
18:30 - data and do what uh do with it what you
18:32 - would like so i'll just end off the
18:34 - video here by mentioning that there is
18:35 - of course other ways to scrape data you
18:37 - don't need to use a tool like this
18:39 - although it is a lot easier than writing
18:41 - your own web scraper if you're working
18:43 - in python you can use something like
18:45 - selenium or beautiful soup again this is
18:48 - not going to be as scalable as a
18:49 - solution like this but if you're just
18:51 - trying to grab a few small pieces of
18:52 - information that's definitely suitable
18:54 - and i have entire tutorials on my
18:56 - channel on how to use modules like
18:58 - selenium for web automation beautiful
19:00 - soup for scraping html documents and if
19:03 - you're working in another programming
19:04 - language i'm sure you can find some
19:05 - other free resources and documentation
19:08 - that will help you scrape if you are
19:10 - really looking at this from a business
19:12 - use case then i would recommend checking
19:13 - out a site like bright data but with
19:15 - that said i think i'm going to wrap up
19:17 - the video here so thank you all for
19:19 - watching if you enjoyed make sure to
19:20 - leave a like leave any ideas you have in
19:22 - the comment down below and i hope to see
19:24 - you in another youtube video
19:28 - [Music]