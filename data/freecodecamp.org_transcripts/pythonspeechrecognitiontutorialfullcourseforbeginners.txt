00:00 - This course will teach you how to implement speech 
recognition in Python by building five projects.  
00:07 - And it's easier than you may think. This course 
is taught by these two amazing instructors. Hi,  
00:13 - everyone. I'm Patrick. And I'm Alyssa. Patrick 
is an experienced software engineer. And Ministra  
00:20 - is an experienced data scientist. And they're 
both developer advocates at assembly AI.  
00:27 - Assembly AI is a deep learning company that 
creates a speech to text API, and you'll learn  
00:33 - how to use the API. In this course, assembly AI 
provided a grant that made this course possible.  
00:39 - They also have a YouTube channel where they post 
weekly Python and machine learning tutorials. So  
00:45 - here's the projects you'll learn to build in 
this course. So on the first project, we are  
00:49 - going to learn how to deal with audio data, we are 
going to see how to capture audio information from  
00:54 - a microphone and save it as a WAV file. In the 
second project, we are going to learn how to do  
01:00 - speech recognition. On top of this audio file that 
we have just recorded using assembly API's API. On  
01:07 - the third project, we are going to change gears 
a little bit and start doing sentiment analysis  
01:12 - on iPhone reviews that you find on YouTube. On 
the fourth project, we are going to summarize  
01:19 - podcasts that we find online and build a web app 
to show the results to users. And on the last  
01:25 - project we are going to use speech recognition in 
combination with open AI API to make an app that  
01:31 - can answer users questions. I hope you're excited. 
Let's get started. Alright, so in this first part,  
01:38 - I teach you some audio processing basics and 
Python. So we briefly touched on different  
01:42 - audio file formats. Then we talk about different 
audio signal parameters that you should know.  
01:47 - Then I show you how to use the wav module to load 
and save a WAV file, then I show you how you can  
01:53 - plot a wave signal. Then I also show you how to do 
a microphone recording in Python. And finally, I  
01:59 - also show you how to load other file formats like 
mp3 files. So let's get started. So first of all,  
02:05 - before we write some code, let's talk briefly 
about different audio file formats. So here I've  
02:10 - listed three of the most popular ones, mp3, FLAC, 
and WAV. mp3 is probably the most popular one that  
02:17 - you may know. And this is a lossy compression 
format. So this means it compresses the data.  
02:24 - And during this process, we can lose information. 
On the other hand, flax is a loss less compression  
02:31 - format. So it also compresses the data. But it 
allows us to perfectly reconstruct the original  
02:37 - data. And WAV is a uncompressed format. So this 
means it stores the data in an uncompressed way.  
02:45 - So the audio quality here is the best but also the 
file size is the largest. And WAV is the standard  
02:52 - for CD audio quality. So we focus on this in the 
first part, because it's actually very easy to  
02:59 - work with this in Python, because we have a built 
in wav module, so we don't have to answer this.  
03:06 - And now let's have a look at how we can work with 
a WAV audio file. By the way, WAV stands for wave  
03:15 - form audio format. And before we start loading 
some data, let's talk about a few parameters  
03:23 - that we have to understand. So before we load our 
first wav file, let's understand a few parameters.  
03:30 - So we have the number of channels, this is 
usually one or two. So one is also known as  
03:36 - mono and two is stereo. So this is the number of 
the independent audio channels, for example to  
03:42 - or stereo has two independent channels. And this 
means it gives you the impression that the audio  
03:49 - is coming from two different directions. Then 
we have the sample with this is the number of  
03:55 - bytes for each sample. So this will get more 
clear later when we have a look at an example.  
04:01 - And then we have the frame rate, which is also 
known as the sample rate or sample frequency.  
04:08 - And this is a very important parameter. So this 
means the number of samples for each second.  
04:16 - And for example, you may have seen this number a 
lot. So this means 44,100 hertz or 44.1 kilohertz.  
04:28 - This is usually the standard sampling 
rate for CD quality. So this means we get  
04:35 - 44,100 sample values in each second. And 
then we have the number of frames. So yeah,  
04:42 - this is the total number of frames we get. And 
then we have the values in each frame. And when  
04:48 - we load this, this will be in a binary format, 
but we can convert this to integer values later.  
04:55 - So now let's have a look at how to load a file. So 
With the wave four wave module. So here I prepared  
05:04 - a simple wav file. So this is five seconds 
long. So let's actually listen to this. Hi,  
05:10 - my name is Patrick, and I'm a developer advocate 
at assembly AI. And yeah, here, we also see a  
05:18 - few parameters are ready. So now let's go back 
to the code. And now let's load this file. So  
05:27 - for this, we create an object and we simply say 
wave dot open, then we have to give it the name.  
05:35 - So this is called Petrick, dot wav. And to read 
this, we say we read this in read binary. And now  
05:43 - we can extract all these different parameters. 
For example, let's print the, let's say the  
05:53 - number of channels. And we get this by saying 
object dot get N channels. Then we also want  
06:04 - to print the sample with so print the sample with 
and we get this biasing object dot get Sam with,  
06:17 - then let's print the frame rates. So print 
frame rates, and we get this by saying object  
06:26 - dot get frame rate. Then what do we also want, we 
also want the number of frames. So we print the  
06:37 - number of frames, and then we say object dot get, 
and not the N channels and frames. And lastly,  
06:50 - let's also print the, all the parameters. 
So we can get all the parameters at once  
06:57 - by saying object dot get per params. And now 
let's print this. So if we run this, so I say  
07:09 - python wave example.pi, then we see we have only 
one channel. So this is a mono format, we have  
07:17 - a sample width of two, so we have two bytes for 
each sample, then we have a frame rate of 16,000,  
07:25 - and a number of frames of 80,000. And here we also 
have all the parameters as a WAV params object.  
07:36 - So for example, now we can calculate the time 
of the audio. And we as I set the frame rate is  
07:46 - the number of samples per second. So if we get the 
whole number of frames, so the number of frames or  
07:56 - number of samples, divided by the frame rate, then 
we get the time and seconds. So now if we print t  
08:08 - audio, and run this, then we get 5.0. So five 
seconds, so this is the same that we see here. So  
08:18 - this works. And now let's get the actual frames. 
So the frames equals object dot get frames gets  
08:33 - no sorry, object dot read frames, and 
then we can give it the number of frames,  
08:39 - or, or we can I think we can pass in minus one. So 
this will read all frames. And let's for example,  
08:48 - so let's print the type of this to see what this 
is. And then also print the type of frames cero.  
08:59 - And then let's print the length of frames. So 
now let's run this. And then we see this is a  
09:14 - bytes object. And so here we see class 
bytes. And when we extract the first byte,  
09:23 - then we see this as a integer. And now the 
length of the frames object is 160,000.  
09:33 - So this is not the same as the number 
of frames. So if we have a look here,  
09:39 - the number of frames is 80,000. But if 
we extract the length here, then this is  
09:46 - twice as much. And if you listen carefully in 
the beginning here, I mentioned the sample with  
09:54 - this means we have two bytes per sample. So now if 
we actually cut collate this divided by two, then  
10:03 - again, we get our 80,000 number of frames. And 
yeah, this is how easily we can read a WAV file.  
10:13 - And then we can work with this and work with the 
frames. And now to load or to save the data again,  
10:21 - we also open let's call this object, new equals, 
and then we say wave dot open, then we can give it  
10:31 - a new name, let's say Patrick underscore new dot 
wave. And now we open this in write binary mode.  
10:41 - And now we can basically call all those functions 
as setters and not as getters. So we say object,  
10:49 - new dot sets, number of channels, so this is only 
one channel, then we say object new dot set sample  
11:01 - with this should be to object new dot set frame 
rates, this is 16,000 as a float, so these are  
11:14 - all the parameters we should set. And then we can 
write the frames by saying object, new dot write  
11:21 - frames, and then the frames. So here we have the 
original frames. And now basically, we duplicate  
11:29 - the file. So we write the frames and what I 
forgot. So when we are done with opening this  
11:39 - and reading all the information we want, we all 
should also should call objects, thoughts close.  
11:47 - And then the same here. So here we say object, new 
dot, close. And this will close the file objects.  
11:57 - And yeah, so now if we save this and run this, 
then now here we see we have the duplicated file.  
12:06 - And if we run this, Hi, my name is Patrick, 
and I'm a developer advocate at assembly AI,  
12:12 - then we see this works and the test the same data 
in it. So yeah, this is how to work with a WAV  
12:19 - file and with the wav module. So now let's see how 
we can plot a WAV file object. Now plotting a wave  
12:26 - signal is actually not too difficult. So for this, 
we just need to install matplotlib and NumPy. Then  
12:33 - we import all the modules we need. So again, 
we need wave, then we need matplotlib.pi plot  
12:42 - as PLT t, and then we import NumPy, num, pi, 
s and p. Then again, I want to read the wav  
12:55 - file. So I say wav dot open. And this was Patrick 
dot wav in read binary mode, then I want to  
13:05 - read all the parameters that I need. So I 
want to read the sample frequency. And this is  
13:13 - objects dot get frame rates, then I need 
the number of samples. So this is object dot  
13:24 - get and frames. And then I also need the actual 
signal. So I call this signal dot wave equals  
13:34 - object dot read frames minus one. So all the 
frames and then I can say object dot close.  
13:45 - And then for example, we can calculate the number 
on the the length of the signal in seconds. So I  
13:54 - call this T audio. And if you remember this from 
the first code, so this is the number of samples  
14:03 - divided by the sample frequency. And now let's 
print the T audio and save this and run this just  
14:14 - as a test. So now we can run Python plot audio and 
we get 5.0. So this works so far. So now I want to  
14:27 - create the plot. So this is a bytes object. So we 
can create a numpy array out of this very easily.  
14:38 - So I call this signal array equals and then we 
can use NumPy from buffer and here we put in the  
14:50 - signal, signal wave. And we can also specify a 
data type. So here I want to be to have this int  
14:59 - C Steam. And now we need an object for the 
x axis or the so the times axis. So we say  
15:09 - times equals, and here we use the numpy linspace 
function, this gets zero as the start. And the  
15:19 - end is the length of the signal. So this is T 
audio or five seconds. And then we can also give  
15:28 - this a number parameter and the number is the 
number of samples. So if you remember, so the  
15:40 - signal wave. So here, we basically get a sample 
for each point in time. And now we want to plot  
15:49 - this. So we create a figure. So we say PLT dot 
figure, and we give this a fixed size of 15  
15:58 - by five, then we say P L T dot plot, and we 
want to plot the times against the signal  
16:09 - array, then we simply give it a title 
P L T dot title, and let's call this  
16:20 - audio signal. Then I also want to say P L T dot 
y label, and the y label is the SIG no wave,  
16:35 - and the P L T x label is the time time 
in seconds. And then we say P L T x Lim.  
16:51 - And we limit this to be between zero and T audios 
for five seconds. And then we say P L T dot  
17:01 - show. And this is all we need. And now if we run 
this, then this should open our plot. And here we  
17:09 - have it. So here we have our audio signal plotted 
as a WAV plot. And this is how easily we can do it  
17:15 - with matplotlib and the wave module. Now let's 
learn how we can record with our microphone and  
17:21 - capture the microphone input in Python. So for 
this, we use PI audio, a popular Python library.  
17:27 - And this provides bindings for port or your the 
cross platform audio i o library. So with this, we  
17:34 - can easily play and record audio. And this works 
on Linux, Windows and Mac. And for each platform,  
17:40 - there's a slightly different installation command 
that they recommend. So for example, on Windows,  
17:45 - you should use this command. On Mac, you also 
have to install port or your first so if you use  
17:52 - homebrew, then you can easily say brew install 
port audio and then pip install PI audio. And  
17:58 - on Linux, you can use this command. So I already 
did this. So here I'm on a Mac. So I use brew,  
18:04 - install port audio, and then pip install PI 
audio. And now I can import this so I say  
18:10 - import pi audio. And I also want to import wav 
to save the recording later. Then I want to  
18:18 - set up a few parameters. So I say frames per 
buffer. And here I say 3200. So you can play  
18:26 - around with this a little bit. Then I specified 
the format. So the format equals pi or your dot  
18:35 - P R int, sixth team. So this is basically the 
same that we use here. So here we use NumPy, n 16.  
18:46 - And then here we have the P r and 16. Then I also 
specify the number of channels. So here I say  
18:55 - one, so simply a mono format, and then also 
the frame rate. So the rate here again,  
19:02 - I say 16,000. So again, you can use a different 
rate and play around with this. Then we create  
19:09 - our PI audio object. So we say p equals pi audio. 
Then we create a stream object. So we say stream  
19:23 - equals P dot open. And now we put in all the 
parameters. So we say format equals format,  
19:33 - then I need the channels. So channels equals 
channels, the rate equals the rate. We also  
19:43 - want to capture the input so input equals true. 
And lastly, we save frames per buffer equals  
19:53 - frames per buffer. Then we have our stream 
object. So now we can didn't start recording.  
20:03 - And now we want to record for a number of seconds. 
So here I say five seconds. And then we store the  
20:12 - frames. And we store this in a list object. And 
now we can iterate over and say, for i in range,  
20:23 - and we start at zero and go until, and now 
we say rate divided by frames per buffer  
20:33 - times the seconds. And then we convert this to a 
integer, not a float. And with this, we basically  
20:43 - record for five seconds. And then we read each 
chunk. So we say, data equals, and then here we  
20:52 - say stream dot read. And then we read the frames 
per buffer. And then we say, frames, dots, append  
21:04 - the data. So basically frames per buffer. So this 
means we read this many frames in at one, so with  
21:12 - one iteration. And now we have it. So now we 
can close everything again. So we can say stream  
21:19 - dot stop stream, then we can also say stream 
dot close. And we can say P dot terminate.  
21:31 - So now we have everything correctly 
shut down. And now we can, for example,  
21:36 - save the frames object again in a WAV file. So 
for this, I say, object equals wav dot open.  
21:46 - And let's call this output dot wav wave, and in 
write binary mode, then we set all the parameters.  
21:56 - So I said object set number of channels, this is 
the channels parameter objects dot set sample with  
22:07 - this is the this we get from P dot get sample size 
of our format, then object dot set frame rate,  
22:23 - this is the rate and then we can write all the 
frames. So we say object, dot write frames.  
22:33 - And we need to write this in binaries. So we can 
create a binary string like this, so a string,  
22:40 - and then dot join. And here we put in our frames 
list. So this will combine all the elements in our  
22:50 - frames list into a binary string. And then we say 
object dot close, and this is everything we need  
22:58 - to do. So now we can run Python, record Mike and 
test this. Hi, I'm Patrick. This is a test 123.  
23:10 - And now it's done. So here we have our new 
file. So let's play this and see if this works.  
23:17 - Hi, I'm Patrick. This is a test 123 And it worked 
awesome. And now As last step I also want to show  
23:25 - you how to load mp3 files and not only wav files, 
so let's do this. So to load mp3 files, we need  
23:32 - an additional third party library and I recommend 
to use pie it up so this is a very simple to use  
23:37 - library it provides an simple and easy high level 
interface to load and also to manipulate audio. So  
23:45 - in order to install this, we also need to install 
FFmpeg so on the Mac, I use homebrew so I had to  
23:55 - say brew install FFmpeg and after this you can 
simply say pip install and then pipe it up.  
24:03 - And now this should install it. So he has already 
set up sfide. And now we can for example say from  
24:10 - pi up we want to import the audio segment. 
And then we can say audio equals audio segment  
24:21 - and then here we can say from mp3 If we have 
an mp3, in my case right now I only have a from  
24:28 - WAV and then here I am, let's load the Petrick 
dot WAV and then we can for example also very  
24:38 - easily manipulate this by saying audio plus 
six audio plus six. So this will increase  
24:50 - the volume by six d be 60 P then we can also for 
example Repeat the clips. So we say audio equals  
25:03 - all your times to, then we can use a fade 
in, for example, audio equals audio dot fade  
25:15 - underscore in with with 2000 milliseconds. So 
two seconds fade in the same works with fade  
25:24 - out. So yeah, this is how we can manipulate. 
And then we can say audio dot export. And then  
25:31 - I want to export this in. Let's call this mash 
up dot mp3. And then I have to say format equals  
25:43 - as a string, mp3. And now for example, I could 
load this by saying, or you two equals or your  
25:54 - dot from mp3. And then here I use mesh up 
dot mp3 and then print done so that we see  
26:05 - it arrives at this part. And now let's 
say python, and then the load mp3 file.  
26:16 - And yeah, this works. So now here we have our 
mp3 file. And we could also load it like this.  
26:21 - So yeah, that's how you can use the pilot module 
to load other file formats as well. And that's all  
26:26 - I wanted to show you. In this first part, I hope 
you learned a little bit about audio processing,  
26:31 - and Python and charters. And now let's move on 
and let's learn how to do speech recognition and  
26:36 - Python. Hey, and welcome. In this project, we 
are going to learn how to do speech recognition  
26:42 - in Python, it's going to be very simple, what 
we're going to do is to take the audio file  
26:47 - that we recorded in the previous projects, 
and turn it into a text file. Let me show  
26:52 - you how the project works. So here is the audio 
file that we recorded in the previous project.  
27:00 - Hi, I'm Patrick, this is a test 
123. And if we run our script  
27:10 - we get the text transcription of 
this audio file. So like this here.  
27:14 - Hi, I'm Patrick. This is a test 123. So let's 
learn how to implement this in Python. So for  
27:20 - this project, we are mainly going to need 
two things assembly API's API to do the  
27:24 - speech recognition and the request library 
from Python to talk to assembly API's API.  
27:30 - So let's first go ahead and get a API token from 
Assembly AI. It's very simple, you just need to go  
27:36 - to assembly ai.com and create a free account. 
Once you have an account, you can sign in and  
27:41 - just copy your API keys by clicking here. And 
right away, I'm going to create a configure file  
27:51 - and put my API key here.  
27:59 - Once I've done that, now I have a way of 
authenticating who I am with SMD as API. And now  
28:04 - we can start setting up how to upload transcribe 
and get the transcription from Assembly as API.  
28:10 - The next thing that I want to do is to have a 
main file that is going to have all my code. What  
28:16 - I need to do in there is to import the requests 
library so that I can talk to the assembly API.  
28:22 - So this project is going to have four steps. 
The first one is to upload the file that we have  
28:26 - locally to assembly AI. Second one is to start the 
transcription. Third one is keep pulling assembly  
28:33 - as API to see when the transcription is done. 
And lastly, we're going to see this transcript.  
28:39 - So uploading is actually quite simple. If 
we go to the documentation of assembly AI,  
28:46 - we will see here uploading local file files for 
transcription. So I can just copy and paste this  
28:53 - and change the code as we need it. So basically, 
yeah, okay, we are importing the request library  
28:58 - already. The file name we are going to get 
from the terminal. So I will set that later.  
29:06 - Just a couple of things that we need to pay 
attention here. Basically, there is a way to  
29:10 - read the audio file from our file system. 
And then we need to set up a Heather's  
29:16 - these headers are used for authentication. 
So we can actually already set this because  
29:20 - this is not going to be your API token. We 
set it to be API key assembly API, right.  
29:28 - And we need to import it here of course.  
29:37 - Alright, that's done. So we also have 
a upload endpoint for assembly and this  
29:42 - one is API that assembly comm V to upload. But 
you know, this might be something that we need  
29:48 - also later, so I'm just going to put 
this to a separate value variable  
29:58 - and then just call this one here. You So when 
we're doing, when you're when you're uploading  
30:03 - a file to assembly AI, we are doing a post 
request. And this post requests, you need to,  
30:08 - you need to send this post request to the upload 
endpoint, you need to include your API key  
30:13 - included in the headers. And of course, you 
need the data. So the file that you read,  
30:18 - and we are reading the data through the 
read file function in chunks, because  
30:23 - some of the AI requires it to be in chunks. And 
in chunk sizes of five megabytes. Basically,  
30:28 - this is a number of bytes that are in there. While 
we're at it, we can already get the file name from  
30:33 - a terminal tool, right. So for that, I just need 
to import system. And inside system, the second,  
30:41 - or the first, not the zeroeth variable, or 
the argument is going to be the file name.  
30:49 - And here, let's clean up a little bit. All right, 
now, we should be able to just run a command on  
30:55 - the terminal, include the name of the file that 
we want to upload, and it will be uploaded to  
31:01 - assembly AI. And we will also let's print 
the response that we get from Assembly AI  
31:07 - to see what kind of response we get. Again, 
this is the file that we are working with.  
31:13 - Hi, I'm Patrick, this is a test 123. And what 
we need to do right now is one Python main.py  
31:22 - and the name of the file in 
this case, output dot love.  
31:28 - All right, so we uploaded our file to assembly 
AI successfully. In the response, what we get is  
31:35 - the upload URL, so where your data where your 
audio file lives right now. And using this,  
31:40 - we can start the transcription. So for the 
transcription, let's again cheat by getting  
31:44 - the code from the docs. Here is the data 
the code that we need, starting from here.  
31:53 - So this is a transcription endpoint, you can see 
that it ends differently than the upload endpoint.  
31:58 - This one ends with upload this one ends with 
transcript, I will call this the transcript  
32:03 - endpoint. Heather's we already have a header, we 
don't really need this anymore. The endpoint is  
32:11 - transcript endpoint. JSON is the data that we are 
sending to or the data that we want somebody AI to  
32:21 - transcribe. So we are going to need to give it the 
order URL, we already have the order URL, right.  
32:28 - So we got the response. But we did not extract it 
from the response. So let's do that. Oh, do URL  
32:37 - is response, JSON. And it was cold, upload girl.  
32:48 - So we're going to give us audio euro to hear 
because that was just an example. Okay. And this  
32:56 - way, we will have started the transcription. 
And let's do this and see what the result is.  
33:02 - I will run this again. Same thing.  
33:08 - Alright, so we got a much longer response. 
In this response, what we have, we have a  
33:14 - bunch of information about the transcription 
that we've just started. So you do not get the  
33:18 - transcript itself immediately. Because 
depending on the length of your audio,  
33:22 - it might take a minute or two, right? So what 
we get instead is the ID of this transcription  
33:28 - job. So by using this ID, from now on, we can 
ask somebody AI Hey, here is the ID of my job,  
33:35 - this transcription job that I submitted to 
you, is it ready or not. And if it's not ready,  
33:40 - it will tell you it's not ready yet. It's still 
processing. If it's ready, it will tell you hey,  
33:44 - it's completed. And here is your transcript. So 
that's why the next thing that we want to build  
33:49 - is the polling we're going to keep we're going to 
write the code that will keep polling assembly AI  
33:54 - to tell us if the transcription is ready or 
not. But before we go further, let me first  
33:59 - clean up this code a little bit so that you know 
everything is nicely packed in functions, we can  
34:04 - use them pre use them again if we need 
to. So this one is the upload function.  
34:12 - Yes, and what it needs to return is the audio 
URL. We do not need to print the response anymore.  
34:20 - We've already seen what it looks like. And we 
need to put the header separately because we want  
34:27 - both upload and transcribe and basically 
everything else will be able to reach  
34:31 - this variable called Heather's for transcription 
again, I will create a function called transcribe  
34:42 - and what I need to return from the transcription 
function is the ID. So I will just say job ID  
34:53 - and that would be response dot JSON and ad again 
don't need this anymore. I'll just call this  
35:03 - transcript response to make it clear this will 
be upload response. Let's call this transcript  
35:12 - request. So everything is nice and clean. This is 
this and this goes here. And for upload response,  
35:22 - we use it here. And we need to return job ID. 
Alright, so now we have them nicely wrapped up  
35:29 - in different functions, and everything else looks 
good. Let's run this again to see that it works.  
35:35 - Now, of course, I'm not calling the function. 
So let me call the functions and then run it,  
35:41 - upload and transcribe. But of course, I also need 
to pass the file name to the upload function. So  
35:50 - let's do that too. Do your URL is not defined, or 
the URL of course, then I also need to pass audio  
36:04 - URL, audio URL to transcribe Good thing we tried. 
So this will be returned from the upload function,  
36:13 - and then we will pass it to the transcript 
function. And as a result, we will get job ID.  
36:20 - And then I can print job ID to see 
that it worked. Let's see. Yeah,  
36:31 - yes, I do get a job ID. So 
okay, things are working.  
36:34 - The next thing that we want to do is 
to set up the fault polling function.  
36:38 - So the first thing we need to do for 
that is to create a polling endpoint  
36:42 - polling endpoint. So as you know, we had the 
transcript endpoint and the upload endpoint here.  
36:49 - That's how we communicate with somebody as API 
with polling endpoint is going to be specific to  
36:55 - the transcription job that you just submitted. So 
to create that, all you need to do is to combine  
37:01 - transcript endpoint with a slash in between, and 
add the job ID but the job ID is a bit weak. So  
37:08 - I'll just going to call this transcript ID. So 
by doing that, now, you have a URL that you can  
37:14 - ask to assembly AI with which you can ask assembly 
AI if your job is done already or not. And again,  
37:20 - we're going to send a request to assembly AI, 
this time is going to be a get request. Well,  
37:24 - I'll just copy this so that it's easy. Instead of 
post is going to be a get request, we're going to  
37:29 - use a polling endpoint instead of the transcript 
endpoint. And we just need the Heather's for  
37:35 - this we do not because we are not sending any 
information to assembly AI. We're just asking for  
37:41 - information. If you're familiar with requests, 
normally, this might be very simple for you.  
37:46 - But all you need to know about this is that when 
you're sending data to an API, you use the post  
37:53 - request type. And if you're only getting some 
information, as the name suggests, you use the  
37:59 - get request type. So the results resulting or 
the response that we get is going to be called  
38:06 - polling response. Let's see it's not job ID, 
I called transcript ID so that it works. Then  
38:15 - we get the polling response. And I can also 
show you what the polling response looks like.  
38:24 - Looks good. Okay, let's run this. Alright, 
so we got response 200. That means things  
38:36 - are going well, but actually, what I need 
is a JSON response. So let's see that again.  
38:47 - Yes, this is more like it. So again, we get the 
idea of the response language model that is being  
38:54 - used and some other bunch of information. But what 
we need here is the status. So let's see where  
39:01 - that is. Oh, yeah, there it is. So we have status 
processing. This means that the transcription is  
39:09 - still being is still being prepared, so we need to 
wait a little bit more and we need to ask assembly  
39:14 - AI again soon to see if the transcription is done 
or not. What we normally do is to wait 30 seconds  
39:20 - or maybe 60 seconds depending on the length of 
your transcription with length of your audio file.  
39:26 - And then when it's done, it will give us status 
completed. So let's write the bits where we ask  
39:31 - assembly AI repetitively if the transcription 
is done or not. So for that, we can just  
39:38 - create a very simple while loop 
while true. We do the polling  
39:50 - and if poling response dot JSON status equals to 
complete it. We return the polling response. But  
40:11 - if polling response, status is error, because 
it is possible that it might air out, then we  
40:21 - will return. There. I'll just wrap this into 
a function, I can call this gets transcription  
40:32 - results URL. And while we're at it, we might 
as well so wrap the polling into a function,  
40:41 - do we need to pass anything to 
it? Yes, the transcript A D,  
40:50 - need to pass a transcript ID to it. And instead 
of printing the response, we will just return the  
40:57 - response. So instead of doing the request here, 
all we would need to do is to call this function  
41:06 - with the transcript ID, we can pass the 
transcript ID here or might as well I  
41:13 - will just call the transcription 
or transcribe function in here.  
41:19 - And the resulting thing would be the transcript 
ID from the transcription function. And then I'm  
41:26 - going to pass this transcript ID to the polling 
function that is going to return to me the polling  
41:31 - response. I will call this polling response 
data. And inside this data, so this is not needed  
41:39 - anymore. Yeah, so the polling response that JSON 
is what is being passed, I call that the data.  
41:47 - So I change this to data here. And also data 
here. Yeah, then I'll just pass the data.  
41:56 - If it's error, I can still pass the data 
just to see the response and what kind of  
42:00 - what kind of error that we got and hear 
them and just just say none. All right,  
42:06 - let's let's do a little cleanup. So we have a 
nice upload function, a transcript function,  
42:11 - what we did before was we were calling the upload 
function, getting the audio URL and then passing  
42:16 - it to transcribe, but I'm running transcribe here. 
So I do not need this anymore. I still need to  
42:20 - pass the order, you're all to transcribe. So then 
I would need to pass it to here. So instead of  
42:27 - this, just need to call this function with 
the audio y'all. Yeah, let's put these here.  
42:42 - Actually, to make it a bit more understandable, 
maybe instead of passing the string error,  
42:47 - I can just pass whatever error 
that was that happened in my  
42:54 - transcription, then you know, we'll 
be able to see what went wrong.  
42:58 - Alright, so what we get as a result from get 
transcription result ID is the data. And if  
43:06 - there is any error, so then let's Why not run 
this and see what the data is going to look like.  
43:19 - All right, so we get something 
really, really big. Let's see,  
43:22 - maybe I'll just clear this and run it again, just 
so that you know, we can see it more clearly.  
43:32 - Alright, so we get the ID, again, language 
model that is being used, etc. Now we want  
43:37 - the results. Yes, it is under Text. Hi, I'm 
Patrick. This is a test 123 is what we get.  
43:43 - And we also get the breakdown of words, when each 
word started meant each word ended in milliseconds  
43:50 - confidence of this classification, and much 
more information. What we want to do though,  
43:57 - even though we have all this information, 
we want to write this transcript that is  
44:01 - generated by assembly AI into a text file. So in 
this next step, that's what we're going to do.  
44:08 - Alright, let's come up with a file name for 
this file. We can call it actually we can  
44:15 - just call it the same thing as a file name plus 
txt. So the file name okay, we were using the  
44:21 - argument or variable file name too. 
So maybe let's find something else.  
44:26 - We'll just call this txt file name. And it will 
be the file name plus dot txt. We can also just  
44:37 - you know remove the dot valve or dot mp4 or 
whatever but let's not deal with that for now.  
44:44 - So once I have this I will just open it  
44:58 - I will open it in Writing format. 
And inside I will write data.  
45:08 - Texts because that's where we have the text 
information on the transcript. If you remember  
45:13 - here, this was a response we got 
and text includes the transcription.  
45:20 - And I can just prompt the user saying that 
transcription is saved, transcriptions saved,  
45:29 - are happy. Of course, there is a possibility 
that our transcription errors out. So you want  
45:34 - to cover that too. If you remember, we returned 
data and error, what we can do is you can say if  
45:40 - data is returned, this happens. But if it 
errored out, I will just print error. No,  
45:51 - it didn't work out and the error itself so that 
we see you know what went wrong. Okay, let's do  
45:57 - a little cleanup. Again, I want to wrap this all 
up in a function, we can call the Save transcript.  
46:08 - Data and error will be returned from get 
transcripts URL, it means the audio URL, so I will  
46:16 - just need to pass over your URL here. And with 
that, we're actually more or less ready. So let's  
46:24 - run this and see if we get what we need the 
transcript saved in a file. For that after  
46:30 - the after calling the upload function, I can move 
this one here and calling the upload function here  
46:40 - called the upload function. And then 
I call the Save transcript function.  
46:44 - And let's quickly follow that up. I call this a 
transcript function. It calls get transcription  
46:51 - result URL, get transcription result, URL 
calls, transcribe, transcribe is here.  
47:00 - It starts with transcription process and then 
get transcription result URL also calls polling.  
47:06 - So it keeps pulling assembly AI. And when it's 
done, it returns something and then we deal  
47:11 - with it in the Save transcript function, and we 
either save a transcript or if there is an error,  
47:16 - we display the error. So let's run 
this and see if we get any errors.  
47:22 - Transcription saved. Alright, let's see. 
Output was that txt. If I open it up,  
47:31 - it looks quite small. Maybe I 
can, if I open it like this.  
47:36 - Yes. Hi, I'm Patrick. This is a test 123 is the 
result that we're getting. So that's awesome, we  
47:43 - actually achieved what we wanted to do. So in this 
next couple of minutes, I actually want to clean  
47:50 - up the code once again, because you're going to 
build a couple more projects. And we want to have  
47:55 - a python file that has some reusable code, so we 
don't have to reinvent the wheel all the time. So  
48:03 - let me first go here, actually, when we're doing 
the polling, if we just have a while true loop,  
48:09 - it's going to keep asking assembly AI for results. 
And you know that that might be unnecessary. So  
48:14 - what we can do is to include some waiting times in 
between, so it can ask if it's not completed yet.  
48:20 - It Can Wait, let's say 30 seconds to ask again. 
So we can inform the user waiting 30 seconds.  
48:33 - What I need is a time module. So let's 
close 30. And I will just import time here.  
48:44 - And this way, it should be waiting 
30 seconds in between asking assembly  
48:47 - AI if the transcript is ready or not. 
And okay, let's create that extra file  
48:53 - that we have API communication, I'll call it. 
Yes. So I will move all of the functions that  
49:03 - communicate with the API there. So 
I need to move the upload function.  
49:11 - I need to move transcribe 
poll all of these actually.  
49:19 - So just remember that Yeah. Let's 
see. Did we miss anything though,  
49:25 - I'll just remove these from here. File Name 
can stay here, of course, headers and the  
49:32 - upload and transcript endpoints need to live 
here because they are needed by the functions.  
49:39 - In here, we have to import the requests library. 
So we don't need it anymore here. We need to  
49:47 - import the assembly AI API key. system 
needs to stay here time needs to go there.  
50:03 - And we also need to import from API communication. 
Import, we'll just say all. And that way we can  
50:13 - use these functions in our main python script. 
I will run this again to make sure that it is  
50:19 - still working. So I will delete the text file 
that was created, I will keep the output.  
50:28 - Nice. So we also get the prompt that the program 
is waiting 30 seconds before asking again.  
50:35 - Oh, yeah, we passed the filename. But of course, 
it might not exist there. So let's go and fix that  
50:41 - the file name is here, we only pass it to the 
upload function and the upload function is here  
50:47 - now. And in the Save transcript, we do not pass 
it, but we're actually using it. So what we can  
50:53 - do is to just also pass the file name here. And 
that should be fine. It should fix the problem.  
51:05 - Transcription saves. Alright, let's see output 
one. txt Hi. Oh, like this. Hi, I'm Patrick.  
51:16 - This is a test 123. So this is a very short audio 
file. And we actually been using it over and over  
51:22 - again. So I want to also show that this code 
is working to you using another audio file.  
51:31 - This is the audio of the one of the latest 
short videos that I made for our YouTube  
51:36 - channel. I was just talking about 
what natural language processing is.  
51:40 - So this time, maybe if I add 
underscores, it will be easier  
51:46 - to call. Yes, I will just copy its name. And 
when I'm calling the script, I will use its name.  
51:58 - This will probably take a little bit longer 
because the audio file has been using is only a  
52:02 - couple of seconds. And this one is one minute. So 
we will see what the results are going to show us.  
52:10 - Right here we go the transcription is saved 
we find here. Right, this is exactly what I  
52:19 - was talking about. Let's listen to it while the 
transcription is open. Kind of like severe, Best  
52:26 - Funny. Well, not now. But probably very soon. We 
haven't seen gigantic leaps over the last couple  
52:32 - of years in terms of how computers can understand 
and use natural language. Alright, you get the  
52:37 - idea. So our code works. This is amazing. I hope 
you've been able to follow along. If you want to  
52:42 - have the code. Don't forget that you can go get 
it and the GitHub repository we prepared for you  
52:47 - using the link in the description. Welcome back to 
the third project. So in this one, I teach you how  
52:52 - to apply sentiment analysis to YouTube videos. So 
you will learn how to use the YouTube DL package  
52:58 - to automatically download YouTube videos are only 
extract the information you need. And then I also  
53:04 - teach you how to apply sentiment analysis. So 
in this example, I use iPhone 30 review videos.  
53:11 - And the result that we get looks like this. So for 
each sentence in the video, we get the text. And  
53:18 - then we also get the sentiment. So this could be 
positive or negative or neutral. For example, if  
53:24 - we read this text here, the new iPhone display is 
brighter than before the battery life is longer,  
53:29 - and so on, and the sentiment is positive. And 
here the text is still there are some flaws,  
53:35 - and now the sentiment is negative. So this works 
pretty well. And this can be applied to so many  
53:40 - use cases. So let's get started and see how to do 
this. So here I've created a new project folder.  
53:46 - And we already have our API secrets and the API 
py file with the helper functions to work with  
53:52 - the assembly API API. And now let's create two 
more files. So the main.py file that will combine  
53:59 - everything and the YouTube extractor files, this 
is another helper file to extract the infos from  
54:07 - the YouTube video. And for this, we are going to 
use the YouTube DL package. This is a very popular  
54:14 - command line program to download videos from 
YouTube and other sites. And we can use this as  
54:20 - command line program. But we can also use this in 
Python. So for this we say pip install YouTube DL,  
54:28 - and then we can import this so we say import 
YouTube DL. And then we set up an instance so  
54:35 - we say why the L equals YouTube DL dot YouTube DL. 
And now I'm going to show you how you can download  
54:45 - a video file and also how you can extract the 
infos from a video. So let's create a helper  
54:51 - function that I call get video infos and this 
takes and URL And now we use the YT l object  
55:03 - as a context manager. So we say with y the L, 
then we say we're CELT equals y, the L dot,  
55:13 - extract info. And this gets the URL. And 
by default, it has download equals true.  
55:22 - So this would also download the file. But 
in my case, I say download equals false,  
55:29 - because of course, we could download the file 
and then upload it to assembly AI. But we can  
55:35 - actually skip this step and just extract the 
URL of the hosted file. And then we can pass  
55:43 - this to the transcribe endpoint in assembly AI. 
So we can set download equals false here, then  
55:51 - we do one more check. So we say if entries, if the 
entries key is in the result, then this means we  
56:01 - have a playlist URL here. And then we want to 
return only the first video of this playlist.  
56:09 - So we say return results with the key entries, and 
then the result zero or entry zero. And otherwise,  
56:21 - we return the results simply so this is the whole 
video info object. And then let's create another  
56:29 - helper file that I call get all your URL, and 
this gets the video infos. And first of all,  
56:39 - let's simply print all the video infos to see how 
this looks like. So now let's say if underscore  
56:47 - name equals equals main. And then let's first 
extract the video info. So video info equals get  
56:58 - video infos this needs in your L. And then we 
say all your your L equals get all your your URL,  
57:01 - and then we want to print the audio URL. So right 
now this is none because we don't return anything.  
57:16 - So let's get an example URL. So for this, I 
went to YouTube and search for iPhone 13 review,  
57:25 - and I choose this video. So I've entered into 
review pros and cons. So we can click on this.  
57:31 - And then we have to watch an ad. But we 
can actually copy this URL right away,  
57:37 - and then put it in here as a string. And 
now if we run this, then so we run Python,  
57:46 - YouTube extractor dot time, then it should print 
the whole URL. So yeah, actually, here, I have to  
57:55 - pass this YouTube Info. And let's try this again. 
And yeah, so here, it extracted the whole or it  
58:05 - printed the whole info. So this is actually a 
very long object, a very long dictionary. So  
58:14 - I can tell you that this has a key in it, that is 
called formats. So let's actually print only the  
58:24 - formats. And if we run this, then this is also 
still a very large, very large dictionary.  
58:36 - But then again, this is an inner dictionary, 
and this has a key that is called. Or actually  
58:44 - this is a list. So now we can iterate over this. 
So here we say, for F in video in four formats.  
58:54 - And then we can print the F let's print F 
dot, and it has the key ext for extension.  
59:04 - And it also has a your L so we also want to 
print F dot u r l and now if we run this down,  
59:16 - let's see what happens. Um, let's actually 
comment out the URL because this is super long. So  
59:25 - let's print only the extension. And now we see 
we have a lot of different extensions because it  
59:35 - actually start the video in a lot of different 
formats and with a lot of different resolutions  
59:41 - and so on. So, what we want is this one, so the 
M for a this is a audio format ending. So we now  
59:53 - check if the format or if the extension 
equals equals m for a, then we return the  
60:09 - F URL key. So this is the audio, 
your L. And if we save this,  
60:17 - and then print this at the very end, then we 
should get the URL to this host that file.  
60:26 - So you can see this is at this URL. So this is not 
related to youtube.com. So now let's, for example,  
60:35 - click on this. And then we have this in our 
browser, so we could listen to the audio file.  
60:43 - So yeah, this is the first part how to work with 
the YouTube DL package to extract the infos.  
60:51 - And now let's combine this in the main.py. So in 
main.py, we combine the YouTube extractor infos,  
60:58 - with assembly AI and extract the transcript of 
the video and also the sentiment classification  
61:03 - results. So sentiment classification is usually 
a pretty difficult task. But assembly AI makes  
61:10 - it super simple to apply this. So if we go to 
the website, assembly itad, calm and have a look  
61:16 - at the features, then we see they provide core 
transcription. So this is basically the speech  
61:22 - recognition we've seen in the last part. But 
they also offer audio intelligence features,  
61:28 - and they are pretty cool. So there are a lot 
of features you can use, for example, detect  
61:33 - important phrases and words, topic detection, 
auto chapters, so auto summaries and much more.  
61:40 - And if we scroll down, and here we find sentiment 
analysis. So if we click on this, then we see a  
61:48 - short description. So with sentiment analysis, 
assembly, AI can detect the sentiment of each  
61:54 - sentence of speech spoken in your audio files. 
Sentiment Analysis returns a result of positive,  
62:01 - negative or neutral for each sentence in 
the transcript. So this is exactly what we  
62:06 - need here. And it's actually super simple to 
use this. So the only thing we have to change  
62:12 - is when we call the transcript endpoint, we also 
have to send sentiment analysis equals true as  
62:20 - JSON data. So this is all we need to do. 
So let's go to our code and implement this.  
62:27 - So let's import all the files we need. So we want 
chasen and we say from YouTube extractor we import  
62:34 - get all your your URL and get video infos. 
And from our API helper file, we import save  
62:43 - transcripts. Then here, I create one helper 
function that I call Safe video sentiments. And  
62:52 - this gets the URL. And here we get the video in 
force by calling Get Video enforce with the URL,  
63:04 - then we get the odd your your URL by calling 
get all your your URL and this gets the video  
63:13 - infos. And then I simply call the safe transcript 
function and this gets the audio URL, and it also  
63:23 - gets a title. And for the title I want to use 
the title of the video so we can get this from  
63:31 - the video info. So this has a key that is called 
title. And then I want to slightly modify this so  
63:40 - I say title equals title dot strip. So I want 
to remove all leading and trailing whitespace.  
63:49 - And then I want to replace all spaces with a 
underscore and then I also say title equals data  
64:01 - slash plus title. So I want to store this in 
a separate folder. So here we create this and  
64:11 - call this data and now we have to modify the 
slightly so if we have a look back, then we see  
64:19 - this needs the additional arguments 
sentiment analysis. And now so in the  
64:28 - safe transcript file, I will put this as 
additional argument and I will give this a default  
64:36 - of false and then here we say sentiment analysis 
equals true and now we have to pass this through.  
64:49 - So we have to pass this to the get transcription 
result your l so this also needs this parameter,  
64:57 - then the transcribe needs the parameter. And here 
this needs the parameter. And now as a JSON data  
65:08 - that we sent, we put sentiment analysis equals 
true or false. And this is all that we need. And  
65:17 - now of course, I also want to save this. 
So here we check if the parameter is true,  
65:26 - then I create a separate file. So again, I say 
File Name equals title plus, and then let's call  
65:35 - this underscore center, man's dot JSON. And now I 
say with, with open the file name in write mode,  
65:52 - s, f, and then I import JSON in the top import 
JSON. And then here, we simply say JSON dot dump.  
66:06 - And first we have to extract the infos, of course, 
so we call this sentiments equals data. And then  
66:15 - the key. If we have a look at the documentation, 
then here we see the chase and response now has  
66:23 - this additional key sentiment analysis results. So 
we use this and then we dump the sentiments into  
66:35 - the file. And I also want to say indent equals 
four, to make this a little bit more readable. And  
66:44 - now in the main.py, we call this function and see 
if underscore name equals equals underscore main.  
66:54 - And then I want to call the safe video sentiments. 
And the URL is this one. So let's copy and paste  
67:08 - this in here. And now let's run the main 
the py file and hope that everything works.  
67:15 - So the website is downloaded and transcripts from 
start. So this looks good. So let's wait. Alright,  
67:22 - so this was successful, and the transcript was 
saved. And now we have a look at the data folder,  
67:26 - then here, we get the transcript of the video. And 
we also see our JSON file with all the sentiments.  
67:33 - So for each sentiment, we get the text of 
the sentence. So for example, this one,  
67:40 - with the exception of a smaller notch, the 
iPhone 13 Doesn't seem very new at first glance,  
67:46 - but when you start using this flagship, you 
start to appreciate a bunch of welcome upgrades,  
67:51 - then we get the start and end time, then 
we get the sentiment which is positive.  
67:56 - And we also get the confidence, which is pretty 
high. Then the next example, the new iPhone  
68:02 - display is brighter than before the battery life 
is longer, and Apple has improved, blah, blah,  
68:07 - blah. So here also the sentiment is positive, 
then we have still there are some flaws here.  
68:14 - And now the sentiment is negative. So this works 
pretty well. And yeah, this is how you can apply  
68:21 - sentiment analysis with assembly API. Now I want 
to show you a little bit more code how we could  
68:27 - analyze this, for example. So now we can comment 
this out. So we don't need to download this again.  
68:35 - Then we can read our JSON file. And here we 
store the positives, negatives and neutrals.  
68:43 - So we iterate over the data. And then 
we extract the text, so the text,  
68:50 - and we also extract the sentiment, so then we 
check if this was positive, negative or neutral,  
68:56 - and appended to the corresponding list, then we 
can calculate the length of each list. And then  
69:03 - we can print the number of positives, negatives 
and neutrals. And we can also for example,  
69:09 - calculate the positive ratio. So here, we ignore 
the neutrals and simply do the number of positives  
69:15 - divided by the number of positives plus the number 
of negatives. And now if we save this and run this  
69:23 - again, then here we get the number of 
positives. So 38, only four negatives  
69:30 - over all positive ratio is 90%. So with this, 
you can get a pretty quick overview of a review,  
69:36 - for example. And yeah, I think the sentiment 
classification feature can be applied to so  
69:42 - many different use cases. It's so cool. So yeah, 
I hope you really enjoyed this project. And now  
69:47 - what would be really cool is if we could display 
these information in a nice looking web app,  
69:52 - and this is actually one thing that you will 
learn in the next tutorial together with Misra  
69:56 - so let's move on to the next project. All right 
Now it's time to build a podcast summarization  
70:02 - app. And we're also going to build a web 
interface for this application. In this project,  
70:07 - we are again going to use assembly API's API that 
offers the chapter isation summarization features,  
70:15 - and we are going to get the podcast from the 
Listen notes API. So let's get into it. Here's  
70:20 - what our app is going to look like once we are 
done with it. So we will get a episode ID from  
70:26 - listen notes API, I will show you how to do that. 
And when we click this button, it will give us  
70:32 - first the title of the podcast and an image, the 
name of the episode. And then we will be able to  
70:39 - see different chapters and when they start in 
this episode, and if we click these expanders,  
70:45 - we will be able to read a summary of the chapter 
of this episode. This is all quite exciting to  
70:52 - start building a front end for our application to 
so let's start building it. So in this project,  
70:57 - like in the previous ones, we are going to have a 
main script. And we are going to have a supporting  
71:03 - Script API communication, where we have all 
of our supporting functions that we want to  
71:08 - use over and over again, we built this before. So 
this is the exact same one from the third project  
71:14 - the project that we did before. And we will only 
need to update this and change some things to  
71:21 - start doing podcast summarization. So the first 
thing that I want to update here is that we will  
71:25 - not actually need the upload endpoint anymore. So 
I'm just going to go ahead and delete that one,  
71:30 - because the transcripts are going to be sorry, 
the podcasts are going to be received from the  
71:35 - Listen notes API. So it's going to be somewhere 
on the internet, we will not download them to  
71:40 - our own computer. So we can immediately tell 
assembly AI hey, here's the audio file here is the  
71:46 - address of the audio file that I want you 
to transcribe. And it will be able to do  
71:50 - that. So there will be no download or upload 
needed. That's why I also don't need the upload  
71:56 - function. Also the chunk size not relevant 
anymore. All right. So that's good for now.  
72:03 - And the next thing that we want to do is to set 
up the Listen notes API communication. So we are  
72:08 - going to use assembly AI to create the summaries 
of the podcasts. And we will get these podcasts  
72:14 - from listen notes. If you've never heard of it 
before. Listen, nose is basically a database of  
72:20 - podcasts, I think nearly all of the podcasts so 
you can search for any podcasts. For example,  
72:26 - one of my favorites is 99% invisible, 
and you will be able to get all of its  
72:32 - information plus the episodes so you can search 
for episodes here if you'd like to. What we're  
72:39 - going to do with listeners is that we are going to 
send it a episode Id like specific episode ID that  
72:45 - we will find on the platform itself. So let's say 
I want to get the latest episode of 99% invisible.  
72:53 - If I go to the episode page, and go 
down to use API to fetch this episode,  
72:59 - I will see a ID. So this is the ID of the specific 
ID of this episode. And using this ID, I will be  
73:06 - able to get this episode and send it to assembly 
AI. And this is exactly the ID that we need  
73:12 - on our application. So to get that first, of 
course, we need the Listen notes endpoints. Listen  
73:19 - node has a bunch of different endpoints. But 
the one that we need is the episode endpoint to  
73:24 - get the episode information. So I will just name 
this listen notes, episode, and point and it is  
73:30 - this one. And of course, we also need the header 
again to authenticate ourselves and in the header,  
73:35 - we're going to need to put a API key so 
all you have to do is go to listen nose,  
73:40 - create an account and get an API key for yourself. 
And we are going to go and paste it here.  
73:56 - And here as you know, we are importing the API 
key for assembly yeah, now I'm also going to  
74:03 - import the API key for listen notes and we are 
going to send it with our requests to listen  
74:10 - notes. So I will call this the Listen notes. 
Heather's and this the assembly AI Heather's  
74:20 - for listen knows this is named 
x listen API key. Alright,  
74:25 - the first thing that I want to do is to build a 
new function that is able to get the episode ID  
74:32 - and give us the URL to the podcast is audio file. 
So I will call this one get episode, audio, Euro.  
74:45 - And it is going to get an episode ID and we're 
going to send a GET request to listen notes.  
74:53 - Let's build a URL first. The URL is going to 
consist of the Listen notes episode endpoint. and  
75:03 - dash plus the episode ID. And we 
are going to send a GET request  
75:18 - to zero, I will call the response we get is 
response for now. And the last thing that we need,  
75:25 - of course, is the headers for authentication. 
And that one is called listen notes headers.  
75:30 - So as ever do this, we should be able to get 
a URL for the episode ID. And the information  
75:38 - is going to be sent to us in a JSON format. So 
this way, we will be able to see it. So maybe,  
75:44 - let's try this at first and see that it works. 
So to do that, I am just going to again, import  
75:52 - from API communications, import everything, I'll 
just make this a simple Python script for now.  
76:00 - And I'm going to call get episode audio Euro. 
And I will use the episode ID that I found here.  
76:11 - This one to keep things simple. 
And as a result, we will  
76:17 - print the response that we get from listen 
notes. So let's run this and see what happens.  
76:28 - All right, this is really long. So 
maybe I'll be I will use a pretty print  
76:33 - to make it more readable. So this print here. 
And instead of this, just use pretty print.  
76:46 - Okay, let's do it again.  
76:49 - All right, that is slightly better. Let's see 
what kind of information we are working with.  
76:57 - Nice, we get the audio URL here. This is the 
URL of the audio. Let's see where that takes us.  
77:11 - Yeah, this is just the audio of 
this podcast, you can hear it  
77:15 - Aerocity that the Roman advance was halted. Nice. 
Alright, so this is exactly what we need. But if  
77:22 - you want, you can also get some extra information 
about the podcast. If you want to display it  
77:27 - in some way, we will definitely use the plus 
blade. And this is a description of the episode,  
77:32 - whether there is explicit content or not the image 
of this episode, and some extra information about  
77:39 - the podcast like Facebook and Google handle, etc. 
So you get a lot of information. So if you want  
77:44 - to make your web application at your 
interface even more interesting,  
77:48 - more interactive, you can of course include more 
of this in your application. So if we just return  
77:55 - data audio from here, we will actually 
just return to order here all but you know,  
78:00 - now that we have all this information 
might as well extract some more of it.  
78:03 - So some of the things that we can get as a 
thumbnail of this episode, name of the podcast  
78:08 - and title of this episode for example, like 
we said, we will display here so let's do that  
78:21 - this will be the audio Euro we 
will also get the episode thumbnail  
78:31 - thumbnail  
78:35 - we can get the podcast title that would 
be in podcasts. And then this podcast  
78:43 - specific information and then we get 
the title. And lastly episode title.  
78:51 - thing it is just title. And we can just 
pass all of this information back episode,  
78:59 - thumbnail episode, title, and podcast title. 
So we don't really need to change much from  
79:09 - the rest of the functions for example, transcribe 
poll get transcription results that we already  
79:13 - built beforehand. The only thing that we need 
to change is now we're not going to do sentiment  
79:18 - analysis we want to do use auto chapters features 
of assembly AI. So I'm just going to rename these  
79:24 - to all the chapters. This is just the name of a 
variable so it is not that important. You can keep  
79:30 - it the same. But for readability it's probably 
better to change it to other chapters but here  
79:36 - in this variable we need to change this name 
to other chapters because we're sending this  
79:42 - request to assembly AI and it needs to know 
that we want other chapters what else we also  
79:48 - just updated the name of the heather so it's not 
only Heather's now it's assembly AI Heather's  
79:54 - same here in the polling. We do not need to change 
anything we are only asking you if a transcription  
80:01 - is done or not, again, get transcription 
result URL we want to change it to or chapters.  
80:13 - One other thing that I want to change is it's 
very small. But normally we were waiting for  
80:18 - 30 seconds. But now I want to wait for 60 seconds 
because podcast episodes tend to be a little bit  
80:24 - longer. So we want to wait a little bit longer in 
between asking assembly AI if the transcription is  
80:30 - ready or not. This is another change. But the main 
work is going to happen in the Save transcript  
80:35 - function. So the main change we're going to need 
to do in save transcript function is that before  
80:41 - we were uploading our audio to assembly AI, and 
then we were getting the result back, but instead  
80:47 - this time, we are going to only have a episode 
ID and then we are going to get the URL from  
80:52 - listen notes. And then we're going to pass that to 
assembly AI to start your transcription. So what  
80:59 - I want to do here is to instead of URL and title, 
I will just give say transcript, the episode ID.  
81:07 - And then I will run the get episode audio URL 
from oops, from inside the Save transcript.  
81:18 - And as a result, what we're getting is 
order your roll episode thumbnail episode  
81:23 - title and podcast title. Again, we are not doing 
sentiment analysis, we are doing order chapters.  
81:33 - And we need to pass the order y'all to get 
transcription results URL, get transcription  
81:40 - result URL gets the order your URL as URL and 
all the chapters but it is not defined. So  
81:48 - you know this is what we want to 
do is hoses coal, it is true here.  
81:53 - The next thing that we want to do is to deal with 
the response that we get from Assembly AI. So  
81:59 - let's first see what the response from Assembly 
AI looks like when we were doing auto chapters.  
82:04 - And then let's deal with it. But 
let's fix some of the problems here.  
82:08 - So I will not save it into a file for now. I can 
comment these out. This will be order chapters.  
82:18 - The main thing that I want to do is see what the 
result looks like. Right? So I will pretty print  
82:26 - the data. And the data is already in 
JSON format. Transcribe Yes, it is.  
82:42 - Yeah, so I will just show that. So I'm 
just going to comment these out for now,  
82:48 - just so that you know, we have an idea of what 
what the response looks like. To run this,  
82:54 - I will just pass the episode 
ID to save transcript.  
83:10 - Oh, we're still printing this one. 
So I will actually stop printing the  
83:17 - response from listen notes on what started again.  
83:30 - Alright, so we got the results. 
Let's see what it looks like.  
83:35 - It's a lot of information. Let's scroll to the 
top. And what we wanted was a chapter is basically  
83:40 - so let's see what the chapter information 
includes. So as you can see, this is one chapter.  
83:46 - And this is another chapter. So for each chapter, 
we have the starting point. And then we have the  
83:52 - ending point, the gist of the chapter. So 
really quickly, what is this chapter about?  
83:57 - We have a headline for this chapter and a 
summary. So in a couple of sentences, what  
84:02 - is happening in this chapter, what what is the 
presenter talking about? What we want to do is to  
84:08 - show this information on our application right 
on our web interface. So that's why what we want  
84:15 - right now is to extract this information 
from the response we get from Assembly AI  
84:20 - and then save it somewhere and then we can 
visualize it on our stream that application.  
84:28 - So I will undo the commenting here. Also here.  
84:36 - So I will call this file with the episode ID it 
will be episode ID that t x t. And as we always  
84:45 - do, I'm just going to say the transcript you know, 
we don't have to touch this so much, but I will  
84:51 - start another file. And let's call this chapters 
file name and This one will be episode, id  
85:05 - plus, maybe let's call like chapters, 
that. txt. All right, so chapters  
85:14 - will be another file. So I'm going to keep all the 
chapter information somewhere else. And in here,  
85:20 - I'm going to write some of the information I 
got from Assembly AI, specifically the chapter  
85:24 - information. And I'm also going to include some of 
the information I got from the lesson notes API.  
85:31 - One mistake here, I do not want it to be 
a text file, I want it to be a JSON file,  
85:35 - so that it will be easier to parse easier to read 
later. For me, the first thing that I want is the  
85:41 - chapters. And I'm going to get that from the data 
variable. It's called chapter so let's check.  
85:50 - The section is called chapters. Yeah. So 
let's start it out. We'll say episode data.  
85:57 - At first, let's include the chapters 
again, I will call the chapters.  
86:04 - And then inside this episode data, what 
do I want, I want the episode thumbnail.  
86:16 - I want the episode title. 
And I want the podcast title.  
86:25 - So that I have all of this information in one 
place saved on my file system, I can just read  
86:30 - it whenever I want and display to the user. 
And finally dump that to the file sewed data.  
86:43 - And I'll let the user know that the transcript 
is saved. This part we don't need any more.  
86:52 - And again, if there is an error, we will just say 
that there is an error. And we will return true.  
87:00 - Now that we got this far already, up till 
now what we do is get the URL from based  
87:06 - on the episode ID from listen notes, and 
then send it to this URL to some of the AI  
87:12 - gets audio chapters information, and then save 
it to a file. So let's see that this works well.  
87:20 - And while it's running, we will start the stream 
with application. So I will just run this again.  
87:28 - But in the main view, of course need to call 
save transcript. Okay, we're open to doing it. So  
87:34 - I will just run the application. And let's also 
start building our assumed application now. So  
87:40 - if you've never heard of streamlet before, it is a 
really easy way to start building web interfaces.  
87:46 - For your application specifically for Python, it's 
very simple to use it is has a very simple API,  
87:53 - it's a very simple library. So what you have to do 
is you call your import streamlet as a see if you  
88:00 - wanted to use it simply. And let's say if you want 
to, you know put a title in your application, all  
88:08 - you need to do is SD title and then you can show 
that it as a title. So I will run this separately.  
88:18 - To show you how it works.  
88:26 - And to run from it applications, you just need 
to say assume it run mean that a PI stream it  
88:32 - is installed on your computer like any other 
Python library, so you just need to use PIP  
88:37 - say pip install a streamer then you will be 
good to go. Unless you make a mistake and call  
88:43 - stream with a capital S which is not the case it 
needs to be a lowercase s so let's do that again.  
88:55 - Alright, so this is actually an application it 
the only thing we're showing right now is a title.  
88:59 - And we know what you want it to look like is 
that so I will start building the elements  
89:06 - in this application. So the first thing that 
you know strikes us is that we have a sidebar,  
89:11 - we have a title that says podcast summaries and 
then we start showing the information from the  
89:18 - information we got from the 
API's that we've been using. So  
89:22 - let's put a sidebar maybe let's let's fix the 
title. First we want to say podcast summaries.  
89:29 - title says podcast summaries or 
it can even say welcome to our  
89:37 - to my application that creates podcast summaries. 
Let's see maybe that won't be too long but we'll  
89:46 - see. And let's create the sidebar is quite 
simple. You call streamlet sidebar dot texts  
89:54 - input Yeah. And then you know you can 
say please input Here's a, an episode ID.  
90:04 - And I can also have a button at the 
end of the sidebar that says, Get  
90:12 - podcast summary, maybe with a exclamation 
point too. So let's run it again.  
90:22 - Okay, this is looking more like it, it says 
Welcome to my application that creates podcast  
90:26 - summaries. I can put an episode ID here. 
And then I can say get podcast summary. So  
90:32 - you see that it is running, it is running because 
I forgot to comment out this one. So it's actually  
90:39 - running the whole application. I'll just stop 
it for now, because we don't have any way of  
90:44 - displaying whatever we get back from the API's. 
So I'll stop this now. And now that we have the  
90:52 - application looking more or less like what we 
want it to look like, let's wait for the chapter  
90:59 - results to be printed on our file. And then we 
will see what it looks like. And then we can start  
91:05 - parsing it and then showing it to the user on our 
streaming application. Okay, so the transcription  
91:09 - is saved to our auto chapter creation is 
done. Let's take a look at what it looks like.  
91:17 - We have the chapter section, we have the episode 
thumbnail episode, title and podcast title.  
91:22 - Or good in the chapters we have chapter numbers. 
And inside each chapter, we have the summary  
91:30 - headline just start and end. So it looks good. 
Let's start showing this. The first thing that  
91:36 - I want to show of course, like we did in the 
beginning, like we showed in the beginning  
91:41 - is the name of the episode, or maybe the name 
of the podcast plus the name of the episode,  
91:49 - and then the episode a thumbnail. So how I'm 
going to show that is again using streamlet.  
91:56 - And that is going to be the header for 
me. And I will include the podcast title.  
92:07 - Maybe with a dash in between and the episode 
title. But as you can see, we do not have it yet.  
92:13 - So first, we need to open the file that includes 
these things. And the file that includes those  
92:18 - things is the episode ID that underscore chapters 
at Jason. So started again, file name would be  
92:27 - episode D underscore chapters, the JSON and where 
do I get the episode ID, I get the episode ID from  
92:38 - the text input. So the user is going to input the 
episode ID and then I am going to save it here  
92:44 - in this variable. And that way I will have the 
file name. So then I just need to open this file  
92:57 - and let's call it data. For example, 
I need to import JSON of course  
93:09 - and loaded into the variable data.  
93:13 - So in this variable data, what do we have? We 
have the chapter so first, let's get the chapters,  
93:18 - data chapters. And then what we want to get is 
the podcast title, and then the episode title.  
93:32 - Let's change the names episode title. And we 
also want some nail. And what did we call the  
93:41 - thumbnail? We can see here, Episode thumbnail. 
Alright, so thumbnail. So we're already showing  
93:52 - the podcast title and episode title streaming 
header. And then we can show the image thumbnail  
94:01 - with the streamlet image function. And from this 
point on the next thing that we want to show  
94:08 - is the chapters of course, one thing we can do is 
for example, we can use a for loop could say for  
94:16 - chap in chapters. You know, you 
can just say stream it right  
94:28 - or just show the chap but that's one way of doing 
it. But you're going to have a lot of texts one  
94:33 - after another. It's not really nice. What we want 
is like in the original one I showed you at the  
94:38 - beginning, we want to expanders, so it's quite 
easy to create expanded restreaming again you  
94:43 - just say stream it expander and then you want your 
right what kind of information you want to be in  
94:49 - your expander so as the title of the expander 
I will write here what I want in title and  
94:57 - whatever I want inside the expander I'm I'm 
going to write inside. So I do not need to  
95:02 - use a stream. Let's think again, because 
this is going to be inside the expander.  
95:06 - And inside the expander, what I want is the 
summary. So I think it was called summary.  
95:13 - Let's just check again here in our JSON file. In 
chapters, we have summary. It's called summary.  
95:18 - Yes, so I want the summary to be in there. And as 
a title of the expander, I want there to be the  
95:25 - gist of each chapter. So for each chapter is 
going to show me the expanders for each chapter,  
95:32 - there will be expanders, and the title of the 
expander will be the gist of this chapter. And  
95:37 - inside the expander, we're going to have the 
summary of this chapter. So let's run this  
95:41 - and see how it looks. But let's do this. First, 
make sure that everything works. So I have the  
95:46 - title. And then I asked for a episode ID from the 
user, there is a button that starts this process.  
95:54 - And for that to happen, I'll just call 
this button. So we this information, this  
96:00 - button variable has information of whether this 
button has been pressed or not. And I only want  
96:06 - this part, this part to happen this visualization 
to display part to happen if the button has  
96:11 - been pressed. So I'm going to wrap this all in a 
condition. So otherwise, it's not going to happen.  
96:17 - Yes, but right now, if someone presses the button, 
nothing really happened. So we also need to add an  
96:22 - action to this button. And how we're going 
to do that is we're going to say on click,  
96:27 - if this button is clicked, what we want to happen 
is the same transcript file to be run. So I'm  
96:35 - going to call it here in the onclick argument. And 
we also have arguments, right. And here is how you  
96:43 - pass arguments to your function that you call 
from your button. This is a tupple. That's why  
96:49 - you write the variable or the argument that you're 
passing to the function and the first one, and  
96:53 - the second one is empty. Now, when the button is 
clicked, this one should run and we should be able  
97:00 - to see all the information on our application. 
So let's run it again and see what happens.  
97:08 - Yeah, we need to run the streamlined application 
this time, streamline run main that py.  
97:17 - I'll close the old one. So we know 
the difference and which one is which.  
97:22 - This is just the example 
from the beginning. Alright.  
97:26 - So we want to get a podcast, we want to 
display it. I will get this one again.  
97:38 - Let's get the podcast summary. And here it is. 
We have the title Welcome to my application that  
97:45 - creates podcast summaries. Okay, maybe that's a 
bit too long, I will shorten it. The name of the  
97:50 - podcast name of the episode number of the episode 
also the missing middle. And here are my chapters.  
97:56 - So apparently there are 1234567 chapters assembly 
as API was able to find an E chapter we have the  
98:05 - gist of the chapter as the title of the expander. 
And the chapter summary here valon. One last thing  
98:11 - that I want to add is a start and end point of the 
just the start point of the chapter here, because  
98:17 - I want to show like how long each chapter is 
maybe. So let's do that. So for that I want to see  
98:24 - in this JSON file, how it looks. So The start 
looks like this. So these numbers might look  
98:29 - a bit random to you. But basically, they are 
milliseconds. So I am wanting to turn it into  
98:35 - minutes and seconds. And if applicable 
hours, minutes and seconds. And there is  
98:40 - already a function that can do that. Here it is, 
we don't need to, you know, work on for a long  
98:46 - time. Basically, you get the milliseconds and when 
you get the milliseconds you can get the seconds  
98:52 - out of it, how many seconds there are, how 
many minutes there are and how many hours  
98:56 - are so basically you're counting the hours and 
everything that is on top of the hour is mentioned  
99:02 - as a minute if it does not add up to an hour, and 
everything that does not add up to a minute is  
99:08 - pointed out as seconds. And here is what we 
will return so we'll say the start time is  
99:13 - either hours, minutes and seconds. And if there 
is no hours, we don't have to say zero something  
99:17 - something. So just show up minutes, and then 
seconds. And how I'm going to show it is within  
99:22 - the expander title. And I can you know show it 
with a dash in between. I'll say get clean time.  
99:34 - And in there what I want is chapter start. Let's 
see what it was. Just just start Okay. All right.  
99:44 - Let's run it one more time and then see what our 
application looks like. Awesome. Okay, this is our  
99:49 - application on the sidebar. We can input a episode 
ID that we get from listen notes we can say get  
99:55 - podcast summary. It will show a nice title tie A 
lot of podcasts title of the episode show was a  
100:02 - thumbnail of this episode. And for each chapter, 
we showed the gist of the chapter kind of like a  
100:07 - headline when this chapter started. And when you 
click the expander, when you expand it, you get  
100:12 - the summary of this chapter. So this is what we 
set out to do. When we achieve that, I hope you  
100:17 - were able to follow along. Again, don't forget 
to go grab the code from the GitHub repository.  
100:22 - Welcome to the final project. In this one, you 
will learn a bunch of new exciting technologies.  
100:27 - First of all, you will learn how to do 
real time speech recognition in Python,  
100:32 - then you will learn how to use the open AI 
API and build a virtual assistant or Chatbot.  
100:38 - And finally, you will learn a little bit about 
WebSockets and how to use async i o in Python.  
100:43 - So I think this is going to be really fun. And 
first of all, let me show you the final projects.  
100:48 - And now when I run the code, I can start talking 
to my bot and ask questions. What's your name?  
100:59 - How old are you? What's the best ice cream.  
101:09 - And you'll see this works. So I think this is 
super exciting. So now let's get started. Alright,  
101:16 - so here I have a new project folder. 
And again, we have our API secrets file,  
101:20 - and now a new main.py file. And the first 
thing we're going to do is set up real time  
101:25 - speech recognition. And for this, we have a 
detailed blog post on the assembly API block,  
101:31 - this will walk you through the step by step. 
So first of all, we need pi audio to do the  
101:37 - microphone recording. So this is the very same 
thing that we learned in part one, then we use  
101:43 - WebSockets. And then we use the assembly AI real 
time speech recognition feature that works over  
101:50 - WebSockets. And then we create a function to 
send the data from our microphone recording  
101:55 - and also a function to receive the data. And 
then we can do whatever we want with this. So  
102:02 - but in order to just copy and paste this, let's 
actually code this together. So let's get started  
102:07 - at one note here, in order to use the real time 
feature, you need to upgrade your account, though.  
102:14 - So yeah, but anyway, let's get started. So 
let's import all the things we need. So we want  
102:21 - pi audio again, then we need WebSockets. So we 
say import WebSockets. And this is a third party  
102:30 - library that I showed you in the beginning that 
makes it easy to work with WebSockets. And this is  
102:37 - built on top of async I O. So now we're going to 
build async code. Then we also import async i o we  
102:46 - also import base 64. So we need to encode the data 
to a base 64 string before we send this, and then  
102:56 - we import chasen to receive the chasen result. And 
then we save from API secrets, we import our API  
103:05 - key from Assembly API. And now the first thing we 
set up is set up our microphone recording. So for  
103:12 - this, we use the exact same code that we learned 
in part one. So I simply copy and paste this part  
103:20 - from here. So let's copy and paste. So we set 
up our parameters, then our PI audio instance,  
103:29 - and then we create our stream. And now we need to 
define the URL for the WebSocket. And we can find  
103:38 - this on the blog post homepage. So here, I can 
copy and paste the URL. So the URL is WebSockets,  
103:50 - and then assembly ai.com. And then real time and 
then the last part is also important. So here we  
103:57 - say question mark sample rate equals 16,000. So 
this is the same rates that we use here. So make  
104:05 - sure to align this with what you have. And now we 
create one function to send and receive the data.  
104:12 - And this is a async function. So we say async. 
Def, and we call the Send Receive. So this is  
104:19 - responsible for both sending and receiving the 
data. And now we connect to the web socket. And  
104:25 - we do this with a async context manager. So again, 
we see async and then with and then web sockets  
104:34 - dot connect, and now we specified the parameters 
u or L, then we say a we set a ping, time out, and  
104:46 - we can set this to 20. For example, then we 
want a ping interval and this should be five  
104:54 - and then we also need to send our authorization 
token. So the key or the A parameter for this is  
105:02 - extra headers. And this is a dictionary with the 
key authorial session, and the value is our token.  
105:13 - And then we say, a sync with AES. And then we 
can call this what we want. So I say underscore  
105:20 - W s for WebSocket, then first we wait 
to let this connect. So here we say,  
105:27 - await async i o async, I O dot sleep 0.1. So be 
careful here, we cannot use timeout sleep. So  
105:39 - we are inside a async function. So we have to use 
the async sleep function. And then we wait or we  
105:49 - we tried to connect and wait for the result. 
So we say, session underscore begins equals and  
105:59 - then again, await underscore W s, and then this 
is called R E S, V for received, I guess. And  
106:10 - then we can print the data and see how this looks. 
Let's also print sending messages. And now we need  
106:23 - to enter functions. So again, async functions. So 
we say async, def sent. And for now, we simply say  
106:34 - pass, and then we say async, def receive. And 
here also we pass. And actually, these are both,  
106:45 - these both will have a infinite to while true 
loop. So they will run infinitely and listen for  
106:52 - incoming data. So here, we say while true. 
And for now, let's just print sending. And  
107:04 - here we also say while true. And here, we simply 
pass, so I don't want to spoil our output. And  
107:15 - now after this, we need to combine them in a async 
i o ways. So in order to do this, we say we call  
107:27 - the gather function. So it's called async, I O dot 
gather. And now here we gather sense and receive.  
107:39 - And this will return two things. So the sent 
results, and the receive results. So actually,  
107:50 - we don't need this. But just in case, we have this 
here. And now, after the finding this function,  
107:59 - of course, we also have to run the code. 
And we have to run this in an infinite loop.  
108:06 - And in order to do this, we call async, I O and 
then dot run, and then our Send Receive function.  
108:16 - So now, this should connect, and then should 
print sending all the time. So let's run  
108:27 - this and hope that this works. So yeah, it's 
already connected and sending work. So you see,  
108:35 - that's why I didn't put the receive in here 
as well. So we get a lot of outputs. And yeah,  
108:41 - I can't even scroll to the top anymore. But 
basically, yeah, it should have printed this  
108:48 - once. And then now this is working so far. So we 
can continue implementing these two functions now.  
108:55 - So now let's implement the send function first. 
And we wrap this in a try except block. And now  
109:01 - we read the microphone input. So we say stream dot 
reads, and then we specify the frames per buffer.  
109:08 - And I also want to say exception on overflow 
equals false. So sometimes when the WebSocket  
109:15 - connection is too slow, there might be an 
overflow, and then we have an exception,  
109:19 - but I don't want this it should still work. And 
then we need to convert this or encode it in base  
109:27 - 64. So we say base 64 b 64, encode our data, and 
then we decode it again in UTF. Eight. This is  
109:40 - what assembly AI expects. Then we need to convert 
it to a JSON object. So we say JSON dump s and  
109:49 - then this is a dictionary with the key audio data. 
So again, this is what assembly AI needs. And then  
109:59 - here we put Can the data and then we send this and 
we also have to await this so awaits W s sent the  
110:09 - JSON data, and then we have to catch a few 
errors. So let's copy this from our blog post. So  
110:19 - these ones, let's copy and paste this in here. So, 
um, we accept a WebSockets exceptions connection,  
110:31 - closed error, and we print the error, and we make 
sure it's have this code, and then we also break,  
110:39 - and then we catch every other error. So it's not 
best practice to do it like this, but it's fine  
110:44 - for this simple tutorial. And then we assert here 
and then after each wild, true iteration, we also  
110:53 - sleep again. And yeah, so now we can copy this 
whole code and paste it into this. So the code  
111:04 - is very similar here. So we have the same try 
except, but now here, of course, we have to wait  
111:14 - for the transcription result from Assembly AI. So 
we say result, string equals, and then again, we  
111:25 - wait and then the w SRESV, then we can 
convert this to a dictionary by saying  
111:33 - results equals JSON dot load from a string. And 
here the result string. And now this has a few.  
111:44 - So this is a JSON object, or now in Python, 
it's a dictionary. So now we can check a few  
111:52 - keys. So we can get the prompt or actually, now 
this is the transcription of what we set. So we  
111:58 - say prompt equals results. And then it tests the 
key text. And it also has a key that is called  
112:07 - message type. So now we check if we have a 
prompt, and if the results and then the key  
112:17 - message underscore type. And now this should be 
final transcripts. And now what assembly is doing,  
112:31 - it will while we are talking, it will already 
start sending the transcript. And once we finished  
112:38 - our sentence, it will do another pass and make 
a few small corrections if necessary. And then  
112:44 - we get the final transcript. So we want only the 
final transcripts. And now for now, let's print  
112:55 - me and then let's print the prompt. And now we 
want to use our Chatbot. So now let's print bots.  
113:06 - And then let's for now let's simply print. Let's 
print our random text for now. And then we set up  
113:14 - this in the next step. But first, I want to test 
this. So let's say this is my answer. And this  
113:23 - is all that we need for the receive functions. 
So let's clear this and run this and test this.  
113:33 - We get an error await wasn't used 
with future async i o gather Oh,  
113:38 - this is a classic mistake. Of course, here, 
I have to say await async i o gather. So  
113:45 - let's run this again. And now it's 
working. So yeah. What's your name?  
113:56 - And you see the transcript is working. So no, 
I stopped this. But if I scroll up, what's your  
114:03 - name? And each time we get this as my answer. So 
this is working. And now of course here we want to  
114:11 - do a clever thing with our prompt and 
use our virtual assistant. So for this,  
114:18 - we now set up open AI. So they have a 
API that provides access to GPT three.  
114:28 - And this can perform a wide variety of natural 
language tasks. So in order to use this,  
114:35 - you have to sign up but you can do this for free 
and you get a free you get free credits. So this  
114:41 - will be more than enough to play around with 
this. And it's actually super simple to set this  
114:47 - up. So let's create a new file. And I call 
this let's call this open a i helper.py.  
114:58 - And then you We also have to install this. 
So we have to say pip install open API.  
115:08 - And then we also after signing up, you get 
the API token. So we have to copy this in  
115:16 - API secrets. And then we can use this. And now we 
can import open API. And we also need to import  
115:23 - our secret. So from API secrets, we import our API 
key open API, then we have to set this so we say  
115:33 - Open API dot API key equals API key. And now we 
want to do question answering. So the open API API  
115:46 - is actually super simple to use. So we can click 
on examples. And then we see a bunch of different  
115:53 - examples. So open AI can do a lot of things, for 
example, q&a, grammar, correction, text to command  
116:01 - classification, a lot of different stuff. So 
let's click on Q and A. And if we scroll down,  
116:10 - then here we find the code examples. So we already 
set our API key. And now we need to grab this. And  
116:22 - let's copy this and let's create a helper 
function. So define, and let's call this ask  
116:29 - computer. And this gets the prompt as 
input. And now I paste this in here.  
116:36 - So we say response equals open AI dot completion 
dot create. Then here we specify an engine.  
116:47 - And now we specify the prompt. And in 
our case, the prompt is going to be  
116:56 - the prompt that we put in. So prompt equals 
prompt from the parameter. And now there are a  
117:03 - lot of other different parameters that you could 
check out and the documentation. So in my case,  
117:10 - I only want to keep the max tokens. So this was 
specify how long the result can be. And yeah,  
117:19 - let's say 100 is fine for this. And now this is 
all that we need. And now of course, we need to  
117:28 - return the response. And this is actually a JSON 
object, again, are now a dictionary. And we only  
117:36 - want to extract the first possible response. So 
it can also send more if you specify this here.  
117:44 - So in our case, we only get one. And then 
we say response. And this is in the key  
117:52 - choices, and then the index zero. So the first 
choice, and then the key texts. So this will  
118:01 - be the actual response from GPT, three. And now in 
the main, the only thing we have to do is say from  
118:11 - open AI helper, we import ask, come pewter, 
and then down here in the receive functions.  
118:22 - Now here we say. Response equals ask computer, 
and then we put in the parent, and then here,  
118:36 - this will be our response. And no, this should 
be everything that we need. So now let's again,  
118:44 - clear this and run the main.pi. And let's hope 
this works. What's your name? What's your name?  
118:58 - How old are you? Where are you from?  
119:08 - All right, so let's stop this again. And yeah, 
you see this works. And this is how you can  
119:13 - build a virtual assistant that works with real 
time speech recognition together with open AI.  
119:20 - And yeah, I really hope you enjoyed this 
project. If you've watched this far,  
119:23 - thank you so much for following along. And also, 
I hope to see you in the future on the assembly AI  
119:29 - channel because on there we also create a lot 
of content around Python speech recognition,  
119:33 - and also machine learning. So please check 
it out. And then I hope to see you soon. Bye