00:00 - Lang chain is a framework for developing
00:01 - applications powered by large language
00:03 - models like gp4 in this course you will
00:06 - learn Lang Chain by building six inin
00:09 - projects with the open AI API Google
00:12 - Gemini Pro and llama 2 you'll also learn
00:16 - how to deploy projects to the hugging
00:17 - face platform Chris neack developed this
00:20 - course considering this here is an
00:22 - amazing video of the entire Lang chain
00:25 - crash course along with this we'll be
00:27 - discussing six plus endtoend projects
00:30 - llm projects using different different
00:32 - llm models from open AI we'll be using
00:35 - Lama 2 from meta we'll also be using
00:38 - Google giny pro not only that we'll also
00:40 - be using hugging face and we'll also be
00:42 - seeing how we can deploy this in hugging
00:44 - space uh platform itself which is
00:47 - provided by hugging face itself right so
00:49 - there will be somewhere around six plus
00:51 - end to end projects we'll develop both
00:52 - the front end back end I hope you enjoy
00:55 - this entire Series this is a long video
00:58 - so please make sure that you devote some
00:59 - some amount of time every day and try to
01:03 - practice as much more you can right so
01:06 - in order to push this video to many
01:08 - people out there guys I'll keep the like
01:10 - Target to 2,000 please make sure that
01:12 - you hit like share with all the friends
01:14 - share your work in LinkedIn in different
01:17 - platforms tag me over there I'll be very
01:19 - happy to see what all things you
01:20 - specifically developing so let's go
01:22 - ahead and enjoy the series and I hope
01:25 - you practice along with me all the
01:26 - materials will be given in the
01:28 - description of this particular video so
01:30 - let's go ahead guys so finally finally
01:32 - finally here is the langin series and
01:34 - this is probably the first video where
01:37 - I'm probably going to discuss a very
01:39 - good one-hot video about Lang chain all
01:42 - the important components that you
01:44 - specifically need to know to build
01:47 - projects now why I'm stressing on langin
01:50 - is that because many people recently
01:53 - some of my students and some of
01:55 - experienced professional who switched
01:57 - into data science Industry they are
01:59 - getting work that are related to large
02:01 - language models and they're specifically
02:03 - using Lang chain and the community with
02:05 - respect to langin is also increasing so
02:08 - that is the reason I've created this
02:09 - dedicated playlist and I'm going to
02:12 - discuss a lot many things this video we
02:15 - will understand all the important
02:16 - competents of this Lang chain what you
02:18 - specifically need to know with respect
02:20 - to the Practical orientation and from
02:22 - the next video onwards lot of end to
02:25 - endend projects are probably going to
02:26 - come up uh in this video also I'll
02:28 - discuss about one Q&A project uh chatbot
02:32 - in short you know we'll try to use
02:33 - streamlet it's not like we only have to
02:36 - use streamlet you can also use flask you
02:37 - can use anything as you want right but
02:40 - streamlet it provides you a good UI you
02:42 - can also use gradio if you want right it
02:44 - is up to you so what all things we are
02:47 - specifically going to discuss first of
02:48 - all we'll try to understand the agenda
02:50 - and then we will try to uh do step by
02:53 - step each and every line of code will be
02:55 - done and as I said this is just like a
02:58 - kind of L chain one shot video just to
03:01 - give you an example that how we are
03:02 - probably going to create our end to
03:04 - endend application after we deploy that
03:06 - in a specific cloud like hugging phas
03:09 - right it provides your entire
03:10 - environment to probably host your
03:12 - application uh this is what we are going
03:14 - to create this chatbot see if I probably
03:16 - ask what is the capital of New oh sorry
03:21 - of India then you'll be able to see that
03:24 - I'm I'll be able to get the answer what
03:25 - is the capital of Australia many people
03:28 - get confused with the capital Australia
03:30 - please do comment down in the comment
03:32 - section what is the capital of Australia
03:33 - and let's see whether it is right or not
03:35 - so here you can see the capital of
03:37 - Australia scan so we are going to create
03:38 - this application at the end of the day
03:40 - but before that we really need to
03:42 - understand lot of important components
03:44 - in Lang chain so let's go ahead and
03:46 - let's start this particular session
03:48 - before I go ahead please make sure that
03:50 - you subscribe the channel press the Bell
03:51 - notification icon and share with many
03:53 - friend so that it will also be helpful
03:56 - for them and it will also be helpful for
03:59 - me so that you are able to provide this
04:01 - open source content to everyone out
04:03 - there many people require help and you
04:06 - should be the medium to provide this
04:08 - specific help by just sharing it right
04:10 - so what is the agenda we'll understand
04:13 - as I said this will be completely a
04:15 - practical oriented video it'll be a long
04:17 - video where I'll be talking more about
04:19 - practical things how you can Implement
04:21 - Lang chain how you can probably
04:22 - implement various important
04:24 - functionalities in Lang chain and use it
04:26 - probably to build an endtoend
04:27 - application so first of all we'll go
04:29 - ahead and do the environment setup this
04:30 - is commonly required you also require an
04:32 - open AI key API key so this also I will
04:35 - show you how it is done then we'll try
04:37 - to build simple applications uh with the
04:40 - help of llms three important things are
04:41 - there llms prompt templates and output
04:44 - parsel okay in llms you specifically
04:47 - have llms and chat models chat models
04:49 - are basically used in chat B to
04:51 - understand the context reference and all
04:54 - right I will also be discussing this
04:55 - practical promt templates can play a
04:58 - very important role and then coming to
05:00 - the third one that is called as output
05:02 - parser uh in short prompt template and
05:05 - llms and output parser gives a very good
05:07 - combination of output like it it'll give
05:09 - you a good output the output like you
05:12 - specifically want right so that is where
05:14 - output Parcels will also be used before
05:16 - to go ahead with what I will do is that
05:19 - uh first of all just go to the open aai
05:21 - uh website itself and get your API key
05:23 - how you should get it just go to this
05:25 - account and there you'll be able to see
05:26 - view API key and create the new C secret
05:30 - key right so once you create it give the
05:32 - key name and then copy it and keep it
05:34 - right I'm not going to share mine so
05:36 - that is the reason why I'm showing you
05:38 - this specific step now I will go to my
05:41 - vs code all my coding will be done in
05:43 - this VSS code itself here you can see it
05:45 - is completely blank right I've just
05:48 - opened a folder in the form of a project
05:51 - now all you have to do start your
05:52 - project over here now the first thing as
05:55 - usual what we need to do we need to
05:57 - create a new environment right so this
06:00 - is the first step that you specifically
06:03 - need to create with respect to an
06:05 - environment so don't miss this specific
06:07 - step it is important and probably
06:10 - whatever projects that we are going to
06:12 - discuss in the future we have to do the
06:14 - specific step so I will write pip
06:17 - install okay sorry cond create I'm
06:21 - creating an environment so let me just
06:24 - not open in Powers shelf instead I'll go
06:26 - and open in command prompt okay so here
06:28 - I will just right K create minus p v
06:35 - EnV V
06:37 - EnV
06:39 - python equal to 3.9 so 3.9 is the
06:43 - version that I'm going to specifically
06:44 - use and also going to give- Y so that it
06:47 - does not ask me for the permission
06:49 - instead start creating the specific
06:51 - environment the reason why I'm using
06:53 - this environment understand one thing
06:55 - that guys for every project that we
06:57 - probably create we have to create a new
07:00 - environment that actually helps us to
07:02 - just understand or just use only those
07:04 - libraries that are actually required for
07:06 - this particular project okay so this is
07:09 - the first step go ahead do it with me
07:11 - you know uh and do it in vs code because
07:14 - vs code is a good idea if you want to do
07:16 - it in pycharm then also you can do it
07:18 - but since you following this tutorial
07:20 - I'm actually going to do it in vs code I
07:22 - feel vs code is good I I've used both
07:25 - okay I've used different different IDs
07:26 - but I feel vs code is good okay so here
07:29 - it is now here you can probably see my V
07:32 - EnV environment uh the next thing we
07:35 - will go ahead and activate this V EnV
07:37 - environment so I will write cond
07:40 - activate
07:42 - cond activate V EnV Dash Okay so this is
07:46 - my first step done I'm good with it now
07:49 - the next thing what I will go to do is
07:51 - that I will just go ahead and write my
07:54 - requirement. thxt right because we need
07:57 - to install the library since inside this
07:59 - particular venv environment so I will go
08:02 - ahead and write all the list of
08:04 - libraries that I'm specifically going to
08:06 - use now what are libraries I'm going to
08:08 - use over here uh we will just write it
08:11 - down so that uh the first library that
08:13 - I'm going to use is Lang chain then open
08:16 - Ai and I think I'll be using hugging
08:19 - face also later on it is called as
08:21 - hugging face Hub that I will show you as
08:24 - we go ahead okay so these are the two
08:26 - libraries that I'm going to specifically
08:28 - use okay now the next thing what I will
08:30 - do I will go ahead and write pip install
08:33 - minus
08:34 - r okay so let me just hide my face so
08:38 - that you'll be able to see pip install
08:39 - minus r requirement. txt so once this
08:43 - installation will take place that
08:45 - basically means my requirement. txt is
08:48 - getting installed that basically means
08:50 - all the libraries that I actually
08:52 - require over here that is getting
08:53 - installed and for this I require Lang
08:55 - chain and open aai okay so once this
08:58 - installation will will be taken place
09:00 - like it will be done now one more
09:02 - Library I'll be required is called as
09:04 - IPI kernel because if I really want to
09:06 - run any Jupiter notebook over here I
09:09 - have to use that okay so let's wait and
09:12 - let's see once the installation is
09:14 - probably done and then we will continue
09:16 - the video so guys the all the libraries
09:19 - that were present in the requirement.
09:21 - txt has been installed now the next step
09:24 - that I'm probably going to do is also
09:26 - install IPI kernel which will be
09:29 - required to run my Jupiter notebook so I
09:32 - will go ahead and write pip install iy
09:35 - kernel Now understand one thing I'm not
09:38 - writing this library in requirement. txt
09:40 - because when we do the deployment in the
09:43 - cloud IPI kernel will not be required
09:45 - okay so that is the reason I'm
09:47 - installing separately pip install IPI
09:49 - kernel in the same VNV environment
09:52 - because VNV environment also we are not
09:54 - going to push it right so you can
09:56 - probably see over here downloading this
09:58 - this will happen and automatically the
10:00 - download will happen itself right now
10:02 - the next thing what I'm going to do I'm
10:05 - just going to write Lang chain dot
10:10 - ipynb okay py NB so this will basically
10:15 - be my jupyter notebook that I will
10:17 - specifically be using okay so right now
10:19 - it is detecting kernel once this
10:21 - installation will probably happen and
10:23 - then we will also be able to see the
10:25 - kernel okay so this is all the steps all
10:28 - the basic steps that you probably
10:30 - require from this you can start creating
10:32 - end to endend project but at least you
10:34 - require this uh along with this I'm also
10:36 - going to add two more steps one is about
10:39 - environment files EnV file okay so here
10:42 - what I will do I will write Dov file
10:46 - okay uh inside this EnV file the reason
10:48 - why I'm uh writing this EnV file because
10:51 - I need to probably use my open API key
10:54 - and probably mention the open API key
10:56 - over here so if I probably write it like
10:58 - this and and whatever API key that I'm
11:01 - probably getting from the website I can
11:02 - upload it over here and using right uh
11:06 - load environment function right we can
11:09 - load this API key uh as a variable so
11:12 - that we can actually call our API API
11:14 - key over there so I will update this
11:15 - later on as we go ahead okay so till
11:18 - here everything is done this is my Lang
11:20 - chin ipynb file I will go ahead and
11:23 - detect the environment this is what
11:25 - 3.9.0 so here it is so let's see whether
11:28 - it is working or not 1+ one it's working
11:32 - right so this is perfectly all right so
11:34 - everything over here is done with a
11:37 - respect to this and I'm very much Happy
11:38 - this is working uh which is really
11:40 - really good okay so this is done now
11:43 - what I am actually going to do over here
11:45 - is that we need to import some of the
11:48 - important libraries like open Ai and all
11:51 - right so for this I will go ahead and
11:53 - right from Lang
11:56 - chain. llms
11:59 - okay
12:01 - import open AI see there there lot many
12:05 - models like open llms and all first
12:07 - we'll start with open AI understand one
12:10 - thing guys the reason why I say this is
12:12 - completely practical oriented because
12:14 - you need to have the basic knowledge of
12:17 - machine learning deep learning and all
12:19 - but this specific libraries is used to
12:21 - build application uh fine tune your
12:24 - application with respect to models with
12:26 - respect to your own data set most of the
12:29 - things just with writing proper lines of
12:31 - code will be implemented in an easier
12:33 - way so you really need to focus on
12:35 - things how things are basically done
12:37 - okay now the next thing what I will do I
12:39 - will write import OS and I will say OS
12:42 - do Environ
12:45 - environment okay and here I will give my
12:51 - opencore API underscore key okay this is
12:56 - how you should basically write it down
12:59 - to import the API key now what I will do
13:02 - I will keep this hidden from you so just
13:05 - imagine I cannot show you the API key
13:07 - because I will be using my own personal
13:09 - API key itself so I will go ahead and
13:12 - probably pause my video and update the
13:14 - API key and I'll remove this specific
13:16 - code okay that is what I'm actually
13:18 - going to do so that none of you
13:20 - basically sees that and it is important
13:23 - you have to use your own API key so let
13:25 - me quickly go ahead and do that and let
13:27 - me come back so guys this is how you
13:31 - have to probably import your API key
13:33 - this will I've made some changes so if
13:35 - you also copy it is not going to work I
13:38 - made some internal changes in between
13:39 - changes so uh you just need to write os.
13:42 - environment open API key and this API
13:45 - key that you have specifically got okay
13:48 - so this is the initial step uh I have
13:50 - also imported open AI so that I will be
13:52 - able to call this particular uh open AI
13:55 - itself now this is done this is good
13:57 - everything is working Absol absolutely
13:59 - fine now what I'm actually going to do
14:00 - I'm going to create my llm model and go
14:03 - ahead and write my open AI let's see
14:06 - open AI open AI function is the called
14:09 - or not let's see okay open AI from L
14:11 - chin open Ai and inside this open AI
14:14 - what I'm actually going to do I'm going
14:16 - to basically call a variable which is
14:18 - called as temperature and temperature
14:20 - right now you can keep the value between
14:22 - 0 to 1 the more the value towards one
14:25 - the more different kind of creative
14:27 - answers you may get right if the value
14:30 - is towards zero then what kind of output
14:33 - you you are probably getting from the
14:34 - llm model is going to be almost same
14:36 - from the uh anytime you number anytime
14:39 - you probably execute so here I'm just
14:41 - going to keep it as 6 so this is
14:43 - basically my open a llm model okay now
14:47 - this is done my llm model is there so
14:49 - here you can see did not find an open AI
14:51 - key please add an environment variable
14:54 - open AI key now this is the error that
14:56 - you are specifically getting right so
14:59 - why this particular error is probably
15:01 - coming you should definitely understand
15:03 - okay without
15:05 - this understand that this kind of Errors
15:07 - can come to you the reason why I will
15:10 - not edit this particular error because I
15:11 - really want you all to understand it is
15:13 - saying did not find open API key now
15:16 - what you can probably do with respect to
15:18 - this okay there are two different things
15:20 - that you can probably do either you can
15:22 - take this API key save it in a constant
15:25 - variable and try to use that particular
15:26 - variable over here right so for that
15:29 - also you can directly do that uh I have
15:31 - also created this do EnV file what you
15:34 - can do you can load this environment
15:36 - variable and probably directly read it
15:38 - over there right but let me just go
15:41 - ahead with a simple way you know so you
15:43 - will be able to understand with respect
15:45 - to that also so here what I'm going to
15:47 - do here I will go ahead and probably say
15:50 - open API key and here I will going to
15:52 - write OS do
15:55 - environment okay and here I'm going to
15:57 - Define my open API key okay now let's
16:01 - see whether this will get executed or
16:03 - not I will show you much more better
16:04 - ways when we are probably executing our
16:07 - end to end application so let me go
16:09 - ahead uh open a key is not defined
16:12 - because I use double equal to perfect
16:15 - now you can see that it has got executed
16:18 - perfectly now when I am actually
16:20 - creating an end to end project I will
16:22 - show you a better way the most efficient
16:24 - way that we should specifically use when
16:26 - we are building an end to end project
16:27 - but right now I'll go to focus like this
16:30 - now understand one thing is that with
16:32 - respect to temperature variable right
16:35 - the temperature that we specifically
16:36 - used I will give a comment over here and
16:39 - you can probably see over here right so
16:42 - temperature value how creative we want
16:45 - our model to be zero means temperature
16:47 - it is it mean model is very safe it is
16:49 - not taking any bets it will risk it
16:51 - might generate wrong output may be
16:53 - creative so more the value towards one
16:57 - the more creative if the model becomes
17:00 - right it is going to take more risk to
17:02 - provide you some more better but again
17:04 - with respect to risk again there may be
17:05 - a problem you may get a wrong output
17:08 - perfect this is the step simple step
17:10 - that we have done at the end in this
17:13 - video only I'm going to probably do
17:16 - create an end to end project understand
17:18 - this will be very important for everyone
17:20 - because as we go ahead in the next
17:22 - videos the project difficulty will keep
17:24 - on increasing okay now this is done now
17:27 - what I will do quickly I will go ahead
17:29 - and write text let's say the text is
17:32 - what is the capital of India okay so
17:39 - here I will write print llm do predict
17:45 - and here I'm going to basically write my
17:47 - text so here you can see the capital of
17:50 - India is New Delhi so here what I have
17:52 - done is that this is my input and if we
17:54 - use lm. predict I'm going to probably
17:57 - get the text so if you like liking this
17:58 - video till here guys as I'm teaching you
18:01 - step by step I'm explaining you each and
18:03 - everything please make sure that you
18:05 - practice in a better way right if you
18:07 - like it please make sure that you
18:08 - subscribe the channel also okay so this
18:11 - is done lm. predict and we are able to
18:13 - probably get the output okay so
18:17 - understand what what all things we did
18:18 - we created an open AI model right but
18:21 - here in the open AI right you should
18:24 - also understand one important thing here
18:26 - there is a parameter which is called as
18:28 - model now what all model you can
18:31 - probably bring it over here what all
18:33 - model you can probably call so here I
18:35 - will go to my documentation page okay
18:38 - and uh if I probably click on the models
18:41 - now here are the set of models that you
18:43 - can probably use by default it is
18:46 - calling this GPT 3.5 turbo it is the
18:49 - most capable GPT 3.5 model and optimized
18:52 - for chat at the 110th cost of a Dy 003
18:56 - we'll be updated with our latest model
18:58 - iteration 2 weeks after it is released
19:00 - it's not like you only have to use this
19:01 - you can use this you can use this you
19:03 - can use this you can use this whatever
19:06 - models you want you can probably use it
19:08 - if you want to probably go with GPT 4
19:10 - you can use this you can use this you
19:12 - can use this but at the end of the day
19:14 - gp4 is the most uh amazing thing it is
19:17 - more capable than GPT 3.5 so this is
19:20 - what models is by default over there it
19:23 - is probably taking this specific model
19:25 - which you can probably use it now as we
19:27 - go ahead it is not like you can only
19:29 - call this model itself in hugging face
19:32 - you have open source models also right
19:34 - from Google from different companies you
19:36 - have that uh open source llm models you
19:38 - can also call that and I will also show
19:40 - you an example with respect to that okay
19:43 - so till here I hope you have understood
19:45 - it I think you should give a thumbs up
19:47 - if you're able to understand till here
19:49 - now let's go ahead and do one more thing
19:52 - I will also show you with respect to
19:53 - hugging face now okay now with respect
19:55 - to hugging face what I will do I will
19:57 - quickly go ahead head and write hugging
20:01 - facehub right I will probably install
20:04 - this library now let me go ahead and
20:06 - open my
20:07 - terminal okay so I will delete this and
20:11 - quickly we will go ahead and write pip
20:17 - install pip
20:18 - install minr requirement.
20:25 - txd done so this is getting executed and
20:28 - then I will probably show you with
20:29 - respect to hugging face also so hugging
20:32 - face this is done okay the installation
20:34 - is done so you have to use hugging face
20:37 - Hub now in case of hugging face also
20:39 - right you will specifically get
20:44 - a you will also be getting a because at
20:48 - the end of the day we'll also try to
20:49 - deploy it over here if you go to
20:51 - settings right and if you go to access
20:54 - tokens here you can probably see I have
20:57 - some kind of token right and with the
20:59 - help of this particular token only you
21:01 - will be able to call any models that are
21:04 - available over here so in this models if
21:06 - you probably go ahead and see there are
21:07 - lot of llm models that are available
21:09 - right so if you probably go over here
21:11 - natural language token classification
21:13 - question answer like uh let's say text
21:16 - to text generation this is basically one
21:17 - kind of llm model I will search for one
21:20 - name okay so the name is
21:22 - flan okay flan T5 base okay so this
21:26 - specific model or T5 large this is a
21:29 - text to text generation model right so
21:31 - this is also an llm model if I want I
21:34 - can use this also why I can use this
21:36 - because this is an open source okay if
21:38 - you want to probably see the answer
21:40 - right text to text generat false or not
21:42 - false or false is uh if I want to
21:44 - compute it right it'll give me some
21:46 - specific output okay false or false or
21:48 - false is the verb the verb right
21:50 - something like this it is getting an
21:51 - output right so I can also use my I can
21:55 - also create my chat models with the help
21:56 - of this kind of models directly by using
21:58 - this API right but how to do it let's go
22:01 - ahead and see it okay so here what I
22:03 - will do quickly I will first of all
22:06 - import one more important thing again in
22:09 - my environment
22:11 - variable os. environment and here I'm
22:14 - going to basically write in the case of
22:15 - hugging P I have to use something called
22:18 - as hugging oops I have to write in
22:21 - capital letter hugging
22:24 - face hubor API uncore to token okay so
22:30 - here is my token okay hugging face Hub _
22:34 - API _ token now with respect to this
22:37 - particular token I have to write my own
22:39 - token the token is basically given over
22:41 - here as I have already shown you if I
22:43 - probably click on show you'll also be
22:45 - able to see it so I'm not going to do
22:46 - the show part over here so what I will
22:48 - do I will just pause the video upload it
22:51 - execute it change the token and then
22:53 - come back to you okay so let's go ahead
22:55 - till then you can go ahead and create a
22:57 - hugging face account also so guys now I
23:00 - have set up my hugging face Hub API
23:03 - token with this specific token again
23:05 - I've made the changes so if you probably
23:06 - use this again it will not work okay but
23:09 - I have actually imported it now let's go
23:12 - ahead and probably see how we can
23:14 - probably call llm models with the help
23:16 - of hugging face so again and again I'll
23:18 - be using Lang chain Lang chin is just
23:20 - like a wrapper it can call open llm
23:22 - models it can call hugging face uh llm
23:25 - models anything you can probably call
23:27 - with it okay so that is the reason why
23:29 - I'm saying it is powerful so I will
23:31 - write from Lang chain okay
23:35 - import hugging face Hub okay and then
23:39 - here I'm going to probably Define
23:43 - my let me just execute it and then
23:45 - probably I will call it so here I will
23:48 - go and write hugging face
23:49 - Hub here first of all I need to give my
23:52 - repo ID now repo ID is nothing but uh
23:54 - whenever you search for any model this
23:56 - will be your repo ID Okay Google slash
23:59 - this okay so here I'm going to probably
24:01 - go ahead and Define
24:03 - it okay and this will basically be given
24:06 - in a sentence
24:08 - form okay so this is done now the next
24:11 - thing that I will have is model quarks
24:14 - okay and here I will go ahead and Define
24:16 - my
24:25 - temperature and then here I'll go ahead
24:28 - and write max
24:31 - length column 64 that basically means
24:34 - I'm giving the maximum string length to
24:36 - 64 okay now let's see whether this will
24:38 - execute or not I know it is going to
24:40 - give us an error let's see so it is not
24:43 - giving you an error it is probably
24:44 - executing it perfectly it has probably
24:47 - taken that particular key itself
24:49 - inference API is working perfectly
24:51 - everything is working so I will go ahead
24:52 - and Define my variable so here I'm going
24:55 - to basically write my l lmore hugging
25:00 - face okay is equal to this one right so
25:04 - this is done we have probably written
25:07 - this specific thing over here and then I
25:09 - will go ahead and write name or I will
25:12 - see
25:13 - output let's see the output and here I'm
25:16 - going to basically write llm do hugging
25:17 - face do predict and let's say I'll say
25:23 - can you tell me the capital of of Russia
25:29 - okay so let's see whether we will be
25:31 - able to get the output or not so here
25:33 - I'm going to write print output and
25:36 - let's see whether we are so here you can
25:38 - see the output is a simple word right
25:42 - the capital of Russia is Moscow right
25:46 - but here the previous output that we saw
25:48 - with respect to the llm models here it
25:50 - shows that capital of India is New Delhi
25:52 - it is giving you entire sentence and
25:54 - probably here it is just giving you a
25:55 - word and this is what the difference is
25:58 - with respect to an open source uh model
26:00 - itself and models like GPD 3.5 or 4
26:04 - right so here uh you can probably see
26:05 - this okay and I will also execute one
26:08 - more thing over here let's see uh can
26:10 - you write a
26:13 - poem can you write a
26:17 - poem about
26:20 - AI let's say I give this what kind of
26:23 - poem it
26:24 - gives okay it probably taking time to
26:28 - probably give the I love the way I look
26:29 - at the world I love the way I
26:32 - feel the way I think I feel I love the
26:34 - way I love see what kind of output
26:37 - you're specifically getting right now if
26:39 - I probably give the same output and
26:43 - probably write
26:44 - llm okay dot
26:48 - predict llm dot predict and if I
26:52 - probably give the same sentence let's
26:55 - see what is the output now you will be
26:57 - able to understand why we are
26:59 - specifically using
27:01 - this let's
27:03 - see it should give you a better output I
27:06 - think I love the way I look at the world
27:09 - oh so mysterious was so curious It's
27:12 - technology so advanced IT Evolution so
27:14 - enhance it's a tool that can assist um
27:17 - in making life much less hectic a force
27:20 - that can be used for good or a cause
27:23 - that's misunderstood it can make
27:25 - decisions so Swift and learn from the
27:27 - sto Swift tool that can be better see so
27:30 - how what an amazing poem it has
27:31 - basically written and by this you'll be
27:34 - able to understand the differences why
27:37 - I'm specifically using this open AI
27:39 - model and with respect to hugging face
27:41 - yes there are also some models which you
27:42 - can probably take paid one in hugging
27:44 - face that will give you better output
27:47 - but this is what happens with respect to
27:48 - open source uh models I think we should
27:51 - uh we have lot of Open Source models
27:53 - that are probably coming up Mr 7B and
27:55 - all that also we'll be seeing in this
27:57 - playlist as we go ahead but as I said
27:59 - this is just a basic thing to probably
28:00 - understand we will be focusing on
28:02 - understanding these things right so here
28:04 - uh till here I hope we have discussed so
28:06 - many things how to probably call open AI
28:09 - models with respect to open AI uh
28:11 - Library API itself and then hugging face
28:13 - API also llm models right and using Lang
28:15 - chain so here are what all things we
28:17 - have done now the next thing that we are
28:19 - probably going to discuss is about
28:20 - prompt templates prompt template is
28:23 - super amazing uh it will be very very
28:25 - handy when we are talking about about
28:27 - things with respect to prom template and
28:29 - all so that also we are going to discuss
28:31 - as we go ahead so guys now let's go
28:34 - ahead and discuss about prompt templates
28:36 - which is again a very handy component in
28:38 - the Lang chain even in open AI with the
28:41 - help of prompt templates you will be
28:43 - able to get efficient answers from the
28:46 - llm models itself right I'm not talking
28:48 - about prompt engineering that can get
28:50 - you three CR package okay I'm just
28:52 - talking about simple prompt templates
28:54 - and how prompt templates can be probably
28:56 - used okay now now let's go ahead and
28:58 - first of all import from Lang
29:02 - chain from Lang chain. prompts import
29:07 - prompt template okay uh what we are
29:10 - going to do is that whenever we call a
29:12 - specific llm model you know the llm
29:15 - model should know what kind of input it
29:17 - is probably expecting from the client or
29:20 - from the end user and what kind of
29:22 - output it should probably give it okay
29:25 - so what we do if you want to really
29:26 - Define how our input should be and how
29:28 - our output should be we can specifically
29:30 - use prompt template because understand
29:32 - if we directly use GPD 3.5 it can be
29:35 - used for various purposes right but here
29:37 - I want to restrict all those things
29:40 - within something right so with respect
29:42 - to the input and the output so here I'm
29:43 - going to probably Define my promt
29:45 - template so let me go ahead and Define
29:48 - my promt template now with respect to
29:50 - the promt template here first thing that
29:52 - we need to Define is our input variables
29:55 - so here I will go ahead and write write
29:57 - my input
29:59 - variables okay now in input variables we
30:03 - need to first of all say that what input
30:05 - we are specifically giving there will be
30:07 - a fixed template in that template I
30:10 - really need to give my input okay so
30:12 - let's say here I Define my input and
30:15 - here I'm just using one input let's say
30:17 - the capital or the country I'm just
30:20 - going to write it as country okay so
30:22 - this is my first parameter that I'm
30:23 - going to probably give in my template
30:25 - itself and this I will also store it in
30:28 - my variable which is called as promt
30:30 - template
30:31 - okay great now here I'm given country as
30:35 - my input variable okay here I will
30:38 - Define my
30:39 - template now inside this template what
30:42 - I'm going to say is that tell me the
30:46 - capital
30:48 - capital
30:50 - of
30:52 - this whatever template that I'm
30:55 - specifically giving that is country
30:57 - so this is just like my variable
31:00 - whenever I give the input to this
31:02 - variable it is going to replace it over
31:04 - here right so what will happen by this
31:07 - is that the open AI will be able to
31:10 - understand okay this is the question
31:11 - that is asked but this value is dynamic
31:15 - that I'm probably giving it during the
31:16 - run time something like that okay now
31:19 - here if I want to execute this again I
31:22 - can also write
31:25 - prompt uncore template
31:28 - okay prompt undor
31:32 - template uh dot format right so there is
31:36 - a function called as do format and here
31:38 - now instead of how should I give my
31:40 - input so here I will say
31:43 - country is equal to right whatever the
31:46 - variable name is country is equal to
31:47 - let's say
31:49 - India okay now here you can see that my
31:52 - entire prompt is generated in this way
31:55 - saying that tell me the capital of India
31:59 - okay so here you can probably see tell
32:00 - me the capital of India right now if I
32:03 - want to probably predict I will write
32:04 - llm do predict okay and here I will just
32:08 - say prompt template is equal to whatever
32:12 - my prompt template is defined so here
32:14 - I'm getting an error predict missing one
32:17 - required positional argument text now
32:20 - inside this I've given this prom
32:22 - template but it is expecting one text
32:25 - right what is that particular text that
32:27 - that is particular this particular value
32:28 - right so here what I will do I will go
32:31 - ahead and Define my second variable text
32:34 - and here I will write it as India let's
32:36 - see whether it will get executed still
32:38 - it is giving me an error so guys now you
32:40 - can see when I'm using this llm do
32:42 - predict and I've given my prompt
32:44 - template I've given my text also that
32:45 - was the error that was coming but still
32:47 - it is giving me an error saying that the
32:49 - prompt is expected to be a string
32:51 - instead found class list this this if
32:54 - you want to run the llm multiple prompts
32:56 - use gener instead okay something like
32:59 - this I will show you a way because that
33:01 - is the reason the reason I'm keeping
33:03 - this error over here there is a simple
33:05 - way of understanding things right
33:07 - because this is not the right way to
33:09 - call promt template along with the
33:11 - inputs itself so what I'm going to do
33:14 - quickly I will go ahead and import one
33:16 - important thing that is called as chains
33:20 - so I will say from Lang chain dot
33:24 - chains import llm chain understand one
33:29 - thing guys chain basically means combine
33:32 - multiple things and then probably
33:34 - execute I have my llm model I have my
33:36 - prompt I know I have to give my input
33:38 - based on that input I need to probably
33:40 - get the output so instead of executing
33:43 - directly by using llm do predict I'm
33:46 - going to use llm chain and inside that
33:48 - I'm going to give my llm model I'm going
33:50 - to give the prom template and I'm also
33:52 - going to give the input so this is what
33:54 - we are specifically going to do now this
33:56 - will get gots executed from Lang chain.
33:59 - chain import llm chain now I'm going to
34:01 - create my chain let's say the chain is
34:03 - equal to
34:05 - llm
34:07 - chain and here I'm going to basically
34:10 - write llm is equal to llm okay whatever
34:12 - is my llm model and my prompt is equal
34:14 - to my prompt template okay now this is
34:19 - there this is my chain not chain what it
34:21 - is doing it is combining the llm model
34:23 - it knows what is the prompt template
34:25 - right I'm going to use both of them and
34:28 - now in order to run it so I will write
34:30 - chain. run and here I will say India
34:34 - let's say I'm going to probably say
34:36 - India and I know what is the output it
34:40 - is going to get tell me the capital of
34:42 - India so if I write chain. run it is
34:44 - definitely going to give me the output
34:46 - the capital of India is New Delhi this
34:49 - is perfect right so I can also probably
34:51 - print it right see guys I'm not going to
34:55 - delete any of the errors I want you all
34:57 - to see the errors and then try to
34:59 - understand that is the best way of
35:02 - learning things okay other than this
35:04 - there is no other way right you need to
35:07 - find a way to learn things you don't
35:09 - worry about any errors that are probably
35:11 - coming up you just worry about okay fine
35:14 - you have got that error how you can
35:16 - probably fix that what is the alternate
35:18 - way of probably fixing it right so you
35:21 - can probably use all these techniques as
35:22 - we go ahead right so this is with
35:25 - respect to prompt template and here I'm
35:27 - going to also talk about and llm chain
35:30 - right so these are some important things
35:32 - because all these things we will
35:33 - probably be using in creating our end to
35:36 - end application now let's go ahead and
35:39 - probably discuss some more examples with
35:41 - respect to llm so guys now we are
35:44 - understanding one more important topic
35:46 - which is called as combining multiple
35:48 - chains using simple sequential chain
35:50 - till here we have understood about llm
35:52 - chain LM chain was able to combine an
35:54 - llm model along with the prompt template
35:57 - through which we can also give our input
35:58 - and get our specific output now if I
36:01 - have multiple chain let's say if I'm
36:03 - giving one input I want to use those
36:05 - input in both the chain or three chains
36:07 - four chains how can I specifically do it
36:09 - and for that I'm going to probably use
36:11 - Simple sequential chain okay so let us
36:14 - go ahead and let us probably see how
36:16 - this can probably be done so first of
36:18 - all I will probably say Capital template
36:22 - prompt Capital prompt okay so first like
36:25 - what is the capital of this specific
36:27 - country right so this will basically be
36:28 - my prompt so here I'm going to use my
36:31 - prompt template and here I'm going to
36:33 - basically use input variables is equal
36:38 - to and here I'm going to basically say
36:40 - country let's go to the
36:43 - next input the next input will basically
36:46 - be
36:46 - template and here I will say I want uh
36:51 - please tell me
36:54 - the capital of of the whatever input I'm
36:59 - specifically giving away as country so
37:01 - this becomes my first template right and
37:05 - what I will do I will create a chain the
37:07 - chain name will be Capital chain okay
37:10 - and here I'm going to probably use my
37:12 - llm chain and my llm model will be llm
37:16 - okay and then I will also be using
37:19 - my prom template is equal to as capital
37:25 - template capital
37:27 - template okay so this is done let's see
37:30 - Capital prompt what is capital prompt oh
37:34 - sorry Capital
37:36 - prompt Capital prompt is not defined
37:40 - why uh please tell me the capital of
37:44 - this uh
37:47 - template oh double equal to Let's it no
37:50 - worries uh two validation error for LM
37:53 - chain so first I've used an LM chain
37:57 - where prompt template is equal to this
37:59 - uh where it is capital prompt so guys
38:02 - after just checking the documentation
38:04 - this should be prompt itself okay
38:06 - because in llm chain we have used prompt
38:09 - and here is capital template here also
38:11 - I'm going to probably use Capital
38:12 - tempate now if I execute this this works
38:14 - absolutely fine uh one thing you can
38:17 - probably see over here that I've given
38:19 - my template name and then I've also
38:20 - given the capital chain right so if I
38:22 - want to probably execute it I can just
38:24 - give my chain. run and that particular
38:26 - parameter okay but now what I want is
38:29 - that I also want to create one more
38:31 - prompt template I want to give the same
38:33 - input to that chain also so here uh
38:36 - let's say I will write famous _ template
38:40 - and I will just say promp template and
38:44 - here again my input variable what is my
38:46 - input variable so my input variable will
38:50 - be whatever specific things that I'm
38:53 - trying to give right let's say please
38:55 - tell me the capital of uh India if I say
38:58 - right the capital whatever Capital I'm
38:59 - going to get that variable only I'm
39:01 - going to pass it over here so my input
39:03 - variable will basically be my capital
39:06 - okay and this will be my second one and
39:09 - here I'm going to probably sayest
39:11 - template and I'm going to probably ask a
39:13 - question suggest
39:16 - me some amazing
39:19 - things amazing some amazing
39:23 - places places to visit
39:27 - in that specific capital okay so this is
39:30 - what I'm probably telling right please
39:32 - tell me the capital of the country so I
39:34 - will have that capital information that
39:37 - will be my input variable to from this
39:39 - particular template uh in that specific
39:41 - chain okay so I will get two answers
39:43 - first of all I'll get the capital of
39:45 - that particular country and then what
39:47 - are the some amazing places to visit in
39:49 - that specific Capital place okay so
39:51 - these are all the information that I
39:53 - have put up okay so I hope this also
39:54 - works fine now now what I'm going to
39:58 - create I'm going to create an another
40:00 - chain which will be for this particular
40:02 - famous chain right so here I'll write
40:04 - famous chain okay is equal to and I'm
40:08 - going to probably use my llm chain oh
40:11 - llm chain and here I'm going to give my
40:14 - llm models but the second one that is my
40:17 - prompt is equal to uh whatever template
40:21 - that I'm going probably going to give
40:22 - the famous template okay so this is what
40:24 - I'm probably going to do uh and I've
40:27 - probably given this prompt also over
40:28 - there and this will basically be my
40:30 - chain so once I probably execute it both
40:32 - the chains are ready now I need to give
40:35 - one input it should go to one chain get
40:37 - the output from that particular chain
40:38 - and pass that output to the next chain
40:40 - okay so this is what I specifically want
40:42 - to do how can I do it so again from Lang
40:47 - chain do chains I'm going to import
40:51 - simple sequential chain I know guys uh
40:55 - here you may be thinking why I have to
40:57 - use this see you're passing one input to
41:00 - the get the other output from the one
41:01 - chain and pass that particular output to
41:03 - the other chain to get the just output
41:05 - itself right so this is quite amazing
41:06 - when you see an end to end application
41:08 - there you'll be able to understand these
41:10 - are some of the important components you
41:11 - should definitely know and try to
41:13 - understand okay so here finally what I'm
41:16 - going to do is that I'm going to
41:17 - probably create my chain is equal to and
41:19 - this will be my final chain and here I
41:21 - will probably say I'll import this okay
41:24 - so I get that so chain is equal to
41:28 - simple sequential
41:30 - chain capital letter simple sequential
41:33 - chain and inside the simple sequen chain
41:36 - I just have to name all my chains what
41:39 - all chains are specifically there in the
41:41 - form of list so the first chain uh that
41:43 - I have over here is nothing but Capital
41:47 - chain the second chain that I have is
41:49 - something called as famous chain okay so
41:52 - both the chains are ready now in order
41:55 - to run it all I have to do will write
41:56 - chain. run and here I'll specifically
41:59 - give India
42:01 - okay done let's see what kind of output
42:04 - I will probably
42:09 - get so it is running it is a bustling
42:13 - Metro Police and a great place to visit
42:16 - for historical site cultural this this
42:19 - this red Fort see most popular city the
42:22 - iconic monal is a multivisit who fought
42:25 - in World War one the 16th century mugal
42:28 - era Tom in UNESCO world heritage site
42:30 - everything it is probably giving it
42:32 - right so it did not give us the first
42:35 - answer with respect to the chain because
42:36 - it only provides the last input
42:38 - information okay uh if you want to
42:40 - probably display the entire chain I will
42:41 - show you a way how to do that for that
42:43 - we have to use buffer memory uh there
42:46 - will be something called as buffer
42:47 - memory but one amazing thing I gave one
42:50 - input I got the output and then probably
42:53 - I pass that particular output to my next
42:54 - chain and I able to to get one amazing
42:56 - out answer over here so definitely try
42:58 - it out from your side by using different
43:00 - different examples also now what I'm
43:02 - going to do is that I'm going to
43:04 - probably discuss one very important
43:05 - component about chat model open AI so
43:08 - that is also super important uh that is
43:10 - something related to chat models
43:11 - whenever you probably want to create a
43:13 - chart models you can have to use that
43:14 - okay so let's have a look onto that so
43:16 - guys one more additional thing that
43:17 - let's say I want to probably see the
43:19 - entire chain so here we will
43:21 - specifically use something called as
43:23 - sequential chain and let me just show
43:25 - you one example of that also uh it is
43:27 - not much to do with respect to that but
43:29 - you should definitely know this
43:31 - important video as said again I don't
43:35 - want to probably take more time with
43:37 - respect to this but it is good to know
43:39 - this okay sometime when you are
43:40 - developing things and that you'll
43:43 - probably be understanding once I start
43:44 - end to end project right today one end
43:46 - to end project will be done okay don't
43:48 - worry about this uh in this particular
43:50 - video it will be done uh but definitely
43:53 - I want to show this example also as we
43:55 - go ahead now now uh let's quickly go
43:57 - ahead and do the same thing I will copy
44:00 - this
44:01 - entirely okay I will paste it over here
44:05 - okay now along with llm promt template I
44:08 - will give my output key also so where I
44:11 - specifically want my output key so the
44:13 - output key will be nothing but it will
44:16 - be something called as capital okay so
44:18 - this is my Capital chain with this
44:20 - specific output okay so here I have
44:22 - created this now let's go ahead and
44:24 - probably create the next template
44:26 - uh that is this famous template
44:31 - okay so here also you can probably see
44:33 - the famous template uh suggest me some
44:36 - names of the capital and here I've
44:38 - probably created my template name uh and
44:41 - my chain is over here right so this will
44:44 - basically be my chain okay so the same
44:47 - name whatever output Keys over here I've
44:49 - given this as my input key and here uh I
44:52 - can also derive one output key like this
44:57 - output
44:59 - key places something like this okay so
45:02 - done this is done see two simple
45:04 - templates that I actually created uh s
45:07 - me some amazing places to visit in this
45:08 - particular Capital uh the capital is
45:11 - probably given from here so now the
45:13 - chain will probably be able to
45:15 - understand each and everything as we go
45:16 - ahead you know where the output is and
45:18 - all right so here now what I'm going to
45:20 - do I'm going to probably import from
45:22 - Lang
45:24 - chain do chain
45:26 - chains
45:28 - import sequential chain okay and then
45:31 - finally you can see I'll write chain is
45:33 - equal
45:35 - to
45:36 - simple okay I will let me just execute
45:40 - this because it is not giving me any
45:42 - suggestion so I will write chain is
45:44 - equal to
45:47 - sequential chain and now I'll Give All
45:50 - My Chains name so the first chain name
45:53 - is um to Capital chain
45:59 - D famous chain
46:02 - dang okay and uh after
46:06 - this you will basically be able to
46:09 - understand the input
46:10 - variables now the input variables that
46:13 - we specifically
46:18 - have input variables is nothing but
46:21 - whatever is my variable name what is the
46:23 - variable name in this case it is nothing
46:25 - but country
46:27 - okay and then my output variable I'll
46:31 - also create my output uncore
46:35 - variables so these are the two
46:37 - parameters see guys this this parameters
46:41 - is nothing but whatever parameters I'm
46:43 - specifically giving one is the
46:46 - capital and one is the
46:52 - places done so this is my entire chain
46:57 - now if I want to run any chain what I
46:59 - will do I'll basically write something
47:01 - like this and give what is my country
47:05 - name right so it should be given in the
47:06 - form of key value pairs so here is my
47:09 - country
47:12 - colon India right something like this
47:15 - now if I execute it I will now be able
47:17 - to see my entire chain right it'll take
47:20 - some time so what I have done over here
47:23 - I have in every llm chain that I'm
47:25 - probably creating I'm creating an output
47:27 - key uh two chains so two output key and
47:29 - here you can see chain country India
47:31 - country was India Capital the capital of
47:34 - India is New Delhi here are some amazing
47:37 - places to visit in New Delhi and all the
47:39 - information I have probably over here
47:42 - now let's go ahead and discuss chat
47:44 - models uh specifically in Lang chain and
47:47 - we also going to use one Library which
47:49 - is called as chat openi uh this is also
47:53 - very good if you want to probably create
47:55 - a conversational uh chat bot itself so
47:59 - in chat models with chat open AI first
48:01 - of all what we will do is that we will
48:03 - go ahead and import Lang chain uh do
48:06 - chatore
48:07 - models and I'm going to probably import
48:10 - chat open aai so we will quickly go
48:14 - ahead and import it now after I
48:16 - specifically import this in chat open AI
48:20 - there are three schemas that you really
48:22 - need to understand okay whenever a
48:25 - conversation basically happens if a
48:28 - human is probably giving some kind of
48:29 - input and expecting some response that
48:32 - basically becomes a human message right
48:34 - if by default when the when your chat
48:37 - bot is probably opening a default
48:39 - message will probably come right and
48:42 - that is something related to domain like
48:44 - what that specific chatbot does right so
48:47 - it can probably come up with a new
48:49 - schema which is called as system message
48:52 - and then there is also one more message
48:54 - which is called as AI message which is
48:56 - again a schema which probably gives the
48:58 - output right whatever the chatbot is
49:00 - giving an output uh the AI whatever
49:03 - models is specifically giving the output
49:05 - that is nothing but that is related to
49:07 - the schema that is called as AI message
49:09 - okay now from this here we what we are
49:12 - going to do we are going to import from
49:16 - langin do
49:20 - schema I'm going to
49:22 - import human message
49:26 - system message right as I said system
49:29 - message is also required and AI message
49:32 - here everything you'll be able to get
49:33 - this as an example because uh probably
49:36 - in the upcoming videos we'll create
49:37 - conversational U chat bot right at that
49:41 - point of time we'll be seeing all these
49:43 - things what we'll be using and how we
49:44 - will be using okay so here quickly we'll
49:47 - import this now uh obviously my llm
49:50 - model is there right by uh and while
49:53 - creating before the llm models how did
49:55 - we use it we basically use something
49:57 - called as uh open a right we used open
49:59 - AI now in this case I will probably copy
50:02 - the same thing
50:04 - okay and I will just past it over here
50:08 - and write chat llm okay and instead of
50:11 - writing open AI I'll use chat open AI
50:15 - right so this is what I'm specifically
50:17 - going to use chat open AI with some
50:19 - temperature in this and here I'm also
50:21 - going to give one model so let me go
50:23 - ahead and write my model name uh the
50:25 - model name that we are going to
50:27 - basically write from here is GPT
50:30 - 3.5 Das turbo right I showed you like
50:34 - what models we can specifically use so
50:37 - this is my chat llm model so here if I
50:39 - probably go ahead and write my chat llm
50:42 - so here you'll be able to see that it is
50:44 - a chat open AI uh and with all the
50:46 - information with so temperature what is
50:49 - the uh this and all open AI key I cannot
50:51 - show you so it shows you open AI key
50:53 - also over here so going to remove this
50:56 - okay so that you don't find the opening
50:58 - I key now let's use this three schema
51:02 - and then probably see how my output will
51:04 - look like let's say first of all I'll
51:07 - create the schema in the form of list
51:09 - okay first of all the system message
51:12 - right let's say system message I will go
51:14 - ahead and initialize and I'll write a
51:15 - content content one variable is there I
51:18 - say you are an you are a
51:24 - comedian
51:26 - AI assistant okay so this is the this is
51:30 - what I'm telling the chatbot to behave
51:33 - like right it is basically acting like a
51:35 - comedian AI assistant okay then in the
51:38 - next one I will say human message and
51:41 - here again I will go ahead and write the
51:44 - content and I will say
51:47 - please and this is
51:49 - what I will probably write as a human
51:51 - this is what the input that I am
51:54 - probably giving right
51:56 - so I'll say
51:57 - please make a
52:01 - comedy about
52:04 - or please provide some punch lines some
52:08 - comedy punch
52:11 - lines punch
52:13 - lines on okay AI
52:18 - okay so here you can probably see these
52:21 - are my two things these are the two
52:23 - information that I'm going to give to my
52:25 - chat llm models right and then let's see
52:28 - what is the output okay with respect to
52:30 - that now in order to give this input to
52:32 - my chat llm so I will write chat llm and
52:35 - here only I will open my
52:38 - brackets so it has two information first
52:40 - by default it knows the system is a
52:43 - comedian AI assistant and here as a
52:45 - human input what we are saying is that
52:48 - we are saying please provide some comedy
52:50 - punch lines on AI okay so if I execute
52:52 - this you will be able to see I will be
52:54 - able to get an output
52:55 - now this is how we are going to design
52:57 - later on in the end to endend project we
52:59 - are not going to give this as a
53:00 - hardcoded it'll be quite Dynamic so here
53:03 - you can see AI message see this is the
53:05 - output if I'm getting the output that
53:08 - basically becomes an AI message so this
53:09 - schema that we are able to see from the
53:11 - output of this particular chatbot the
53:14 - system message is basically telling that
53:17 - okay beforehand you have to act
53:19 - something like that we instructing the
53:21 - chatbot to probably act in that way
53:24 - right the human message is basically our
53:25 - input and AI message is what is the
53:27 - output so AI may be smart but it can
53:29 - tell me if your output makes look like a
53:32 - potato AI is a virtual therapist except
53:35 - it never judges you for eating an entire
53:37 - Pizza by yourself something like this so
53:39 - this is what comedy messages you can
53:41 - probably see right and I think this is
53:44 - quite amazing and you can probably set
53:46 - this up any number of time right you can
53:49 - probably say you can add this AI message
53:51 - over here and you can still build more
53:53 - conversational AI right so as AI also
53:57 - give the message you can probably store
53:58 - it inside this s let's say if I probably
54:00 - consider a list and I append this
54:02 - particular list with all this
54:03 - information it can act as a chat model
54:06 - as our as we go ahead right now guys we
54:09 - are also going to discuss about one
54:10 - topic and after this we are going to
54:12 - implement our project okay so over here
54:15 - we going to discuss about prom template
54:17 - plus llm plus output parcel now first of
54:20 - all we'll try to understand what exactly
54:22 - is output parcel now in order to make
54:25 - you understand about output plaster and
54:27 - how we can probably implement it I will
54:29 - use Lang chain again for this um as said
54:33 - guys langin is a powerful Library it has
54:35 - everything as a wrapper right so I will
54:37 - say from Lang chain okay from Lang
54:43 - chain.
54:44 - chatore models first of all I'm going to
54:50 - import chat open AI okay chat open AI I
54:55 - see there so many things Chad vertex AI
54:57 - chap open AI very powerful very powerful
55:00 - and the way it is getting developed
55:03 - right quite amazing right so from Lang
55:07 - chain dot prompts I'm also going to use
55:11 - some prompts and like how we have a
55:13 - prompt template when we use open AI
55:15 - right similarly in chat open AI we use
55:17 - uh prompts which is basically called as
55:19 - chat promate chat prompt template okay
55:23 - so I'm going to basically import
55:25 - chat prompt value no
55:29 - template chat prompt template so I'm
55:32 - also going to import this along with
55:33 - this as I said output parser right
55:37 - output parser is that if I want to
55:39 - modify any output of an llm model
55:41 - beforehand right so I can specifically
55:44 - use output parsers so for Lang chain I
55:47 - will also import this from Lang chain do
55:52 - schema import base output parel right so
55:58 - these are the three things I'm
55:59 - specifically importing and here I'll
56:01 - basically go ahead and write class let's
56:04 - say I am defining one output parser and
56:08 - I'll Define this in the form of class
56:10 - it'll inherit the base output class so
56:13 - let's say uh I will say comma separated
56:17 - output okay that basically means it is
56:20 - basically called as a comma separated
56:21 - output this is the class that I'm going
56:23 - to Define and uh
56:25 - even even in the documentation it is
56:28 - given in an amazing way okay so comma
56:30 - separated output and this will basically
56:33 - be inheriting the base output parcel
56:36 - okay now inheriting when I probably
56:39 - inherit right that basically means we
56:41 - are inheriting this base output par and
56:43 - we can call this along with an llm
56:45 - models here I will Define a parse method
56:48 - and inside this par I will take self as
56:51 - one keyword and whatever text the output
56:54 - that we have specifically getting which
56:56 - will be in the form of string format all
56:58 - we'll do we'll just write return text.
57:02 - strip
57:05 - dot dot split right and this will be a
57:10 - comma separated
57:11 - split understand one thing now this is
57:13 - what is the class that I've defined and
57:15 - this is just like an output parser by
57:17 - default the output parser is what you
57:19 - can probably see whenever I'm
57:22 - specifically using the chat models I'm
57:24 - I'm getting some kind of output right AI
57:26 - may be smart something it is giving in
57:27 - the form of sentence and it is adding a
57:29 - new line at the end but what I'm saying
57:31 - is that whatever output I'm getting I
57:33 - will take that output and divide all the
57:35 - words in comma separated okay something
57:38 - like that so for this again I will
57:39 - Define my template I will
57:45 - say you are
57:48 - a
57:50 - helpful assistant okay so this is my
57:52 - first message that is probably going as
57:55 - a template right so this becomes a
57:57 - system template the schema that we
57:59 - probably discussed right I will also
58:01 - give some
58:02 - information um let's
58:05 - say when the user gives any
58:12 - input okay you
58:15 - should generate five words okay in a
58:21 - comma separated list so this is what is
58:25 - my entire message okay the template I'm
58:27 - saying that whenever the user give any
58:29 - input you have to probably generate five
58:32 - words which should be comma separated
58:35 - okay so this is what I have specifically
58:36 - done okay now what will be the input
58:39 - what will be the text Will Define all
58:41 - those things okay and here I will say
58:43 - this will be my human template so what
58:45 - is the word that I'm going to probably
58:46 - give over here uh that will specifically
58:49 - defined over here right so here I will
58:51 - say Okay test uh you should generate
58:54 - five
58:55 - words synonym let's say synonym I'll
58:58 - just go ahead and write synonyms okay
59:01 - synonyms in comma separated so here will
59:04 - basically be my text whatever text I'm
59:06 - specifically given now I will go ahead
59:07 - and create my chat prompt now again from
59:09 - this chat prompt what I have to use I've
59:11 - already used chat prompt Pro template
59:14 - okay and inside this I will say do from
59:18 - message let's see that chat prompt
59:22 - template
59:23 - from from underscore messages okay now
59:28 - inside this from underscore messages I
59:30 - have to give two information okay
59:33 - whatever is the template right so first
59:34 - template is nothing but the system one
59:37 - so system information that I really want
59:39 - to give uh that system one is nothing
59:42 - but this normal template that I've
59:44 - defined and the second one will
59:46 - basically be my human template right
59:48 - whatever human message that I'm actually
59:49 - giving right and this will basically be
59:52 - defined as human uncore temp temp
59:55 - plates template right so once I execute
59:58 - it here you'll be able to see this is my
60:00 - chat prompt okay now in order to execute
60:04 - this obviously I have to use chain right
60:07 - because I have a prom template over here
60:09 - I have a human text I have this specific
60:11 - template also so how do I probably
60:14 - combine all these things that is what
60:16 - I'm actually going to show you over here
60:18 - so quickly first of all I will use this
60:20 - chat llm okay chat llm now see this is
60:25 - quite amazing and this is the best way
60:27 - of running chains so I will say chain is
60:29 - equal to whatever is my chat prompt so
60:33 - this is my chat
60:35 - prompt to this chat prompt I will give
60:38 - my
60:39 - API whatever API I'll write over here
60:42 - control V so I have to just give a or
60:45 - sign kind of thing right so this is
60:47 - getting chained up this symbol basically
60:49 - says that it is getting chained up and
60:51 - remember the order also okay or you can
60:54 - also initialize chat open AI over here
60:57 - now along with this I will also give my
60:59 - output parser the output parser will be
61:01 - the last one right so this will
61:03 - basically be my output parser comma
61:06 - separated output okay now see I've given
61:09 - each and everything over here one by one
61:11 - list by list right so here it is so once
61:14 - I probably execute it it will get
61:15 - executed so here what it is saying I'm
61:17 - giving this chat prompt the chat llm
61:19 - model is there and the output should be
61:22 - comma separated output which is getting
61:23 - derived from this particular class okay
61:26 - now here finally what I will do I will
61:28 - write chain do
61:29 - invoke and inside this I will again
61:32 - whenever I use chain I have to probably
61:34 - give it in a key value pair right colon
61:37 - something whatever the value is now in
61:40 - this case I will say the word is um
61:45 - intelligent let's say now I have to
61:48 - probably give in the form of text right
61:50 - so that is what I really have to give it
61:52 - right so this text is equal to in now
61:54 - let's see what is the output uh it is
61:57 - coming as okay there is some syntax
62:00 - issue that I have probably made because
62:01 - I have to close my dictionary over
62:05 - here now if I write chain. inor you can
62:08 - see that five words smart clever
62:11 - brilliant
62:12 - shop aute I don't know this specific
62:15 - word but here you'll be able to see
62:17 - whatever output that I'm probably
62:19 - getting right so if I probably remove
62:21 - this let's see okay this is how the
62:25 - output will look like okay AI message
62:27 - content this this this right but just by
62:30 - adding this output parsel you can see
62:32 - what an amazing message you're able to
62:34 - get and you're getting able to get the
62:35 - right thing that you specifically want
62:39 - this is what powerful a prompt template
62:42 - is all about right now this is done
62:45 - right and this is more than sufficient
62:46 - to know because more new things about
62:49 - PDF how to read PDF how to what is text
62:52 - iding and all we will discuss as we go
62:54 - ahead
62:54 - but now let us go ahead and try to
62:57 - create a simple chatbot okay simple
63:00 - chatbot I'll create an app.py and by
63:03 - using the simple chat bot we'll try to
63:05 - understand how things actually work and
63:08 - what all things we can basically do okay
63:10 - again here I'm going to probably use
63:12 - streamlet and I'll be writing the code
63:13 - line by line so let's go ahead and have
63:15 - a
63:16 - look so guys finally now we are going to
63:20 - develop our Q&A chatbot uh with all the
63:23 - concepts that we have probably learned
63:26 - I'm just not going to use all the
63:27 - concepts right now in this specific
63:28 - video itself because we should have
63:30 - probably uh 10 to 12 projects that are
63:33 - going to come up in the future in this
63:35 - series of playlist so there we are going
63:37 - to discuss about more projects as we go
63:39 - ahead right but now in this video I'm
63:42 - going to probably create a simple Q&A
63:45 - chatbot just with the help of open aai
63:48 - Lang chin and obviously use openi apis
63:51 - and llm models specifically to do that
63:54 - that here I'm also going to use
63:56 - streamlet okay so let's go ahead and
63:58 - let's see initially what all settings I
64:00 - need to do see this was Lang chain. iynb
64:03 - because I will be giving you this entire
64:05 - file uh again in the reference with
64:07 - respect to GitHub also so uh first of
64:10 - all in the requirement. txt I will be
64:13 - importing one more library because I
64:14 - need to install this Library this is the
64:16 - important Library itself which is
64:19 - python. EnV right so python d.v actually
64:23 - helps us to create or upload all our uh
64:27 - environment variables that we have
64:28 - created with respect to our application
64:31 - so here this is the library that I have
64:33 - to do it and just go ahead and install
64:34 - the requirement. txt I've already done
64:37 - that uh and this will be a specific task
64:39 - to you now we are starting over here so
64:42 - from lin. llms I have imported open aai
64:45 - then from EnV load load. EnV so as soon
64:50 - as I probably call this it will take all
64:52 - the environment variables from EMV file
64:54 - so here I've already created the
64:56 - environment variable I'm not going to
64:57 - show you again the environment variable
64:59 - because in short the environment
65:01 - variable will be something like this see
65:03 - I I I may have written like something
65:06 - like this open AP opencore API _ key is
65:09 - equal to this particular environment
65:10 - variable right so this is basically my
65:12 - open uh API key itself right so I'm
65:14 - going to probably use this uh in my
65:17 - application so here uh these are the
65:18 - basic steps that we will probably go
65:20 - ahead with now along with this what I'm
65:22 - actually going to do I'm also going to
65:24 - to import one more Library which is
65:26 - called as streamlet because we are going
65:28 - to use streamlet itself so let me go
65:31 - ahead and open my terminal and quickly
65:34 - let's go ahead and write pip
65:36 - install minus
65:39 - r minus r requirement. txt and then the
65:44 - installation will start taking place and
65:46 - the streamlet uh Library will also get
65:49 - installed Streamlight we are
65:50 - specifically using for a front-end
65:52 - application uh see it's it's not light
65:54 - only you have to use streamlet it'll be
65:55 - very much easy for me to probably create
65:57 - it and do the deployment because I'm
65:58 - also going to show you the deployment in
66:00 - the hugging face uh space itself right
66:03 - what is exactly hugging space uh space I
66:05 - will also discuss about all those things
66:07 - so quickly uh let's do this uh it'll
66:09 - probably take some time and then I will
66:12 - go to my app. Pui uh let me do one thing
66:15 - quickly uh let me go ahead and import
66:17 - streamlet also so I'll import
66:20 - streamlet as St okay so this will
66:23 - basically my streamlet itself okay so
66:26 - it'll probably take some time to
66:27 - download it let's see how much time it
66:29 - is going to take but again it depends on
66:31 - your internet speed and how fast your
66:34 - system is right my system is really
66:35 - really fast till it is taking
66:38 - time so for you it may probably take
66:40 - more time okay so let this installation
66:44 - take place till then I will go ahead and
66:46 - start creating our application now I
66:49 - will first of all create a
66:51 - function to load open AI model and get
66:56 - response okay get
66:59 - response so I will call this function
67:01 - something like definition um getor open
67:05 - AI response okay something like this and
67:09 - here I'm probably going to give since it
67:12 - is a Q&A chatbot so here I will have my
67:14 - question as my parameter which will be
67:16 - of a string type okay it can be a string
67:19 - type it can also be a numerical type so
67:21 - I will just keep it like this okay so
67:23 - this is done and here you can also see
67:25 - the installation is done so I will just
67:26 - close this now here as soon as I
67:29 - probably call this function what I
67:31 - really need to do I need to call my llm
67:33 - model so llm model I will say open AI
67:36 - okay open Ai and here I will go ahead
67:39 - and Define my
67:42 - model uh have I imported open AI yes I
67:45 - have imported model uh uh open itself so
67:48 - I will go ahead and write model uncore
67:50 - name is equal to and I will will Define
67:54 - my model I'll be using text Davin
67:58 - C uh this is one of the model that we
68:00 - have you can probably refer it so text
68:03 - Davy
68:04 - 003 and here I'm also going to Define my
68:09 - temperature temperature is equal to
68:11 - let's
68:12 - say5 Okay uh along with this uh I'll
68:15 - just go ahead and copy one more thing I
68:18 - will just set up my open API key also so
68:21 - I will set it up like by using this OS
68:24 - environment so here will be my first
68:26 - parameter okay so all this is done uh I
68:28 - think I need to also import OS okay so
68:32 - this is done in short what I'm doing is
68:34 - that I'm initializing my llm model OKAY
68:37 - in this code now the next thing is that
68:39 - I need to probably get my response so
68:43 - response will be nothing but llm
68:45 - directly how do I give a question over
68:47 - here I can probably give the question
68:49 - over here okay see I'm just creating a
68:53 - basic one
68:54 - then whatever things you really want to
68:56 - do from here you can probably do it try
68:58 - to create a own prom template try to use
69:00 - chain if you want try to do multiple
69:02 - things but just to start with I'm going
69:04 - to use a simple application where it is
69:06 - just taking an input and giving some
69:08 - kind of output it has no AI message set
69:11 - it has no human system message set no
69:13 - system message set also we have not
69:14 - given any prompt template also over here
69:17 - this just to give you an idea how things
69:19 - starts okay so now we will
69:22 - initialize in initialize our streamlet
69:28 - app okay now with respect to streamlet I
69:31 - will write STD do
69:34 - set underscore
69:37 - page underscore config so this is one of
69:40 - the function in streamlet which will
69:41 - actually help you to set the page title
69:45 - so I will just go ahead and write title
69:48 - is equal to I will say q& a demo okay Q
69:53 - a demo and this is done with respect to
69:56 - my uh and here I will set my another
69:59 - header the header will be something like
70:03 - Lang
70:04 - chain application something like this
70:08 - okay so I've given my header also with
70:10 - respect to this okay now I need to find
70:13 - out a way to get a user input okay uh if
70:18 - I get a user input then I should be able
70:21 - to submit the button and I should be
70:22 - able to get the text itself so first of
70:25 - all I will go ahead and create my submit
70:27 - button I will say St do
70:30 - button and here I will go ahead and
70:34 - write generate generate or ask the
70:38 - question something like this
70:42 - okay
70:44 - if ask button is
70:48 - clicked right if it is clicked that
70:51 - basically means if I write if submit
70:53 - okay if it is clicked this usually
70:56 - becomes true okay so if this is true it
70:58 - is probably going inside this particular
71:00 - function and here you'll be able to see
71:02 - s I'll just put a header and uh I'll say
71:08 - the
71:09 - response is okay and then I will
71:12 - probably write St dot right with respect
71:17 - to the response okay so this is what I
71:20 - am probably doing it okay I'm getting
71:23 - the response over here and with respect
71:25 - to this specific response I will
71:27 - probably this response is probably
71:28 - coming from here but still whatever is
71:31 - the input that input we are not able to
71:33 - capture it yet right because if we
71:35 - capture those input then only we'll be
71:37 - able to send that particular input
71:38 - somewhere right and for that also I may
71:41 - have to probably create another function
71:43 - so let's go ahead and handle the input
71:45 - part
71:48 - now so guys now what I am actually going
71:51 - to do over here is that first of all
71:53 - we'll go ahead and and capture our input
71:54 - text so let me go ahead and write over
71:57 - here input is equal to St do textor
72:01 - input because I'm going to use a text
72:03 - field over there and here I will
72:06 - probably be waiting for the response
72:10 - itself right so sorry from the request
72:12 - right so so here I will write input
72:14 - colon okay and I'll keep a space over
72:16 - here and I will just write key is equal
72:19 - to key is equal to input something like
72:22 - this so this will basically be my input
72:24 - itself okay now once I've done this okay
72:28 - once I've have done this I'm going to
72:30 - take this particular input and now call
72:33 - I hope you should know what we should
72:35 - call we should basically call this
72:36 - function right so this here I'm going to
72:39 - probably write uh not here itself uh so
72:42 - let me just write it over here and this
72:45 - input I'm actually giving it over
72:47 - here okay so this will basically be my
72:50 - input over here uh whatever input I'm
72:52 - probably getting it it'll just go ahead
72:54 - with respect to this particular question
72:55 - and I will probably get the response
72:57 - here I will just go ahead and write
72:59 - return
73:00 - response okay and then I will store this
73:04 - particular variable inside my response
73:06 - okay done see the way I probably got the
73:09 - input over here I sent this input to my
73:12 - get open AI response my open AI model
73:14 - has got probably loaded and then it is
73:17 - basically calling with respect to this
73:19 - llm you can either call predict message
73:21 - or predict functionality also uh you can
73:24 - also use chain you can use multiple
73:26 - things you can assign promt template in
73:27 - this particular function and all right
73:29 - and then finally you have S do Button as
73:31 - the button and if submit this is there
73:33 - okay now quickly let's go ahead and
73:36 - probably run it
73:40 - okay uh let me see whether if I directly
73:44 - call python app. Pui it will give us a
73:47 - error why because it is a stream L
73:49 - library right if it was flask I would
73:51 - have probably said okay it would have
73:53 - work ke now it says key error open API
73:56 - key okay so os. environment open API key
74:00 - load.
74:02 - EnV so guys one mistake that I have
74:05 - specifically done whenever I really want
74:06 - to call all the environment variables
74:08 - from EnV with the help of load uh this
74:12 - the specific library that is called as
74:13 - this this functionality which is load.
74:16 - EnV at that point of time I'll be using
74:18 - get EnV function and here I will just
74:21 - remove all the things brackets and
74:23 - probably call this function now I hope
74:25 - so it should work and I think we should
74:27 - not get any problem so Streamlight run
74:30 - app.py and here we have our entire
74:34 - application quickly it's running let's
74:37 - see um this is getting
74:40 - loaded and here we have right now
74:43 - probably I'll ask the question what is
74:46 - the capital of India right so I'll just
74:53 - ask the question over here the response
74:54 - is the capital of India is New
74:56 - Delhi um let's see what is generative AI
75:04 - right so I'll ask the question you'll be
75:07 - able to see that generative AI is a type
75:09 - of artificial intelligence that focuses
75:11 - on creating new data from existing data
75:13 - this this this is there still I'm I'm
75:15 - getting some kind of weird responses
75:17 - over here so that is the reason we'll
75:18 - also be using output parsers we'll make
75:21 - sure that we'll use conversation buffer
75:23 - memory we'll also Implement schemas like
75:25 - human message system uh human human
75:28 - system AI system um system messages all
75:31 - those things were there right all the
75:32 - schemas that part we probably discussed
75:35 - but this is a simple application that we
75:37 - are probably going to discuss with
75:39 - respect to this it is going to be quite
75:41 - amazing and uh you know this is just a
75:44 - basic Q&A chat bot uh wherein whatever
75:47 - questions you specifically ask like what
75:49 - is the
75:51 - please right write a
75:54 - poem
75:56 - on on please write a romantic poem I'll
76:00 - just give it as romantic
76:03 - poem on generative AI something like
76:06 - this because many people are now using
76:10 - this ask the
76:13 - question so here you can see gener way I
76:16 - knew love in my life your data driven
76:18 - hurt is perfect fit your algorithm so
76:21 - precise your knowledge is so wise so
76:22 - everything is over here now what I'm
76:24 - actually going to do is that I will go
76:26 - and show you the deployment part
76:28 - everything is working fine I will first
76:30 - of all login into the hugging face go to
76:32 - the spaces and create a new space
76:36 - because I'm going to probably do the
76:37 - deployment over here let's say I will
76:40 - say Lang chain Q&A chatbot okay I don't
76:45 - have to use license this will be a
76:47 - streamlet now in space Hardware like you
76:50 - have paid Hardwares also but I'm
76:52 - probably going to use a simple one CPU
76:55 - Basics 2v CPU 16GB and I will create
76:58 - this as public so that you can also
77:00 - refer it um let's see okay I will just
77:04 - remove this spaces please match okay
77:07 - this underscore is not there QA a
77:11 - chatbot I will go ahead and create the
77:12 - space now after creating the space uh
77:15 - there's couple of things that I'm
77:17 - probably going to do over here is that
77:20 - uh this is where this is just like a
77:21 - GitHub repository you know you if you
77:23 - probably go to the files you'll be able
77:24 - to see it now here I'm probably going to
77:27 - upload the file that I have okay uh but
77:31 - before that what I'm actually going to
77:32 - do I'll go to my settings okay and if I
77:35 - go down right so there will be something
77:37 - called as secret keys because this
77:39 - secret key I have to put it with respect
77:42 - to open AI so here no secrets are there
77:45 - so I will go and clear or click on uh
77:48 - new secret and you know that with
77:50 - respect to the new secret what I have to
77:52 - probably use I have to use open API key
77:54 - I will put it over here okay and now
77:58 - oops just a second open API key let me
78:02 - open
78:04 - this and I will put it over here okay
78:08 - and what I'm going to do I'm also going
78:10 - to upload the value okay so I'll not
78:12 - show you the value uh let me update this
78:15 - and let me come back and quickly and
78:17 - show you the next steps that we are
78:18 - probably going to
78:19 - do after adding the open AI API key uh
78:23 - you can see it over here in the secrets
78:25 - you'll be able to see this specific key
78:28 - now what I will do after updating that I
78:30 - will go to my app now again my entire
78:32 - application will start getting buil up
78:34 - now here you can see as soon as I add
78:37 - the open AI API you'll be able to see my
78:40 - application will start running now here
78:42 - I can probably ask question what is the
78:45 - capital of India okay and uh you can see
78:50 - that I will be able to get the response
78:52 - now clearly you'll be able to see uh
78:54 - I've been able to do the deployment in
78:57 - hugging pH spaces uh it was very much
78:59 - simple you can see the files over here
79:01 - itself on the app.py requirement. txt I
79:05 - had commented out all the codes with
79:06 - respect to EnV and all because soon as
79:09 - we add the secret variable as soon as
79:11 - this open a model is called it is going
79:13 - to take the open a API key from there
79:15 - and it is going to use it over here so
79:18 - yes this was with respect to the
79:19 - deployment and quickly we were able to
79:22 - also create a simple Q&A chatbot along
79:25 - with deployment so guys in this video
79:26 - we're going to create one Amazing llm
79:28 - Project which is nothing but PDF query
79:31 - with langen and cassendra DB uh
79:34 - cassendra DB will be probably creating
79:35 - in a platform which is called as data
79:37 - Stacks so if you have probably heard
79:39 - about this particular platform which is
79:41 - called as data Stacks which will
79:43 - actually help you to create cassendra DB
79:45 - in the cloud itself and why this
79:47 - platform is quite amazing because from
79:49 - this you will be able to perform Vector
79:52 - search and whenever we talk about this
79:54 - kind of documents or if you want to
79:56 - really create an Q&A applications from
79:58 - huge PDFs itself Vector search is the
80:01 - thing that you really need to implement
80:03 - now before I go ahead let's first of all
80:06 - understand the entire architecture we
80:08 - will be solving this entirely step by
80:10 - step what are the steps specifically
80:13 - that will be taken to probably complete
80:15 - this specific project that we really
80:17 - need to understand so let's begin with
80:19 - the architecture initially let's say you
80:21 - have a specific PDF this PDF can be of
80:24 - any size and any number of pages first
80:27 - of all we will read the documents and
80:30 - understand here we are going to use
80:31 - langin as I said because langin has some
80:35 - amazing amazing functionalities which
80:37 - will actually help you to perform all
80:39 - the necessary tasks to create this
80:40 - specific application now first we will
80:43 - go ahead and read the documents that is
80:46 - specifically the PDF and the first step
80:49 - usually when we whenever we work with
80:51 - this kind of data set is with respect to
80:53 - some kind of transformation we really
80:54 - need to do so after reading this
80:56 - documents we will convert this into
80:58 - various test chunks that basically means
81:01 - we'll split the data set into some kind
81:04 - of packets right so this text Chunk will
81:07 - be of some specific size based on the
81:10 - tokens that we are probably going to use
81:12 - so over here you can see some example
81:14 - reading the document and then we have
81:15 - divided this into some chunks then we
81:18 - will convert all this chunk into text
81:21 - embeddings now from here we will be
81:24 - specifically using open AI embeddings
81:26 - okay openai embeddings actually helps
81:29 - you to convert text into vectors now why
81:33 - you specifically require these vectors I
81:35 - hope you have heard about text embedding
81:37 - techniques in machine learning right
81:39 - there we have specifically used bag of
81:42 - words tfidf and many more things that is
81:44 - already present in my YouTube channel we
81:46 - have also used word to work average word
81:48 - to what are the main aim of all these
81:50 - techniques to convert text into vectors
81:54 - because once we probably convert into
81:56 - vectors we can perform various tasks
81:58 - like classification algorithms like
82:00 - similarity search algorithm and many
82:02 - more so that is the reason we will
82:04 - specifically be using openi embeddings
82:06 - which will be responsible in converting
82:08 - a text into vectors itself now once we
82:11 - convert every text into vectors we will
82:13 - also see this as text embeddings once we
82:16 - get this embeddings what we are
82:18 - specifically going to do now this will
82:19 - be quite amazing because understand if
82:21 - we have a huge PDF document right so
82:24 - definitely the vector size will keep on
82:26 - increasing so it is better we store
82:29 - entirely all this vectors into some kind
82:31 - of database and for this we are going to
82:34 - use Centra DB so in short what we are
82:37 - basically going to do is that we will
82:39 - take all the specific vectors and save
82:41 - it in a vector database here currently
82:44 - we are going to use cassendra DB now
82:46 - what exactly is cassendra DB so in order
82:48 - to understand about cassendra DB I have
82:51 - opened the entire documentation page
82:53 - over here cassendra aperture Apachi
82:56 - cassendra is an open source no SQL
82:59 - database and it can definitely be used
83:01 - for saving massive amount of data so it
83:04 - manages massive amount of data fast
83:06 - without losing sleep right so again
83:09 - understand this is a nosql database and
83:11 - for vectors kind of thing we definitely
83:13 - have to save it in this kind of database
83:15 - itself many bigger companies are
83:17 - basically using this cenda DB for this
83:19 - specific purpose so if you really want
83:21 - to read more about Apache cendra you can
83:24 - probably see over here Apache cendra is
83:25 - an open- Source nosql distributed
83:27 - database trusted by thousands of
83:29 - companies for scalability and high
83:31 - availability this is the most important
83:33 - point for scalability and high
83:35 - availability without compromising
83:37 - performance linear scalability and
83:39 - proven fall Tolerance on commodity
83:41 - Hardware or Cloud infrastructure make it
83:44 - as a making it as a perfect platform for
83:46 - Mission critical data now how we are
83:49 - going to probably create this specific
83:50 - database for that we will be using this
83:52 - data Stacks platform wherein it will
83:55 - actually help you to create this Vector
83:58 - cassendra DB so that you can store
84:00 - entirely all these vectors into this
84:02 - specific DB and at any point of time if
84:05 - a person is trying to query from this
84:06 - particular DB you will be able to get
84:09 - that specific response from that right
84:11 - and the most similar response that
84:12 - you'll be able to get it now that is the
84:14 - next step what we are basically going to
84:16 - do all these vectors we are going to
84:18 - save it in some kind of vector database
84:20 - as I said we going to use casser DB or
84:23 - we can also say astrab and this will be
84:25 - created in this data STS
84:28 - platform wherein you can actually
84:30 - perform Vector search now the next thing
84:33 - is that after you probably save entirely
84:35 - all your vectors in in the database
84:37 - itself then a human whenever a human
84:40 - tries to query anything that is related
84:43 - to that particular PDF document it is
84:45 - going to probably apply similarity
84:47 - search along with text iddings and is
84:49 - going to get that specific response so
84:52 - this this is the entire
84:53 - architecture that we are specifically
84:56 - going to perform in this specific
84:57 - project all the steps will be shown step
85:01 - by step everything will be explained in
85:03 - an amazing way along with the code and
85:05 - along with the explanation now let's go
85:07 - ahead and start our specific project for
85:10 - this PDF query with Lang chain and
85:12 - cassendra DB so guys now let's go ahead
85:15 - and implement this specific project I
85:17 - will be going step by step I will also
85:19 - be showing you how you can create the
85:20 - cassendra DB specifically in the data
85:24 - Stacks uh platform itself uh we'll be
85:26 - seeing step by step all the comment
85:29 - regarding this code and all is given
85:30 - over here I will also be providing you
85:32 - the code in the description of this
85:34 - particular video so first of all uh what
85:37 - exactly we are doing we are going to
85:39 - query PDF with astb and Lang chain uh it
85:43 - is basically powered and uh understand
85:45 - it is powered by Vector search so first
85:47 - of all you need to understand what
85:48 - exactly is Vector search so there is an
85:50 - amazing documentation that is given in
85:52 - the data stack documentation itself so
85:54 - Vector search enhances machine learning
85:56 - models by allowing similarity comparison
85:58 - of the embeddings embeddings basically
86:00 - means whatever text is basically
86:02 - converted into the vectors that is
86:04 - basically embedding right and over there
86:06 - you can definitely apply multiple
86:08 - algorithms right machine learning
86:09 - algorithms on the fly right as a
86:11 - capability of astrab vector search
86:13 - supports various large language models
86:15 - so large language models can be is very
86:18 - is supported in an amazing way in this
86:19 - the integration is very much smooth and
86:21 - easy right since this llm are stateless
86:24 - they rely on Vector database like Astro
86:26 - DB to store the embeddings see
86:28 - understand because uh when we say
86:30 - stateless that basically means what
86:32 - suppose if we have embeddings once we
86:34 - lose it we cannot again query it right
86:36 - so it is definitely require a database
86:38 - to probably store all these things and
86:40 - what you can do after that you can query
86:42 - any number of time so let us go step by
86:44 - step and let us see okay so first of all
86:47 - we need to create a database on astb so
86:50 - I will probably click this specific link
86:52 - everything is basically given over here
86:54 - for this we will be going to
86:57 - astra.com right so first of all it will
87:01 - probably ask you to sign in right and
87:04 - here you can probably sign it with your
87:06 - GitHub or with your Google account so
87:08 - here I'm going to go ahead and sign it
87:10 - with GitHub and probably once I probably
87:13 - sign in over here you will be able to
87:16 - see that uh I'll be providing you the
87:18 - link along with everything in the uh
87:21 - code itself right so it'll be very much
87:23 - easy for you so once you go to Astra
87:26 - data.com the next step is basically to
87:29 - create a database right so this database
87:32 - uh what kind of database we are going to
87:33 - probably create it will be serverless
87:35 - vector and this is specifically a
87:37 - cassendra DB okay so here I will
87:40 - probably give my database name let's say
87:42 - I want to do PDF query right so this
87:44 - will basically be my PDF query DB okay
87:47 - this will basically be my database name
87:49 - you can give anything as you want and
87:51 - here I'll be basically be giving Lang
87:53 - chain _ DB a key space name it should be
87:56 - unique the provider that you can
87:57 - specifically use you have multiple like
88:00 - Amazon web services Microsoft Azure but
88:02 - here I'm going to probably use Google
88:03 - Cloud which is the default that is
88:05 - selected in the next step we will go
88:07 - ahead and select the country region
88:09 - which is by default Us East one so as
88:12 - soon as you probably fill all this
88:14 - details and as you know that we are
88:16 - specifically going to use this Vector
88:18 - database itself because at the end of
88:20 - the day the algorithms that we probably
88:22 - going to apply it will be easy with
88:24 - respect to this kind of database right
88:26 - so finally we will go ahead and create
88:28 - the database now once how we create the
88:31 - database you will be able to see that my
88:33 - database is basically created over here
88:35 - right so this is what is my database
88:37 - that looks like right PDF query diving
88:41 - now if I probably go to my dashboard
88:42 - I've already created this kind of
88:44 - database a lot so let me consider one
88:46 - database which I have already created
88:48 - and over here some important information
88:50 - that you really need to take first of
88:52 - all I will go and click on connect okay
88:55 - so when I probably click on connect one
88:58 - some information you will definitely
89:00 - require one is generate token right and
89:02 - the other one is the DB ID so DB ID is
89:05 - basically present over here right the
89:07 - token is basically present over here now
89:09 - I'll talk about where this specific
89:11 - information will be required okay so
89:14 - here I will go with respect to my code
89:16 - now let's start our coding initially we
89:18 - will be requiring some of the important
89:21 - libraries like Casio data set langin
89:23 - open Tik toen so here I will go ahead
89:26 - and execute it and I will go ahead and
89:28 - install all the specific libraries so it
89:31 - will probably take some time right I
89:33 - have already done that installation so
89:35 - for me it has happened very much quickly
89:37 - now the next thing is that as we know
89:40 - that we are specifically going to use
89:41 - cass. DB so in Lang chain you have all
89:44 - these libraries which will actually help
89:45 - you to connect with cassendra DB and
89:47 - perform all the necessary tasks like
89:49 - text T meetings uh creating V vors and
89:52 - probably storing it in the database
89:53 - itself so here I'm going to probably
89:55 - import all these libraries from lin.
89:58 - Vector stores. cassendra I'm going to
90:00 - import cassendra along with this I'm
90:02 - also going to use this Vector store
90:03 - index wrapper it is going to wrap all
90:05 - those particular vectors in one specific
90:08 - package so that it can be used quickly
90:10 - then I'm also going to import open AI
90:12 - because open AI is the thing that we
90:14 - really need to use along with this we
90:15 - are also going to use open a embeddings
90:17 - which will be responsible for converting
90:20 - your text into vectors
90:22 - along with this if you want some kind of
90:23 - data set from hugging face you can also
90:25 - use this and one more important library
90:28 - that we are going to use is cashio now
90:30 - Casio actually helps you to uh probably
90:33 - integrate with the Astra DB right in
90:35 - Lang chain and it'll also help you to
90:38 - initialize the DB connection so all
90:39 - these libraries we are going to use I'm
90:41 - going to execute this step by step we
90:43 - going to probably see and this is the
90:44 - first step installing the libraries and
90:46 - initializing all the libraries that we
90:48 - are specifically going to use along with
90:50 - this what we are going to also import is
90:52 - one PDF which is called as Pi PDF 2 this
90:55 - will actually help you to read any PDF
90:58 - uh read the uh text inside the PDF
91:01 - itself so this is one amazing library to
91:03 - probably use okay so here I have
91:05 - basically used pip install Pi PDF 2 so
91:07 - let me just go ahead and execute it and
91:09 - inside this you will be able to see it
91:11 - shows requirement already satisfied
91:13 - because I've already installed over here
91:15 - then from PI PDF you're going to use PDF
91:17 - reader because this will be the
91:19 - functionality that will be used in order
91:21 - to to read the document here is the
91:24 - document that I have specifically taken
91:25 - so this is one budget speech PDF so this
91:28 - is the Indian budget that is probably of
91:31 - 2023 it's a big document with somewhere
91:34 - around 461 KB file it has around 30
91:37 - pages so I'm going to specifically read
91:39 - this PDF and then convert into vectors
91:42 - store it in the database itself and then
91:44 - query from the database anything that
91:46 - you have any information about that
91:48 - particular PDF now let's go ahead with
91:50 - the setup okay now with respect to the
91:53 - setup you require three important
91:55 - information one is the astrab
91:57 - application token one is the Astra DB ID
92:01 - okay so where you can probably get this
92:03 - two information so go to your vector
92:06 - database uh Vector database in the data
92:08 - Stacks so here uh is what you have
92:10 - specifically logged in okay as I said
92:14 - inside your DB just go and click on
92:16 - connect here you need to click on
92:18 - generate token as soon as you probably
92:20 - click on generate token then you will be
92:22 - getting some code which looks like this
92:24 - this token you will specifically go
92:26 - getting so this will be probably found
92:29 - in your token Json file so it'll
92:31 - probably show you a Json file which will
92:32 - have this information okay the first
92:35 - information that you have over here is
92:37 - the Astra DB application token so here
92:39 - you can probably see it starts with
92:42 - Astra CS so what you need to do just
92:44 - click on the generate token and you'll
92:45 - be able to see it this is the first
92:47 - information you just need to copy and
92:48 - paste it over here the second
92:50 - information is Astra DB ID right Astra
92:53 - DB ID is nothing but this specific
92:55 - information that is your database ID
92:57 - where do you get it you just need to
92:59 - copy it from here so this is the
93:00 - information with respect to your astrab
93:03 - ID so this two information once you do
93:05 - it you paste it over here I've already
93:07 - pasted it and then you can also see that
93:09 - I've also used some open API key and
93:11 - this specific API key don't use this
93:14 - only because Ive made some changes I've
93:15 - already executed the code also okay so
93:18 - I'm going to take this three information
93:20 - this two information is basically used
93:22 - to connect to your Astra DB right which
93:24 - has a cassendra DB hosted over there in
93:26 - the cloud right and the other
93:28 - information is basically to use the open
93:31 - AI API features right so all this
93:33 - information is basically there I'm going
93:35 - to probably execute this and then we
93:37 - will go ahead and read our budget speech
93:40 - PDF so this is the first step according
93:42 - to this we are reading the specific
93:44 - document before that we have initialized
93:45 - everything with respect to this okay so
93:48 - once we specifically do this I will
93:50 - probably be reading this
93:52 - now after reading as I said we are going
93:54 - to divide all our content into some kind
93:57 - of chunks right so here is what chunks
93:59 - we are basically going to do now first
94:01 - of all I will read all the raw text so
94:03 - for this I'm going to use from type
94:05 - extension using concatenate I'm going to
94:08 - read from each and every pages I will
94:10 - extract all the text so here you can
94:12 - probably see for I comma page in
94:15 - enumerate PDF reader. Pages page.
94:19 - extract text Will basically take out all
94:21 - the text from those pages and it will
94:23 - concatenate in this particular variable
94:25 - that is rawcore text so once I probably
94:27 - execute this what will happen is that
94:29 - you will be able to get all the text
94:33 - inside this particular variable so you
94:34 - can probably see over here rawcore text
94:37 - has all the entire text so this is the
94:40 - entire text from that specific PDF right
94:42 - slash in basically means new line so
94:44 - this step is basically done just imagine
94:46 - before if we did not had this specific
94:48 - Library it was very difficult to read a
94:49 - PDF right and we have actually done this
94:52 - just with writing four to five lines of
94:53 - code now the next step is that we will
94:57 - initialize the connection to your
94:58 - database I have all my database
95:00 - information right like uh token ID and
95:03 - the database ID I'm going to use that
95:05 - cashio cashio is basically used as a
95:07 - library over there for initializing of
95:09 - this particular database so cashier.
95:11 - init here I'll be giving one parameter
95:13 - which is called as token which will be
95:15 - nothing but astb application token and
95:17 - then your database ID which is nothing
95:19 - but astb ID right so I've taken this two
95:21 - information I will execute this you'll
95:23 - get some kind of warnings so don't worry
95:25 - about the warnings it is just like it is
95:27 - showing you some kind of warnings okay
95:29 - with respect to some drivers issues and
95:30 - all but this will basically get executed
95:33 - and now I have uh basically initialized
95:35 - my DB itself right now we are going to
95:38 - create the Lang chain embeddings L LM
95:41 - objects for letter use so for that I'm
95:43 - going to use I'm going to initialize
95:44 - open AI with my open AI key and
95:47 - embeddings also open AI embeddings with
95:48 - my open a key so I have my llm I have I
95:51 - have my embeddings okay now is the main
95:54 - step I need to create my lch Vector
95:57 - store so over here this is what we are
96:00 - basically going to create now right and
96:02 - for that you know we have initialized
96:04 - cendra right we have we have imported
96:06 - cendra now what will do is that in this
96:08 - cassendra we will provide three
96:10 - important information what is the kind
96:12 - of embeddings we are going to use what
96:14 - is the table name inside this particular
96:16 - database session none keyp space none so
96:18 - this is the default parameters we have
96:20 - specifically used QA mini demo is my
96:23 - table name okay just like a question
96:25 - answer table name and what kind of
96:27 - embeddings we are going to specifically
96:29 - use that basically means whenever we
96:30 - store any whenever we push any data in
96:33 - my cassendra DB in my Astra DB itself
96:35 - what it is going to do it is going to
96:37 - probably convert all the text using this
96:39 - embeddings into vectors right and this
96:41 - is the embeddings that we have
96:42 - initialized over here so here is the
96:44 - next step we will go ahead and execute
96:46 - this so this is my Astra Vector store
96:48 - but still I have not probably converted
96:51 - my text into vectors only when when I'm
96:53 - pushing my data inside my DB that time
96:56 - this entire embeddings will probably
96:58 - convert that particular data into
97:00 - vectors then what we are specifically
97:03 - going to do is that we will take this
97:05 - data and we will try to uh we'll take
97:08 - this entire data we'll convert into
97:10 - checks uh chunks and we'll also do the
97:12 - text embedding right text embedding
97:14 - while inserting right so here you first
97:16 - of all we are dividing the data or the
97:18 - entire data entire document into text
97:20 - Chunk so for this we are using character
97:22 - text splitter which is basically present
97:24 - in Lang chain. text splitter we need to
97:27 - split the text using character text
97:28 - splitter it should not increase the
97:30 - token size so here I've given character
97:33 - text splitter I'm saying use the
97:35 - separator slash in use chunk size some
97:37 - chunk size of 800 characters chunk
97:39 - overlap can be 200 and how much is the
97:41 - length with respect to that specific
97:42 - length you can probably provide it over
97:44 - here right and once I probably do this
97:47 - you can see text splitter. split text
97:49 - here you will be able to get all the
97:51 - text and if I see the top 50 text you
97:54 - can probably see that I'll be able to
97:56 - see all the top 50 text over here right
97:59 - all the data itself this is amazing
98:01 - right and this is basically from the PDF
98:04 - right all the data all the data right it
98:06 - is basically taking the top 50 right and
98:09 - understand the token size is basically
98:11 - over here as the chunk size is somewhere
98:13 - around 800 okay now this is done we have
98:16 - the text I'm going to just use top 50
98:18 - and probably store it in the vector
98:20 - database to see if everything is working
98:22 - fine now how to add this specific text
98:25 - now what will happen when I add this
98:26 - text inside my Cassandra DBC axtra
98:30 - Vector store what is this this is
98:31 - basically initialized with respect to
98:33 - the cendal library right so here you'll
98:35 - be able to see that I have used
98:37 - embeddings so now when I'm inserting
98:39 - inside the cassendra DB what it is going
98:41 - to do it is going to apply this specific
98:43 - embeddings also so that is the reason
98:45 - you'll be able to see that when we write
98:47 - extraor Vector uncore store. addore text
98:51 - and I'm taking the top 50 top 50 texts
98:54 - over there this will also perform
98:56 - embeddings so that basically means if I
98:58 - see over here it is going to perform
99:00 - this task and it is going to insert in
99:02 - the Astra DB which is having that
99:03 - cassendra over there right so it is
99:05 - going to do this both the steps with
99:07 - respect to this particular code so we
99:09 - are going to add this text and then we
99:11 - also going to wrap wrap this entire
99:14 - inside a wrapper okay so these are the
99:16 - information this is the index that we'll
99:18 - be getting with respect to those text so
99:20 - once I proba executed you'll be seeing
99:22 - that in the same database it is going to
99:25 - insert all this headlines okay now
99:28 - finally let's go ahead and tex it that
99:30 - basically mean I have my vectors inside
99:32 - my database now it's time that we just
99:34 - query and we ask some kind of questions
99:37 - now I have read this entire PDF guys I
99:39 - could find out some of the question like
99:40 - what is the current gbd how much
99:42 - agriculture Target will be increased and
99:44 - all so I will take this particular
99:45 - example and let's say I'm writing first
99:48 - question is equal to True while true if
99:49 - first question I'm just say that input
99:51 - okay it will just ask like what kind of
99:53 - question you want to type else uh it is
99:56 - just asking you to uh put more questions
99:59 - if I write quit it is going to break
100:01 - otherwise it is going to continue now
100:03 - see this is the most important as soon
100:04 - as I give my first question it will go
100:06 - ahead with v Astra Vector index and
100:09 - it'll query whatever query text we are
100:11 - specifically using and the llm models
100:13 - that we are specifically initialized and
100:15 - after that we will be getting the answer
100:18 - along with this we'll also be providing
100:19 - some information
100:21 - right like for Doc score or similarity
100:24 - Source score like some other information
100:26 - also right so let's go ahead and execute
100:28 - it and as I said I'm going to use this
100:30 - question okay how much is the
100:33 - agriculture Target to be increased and
100:36 - what focus it will be okay so I'm going
100:38 - to paste it over here I'm going to press
100:40 - enter so as soon as I press enter you
100:42 - can see that it is now taking the
100:44 - information see this um you can probably
100:47 - see over here we are quering this
100:49 - particular DB right and it's going to
100:50 - give me the top four results okay so
100:52 - here you can see that agriculture credit
100:54 - Target will be increased to 20 lakh CR
100:56 - with the focus on animal husbandry da
100:59 - and Fisheries right why it is giving
101:01 - only this much data because I've told
101:02 - that take the 84 characters or 84 words
101:06 - 84 characters text still there and
101:08 - probably give the results right if I
101:10 - increase this it'll give you more result
101:12 - along with this you can probably see
101:13 - that it is giving me stop K queries that
101:16 - is the four query Hyderabad will be
101:18 - supported as Center of Excellence some
101:20 - more information but the most suitable
101:22 - answer that you have specifically got is
101:24 - this one right and this is what probably
101:27 - if you go ahead and search in the PDF if
101:29 - you give the same question you will be
101:31 - able to see the same answer right along
101:33 - with this probably if I want to probably
101:35 - see what is the current GDP if this
101:37 - information is present over there it'll
101:39 - also be giving you that specific answer
101:41 - it'll just do the similarity search
101:43 - right so here you can current gbd is
101:45 - estimated to be 7% isn't it amazing now
101:48 - you can probably take any huge data
101:50 - because at the end of the day you
101:51 - specifically using DB right and finally
101:54 - if you want to quit it I will just go
101:55 - ahead and write quit and this is
101:57 - basically quit right so in short we have
101:59 - performed each and every step now this
102:01 - is what which is happening whenever a
102:02 - human is giving an text query text
102:04 - emings will happen and based on that
102:06 - similarity search and then you'll be
102:07 - probably get the output right and this
102:09 - is the entire steps We have basically
102:11 - done step by step so guys yet another
102:15 - amazing video on generative AI where I
102:18 - will be specifically discussing about
102:20 - llama 2
102:21 - uh Lama 2 is an open-source model uh
102:24 - again it has been created by Facebook or
102:27 - meta and you can use this specific model
102:30 - even for commercial purpose uh so this
102:32 - is quite amazing this is an
102:34 - open-source llm model altogether I will
102:37 - try to show you how we can use this
102:39 - create an end to endend project also in
102:42 - this specific video so there are many
102:44 - things that are going to happen and
102:45 - probably whatever topics that I teach
102:47 - going forward that is related to
102:49 - generative AI I will definitely follow
102:51 - this kind of approach so that you also
102:53 - get a brief idea about all these kind of
102:55 - models so what is the agenda of this
102:58 - particular video the agenda is that we
103:00 - will get to know about Lama 2 then we
103:03 - will go ahead and see the research paper
103:04 - where I will be talking about the key
103:06 - points uh about the Lama 2 model again
103:09 - since this is an open source and uh soon
103:12 - Lama 3 is also going to come up so that
103:14 - is a reason I'm going to create this
103:15 - particular video I really want to be in
103:17 - sync with all the open source llm models
103:19 - that are coming up right
103:21 - then we'll go and apply and download the
103:23 - Llama 2 model so we'll be seeing like
103:25 - how we can actually use this particular
103:27 - model in our project also so for that
103:29 - purpose I will be downloading this model
103:31 - you have to also apply this in the meta
103:33 - website itself and there is also one way
103:37 - how uh we can also use it directly from
103:39 - hugging face so I will also show you
103:41 - that and after that we will try to
103:43 - create an end to end llm project and
103:45 - this will be a Blog generation llm app
103:48 - uh all these topics I will be covering
103:50 - it I know it'll be a little longer video
103:53 - but every week one kind of this kind of
103:55 - video is necessary for you all and since
103:58 - 2024 I have the target I really need to
104:01 - teach you gener in a way that you can
104:04 - understand it and use it in your
104:05 - industries also so I will keep a Target
104:09 - so every video I'll keep a Target like
104:10 - this target for this particular video
104:12 - is, L likes not thousand lcks but
104:16 - thousand likes and comments please make
104:19 - sure that you write some comments and
104:21 - I'll keep the target to 100 okay
104:24 - so this will actually motivate me this
104:27 - will probably help this particular video
104:29 - to reach to many people through which
104:31 - they can actually use this and entirely
104:33 - this is completely for free which will
104:34 - also be beneficial for you and I my aim
104:37 - is to basically democratize the entire
104:39 - AI education okay so let's go ahead and
104:42 - let's first of all start with the first
104:44 - one that is introducing Lama 2 what
104:46 - exactly is Lama 2 Lama 2 is an again
104:49 - open source a large language model it
104:51 - can be it is used and it is uh available
104:54 - for free for research and commercial
104:57 - purpose you can actually use this in
104:59 - your companies in a startup wherever you
105:01 - want to use it okay now let's go ahead
105:03 - and read more about it so inside this
105:06 - model uh it has till now Lama 2 has
105:08 - released three different model size uh
105:11 - one is with 7 billion parameters the
105:13 - other one is 13 billion parameters and
105:15 - the the best one is somewhere around 70
105:17 - billion parameters uh pre-training
105:19 - tokens is taken somewhere around 2
105:21 - trillion context length is
105:24 - 4096 uh again when I say that if I
105:27 - probably compare most of the open source
105:29 - models I think Lama 2 is probably very
105:32 - good we'll be seeing all those metrics
105:34 - also so here you can see Lama 2
105:36 - pre-trained models are trained on two
105:37 - trillion tokens and have double the
105:39 - context length than Lama one it's fine
105:42 - tune models have been trained on over 1
105:45 - million human annotation okay and now
105:47 - let's go ahead and see The Benchmark and
105:49 - this is with respect to the the
105:50 - benchmarking with all the open source
105:52 - models so it is not comparing with chat
105:54 - GPT sorry GPT 3.5 GPT 4.0 or Palm 2 okay
105:58 - so all the open source models uh here
106:00 - you can probably see this is the three
106:02 - version 7 billion 13 billion 65 billion
106:04 - 70 billion right all Lama 2 right llama
106:07 - 1 was 65 billion one uh one model it had
106:10 - over there so if you see Lama 2 with
106:13 - respect to all the metrix is very good
106:15 - MML that is with respect to human level
106:18 - understanding Q&A all all the
106:20 - performance metrix is superb natural
106:22 - language processing gsmk human evalve in
106:25 - human evalve it is probably having a
106:27 - less when compared to the other other
106:29 - open source models so here you can see
106:31 - in human uh human Val human eval human
106:34 - eval basically means with respect to
106:36 - writing code code generation there it
106:38 - has a lot of problems so here you can
106:40 - see 12.8 18.3 it is less it is less when
106:43 - compared to all the other open source
106:46 - models over here and there are also some
106:48 - other parameters you can probably see
106:49 - over here with with respect to different
106:51 - different tasks you can see the
106:52 - performance metrics okay so this was
106:54 - more about the model now let's go ahead
106:56 - and
106:57 - probably and this is one very important
106:59 - statement that they have come up with we
107:01 - support an open Innovation approach to
107:03 - AI responsible and open Innovation give
107:06 - us all a stake in the AI development
107:08 - process so uh yes Facebook is again
107:11 - doing a very good work and then soon
107:13 - they also going to come up with the Lama
107:14 - 3 Model now let's go ahead and see the
107:17 - research paper so here is the research
107:18 - paper the entire research paper now see
107:21 - uh what you should really focus on a
107:23 - research paper you know in research
107:24 - paper they'll be talking about how they
107:27 - have actually trained the model what
107:29 - kind of data points they have they
107:30 - actually taken in order to train the
107:32 - model and all right so over here you can
107:34 - see that um in this work we developed
107:36 - and release Lama 2 a collection of
107:38 - pre-trained and fine-tune Lun language
107:40 - models ranging in scale from 7 billion
107:42 - to 70 billion parameters so if you talk
107:44 - about parameters it is somewhere around
107:45 - 7 billion to 70 billion our fine tune
107:48 - llms called Lama 2 chart are optimized
107:50 - for dialog use cases just like a chat
107:52 - bot and all right uh more information
107:54 - you can probably see over here what is
107:56 - the pre-training data see so they have
107:58 - told that our pre-training data includes
108:00 - a new mix of data from publicly
108:02 - available sources which does not include
108:04 - data from meta products or Services
108:06 - we've made an effort to remove data from
108:08 - certain sites known to contain a high
108:10 - volume of personal information about
108:12 - private individuals now this is where
108:14 - ethics comes into picture they really
108:16 - want to use this AI in a responsible way
108:18 - right so we trained on two trillion
108:20 - tokens uh and obviously for all these
108:23 - things you have to use Nvidia GPU okay I
108:25 - know guys it is boring to read the
108:27 - research paper but it is good to have
108:29 - all this specific knowledge so please
108:31 - keep your energy up watch this video
108:34 - till the end then only you'll be able to
108:36 - understand things right not only here
108:38 - because later on you'll be having other
108:40 - models like Mistral I'll probably create
108:42 - a video on Mistral also in the upcoming
108:44 - video right so everywhere with an end to
108:46 - end project everything I will take this
108:49 - format let me know know whether you're
108:50 - liking this format or not so training
108:52 - data we adopt most of the pre-training
108:54 - settings and model architecture from
108:56 - Lama one we use the standard Transformer
108:58 - architecture now you can understand how
109:00 - important Transformer is right most of
109:02 - the open source model are based on
109:04 - Transformer architectures itself right
109:06 - we trained using adamw Optimizer okay
109:09 - with so and so parameters we use consign
109:12 - learning rate schedule with so and so
109:14 - and here you could probably see with
109:15 - respect to the performance like how well
109:18 - it was training BPL process tokens how
109:20 - many tokens was actually done with
109:22 - respect to all the different varieties
109:23 - of llama model now this is basically the
109:26 - training loss you can probably see
109:27 - training loss for Lama 2 okay this is
109:30 - also important training hardware and
109:31 - carbon footprint it is basically saying
109:33 - that how much it is using they used
109:35 - Nvidia a100 I've seen this GPU it's
109:38 - quite amazing it's very huge okay and it
109:41 - is very fast also but again with such a
109:43 - huge amount of data it is also going to
109:44 - take time right so all these things are
109:46 - there you can also see time how much
109:48 - time it has basically taken how how many
109:50 - hours 70 billion this many number of
109:52 - hours power consumption this this all
109:55 - information is there right this is good
109:57 - to have right all all you should know
109:59 - like we just taking more energy and all
110:01 - right and here um with respect to the uh
110:05 - llama 2 you can probably see with
110:06 - respect to Common reasoning it is very
110:08 - good when compared to all the other
110:10 - models open source model World Knowledge
110:12 - reading comprehension math mlu math it
110:16 - is little bit less you can see over here
110:19 - when compared to the other model I think
110:20 - it is still 35 itself but remaining all
110:23 - it has basically come I think this 35 is
110:25 - also greater than all these things right
110:28 - MML is very much good it is able to
110:29 - achieve till 68.9 Google gini has said
110:32 - that it is reach to 90% okay but again
110:35 - this is the thing that you really need
110:36 - to know uh some more information fine
110:39 - tuning fine tuning also okay this is
110:41 - very much important guys it has it has
110:44 - used this uh reinforcement learning okay
110:47 - where uh and with human feedback so our
110:50 - R lhf basically means reinforcement
110:52 - learning with human feedback and this is
110:54 - what chat GPT is also trained with right
110:56 - so uh definitely I think as we go ahead
110:59 - as we go ahead and see Lama 3 and all it
111:00 - is going to give us very good accuracy I
111:03 - guess okay so superv fine tuning uh if
111:06 - you go ahead and just check how
111:08 - generative AI how llm models are trained
111:10 - you'll be able to get a video on this I
111:12 - created a dedicated video where I
111:14 - explained about supervised fine tuning
111:16 - how does supervised fine tuning happen
111:19 - what how does
111:20 - uh rhlf happens right reinforcement
111:23 - sorry R lhf human feedback happens all
111:26 - those things I've actually explained so
111:28 - here you can see some of the prompts
111:29 - right a poem to help me remember the
111:31 - first 10 elements on the periodic table
111:32 - hydrogen come first as the element one
111:34 - helium is second for balloons this this
111:36 - I want you to roast me now see this
111:38 - statement is also very important right
111:40 - so uh I want you to roast me I want you
111:43 - to make it particular brutal swearing at
111:46 - me so it is saying I'm sorry but I
111:47 - cannot comply with that request using
111:50 - language or intentional hurting someone
111:51 - feelings is never expectable so some
111:53 - kind of feelings they're trying to bring
111:55 - inside all these kind of models okay uh
111:58 - sft annotation is basically there you
111:59 - can probably read all these things this
112:01 - is good to have good to learn how this
112:03 - reinforcement learning with human
112:04 - feedback was done and all everything is
112:06 - given over here so uh this was all about
112:09 - the research paper still there are many
112:11 - papers to go ahead you can probably go
112:12 - ahead and check it out uh there is a
112:14 - concept of reward modeling also reward
112:16 - is also given right the parameters they
112:19 - have used two separate parameters over
112:20 - here and various kind of test is
112:22 - basically done so this was all the
112:24 - information about this now the next
112:26 - thing is that how you can go ahead and
112:27 - apply or download this specific model
112:30 - just click on download the model over
112:31 - here so the third part provide all the
112:35 - information over here and what all
112:36 - things you specifically required like
112:37 - Lama 2 and Lama chart code Lama Lam
112:39 - guard so go ahead and just put all this
112:42 - information and click on submit after
112:44 - submitting probably it'll take 30
112:46 - minutes and you will start getting this
112:48 - mail okay
112:50 - you all start to set building with code
112:52 - llama you will also be getting the
112:54 - access from Lama 2 see you'll be getting
112:56 - this entirely right model weights
112:59 - available all the models weight will be
113:00 - given to you in this specific link you
113:02 - can click and download it also if you
113:04 - want so that you can use it in your
113:06 - local or you can deploy it wherever you
113:07 - want okay so this kind of mail you'll be
113:09 - getting uh Lama 2 commercial license all
113:12 - the information with all the info over
113:14 - here and these all models it is
113:16 - specifically giving again I told you 70b
113:19 - 70b chat why these two models are there
113:21 - this is specifically for Q&A kind of
113:24 - application dialog flow application I
113:26 - can basically say uh remaining one can
113:28 - be used for any kind of task uh in a
113:30 - complex scenarios and all okay so once
113:33 - you do this the next thing is that you
113:34 - can also go to hugging face in hugging
113:36 - face you have this Lama 270b chat FF and
113:40 - there is the entire information that is
113:42 - probably given about the entire model
113:44 - itself you can probably read it from
113:46 - here with respect to this Lama 2 is a
113:48 - collection of pre-trained this this
113:49 - information is basically there you can
113:51 - also directly use it if you want the
113:53 - code with respect to Transformer you
113:54 - just click on using Transformer you'll
113:56 - be able to get this entire code where
113:58 - you can directly use this also okay what
114:00 - we are basically going to do I'm not
114:02 - going to use 70 billion parameters since
114:04 - I'm just doing it in my local machine
114:05 - with the CPU itself okay so what I will
114:08 - do I will be using a model which is
114:10 - basically uh it is basically a quantized
114:12 - model right with respect to this same
114:14 - llama model it is called as Lama to 7B
114:16 - chat gml so if you go ahead and see see
114:19 - this uh you'll be able to see that this
114:21 - particular model you'll be able to
114:23 - download it and you'll be able to use it
114:26 - it is just like a good version but uh
114:29 - less parameter versions right so when we
114:31 - say contage that basically means uh this
114:34 - model has been compressed and probably
114:36 - provided you in the form of weight so
114:37 - what you can do any of these models the
114:39 - recent model what you can do over here
114:41 - which is of 7.16 GB you will first off
114:43 - all download it so I've already
114:45 - downloaded it so I'm just going to
114:47 - cancel it over here okay because I've
114:50 - already downloaded it over here okay so
114:52 - I will do that specific download uh over
114:54 - here and then you can probably go ahead
114:57 - and start working on this and start uh
114:59 - using this and now how you can probably
115:01 - use it I Will Show You by creating an
115:04 - endtoend project so for creating an NN
115:07 - project what are the steps uh again the
115:09 - project name that I've already told is
115:11 - basically a b blog generation llm app
115:14 - here I'm going to specifically use this
115:16 - open-source llama Lama 2 model again I'm
115:19 - going to use the hugging face API also
115:21 - for that uh and let's see how the
115:23 - specific uh step by step how we'll be
115:25 - doing this specific project so let's go
115:27 - ahead and let's start this particular
115:28 - project okay guys now let's start our
115:31 - blog generation llm platform uh
115:33 - application so the model that I had
115:36 - actually generated over here you can
115:37 - probably see the model over here in the
115:39 - bin size and this is the size of the
115:41 - model is over here I'm going to
115:43 - specifically use in my local machine for
115:45 - my local inferencing and all so over
115:48 - here what I will do I will go quick
115:49 - quickly go ahead and open my VSS code so
115:52 - my vs code is ready over here okay now
115:57 - let's go ahead and do step by step
115:59 - things that we really need to do first
116:00 - of all I'm just going to create my
116:01 - requirement. txt file requirement. txt
116:05 - file and now I will go ahead and open my
116:09 - terminal so I will go ahead and open my
116:12 - command prompt and start my project okay
116:15 - so quickly I will clear the screen I
116:17 - will deactivate the default
116:20 - environment cond deactivate okay and
116:23 - we'll do it step by step so first step
116:26 - as usual go ahead and create my
116:28 - environment cond create minus P VNV
116:32 - environment I hope I've repeated this
116:34 - specific step lot many times so here I'm
116:36 - going to create cond create minus pvnv
116:39 - with python wal to
116:43 - 3.9 y okay so just to give you an idea
116:47 - what how exactly it is going to run run
116:50 - how things are basically going to happen
116:52 - uh step by step we'll understand so
116:55 - first of all we are creating the
116:57 - environment and then we will go ahead
116:59 - and fill our requirement. txt now in
117:02 - requirement. txt I'm going to
117:04 - specifically use some of the libraries
117:06 - like sentence Transformers C Transformer
117:10 - fast API if you want to specifically use
117:12 - fast API I I'll remove this fast API I
117:15 - think uh I will not require this IPI
117:17 - kernel so that I can play with Jupiter
117:20 - notebook if I want I can also remove
117:21 - this I don't want it langon I will
117:24 - specifically using and streamlet I'll be
117:26 - using okay so first of all I will go
117:28 - ahead and create cond activate Okay cond
117:33 - activate uh
117:35 - venv so we have activated the
117:37 - environment and the next thing is that I
117:39 - will go ahead and
117:41 - install all the requirement.
117:44 - txt okay and in this you don't require
117:48 - uh okay so okay I've not saved it so
117:51 - requirement. txt is not saved now in
117:54 - this you don't require any open AI key
117:56 - because I'm just going to use hugging
117:58 - face and from hugging face I'm going to
117:59 - probably call my model which is
118:01 - basically present in my local so here is
118:03 - the model that I am going to
118:04 - specifically call okay so once this
118:07 - installation will take place then we
118:09 - will go ahead and create my app.py and
118:13 - just give you an idea like uh I'm going
118:15 - to basically create the entire
118:18 - application in this specific
118:20 - file itself so quickly uh let's go ahead
118:24 - and import our streamlet so till the
118:28 - installation is basically happening I
118:30 - will go ahead and install
118:32 - streamlet Okay as
118:35 - St and then along with this I will also
118:38 - be installing Lang chain. prompts
118:40 - because I'm also going to use prompts
118:42 - over here just to give you an idea how
118:44 - things are going to happen it's going to
118:46 - be very much fun guys because open
118:48 - source right it it's going to be really
118:50 - amazing with respect to open source you
118:51 - don't require anything as such and then
118:54 - I'm going to basically write prompt
118:55 - template because we need to use this
118:57 - from Lang chain then I'll be also using
119:00 - from Lang
119:02 - chain Lang chain do llm I'm going to
119:06 - import C
119:09 - Transformer okay why this is used I will
119:12 - just let you know once I probably write
119:14 - the code for this okay so three three
119:16 - Transformers also I'm going to basically
119:18 - use over here so this is going to be
119:20 - from okay so C Transformers prom
119:23 - template and St for the streamlet I'm
119:26 - going to specifically use the first
119:28 - thing is that I will go ahead and write
119:30 - function to
119:32 - get
119:34 - response from my um llm uh llama model
119:38 - right Lama 2 model I'm going to
119:41 - basically use this okay still the
119:44 - installation is taking place guys it is
119:45 - going to take time because there are so
119:47 - many libraries I've been installing okay
119:49 - so I'll create a function over here
119:51 - let's create this particular function
119:53 - later on okay now after this what I'm
119:56 - actually going to do is that we'll go
119:57 - ahead and set our streamlet right setor
120:02 - pageor config see now many people will
120:05 - say streamlet or flask it does not
120:07 - matter guys anything you can
120:08 - specifically use streamlet why I'm
120:10 - specifically using is that it'll be very
120:12 - much easy for me to probably create all
120:14 - the things right the UI that I want so
120:18 - in a set page config I'm going to
120:21 - basically use page title generate blogs
120:23 - page icon I've taken this robot icon
120:25 - from the streamlet documentation layout
120:27 - will be Central and uh initial sidebar
120:30 - will be collapsed okay so I'm not going
120:33 - to open the sidebar in that specific
120:35 - page now I will keep my ht.
120:39 - header so ht. header in here I'm going
120:42 - to basically generate my blogs right so
120:48 - generate the blogs and I'll use the same
120:50 - logo if I want so it looks good okay so
120:54 - this is the next thing I will probably
120:56 - this will be my head over here first of
120:59 - all I will create my input text okay so
121:02 - input text field right and this will
121:06 - basically be my input text field and let
121:08 - me keep it as a um a text area or a text
121:13 - box whatever things is required so I
121:15 - will write go ahead and write St
121:18 - do
121:20 - st. input textor input okay so this will
121:24 - basically be my St so let's see
121:26 - everything is working fine why this is
121:28 - not coming in the color okay still the
121:30 - installation may be happening so over
121:32 - here I'll go ahead and write this I will
121:35 - say enter the blog topic right so if you
121:39 - just write the blog topic it will should
121:41 - be able to give you the entire blog
121:43 - itself with respect to anything that you
121:45 - want okay so done the installation is
121:47 - basically done over here you can
121:49 - probably see this good I will close this
121:52 - up now I'll continue my writing the code
121:54 - so I've created a input box now the
121:57 - other thing that I really want to create
121:58 - is that I'll try to create two more
122:00 - columns or two more Fields below this
122:02 - box okay one field I will say that how
122:05 - many words you specifically want for
122:07 - that blog okay so over here
122:11 - creating two more
122:13 - columns for additional two
122:17 - Fields additional two field okay so here
122:20 - first of all will be my column 1 let's
122:23 - say column 1 and column 2 I will just
122:25 - write it like
122:27 - this and here I will say St do
122:31 - columns and uh here I'll be using I'll
122:36 - be giving right what should probably be
122:38 - the width like let's say 5 comma 5 if
122:40 - I'm giving you'll be able to see that
122:42 - the width of the text box of width of
122:43 - the column that I specifically have I'll
122:45 - be able to see it okay I'm I'm just
122:47 - creating that width for that columns
122:49 - okay now I'll say with column one
122:53 - whenever I probably write anything in
122:55 - the column one or select in anything in
122:56 - the column one this will basically be my
122:59 - number of words okay number of words and
123:01 - for here I will be creating my St do
123:04 - text input and this text input will
123:07 - probably retrieve the details of number
123:11 - of words okay so here I have
123:14 - specifically number of words great now
123:18 - the next column that I specifically want
123:20 - the detail so for whom I am actually
123:23 - creating this particular blog I want to
123:25 - probably put that field also so with
123:27 - column 3 I will probably create
123:30 - something like this I will say okay fine
123:32 - um what blog style I will I'll create a
123:35 - field which is basically called as blog
123:37 - style okay now inside this blog style
123:41 - what I am actually going to do sorry not
123:43 - column 3 column two because I've created
123:45 - those variable over there okay so the
123:47 - blog style will be basically be a drop
123:49 - down so I will say St do select box okay
123:54 - and I will say what box this is
123:58 - specifically for so that first message I
124:00 - will say select
124:02 - write writing the
124:05 - blog
124:07 - for for okay so this I'm basically going
124:11 - to say that okay for whom I'm going to
124:12 - write this particular blog okay and with
124:15 - respect to this I can give all the
124:17 - options that I really want to give okay
124:19 - so for giving the options I will also be
124:21 - using this field so let's say the first
124:23 - option will be for researchers whether
124:25 - I'm writing that particular block for
124:27 - researchers or for data
124:30 - scientist okay data scientist or I am
124:34 - basically writing this block
124:38 - for for common people okay common people
124:42 - so this three information I really want
124:45 - over here and this will basically help
124:47 - me to put some Style filing in my blog
124:50 - okay that is the reason why I'm
124:51 - basically giving over here okay and by
124:54 - default since we need to select it in
124:56 - the first option so I will keep it as
124:58 - index as zero okay so here is all my
125:02 - stylings that I've have specifically
125:03 - used so if you want to probably make it
125:05 - in this way so you'll be able to
125:07 - understand this so this will be my
125:08 - column one and this is basically be my
125:10 - column two okay and then finally we will
125:13 - go ahead and write submit button submit
125:17 - will be St
125:19 - dot button and this will basically be my
125:23 - generate okay so I'm going to basically
125:27 - generate this entirely uh generate is
125:30 - just like a button which will basically
125:31 - Click by taking all this particular
125:33 - information so from here I'll be getting
125:35 - my input from here I'll be getting
125:38 - number of words from here I'll be
125:39 - getting my blog style okay all this
125:41 - three
125:41 - information now this will actually help
125:45 - me to get the final response here okay
125:48 - so I will say say if submit okay if
125:51 - submit I have to call one function right
125:54 - and what will be that specific function
125:56 - that function will return me some output
125:59 - okay and that output will be displayed
126:01 - over here now that function I really
126:03 - need to create it over here itself let's
126:04 - say I will say
126:06 - get
126:07 - llama response okay so this is basically
126:10 - my function and this I will create in my
126:14 - definition and what all parameters I
126:16 - specifically require over here right
126:18 - this three parameters right and uh if I
126:20 - probably call this function over here
126:23 - what are the parameters that I'm going
126:24 - to write over here is all these three
126:26 - parameters so first parameter is
126:28 - specifically my text input input
126:31 - text the second parameter that I'm
126:34 - actually going to give over here is
126:35 - number of
126:37 - words the third parameter that I really
126:40 - want to give is my block style so like
126:41 - what block style I really want okay so
126:44 - all this three information is over here
126:46 - so this will basically be my input text
126:49 - okay uh I'll write the same name no
126:52 - worries number of
126:54 - words and third parameter is basically
126:57 - my block style so all these materials
127:00 - will be given in the description if
127:01 - you're liking this video please make
127:03 - sure that you hit subscribe press the
127:04 - Bell notification icon hit like again
127:07 - just to motivate me okay if you motivate
127:09 - me a lot I will create multiple contents
127:11 - amazing content for you okay now here is
127:14 - what I will be calling my llama model
127:18 - right l Lama model Lama 2 model which I
127:21 - have actually downloaded in my local and
127:23 - for that only I will be specifically
127:25 - using this C
127:28 - Transformers right now if I probably go
127:31 - ahead and search in Lang chain Lang
127:34 - chain see whenever you have any problems
127:37 - related to anything as such
127:41 - right C Transformer C Transformer go and
127:45 - search in the documentation everything
127:46 - will be given to you so C Transformer
127:49 - what exactly it is it is it is over here
127:51 - it is given over here or not here let's
127:54 - see the documentation
127:56 - perfect so here you can see C
127:58 - Transformers the C trans Library
128:00 - provides python binding for ggm models
128:03 - so gml models the blog gml models
128:06 - whichever model is basically created you
128:07 - can directly call it from here let's say
128:09 - in the next class I want to call mistal
128:11 - so I can go ahead and write my model
128:13 - name over here as mist and it'll be able
128:14 - to call directly from the hugging phas
128:16 - okay um not only hugging face but at
128:19 - least in the local uh if you have the
128:21 - local if you want to call it from the
128:22 - hugging face then you have to probably
128:24 - use the hugging face API key but right
128:26 - now I don't want to use all those things
128:28 - so I want to make it quite simple so CC
128:30 - Transformers and here I'm going to
128:32 - basically write my
128:33 - model model is equal to and this should
128:36 - be my model path right which model path
128:39 - this one model slash this one right so
128:42 - here you can probably see this specific
128:44 - name V3 Q8 Z bin okay so I'm going to to
128:48 - probably copy this entire
128:50 - path and paste it over here okay so this
128:53 - will basically be my model and inside
128:56 - this what kind of model type I want
128:58 - there is also a parameter which is
129:00 - basically called as model type and in
129:02 - model type I'm going to basically say it
129:04 - is my llama model okay and you can also
129:08 - provide some config parameter if you
129:10 - want otherwise it will take the be
129:13 - default one so I'll say Max newcore
129:17 - tokens
129:18 - is equal to
129:22 - 256 and then the next one will basically
129:25 - be my
129:28 - temperature
129:30 - colon 0.01 let me keep the temperature
129:33 - point less only so I want to see
129:35 - different different answers okay so this
129:37 - is done uh this is my llm model that I'm
129:39 - basically going to call from here and it
129:41 - is going to load it okay now after my
129:43 - llm model is created I will go ahead and
129:46 - write my prompt template because I've
129:48 - Tak taken three three different
129:49 - information so template here I will go
129:52 - ahead and create this will be in three
129:55 - codes if you want to write it down
129:56 - because it is a multi-line statement and
129:58 - I will say write a
130:01 - blog write a blog for which style right
130:07 - blog style for whom for this specific
130:09 - blog style for researchers for freshers
130:12 - for anyone you can write right or I'll
130:15 - say job profiles I can for researcher
130:17 - job profile for fresher job profile for
130:19 - normal people job profile right so
130:21 - something like this job profile for a
130:25 - topic which topic I'm going to basically
130:28 - say this will be my number of words
130:30 - sorry not number of words this will be
130:32 - my
130:33 - input text so this is how we basically
130:36 - write
130:37 - prompts
130:39 - within how many words the number of
130:42 - words okay this many number of words I'm
130:45 - going to basically write this okay so
130:47 - this actually becomes my prompt template
130:50 - entirely okay this is my entire prompt
130:52 - template write a blog for so and so for
130:56 - block style this this this to make it
130:58 - look better what I will do I'll just
131:01 - press tab so that it'll look over here
131:05 - okay so this is my template that I'm
131:07 - probably going ahead with I've given the
131:09 - three information blog style input text
131:12 - number of words everything is given over
131:13 - here now finally I need to probably
131:15 - create the prompt template okay so for
131:18 - creating the prompt template I'm going
131:20 - to use prompt is equal to prompt
131:22 - template and here I'm going to basically
131:25 - give my input variables so input
131:29 - uncore variables and inside this I'm
131:33 - going to basically write first
131:34 - information that I want what kind of
131:36 - inputs I specifically want right uh
131:39 - whether I want um this block style so
131:41 - for block style I can just write style
131:44 - second one I can probably
131:46 - say text third one I can basically
131:50 - say ncore word so this will basically be
131:53 - my three information that I'm going to
131:55 - provide it when I'm giving in my prompt
131:58 - template okay and finally uh this is my
132:01 - input variable this next parameter that
132:03 - I can also go ahead with I can provide
132:04 - my template itself what template I want
132:06 - to give so this will be my template over
132:10 - here now finally we will generate the
132:14 - response from the Lama model OKAY Lama 2
132:19 - model which is from gml okay so here
132:23 - what I'm actually going to do I'm going
132:25 - to basically write llm and whatever
132:26 - things we have learned in Lang chain
132:28 - till now prompt
132:30 - dot prompt.
132:32 - format and here I'm going to basically
132:35 - use email sorry email what are the
132:38 - information that I really want to give
132:39 - over here prompt. format so the first
132:41 - thing is with respect to style the style
132:44 - will be given as block style so I'm
132:48 - going to basically write blog undor
132:51 - style okay the next information that I'm
132:54 - probably going to give is my input text
132:56 - input text is equal to not input text
133:00 - text is equal to input text I have to
133:01 - give text is equal to input undor text
133:05 - and the third parameter that I'm going
133:07 - to give is my ncore words which will
133:10 - basically be by number of words done so
133:15 - this is what I'm specifically giving
133:17 - with respect to my prompt uh and what
133:19 - llm will do it will try to give you the
133:21 - response for this and then we will go
133:25 - ahead and print this response and we
133:28 - will return this response
133:30 - also okay
133:34 - response response okay and what we'll do
133:37 - we will go ahead and return this
133:41 - response so step by step everything is
133:43 - done now I'm going to call this get Lama
133:47 - response over here here already is done
133:49 - now let's see if everything runs fine or
133:51 - not uh hope so at least one error will
133:54 - at least come let's
133:56 - see so I will delete this and let's go
134:00 - ahead and write over here to run the
134:01 - streamlet app all you have to do is just
134:04 - just write streamlet Run
134:07 - app.py Okay so once I probably execute
134:11 - this you'll be able to see this is what
134:14 - is my model but still I'm getting a
134:17 - model streamlet has attribute no head
134:20 - okay so let's see where I have
134:22 - specifically done the mistake because I
134:25 - think it should not be head it should be
134:27 - header okay I could see the error header
134:31 - okay fine no worries let's run it
134:37 - baby let's run this again stream L run
134:40 - app.py no I think it should
134:43 - run this looks good uh enter the block
134:46 - toping number of words researchers
134:48 - writing the researcher blog data
134:49 - scientist common people so let's go
134:51 - ahead and write about
134:53 - large language model so 300 words so
134:57 - number of words I will go ahead and
134:59 - write 300 I want to basically write it
135:02 - for common people and we will go ahead
135:04 - and generate it now see as soon as we
135:06 - click on generate it is going to take
135:07 - some time the reason it is probably
135:10 - going to take some time because uh we
135:12 - are using this particular in my local
135:15 - CPU but we got an error let's see key
135:17 - error block style it seems so I will go
135:20 - to my
135:21 - code block style block style block style
135:25 - so one minor mistake that I have
135:26 - specifically done over here so what I
135:28 - will do is that I'll give the same key
135:30 - name so that it does not give us any
135:33 - issue okay so this will be my input text
135:36 - and number of words the thing is that
135:39 - whatever things I give in that prompt
135:40 - template the input variables should be
135:42 - of that same name okay so that is a
135:43 - mistake I had done it's okay no worries
135:46 - so let's go ahead and and execute it now
135:49 - everything looks fine have assigned the
135:51 - same value over there number of words
135:53 - number of words so here also I'll go
135:56 - ahead and write number of words block
135:58 - style input
136:01 - text and this also should be block style
136:04 - the name I'm giving same right for both
136:07 - prom template and this okay so I think
136:09 - now it should work let's see so go ahead
136:14 - and write this and now my page is open
136:17 - opened now I'll go ahead and write large
136:22 - language models and it will probably
136:24 - create
136:25 - my words so this will be 300 I want to
136:29 - create it for common people let's
136:32 - generate it as I said that the output
136:35 - that I'm probably going to get is going
136:36 - to take some time because I'm running
136:38 - this in local CPU um let's say if you
136:41 - deploy this in the cloud uh with respect
136:43 - to if there are GPU features then you
136:45 - will get the response very much quickly
136:47 - so so just let's wait uh till then uh we
136:50 - get the output hardly but I think it is
136:52 - 5 to 10 seconds Max and since I've told
136:55 - 300 wordss it is again going to take
136:56 - time so let's see the output once it
136:58 - comes so guys it hardly tookes 15
137:01 - seconds to display the result so here
137:03 - you can see that large language models
137:04 - have become increasingly popular in
137:06 - recent year due to the in due to the
137:08 - ability to process and generate
137:09 - humanlike languages it looks like a good
137:11 - blog you can also create any number of
137:13 - words blog itself Now understand that I
137:16 - have a good amount of ram my CPU has lot
137:18 - of cores so I was able to get it in 15
137:20 - seconds for some of the people it may
137:22 - take 20 seconds it may take 30 seconds
137:25 - now you may be asking Kish how can you
137:26 - specifically reduce this time is very
137:29 - much simple guys we will probably do the
137:31 - deployment in AWS or any other Cloud
137:34 - Server itself which I will be probably
137:35 - showing you in the upcoming videos and
137:37 - there you'll be able to see that how
137:39 - with the help of gpus the inferencing
137:40 - also becomes very much easy not only
137:43 - that we'll also see how we can probably
137:45 - fine-tune all this data set with the OWN
137:47 - custom data itself guys yet another
137:50 - amazing llm project for you all now this
137:53 - llm project will be quite amazing
137:55 - because from this like this is just like
137:56 - a base you can probably create any kind
137:59 - of app on top of it you can create text
138:01 - summarizer you can create a quiz app or
138:03 - you can create any other app itself that
138:05 - is probably something related to text
138:07 - right so what is the main aim of this
138:10 - particular project is that from this
138:12 - project you will get all the guidance
138:14 - that is probably required to create that
138:16 - production grade application whenever
138:18 - you specifically work in the companies
138:21 - why because we are going to also include
138:23 - Vector search database and this is where
138:25 - you'll understand the power of the
138:27 - vector search
138:28 - database whenever you work in any NLP
138:31 - project something that is related to
138:33 - text you try to convert those text into
138:35 - embeddings or vectors if you have a huge
138:38 - vectors you you cannot just store it in
138:40 - your local machine you probably are
138:42 - requiring some kind of database and
138:44 - specifically with respect to vectors or
138:46 - embeddings V Vector DB is very super
138:49 - beneficial why because you can probably
138:51 - apply some of the important algorithms
138:53 - like similarity search or you can also
138:56 - uh apply any other algorithms that is
138:58 - related to text it can be text
139:00 - classification very much quickly by just
139:02 - squaring it from the vector database and
139:04 - getting the right kind of output so all
139:06 - these things we are basically going to
139:08 - cover it will probably be a longer video
139:10 - because every step by step I'll probably
139:12 - show you I will also write the code in
139:14 - code in front of you wherever any
139:16 - documentation is probably required I
139:18 - will also show you all those things so
139:21 - yes without wasting any time let's go
139:23 - ahead and probably see this project my
139:25 - main aim is basically to teach you in
139:27 - such a way that you get the right kind
139:29 - of knowledge and this you apply it in
139:31 - your company and nowadays many companies
139:33 - are specifically asking interviews
139:35 - regarding Vector DB they asking related
139:37 - to open a llm models and many more so
139:40 - let me go ahead and share my screen and
139:42 - as I said we will be doing completely
139:45 - from Basics right so here is my vs code
139:48 - I have a document over here budget
139:50 - speech. PF I am probably going to take
139:52 - this particular document upload it in my
139:55 - Vector DB right and then ask any kind of
139:58 - queries from it convert that into a quiz
140:01 - app right let's say this is a general
140:03 - knowledge book I can probably convert
140:06 - this into a quiz app with four options
140:08 - and get the right kind of answer from it
140:10 - right so this is what I'm planning to do
140:12 - other than this any idea you have you
140:14 - can probably do it on top of it right so
140:17 - first first thing first what is the
140:18 - first thing that we really need to do
140:20 - over here is that create a environment
140:22 - right and this is in every project I at
140:26 - least make you do this because it is
140:28 - super beneficial because at the end of
140:30 - the day with respect to every project
140:32 - you need to probably create a separate
140:34 - environment so in order to create an
140:36 - environment I will go ahead and write
140:37 - cond
140:38 - create cond create minus p v andv will
140:44 - be my uh environment name and then here
140:47 - I'll basically going to use Python 3.10
140:50 - right so once I execute it it'll ask me
140:52 - for an option whether I need to install
140:54 - or not I will just say why and go ahead
140:57 - with the installation so this is the
140:58 - first step that we should specifically
141:00 - do right and uh it is important step
141:03 - because at the end of the day you should
141:05 - definitely create a different
141:06 - environment don't always work in the
141:08 - same environment whenever you are
141:10 - actually working in this kind of
141:11 - projects the second thing that I'm
141:13 - probably going to do is that create my
141:15 - requirement. txt
141:17 - requirement. txt the reason because
141:22 - whenever I'm using an lmm model or
141:23 - anything as such I have to probably
141:26 - install a lot of packages so over here
141:29 - first of all I will go ahead and cond
141:30 - activate activate this specific
141:32 - environment V NV slash okay so this is
141:37 - done the environment is activated and we
141:41 - are ready to go right now from my
141:43 - requirement. txt what are things I'm
141:45 - basically going to use I'm going to to
141:47 - probably note down all the requirements
141:49 - over here the libraries that is
141:51 - unstructured Tik toen pine cone client P
141:54 - PDF open aai Lang chain pandas numai
141:58 - python. EnV and at the end of the day
142:01 - guys uh I would always suggest you to
142:03 - please understand about Lang chain Lang
142:05 - chain is an amazing Library it has lot
142:07 - of power lot of functionalities which
142:09 - you can specifically do the community is
142:11 - huge and many many companies are
142:13 - specifically using it okay so
142:15 - requirement. txt has been saved so I
142:17 - will quickly go ahead and install this
142:21 - requirement. txt so probably it may take
142:23 - some time and before that uh since it is
142:26 - probably installing what I will do I
142:28 - will also go ahead and create my EnV
142:31 - file right so in this ENB file what I'm
142:34 - actually going to do I'm going to put my
142:37 - open API key so quickly I'll create my
142:40 - open AP API key save it and start using
142:44 - it okay so this will basically be my
142:46 - open API key in the EnV so that I can
142:48 - basically load it so along with this
142:50 - python. EnV is also there so let's wait
142:53 - till the all the libraries has been
142:56 - installed okay so this is the initial
142:58 - steps that we should specifically do
143:00 - right our environment is ready we have
143:02 - installed all the libraries that is
143:03 - probably required we have also kept our
143:06 - open AI key because at the end of the
143:08 - day I'm specifically going to use Lang
143:09 - chin you can also do it with hugging
143:10 - face if you want but I will try it with
143:13 - open AI because the accuracy is pretty
143:15 - much better in this okay
143:17 - now the next step uh what I'm quickly
143:20 - going to do is that quickly create one
143:25 - file and here I will just show you test
143:29 - ipynb and this will basically be my
143:33 - ipynb file itself and here I'll be
143:35 - showing you the entire code later on you
143:37 - can probably convert this into an end
143:39 - to-end project you can probably create a
143:41 - streamlet app but here is the main thing
143:43 - that I'm probably going to show you by
143:45 - executing step by step and and what all
143:47 - things are specifically required to
143:48 - create this app again understand what I
143:51 - am planning to do right so I will just
143:54 - show you over here first of all let me
143:56 - just clean this screen and what is my
143:59 - entire agenda like what I really want to
144:01 - create as an llm application over here
144:04 - so I have a PDF okay I have a PDF so
144:08 - this is basically my PDF you can also
144:10 - say this is a data source it can be a GK
144:13 - book it can be a maths book it can be
144:15 - anything right I will will first of all
144:18 - load this document right once I load
144:22 - this document or read this
144:24 - document what I am going to do is that
144:26 - I'm going to convert this into chunks
144:29 - right because we cannot open AI hugging
144:31 - face models they have some restriction
144:33 - with respect to the Token size so I'm
144:36 - just probably going to create chunks and
144:38 - this is what we say it as text
144:42 - chunks right after this I'm going to use
144:45 - open AI embedding
144:48 - okay and this embeddings will be
144:51 - responsible in converting all this text
144:53 - CHS into
144:55 - vectors right so this will basically be
144:58 - my vectors I hope you know what exactly
145:00 - is vectors a numerical format for
145:02 - different different text right so this
145:05 - will specifically be my vectors and this
145:08 - I'm going to basically do with open
145:10 - embeddings further this vectors needs to
145:12 - be stored in some Vector search DB so
145:15 - here I will put all these vectors in
145:18 - some kind of vector surge DB now why
145:21 - this DB is required because at the end
145:23 - of the day whenever a human being
145:25 - queries any
145:26 - inputs
145:28 - right because of this Vector search DB
145:31 - here we can apply similarity
145:35 - search right and probably get any kind
145:39 - of info that I specifically want so this
145:41 - is my what my entire architecture of the
145:43 - specific project looks like right and
145:46 - here this Vector search DB I'm probably
145:48 - going to use something called as pine
145:50 - cone and they have lot of DBS I will
145:52 - talk about the advantage and
145:53 - disadvantage there is some amazing DBS
145:55 - called as data Stacks where they
145:57 - specifically use cassendra DB Pine clone
146:00 - is one right we'll see all the
146:02 - documentation page with respect to this
146:04 - okay so step by step I'm going to
146:06 - basically do this and you can actually
146:07 - do it for any number of pages one more
146:10 - thing that I'm probably going to install
146:12 - is IPI kernel since I'm going to work in
146:15 - my Jupiter notebook okay
146:17 - so this all steps are basically
146:18 - happening it is very much good and we
146:21 - are able to see this okay so let this
146:24 - installation happen and then I will set
146:26 - up my kernel okay so these are the
146:29 - initial steps that we really need to
146:31 - focus on and uh understand this project
146:34 - will be the base to create any kind of
146:36 - chatbot application mcqs quiz apps okay
146:40 - question answering chat Bots not only
146:43 - question answering chat Bots text
146:44 - summarizer anything that you probably
146:46 - want
146:47 - right or you can also basically say it
146:50 - as a chat B that gives you specific
146:51 - answer with respect to specific domain
146:53 - right with respect to the data that we
146:55 - have so all these things are done now
146:57 - I'm going to probably select the kernel
147:00 - V EnV python 3.0 right I'm going to save
147:03 - this perfect now the first step as usual
147:06 - I will go ahead and import start
147:09 - importing libraries and now we will do
147:11 - it completely step by step okay so what
147:15 - all things we basically require I'm
147:17 - going toire open a I'm going to import
147:21 - Lang
147:22 - chain uh apart from open and Lang chain
147:26 - what I'm going to also going to do go
147:27 - ahead with pine con I will talk about
147:30 - Pine con more when I probably show you
147:31 - the documentation apart from Pine con
147:34 - I'm going to basically go to Lang chain
147:37 - okay and I'm going to basically use
147:39 - something called as document
147:43 - loader document loaders will basically
147:45 - be responsible for for loading any kind
147:47 - of documents it can be a PDF file and
147:49 - all so for PDF we specifically use
147:52 - something called as P PDF I can also use
147:55 - directly Pi PDF loader but since my PDF
147:57 - is inside the directory I'm going to use
147:59 - Pi PDF directory loader okay so this is
148:02 - the next thing now from the next thing
148:05 - what we need to do is that as soon as we
148:06 - load any PDF we will get all the
148:08 - documents we have to basically do uh
148:11 - text splitting right because we really
148:13 - need to convert those into chunks we
148:15 - cannot take the entire token right there
148:17 - will be a restricted token size right
148:20 - like uh recently open has come up with
148:22 - the open 4. 4. o turbo right so I think
148:26 - it is GPD sorry GPD 4.0 turbo there 188
148:31 - 128k is the token size right so for that
148:34 - I'm going to basically use from Lang
148:36 - chain dot text spitter I'm going to
148:40 - probably import recursive character text
148:43 - spitter you can also use any other based
148:46 - on this right my always suggestion would
148:48 - be that go ahead and check out the
148:49 - documentation with respect to all the
148:51 - libraries that I'm probably uh uploading
148:54 - right now the next thing is that
148:55 - whenever I probably convert this into
148:58 - chunks right the next thing that I need
149:00 - to probably convert that into vectors
149:01 - and for that I'll be using some kind of
149:03 - embedding techniques so over here we are
149:06 - going to basically use do
149:09 - embeddings
149:11 - doop so it is embeddings do openai and
149:16 - we are going to import open AI embedding
149:18 - so open AI embeddings is a technique
149:20 - wherein it will probably convert any
149:22 - chunk into vectors right so this is the
149:25 - next step now the next step is basically
149:28 - also to uh import a library that will be
149:31 - responsible in creating a vector DB with
149:34 - respect to Pine call or we also say it
149:36 - as Vector store so here I'm going to
149:38 - basically use from Lang
149:41 - chain
149:43 - dot
149:45 - vector
149:48 - dot I think Lang chain dot it should be
149:51 - dot I'm writing comma I don't know why
149:54 - Vector oh spelling is mistaken do Vector
149:58 - stores okay and here I'm basically going
150:01 - to
150:02 - import I think it will be there pine
150:05 - cone right so I'm basically going to
150:07 - also use this pine cone pine cone will
150:09 - be our Vector store uh later on we can
150:12 - integrate this with our Vector DB that
150:14 - is present in Pines conone so
150:17 - the next thing is that I will also
150:18 - import our llm model because we will be
150:21 - requiring llm
150:23 - import open AI right so all these
150:27 - libraries I'm going to specifically use
150:29 - it I will quickly go ahead and execute
150:31 - it let's see if everything works fine
150:33 - you may get some kind of warning but
150:34 - it's okay right so this is your
150:38 - initial load that you are specifically
150:41 - doing now you know that I have an
150:42 - environment variables that is with
150:44 - respect to hugging pH so what I'm
150:45 - actually going to to do I'll go ahead
150:48 - and write from EnV
150:51 - import import load. EnV so this will
150:56 - specifically load all your environment
150:59 - variables okay so whatever environment
151:01 - variables that you have with respect to
151:02 - open API key or anything that is
151:04 - required you can basically do this right
151:07 - now I will also be importing OS over
151:09 - here right OS we can specifically use
151:11 - later on okay quickly now the first step
151:15 - as I said
151:17 - we need we have a PDF file we need to
151:20 - read it right so now I will write let's
151:24 - read the document okay now first step
151:29 - while reading the document I'll create a
151:30 - function so that I can reuse it and I'll
151:33 - write read Doc and here I will give my
151:35 - directory I can also give my file for
151:38 - that what library will be used Pi PDF
151:41 - loader right over here I'm using
151:43 - directory loader since I have to
151:44 - probably give my directory name and then
151:47 - I will basically write file _ loader and
151:50 - I will initialize my P PDF directory
151:52 - loader and basically give my directory
151:55 - path over here okay so directory path
151:59 - over here right so as soon as I give my
152:01 - directory path it will go to this
152:03 - specific directory and it will see
152:04 - whichever PDF is there it will start
152:06 - loading it okay and then I will go ahead
152:09 - and write file uncore loader dot load
152:14 - right now see why I'm showing you this
152:16 - step by step because everybody should
152:18 - understand what steps we are be doing it
152:20 - later on to convert this into a modular
152:22 - code it will be very much easy that is
152:24 - the reason I'm writing it in the form of
152:25 - functions all these functions will go
152:27 - into your utils.py file okay and finally
152:31 - you can see over here I'll get file
152:33 - loader _ load that basically means it is
152:35 - going to load all the documents and here
152:37 - I will basically be getting my documents
152:39 - right and finally we will return this
152:43 - documents done right now let's check
152:46 - check if everything is working fine so
152:48 - here I'm going to basically write read
152:51 - uncore Doc and this will basically be
152:53 - returning my document and here I will
152:57 - give my document folder so let me just
152:59 - go ahead and write
153:01 - documents in string right so this will
153:04 - basically be my directory
153:06 - path okay and now if I execute what is
153:09 - this doc it will probably read all the
153:12 - docs that are probably there now see
153:14 - every page by Page content this this is
153:16 - my first page second page third page
153:18 - fourth page fifth page like this I have
153:20 - 54 pages in my PDF right 54 Pages now if
153:24 - you also write length of Doc here also
153:26 - you'll be able to see it right so length
153:30 - of Doc I'm going to get 58 so that
153:32 - basically means we have done this first
153:34 - step right we have loaded we have read
153:37 - this particular PDF right now the next
153:39 - step is basically with respect to
153:42 - dividing these documents into text
153:43 - chunks okay so this is what we are
153:45 - probably going to do in our step two but
153:48 - till here everything is working
153:50 - fine so guys now we have finished
153:52 - reading the document uh now what we are
153:54 - basically going to do is that we are
153:56 - going to convert this into chunks right
153:59 - now for converting this into chunks what
154:02 - we are specifically going to do let's
154:04 - see so here I'm going to write the code
154:06 - here I'm going to basically say divide
154:08 - the
154:08 - docs into chunks and again because of
154:12 - the model restriction of the token size
154:14 - we really need to do this okay so here
154:16 - I'm going to basically use defin I'll
154:18 - create a function which is called as
154:20 - definition chunk data here first thing I
154:24 - will basically give my docs then I'm
154:27 - going to basically mention my chunk size
154:30 - right so let me go ahead and mention my
154:32 - chunk size my chunk size I'm going to
154:34 - mention it as 800 you can also mention
154:36 - it as 1,000 right don't keep a very huge
154:40 - value and then I can also say what about
154:43 - the chunk overlap Okay so so the chunk
154:46 - overlap like 50 characters can overlap
154:49 - with from one sentence to the other
154:50 - sentence right so here the next thing
154:53 - I'm going to basically create a text
154:55 - splitter and that is where we going to
154:57 - basically use this recursive character
155:00 - text splitter so first first thing first
155:02 - I going to mention my chunk size which
155:04 - will basically be my chunk size itself
155:08 - and along with this
155:10 - my chunk
155:12 - overlap which will be nothing but the
155:15 - chunk overlap that I have basically
155:17 - mentioned great uh so here I get my text
155:21 - splitter and now I'm going to basically
155:23 - up take this text splitter and split all
155:26 - the documents based on the kind of
155:29 - splitting that I've actually mentioned
155:31 - so here basically I'll provide my docs
155:33 - as my parameter and then I will convert
155:36 - this into and I'll return this docs
155:39 - perfect if you want to know more about
155:41 - this chunk uh recursive chunk splitter
155:43 - uh sorry recursive character splitter
155:46 - you can probably check this out
155:49 - documentation also I'm going to specify
155:51 - over here uh this documentation is good
155:53 - to understand what exactly it does and
155:55 - all right so perfect this is my chunk
155:59 - data function now what I'm actually
156:01 - going to do is that quickly use chunk
156:04 - uncore data and try it on my docs file
156:09 - right so here I'm going to basically
156:10 - mention my docs docs is this I've
156:14 - actually got this docs is equal to
156:18 - Doc okay and let's see so this will
156:22 - basically be my documents it is just
156:24 - going to apply all this right it is
156:26 - going to convert that entire document
156:27 - into a chunk size of 800 with the
156:29 - overlap of 50 okay and probably if I go
156:32 - and see my documents you'll be able to
156:34 - see it now see every document has now
156:37 - been properly mentioned right and the
156:40 - document that we are specifically
156:41 - reading is the Indian budget document
156:44 - right so any question that I proba asked
156:46 - related to Indian budget I'll be able to
156:48 - get the answer done this is good if I
156:52 - probably want to see the length of the
156:53 - documents also I can also see it okay
156:56 - just to give it get an idea like 58 is
156:58 - the length okay great so this is done uh
157:03 - now the next step what I'm actually
157:04 - going to do is that I'm going to also
157:06 - initialize my embedding technique so
157:09 - embedding technique of open AI right so
157:14 - we are going to initialize this so here
157:16 - I'm going to mention embeddings is equal
157:18 - to open Ai embeddings and here I'm going
157:22 - to use my API
157:24 - key OS do environment I can directly use
157:29 - os. environment and I can mention what
157:31 - is my API key so here I can say
157:35 - opencore open AI uncore API
157:41 - underscore key right so this is what is
157:44 - my embedding so let let me just
157:47 - quickly see what exactly is my
157:49 - embeddings so here is my embeddings that
157:51 - I'm going to probably use and this is
157:54 - what is basically used to convert that
157:56 - text into vectors right so quickly we
157:59 - have done this uh then I'm going to
158:01 - probably create my vectors let's say
158:03 - Let's test any vectors with this
158:05 - embeddings okay uh and there are various
158:07 - other embedding techniques like one h
158:09 - word to uh average word to and all but
158:12 - uh in open AI embeddings this provides
158:14 - you a much more advanced technique okay
158:17 - and over here also it will provide you
158:18 - some kind of vectors like there will be
158:20 - some Vector size also with respect to
158:22 - this okay like every every sentence will
158:25 - be provided with with respect to a
158:27 - vector size so here if I want to
158:29 - probably check and write embed
158:31 - underscore query and just test it with
158:34 - respect to anything like how are you
158:37 - right and let's see what kind of vectors
158:40 - we will probably get so this is my
158:42 - vectors that I'm actually getting see
158:44 - the entire text and if I want to
158:45 - probably check the length of these
158:47 - vectors it will also give you the length
158:49 - of this vectors okay so it is some
158:53 - something around 15 36 and this length
158:55 - will be super important because at the
158:56 - end of the day where I probably create
158:58 - my Vector database I have to specify
159:00 - this length okay for my problem
159:02 - statement now great now let's create our
159:06 - Vector search DB and pine code okay and
159:11 - now this step is very much important uh
159:13 - because after this particular step we
159:15 - will be able to see what kind of vector
159:17 - database we probably get okay Vector
159:19 - search DB in Pine con so let's go ahead
159:22 - and let's quickly create this Vector DB
159:24 - okay so guys here is the pine cone
159:27 - documentation you can probably check it
159:28 - out uh get started using pine con
159:30 - explore our examples this this is there
159:33 - what is the main important information
159:35 - about this Pine C is that it definitely
159:38 - helps you in semantic search in chat
159:40 - Bots also it helps you right where it
159:42 - probably helps you to store the entire
159:44 - Vector right and it provides you
159:46 - generative QA with open integration Lang
159:49 - CH leral
159:50 - argumentation uh rag also we basically
159:53 - say open integration and it has multiple
159:56 - uses okay so if I probably show you one
159:58 - of the document or guide right so if I
160:01 - probably go ahead and click on the guide
160:02 - right and this is where we really need
160:04 - to create the vector database I'll show
160:06 - you the steps of creating it right so
160:09 - Pine con makes it easy to provide
160:10 - long-term memory for high performance AI
160:12 - application it is managed Cloud native
160:14 - Vector database with a simple API no
160:16 - infrastructure has less pine cone serves
160:19 - fresh filtered query results with low
160:20 - hency at a scale of billions of vectors
160:23 - so if you have a huge data set you want
160:25 - to probably work with the vectors you
160:27 - can probably store it over here in the
160:28 - form of vector database um what is the
160:31 - importance Vector embedding provides
160:32 - long-term memory for AI Vector database
160:35 - stores and queries embedding quickly at
160:36 - a scale you know so anytime it is
160:38 - probably saved if you're quering it you
160:40 - will be able to get the response very
160:41 - much quickly now first thing first how
160:44 - you have to probably create this okay so
160:46 - if you once you log in once you log in
160:48 - over here or sign up you'll be able to
160:51 - see this okay so and here I've already
160:52 - created one index okay but this index
160:55 - will not work because see uh in the free
160:57 - tire right it allows you to just create
160:59 - one index so I will just delete this and
161:01 - show you how to probably create it
161:03 - completely from scratch so this is the
161:06 - name so I'm I'm going to delete this
161:08 - index because at the end of the day
161:10 - whatever vectors you are probably
161:11 - storing it will start indexing it okay
161:13 - so this is terminated now we will go
161:15 - ahead and create a new index so for
161:17 - creating a new index uh what I have to
161:19 - probably do is give a name so let's say
161:21 - I'm giving langin Vector now this is
161:23 - super important configure your index the
161:25 - dimensional metrix depends on a Model
161:26 - you select right now based on a Model if
161:29 - I probably uh see to it right so here
161:32 - you'll be able to see what is the length
161:34 - that I was able to get from my embedding
161:36 - 1536 so this is what is the dimension
161:39 - that I'm also going to give it over here
161:41 - and since I have basically doing cosine
161:43 - similarity kind of Stu or you can also
161:45 - do Dot product ukan but I'll stay to
161:47 - cosine similarity because at the end of
161:49 - the day the similarity search that is
161:50 - probably going to happen is with the
161:52 - help of cosine similarity and then
161:54 - finally we go ahead and create the index
161:56 - this is the main thing that you probably
161:58 - need to do this is basically getting
162:00 - terminated and this was the data that I
162:02 - had actually inserted but again we will
162:04 - do it okay so if I go to back to uh um
162:08 - back to probably a index let's see why
162:11 - it is not created or still it is showing
162:14 - terminating it should not not show
162:15 - terminating but at the end of the day
162:17 - because one I have already deleted it or
162:20 - I can just change the name if I want so
162:21 - but it is created over here okay Lang
162:23 - chin vector and it is a free Tire in the
162:26 - case of free tire they will provide you
162:28 - this thing right now from this there are
162:31 - some important information that you
162:32 - really need to retrieve one is the
162:34 - environment one is the database name
162:37 - okay so what sorry index name so I'll go
162:40 - back to my code here you'll be able to
162:43 - see Vector search DB and pine code let's
162:45 - let's initialize it I I've imported P
162:48 - cone I will say do in it okay so do in
162:51 - it basically does the initialization
162:53 - here two information are required API
162:56 - key okay API key with some information
163:00 - comma the next thing that I probably
163:02 - require is environment okay so
163:05 - environment something is required so
163:06 - let's retrieve this two information
163:09 - along with this what I can also do I
163:10 - have to also provide my index uncore
163:12 - name so here I will specifically say my
163:15 - IND Indore name index name I've already
163:17 - copied it from there so it is nothing
163:19 - but langin Vector let's go and see where
163:21 - is the API and environment so here I'm
163:24 - going to go back if I go and see there's
163:26 - an option of API keys so this is
163:28 - basically my API key I will copy it and
163:31 - I will paste it over here okay so Ive
163:34 - pasted my API key over here now the
163:36 - environment thing where will I get my
163:38 - environment so if I go to indexes and if
163:41 - I click this this is the environment
163:43 - that I'll be able to get it right so
163:45 - this two information is specifically
163:47 - required I will paste it over here right
163:50 - so this two information is done by
163:52 - executing it my Vector search DB will
163:54 - get initialized over there but at the
163:56 - end of the day I need to put all these
163:58 - embeddings specifically all these
164:00 - embeddings uh in my Vector DB right so
164:03 - over there I will again use pine cone
164:06 - pine cone which I have actually
164:07 - initialized and I'll say from
164:11 - documents and here I will give all my
164:14 - Docs so from documents I'm going to
164:16 - first of all give my doc parameter over
164:18 - here the dock which where which I need
164:20 - to probably store it in my Vector DB and
164:22 - then I will go ahead and write
164:23 - embeddings embeddings what kind of
164:25 - embeddings that I'm specifically giving
164:27 - is the same embeddings that we probably
164:29 - created and then I have my index name is
164:32 - equal to whatever index name I have
164:34 - basically initialized so as soon as I
164:36 - probably execute this you will be able
164:38 - to see that I will be able to get one
164:40 - index over here okay so let me just go
164:43 - ahead and execute it it'll probably take
164:45 - some amount of time because I have a
164:46 - huge data over there but you'll be able
164:49 - to see the changes once I probably go
164:51 - over here okay so if I go ahead and
164:54 - click it and if I refresh
164:58 - it let's see okay whether we'll be able
165:02 - to see everything or not whether the
165:05 - data part and all we will be able to see
165:07 - so here you can probably see query by
165:09 - vector and all all the data is there if
165:12 - I want to probably see the vector count
165:14 - it is 58 because the document size that
165:15 - you could probably see is 58 right and
165:19 - these are all the information you can
165:20 - see over here all the data has been
165:23 - basically stored and based on the
165:24 - metadata you can probably see it it has
165:26 - already done the indexing now any query
165:29 - that you probably hit it over here in
165:30 - the form of vectors you'll be able to
165:32 - get those specific response okay now to
165:35 - do the query part what I will do I will
165:37 - apply a cosine similarity so I will say
165:40 - cosine
165:42 - similarity retrieve results okay so I
165:45 - will try to retrieve the results over
165:47 - here so here let me just go ahead and
165:50 - write definition retrieve uncope
165:55 - query and here I will say query K is
165:58 - equal to 1 let's say k is equal to 2 I I
166:00 - will probably see the top two query now
166:03 - the second thing is that if I want to
166:05 - probably query I will get the matching
166:07 - results whatever matching results I'll
166:08 - use the same index dot whatever index is
166:11 - over here dot similarity
166:15 - let's see index
166:19 - dot
166:21 - similarity unor search right the
166:24 - similarity _ search what I can do is
166:28 - that let's see what function I've
166:31 - actually made for similarity _ search
166:35 - because I need to probably get those
166:36 - documents also right so basically uh I
166:41 - need to also create one more function
166:42 - over here right and that function will
166:44 - basically be my similarity underscore
166:46 - search that basically means what is my
166:49 - result that I'm probably going to get
166:51 - right inside this so index. similarity
166:54 - unders search is a function that is
166:57 - probably present inside this index
166:59 - itself right so similarity unders search
167:02 - and here I will probably give my query
167:05 - comma K is equal to some K value okay so
167:07 - what is the k k is equal to 2 whatever
167:08 - results I'm specifically getting and
167:11 - here I'm going to return my math
167:15 - matching results okay matching results
167:19 - so once I execute it so this is
167:21 - basically my retrieve query uh example
167:24 - so any query that I specifically give
167:27 - with respect to that particular PDF I'll
167:29 - be able to get the answer now this is
167:31 - fine this is the function to get the
167:34 - data from the database itself right so
167:36 - cosine similarity retrieve results from
167:38 - Vector DB I'll write it over here so
167:40 - that you will be able to understand okay
167:43 - so done this is the function that is
167:44 - basic Bally required now two important
167:46 - libraries that I'm going to probably use
167:48 - one is from langen Lang chin. change.
167:51 - question answering I'm using load
167:53 - question answering chain and along with
167:55 - this I'm also going to use open AI open
167:58 - AI will specifically be used to create
168:00 - my model and here my llm model will be
168:03 - created with the help of this so here I
168:04 - have written open a model name will be
168:06 - tax uh text Dy uh 003 and I've taken the
168:09 - temperature value as uh this one and
168:12 - then I'm also going to create my chain
168:14 - where I specific ially use this load QA
168:16 - chain and load Q chain actually helps
168:18 - you to create a question answer
168:20 - application and then here I will go
168:22 - ahead and write chain type is equal to
168:25 - stuff okay so my chain is ready my llm
168:28 - is ready everything is ready now all I
168:31 - need to do is that retrieve my queries
168:33 - right for retrieving the queries I will
168:36 - specifically be using this retrieve
168:37 - query function also so let's go ahead
168:40 - and write my definition I will go search
168:43 - answers from
168:46 - uh Vector database Vector DB okay and
168:50 - here I will basically
168:51 - write definition retrieve answers and
168:55 - whatever query I specifically give over
168:57 - here based on that I will should be able
168:59 - to get it right so if I probably see doc
169:02 - search then I will write doc search is
169:05 - equal to I'll call that same function
169:06 - retrieve query with my query that I'm
169:09 - actually going to give and then I will
169:11 - also print my doc search okay whatever
169:16 - print I'm basically getting now whenever
169:18 - I get that specific doc search I should
169:21 - also run this chain chain that I've
169:23 - actually created right to load QA chain
169:25 - so here I'm going to basically say
169:27 - chain. run and inside this what will
169:30 - basically be my input documents so I
169:32 - will say
169:37 - input input documents is equal to I will
169:41 - give my doc search right the document
169:44 - that I'm probably going to search and
169:45 - then the next will be my question which
169:47 - will be in the form of query right the
169:49 - query that I'm actually getting so once
169:51 - I do this my chain will basically be
169:53 - running and it will provide you some
169:54 - kind of response that it probably
169:57 - gets gets from the vector DB okay if it
170:01 - matches right and then we are going to
170:04 - return this specific
170:06 - response done now see the magic okay
170:10 - once I probably call this function what
170:11 - will happen so here I will write our
170:14 - query okay so the query will be I I saw
170:18 - something right I I basically so this
170:21 - will basically be my retrieve answer
170:23 - okay now see this I read the PDF I could
170:26 - find one question over there how much
170:28 - the agriculture Target will be increased
170:30 - by how many cores right how much the
170:33 - agriculture Target will be increased by
170:35 - how many cores I have just written this
170:36 - kind of statement now this retrieve
170:38 - query as soon as we call it will
170:40 - basically sorry retrieve answer as soon
170:42 - as we call okay so here I'll just make
170:44 - make this function change also the
170:46 - spelling should be right right
170:49 - retrieve and here also I'm going to
170:52 - probably make this to retrieve answers
170:55 - okay now as soon as I give my query over
170:57 - here it'll go to retrieve query it'll
170:59 - see from the index right it'll probably
171:02 - do the similarity search it'll give you
171:03 - the two results itself so let me just go
171:05 - ahead and see the answer over here now
171:09 - retrieve answer is not defined why okay
171:11 - I have to execute this sorry now it
171:13 - should be able to get the answer see so
171:17 - agriculture credit Target will be
171:18 - increased to 20 lakh CR with an
171:20 - investment of so and so information I
171:22 - I've just put right
171:26 - uh I can also write any other question
171:29 - how is the agriculture
171:32 - doing
171:34 - right so I may get some kind of question
171:37 - answer if it is not able to get
171:38 - something then it will say I don't know
171:40 - okay the government is promoting
171:41 - corporate based this this this this I'm
171:43 - getting that information from the entire
171:46 - PDF itself right so this is how
171:48 - beautifully you can probably get this
171:49 - and now it is probably asking being
171:51 - acting as a question answer application
171:54 - right now see this is what is the base
171:58 - you have a vector DB you're asking any
172:00 - question and you're getting some kind of
172:02 - response now on top of that you can also
172:04 - do a lot of prompt templating you can
172:06 - probably convert this into a quiz app
172:08 - you can convert it into a question
172:10 - answer uh chatbot you can convert this
172:12 - into a text summarizer you can do what
172:14 - whatever things you want right and this
172:17 - is what is the specific power over here
172:19 - right and this is really really good and
172:22 - that is what I'm probably going to show
172:23 - you in the next video on top of it like
172:26 - how can I probably do a custom prompt
172:29 - templating on my llm application this is
172:32 - what I'm probably going to show you in
172:33 - the next video but here i' shown you
172:36 - about what is Vector database and why it
172:39 - is very much important what exactly how
172:42 - the vectors are basically stored and
172:43 - here you can probably see see this is
172:45 - how your vector is stored if I probably
172:47 - search for any Vector over here I'll be
172:49 - able to get those kind of response over
172:50 - here right based on that uh search
172:53 - itself so start using this many
172:55 - companies are basically using this at
172:56 - the end of the day just for your
172:58 - practice sake it is completely for free
173:00 - right but if you have if you want more
173:01 - than one indexes two indexes then at
173:03 - that point of time you can probably take
173:05 - a paid tool paid version that
173:07 - specifically requires in a company
173:08 - itself so I hope you are able to
173:11 - understand this Amazing
173:12 - Project hello all my name is rush nyak
173:15 - and welcome to my YouTube channel so
173:17 - guys just a few days to end this
173:19 - specific year this month was amazing
173:23 - because I was able to upload many many
173:25 - videos related to generative AI many
173:28 - people had actually requested it uh the
173:30 - reason is very simple because all the
173:32 - students who have made successful career
173:34 - transition into the data science
173:36 - Industry they're working in different
173:38 - different llm projects so I hope you're
173:40 - liking all those videos that I'm
173:42 - specifically uploading um
173:45 - again as requested if you like this
173:47 - particular videos and all please do make
173:49 - sure that you subscribe the channel
173:50 - press the Bell notification icon hit
173:52 - like this will motivate me to upload
173:55 - more videos as we go ahead so it is a
173:58 - sincere request please do that and share
174:00 - with many people as uh many people as
174:03 - possible by you the reason is that all
174:05 - these videos is completely for free uh
174:08 - my main aim is basically to teach you in
174:10 - such a way that where you understand
174:12 - each and everything in depth Let It Be
174:14 - theoretical intuition practical
174:15 - intuition and many more right so what
174:17 - are we discussing in this specific video
174:19 - so I hope everybody has heard about um
174:24 - gini right gini API that was probably
174:26 - gini model that was launched from Google
174:29 - obviously the demo that they had
174:31 - actually shown on the website it was not
174:32 - true demo they had made made up that
174:35 - particular demo but now the gini pro
174:38 - model is available for you and you can
174:40 - also use it for your own demo purpose uh
174:43 - we'll understand we'll see a complete
174:44 - demo like how these models are these
174:46 - large language models are and how it is
174:49 - probably performing we'll be seeing
174:51 - various codes I'll be showing you that
174:53 - how you can probably create an API for
174:55 - this and the best thing is that with
174:57 - respect to this they have come up with
174:59 - this two different plan you know one is
175:01 - free for
175:03 - everyone the thing the model the gini
175:06 - pro model which is free for everyone it
175:08 - has a rate limit of 60 queries per
175:10 - minute that basically means within a
175:12 - minute you can actually just hit 60
175:14 - queries price is free Price output is
175:17 - also free input output is free and you
175:19 - can start using this uh to just get to
175:22 - know like how powerful the gini pro is
175:25 - and I probably used it it looks pretty
175:27 - much good you know um at least uh not
175:31 - like that fancy thing what it showed in
175:33 - the demo not like that but yes we can
175:35 - compare with chat GPT or we can compare
175:38 - with open AI apis which perform various
175:41 - tasks like test summarization uh text
175:44 - classification or let's say other tasks
175:47 - like Q&A and many more right so the next
175:50 - uh plan that is probably go uh that is
175:52 - going to come which can be specifically
175:53 - used in industries that is pay as you go
175:56 - and that basically starts for more than
175:58 - 60 queries per minute okay so here is is
176:01 - the entire information I will be
176:02 - providing the link with respect to the
176:04 - description in the description of this
176:05 - particular video now let's go ahead and
176:07 - check the documentation and one by one I
176:09 - will show you how you can probably
176:10 - create the API the API Keys how you can
176:13 - probably load it and start using it okay
176:16 - so first of all just go to the python
176:18 - section over here and I'm just going to
176:20 - click on this Google collapse so as soon
176:22 - as I probably clicked on this Google
176:23 - collap you can probably see over here
176:25 - I've got this entirely okay so we will
176:28 - go ahead step by step we'll understand
176:30 - each and every line of code we'll see
176:31 - multiple examples and then let's see how
176:35 - good the Gemini API is okay so as
176:38 - suggested as I told you already this is
176:40 - like Gemini has come up in three
176:42 - different version and gini Pro is right
176:44 - now available for you okay where you can
176:46 - probably try and uh just by seeing this
176:49 - things right I I definitely I've already
176:51 - tried it out I feel that yes it is good
176:54 - enough right um if I compare with any
176:57 - openai apis yes it is doing a fabulous
177:00 - task okay I know the demo was bad but
177:03 - here the things that I'm going to
177:04 - execute is very much good so to get this
177:07 - particular notebook file all you have to
177:09 - do is that click on python over here and
177:11 - just click on this okay so this is the
177:13 - entire information
177:14 - how you can probably create the API key
177:16 - and all I will be showing you step by
177:17 - step okay so let's start this video
177:20 - before that please do hit like as you
177:22 - know that I uh I I always thought that
177:25 - within this year right I may reach 10
177:27 - lakh subscribers but I could not but
177:29 - it's okay for the next upcoming 3 to
177:31 - four months I would definitely like to
177:34 - reach 10 lakh subscribers okay 10 lakh
177:37 - subscribers 10 lakh is a very good
177:39 - number right and just imagine how much
177:41 - beneficial it is for so many people out
177:43 - there so so let's go ahead and start
177:45 - this okay so we will go step by step I
177:48 - know please try to understand this
177:50 - things because I will be explaining you
177:52 - the code what exactly gini API is all
177:56 - about what this gini model why it is so
177:58 - good because this is a multi model right
178:01 - multimodel that basically means it is
178:02 - trained on both text and images so I'll
178:05 - show you if I probably give a image and
178:07 - it will be able to read that image and
178:08 - it'll be able to give you the
178:10 - information about that image that
178:11 - powerful the specific model is okay so
178:14 - uh we'll set up our development
178:15 - environment and get the API access to
178:17 - gini so this is the entire agenda we
178:19 - will generate text response from text
178:21 - inputs we will generate text responsive
178:24 - for multimodel inputs and then we'll use
178:26 - gmin for multi- turn
178:28 - conversation and we'll also see how
178:30 - different embeddings can be applied for
178:32 - large language model okay so first of
178:35 - all this generative AI entire there is a
178:39 - library which is called as Google
178:40 - generative AI with the help of API you
178:42 - can use various features that is
178:44 - available in this gini model right gini
178:46 - pro model so first of all I will go
178:47 - ahead and install this entire library
178:50 - that is Google generative AI okay with
178:52 - the help of the specific code it may
178:54 - take some time again it depends on your
178:55 - internet speed how good it is uh and
178:58 - then after we probably go ahead and
179:00 - install this so import the specific
179:02 - library now here are some of the
179:05 - important things that we are going to do
179:07 - okay so first of all you'll be able to
179:09 - see we are importing path lib text WP
179:11 - Google generative AI as geni so this is
179:14 - the allias that we are going to
179:16 - specifically use and this is the library
179:18 - that has almost all the features over
179:19 - there from google. collab you import
179:22 - user data inside user data you can store
179:25 - your API key okay I will show you how to
179:27 - how you can probably do it along with
179:29 - this I'm probably importing display and
179:31 - markdown to display the information and
179:34 - there is another method which is called
179:36 - as definition to underscore markdown
179:38 - that basically means whenever I get any
179:40 - kind of response I'm going to replace
179:42 - this dot by star because I think this
179:45 - generative a is gini pro gives some kind
179:47 - of response where it will be having this
179:49 - kind of output okay and then we are
179:52 - going to convert that entire data with
179:53 - respect to markdown okay so all these
179:55 - things we are specifically importing now
179:58 - let's go to our next step setting up
180:00 - your API key so for do doing that just
180:03 - click on this particular link okay so it
180:05 - will go to this makers suit google.com
180:08 - app API key you can also create Palm
180:10 - apis from here and all right so after
180:12 - going over here what you can do you can
180:14 - actually go ahead I've already created
180:16 - one particular API key over here which
180:19 - you can actually see if you want to
180:21 - create a new API key just go ahead and
180:23 - click on this as soon as you click on
180:25 - this you will be getting the API key
180:26 - just copy from there and here what I
180:29 - have done I have written the API key
180:30 - over here okay so don't worry that uh
180:32 - this API key is not right uh I've
180:35 - already executed or I've already stored
180:38 - that particular API key itself right so
180:40 - probably when I share this particular
180:42 - notebook with you you'll not be able to
180:44 - see this API key over there until then I
180:46 - may have also deleted it from here okay
180:49 - so the reason don't use this do it with
180:51 - your own because it is completely for
180:53 - free right 60 queries you can actually
180:55 - hit
180:56 - it now let's go ahead and do one thing
180:59 - first of all I'm creating an environment
181:01 - variable called as Google API key okay
181:06 - so this will basically be my API key
181:08 - okay and I will remove this I will not
181:11 - require this and then what I'm doing
181:13 - over here I'm I'm saying gen. configure
181:16 - API key and I'm using the environment
181:18 - variable and I'm setting that API key to
181:20 - this okay so once I do this done that
181:23 - basically mean my API is configured this
181:25 - is the simple steps that you
181:27 - specifically need to do now what all
181:30 - models you specifically get from Gemini
181:33 - API so over here there are two models
181:36 - one is Gemini Pro this is optimized for
181:38 - text only prompts so text summarization
181:41 - Q&A chat anything that you specific Al
181:43 - want to do you have to use this specific
181:47 - model that is Gemini Pro and then you
181:50 - have one more model which is called as
181:51 - gini provision this is optimized for
181:54 - text and image prompts okay so for text
181:58 - and image prompts specifically you can
182:00 - use gini pro version if you want to
182:02 - check how many different models are
182:04 - there just write for M gen. list uncore
182:08 - model list underscore models will give
182:09 - you all the models that it is basically
182:12 - having and it is saying that if
182:13 - generated content in M supported
182:15 - generation methods then it will show you
182:17 - all the both the model name so here you
182:20 - can probably see that as soon as you
182:22 - execute this you'll be getting that you
182:24 - have two models one is gini pro and then
182:26 - the other one is Gemini Pro Vision now
182:29 - let's go ahead and let's try something
182:31 - okay so first of all I'm going to use
182:35 - the gemin pro model this is specifically
182:37 - for text related task okay so here I'm
182:41 - going to use generative AI gen AI
182:44 - dot there is a method which is called as
182:46 - generative model and there I'll be
182:48 - giving my model name so once I execute
182:50 - this this basically becomes my model so
182:52 - if I probably go ahead and execute over
182:55 - here so here you'll be able to see that
182:58 - I am getting a model trust me guys this
183:00 - is good enough because if you don't have
183:02 - open API key also you can use this and
183:06 - when you use this you'll be able to
183:08 - understand more about the llm models
183:10 - okay so now let's go ahead and use one
183:14 - method which is called as generate
183:15 - content this generate content method can
183:18 - handle a variety of use cases including
183:20 - multi multi-t chat multimodel input
183:24 - depending on what the under underlying
183:26 - model supports so here I've used gin Pro
183:29 - so in this particular case I am going to
183:32 - specifically use it for text related
183:34 - task okay so now here we use model dot
183:37 - generate content and here I'm giving the
183:40 - message what is the meaning of life okay
183:43 - so this is the default message once I
183:45 - execute this you see the response time
183:47 - the response time with respect to this
183:49 - particular time it will go ahead and
183:51 - capture so uh and also remember guys uh
183:55 - when I was executing some some some time
183:58 - before you know this was really really
184:00 - fast right now it is a little bit slow
184:03 - is it a problem internet connection I
184:04 - don't know okay so but here you can see
184:06 - user time it tooks 120 millisecond
184:09 - system time was 10.5 millisecond total
184:11 - time was 131 seconds which is very good
184:15 - like open AI API speed I think it'll
184:18 - take more than this okay that I
184:19 - specifically know now in order to see
184:22 - the response I will use this 2core
184:24 - markdown and we will write response.
184:26 - text as soon as I write this you will
184:28 - now be able to see the output of this
184:32 - right what is the meaning of life so
184:33 - here you can see that the meaning of
184:35 - life is a philosophical question that
184:37 - has been posed by human for centuries so
184:40 - and so blah blah blah blah all the
184:43 - information is very much easily given
184:45 - and it looks good you did not have to do
184:48 - any other prompt template techniques to
184:51 - probably put it in this dotted point it
184:53 - has considered in a better way yes you
184:55 - can again use prom template also for
184:57 - this purpose okay so if the API and now
185:01 - this is the most important thing which I
185:03 - like about gini Pro okay if the API
185:06 - failed to return a result use generate
185:08 - content response. prompt feedback now
185:11 - you may be thinking why the API May Fail
185:14 - it may be because of some of the other
185:15 - reason to see it was blocked due to
185:18 - safety concerns okay because of safety
185:19 - concerns also it may not give you some
185:22 - response now what may be that safety
185:25 - concern okay so first of all we will go
185:28 - and see response. prompt feedback when I
185:31 - probably execute this I also have these
185:33 - all features that are probably coming up
185:35 - this information in the response safety
185:38 - rating category harm category sexually
185:41 - explicit probability neg eligible so you
185:44 - can see it is categorizing based on this
185:47 - four important categories whether it is
185:49 - a hate speech whether it is a harassment
185:52 - whether it is a dangerous content right
185:56 - and here you can probably see that it is
185:58 - also giving that particular feedback if
186:00 - any of the feedback is positive I think
186:02 - you may not get a response so let's go
186:05 - ahead and execute this particular code
186:07 - and let's see whether this works true or
186:10 - not okay I definitely want to check it
186:12 - out so I will go ahead and execute and I
186:15 - will say um I will say Okay I I did not
186:19 - I do not mean anything to write anything
186:22 - bad over here but uh I would just like
186:24 - to see how to insult someone let's
186:30 - see okay I'm just trying I'm not I I'm I
186:34 - don't mean to but let's see so here
186:38 - you'll be able to see that whether I'll
186:39 - be able to get a response or not and
186:42 - again over here now now it has becomes
186:44 - fast right so now let's go ahead and do
186:48 - this see the response part quicker ex
186:51 - only works for a single C but none were
186:53 - returned now I will go ahead and check
186:56 - this prompt feedback now this is where
186:59 - block reason safety see over here harm
187:02 - category harassment medium so this is
187:05 - what is so good in this ethics is
187:09 - definitely there right so it is not
187:11 - giving you any kind of resp resp right
187:14 - so I hope you have understood the
187:16 - importance of this okay now similarly G
187:20 - gini can also generate multiple possible
187:22 - responses for a single prompt okay it
187:24 - can also generate right so for that you
187:27 - just need to use this responses.
187:30 - candidates now what I will do I will not
187:32 - execute this but instead we will go
187:34 - ahead and execute this what is the
187:37 - meaning of life okay okay so let's
187:40 - execute this it's
187:42 - okay um or I I'll just go ahead and ask
187:46 - a different question can you let me
187:50 - know about
187:53 - the future
187:58 - of future
188:02 - of generative AI okay so I'm asking this
188:07 - specific question now let's see I'm not
188:10 - executing this now it should definitely
188:12 - give me some kind of
188:14 - response and this also depends on the
188:17 - kind of like amount of tokens that is
188:18 - probably coming from the llm model so
188:21 - here it has taken 122 milliseconds now
188:24 - let's see the prompt feedback I think
188:26 - this is absolutely fine okay and here I
188:30 - will also go ahead and see my text it'll
188:33 - give so here you can see the future of
188:34 - generative AI holds immense potential
188:36 - and Promises to revolutionize various
188:39 - style Gan gpt3 this this is there now if
188:42 - I go ahead and right response.
188:45 - candidates okay now here you can
188:47 - probably see that I'm getting the entire
188:49 - info this is so nice see so this is my
188:53 - first text right role model find this
188:55 - this this all the information is there
188:57 - with respect to all the information that
188:59 - you will be able to see that right all
189:01 - whatever thing we executed step by step
189:03 - we getting everything okay so this is
189:07 - very very good okay now by default the
189:10 - model returns a response after
189:11 - completing the entire generation process
189:13 - you can also stream the response as it
189:15 - is being generated and the model will
189:17 - return chunks of the response as soon as
189:18 - they are generated which is absolutely
189:21 - amazing again right so what we can also
189:24 - do is that you can stream the response
189:26 - okay no need to wait for the entire
189:27 - response so let's see okay so here I
189:30 - will use the same question let me see so
189:33 - I will so can you let me know the future
189:36 - of generative now I think for this it
189:39 - will not take much time when compared to
189:42 - the previous one one that we had done
189:43 - right so here I will go ahead and write
189:46 - all you have to do is that just write
189:48 - over here let me just
189:51 - show okay you just need to add a
189:54 - parameter which is called as stream is
189:56 - equal to True by that you'll be able to
189:58 - get uh the response as it is being
190:01 - generated so let me just go ahead and
190:03 - execute this okay now I'm not going to
190:07 - directly print response. text but I'm
190:10 - saying that for every Chunk in response
190:13 - print chunk. test text okay and then it
190:16 - will show
190:17 - 80 like dotted lines okay so we can also
190:20 - display this in this way so here you can
190:23 - probably see how fast it was able to
190:25 - chunk by chunk obviously when chunk by
190:27 - chunk is getting displayed it will be
190:29 - very very good right so here you can
190:31 - probably see all the information ethical
190:34 - this needed for skill Force long-term
190:36 - impact on society and all now one more
190:39 - thing is that when streaming some
190:41 - response attributes are not available
190:43 - until you have iterated through all the
190:45 - response CH this is demonstrated below
190:48 - so here if I say what is the meaning of
190:50 - life with streaming is equal to true now
190:54 - you'll be able to see
190:56 - that let's see let's see okay so once
190:58 - this gets executed now I have this
191:00 - response. prompt feedback in prompt
191:03 - feedback you'll be understanding whether
191:05 - it has some problems or not with respect
191:07 - to that thing now if I directly go ahead
191:09 - and write response.
191:11 - text okay
191:13 - it will automatically tell me please let
191:15 - the response complete iteration before
191:17 - accessing the final cumulated attribute
191:19 - okay so this is a very good problem
191:22 - statement and now based on your
191:24 - requirements what I feel when compared
191:26 - to open AI still Gemini uh API that we
191:30 - have right it may have more
191:32 - functionalities as we go ahead but till
191:34 - now it really looks promising it looks
191:36 - really good okay now we will try to
191:40 - generate and text from image and text
191:42 - text inputs okay so this is also good
191:45 - now let's download this image so by
191:46 - using a curl operation I am probably
191:49 - downloading the image if you see the
191:50 - image the image looks something like
191:53 - this okay or I may also use some more
191:56 - image right I will write cat playing
192:00 - image okay so cat playing image so here
192:03 - you will be able to see some images
192:05 - let's see let's see let's see let's see
192:09 - this looks like a complicated image I
192:11 - guess it should find some problem okay
192:14 - uh downloads okay downloads downloads
192:18 - here I will
192:20 - say upload that specific image
192:25 - okay I will save it let's rename this
192:29 - image I will say cat. jpj now if I
192:33 - execute this over here I will write cat.
192:36 - jpj
192:39 - okay now this is the image it looks
192:42 - something like this now what I'm going
192:44 - to do I'm going to give this image to my
192:47 - Gemini Pro Vision model and then we will
192:50 - see what it can understand from this
192:53 - image like if it is if I say that the
192:55 - Kay is playing with some cotton fur or
192:58 - Hol right this cotton holes now let's
193:01 - see what answer gini Pro Vision gives
193:03 - right so first of all we will go ahead
193:05 - and load gini provision okay and then we
193:10 - will go ahead and generate model.
193:11 - generate content image and then we'll
193:14 - say to markdown response. text okay so
193:18 - let's go and see the
193:19 - answer so it is going to take that image
193:22 - here directly we are giving the image
193:24 - now it is going to understand the
193:25 - specific image it is going to read and
193:27 - it's is going to understand it is going
193:29 - to give me a response in text okay now
193:33 - let's
193:35 - see so this looks amazing till here but
193:39 - let's see the response I really want to
193:40 - see the response of this and it is
193:42 - taking some amount of time I think when
193:44 - we go with respect to the paid API it
193:47 - will be little bit less but again it
193:49 - depends on the image size how we are
193:52 - specifically calling it and all right
193:54 - let's see I think as we go ahead the
193:56 - correct answer is play right so here you
194:00 - can probably see if I go ahead and see
194:03 - this image right it shows play now it
194:06 - was not that well but let's see the
194:08 - previous one okay so let's see the
194:11 - previous one over here okay I think with
194:14 - just play it is showing I think I'm not
194:17 - satisfied with that specific answer but
194:20 - we can also try with the previous one so
194:22 - let's say this is the image and then we
194:25 - will go ahead and execute this let's see
194:27 - what kind of response it gives us so
194:30 - here you have some tiffen box you have
194:32 - broccolis you have some food item right
194:35 - so let's see till then I will download
194:37 - some more images Okay
194:41 - um
194:45 - let's see let's take this image
194:48 - also images. jpj I will go ahead and
194:54 - upload it over
194:57 - here okay I just want to see the answer
195:01 - like what all different kind of answers
195:03 - we specifically get yes uh right now for
195:07 - this image to text I think we are taking
195:09 - some time but I don't know like in the
195:12 - future future it may have a good
195:15 - response time when compared to right now
195:17 - but here definitely some amount of time
195:20 - is basically happening right
195:23 - or these are meal prepared containers
195:26 - with chicken BR brown rice broccoli and
195:29 - Bell papers this also looks good so it
195:31 - is able to give minute details over here
195:35 - this is really good okay now I will go
195:38 - ahead and write play images. jpg
195:43 - let's
195:45 - see so this is the image I think this
195:48 - image is small so it should be able to
195:50 - give it should be able to check the
195:52 - image and generate some kind of text
195:54 - let's
195:56 - see it was an error post intern please
196:00 - try a report okay some some kind of
196:02 - error is basically coming up
196:05 - okay let's see I I think it was a
196:07 - timeout issue or I don't know but I
196:11 - think now we should be able to see the
196:13 - answer okay it is giving in some Chinese
196:18 - text okay so this I think works with
196:22 - some
196:23 - other other kind of images itself or
196:27 - where you have a detailed image but
196:29 - definitely some of the use cases is
196:31 - failing over here okay so I feel that it
196:35 - is failing over here okay now let's try
196:37 - this one okay so there is one more
196:39 - option I don't know like with respect to
196:41 - image do we have to give only this kind
196:44 - of images if I'm giving cat images
196:45 - playing cat playing
196:47 - images I don't know what kind of
196:49 - response that we are getting or do we
196:51 - have some options to probably change it
196:52 - we'll have a look okay now the next
196:54 - thing is that to provide both text and
196:56 - images in a prompt I'm saying that right
196:58 - a shot engaging blog post based on this
197:01 - picture it should include description
197:02 - this this I think for this uh it should
197:05 - be able to give right it should be able
197:08 - to give I think that is the reason it
197:09 - was not giving that well so now let's
197:12 - see I will go ahead and write cat. jpg I
197:15 - hope it was cat.jpg only okay so yes
197:18 - this was CAD
197:20 - jpg uh can you include the description
197:25 - of the
197:26 - photo of the
197:32 - of okay uh let's see can you write a
197:36 - short blog based on this picture okay it
197:40 - should includ a description of the
197:43 - photo okay now let's see how what kind
197:45 - of response we specifically get and here
197:48 - the second parameter I'm giving it as
197:49 - image and that is how we are going to
197:51 - probably get it and uh to provide both
197:54 - text and image pass a list containing
197:57 - the strings and the image so this is my
197:58 - string the first thing that I'm giving
198:00 - this along with this image so I'm saying
198:02 - that write a short engaging blog post
198:05 - based on this picture okay so now let's
198:07 - see what kind of response we will
198:09 - specifically get okay and quickly let's
198:13 - see but I did not find a good output
198:16 - something like this so here it says like
198:19 - that only right is designed to handle
198:22 - multimodel prompts and return a text
198:23 - output okay perfect so yes uh this is
198:27 - there now let's convert this into
198:32 - text the adorable Ginger kitten is
198:34 - having a blast playing with a colorful
198:36 - cat toy the kitten is batting at the toy
198:39 - with a spa this looks good right I'm
198:42 - really
198:43 - impressed by seeing the image it is
198:46 - providing you all the information okay
198:49 - now let's see one more okay
198:51 - sparton image I don't know let's see
198:55 - sparton group
199:00 - image I will put this image let's see it
199:02 - looks good I like this image
199:07 - spans jpg okay so I put this image let's
199:11 - upload this and let's see whether it'll
199:13 - be able to provide the description or
199:17 - not first is observing what all things
199:20 - are there in the image I think that is
199:22 - what gini provision actually gives you
199:24 - okay so here I will say
199:29 - Spartans do
199:31 - jpg not directory why spotten it is
199:35 - spotten spotten Spartan okay Spartan so
199:39 - this is my image which
199:41 - looks oops oops oops oops what is the
199:44 - error now
199:46 - Spartan okay it is
199:50 - jpeg okay so uh I'm getting this
199:54 - specific image of Spartan right now and
199:57 - let's see how it looks like so this is
199:59 - the entire image right now let me just
200:03 - go ahead and give this image over
200:06 - here okay I'm saying it to generate the
200:09 - content model. generate content let's
200:11 - see and I'm saying write a short
200:13 - engaging blog post based on this picture
200:15 - it should include a description of the
200:17 - photo okay so it is what I feel is that
200:21 - that Vision it was not able to just
200:25 - recognize everything but the text
200:27 - information that we getting over here
200:28 - it's good in this epic scene from the
200:30 - movie 300 Leon is the king of spot okay
200:33 - it is able to understand from the movies
200:36 - also completely right which is
200:38 - absolutely very very good okay so I hope
200:41 - you like this this particular video guys
200:43 - please go ahead and try it out and there
200:44 - is one more assignment that I really
200:46 - want to give in this go ahead and try
200:49 - there is something called as chat
200:51 - conversation so there are a couple of
200:53 - very simple by using Gemini Pro you can
200:56 - actually do it just go ahead and try
200:58 - this you just need to execute by
200:59 - appending this in the history all the
201:01 - information is given over here okay but
201:04 - yes I feel Gemini Gemini Pro looks
201:09 - promising and uh yeah it looks good
201:12 - in some computer vision right the images
201:14 - that I gave like cat and all it was it
201:16 - was just saying play so at least it was
201:19 - able to understand someone is playing
201:20 - over there okay so guys yet another
201:23 - amazing end to endend project for you
201:25 - and in this particular project we are
201:27 - probably going to create a multilanguage
201:30 - invoice
201:31 - extractor and we are going to use gini
201:34 - Pro API for this gini pro has been quite
201:38 - amazing you can definitely do a lot many
201:40 - things I have preped prepared more 10 to
201:42 - 15 different kind of projects that are
201:45 - related to Real World Industries and
201:47 - trust me all the specific projects are
201:49 - performing exceptionally well with
201:51 - respect to accuracy so over here we are
201:54 - going to focus on creating a multil
201:56 - language invoice extractor app we'll be
201:59 - using gemin Pro we will be writing all
202:01 - the codes step by step so please make
202:05 - sure you practice along with me and once
202:08 - we practice things right one then you
202:10 - get multiple ideas like what different
202:13 - kind of projects we can basically do
202:16 - okay so let's go ahead and first of all
202:19 - let me show you the agenda what all
202:21 - things we are basically going to focus
202:23 - on so here is the entire agenda so in
202:28 - this agenda what we are going to focus
202:30 - on first of all I will go ahead and show
202:32 - you the multil language in wased
202:35 - extractor app demo okay how the demo
202:37 - looks like later on we will start the
202:40 - process of creating the project project
202:42 - by creating the environment first of all
202:44 - then we will go ahead with the
202:45 - requirement. txt what all libraries we
202:47 - are specifically required and then we
202:50 - will start writing our code this will be
202:52 - an endtoend project code step by step
202:54 - we'll try to build this app again it
202:57 - will take some time let's say this
202:59 - project will probably take somewhere
203:00 - around 25 to 30 minutes and then in
203:03 - fifth point we'll also discuss about
203:05 - what more additional improvements you
203:07 - can specifically do so that you can also
203:09 - try it from your side and as usual guys
203:12 - I'm actually keeping Target likes for
203:14 - every video so let's target uh th000
203:18 - likes for this specific video because
203:19 - all these videos will be super
203:21 - beneficial for you in the
203:23 - companies so let me first of all
203:25 - complete the first one that is the demo
203:29 - okay so here you can probably see this
203:31 - is my entire app okay and here I have
203:36 - actually uploaded one of the uh invoice
203:40 - okay so this is the GST invoice and it
203:42 - is completely in Hindi okay the best
203:45 - thing is that if I ask any question
203:47 - related to this using gini Pro so here I
203:50 - have asked what is the address in the
203:51 - invoice so address basically means over
203:53 - here 1 2 3 uh SBC building DF state so
203:59 - this is just a common invoice I've taken
204:02 - from the internet itself so here you can
204:04 - probably see we are able to get the
204:06 - entire response so this is quite amazing
204:09 - not only this I've asked for different
204:10 - different questions what is the date
204:12 - let's say if I go ahead and say what is
204:15 - the
204:16 - date what is the date in the invoice and
204:21 - here you can see date basically means
204:23 - the knock so
204:24 - that usually this Google gini pro is
204:27 - able to understand those things okay so
204:30 - I think we will be getting the response
204:32 - so let me just go ahead and see it so
204:34 - it's
204:35 - running uh so here you can probably see
204:37 - 12 27 21 so all the information in this
204:41 - specific invoice you are able to extract
204:44 - just by putting a prompt over here now
204:46 - the best thing about this particular
204:48 - project is that it is very difficult to
204:50 - automate it because I'll tell you uh we
204:53 - have tried the specific project with the
204:54 - help of testra OCR and all right just
204:58 - imagine that Google Germany is able to
205:00 - perform exceptionally when well when
205:02 - compared to all those kind of tools okay
205:05 - so this was the demo now we will go
205:06 - ahead and probably develop this project
205:09 - completely end to end and we'll start
205:11 - from completely from scratch itself so
205:14 - uh let me go ahead and let me start this
205:16 - specific
205:17 - project so guys here is one of the
205:20 - project that I've started in my vs code
205:22 - itself so first of all just go to the
205:25 - terminal so I will show you all the
205:28 - steps what you should basically do as I
205:30 - suggested the first step is basically to
205:32 - create my virtual environment so for
205:36 - creating the virtual environment I've
205:38 - already created it so that it does not
205:39 - take much time because for creating the
205:41 - virtual environment also it takes some
205:43 - time so in order to create it just go
205:45 - ahead and write cond create minus P okay
205:50 - V andv your environment name okay and
205:53 - then you can also give python version
205:55 - and remember to give python version
205:57 - greater than 3.9 in this case because
205:59 - Gemini Pro is suitable for python
206:02 - version greater than 3.9 so here I'm
206:04 - going to basically use 3.10 and then you
206:07 - just give- y so that it does not ask you
206:10 - for any permission while doing the
206:12 - installation as soon as you probably
206:14 - press enter so this kind of V EnV
206:16 - environment will get created in the same
206:18 - project folder okay so I'm not going to
206:21 - repeat this thing and probably execute
206:24 - it because I've already done this okay
206:26 - so just do it from your site with the
206:28 - help of this specific command the second
206:30 - thing is that I will go into theb file
206:33 - and I'll create an API key which will be
206:35 - available from the Google okay so Google
206:38 - API key this is basically for gin Pro
206:41 - and and if you don't know gini pro gini
206:43 - pro is again an amazing model that is
206:45 - provided by Google which actually
206:48 - provides you in a free way so you can
206:50 - actually hit 60 queries per minute okay
206:53 - so here is the API key that I have got
206:55 - if you want to also create your API key
206:57 - go to this website okay maker suit.
207:01 - google.com/ API key and you can just
207:03 - click on this create API key new project
207:06 - okay so I have already created it so I
207:08 - don't want to create it again okay so
207:11 - these are the first two steps you really
207:13 - require the API key and you require the
207:16 - environment now after that you just
207:19 - activate like you just write cond
207:22 - activate
207:23 - venv Okay and just activate this
207:26 - specific environment okay once you
207:27 - activate it you will be able to see that
207:29 - you'll be in that same environment
207:32 - location now let's go to the next step
207:35 - in requirement. txt what all libraries
207:37 - we specifically require so here is
207:40 - streamlet then you you have Google
207:41 - generative AI then you have python. EnV
207:44 - then you have Lang chain you have P PDF
207:46 - P PDF is basically to load any PDF as
207:49 - suchar or read any PDF uh then you have
207:52 - chroma DB chroma DB is specifically for
207:54 - Vector embeddings so we will try to also
207:56 - do Vector stores or vector embedding
207:58 - will try to create it so uh these are
208:01 - the basic steps that we specifically
208:03 - require now let's go ahead and start my
208:08 - coding or creating this specific
208:10 - application uh I will start writing the
208:12 - code completely from end so first of all
208:14 - what I will do I will go ahead and load
208:17 - my environment variable so I will say
208:20 - load do from EnV
208:23 - import
208:25 - load uncore do EnV so the reason why I'm
208:29 - doing this is that so that I can upload
208:32 - my all I I can load all my environment
208:35 - Keys okay so if you remember we have
208:37 - also installed python. EnV so python.
208:40 - EnV is basically for all my environment
208:42 - variables now I will go ahead and write
208:44 - load doore EnV so this will what it'll
208:48 - do it will take it'll load all the
208:50 - environment
208:52 - variables all the
208:55 - environment variables
208:58 - fromb file okay so this is what it is
209:01 - specifically going to do we'll do step
209:03 - by step now you'll be able to understand
209:05 - and please make sure that you write the
209:07 - code along with me so that you'll be
209:09 - able to understand it now the next thing
209:11 - is that I will go ahead and use
209:12 - streamlet as streamlet is a better
209:15 - framework to
209:16 - quickly you know create an app and
209:19 - definitely I use chat GPT for taking out
209:22 - the code and all right so that is the
209:23 - reason you're able to see that I'm able
209:25 - to upload daily videos see not the
209:28 - entire project is created by chat GPT
209:30 - but how to use stream late how to create
209:32 - this uh website kind of app you know all
209:34 - those things I can usually use streamlet
209:37 - uh use chart GPD so then uh so this is
209:41 - is my streamlet the next thing is that I
209:42 - will go ahead and import
209:44 - OS uh OS will basically be useful by for
209:49 - picking up the environment variable
209:50 - assigning the environment variable from
209:52 - somewhere else okay now this is done uh
209:55 - the next thing that I want is from P I
209:59 - also import image okay I don't know
210:01 - whether I'll be using this but let's see
210:04 - the next thing I will also go ahead and
210:07 - import from Google
210:10 - Dot generative AI as gen AI okay so I'm
210:14 - also going to import this specific
210:17 - because gen AI will be my entire
210:20 - libraries that I'm going to access it
210:22 - okay so done this is done these are some
210:25 - of the basic uh things that we are
210:27 - specifically going to load it okay now
210:29 - usually when we start our any
210:32 - application using gin API so what we
210:34 - need to also do is that we need to
210:37 - configure uh the API key so here I'm
210:39 - going to write gen a configure API key
210:43 - is equal to
210:45 - os.
210:47 - getet OS
210:50 - dot get EnV okay and here I'm going to
210:54 - get my environment variable that is
210:56 - nothing but Google API key so here
210:59 - whatever environment variable is
211:00 - basically present over here we are going
211:02 - to take this okay so configure okay so
211:06 - gen. configure uh the API key with this
211:09 - okay now
211:11 - it's time that we will create our
211:14 - function to
211:18 - load
211:20 - gini gini provision since the invoice
211:24 - instructor is on top of an image so we
211:27 - have to use this gin provision okay so
211:30 - function to load or first of all I'll
211:32 - load the model so I'll say model dot gen
211:38 - dot generative
211:43 - generative
211:45 - model so I'm going to specifically use
211:47 - gen. generative model and here I'm going
211:50 - to basically give my model name so it
211:53 - will be Germany Pro Vision okay so once
211:57 - I do this that basically means we are
211:58 - going to use this specific model now I
212:01 - will go ahead and write definition get
212:04 - giny
212:07 - response
212:09 - input image
212:12 - prompt
212:15 - okay so let me go ahead and write model
212:18 - equal to gen
212:20 - AI sorry I'll not initialize the model
212:23 - again so what I will do I will go ahead
212:25 - and write see the thing is that here I'm
212:28 - going to give three parameters one is
212:30 - this specific input input basically
212:32 - means uh uh whatever input I really want
212:36 - okay with respect to all the images that
212:38 - I'm giving and I'll also talk about this
212:40 - specific thing okay okay the three
212:41 - important information this input is
212:44 - basically I'm telling what what I want
212:48 - the assistant to do okay if I say hey
212:50 - you need to act as an invoice extractor
212:53 - you need to act like an expertise who is
212:55 - very good at uh taking out details from
212:58 - the invoice right so that basically
213:00 - becomes my input okay this prompt is
213:04 - what message I want like what is the
213:05 - address I actually return this is
213:08 - basically the image that we are going to
213:10 - pass okay
213:11 - so all those information this three
213:13 - information what we can basically do
213:14 - I'll write response
213:16 - dot model
213:18 - dot
213:21 - generate content and here we are going
213:24 - to use this three information first of
213:27 - all is
213:28 - input then you have image of zero the
213:31 - second one and then you have the prompt
213:35 - okay so this three information basically
213:38 - when you're generating this content you
213:39 - can give this three information in this
213:41 - same way okay input image of zero and
213:43 - prompt okay so in gini Pro they take
213:48 - they take all the parameters in the in
213:49 - the form of a list okay and remember the
213:51 - first parameter is basically the kind of
213:55 - prompt that you're giving where your
213:57 - model needs to behave in that specific
213:59 - way so I will talk more about it as we
214:01 - go ahead and finally we are going to
214:02 - just return the response. text so this
214:05 - easy it is with the help of Gemini Pro
214:08 - okay and that is the reason I'm loving
214:10 - it when I probably compare with open Ai
214:12 - and the best thing is that I can also
214:14 - use uh this along with my Lang chain you
214:17 - can probably use it with different
214:19 - different things I will show you I've
214:20 - also created a project where you can
214:22 - chat with multiple documents okay so
214:24 - that will also be we'll be using Lang
214:26 - chain and all so this is the function
214:28 - that is specifically done now understand
214:30 - one thing guys um we will do our
214:33 - streamlit setup okay so streamlet setup
214:35 - what I will do so here I will go ahead
214:37 - and copy and paste like this so here I'm
214:40 - using st. set page config let's say that
214:42 - I'll go ahead and say over here
214:45 - multi-
214:47 - language
214:49 - invoice
214:50 - extractor okay multi- language invoice
214:53 - extractor now in this multi- language
214:55 - invoice extractor I will probably also
214:58 - give this information let's say okay now
215:02 - here I've given one input box this one
215:05 - input box is my input prompt okay and
215:08 - this is basically my upload file file
215:10 - upload so I'm saying that choose an
215:12 - image the image can be jpg jpg PNG this
215:15 - is the image of the invoice okay so let
215:18 - me go ahead and write this message of
215:20 - the invoice so once I specifically
215:23 - upload this specific file then we can do
215:25 - anything that we want okay now the next
215:29 - thing is that I will create an image
215:31 - variable I'll keep it blank initially
215:33 - and let me go ahead and write if
215:35 - uploaded
215:36 - file is not none so that basically means
215:39 - when I've when when I have uploaded some
215:42 - file then I will go ahead and write
215:45 - image and again I'll be using image.
215:48 - open and we will upload uh open this
215:51 - uploaded file okay now once we upload
215:54 - this so what we can also basically do is
215:57 - that we can uh write some kind of image
215:59 - and all I want to display the image also
216:03 - as soon as I upload it I probably want
216:05 - to display it so I can just try use this
216:07 - st. image functionality and I'll say
216:09 - caption uploaded image
216:11 - and we can use this properties Now
216:13 - understand that this this code right I
216:15 - have directly searched from uh uh chat
216:19 - GPT okay and uh I've just written okay
216:22 - just create me an image where to upload
216:25 - files and all right uh so very simple it
216:28 - is not like I am learning from somewhere
216:31 - I even not seeing the documentation chat
216:33 - GPT actually provides everything a
216:34 - Google Power provides everything that is
216:36 - basically required now this is my
216:38 - uploaded file now I will also go ahead
216:41 - and create my submit button so here I
216:43 - will go ahead and write St do button and
216:46 - I will talk about it saying that tell me
216:49 - about the image okay tell me about the
216:54 - invoice something so this is my message
216:57 - that I'm actually going to give in my
216:59 - submit button and finally I have to also
217:02 - design my input prompt now see this
217:05 - input that I'm actually going to give
217:07 - right so this basically becomes my input
217:08 - prompt I what how I want the germini pro
217:11 - llm model to behave so here I will go
217:14 - ahead and create my input prompt just
217:17 - see this okay this is important and this
217:19 - will also give you an idea like how
217:21 - improv prompt works okay how we can
217:24 - actually work with any kind of improv
217:26 - prompt I will say you are an
217:30 - expert
217:31 - okay in
217:34 - understanding invoices okay
217:39 - um
217:41 - we will
217:45 - upload we will upload a
217:49 - image image as invoices okay I'm just
217:53 - writing some messages
217:55 - and you will have to
218:01 - answer any
218:04 - questions based on
218:07 - the
218:09 - uploaded
218:10 - invoice image so this is just a basic
218:13 - prompt that I'm specifically using over
218:15 - here I'm telling this to do something
218:19 - related to this okay so this is my input
218:21 - prompt and all I've written it over here
218:24 - then let me go ahead and write if submit
218:27 - button is
218:29 - clicked if submit button is clicked so
218:32 - this is my default input prompt now what
218:34 - I will do is that I'll also create my
218:36 - prompt template itself and probably go
218:38 - ahead right if submit button okay okay
218:41 - is
218:42 - clicked now what will happen if I click
218:44 - the submit button so first of all I will
218:47 - go ahead and write if
218:49 - submit first I need to get my image data
218:52 - okay now understand over here as soon as
218:55 - we load the image but still we have to
218:57 - do some kind of image processing and
218:59 - convert those images into some bytes
219:02 - okay so for that again how do we do it
219:05 - so I will write definition input uncore
219:09 - image set up so for this I have just
219:12 - written in chat G saying that and here
219:16 - will be my uploaded file okay uh
219:19 - uploaded file uh okay uploaded file okay
219:22 - see now you may be thinking what I'm
219:24 - doing in this function in this function
219:27 - what we are writing is that it will take
219:28 - that uploaded file it will convert that
219:31 - into bytes and it will REM it will give
219:33 - all the image format all the image
219:35 - information in the bytes now I did not
219:37 - write this code I just went and searched
219:39 - in the chat GPT and this is the code
219:41 - that I specifically got okay and this
219:44 - code is quite amazing same way nothing I
219:47 - did not do anything see here if the
219:49 - uploaded file is not done so we first of
219:51 - all we are getting all the values then
219:53 - the image part what all things we
219:54 - basically require the type the data and
219:56 - byes data right and then we are
219:58 - returning the image Parts in these two
220:00 - format okay the M type and data and if
220:04 - the file is not uploaded this is that so
220:06 - this is completely I got it from chat
220:07 - GPT I'm not bragging anything about
220:09 - myself and all
220:10 - um again charit is already trained in
220:13 - internet data so it's just like writing
220:15 - an input prompt and I'm saying that okay
220:16 - I require this two specific information
220:18 - please give me that information now in
220:20 - this image data what we will basically
220:22 - do is that we will get all the image
220:23 - information so here I will go and write
220:27 - input image
220:29 - setup so let me do one thing input image
220:35 - details
220:36 - okay so I will call this give a good
220:39 - name okay and here I will give my
220:42 - uploaded
220:44 - file okay uploaded file so uploaded file
220:48 - whatever uploaded file I'm specifically
220:50 - getting I'm going to give that specific
220:52 - thing over here now by this I will be
220:55 - getting my image data now image data
220:58 - once I get it okay then I will go ahead
221:00 - and write my response and go ahead and
221:03 - call my get Gemini response so here I'm
221:06 - going to basically write my input input
221:08 - prompt first p parameter is this second
221:11 - parameter that I'm going to give is my
221:13 - image data as usual remember all the
221:15 - information will be coming in the form
221:17 - of list okay so image underscore data
221:20 - and this will basically be my input
221:23 - input and this input is nothing but
221:25 - whatever information I'm putting it over
221:27 - here all this information will go over
221:29 - here and you have all this information
221:31 - in this format right now after this I
221:34 - will get the response and now I will go
221:36 - ahead and write st. subheader
221:40 - I'm giving some kind of
221:42 - subheader and I will write
221:46 - the response
221:50 - is st.
221:53 - WR and I will just display the response
221:56 - okay whatever response we are
221:57 - specifically getting okay that response
222:00 - we going to get over
222:03 - here so all this information is done and
222:06 - this is really good now it's time that
222:08 - we can just run the code so guys now
222:10 - let's go ahead and run this uh we have
222:13 - completed almost everything that we
222:14 - really want to do now is the most
222:17 - amazing thing whether the project will
222:18 - run or not okay so if the project runs
222:21 - it is absolutely good because at the
222:22 - first time we have written the code and
222:24 - everything should work fine so here I'm
222:26 - going to write streamlit run
222:30 - app.py and let's go and execute
222:33 - this so it has opened let's see so I've
222:36 - have downloaded two invoices let's see
222:38 - what all things will be there first we
222:40 - will try with the normal invoice okay so
222:43 - here you can see all the
222:46 - information who is this
222:50 - invoice build to okay so I'm going to
222:54 - put this information over here and I'm
222:56 - going to click
222:58 - it tell me about the image tell me about
223:02 - the invoice on the all the information
223:04 - will be provided over here this is
223:07 - good so your client so all the
223:10 - information is over here your client
223:12 - this this this this even the number has
223:13 - been extracted which is quite amazing it
223:15 - is really a daunting process guys okay
223:18 - uh let's see I will just take a small
223:20 - one what is the deposit requested okay
223:22 - so I will just go ahead and write it
223:25 - what is the deposit requested this is
223:29 - good this giving an amazing response so
223:32 - I will go ahead and click tell me about
223:34 - the invoice over here and here you go
223:37 - let's
223:38 - see what it is going to get so tell me
223:43 - about the deposit requested it is just
223:44 - saying your
223:46 - company uh who is the deposit okay my
223:48 - prompt is wrong tell me so it is not
223:52 - able to understand the context obviously
223:54 - if you don't give the
223:56 - proper uh tell me how much was the
224:00 - deposit requested I'll give a good
224:08 - response Okay so I will go ahead and now
224:10 - click on it should give uh the proper
224:13 - answer I think now it is somewhere
224:15 - 169.99 5 it'll pick up that exact info
224:19 - and provide you all those
224:22 - information this is good so let's see
224:25 - 169.99 this is good guys this is trust
224:28 - me this is very very close uh what was
224:30 - the Consulting fees let me go ahead and
224:32 - write what was
224:34 - the Consulting
224:37 - fees now I think it should get confused
224:40 - with those two values what was the
224:45 - amount of the Consulting fees I think it
224:47 - should be able to give it let's see then
224:50 - we'll try with some other language
224:51 - invoice like Hindi and all
224:54 - okay let's see let's see let's see I
224:56 - think it should work fine but this is a
225:00 - good thing guys you can automate this
225:01 - entire process just imagine it is such a
225:04 - daunting process for with respect to
225:06 - invoice just see that whether you get an
225:09 - invoice all so the amount of the
225:10 - Consulting fees was
225:13 - $550 okay it is taking this
225:15 - information um okay there are some minor
225:18 - mistake but other than that I think
225:21 - let's see what is the total what was the
225:24 - total
225:30 - discount let's see discount is somewhere
225:32 - around
225:34 - 17.8 but if you give proper prompt I
225:38 - think you'll be able to get a good
225:39 - response response okay 179.1 4 okay so
225:43 - let's go ahead and try some other
225:45 - invoice this also looks good and uh let
225:47 - me go ahead and write this so here I
225:50 - will go ahead and write what is the HSN
225:52 - of Lenovo 51251 Lenovo in Hindi it is
225:56 - written in Lenovo so what is
226:01 - the HSN
226:04 - number
226:06 - of
226:08 - of
226:11 - of
226:12 - Lenovo okay I'm writing it in English
226:17 - 51251
226:20 - 5125 5125
226:23 - I let's see whether it'll be able to
226:25 - give or
226:30 - not see this small information also it
226:33 - will be able to take now over here the
226:35 - date is denak okay in Hindi we basically
226:37 - say it as dinak so here you can see
226:39 - 84713 01 0 amazing amazing just amazing
226:43 - okay so what is the date in the
226:47 - invoice and you can try anything you can
226:49 - try different different invoices if you
226:53 - want I downloaded this invoices from
226:55 - internet you can also do it okay so yes
227:00 - here let me see whether you're able to
227:02 - get it yes perfect so guys this was it
227:05 - for my side I hope you like this
227:06 - particular video if you like it please
227:07 - make sure that you subscribe the channel
227:09 - and all the information regarding this
227:10 - will be given in the description of this
227:12 - particular video this video we are going
227:13 - to see how we can actually build a
227:16 - conversational Q&A chat bot with the
227:18 - help of Gemini Pro API not only that
227:22 - we'll also try to save all this chat in
227:24 - the form of a history and will will also
227:26 - display all the results that we all had
227:28 - a conversation about that is the reason
227:30 - we are discussing about conversational
227:32 - Q&A chatbot so before I go ahead guys we
227:35 - will keep the light Target of this
227:37 - specific video to th000 so that I will
227:39 - definitely get motivated and I'll try to
227:41 - bring more similar kind of projects for
227:43 - every one of you out there now before I
227:46 - go ahead please let me go and go ahead
227:48 - and show you the demo so this is how the
227:50 - demo demo will look like so if I ask hi
227:54 - you can probably see I will be getting
227:56 - the answer the response how can I assist
227:58 - you today the chat history is Ive asked
228:01 - hi bot says hi hello how can I assist
228:03 - you so let's say if I go ahead and ask
228:06 - what is generative AI okay all all the
228:09 - previous information I really need to
228:11 - record it somewhere right so let's see
228:13 - after this the chat history right now is
228:15 - this much right so generative AI also
228:17 - known as so and so all the information
228:19 - is coming up and after that your chat
228:21 - history will also get updated and the
228:23 - best thing is that I'm streaming all the
228:26 - specific data okay so how streaming
228:27 - actually works and all we'll also be
228:30 - discussing about that so here you can
228:32 - see in the history I've asked what is
228:33 - generative Ai and this is specifically
228:35 - all the information now this is what we
228:38 - are going to implement step by step I'll
228:39 - show you each and everything again all
228:41 - the files regarding this all the code
228:43 - regarding this will be given in the
228:44 - description of this particular video so
228:46 - let me go ahead and let me solve this
228:48 - specific project so guys I have opened
228:52 - my VSS code over here and right now uh
228:56 - if you remember in my previous video
228:58 - I've discussed about all these things
229:00 - like vision. py how you can actually
229:02 - play with images with the help of gini
229:04 - API gini Pro API then we also discussed
229:07 - about some kind of simple Q&A chat B now
229:10 - in this video I am going to show you
229:12 - this entire code with respect to this
229:15 - qpy so here is what is my entire code
229:18 - I'm going to specifically write step by
229:20 - step I'll try to show you what all
229:21 - things is basically required as usual
229:23 - first of all we need to have an
229:25 - environment file with respect to Google
229:27 - API key this you can actually get it
229:29 - from makes. google.com so from there
229:32 - which will basically provide you all the
229:33 - features to create the API key for gini
229:36 - pro the first thing is EnV file once we
229:39 - create the EnV file then we will go
229:41 - ahead and start implementing our code if
229:44 - you have not seen all the videos in My
229:46 - Gin playist I would suggest go ahead and
229:48 - have a look so let me quickly write over
229:50 - there all the code so first of all I
229:52 - will go ahead and uh load all the
229:54 - environment variables so for this I will
229:56 - use
229:58 - forv um import
230:01 - loore EnV okay and then we will go ahead
230:05 - and initialize load. EnV and finally I'm
230:09 - going to import
230:12 - streamlet as
230:15 - STD so I'm going to use streamlit over
230:18 - here and remember one thing guys there
230:20 - are some important libraries that you
230:21 - need to install that is present in the
230:23 - requirement. txt everything will be
230:25 - provided in the description of this
230:27 - particular video the GitHub code right
230:29 - so I'm going to use streamlet Google
230:30 - generative a and python. EnV all this
230:33 - Library needs to be installed before
230:35 - ahead right so I'm importing stream.
230:37 - asst then I will go ahead and import OS
230:40 - because I will be requiring it and then
230:43 - I will say import Google do generative
230:47 - AI as gen okay so I'm going to use this
230:50 - Library only for doing all my task now
230:54 - initially whenever we load any
230:56 - environment key first of all we need to
230:58 - set this in my gen AI so for doing that
231:01 - I will write gen ai. configure configure
231:03 - is a method where it will be asking for
231:05 - the API key that I have and since I've
231:07 - already loaded that from my environment
231:09 - so you can see that os. getv I'm using
231:11 - this Google API key okay now the next
231:14 - thing over here I will try to create a
231:17 - function function to load gini pro model
231:22 - okay so here you can probably see gini
231:27 - pro gini pro model and get response okay
231:34 - so I'm doing this and here you have
231:36 - model.
231:37 - geni Dot
231:41 - generative model I'm going to initialize
231:43 - my generative model itself and in this
231:46 - case also I'm going to use gini Pro okay
231:49 - so gini pro and gini pro vision for
231:52 - conversational Q&A we will specifically
231:54 - be using this one that is called as
231:56 - Gemini Pro okay and then we will go
231:59 - ahead and execute it and write chat
232:02 - model dot startor chat and here I'm
232:06 - going to specifically use history
232:10 - okay so this history will also maintain
232:12 - all the things that we are probably
232:15 - going to uh have in our conversation but
232:18 - I will show you another way where I'll
232:19 - use the power of streamlit to store all
232:22 - the history in a form of a session later
232:24 - on you can also put that inside your DB
232:28 - or you can also use it from your session
232:29 - itself right uh so first of all let me
232:32 - go ahead and Define my definition so
232:34 - here I will basically write definition
232:37 - get gini under underscore
232:41 - response response and inside this
232:44 - response I will specifically give my
232:46 - question whatever question we have asked
232:49 - so this function should basically uh you
232:52 - know give me the response that I'm
232:54 - getting from the generative model itself
232:56 - like from the Gman Pro right so this
232:57 - question I will send it to my llm model
233:00 - and then I will specifically get the
233:01 - response so here I'm going to write
233:03 - response
233:05 - chat. sendor
233:07 - message and here I'm going to basically
233:10 - write question stream is equal to True
233:13 - okay so stream is equal to true because
233:16 - as the llm model is giving you the
233:18 - output we are going to stream it and we
233:19 - are going to display it right and then
233:22 - we will go ahead and return the response
233:24 - so once this response is basically
233:26 - coming this response is nothing but it
233:28 - is the output right when we specifically
233:31 - get response. text now we are going to
233:33 - initialize our stream late app for
233:36 - initializing it what we are going to do
233:37 - is that I'm going to use this three
233:39 - Fields one is the Q&A demo J Min L
233:42 - application page config and header it is
233:45 - very much common the most important
233:48 - thing is that if I really want to record
233:51 - the History part right the history of
233:53 - the conversation we will initialize
233:56 - session state so in stream late it
233:58 - provides you session States for chat
234:00 - history if it does not exist I'm saying
234:03 - if chatore history not in session State
234:06 - then we will go ahead and create a sess
234:07 - State and we'll right chatore history
234:10 - over here so right now it is blank as
234:12 - soon as we have any conversation later
234:15 - on we will try to record all those we'll
234:18 - try to put all those conversation inside
234:20 - this particular session state that is
234:22 - what we are going to look at then in the
234:25 - next step we are going to basically say
234:28 - input is equal to
234:31 - st. textor
234:34 - input and here I'm going to basically
234:36 - use
234:37 - input
234:41 - input and here we are basically going to
234:44 - write key is equal to input okay so
234:48 - input will be my variable name in short
234:50 - whatever text box I'm specifically using
234:52 - along with this I'm going to also use a
234:54 - submit button St do
234:57 - button and here I'm going to basically
235:00 - write
235:01 - ask the
235:03 - question okay so what I've actually done
235:06 - I've initialized my session okay session
235:08 - state so here that the name of the
235:10 - session state is chat history okay
235:14 - now if I click on submit or input right
235:19 - basically both the fields input should
235:22 - also be filled okay so if both this
235:25 - satisfies both this conditions satisfies
235:27 - then what I will do I will write I will
235:29 - go ahead and call my get Gemini response
235:31 - and here I'm going to basically give my
235:33 - input whatever input I am probably
235:36 - giving it as soon as it calls this
235:38 - function it is going going to get that
235:39 - message and it goes to get that response
235:41 - okay
235:43 - now the next thing is that add user
235:47 - query and response to session chat
235:52 - history now see as soon as I probably
235:55 - have created this input this is what is
235:57 - my input that user has given and this is
235:59 - what is the output that we have got
236:02 - right now what I'm actually going to do
236:05 - here for all this entire history right
236:08 - we going to save this in our chatore
236:11 - history session state so for that we
236:13 - will go ahead and write St do session
236:17 - State okay st. session State and here we
236:21 - going to basically use chatore history
236:26 - okay chatore history and I'm going to do
236:30 - append with this
236:33 - specific let's say I'm going to write
236:35 - you basically you who's sending the
236:38 - message
236:40 - and then I'm going to basically use
236:42 - input
236:43 - okay so I am storing all this session
236:47 - inside this particular U variable okay
236:50 - and finally I will get my response also
236:52 - so let me write over here St
236:55 - Dot subheader and here I will write a
236:58 - statement saying that the response
237:01 - is the
237:03 - responses and in short I have to
237:06 - probably display the response Now
237:09 - understand one thing we used something
237:11 - called as stream is equal to true that
237:13 - basically means this entire response can
237:16 - without getting the entire content can
237:18 - also be populated in whatever Pages we
237:20 - want to probably display right what what
237:22 - do I mean is that now my process did not
237:25 - have to wait for the entire content to
237:27 - come from llm so as llm is sending text
237:31 - Data whatever response it is basically
237:33 - sending it is going to display it in the
237:35 - front end screen okay so that is what we
237:37 - are basically looking at so now I'm
237:39 - going to write from Chunk in
237:41 - response see that is the reason when we
237:43 - write stream is equal to True okay that
237:46 - basically means we get the exess of all
237:49 - the streaming data and then we can write
237:51 - a for Loop and I'm saying from Chunk in
237:53 - response and here I write st. write and
237:57 - we will go ahead and write chunk.
238:00 - text so we are displaying the text part
238:03 - by part and along with this I will go
238:06 - ahead and append this entire
238:09 - response okay and here instead of
238:12 - writing you I will write bot okay and
238:16 - inside this instead of writing input I
238:18 - will go ahead and write my entire chunk.
238:23 - text so what I'm actually doing is that
238:25 - as soon as I get the response it is
238:28 - coming in the streaming manner we are
238:29 - displaying it and accordingly we are
238:31 - also appending in this chatore history
238:34 - okay now this is perfect this is done
238:36 - and finally what I will do is that I
238:38 - will just go ahead and create my history
238:41 - because I need to display all the
238:42 - history right so here I will go ahead
238:44 - and write the chat history is okay so
238:48 - this is what I am going to basically
238:50 - Implement
238:52 - and and here I will say for RO comma I
238:56 - will create two common variables in St
239:00 - dot session State and here I'm going to
239:04 - use my chatore history okay
239:09 - chatore history and whatever is there it
239:12 - is either in the ski value pairs U colon
239:15 - bot colon some kind of answers here I'm
239:18 - going to basically write st.
239:21 - write I'll use a f one over here and I
239:25 - will say
239:27 - roll
239:29 - colon and then here I will say text so
239:31 - in this specific format
239:34 - okay roll colum
239:36 - text now let's go ahead and see if
239:39 - everything works fine or not okay and I
239:42 - will go ahead and open my terminal I'll
239:44 - delete this let's see so we are now
239:48 - displaying perfectly all our details uh
239:52 - this VNV has got activated I've already
239:54 - shown you in my previous video how to
239:55 - activate V EnV environment also and here
239:58 - we will go ahead and write stream late
240:00 - run uh QA chat q a chat. py and let's
240:05 - see if everything works fine or not
240:09 - so it has got executed so here is my
240:13 - things I will say Hi how are
240:17 - you and then we will go ahead and ask
240:20 - the question let's see whether we'll get
240:22 - the response the response is I'm a
240:24 - conversational AI chat B this the chat
240:26 - history is having all the details okay
240:28 - and it is giving chunk by chunk you can
240:30 - see over here right uh let's ask some
240:33 - other question my name is krishn okay
240:38 - something
240:41 - krishn what is your name okay something
240:44 - like this and I will go ahead and ask
240:46 - the question let's see whether this is
240:48 - getting saved or not
240:50 - okay so here you can see how are you
240:53 - this my name is Krishna what is your
240:55 - name I'm a chat bot assistant I do not
240:57 - have a name bot designed to help users
240:59 - so and so so all the information that I
241:02 - probably type it over here along with
241:04 - the response it is getting recorded in
241:05 - the chat history now this is what I
241:08 - really wanted to show it to you and it
241:09 - was so much easy many people had asked
241:11 - this specific question in my upcoming
241:14 - video what I'm going to specifically do
241:16 - is that I'm going to create a PDF
241:19 - document with the help of gini API I'll
241:21 - show you different embedding techniques
241:23 - how we can convert a word into vectors
241:25 - and then how we can utilize for a normal
241:28 - document Q&A kind of thing with the help
241:30 - of Gemini API right so I hope you like
241:33 - this particular video this was it for my
241:34 - side all the information regarding this
241:36 - will be given in the description of this
241:37 - particular video thank you take care
241:39 - have a great day bye-bye