00:00 - You are about to learn about the popular 
statistical application SPSS from IBM. This  
00:05 - course from university professor Burton Paulson 
will show you how you can use SPSS to explore  
00:11 - your data for actionable insights. Welcome to SPSS 
an introduction. I'm Martin Paulson. And in this  
00:18 - course, we're going to look at these statistical 
program SPSS and some of its basic functionality,  
00:24 - and give you an idea of what it can do and 
how well it might work in your own data work.  
00:29 - Now, SPSS, the name deserves a little bit 
of explanation. Once upon a time, it stood  
00:34 - for a statistical package for the social sciences. 
Now it's just SPSS. But that's its origin.  
00:41 - One important thing to know is how popular 
SPSS is. Here's a chart right here that  
00:45 - comes from the excellent website are for 
stats.com. And what it shows is the number  
00:51 - of scholarly articles published in 2015, using 
various statistical packages and languages.  
00:58 - And we can see here is right at the top is SPSS 
Statistics. SPSS is number one, by far in terms of  
01:05 - scholarly research. Also, you can look at jobs. 
Here's another chart that is also from our for  
01:13 - stats Comm. And what this shows is analytics 
and job listings on indeed.com. In 2015,  
01:19 - one major source of tech jobs, SBS is on the list, 
but this time, you see, it's actually a lot lower,  
01:25 - it's number six. And so there is a difference 
here, between academic publishing and employment  
01:34 - in analytics. Really what this tells you something 
about the population or the audience for SPSS,  
01:40 - the primary audience of SPSS is academic 
researchers, especially in the social sciences,  
01:45 - but in other fields like business. Now, there's 
some reasons that SPSS is popular in these fields.  
01:51 - Number one, it's user friendly. It's kind 
of point and click interface, which allows  
01:56 - you to assemble code really quickly. You can 
save that code as what's called a syntax file.  
02:02 - And then you can reuse it, you can adapt it 
and you can share it with others. Also, SPSS is  
02:08 - really well adapted for data from experiments, 
where you're comparing means via t tests and  
02:13 - analysis of variance, several important options 
like effect sizes and power analysis built in.  
02:19 - And so those are some of the reasons for SPSS is 
popularity, especially within academic research.  
02:24 - In some who can say a few things. Number one, 
SPSS, despite being developed about 40 years ago,  
02:30 - is still popular. It's got an easy to use 
interface. And it's easy to save and reuse  
02:36 - the syntax, giving you a code basis 
for the work that you do within SPSS.  
02:46 - The first thing we need to talk about in SPSS 
and introduction is setting up and getting  
02:51 - ready to do the work. To do that, however, we 
need to take a minute and talk about versions,  
02:56 - additions and modules, which all refer 
to different kinds of things in SPSS.  
03:02 - The choice is really making me think of an 
overwhelming a plethora of possibilities ahead  
03:07 - of you. And it's nice to break it down a little 
bit. So the things we're going to talk about are  
03:13 - versions, those are the release updates, the 
old version one version two additions, those  
03:19 - vary according to what's included in a particular 
purchase. And modules are extra functions that you  
03:26 - can get to add on to the abilities of SPSS. We'll 
start by talking about versions. version one came  
03:33 - out in 1968. And at that point, it was called 
statistical package for the social sciences  
03:38 - SPSS version 24 came out in 2016. And now it's 
called IBM SPSS Statistics act like SPSS doesn't  
03:49 - stand for anything. Now for this course, I'm using 
version 22 on a Macintosh computer. Fortunately,  
03:56 - there haven't been any extraordinarily major 
changes between 22 and 24. And everything  
04:01 - I'm going to show you in this course will work 
just fine in almost any other version of SPSS.  
04:07 - Now, it is possible that you've heard of 
something called p a s, w at some point, and SPSS  
04:14 - was briefly called predictive analytics software. 
During a trademark dispute after SPSS got bought  
04:21 - by IBM, it only lasted for a year or so and it 
got resolved. The important thing to know is that  
04:27 - no matter what version you're using, the files 
generally are highly compatible between versions.  
04:33 - And so code that you created in version 16 is 
probably readable in version 24. There are some  
04:40 - backwards compatibility issues for advanced 
functions like automatic modeling and so on.  
04:44 - But most of it is consistent all the way through. 
Now we also need to talk about editions of SPSS.  
04:52 - And there are a few major choices here. 
There's the base edition, the standard edition,  
04:58 - the Professional Edition The premium edition. 
And they differ by price. And they differ by  
05:06 - the functions that are included with each edition. 
So for example, in base, you get basic statistics,  
05:13 - you get linear regression, you get clustering 
and factor analysis. On the other hand  
05:20 - standard adds on to that logistic regression, 
generalized linear models and survival analysis.  
05:31 - It also adds drag and drop interactive 
tables. The Professional Edition adds to that  
05:38 - Data Prep, forecasting decision trees, 
and imputation methods. And then finally,  
05:44 - the top of the line premium edition of 
SPSS adds bootstrapping, complex sampling,  
05:50 - exact tests and structural equation modeling. And 
so each one adds on a number of other functions.  
05:58 - Now, this is the product pricing as of 
August of 2016. And you see, for instance,  
06:05 - that SPSS starts in the base at $1,170 per 
year per person. So it's an annual license.  
06:14 - And it goes all the way up to nearly $8,000 per 
user per year. And so it gets really expensive.  
06:22 - However, I want to say this, don't panic. 
There are other ways aside from having to like,  
06:27 - you know, sell your house to get SPSS. 
Number one, there is a free trial.  
06:32 - And you can download SPSS and you can try it 
for 14 days. And during that time, the best way  
06:38 - to do this is see if you can make a business 
case and get somebody else to buy it for you.  
06:43 - There is also academic pricing student pricing 
for SPSS started $35 for six months. It's not  
06:49 - the super duper version, but it is absolutely 
sufficient for doing the majority of academic  
06:55 - research. Now, we also need to talk about modules. 
And these are the components that add extra  
07:03 - functionality to SPSS. And they're the things that 
differentiate the different editions primarily.  
07:09 - modules of rephrase the available 
modules include advanced statistics,  
07:14 - bootstrapping categories, and complex samples, can 
joint custom tables, data preparation, decision  
07:22 - trees, direct marketing, exact tests, forecasting, 
missing values, neural networks, and regression.  
07:29 - So that's 14 additional modules. And this sounds 
like a lot, but if you can compare it to the  
07:35 - 9000 packages that are available for our, there is 
a difference there. The other major difference is  
07:41 - that these packages, they cost money, so you need 
to work that into your budget. On the other hand,  
07:47 - there are also free plugins that make it 
possible to use code in our Python, Java,  
07:55 - and the Microsoft dotnet framework within SPSS. So 
there are abilities that you can add depending on  
08:02 - what you need. In some way we can say this. SPSS 
has a long history as far as statistical software  
08:09 - goes, there are several variations and additional 
rephrasing. There are several variations and  
08:16 - additions that you can make to it by adding extra 
modules. On the other end, it can be very pricey,  
08:22 - so it's something to consider when you're 
doing the cost benefit analysis of SPSS.  
08:29 - The next step in SPSS an introduction and 
setting up is simply taking a look at SPSS  
08:35 - and seeing what the program's like. And the 
easiest way to do that is to just open it up.  
08:42 - When you first open SPSS, you'll get this 
introductory splash screen. That gives you  
08:47 - an opportunity to open up some files, recent files 
and learn more about various things that you can  
08:52 - get from SPSS. If you want to, you can click on 
this box, don't show this dialog in the future,  
08:58 - then you won't have to deal with it 
again, you can also just press Cancel.  
09:02 - And that brings you to the data window in SPSS, 
which has a lot in common with a spreadsheet.  
09:07 - It has these rows and columns, where you have 
one row per case and one column per variable.  
09:13 - But there's a very important differences between 
SPSS and a spreadsheet. To demonstrate this,  
09:20 - I want to open up a data 
set that I've used recently.  
09:29 - And then when this opens up, you see that it does 
resemble a spreadsheet, we have the variable names  
09:34 - across the top, we have row numbers down the 
bottom and we have data in the middle. Now one  
09:40 - important difference between SPSS is data window 
and a spreadsheet is this. You have a Data View,  
09:46 - but you also have something called a variable 
view. And it's the same data set but if we click  
09:51 - on it, we see it in a different way. Each of the 
variables has metadata associated with it. So for  
09:57 - instance age, it tells you the time type of the 
variable. Now these are mostly numeric, there's  
10:03 - a string variable. But you can see there's a lot 
of choices here, numeric common dot, and so on.  
10:10 - You also can specify the width of the variable, 
the number of decimal places. And then an really  
10:15 - important thing that makes SPSS different from 
most other programs is the use of labels. This  
10:20 - column right here shows variable labels. And the 
idea is we have a short one word variable name  
10:26 - over here on the left. And if you use a very 
old version of SPSS, they were limited to  
10:31 - eight characters. And you ended up with sometimes 
with very cryptic names, you don't have quite the  
10:36 - same restrictions anymore. But what's common 
is to give a short name to the variable.  
10:41 - And then to give it a label, that is more 
descriptive. In addition, you can have value  
10:48 - labels. So let's come here to marital and we 
click on this. And this is a way of telling SPSS  
10:55 - that in that column zero means unmarried and 
one means and married. Obviously, you can  
11:00 - make them whenever you want. And when you come 
back here, you have the option of seeing them.  
11:06 - So I'm going to come right up here. And 
I'm going to click on this one, too, which  
11:10 - will show the value labels, and you see how 
they've appeared. Now, I can have them go away.  
11:17 - There were the variables, if I just 
hover over, then I see the longer name.  
11:24 - Going back to Variable View, you can also 
specify values for missing values, you can  
11:30 - give the width of the column, the alignment, and 
then you can specify the scale of the rephrase.  
11:38 - And then you can specify the level of measurement. 
Now SPSS uses three values scale, which is  
11:44 - a interval or ratio level measured variable 
ordinal, which is ranked data, and nominal,  
11:50 - which is categories, you also have the option of 
specifying whether something is an input variable,  
11:56 - a target variable, or both. And there are certain 
functions that use those. But most of the time,  
12:02 - that's not a big deal. And you see that in this 
demonstration data set, those haven't been changed  
12:07 - at all. So the first window in SPSS is this 
data window. But there's more to SPSS than that.  
12:17 - So for instance, let's make a very quick graph, 
I'm just going to make a simple chart here. Come  
12:24 - and make a histogram of age. and hit OK. And so 
you see, I have a graphical user interface with  
12:32 - drag and drop menus that allows me to assemble 
my commands this way, I hit OK. And then what we  
12:39 - get is a another window that opens up, it's super 
tiny up here. So I'm going to make it much bigger.  
12:47 - And this is the output window. So it's a separate 
window, the data is in one window. And when you do  
12:52 - an analysis, you get a separate output window, 
you can actually have multiple output windows.  
12:57 - And what this one does is it has the graphs or any 
statistical analyses we do. It also has a table of  
13:02 - contents over here that you can collapse things 
or you can expand them. And an important thing  
13:09 - is I've got it set. So it shows the code that 
SPSS generates behind the scenes to create this  
13:18 - analysis. And the nice thing about that is you can 
actually use that code and you can manipulate it  
13:23 - directly. This code is called syntax in SPSS. Now, 
by default, SPSS opens up only a data window and  
13:32 - an output window. But you can get a syntax window 
as well. In fact, let me do that I'm going to come  
13:36 - up to File, New, and syntax. And this is a very 
blank window. But it's one that you can type in.  
13:46 - Or you can also use the drop down menus to put a 
command in there. So I'm going to come back here  
13:52 - to the recent command. And I did it histogram. 
And I could Press OK again, but now what I'm  
13:59 - going to do is I'm going to press a paste. 
And what that's going to do is is going to get  
14:03 - the code for that chart. And it's going to put it 
right here. In fact, this is the part that we use.  
14:11 - And if I select that, I can hit Run, 
I can also do Command or Ctrl R,  
14:17 - it runs the selection, and you'll see we get the 
output window again. And it's done the exact same  
14:23 - thing a second time. But this time it did it from 
a window where I'm able to have the text. Now a  
14:29 - lot of people are uncomfortable with syntax, and 
they like the drag and drop menus. But a really  
14:34 - important thing about this is it allows you to 
save your analysis. So you can repeat it again,  
14:40 - without having to go through all the menus. You 
can simply paste the syntax from the dialogues  
14:46 - into a syntax file, and then you can repeat it as 
many times as you want. It's also really easy to  
14:51 - modify things when you do it that way. And syntax 
files are just plain text files. They're saved  
14:56 - with a dot SPSS extension, but they read Just 
like plain text files. Now, these are the most  
15:03 - important elements of the SPSS environment, the 
data window with both the data and the Variable  
15:10 - View, the output windows and the syntax windows 
that allow you to save the command. And this is  
15:15 - what gives SPSS both some of its flexibility and 
its power. And as you become more comfortable,  
15:22 - moving back and forth between these various 
windows, and seeing what you're able to do,  
15:26 - both with the drag and drops and by typing 
text, you will discover there's a great amount  
15:30 - of flexibility and power in SPSS looking to allow 
you to do the analyses you need to do and get the  
15:35 - insight you want from your data. We'll continue 
our introduction and discussion of setting up  
15:42 - in SPSS by taking a look at the sample data 
that comes as part of the SPSS application.  
15:49 - The really nice thing about that is it 
allows you to get started now start working  
15:53 - with things and see how SPSS works. The hard 
part, however, is that it's totally hidden.  
15:58 - And so you need to know where to 
look in order to use the sample data.  
16:03 - Now, if you're on a Macintosh like I am, then 
it's going to be in your Applications folder  
16:09 - under IBM SPSS Statistics 22 or whatever version 
you're using, then samples and then in English,  
16:17 - then you'll have them. In Windows, it's a little 
bit different. It's going to be C program files,  
16:23 - IBM SPSS Statistics 22, or whatever 
version you have samples and then English.  
16:30 - So you have to navigate to that manually in 
order to be able to find those. But when you do,  
16:37 - you'll see a bunch of files there. Now, there's 
a few kinds in particular that are important.  
16:42 - There are the dot s, a V files. These are 
data files in the proprietary SPSS format,  
16:48 - they can only be opened up in SPSS. Usually, 
there are also dot SBS files. And these are SPSS  
16:56 - syntax files. There are text files with the 
commands that can run a number of analyses and  
17:01 - graphs and other functions in SPSS. Now, we can 
try it in SPSS, by having you on your computer  
17:08 - open up the window, and opening up a file called 
demo dot save. But let me show you how it works.  
17:16 - When you navigate to the folder with the SPSS 
Sample Files in it, again, it's several hidden  
17:22 - layers down. These are the files that you'll find 
these are the dot shp data files. And these are  
17:30 - the dot SPSS syntax files. Now there are other 
things in there, there's something called a CSA  
17:36 - plan. That's an analysis plan. There's an XML 
file, and there's a few other things in there.  
17:43 - But the majority of what we want to deal with, in 
fact, rephrase. But the only ones that we're going  
17:49 - to deal with are the dot shp files, and possibly 
the dot SPSS files. Let's scroll down here until  
17:55 - we find demo dot Save. Now, please note, there's 
a lot of other demo files around that. So you want  
18:02 - this one in particular demo dot shp because that's 
the SPSS file. I'm going to double click on that.  
18:14 - And SPSS opens up the file. Now you can set SPSS, 
so it has only one data file open at a time,  
18:20 - or you can have multiples, I'm going 
to close this empty file right here.  
18:27 - But here is our demo file. And this allows us 
to start working with a lot of the analyses and  
18:32 - see how they work. In fact, I'll be using this 
file all the way through this entire course,  
18:37 - because it allows you to do a number of analyses 
that require specific kinds of data. And this has  
18:44 - it all set up. So I'll show you a very quick one 
I'm going to come up to analyze, and to explore.  
18:53 - And I will get level of education and put that in. 
And so I have a long list of variables that I can  
19:00 - work with. These are all the same variables, just 
hit OK. And that opens up my output window again,  
19:08 - opens up microscopically here in the top corner. 
So I'm going to make it bigger. And now I'm able  
19:16 - to start working with my sample data. And that 
allows me to get some hands on experience to see  
19:21 - how the functions work in SPSS and to try some 
of the options and see how they affect things.  
19:29 - Our next step in SPSS and introduction is to look 
at basic graphics because those are always a good  
19:35 - first step in analysis. And the easiest way to do 
that in SPSS is with something called graph board  
19:41 - templates. Really, you can just think of these 
as graphs made easy. The idea here is that if  
19:47 - you set the levels of measurement in SPSS, 
then SPSS considered just graphs that would  
19:53 - be appropriate for those variables. Now in terms 
of level of measurement, remember SPSS uses the  
20:00 - Number one is nominal for different 
categories. Number two is ordinal for ranks,  
20:08 - and number three is scales, that's for 
interval or ratio level measurements.  
20:14 - And then when you're in the graph board 
templates, you have two basic choices,  
20:17 - you have basic graphs. And those are where 
you choose the variables. First that you want  
20:23 - to graph. And then SPSS will show you suggested 
graphs, you can see what you want to do with them.  
20:29 - There's also an option for detailed and this is 
where you choose the graph style first, and then  
20:34 - you choose the variables that go into it. Now, 
these aren't exclusive, you can bounce back and  
20:40 - forth between the two tabs, and it'll be easiest 
to see how it works. If we just go to SPSS,  
20:46 - if you're logged into data lab.cc, then you 
should be able to download the exercise files  
20:50 - from the same page that this video is on, open 
up this file SPSS, oh one, underscore three  
20:56 - underscore one underscore graph board dot SPSS 
syntax file. And let's see what it looks like.  
21:03 - Syntax file that you've opened, looks kind 
of complicated. But this is really because  
21:08 - I want to have a written record of the same 
things that we're going to do with the drag  
21:12 - and drop menus and the graph board, we do need 
to open a data set. And as I mentioned before,  
21:17 - depending on whether you're on a Macintosh or on 
a Windows computer, the path to the data set is  
21:23 - a little bit different. And also depending 
on the version you're using, I'm using 22.  
21:28 - And so if you're using something else changed that 
number right there, most of it should be the same.  
21:33 - And you can run this command and open up the 
dataset and activate it. Now I've already done  
21:38 - that, I'll show you. There's my data set right 
there as the demo dot save. And we can come  
21:45 - down here to Variable View. And see the levels of 
measurement that SPSS is assigned to these. Most  
21:51 - of them are scale, we have a few that are ordinal, 
we have only one variable in this data set that's  
21:56 - truly coded as nominal. And that's gender, which 
is actually a string variable. In this case.  
22:03 - I'll go back to this index.  
22:09 - Now, I have some rather complicated syntax here. 
But what you'll see is that when we use the menus,  
22:14 - it's actually pretty simple. The first thing 
we're going to do is make a chart of age. But I'm  
22:20 - going to come up here to graphs to the graph board 
template chooser. And when I come to that, you see  
22:29 - I'm in this tab of basic graphs, and this is where 
I choose a variable. I'm going to choose age right  
22:34 - here. And it recommends three different kinds of 
charts, a dot plot the histogram and the histogram  
22:39 - with a normal distribution. We'll take the very 
first one that's available dot plot, and hit OK.  
22:48 - It puts it in the output window, which I have 
to maximize. And there it is, it's a dot plot  
22:52 - looks a lot like a histogram of aging year. So it 
goes down to 18 years, it looks like it goes up to  
22:58 - about 7778. And it's an easy way to get a feel of 
the distribution that we're dealing with. Again,  
23:05 - the command in text and syntax is complicated. 
But the graphical interface makes this very easy  
23:11 - to do. Go back to the syntax for a moment. If you 
were to paste the syntax for that command, this  
23:18 - is what you would see right here. And this way of 
saving it, you can modify it manually if you want.  
23:23 - Now we'll do a histogram of age with 
a superimposed normal distribution.  
23:29 - Again, I'll come up to graphs, graph board 
template chooser. And this time, all I  
23:37 - have to do is come over to the right, I click 
histogram with normal distribution, and hit OK.  
23:45 - Expand the output window. And it's really simple.  
23:53 - Now both of those charts that I showed you 
were with age, which is a ratio level or  
23:57 - scaled variable in SPSS terminology, we can also 
do this with categorical variables, I'll use  
24:03 - gender and make a bar chart, 
come back up to graphs,  
24:07 - hit GRAPH board template chooser. And when 
I come down to gender, you'll see that the  
24:12 - Recommended Charts change because this 
time it knows it's a categorical variable.  
24:17 - Now, if I had GPS data, I could put that in 
here, I can do a bunch of different things,  
24:23 - I'm just gonna do a bar chart because that's 
the easiest to deal with. I'll hit OK.  
24:30 - Make the output window bigger. There's 
my bar chart and you see that in this  
24:34 - particular data set, we have an almost exactly 
equal number of men and women or data on them.  
24:45 - Now, those are the basic charts where you choose 
the variable first and SPSS recommends particular  
24:50 - graphs. You can also do detailed charts. These are 
ones where you choose the style of chart first and  
24:56 - then you fill in the variable. I'm going to do 
this again for $1 plot of income and then show  
25:01 - you that it's really easy to modify it, come 
up to graphs to graph board template chooser.  
25:09 - This time, I'll go to the detailed tab, click 
on that. And I'm going to make a dot plot.  
25:17 - So I'm going to scroll through this, you see 
we have a lot of choices. Choose dot plot. And  
25:23 - that's going to ask what I want to make a dot 
plot of. I'm going to click on this, and I'm  
25:29 - going to scroll to income. See, the one that I 
want is right here, household income and 1000s.  
25:38 - I can click OK. then expand the output window. 
And here's my chart. It's really basic charting,  
25:47 - you see that most of the people are at 
the low end, especially because this  
25:50 - is hundreds of 1000s of dollars. So that's 
going to be a million dollars right there.  
25:55 - But I want to show you an interesting thing 
about this. If we double click on the chart,  
25:59 - that opens up the Edit window, and the 
graph board editor has some special options.  
26:04 - For one thing, I can change the number of 
decimal places here, I just click on the decimals  
26:08 - come to format and change the minimum level, or 
rather the minimum number of decimals to zero.  
26:16 - That's better. But the more interesting one is, 
if I click on the dots themselves, they're done  
26:23 - as points and the modifier is to pile them, there 
are a few other modifiers that can be useful. One  
26:29 - is to dodge them. And what that does is it puts 
them in the middle of expanding out either way,  
26:36 - it might be a little harder to make comparisons 
from one level to another. But it's an interesting  
26:41 - kind of chart, I can click on it again. And 
we can do what's called jitter with a normal  
26:48 - distribution, and that takes points with the same 
value and it kind of randomly spreads them out,  
26:53 - up and down. And again, you can see that 
we've got a whole lot there at the bottom.  
26:58 - One other choice is jitter uniform, which makes 
them stay within certain boundaries. But it's  
27:04 - hard to tell really how much things are spread 
out there at the bottom. So I actually prefer  
27:10 - pile or I think dodge is interesting in this case. 
And so that's one way of using graph board to both  
27:17 - set it up and then to manually modify 
it by double clicking on the chart  
27:22 - can close this because I'm done with that. And 
you see I have the modified version right there.  
27:29 - Now, we can get a lot more complicated. So 
for instance, I can make a scatterplot of  
27:34 - age and income with colors for point 
density. There's a lot of options,  
27:38 - and you can explore them. This time, I'm going 
to do a little bit differently, I'm just going to  
27:42 - select this command. And again, the way I got 
these was by setting them up in the menus and then  
27:49 - simply hitting paste, and it put this index 
into this index file, so I could save it and  
27:54 - run it later. So I'm going to show you how that 
works. I've got the command here that I created  
28:00 - using the graph board template chooser. And 
I'll simply come up and select Run selection.  
28:08 - And I maximize that window. And there you can see 
I actually have what's called a hex scatterplot.  
28:15 - And it's showing a few different things. And 
it's a really neat way. So you have a lot of  
28:19 - options on the way you display things in the 
graph board template chooser. And while the  
28:24 - code is complicated, the interaction with the 
menus is really simple. He can be creative and  
28:30 - you can get different views on your data and try 
to get more insight as you're doing your analysis.  
28:36 - The next step in our introduction to SPSS 
and basic graphics is bar charts. And we  
28:41 - like bar charts for a very simple reason. They are 
simple and simple is good, or more specifically,  
28:48 - bar charts are the most basic graphic for the most 
basic data just frequencies for a simple category.  
28:56 - It's also a very basic command in SPSS. Now, 
we actually have a few options on different  
29:03 - kinds of bar charts. One, we can make a simple 
bar chart, so a single variable simply showing  
29:10 - the category frequencies in that variable, too. 
We can do a group bar chart where we break it  
29:17 - down by some other variable. And then three, 
we can do multiple variables and show the bars  
29:24 - simultaneously. But let's try this in SPSS, it's 
really easy to do, just open up this SPSS syntax  
29:32 - file, and we'll give it a whirl. Once you've 
got the file open, you'll need to open the demo  
29:37 - data set and we've used it before. This is the 
command for Mac if you're running 22 and this  
29:44 - is the command for Windows if you're running 22 
just change the version number if you need to.  
29:50 - Once you have the file open, we're going to make 
some bar graphs. Now I'm going to do it by coming  
29:55 - up here to what are called the legacy dialogues. 
These are specialized ones One graph only  
30:01 - dialogues that come from earlier versions of SPSS. 
And truthfully, I usually use these because I find  
30:06 - them so quick and easy to deal with, what we're 
going to do is we're going to make a bar chart for  
30:11 - levels of education in our sample. So I'm gonna 
hit bar, we're going to do a simple bar chart.  
30:19 - And we'll do groups of cases.  
30:25 - And all I need to do is hit level of education, 
put it into the category axis, and hit OK.  
30:35 - And I make the output bigger. There it is,  
30:39 - absolute Piece of cake. And it's also very, very 
simple syntax. You see this syntax right here,  
30:43 - it's really could be one line. And just 
as a point of comparison, here's the same  
30:52 - chart produced with the chart builder. But 
you see, we have this really complicated,  
30:57 - overwhelming code, the legacy chart produces 
an extremely simple way. So that's a simple bar  
31:04 - chart, Piece of cake. Now let's do a clustered 
bar chart for groups of cases, we'll look at  
31:09 - levels of education by gender. To do that, we 
come back up to graphs, legacy dialogues to bar.  
31:17 - And now we're going to cluster it into a level 
of education clustered by gender, I hit define,  
31:25 - get level of education, that sort of our 
outcome variable, put that under category axis,  
31:30 - and then define clusters by gender, 
I put that right there. I'll hit OK.  
31:40 - And make it bigger. And this time, it uses nicer 
colors. But you have the five levels of education  
31:47 - broken down where women are in blue, and men 
are in green. But it's really easy to see here,  
31:53 - the relationship between the two variables. 
And in this particular data set, it really  
31:57 - looks like there's no substantial difference 
between the men and women. Now, I will say  
32:01 - I believe this is an artificial data set. 
So we wouldn't expect a lot of differences.  
32:05 - But this is a nice way to compare them. By the 
way, come up, and you'll see that the code for  
32:11 - this is really simple. All it does is it adds 
by gender. So again, a very short command,  
32:19 - I'm going to go back to the syntax. And we're 
going to do one more here. And that is for  
32:23 - multiple variables. So this is a situation 
in which it can be confusing if you have  
32:31 - a lot of categories within each variable. What 
I'm doing here, is I'm going to get the means of  
32:36 - variables or the numbers of ones. If you have an 
indicator variable where 04 No, no one, four, yes,  
32:44 - this is a really nice way of comparing 
the frequencies of each one of them  
32:48 - across. I'll show you how that works. We'll 
go up to graphs, we'll come back over to bar.  
32:55 - And we're going to do a simple one. But this 
time we're doing separate variables define.  
33:02 - Then I'm gonna come down here and this data 
set. Again, which I believe is fictional,  
33:08 - asked a lot of people about various things 
that they might do. We're gonna ask them about  
33:17 - wireless service. And we're going to come down to 
whether they own a fax machine, because this is  
33:22 - old data. And it's asking about old technology 
pagers, I've never had a pager. But I simply  
33:28 - select all those variables, I put them in here. 
And as long as they're all in the same scale, it's  
33:32 - going to do the mean of each one. And on the 01, 
the mean is the proportion of one's head, okay.  
33:44 - And there we have it, it's a way 
of looking at the distribution of  
33:47 - multiple variables simultaneously. It's a very 
information dense display. And especially when  
33:53 - you're the analysts are exploring your data, 
this can be a really quick and easy way  
33:58 - of getting a feel for your data, which 
can then direct your further analyses.  
34:05 - As we continue to look at basic graphics in 
SPSS, a really common one is histograms. And  
34:11 - this is a graphic for data that is quantitative 
or scaled or measured, or interval or ratio level,  
34:19 - those really all are referring to basically 
the same thing. And in any of them,  
34:23 - you're going to want to make a histogram to see 
what the variable is like. Now, I mentioned that  
34:29 - SPSS prefers the terms scale for these variables. 
And that's what shows up in the data definitions.  
34:35 - And I like to think of it as the scales of 
justice. But why are we making a histogram? The  
34:41 - point is to see what you have to see what the data 
is like. And there's a few things in particular  
34:46 - that you're going to be looking for. Number one, 
you're going to be looking for the shape of the  
34:50 - distribution, is it uni modal, bi modal skewed, 
left skewed right? Are there gaps in the data  
34:55 - This suggests that maybe you have some important 
mechanism operating or they're out wires that  
35:00 - you would need to take consideration of before 
you do your analysis. Is your data symmetrical,  
35:06 - there are a lot of different things that you 
could look for. And some of these are going to  
35:09 - have a lot of influence on your analyses. So it's 
important to take a look at the data and histogram  
35:15 - will give you a great impression of a quantitative 
or scaled variable. We'll try it in SPSS, simply  
35:21 - open up this syntax file, and we'll see how it 
works. When you're in SPSS, most of this is really  
35:28 - just to open up the data set is the same one we've 
used in the others this demo data set. And here's  
35:33 - the code for Mac, adjust the version number if 
you need to, and here's the code for Windows.  
35:39 - But once you have the data set open, you 
can use the commands and it's really, really  
35:44 - simple. All you need to do is come up to graphs, 
we'll go to legacy dialogues. And we'll come down  
35:51 - here to the bottom to histogram. And we're going 
to make a basic histogram of age. So I click that,  
35:58 - and I come to age, it's our first variable. And 
I simply click this to move it over and hit OK.  
36:08 - Make the output window bigger. And there's our 
histogram. And from this, we can see that our  
36:13 - distribution is uni modal, we can see it's pretty 
close to normal, it's slightly skewed on the high  
36:19 - end, but not very much. And this is going to be 
a really good variable for most of our analyses,  
36:25 - because it means most of the assumptions of the 
kinds of procedures that we might want to use.  
36:30 - Now if I want to make things 
slightly more complicated,  
36:33 - because you see that the command 
for this is extremely simple,  
36:38 - we can make a small modification I'll show you 
here, we can superimpose a normal distribution.  
36:45 - And all I have to do for that is come back 
to graphs, legacy dialogues into histogram.  
36:52 - And I just checked this box right here display 
normal curve. And what that's going to do is  
36:57 - going to create the same distribution, we're 
just going to put on top of it, a line of a  
37:03 - bell curve, a normal distribution that 
has the same mean and standard deviation.  
37:08 - And here you can see, we're pretty close to 
normal. And this is a nice way of confirming that.  
37:14 - And again, the code for it is really simple. 
All it does is it adds the word normal in this  
37:21 - sentence, and that gives us everything 
we need. One of the reasons I really  
37:25 - like the legacy dialogues in SPSS, is 
because it's so concise, it's so simple,  
37:30 - and it gets you what you need. So you can 
get a grip of your data and move ahead.  
37:40 - As we continue SPSS and introduction in basic 
graphics, we should look at scatter plots a very  
37:46 - common method of looking at associations, or as I 
like to think as a way of assessing togetherness  
37:52 - in data. In other words, you want to see 
what goes with what or more specifically,  
37:58 - what variable goes with what other variable. 
So scatterplot are a great way of visualizing  
38:05 - the association between two quantitative 
variables. When you make a scatterplot,  
38:10 - there are some things you should look for. And in 
case you're wondering what they are. They include,  
38:14 - for instance, whether the association between 
the two variables is linear, because a lot of  
38:19 - the procedures that are common, assume that 
you can draw a straight line through the data,  
38:24 - you want to check the spread of the data, 
especially whether the spread changes as you  
38:29 - go from left to right, on a scatterplot. That's 
called heterogeneity of variance and it can cause  
38:35 - problems with certain procedures. You want to look 
for outliers, either univariate. That's a score  
38:40 - that's unusual on a single variable by itself. Or, 
in this case, what's even more significant is by  
38:46 - variant where you have an unusual combination of 
scores. And then finally, you want to try to get  
38:51 - some idea for the correlation or the strength 
of the association between the two variables.  
38:55 - his counterpart will allow you to do all of 
those. Now in SPSS, there are three general  
39:01 - kinds of scatter plots that you can do. Number 
one, is a simple scatter. It's a binary x&y chart,  
39:08 - easy to do. Number two is a matrix scatterplot, 
where you actually have several variables,  
39:14 - and they're simultaneously. And it's a good 
way of looking at complex associations between  
39:19 - collections of variables. And number three, SPSS 
is able to do a 3d scatterplot. But I'll have some  
39:26 - words to say about that a little bit later. But 
let's try this and see how scatterplots work in  
39:32 - SPSS, at least very basically. So just open up 
this syntax file, and we can see how it works.  
39:40 - When you open up the syntax file, we have the 
same situation where you can load the data,  
39:45 - we'll use demo dot save. And you can use this 
command if you're on a Mac using version 22.  
39:50 - And this command on Windows version 22. But 
we're just going to make a couple of scatter  
39:55 - plots and it's a really basic, easy command. 
The first thing we're going to do is make a  
39:59 - scatterplot of age and income, let's come up to 
graphs, legacy dialogues, and down to scatter,  
40:09 - want to use a simple scatter, that's just a 
basic bi variate xy chart, I'll hit define.  
40:15 - And all I need to do here is pick my 
variables for the x axis across the bottom,  
40:20 - and the y axis of the side, we're going to 
pick age for the x axis and put it right there.  
40:25 - And household income for the y axis. And the 
idea is, maybe there's an association between  
40:30 - household income and how old the person is. 
That's all I need to do, except click OK.  
40:37 - And when I get that, I get this basic scatterplot. 
So I have agent years across the bottom,  
40:44 - I have household income and 1000s of this side. 
And you can see, of course, that most of the  
40:48 - people are near the bottom. That's because most 
people make less than $200,000 a year, this graph  
40:54 - goes up to 1.2 million. We have a marker that's 
a large, empty circle, it's in black, and you can  
41:00 - change the markers. And there's things you can do 
to clean up the chart. But it's also easy to tell  
41:04 - the people who for instance, make a lot of money 
are generally older. So we can see in this data,  
41:10 - there is some kind of association between 
age and income. But let's try to get a more  
41:16 - nuanced one by looking at several variables 
simultaneously with a scatterplot matrix.  
41:24 - Come back up to graphs and legacy 
dialogues. And down to scatter.  
41:28 - This time, however, I'm going to pick matrix 
scatter, click define. And now all I need to do  
41:36 - is pick the variables I want to include, I don't 
have to specify X or Y, because they're all going  
41:40 - to serve as both x and y in different parts 
of the matrix. I'm going to pick a few here,  
41:45 - I'm going to get household income, I'll move 
it over, I will get age and move that over.  
41:52 - Okay, address yours at current address and move 
that over, I'll get reside, which is the number  
41:59 - of people residing in the house, move that. 
And then finally, I'll get level of education.  
42:07 - There's nothing especially meaningful about these, 
they're just ones that I thought would be easy to  
42:11 - look at. Now, as a general recommendation, if you 
do have one variable that is an outcome variable,  
42:18 - you might want to put that one in first, 
that puts it in the first column in the  
42:21 - first row. And it makes it easier to find 
it when you're looking at your analyses.  
42:25 - But I've got my five variables in 
there, and I just come in, press OK.  
42:32 - takes a moment. And then I come up. And this 
is the scatter plot matrix. And so you have  
42:39 - all five variables listed on the side, you 
have all five variables listed across the  
42:42 - bottom. So each one functions as both an X and 
a Y, you have empty boxes down the diagonal,  
42:48 - because that would be each variable with 
itself. And the correlation is always one. Now,  
42:54 - there are things you can do to clean this up, you 
can change the marker from a big black circle to  
42:59 - something that's smaller and easier to see you 
can put regression lines through. But it's easy  
43:04 - to see that there's some really important 
patterns. So for instance, age in years,  
43:09 - and years at current address right here, 
obviously, there's a limit, you can't live  
43:13 - someplace longer than you've been alive. That's 
why we have nothing in the top left at that.  
43:18 - But you do see some associations and some cut 
offs that go through. Now, this one's really  
43:24 - dense in a lot of situations, it's going to be 
a lot easier to see the patterns that's there,  
43:29 - especially if you change the markers and put 
in regression lines. But this gives a good idea  
43:33 - of what you can do with a scatter plot matrix. 
Now, let's go back one more time to the legacy  
43:40 - dialogues and to scatter, because you saw that 
there were other options there. There's a dot plot  
43:46 - that's like a histogram. And there's an overlay 
scatter, which I don't want to deal with. And then  
43:51 - there's a 3d scatter. And you might look at that 
you're like, oh, cool, it's interactive, it's 3d,  
43:55 - it's a great thing. I'm actually not even going to 
do it. Because every time I've done a 3d diagram,  
44:00 - I found it, it's impossible to read it clearly. 
It's very hard to manipulate in SPSS. And it  
44:07 - ends up being really a bad experience. And it's 
much easier to look at the association between  
44:13 - variables using a scatterplot matrix. That's why 
I recommend that you avoid the 3d completely,  
44:19 - even though it's available here. But avoid 
it completely. And use the BI variate and  
44:24 - the scatterplot matrices as a way of looking at 
the associations between variables in your data.  
44:31 - Once you've done the basic graphics for your data 
and seeing what you're dealing with, it's a good  
44:35 - idea to move on to basic statistics. And in SPSS, 
the most basic version of this is frequencies.  
44:42 - I like to think of it as putting things into 
buckets, and then simply counting what's in the  
44:48 - buckets. So the idea is when you have a limited 
number of categories in your data, then you should  
44:54 - just count how often each category occurs. It's 
a first step to release some significant insight.  
45:02 - But wait, I just want to mention 
that the frequencies command  
45:06 - in SPSS can do so much more than that. And I'm 
going to show you how it works. For example,  
45:13 - it can do charts. It can do bar charts and pie 
charts and histograms and normal distributions.  
45:19 - And they can do a lot of statistics beyond 
frequencies, it can do quartiles, percentiles,  
45:24 - mean, median, mode, standard deviation, 
variance, skewness, kurtosis, and so on. In fact,  
45:29 - because of this, I like to think of frequencies 
as SPSS is version of the competent man character  
45:35 - in literature and movies, who can do everything 
well. You know, somebody like Leonardo da Vinci,  
45:42 - or Iron Man who seems to be able to do everything, 
or you know, Mary Curie right here, because she  
45:48 - won two Nobel prizes, and one of the rest of us 
done. But anyhow, back to statistics. Let's take  
45:54 - a look at frequencies and let's try it in SPSS. 
Just open up this syntax file, and we'll see the  
46:00 - things that it's able to do for you. As always, 
we need to begin by opening a data set, we'll  
46:05 - use demo dot save. And you can use this command 
in Mac or this command in Windows to do that.  
46:11 - Once you have the data set open, it's a 
very simple thing to get the frequencies.  
46:15 - Now I have the syntax saved here. But really, it's 
more as a record of what I've done, because I use  
46:22 - the drop down menus to create these commands. 
So I'm going to come up to frequencies and  
46:26 - I'm going to get the frequencies for gender and 
job satisfaction. To do that, I come to analyze  
46:32 - two descriptive statistics. And then 
the first option there is frequencies.  
46:39 - And what I'm going to get is gender.  
46:43 - Just right here, I'll just double click to move 
it over. Was it good job satisfaction, I'll double  
46:48 - click and move that over. Now, what's important 
is these are two different kinds of variables.  
46:53 - Gender is a categorical variable, nominal. And 
job satisfaction here is a scaled variable. And so  
46:59 - normally, you don't do the same kinds of things 
for these. But frequencies is very flexible.  
47:04 - So I'm just going to hit OK, and we'll 
see the default output for frequencies.  
47:12 - The first thing that it shows us is how many 
valid observations are so how many of our 6400  
47:18 - cases have data on these variables? The answer 
is all of them. There's no missing data here.  
47:23 - And then it comes down. And it gives us frequency 
tables where it lists every value, or a possible  
47:29 - score on the variable, and then says how often 
each one occurs. So for gender, we have 3179  
47:37 - female respondents, that's 49.7%. And the percent 
and the valid present would be different if we had  
47:45 - missing data. But we don't, so we can ignore that. 
And then the cumulative simply adds up to 100.  
47:51 - And then job satisfaction. This is a scaled 
variable, which has 12345 as answers.  
47:58 - And here you can see how many people put each 
of the answers 17% highly dissatisfied, 21.8,  
48:05 - neutral and 19.1 highly satisfied. And 
that's a quick look at the frequencies  
48:10 - that we're dealing with. It's a nice way also 
to check if your variables are coded well.  
48:17 - But what we can do is more than that, we can also 
turn off the tables. And we can do bar charts  
48:24 - using the frequencies command. So I'm going 
to keep those same two variables, gender and  
48:28 - job satisfaction. But this time, I'm just going 
to make bar charts. I'll go back to my recent  
48:34 - commands and frequencies. And what I'm 
going to do is I'm going to click this,  
48:40 - it's going to give me a little error message 
because I haven't changed the other thing. First,  
48:44 - I'm going to come to charts right here. 
I tell it to make bar charts, obviously,  
48:48 - you can make pie charts and histograms as 
well. I'll click Continue. And then click OK.  
48:58 - And now the same general command 
frequencies is not producing tables,  
49:03 - but it's producing charts. And here 
you can see that we are very closely  
49:06 - mess in terms of the number of 
male and female respondents.  
49:10 - And here you can see job satisfaction sort of 
peaks at neutral and somewhat satisfied. So that's  
49:15 - a really nice thing. You don't even have to use 
the bar chart command, you can do it right here.  
49:23 - You can also get more kinds of statistics 
in there. So for instance, this one,  
49:30 - I'm going to keep the tables off when I'm going to 
ask for a few extra things. In fact, let me just  
49:35 - come back to this one. We're going to analyze, 
descriptives and frequencies. And this time,  
49:45 - I'm going to do age, reside and job set. So I'm 
going to remove my one categorical variable here.  
49:54 - Just reset that I'll do age or 
the other to resign. And job set.  
50:02 - And then I think that's this one right here. 
Then we'll come down to job satisfaction.  
50:08 - And we'll move that over. So I have three 
variables, but they're all scaled variables.  
50:12 - What I'm going to do here is first 
I'm going to come to statistics.  
50:16 - And I have a really an impressive range of 
things I can get, I can get the mean, I can  
50:22 - get the median, the mode, if you want the mode, 
I think this is the only place to get it in SPSS,  
50:27 - I can get core tile values. Now it doesn't do 
the minimum and the maximum, you have to select  
50:33 - those separately down here. But you can also get 
cut points. Now, a cut point an interesting one.  
50:42 - The quartiles are cut point, it splits the data 
into four equal sized groups with the same number  
50:46 - of people in each. Sometimes you want something 
other than that. So for instance, I know that  
50:50 - if you're doing propensity scores, it's not 
uncommon to use five equal groups quintiles.  
50:56 - And also, there are situations in which you 
want not the most extreme scores, but near the  
51:01 - most. And so I'm going to put, for instance, 
the 2.5 percentile. And the 97.5 percentile,  
51:09 - because those frame the middle 95% of the 
data, I can also get the standard deviation  
51:15 - and the variance sentence or anything else I 
want right here. I want skewness and kurtosis.  
51:23 - I'm gonna hit continue, then I'm going to 
come back to this one, I'm going to turn  
51:27 - off the frequency tables, because otherwise, I 
have a lot of different possible interest here,  
51:31 - I'd have a lot going on. I'll hit charts. And 
this time, I'm going to ask for histograms. And  
51:36 - we'll put a normal curve on top of each 
histogram. Click Continue. And click OK.  
51:47 - And so here's what we get. It starts with 
the statistical output, here are the three  
51:52 - variables I selected, it gives us the mean, 
the standard deviation, the variance, skewness,  
51:57 - and standard error of Skewness kurtosis. 
We have the minimum and maximum scores. And  
52:02 - then the percentiles. Now it's a funny list here, 
because I've got three things intermingled, I have  
52:07 - the core tiles, that's something I asked for. So 
we have the 25th percentile, the 50th percentile,  
52:12 - and the 75th percentile. Those are the core tile 
values. I had the minimum and maximum up here.  
52:17 - So those are the zero and 100% courthouse, but I 
also asked for quintiles. And so that's puts it at  
52:23 - 20 4060 and 80%. And then finally, I manually 
entered the two and a half percentile,  
52:31 - and then 97 and a half percent. And so they're all 
put there together, but it's really easy to see  
52:37 - the changes in the distribution. Beneath that 
we have the histograms and we have each variable  
52:43 - has its own histogram, along with a normal 
distribution with the same mean as standard  
52:48 - deviation laid on top age is pretty close to 
normal. Here's the current address, however,  
52:53 - you can see is really skewed because most people 
haven't lived there that long. And then finally,  
52:58 - job satisfaction is a little flatter than we would 
expect if it were normally distributed. The point  
53:04 - of this is that I'm able to do a tremendous amount 
of statistical and graphical work using a single  
53:09 - command the frequencies function in SPSS, one 
of the most versatile commands you'll ever use.  
53:17 - In our previous movie, we looked at the power of 
the frequencies command, but for basic statistics,  
53:22 - another very common choice is descriptives within 
SPSS. The nice thing about descriptives is it  
53:28 - allows you to achieve maximum density. That is 
how to get a lot of numbers on a lot of variables  
53:36 - in just a little space. That's what descriptives 
is really good for. On the other hand, there is  
53:42 - a restriction, it works only with numerical 
variables. But that's a lot of the data that  
53:47 - you might have. And if you have that, it can give 
you things like the mean the sum, the standard  
53:53 - deviation, the standard error, the variance, 
the minimum and maximum, the range, the skewness  
54:00 - and kurtosis. Now, I say that Guess what, you 
know, in case you don't remember frequencies  
54:07 - does more, but that's okay. There's certain 
things that the descriptives command does well,  
54:13 - here's what it does well, first, it gives 
you a very concise compact tabular output.  
54:20 - So it's really easy to see a bunch 
of information in a small space.  
54:25 - Second, it's a really quick way to find 
obvious errors in coding in your data. Finally,  
54:33 - you can get proportions for indicator variables 
as 01 variables and I'll show you how that works.  
54:41 - Also, we have a bonus feature here in 
descriptives. descriptives is the home  
54:45 - of SPSS is top secret hidden one step Z score 
procedure. I've seen people knock themselves  
54:52 - out trying to get z scores by getting standard 
deviations in means you don't have to do any  
54:56 - of that you click one button and you're done. 
But let's try it in SP SS and I'll show you how  
55:00 - it works. Just open up this syntax file, and 
we'll see what you can do with descriptives.  
55:07 - We'll begin as always, by opening the dataset, 
we'll be using demo dot save, here's the path on  
55:13 - a Macintosh, it running version 22. And the path 
on a Windows also running version 22. This is  
55:20 - my first command, and it looks really long. But 
that's because I have a lot of variables in it.  
55:24 - All we need to do is come up to analyze, to 
descriptive statistics, and descriptives.  
55:32 - We click on that. Now one of the things it does 
is it only shows you the variables that it can  
55:38 - analyze. So gender, which was a string variable, 
meaning it had just text that's not in there.  
55:43 - But what I can do is I can just select all of 
them and do a command or control a, and then  
55:50 - move everything over. And then I'm just going 
to do the default analysis. I'll just hit OK.  
55:58 - And here's our output. We have 
a whole bunch of variables,  
56:02 - and it tells us first, the number of 
observations is 6400. Almost all the  
56:08 - way down this question about internet is missing 
some data. But that appears to be the only one  
56:15 - we have the minimum value and the maximum value. 
By the way, this is where I talk about quick and  
56:20 - easy data checking. If you have a variable that's 
only supposed to go from one to five or zero to  
56:25 - one, if you have a 17, you know something's wrong. 
And so by simply checking the outer boundaries,  
56:31 - that's a fast way seeing if there are any really 
obvious errors, we also have the mean and the  
56:36 - standard deviation to the things, you generally 
need the first two moments of a distribution.  
56:41 - And so that's a lot of information. And it's in 
a very concise format. That's a wonderful thing.  
56:48 - If we go back to the syntax, I do want to mention 
this one thing about indicator variables I said it  
56:53 - earlier, is this. If you have indicator variables 
that a binary or dichotomous variable that has  
57:00 - only two possible values, and if that variable 
is coded as zero and one, then you can in fact,  
57:07 - get the mean of it, and it tells you something 
that tells you the proportion of observations  
57:12 - that have once. And this works best if you use the 
standard programmer format, zero equals false or  
57:19 - no. And one equals true or Yes. And strangely, 
in this particular data set, that's true for  
57:26 - most of the variables, but not the last one or 
two and demo dot save. And I have no idea why they  
57:31 - switch that. But it's something that you want to 
check in the coding before you go ahead and do it.  
57:36 - So if I go back to the output, you can see for 
instance, that most of these wireless service down  
57:43 - through owns fax machine, those are all zero ones 
were zeros, no. And one is yes. The mean right  
57:50 - here tells us that 99% of the people own TVs, 
nine six own VCRs because this is a long time ago  
57:58 - that 25% had paging services. And I like 
this one, where's the internet on this list?  
58:06 - 27% of the internet because this was apparently 
generated and like, you know, 1990 who knows what?  
58:13 - Anyhow, those are meaningful data points, the 
mean tells you that proportion of ones or yeses.  
58:20 - I'll go back to the syntax here. And 
then let's take a quick look at the Z  
58:25 - scores. Now any reasonable person would 
think that Z score is a transformation of  
58:30 - the data and therefore it would be under the 
transform menu. But you know it's not there.  
58:36 - Instead, it's hidden as an option and 
descriptives. So let's go back to descriptives  
58:45 - unless you age in income, 
so I'm going to reset this.  
58:48 - I'm going to pick age. And I'm going to pick 
household income. And I'm going to get both of  
58:54 - these z scores because a lot of procedures work 
a lot better if you have z scores. All you have  
58:59 - to do is this. Click Save standardized 
values as variables. And if I hit OK.  
59:11 - What it's done here is it gives me the 
descriptives because I actually still  
59:15 - ran the descriptives command for those 
two variables. But more significantly,  
59:18 - let's take a look at the data set. When I come 
to the data set, if I scroll to the end here,  
59:27 - I have two variables that 
were not there previously z  
59:31 - age, pansy income, and they have lots of 
decimal places because you need those z scores.  
59:38 - Now, I'm refreshed. Now under normal 
circumstances, you would want to save this  
59:43 - into the data. I'm not going to do that because 
this is one of SPSS built in default data sets.  
59:48 - But I do want to show you that we can do 
one other thing here. Let's go back and  
59:52 - get descriptives for those z scores. So 
I'm gonna come to analyze, descriptives.  
59:58 - I'm going to reset this Come down to see our two 
new variables. I'll select do a little shift click  
60:06 - to get both of them and pop them over here, then 
I'll hit OK. And as you would expect, a z score  
60:16 - has a mean of zero, and a standard deviation 
of one. And we didn't have to do it manually,  
60:20 - we didn't have to remember any values, we didn't 
have to round things off and did exactly for us.  
60:25 - And so that is what the descriptives command 
does, it makes a very concise tabular output.  
60:31 - And it also allows you to save standardized 
or z scores for use in certain procedures.  
60:38 - For a final look in SPSS at basic statistics, 
we'll look at the Explorer command.  
60:44 - I like to think of this as a way to get a lot 
closer get a little macro view on your subject,  
60:49 - get closer and see what's there in detail. 
Now, the Explorer command is going to give  
60:54 - you a bunch of statistics, it can give you the 
mean and the confidence interval for the mean.  
61:00 - And the trimmed mean, as well as the variance, 
the standard deviation, the interquartile range,  
61:06 - the minimum and maximum, the range skewness. 
kurtosis, is a collection of M estimators,  
61:13 - which are special robust ways for 
measuring the center of a distribution.  
61:18 - percentiles, which we've seen before, and lists 
of outliers can also give you a collection of  
61:26 - plots. It's the one place in SPSS that you can 
get a stem and leaf plot. Now, traditionally,  
61:31 - those are things that are drawn by hand. So 
it's kind of cute to see a computer do them.  
61:37 - You can also get box plots, 
and you can get histograms.  
61:41 - And you can get a set of normality plots, 
such as a QQ plot or a detrended QQ plot.  
61:48 - And the neat thing after that is you can break 
all of these analyses down by groups. So let's  
61:53 - try it in SPSS and see how it works. Just open up 
this index file. And we'll run through the various  
61:59 - procedures and explore and see how it can add 
up to your own analysis. As always, we'll begin  
62:05 - by opening the demo dot save data set. Here's the 
command for a Mac, here's the command for Windows.  
62:13 - Now, again, I'm saving this as syntax that 
makes it repeatable, and it means that you  
62:17 - can download it and try running it on your own. 
But I created all this by using the menu commands.  
62:23 - Let's start by doing a default explore analysis 
for a couple of variables. I'll come up to  
62:29 - analyze, to descriptives, and then we'll come over 
here to explore. And what we're going to do is age  
62:40 - and income category. And again, this is kind of 
interesting, because these are different kinds  
62:47 - of variables. Age is a scalar variable. 
And income category in this case is an  
62:52 - ordinal variable. I'm just going to leave 
all the defaults as they are and hit OK.  
63:01 - And here's what we get from this. 
First, we find out whether there  
63:04 - were any missing cases there weren't in this 
situation. And then we get a collection of  
63:09 - descriptive statistics for these we have 
first for age, then for income category,  
63:14 - we have the mean with the standard error, the 
confidence intervals, the 5%, trimmed mean,  
63:20 - median, variance, standard deviation, minimum 
maximum range, Interquartile, range, skewness,  
63:25 - and kurtosis, along with their standard errors. So 
there's a lot of information there. And we scroll  
63:30 - down we find the same kinds of information 
for income category in 1000s. Now remember,  
63:37 - some of this you wouldn't normally want to 
use because income category in this case  
63:40 - is not a scaled variable. And a lot of these 
things like minimum maximum and trim mean work  
63:45 - best with a scale variable. But SPSS is able to 
kind of run it on everything. So interpret with  
63:51 - caution. Then we come down and look we have a 
stem and leaf plot, where this is age, which  
63:58 - in our sample is two digit numbers. And so this 
means 118. And each of these leaves, each of these  
64:06 - numbers over here is the leaf that represents 
10. cases. Remember, we have 6400 cases,  
64:12 - we have about 640 numbers right here. And you 
can see for instance, that the 30s appear really  
64:18 - common late 30s. And that we go up to somebody 
in their late 70s. And so that's an easy way  
64:26 - to see what's going on. Simultaneously, we 
get a boxplot. And the nice thing about this  
64:32 - as you can tell really quickly if there are no 
outliers on age, not in this particular data set.  
64:38 - We do the same thing with income category. 
And the stem and leaf plot looks funny,  
64:41 - but that's because there's only a few possible 
values one or two or three or four. And  
64:47 - it's drawing it so it looks a little weird. 
But we can come down and get the boxplot as  
64:52 - well and see there's no outliers, at 
least on this kind of variable. Again,  
64:56 - not normally something you would do with a 
rank order variable. But it's possible here.  
65:04 - Now the neat thing is there are additional 
statistics. I'll do the same to statistics.  
65:09 - But I'm going to go check off a lot of options 
that I have right here. So let's go back to that  
65:15 - dialog, I'll go to explore. What I'm going 
to do is I'm going to say, just give me the  
65:21 - statistics right now. And I'll come up here, 
and I'll make some selections. One thing,  
65:26 - although 95% confidence intervals 
are by far the most common,  
65:31 - I have seen significant situations where 
people use 80% confidence interval,  
65:35 - so you can change it if you want. Then I can get 
all of the estimators. It's a whole collection,  
65:41 - I can get a list of outliers and a list of 
percentile values. I hit Continue. And I click OK.  
65:51 - And now we have the same table we had before. 
That's their descriptives up their top,  
65:56 - then we have the M estimators. And this is 
for different robust measures of center.  
66:01 - Again, all of them are trying to give us something 
equivalent to the mean. And you see in this case,  
66:06 - huber's estimator, turkeys by weight 
handles, estimator, and Andrews wave,  
66:11 - the numbers are all pretty similar. I mean, it 
goes from a low of 41, point 18 to high 41.5  
66:17 - to four, they're all really close. And each of 
these has specific parameters that go into them,  
66:22 - you can't adjust them in the dialog box. But 
let me just return to the syntax for one second.  
66:29 - You see here, these are the parameters for each of 
the EM estimators, you could change them here, if  
66:34 - you want to do. I'll go back to the output. Then 
we have percentiles 510 25, up to 95. And then  
66:43 - it gives us the case numbers for the highest and 
lowest five cases on each variable. And so this is  
66:49 - a really nice way of seeing a multi dimensional 
picture of our data. Now in terms of pictures,  
66:57 - and even better ways to do this with more graphs. 
So let me go back to the syntax for a second.  
67:03 - And you see that we can get some additional plots, 
I'm going to use age and income category again.  
67:09 - But I'm going to change that what it tells us. 
So first off, I'm going to say give me just the  
67:15 - plots, we're not going to get any statistics, 
I'm coming to the plots menu, I say well,  
67:21 - we have a stem leaf by default, let's get a 
histogram. Let's also get normality plots. That's  
67:26 - a way of assessing how closely your data match a 
normal distribution. I'll hit Continue. And Okay.  
67:39 - Now I have a histogram for age, the stem 
and leaf plot. But this one here is normal.  
67:46 - But this one here is new. It's a normal qq 
or quantile quantile plot of age in years.  
67:52 - And if it were normally distributed, all of 
these circles would fall exactly on this line.  
67:58 - You see, it's really close, but it does deviate 
at each end. And then a D trended one takes that  
68:03 - line sort of flattens it out, and it's much easier 
to see where the changes are. Now I know it looks  
68:08 - really big in this case, but this variable is 
in fact pretty close to normal distribution.  
68:14 - Then we have our boxplot. And then we do the 
same thing for income, we start with a histogram,  
68:23 - our stem and leaf plot. And 
our normal QQ plot, again,  
68:27 - a little weird, because there's only four possible 
values in this data set. But they all fall pretty  
68:31 - well on the line. And there's our D trended plot. 
And then finally, the bot file that we saw before.  
68:39 - Now there's one more thing we can do with the 
Explore command. And that is we can take some  
68:43 - of these analyses and break them down by groups. 
So if we go back to the syntax, we'll see I'm  
68:49 - going to do income and break it down by gender. 
Let's go back to the menu here. But explore.  
68:57 - And I'm going to reset this. And we're 
going to take income, and put that into  
69:03 - our dependent or outcome variable list or the 
thing that we're pretending to predict. And  
69:07 - then we'll take gender scroll down a little bit, 
there's gender and put into the factor list. Or  
69:12 - sometimes people call it independent variable. 
So that's if it's an experimentally manipulated  
69:16 - variable for the predictor variable. I'm going 
to come up here and I'm actually going to skip  
69:21 - the statistics and get plots only. I don't want 
a stem and leaf but I will get a histogram on  
69:28 - get the normality plot. And now because I'm 
breaking it down by groups, I can check the  
69:32 - spread versus level with Levine's test. The 
idea here is that the data should be spread  
69:37 - out approximately the same amount for each of the 
groups so we can compare them using some uniform  
69:42 - statistics. I'm going to do what's called a power 
estimation here, click Continue. And then okay.  
69:54 - And now what we get is, again, is a list of the 
number of cases that have complete data and then  
69:58 - all of them do that With no missing data, 
we have a test of normality. And what we  
70:03 - see here is based on both of these, that 
the data for neither group is normal.  
70:09 - That's okay, because we knew that 
income was strongly positively skewed.  
70:15 - As for homogeneity of variance, whether the two 
groups have about the same variance or spread,  
70:22 - you know, there is some difference, but they 
are not statistically significant. And so it  
70:26 - appears to be the same for the men and the women, 
which is good in this particular data set. And  
70:30 - then we can come down and see the histograms first 
for women. And you see, it's got a really strong  
70:35 - skewness there. And the same thing, again, for men 
really strongly skewed, then we get the normal qq  
70:45 - or quantile quantile plots. And again, if it 
were normally distributed, all of these points  
70:50 - would fall right on this line is strongly skewed. 
And so we have this really big bend in the data.  
70:56 - The same is true for men. And here's the 
detrended lines, where they should all be  
71:01 - flat on that lines too, as you get this swoosh 
Mark instead. So it just confirms that we're  
71:06 - not dealing with normally distributed data 
they want you to have is this big collection  
71:12 - of outliers in the box plots, I'm going to do 
one thing, I'm going to double click on this.  
71:18 - And then I'm going to come right up to here. 
And this will turn off the data labels so we  
71:22 - can get rid of the ID numbers. And you can 
see that we have a lot of outliers in both  
71:28 - demand and both the women and there's no really 
obvious differences between the two groups.  
71:34 - And the spread versus level plot is something 
that you can use if you have multiple levels,  
71:40 - that it can help you select a 
kind of power transformation,  
71:44 - a square root or reciprocal, a square, something 
like that. But that's a more complicated topic  
71:50 - and something for another day. And besides, 
it appears that we have relatively homogeneous  
71:55 - variance in the two groups. So we'd be good to go 
ahead and do our other analyses. So those are some  
72:00 - of the options and explore. And that's where 
we'll end our discussion of basic statistics,  
72:05 - we can see how they can be used to see how well 
your data meet the assumptions of the procedures  
72:10 - that you use, and then really, how well you can 
make inferences from your sample to other groups.  
72:19 - When you're working in SPSS, 
and you're accessing data,  
72:23 - one of the most important things you can do is 
to create labels and definitions for your data.  
72:29 - I like to think of this as the statistical 
version of Alice in Wonderland and the caterpillar  
72:34 - asking her to explain herself, you need to explain 
yourself or more specifically, when it comes to  
72:40 - your data, you need to tell SPSS, what do your 
data mean. Now, that is the data description,  
72:49 - and I see two kinds of information that you 
tell SPSS about your data. The first one I'm  
72:55 - going to call semiotics, which comes from the 
study of meaning. This is where you tell SPSS,  
73:02 - what the variable names are the data types, 
the variable labels, the value labels,  
73:08 - the missing values, the level of measurement, and 
the role that each variable plays. contracted with  
73:14 - that there are other elements that even call 
aesthetics. And that addresses variable width,  
73:20 - decimal places, column width, and alignment. And 
these are all settings within the data window of  
73:28 - SPSS. One of the most important though, at 
least for human consumption is going to be  
73:33 - the variable and value labels. And so I'm going 
to take a little time and talk about those  
73:38 - with the variable names. That's what the short 
names the ones that you have there at the top  
73:43 - of the column, there are some important 
rules. So the rules for variable names.  
73:48 - Number one, the names must be unique. No two 
variables can have the same name, that shouldn't  
73:53 - be too surprising. It's an identifier. Rule 
number two, the names must start with a letter.  
73:58 - I put an asterisk there because you can 
start with an ad a pound sign or $1 sign,  
74:04 - but you don't want to because those are generally 
reserved for special functions within SPSS.  
74:10 - Rule number three names can use letters, upper or 
lowercase, they can use numbers, and they can use  
74:17 - period underscore at pound dollar sign, on the 
other hand, don't end with a period that can  
74:23 - cause confusion with the command Terminator. And 
don't end with an underscore because that's used  
74:27 - for automatic variable names when SPSS is doing 
computations. Rule number four names cannot  
74:33 - include spaces. And rule number five names must be 
less than 64 bytes. And most text coding systems  
74:43 - that 64 characters, but if you're using a 
Unicode system that might be only 32 characters.  
74:49 - And the last rule rule number six is the names 
cannot be any of these words all and by eq GGTL,  
74:56 - e, lt and E not or two or with Because those 
are all reserved function names within SPSS,  
75:04 - so don't create that confusion. So those are the 
short names that go at the top of a variable.  
75:10 - On the other hand, the label that you associate 
with that you can give it a more descriptive name.  
75:16 - Those are the variable labels. And so there 
are a few rules for those. Rule number one,  
75:21 - they must be less than 256 bytes. That actually 
means it could be really long, although you don't  
75:26 - usually want to do that, because some procedures 
will display as few as 40 bytes 40 characters,  
75:33 - and you really want to be able to read what it 
is. So you want to keep it short. But you can go  
75:38 - longer if you need to. Rule number two, the labels 
must be enclosed in quotes, although on tell you  
75:44 - they need to be straight quotes, the vertical 
ones, and not the curly quotes are SPSS chokes  
75:50 - on those. Rule number three labels can include any 
character, including spaces, which is something  
75:55 - that you can't have the variable name, but you can 
put it here. So that allows you to put labels that  
76:02 - sort of float on top of the variable names. 
And those can show up in the variable lists,  
76:07 - they can show up in the charts in the output 
that you create. Another really important one is  
76:12 - value labels. So you may have a variable called 
gender and you may put zeros and ones. But do you  
76:19 - remember what those zeros and ones are. And so I'm 
going to show you some ways of dealing with that.  
76:23 - The most important thing is to put value labels 
on there. So here are the rules for value labels.  
76:29 - Rule number one, they must be less than 121 bytes. 
So that actually is really long, you generally  
76:35 - want to keep your labels pretty short. Rule number 
two, like the variable labels, the value labels  
76:41 - must be enclosed in quotes, and they need to 
be the straight quotes and not curly quotes.  
76:46 - Rule number three labels can include any 
character including spaces, that's good.  
76:52 - This is an interesting one. And rule number four, 
the value labels do not need to be unique, that  
76:57 - is more than one value can have the same label. 
So you might have the numbers one through nine.  
77:05 - And it could be that 789 all say the same thing. 
But they underneath have different code interest  
77:12 - situations where you might want to do that. But 
mostly, I want to show you how this works in SPSS.  
77:18 - So just open up this syntax file. And this one's 
going to be a little different, cuz we're actually  
77:23 - not going to use a data file, I'll refer to one 
but I mostly just want to show you the syntax.  
77:29 - This index file shows how to write variable labels 
and value labels. Now, you don't necessarily have  
77:37 - to put them all broken down in lines, I do 
it because it makes them a lot more readable,  
77:41 - it's a lot easier to see what's going on. The 
first thing is the command variable labels.  
77:46 - Because it's an SPSS command, it's written on all 
capitals. And then what you do is you write the  
77:52 - short name of the variable. And then you have at 
least one space and then you have straight quotes,  
77:58 - and then the long label. So here, for instance, 
I've got vair 01, that would be the first  
78:05 - variable. And then this is its label written out. 
And you don't need to have anything after don't  
78:11 - need any commas or question marks or semi colons 
or anything. You just go to the next one. Now I  
78:17 - put it into another line, because that makes it 
easy to follow. And I run them all through here,  
78:23 - I'm going to make one important recommendation. If 
you have a dichotomous variable or binary one that  
78:28 - has only two possible values, and gender might 
fit into that category. Let me recommend this,  
78:34 - that you coded as zeros and ones. A lot of people 
use ones and twos, but that gets confusing if you  
78:38 - coded as zeros and ones, and named the variable 
after whatever the one is. Now, when it comes to  
78:45 - male and female, I generally give one to whichever 
group I think's going to have the higher score on  
78:50 - my main outcome variable, so it'll switch around. 
But if for some reason, I think that men are going  
78:56 - to have a higher score on an outcome variable, 
then I will call it male and then the label will  
79:02 - be are for respondent is male. On the other hand, 
if I think women are going to have a higher score,  
79:07 - then I will call the variable female and the label 
will be RS female, I would obviously only use one  
79:13 - of those two. Now here are some other examples. 
I tend to give generic names such as variable  
79:21 - or really just q for question q one q two, and I 
use the leading zeros so they store it properly  
79:27 - in the dialog boxes. And when you're done listing 
all of your variable names and the variable labels  
79:35 - and quotes, just end with a period doesn't have 
to be have a space before it that's leftover from  
79:40 - earlier versions of SPSS. It's a habit I have. So 
you can run this at any time and it will assign  
79:47 - these labels to the variables and then they'll 
show up in the data file which is nice.  
79:53 - Next are the value labels. And what you have 
here is the first command Which is written  
80:00 - in all caps. And then you give a list 
of variables to which the values apply.  
80:07 - And you can list them out separately, very 
one very two. Here, I've got a VAR three  
80:12 - without a leading zero. And then if they're 
all next to each other, if they are adjacent,  
80:19 - they can actually specify ranges vair, three, two, 
and capitals, very tan, so that'll do 345678 910.  
80:27 - And then you just go to the next line, 
and you give the first value that is zero,  
80:33 - and then I give zero equals No, and one equals 
Yes, when you're done giving the values need to  
80:39 - put a slash, so it knows you're done 
with the values for that variable,  
80:43 - then you can go on to the next variable. I said, 
for instance, if I gave one on a gender variable  
80:50 - to men, I would call it male. And so zero, which 
would mean No, they're not male, would be female  
80:57 - in one, yes, they are or true, that would be male, 
and do a slash. On the other hand, if you coded it  
81:03 - the other way, and then you just call it female 
and zero, which means no or false means they're  
81:07 - not female, they're male, one means they are fine. 
Obviously, use just one of these, I do the slash.  
81:14 - And then I could have a rating variable, say, for 
instance, a lot of people call it a Likert scales,  
81:20 - just a rating scale. And I could do rate 01, to 
rate 10. And I can specify every value. So this  
81:28 - is a five point scale from strongly disagree 
to strongly agree, finished with a slash,  
81:34 - or maybe you have a different kind of scale. Here 
at the end, I have scale 01 through scale 02.  
81:39 - That's an 11 point scale, but I only mark the two 
ends, the zero and the 10. So zero is never or not  
81:46 - at all 10 is always completely. And then to let 
SPSS know that I'm done specifying value labels,  
81:53 - and with a period. So this is actually a 
single sentence. And it's a way of telling it,  
81:59 - how you want the numbers to appear, both in the 
data window, and in any output that you get.  
82:07 - Finally, I'll mention something about 
missing values, because it can also be  
82:10 - easier to specify these in syntax, the command 
is missing values. And you just give the names  
82:18 - of the variables and you can use two in the same 
way. And then in parentheses, you put the number  
82:24 - that is assigned to missing values. 99 is 
common. So I've got that there. And then you  
82:30 - can do a slash if you're going to use different 
codes after that, I could do male through female.  
82:35 - And here I say two through high. And really what 
that means is anything other than a zero or a one  
82:41 - is missing. So if I accidentally type in a seven, 
you know it's missing. And then here I specify  
82:47 - several different values, I can put seven comma 
eight, comma, nine. So if any of those show up,  
82:53 - those would be considered missing values, do 
what you want. The nice thing is it will exclude  
82:58 - them automatically from analyses. But it will 
include them in frequencies when you're getting  
83:02 - that output finished with a period. And then you 
just run these like you do any other command.  
83:09 - And it's going to do a lot to clarify your data 
and make it easier to follow your analyses and  
83:13 - reconstitute your work in the future. When you're 
working in SPSS, and you're trying to access data,  
83:23 - you may get the idea of entering data. Well, 
let me tell you my thoughts. You want to enter  
83:28 - data in SPSS, I just see it as an exercise in 
frustration. It's a pain to do it manually. And  
83:36 - I'd say maybe you're entering 10 or 12 numbers, 
you know, basically, nothing is something that's  
83:42 - often referred to as a toy data set. Maybe you 
could do that. Now, it's also possible to copy  
83:49 - and paste data, but I'm gonna say sort of because 
it doesn't work really well, I'll show you that.  
83:54 - It's much, much easier to just import 
the data from a CSV file or txt file. And  
84:00 - I'll show you how to do that in the next 
section. But in terms of entering data,  
84:05 - let me show you how it works in SPSS, we'll 
just open up a blank document. And we'll try  
84:10 - it. So here's a blank data window in SPSS, I 
can come right here and I can enter a number.  
84:19 - And, you know, unfortunate if I press tab, it 
actually goes down, which is an unusual behavior.  
84:25 - And you see it gives it an automatic variable 
name very 00001. Well, if I want to move sideways,  
84:31 - I actually need to move the right arrow key. 
So I'll go this way to three, and so on.  
84:37 - And then I can hit return, and it goes down. I'll 
come back to here and I'll go 456 I'll hit tab and  
84:45 - it comes back to the beginning. So it's not the 
most intuitive behavior plus you see it gives  
84:51 - it these generic names. That's because you can't 
enter the variable name directly in this window.  
84:56 - Instead, what you have to 
do is go to Variable View  
84:59 - How to get there by just double 
clicking on the variable name.  
85:04 - Here we go. And you can enter the variable name 
and you can change other things you want to do.  
85:10 - It works, but it's a pain. I'm going to come 
back here to Data View. Now, I mentioned you  
85:15 - can important data sort of. So let me show you 
how this works. I'm actually going to go to  
85:21 - a Google Sheet that has nothing in it at the 
moment. And here, I'm going to enter a few values,  
85:30 - I have a few different kinds, I'll do 
5643. And I'll enter a number j, return.  
85:44 - Okay, so there's some data, I've 
got two digit numbers, and I have  
85:49 - letters, which will be string variables 
in SPSS, I'm going to copy those.  
85:57 - And we'll see how well they paste over 
in SPSS. So I'm going to go back there.  
86:02 - I'll come over here to the side. And I will paste 
those in. And you see that the values came in and  
86:12 - showed up with decimal places, and I can get rid 
of that. But it's really weird with the string  
86:16 - variable with the letters and so you can copy 
it. Notice also, I can't copy in variable names,  
86:25 - I still have to enter those in manually, you can 
deal with those when you import. But really, this  
86:30 - is a demonstration that putting stuff manually in 
SPSS, it's not a good environment for that. Use a  
86:37 - spreadsheet, use Google Sheet, use numbers, use 
Excel, anything, enter it there and then import  
86:44 - it. I'll show you that in the next section. And 
you'll see that it's a much, much easier process.  
86:52 - The last thing I want to say in SPSS about 
accessing data is about importing data. And  
86:58 - you know, compared to entering it manually, it 
just makes me feel like this and I resorted to  
87:04 - cheesy clipart to show how happy I am. Because 
no doubt about it. Importing is absolutely the  
87:10 - best way to go if you want to get data into SPSS. 
Now the nice thing is SPSS can open text files,  
87:17 - it can open CSV or comma separated value files, 
and even XLS. x that's Excel files, as long as  
87:25 - they're formatted right. Now, what do I mean 
by formatted right? There's a term from Hadley  
87:32 - Wickham in the our developer community tidy data 
and it's referring to something very specific.  
87:38 - It says that your file should have only one sheet. 
So that's one worksheet even though Excel can take  
87:42 - more than that, that each column should be exactly 
equal to one variable. And that each row should be  
87:49 - equal to one case. And an important thing is no 
funny stuff in your Excel sheet. Because Excel  
87:57 - is very flexible. And when I refer to funny stuff, 
I'm talking about things like macros, and formulas  
88:04 - and graphs and formatting and comments or merge 
cells, or headers, taking up their own rows or  
88:11 - duplicating row numbers. You don't want any of 
that, basically, you want to treat it like a CSV  
88:17 - file. And if you do that, then you find you can 
import it very easily into SPSS. And in fact,  
88:23 - let me show you how this works. We're going 
to try this in SPSS, but I want you to do two  
88:27 - things. First, I want you to download the course 
files. And that will include a zipped folder by  
88:34 - this name that ends with data sets, that's going 
to have three files inside it. I'll show you those  
88:40 - in just a second. And then you can also open 
up this syntax file that will work with them.  
88:46 - But let's go to see what's inside the folder and 
explain a little bit what's going to happen here.  
88:53 - The folder that I've asked you to download 
contains three different files. Now, I have both  
88:59 - the folder here, and I have the three files saved 
separately next to it, but normally they would be  
89:04 - inside it. But for the syntax to work properly, 
you want them sitting separately on the desktop.  
89:10 - All three of them contain the same data. It says 
MBB, which stands for Mozart, Beethoven and Bach,  
89:16 - because this is Google Trends data about the 
popularity of search for each of these three  
89:22 - composers names since 2004. This first one 
is in CSV or comma separated value format.  
89:29 - The second one is a plain text file, and 
it's tab separated. And the third one  
89:36 - is an XLS. x file. So it's an Excel sheet. And 
you can see it's the same number but it appears  
89:41 - a little bit differently when I do the quick view 
here on my Macintosh. What we're going to do then  
89:47 - is open up the syntax file. And we're going to see 
what we need to do to import each of these. Now.  
89:54 - I've saved this syntax, but the fact is, it's 
easier to do this stuff through the menus. Now  
90:00 - I give some information here about using the 
file path. In each of these syntax commands,  
90:06 - I have to specify the file location. Now, this is 
the format. If you're on a Macintosh like I am,  
90:13 - of course, you'll want to change Bart to be 
the name of your home directory. If you're  
90:18 - on a Windows computer, you're going to need to 
change it to something a little more like this,  
90:23 - or possibly depending on the version of your 
operating system using backslashes instead.  
90:29 - Anyhow, I'm going to show you how to import each 
of these. And I've got the duplicate information  
90:36 - here in the script, in case you want to run it 
that way. But it's actually really easy to do it  
90:41 - from the menus. So here's what I'm going to 
do, I'm going to come up to my data window,  
90:47 - I'll just click over to that. And my data window 
is empty right now. I'm going to go to File,  
90:54 - Open, and data, you do that if you're opening 
an existing SPSS file, or if you're importing  
91:00 - something in a different format. Now here, I'm 
on the desktop, you can see my folder there. But  
91:05 - you can't see the three data files I have next 
to it, because right now, it's only going to  
91:09 - display files that are in the dot save. That's the 
SPSS proprietary data format. I'm going to click  
91:15 - on that, and come way down here. And we'll start 
with the text file the txt version. I'm going to  
91:22 - hit that and now you can see that it's there. 
I'll select that file, and I'll click Open.  
91:33 - So now I have the SPSS text import wizard. And we 
can scroll through most of this pretty quickly. It  
91:40 - asks if it matches a predefined format, something 
that would have saved somewhere else it doesn't.  
91:45 - It asked if they're delimited Yes, or delimited by 
tabs in this case, are the variables included at  
91:51 - the top of the file, you see how they show up here 
as the first row. I click Yes. And now it excludes  
91:58 - those because it knows that those need to be the 
in the header of the data file. hit Continue. Each  
92:05 - line represents a case, I want all of the cases 
you could sample from if you had a very large  
92:11 - data set, they would allow you to do exploratory 
analyses more quickly than you could otherwise.  
92:18 - And that's what delimiters 
appear. Now, by default, a  
92:21 - text file, the one that I have uses tabs and 
it knows that it asks about text qualifiers,  
92:27 - I don't have text qualifiers in here. So I just 
hit continue, don't have to change anything.  
92:31 - Now I have dates here at the beginning, and they 
are year dash month. Now, SPSS can handle dates,  
92:40 - however, it doesn't like the fact that I'm using 
year and month without the day associated with it.  
92:46 - Consequently, I'm gonna leave it just 
as a string variable as a text variable.  
92:50 - And it still works properly in any analyses 
I want to do. So that's fine. I'm just gonna  
92:55 - hit continue, I'm not changing anything here. 
It asked if I like to save the file format for  
93:00 - future use. That's the thing I was referring to 
in the first dialog here. And that's if I want  
93:05 - to paste the syntax, I could do that. But I've 
already got it pasted, I'm just gonna hit Done.  
93:15 - And there it is, it's opened it up, and it's 
formatted properly. If we go to Variable View,  
93:21 - you can see it's got a string variable, it's 
got three numeric variables, it has the proper  
93:26 - number of digits, it has the proper number of no 
decimal places, and it recognizes them as nominal,  
93:34 - which actually is not the case. So I actually need 
to come here and change that to a scale variable.  
93:40 - Because the data that you get from Google Trends 
is sort of zero to one percentages in terms of  
93:47 - relative popularity, search terms, change 
that to scale. And otherwise, I'm good to go.  
93:55 - Now, let's do the same thing, but with a CSV file. 
To do that, I'm just gonna get rid of this data  
94:00 - file, I'll just open up a new one. There we go. 
I'll come back up to the file and open to data.  
94:12 - This time, I need to tell I'm looking for 
a CSV, but if remember it that's actually  
94:16 - under text. So I click here. And except this 
time, instead of selecting the dot txt file,  
94:22 - I'll select the dot CSV file. And what you find 
is that the procedure is almost identical. There's  
94:29 - only one super tiny change here. I hit Continue. 
I tell the variable names are at the top.  
94:36 - It is delimited. and nice to know that each line 
is a case I just hit continue and all this. Here's  
94:43 - the one difference. When I did the text file tab 
was automatically selected. Now that I'm doing a  
94:48 - CSV, which means comma separated values, comma is 
automatically selected. I hit Continue. It does  
94:55 - the same thing with month we're going to leave 
it as string I hit continue and I can hit Done.  
95:05 - And you see, it looks exactly the same. I do 
have the same issue though, that these three  
95:11 - numbers which go from zero to 100, are coded as 
nominal, I need to change them manually to scale.  
95:20 - Right. Now we'll do the third one, an 
Excel file. Now in a lot of programs,  
95:26 - you get very stern warnings about importing 
Excel files. And there's good reasons for that.  
95:31 - Because Excel files are very flexible, and people 
can put a lot of stuff in there, again, comments  
95:36 - and changing column widths and merging cells that 
make it easy to use Excel just for displaying  
95:41 - information. But if you're importing it don't want 
to do that. Fortunately, I have it set up as tidy  
95:47 - data already. columns are the same as variables, 
rows are the same as cases, there's nothing else  
95:53 - in there. And so what I can do in this case 
is come to File, Open, we'll go to data again.  
96:01 - And this time I come down to this one, 
it actually has Excel file as a format.  
96:08 - There it is, I'll hit open. And you'll see 
that the dialog is different. In this case.  
96:14 - It says opening Excel data source instead 
of the text import wizard. It says read the  
96:19 - variable names from the first row that's checked, 
by default, it knows how many rows of data I have.  
96:24 - And it's got this thing about maximum width, I 
don't need to worry about that I just hit OK.  
96:32 - And that was that. Here's the data from Excel,  
96:35 - it's the same data, I still need to 
change these three measures manually,  
96:40 - you could save this information in syntax if 
you're going to be doing it many times over.  
96:45 - But that is sufficient for the need. And so it 
turns out that importing information into SPSS  
96:52 - is really easy. And it's massively more efficient 
and easier to do than entering it directly.  
97:00 - You do it in a spreadsheet. And especially if you 
do it on Google Sheets, if you're entering stuff  
97:03 - manually, you can collaborate on it. And then you 
save it as a CSV file, and you pop it in there.  
97:09 - And then you can get straight to your analysis. 
And that is the point of all this work anyhow.  
97:16 - And now in SPSS and introduction, we get to 
the part that maybe you were waiting for,  
97:21 - and that's analyzing data. All mentioned. However, 
I'm going to give only a very small overview of  
97:27 - analyzing data, because we have an entire 
separate course here for data analysis, and  
97:33 - also data visualization in SPSS. And I recommend 
that you check those out. But as a taste of what's  
97:39 - available, we'll talk about a procedure that's of 
interest to a lot of people in applied settings.  
97:44 - And that's hierarchical clustering. Now, the 
idea here is that you're trying to find clusters,  
97:51 - you're trying to find the clusters in your data. 
More specifically, what you're trying to see is  
97:55 - whether similar cases cluster together in some way 
that you can use to make inferences about them.  
98:03 - The trick, however, is that 
similarity depends on your criteria.  
98:07 - And there's a few decisions that you have to make 
when you're doing a cluster analysis of any kind.  
98:12 - So for instance, you have to decide whether you're 
going to do a hierarchical cluster analysis,  
98:17 - which goes from one group to as many groups as 
you have cases, or whether you're going to use  
98:22 - a set K or set number of clusters. You also have 
to decide on the measures of distance that you're  
98:29 - going to use Euclidean distance, which is sort 
of like measuring the as the crow flies distance  
98:34 - between cases is very common as his squared 
Euclidean distance, which is what SPSS uses.  
98:41 - There's also the question of whether you want to 
start with everything together and split it up  
98:44 - in a divisive procedure, or start with everything 
separate and put it together in an agglomerative  
98:51 - procedure. By default, some programs 
like our devices, but by default, SPSS  
98:58 - does agglomerative, you basically end up 
with the same general findings anyhow,  
99:03 - so it's really not a huge difference. 
So we're going to do a cluster analysis,  
99:08 - but we're going to try to keep it simple. We're 
going to use some of the most basic methods for  
99:12 - doing this will use Euclidean distance or 
squared Euclidean distance. In this case,  
99:17 - we'll use hierarchical clustering where we don't 
have to choose the number of groups ahead of time.  
99:21 - And we're going to use an agglomerative procedure 
where it starts with every case separate and then  
99:26 - gradually puts them together. Well try this 
in SPSS, but I need you to do something first.  
99:33 - There is a folder that you can download from the 
case files that ends with data here and in it  
99:39 - there's one file, it's cars dot save word SAE is 
a proprietary SPSS data format. And in addition to  
99:48 - that, there is the SPSS syntax file and you'll 
want both of those for this demonstration.  
99:55 - If you save the data file to your desktop, 
it looks like this. You can just double click  
100:01 - on it and it will open up in SPSS, you also 
have the option of using syntax to do that.  
100:07 - It depends on your operating system. This is for 
a Macintosh right here. And this is for a Windows  
100:12 - computer though, you may need to use backslashes. 
Instead, depending on your version of Windows.  
100:17 - I'm just gonna go back and double 
click on this, to open it up in SPSS.  
100:26 - And there's my data set. What this data set 
is, is a slight variation on a data set called  
100:33 - m t cars. That's in the default data sets package 
in R. It contains road test data on a number of  
100:40 - cars from 1974, from the magazine Motor Trend. And 
what we're going to do is we're going to look at  
100:47 - this information, we're going to see whether the 
cars clustered together in some important way.  
100:52 - I'll go to the data view here. And you can see we 
have Mazda RX four Hornet sport about Mercedes,  
100:58 - 450, se, Lincoln, continental and so on cars 
that were all available in the early 70s.  
101:04 - And we have information about miles per gallon. 
We have the cylinders, we have the displacement  
101:11 - and cubic inches horsepower, weight in tons, 
quarter second time in the standing quarter mile.  
101:19 - Whether it's an automatic or manual transmission, 
the number of gears in the transmission.  
101:24 - And the number of carburetors are 
probably carburetor barrels here,  
101:28 - I'm going to turn on the labels. Only one variable 
changes here. By the way, one of the things I did  
101:35 - is I formatted this for SPSS by adding labels 
and change some of the decimals makes it a  
101:42 - little easier to work with in the program. 
But let's go to the syntax file right now.  
101:48 - Once we have the data open, we want to do a 
default hierarchical clustering. Now this is  
101:55 - the code to produce it right here. But I'm 
going to do it with the drop down menus to  
102:00 - show you that it's really not hard to do. 
All we need to do is come up to analyze.  
102:07 - And then we come down to classify. Now 
I have to admit off the top of my head,  
102:16 - I cannot remember if every version of SPSS 
has this particular menu, most will, I hope  
102:23 - yours does. So you can follow along with this 
hierarchical cluster. I'm going to click on that.  
102:31 - And what I'm going to do here is I'm going to take 
Carnegie, which really tells me just says what the  
102:36 - cars are. And I'm going to use that to label cases 
because that's going to mean something to me.  
102:41 - And I'm going to take all of my other variables 
on the stool will shift click here and put them  
102:46 - over here. And at this moment, I'm going to change 
nothing else, you'll see there's going to cluster  
102:51 - cases, that's what we want, it's going to give us 
both some statistics and some plots, that's fine.  
102:57 - I'm going to hit OK. And we're going to get a 
result identical to my first syntax command.  
103:05 - I see it sound I'll make the output window bigger 
here. And here's what we have. First off, it tells  
103:10 - us how many cases there were and there were 32. 
And they all had complete data, which is nice.  
103:16 - Then SPSS gives us something kind of unusual, 
called an agglomeration schedule. And it really  
103:21 - specifies, at what point in the procedure did two 
cases get put into the same cluster. I personally  
103:31 - don't have much use for this, except I know that 
when there's a big jump in the coefficients as  
103:36 - there is here from three to 26, you know that 
there's a very distinct category change as far  
103:42 - as from 662 1125, and so on. Most of the time, 
though, I would just completely ignore this one.  
103:50 - And this, this is called an icicle plot. And 
it's just sort of the same information about when  
103:56 - various cases got dropped in with everything else. 
It's kind of pretty to look at, I find it kind of  
104:03 - meaningless. And so truthfully, the default 
output for SPSS is hierarchical clustering  
104:08 - to me is not very helpful. In fact, it's so 
unhelpful, I'm just going to delete it all.  
104:14 - And I'm going to do this over 
again, come back up to my recent  
104:19 - menu items, I'm going to go to this analysis 
again, I'm going to make a couple of changes.  
104:24 - I don't want the agglomeration schedule, 
that doesn't really help me. And for plots,  
104:29 - I'm going to get rid of the icicle plot. And 
then when you get a dendrogram instead of  
104:36 - dendogram. That means branches in Greek. So 
it's a graph of the branches. And this is  
104:40 - usually the most important thing you can get out 
of a hierarchical cluster analysis. I'll hit OK.  
104:52 - And now what we have is a chart here that 
lists all the cases the cars on On the side,  
105:00 - and it shows how they grouped together. So 
we see, for instance, these first four cars,  
105:06 - the Mazda RX four, and the wagon and the Mercedes 
280 and two, etc, are very similar to one another,  
105:13 - they all go here together, we see 
this a mother's, we come down here.  
105:19 - So for instance, the Cadillac Fleetwood, the 
Lincoln Continental, the Chrysler Imperial, which  
105:24 - are all gargantuan American cars with big VAT, 
they all go there together. And then we see down  
105:31 - here at the bottom, that this one, the mazarine 
board is all by itself for a very long time.  
105:36 - This is where cases are individual here on the 
left, and they gradually get put together. And  
105:42 - you see how they come together in each of these 
branches. That's why it's called a dendrogram.  
105:47 - And so this is a really nice way of 
seeing how similar your cases are.  
105:52 - And if you have more pixels displayed, you 
can see the entire graph at once I've got a  
105:57 - low resolution right here. And you can see, 
maybe it makes sense to split this off into, say,  
106:03 - four groups looks like we've got a distinct 
group right here, right there, right there, and  
106:09 - right there. And so I can do something else with 
this. I'm going to come back to the menu here.  
106:17 - And what I'm going to do is I'm 
going to save group membership.  
106:22 - Now, I've done a hierarchical analysis. So I 
didn't have to specify the number of groups. But  
106:27 - now that I've looked at the chart, for seems like 
a good number. So I'm going to come here and say,  
106:33 - give me the group membership for each 
case, breaking it down into four clusters.  
106:40 - I'll hit Continue. And then I'm going 
to ask for it to not give me any plots.  
106:45 - I hit OK. And this time, we're not going to get 
the output except for to say that it did the work.  
106:53 - Let's just get that. Here it says it it 
processed them. The place where we're going  
106:57 - to see the differences in the data files, 
I'm going to move over to the data file.  
107:03 - This button, by the way, will get me over to the 
data. And now you can see I have a new variable  
107:09 - that got added here, for clusters for and you 
can see that each of the cars is listed in one  
107:16 - of these four clusters. And what you can do then 
is you can then take these cluster memberships,  
107:24 - and you can compare them on the 
other variables. Again, remember,  
107:27 - the clustering here is only as valid as the data 
that we give it. So it's only comparing these cars  
107:33 - on a small number of variables. And it's using 
that to decide what goes with what it's here,  
107:39 - for instance, that you see them was Roddy Bora 
is in a category all by itself. And this is a  
107:44 - neat way of looking at the similarity between 
items. You can do it with people if you're doing  
107:49 - market research you can do with companies 
if you're doing some sort of segmentation.  
107:54 - And it allows you to see what groups have 
important similarities for what your purposes are,  
108:00 - and which groups you need to treat 
differently as one another. That's the  
108:03 - goal of hierarchical clustering analysis. And 
you find it's a very easy thing to do in SPSS.  
108:12 - Another important procedure in SPSS when you're 
analyzing data is something called a factor  
108:18 - analysis. Now, I like to think of it as looking 
at your data and trying to find shadows.  
108:24 - In this picture, what you have are shadows, those 
are the black figures that you see, it takes a  
108:29 - moment to figure out that you're looking down and 
there actually are people, but kind of sticking  
108:34 - straight out. And so in this photo, we are going 
from a sort of a three dimensional origin, that's  
108:39 - the person itself to a two dimensional variation 
with the shadow. What's interesting about that  
108:45 - is you maintain most of the useful data, you can 
tell that there are people that they're walking,  
108:50 - you can probably even tell some things about how 
tall they are, what they're wearing, and so on.  
108:55 - What you've done is you've made things more 
efficient. Now in the data world, that's called  
109:01 - dimensionality reduction, where each variable is 
a dimension. And too many variables can actually  
109:08 - be really problematic. You're trying to boil 
things down a little bit. And you can think  
109:13 - about the saying less is more or less equals 
more. More specifically, that is less noise,  
109:21 - and fewer unhelpful variables in your data set. 
Equal more meaning because that's what you're  
109:28 - trying to do, you're trying to extract meaning. 
Now, when it comes to factor analysis and related  
109:34 - techniques, I have one very important piece of 
advice and that is to be practical. at all points,  
109:40 - you want to remember what is your goal? So what 
is the goal? Well, the goal of factor analysis,  
109:47 - I'll tell you what it's not. It's not an exercise 
in analytical purity. You're not there to show  
109:54 - that you know how to go through all the steps 
in the approved format. Really, you're working  
109:59 - with your data Because you're trying to get 
some understanding. So the goal of a procedure  
110:05 - like factor analysis is useful insight, trying 
to follow the rules, do what you can to make  
110:12 - sure you don't make any obvious mistakes. But 
remember, you're not bound by the mathematics,  
110:17 - you're bound by what the data tells you about 
the people. Another way of looking at that is use  
110:23 - factor analysis, or really any other procedure 
for us heuristic value. That is, it suggests  
110:30 - possibilities to you as you analyze the data 
as you're trying to get insight to people. Now,  
110:36 - that's sort of a philosophical discouraging, 
let me show you how this actually works in SPSS,  
110:42 - you're going to need to download from the course 
files a folder that says data here at the end. And  
110:49 - from it the cars dot save dataset, this is the one 
that we use in hierarchical clustering as well.  
110:56 - And then you want to open up the SPSS syntax 
file that goes with this particular section.  
111:04 - Now, the easiest way to open the data set 
is simply to double click on it and you'll  
111:08 - be ready to go. I do have some syntax you 
can use if you saved it to your desktop.  
111:14 - I've got it open already. So let's 
take a quick look at the data set.  
111:19 - We have a collection of cars listed down the 
side and attributes like mpg and so on and  
111:25 - gears in the transmission and carburetors. That's 
great. Now I will have to make a very important  
111:32 - confession here. This is a very, very 
small data set for factor analysis.  
111:37 - It only has nine variables other than 
the identifier, and it only has 32 cases,  
111:43 - really, you would want to have at least several 
100 cases. And let's say several dozen variables  
111:51 - before you can do this really reliably. But this 
example works. And it, it actually is really easy  
111:57 - to see how it's happening, and how to interpret 
the results. The first thing we're going to do,  
112:02 - if you look at the syntax, is we're going 
to do a default factor analysis. And it's  
112:07 - actually a misnomer, because it's not a factor 
analysis. It's principal components analysis,  
112:13 - but it's in the factor analysis command 
within SPSS. So let's come up here to analyze.  
112:19 - And down to dimension reduction. Remember I 
said that's what this is called pick factor,  
112:25 - It's our only choice there. And what we need to 
do is choose the variables that we're going to use  
112:32 - to see what we can compress what goes into what so 
we don't need the name of the car, that's just an  
112:38 - identifier. We can take the rest of these however, 
and we can put them under variables. Now we've got  
112:46 - a lot of options here, I'm not going to do any 
of them, I'm just going to hit OK for right now.  
112:54 - And make the output window bigger. And here's 
what we get from the default analysis, we get a  
113:00 - text output of the commands that were 
generated by the drop down menus,  
113:05 - we get something called communality. each 
variable brings with it one unit of standardized  
113:12 - variance. That's based on how spread out 
the scores are. And if you standardize them,  
113:16 - then you have a variance and the standard 
deviation of one for each. And the extraction  
113:21 - tells us how much of that variance is really able 
to get constituted through the process that we're  
113:26 - doing. An important one right here is the total 
variance explained because what this has done is  
113:32 - it has created components memory said this is 
actually a principal components analysis here,  
113:38 - which well, it has profoundly different 
philosophical underpinnings from factor analysis,  
113:43 - the difference has to do with which came first, 
the factors or the observed variables. And  
113:48 - truthfully, most people treat them 
as relatively interchangeable. And if  
113:53 - you're using them for heuristic value, 
it's not going to be a big difference.  
113:57 - But what we have here are two components, we 
have one with 5.472 units of variance that 61%  
114:05 - of the original variance of the nine variables, 
and then another one with 2.341. I'm getting  
114:11 - those numbers from right here. And you can see 
it held on to these two, which collectively  
114:17 - add up to about 87% of the variance. Now the 
component matrix shows the relationship between  
114:24 - the original variables and the two components. 
These are like correlation coefficients,  
114:29 - you can see that mpg is strongly negatively 
associated with the first component and really  
114:35 - not associated with the second. But number of 
carburetors has a pretty strong association with  
114:41 - each. And so that's a way to start to look at 
it. But it's going to be a lot easier if we do  
114:48 - certain modifications to this. In fact, I'm 
going to just delete this output right here.  
114:55 - And we're going to start over 
I'm going to make a few changes  
115:00 - Let's go through each of these options. First 
we go to the descriptives. And I don't really  
115:04 - feel like I need the initial solution. So 
I'm going to unselect that I'll hit Continue.  
115:10 - extraction. This is the actual algorithm that 
SPSS uses to work through the relationships  
115:17 - in the multi dimensional space. You'll see 
right here is principal components. That's  
115:22 - why I said this is really a principal components 
analysis, you've got a lot of options here. Now,  
115:28 - in many situations, maximum likelihood would 
be a very good answer, I'm going to choose  
115:32 - principal axis factoring simply because it's 
the classical version of factor analysis.  
115:40 - I don't need to see the unrotated factor solution, 
but I do want to see something called a scree  
115:45 - plot. And that is a graph that shows me 
maybe how many factors I should keep,  
115:53 - I'm going to come down here and change the maximum 
iterations for convergence that has to do with the  
116:00 - math, that's done, I'm going to change it to 50.  
116:05 - Then I'm going to come to rotation, what you 
get here is a multi dimensional space. And  
116:09 - sometimes it's a little easier. If you rotate, 
the axes can increase interpretability. Now,  
116:17 - there are a lot of different methods. varimax is 
a method that maintains orthogonal relationships  
116:23 - that makes all of your axes perpendicular to each 
other. There are situations where that's really  
116:28 - good. But truthfully, for exploratory purposes, 
which is what we're doing, I like to use what's  
116:33 - called an oblique rotation, that allows your 
factors to be correlated with each other,  
116:39 - they don't have to be totally perpendicular. 
I'm gonna use direct oblem. And promax is  
116:44 - another really good choice. But it usually is for 
larger data sets, and I've got a tiny one here.  
116:51 - Now, here, I can get a rotated solution, 
I don't think I really need that. But I do  
116:56 - want to see the loading plot. And I'm going to 
increase the maximum number of iterations to 50.  
117:01 - I'll hit Continue. We'll come down 
to scores. And you can save the  
117:09 - factor loadings as scores. And there might 
be situations where you want to do that.  
117:13 - But because I'm using factor analysis for its 
heuristic value, as a way, suggesting what  
117:18 - variables to go with others, I'm actually not 
going to do that. So I'm going to hit cancel.  
117:23 - Then finally, options. This is where you get to 
talk about excluding cases, I have a complete data  
117:28 - set, so I don't need to worry about that. 
But the coefficient display format, now,  
117:33 - I'm going to sort it and then I'm 
actually going to have it completely  
117:37 - erase small coefficients. Now I've done this 
one before. So I happen to know that a value  
117:45 - of point six, under normal circumstances has 
really high. But given my very small data set,  
117:51 - this seems like a reasonable choice. 
And it makes the solution very,  
117:54 - very clear when we look at it. So I'm going to 
hit Continue. And then there, I'm going to hit OK.  
118:02 - I've got my output here. And the first part is 
pretty similar, except it doesn't start with a  
118:08 - unit variance for each of these. That's because 
I'm not doing principal components anymore. I'm  
118:12 - doing principal axis factoring. And so the math 
behind it's a little bit different. But we don't  
118:18 - need to dwell on that one. total variance 
explained, you see that we still have two  
118:23 - factors. And the first one accounts for a lot 
of the variance, the second one accounts for  
118:28 - a fair amount also, and these are very close 
to what we had with the principal components.  
118:34 - The scree plot, is a very simple line pot. This 
suggests how many factors we might want to keep.  
118:39 - Now there are several different rules you can 
use for interpreting this. One is anything that's  
118:45 - above a value of one because one is what it would 
be if a variable explained simply one unit of  
118:52 - variance, but that's what it brought with it, you 
want factors that have been explained more than  
118:56 - that. And you see we have two that do a lot more 
than one and these others are sort of straggling  
119:01 - down. The other rule is to look for a bend in 
the line and you do see a strong band right here.  
119:08 - So three is where the band is, we're justified in 
saying with two, there are other methods to get  
119:14 - more involved about checking for the slope of this 
line and finding things that are above that slope.  
119:20 - You can do those in another time. This is 
a quick demonstration. Now what we get next  
119:26 - are three matrices, we get a factor matrix, a 
pattern matrix, and a structure matrix. They're  
119:33 - all associated with each other. And I've got a 
little note here in the syntax that explains them.  
119:38 - I'll come down here. The factor matrix is the 
Association of each variable with each factor and  
119:46 - it's similar in nature, it's analogous to our the 
correlation coefficient. That's the one that we're  
119:52 - going to be focusing on. The structure matrix 
tells us how much each variable is predicted by  
119:58 - the factors because the idea Here's the factors 
come first and variables come second, using what  
120:03 - are called the unique and common contribution. 
So a factor might contribute something on its own  
120:10 - compared to the other factors or it contributes 
together. And then the pattern matrix is an  
120:17 - indication of each factor is unique contribution 
to variables variance. Those can both be important  
120:22 - in different situations, and they can help you 
interpret things. But for right now, I'm just  
120:26 - going to focus on this first one. There we go, the 
factor matrix. So let me go back to where I was.  
120:35 - And when we come up to the factor matrix, 
what you see here is because I suppressive  
120:39 - values with an absolute value of less than point 
six, we have this totally clear separation.  
120:45 - Factor one is strongly associated with the number 
of cylinders in the car. So more cylinders higher  
120:54 - on factor one, and then displacement, very high, 
mpg is negative, but very strong. And then we have  
121:03 - weight in tons very strong in horsepower. This is 
really the big factor cars that are really big are  
121:10 - going to score heavily on factor one. factor two 
is composed of the number of gears and more gears,  
121:18 - the quarter mile time, so the less time it 
takes to get through the quarter mount that is,  
121:23 - the faster it is. That's because 
it's negative here, the higher it is  
121:28 - automatic or manual, you have to know 
that zero is automatic, and one is  
121:32 - manual. So these are manual transmission 
cars, and those with more carburetors.  
121:38 - This is really the fast factor. And that's 
where sports cars are going to this one,  
121:43 - this one has the Cadillacs and the Lincoln's and 
this one has the Ferraris and the Lotus isn't and  
121:49 - so on. And that makes perfect sense, it's really 
easy to see why that would be the way it is.  
121:57 - And then if you come down here, this plot is 
also really helpful, it's got the two factors,  
122:03 - we have factor one across the bottom, that's 
our big factor. And you can see that weight  
122:09 - goes on that one displacement goes on that 
one cylinder, and then we have number of  
122:13 - years and miles per gallon, obviously, you're 
on the low end. factor two is the fast factor.  
122:19 - More carburetors, more horsepower, more 
cylinders, and lower quarter mile times.  
122:25 - And that makes a lot of sense. And so this 
lets us know that we could boil down our data  
122:29 - to really just these two factors, sort of how 
big is the car, and how fast is it. And that  
122:35 - can give us a much more concise image of our 
data, and allows us to extract more meaning and  
122:42 - that is the overall purpose of a procedure like 
factor analysis or principal components in SPSS.  
122:51 - For a final look at SPSS and analyzing data, 
at least in this brief overview course,  
122:57 - let's take a look at one of the most useful 
procedures around regression. Now, you might think  
123:03 - of regression as sort of the statistical version 
of The Three Musketeers where it's all for one.  
123:09 - I say that because all for one is actually 
all variables for predicting one outcome.  
123:17 - Put another way, regression uses many different 
variables many predictor variables to predict  
123:22 - scores on one outcome variable. This makes it 
really useful in a huge range of circumstances,  
123:28 - especially because there's something for everyone 
with regression. There are many different versions  
123:35 - of it and many adaptations of regression that make 
it truly flexible, and powerful. When analyzing  
123:42 - data and make it a go to tool for almost any 
analytical purpose you might have. We'll try  
123:49 - a simple version of this in SPSS. First, make sure 
you've downloaded this data folder from the course  
123:56 - files. It will use the cars dot save data set 
that we've used in our two previous examples,  
124:02 - along with this syntax file. And when you 
get to this index file, it begins as usual.  
124:09 - With the code for loading the data set from the 
desktop truthfully, is easier to just double click  
124:15 - on the file cars dot save and haven't opened it 
up directly in SPSS. That's what I've done here.  
124:22 - And you can see is the same data set with about 
32 rows of data, a bunch of cars from 1974.  
124:30 - And several variables we're going 
to try to predict in this one is  
124:33 - miles per gallon, based on things like the 
number of cylinders the displacement, horsepower,  
124:39 - weighed quarter, second time transmission 
and kind and gears and carburetors.  
124:44 - Alright, so that should be pretty easy. What 
we're going to do is go to analyze, and come down  
124:52 - to regression. And we'll use this second option 
here linear. That's just basic linear regression.  
125:01 - Now we need to put under dependent the outcome 
variable, the thing we're trying to predict,  
125:06 - kind of bugs me here, because independent 
and dependent really should be reserved for  
125:09 - manipulated experiments. But 
we still know what they mean,  
125:13 - our outcome variable, the thing that we're 
trying to predict goes here independent.  
125:17 - So that's mpg. Now we can take everything 
else except car name, that's just a  
125:22 - label, we'll take all the rest of these and we'll 
put them under our independent or the variables  
125:28 - that we are using to predict the outcome. Now, 
I want to do the totally default, no extra steps  
125:35 - version first. So I've put the variables in 
their respective place. And I'll just hit OK.  
125:43 - And now we get our output. And it tells us first, 
the code that was used to produce this analysis,  
125:51 - that it used all of these variables 
simultaneously to predict a single outcome,  
125:57 - which is listed down here. And they were entered 
at once. The model summary tells us that we have a  
126:04 - multiple correlation of these predictor variables 
with our outcome variable of point 931, which is  
126:12 - really high. If you square that to get the 
proportion of variance explained it's 86.7%.  
126:19 - Even the adjusted R squared, because we have 
a small sample is still 82%. It's It's huge.  
126:25 - We get a significance test right here, we are 
not surprised to see that the significant is  
126:31 - point 000. It's not zero all the way through, 
but it's it's highly significant. And then we  
126:38 - get coefficients for the individual regression 
coefficients. So what we're looking for here are  
126:46 - significance levels that are under oh five, and 
interestingly, only one of them in this collection  
126:53 - is under oh five and that weight in tunt. None of 
the others are there close. That doesn't mean that  
127:00 - none of the others matter. It simply means that 
when you take all of the variables together at the  
127:05 - same time, when they are taken as a whole, really 
only one of them deviates significantly from zero  
127:12 - to become a predictor. That's a wait. Now, there 
are a lot of other ways of doing regression.  
127:20 - And SPSS gives you a lot of choices. I'm going to 
come up here, back to analyze, down to regression.  
127:28 - Now I will mention, there's a really interesting 
one here called automatic linear modeling. This is  
127:34 - a SPSS function, it's came in a few versions ago, 
it does a lot of automatic Data Prep, it does a  
127:40 - lot of combining and splitting up the variables. 
On the other hand, it's really kind of difficult  
127:46 - to explain how it all works. And then to interpret 
it properly. I'm going to save that for another  
127:51 - course where I specifically talk about analyzing 
data. For now I'm going to go back to linear.  
127:58 - And we're going to make a few choices, 
we're going to make a few options, rephrase.  
128:07 - And we're going to make a few choices, we're 
going to take some of the options that SPSS  
128:11 - makes available. Now the first one I'm going to do 
at the risk of doing something very controversial,  
128:15 - is I'm actually going to go from simultaneous 
entry to stepwise regression. This is  
128:20 - controversial because some people in the 
literature have called it positively diabolic.  
128:25 - And its risk of a type one or false positive 
error. And there's some good evidence for that.  
128:31 - On the other hand, in modern machine learning, 
stepwise procedures have been very fruitful  
128:37 - use. And so it's not totally unacceptable to 
try, especially when we're doing sort of an  
128:43 - exploratory project like this right now, 
you certainly wouldn't want to use it for  
128:48 - rigorous model building, but it's a nice way to 
get some insight into the data pretty quickly.  
128:55 - I'll come just to statistics, and I'm going to 
add a few things, I'm going to get confidence  
128:59 - intervals for the coefficients, those are nice to 
have, we have the overall model fit. And I'm going  
129:04 - to get the R squared change, because a stepwise 
model goes through several different steps, adding  
129:09 - variables. And we want to see if each variable 
adds something that is statistically significant  
129:14 - to the overall model. We could get a lot more 
information here, but I'll leave it there for now.  
129:21 - Under plots, we can get a ton of different 
plots, but I'm actually just going to come  
129:25 - down here and choose the standardized residual 
plots a histogram and a normal probability plot.  
129:34 - Now there are other options as well. I could save 
about 15 different kinds of scores to the data  
129:42 - set. I can say unstandardized predicted values, I 
can save studentized, deleted residuals, and so on  
129:48 - and so forth. things I could do here and there are 
situations in which I might want to do those. But  
129:53 - for right now, I'm going to skip them because I'm 
simply trying to build a model without necessarily  
129:58 - saving all of the steps in between Options really 
just talks about the criteria used in the stepwise  
130:06 - procedure, I'm gonna leave it at the default right 
now, but you could change it if you wanted to.  
130:13 - And then style is a new thing that has 
to do with the formatting of the table.  
130:17 - I'm going to leave that one alone for right now, 
because we're going to have exactly what we need.  
130:22 - Now I've created this already, and I've 
saved it in the syntax, I'm just going to hit  
130:25 - OK. And you'll see that we get a different 
kind of output right now. I'll zoom in on this.  
130:37 - Now what we have is some code that's a little bit 
longer, this has to go through the variables one  
130:43 - at a time. And find the predictive variable that 
is most strongly associated with the outcome,  
130:48 - put it in the model, get partial correlations 
and go through step after step. What we find  
130:55 - here is that although we had nine predictors, 
originally, only two of them were statistically  
130:59 - significant when put into the model. They 
were weight, and number of cylinders.  
131:05 - Again, what we're trying to predict is gas mileage 
mpg. If you come down here, you can see that they  
131:11 - were both statistically significant, or the 
adjusted R squared for just weight is 74.5.  
131:19 - And when you add on number of cylinders, it goes 
up. Not a huge amount, but it goes up almost 8%.  
131:27 - The analysis of variance table lets us 
know that both of these models with just  
131:31 - one variable and with two predictor variables, 
they're both statistically significant.  
131:36 - Here are the individual coefficients along 
with their confidence intervals over here on  
131:41 - the right side. Now, because we've gone through a 
stepwise procedure, it's not surprising that all  
131:46 - of these are statistically significant, because 
that was the criterion used for including them.  
131:53 - Here we have a list of excluded variables along 
with their colinearity statistics. And this has  
131:58 - to do with how much each of these variables is 
correlated with the others. So for instance,  
132:02 - number of carburetors is highly colinear,  
132:06 - or easily predicted by the other variables 
that we could have included in the model.  
132:12 - Now we come down to the residuals, I'm 
going to look specifically at the chart.  
132:17 - In an ideal world, your residuals are normally 
distributed, which means they're just as likely to  
132:21 - be high as they are low, and they're symmetrical. 
And we see here that they're not horribly,  
132:28 - pathologically far from normal. So this is 
probably a good model on the set. And here's  
132:33 - a normal p p probability probability plot of 
this same data. And if it were perfectly normal,  
132:40 - all the dots would be on the line, the diagonal 
line, they're close. These are the 32 individual  
132:46 - observations and how far off they're, they're 
close enough. And so this lets us know that our  
132:50 - model is predicting really well and it appears 
to be not biased in one direction or another.  
132:57 - So this is one method of developing a model. 
Again, this stepwise procedure is best for  
133:03 - exploratory analyses, it's not something 
you would use for confirming a finding.  
133:09 - But as a quick way of sifting through a 
large collection of potential variables,  
133:15 - this is a nice way to do it. It lets us know for 
instance, that in this particular data set mpg  
133:21 - is predicted primarily by a weight, which 
completely makes sense about the car,  
133:25 - and number of cylinders, which is associated with 
having a large and thirsty engine. So the general  
133:33 - idea of multiple regression, again, is to use 
many variables to predict a single outcome, SPSS  
133:39 - gives a lot of options for those we've looked at 
the default we looked at one variation on there,  
133:43 - but there's a lot more that you can explore 
and that we will cover in another course on  
133:47 - statistical analysis in SPSS. But for now, 
I encourage you to take some time and look  
133:52 - at some of these options and see the kind of 
insight that they can give you on your own data,  
133:57 - and see what options you can use to get 
useful insight into your own analyses.  
134:05 - I want to thank you for joining 
me in SPSS and introduction.  
134:09 - And we'll conclude by giving you some next steps, 
things that you can do next, because you know,  
134:14 - once you get through this, it can be a little 
confusing, feel like things are going everywhere.  
134:19 - And it may not be totally clear where you should 
go. Well, here at data lab.cc, we've got a few  
134:26 - opportunities for you. First, of course, is 
more SPSS, we have additional courses on data  
134:33 - preparation, on data visualization, on statistical 
analysis, and other topics that you can use  
134:39 - to expand what you've learned in this introductory 
course, and work on your own data. Now, if you've  
134:44 - liked what you've learned with SPSS, you may want 
to try branching out into some other languages.  
134:49 - This statistical programming language R and the 
general purpose programming language Python,  
134:53 - are very common powerful tools in the data 
science community and analytics in general.  
134:58 - They're a great way to To expand both the 
things that you can do with your analyses and  
135:03 - your employment opportunities, and so, I strongly 
encourage you to take a look at the courses on our  
135:08 - in Python data lab. Next, we have specific courses 
on data visualization, one of the most important  
135:14 - things you can do in getting to understand your 
data. SPSS can work well in those as well as  
135:21 - other programs. And then I'm going to mention one 
final thing here. SPSS is a wonderful program,  
135:28 - but it still has a fair amount of bugs and 
it can also be very expensive. Fortunately,  
135:33 - some really interesting work recently in the 
open source community has developed a program  
135:37 - called j SB. It's actually pronounced Jasper, 
which is sort of an open source version of SPSS,  
135:45 - it runs very differently, I find it very easy to 
use, and it makes it reproducible. It makes it  
135:52 - easy to share. It's got some tremendous advantages 
and we have courses on Jasper here today lab,  
135:58 - I suggest you check those out and see how well 
that program is able to fulfill some of your  
136:02 - computing needs. That being said, there are some 
things missing. What's missing exactly? Well, SPSS  
136:10 - doesn't have a really strong and active user and 
developer community the same way that languages  
136:16 - like R and Python do. But if you're creative, 
you can get around that academic conferences,  
136:23 - meaning specifically topical academic conferences 
like biology or management or the social sciences.  
136:29 - They often have very dedicated SPSS users, 
and teachers and may sponsor specific hands  
136:36 - on workshops for learning more about SPSS and 
how I can use it within your particular domain.  
136:42 - But no matter what you do, I'm going to encourage 
you to simply get started, go exploring and see  
136:49 - what you can do with SPSS in your own data work. 
Thanks so much for joining me and happy computing