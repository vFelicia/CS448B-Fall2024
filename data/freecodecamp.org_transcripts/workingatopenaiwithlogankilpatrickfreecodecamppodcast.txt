00:00 - [Music]
00:15 - we are here in the studio the virtual
00:17 - studio with none other than Logan
00:22 - Kilpatrick developer Advocate at open Ai
00:26 - and somebody whom I've had the joy of
00:28 - corresponding with for several years at
00:30 - this point uh huge advocate for Julia
00:34 - Lang which is a data science uh
00:37 - statistical language uh in addition to
00:40 - Python and R there's Julia and you've
00:42 - been very uh instrumental it sounds like
00:44 - in helping raise awareness of that and
00:46 - getting more people using it and
00:48 - learning how to use it and we're going
00:50 - we're going to talk about that we're
00:51 - going to talk about your time at open AI
00:53 - but of course I want to dive straight in
00:56 - and uh welcome you welcome thank you
00:59 - keep going say this is going to be
01:00 - awesome I'm I'm such a fan of of free
01:02 - code cab and I think the work that that
01:04 - you and the team and the entire
01:06 - Community are doing is is super
01:08 - important so um I'm I'm happy to to
01:10 - support where I can and uh just be a
01:13 - cheerleader from the sideline as well in
01:15 - many cases awesome yeah well we are very
01:18 - excited to have you uh cheerleading and
01:20 - I will continue to cheerleader for uh
01:23 - all the amazing tools you all are
01:24 - cooking up over at open AI as well both
01:27 - uh you know the foundational model the
01:29 - foundation model that I use many times a
01:31 - day and the open source projects that
01:34 - we're also using within free C Camp so
01:37 - uh I want to start by just diving in
01:40 - before you were Logan Kilpatrick you
01:43 - know uh you you have so many different
01:46 - hats that you wear uh somebody who has
01:48 - you know interned at Nasa somebody who
01:51 - has um who is working as a developer
01:54 - Advocate somebody who is going to lots
01:56 - of conferences and speaking
01:57 - authoritatively on a lot of these topics
02:01 - um and of course uh somebody who himself
02:03 - is like an angel investor in the AI
02:07 - space I want to go back a little bit way
02:10 - a little
02:11 - bit back to Illinois because my
02:15 - understanding is is is that where you
02:17 - you grew
02:18 - up yeah grew up in the suburbs of
02:20 - Chicago and I'm actually um and we can
02:22 - talk about it but I'm actually back in
02:23 - the sub not not in the suburbs now
02:25 - living in the city of Chicago yeah um
02:27 - bounced around to California and to
02:29 - Boston and then uh met met my girlfriend
02:32 - and then ultimately moved back to to
02:34 - Chicago uh about a year and a half ago
02:36 - amazing yeah so Chicago of course
02:39 - Central Time Zone like Dallas and uh
02:42 - slightly larger than Dallas I think it's
02:44 - the third largest metropolitan area in
02:46 - the United States a lot of people sleep
02:49 - on Chicago they're focused on the coast
02:51 - but you know Chicago's got a lot going
02:53 - on as well and I I'd love to hear a
02:56 - little bit more about Chicago and like
02:58 - your decision to move back there cuz you
03:01 - were living I think in the uh the bay
03:03 - area where which is where a lot of the
03:04 - AI action is happening but now uh I mean
03:08 - that that's a testament to the power of
03:10 - remote work that you can do that of
03:11 - course but let's let's go all the way
03:13 - back because I mean there's so much
03:15 - we're going to talk about during this
03:16 - conversation in terms
03:18 - of if you don't mind me using words like
03:21 - precociousness and uh you know you've
03:25 - studied so many different topics and
03:27 - things like that but but at one point
03:28 - you were just a kid
03:30 - going to school uh hoping
03:33 - to hoping to go to California like uh
03:36 - Danza Community College one of the uh
03:39 - famous uh community colleges in the
03:42 - legendary California community college
03:44 - system uh if you're looking to go to
03:47 - college Community College in California
03:50 - if you can get there that is a very good
03:52 - bet especially if you happen to live in
03:55 - uh California and can get like insay
03:57 - tuition but like maybe you can tell me a
03:59 - little bit about about what your your
04:00 - formative years were
04:02 - like yeah it's such a good question like
04:04 - I think you know I I have a lot of
04:07 - conversations with people and and in
04:09 - hindsight everything looks like it was
04:11 - supposed to happen the way that it did
04:13 - and I think like in the moment if I put
04:15 - myself back in the shoes of like high
04:17 - school Logan you know in 2014 in
04:20 - sophomore year of high school and like
04:22 - thinking about that
04:24 - experience like nothing nothing at that
04:27 - point like would have led me to think
04:29 - that I would get the chance to like do
04:30 - the incredible things that I'm doing
04:32 - today so I'm super happy about that and
04:34 - I think a lot of it was just like the
04:37 - it's fascinating to like be so
04:39 - abstracted out of that world now and
04:41 - like look back but like nobody cared
04:43 - about technology stuff like no one cared
04:45 - about like you know building things and
04:48 - like all the things that like I love so
04:50 - much today like it's really stuff that
04:51 - like I wasn't exposed to um like to the
04:54 - extent that I am today like I think of
04:56 - course like I had uh and have like
04:58 - incredible parents who like were you
05:00 - know giving me a bunch of opportunities
05:01 - to do a bunch of interesting stuff but
05:03 - like life was like so focused on like
05:06 - sports and like just trying to like
05:08 - socially survive and you know got a
05:11 - little bit of exposure to computer
05:13 - science stuff because my grandfather was
05:14 - an electrical engineer and um you know
05:16 - we spent a lot of time like taking apart
05:19 - old computers but like never really like
05:21 - building a working computer it was more
05:23 - just like destroying old computers which
05:25 - was probably not super safe in HS side
05:28 - especially cuz computers I'm sure had a
05:30 - bunch of like terrible stuff inside of
05:32 - them so hopefully that doesn't take any
05:34 - years off of my life in the long R were
05:36 - you like using the S ring iron and like
05:38 - tring trying to get like gold out of
05:41 - this the motherboard literally like
05:43 - pliers and screwdrivers and we were just
05:45 - like tearing these things apart I don't
05:47 - really understand again thinking back I
05:50 - don't really understand why we were
05:51 - doing that but um we had fun doing it
05:53 - and I think ultimately like I took um AP
05:57 - Computer Science in in in high school
06:00 - and like literally had no idea what was
06:02 - going on like I just remember thinking
06:04 - back to that class and like it was one
06:06 - of those classes where like you would
06:07 - they would just like kind of give you an
06:08 - a because you went through all the stuff
06:10 - but like I really pretty sure I learned
06:12 - like absolutely nothing and a lot of it
06:15 - and if I think back was like you know we
06:17 - were learning these Concepts in in such
06:19 - a vacuum that it was like hard to think
06:22 - like why will this ever be useful to me
06:25 - and I think the thing that actually
06:26 - really clicked was like coding and
06:28 - developing stuff that like made me want
06:30 - to like push myself to do more was the
06:33 - the game Flappy Bird like I saw Flappy
06:35 - Bird come out and I was like this is so
06:37 - cool and then I heard that the guy was
06:39 - making like $500,000 a day or something
06:42 - like that because Flappy Bird was going
06:43 - so vir and I was like wait this is does
06:45 - not look that difficult I should be able
06:47 - to do this um and I think that really
06:49 - like sparked much more of an interest in
06:51 - me to like actually go and and learn
06:53 - what was going on interesting Flappy
06:55 - Bird yeah like I mean phenomenal
06:57 - overnight sensation to the point that
06:59 - people are like
07:00 - selling the guy kind of freaked out at
07:03 - this success and he already had more
07:04 - than enough money to like live
07:06 - comfortably for the rest of his life in
07:07 - Vietnam right uh and uh yeah he and he
07:12 - he didn't like the way that people were
07:13 - like so addicted to it because he'd get
07:14 - on like the train or whatever and you
07:16 - just see everybody playing Flappy Bird
07:18 - and he was like oh they should be like
07:19 - learning or something like that right um
07:22 - but yeah like that is such an amazing
07:24 - story like how Flappy Bird of all things
07:27 - inspired you kind of like uh I mean it
07:29 - was a big hit obviously it was probably
07:32 - the app of the year um I mentioned
07:34 - earlier like people
07:36 - were selling iPhones that had Flappy
07:38 - Bird installed remember that a huge
07:41 - margin because he pulled it from the
07:44 - iPhone you couldn't get it anymore right
07:47 - and of course there were lots of clones
07:48 - but none of them were the original
07:49 - Flappy Bird something thought about that
07:51 - yeah so so that's what got you inspired
07:53 - and what were your first steps once you
07:54 - felt inspired by Flappy Bird like how
07:57 - did that change your data today activity
08:00 - and like your goals yeah I I started um
08:03 - so at the time I didn't have a Mac and
08:05 - Macs were like out of the you know we we
08:08 - my family had a bunch of Windows
08:09 - computers and it was like oh well let's
08:10 - go spend $2,000 on a Mac for for no
08:13 - reason and like that was kind of like
08:14 - outside the realm of what what we were
08:16 - going to do so the library um where I
08:19 - grew up in Arlington Heights like had a
08:20 - bunch of Macs and I went there and like
08:22 - start my mom started dropping me off so
08:24 - that I could try to build my own Flappy
08:26 - Bird uh clone and I found this guy um
08:29 - who I should try to reach out to and
08:30 - connect to Matt he Matt heinley apps
08:33 - Matt heene apps something like that and
08:35 - he made these really cool tutorials
08:36 - about like how to build iOS applications
08:38 - and if anyone's tried to do iOS it is
08:40 - very difficult it is definitely at least
08:42 - in my experience like not the place to
08:44 - start like there's just so much going on
08:46 - um ultimately tried to make something
08:48 - called Flappy Pig did it really work out
08:50 - that didn't it work out that well
08:52 - because I literally had no idea of what
08:53 - I was doing and had to like keep working
08:55 - with the library people cuz like they
08:57 - had these computers like pretty locked
08:58 - down and like the xcode stuff like
09:00 - wanted to do all these crazy things so
09:02 - it was like this very long and uous
09:04 - process but it made me realize like this
09:06 - is the thing that I probably want to do
09:08 - like I should go to school and study
09:10 - computer science and I think the
09:11 - challenge for me at this point was like
09:13 - you know I I was a decent like fine
09:16 - student but like I had never really like
09:18 - tried to make that my goal before and
09:22 - this was like junior year of high school
09:23 - where I really had this sophomore junior
09:25 - year of high school right where I had
09:26 - this realization like yeah I mean like
09:28 - suddenly you really have to kick into
09:29 - gear if you want to get into Harvard
09:33 - yeah foreshadowing a little bit but yeah
09:36 - yeah and I it was and which is kind of a
09:39 - one of those challenges of high school
09:40 - is like you're the timing is like very
09:43 - unideal like you basically like have to
09:46 - be mature at like 12 years old in order
09:49 - to like really be on the right curve to
09:51 - get into a great school right out of
09:52 - high school and like I was not on that
09:54 - curve so um I I did get into a bunch of
09:56 - point I was thinking about going to um
09:59 - Purdue to study computer science and um
10:01 - some other places and ultimately decided
10:03 - like in the uh in the yeah in the
10:06 - midwest is it in h Chicago Urbane champ
10:10 - or something like that u ofis in Urbana
10:12 - champagne uh Purdue in West laia Indiana
10:15 - which is like a a ston throw two hours
10:18 - uh East in in Indiana but um ultimately
10:21 - like I wanted to go to Berkeley and I
10:23 - was fortunate enough that my dad had
10:25 - started at a new job in California and
10:27 - um one of his co-worker Sons had gone
10:30 - through the California community college
10:32 - system and they were talking and he told
10:34 - me about this I was like wait this
10:35 - sounds like a really great opportunity
10:36 - and you you foreshadowed this but like
10:38 - the California community college system
10:41 - is like very unlike every other
10:43 - community college system in the country
10:45 - like if you go to Community College in
10:46 - Illinois for example like it is not this
10:49 - like incredible opportunity that like
10:52 - feeds you into the greatest schools in
10:54 - the country and like the California
10:55 - community college system is that and
10:56 - they've done such a great job of like
10:58 - every every single person who is at
11:00 - those schools is like going to end up
11:02 - going to one of the University of
11:03 - California school systems which are like
11:05 - hard schools to get into and like really
11:07 - great and um yeah was fortunate that my
11:10 - my dad had started that job in
11:12 - California and I was able to move to
11:13 - California go to Community College at
11:15 - the ends for a couple of years and just
11:17 - like meet so many great professors who
11:20 - were like engineers at Apple or Google
11:22 - and their in their full-time job and
11:24 - then would come teach a class about
11:25 - software engineering at deanza uh at
11:28 - night time or something like got and it
11:29 - was just such a cool experience yeah man
11:31 - that's wild just having these world
11:33 - class engineers at like big tech
11:34 - companies just dropping in teach some
11:37 - night school classes yeah that that
11:39 - sounds like a really amazing opportunity
11:42 - so so you go over you're able to move
11:44 - over with your dad to uh NorCal like uh
11:48 - it's in the the Bay Area it's like is it
11:50 - close to Palo where exactly is deanza
11:52 - it's deanza is literally like uh less
11:54 - than a mile from Apple's uh HQ in
11:56 - copertino yeah yeah that's wild
11:59 - and uh while you're there what what do
12:02 - you do like do you do two years there um
12:05 - and and do Community College before
12:07 - transferring to uh a
12:09 - university yeah so the plan um the
12:13 - California community college system has
12:14 - this program called tag so if you meet
12:16 - some certain requirements after you've
12:18 - gone through um it's actually not like
12:21 - year base it's just like the requirement
12:23 - base which usually takes about like two
12:24 - years actually some people takes three
12:26 - years depending on how long you're there
12:28 - but you ESS do all these requirements
12:30 - and then you tag into one of the
12:31 - University of C California school
12:33 - systems um so of course they only let
12:37 - you tag into certain uh UC schools so
12:40 - like Berkeley and UCLA because of how
12:42 - competitive they are not one of the
12:44 - schools that you can tag into so you
12:45 - just need to like straight up apply to
12:46 - those schools so I I applied to Berkeley
12:49 - um which was all the the school I wanted
12:51 - to go to got weight listed and um
12:54 - ultimately didn't end up getting in and
12:56 - was trying to figure out like what is
12:58 - the next
12:59 - thing like I I could have gone to one of
13:01 - the other University of California
13:02 - school systems but I think I had in this
13:05 - mind that I wanted to like go to the
13:08 - best place possible and um ultimately
13:10 - had also applied to a program at Harvard
13:13 - and that's that's what I got into um I
13:16 - think like people have this perception
13:18 - that like Harvard is this incredible
13:19 - school which it is um if you
13:21 - comparatively look at like Harvard for
13:24 - computer science versus Berkeley for
13:25 - computer science like Berkeley's a much
13:27 - better school for computer science like
13:28 - Harvard is a great School in general but
13:30 - like Berkeley is where computer science
13:33 - was started where it where like all the
13:35 - best uh computer science stuff happened
13:37 - so um it is you know people think
13:40 - Harvard upgrade over Berkeley but in
13:42 - some in some sense but like really like
13:44 - it was a downgrade for computer science
13:46 - so um again a nice expectation setting
13:48 - for for myself yeah well and and what
13:51 - you just said Ju Just for anybody who's
13:53 - listening who is you know considering
13:55 - applying to universities maybe your high
13:57 - school age maybe you're a
13:57 - non-traditional student thinking about
13:59 - going back to University uh what Logan
14:02 - just said there uh you know the
14:04 - university itself Harvard of course
14:06 - generally considered the greatest
14:08 - University on Earth by like uh all the
14:11 - uh the standard like metrics and stuff
14:13 - uh of course also amazing uh computer
14:16 - science program cs50 David ma over there
14:20 - uh but you know
14:21 - Berkeley is like in a a league of its
14:24 - own really um and so so don't just look
14:27 - at the University
14:29 - look at the programs and and the the
14:32 - college within the university and and so
14:35 - different colleges have different levels
14:37 - of prestige and different like caliber
14:39 - of instruction and things like that so
14:41 - so those are some things to think about
14:43 - also worth pointing
14:44 - out you got into Harvard which is often
14:46 - seen as like the most selective or one
14:49 - of the most selective and you didn't get
14:50 - into Berkeley so don't be afraid to
14:53 - apply to multiple schools because you
14:55 - know uh sometimes you might get into
14:57 - what seems to be a more selective
15:00 - institution and not get into a less
15:02 - selective institution and some of that
15:03 - comes down to just dumb luck
15:05 - circumstance whoever the admission uh
15:07 - person reviewing your application was
15:10 - maybe your extracurriculars any number
15:12 - of different circumstances this is very
15:14 - complicated and there there's not some
15:17 - deterministic path to getting into these
15:20 - different programs and so it's hardening
15:22 - kind of uh probably not for you but for
15:24 - me and for other people listening
15:26 - probably to hear that you didn't just
15:27 - get into every single program you
15:29 - applied for that that You Too Faced uh
15:32 - some degree of I guess rejection for
15:34 - lack of a better word yeah it's it's
15:36 - also interesting like the thing that I I
15:38 - would not have gotten into Harvard if I
15:41 - tried to go in through the normal door
15:44 - that everybody else goes in through so
15:46 - like there's actually an a bunch of
15:47 - other schools have this like my little
15:49 - brother went to the University of
15:51 - Pennsylvania um which is again is an
15:52 - incredible School through like one of
15:55 - these like non-traditional student
15:58 - programs um and that's actually what I
16:01 - what I went to Harvard through is like
16:03 - one of the non-traditional student
16:05 - programs that they had um and again I I
16:08 - don't think I would have been able to go
16:10 - if I was just trying and this is just
16:12 - like one of those lessons in life like
16:13 - if you're trying to do the same thing
16:15 - that everyone else was doing like
16:16 - there's just going to be like more
16:17 - competition and you find like sort of
16:19 - these weird like edge cases and you're
16:22 - able to go and do like I don't think I
16:24 - would have gotten into Harvard if I had
16:25 - not found that edge case for myself so
16:28 - look look for those programs um and I
16:30 - think it's more common now that like
16:32 - more and more schools do have those
16:34 - like it's like not the normal program
16:38 - yeah I I don't I don't know what the
16:39 - best way to to frame it is but Harvard
16:41 - has it upen has it a bunch of other
16:43 - grade schools have them as well so look
16:45 - for those things if you're a
16:46 - non-traditional college student
16:47 - especially yeah be like the
16:48 - Velociraptors in Jurassic Park like
16:50 - attack the electric prins from all the
16:52 - different angles and eventually you'll
16:53 - find a way over the fence into the
16:56 - general population right um so
16:59 - while you're there uh you know college
17:02 - or college job you start working at
17:05 - Apple and and I I heard about this on
17:07 - another interview that You' done and I
17:09 - didn't realize this but you worked at
17:10 - the Apple uh store for a couple years
17:13 - and uh
17:16 - like can you talk a little bit about
17:18 - what you learned from working at the
17:20 - Apple Store uh I mean Apple of course
17:22 - the Apple Store literally like ordained
17:25 - by Steve Jobs himself and so much of
17:27 - like Apple culture and philosophy and
17:29 - everything like kind of distilled into
17:31 - that um retail experience and and there
17:34 - you are working as a a retail worker
17:36 - like a everyday job that lots of people
17:39 - who don't have education hold and you
17:40 - were working there what did you learn
17:42 - during that
17:44 - experience so much it was I think like
17:47 - the Apple Store was like one of the most
17:50 - formative experiences for for me like
17:53 - growing up and it
17:54 - was again it's like one of those things
17:56 - that like I just applied onl and like
17:58 - got lucky enough to make it through the
18:01 - inter because like it's actually kind of
18:02 - hard to get those jobs too like there
18:04 - was this I went to this recruiting event
18:06 - and there was like a massive number of
18:08 - people there and end up being like a
18:09 - small group of us who who were hired and
18:11 - it was just such a like a few things
18:13 - that are extremely relevant to me today
18:15 - which is like how to talk to people who
18:18 - have like such varying levels of
18:20 - technical background like you go into a
18:21 - conversation and like one like
18:23 - especially being at an Apple store in
18:24 - California like one of the people who
18:26 - I'm trying to help uh you know their
18:28 - phone like could be an engineer at Apple
18:30 - or we were like a stone throw away from
18:32 - the Netflix uh headquarters like could
18:34 - be an engineer from Netflix the next
18:36 - person who comes in could be like a
18:37 - little old grandma who's 80 and like
18:39 - literally has no idea how her phone
18:40 - works and having to meet people where
18:43 - they're at both from like a technical
18:45 - perspective but also like an emotional
18:47 - perspective like I don't think people
18:48 - think a lot about this unless this has
18:50 - happened to you but like the Apple Store
18:52 - is like a really emotional place like
18:54 - from a bunch of different angles whether
18:55 - it's like the excitement of you know
18:57 - getting a new device and like this new
18:59 - cool thing that you're really excited
19:00 - about or like the frustration of like I
19:03 - have something that has my personal data
19:06 - on it has so many of my memories on it
19:07 - and it's not working or like it's not
19:09 - doing the thing that I'm expecting it to
19:10 - do so you you're really like constantly
19:13 - level setting and matching people across
19:15 - these like really wide spectrums and
19:17 - it's such a such a life lesson and I
19:20 - don't think like you you're not forced
19:23 - into that type of like environment on a
19:26 - very consistent basis like many many
19:28 - many like you would I would go out to
19:30 - help customers and like you're really
19:31 - helping someone for five minutes and
19:33 - then you're going on to the next thing
19:35 - for eight hours and like you you know
19:38 - you don't normally in life like get that
19:39 - many shots on goal um to sort of build
19:42 - those skills and I think it was just
19:43 - such a transformative experience for me
19:46 - interesting so like every experience
19:48 - like and you know there's so many other
19:50 - emotions that I feel going into like an
19:52 - Apple Store like oh my gosh I'm about to
19:54 - spend a thousand bucks on a phone or
19:55 - whatever right like this is like uh you
19:58 - know a week's worth of pay or more uh or
20:01 - you know um uh am I getting the right
20:04 - thing like like am I going to look dumb
20:06 - in front of the employee there who knows
20:09 - all this stuff am I going to look like
20:11 - I'm no more sophisticated than you know
20:14 - the geriatric you know person who just
20:16 - needs to use a few features on their
20:18 - phone right uh especially as a developer
20:20 - now when I when I go to like an Apple
20:21 - store or something it's kind of like you
20:24 - know they don't know how to talk to me
20:25 - and at the same time I don't want to see
20:27 - pompus and like oh know all about that
20:29 - you know so I can only imagine like the
20:31 - sheer number of interesting interactions
20:34 - there have been and you did this for
20:35 - like two two and a half years yeah I
20:38 - started as a specialist somebody who
20:39 - like just helps you buy your phone
20:41 - became like a technical uh
20:44 - troubleshooting person became a
20:45 - technical expert and the cool thing for
20:47 - me was like um so like apple does such a
20:50 - great job of like building this pipeline
20:54 - from the from the stores to Apple
20:57 - corporate so I ended up like lots of
20:59 - folks who I worked with were in college
21:01 - and like as they were graduating were
21:03 - fortunate enough to like get jobs at
21:04 - Apple corporate and someone who I knew
21:07 - uh my mentor Omar was uh yeah like got a
21:12 - job at corporate referred me for the
21:13 - internship program I ended up
21:15 - interviewing and they were like at the
21:17 - time I you know was was also going to
21:20 - Harvard and had done some internships
21:22 - and stuff like that so um they were like
21:24 - yeah this is actually like such a
21:25 - perfect set of experiences like they
21:27 - really wanted someone who had Apple
21:29 - retail experience and then when I joined
21:31 - Apple um I was a software engineer like
21:34 - working on retail store apps like
21:35 - there's all these internal applications
21:37 - that power the Apple Store so it was
21:38 - fortunate enough to do that and then uh
21:41 - yeah worked on some machine learning
21:42 - stuff for the Apple Store too so like it
21:43 - was all of these experiences again like
21:46 - in the moment I was like had no idea
21:48 - that it was going to end up being like
21:50 - extremely useful to my actual job in the
21:52 - future having had this retail experience
21:54 - and it ended up being like the
21:56 - differentiator from being between
21:57 - solving these problems like well and not
21:59 - being able to solve them at all well
22:01 - that that's also a testament to the
22:03 - Apple Store and like the administration
22:04 - of it that they saw that you were
22:06 - interested and curious and and you know
22:08 - willing to learn new things and and they
22:11 - gave you kind of the slack to be able to
22:13 - uh progress uh with your skills and and
22:15 - help in other ways rather than I mean
22:18 - amazing like you could be like the
22:19 - number one iPhone salesperson in the
22:21 - store or something like that and like
22:23 - maybe they would be like well we need to
22:25 - keep him here because he's already
22:27 - really good at what he's doing but like
22:28 - they actually let you kind of grow
22:29 - within the role a little bit that's
22:31 - that's really good um and I'm curious
22:34 - like I I don't remember the exact
22:35 - timeline because I spent a great deal of
22:37 - time on your website and your LinkedIn
22:39 - trying to like piece together okay what
22:40 - is the chronology of Logan Patrick but
22:43 - like at what point did you start
22:46 - interning at
22:48 - Nasa yeah so that's a that's a great
22:51 - question and there's so much um I think
22:54 - the the thing that I appreciated about
22:56 - my time in community college is like
22:58 - like it is not um going back to like the
23:01 - differences between like the regular
23:03 - like traditional four-year college
23:04 - experience like it was not a very social
23:06 - experience so like I had a lot of free
23:09 - time to work at the Apple Store to do a
23:11 - bunch of other stuff because it's like
23:13 - people are like everyone is like so
23:15 - focused on like getting out of dianza
23:18 - actually getting out of Community
23:19 - College is like the thing that people
23:20 - care about like to go on with the next
23:22 - step of their Journey so um I spent a
23:25 - lot of time just like applying for
23:26 - random internships and was lucky enough
23:29 - at the time I was like cold reaching out
23:32 - to people on LinkedIn being who were
23:34 - researchers at Nasa being like hey I'm
23:36 - really interested in the work that
23:37 - you're doing like would love to hear
23:39 - more and like come in and talk and like
23:40 - see how I can help like I'm a have a
23:42 - computer science background and um
23:44 - somebody who I had messaged like three
23:47 - months prior ended up messaging me back
23:49 - being like Oh hey like super cool like
23:51 - you want to come in and like talk and I
23:53 - went in he was like yeah like would love
23:55 - to have you on the team and it was like
23:57 - really
23:58 - really it was like that that simple and
24:01 - that was the first team that I worked
24:03 - with and we were doing some stuff with
24:05 - um with NASA satellites ultimately left
24:08 - that team applied for a bunch of
24:09 - different internships at Nasa after I
24:11 - had a little bit more experience like
24:12 - doing that for a few months and um then
24:15 - joined the team that I ultimately spent
24:17 - like the next like three years on uh
24:19 - using Julia doing a bunch of other stuff
24:21 - so um yeah
24:24 - it's awesome well so again I'm just
24:28 - trying to like distill what you're
24:29 - saying down into actionable insights for
24:31 - people that are listening like don't be
24:33 - daunted don't don't be afraid to hit up
24:36 - some engineer at Nasa and just say like
24:38 - hey are there any roles for me there
24:40 - like that takes a lot of audacity as a
24:42 - community college student who's working
24:44 - at the uh you know Apple Store but we
24:47 - can definitely get into juliia and I'm
24:49 - excited to talk about that but I want to
24:50 - talk about how you transition from going
24:54 - to Danza to going to Harvard because
24:57 - again as we as we said several times
24:59 - before like Harvard is like kind of the
25:02 - educational mecca for so many students
25:04 - it it attracts so many ambitious people
25:07 - every year and it's extremely selective
25:09 - I think it's like three or 4% of people
25:10 - who apply get in uh so maybe you can
25:13 - talk about how you got in and what you
25:16 - did there and the difference maybe
25:18 - compare and contrast Community College
25:20 - where everybody's just trying to get
25:22 - through it to the actual kind of
25:24 - classical college experience that's
25:26 - existed for like 400 years
25:28 - in this country where people like you
25:31 - lived on campus in
25:33 - Harvard yeah it's it's an interesting I
25:36 - I've had a a very unique College Journey
25:39 - so I um at the end of my two years at
25:42 - deanza I was still in California and
25:45 - decided I was going to go to Harvard
25:49 - um started looking for so again I I was
25:52 - part of one of those one of the
25:53 - non-traditional programs at Harvard so I
25:55 - had the capacity like I had to SP spend
25:58 - I had two years left of college I had to
25:59 - spend a year on campus um to fulfill
26:02 - that requirement but I also had a little
26:03 - bit more flexibility like I didn't have
26:05 - to spend both years on on campus I was
26:07 - actually planning to spend both years uh
26:10 - on campus but I this was also when I was
26:13 - interning at Nasa this is also when I
26:14 - was working at the Apple Store um so I I
26:18 - decided and like all happened very
26:19 - quickly like I would have had to like
26:21 - move to Boston like the next month and
26:25 - like move in and like do all stuff I was
26:26 - like well this is a little bit
26:27 - overwhelming like I'll I'll move in in
26:29 - January and like do the next so then
26:31 - I'll spend like three semesters on
26:32 - campus um so I was still at the Apple
26:34 - Store I was still um working uh at Nasa
26:40 - part-time and I was going to I did my
26:42 - like first semester remotely essentially
26:44 - interesting like I didn't even know that
26:45 - was possible what year was this this was
26:49 - 20 uh 2018 okay so it was like
26:54 - correspondence courses or or was it like
26:56 - like Muk type where you're were you
26:59 - watch a lecture no it wasn't M I
27:01 - actually think one of them was more like
27:03 - more like traditional Muk type but the
27:05 - other ones were like live like we were
27:07 - actually on Zoom we were like doing all
27:08 - this stuff like like pre pandemic like I
27:11 - think Harvard was like a little like
27:12 - actually around that corner already like
27:15 - they had this infrastructure set up and
27:17 - like there were students in the
27:18 - classroom there were these like virtual
27:21 - um kind of like what again happens with
27:23 - like virtual classrooms today there was
27:24 - like uh TVs in the classrooms with like
27:27 - where virtual students were dialing in
27:29 - um because part of the part of the like
27:31 - non-traditional angle of this was like
27:33 - also making some of these classes
27:35 - accessible to people who are not um like
27:37 - based in the like who are't US citizens
27:39 - who could like take classes
27:41 - internationally so there people from all
27:42 - over the world like all walks of life
27:44 - which is really interesting um but it it
27:48 - ended up being like the fact that I had
27:50 - stayed at the Apple Store that semester
27:53 - while I was taking those first four
27:54 - classes um the fact that I stayed at
27:57 - NASA while I was doing those classes as
28:00 - well so things got very busy very very
28:01 - quickly that's ultimately when I got my
28:04 - interview and internship offer to come
28:07 - back to work at Apple as a software
28:08 - engine here so had I actually left and
28:10 - gone and done something else like I
28:11 - perhaps wouldn't have had that
28:13 - opportunity so in hindsight I'm really
28:14 - glad and then in the course of a very
28:16 - short amount of time I did my interview
28:18 - to join apple as an intern while I was
28:21 - doing my first semester at Harvard um
28:23 - and like the next week i' had applied
28:25 - for a bunch of other internships and and
28:28 - uh got an interview at Disney to go do
28:32 - um engineering down in Los Angeles and
28:34 - ultimately like got the offer to join
28:37 - Disney and it started at uh in January
28:40 - so I had this plan of like moving to
28:42 - Boston that semester um in the coming
28:46 - January and like that like kind of
28:47 - shifted under my feet as I was like hey
28:49 - this is a really really cool opportunity
28:51 - and also like had I been a part of a
28:53 - traditional program I would not have had
28:55 - the capacity to do that so I ultimately
28:57 - moved to LA in January of
29:00 - 2019 um and like reduced my course load
29:04 - uh and was only taking like two classes
29:06 - that semester because I was working
29:08 - full-time at Disney at that point and
29:09 - wow uh left yeah left the Apple Store
29:13 - wow that's such like it sounds like you
29:16 - had to do a lot of on the-fly planning
29:18 - and uh reworking of your schedule so you
29:21 - worked at Disney for a while uh as a
29:23 - software
29:24 - engineer yeah we we were doing like sis
29:27 - I think it was like system software
29:29 - engineering or something like that but
29:30 - we were building roller coaster
29:31 - simulations which is really really cool
29:33 - so we were part of um we were a like
29:35 - embedded team at the Walt Disney
29:38 - imagineering campus in in LA and focused
29:43 - on like again improving ride throughput
29:46 - and like all these really interesting
29:48 - like roller coaster engineering problems
29:50 - that like people don't think about but
29:51 - like it's a very very very Niche Disney
29:54 - thing but it was it was a ton of fun it
29:56 - was my first like
29:58 - as
29:59 - a as a junior in college was like really
30:02 - embedded in this team and like be was
30:04 - fortunate enough to work with like so
30:06 - many incredible people and it was like I
30:07 - was a real member of the software
30:09 - engineering team like I was doing the
30:10 - same work as they were hand inand side
30:13 - by side the same level of
30:14 - responsibilities it was like a very very
30:17 - like people think about like sometimes
30:19 - internships and like you're getting
30:20 - coffee for someone or whatever like this
30:22 - was like the very opposite end of the
30:24 - spectrum where I was like a true member
30:26 - of this team doing this work and it was
30:28 - so like eye openening to have that
30:30 - experience and be able to like be a real
30:32 - contributor and I I loved it yeah wow uh
30:35 - I saw a really cool like YouTube video
30:37 - about like Space Mountain and like the
30:39 - the throughput in terms of like the
30:40 - number of people how many different you
30:43 - know I guess trains they have going
30:45 - through the ride and like that's exactly
30:47 - what we would do we would literally like
30:48 - build those simulations so that we could
30:50 - be like okay as we tweak these like few
30:52 - parameters and like we change the show
30:54 - or we like slow down the ride here like
30:57 - how does that affect the overall number
30:58 - of people who we can get through this
31:00 - ride in one day without like lowering
31:02 - the experience for people so um we I I
31:05 - worked for a long time on uh the I
31:09 - forgot the Tower of Terror in Florida so
31:11 - we built that Tower of Terror simulation
31:13 - and like did a bunch of modifications so
31:14 - I wonder if it's uh made any impact on
31:17 - the actual ride yeah man that so I mean
31:21 - a lot of mechanical engineering types
31:23 - would that would be like their
31:24 - destination like after a long career
31:26 - they're like finally I'm at Disney where
31:28 - I wanted to be all along doing
31:30 - simulations on you know roller coasters
31:32 - and you're here as a community college
31:35 - student who like or recent like you're
31:38 - here as like basically like a probably
31:40 - like a junior at Harvard taking this
31:42 - reduced load and working at Disney in La
31:45 - like that's got to be a wild uh I mean
31:47 - did you ever have to like wake wake up
31:49 - in the morning and like pinch yourself
31:51 - that like things are actually moving
31:52 - this quickly did you have any inkling
31:54 - that this would happen when you were you
31:56 - know a kid
31:57 - like sophomore year like playing Flappy
32:00 - Bird that it would lead to this I I
32:02 - don't think so and I think like this
32:04 - goes back to like what is the value um
32:07 - like I think Harvard is an incredible
32:08 - institution to like learn a bunch of
32:10 - stuff but I also think like despite you
32:12 - know what what everyone says and despite
32:14 - like all the trade-offs and downsides
32:15 - like it does open up a lot of doors and
32:17 - I think like had I had I chosen to go to
32:19 - one of those other schools like maybe I
32:21 - wouldn't have had that door open for me
32:23 - and um I'm fortunate and I'm glad that I
32:25 - was able to but I yeah the even looking
32:28 - back now it's like again in hindsight
32:31 - it's like oh yeah this makes a lot of
32:32 - sense but like in the moment it was like
32:34 - all of these like I'm like seeing the
32:37 - like splintering of the fabric of the
32:39 - universe in front of my eyes being like
32:41 - this is weird like I don't think this is
32:42 - what is supposed to be happening but it
32:44 - goes back to like I I didn't talk about
32:46 - this um but
32:49 - the the amount of times that it takes to
32:53 - apply to some of these things when
32:55 - you're somebody who's early career is
32:58 - just like is a little bit mind- dumbing
32:59 - like to get my job at to get my
33:03 - internship at NAS at Apple during that
33:06 - time that I was working at the Apple
33:07 - Store I applied like 506 times to
33:10 - different roles and opportunities only
33:13 - specifically at Apple like that wasn't
33:14 - including all the stuff at Nasa that
33:16 - didn't include Disney and like all these
33:17 - other times 500 times just at Apple and
33:20 - I got probably like 10 or 12 different
33:23 - interviews for like different teams for
33:25 - like random full-time jobs which I was
33:27 - totally not qualified for I don't know
33:29 - why they were interviewing me CU I was
33:30 - like working at the Apple Store in a
33:31 - community college student but somehow
33:33 - they were like oh this kid maybe could
33:34 - do something but then ultimately got the
33:37 - one interview that led to my internship
33:39 - which led to like my full-time job offer
33:41 - out of those 500 and I think the the
33:43 - lesson is like so many people that I
33:46 - talk to even like folks who are very
33:48 - close to me who have like heard this
33:49 - story from my own mouth and like seen
33:52 - that this experience with their own eyes
33:54 - like they're like yeah you know I apped
33:56 - like five or six times or this thing and
33:58 - like it didn't work out and therefore
33:59 - I'm going to move on to the next thing
34:01 - and I have this posted note sitting
34:03 - above my computer with the with the
34:05 - simple phrase which is measure in
34:07 - hundreds and I think like people are so
34:09 - quick to measure things in a very like
34:12 - small way and like not see it work out
34:15 - and then move on to the next thing and
34:17 - like you really need to measure in
34:18 - hundreds when you're when you're that
34:20 - early in your career because it just
34:22 - takes so like there's just so much blind
34:24 - luck that's involved that that is
34:26 - amazing
34:27 - anecdote that you have a posted measure
34:29 - in hundreds that's definitely a
34:31 - candidate for the title of this podcast
34:32 - episode so let's talk about uh uh
34:37 - Harvard I mean when you eventually get
34:38 - over there as like a a student were you
34:41 - able to actually do three semesters
34:42 - there I I did one so in um fall of 2019
34:47 - I moved uh to Boston to to Cambridge and
34:50 - actually at the time my little brother
34:52 - had started that program at the
34:54 - University of Pennsylvania which was a
34:56 - again kind of like a hybrid type program
34:59 - so he actually moved to Cambridge with
35:00 - me and we lived um right by uh uh this
35:06 - this Fresh Pond if anyone lives in
35:08 - Cambridge there's this uh Pond that that
35:10 - is really nice to go walk around and
35:12 - hang out near um but we lived right by
35:14 - Fresh Pond and very very overwhelming
35:17 - experience coming because at that time I
35:19 - was now essentially like a senior in
35:21 - college like stepping on to this campus
35:23 - for the first time like not knowing
35:25 - anyone um never having had that it was
35:28 - it was actually like my first time ever
35:29 - going to Harvard so it was just you
35:32 - never even been to the campus never even
35:34 - been to Boston before never been to the
35:35 - campus like first time experiencing that
35:38 - and it was just um yeah very very very
35:42 - overwhelming I think yeah like it was it
35:45 - was like a fine first semester but like
35:46 - all the like normal challenges you can
35:48 - imagine like at at by the time it's
35:50 - senior year of college like everybody
35:52 - has their friend group like everybody
35:53 - has all these other things going on so
35:55 - like again this was a very
35:57 - like I I don't think I was like you know
35:59 - very
36:00 - like um yeah I'm a I'm a a social person
36:04 - by default so like I always I find some
36:07 - like social Outlets like it's not like I
36:08 - was like sad because I didn't meet
36:10 - everyone like it wasn't like a
36:12 - depressing experience but it was just
36:13 - like kind of interesting to like have
36:15 - the observation of like going in as like
36:17 - a complete Outsider and like not really
36:19 - feeling a strong sense of like being a
36:21 - part of the culture um and that that
36:24 - ultimately led to like well we could
36:25 - talk more about it but like me having
36:27 - the time and freedom and desire to like
36:29 - want to go do a bunch of Open Source
36:31 - stuff because I was like hey I'm not
36:32 - connecting with this community that I'm
36:33 - there in person with really like I have
36:36 - this community that I've connected with
36:37 - online and like would love to like do
36:39 - more around that but yeah did my first
36:41 - semester on campus um and then Co
36:43 - happened and then and then spent the
36:46 - next spent the next six months
36:48 - hibernating inside of an apartment um
36:51 - again doing like it was it was you know
36:54 - a lot of bad stuff around Co and it was
36:56 - probably not the idea ideal timing but
36:57 - like it also gave me the forcing
37:00 - mechanism to like spend my time inside
37:03 - contributing to open source and like
37:04 - building my like next career step in in
37:07 - that sense well let's talk about Julia
37:09 - Lang now because that is again a a
37:12 - statistical language that's used by a
37:14 - lot of data scientists a lot of um
37:18 - scientists and maybe you could talk a
37:20 - little bit how you got involved in that
37:22 - community and became one of the more
37:24 - prominent voices uh teaching
37:27 - spreading the gospel of
37:29 - Julia yeah I was again another great
37:32 - example of like how you never know
37:34 - what's going to happen in life so when I
37:35 - applied to the second team that I was on
37:38 - um at Nasa I showed up the first day and
37:41 - they happened to be using a programming
37:42 - language called Julia and like that's as
37:45 - simple as The Story Goes and like as
37:47 - part of that um as part of that process
37:50 - they this was before Julia had hit the
37:52 - 1.0 release like one of the first tasks
37:54 - was like helping migrate some of the
37:56 - initial code bases to like the 7 release
38:00 - which was like the precursor to the 1.01
38:02 - um and I like things were broken like it
38:06 - stuff wasn't well documented so I just
38:08 - kind of like had to get involved in the
38:09 - community um over time to like fix my
38:13 - own problems uh which is why I like met
38:16 - a bunch of people and then ultimately
38:18 - like I was like oh there's all these
38:19 - really cool opportunities where I could
38:20 - actually contribute and start doing some
38:22 - of this like educational and Community
38:24 - work um and just kind of like step Ste
38:26 - in and initially ran our I don't know if
38:30 - you remember Google codein but it was
38:32 - like Google's kind of Google summer of
38:34 - code but for high school students you
38:36 - could build these tasks and help high
38:38 - school students um so ended up running
38:40 - our initial engagement with Google codin
38:43 - we like mentored like 212 high school
38:45 - students um and it was like this
38:48 - incredibly empowering experience and I
38:51 - was like I really want to do more of
38:52 - this type of work and I reached out to
38:54 - the folks who were like running the
38:56 - actual language and the development of
38:57 - the project and was like Hey I L doing
39:00 - like I did this thing and like I loved
39:01 - it and I would love to do it in a more
39:03 - of an official capacity and they were
39:04 - like awesome we'll bring you on the team
39:06 - um join the team and then like a month
39:10 - in they were like oh we actually have
39:12 - this community manager title that like
39:14 - no one is using right now and like we uh
39:18 - yeah like would you want to would you
39:19 - want to have that title and I was like
39:21 - naively I was like really had never
39:23 - heard of a community manager at that
39:24 - point I was like yeah that kind of
39:26 - sounds fine like I'm happy to take that
39:28 - on and they gave me that title and all
39:30 - of a sudden there was a sort of uh
39:32 - commentator of explosion of like
39:34 - different things that now fell under the
39:36 - umbrella of what I was supposed to be
39:38 - doing um yeah and took on had to take on
39:42 - a lot more work once that happened yeah
39:44 - I can imagine so maybe you can just give
39:47 - us a quick rundown of Julia language
39:50 - obviously used by NASA huge endorsement
39:53 - of its Merit as a language for doing
39:55 - scientific computing
39:57 - uh what are if you had to like pitch the
40:00 - audience on Julia as like hey it's worth
40:03 - learning Julia like what would be your
40:05 - kind of elevator pitch for
40:06 - Julia yeah there's there's three things
40:09 - that so deeply resonate with me um as
40:11 - far as why folks use Julia today one of
40:14 - which is speed so um with Julia you can
40:16 - get like C or C++ level uh code
40:21 - execution um with a high level language
40:25 - still so like with a high level language
40:26 - which like python so it runs a lot
40:28 - faster than python but um yeah still
40:31 - still easy to use I think the second
40:33 - thing and this is one of the things
40:34 - that's a little bit slept on is the
40:36 - package ecosystem and the way that you
40:39 - manage packages in Julia just works they
40:42 - built the language and they're like
40:43 - let's really solve this problem and
40:45 - let's do a bunch of things from a core
40:47 - language design principle that makes it
40:48 - so that you don't run into all the
40:50 - annoying problems that you run into
40:52 - installing python packages so that's
40:54 - something that I love like I never I I
40:56 - still just literally yesterday was
40:58 - running a bunch of code and I was like
40:59 - why is it so annoying to install python
41:02 - packages um so you don't have that
41:04 - problem in Julia and I think the last
41:07 - thing is the language was really
41:10 - purpose-built
41:11 - um to to make it so that you can like do
41:15 - everything in Julia but also tap into
41:19 - other languages where it's useful so
41:21 - like I I think a lot of languages are
41:22 - like oh like we are the one solution
41:24 - that is going to do this and like you
41:26 - need to move all your stuff to our
41:28 - language if you want to successfully use
41:30 - you know python as an example and um
41:33 - Julia has first class interoperability
41:36 - support between it and like every other
41:38 - large language um so if you have like a
41:41 - you know some python code that you're
41:43 - really happy with and you're like I'm
41:44 - not getting rid of this python code
41:45 - that's fine you can actually keep that
41:47 - python code put it directly into a Julia
41:49 - file and then use Julia for what it's
41:51 - great for and you keep using python for
41:53 - what it what it's valuable for for you
41:54 - as well so I I really love that as like
41:56 - a middle ground between like being super
41:59 - absolutist that you need to move
42:00 - everything to one language um yeah well
42:03 - that seems like a very pragmatic way to
42:05 - position a language when you've got you
42:06 - know the dominant like languages that
42:09 - have that are pretty entrenched like
42:10 - python is is you know a big deal right
42:14 - now and then of course you you've got
42:15 - like R and even mat Lab at like the
42:18 - University Research type level so the
42:21 - fact that Julia it seems very Savvy to
42:23 - them to to make it like uh you don't
42:25 - have to adopt Julia Whole Hog so to
42:28 - speak you you can just uh incorporate it
42:31 - a little bit into your your
42:33 - workflow yeah and really I I also think
42:36 - like Julia at the end of the day like
42:38 - python is so widely distributed that
42:40 - Julia is not really competing against
42:42 - python uh I think Julia is really
42:44 - competing against like the mat Labs of
42:46 - the world and like nobody really likes
42:47 - mat lab that much like matlb you have to
42:49 - pay like it's expensive yeah it's a it's
42:53 - a pain to use like Julia's really aimed
42:55 - at like targeting the core demographic
42:58 - of folks who are using mat lab not
43:00 - really P like I think people who use
43:02 - Python can also use Julia but it's
43:04 - really the mat lab users that were like
43:06 - the core reason that the language was
43:07 - built well I'd be excited to first of
43:11 - all I just want to take a moment to
43:12 - thank you for writing these excellent
43:14 - tutorials on Julia that we published on
43:17 - the Freo Camp Community publication uh
43:20 - tens of thousands of people have learned
43:22 - about Julia thanks to your your
43:24 - thoughtful tutorials so thank thanks for
43:26 - making time to do that yeah that's so
43:28 - cool that's one of the most like
43:30 - rewarding things about writing stuff is
43:32 - knowing that like people actually went
43:34 - and read it and then were able to like
43:36 - hopefully effectively like learn
43:37 - something new so that's that's so cool
43:39 - yeah and I also want to talk a little
43:41 - bit about num Focus which is this really
43:43 - important charity that is you know
43:47 - essentially overseeing like a lot of the
43:48 - key infrastructure that the entire
43:50 - scientific Community relies on uh and
43:53 - you're on the board of the charity so
43:56 - that's a pretty big deal I don't know
43:57 - how big the board is but um being a
44:00 - board member on a charity is like that's
44:03 - not an easy feat to accomplish and
44:06 - there's a lot of responsibility there
44:07 - maybe you can talk a little bit about
44:08 - numb numb focus and and you know they
44:11 - support like conferences like Pi data
44:14 - they're in charge of the projects like
44:16 - Jupiter notebook um numpy like projects
44:21 - that developers use all the time that
44:23 - are dependencies in so many important
44:26 - applications uh how how did you get
44:28 - involved with num
44:29 - Focus yeah it's a great question so num
44:32 - focus is the fiscal host for a ton of
44:35 - Open Source projects which what what
44:37 - that means for folks who aren't super
44:39 - familiar is like if you want to donate
44:41 - money to the pandas project or Jupiter
44:43 - or Julia or something like that num
44:45 - Focus basically acts as the legal entity
44:47 - and the and the bank account for these
44:49 - organization so that open source
44:51 - maintainers like don't need to go and
44:53 - try to figure out how to set up a legal
44:55 - entity and don't need to figure out how
44:56 - to like pay people who are working on
44:59 - code for them and accept donations and
45:01 - do all the taxes so um they take care of
45:03 - all that administrative overhead which
45:05 - is really incredible and and freeing for
45:07 - projects and um I just I got connected
45:10 - through the ecosystem as I was taking on
45:13 - more um ownership in the Julia community
45:15 - and um we needed someone uh we num Focus
45:21 - kind of wanted somebody who was
45:23 - representing some of the non uh
45:26 - non-dominant language players on the
45:29 - board um so there was like six other
45:32 - board directors and they were they were
45:33 - looking for folks who like could
45:34 - represent that perspective of projects
45:36 - that like weren't the dominant players
45:38 - and make sure that that voice was heard
45:39 - so uh joined the board at numfocus like
45:43 - over two and a half years ago and it's
45:45 - been it's been super interesting to see
45:47 - like there's so many um how big is focus
45:50 - has today it's like six people um and
45:54 - how frequently do you meet
45:56 - every other week so
45:58 - there's very very active for a for a
46:01 - nonprofit board like usually nonprofit
46:03 - boards meet like twice a year or
46:05 - something like
46:06 - that at uh freeo Camp also 51 C3 public
46:10 - charity um yeah so so you're meeting
46:13 - with them what kind of things are you
46:14 - discussing like what what what would
46:17 - like I mean it's it's probably public
46:19 - information because you probably have to
46:20 - publicly publish the minutes and
46:21 - everything so I hope I'm not prying but
46:22 - like what would a typical board meeting
46:25 - be like what might be on the uh the
46:27 - table yeah we're we're usually talking
46:30 - about like things that are on fire um so
46:33 - there's a there's always a lot of things
46:34 - that are on fire when you have a like a
46:38 - really large like I think proportionally
46:41 - to the amount of developers that are
46:44 - like there is I was doing the numbers
46:46 - like I'm pretty sure the the software
46:48 - that num Focus use it that that like num
46:50 - Focus supports is like downloaded like a
46:53 - billion times a month or something like
46:54 - that so like it's a crazy amount of
46:57 - people and like scope for such a small
47:00 - organization to support so like there's
47:02 - always things going wrong and like as
47:03 - you know like uh nonprofits are like
47:06 - historically under resource so like
47:08 - we're trying to make a lot of things
47:10 - work with like duct tape and glue and
47:12 - like it's very uh it is very difficult
47:14 - so it's a lot of those things I think
47:16 - there's a decent amount of our time is
47:18 - focused on like how do we make sure that
47:20 - num Focus as a nonprofit like stays like
47:22 - financially solvent so like we're we're
47:24 - going and talking to large operations
47:26 - about like how do we how do we partner
47:28 - with them to like get money in the door
47:30 - um I know you you have to do this all
47:32 - the time to like keep the lights on at
47:33 - free code camp and like it's not the
47:34 - most exciting thing to do sometimes but
47:36 - like it's important and like at the end
47:38 - of the day we have all these open source
47:39 - projects that are relying on the
47:41 - services that we provide and like if we
47:42 - don't keep if we don't stay solvent if
47:45 - we don't keep the lights on we can't pay
47:46 - people to do the work that's required to
47:48 - support these projects so it's um that
47:50 - that is often times like priority number
47:53 - one is how do we make sure we have money
47:55 - coming in the door so that we can
47:56 - provide services to projects uh there's
47:58 - there's a bunch of fun stuff too like
48:01 - getting to focus on and like help
48:02 - support um a bunch of our PI data events
48:05 - which are just like this Global
48:06 - distributed network of um of events for
48:09 - developers who are building with the
48:11 - scientific tools that we support um but
48:15 - it's a lot of putting out fires it's a
48:16 - lot of um it's a lot of trying to make
48:19 - sure we have money coming in I can
48:20 - imagine all right so of course Logan a a
48:24 - little more than a year ago you got a
48:26 - job at open aai the company that
48:30 - everybody's been like focused on for the
48:32 - past um really since chat GPT dropped
48:36 - and of course a lot of people were
48:37 - interested in it way back in gp2 you
48:39 - know uh era using the playground and
48:41 - stuff like that and I really enjoyed
48:43 - watching it evolve from something that
48:46 - was kind of a novelty like this is cool
48:48 - I can see how this could be useful to
48:50 - something that I use probably like eight
48:52 - or 10 times a day right so like it's a
48:54 - dramatic uh shift and I'll say I didn't
48:57 - immediately see the value in chat GPT
49:01 - 3.5 but like GPT 4 I was like oh this is
49:04 - this is really cooking and um a lot of
49:07 - people were like H I'm not sure if it's
49:09 - useful because it so hallucinates and
49:10 - stuff like that but I I was able to kind
49:12 - of push past that and really start to
49:15 - figure out ways that I could use this
49:17 - really productively and the
49:18 - hallucination itself I think has has
49:21 - decreased but that's a whole lot of for
49:25 - me to talk about but basically what I'm
49:27 - interested in hearing from you is like
49:29 - how do you perceive this as somebody uh
49:32 - both from the outside as a user of uh
49:35 - these tools uh of the foundation model
49:39 - and of the many other ecosystem tools
49:42 - and uh then maybe you can compare and
49:44 - contrast that with what it's like to
49:45 - actually work at open
49:48 - AI yeah I'm it's it's incredible to see
49:52 - how much how how everyone when gbt 4
49:56 - came out was like this changes
49:58 - everything like everything whether I'm
50:00 - an engineer or in some other job like
50:01 - this is going to change everything and I
50:03 - think that's true in many ways and then
50:05 - it's also interesting how
50:08 - subtly humans adapt to this change and
50:11 - then now all of a sudden it went from
50:13 - this thing is crazy and it's going to
50:14 - change everything to like hey I'm just
50:16 - using this as a tool in my job eight
50:18 - times a day and like that's how I feel
50:20 - as a as an engineer as somebody who's
50:22 - who's using uh chat gbt and gbt for or
50:25 - to like help me write better code
50:27 - honestly is like the main use case that
50:29 - I'm I'm playing around with these days
50:31 - um I want to ship some new feature and
50:33 - like I'm not a typescript expert and I
50:35 - want to go and have ch gbt help me write
50:38 - better typescript code and like honestly
50:40 - it takes the first pass at like most of
50:42 - the code that I write these days like
50:44 - I'm I'm not like scribbling things down
50:46 - by hand and like doing it myself I'm I'm
50:48 - having chbt do it and then going in and
50:50 - debugging and troubleshooting I think a
50:52 - lot of the like same skills that you
50:54 - learn and a computer science education
50:56 - which is just like trying to fix things
50:59 - that are broken essentially is my is my
51:01 - like gut instinct of like what
51:03 - programming really is um is like very
51:06 - much true in the world of chbt as well
51:08 - like sometimes it's going to make
51:09 - assumptions or hallucinate things or uh
51:12 - Miss some context that was that you
51:14 - didn't give it or it it maybe just gloss
51:17 - over um and it's it's just that that
51:19 - debugging trait I think as an engineer
51:21 - becomes like so much more important um
51:24 - and so much more like visible as you're
51:26 - using codee that's been generated by AI
51:28 - in some capacity um yeah and I I think
51:32 - for like on the inside it's like
51:34 - absolute cha not not absolute chaos from
51:38 - like the like chaos perspective but like
51:41 - the the speed at which people are moving
51:44 - is is incredible to see and I think it's
51:46 - like super inspiring and it's something
51:47 - that I really like how fast we're we're
51:50 - we're building towards um stuff and like
51:53 - also not from like this like very high
51:55 - level like changing the world speed
52:00 - perspective but it's like there are all
52:01 - these like very very tangible problems
52:04 - that like people have brought up because
52:06 - like now there's millions of people who
52:07 - are using our platform and our tools and
52:09 - like I appreciate the speed at which
52:10 - people are solving those problems like
52:12 - hey I'm a user I have this bug we go and
52:15 - tackle that like really really quickly
52:16 - and and I love that like hey it would be
52:18 - awesome if as a developer you know we
52:20 - had these higher levels of abstraction
52:22 - on top of some of the chat completions
52:25 - and completion tools and like awesome we
52:26 - went and built assistance for people so
52:28 - that they don't have to manage the
52:29 - conversation history themselves all
52:31 - those kinds of things like there's just
52:33 - so much urgency and in doing what users
52:35 - and developers are asking us for and I
52:38 - love that yeah so as a developer like
52:41 - you mentioned earlier just like using it
52:43 - to kind of Coach you on typescript like
52:45 - here's some typescript I wrote like how
52:46 - can this be more I guess succinct or how
52:50 - can it be less prone to errors or
52:52 - something like that right um can you
52:54 - give some other examples of how you use
52:57 - uh GPT just like in your day-to-day
52:59 - workflow like do you have like a chat
53:00 - GPT window open or do you have some sort
53:02 - of like uh you know Chrome brow browser
53:05 - extension that like hits the API and
53:07 - like does other stuff like how do you
53:09 - consume
53:11 - GPT yeah I'm a I'm a big um I'm a big
53:15 - chat gbt user like I actually I I use
53:18 - sometimes I use like copilot and cursor
53:20 - folks have tried cursor before it's like
53:22 - a intelligent uh IDE that's like built
53:25 - with AI first Primitives um but really I
53:28 - like I like chat gbt I like having the
53:30 - same experience that our users do and
53:32 - like honestly what what usually ends up
53:34 - happening is I go into one of the code
53:36 - bases that I'm working in I copy a big
53:38 - typescript file and I paste it in chat
53:40 - gbt and I say hey like here's the file
53:42 - that I'm working with like this is what
53:44 - I want to do in plain English I want to
53:46 - add X Y and Z feature um it should do
53:49 - you know have these different
53:50 - characteristics like help me do that and
53:52 - chyt literally will like take that first
53:54 - pass at like writing all the code that I
53:56 - need um I think the challenging part
53:59 - today for using chat gbt to do this is
54:02 - like again there's like all this Nuance
54:04 - of the context that it's missing like it
54:05 - knows what's in that file but like it
54:07 - doesn't know the like seven files that
54:09 - I've imported and like I can't really
54:12 - like in some cases I can copy and paste
54:14 - multiple files but all that context is
54:16 - sometimes overwhelming to the to the
54:18 - model just like and and I love drawing
54:20 - these analogies like just like it would
54:22 - be overwhelming for a human like if I
54:23 - went and sent you like thousand lines of
54:25 - code and I'm like oh help me do this
54:27 - thing you're like okay hold on this is
54:28 - going to take me a while because that's
54:30 - a lot of code to digest so I think
54:32 - people uh often times like forget that
54:36 - these models are trained oftentimes in
54:39 - like ways that humans interact and
54:42 - understand and read things so like some
54:43 - of the limitations that we run into are
54:45 - the same limitations that um that the
54:48 - models are going to run into like
54:49 - hallucinations is a great example of
54:50 - this as as well like I might say
54:53 - something that like in my my probability
54:56 - distribution and my head is like very
54:58 - true and like that does not mean that
55:00 - like it is an empirical fact in the
55:02 - world uh just because like I feel deeply
55:04 - that it's true and like the models are
55:06 - exactly the same way like based on the
55:08 - the information the model was trained on
55:10 - it thinks something is true um does that
55:12 - mean that that it's agreed upon by
55:14 - everybody in the world probably not in a
55:16 - lot of cases but um it's interesting to
55:18 - have that perspective I mean eventually
55:20 - you start to get into philosophy and
55:23 - like epistemology and like
55:25 - uh what is the nature of Truth what is
55:28 - the nature of reality like how could
55:29 - this be expressed in how do you arrive
55:32 - at a consensus on this how do you uh
55:35 - Express like balance like some
55:37 - scientists believe this but there's some
55:39 - small contingent that believes this you
55:41 - know like it doesn't necessarily have
55:43 - the uh if it went into every single
55:46 - pedantic detail people would stop using
55:48 - GPT right they'd be like oh my goodness
55:50 - it's like it's like uh um ask asking a
55:54 - dictionary or something like that right
55:56 - like yeah it it has to figure out kind
55:58 - of like how to cut to the Chase and
56:00 - figure out what to uh assume away right
56:04 - in terms of giving tur answers that are
56:06 - actionable and at the same time you know
56:08 - GPT does apologize for itself a lot and
56:11 - it's always kind of like well there's
56:13 - not yet like consensus on this or
56:15 - there's not uh um like I don't have the
56:18 - latest version of information on this so
56:20 - events could have changed and there's
56:22 - all this kind of like almost boiler
56:23 - plate that that sometimes shows up in in
56:25 - the responses and um I I think a lot of
56:29 - that is just an admission that reality
56:32 - is incredibly complicated or complex
56:34 - even yeah yeah I think that's why I'm
56:37 - kind of excited for for agents to like
56:40 - go out and be able to like get some of
56:42 - that like in the moment context that
56:45 - would be like really helpful and like
56:46 - get like the yeah get a lot of the
56:48 - nitty-gritty details because it is like
56:51 - um like I I hear people in the feedback
56:53 - that like it's kind of uh frustrating
56:55 - sometimes when the model gives you
56:56 - answers like that where it's like trying
56:58 - to be nuanced but like it just ends up
57:01 - not being really nuanced and just kind
57:03 - of likeah um so I I hear people on that
57:06 - and like I I think there's like a bunch
57:07 - of really interesting like technical um
57:10 - and like social things that that we'll
57:11 - hopefully be able to to try and and see
57:14 - if that helps improve those situations
57:16 - yeah like what do you think the the most
57:19 - immediate wins that are going to be
57:21 - realized over the next few years with uh
57:24 - well we'll talk specifically about chat
57:26 - gbt and this kind of like conversational
57:28 - user experience uh what do you think the
57:31 - like is it increasing the context window
57:34 - is it uh speeding up the processing uh
57:37 - like like what are the the biggest
57:39 - things that you think are going to have
57:40 - the the most profound net benefit to
57:43 - people like me and you that just use GPT
57:46 - to get things done all
57:48 - day yeah this is a great question I
57:50 - think those two that you mentioned speed
57:52 - context windows are huge ones I think
57:54 - they needs to be
57:56 - some there needs to be more reasoning
57:59 - that happens at the model level today
58:01 - the model is like truly just a token
58:04 - predictor like it is going you're going
58:05 - to put something in it's going to
58:06 - predict the next token like there is
58:08 - like people like use that as some proxy
58:11 - for it like thinking behind the scenes
58:13 - but it's not it's not thinking like it
58:16 - is truly just generating tokens um so I
58:18 - think there needs to be some ability for
58:20 - the model to like actually think about
58:22 - problems and I I don't know what what
58:23 - that will what that will look like um I
58:26 - also think like from a tooling
58:29 - perspective I think the models need to
58:32 - be able to like go and fetch the
58:34 - information that it does not know the
58:36 - answer to it needs to be able to like
58:37 - actually go and get you empirical
58:39 - information and like today the modelist
58:41 - is too uh too likely to just kind of
58:45 - like give you the answer that it thinks
58:47 - is going to be true without like
58:48 - validating that in some cases and like
58:50 - often times it's it's still correct but
58:53 - like it would be nice to like see see
58:55 - some proof of work and like know that
58:56 - it's actually done this computation or
58:59 - it's gone and pulled up these certain
59:01 - things to make sure that something is
59:03 - true I think that's going to be awesome
59:04 - I think the very last like very tactical
59:07 - piece is
59:09 - today and again using the human analogy
59:12 - the models are so inclined to just
59:15 - answer the question that you asked it
59:18 - and I think that's partially because of
59:19 - the way that the model is trained and it
59:20 - wants to like provide value as soon as
59:22 - possible but in a sorry I don't mean to
59:25 - interrupt you but I just want to Riff on
59:26 - what you were saying like if you were to
59:28 - ask a university Professor they would
59:30 - step back and say well a better question
59:32 - would be XYZ but because it's a a bot
59:37 - essentially it's in this there's this
59:38 - power Dynamic like the user is so much
59:40 - more powerful than the the bot that's
59:43 - doing the user's bidding and it doesn't
59:45 - want to like upset you or get all uppity
59:47 - or something like that because humans
59:49 - are like I'm the user damn it you know
59:51 - like do what I say and so so to some
59:54 - extent it it might give you what it
59:56 - thinks you want to hear as opposed to
59:57 - like gently pushing back and saying well
59:59 - that's that's not the right question to
60:00 - be asking or something like that right
60:03 - uh yeah it beol there like professorial
60:06 - mode or something like maybe that's just
60:08 - a prompting thing like you're an
60:10 - academic you know you're an expert in
60:12 - this field and you don't mind pushing
60:14 - back against my naive questions or
60:16 - something like that maybe if I prompted
60:17 - it differently uh I could get that kind
60:19 - of experience but um sorry I didn't mean
60:21 - to interrupt your flow but I just wanted
60:22 - to point that out that a lot of the
60:23 - frustration people may have is just by
60:26 - design of like it is a product that it
60:29 - wants people to use it right like so
60:32 - there are some accommodations that have
60:34 - been made to make it not like you know
60:37 - extremely like contrarian or
60:39 - something yeah and to go like one level
60:42 - deeper on like why this actually happens
60:44 - like this is a very um very like
60:47 - intentional design decision that's been
60:50 - that's been made so like the whole like
60:52 - the model essentially it has this pre-
60:54 - training stage where it has this large
60:56 - Corpus of information it's trained on
60:58 - all that like large Corpus of text and
61:01 - really the goal is like just predicting
61:02 - the next token based on all that text
61:05 - after it finishes that process it goes
61:07 - into this reinforcement learning with
61:09 - human feedback loop and this is where it
61:11 - sort of learns this behavior of like how
61:13 - do I interact with humans how do I give
61:16 - answers to the questions that they're
61:17 - asking and like you know if you were to
61:19 - like really plain and simple like look
61:21 - at the data that's being trained for
61:23 - these models for that reinforcement
61:25 - learning with human feedback cycle it's
61:27 - like I have this question here is the
61:29 - answer to the question I have this
61:31 - question here is the answer to this
61:32 - question like that's the way that the
61:33 - model has been trained which is why it
61:35 - it acts like that um and there are
61:38 - things you can do like the prompting is
61:39 - a great example of this like you can and
61:41 - I've seen a bunch of great examples
61:42 - online of people using custom
61:44 - instructions or gbts to be like like
61:46 - always ask me clarifying questions like
61:48 - always come to me and like try to help
61:50 - me get to a better uh like a better base
61:53 - question um and that really does improve
61:56 - the performance of the model but I think
61:58 - it's also like very
62:00 - fundamentally it's a byproduct of the
62:02 - way that these models are trained and I
62:03 - think like in the future we'll have
62:05 - probably models that are like trained in
62:06 - a slightly different way that like maybe
62:08 - push back on people a little bit more if
62:10 - they want that yeah and uh do you think
62:13 - that that's G do you think there's going
62:14 - to be like a bifurcation of products in
62:17 - the sense that like you can choose the
62:18 - model that's more like concerned with
62:21 - like probabilistic veracity and things
62:24 - like that versus just um you know being
62:27 - more
62:29 - amiable I think we've really focused on
62:33 - uh building like general purpose models
62:36 - that can do a lot of these different use
62:37 - cases well so I'm hopeful that like I
62:39 - think you know you actually probably
62:41 - could today take some problem space and
62:44 - like integrate like 25 different models
62:47 - and like have some really like complex
62:49 - logic about like what models are used in
62:51 - what situations and what types of
62:53 - questions I think like that's that's
62:55 - possible I I don't think you'll end up
62:57 - getting the best solution to a lot of
62:59 - the things by doing that because there's
63:01 - so much nuance and I think what probably
63:02 - makes the most sense is like just having
63:04 - one great model that hopefully is
63:05 - trained on like this really nice
63:06 - distribution of data um that can answer
63:09 - questions and like put it in different
63:10 - modes and stuff like that well that
63:12 - brings me to another question which is
63:14 - the developer ecosystem uh you know
63:18 - people adopting the open AI API you were
63:22 - open ai's first developer it higher
63:25 - famously and uh so one of the big things
63:27 - you're doing is trying to get people to
63:30 - adopt this and build on top of it uh and
63:33 - uh I'm curious like what are some of the
63:36 - companies in the space that are in your
63:39 - assessment doing a really good job of
63:41 - building on top of the open AI
63:44 - API yeah this is a great question I
63:46 - think one of my favorites uh people who
63:49 - have done this in a really thoughtful
63:51 - way is KH Academy KH Academy was one of
63:53 - the original gbd for launch partners and
63:56 - we we got them early access to the model
63:58 - and they were really pushing on like you
64:00 - know cellc cons uh and this is like hits
64:02 - close to home for you I'm sure because I
64:04 - think there's a lot of parallels between
64:05 - pre code camp and and KH Academy but um
64:08 - I think salon's vision is being able to
64:10 - give students like every student in the
64:13 - world the worldclass education and uh
64:16 - enabling that using like personalized AI
64:19 - tutors and they released this Con Mingo
64:21 - product and did such an incred like
64:23 - there so much Nuance in bringing AI to
64:28 - students around the world and having it
64:30 - actually be like an amplifier and not a
64:33 - tool that just like people use as a
64:35 - crutch and I think K Mingo has like
64:37 - really threaded the needle on this super
64:40 - well like if if folks have tried the
64:41 - product before um it actually like
64:45 - despite the model really wanting to give
64:47 - an answer and like being trained in many
64:49 - cases to like just give you the answer
64:50 - to the question that you asked they've
64:52 - done a bunch of things to add guard
64:53 - rails so so that students using Kingo
64:56 - don't actually uh just get the answer
64:58 - when they ask her the question they like
65:00 - actually get like the the reasoning and
65:03 - like they get more questions like the
65:04 - question goes back to them about like
65:06 - you know how would you approach this
65:08 - like how like here maybe here are some
65:09 - things to think about and like trying to
65:11 - guide people towards the answer and it
65:13 - it's a really great like they've done a
65:16 - great job of like the intersection
65:18 - between like the core technology and
65:20 - like the user experience like really
65:22 - matching up in this perfect
65:24 - yeah yeah and Khan Academy of course uh
65:27 - I think you and I have both read s
65:28 - Khan's book um and yeah like what
65:31 - they're doing for kids free Cod camps
65:33 - aming to do for busy adults essentially
65:36 - uh love we're we're not yet
65:38 - using um we don't yet have a chat bot uh
65:43 - we we decided to like wait until it was
65:45 - like a little bit more mature because
65:46 - there wasn't like any urgency we've
65:47 - already got this forum where we do
65:49 - essentially that like we use kind of a
65:51 - Socratic method of helping people answer
65:54 - their own questions essentially rather
65:56 - than just you know here's the answer
65:58 - right because I mean there's plenty of
66:00 - wikis and like every single Freo Camp
66:02 - challenge has like the solution is
66:04 - probably a million places uh all over
66:06 - the internet but if you don't want the
66:08 - raw solution if you want to be guided
66:10 - toward the answer and like make the same
66:12 - kind of like cognitive leaps that would
66:16 - be involved in discovering that for
66:18 - yourself like you can kind of do that
66:19 - just through conversation and that's
66:21 - where I'm really bullish on using uh GPT
66:26 - is one of the big things I use it for is
66:28 - language learning and so I'll ask a lot
66:31 - of questions like like you know can you
66:33 - guide me toward uh and I'll ask these in
66:36 - different foreign languages so but I'll
66:38 - ask uh questions about um what would be
66:41 - a usage pattern that would work really
66:43 - well in this situation and maybe try not
66:47 - to give it get it to give me an exact
66:49 - sentence but maybe just a structure and
66:51 - then I can say like this and then it'll
66:53 - be like oh yeah like that that's a
66:54 - that's a or not quite this is more like
66:57 - try try doing this try using this
66:59 - grammatical marker or whatever right
67:02 - so yeah I I mean that that's awesome
67:05 - what are some other companies that are
67:07 - using uh the open AI API in interesting
67:11 - ways that you think are impactful and
67:12 - that you think I think uh represent like
67:16 - um something that other companies could
67:17 - seek to
67:18 - emulate yeah another really interesting
67:20 - one on the topic of like interfaces that
67:24 - like really bring this technology to
67:26 - life I don't know if you've seen the
67:27 - demos of TL draw um it's this it's this
67:32 - yeah it says interface where it's
67:33 - essentially like a blank canvas and you
67:35 - can use prompting to like and drawing to
67:37 - like generate images and a bunch of
67:39 - other stuff but the the basic idea is
67:42 - like the form factor for AI today for so
67:45 - many people is like chat experiences and
67:48 - people like Chad they do text in text
67:50 - out maybe add some images and I think TL
67:52 - draw is really pushing on this idea that
67:54 - like what maybe could be more useful
67:56 - than chat in some cases is this like
67:58 - Infinite Canvas experience and being
68:00 - able to like you know take all these
68:02 - different like our our lives are very
68:05 - like I'm looking at my desk it's like
68:06 - almost this Infinite Canvas that I'm
68:08 - like have in my physical world and um it
68:11 - like brings to life all the things that
68:12 - I need and I'm really excited for the
68:14 - for AI experiences to move more towards
68:17 - things like that where like they're
68:18 - these very unique interfaces which like
68:21 - actually bring this technology to life
68:23 - and a different way than just like a
68:25 - chat chat in and out so yeah I think
68:28 - 2024 we're going to see so many more
68:30 - products that are like that where it's
68:31 - like this different user experience I'll
68:34 - link to uh a demo I'll see if I can find
68:36 - a demo but maybe you can just describe
68:37 - verbally like how it works so like I
68:39 - draw something and then it's like like
68:41 - this like does it does it enhance my
68:44 - stick figures or how does it work yeah
68:47 - exactly that so it's using like image
68:48 - models and some Vision models and and uh
68:51 - text prompting models to take what you
68:53 - draw and actually turn it into something
68:56 - something super crazy um and that's just
68:58 - like one like that that's like they've
69:00 - built all of these different demos but
69:01 - it's really like the underlying
69:03 - technology that powers that demo is this
69:06 - like Infinite Canvas experience where
69:08 - like you can go and like interact with
69:11 - like Ai and also like multiplayer with
69:13 - other humans and like really like bring
69:15 - some of this stuff to life that I don't
69:17 - think like traditional chat experiences
69:19 - really allow you to do so it's it's
69:21 - super cool yeah and
69:25 - multimodal is like a big thing that uh
69:27 - GPT has been incorporating and just the
69:30 - notion that you can like feed in images
69:32 - you can feed in uh potentially video you
69:34 - can feed in like all all kinds of
69:36 - different media into it and then it can
69:39 - kind of Riff on that um and and that's
69:42 - something that like what are some ways
69:44 - that you see that being impactful over
69:46 - the next year or
69:47 - two yeah that's a great question I think
69:49 - like vision is one of the biggest
69:51 - unlocks for these systems like I I when
69:54 - I was working at Apple as a machine
69:56 - learning engineer the project that I was
69:58 - working on was uh being able to predict
70:02 - the tradein price of an iPhone based on
70:05 - pictures of it so we actually if you go
70:07 - into the store today and you trade in
70:09 - your phone they do this they take
70:10 - pictures they run the machine learning
70:12 - model that we trained um and it predicts
70:14 - based on the condition of the phone the
70:17 - uh price of it and a very very difficult
70:20 - machine learning problem because of all
70:22 - these different constraints and I'm
70:24 - I saw Vision come out and I was it was
70:26 - this moment where I was like there's so
70:28 - many of these types of problems in the
70:30 - world and like they're very very narrow
70:32 - problems but they require this deep and
70:36 - nuanced understanding of the world and
70:38 - all of these different things and that
70:40 - model can actually do like the vision
70:42 - model can do way better probably at this
70:45 - problem than this like very domain
70:47 - specific custom model that we spend
70:49 - hours and hours weeks and weeks months
70:51 - and months training um and it's it's
70:53 - super interesting I think there's going
70:54 - to be like tons of those like really
70:57 - small use cases that are unlocked now
71:00 - because you have a model that like
71:01 - really understands the world I think
71:02 - like going back to language learning you
71:04 - mentioned like one of the coolest use
71:06 - cases I've seen for vision so far has
71:08 - been like people traveling in other
71:09 - countries and you can literally just
71:11 - like snap a picture of some random
71:12 - building in Italy and be like tell me
71:15 - the history of this and like really
71:16 - bring it to life for me and like you
71:18 - have this personalized guided tour now
71:20 - of everywhere in the world by just like
71:23 - pictures of things which I don't think
71:25 - was possible before yeah and probably
71:27 - even a lot of like very mundane things
71:29 - like like what bird is this like you
71:31 - know things like that like and of course
71:33 - there are lots of you know bird computer
71:36 - vision apps that have been in the app
71:38 - store for probably years at this point
71:40 - but just the the fact that there's a
71:42 - single model that's kind of powering all
71:44 - this stuff is new and and one of the
71:47 - things that surprised me learning more
71:49 - about uh gp4 and about llms in general
71:53 - is just how how surprising a lot of the
71:55 - emergent properties of just having such
71:57 - a massive model have been can you talk a
71:59 - little bit about that because that is
72:01 - just mind-blowing the fact that like for
72:04 - example you can dramatically improve
72:06 - illustrations by teaching uh or
72:10 - essentially by having it like verbalize
72:12 - to itself like oh this this property
72:15 - like using English language as kind of
72:17 - like an intermediary step between one
72:20 - drawing and another drawing uh as I
72:22 - naively understand working can can you
72:25 - explain how that works yeah I I don't
72:27 - know if I'll have a good explanation or
72:30 - like what the right direction to take it
72:31 - is but I think the the what you
72:34 - mentioned is very true and actually to
72:37 - like abstract it to like developers a
72:40 - little bit more the text being this like
72:43 - interface layer like text for large
72:47 - language models is essentially like
72:49 - thought for humans like you know when I
72:51 - want to do something I think about it
72:53 - text is really that interface layer like
72:55 - as you're building different
72:56 - applications incorporating different
72:57 - modalities whether it's like image
72:59 - generation or image understanding or
73:01 - text generation or or speech even or or
73:04 - like audio processing the the layer
73:07 - between all of those is text and I think
73:09 - it's really fascinating that that's
73:12 - that's like what that's like one of the
73:13 - emergent characteristics of all of these
73:15 - things is like that it's text that's the
73:17 - interface between all those and I don't
73:19 - think like if you would ask people 20
73:21 - years ago what would be like I think
73:23 - people have assume that like I don't
73:24 - know the models would be like talking
73:26 - binary to one another or something like
73:28 - weird and abstract and esoteric like
73:30 - that and it's actually really cool for
73:32 - us as humans to be able to see like it
73:34 - is actually T like they're actually
73:35 - doing kind of the same thing that we're
73:37 - doing which is really interesting yeah
73:39 - and like I mean text is kind of the
73:41 - stuff of thought language right and uh
73:44 - so it is really interesting that
73:47 - computers can work very similar to how
73:49 - humans work now obviously like kind of
73:51 - like your internal monologue and like
73:54 - all these different things there only
73:55 - one part of memory only one part of
73:58 - experience but I I think as a complete
74:01 - lay person who doesn't know much about
74:03 - psychology I do feel that like a lot of
74:06 - the ways I code things into my memory
74:09 - are how I kind of think about them in
74:11 - terms of language like it was a splendid
74:13 - day and man that Sunset looked just like
74:17 - you know a smash bottle of champagne
74:19 - against like a yacht or something like I
74:21 - don't know just like random like kind of
74:22 - ways that would like just have these
74:26 - little insights and and they stick with
74:27 - me you know ways to think or or when you
74:30 - read a book I mean books can be so
74:32 - illustrative and it's just words on a
74:34 - page and yet it can be this really um
74:37 - Vivid experience if you're reading a
74:39 - well-written book uh it can almost feel
74:42 - like you're you're like having a dream
74:44 - it it it can be that level of resolution
74:47 - uh so it it's very interesting that
74:50 - computers can work so similar like how
74:53 - humans work and that even though like a
74:56 - an artificial neural network is not
74:58 - exactly like the neural network that
75:00 - we're using in our brain that so much of
75:03 - it is Sim like the degree of similarity
75:05 - is staggering to me that that that is
75:08 - what we arrived at it wasn't like
75:09 - semantic logic or one of these other
75:11 - branches of AI that we've been going
75:13 - down for the past 60 years but it was uh
75:16 - neural networks that got us there and
75:18 - and I'm not saying that it's like the
75:20 - last step I'd be interested in your
75:22 - you're thinking like do you think that
75:24 - this that we've kind of hit on something
75:25 - here and that this is the way we get to
75:27 - artificial general intelligence is
75:29 - through using neural networks or do you
75:31 - think that it's going to be some
75:32 - combination of different disciplines or
75:33 - do you think this will get us there yeah
75:36 - it's a good question I think there need
75:38 - there fundamentally needs to be like
75:39 - additional layers like I still think
75:41 - there's a ton of breakthroughs my my
75:43 - intuition is that you could sort of take
75:45 - the existing gbt Paradigm and like it
75:47 - will continue to scale up like you know
75:49 - the gbt fs the gbt 6s of the world
75:51 - whatever in the future um but there will
75:54 - have to be like fundamentally different
75:56 - changes like just transformers just like
75:58 - next token prediction is like a very
76:01 - poor proxy for like what actual general
76:04 - intelligence and again maybe maybe that
76:06 - will turn out to be wrong and like this
76:07 - will be the thing that works really
76:10 - really well and continue to scale but I
76:12 - think they'll have to be like going back
76:13 - to that like reasoning piece like I
76:15 - think reasoning is something that has to
76:17 - really happen for these models to start
76:19 - like taking on much more complex tasks
76:22 - like that we as humans today yeah yeah
76:25 - well we can talk philosophically about
76:27 - like AI but I want to get back into the
76:30 - kind of the nitty-gritty of of Logan
76:32 - Kilpatrick and his journey into open AI
76:34 - so you joined like right
76:36 - after chat GPT hit the world and became
76:39 - like the fastest adopted consumer
76:41 - product of all time basically um what
76:44 - was it like because it was a pretty
76:45 - small organization uh it is a 51 C3
76:48 - charity that's kind of like swallowed
76:50 - this giant whale of a for-profit entity
76:52 - but but like like and and you've got
76:54 - like Microsoft there you've got like so
76:55 - many different things going on you got
76:57 - this incredibly charismatic founder uh
77:00 - you've got all these uh brilliant and
77:02 - and many idealistic people that work at
77:05 - open AI like what was it like uh first
77:07 - of all I guess maybe first question how
77:09 - did you get that job and then maybe you
77:12 - can talk about what it was like starting
77:13 - that job yeah I started interviewing
77:16 - back in like June of 2022 and literally
77:20 - just applied online I was like hey this
77:22 - is was was thinking about doing
77:24 - something different and found a job
77:26 - applied online started interviewing and
77:29 - at the time they're actually um I by the
77:32 - time like I got to the actual like
77:33 - in-person interviews and started going
77:35 - through some of the rounds they I had
77:37 - moved back to Chicago and they were
77:39 - looking for someone in San Francisco at
77:40 - the time so I was like yeah it's not for
77:42 - me I just moved back I I love my
77:44 - girlfriend she's in Chicago um they
77:46 - ended up reaching out like 3 months
77:47 - later and they're like hey we're
77:48 - actually willing to hire someone
77:49 - remotely now um and like continued the
77:52 - interview process ultimately end up
77:54 - getting the job offer accepted did all
77:56 - this stuff the whole pitch to begin with
77:58 - was like hey we have these models like
78:00 - gbt 3. 5 like it's incredible it can do
78:02 - so much stuff but like developers don't
78:04 - really know what to build with this like
78:05 - come help us uh help develop like figure
78:08 - out how to help developers and build
78:09 - really cool things um and they were like
78:12 - yeah we also have these other like
78:13 - really really crazy models but like we
78:15 - can't tell you about it till you join uh
78:17 - which ultim ended up being gbt 4 um but
78:20 - again at the time like it was not clear
78:22 - that like it was about to be this
78:24 - Breakaway success of like all this like
78:27 - crazy stuff that people associate with
78:28 - open AI today and my first day was uh
78:32 - the Tweet by Sam of open AI of chat gbt
78:35 - hitting a million users and it kind of
78:37 - like started to like really The
78:39 - Narrative started to blow up from there
78:42 - um it when I joined I was on our like
78:47 - developer platform team and at the time
78:49 - it was like six or seven people who were
78:51 - like building the entire ire API and all
78:54 - of the infrastructure for developers
78:56 - like literally just that six or seven
78:58 - person team um really really small and
79:02 - like moving so quickly and I think the
79:04 - thing that like people uh don't don't
79:07 - pick up on sometimes is like you have
79:10 - this like moment of success and then all
79:12 - of a sudden we have like millions and
79:14 - millions of people showing up to use J
79:15 - gbt we have millions and millions of
79:17 - people showing up to use our developer
79:19 - platform um your intuition is like oh
79:21 - like perfect you know you money we we'd
79:24 - gotten we'd like rais money from
79:25 - Microsoft and we announced it at that
79:27 - time as well um you know just go hire a
79:30 - bunch of people and like I think people
79:32 - who have not been close to the hiring
79:34 - process don't realize like how it it
79:38 - like takes time to like spin up that
79:40 - hiring engine so even by the time we got
79:42 - to the gbt 4 launch and the cat gbt API
79:45 - launch in um in March of 2023 like we
79:50 - still really hadn't grown that
79:51 - significantly because like it takes time
79:53 - to interview people like people have to
79:55 - leave their jobs they have to move they
79:56 - have to do all this stuff it's really
79:58 - counterintuitive too just for uh anybody
80:01 - who hasn't worked on an engineering team
80:03 - like just what you were talking about
80:04 - earlier getting context into the Legacy
80:06 - codebase understanding like just the
80:08 - human element of being on a team and
80:10 - interacting with new people who's doing
80:12 - what like what do I do like there's so
80:15 - much kind of onboarding necessary to get
80:17 - somebody from being like I mean frankly
80:19 - like a net negative when they're first
80:20 - starting out they're taking time away
80:23 - from other things so they can gradually
80:24 - get up to the break even and then
80:26 - ultimately they'll be a net positive the
80:28 - longer they stay the more kind of return
80:30 - on investment you get on bringing them
80:31 - onto the team but yeah there's
80:33 - definitely like a spooling up process
80:36 - and I can only imagine what it would be
80:38 - like with all that pressure on uh
80:41 - basically everybody like the the
80:43 - dominant like like I saw like the top
80:45 - article uh on Wikipedia for 2023 was I
80:49 - think it was the open AI or Chad gbt one
80:51 - of those two right so so I can only
80:53 - imagine and then everybody's like
80:55 - expecting like magic Microsoft money to
80:58 - just instantly make everything better
81:00 - but the reality is there's still a lot
81:01 - of work to do even when you have the
81:03 - resources to bring on good people right
81:05 - yeah and we've been like the the caliber
81:08 - of folks who have joined the team is is
81:09 - so incredibly high and so amazing like I
81:12 - actually think a lot of people and this
81:14 - is like I think become implicitly part
81:16 - of open AI culture but like you join and
81:19 - I've worked with so many people who have
81:20 - joined and their first week they're like
81:23 - a major contributor to some like huge
81:27 - launch like i' I've like the yeah the
81:30 - Chad gbt API like we had folks joining
81:32 - like literally that week and they just
81:33 - like saddled up and like started
81:35 - shipping code and like it's incredible
81:37 - to see like so I mean there is that
81:38 - there is still that like spin up time
81:40 - but I think also when you like you can
81:43 - sort of mitigate some of that by finding
81:45 - folks who have experiences that that
81:48 - like really translate well to building
81:51 - what we're building and like we're
81:52 - fortunate enough from a API side to like
81:54 - get a bunch of folks from like places
81:56 - like stripe who have built this
81:57 - incredible developer platform and a
81:59 - bunch of apis that are similar um so it
82:02 - it does help like reduce that spin-up
82:04 - time and then folks like ship stuff on
82:06 - their first day which is uh crazy and
82:08 - like not the normal there so many places
82:10 - like and again this is not like a a
82:12 - picking on Facebook or casting judgment
82:14 - on them but like you know I Facebook's
82:16 - like one of their core things was like
82:18 - you join and you go through like a six
82:19 - week uh Facebook like engineering
82:23 - like boot camp essentially to like learn
82:25 - the things that Facebook does and it's
82:26 - like a very different culture than like
82:29 - than at least in the context of well I
82:31 - mean to to some extent it sounds like
82:32 - you all didn't necessarily have the time
82:34 - and energy to build up that system uh I
82:37 - mean you said the engineering team was
82:39 - like six people building chat gbt and
82:41 - building the the opening so like maybe
82:43 - you could talk about the composition of
82:45 - the the company or the charity I'll just
82:47 - use the word company uh because I know
82:50 - like I'm not I'm from the charity owns
82:53 - the charity owns the the the actual
82:57 - capped profit company but like all the
82:59 - employ like the majority of the
83:00 - employees work for the cap like I work
83:03 - for a a capped profit that's owned by a
83:06 - nonprofit and the the ca Profit just in
83:08 - case anybody's curious what that means
83:10 - essentially it's it's like a traditional
83:12 - you know company where people hold stock
83:14 - but uh the people who invest like they
83:17 - they can maximum the maximum amount of
83:18 - money they can get out is 100x their
83:20 - initial investment or something like
83:21 - that right um yeah I don't know what it
83:24 - is specifically for us but that's part
83:26 - of the intent is like there's some
83:27 - there's some capped amount of upside for
83:29 - investors and employees and then the
83:31 - rest of the upside like flows back to
83:32 - that charity um which which has like a
83:35 - fiary duty to benefiting Humanity
83:38 - instead of a fiduciary duty to like
83:40 - maximizing profits for shareholders
83:43 - which is the normal structure yeah so so
83:45 - a lot of people might be like well why
83:46 - is this a nonprofit how is this a
83:47 - charity or something like legally you
83:49 - know I've I've spent a lot of time
83:50 - studying it like it it's a a different
83:52 - type of Charity from like the Red Cross
83:54 - or Doctors Without Borders or Freo Camp
83:57 - uh but it it is still uh technically a
84:00 - charity and like I don't think that's a
84:02 - controversial thing inside the charity
84:03 - world or anything but uh I guess uh I'll
84:07 - just call it the company since you're
84:08 - within the the capped for-profit that's
84:10 - inside the charity um so uh one question
84:14 - I have for you is like you said that um
84:17 - like there were like six or seven people
84:18 - working on the actual products that
84:20 - people were using like What proportion
84:22 - of the team when you joined was just
84:26 - scientists like people actually doing
84:28 - the training of the models and and
84:30 - building doing doing the the basic
84:33 - science that that would ultimately be
84:35 - productized um What proportion of the
84:37 - team was that versus the actual
84:39 - engineering and product side yeah so we
84:42 - had like those six or seven folks on the
84:45 - just on the API side Chad chbt has like
84:48 - a separate um it's a separate team from
84:50 - like our API developer platform form
84:52 - team so I think there was at least a few
84:55 - uh probably like I I don't know at that
84:57 - time whether I was going to say a dozen
84:59 - but that sounds much too ambitious for
85:01 - yeah so it was even fewer than it dozen
85:02 - basically they built I think it was like
85:04 - the actual user
85:05 - interface yeah exactly and the research
85:08 - team is uh very intentionally small I
85:12 - think it it was probably a much larger
85:13 - portion when I joined I was like
85:15 - employee like 280 or something like that
85:18 - um at the end of the at the end of last
85:20 - year we at like 750 so a ton of growth
85:23 - and um it's interesting like the
85:25 - research team has not grown
85:26 - significantly and I saw uh a great tweet
85:30 - from one of the researchers on our team
85:32 - who is actually talking about how in
85:35 - many cases and this is kind of
85:37 - unintuitive um especially coming from an
85:39 - engineering world where I don't think
85:40 - this is necessarily always true but for
85:42 - every new incremental researcher you add
85:45 - to um a research organization it's
85:49 - actually like a net loss for every other
85:53 - researcher like independent of like the
85:54 - like helping that person on board you
85:56 - could never talk to that person in your
85:58 - time um as a researcher and it would
86:00 - still be a net loss for you for that
86:02 - person to join in general and the
86:05 - reasoning is because you have this
86:07 - allocation this pool of gpus and if
86:10 - you're a researcher and you need the
86:11 - currency of research at openai is gpus
86:15 - you know you now have to give off a
86:16 - thousand of your gpus to some other
86:18 - person who's going to try a bunch of
86:20 - other stuff in their research and like
86:21 - all of a sudden you know you're now less
86:24 - effective as a researcher because you
86:25 - can't try as many things you can't scale
86:28 - things up as much um and again there's
86:30 - Nuance this like you could come in with
86:32 - some optimization technique that enables
86:34 - everyone to be more effective and then
86:36 - now it's like a plus 10% gpus foreverone
86:38 - or something like that but it's
86:39 - interesting and that's part of the
86:41 - reason why our research organization
86:43 - hasn't scaled up a ton is because you
86:45 - need gpus and we live in a world where
86:47 - we're constrained by the number of gpus
86:49 - it's interesting it's almost like we're
86:50 - going back to the the days of like the
86:52 - Mainframe when like researchers would
86:55 - fight for time slot to actually use the
86:57 - computer because the GPU is so expensive
86:59 - and so scarce that becomes the gating
87:01 - Factor rather than the actual human
87:05 - Talent it's also funny that it's like
87:07 - you could have all the money in the
87:08 - world that doesn't actually matter like
87:10 - I could show up like today me I could
87:12 - personally have1 billion dollars of cash
87:15 - to go and buy and it doesn't matter
87:17 - because there aren't any gpus to buy
87:19 - like there are no free GP like the G
87:21 - yeah there back order for like years and
87:23 - it's like this super long spin up
87:25 - process to to get more gpus and I think
87:28 - that's why like us working so closely
87:31 - with Microsoft and Azure like they've
87:33 - been an incredible partner and like
87:35 - getting us the resources that we need to
87:37 - continue to push on the frontiers of
87:38 - these models and and serve traffic to
87:40 - chbt customers so I don't think anyone
87:43 - is um I have nothing but good things to
87:45 - say about Azure I don't think anyone is
87:46 - like pushing on things as as much as
87:48 - Azure is from a GPU perspective so are
87:52 - there a lot of efforts to try to figure
87:54 - out ways like I guess compression hacks
87:56 - to like reduce uh the size of the model
87:59 - dramatically so you need fewer gpus to
88:01 - be able to run it and and train it or
88:04 - like like I assume that there are lots
88:06 - of different branches of research into
88:08 - that to like kind of try to solve that
88:11 - bottleneck yeah 100% I think there's
88:13 - there's been ongoing stuff like there's
88:15 - actually been things that we've done
88:17 - that have led to like the model
88:19 - potentially in some cases being smaller
88:21 - but in in principle it's like there's
88:24 - only so much of that you can do without
88:26 - some like crazy new breakthrough like a
88:29 - lot of that work is actually like more
88:30 - like pure engineering effort like you
88:32 - can do a lot of things to like make it
88:34 - so that the models are smaller and more
88:35 - efficient and stuff like that and like
88:36 - it's more from a engineering perspective
88:38 - I think like there really needs to be
88:39 - some research breakthroughs and I think
88:41 - a lot of people are actually like
88:42 - Microsoft is doing some of this work
88:43 - I've seen others doing this work like
88:45 - the small model uh sort of movement of
88:48 - like how much can you get with some of
88:49 - these smaller models and I think it's
88:51 - important that people do that research
88:53 - because there's a lot of use cases that
88:55 - don't work or aren't feasible today
88:57 - because of how large these models are
88:58 - could there be like a at home type uh
89:02 - solution for training models or or is
89:05 - just fundamentally like a different
89:07 - engineering problem where like having a
89:09 - whole bunch of compute on a whole like
89:12 - millions of computers like said at home
89:14 - if you're familiar with that like that
89:15 - was like the search for extraterrestrial
89:18 - life they had a whole bunch of uh I
89:20 - guess data that they needed to munge and
89:22 - the way that you could help was you
89:24 - could install this thing whenever your
89:25 - computer was idling it would help crunch
89:28 - on the uh the data for seti and send it
89:29 - back to them uh I mean could there be
89:32 - like an equivalent type effort where you
89:35 - could you could have people opt in uh to
89:37 - to use their computer or is you're just
89:40 - you're digging for coins in the couch at
89:42 - that point like would that work in any
89:44 - way yeah I think at the scale that we
89:48 - operate today and like the scale that
89:49 - we'll operate in the next few years like
89:52 - and and I I'm just kind of making up
89:54 - this based on my intuition so I don't
89:56 - actually have the real numbers but like
89:58 - I don't think that that would make like
90:00 - even if you got every like like uh every
90:04 - iPhone in the world signed on to this
90:07 - thing to like give it spare compute I
90:09 - don't think you would actually it would
90:11 - end up giving like that much net benefit
90:14 - um just because like the hard it's like
90:16 - if you look at the hardware that's used
90:18 - to train models it's like the A1 100s
90:20 - and h100s are like custombuilt like
90:24 - science experiments that are like built
90:26 - for one thing and it is like very
90:28 - expensive and does that one thing really
90:31 - really well and like I just don't I I
90:33 - don't think like the hardware would
90:35 - actually allow you to do what you need
90:36 - to do do you know if like Google's TPU
90:38 - like the tensor processing units and
90:40 - things like that are those like
90:42 - competing for you know Foundry space
90:45 - over in uh Taiwan at uh uh what is it
90:48 - Taiwan semiconductor Corporation tsmc um
90:52 - like uh is there any like clear kind of
90:56 - like opening like uh I guess end to this
91:00 - bottleneck in sight or is it just going
91:01 - to be years and years of like having to
91:03 - build out additional Foundry uh capacity
91:07 - like I think we're doing that here in
91:08 - the US it's just kind of like an energy
91:10 - Independence for compute type movement
91:12 - but uh like like how long do you think
91:15 - it's going to remain a key
91:18 - constraint yeah I'm I'm guessing if you
91:21 - if you dig a little bit into this and
91:23 - I'm not an expert at all I've just like
91:25 - read a few articles here and there but
91:28 - um it's actually fascinating that
91:30 - there's like all of these all of these
91:33 - points of failure in that existing
91:35 - system today and it's unclear to me like
91:37 - how much is by Design because there's
91:38 - like lots of of corporate interests and
91:40 - and such involved but like you know one
91:43 - of the like machines that you'll need is
91:46 - like only made by this one company and
91:48 - like it's like the one company that
91:50 - supplies all of these types of Mach for
91:52 - every Fab and it's like well they don't
91:54 - make any more of those because like
91:56 - they're also constrained by these five
91:58 - other things and it's just like this
91:59 - incredibly complicated supply chain I
92:01 - think like there are a bunch of like
92:04 - bright uh opportunities like I think
92:06 - like bringing some of those back to the
92:08 - us bringing faps back to the us is going
92:09 - to be super important uh South Korea has
92:12 - become like a huge uh location for new
92:15 - faps you went South Korea I heard I saw
92:17 - on Twitter you were there for how long
92:19 - like three days like literally I was 36
92:22 - hours flying 36 hours on the ground that
92:25 - is crazy what did you do while you were
92:27 - there what was so important that you
92:28 - endured all that jet lag and all that
92:30 - travel we we were doing an event with
92:33 - the um South Korean government the
92:35 - ministry for for small business and yeah
92:39 - we're fortunate enough to like get to
92:40 - hear from and and essentially be like
92:43 - see the pitch from um 20 plus uh South
92:47 - Korean startups and see some of the
92:48 - stuff that they're working on it was it
92:49 - was super empowering to yeah to see like
92:53 - The Innovation is not just happening in
92:54 - San Francisco it's not just happening in
92:56 - the US like there's people all over the
92:58 - world who are pushing on it and pushing
92:59 - on like the very Regional problems as
93:01 - well like so many startups in South
93:03 - Korea uh like Logistics and the supply
93:05 - chains of of Asia are like top of mind
93:08 - for them um and they're really really
93:10 - interesting Solutions and like using the
93:12 - models in different ways to try to solve
93:14 - some of that stuff so it was super cool
93:16 - to to see that it was a ton of fun well
93:18 - I don't want to tease any proprietary
93:19 - data out of you or anything like that uh
93:21 - but just like in terms of the next big
93:24 - model like I GPT 5 or GPT 4.5 or
93:28 - something like that like how how soon do
93:30 - you think we're likely to see that has
93:32 - has any of that work commenced in terms
93:34 - of like in Earnest have they actually
93:35 - started training models at this point
93:38 - yeah I'm not 100% sure whether or not
93:40 - like what the status of of training
93:42 - stuff is just because I'm I'm abstracted
93:44 - away from it um so I I won't come on on
93:46 - that I think my my assumption just like
93:48 - as somebody who's like followed the
93:50 - progression of these models mod um is
93:52 - like hopefully we'll have something cool
93:54 - this year and like um yeah I mean I'm
93:57 - I'm biased and like I love developer Stu
93:59 - so like I'm hopeful that it comes out on
94:00 - developer day like that'd be a ton of
94:01 - fun to like showcase something like that
94:03 - to the world but um yeah I think it'll
94:05 - be it'll be really cool and people have
94:08 - such high expectations for whatever we
94:09 - do next so um I think that adds a ton of
94:12 - pressure for us to to build something
94:14 - incredible that people want and I have a
94:16 - ton of faith in the team like I think
94:18 - the scaling laws are are in our favor
94:20 - and like there's there's a like gbt 4
94:22 - was the first Model this was part of the
94:24 - technical report that we released it was
94:26 - the first Model where we could like
94:27 - reliably predict how powerful that model
94:31 - was going to be and the capabilities
94:32 - based on the amount of compute that we
94:34 - put in so I'm really fascinated to see
94:35 - like when the next iteration of this
94:37 - model comes out like does that scaling
94:39 - law hold true or not so it'll be
94:41 - interesting to see in terms of like
94:43 - using software uh on top of the model to
94:47 - like improve the quality of results and
94:49 - stuff like that like I this is a super
94:51 - vague question and it might seem like
94:53 - extremely uh ignorant but like what
94:56 - percentage of performance juicing can we
94:58 - get out of just like good software
95:00 - engineering on top of the model that we
95:02 - already have like let's say
95:03 - hypothetically there was never a GPT 5
95:06 - and we just had to deal with the tech
95:08 - that we have today how much better do
95:10 - you think we could improve it just by uh
95:13 - you know new prompting techniques or um
95:16 - new you know Frameworks and things like
95:18 - that sitting on top of it uh consuming
95:20 - the a API and like mixing that with
95:22 - other uh
95:25 - techniques yeah I there's probably a a a
95:29 - pretty close like endof the line
95:31 - threshold I think people would figure I
95:33 - mean I think there's like always going
95:34 - to be interesting Innovation that you
95:36 - could do around prompt engineering and
95:37 - stuff like that but I do think like gbt
95:39 - 4 has a bunch of fundamental limitations
95:41 - and it's like just because of the data
95:43 - that it's been trained on and like how
95:44 - long it's been trained and all that
95:45 - stuff um so I think we need we do need
95:48 - new models I'd imagine you could
95:49 - probably like you know really cleverly
95:52 - figure out with a lot of engineering
95:53 - work like you know how to get like 50%
95:56 - better performance or something like
95:57 - that but even still it's like what does
95:59 - that 50% actually look like like what
96:01 - does it mean along sub probably right
96:05 - there will be like all all the
96:06 - benchmarks and stuff to evaluate it
96:07 - maybe better performance on some
96:09 - esoteric test that nobody takes right
96:12 - exactly right yeah um okay so so last
96:15 - question uh free form
96:18 - question what are some things that
96:21 - people could be using GPT 4 and and the
96:25 - open a AI API that they don't that they
96:28 - may not necessarily realize it's
96:30 - extremely good at and useful for like
96:32 - maybe if you could just list off some
96:34 - use cases that you think are really
96:35 - interesting and uh that people may not
96:37 - be aware of that they might be able to
96:39 - go and try
96:40 - themselves yeah I think that this is the
96:43 - most exciting
96:45 - reason uh for the GPT store so like the
96:49 - the reality is like as a as some
96:51 - somebody who's using AI like I I live in
96:53 - Chicago and I talk to people all the
96:54 - time who like aren't part of the AI or
96:56 - technology bubble and they go and use
96:58 - chat gbt and they're like what do I do
97:00 - like it's this blank thing and like it's
97:02 - not super clear to me I think gpts
97:04 - really solve this problem like you have
97:06 - this very tangible experience that
97:08 - you're sending to Someone Like You know
97:10 - it could be things as simple as like
97:12 - generating logos for your company like
97:15 - doing goal planning like I I was working
97:17 - on a GPT to like help me plan my uh like
97:21 - not not okrs but like the similar
97:23 - version ofr which is basically like a
97:26 - performance review uh for team members
97:29 - that you manage or something like that
97:30 - right exactly like planning all the
97:32 - different things that that I I need to
97:34 - actually go and do and um I my my
97:37 - girlfriend made uh planty which is like
97:39 - a house plant GPT and and for gardening
97:42 - and you can like get advice on how to
97:44 - like take care of your plants and
97:45 - hopefully none of my plants will die
97:48 - because I'm using planty to like help
97:50 - keep them alive like there's so so many
97:51 - like every tangible thing that you could
97:53 - imagine is possible with gpts and now we
97:56 - have the GPT store and you can go in and
97:58 - like search for some of these things use
98:00 - them and like there's so much more that
98:01 - we're going to push on with gbts to
98:03 - allow them to like actually take actions
98:05 - on your behalf so like plan a trip for
98:07 - you and like help you book the tickets
98:09 - and like find stuff like that we talked
98:11 - about like the tour guide example like I
98:13 - think all of those are are such exciting
98:16 - use cases and it's going to take a while
98:18 - for all these use cases to shake out
98:19 - like uh I mean we're still figuring out
98:22 - new uses for spreadsheets you know 30
98:24 - years later right 40 years later so um
98:27 - well it's been an absolute
98:29 - privilege learning so much from you
98:31 - Logan uh hearing about your own
98:33 - developer Journey uh the tenacity the uh
98:36 - measuring in hundreds uh as you've
98:39 - applied for various jobs and and been
98:41 - incredibly successful at applying to uh
98:44 - companies uh applying uh to universities
98:48 - and uh getting on the board of num Focus
98:50 - again I just want to emphasize what a
98:52 - huge deal that is you have so much power
98:55 - and so much responsibility helping
98:57 - oversee and sustain these various uh you
99:00 - know scientific Computing projects that
99:03 - we all rely on whether we know it or not
99:05 - every day so uh I just want to thank you
99:07 - again for coming on and I want to
99:09 - emphasize that anybody who is interested
99:12 - in AI should definitely be following
99:14 - Logan on Twitter uh he's got a pretty
99:17 - active Twitter account there uh he
99:19 - writes a lot on medium uh hopefully
99:21 - we'll get some more free C Camp
99:22 - tutorials at some point when he has some
99:24 - time about various things if you want to
99:26 - write about like you know open AI API or
99:29 - something like that we we would be
99:30 - thrilled to publish some stuff on that
99:32 - uh but I I just want to thank you for
99:34 - coming on man uh I'm going to add some
99:35 - notes uh show notes that include some
99:38 - links to some various things we've
99:39 - talked about and also things that Logan
99:41 - thinks you might be interested in so uh
99:44 - thanks again for coming on man viny this
99:46 - was a ton of fun and and hopefully like
99:48 - the takeaway for folks is like you can
99:50 - do it like there's so much opportunity
99:52 - in the world and I think especially with
99:54 - everything that's happening in AI like
99:55 - this is such a such a moment to get
99:58 - involved in a new space and like the
100:00 - beautiful thing is like there's no
100:01 - experts like this just started like you
100:03 - can get in and like in six months like
100:05 - be the person that people are going to
100:07 - and like I felt this myself if like
100:09 - people think that I'm an expert in a
100:11 - like I'm I'm in the shoes of a lot of
100:13 - everybody else like I just started doing
100:14 - a lot of this stuff like super recently
100:16 - so U it's such a cool opportunity I'm
100:18 - excited for for the developer space
100:19 - thanks for having me on and um yeah I'm
100:22 - I'm happy that we got to chat absolutely
100:25 - well everybody thanks for sticking with
100:26 - us I hope you learned a lot until next
100:29 - week happy coding