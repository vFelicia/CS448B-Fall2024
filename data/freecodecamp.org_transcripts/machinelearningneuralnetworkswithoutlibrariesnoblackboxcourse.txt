00:00 - in this course you will learn machine
00:01 - Learning Without libraries coding
00:04 - without libraries is the best way to
00:06 - learn the inner workings of a machine
00:08 - learning system and it will help you
00:10 - greatly improve your software
00:12 - development skills Dr redu teaches this
00:14 - course we already released his no black
00:16 - box phase one course this is phase two
00:20 - but you can still follow along even if
00:22 - you didn't see phase one in this course
00:24 - you will learn how to implement
00:25 - classification methods such as neural
00:27 - networks to recognize drawings you'll
00:30 - also learn about data cleaning confusion
00:32 - matrices geometry and the difference
00:34 - between vector and raster data if you
00:37 - want to learn how common machine
00:38 - learning algorithms work under the hood
00:40 - this is the course for you hi and
00:43 - welcome to phase two of the null Black
00:45 - Box machine learning course in
00:47 - JavaScript the goal here is to take the
00:50 - drawing recognizer we built in Phase One
00:52 - and improve its accuracy by implementing
00:55 - more advanced methods now if you didn't
00:58 - complete Phase 1 you may be okay
01:01 - starting directly with this especially
01:03 - if you already know some basic machine
01:05 - learning Concepts I will explain our
01:07 - code base briefly in the beginning so
01:10 - try to understand ask questions below or
01:12 - on Discord and if all else fails then go
01:15 - to phase one
01:17 - this time we'll learn about data
01:19 - cleaning it's a tedious process but I'll
01:22 - teach you how to build a tool to make
01:23 - the job easier then we'll learn to
01:26 - visualize a confusion Matrix a special
01:28 - kind of table that helps us understand
01:30 - our model even better than the chart we
01:32 - built last time it will be especially
01:35 - helpful when working with more than two
01:37 - dimensions
01:38 - speaking of which so far we've only been
01:41 - using two features but the K nearest
01:43 - neighbor algorithm is not limited to
01:45 - that all it needs is the way to
01:47 - calculate the distance between data
01:49 - points and I'll teach you how to do that
01:51 - in 3D 4D 5D any D really I'll show you
01:56 - an intuitive way to think about
01:58 - multi-dimensional spaces and distances
02:00 - and we'll use up to 400 dimensions in
02:02 - this course
02:04 - we also study another classifier the
02:07 - neural network we'll use the same code
02:09 - from my self-driving car course because
02:12 - I want you to understand that machine
02:14 - learning methods are General techniques
02:16 - and algorithms we just apply to solve
02:19 - different kinds of problems
02:21 - now this is more complex than that
02:24 - self-driving scenario and our
02:26 - optimization strategy there wasn't
02:28 - really good so I should teach you
02:30 - something better like back propagation
02:33 - but I don't know how
02:36 - I tried to come up with a lesson I just
02:38 - can't seem to add anything to those out
02:40 - there so I'll teach you how to train the
02:42 - network in Python and then take the
02:45 - resulting model and just use it in
02:47 - JavaScript so python will do the heavy
02:49 - lifting and our Javascript app just
02:52 - benefits from it
02:53 - am I cheating
02:55 - maybe a bit but I think that learning
02:58 - this is possible is a really important
03:00 - lesson here you'll see finally I'll
03:03 - demonstrate deep neural networks as well
03:05 - so I don't get many comments about it
03:08 - now I need to stress this course is
03:11 - supposed to be a learning experience I
03:13 - want you to understand how machine
03:14 - learning works and why we do the things
03:16 - we do
03:17 - we use the data you helped me collect so
03:20 - we have a real challenge not some
03:21 - textbook data set and we use JavaScript
03:24 - because it's a high level language where
03:26 - we don't need to worry about the small
03:27 - things and because we can use it to
03:30 - build nice user interfaces that we can
03:32 - share without the need to download
03:33 - install and so on I really hope you
03:36 - learned to build real things not just
03:38 - something that reads from files and
03:39 - writes into the console another reason I
03:42 - use JavaScript it's because it's not
03:44 - well known for machine learning but many
03:46 - people do know JavaScript and want to
03:48 - learn machine learning so if this is you
03:51 - you found the perfect course and if you
03:53 - don't like JavaScript take it as a
03:55 - challenge and implement the same things
03:57 - in something you like we don't use
03:59 - libraries so it's really doable I think
04:03 - sound good Okay then if you plan to
04:06 - follow along take the starting code from
04:08 - GitHub it's similar to the last one from
04:11 - phase one but a little bit different
04:13 - I've added your homework submissions and
04:15 - made few other optimizations as well
04:18 - also remember to get the data from this
04:20 - link place it next to the code like this
04:23 - and you're ready to start
04:27 - the first thing we'll check out is the
04:29 - drawing app we use to create new data
04:31 - here inside the web folder and create
04:35 - our HTML
04:36 - if you open this in the web browser
04:40 - you'll see it looks quite different from
04:42 - before but the functionality is still
04:44 - the same it's going to ask you to enter
04:46 - a name here and then to draw several
04:50 - things but the style is different
04:52 - because ninja coder did homework too and
04:56 - I adopted his style
04:58 - you can see these changes here in style
05:01 - CSS and everything I've marked as new
05:05 - style starting from beginning are things
05:08 - that he has added and I commented out
05:10 - previous Styles I've used in case you're
05:13 - curious how to do different styling I
05:15 - kept both here for reference now you'll
05:18 - also notice this compatibility section
05:20 - here at the top and that's because in
05:23 - homework 1 I asked you to test the app
05:25 - and let me know how it went there were
05:27 - some problems on iPhones making the
05:30 - screen scroll when you want to draw
05:32 - I got a suggestion from meso to set
05:35 - touch action To None Aaron commented
05:38 - that these should be set to none as well
05:40 - for it to work really not sure if these
05:42 - are enough because I don't have an
05:44 - iPhone to test but I also got feedback
05:46 - from mjake and Rick and they said that I
05:50 - should go here in the sketchpad
05:53 - component
05:54 - and add prevent default to the pointer
05:57 - events which by the way Kelvin said I
06:01 - use instead of the mouse events and
06:03 - touch events separately
06:05 - I really don't know if these comments
06:08 - help because when I test on mobile it
06:10 - works just fine
06:12 - but please let me know if it works for
06:15 - you I've added these changes on the
06:17 - version of the app on my website that I
06:19 - still use to collect data if you want to
06:21 - submit and also in the recognizer that
06:23 - will build by the end of this course
06:26 - now after you're done with the drawing
06:28 - and press next you're gonna get the
06:31 - option to save this and it's going to
06:33 - create this file that contains all the
06:35 - information about the drawings you just
06:37 - made
06:38 - it's a Json file that if I'm going to
06:41 - format like so contains the information
06:44 - about the student some unique identifier
06:46 - and then the different drawings the
06:49 - eight different drawings Each of which
06:51 - are made of a collection of paths
06:54 - containing points so this is the x y
06:58 - coordinate of the points and this here
07:01 - is One path
07:03 - that is used to draw the car and this is
07:05 - another path of the car and another path
07:07 - of the car so the car I drew had three
07:11 - different paths and then the face and so
07:14 - on
07:15 - a quick note here about downloading this
07:18 - Json file
07:21 - Marcus suggested I set here application
07:24 - Json otherwise there could be some
07:26 - problems and Godlike Mouse pointed out
07:29 - that I don't need to add this anchor
07:32 - here in the body and it still worked
07:35 - just fine now all the data I collected
07:37 - from you has the same structure as this
07:40 - one right here
07:42 - but it's inside of this data folder and
07:46 - there are a bunch of them
07:48 - 716 of you made drawings so that's a
07:51 - total of
07:53 - 5728 drawings and we can visualize these
07:57 - drawings using this other app that we
08:00 - built but if we open this viewer HTML in
08:02 - a browser we see that nothing is there
08:05 - and if we open the console
08:08 - there are some errors and that's because
08:11 - we need to run some scripts to get
08:13 - things started
08:15 - these are here inside of the node folder
08:19 - we open a terminal
08:22 - I took Diego's advice to use the
08:24 - terminal from here instead of command
08:26 - prompt
08:27 - change the directory to be inside of
08:30 - this note folder and let's make sure
08:33 - that we have node installed
08:37 - and we do if not you're gonna have to
08:39 - install it and then you can run npm
08:43 - install inside of this folder and it's
08:46 - going to automatically run all the
08:48 - scripts that we need
08:50 - it now generates a data set by running
08:53 - this script
08:55 - and what that means is that here inside
08:57 - of the data we don't have just that raw
09:00 - folder anymore it created a couple of
09:02 - new ones
09:03 - the data set folder contains two
09:06 - subfolders the Json folder contains one
09:10 - file per sample so now these paths here
09:14 - are for one drawing the same drawing
09:17 - that you can actually see here in the
09:20 - image folder if you open one.png there
09:24 - is a car here but because it's black and
09:27 - with the transparent background doesn't
09:29 - look very nice but it's okay because all
09:32 - our scripts have finished now so we can
09:34 - investigate this data in the viewer HTML
09:38 - after we refresh it
09:40 - you can see how ninja coder's style
09:42 - looks here as well
09:44 - I like this dark mode I think it's
09:47 - better on the eyes
09:49 - now what we see here on the left are
09:52 - many many people the 716 who have made
09:55 - drawings the drawings are here in one
09:58 - row and if you click on one you can see
10:01 - its features on the right highlighted on
10:04 - the chart
10:05 - now these features the width and the
10:08 - height that we extract are the features
10:11 - of the bounding box if I drag this item
10:14 - up here like so to see it better
10:17 - this is what the width means and this is
10:19 - what the height needs
10:21 - so this car has a much larger width than
10:24 - the height
10:26 - seems to be about double
10:28 - now if we scroll down here about halfway
10:33 - we're going to see a new section
10:35 - starting called testing and here the
10:38 - labels that you see written are what our
10:41 - machine learning system thinks that they
10:44 - are
10:46 - the blue highlights are the correct ones
10:49 - but the others are wrong and here if we
10:53 - are going to click on something for
10:55 - example this pencil
10:57 - we will see a different kind of
10:59 - highlight here on the chart let me zoom
11:02 - in a little bit
11:04 - and just to make things clear I'm going
11:07 - to click on this pencil few more times
11:10 - and notice that it's not originally
11:13 - there it's a new point that we've added
11:15 - now and it's categorized as a pencil
11:18 - because its nearest neighbors the
11:21 - majority of them are pencils here we use
11:24 - 50 nearest neighbors and I'm drawing a
11:27 - connection to all of them so based on
11:29 - the majority our machine Learning System
11:31 - the K nearest neighbor classifier
11:34 - categorizes this as a pencil but
11:37 - sometimes like this guitar for example
11:40 - seems to be a house
11:43 - let's figure out why
11:55 - it's quite hard to count but you can
11:58 - probably see quite many houses here in
12:00 - this area so it is a house our accuracy
12:04 - is not that good at the moment but I'm
12:07 - gonna teach you how to double it by the
12:09 - end of this course
12:11 - there's also this button here for
12:13 - opening the sketch pad
12:15 - and here you can draw something
12:18 - live and in real time you're going to
12:21 - get the classification if you zoom out
12:24 - you're gonna see this drawing that we
12:26 - made here and all of its nearest
12:28 - neighbors and in this case the majority
12:30 - are pencils but maybe if we're gonna
12:33 - turn this into a tree
12:37 - now this has changed
12:40 - and the new majority
12:43 - seem to be
12:45 - trees we've built some really nice tools
12:48 - didn't we
12:49 - one more thing I should remind you of is
12:52 - that we also have this decision boundary
12:55 - plot is colored background right here
12:59 - we can use this decision boundary plot
13:03 - more effectively if we go inside of the
13:06 - viewer here and pass the
13:10 - testing samples
13:12 - instead of the training samples to the
13:15 - Chart so now when we refresh
13:18 - well okay things look quite different
13:21 - the decision boundary is only on this
13:24 - side but that's because we have this one
13:27 - sample here from armenio which I suspect
13:31 - actually has a really really long width
13:34 - and it was some glitch in the drawing so
13:37 - for that reason it has about two width
13:41 - instead of a maximum of one these are
13:44 - normalized
13:46 - anyway now when we look at these testing
13:50 - samples here
13:52 - if they lie on the same color as the
13:55 - decision boundary plot indicates they
13:58 - are correctly classified
14:00 - but if they don't like this one right
14:02 - here then it means that it's a wrong
14:06 - classification so anything that looks
14:08 - colorful on a different background it's
14:11 - a bad classification
14:13 - like this is apparently a guitar
14:17 - let's review a bit how these scripts
14:20 - work in the node folder the data set
14:23 - generator is creating necessary
14:26 - directories if they don't exist yet and
14:29 - then it's generating this new form of
14:32 - the data set it's going through each of
14:35 - the samples one by one and it's writing
14:38 - them in a new file and also generating
14:41 - an image for each one
14:44 - this is the function from down here
14:47 - now feature extractor is going through
14:50 - the samples one by one and extracting
14:53 - features as specified by this feature
14:56 - functions in use
14:58 - you can find these feature functions in
15:01 - the common folder at the top right here
15:05 - and there are several functions defined
15:07 - here but in use we just have the width
15:11 - and the height functions that I
15:13 - mentioned previously
15:16 - these two are not used at the moment
15:19 - they could replace the width and the
15:21 - height here but these are just much
15:23 - better so we keep them for now
15:26 - now back to our feature extractor.js
15:29 - after we get these functions we call
15:32 - them here on the paths of every sample
15:36 - one by one and extract the data point
15:40 - we then split in training and testing
15:44 - half and half and normalize the data to
15:47 - be between 0 and 1. and then we just
15:50 - write the output files in training and
15:54 - testing respectively and there are three
15:56 - formats here training training
16:00 - JavaScript and training CSV and same for
16:03 - testing you can find these in the data
16:08 - data set
16:11 - and they are right here the Json files
16:14 - are here and the CSV files are here and
16:19 - the JavaScript files are up here in JS
16:22 - objects
16:24 - testing and training JS they are the
16:27 - same information written in a bit
16:29 - different way because I want these to be
16:32 - accessed by our scripts here but also by
16:35 - our web page and also by the Python
16:38 - scripts
16:40 - that we have here that's what the CSV is
16:43 - for and yeah I know python can read Json
16:46 - too but I've seen so many people use
16:49 - csvs in Python and I think it's a common
16:51 - practice and you should know about it
16:53 - too
16:55 - so if I'm going to open here testing
16:58 - Json
17:00 - and I'm going to format it here you will
17:03 - see first the feature names the width
17:04 - and the height and then all the samples
17:07 - here Car Fish House tree bicycle guitar
17:11 - pencil Rock and then
17:14 - another car Fish House tree and so on
17:17 - all of the
17:21 - 2864 samples are listed here and this
17:25 - long array and the point is just the
17:28 - width and the height values for each of
17:30 - these samples you're gonna find the same
17:33 - information here in testing CSV but here
17:36 - it's a different form
17:37 - but width and the height and then the
17:39 - label here it's something you could
17:42 - easily paste in Excel as well
17:45 - and the Javascript file here at the top
17:48 - is the same as testing Json but with
17:51 - this in front of it it's creating
17:53 - essentially a global variable called
17:55 - testing with this content here and I'm
17:59 - not particularly happy about this code
18:01 - structure it would have been much better
18:04 - to use modules here and make them read
18:06 - Json actually rumax suggested I do that
18:09 - and I recommend you try what he says
18:12 - there the problem for me is that if I
18:14 - use the live server extension for some
18:17 - reason everything starts lagging on my
18:19 - computer I'm not sure if it's just me or
18:21 - for some reason the code we're writing
18:24 - doesn't work in general with the live
18:26 - server extension but if you do try it
18:28 - out let me know how it went now going
18:32 - back to these
18:34 - node scripts the last one is run
18:38 - evaluation and it's going to use the k n
18:41 - classifier here built using the training
18:45 - samples and it's going to classify the
18:48 - testing data and compute an accuracy it
18:52 - also generates this decision boundary
18:54 - plot and stores it here in data models
18:59 - this is where that image comes from now
19:02 - this image is a low resolution here
19:05 - because when running this script this
19:08 - part is quite slow it's going to
19:11 - generate that color for each individual
19:14 - pixel and the size of this image is 100
19:17 - by 100 pixels but that means 10 000
19:20 - different pixels there to calculate and
19:23 - for each pixel you need to calculate the
19:25 - distances to all of the nearest
19:28 - neighbors and that's a really intensive
19:30 - process so if you want to set here a
19:34 - bigger value like 5000 this decision
19:38 - boundary plot it's going to look much
19:39 - nicer but you're going to have to wait a
19:41 - few hours but you're in luck because if
19:44 - you want to see how such a decision
19:46 - boundary plot looks like you can open up
19:49 - this resources folder and it's this one
19:53 - right here
19:55 - kmn 50. you can replace the one from
19:59 - here if you want to see it in action on
20:01 - the web page
20:11 - and refresh
20:14 - and now it's much sharper and you can
20:17 - also zoom in to see how the edges look
20:20 - like
20:22 - now before we get into implementing new
20:25 - things I have to mention this chart
20:27 - right here I've implemented a more
20:30 - optimized version of it
20:33 - if we close these
20:37 - things
20:40 - and open the chart from the web folder
20:44 - the optimization I've done is that from
20:47 - the chart homework nobody did it and I
20:50 - can understand why it's kind of
20:52 - challenging
20:53 - but I did point out what I did here and
20:56 - there and you can compare with the
20:57 - previous code if you're curious
21:00 - basically if doing something like maybe
21:03 - updating now this
21:05 - Point here
21:10 - the one that we are drawing I'm not
21:13 - redrawing everything all the time it
21:17 - just Updates this one drawing on an
21:20 - overlay canvas on top of the previous
21:22 - one
21:24 - I did get one
21:26 - optimization for the scaling
21:30 - which I've added here this was suggested
21:33 - by better and I also want to point out
21:36 - improvements I got to my prerequisite
21:39 - videos about 2D vectors and trigonometry
21:42 - from Christian and Georgia Christian
21:45 - rewrote the code in an object-oriented
21:48 - way and used bootstrap and Georgia tells
21:51 - us how to make it work if you scroll
21:53 - with the magic mouse on Apple devices
21:57 - also one funny thing that happened is
21:59 - that these emojis now are different than
22:01 - before because I got Windows 11 on my
22:04 - operating system and they changed a bit
22:08 - I recorded them a little bit differently
22:11 - here with the filters
22:13 - but they would have been just fine
22:15 - otherwise as well quick mention to this
22:18 - python folder here so if I'm going to
22:21 - start the terminal now and go to
22:27 - python folder and type
22:32 - python k n we're going to get the
22:34 - accuracy here as well but the code there
22:37 - is really small like this is it because
22:41 - we use the scikit-learn library and we
22:43 - import the K nearest neighbor classifier
22:45 - from there read the data from our CSV
22:48 - files directly and this is actually done
22:51 - here with a read feature file function
22:55 - from the functions py and the python is
22:58 - not really adding anything into this
23:00 - project it's just showing you another
23:01 - way of doing things with libraries which
23:04 - is common I think
23:06 - now let's begin to implement a way to do
23:09 - data cleaning and speaking of cleaning I
23:12 - reformatted all the code to use spaces
23:15 - now and we are going to be testing on
23:19 - the different window like this I got a
23:21 - lot of bad comments saying I should use
23:23 - spaces and now with this larger window
23:27 - here I have room for that
23:30 - now data cleaning means that we are
23:33 - going to throw out some samples which
23:36 - make our model bad for some reason
23:40 - for example here this is a drawing of a
23:43 - guitar but it looks like some kind of
23:45 - mistake
23:47 - and same for this pencil here
23:49 - we can also see maybe here this one this
23:54 - is not the drawing of the car it's a
23:56 - drawing of a of a bird I think
23:59 - so small things like that that are
24:03 - probably ruining the model in some way
24:07 - I'm going to want to throw away it's
24:11 - very tedious to start writing down which
24:14 - samples need to be removed so I'm going
24:17 - to build a tool that allows me to click
24:20 - on the samples here and remove them
24:24 - you'll see
24:26 - but now the clicking is implemented
24:28 - already here
24:32 - in display.js
24:35 - right here where we click on the sample
24:38 - container and we should inspect the
24:42 - event we get when clicking here to see
24:44 - if we can figure out how to maybe
24:47 - control click on the item and do
24:49 - something else instead of this handle
24:52 - click function so I'm going to type here
24:55 - EVT for event and now I'm going to open
24:59 - here a curly brace and close it like
25:02 - this because we're going to write more
25:04 - things let's begin with the log in the
25:07 - console
25:09 - logging this event saving the file and
25:13 - now refreshing the page and I'm going to
25:16 - open the console
25:18 - and click on something here and you can
25:21 - see now the event is printed here if we
25:24 - look at the properties we will find this
25:27 - control key that is set to false and if
25:31 - I hold now control when I click on
25:33 - something
25:34 - and scroll down here we will get another
25:38 - print of the event but this one has Ctrl
25:41 - key set to true so that's how we're
25:43 - gonna distinguish between the two
25:46 - let's remove this line
25:49 - and check if
25:52 - the control key is on
25:56 - we are going to toggle
26:00 - the flagged sample because I want to
26:03 - flag something when I click on it like
26:05 - that but I also want to unflag something
26:07 - in case I did a mistake I don't want to
26:10 - refresh the whole page if that happens
26:13 - so otherwise here we are going to set
26:16 - else and put this handle click in that
26:20 - case now this functionality for toggle
26:24 - flagged sample will be implemented in a
26:27 - new file I'm going to call this data
26:30 - cleaner
26:31 - so let's open our viewer here and
26:36 - import this new file
26:43 - data
26:45 - leaner
26:47 - and created here inside of this
26:50 - JavaScript
26:51 - folder
26:55 - data winner dot JS here our flagged
27:00 - samples are going to go
27:03 - inside the list which is empty for now
27:06 - and our function for toggle flag simple
27:11 - given a sample
27:14 - is going to do the following
27:16 - it's going to check if the flag samples
27:20 - includes the ID of the sample
27:24 - and if so we will remove it I first get
27:28 - the index
27:31 - of this sample that we clicked on
27:35 - and then I'm going to remove it
27:38 - by using the splice at the given index
27:41 - removing one item now if we clicked on
27:45 - something that isn't yet in the flagged
27:47 - samples we just
27:49 - add it there using the push method
27:52 - like so and now we want to visually
27:55 - emphasize which items are flagged and
27:57 - which not we're going to make a flagged
28:00 - class that is going to be added to all
28:02 - the flagged samples and every time we
28:05 - click on something we remove the class
28:07 - from everything and then add the class
28:10 - to those flagged samples kind of like a
28:13 - refresh mechanism so let's first remove
28:16 - this flagged class
28:20 - from all items that are flagged like
28:24 - this
28:25 - using a for each Loop
28:28 - so that each items
28:34 - lagged class gets removed
28:38 - and then re-added
28:44 - like so we are going to Loop through the
28:46 - flagged samples
28:49 - get the element using get element by ID
28:56 - the sample with that ID
28:59 - and add this to the class list
29:03 - like so
29:05 - so this should work
29:07 - only thing we need is a new class called
29:10 - flagged and we're going to be adding
29:12 - that in styles.css and I'm going to be
29:15 - doing it here at the bottom of the file
29:21 - it's just going to be marking everything
29:24 - with a red color and I'm using here
29:27 - important because I want it to be on top
29:31 - of the previous style let's save this
29:35 - and now refresh
29:37 - and clicking things normally works as
29:40 - before but control clicking gives us
29:44 - this flagged View and if I click again
29:46 - on the item is going to go away
29:51 - so let's start flagging here the things
29:53 - I pointed out previously and I'm now
29:56 - going to go through all the things and
29:59 - mark down anything I see suspicious
30:09 - and I'm done it took much longer than I
30:12 - thought it will
30:15 - but it's over and um
30:18 - I basically marked down things that are
30:21 - incorrect or don't look at all like what
30:24 - they should be
30:25 - this should be a bicycle but somebody
30:28 - drew a house here so sometimes these
30:30 - things happen and Pi just drew mixing
30:34 - things up I think they wanted to see how
30:37 - the system handles those cases
30:41 - but most of the data is quite good and
30:45 - in total I think there is probably about
30:49 - maybe 200 or so flagged samples this is
30:53 - a funny one this is supposed to be a
30:55 - house but many people drew a horse there
31:00 - instead like gin and I think this has to
31:04 - do with psychology
31:06 - um basically
31:07 - house and horse are very close when you
31:11 - look at the letters and I asked you to
31:14 - draw a house after a fish so it's after
31:17 - another animal and without the context
31:21 - just being told to draw this then you
31:26 - might read Horse by mistake and Jin is
31:28 - not the only one there are actually
31:30 - quite many horses here in the database
31:34 - and that's funny because it reminded me
31:37 - of this uh Mandela effect if you don't
31:39 - know what it is I'm gonna link it in the
31:42 - description but basically there are
31:45 - things that people remember differently
31:49 - than what they happened and there are
31:51 - things that large groups of people
31:54 - remember something differently than what
31:58 - what actually happened and this could be
32:01 - one example of that like if we're gonna
32:03 - group together everybody who has drawn
32:07 - horses here and we asked them what were
32:10 - they supposed to draw they will
32:12 - definitely remember the horse being
32:14 - asked but I never asked anybody to to
32:17 - draw a horse I asked for a house
32:21 - anyway let's have a look at our flagged
32:24 - samples so
32:27 - I'm going to type this in the console
32:29 - here
32:30 - and there are oh actually close to 300
32:33 - of them
32:34 - so 300 flagged samples that means we
32:39 - have
32:41 - 5445 to work with and one thing I really
32:44 - need to mention here is that I actually
32:48 - flagged samples also in the testing set
32:52 - and normally you don't do that because
32:55 - testing should be as natural as possible
32:58 - and we only want to do the flagging in
33:00 - the training data which we use to create
33:03 - our models but I did it because I don't
33:06 - think it's going to impact on the
33:07 - accuracy that much and I think that the
33:10 - people who have made those
33:12 - drawings that are messed up on purpose
33:15 - will not expect the system to mess up
33:19 - as well so normally that's not needed
33:23 - but also because I don't want to do this
33:25 - again anytime soon and if more data
33:28 - comes then a lot of them are going to be
33:30 - flagged already so yeah just keep in
33:34 - mind that normally you don't touch the
33:36 - testing samples now this array here is
33:40 - quite long and I would like to
33:42 - copy it somehow I'm just going to write
33:46 - here Json
33:48 - stringify
33:50 - the flagged samples and this is going to
33:54 - display all of it here
33:56 - as a string like so I'm going to copy it
34:02 - and go into common and utils and under
34:07 - the flagged users which are people that
34:10 - have drawn some bad stuff I'm going to
34:13 - add here
34:15 - flag samples
34:19 - and I'm going to paste here
34:22 - what we got
34:27 - and remove the string syntax from there
34:31 - and now we're going to use these flagged
34:34 - samples when creating the data set to
34:36 - Omit them from the raw data we'll still
34:40 - keep them in the Raw data for a
34:42 - reference but we won't be using them in
34:45 - any of our tasks
34:46 - so let's go here inside of our node
34:51 - folder and data set generator
34:54 - and right here a line in this for Loop
34:58 - that is going through all of the samples
35:01 - like so if
35:04 - the sample is not flagged
35:08 - so if the flagged samples doesn't
35:10 - include this ID that we are generating
35:14 - here
35:15 - then
35:18 - we do everything for it write it in the
35:21 - new file and generate the image for it
35:24 - here
35:26 - like so and now we can run this data set
35:29 - generator using node so I'm going to
35:33 - start the terminal go to the
35:36 - node directory and type here node
35:41 - data set generator
35:45 - you can put JS if you want but it will
35:47 - work like this as well
35:51 - and now those samples that are
35:54 - problematic should be omitted from our
35:57 - processing
36:02 - now after the script is done we also
36:05 - have to run feature extractor and this
36:07 - run evaluation if we want to use the
36:10 - viewer app because it's based on the
36:13 - features and the decision boundary plot
36:16 - is calculated using that so node
36:21 - feature extractor
36:26 - and node run evaluation
36:32 - we are done and you can see the accuracy
36:35 - is actually a little bit different 42.36
36:40 - compared to what we had previously so
36:43 - now when we refresh this page we will
36:46 - see these changing maybe here also some
36:49 - of these will look different I don't
36:52 - know
36:53 - and of course some of these samples will
36:56 - not appear here let's see refresh
37:00 - so a different result here
37:03 - as expected and now the decision
37:06 - boundary plot is again pixelated if you
37:10 - want to have a better one then you have
37:13 - to wait and put there something like
37:15 - 5000 or use the one that I provide for
37:20 - you in the resources here
37:23 - there are two of them one that you used
37:26 - previously is this KNN 50 and the other
37:29 - one is kmn 50 after filtering and they
37:35 - look a little bit different but not by
37:37 - much
37:38 - so let's take this one and in the data
37:43 - models I'm going to paste it here
37:48 - and delete the small resolution one we
37:51 - just created and rename this one so that
37:55 - I remove everything except for decision
37:58 - boundary
38:03 - and refreshing now the page is going to
38:05 - show the other one that I gave you
38:09 - it's much sharper now
38:11 - now if we scroll down we see that some
38:15 - of these samples are missing
38:20 - sometimes entire users might be missing
38:23 - if I flagged all the samples and I
38:26 - actually flagged all the samples of the
38:28 - flagged users so those won't appear here
38:31 - anymore
38:32 - and everything looks fine but out of
38:34 - proportion I would like to keep
38:36 - everything the same size here so I'm
38:40 - going to fix that by going
38:42 - to Styles CSS
38:47 - at our sample container
38:54 - and I'm going to add here
38:57 - a Max width of eight percent I notice
39:01 - that this does the trick
39:03 - so let's refresh
39:05 - and now the things look better aligned
39:09 - one more thing is that when we go here
39:14 - at our halfway point where the testing
39:17 - starts you will notice profit here has
39:21 - his data split into some of it will be
39:24 - the training data and some of that is
39:27 - used for testing that's just fine it's
39:30 - where the midpoint happened to be
39:33 - now one more thing I want to do is say
39:37 - somehow that we have this new flagging
39:39 - functionality
39:41 - so I'm going to add the title here an
39:45 - info button and when we hover it it's
39:47 - going to say some instructions how to
39:49 - use that we do that in this viewer HTML
39:53 - file and here in the H1 tag let me just
39:58 - open it like this and type here span
40:04 - with the class called info button
40:08 - let's close this pan and I'm going to
40:12 - add here this info button symbol
40:17 - and then inside here I will have a tool
40:22 - tip inside this I will just write
40:29 - now let's save this and go inside our
40:33 - styles
40:35 - at the bottom one for the info button
40:43 - let's make it red and have the cursor be
40:46 - a pointer because we can click on it or
40:49 - hover it and then when hovering
40:52 - it's going to make the tooltip text
40:56 - visible
40:58 - so one more style now for this tool tip
41:01 - text
41:03 - and I'm gonna have this one have white
41:06 - text on a red background I think the
41:09 - combination goes well
41:12 - and let's position it so absolute
41:15 - positioning
41:18 - hidden by default and a small font size
41:23 - and let's have it
41:25 - around a bit
41:27 - and give it also padding and remove the
41:34 - bold of the font because that's how they
41:37 - are by default inside of this H1 tag
41:41 - so refreshing
41:43 - here's now our button here
41:46 - and when we hover it we get the
41:48 - instructions
41:50 - so far we've measured the goodness of
41:52 - our system using one number but if we
41:55 - want to improve our recognizer we need
41:57 - to understand what it does good and what
41:59 - not like can it recognize pencils better
42:02 - than houses for example a good tool for
42:05 - understanding this is the confusion
42:07 - Matrix a table that says how many items
42:10 - are misclassified as something else like
42:12 - here out of 343 trees 211 are correctly
42:17 - recognized but three are classified as
42:19 - cars one is a fish 45 is a house and so
42:22 - on
42:23 - now let's learn how to code this new
42:26 - visualizer and don't worry you won't be
42:29 - confused for long
42:31 - we will draw the confusion Matrix on top
42:33 - of this chart somehow and there will be
42:36 - a button here to toggle it on or off so
42:38 - we can still see the chart sometimes
42:40 - let's go to viewer HTML
42:44 - where we have our chart container and
42:47 - I'm going to open it up like this and
42:50 - add the container for the confusion
42:52 - Matrix here
42:54 - so this will be a simple div just like
42:58 - this one
43:00 - but it will be called
43:02 - confusion
43:04 - container let's give this a style and I
43:08 - will go in style CSS let's look for our
43:12 - chart container and put this one
43:15 - underneath because they're related
43:19 - and type confusion container
43:23 - the position will be absolute
43:26 - and I want it to be far right as
43:30 - possible so right 0 and let's give this
43:33 - a white background color
43:36 - and I want the Z index of one the chart
43:40 - has now there are some additional items
43:42 - and I want it to be on top of those
43:44 - let's save this and go back to viewer
43:47 - HTML and add a button to toggle this
43:51 - output as well so this we will refer to
43:55 - as the output what is on the right and
43:58 - now the toggle input function is in JS
44:02 - display JS at the very bottom here I'm
44:06 - going to copy it and make a similar one
44:09 - for toggle
44:12 - output and this one is going to use the
44:16 - confusion container instead of this
44:20 - input container so
44:22 - Fusion container here and we don't need
44:27 - anything else than doing this styling
44:30 - right here let's refresh
44:33 - and here's the button and when we press
44:37 - it nothing really happens but if we open
44:40 - the console here
44:42 - and inspects
44:45 - this element we can see that this
44:47 - confusion container is actually there
44:50 - it's just empty so it has 0 0 width and
44:54 - height if we would force it to have here
44:57 - maybe a width of 500 pixels
45:01 - and the height of 500 pixels
45:05 - then it's now going to cover the charts
45:07 - perfectly and toggling it
45:11 - seems to work let's implement this
45:14 - component next
45:18 - we will make this component very similar
45:21 - to the Chart component here
45:25 - it's just going to work something like
45:29 - confusion is a new confusion
45:36 - and here we pass the container the same
45:40 - way that we passed the container for the
45:42 - chart and then we also need to pass here
45:45 - the testing samples and we will also
45:48 - need as all the classes here so in order
45:53 - they are Car Fish House three
45:58 - bicycle guitar
46:01 - pencil
46:03 - look
46:04 - and I just realized that we don't have
46:07 - these
46:08 - defined anywhere really so let's cut
46:12 - this from here and add these to utils so
46:16 - utils
46:18 - classes
46:20 - and now here in common utils at the top
46:24 - we have these styles that contain them
46:26 - somehow but it's convenient to have them
46:29 - listed as well so utils
46:33 - classes is equal to
46:37 - what I just copied from there
46:40 - and back to viewer HTML I will also pass
46:44 - these options
46:46 - to the confusion Matrix component as
46:50 - well
46:54 - okay now we Define this confusion
46:59 - in another file so let's go up here
47:03 - next to the other chart elements I will
47:06 - also put it inside of the chart folder
47:09 - so let's put here
47:12 - confusion
47:14 - Js inside of the chart here I will
47:18 - create a new file
47:21 - confusion
47:23 - Js
47:24 - and here we begin to type this new class
47:27 - so class confusion
47:32 - and in the Constructor the first thing
47:36 - is the container followed by the samples
47:39 - we will be passing the testing samples
47:42 - here
47:43 - and the classes list
47:45 - and then these options
47:48 - let's store these as attributes so first
47:51 - samples
47:54 - then passes
47:59 - and I'm gonna take out the size and the
48:03 - style from the options that's really
48:06 - what we need here
48:08 - now the Matrix inside there will be an 8
48:12 - x 8 Matrix but I will actually make it 9
48:16 - times 9 because I wanted to include the
48:19 - header section on the top and another
48:22 - kind of header section on the left those
48:25 - would have cumulative values on the
48:28 - columns and rows respectively
48:31 - so a size for this Matrix let's say n is
48:36 - going to be equal to
48:39 - the length of the class is how many
48:41 - classes there are plus one and now
48:44 - imagine the space here divided as a grid
48:48 - of 10 by 10 cells
48:51 - we'll use the left Mouse and the topmost
48:54 - for the labels and then the Matrix will
48:57 - go in the remaining space
49:00 - so the cell size that we are looking for
49:03 - can be calculated here like so
49:11 - we need to add another more 1 to that n
49:14 - for it to be proper
49:16 - we'll display this confusion Matrix as a
49:19 - table so let's create a table element
49:22 - using the create element the passing
49:26 - table here and now I'm going to pass
49:29 - here
49:30 - a style we will collapse the borders
49:33 - borders make
49:38 - things very confusing to me at least and
49:40 - we just don't need them it's going to be
49:42 - quite
49:43 - nice looking without you'll see
49:46 - and everything will be also aligned to
49:51 - Center all the text elements and because
49:54 - I want to keep space for those labels on
49:57 - the left and on the top I'm going to
49:59 - also add here a margin left
50:03 - of the cell size like so and the same
50:08 - goes for margin
50:11 - top now we also need to append this
50:16 - table to the container
50:19 - and now this table is going to be the
50:21 - holder of the Matrix we need to prepare
50:24 - the Matrix and fill the table
50:27 - so these are going to be
50:29 - two private methods
50:33 - let's get the Matrix ready from the
50:35 - samples and then fill the table like so
50:39 - the Matrix will be an attribute here so
50:42 - we'll have access to it
50:46 - this free per Matrix function
50:52 - is going to start off with an empty
50:55 - Matrix
50:56 - so let's define it as an empty list like
51:00 - this
51:01 - but we will have to generate its rows as
51:06 - well and different rows
51:08 - each of them is going to be an empty
51:11 - list and
51:13 - each row will be filled with n zeros for
51:17 - now so I'm going to generate this Matrix
51:22 - filled with zeros
51:26 - like so and now we can start putting
51:29 - here the values coming from the samples
51:33 - so let's look through the samples I'm
51:37 - going to name each sample s because it's
51:39 - shorter and the next line is going to be
51:42 - quite long
51:43 - so the Matrix of and now I want to get
51:48 - the index of the true value of that
51:52 - sample so the index relative to this
51:55 - classes
51:57 - up here
51:59 - I'm going to type
52:01 - Oasis index of
52:05 - the true value of the sample because
52:08 - those are going to be vertically and
52:11 - because the leftmost column will do
52:13 - something special and have some
52:15 - cumulative values I want to go past that
52:19 - so I add here one
52:22 - and the second
52:24 - index is going to be the same but with s
52:29 - dot label which is the label we
52:32 - predicted using our machine Learning
52:34 - System
52:35 - and also the top header means shifting
52:39 - here by one as well we take that value
52:42 - of the Matrix at these indices and we
52:47 - increase it
52:48 - and that's it now we just have to return
52:51 - here
52:52 - this Matrix like so and it will be
52:56 - passed to this attribute now the fill
52:59 - table
53:00 - method here
53:03 - is going to add the rows and cells into
53:06 - that table
53:08 - so let's define it
53:11 - like so
53:13 - and because I don't want to type this
53:15 - all the time I'm going to use this
53:18 - destructuring assignment here and I will
53:22 - take out
53:23 - some of the attributes
53:26 - from this
53:28 - and now I can just use them by typing
53:30 - them as such
53:34 - we will look
53:37 - from 0 to n like this and generate a new
53:42 - row in The Matrix
53:44 - this role we generate with the create
53:48 - element and we use the TR element for
53:51 - table row
53:54 - and let's append this to the table
53:58 - and now we can loop again so now we are
54:02 - going to go through each individual
54:04 - cells and create those
54:07 - these cells are going to be
54:10 - create elements
54:12 - a TD element is for creating the cells
54:16 - and let's style this cell
54:21 - so that it has cell size pixels in width
54:25 - and I'm going to copy this
54:28 - or the height as well
54:32 - and let's remove the padding
54:36 - also and now I'm going to add the text
54:40 - of this cell
54:41 - to be the value of the Matrix at inj
54:46 - simple as that we just have to add the
54:51 - cell to the row now and we can save
54:55 - refresh
54:56 - and this looks as expected these zero
55:00 - values will have to take care of but I
55:02 - also want to take care of this top text
55:05 - here and the left text here let's begin
55:08 - with that
55:09 - so
55:11 - at the top after we create this
55:15 - table I'm going to add to the container
55:18 - two more things so let's generate
55:22 - a div for this
55:25 - top text
55:28 - like so and this is going to be
55:32 - saying
55:35 - predicted
55:37 - class
55:39 - and we'll style it to have an absolute
55:43 - positioning and give it a really large
55:47 - font
55:49 - extra large and let's set the Top Value
55:53 - to 0 pixels
55:55 - and I'm going to position it 50 from the
55:59 - left but that's going to position its
56:01 - top left corner 50 from the left so I'm
56:05 - also going to transform
56:08 - translated by minus 50 horizontally
56:13 - and let's append this
56:17 - to the container
56:20 - now if I'm going to refresh
56:22 - it's almost good I would like it to be
56:26 - lower like this if possible so I'm gonna
56:30 - give this a height equal to the cell
56:33 - size and then I'm gonna use flex
56:35 - positioning here to align the center
56:38 - so let's go here
56:41 - and give the height of cell size in
56:46 - pixels
56:49 - and
56:50 - set the display to flex
56:54 - and the Align items
56:57 - Center
57:01 - okay much better
57:05 - but
57:07 - um I would like this to be in the middle
57:10 - of this right here so this should be the
57:13 - middle point and that means I need to
57:15 - add the margin of half the cell size
57:19 - to the left so let's go here and say
57:27 - so that
57:33 - great now we need to do the same for the
57:36 - left text
57:37 - so let me just copy everything here
57:43 - and I'm gonna rename this left text
57:53 - and the differences are this is going to
57:56 - be the label for True class
58:00 - and I want this text to be rotated by
58:03 - minus 90 degrees
58:07 - and here
58:09 - left and top should be switched so let's
58:13 - move this stop here and this
58:17 - left value here
58:20 - now we refresh
58:22 - looks good
58:24 - let's calculate these cumulative values
58:27 - here by adding everything
58:30 - in this way and everything in that way
58:34 - I'm going to go after we prepared The
58:37 - Matrix here at the end of this prepare
58:40 - Matrix and now we have those values the
58:44 - ones that we see here
58:47 - in this bottom right corner
58:50 - and I'm going to use them to add to the
58:55 - zero values on the left here and at the
58:58 - top
58:59 - so we do that with
59:01 - a for Loop
59:04 - so going through all the elements but
59:07 - skipping the zeroth row
59:11 - and another for Loop going through all
59:13 - the elements of each row but skipping
59:16 - the First Column so starting at one
59:19 - instead of 0. and here we set the Matrix
59:23 - 0 and J
59:26 - to be increased by matrix of I and J and
59:31 - the same for the First Column also
59:34 - let's refresh
59:36 - and these seem to be
59:40 - just right
59:42 - this looks like a very small value here
59:44 - and these all here seem to be small
59:47 - values none of them is over 100 so
59:51 - I think this calculation is correct
59:54 - now these numbers here is what I would
59:58 - expect to get these values should match
60:02 - these values here if we would do a
60:05 - perfect prediction
60:06 - and if a value is bigger like for
60:09 - example this 466 here is much bigger
60:13 - than this 343 or
60:17 - five three seven here it's much bigger
60:20 - than three three nine then we are
60:23 - generating too many of these items if
60:26 - it's too small then we are generating
60:28 - too few of these items so I would
60:31 - actually like to see these at the top as
60:33 - a kind of a relative difference to this
60:37 - let's do that also
60:41 - with the for Loop
60:43 - going through all of the items at the
60:47 - top
60:48 - I'm going to modify them now that they
60:51 - exist by subtracting the value at I and
60:56 - zero basically the value on the left
60:58 - there
61:00 - refresh
61:02 - and now you read these as here we have
61:06 - too many there is an excess and here we
61:09 - have too few there should be more of
61:12 - this item
61:13 - I think that I would like to see a plus
61:15 - sign there for those particular cases
61:19 - and um
61:21 - and also this is zero here is useless
61:24 - and should be removed so let's do that
61:28 - I'm going to set here Matrix 0 0 to
61:32 - nothing and
61:34 - here
61:37 - if the value is greater than zero
61:41 - add the Plus in front of it
61:45 - I'm styling these just the way I like if
61:48 - you want to do it differently then
61:50 - feel free but I'm quite happy with what
61:53 - the end result is going to be you'll see
61:56 - okay good but we don't really know what
61:59 - these objects are supposed to be we can
62:02 - probably remember the
62:04 - Car Fish House tree bicycle guitar
62:08 - pencil clock but better if we show their
62:11 - the icons and they are part of the
62:13 - styles
62:14 - so I'm going to go here
62:18 - and style these cells even more but only
62:23 - if it's the top row and skipping the
62:26 - first item there in that corner so if I
62:30 - is 0 and J is greater than 0 Let's give
62:34 - this cell a background image
62:38 - and I will set this to a URL
62:42 - coming from
62:44 - this place so the styles
62:49 - are going to contain for each class the
62:53 - image and I will take the source of that
62:55 - image and pass it to this URL now here
62:59 - we need to do a j minus 1 because our JS
63:02 - increase by one because of that First
63:05 - Column header
63:08 - and let's close this here like so now
63:12 - I'm going to save this file
63:14 - refresh and we should see on the top row
63:19 - I'll add the items are but these
63:22 - background images repeat now
63:25 - unnecessarily
63:26 - so let's go here and
63:29 - say
63:33 - background repeats set it to no repeat
63:42 - and now let's align these the center and
63:46 - I also want to give them a little bit
63:48 - spacing from the top there
63:50 - so let's type here
63:56 - background position 50 from the left and
63:59 - let's say 20 from it
64:03 - okay and let's move now the text lower
64:06 - so I'm gonna align it vertically to
64:09 - bottom
64:14 - and let's make it bold as well to be
64:18 - emphasized as a header
64:24 - okay good and I want to apply the same
64:27 - style also here on this side
64:30 - so let's just copy this
64:34 - below and replace here I with J and J
64:39 - with I and here J with I
64:43 - as well
64:45 - now this is good
64:47 - but these values here the plus and minus
64:50 - I would like to emphasize them using
64:52 - colors as well it's hard when looking at
64:55 - so many numbers otherwise so let's have
64:59 - these positive values red and the
65:01 - negative values
65:03 - blue kind of like uh temperature scale
65:07 - I'm going to go up here the color
65:11 - intensity is really going to depend on
65:13 - those values from the left so we could
65:17 - take out this as a proportion
65:21 - Matrix of i j divided by matrix of JY
65:26 - like so
65:28 - and let's set the value for red
65:32 - if B is greater than 0 then I'm just
65:35 - going to take e and multiply it by 255
65:39 - that's the maximum of the red that you
65:42 - can get and here zero red otherwise and
65:47 - blue is going to be the same but looking
65:50 - in the negative and I can't give it a
65:53 - blue intensity that is a negative I have
65:56 - to put here minus B times 255 or 0. and
66:01 - with these I'm going to set the style
66:03 - color of the cell using this RGB a
66:11 - like so actually I don't think we need
66:14 - this a at the end so just RGB I was
66:19 - thinking to use the alpha as well but I
66:21 - think that this is going to look just
66:23 - fine
66:24 - let's
66:26 - a refresh
66:28 - and you can see some kind of color here
66:32 - but to get here maximum red or here my
66:36 - maximum blue these differences would
66:39 - need to be really really big
66:42 - um they are not like this should be
66:46 - double
66:48 - 339 so 600 something and even at our
66:52 - current situation with this low accuracy
66:55 - it doesn't appear so strong so I'm going
66:59 - to go here and multiply this P value by
67:05 - two and that's going to make it more
67:08 - striking when there is a
67:11 - considerable high value here
67:14 - and this looks good I think
67:17 - now the next step is going to be to give
67:20 - these cells in the middle a background
67:22 - color also depending on their value
67:26 - and I'm going to use linear
67:28 - interpolation here and give them some
67:32 - values in between the minimum value that
67:35 - we see here and the maximum value that
67:37 - we see here
67:39 - you can also use 0 and the maximum value
67:42 - it it's up to you really but let's first
67:45 - take out all of these values from our
67:48 - Matrix and find out those extremes
67:53 - I'm going to go here at the top of fill
67:56 - table
67:58 - and write
68:00 - the values that we are interested in we
68:03 - take them from the Matrix I'm going to
68:06 - slice The Matrix
68:09 - from one so that we skip the first row
68:13 - entirely
68:14 - and then we are going to take just the
68:16 - items inside by slicing from one so that
68:21 - we skip also the first element on the
68:24 - left
68:25 - and I'm going to flatten these so that
68:28 - all of the values are in one long array
68:31 - and from these I can easily calculate
68:34 - now the minimum using the math minimum
68:38 - function I just have to spread this
68:40 - values array like so
68:45 - and let's do the same here for Max
68:51 - using the max function
68:55 - so now we know the range where we want
68:57 - to do this polar scale in between and we
69:03 - can calculate the value
69:06 - in between this range using the inverse
69:09 - lerp function the inverse linear
69:11 - interpolation function that we defined
69:14 - some time ago
69:18 - I do have a video on that
69:21 - interpolation concept
69:24 - if you want to learn more
69:27 - but basically here if we are inside of
69:31 - the Matrix so that we are not in header
69:33 - section
69:37 - so if these are positive I'm going to
69:41 - get this p-value using this inverse
69:45 - slurp between minimum and maximum
69:51 - from The Matrix of I and J value that we
69:55 - are currently displaying
69:58 - and I'm going to set the background of
70:01 - the cell
70:03 - here using rgba so
70:07 - 255 for red and let's put 0 and 0 4
70:12 - green and blue and the alpha is going to
70:15 - be this p-value which is going to be
70:18 - between 0 and 1 depending on how far it
70:22 - is from mean between Min and Max so this
70:26 - inverse slurp function is a really
70:28 - simple function here
70:30 - given an interval A and B and the value
70:33 - inside the interval it first subtracts
70:37 - from the value a and then divides by
70:41 - this difference so you get a result
70:44 - between 0 and 1 depending on this
70:46 - difference
70:48 - back here let's save the file
70:53 - and refresh the page
70:55 - and this is how it looks like it's
70:57 - really easy to tell what we are seeing
71:00 - here like
71:02 - many houses are classified as as clocks
71:06 - which is a bad thing
71:09 - but um here many trees are classified as
71:13 - trees this is a good thing so one thing
71:16 - that I would still like to emphasize is
71:18 - that anything on this diagonal
71:21 - is a good thing because it means that
71:23 - the item is classified as itself and
71:28 - let's change the color for that as the
71:31 - final update here
71:33 - so
71:34 - well let's say
71:38 - if I is equal to J so if we are under
71:41 - diagonal
71:44 - I'm going to have this let's copy it
71:48 - and here let's close this curly brace
71:51 - else
71:53 - I paste this again inside close the
71:56 - curly brace and for the diagonal let's
71:59 - replace here this red green blue
72:04 - with 255 and set this one to zero so
72:07 - this is going to be blue and again the
72:10 - transparency is controlled by the same
72:11 - thing
72:13 - let's save this
72:15 - and refresh
72:17 - and we're done with the confusion Matrix
72:21 - and some things here are kind of obvious
72:24 - like um
72:26 - the house could be classified as a clock
72:29 - I can accept that because we are now
72:31 - just looking at this bounding box there
72:34 - and the aspect ratio so it doesn't
72:36 - really matter what's inside
72:39 - but some things here are really strange
72:41 - like why so many pencils are classified
72:44 - as clocks
72:45 - this makes no sense I mean
72:49 - pencils and clocks look nothing similar
72:52 - even if you look at the bounding box
72:53 - let's close this output and
72:57 - try to figure out
72:59 - what happens here
73:02 - and if we go here
73:06 - this is really a mess I don't see
73:09 - anything useful here with so many things
73:12 - displayed there what we can do is tell
73:16 - the charts to display fewer items maybe
73:19 - just the
73:21 - pencils that are labeled as clocks
73:25 - so these are very easy things to do we
73:28 - just go to the viewer here
73:31 - where we have our testing samples that
73:34 - we pass to the chart and we can filter
73:37 - them
73:38 - so let's filter these testing samples
73:44 - so that each sample has
73:47 - is going to be kept if
73:51 - it is a pencil
73:53 - but it's labeled
73:56 - as a clock
73:58 - now I'm teaching you this not just for
74:00 - the demonstration now but also that you
74:02 - can inspect your data like this quite
74:04 - efficiently and if I refresh here
74:09 - and close this output
74:12 - all we see now is the pencils and these
74:16 - are pencils that are within this
74:19 - gray region in our decision boundary
74:23 - plot so they are labeled as clocks but
74:27 - now we can click on them
74:30 - ah okay
74:33 - they are probably all drawn at an angle
74:37 - like this
74:38 - so that means that the aspect ratio is
74:42 - pretty much
74:44 - it's comparable to a clock
74:47 - most likely all of these pencils here
74:50 - are drawn at this kind of 45 degree
74:53 - angle
74:55 - I actually thought that pencils are very
74:57 - easy to classify because they were so
75:00 - clearly visible inside of this
75:04 - magenta region let's actually see here
75:09 - like if I remove here this filter
75:14 - and refresh
75:16 - toggle this output
75:21 - it's like nothing else is there blocking
75:23 - them
75:24 - but what I understand now because of
75:26 - this
75:28 - confusion Matrix is that there are
75:31 - actually a lot of pencils there in the
75:33 - middle we just don't see them because
75:35 - this visualization is so crowded
75:38 - we could see them if I add my filter
75:40 - back here and remove this part It's
75:45 - Gonna Keep just those things that should
75:47 - be pencils
75:48 - and let's see where they appear now
75:51 - pretty much everywhere
75:54 - and since we are not drawing everything
75:57 - including herminia's house
76:00 - which is somewhere
76:04 - there
76:06 - it means that our decision boundary plot
76:10 - is scaled in a nicer way these pencils
76:13 - here seem to have a square aspect ratio
76:16 - inside of this feature space
76:27 - so far we've only been using two
76:29 - features the width and height of the
76:31 - bounding boxes but we saw that they're
76:34 - not good enough a pencil like this can
76:36 - be confused with the clock for example
76:38 - today we'll introduce a new feature
76:40 - which will measure how elongated the
76:43 - shape is this will help to separate
76:45 - pencils from other items in a third
76:47 - dimension now Elia solved this problem
76:51 - on Discord it was part of homework
76:53 - assignments 3 and 4. so we're going to
76:56 - use his code and let me briefly explain
76:58 - how it works
77:00 - he first computes something called the
77:02 - convex Hall the smallest convex polygon
77:05 - that encloses the drawing he did it
77:07 - using the gram scan algorithm it's not
77:10 - the only algorithm that can calculated
77:12 - but Ilya used it and I think it's a good
77:15 - choice
77:15 - it goes like this first it only
77:18 - considers the points not the paths it
77:21 - finds the lowest point and from there it
77:23 - calculates the angles to all other
77:25 - points and sorts them then in order new
77:28 - points are added to the stack again and
77:30 - again but if the points are found to be
77:32 - in a clockwise order the middle one is
77:34 - removed from the stack repeating this
77:37 - until the end gives us the convex Hall
77:40 - now Elia used the edges of the convex
77:43 - hole one by one to construct oriented
77:46 - bounding boxes around the shape and
77:48 - chooses the one with the minimum area
77:49 - that's how he solved the problem
77:52 - scared don't be Elia did the hard part
77:56 - and we're just going to use the end
77:57 - result I also think that if you study
78:00 - his code it won't take long before you
78:02 - understand it
78:04 - we're gonna implement the new feature
78:06 - using ilia's help
78:08 - who solved homework assignments 3 and 4
78:10 - pretty much
78:12 - I'm gonna give you this link in the
78:14 - description
78:16 - let's copy this code
78:23 - and I'm also gonna write it in a file
78:26 - called geometry.js
78:30 - let's go and put it inside of common
78:32 - here create a new file
78:36 - geometry
78:38 - Js
78:39 - and I'm going to paste his code here
78:43 - format it slightly and at the top
78:47 - let's write where this code belongs to
78:51 - originally
78:56 - and I'm gonna paste this link
78:59 - right here as well
79:02 - and here we find all the functions
79:04 - needed by the algorithm
79:06 - this Returns the lowest point and it
79:09 - keeps in mind that the y-axis goes
79:12 - downward
79:13 - then here the points are sorted relative
79:16 - to their angle
79:18 - and here is the actual implementation of
79:21 - the Graham scan algorithm
79:24 - the points are added to this stack right
79:27 - here and then the stack is returned
79:29 - there's also this helper function here
79:32 - that calculates the width and height of
79:35 - a box aligned to the hole in some way
79:38 - these are all Vector operations and they
79:41 - should be clear if you've watched my
79:43 - prerequisite video
79:45 - but basically it finds out what is the
79:48 - left top right and bottom and then
79:51 - calculates the width and height using
79:53 - that
79:54 - Elia also returns these vertices here
79:57 - which were returned back in the original
80:00 - space they're not really needed I think
80:03 - but it helps debugging and you'll see
80:07 - will make use of them
80:10 - now this one is basically going to
80:14 - iterate through all the possible
80:16 - orientations and find the box that has
80:19 - the minimum area
80:21 - and then everything is returned here
80:23 - like so
80:25 - two other helper functions here one for
80:28 - getting the angle and one for
80:30 - calculating the distance the squared
80:32 - distance actually because Ilia only
80:34 - needs here the relative distances and
80:38 - there's no point in taking the square
80:39 - root anymore it's a kind of an
80:41 - optimization now that's the code pretty
80:44 - much and it looks good but how can we be
80:47 - sure it's good
80:48 - the only way really is to test it we
80:51 - could write unit tests for it but I
80:54 - prefer to debug visually
80:56 - so let's go to our data set generator
81:01 - file here
81:03 - and now where we generate the image file
81:07 - here I'm going to
81:10 - run elia's code
81:15 - take out the vertices
81:19 - from the minimum pounding box
81:23 - and here we need to pass an object
81:25 - containing points
81:31 - so I'm going to flatten the paths and
81:34 - just take the points from there and make
81:36 - sure that you pass here this it's
81:39 - required and then with these vertices
81:41 - I'm going to draw
81:46 - them with the red color on the canvas
81:50 - now let's save this and open a terminal
81:54 - go to the node directory
82:00 - and here let's run the data set
82:02 - generator
82:08 - like so and while it's doing it we can
82:11 - check the
82:13 - progress here
82:19 - and we can see now this rotated pounding
82:23 - box
82:27 - but it's missing one of the lines there
82:30 - let me just stop this
82:34 - and fix it by passing the first vertex
82:38 - one more time at the end so what I will
82:41 - do is I will create here a new array
82:44 - containing all the elements of vertices
82:47 - and then one more time
82:50 - vertices of zero the first vertex vertex
82:54 - is just a funny word for a point
82:57 - now if we run this again
83:01 - and check what happens in the images
83:06 - it's closed as we expect but I would
83:10 - like to see also the whole
83:12 - and just to make sure that whatever
83:15 - happens here is correct so let me close
83:17 - this one more time and in the geometry
83:21 - I'm going to go
83:27 - here where the hole is also calculated
83:31 - and I'm going to add it
83:34 - here
83:38 - let's save this file and back in data
83:41 - set generator
83:42 - I'm going to also destructure here the
83:46 - wall that we are passing now and I'm
83:49 - going to copy this one more time with
83:53 - hole here and maybe let's put this color
83:56 - to Blue
83:58 - let's try one more time
84:07 - now we can really debug what happens
84:09 - here and make sure that the bounding
84:12 - boxes and the convex holes are what we
84:15 - expect
84:16 - really
84:18 - while this is processing let's go and
84:23 - Implement our new feature
84:26 - using Elias code so in feature functions
84:30 - I'm going to import here
84:33 - at the top
84:37 - geometry if it's undefined I'm doing
84:40 - this check because we're going to need
84:41 - to
84:43 - also use this file on the web
84:48 - and geometry might be there already
84:51 - and now the feature name is going to be
84:57 - elongation
85:04 - and what we do to calculate this
85:06 - elongation
85:08 - is take out the points by flattening the
85:11 - paths
85:13 - and then we just get the width and
85:15 - height from Helios function here
85:22 - as before
85:24 - and we return here
85:27 - the maximum between the width and height
85:30 - divided by
85:32 - the minimum
85:34 - of the width and height
85:36 - and now in practice it could be possible
85:40 - that the width or height is zero from
85:45 - the drawings like if somebody draws a
85:47 - perfectly horizontal line then the
85:49 - vertical coordinate is the same for all
85:53 - the points and then height is going to
85:55 - be zero and then this is going to be
85:57 - zero so typically what you can do in
86:01 - this case is wrap these
86:04 - like so
86:06 - and add the plus one to each of them
86:09 - because it kind of makes sense
86:14 - if you think about
86:15 - pixels that it does have some kind of
86:20 - height even if it's zero from this
86:24 - Vector point of view and it's just one
86:26 - way that we avoid this problem I'm not
86:30 - really sure if it happens here but I was
86:32 - thinking about this division by zero so
86:36 - anyway
86:37 - this new function now we can add right
86:40 - here
86:41 - elongation
86:43 - and get the elongation
86:47 - and for it to work we need to adapt our
86:51 - distance function in utils
86:55 - right here to use the third dimension as
86:59 - well
87:00 - so we could do that for example like
87:04 - this
87:07 - by just including here the difference on
87:11 - this third dimension denoted by this 2
87:15 - here so 0 1 2 means one two three but
87:20 - it's
87:21 - nicer to write this in a more General
87:23 - way so we don't have to do this again
87:25 - and again every time we add a new
87:27 - dimension so let's remove this and
87:31 - initialize the variable called squared
87:34 - distance
87:37 - with zero and loop through all of the
87:40 - dimensions of the first point one by one
87:44 - and add to this squared distance
87:47 - the difference on that Dimension squared
87:50 - and here we just return the square root
87:53 - of that squared distance and now we
87:55 - don't have to bother with this function
87:57 - anymore so let's try to extract these
88:00 - new features now I'm going to go here
88:02 - and type node feature extractor Js
88:12 - and now let's run our evaluation
88:21 - and look at that we went above the 50
88:24 - mark
88:25 - quite a significant Improvement here
88:30 - let's see the results on the web as well
88:33 - so I'm going to go here and make a few
88:37 - changes in viewer HTML we need to import
88:42 - also geometry now and I'm going to do it
88:47 - here under utils I think it's a good
88:50 - place
88:52 - and let's save the file
88:57 - and refresh the page
89:01 - and something is not right because this
89:06 - input shouldn't be there
89:09 - and if I open the cons so
89:13 - I see there are some errors in Geometry
89:16 - there and I'm quite sure they are
89:18 - because this input is empty and it's
89:20 - giving a list of
89:23 - zero points basically
89:25 - and let's have a quick look here
89:29 - insides of geometry.js
89:38 - there are sometimes used points from the
89:41 - first index second third index at least
89:46 - so we would need to have at least three
89:50 - points for this code to work properly
89:54 - and we can do that in multiple ways
89:58 - maybe we could go here and viewer HTML
90:01 - at the bottom and only update what's on
90:05 - the sketch pad only process that
90:09 - for example his
90:12 - there are paths and if they have more
90:16 - than three points
90:18 - so here I'm writing the opposite and I'm
90:21 - saying return if it's not like that so
90:25 - this would work here
90:29 - there's no more error but the problem is
90:31 - if we do draw something here
90:34 - and then maybe
90:38 - revert everything it doesn't process
90:42 - anymore this empty page so I would
90:46 - actually like to return 0 with and zero
90:49 - height if not enough points so I don't
90:55 - keep this update here instead I cut it
91:00 - and I go in Geometry Js
91:05 - in the function that calculates here
91:10 - the minimum bounding box and I say
91:15 - paste but only focusing on the points
91:20 - and
91:21 - if they are too few I will return now
91:30 - a width of zero height of zero and let's
91:34 - return the vertices on the whole and I'm
91:37 - just going to return all the points
91:40 - so points points
91:43 - like so
91:45 - now this should work again without an
91:49 - error here
91:52 - right
91:54 - and if I draw something on the input
91:59 - and I undo it also changes so nothing is
92:04 - a car in this model's mind now this is
92:07 - much better accuracy and also if we look
92:10 - at the column here and the row here the
92:14 - pencils are doing really really good now
92:17 - so we got what we wanted
92:20 - and let's toggle this output to see the
92:23 - chart as well
92:25 - and this is quite confusing now because
92:29 - we are having three dimensions so we
92:32 - should plot that elongation also on the
92:35 - third dimension
92:36 - but it's Overkill I think and soon we're
92:40 - gonna have even more Dimensions than
92:41 - that and what do we do then also this
92:44 - decision boundary plot it's not proper
92:47 - at the moment uh it should be a decision
92:50 - boundary
92:51 - Cube not a rectangle like this one but
92:56 - we could start slicing this Cube somehow
93:00 - if we really want let me first actually
93:03 - remove these
93:04 - samples from here because they are
93:07 - confusing for what I want to show you
93:10 - next
93:11 - and I do that here in the chart options
93:16 - by typing
93:18 - hide samples set to true and then for
93:22 - that decision boundary plot
93:26 - in run evaluation here I'm going to go
93:29 - at the bottom and here it's doing the
93:33 - prediction with just two Dimensions so
93:35 - we basically get the same as only with
93:38 - the width and height here
93:40 - because the distance function is
93:42 - implemented based on how many dimensions
93:44 - this point has
93:46 - so to have a three-dimensional plot we
93:51 - need to add another
93:54 - value here and it would actually require
93:57 - another for Loop and passing here
94:01 - another dimension but this will just be
94:04 - a set of images on top of each other so
94:07 - we have to slice this Cube somehow and
94:10 - now I'm slicing it at the minimum
94:15 - elongation and I could slice it in other
94:18 - parts as well if I want but let's just
94:20 - see what we get here
94:22 - and I'm going to run this evaluation
94:25 - again
94:29 - and refresh
94:31 - toggle the output
94:34 - and you can see the pencils are actually
94:37 - gone but that can't be true because
94:40 - pencils are being classified correctly
94:44 - and they are even classified the best
94:47 - according to our confusion Matrix here
94:50 - what happens is that the slice that we
94:52 - are doing in this cube with the minimum
94:54 - elongation doesn't contain them we would
94:57 - have to slice further away maybe with
95:00 - the maximum elongation since they are
95:02 - the most elongated shapes there
95:06 - so let's try that put here one instead
95:10 - regenerate the decision boundary plot
95:17 - refresh the page toggle the output
95:21 - and everything seems to be pencils so if
95:25 - it's the maximum elongation our model
95:27 - thinks that everything should be a
95:29 - pencil here but there must be a place
95:31 - where it kind of contains pencils and
95:35 - something else so let's try cutting this
95:38 - Cube maybe in the middle
95:41 - regenerate the decision boundary plot
95:48 - refresh the page
95:50 - toggle the output
95:52 - and seems like even here everything is a
95:55 - pencil
95:56 - okay let's go even smaller maybe 0.2
96:07 - refresh the page
96:09 - toggle the output
96:11 - and now we see something like that
96:13 - basically the pencils are creeping out
96:16 - somehow and being replaced with
96:18 - something else as we Traverse this this
96:21 - cube in the z-axis
96:23 - but let's inspect the samples a bit too
96:27 - I'm going to go to viewer HTML and
96:31 - remove this height samples
96:34 - let's comment it for now
96:38 - and here
96:41 - let's still focus on the pencils but
96:44 - only those pencils that are
96:48 - incorrectly
96:49 - predicted
96:51 - let's refresh
96:53 - toggle the output
96:56 - and here are the incorrectly predicted
96:58 - pencils but this decision boundary plot
97:02 - now is kind of useless because we don't
97:06 - really understand it anymore with the
97:10 - third dimension there like these are all
97:14 - wrongly classified pencils but some of
97:18 - them appear to be over this magenta
97:20 - patch here because they might be in
97:25 - somewhere close to low elongation so if
97:30 - I would click something here you can see
97:32 - this pencil is very fat so to speak so
97:36 - it's in that
97:37 - Zone where there was no magenta at all
97:41 - maybe and that's why it's categorized as
97:44 - a house and not a pencil
97:49 - this seems to be a guitar it's also a
97:52 - little bit thicker and all of these
97:54 - bounding boxes and
97:58 - convex Halls look great I think
98:06 - really good job Ilia
98:12 - what happens here this looks interesting
98:17 - this looks like a problem but what I
98:20 - think is here is that there is actually
98:22 - a small point there that somebody drew
98:25 - and in our system if somebody makes a
98:28 - point it's not going to be drawn because
98:32 - there is no thickness basically
98:36 - but it might be there let's inspect a
98:39 - little bit so it's this five zero seven
98:43 - eight image
98:47 - I'm going to go in our data data set
98:52 - Json this time
98:55 - and five zero seven eight
99:04 - is here
99:06 - let me format this
99:08 - and I actually see here the first path
99:11 - even
99:13 - it's exactly the same point repeated
99:16 - twice so I guess this can happen too
99:18 - basically there's one path there that is
99:22 - small and it's not rendered by our
99:24 - software but the calculations pick it up
99:28 - so it's not really a problem with ilia's
99:31 - implementation maybe it's a problem with
99:33 - mine with my visualization but I don't
99:36 - want to bother with with things like
99:38 - this so let's forget it's an issue
99:42 - let's focus on clocks next most clocks
99:45 - are round so the next feature we'll
99:48 - Implement is a kind of roundness
99:50 - measurement I've already done something
99:52 - like this in my AR portal drawing game
99:55 - tutorial here on YouTube so you may know
99:58 - it already but this time we combine it
100:00 - with the convex hole from before
100:02 - to measure the roundness we first
100:04 - calculate the length and the area of
100:06 - this shape and compare it to the area of
100:08 - a circle with the same length if you
100:11 - want to learn why the circle has the
100:13 - largest area I have a video on that
100:16 - it's quite intuitive though so I don't
100:18 - think you really have to watch it now
100:21 - get ready for another round
100:24 - to calculate the roundness I'm going to
100:26 - add some functions here inside of the
100:29 - geometry file
100:31 - let's begin with the function called
100:35 - length of a given polygon now this
100:39 - polygon is just going to be our paths
100:42 - but I write it here as such because I
100:45 - think it gives the idea that the
100:46 - function will consider the first point
100:49 - also at the end to Loop
100:52 - and let's implement it
100:55 - unlike so initialize the length with
100:58 - zero
100:59 - and then Loop through the points
101:04 - like so
101:07 - and get a value for the next index so
101:12 - next index
101:15 - is going to be I plus 1 but when we are
101:18 - going to have I is equal to polygon
101:21 - length minus 1 at the end adding 1 to
101:25 - that will give us an index that is not
101:27 - good and we should Loop that around to
101:30 - be zero again so I'm going to use the
101:33 - module operator
101:34 - like this
101:36 - and add to the length the distance
101:40 - between the polygon of I and the polygon
101:43 - of next I like so
101:46 - let's return now this length and because
101:50 - we're using utils here I need to add it
101:54 - here at the top to include it
101:58 - if it's not existing and then
102:06 - include it like that
102:09 - and we are adapting now this file from
102:12 - Ilia here so let me just write a quick
102:14 - comment here adapt it from the original
102:18 - author now the next thing we'll need
102:20 - here is to calculate the area of a
102:25 - polygon and we'll do that by breaking it
102:27 - into triangles
102:29 - according to
102:31 - some fixed point and calculating the
102:35 - area of each triangle and adding them
102:37 - together
102:38 - so let's say our fixed point is going to
102:41 - be
102:43 - a and that will be polygon of zero and
102:47 - now we Lu
102:49 - from I is equal to 1
102:52 - and less than polygon length minus 1
102:56 - this time because we're also going to
102:58 - use this next index here but we don't
103:00 - want to Loop anymore
103:02 - and here let's define B as the polygon
103:08 - of I and C as the polygon
103:12 - of I Plus 1. so a is going to be fixed
103:16 - but b c is going to change from those
103:18 - next to I and then B is going to be the
103:22 - previous C and we get the new C and so
103:25 - on until we add up all the triangle
103:28 - areas
103:29 - and for the triangle area I'm going to
103:32 - write the separate function
103:34 - here called triangle area between these
103:38 - three points
103:39 - and let's return the area here
103:43 - to get the area of a triangle we're
103:46 - going to first calculate its side length
103:48 - and then use Heron's formula it's one of
103:51 - my favorite formulas I learned in school
103:53 - now I won't prove it here but you can
103:56 - take it as a homework and prove it
103:58 - yourself maybe using the Pythagorean
104:00 - theorem
104:01 - anyway this way of measuring the area of
104:04 - a polygon is not the only way in fact in
104:07 - the portal drawing game I mentioned
104:09 - earlier I use the shoelace formula and
104:11 - that one works with concave polygons as
104:13 - well
104:14 - check it out if interested
104:24 - so the formula works by calculating the
104:29 - lengths of the triangles so typically we
104:33 - refer to as the side length of a of B
104:36 - and C
104:37 - and we do the same thing here for
104:42 - B and that will be
104:46 - A and C and we get here C and that will
104:51 - be
104:53 - A and B so these are the side lengths
104:56 - that we just calculate as the distance
104:58 - between those
105:00 - and then we Define p as the semi
105:05 - parameter
105:06 - or half parameter the half length of the
105:10 - triangle so this is going to be a plus b
105:14 - plus C divided by two and this is
105:18 - Heron's formula so the area will be the
105:22 - square root of the half parameter times
105:28 - P minus a times P minus B times P minus
105:34 - C we just need to return it here
105:37 - and now we can use these two functions
105:40 - the area of the polygon and the length
105:43 - of the polygon to implement our
105:45 - roundness function
105:48 - the roundness function
105:51 - is going to take the polygon as a
105:53 - parameter and first thing we do is get
105:56 - its length
105:58 - hand area
106:02 - using the but functions we built
106:06 - previously
106:08 - and now let's calculate the
106:11 - radius of the maximum Circle that could
106:15 - be built using this length
106:18 - so that would be the length divided by
106:24 - 2 pi like this
106:28 - and the area of such a circle would be
106:32 - pi times the radius squared so the
106:36 - roundness is going to be
106:39 - the area divided by this
106:43 - circle area
106:44 - and here we could return the roundness
106:48 - but in case this circle area ends up
106:51 - being 0 then this roundness is going to
106:54 - be not a number so
106:57 - to be safe we are going to check here
107:00 - if it's not a number let's just return 0
107:03 - in that case otherwise we return this
107:06 - roundness value and that's it now let's
107:10 - debug if what we implemented works and
107:13 - I'm going to go here in data set
107:15 - generator where we were previously
107:18 - drawing these vertices and the whole to
107:22 - debug Elias code and let's include now
107:28 - our roundness calculation here
107:31 - so we can do that like this
107:36 - roundness is equal to
107:39 - calling geometry dot roundness on the
107:44 - whole this time because that's what we
107:46 - want to measure the roundness of
107:51 - and now I won't need these vertices
107:54 - anymore I will just focus on the hole
107:57 - here but I will give it a different
107:59 - color the color will range between blue
108:03 - and red if it's blue it means a low
108:06 - roughness and if it's red it means a
108:09 - high roundness
108:10 - so let me go here and say
108:14 - R for red is going to be the floor of
108:19 - this roundness
108:23 - multiplied by
108:25 - 255 because that's the range of the
108:28 - colors
108:29 - then green is going to be zero we won't
108:33 - care about that and for blue I'm just
108:36 - going to copy this and invert it here so
108:42 - 1 minus this roundness multiplied by
108:46 - that
108:48 - and this is B here with this we create a
108:52 - new color
108:55 - and I'm using here these template
108:57 - literals
109:00 - and replacing the color here when
109:04 - drawing the hole
109:05 - now let's save this and open the
109:09 - terminal
109:13 - in the regenerate the data
109:16 - and let's check it out as it's doing it
109:19 - here in the data data sets image
109:25 - this looks
109:27 - reddish
109:31 - okay
109:33 - okay much red here in this house
109:42 - pencil is quite blue here
109:45 - and the clock is red as expected let's
109:50 - go here and make this line thicker
109:55 - I'm going to add here
109:58 - 10 pixels in width and I will modify
110:02 - this draw path function
110:09 - from here
110:14 - to accept also
110:17 - the width let's set it by default to
110:20 - three and replace the three that was
110:23 - hard coded here previously and let's
110:26 - write the function for extracting this
110:28 - roundness feature as well I'm going to
110:31 - go in feature functions and type it here
110:39 - it will be get aroundness of the paths
110:45 - and let me copy here this code from the
110:50 - elongation because we're going to call
110:53 - ilia's minimum bounding box function and
110:56 - instead of width and height we are going
110:58 - to extract the whole now and then return
111:02 - here
111:03 - the roundness of that hole like so let's
111:08 - add this also to our feature list here
111:13 - and roundness
111:15 - get around this
111:17 - and regenerate the data
111:29 - extract the features
111:37 - and run our evaluation
111:44 - and look at that we're getting above 60
111:47 - now
111:49 - but this decision boundary won't be
111:52 - proper there because it's not yet
111:55 - slicing the hyper Cube four-dimensional
111:59 - Cube now just yet
112:02 - we'll get to that but first let's just
112:05 - refresh the page
112:07 - and our colors here are not proper
112:12 - because they are inverted by Ninja
112:16 - coders new style here let me just go
112:20 - back here
112:21 - in data set generator and invert these
112:26 - as well so 255 minus that 255 minus that
112:31 - 255. minus that
112:34 - and re-run everything
112:46 - and the features
112:54 - and run the evaluation
113:04 - forgot that hypercube again but we'll
113:07 - get to that
113:11 - Okay so
113:13 - refresh and now it's how I want it red
113:17 - for these and you can see
113:20 - a lot of clocks are red
113:23 - but there is a lot of red everywhere
113:25 - because things tend to have a high
113:29 - roundness value
113:32 - if you look at the convex hole here in
113:34 - general if you would like to
113:36 - differentiate better between really
113:39 - round things like these circles here
113:42 - that are making the clocks
113:44 - you could
113:45 - use a non-linear function here for the
113:49 - roundness like maybe Square this value
113:52 - or even a higher power will make the
113:55 - difference even more significant maybe
113:57 - like
113:58 - fifth power here
114:16 - you'll notice that generating these
114:19 - decision boundary plots is becoming
114:21 - slower and slower because the
114:23 - classification is becoming slower and
114:25 - slower because we're adding more and
114:27 - more Dimensions so that distance
114:29 - function has to do more work for all of
114:32 - the neighbors repeated many many times
114:34 - let's refresh
114:38 - and now these differences are more
114:40 - striking the circles here do appear more
114:44 - reddish than anything else
114:47 - but our decision boundary plot still
114:51 - looks the same as before here and that's
114:54 - because in our run evaluation here we
114:58 - are still sending three dimensions to it
115:01 - when we now have four and we could in
115:05 - principle add one more Point here but to
115:07 - make this function General enough so
115:10 - that we don't have to do this every time
115:12 - we can just remove this and use a while
115:16 - loop until the length of this point is
115:20 - going to be the number of Dimensions
115:24 - let's just add the value here so maybe
115:30 - point
115:32 - push and I'm just going to slice at the
115:35 - lowest value in the elongation and
115:39 - roundness dimensions and get something
115:43 - but this is not really going to be
115:46 - something useful when we have so many
115:48 - dimensions so this decision boundary
115:51 - plot is only useful for two Dimensions
115:53 - really
115:54 - let's see what we get we just have to
115:57 - run the evaluation now so that we get a
116:01 - different decision boundary plot
116:04 - and refresh the page
116:07 - toggle the outputs
116:10 - and that's
116:12 - how it looks like apparently not
116:15 - interesting really let's go back to the
116:18 - confusion Matrix here and notice how
116:22 - white this section is becoming here and
116:24 - how good our system became at
116:28 - recognizing
116:29 - pencils and clocks which is what we were
116:33 - trying to do looking at elongated shapes
116:36 - and looking at Round shapes started
116:39 - working now what doesn't work is the car
116:43 - being confused with Fish And The Fish
116:45 - being confused with the car we have this
116:48 - small square here and actually cars are
116:51 - also confused with bicycles and fish the
116:53 - same because these tend to have the same
116:56 - aspect ratio and their
117:00 - convex holes tend to look similar as
117:04 - well the guitar as well actually gets
117:07 - confused with the car and the fish for
117:10 - similar reasons I think we just didn't
117:12 - try to extract features that would help
117:14 - distinguish these and we could like cars
117:19 - are much more blocky I think and fish
117:22 - are much more organic in shape maybe
117:25 - looking at this kind of a
117:28 - curviness how curvy the lines are it may
117:32 - help to recognize the fish and
117:35 - distinguish them from Cars also from
117:38 - bicycles
117:40 - the bicycles well they do have circles
117:45 - here so maybe using the roundness
117:47 - measure in some other way could help to
117:51 - recognize those
117:53 - maybe looking for corners
117:56 - when I look at houses they typically
117:59 - have some triangles there
118:01 - Corners many corners there is a problem
118:05 - when considering triangles and let me
118:08 - show you let's close this
118:10 - and start our input here
118:14 - if I'm going to draw a house I could
118:16 - draw it for example like this and now
118:20 - start making a rectangle here and a
118:24 - triangle here
118:26 - like so and these could be recognized
118:30 - relatively easy if you look at the data
118:33 - that we collected because there are
118:35 - three independent shapes so you could
118:36 - maybe recognize that one is a triangle
118:39 - one is a rectangle and there is a flat
118:42 - line here but what if you draw the house
118:45 - like this
118:47 - now the second shape will be just this
118:50 - kind of
118:52 - upside down U shape and then
118:57 - the roof I'm not going to draw a full
118:59 - triangle I'm just going to draw this
119:02 - upside down V shape to me both of them
119:05 - look pretty much the same but the data
119:09 - that we store is significantly different
119:11 - this has just two sides this has three
119:14 - this has three sides this has four and
119:18 - you can draw these in different ways but
119:21 - the problem is if we would like to
119:23 - extract things like triangles or
119:25 - rectangles or these kind of shapes
119:27 - looking at the vector data is not as
119:32 - easy as looking at the pixel date so
119:35 - we're gonna study how to access pixels
119:38 - next
119:39 - so far we've been working with the data
119:42 - in raw Vector form the coordinates of
119:44 - the points and the paths they create but
119:47 - that's not what we humans see when we
119:49 - look at the drawings we see the pixels
119:52 - and some features can be calculated more
119:55 - meaningful if using those like these
119:58 - drawings look the same but their Vector
120:00 - representation is very different and it
120:03 - would be quite strange if they would not
120:05 - be classified as the same thing wouldn't
120:07 - it
120:09 - if you've never worked with images you
120:11 - can watch this video where green Rado
120:13 - explains how to make an image recognizer
120:15 - that works with the camera
120:17 - I think it's a good watch especially now
120:19 - that you have a good understanding of
120:21 - machine learning already
120:23 - now I won't teach you any sophisticated
120:26 - image processing techniques but I want
120:28 - to set you up just in case you want to
120:30 - experiment more
120:31 - there are a bunch of things that can be
120:33 - tried out with this new approach
120:35 - self-study them ask me questions in the
120:38 - comments or on Discord and we'll try to
120:40 - figure things out
120:42 - let me show you how we can access the
120:45 - pixels from the canvas
120:47 - I'm going to do this in the console here
120:50 - and type
120:53 - sketchpad CTX getting the context of
120:57 - this sketch pad that we're drawing on
120:59 - and get image data
121:03 - from 0 0 which is the top left corner
121:06 - using the sketchpad canvas width and the
121:11 - sketch pad canvas height so I want to
121:15 - get all of this information
121:17 - and we press enter we get this which is
121:22 - containing some information about color
121:25 - space the width and height 400 by 400
121:28 - and this really really long data array
121:32 - here now this data array is going to be
121:36 - filled with the zeros pretty much
121:39 - because that's what is drawn on the
121:42 - canvas now
121:43 - everything is actually
121:45 - transparent black this stands for red
121:48 - green blue Alpha of the first pixel in
121:52 - the top left corner on the canvas
121:55 - and this is the pixel on the right of
121:58 - that so red green blue Alpha red green
122:01 - blue Alpha and so on if I'm gonna draw a
122:04 - line here on the canvas and run the same
122:09 - code here again
122:16 - you can see zeros here but at some point
122:24 - we start getting some values and these
122:27 - are the values from this line that I
122:29 - drew here and they only appear as Alpha
122:33 - values because the lines are black
122:36 - actually they are here inverted because
122:40 - of the styling but basically anything
122:43 - with an alpha is a pixel that is
122:46 - lighting up
122:47 - so that's what we want to extract from
122:51 - here really we don't care about colors
122:54 - we just want to know which pixels are
122:57 - visible and which not
122:58 - so if I'm gonna bring this code back
123:01 - here again we can filter this to take
123:04 - just the fourth item in the array every
123:08 - fourth item in the array using
123:11 - filter on the data and taking the value
123:15 - and the index
123:17 - so here we're gonna filter using this
123:20 - index if modulo 4 is equal to 3.
123:25 - and this gives us that just the alpha
123:29 - values and they are 160
123:32 - 000 so this is 400 times 400 a matrix
123:37 - written in linear form pretty much
123:39 - so let me close this console and write
123:42 - the code to extract these pixels
123:46 - in our feature functions I'm going to go
123:49 - in common feature functions and here
123:53 - below the roundness feature I'm going to
123:56 - implement a function to get these pixels
123:59 - it won't be a single number as an output
124:02 - it will be all the pixels it's not a
124:05 - feature yet but eventually we'll use it
124:09 - as a feature as well you'll see and I'm
124:12 - gonna write it here in the feature
124:14 - functions for now
124:15 - so
124:17 - let's right here get pixels
124:21 - and given the paths Now by default we
124:25 - used this 400 by 400 pixel canvas all
124:29 - the time I'm gonna set the size here
124:31 - equal to 400 but we can set the
124:34 - parameter here to get the pixels from a
124:37 - smaller canvas if necessary let's first
124:39 - Define our canvas and I'm using let here
124:43 - and setting it to null because now I'm
124:45 - going to do a trick I'm going to try
124:50 - to initialize the canvas
124:53 - for the web
124:55 - by
124:57 - asking the document to create the canvas
124:59 - element like this
125:01 - and then setting its width
125:04 - the size and its height to the size like
125:08 - so
125:09 - but if this fails it probably means that
125:13 - we are doing this in a node and I'm
125:16 - going to catch an error I'm not going to
125:19 - worry too much about what the error is
125:21 - because in our environment this can only
125:24 - be the reason why it doesn't work that
125:26 - we're trying it on node so this code
125:28 - here is for node
125:30 - and here we have to require the create
125:34 - canvas function
125:36 - from node node modules
125:41 - canvas where the canvas was installed
125:44 - and then our canvas can be
125:47 - initialized with create canvas size and
125:51 - size like this
125:53 - now the code should work both on web and
125:56 - inside of node
125:58 - and we can now get a reference to the
126:02 - canvas context
126:05 - like so
126:07 - and draw these given paths here
126:11 - on this new canvas
126:16 - we then get the image data
126:25 - from the whole canvas
126:27 - and take out just the alpha values that
126:31 - we're interested in so I'm just going to
126:33 - return directly image data dot data dot
126:37 - filter value index and then
126:41 - index module for when it's equal to
126:44 - three so every fourth element will be
126:46 - returned now we're drawing here and we
126:50 - haven't included that file here yet so
126:54 - I'm just going to do that real quick
126:57 - troll draw
127:00 - like so
127:02 - and now let's test our code in the data
127:06 - set generator again I'm going to go here
127:09 - in node data set generator and we need
127:13 - to include the feature functions here
127:17 - so feature functions
127:22 - and feature functions and let's go down
127:26 - where we are generating the image and we
127:29 - don't need this fancy stuff anymore
127:31 - because this new visualization will be
127:35 - just me writing some text on the images
127:37 - how many pixels are visible
127:42 - so let's first access these pixels
127:48 - using our newly created function and
127:52 - let's store the number of pixels in a
127:56 - variable which we're gonna call
127:58 - complexity because I'm eventually going
128:01 - to make a feature from this and
128:04 - complexity just means the more pixels
128:07 - the more complex it is
128:09 - so let's say complexity is and we count
128:14 - now
128:15 - how many
128:18 - values are non-zero these are just the
128:22 - alpha values remember that
128:24 - so if they are visible they will be
128:26 - counted
128:27 - and then let's just draw some text
128:32 - this complexity value and let's use blue
128:35 - color
128:36 - now this draw text doesn't exist so
128:40 - let's save this file and go here to draw
128:43 - JS we can draw paths but we can't draw
128:47 - text just yet so we need to implement a
128:50 - function for this given the context and
128:54 - the text and the color we set it to Blue
128:58 - but let's give this one a default color
129:01 - as well
129:02 - and now the location by default will be
129:05 - 0 0 where we want the text to be in the
129:08 - top left corner and let's set a
129:11 - relatively large size because we are
129:14 - just printing there those small
129:15 - thumbnails in the viewer the text should
129:17 - be quite big
129:19 - now this function is going to
129:24 - first set the font and I want it bold
129:29 - let's concatenate here the size and I
129:33 - will use Courier font
129:36 - because I want the text to be in the
129:38 - screen I want the bass line to be on the
129:40 - top because if zero zero chord then it
129:43 - is used otherwise the text would just be
129:45 - over that then we wouldn't see it
129:48 - and I'm gonna put here text Baseline
129:51 - stop
129:53 - and let's set the fill style to the
129:56 - color
129:57 - and
129:58 - fill the text
130:00 - at this location I'm just spreading the
130:03 - array into the two X and Y components
130:06 - and that's it let's save this and open
130:09 - the terminal
130:10 - make sure we are in the node folder
130:14 - and let's
130:17 - generate our data set once again and
130:21 - while it's doing that we can quickly
130:23 - check what happens here in data data set
130:26 - image
130:29 - and this is a number that probably works
130:34 - meaning it's the number of visible
130:37 - pixels here
130:40 - maybe it's okay we'll see later when we
130:42 - can visualize them in the app but while
130:44 - it's doing this I'm actually going to
130:48 - implement the complexity function that I
130:51 - mentioned so let's go to our feature
130:54 - functions here below the new function we
130:58 - just created
130:59 - and the complexity function is going to
131:03 - be just get complexity from the paths
131:07 - and it's going to return this one number
131:11 - so first thing that happens is we
131:13 - extract these pixels
131:19 - and now we're going to count how many of
131:23 - them
131:25 - are visible
131:28 - like so and we can add this new
131:32 - feature here
131:37 - and get complexity like so now we're
131:41 - dealing with this five dimensional
131:43 - feature vector and I don't really know
131:46 - how good this feature is going to be I
131:49 - don't really have High Hopes I just want
131:51 - to teach you how to work with pixels and
131:54 - then it's up to you
131:56 - you can look online find some help how
131:59 - to do image processing if you're curious
132:01 - but I won't get into that
132:06 - now this is done let's also
132:12 - extract the features
132:15 - and this is probably going to take some
132:18 - time now because doing this pixel
132:20 - manipulation is time consuming each
132:24 - image is 400 times 400 so a lot of
132:28 - calculations let's add here also this
132:31 - kind of progress indicator
132:33 - so I'm going to go to
132:36 - feature extractor
132:38 - and
132:39 - this for Loop here where we are looping
132:43 - through the samples let's rewrite it
132:45 - using a classical for Loop
132:49 - looping through all the samples like
132:53 - that and let's here initialize the
132:56 - sample list samples of I
132:58 - and at the bottom here let's print the
133:01 - progress using our utility function
133:06 - high and samples length
133:09 - minus one for a hundred percent
133:12 - now next time we run this code we will
133:15 - know how long it takes at the moment I
133:17 - have no idea so
133:19 - I just have to be patient
133:22 - band it's done let's now run the
133:25 - evaluation
133:31 - there is some improvement it jumped to
133:35 - 66.13 here
133:38 - and now this decision boundary plot is
133:41 - going to use all of the features because
133:45 - we implemented in a general way last
133:47 - time but I don't really care about this
133:49 - decision boundary plot anymore it's not
133:52 - very usable as it is when more than two
133:55 - dimensions
133:56 - so we're done let's refresh the page
133:59 - and this is what we get we see now the
134:02 - numbers here
134:04 - and I think they're proper
134:07 - this is a very small value here 1000
134:10 - something when most of them of several
134:13 - thousand and you can see just a few
134:15 - pixels showing up for this small pencil
134:18 - I think that this is correct but
134:20 - thinking about it it's kind of unfair to
134:23 - say that this is less complex than this
134:28 - because they kinda look the same if we
134:32 - talk about the feature meaning
134:33 - complexity maybe we should scale these
134:37 - items so they fill the whole canvas and
134:41 - then count how many pixels are lighting
134:43 - up
134:44 - let's try to do that I'm gonna teach you
134:46 - a little bit of image processing anyway
134:48 - so let's just scale these and stretch
134:52 - them to fill the whole canvas and see if
134:55 - this feature improves or not but I won't
134:58 - insist more than that
135:02 - in feature functions
135:04 - where we extract our pixels here I'm
135:08 - going to pass another parameter to the
135:11 - function saying if we want to expand or
135:15 - not so that the drawn image fills the
135:18 - entire canvas
135:19 - and if it's set to True which will be
135:22 - the case by default then we go here
135:26 - before drawing the paths and rescale
135:30 - these paths somehow
135:33 - we check if we need to expand
135:35 - and if we do I'm going to take the
135:38 - bounds first the minimum maximum on the
135:42 - X and Y so let's take out the points by
135:47 - flattening the paths
135:49 - and these bounds
135:52 - will be an object
135:55 - with left equal to the minimum
135:59 - points
136:02 - only looking at this x chord and it's
136:06 - the first chord in it here
136:08 - so I'm going to copy this like so for
136:11 - the right
136:14 - with the maximum here
136:17 - and let's copy both of these for the top
136:23 - and the Bottom now these will be
136:27 - one here
136:30 - because we're using the second dimension
136:33 - we are now going to remap these points
136:36 - and generate some new paths with
136:39 - remapped points so let's write here
136:44 - New Paths and this is going to be an
136:47 - empty array
136:48 - and we're going to Loop through the
136:51 - paths
136:52 - pass by path
136:54 - and now we're gonna generate new points
136:57 - from the path's current points so these
137:00 - will be
137:01 - in this variable and we'll use the map
137:05 - function where we remap each point p
137:09 - to be a new two-dimensional array
137:13 - the first will be
137:16 - remapping using inverse slurp
137:19 - between left and right
137:21 - using p of 0 and this is going to give
137:25 - us a value between 0 and 1 depending how
137:27 - far from left to right we are so we have
137:30 - to scale this also by the size of our
137:33 - canvas
137:35 - now I'm going to copy this again here
137:38 - and this will be between
137:42 - top and bottom
137:46 - using the First Dimension here now we
137:49 - need to push these new points into our
137:52 - new paths every time we create them
138:00 - and finally we can draw here the New
138:05 - Paths on the canvas
138:07 - so New Paths like so
138:11 - and this will go in the else Clause so
138:14 - here we have else
138:19 - we do that because in this case we don't
138:22 - want to expand anything
138:24 - now if we open our terminal
138:26 - and regenerate
138:31 - our data
138:34 - if we look here we will start to see
138:37 - that
138:39 - the values are different than before but
138:42 - I would also like to visualize what we
138:44 - did exactly so while it's running I'm
138:47 - going to redo the visualization part in
138:50 - this data set generator here and I'm
138:53 - going to show the new image that we get
138:56 - after expanding them
138:59 - so here after we have our pixels I'm
139:03 - going to figure out the size they are
139:08 - going to be a square canvas always so I
139:11 - just take the square root of these
139:13 - pixels
139:14 - length
139:16 - and then let's get the image data that
139:19 - we have on the canvas at the moment I
139:22 - just need the data structure essentially
139:26 - and
139:28 - I'm going to Loop
139:30 - through these pixels one by one and I'm
139:34 - going to write on top of this image data
139:37 - the values that we currently have
139:40 - so to do that I'm going to consider just
139:44 - this Alpha value others will be 0 for
139:48 - red green and blue so starting at the I
139:54 - times for index because they come in
139:58 - group of four I'm going to set the image
140:00 - data data at the start index to zero so
140:05 - this is for red now and this has to be
140:08 - copied
140:10 - three more times here and now we're
140:12 - going to set
140:14 - the green
140:16 - and the blue
140:18 - and the alpha component
140:21 - this is not zero this will be the alpha
140:24 - that we calculated previously
140:28 - and now we put this new image data on
140:32 - the
140:33 - context so put image data image data 0
140:39 - 0.
140:41 - and I don't think I need this complexity
140:44 - value appearing anywhere here when
140:46 - debugging I know the number of pixels is
140:49 - calculated correctly already
140:53 - let's regenerate the data
140:57 - okay this is done and now let's extract
141:01 - the features
141:05 - we can see how this progress indicator
141:08 - works now
141:09 - much slower when we're dealing with
141:11 - these pixel values
141:16 - okay and now let's run the evaluation
141:24 - and done a little bit improvement from
141:27 - previously but not much and this is what
141:31 - we get the images are now stretching
141:34 - all over the canvas there
141:38 - and
141:39 - I kind of like this view because now we
141:42 - can see the drawings much better even
141:44 - for those who made small images they are
141:47 - stretched here like that but remember
141:49 - that all we do with these stretched
141:52 - images here are counting the pixels as a
141:56 - kind of complexity measure all the other
141:58 - calculations still happen the same on
142:01 - the raw Point data one thing I am really
142:04 - curious to see is
142:07 - arminio's house
142:11 - aha
142:14 - it was like that
142:17 - for some reason the app registered some
142:20 - point very very far away and that's why
142:24 - its width is so huge
142:31 - now let's try drawing here
142:33 - and I do sense a little bit
142:38 - slower reaction time here because every
142:41 - time we make a new update to the drawing
142:43 - it's going to take the features
142:45 - including this pixel feature which is
142:48 - slower to calculate and
142:52 - um
142:53 - basically it takes a little bit longer
142:55 - time here I would say it's still real
142:58 - time
142:59 - we move on to neural networks next and I
143:02 - don't have the patience to teach you
143:03 - what they are but don't worry I know
143:06 - just a person to do it take it away red
143:09 - Rado
143:11 - neural networks are Computing systems
143:13 - inspired by the biological neural
143:15 - networks in our brain
143:18 - these are some neurons
143:20 - these branch-like structures receive the
143:23 - signals
143:24 - when stimulated enough a neuron will
143:27 - fire a signal through its Axon
143:30 - so a single neuron does something really
143:32 - simple and intelligence only comes when
143:35 - they work as a team
143:37 - you see your brain has 86 billion
143:40 - neurons
143:41 - you also have quite many of them in your
143:44 - spinal cord and sensory organs like in
143:47 - your eyes and ears
143:48 - these sensors send signal to some
143:51 - neurons that pass it to the brain
143:54 - there the processing happens like a
143:56 - chain reaction where some neurons fire
143:58 - some don't eventually signals arriving
144:01 - to motor neurons that pass them through
144:03 - your spinal cord and make some muscles
144:06 - contract in very specific ways
144:09 - hey
144:10 - A lot happened in just a split second
144:13 - let me try to slow this down and explain
144:16 - it to you
144:18 - pay attention
144:22 - sensors inside the ear pick up
144:24 - compression waves from the air and send
144:26 - signals to the brain which figures out
144:28 - the direction based on different
144:30 - intensities
144:31 - signals then travel to neck muscles tell
144:34 - them to contract and turn the head in
144:36 - that direction
144:39 - the eye catches a glimpse of what's
144:40 - happening and new signals travel to the
144:43 - brain
144:44 - peripheral vision is blurry but good
144:46 - enough information exists to detect some
144:48 - kind of object approaching and new
144:50 - signals travel to facial muscles to
144:52 - contract and protect the eyes from
144:54 - getting hurt eyes are really important
144:58 - at the same time the brain begins a kind
145:00 - of Defense protocol by sending signals
145:03 - throughout the body
145:04 - time passes and the image becomes more
145:06 - clear
145:07 - the brain does pattern matching and
145:10 - recognizes the object as a ball
145:12 - contextual and historical information
145:14 - will play an important role in what
145:16 - happens next let's stick to the first
145:18 - one
145:19 - the brain concludes there is no threat
145:22 - and uses knowledge about physics it
145:23 - learned during its lifetime to predict
145:25 - where the object is headed it then sends
145:28 - new signals to the muscles to contract
145:30 - in slightly different ways to catch the
145:31 - object instead of blocking it and the
145:34 - rest is history
145:35 - one history where the brain did the good
145:37 - thing and not much happens afterwards
145:39 - but sometimes this happens and the Brain
145:42 - learns it did something wrong and
145:44 - configures itself so the same thing
145:45 - doesn't happen again
145:47 - hopefully
145:49 - anyway I'm feeling really good about
145:51 - myself now that I know my brain can do
145:53 - something like that in an instant
145:55 - hope you do too
145:57 - our cars in your own network will do
145:59 - something like that
146:01 - neurons on the first layer will be
146:03 - connected to the sensors
146:05 - they will send signals forward a few
146:07 - times and the last layer will be
146:09 - connected to the car controls to make it
146:12 - actually do something
146:13 - spoiler alert will be working with
146:16 - relatively small networks here but
146:18 - that's okay because we actually don't
146:20 - need very large networks to solve this
146:22 - problem
146:23 - now that you have a basic idea take the
146:26 - code from the link in the description
146:27 - you'll need it to follow along but
146:30 - beware I will just briefly go through it
146:32 - and if you really want to understand it
146:34 - go watch these two videos first
146:36 - of course watching the whole
146:38 - self-priving car series is even better
146:41 - there is one thing about what redrado
146:44 - said in the beginning that bugs me
146:47 - so a single neuron does something really
146:50 - simple
146:52 - I got this comment from Mikhail and I
146:54 - should point out that biology is really
146:56 - not that simple we don't fully
146:59 - understand how brains work to this day
147:01 - but a simple model like that is all we
147:04 - need to build an artificial neural
147:06 - network I definitely don't want you to
147:08 - draw the wrong conclusion and that
147:10 - comment made me think twice about my
147:13 - wording
147:15 - I've added the two files here in common
147:19 - we have Network JS now
147:23 - and in web JS we also have viewer JS
147:28 - here
147:30 - viewer.js is pretty much the same as in
147:32 - that tutorial except that I made these
147:36 - output labels
147:38 - be images now there I used emojis but
147:42 - here I wanted to use the colored emojis
147:44 - we generated earlier
147:47 - and there are a few other small tweaks
147:50 - here and there but pretty much the same
147:52 - code as you've seen there and network JS
147:56 - here is the same code from the tutorial
147:59 - with this small difference here instead
148:03 - of how it was originally written
148:05 - because in the self-driving car case the
148:08 - car could press two keys at the same
148:11 - time like maybe accelerate and go to the
148:14 - left
148:15 - but here we need to decide which is
148:18 - going to be the winning class so we are
148:21 - leaving these outputs as the raw value
148:23 - there and we will select the class to be
148:27 - the maximum value that we get
148:29 - I've also added here this export so that
148:34 - it fits with our current structure
148:37 - but other than that it's exactly the
148:40 - same we have here the neural network
148:42 - made out of different levels
148:45 - the level having inputs outputs biases
148:48 - and the weights we have methods for
148:51 - randomizing these weights and biases
148:54 - because that's how we knew to optimize
148:56 - in that other course we just tried
148:58 - randomly different networks and hoped
149:02 - for the best we kept the best one all
149:05 - the time then the feed forward algorithm
149:07 - just implements that summation and
149:10 - outputs all the outputs
149:13 - to feed forward for the whole network
149:15 - just feed forwards each individual level
149:18 - like that and the only difference is
149:21 - really this line of code here but if
149:23 - you've watched that tutorial you know
149:25 - what it means now to use this new code
149:28 - we will build a new classifier next to
149:31 - our KNM classifier that we had here
149:34 - already and I'm going to copy this one
149:36 - for reference let's copy and paste it
149:41 - here with a new name
149:44 - I will rename this file
149:47 - mlp.js
149:50 - MLP stands for multi-layer perceptron
149:53 - and I think it's a good name here
149:56 - because neural network is kind of like
149:58 - an N from here so I want to keep this
150:02 - different and it will also match with
150:04 - what we do in Python later on
150:07 - now we will modify this code inside of
150:10 - mlp.js so here we have
150:14 - MLP now and let's export here also
150:18 - MLP like so
150:21 - and I'm going to empty here the
150:25 - Constructor we won't save the samples
150:27 - here this model doesn't store the
150:30 - samples it's what makes it much more
150:32 - efficient than this K nearest neighbor
150:36 - let's remove them from here as well and
150:38 - I'm going to empty also this predict
150:42 - method but I will keep the return so
150:44 - that we know what structure we need to
150:46 - return things in now the Constructor is
150:50 - going to take as parameters the neuron
150:53 - counts
150:54 - we need to know how many neurons we
150:58 - should use and also the classes the
151:01 - model needs to know what are the options
151:04 - let's save these here
151:07 - as attributes of this MLP
151:12 - so the classes
151:16 - and now let's initialize a neural
151:19 - network with the code from the file we
151:21 - just added and pass here the neuron
151:25 - counts
151:26 - so this we need to include here same as
151:31 - we include utils but here we include the
151:35 - neural network
151:37 - like so
151:39 - from the network
151:42 - JS file
151:44 - and the prediction here is what changes
151:48 - we just get the output
151:51 - from the neural networks feed forward
151:54 - algorithm when we pass this point the
151:58 - parameter from here
152:00 - and this network that is stored as the
152:04 - attribute of the class right here
152:06 - from these outputs we calculate the
152:09 - maximum so let me use math Max and
152:13 - spread here this output array and let's
152:16 - get the index of the element
152:20 - with the maximum
152:22 - like so
152:23 - and the label of that is going to be
152:27 - taken from classes at that index
152:31 - simple as that
152:33 - now for consistency with the KNN I will
152:37 - keep here an object with the attribute
152:39 - label but we don't have any nearest
152:42 - samples here it's gonna be null
152:45 - let's save this file and to evaluate
152:48 - this MLP model I'm going to copy here in
152:53 - node the Run evaluation so let's copy
152:57 - this
152:58 - paste it here and we will have two run
153:01 - evaluations one will be with
153:06 - knnn
153:08 - and the other one will be with
153:13 - MLP like so
153:16 - so let's modify this run evaluation MLP
153:20 - and the first thing we do here at the
153:23 - top is rename our classifier to MLP like
153:28 - that
153:29 - and then reading it here from MLP JS and
153:35 - here where we initialize our model
153:38 - we don't have K and N instead we have
153:42 - MLP and this MLP is going to take
153:48 - the two parameters first the neuron
153:50 - counts and we have five features at the
153:53 - moment so the first neuron count is
153:56 - going to be five
153:58 - and the second one is going to be let's
154:01 - just say directly the outputs and we
154:04 - have eight different outputs
154:08 - Car Fish House tree bicycle guitar
154:10 - pencil clock and the second parameter we
154:13 - pass are the classes which are
154:16 - here and these hard-coded values we
154:20 - don't have to keep them hard coded we
154:22 - can just replace here five with
154:27 - taking the training samples first item
154:30 - there the point and the length of that
154:33 - point and here is just the length of
154:36 - these classes so now we don't have to
154:38 - change these anymore they will work as
154:41 - expected so this is a neural network
154:44 - without a hidden layer it just connects
154:46 - the inputs to the outputs directly and
154:48 - we will experiment with hidden layers
154:50 - later here you could pass a hidden layer
154:53 - with maybe
154:54 - 10 neurons and another one with 10
154:57 - neurons and one with five and so on but
155:00 - at the moment we don't we just have this
155:03 - simple connection
155:04 - now let's copy this and replace every
155:08 - time we want to do a prediction
155:10 - n with MLP
155:15 - and here also
155:19 - that's it now let's run this new
155:22 - evaluation I'm going to start the
155:23 - terminal
155:24 - make sure we're in the node directory
155:29 - and node run evaluation
155:32 - MLP this time
155:36 - and it's really fast I didn't speed up
155:39 - the video this time
155:41 - it's also not very good this accuracy
155:45 - here
155:46 - is random chance if you've done homework
155:49 - 7 then you know this is random chance
155:52 - and Leo Caesar 3D mentioned this in a
155:57 - comment
155:58 - now because this is based on Randomness
156:01 - when we add the weights and biases every
156:04 - time we run this evaluation we will get
156:08 - a different value here
156:11 - sometimes we're more lucky than others
156:14 - because the networks that we are getting
156:17 - just happen by chance to be a good or a
156:21 - bad configuration
156:23 - in the self-driving car course we
156:26 - experimented with many different
156:28 - networks and choosing the best so let's
156:31 - try to do that here as well we will try
156:34 - to fit the network to the training data
156:38 - so let's open our MLP file here and
156:43 - Implement a new method here called fit
156:52 - the samples now we pass the samples to
156:55 - this because it's going to need them but
156:58 - it's not going to store them it's just
157:01 - going to update the weights and biases
157:04 - according to these samples somehow
157:06 - you'll see and we'll use the same
157:09 - strategy of Randomness and trial and
157:12 - error we will try for example
157:15 - one thousand times and keep the best
157:18 - network that came
157:21 - so
157:22 - let's consider the best network being
157:25 - the one in the class attributes and the
157:28 - best accuracy
157:30 - let's evaluate
157:33 - that Network on the samples now we are
157:36 - evaluating on the training data we are
157:39 - not yet seeing testing data but we are
157:42 - trying to improve the model this is okay
157:44 - I'm going to now Loop
157:48 - through this number of tries
157:51 - and
157:53 - let's try
157:55 - to generate a new network
158:00 - after we do that we evaluate its
158:03 - accuracy
158:06 - on the training samples
158:09 - and if it's better than the best
158:11 - accuracy
158:12 - we keep it
158:14 - and we also keep
158:17 - the network
158:21 - like so now here at the end we just set
158:25 - this network to the best one that we
158:27 - found
158:28 - and we still need to implement this
158:30 - evaluate method here
158:33 - it's not complicated all we have to do
158:36 - is
158:41 - implement the method like that and count
158:44 - how many of them are correctly predicted
158:48 - when we Loop through all of the samples
158:52 - take out the label and remember here to
158:55 - destructure because that's what
158:58 - MLP
159:00 - predict will return
159:03 - on the sample point
159:06 - now the true value for this is what is
159:10 - stored in the sample label we know the
159:13 - true labels for our samples but if this
159:16 - predicted label here matches the truth
159:19 - then we increase the correct count so
159:22 - correct count
159:23 - increases if truth is equal to label one
159:28 - otherwise it doesn't increase
159:30 - and here we just calculate the accuracy
159:34 - by dividing
159:36 - correct count
159:38 - by samples length and let's return this
159:41 - accuracy let's save this file and in run
159:45 - the evaluation MLP
159:48 - after we initialize the MLP classifier
159:54 - here we fit it to the training date
159:57 - so MLP set training samples and let's
160:02 - try this again I'm going to open now the
160:05 - terminal and rerun the evaluation MLP
160:12 - now we get 26.8
160:15 - which is much better than the random
160:19 - chance things we were getting previously
160:22 - so it is working we are searching
160:25 - through 1000 networks and if we're going
160:28 - to increase here maybe by
160:31 - I don't know 5000 then this accuracy
160:35 - should be even better because now it's
160:38 - trying even harder it's going through
160:40 - even more
160:41 - it's an expectation but of course you
160:44 - can be really unlucky with those 5000
160:46 - randomly generated networks and then
160:49 - it's not gonna look sick
160:53 - and it doesn't really make sense once we
160:57 - have found the good one like this to go
161:00 - back down to a crappier one so what we
161:05 - could do is save this model every time
161:09 - we find it and then load it when we do
161:15 - this optimization so we can continue a
161:18 - previously made optimization with the
161:22 - saved Network as a basis let's save this
161:26 - model so I'm going to type here
161:31 - write file sync and
161:35 - we will need the constant for where the
161:38 - model should go
161:39 - and then I'm just going to stringify the
161:43 - whole MLP object
161:45 - and that's it
161:47 - now I want this model to be accessed
161:50 - also by the web page so that we can try
161:54 - the neural network there as well and I'm
161:57 - going to use the same structure here
161:59 - putting model
162:02 - and JS also as a constant and here
162:06 - initializing a variable called model
162:13 - and then putting this stringified Json
162:17 - inside of it and now let's close this
162:21 - template literal like so now these
162:24 - constants need to be added I'm going to
162:27 - go here in constants.js
162:30 - and let's copy this one for the decision
162:33 - boundary this is going to be model now
162:38 - and it's going to be in this models
162:41 - directory let's call it model dot Json
162:45 - and the JS object let's just copy this
162:49 - min max here and this is going to be
162:52 - model Js
162:55 - and
162:57 - model Js
163:00 - now when we are going to run this
163:02 - evaluation
163:06 - this model with
163:08 - 31.96 percent accuracy is going to be
163:12 - saved
163:14 - in data models model here next to the
163:19 - decision boundary
163:20 - and if I'm gonna format it
163:23 - you will see it has the neuron counts
163:26 - information the classes information and
163:29 - the network with all the levels
163:32 - which is just one level for this one and
163:35 - we have the inputs the five different
163:37 - features the outputs the result of the
163:41 - feed forward algorithm and here the
163:44 - biases and the weights
163:47 - through from all the inputs to all the
163:50 - outputs now the inputs here and the
163:54 - outputs here are just the last values
163:56 - that have been used in the training
163:58 - process they are meaningless every time
164:00 - you do a classification these will
164:03 - become overwritten with whatever the
164:05 - features are and these here are going to
164:08 - become generated from the feedforward
164:11 - algorithm they're now just placeholders
164:14 - here and that's okay
164:16 - now if we want not to lose this model
164:19 - and get at least
164:22 - 31.96 accuracy in the next model we have
164:26 - to load this one
164:28 - so in run evaluation MLP after we do
164:32 - this initialization
164:34 - let's load it from that file before we
164:37 - do the fitting
164:39 - so let's say here
164:41 - if that file exists the one that
164:46 - contains the model
164:49 - I'm going to
164:51 - mlp.load and parse it
164:57 - after we read it
165:02 - like so
165:03 - now this load is a really simple method
165:06 - that we still need to implement
165:08 - here inside of mlpjs
165:12 - I'm going to do it
165:14 - just below the Constructor here
165:16 - and load
165:19 - given an MLP model I'm just going to
165:23 - update this model's neuron count to that
165:26 - ones
165:29 - and the same thing for the classes
165:33 - and the same thing for this network
165:37 - it's basically a copy Constructor
165:40 - now let's save this and rerun the
165:44 - evaluation
165:48 - and the same accuracy as before
165:51 - we didn't get lucky with the 5000 tries
165:54 - here but if we try again
165:59 - still no luck if we try again
166:04 - still nothing
166:08 - still nothing
166:12 - but now it worked
166:13 - so we could optimize like this
166:17 - would take quite a long time to reach
166:20 - the same level accuracies that we are
166:22 - getting with our knnn
166:25 - there are better optimizers than this
166:27 - trial and error out there and we'll try
166:30 - those later but now let's get this to
166:33 - work on the web page as well
166:35 - let me close some of these things
166:48 - and here in viewer HTML
166:54 - we are gonna have to import many
166:56 - JavaScript files
166:58 - so here we need the new MLP classifier
167:03 - similar to the kmn classifier
167:08 - then we also need that model the one
167:10 - that we calculated on the back end
167:15 - so this is here in JS objects the
167:19 - JavaScript variant then we need the
167:22 - neural network code and the visualizer
167:25 - let me add this network JS here
167:29 - underneath utils and the visualizer
167:34 - here
167:36 - from this JS folder
167:40 - now we'll visualize this on another
167:43 - canvas and I'm going to Define it here
167:46 - inside of the chart container underneath
167:50 - the confusion container so this is going
167:53 - to be Network canvas
167:55 - and it's going to be what we draw the
167:57 - canvas on
167:59 - let's give this a style similar to the
168:02 - confusion container inside of styles CSS
168:07 - the confusion container is here I'm just
168:10 - going to copy it
168:11 - below rename this to network canvas
168:18 - and give it a black background
168:22 - let's save this and close this file and
168:26 - let's begin to work with the MLP
168:29 - classifier
168:32 - we won't use KNM anymore in this course
168:36 - I'm going to keep it here for reference
168:39 - but I'm going to start using the MLP
168:43 - classifier
168:44 - so MLP and I will initialize it with uh
168:49 - empty and empty ear for the neuron
168:52 - counts and for the classes because they
168:55 - will be loaded from the model that we
168:59 - have calculated with the scripts now
169:02 - every time we see KNN here I'm going to
169:07 - comment out the line
169:09 - and
169:11 - write MLP variant below so this happens
169:17 - here when we are calculating the
169:20 - accuracy of the testing samples but also
169:23 - below for the real time processing here
169:27 - so let's copy this
169:30 - comment it out and replace KNN with MLP
169:35 - so it's the same thing but now with the
169:38 - different classifier
169:39 - this should work already but we are not
169:42 - visualizing it yet
169:44 - so let me go here at the top and also
169:51 - do the visualization I'm going to
169:55 - set the width of the network canvas
170:00 - 500 and same for the height
170:04 - and let's get a reference to the network
170:08 - context from this network canvas
170:14 - like so
170:16 - now we also need the output labels to
170:20 - look nice and we can get those
170:26 - here after the graphics generate images
170:30 - but let me just put this
170:33 - maybe here above the sketch pad
170:36 - and below the confusion because now we
170:40 - have these related somehow so we
170:44 - generate these output labels from the
170:47 - styles by looking at the values
170:52 - of the Styles and then remapping them so
170:56 - we only take out the image of that style
171:00 - we don't care about the color or the
171:03 - text just the image component and then
171:05 - we use our visualizer
171:09 - to draw the network
171:10 - on this network canvas
171:13 - the network stored in our MLP classifier
171:17 - and using these output labels that we
171:20 - just defined
171:21 - we also want to update the visualization
171:25 - here after we do a real-time prediction
171:28 - like so
171:31 - and now let's save the file and we
171:33 - should be able to test
171:36 - the refresh the page
171:40 - and something looks horribly wrong
171:49 - I noticed that this width and height
171:52 - features that we calculate for this
171:54 - empty canvas are minus infinity and
171:57 - minus infinity and this is causing some
172:00 - problems now for this neural network it
172:04 - was working okay for the KNN because it
172:07 - was just some coordinate but now it's
172:10 - sent to some calculations there and it's
172:12 - causing some not a number to happen and
172:15 - problems
172:16 - so let's fix those functions real quick
172:18 - I knew they will become an issue at some
172:21 - point so inside of this feature
172:24 - functions
172:25 - at the top
172:27 - our width here if the points are empty
172:32 - if there is nothing there
172:38 - I'm just going to return
172:40 - 0 for the width and same thing will
172:44 - happen for the height as well
172:48 - now let's refresh this page
172:52 - and close this console
172:56 - toggle the input
172:58 - and now
173:03 - the network does something here
173:06 - it's saying that this is a car because
173:08 - this car note here output value is the
173:12 - highest and you can see that there's a
173:14 - yellow color coding here blue means
173:17 - negative values and the least visible
173:20 - they are closer towards zero so this is
173:23 - very visible bright yellow here it means
173:26 - it's a high value
173:28 - and um it's not fantastic
173:32 - 33.28 we had much better results but
173:37 - that is what we can do now with this
173:39 - random optimization strategy
173:42 - and this here at the bottom are the
173:44 - features so when we look at this we can
173:47 - see a relatively high value for the
173:51 - width because it's a wide image and this
173:54 - is the height here which is smaller
173:57 - then this is going to be the elongation
174:02 - apparently quite the small value but if
174:05 - we draw something like
174:08 - this really elongated shape it's going
174:11 - to be bright and then these final ones
174:15 - are the round Miss value and this is not
174:17 - round at all but if we do make it round
174:22 - it's going to be bright and the last one
174:25 - is the number of pixels basically
174:29 - so if we would fill this space with a
174:32 - lot of pixels then that one starts to
174:35 - light up as well
174:37 - and apparently it is able to pick up
174:40 - that this is a clock one thing that I
174:42 - still want to do is
174:43 - toggle the output and this doesn't work
174:46 - anymore
174:47 - we need to rewrite it so that we
174:50 - consider this one as well not just the
174:53 - confusion Matrix and the chart so let me
174:58 - go to
175:00 - display JS and quickly rewrite this
175:06 - from scratch
175:08 - and I will just say that if the network
175:11 - canvas
175:13 - is visible then let's make this one
175:17 - invisible and let's make the confusion
175:21 - container
175:24 - visible otherwise
175:30 - if the confusion container
175:36 - is visible
175:39 - we will make it invisible
175:44 - otherwise
175:48 - we will make
175:49 - both of them visible again
175:54 - so now we are going to toggle between
175:58 - the three items there
176:02 - let's save this
176:05 - refresh
176:09 - and this seems to work
176:12 - interestingly we get a lot of zeros here
176:16 - so it looks like the network that we
176:19 - have is really good at recognizing cars
176:22 - and pencils and clocks
176:24 - but nothing else so now we can see that
176:27 - this accuracy really doesn't tell
176:30 - a good story but this confusion Matrix
176:34 - really tells us what is really going on
176:37 - the model forgot about these other
176:39 - things pretty much and let's see now in
176:44 - this decision boundary plot we can't
176:47 - really see much because it's still this
176:50 - High dimensional Cube
176:52 - but we could revert to the simple
176:55 - features I like doing that let's go back
176:58 - to width and height two features and see
177:01 - how this decision boundary plot looks
177:03 - like now when using a neural network
177:06 - so
177:08 - in feature functions I'm just going to
177:12 - comment out here everything except for
177:16 - these width and height
177:21 - and let's open the terminal and let's
177:24 - rerun the feature extraction
177:27 - so node feature extractor.js
177:31 - and now it's fast because it's not doing
177:34 - the pixels thing
177:36 - and now we have to optimize again our
177:39 - neural network model but the model that
177:43 - we created previously here inside of the
177:47 - data models is pretty good and it's
177:50 - using the five different features so
177:54 - it's incompatible with the two feature
177:57 - models that we try to create now and
177:59 - we'll need to delete this for the code
178:02 - to work
178:03 - so right click delete the model
178:08 - and now
178:09 - run evaluation MLP
178:13 - should work
178:16 - we got a new model with 26.38 accuracy
178:21 - now if I run this again it's going to
178:24 - try 5000 more times and maybe get the
178:27 - better version
178:29 - or not let's try one more time see if
178:32 - we're lucky
178:34 - and we are we got 29 accuracy with this
178:37 - one
178:38 - and you'll notice that this decision
178:40 - boundary plot is generated really
178:42 - quickly now because
178:45 - doing the feed forward algorithm is much
178:48 - faster than doing the nearest neighbor
178:51 - search
178:53 - so we could go
178:58 - in node here in the Run evaluation MLP
179:03 - and set a higher value for this image
179:07 - size to get a better quality image there
179:10 - maybe 1000 is enough
179:14 - now let's rerun this
179:17 - took a bit longer but it's done and
179:21 - accuracy didn't change so let's try to
179:24 - refresh
179:26 - and we see now this network with just
179:29 - two nodes here the width and the height
179:32 - just two features and the input layer
179:35 - and the output it looks different but it
179:38 - seems again the same kind of scenario
179:40 - with just three things considered the
179:43 - car the tree and the bike
179:47 - now let's toggle again and this is now
179:51 - the Precision boundary plot and it looks
179:55 - interesting it has here at the top the
179:57 - tree section and then the bicycle
180:00 - section and then the car section this is
180:04 - confusing me with the pencils so let's
180:07 - go back to viewer HTML
180:10 - and
180:13 - put all the testing samples now I'm
180:16 - going to comment out this filtering from
180:18 - here
180:21 - a refresh
180:24 - and now we can see this decision
180:27 - boundary plot and
180:29 - every one of these trees here in the
180:33 - green region is classified correctly
180:35 - every one of these bikes here is
180:38 - classified correctly and every one of
180:40 - these cars here is classified correctly
180:43 - but a lot of misclassifications happen
180:45 - there is a pencil region here and
180:49 - this car is in the pencil region so why
180:52 - didn't it show up in our confusion
180:55 - Matrix
180:56 - oh it did it has a one here I didn't
181:00 - notice it and the tree should be there
181:02 - as well apparently
181:07 - and there it is
181:10 - hermino's house is also there classified
181:13 - as a car nice now let's try one more
181:16 - thing and see if we can add the hidden
181:19 - layer here and if we get any difference
181:22 - in our run evaluation MLP
181:26 - at the top
181:29 - let's say we are going to add
181:31 - 10 nodes on a hidden layer and see what
181:35 - happens because we redo this evaluation
181:37 - and the network that we have at the
181:40 - moment doesn't have those I'm gonna have
181:43 - to delete again this model here
181:50 - and rerun the evaluation
181:56 - a bit worse accuracy let's try to
181:59 - improve it give it five thousand more
182:02 - tries
182:04 - doesn't seem to work one more try maybe
182:07 - we're lucky
182:12 - and we are not let's just keep it like
182:15 - this and see what we have on the page
182:19 - so this is how the neural neural
182:22 - networks looks like and if we toggle the
182:24 - inputs and we draw something really wide
182:28 - you can see now this lighting up let's
182:31 - make it also tall so this will light up
182:36 - and a lot of things are lighting up here
182:38 - in the middle in interesting ways when
182:41 - these properties change so it's a more
182:43 - complex model but not a very good one
182:48 - it also seems to now prioritize two
182:50 - things here let's see the decision
182:53 - boundary plot
182:55 - let's close this input
182:58 - and I don't really see it so well
183:03 - let's keep just the decision boundary
183:06 - plot now here
183:10 - and I'm going to add again this filter
183:13 - because
183:16 - it keeps that plot in a kind of squarish
183:18 - aspect ratio because that's where the
183:20 - pencils are there's no arminius house to
183:23 - stretch things
183:25 - so
183:28 - let's hide the samples
183:31 - and refresh
183:33 - toggle the output
183:35 - that's how it looks like
183:41 - let's re-add all the features one last
183:44 - time now with this hidden layer there
183:48 - so in feature functions
183:51 - I will remove this comment from here
183:54 - and here
183:56 - we go down and
183:58 - feature extractor
184:02 - it's done and now let's run evaluation
184:05 - MLP
184:11 - oh I forgot to remove that model that we
184:15 - had last time
184:17 - delete
184:21 - and now run evaluation MLP
184:27 - refresh and now the input layer is more
184:30 - complex again
184:33 - still this kind of bad looking confusion
184:36 - Matrix
184:38 - and this one is unreliable now because
184:41 - we just showed the first two Dimensions
184:43 - there
184:45 - now optimizing this with the current
184:47 - strategy is not going to work well you
184:51 - could wait for it to randomly try a
184:54 - bunch of different values and you could
184:57 - leave it overnight or something you will
184:59 - get better values
185:01 - but next time I'm going to teach you how
185:03 - to use Python to get the values with
185:05 - more complex optimization algorithms
185:09 - the neural network is now there but it
185:11 - needs to be optimized better and the
185:14 - typical way of doing this is with the
185:15 - back propagation algorithm I don't have
185:18 - a good way to teach it and the best
185:20 - video I know on the topic is from three
185:22 - blue one brown so go watch it what we'll
185:26 - do is use back propagation in Python
185:28 - there are some JavaScript
185:30 - implementations as well but I wanted to
185:32 - see that you can combine programming
185:34 - languages like that and use their
185:36 - strengths when needed python has many
185:38 - machine learning libraries we'll
185:40 - continue to use scikit-learn because we
185:42 - use it in phase one but others are more
185:45 - popular nowadays I think
185:47 - it doesn't really matter all we need is
185:50 - something that gives us good weights and
185:52 - biases and paste them into our model
185:55 - now get ready to blur the lines between
185:58 - programming languages
186:01 - make sure you have python installed for
186:03 - this next part
186:04 - last time we used python we were in this
186:07 - python folder and we had this KNM py and
186:12 - some functions for reading the CSV
186:14 - features we're going to make a new file
186:17 - similar to this KNN but we'll call it
186:20 - MLP so copy
186:24 - and paste it here
186:26 - rename
186:28 - MLP
186:31 - and it's the same thing as k n for now
186:34 - but we will include from this
186:36 - scikit-learn Library not from Neighbors
186:39 - this time but from neural network and we
186:43 - import the MLP
186:47 - classifier it has an implementation of
186:49 - it already then here we write
186:53 - MLP
186:55 - MLP
186:57 - MLP everything looks the same
187:01 - but here we are going to have this MLP
187:03 - classifier and these parameters don't
187:06 - fit anymore instead we should pass the
187:10 - number of hidden layers and actually how
187:14 - many neurons should be on each hidden
187:16 - layer
187:17 - so we have to use a tuple for that and
187:21 - at the moment I just have here 10
187:24 - because I want it to be the same kind of
187:26 - structure as we used last time in
187:28 - JavaScript
187:30 - so let's pass here this hidden
187:36 - and now we can test
187:39 - so let's open the terminal
187:41 - we normally worked inside of this node
187:44 - directory so if you're still there make
187:47 - sure that you're gonna run this python
187:49 - code by first going outside so
187:53 - bison to running command and then
187:58 - going outside of the node folder and
188:01 - then python
188:05 - mlp.py this is what we'll run this code
188:11 - and looks like we're getting something
188:13 - really good 61 percent and an error here
188:17 - saying something about the optimization
188:20 - not being finished yet and that's
188:24 - because there is a parameter that we can
188:26 - set to this classifier that it can
188:29 - iterate longer so I'm going to pass this
188:33 - set here Max either
188:36 - to ten thousand and let's save this and
188:40 - run this again
188:42 - now we get
188:44 - 66 percent almost 67 percent which is
188:49 - really good
188:50 - now if you're gonna run this code again
188:53 - it's possible that you're gonna get
188:55 - another accuracy here
189:00 - like now it changed slightly and that's
189:02 - because it also uses randomness of some
189:05 - kind
189:06 - but if you want to have predictable
189:08 - results here you can pass another
189:10 - parameter and fix the random State it's
189:14 - still going to use Randomness but now
189:16 - the randomness is predetermined if that
189:19 - makes sense so saving this and running
189:21 - this
189:24 - gives us some value now maybe 61 percent
189:27 - I guess we weren't as lucky as we were
189:29 - before
189:34 - but it's consistent and if you change
189:36 - this value to something else you will
189:38 - get some other accuracies there some of
189:40 - them will be more lucky some of them not
189:43 - depending on your
189:45 - luck I guess but I'm just gonna fix one
189:50 - here I don't really care about the
189:51 - accuracy that much
189:54 - sixty percent is definitely very good
189:56 - compared to what we were getting with
189:58 - random chance but okay this is just one
190:00 - of these printing in the console things
190:03 - it's not so great how to get it to work
190:07 - inside of our web application and see it
190:10 - in practice
190:12 - well we have to first debug what this
190:15 - MLP object contains and I'm going to
190:19 - start to print some of its properties
190:22 - like the intercepts
190:25 - so let's run this again
190:29 - and you can see here two values pretty
190:33 - much the first value here are 10 numbers
190:36 - and these are the biases for the neurons
190:40 - on the hidden layer the 10 neurons on
190:43 - the hidden layer and these ones here are
190:46 - the eight biases for the output neurons
190:50 - the eight different classes we can also
190:53 - print here the so-called coefficients
190:58 - run this again
191:00 - and now we're getting something much
191:04 - bigger here
191:05 - these are the weights
191:07 - so
191:09 - the weights are much longer than the
191:13 - biases
191:15 - so these intercepts and coefficients
191:18 - need to go
191:20 - over our model here if I'm going to
191:25 - format this
191:27 - we also have to specify in your own
191:30 - counts and the classes here and then the
191:33 - network
191:34 - we have the different levels for each of
191:38 - them we have inputs outputs and then the
191:41 - biases and the weights
191:44 - so the intercepts and the coefficients
191:48 - are going to be the biases and the
191:51 - weights we need to fill those in here
191:54 - for all of the levels
192:01 - but the inputs and outputs we don't need
192:04 - to worry about that because these are
192:06 - going to come in as a given the inputs
192:09 - and the outputs are going to be
192:11 - calculated by the network so really we
192:14 - only need to pass here the weights and
192:17 - the biases and also these things that
192:20 - the model requires
192:23 - so let me show you how to do that let's
192:26 - remove here this and I'm going to need
192:30 - to know what these classes are let's
192:33 - define them in a list
192:35 - Car Fish House tree
192:38 - bicycle guitar pencil
192:43 - clock
192:44 - and now let's start forming our object
192:48 - it's going to be this adjacent object
192:54 - and the neuron counts now the values
192:57 - from this are going to be the length of
192:59 - X of 0 where we have the number of
193:02 - features basically for the input layer
193:05 - and then the hidden which is defined up
193:10 - here
193:11 - followed by
193:13 - the length of the classes which we just
193:15 - defined here
193:17 - then
193:18 - the classes I'm just going to pass this
193:21 - object directly and then the network
193:24 - this is going to be a dictionary here
193:28 - with levels which is going to be an
193:31 - empty list and now these Network levels
193:35 - is what we have to fill in from the
193:39 - intercepts and the coefficients
193:42 - so I'm going to Loop
193:45 - through all of the coefficients like
193:49 - this
193:50 - and let's define the level
193:53 - with the weights and I'm going to
193:56 - convert these coefficients
193:59 - into a list and I'm going to do the same
194:02 - thing with the intercepts
194:07 - like so
194:09 - and inputs is going to be just zeros I'm
194:14 - just going to multiply them by how many
194:16 - coefficients there are and outputs I'm
194:19 - going to multiply them by how many
194:22 - intercepts there
194:23 - so these are just zeros and then we need
194:27 - to append this level
194:30 - to our Json object Network levels
194:34 - so
194:37 - this is a dictionary so we refer to the
194:40 - Keys like that
194:42 - and append
194:44 - the level
194:45 - now python does have a Json module and
194:49 - we can import it here and use it to
194:54 - define a Json objects
194:58 - with an indent so we can read it more
195:00 - nicely and now what we have to do is
195:03 - write this Json object into our file
195:08 - here that we will use in our viewer both
195:11 - the one year and the models and the one
195:14 - in JS objects here I will modify both of
195:18 - them in Python so we don't have to worry
195:20 - about it
195:22 - let's open
195:24 - the one in data models
195:28 - model.json for writing
195:31 - and
195:33 - right
195:36 - the Json object now I'm going to copy
195:39 - this also for the JS object the
195:42 - JavaScript object and this is going to
195:45 - be in
195:50 - common JS objects and model JS like that
195:56 - and when we write it here we also need
195:59 - to concatenate that string to assign it
196:02 - to an object
196:03 - so const model is equal to endless
196:07 - concatenate with this and then here at
196:10 - the end concatenate to it a semicolon
196:14 - and now when we run this python code
196:18 - again here in the terminal let me first
196:21 - clear it up a bit
196:23 - so if I'm going to run it again
196:28 - it lists here the accuracy but our
196:31 - models the model JS file here and also
196:36 - the model Json file here should have
196:39 - updated
196:41 - with the new values so now the weights
196:43 - are going to be
196:45 - calculated from Python and the biases
196:48 - come from Python and the inputs outputs
196:51 - are turned into zeros
196:54 - if we did everything correctly then now
196:58 - we can run this
197:00 - run evaluation MLP
197:07 - and it's actually now trying to improve
197:10 - that model if it can but most likely it
197:14 - cannot and it's done
197:17 - let's see it now in practice I'm gonna
197:19 - refresh the page
197:22 - and there you have it a neural network
197:25 - that now has
197:26 - 61.79 accuracy
197:30 - and if we toggle this we can see this
197:33 - confusion Matrix looks much nicer
197:37 - quite similar what we got with the k n
197:39 - actually
197:41 - and the decision boundary
197:46 - not going to help us much in these high
197:48 - dimensional spaces but we now have a
197:52 - neural network here that actually is
197:55 - able to recognize things quite nicely
197:58 - quite well with
198:01 - 61.79 accuracy
198:10 - nice
198:23 - okay it's quite good actually now I
198:26 - didn't plan to teach too many things
198:28 - about neural networks here I plan to do
198:31 - that in phase three of my self-driving
198:34 - car course
198:35 - after Phase 2 is done
198:38 - but let's try to investigate a bit using
198:43 - just two features again so we can see
198:45 - also this decision boundary plot
198:49 - coming from a good neural network
198:52 - I'm going to go
198:54 - here inside of common feature functions
198:58 - and let's
199:01 - keep just the width and the height again
199:05 - and now let's do
199:10 - feature extraction
199:12 - with these two features only
199:15 - and now let's do the training
199:19 - with python
199:24 - so we got a
199:26 - 42.3 percent accuracy with just two
199:29 - features
199:30 - which is comparable to the k n we got
199:33 - previously with just two features now
199:35 - let's run the evaluation so it generates
199:38 - also the
199:40 - decision boundary plot
199:43 - and something looks off this 31.7
199:47 - percent accuracy what
199:50 - what happened
199:52 - it was supposed to be 42 percent why did
199:55 - it drop so much
199:57 - Well turns out the reason is
200:00 - the activation function that this MLP
200:04 - classifier uses by default is the
200:07 - rectified linear unit
200:12 - and we will need to implement this
200:14 - rectified linear unit into our
200:17 - JavaScript code for it to be fully
200:20 - compatible
200:22 - let's do this
200:24 - I'm gonna open here the network Js
200:28 - and here where we're Computing the
200:31 - outputs we need to apply this value
200:34 - activation function here goes
200:48 - done
200:50 - it's just a maximum between zero and
200:52 - that other value it doesn't like to have
200:55 - negative values here
200:57 - so let's save this
201:00 - and now run this evaluation again
201:07 - I should really turn off this trying to
201:11 - optimize here let me go to run
201:14 - evaluation MLP and here where we're
201:19 - doing the fitting I'm just going to
201:22 - decrease this value by a lot let's say
201:25 - I will remove it so it defaults back to
201:28 - 1000. it's gonna be almost instantaneous
201:31 - okay and now you actually see here the
201:33 - accuracy being 42
201:36 - .4 percent so the same as we got in
201:40 - Python
201:42 - and now let's test on the web page
201:47 - there's the network and if we toggle the
201:50 - output
201:51 - it looks okay for just two features the
201:54 - width and the height
201:55 - and the decision boundary plot
201:59 - looks like this it's much more
202:02 - simple than the complex one we got
202:05 - previously from KNN
202:08 - but otherwise it's comparable in many
202:10 - ways like a section here for the pencils
202:13 - and one for the fish and this one for
202:15 - the clocks I can obviously tell that
202:17 - they are there now these activation
202:20 - functions they are several of them and
202:24 - you can check the documentation and the
202:26 - scikit-learn library web page for
202:29 - example if we go back in Python we can
202:32 - actually pass them here
202:35 - we could say activation set to
202:40 - hyperbolic tangent for example
202:44 - and this is going to be again one of
202:46 - those really difficult ones to implement
202:49 - but let's see first if it works so let's
202:52 - try the hyperbolic tangent now
202:56 - in Python here
202:59 - it's not a big difference but I want to
203:02 - show you just how the decision boundary
203:04 - looks different
203:05 - now let's implement this hyperbolic
203:07 - tangent in JavaScript
203:10 - and the good news is it's already there
203:13 - the math library has an implementation
203:16 - of it so we can just call it directly
203:18 - here and remove that zero that we used
203:21 - for the max previously
203:23 - now let's run also the evaluation here
203:27 - so that we get a new decision boundary
203:30 - plot
203:34 - and if we refresh
203:36 - toggle the output
203:38 - and again
203:40 - you'll see that it looks more curved
203:42 - because of what we just did
203:45 - I think this way of learning is really
203:47 - nice and if you're gonna go deeper and
203:49 - study the mathematics behind the things
203:51 - you're going to have an intuition of
203:53 - what to expect
203:54 - but yeah let's add all the features
203:57 - again
203:59 - and see what effect this hyperbolic
204:02 - tangent has
204:08 - on all of them
204:19 - wow we got the 68 percent now
204:23 - to see this on the web page we don't
204:25 - really have to run the evaluation
204:26 - anymore because the model is already
204:28 - there and with so many features the
204:31 - decision boundary plots are useless
204:34 - pretty much so when we want to optimize
204:36 - we can just run this python code and
204:39 - open the viewer unless we change the
204:42 - features as well then we have to do the
204:44 - feature extraction again if we refresh
204:46 - the viewer
204:49 - this is what we get we have now this
204:52 - neural network here and it starts to
204:54 - have kind of a
204:56 - structure it's not anymore completely
204:59 - random if you look at the links
205:02 - The Matrix here looks better and better
205:04 - all the time almost 70 percent accuracy
205:08 - so that's quite good
205:10 - and this I won't bother with it anymore
205:13 - we can check also down here in the
205:16 - testing section
205:18 - to see that a lot of blue started
205:21 - appearing recently
205:23 - and in many situations all the drawings
205:26 - from one person are recognized
205:30 - starts to feel like this is actually
205:32 - doing something good
205:34 - I decided to include this section on
205:37 - deep neural networks so you don't ask
205:39 - something like when are you going to
205:41 - teach us something cool like deep neural
205:43 - networks
205:44 - well you already know how to use them
205:47 - it's just a neural network that has many
205:49 - connections many hidden layers and so on
205:52 - I'm also going to teach you a way to go
205:54 - from the five features we've been using
205:56 - to 400 features but as you can see from
206:01 - how long this video is it won't be
206:03 - rocket science we'll just use the pixels
206:06 - themselves as features so it won't
206:09 - really be a deep dive this time we'll
206:11 - only go Skin Deep
206:14 - inside of feature functions
206:17 - I'm going to comment out everything here
206:21 - really
206:22 - and we will implement
206:25 - a different kind of code structure here
206:28 - it will break what we have previously so
206:32 - keep a backup of that if you want to
206:34 - compare but we won't do many changes
206:37 - today so you can also revert if you pay
206:39 - attention
206:41 - now what we do here is we open up an
206:46 - object with the name pixel array so this
206:50 - will have all the features coming from
206:53 - one function call and the function is
206:56 - going to be called on paths but then
207:00 - it's going to return
207:04 - all the pixels
207:07 - from our get pixels function which we
207:09 - call on the paths but I'm also going to
207:12 - specify a size because I don't want to
207:15 - have 400 times 400 pixels
207:19 - that's going to be a lot of pixels and
207:22 - they are not necessary we can figure out
207:24 - what the drawing is even from a small
207:27 - drawing and it's going to be more
207:29 - efficient
207:30 - so in my case here I'm going to use a
207:33 - small 20 by 20 canvas now let's close
207:38 - these and this is going to be a feature
207:41 - Vector with 400 dimensions
207:45 - now we need to change some things in the
207:47 - code to work with this new structure and
207:50 - we're going to go to node feature
207:54 - extractor.js
207:55 - and comment out this line here
208:00 - and instead write this new one
208:04 - that only takes out the values
208:08 - of calling the first and only function
208:12 - that we get from the feature functions
208:14 - in use so we call this one here directly
208:18 - on the paths and get the values assigned
208:21 - them to the point now this feature names
208:24 - at the moment would just say
208:27 - pixel array here and that's not good
208:29 - they need to be many of them 400 of them
208:34 - so what we do here is comment out this
208:38 - line and I'm gonna write this new one
208:43 - where we create an array
208:47 - the same size as the first samples Point
208:51 - length
208:52 - and we fill it with zeros or anything
208:56 - you want really we can fill it with
209:01 - an empty string like this
209:04 - it just needs to have 400 items for the
209:07 - code to work now for the web to work we
209:10 - also have to do this for the real time
209:15 - calculation of the features there
209:17 - instead of this mapping here
209:21 - and here we can just
209:24 - take the first function
209:26 - and call it underpaths like so now this
209:29 - should work if we open now
209:32 - the terminal we can extract these new
209:36 - features let's go to the node
209:39 - folder and then
209:44 - extract these new features
209:51 - and let's have a quick look
209:53 - what they are
209:55 - inside data
209:57 - data set
209:59 - and now let's for example open these
210:02 - csvs they are easier to read
210:06 - you can see at the top the feature names
210:08 - they are those empty strings separated
210:12 - by commas
210:13 - and there are many of them 400 of them
210:17 - and last thing is still the label
210:20 - and then
210:22 - here there are pixel values visible
210:25 - pixels here and some pixels may not be
210:28 - fully visible because of this
210:30 - anti-aliasing
210:32 - but some pixels are completely invisible
210:36 - and
210:38 - this is the
210:40 - whole very long feature Vector for each
210:45 - individual sample
210:46 - so can this work
210:49 - well if I'm going to optimize now with
210:53 - python
211:07 - it seems it does and we're now at 70
211:11 - almost 75 percent
211:13 - wow let's take a look in the web page
211:18 - and we now have this Beast here
211:22 - with all these connections here from
211:25 - each individual pixel all 400 pixels of
211:30 - the small 20 by 20 size image and this
211:33 - is the new accuracy
211:36 - this is the new Matrix here and it looks
211:40 - really really good doesn't it
211:44 - this we already said we don't look at
211:46 - anymore with these high number of
211:48 - Dimensions there
211:50 - and if we try to make a new input here
211:59 - it seems to work and I made these nodes
212:03 - here very very small in the visualizer
212:06 - if they exceed a certain value
212:08 - now if you want to get an even nicer
212:11 - visualizer here that somehow modifies
212:14 - also the weights based on the activation
212:18 - of these bottom neurons here
212:20 - then you could go in the visualizer
212:26 - and go to draw level
212:31 - and here we're drawing these weights
212:34 - between the inputs and the outputs so
212:37 - they are the lines and we set here the
212:40 - value the rgba of the weight value but
212:44 - we can multiply this by the
212:48 - inputs of
212:51 - I and this is going to make that
212:54 - connection disappear if that pixel is
212:56 - off or be there present if the pixel is
213:00 - on because of that
213:03 - anti-alias saying it could be also some
213:05 - transparent value
213:07 - so let's save this
213:09 - refresh and now everything is off here
213:14 - but if we start drawing something
213:18 - we start to see there
213:21 - those connections appearing and I think
213:24 - it's interesting it makes this a much
213:26 - more dynamic system
213:28 - this is not a pencil oh come on
213:32 - maybe if we give it some more detail
213:34 - like
213:36 - okay now it's a fish
213:39 - great but um this is not yet a deep
213:42 - neural network because it just has this
213:45 - one hidden layer
213:47 - let's go deeper
213:51 - we're going to go to our python script
213:55 - let's put
213:57 - 100 nodes on this one hidden layer for
214:01 - now and then we try more later
214:05 - so let's optimize again
214:08 - 82 percent accuracy we broke another
214:13 - barrier there at 80 percent
214:16 - let's see how this one looks like
214:19 - and this is it
214:26 - wow look at that
214:35 - now this system starts to become slow
214:37 - because of this visualization here
214:40 - but also because the model becomes more
214:42 - complex and there are more calculations
214:45 - I think we can try with two hidden
214:48 - layers so that we do get some deep
214:51 - Network
214:52 - even though deep means a lot of them but
214:55 - you get the idea
214:58 - let's add 100 more
215:08 - 83 percent not a very very big
215:11 - Improvement but it's still an
215:13 - improvement
215:14 - now let's see how it looks like
215:19 - so now we have this
215:22 - and if we draw something
215:28 - a lot of crazy stuff happening there
215:33 - and it is a house
215:36 - it seems to be quite reliable like after
215:39 - it's a house it's it's a house here
215:42 - let's see our confusion Matrix one more
215:45 - time
215:46 - and yeah this looks really good
215:52 - and let's have a look also at the
215:54 - classifications
216:00 - very few of them are not blue right now
216:31 - now people have different views here
216:34 - some like the small models with
216:36 - relatively few features and consider big
216:39 - models like what we just built as a
216:41 - waste of resources but others think
216:43 - they're worth it because you can teach
216:45 - them pretty much anything without the
216:47 - pain of tailoring features one by one
216:50 - the problem is it's really hard to
216:52 - explain why the system works a certain
216:54 - way if the model is so big
216:57 - hope you liked the course let me know if
217:00 - you want to see more like I didn't teach
217:02 - you anything about clustering yet and
217:04 - it's an important part of machine
217:05 - learning or we could try to identify the
217:08 - person who is doing the drawing instead
217:10 - of what is being drawn maybe we can make
217:12 - a really sophisticated authentication
217:15 - system like that
217:16 - what do you think go in the poll in the
217:19 - description and vote your favorite
217:21 - see you guys