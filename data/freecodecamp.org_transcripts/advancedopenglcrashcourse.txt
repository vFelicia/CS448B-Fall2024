00:00 - OpenGl can be used to create complex graphics 
effects. This advanced OpenGL course from Victor  
00:06 - Gordan will take your skills to the next level.
Hi everyone! In this course I'll teach you about  
00:12 - different advanced topics in OpenGL that 
will help you achieve more complex effects,  
00:16 - better looking renders, and more optimized 
scenes. If you don't know what OpenGL is or  
00:21 - are not familiar with it, then you should first 
watch the beginners course for OpenGL which you  
00:26 - can find on this channel. And that should be all 
you need to know about this course, enjoy!
 
00:36 - In this tutorial we'll take a look at Depth 
Buffers in OpenGL and also see how we can make  
00:41 - use of them for a little graphical effect.
You might remember that we've already made  
00:47 - use of the Depth Buffer in the "Going 3D" 
tutorial in order to fix a weird issue we had.  
00:53 - Since the buffer is turned off by default, 
we want to make sure we have it enabled,  
00:58 - and that we clear it each frame just like the 
Color Buffer. Now what this buffer basically does,  
01:03 - is that it stores "depth" values that represent 
how far away from the near plane of the projection  
01:09 - matrix a certain fragment is. A depth value of 
0 meaning that it's right on the near plane,  
01:16 - and of 1 meaning it's on the far plane.
Using this depth information, we can asses  
01:22 - which object should be in front of which other 
object. We can do this by using the glDepthFunc  
01:28 - and inserting one of the following inputs. By 
default OpenGL chooses GL_LESS which means that  
01:35 - if the depth value of an object is less than that 
of the current depth value, then the first value  
01:41 - replaces the second. In most circumstances 
you should use GL_LESS, but I suppose you  
01:46 - could also choose one of the others if you want 
your game or application to be mind bending.
 
01:52 - Now the cool part. Let's visualize the depth 
buffer. We can easily do this by going to the  
01:57 - fragment shader and outputting gl_FragCoord.z as 
the FragColor. The problem is, that as soon as  
02:06 - we press run, you'll notice the screen is mostly 
pure white. The only way to see a bit of darkness  
02:11 - is to get very close to an object. This is due 
to the fact that depth in OpenGL is not linear.  
02:18 - If the depth was linear, then we would have 
the same amount of precision for depth at a  
02:23 - close distance as we would at a far away 
distance. Since we almost always focus on  
02:30 - things that are close to us, we want to make the 
precision be very high near us, and low away from  
02:36 - us. This is achieved by using this formula. 
Don't worry, we don't have to implement it  
02:42 - since OpenGL does it automatically.
Sometimes though, you want to use another formula,  
02:47 - so in order to do that, we must first get the 
z-value by linearizing the depth function, which  
02:53 - can be done using this function. Now using this 
function we get the z value which keep in mind,  
02:59 - is not normalized. This value is simply the 
distance from the near plane. So let's declare  
03:04 - the near and far constants of our frustum, and 
divide the linear depth by the far length to  
03:10 - quickly normalize it just to see what the results 
look like. Now let's just look at a quick problem  
03:22 - you can get, and then I'll show you the cool 
effect we can achieve with depth buffers.
 
03:26 - So the main issue that arises from depth buffers 
is called Z-fighting, and it occurs because  
03:32 - two or more triangles have the same depth 
buffer and thus the depth function can't  
03:37 - decide which one is closer than the other, and 
thus it keeps changing between them constantly.  
03:43 - An easy fix to this is usually to make sure you 
don't have triangles that are too close to one  
03:48 - another and parallel. If Z-fighting appears at a 
far away distance, then you might also consider  
03:54 - tweaking the function of the depth buffer so 
that you have more precision at that distance.  
03:59 - And the final trick is to use a bigger integer 
for the depth buffer. Usually by default it uses  
04:05 - 24bits, but you could change it to 32bits if your 
card supports it. This will increase the precision  
04:12 - and thus decrease the change of Z-fighting.
Now for the cool effect. We can take the z value,  
04:17 - and plug it into a logistic function for 
which we have a steepness parameter, and  
04:22 - an offset parameter. The steepness will control 
how fast the depth value changes from close to 0  
04:29 - to close to 1, and the offset will determine 
at what z-value this change is half way done.  
04:35 - The cool thing about this, is that this can give 
you smooth edges for the end of your frustum  
04:40 - if you want that, but the even nicer thing, is 
that this can somewhat simulate a fog effect.  
04:46 - So let's change our background color to a grey, 
and calculate the depth value using our function.  
04:51 - Then multiply our usual direcLight() by the 
reverse of our depth value, and also add the depth  
04:58 - value times the grey color from before. Now we 
should have a nice simple fog effect. Keep in mind  
05:04 - that you might need to adjust the steepness 
and offset a bit to get it just right.
 
05:09 - Have fun playing around 
with different effects!
 
05:16 - In this tutorial we'll take a look at the 
Stencil Buffer and how we can use it to create  
05:21 - useful effects such as outlining a model.
So the Stencil Buffer, just like the Depth Buffer,  
05:27 - holds a value for each pixel you can see, these 
values being used for image masking in general.  
05:34 - Unlike the Depth Buffer though, 
where each pixel holds between  
05:38 - 2 and 4 bytes of data, for the Stencil 
Buffer each pixel only holds 1 byte of data,  
05:44 - so values from 0 to 255. But you'll 
mainly only use the values of 0 and 1.
 
05:52 - So let's look at how we can work with this 
new buffer. First of all we have the function  
05:57 - glStencilMask that allows us to choose which 
parts of the Stencil Buffer we want to be able  
06:02 - to modify. It simply takes a pixel from the mask, 
and a corresponding pixel from the Stencil Buffer,  
06:08 - and applies a bitwise "AND" comparison on them. 
Keep in mind each pixel has a byte of data,  
06:15 - so 8 bits. A bitwise "AND" operation compares 
each bit with it's corresponding counterpart and  
06:22 - only outputs 1 if they are both 1. Therefore if we 
input 0x00 into glStencilMask, which means that we  
06:32 - have 8 bits equal to 0, then all the comparisons 
will fail and the Stencil Buffer won't change  
06:38 - at all. But if we input 0xFF into glStencilMask, 
then all the bits of the mask will be 1 since  
06:46 - 0xFF is equal to 8 ones, and so we'll be able 
to modify any part of the Stencil Buffer.
 
06:53 - Now let's look at two more functions we can 
make use of: glStencilFunc, and glStencilOp.  
06:59 - glStencilFunc allows us to control how the 
Stencil Buffer passes a test or fails a test,  
07:05 - while glStencilOp allows us to dictate 
what happens when the stencil test fails,  
07:11 - when the stencil test passes but the 
depth test fails, and when both pass.
 
07:16 - Let's take a deeper look at glStencilFunc. 
It takes in three arguments: a function,  
07:21 - a reference value, and a mask. The function can 
be one of these, by default being set to GL_ALWAYS  
07:28 - so the test always passes. The reference value 
is simply the value we use to compare in the  
07:34 - function. Notice how before comparing the stencil 
value with the reference value we apply a bitwise  
07:40 - AND operation to both using the mask. This means 
that if you want to compare the numerical value  
07:46 - of the two accurately you will want your 
mask to be 0xFF so that nothing changes.
 
07:52 - Now for glStencilOp, it has four arguments: sfail, 
dpfail, and dppass. These stand for stencil fail,  
08:01 - depth fail, and depth pass. For all of 
these you can choose between the following  
08:06 - options. By default they all have GL_KEEP 
which basically means that nothing changes.  
08:11 - There's not really much more to say about these 
functions, so if you want to know more about them,  
08:16 - look them up in the documentation.
The Stencil Buffer can be used for many  
08:20 - things such as portals, mirrors, and more, but an 
easy feature to implement is outlining of models,  
08:27 - so let's take a look at that. We first want to 
render our object like we normally do and update  
08:32 - the stencil buffer with 1s everywhere we have 
a fragment from our object, and 0 everywhere we  
08:39 - don't have a fragment from our object. This 
will essentially create a figure like this.  
08:44 - Then we want to disable writing to the stencil 
buffer so we don't accidentally modify it,  
08:50 - and also disable depth testing so that we can make 
sure the next object we draw will be completely in  
08:56 - front of the previous one. Now we want to render 
a scaled up version of the object we had before,  
09:02 - but this time in a flat color, and with the 
following condition: we only draw it's fragments  
09:07 - where the stencil value is not 1, so basically not 
where the silhouette of the previous object was.  
09:14 - Then we just restore writing to the 
stencil and enable the depth buffer  
09:19 - again. That's all we have to do.
Now let's implement it in code. We  
09:22 - start of by enabling our stencil buffer using 
glEnable(GL_STENCIL_TEST), and making sure we  
09:29 - also have our depth buffer enabled. Then we 
use glStencilOp plugging in GL_KEEP, GL_KEEP,  
09:36 - and GL_REPLACE. This will make it so that 
when both the depth and stencil tests pass,  
09:42 - we'll use the reference value specified by 
glStencilFunc. Now let's make sure we clear  
09:47 - all the buffers before each frame, and go 
on to the part where the magic happens.
 
09:52 - First we specify our stencil test always 
passes, and set the reference value to 1.  
09:58 - Then we enable writing to all of our stencil 
buffer with a stencil mask of all 1s. And now  
10:04 - we simply draw our object. By this point in time, 
our stencil buffer looks like this, and our color  
10:10 - buffer like this. Remember that all these values 
are 1 because we specified in the glStencilOp  
10:18 - function that if both the stencil and depth 
tests pass, then make the pixel of the stencil  
10:25 - buffer equal to 1. Now for the outline we want our 
stencil test to only pass when it's not equal to 1  
10:31 - and the depth test passes. Then we disable out 
depth buffer for previously mentioned reasons,  
10:37 - and disable writing to the stencil mask 
so we can keep our original silhouette.
 
10:41 - Now since we want to make the outline a flat 
color, we'll have to create two new shaders,  
10:46 - and a shader program. So let's first create the 
shader program like so. Then for "outlining.frag"  
10:53 - we simply want to return a color, while for 
"outlining.vert" we want to get the position,  
10:58 - and all the uniforms related to transformations, 
plus a new float uniform called outlining,  
11:04 - which we'll multiply with the scale matrix. Now 
back in the main function we'll want to send  
11:09 - that outlining uniform to the shader with a value 
of something like 1.08. Then we simply draw the  
11:16 - same object again, but this time using the other 
shaders. The last step we need to do is to enable  
11:22 - writing to the whole stencil, clear it by always 
passing the test and replacing the values with 0,  
11:28 - and enabling the depth buffer. Now if 
you run the program, you should see  
11:32 - an outline around your object. If your object 
has it's origin at its geometrical center and  
11:38 - if it doesn't have very complex shapes, then the 
outline probably looks fine. In my case though,  
11:44 - you can see that the origin is not at the center 
since the outline is skewed upwards, and that  
11:51 - the shapes are pretty complex, with many curves, 
therefore this method won't work that well.
 
11:57 - A better method that doesn't take much would 
be to import the normals in the vertex shader,  
12:02 - and add those to the position vector, multiplying 
them by the outlining, which we'll remove from the  
12:08 - scale matrix, and which we'll now lower from 
1.08 to 0.08. Now when scaling the vectors,  
12:16 - instead of scaling them from their origin, we 
are sort of scaling them outwardly from the model  
12:23 - using the normal as a reference for what "outward" 
means. This will give you much better results,  
12:29 - with one exception. If you have hard 
edges, then your normals will be close  
12:34 - to perpendicular to one another and so will 
create a little gap when expanding the model.
 
12:40 - Therefore a third solution to this would be to 
simply have another model that's bigger than  
12:45 - the first one. To be more specific, it has to be 
thicker, not necessarily bigger. You can achieve  
12:52 - something like this using Blender's solidify 
modifier. Here you can see I have the initial  
12:57 - model, and the bigger version of it. Now I've 
already exported both as different models, and I  
13:04 - only have to import them into my program like so. 
Then instead of drawing the object a second time,  
13:09 - I simply draw the bigger version of it, this 
time not even needing a uniform to scale it.  
13:15 - And as you can see, this gives the best results, 
though at the cost of doubling the storage cost...  
13:22 - You could of course make a function similar 
to the solidify function that blender has,  
13:27 - but that would be slightly more 
complicated for this tutorial.
 
13:36 - Today I'll show you what face culling 
is, and how it affects performance.  
13:40 - We are also gonna measure this performance 
change by making an FPS counter.
 
13:45 - So face culling is a step in the graphics pipeline 
that decides if a triangle will move on to the  
13:51 - fragment shader (aka, if the triangle will be 
drawn or not). OpenGL decides this by seeing  
13:57 - which side of the triangle is currently facing the 
camera. Generally speaking, in most 3D graphics  
14:02 - programs, it is the front side of a triangle 
that is sent to the fragment shader, and the  
14:06 - back side of a triangle that is discarded. 
The way OpenGL figures out which side is which,  
14:12 - is by an index convention, which can either 
be clockwise, or counter-clockwise. In a  
14:18 - counter-clockwise framework, if the order of the 
indices of a triangle are counter-clockwise when  
14:23 - facing us, then the side we see, is the front 
side. Likewise, if the order of the indices of a  
14:29 - triangle are clockwise when facing us, then the 
side we see, is the back side. For a clockwise  
14:36 - framework it's the exact opposite. Most graphics 
programs use a counter clockwise standard,  
14:41 - but don't expect all of them to use this.
Now in order to put all of this into code,  
14:46 - we just have to enable the face culling 
using glEnable with GL_CULL_FACE,  
14:51 - specify which face we want to keep, 99% of the 
time that will be GL_FRONT, and then specify the  
14:58 - standard we want to use. Again I suggest using 
the counter-clockwise one since from what I've  
15:03 - seen it's more common than the clockwise one.
Now if we run the program, you'll notice that  
15:08 - when we get inside an object, we won't be able 
to see its insides, since it contains the backs  
15:13 - of the triangles, which get discarded. 
Therefore we only see the background.
 
15:18 - So let's see if this makes any difference in 
performance. For that we'll need an FPS counter,  
15:23 - which I'll display in the title of the window. 
Let's start by creating three doubles for  
15:28 - the previous time, the current time, and the 
difference of these two. Then we also want an  
15:33 - unsigned integer that will act as a counter 
to see how many frames we have in a certain  
15:38 - amount of time. Now, FPS, is simply the 
amount of frames you get in a second.  
15:43 - So that means that in order to get the FPS, we 
can count the number of frames we get in a second,  
15:49 - a frame being one loop in our main while loop. 
But that would also mean that our FPS will get  
15:55 - updated only once a second. Instead let's 
update it every 30th of a second for example.
 
16:01 - To do that we just need to get the current time 
in seconds using glfwGetTime, the time difference,  
16:07 - and increment the counter. Then if the difference 
is higher or equal to a 30th of a second,  
16:13 - we go ahead with the measurement of the FPS. 
The FPS will simply be equal to 1 divided by the  
16:19 - time difference, which is the amount of frames 
in a second that this time difference gives,  
16:24 - but the time difference contains multiple frames, 
which are equal to the counter, so we also need to  
16:29 - multiply it with the counter as well. Now we could 
stop here, but it's also useful to know how long  
16:35 - a frame takes in terms of milliseconds. To do 
that we simply divide the time difference by  
16:41 - the counter which gives us the number of seconds 
a frame takes, and then multiply that by 1000 to  
16:46 - transform it into milliseconds. Then we simply 
put together the new title and apply it to the  
16:51 - window using glfwSetWindowTitle. Then we want 
to set the previous time as the current time  
16:57 - in order to get the time difference back 
to 0, and also set the counter to 0.
 
17:02 - Now if you start your program, you'll be able 
to see the amount of frames you have. If they  
17:06 - are stuck on 60, then that means that you have 
VSync on, which tries to keep your FPS constant  
17:12 - to 60 frames per second. If you wish to disable 
this, then write glfwSwapInterval(0) in your  
17:19 - main function. Keep in mind that this will only be 
able to deactivate VSync if VSync is not forced by  
17:25 - your graphics driver. In any case, I recommend 
keeping it at 60 frames per second. But if you  
17:31 - don't want to do that, at least make sure that the 
functions that handle user inputs are put into an  
17:36 - if statement that works periodically like this 
one, otherwise the responsiveness of your inputs  
17:41 - will vary with your FPS, which you do not want.
And just to show you that face culling improves  
17:47 - your FPS, here is a very high resolution model 
and the difference in FPS. The difference is not  
17:53 - big here, but it's noticeable in the numbers. 
When you have multiple models and a lot of  
17:58 - stuff happening, the difference will 
become even more noticeable.
 
18:06 - In this tutorial I'll show you how to 
quickly get transparency turned on,  
18:10 - and also how to make use of the 
blending feature in OpenGL.
 
18:14 - So as you might have noticed, all the textures 
we've been using so far had 4 components: RED,  
18:21 - GREEN, BLUE, and ALPHA (RGBA). The first three 
of those give color to our scene, while the  
18:27 - last one controls the level of transparency 
different objects have. Now if you look at  
18:32 - this grass model I have imported you'll notice 
there is no transparency to it. To enable that  
18:38 - we simply have to create a new fragment shader 
which will be identical to our normal fragment  
18:43 - shader, but we'll check if the alpha value is 
smaller than a certain threshold, and if it is,  
18:50 - we'll discard that fragment. Don't forget to 
also make a new shader program for this new  
18:55 - fragment shader. So if you run the program, you 
should see the grass is now as it should be.
 
19:00 - Now I'll just add a bunch of randomly placed 
transparent windows. Since the code here is not  
19:06 - relevant to OpenGL I won't be explaining it. The 
shader I use for these is a very basic shader that  
19:12 - just displays the textures without any lighting. 
So now as you can see there are a bunch of  
19:19 - WINDOWS, but even though in my texture they 
are see-through, here they are not. In order to  
19:25 - achieve a see-through effect we need blending.
Now for a bit of theory. This is the formula  
19:32 - OpenGL uses for blending different colors 
together. All the C terms stand for Color,  
19:38 - while the T terms stand for transparency. 
Which in case you didn't know or forgot,  
19:44 - an alpha level of 0 is fully transparent and an 
alpha level of 1 is fully opaque. And then the  
19:52 - source color is the color in the fragment shader, 
while the destination color is the color in the  
19:58 - color buffer. These transparencies can have 
different formulas. The most common one is that  
20:03 - in which the source gets its transparency value 
from the alpha part of the source color, while  
20:09 - the destination's transparency is 1 - the alpha 
value of the source. So now let's tell OpenGL we  
20:16 - want to use this configuration using glBlendFunc 
specifying the source and destination functions.  
20:23 - Here is a list of some functions you might want 
to use for one reason or another. Then if you  
20:28 - want to you can also use glBlendEquation with one 
of these arguments in order to specify how you  
20:34 - want the previous colors to interact, basically 
changing the default equation. And lastly you can  
20:40 - use the glBlendFuncSeparate function to choose how 
to interact with the RGB channel, and the alpha  
20:47 - channel for both the source and destination. 
Keep in mind you can't specify a function for  
20:53 - each RGB value, only for all of them together.
At this point we just have to enable blending  
20:59 - using glEnable(GL_BLEND) right before our windows, 
and then disable it right after we are done  
21:06 - drawing them so that we don't accidentally affect 
anything else. You should always do this with  
21:12 - transparent objects. After that just compile and 
you should see that the windows are transparent.  
21:18 - But there is one problem... the blending is all 
messed up. It just doesn't look right. And for  
21:26 - that we have our friend the Depth Buffer to blame. 
Since the windows are drawn in a random order,  
21:32 - windows that are drawn behind already existing 
ones don't get drawn at all since the depth test  
21:39 - fails. So in order to draw all the windows 
we should draw the furthest one first, and  
21:45 - the closest one last. Or you could of course be 
lazy about it and simply disable the depth buffer  
21:51 - when drawing the windows, but that will not work 
in most circumstances, and I would not recommend  
21:57 - it usually. Another option would be to sort the 
windows by their distance from the camera.
 
22:03 - Now sorting has nothing to do with OpenGL, so 
I won't be explaining this part, and I actually  
22:09 - encourage you to come up with your own solution 
for sorting the windows. The important thing  
22:15 - is that I calculate all the distances from one 
window to the camera by subtracting the window  
22:20 - position from the camera position and getting the 
length of that vector. Then based on that length  
22:27 - I sort all my windows from the furthest to the 
closest and draw them. It's that simple! You just  
22:33 - have to be a bit creative with the sorting part 
and how you store your objects. Just keep in mind  
22:39 - that this method where you just draw the objects 
in order is not guaranteed to work 100% of the  
22:45 - time. If different transparent objects intersect 
or do some weird stuff, you will get weird  
22:52 - results. But other methods are pretty complicated 
so for now this will have to do.
 
23:03 - In this tutorial I'll show you how to implement 
a custom framebuffer into your OpenGL application  
23:08 - and how you can use the framebuffer 
to achieve post processing effects.
 
23:13 - So first of all, what is a framebuffer? 
Well you can think of a framebuffer as a  
23:18 - collection of multiple buffers that result 
in the final image you see on your screen.  
23:23 - So it contains a color buffer, a depth buffer, and 
a stencil buffer. Now why would you want to use  
23:29 - one? Well if we create our own framebuffer, 
then we can display it on a rectangle that  
23:35 - covers the whole screen and then using shaders 
modify the pixels displayed on the rectangle  
23:40 - to achieve different effects. This is called 
post-processing because you process the pixels  
23:46 - after all the rendering has already been done.
Ok, now let's implement the framebuffer. Just like  
23:52 - any OpenGL object, we create an unsigned int, we 
generate the framebuffer using glGenFramebuffers,  
23:58 - and we bind it. That was it for the framebuffer. 
Now we need to add a color texture for it to be  
24:04 - of any use. So we'll create a texture just like 
in the textures tutorial, making sure we clamp  
24:10 - the texture to the edges since otherwise certain 
effects will bleed from one side of the screen  
24:16 - to the other due to the default repetition of the 
texture. Then we simply attach the texture to the  
24:21 - framebuffer using glFramebufferTexture2D.
Keep in mind we store our color in a texture,  
24:28 - therefore we can access it from a shader, which we 
want to do. But in the case of the depth buffer,  
24:33 - we don't really care about reading it in a shader 
for this tutorial, so instead of using a texture,  
24:39 - we can use a Render Buffer Object which 
is much faster but has the disadvantage  
24:44 - that you can't read it directly in a shader. We 
create it using glGenRenderbuffers, and then we  
24:50 - configure its storage using glRenderbufferStorage, 
plugging in GL_RENDERBUFFER, GL_DEPTH24_STENCIL8,  
24:58 - and the width and height. We use 
GL_DEPTH24_STENCIL8 so that we can store in it  
25:04 - both the stencil buffer and depth buffer. Also be 
very careful that all the framebuffers components  
25:11 - have the same width and height, otherwise you 
might get an error. Then we just attach it to the  
25:16 - framebuffer using glFramebufferRenderbuffer.
And for a bit of error checking,  
25:22 - just write this. Sadly the errors are not very 
specific, they just give you a number. Here are  
25:28 - the meanings of the errors you can get.
Now that we have the framebuffer object,  
25:33 - we can make our rectangle which will always 
cover the whole screen, and so we don't want to  
25:38 - apply any sort of transformations to it. Now let's 
create two very basic shaders for the framebuffer,  
25:44 - make them into a shader program, and 
then send the unit of our texture,  
25:49 - 0 since it's the only texture in this shader.
Now let's handle the drawing part. First we make  
25:55 - sure to bind the framebuffer before we draw 
anything, including the background. Make  
26:00 - sure your buffers are cleared and that you 
have depth testing enabled after that. Then  
26:05 - after we are done drawing everything in the scene, 
we want to switch back to our default framebuffer  
26:10 - by binding 0, and draw the rectangle which 
displays the framebuffer we've just unbinded.  
26:16 - Just make sure to disable depth testing so that 
the rectangle doesn't fail the depth test.
 
26:21 - Now if you run the program you should be seeing 
whatever you were seeing before without any  
26:26 - difference. If your screen is a flat color, then 
first check that you don't have any errors in  
26:31 - your cmd-like window, then make sure your face 
culling isn't getting rid of the rectangle (so  
26:38 - either change the order of the vertices, or 
disable culling when drawing the rectangle).  
26:44 - For any other errors check the source code 
in the description and look through your  
26:48 - code very carefully, there are a lot of 
things that can go wrong in this case.
 
26:53 - Ok, now let's make this interesting. In 
the framebuffer fragment shader we can do  
26:58 - all kinds of interesting effects. Some easy 
ones would be inversing the colors like so,  
27:03 - or making the image black and white. But these 
are not that interesting. To get more interesting  
27:09 - results, we want to sample multiple pixels when 
we choose the color of a single pixel. For that  
27:15 - we first want to declare an array of vec2s which 
will represent the offset from the pixel we are on  
27:21 - to its 8 neighbours. Notice how I divide 1 by 800 
to get the width and height of one pixel for my  
27:28 - 800 by 800 window. After that we want to create a 
float array which will represent something called  
27:34 - a kernel. It's basically a matrix that helps 
us achieve cool effects by sort of defining how  
27:41 - important each pixel is in relation to the pixel 
we are currently on, that being the one in the  
27:47 - middle. Generally speaking you probably want 
them to be somewhat symmetrical and always add  
27:53 - up to 1. If they add up to more than 1 the final 
color will be brighter, and if they are under 1,  
28:00 - the final color will be darker. Here though they 
add up to 0, but that is intentional since this  
28:06 - is an edge detection kernel and I want everything 
to be really dark, except the edges of things.
 
28:12 - Now all we have to do is to multiply each part of 
the kernel with each pixel at a certain offset and  
28:18 - add up all of them in this vec3 named color. 
Just keep in mind that even though these look  
28:24 - like matrices, we don't actually multiply them the 
same way we do matrices. Then the last step is to  
28:30 - output color as the FragColor, and we're done! 
I think this kernel gives a pretty cool effect.  
28:36 - Here are some other kernels you might want to 
try out. I suggest you just play around with  
28:41 - this a bit and make your own kernels so that 
you get a feeling as to how they work.
 
28:51 - In this tutorial I'll show you 
what cubemaps are in OpenGL,  
28:54 - and how you can use them to create skyboxes.
So what are cubemaps? Well they are simply another  
29:00 - type of texture, which holds 6 2D textures, one 
for each side of a cube. When sampling a cubemap,  
29:07 - you specify a 3D vector instead of a 2D one. 
This allows you to easily sample between  
29:12 - all 6 sides of the cube. And since the coordinates 
of the cube correspond to the sampling vectors,  
29:18 - there is no need for UVs. The most common uses for 
cubemaps are quadsphere texturing and skyboxes.
 
29:25 - So now let's code it in. The first thing you 
need to do is to write out the cube vertices  
29:30 - and indices. Then we'll want to create a VAO, 
VBO, and EBO just like in the first tutorials.
 
29:37 - Now let's create an array with 6 strings that will 
hold the paths to the 6 images we'll be using for  
29:43 - the skybox. Then we want to create the cubemap 
texture itself just like any other texture,  
29:48 - except that where we put GL_TEXTURE_2D 
before, we not put GL_TEXTURE_CUBE_MAP.  
29:55 - Make sure to clamp the texture in all three 
directions since the texture is a cube,  
30:00 - therefore 3D. This clamping should 
prevent any seams from showing up.
 
30:05 - And now we'll go over all six textures and read 
them using the stb library, putting them in the  
30:11 - cube texture once we read them. Notice how I 
disable the vertical flipping. This is because  
30:17 - unlike most textures in OpenGL, cubemaps are 
expected to start in the top left corner,  
30:22 - not the bottom left corner. Also notice how 
I add i to GL_TEXTURE_CUBE_MAP_POSITIVE_X.  
30:29 - This represents the side of the cube 
I am currently assigning a texture to,  
30:34 - and I am adding i to it in order to cycle through 
all the sides. Here is the order of the sides  
30:41 - which you can find in the OpenGL docs, and here is 
the order we wrote the paths in. Notice something  
30:47 - weird? Well, normally in OpenGL, the front is 
in the negative Z direction, but for cubemaps,  
30:55 - the front is in the positive Z direction. That 
means that cubemaps work in a left-handed system,  
31:02 - while most of OpenGL works in a right-handed 
system. This can be very confusing, and I honestly  
31:09 - have no idea why they chose to do this, but oh 
well. Keep in mind you will likely get small  
31:15 - bugs because of this if you are not careful. In my 
case, my right texture kept being displayed upside  
31:22 - down for some reason. To fix that I just flipped 
the texture in an image editor. So be prepared for  
31:29 - this sort of stuff since from what I've heard 
it can happen pretty often with skyboxes.
 
31:35 - Ok, back to the tutorial. We'll now need to 
create two shaders for the skybox. The vertex  
31:41 - shader will take in the coordinates, output 
texture coordinates, and also take in uniforms  
31:46 - for matrix transformations. In the main function 
create a vec4 which holds the final transformed  
31:52 - coordinates. Now since these coordinates are now 
in screen space, we'll do something a bit weird.  
31:58 - Instead of feeding gl_Position the coordinates 
as they are, we'll give it the x, y, w,  
32:04 - and again w components. This will result 
in the z component always being 1 after  
32:10 - the perspective division. And since the depth 
buffer takes the z component as its depth value,  
32:16 - the skybox will always have a depth value of 
1, so the furthest depth value possible, thus  
32:23 - being behind all objects, as it should be. And 
finally we want to export the texture coordinates  
32:29 - as the positions, except we'll flip the z axis 
to combat the coordinate system change.
 
32:35 - For the fragment shader we just want to import the 
texture coordinates, the cubemap, and then set the  
32:41 - fragColor to equal the texture. That's it.
Back in the main function I'll create a shader  
32:46 - program and export the skybox texture unit. 
All that's left now is the drawing part.
 
32:51 - We'll start by setting the depth function 
to GL_LEQUAL instead of the default GL_LESS  
32:57 - since our skybox is right on the edge, aka 1, so 
we need that equal sign. Then we'll activate the  
33:04 - shader and create the view and projection matrices 
which are identical to the ones we created in the  
33:10 - camera class, except for one small detail. For 
the view matrix, we downgrade it to a mat3, and  
33:18 - then we scale it back up to a mat4. This will make 
the last row and column of the matrix equal to 0,  
33:24 - thus having no effect on translations. 
We only want the skybox to rotate,  
33:30 - not move around. Then simply export 
these matrices to the vertex shader.
 
33:34 - Now the final part is to draw the cubemap itself 
just like any other object, except that when  
33:40 - we bind the texture, we use GL_TEXTURE_CUBE_MAP 
instead of the usual GL_TEXTURE_2D. Don't forget  
33:46 - to switch the depth testing to it's default 
GL_LESS after you are done with the skybox.
 
33:52 - If you boot up your program, you should now have 
a nice skybox all around you. If any of the faces  
33:58 - are inverted or something like that, play around 
with the orientation of your images in an image  
34:04 - editor. Trust me, it's a lot easier to just do 
that rather than trying to find a little logic bug  
34:10 - caused by the two different coordinate systems, 
and the different texture reading origins. If you  
34:16 - have seams that are clearly lines, then you can 
try adding glEnable(GL_TEXTURE_CUBE_MAP_SEAMLESS)  
34:23 - somewhere in your code. If your seams are 
not lines, but simply clear differences in  
34:29 - color between one face and another, then you 
probably just have a shitty skybox. If you  
34:34 - can't see anything or only parts of the skybox, 
then you probably have back face culling enabled  
34:41 - and wrote the indices in the wrong 
winding order. Simply disable face  
34:46 - culling when drawing the skybox, or write the 
indices in the correct winding order.
 
34:56 - In this tutorial I will show you what the 
geometry shader is and how you can use it  
35:00 - to create things such as visible normals.
So far we've only used the vertex shader,  
35:06 - and fragment shader, which suffice in most 
situations. But sometimes between the vertex  
35:13 - and fragment shaders you want to have an extra 
step to modify the geometry of your meshes.  
35:19 - Even though it might seem like you can do that 
in the vertex shader, you can only do things to  
35:25 - individual vertices. If you wanted to modify a 
whole triangle, so a group of vertices, then you  
35:31 - would need to use the geometry shader. The second 
advantage of the geometry shader is that it can  
35:37 - switch between different types of primitives, 
and so can create or delete vertices.
 
35:44 - So let's begin by adding the geometry shader to 
our shader class. Notice how I am doing the exact  
35:50 - same thing as for the other two shaders, 
except that I use GL_GEOMETRY_SHADER. Now  
35:56 - that we support custom geometry shaders, let's 
create a geometry shader that does nothing.
 
36:03 - Just like any other shader we'll begin with the 
version. Then we need two layouts written like so.  
36:09 - The first layout signifies what type of primitive 
we receive, which can be one of the following,  
36:15 - while the second layout shows what 
type of primitive we are outputting,  
36:20 - which can be one of the following. In 
this case we want to receive a triangle  
36:24 - and export a triangle. Then we have our outputs to 
the fragment shader. Keep in mind you should pass  
36:31 - data from the vertex shader to the geometry 
shader and then to the fragment shader.
 
36:37 - Now for importing data into the geometry shader, 
we need to do something a bit different. Instead  
36:42 - of simply having an "in", we'll have a sort of C 
structure written out like so. Note that we don't  
36:49 - have to include the position in this because 
it is already built into a default structure  
36:55 - just like this one called gl_in. Now we need to 
go back to the vertex shader and replace all the  
37:01 - outgoing data with the exact same structure except 
for this last part and "out" instead of "in".  
37:08 - Make sure that everything else from the structure 
is identical to its counterpart in the geometry  
37:14 - shader. Notice how I also included the projection 
matrix. That is because we only want to apply the  
37:20 - projection matrix AFTER we modify our geometry. 
Now to assign data to these outgoing values  
37:27 - we simply write the name we gave them plus a dot 
and the name of the variable we want to assign  
37:32 - data to. Very similar to a C or C++ structure.
Now in the geometry shader we have all the data  
37:40 - we need, so all that's left to do 
is to assemble this data together.  
37:44 - To do that we simply assign the position, normal, 
color, and texture coordinates their data. Notice  
37:51 - how here I also have an index besides the name of 
the part of the structure I want to access. That's  
37:57 - because we are in the geometry shader and thus 
we essentially have an array of such structures,  
38:03 - each with different values for a specific vertex. 
Once we are done assigning the values of a vertex,  
38:09 - we must use EmitVertex() to declare that we 
are done with this vertex, VertEx veRTeX veRtEx  
38:14 - vERTeX. Now we can do the same thing for the other 
two vertices, and once we are done with all three  
38:19 - vertices we need for a triangle, we declare that 
our primitive is complete using EndPrimitive().  
38:26 - And that was it for the default geometry 
shader. If you run your program you should  
38:30 - have exactly what you had before, amazing!
But that's really boring, so let's change things  
38:36 - up a bit and make the geometry shader more fun. 
Something that is extremely easy to do is to  
38:41 - calculate the surface normal using a cross product 
and then add that normal to the three positions of  
38:48 - the primitive. This will make your meshes look as 
if all the primitives exploded or glitched out.
 
38:54 - Now let's do something a bit more serious. 
Let's create a new shader which will take our  
38:59 - default vertex shader, a new fragment shader, 
and a new geometry shader. And let's draw our  
39:05 - model using this shader after we draw it using the 
default shader. Now for the fragment shader we'll  
39:11 - simply output a flat color, nothing fancy.
But for the geometry shader, we'll get a triangle,  
39:18 - and output not a triangle, but multiple lines! 
So now we are actually destroying and creating  
39:26 - new geometry since as you can see we'll output 6 
vertices even though we only got 3. Then we'll use  
39:34 - the exact same structure, and in the main function 
we'll simply retrieve the first vertex position  
39:40 - and declare it. But then instead of moving to 
the next vertex, we'll remain on this one but  
39:45 - add to it the normal of the vertex and then emit 
it. This essentially creates a line across the  
39:51 - normal of the vertex. Now we want to do the same 
for the other vertices, but in order to not link  
39:57 - all the lines together we must first end this 
line by using EndPrimitive and then move on.  
40:03 - After doing this for all the vertices we 
can press play and see that we are now able  
40:07 - to visualize all the normals of our model which 
can be pretty useful for debugging purposes.
 
40:13 - Keep in mind that geometry shaders can 
also be very useful for things such as  
40:18 - grass or subdividing models. So they 
are actually pretty interesting.
 
40:28 - In this tutorial I'll show you what Instancing is 
and how you can use it to massively improve the  
40:33 - performance and looks of your OpenGL project.
So instancing is simply a feature that allows you  
40:40 - to draw a mesh multiple times in a single 
draw call. Now why would you want this?  
40:46 - Well consider these scenarios where I have a belt 
of asteroids all made out of a single asteroid  
40:52 - mesh that is deformed in the vertex shader to give 
some variety. In the scenario on the left I simply  
40:58 - have a loop that draws each asteroid individually. 
So that means that each asteroid has a draw call.  
41:05 - Now in the scenario on the right I draw all the 
asteroids together. So that means that I only have  
41:10 - a single draw call. If you look at the performance 
difference, you'll see it is massive.
 
41:16 - Now let's code it in. I'll start with the 
code already written for the first scenario  
41:21 - since it's nothing new for this series. So in 
order to enable instacing, all we have to do  
41:28 - is to use glDrawElementsInstanced instead of 
glDrawElements, and add at the end of it how  
41:35 - many instances of the mesh we want. The only 
problem is that this will draw all the meshes  
41:41 - in the exact same positions, so it is useless.
There are multiple ways you could move each mesh  
41:47 - to a unique position though. You could have code 
that does that in the vertex shader for example.  
41:53 - Using gl_InstanceID you'll get the index of 
the the instance you are currently drawing,  
41:58 - and so you can use that for controlled random 
number generation. Alternatively you could have a  
42:04 - uniform with all the transformations and retrieve 
the correct transformation for a specific instance  
42:10 - using gl_InstanceID. But the problem with this 
is that uniforms can't store that much data. So  
42:16 - the best way to have a lot of transformations and 
not have the generation inside the vertex shader  
42:22 - is to store the transformations inside a vertex 
buffer that is attached to the VAO of the mesh.
 
42:28 - So let's start by creating a VBO constructor 
which takes a vector of mat4s. Then we want  
42:35 - to add an unsigned integer public variable to 
the Mesh class that will signify the amount of  
42:40 - instances we desire. And of course we also need 
to add it to the constructor to easily change it.  
42:47 - Also in the constructor we should add the vector 
of matrix transformations for the instances  
42:53 - so that we can plug it into the vertex buffer. 
Now in the Mesh.cpp file we want to create a VBO  
42:59 - for the instances and then link its attributes to 
the VAO only if we are drawing more than one mesh.  
43:06 - Make sure to link the matrix as 4 different vec4s 
since otherwise your program won't work. And at  
43:13 - the end use glVertexAttribDivisor plugging in the 
layout number of each vec4 and 1. This 1 means  
43:21 - that the vec4 will be used for a whole instance. 
If it were 0, then the vec4 would be used for  
43:28 - a vertex, and then the next vec4 will be used 
for the next vertex, which we for sure don't  
43:34 - want. And just to make it clear, if it were 
2 it would be used for two instances before  
43:40 - switch to the next vec4. Now let's also 
limit the use of glDrawElementsInstanced  
43:45 - only for multiple instances.
For the Model class we need to do the  
43:49 - exact same thing as for the Mesh class where 
we add instanceMatrix to the constructor and  
43:55 - as a variable, and instancing as a 
variable yet again. Now in our loadMesh  
44:00 - function we want to include the instancing and 
instanceMatrix in the Mesh creation process.
 
44:06 - Now we need a slightly modified shader 
for instance drawing to accommodate for  
44:11 - the new layout. So create a new shader program 
specifically for the asteroids using a special  
44:17 - vertex shader and the default fragment shader. 
The vertex shader will be identical to the  
44:23 - default one except we'll have a 5th layout for the 
instanceMatrix, we'll delete the uniforms we don't  
44:29 - need, and replace all transformations with just 
the instanceMatrix one. Don't forget to export the  
44:36 - lighting uniforms in the main function as well.
Then all that's left to do is to merge the  
44:41 - translation, rotation, and scale matrices together 
and add all of them to the instanceMatrix vector.  
44:48 - Then simply add that and the instancing number 
to the Model constructor of the asteroids,  
44:53 - and draw the asteroids once. Remember that 
we only need to call the draw function once.  
45:00 - Now compile and witness thousands upon thousands 
of asteroids with a minimal performance impact. Of  
45:07 - course keep in mind that the performance 
will differ from one GPU to another,  
45:12 - so it might not work as well on yours 
as it would on someone else's.
 
45:21 - In this tutorial I'll show you 
what Anti-Aliasing is and how  
45:25 - you can implement it in your OpenGL project.
So you might have noticed that while horizontal  
45:31 - and vertical edges look extremely crisp, 
diagonal edges tend to look a bit choppy,  
45:38 - like a flight of stairs. This is due to how 
we display images on our screens. Since our  
45:44 - displays are made out of a bunch of tiny squares, 
aka pixels, it is impossible to have a smooth line  
45:51 - on the diagonal. But thankfully, we can 
fake smoothness by bleeding the color of  
45:56 - an edge into the adjacent pixels like so.
Now, these jagged edges are called Aliasing,  
46:03 - and an Anti-Aliasing technique is what helps us 
get better edges. There are multiple techniques  
46:09 - for Anti-Aliasing each with their advantages 
and disadvantages, but today I'll focus on MSAA  
46:17 - which stands for Multi Sampling Anti-Aliasing. 
So what does this Multi Sampling refer too?
 
46:23 - Well in the rasterization part of the pipeline 
primitives are filled in. The way it is decided  
46:30 - which pixels should be given a color and which 
should not, is by checking if the sample point  
46:35 - of a pixel, which is normally in the center of it, 
is inside the shape of the primitive. This means  
46:42 - that if the sample point is even just slightly 
outside the triangle, it won't get sampled,  
46:48 - even though you would think it should at least do 
so partially. Well, that is where MSAA comes in.  
46:55 - As you might have guessed, this technique 
simply adds multiple sampling points so  
46:59 - that a more accurate result can be reached.
Here for example, two out of the 4 sampling points  
47:05 - are inside the triangle, and so the color of that 
pixel will be somewhere between the color of the  
47:11 - background and the color of the primitive.
Now let's actually implement this. Let's start  
47:17 - off by creating a variable where we specify how 
many samples we desire. Now, if you don't have a  
47:23 - framebuffer, then you can just give a window hint 
to GLFW saying you want GLFW_SAMPLES and then the  
47:30 - number of samples you want, and then activate 
GL_MULTISAMPLE. That was it for this tutorial,  
47:36 - as... nah I'm joking. But for real though, if you 
don't have a framebuffer that's all you have to  
47:42 - do, you are done. If you do have a framebuffer, 
then you'll want to delete the GLFW part.  
47:48 - Instead you need to go to your framebuffer 
and replace all GL_TEXTURE_2D with  
47:53 - GL_TEXTURE_2D_MULTISAMPLE. Then replace 
glTexImage2D with glTexImage2DMultisamples,  
48:01 - plugging in the type of texture, the number of 
samples, the color format, the width, the height,  
48:06 - and whether or not you want all samples to be 
in the exact same position in the pixels.
 
48:12 - Then for the renderbuffer object we need 
to change from glRenderbufferStorage  
48:16 - to glRenderbufferStorageMultismaple and 
add the number of samples we want.
 
48:22 - Now the problem is that we can't do any sort 
of post-processing on this framebuffer anymore  
48:27 - since it has multisampling enabled. So to get 
around that we'll need a normal framebuffer  
48:33 - which we can post-process. This is just like 
the one I made in the framebuffer tutorial.
 
48:38 - Now in the main function we want to make 
sure we first bind the multisampling FBO,  
48:43 - clear the screen, clear the buffers, and enable 
depth testing. Then we draw everything we want  
48:49 - to draw. After that we bind the multisampling 
FBO as read only, and the postprocessing FBO as  
48:56 - draw only. Now using glBlitFramebuffer 
we'll resolve all the multisampling and  
49:02 - copy the result onto the post-processing FBO.
Now make sure you bind the default framebuffer  
49:08 - and draw the framebuffer rectangle using the 
postprocessing texture. Run the program and  
49:13 - you'll see that the edges of primitives are 
a lot smoother and nicer. Just be aware that  
49:19 - applying kernels in the post processing will 
essentially overwrite the anti aliasing and so  
49:26 - you may end up with aliasing again. As 
for the number of samples you should use,  
49:31 - I suggest using either 2, 4, or 8. You can 
go up to 16 and 32 on some GPUs but the  
49:38 - improvement/performance ratio is not worth it.
That was it for this tutorial, as always the  
49:45 - source code and all resources used 
are in the description. Bye!