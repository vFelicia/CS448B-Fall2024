00:03 - [Music]
00:21 - hey hello everyone how is it going
00:24 - good
00:25 - what about the party yesterday did you
00:27 - stay long
00:29 - nice that's a good feeling i was about
00:30 - to stay long enough was like nah maybe i
00:33 - need to work on my slide a bit more and
00:35 - maybe i should have stayed longer so
00:37 - we'll see okay
00:39 - so as you have seen um
00:41 - you know this uh title of my talk is
00:44 - about tensorflow and uh
00:46 - i kind of like had a bit of like hard
00:47 - time to see um
00:49 - how deep we are in a topic so um if you
00:52 - can put your hands up
00:54 - how many of you
00:55 - do some machine learning like i don't
00:57 - know from time to time
00:59 - oh that's amazing okay how many of you
01:01 - did some neural networks
01:04 - nice and deep learning
01:07 - cool and tensorflow
01:09 - i like your people okay so since
01:12 - you know depending on the city sometimes
01:14 - background is like a bit harder right uh
01:17 - for instance in munich um i also
01:19 - organize machine learning meetup when we
01:21 - have like a bunch of talks about i don't
01:23 - know all kind of deep learning right and
01:25 - um
01:26 - you know sometimes you know that the
01:28 - city is like a bit more prepared so like
01:30 - a general audience is like a bit
01:32 - um aware of things here i wanted to kind
01:35 - of start with the small things and after
01:37 - i go like deeper and more high level so
01:40 - hopefully even if you i don't know
01:42 - android developer or um like web
01:44 - developer you're not going to be feeling
01:46 - lost it's more like we will get there so
01:48 - we'll start slowly and after i get
01:50 - somewhere else um as you also noticed uh
01:53 - those slides didn't look like super
01:54 - amazing like for instance like pictures
01:56 - like super small you know why because
01:58 - it's in jupiter and there is a real gs
02:00 - that rendering that that also means that
02:02 - uh all the codes that they're going to
02:04 - be showing today and they're going to be
02:05 - a bunch of it
02:06 - you can just download jupiter notebook
02:08 - and just like run through it so um it's
02:10 - kind of excuse for myself like why it
02:12 - doesn't look that amazing
02:14 - yes um
02:16 - i mean uh
02:17 - one of the parts as well that you know
02:19 - people start talking like all this
02:20 - machine learning stuff right and
02:22 - it's all amazing right google changed
02:24 - from mobile first to ai first like and
02:27 - uh sometimes it feels like high pipe
02:29 - hype right and i didn't want to bring
02:31 - like many examples like how you can do
02:33 - like image classification is in this
02:35 - part so
02:36 - since we are talking about hitchhiker
02:38 - guys to the galaxy i brought this like
02:40 - babel fish like who's a wire what is
02:42 - that
02:43 - yes at least a couple of people travel
02:45 - the galaxy so in the original movie
02:47 - right they had this uh small babble fish
02:49 - right that um one of the actors kind of
02:52 - like putting inside of the ear right and
02:54 - this fish is translating to no matter
02:56 - what language you are listening to right
02:58 - into your own language basically right
03:01 - so it sounds pretty cool right you don't
03:02 - need to learn a land which you can go to
03:04 - whatever country and it just like does
03:06 - it for you
03:07 - um turns out uh it's not like you know
03:10 - futuristic and super crazy if you have
03:12 - seen uh you know announcement event from
03:14 - google
03:15 - i don't know maybe a couple of weeks ago
03:17 - they also announced like google pixel um
03:20 - buds right so those like headphones that
03:22 - you can tap on them and they're gonna be
03:24 - doing translation right
03:26 - um and it's kind of like pretty close
03:27 - what battlefish basically does right but
03:30 - you can basically buy it more or less
03:32 - right now and it's already going to be
03:33 - working
03:34 - um what is interesting about that that
03:37 - i don't i don't know i think like a huge
03:38 - percentage of that is basically based on
03:40 - the machine learning and deep learning
03:42 - right um on this case on this picture
03:45 - you can see just like a nice animation
03:46 - how google does uh
03:49 - one shot learning right so they do um
03:52 - like corp they have a corpus like of
03:53 - different languages right and uh
03:55 - essentially they are able to you know
03:57 - like build embeddings that means that uh
03:59 - you know you can uh um
04:02 - if you have different words right and
04:04 - based like how words are used right
04:05 - there is some common sense what they
04:07 - call the distributed presentations right
04:10 - and based on this information if you um
04:12 - give your network like a huge amount of
04:14 - text right you can learn that uh
04:16 - i don't know stage is uh somehow similar
04:19 - uh to the speaker right or clause in the
04:21 - um embedding space and what they also
04:23 - using like for uh translation like as a
04:26 - part of it right um another hand like
04:28 - right now even uh you know uh generating
04:31 - these audio waves is uh also in many
04:34 - cases like way better if you use like
04:37 - deep learning there so there was like an
04:38 - article from apple and this uh one from
04:41 - deepmind and they basically switch it
04:43 - more or less completely right and the
04:45 - sounds uh of you know what google home
04:48 - saying what is uh uh other part of
04:50 - google is saying and most likely this
04:51 - google buzz they sounds also like way
04:54 - better like way realistic right because
04:56 - you don't do concatenation of like
04:57 - smaller pieces but the network does is
04:59 - like end-to-end basically it's a wavenet
05:01 - yes
05:02 - and uh you know when you're starting to
05:04 - talk about all those uh um
05:06 - i don't know like machine learning and
05:07 - deep learning stuff usually you see this
05:10 - picture like how many of you have seen
05:11 - that
05:13 - yeah it's quite many especially at
05:14 - google i o and other place and you know
05:16 - i mean it's cool like it's showing you
05:18 - some information there are some layers
05:20 - right and
05:22 - i know like kind of a structure right
05:23 - and
05:24 - it's magically kind of works right but
05:26 - the problem right that uh sometimes it's
05:29 - kind of like missing all the details
05:30 - right you're like okay i got data i put
05:33 - it inside pom pom and it already works
05:35 - right it always remind me of this like
05:37 - oh how you do that you do circles
05:40 - pom-pom and here we go like he's already
05:41 - oh
05:42 - and what is even more funny and like the
05:44 - same time is like helpful right that
05:47 - many people that i was like meeting like
05:49 - lately right they were like so what they
05:51 - do i do some i don't know data science
05:53 - machine learning is all like oh yeah i
05:54 - can do data science and machine learning
05:56 - like i did a course like on udacity you
05:58 - put data inside bum bum and it already
06:00 - works right and i mean on one hand it's
06:02 - fine right because
06:04 - people feel motivated on the other hand
06:06 - like
06:06 - it's not that easy right otherwise we're
06:08 - not gonna be get paid for that
06:11 - and uh i wanted to go like a bit more in
06:14 - details right but is it gonna be like
06:16 - all this crazy about formulas and uh
06:19 - basically this is a formula uh i think
06:22 - that was for gans right how you can do
06:23 - that um
06:25 - no like i i think it's it doesn't make
06:27 - sense right because i mean we don't have
06:30 - like time for that and uh maybe
06:32 - you know you need like more your own
06:34 - time to digest it and like feel good
06:36 - about that so we kind of like have like
06:38 - a different approach we kind of go
06:40 - through a bunch of like cod samples um
06:42 - trying to you know like show some pain
06:45 - points and from there explain okay why
06:47 - did you do that or like what was
06:49 - happening there um yeah and the some
06:52 - first part is basically
06:54 - um it's just how we do kind of logistic
06:56 - regression just to give you a feeling
06:58 - like what is that about and after we
06:59 - will you know go like deeper a bit um
07:02 - yes
07:03 - if any moment you feel like what's
07:06 - happening just put your hands up and uh
07:09 - i will react on that and uh i don't know
07:11 - we will
07:12 - slow down and maybe do something crazy
07:14 - um okay so
07:16 - i think if you were doing i don't know
07:19 - computer science or um
07:21 - other uh related subjects uh most likely
07:24 - you have heard about logistic regression
07:26 - right and you know already how is it
07:28 - working and uh like have some ideas um
07:30 - it's a very basic and uh super
07:33 - simplified approach that
07:34 - you have some nice
07:36 - kitten right because everybody loves
07:38 - them and you have some
07:40 - you know vectors that you transfer it
07:42 - afterwards right and uh theoretically
07:45 - you can
07:45 - you know learn some kind of like
07:47 - representation that uh you'll be able to
07:50 - you know
07:51 - have some uh um
07:53 - activations or like hot points like on
07:55 - the pictures that will say okay because
07:58 - i'm getting you know positive values
08:00 - here right and negative like somewhere
08:02 - else right i can uh basically detect
08:04 - that it looks like cat like in that
08:05 - direction right and uh because we don't
08:08 - want to do it uh super simple we can
08:10 - also add some non-linearity right that
08:12 - in future we can
08:14 - use it for something more complicated
08:15 - right
08:16 - and i mean there's like a bunch of
08:18 - formulas how you can uh you know in
08:20 - terms of like mathematics define it
08:22 - right and um
08:24 - yeah so you can uh define your functions
08:27 - that is uh based on uh your weights
08:29 - right your input vector or some bias you
08:31 - can uh uh add some activation on top of
08:33 - it and uh you can have some loss
08:35 - function right so you can understand how
08:38 - bad you are right and
08:40 - on top of it you can have like a cost
08:41 - functions that you're trying to minimize
08:42 - right
08:45 - next one um yeah but
08:47 - you know
08:48 - if you have this part you still need to
08:50 - learn like what weights are coming from
08:52 - right and i'm not really going like that
08:54 - much deep in details because i think um
08:57 - it might be like a good topic to talk
08:58 - about but you can also like easily
09:00 - google how exactly back propagation
09:02 - works but ideas that um you know you
09:04 - have
09:05 - the way how you compute your cost
09:07 - function right and you can understand uh
09:09 - how to take like derivative of that so
09:11 - you know okay what smaller pieces you're
09:13 - taking from there and uh um
09:16 - if you will have like a small uh
09:18 - implementation in i don't know like a
09:20 - numpy for instance um
09:22 - it's not going to be like super
09:23 - complicated right in that direction so
09:25 - uh the formulas that you have seen
09:27 - before like it just
09:28 - goes like in the presentation of a numpy
09:31 - right and
09:32 - um once you analytically compute like
09:35 - derivatives you can also like measure
09:37 - how much they're coming from right and
09:39 - um when you do like in direction of
09:41 - optimization right what you do is
09:43 - basically um you compute your gradients
09:45 - right you know that okay you have some
09:48 - learning rate how much we kind of like
09:49 - going deeper and uh like how fast we are
09:53 - um but overall it's about you know step
09:55 - by step trying to adjust like your
09:57 - weights and the like biases in the
09:59 - direction
10:01 - and i mean okay it's not that hard right
10:04 - you can also um you got this working you
10:06 - got like your weights and after you
10:08 - basically compute the same functions
10:09 - that you had even before right and uh
10:12 - yeah
10:14 - sounds good in that direction right and
10:15 - i mean i'm not focusing that much on
10:17 - those slides because they still gonna be
10:18 - like available online and i better spend
10:21 - a bit more time like this uh tensorflow
10:23 - it's just like to show you how that you
10:25 - know
10:26 - it's not like totally crazy
10:28 - um yeah and uh essentially your model is
10:31 - basically um what it does like it
10:34 - initializes those like waste and biases
10:36 - right you do some optimization steps
10:38 - that you showed before and um when it's
10:41 - uh get like into proximity of your good
10:43 - parameters you say like okay we get from
10:45 - there um you know it's kind of like
10:48 - taking some time and uh depending like
10:51 - on uh structure because we had just
10:53 - logistic regression right it's pretty
10:54 - straightforward but if you go to like a
10:56 - deeper um like
10:58 - i don't know you could do like a
10:59 - multi-layer perceptron even um it's
11:01 - getting more complicated because you
11:03 - still need to um do some gradient
11:05 - checking now like other techniques that
11:07 - help you to understand that your
11:09 - implementation is still working right
11:11 - and i mean um especially right now
11:13 - there's like a bunch of companies that
11:15 - uh um do all those like frameworks for
11:18 - neural networks
11:21 - and i mean
11:22 - sometimes i have a feeling that um you
11:25 - know everybody wants to invent their own
11:26 - right there's like amazon there's uh
11:28 - google there's uh facebook with cafe too
11:31 - and stuff like that but today we're
11:32 - gonna be talking more about tensorflow
11:34 - right
11:35 - so tensorflow is kind of uh like a big
11:37 - animal right um
11:39 - it has many things that not really super
11:41 - visible for us like for instance
11:43 - all this uh super useful but uh
11:46 - not super you know
11:48 - applicable by like big percentage of
11:50 - people is uh execution engine right that
11:52 - knows like okay how do i work like with
11:54 - your symbolic graphs like how do i
11:56 - schedule them how like what to do with
11:58 - that right
11:59 - and plus some like
12:01 - uh optimizations as well that
12:03 - can run your vector operations like even
12:05 - faster on the all kind of hardware right
12:07 - so you don't need to think like okay i
12:10 - implemented like a numpy now i need to
12:13 - use like uh i think it's called like
12:14 - scipy there's a python package that you
12:16 - can
12:17 - not like sci-fi but to cooper
12:20 - that can run it like on a good
12:21 - architecture but uh
12:23 - in this case uh um tensorflow is kind of
12:25 - like taking care of all those things and
12:27 - even if it's like tpu you don't need to
12:28 - like you know implement the stuff like
12:30 - on your own um on top of it there is
12:32 - like a front end right like that it
12:34 - gives you ability to write some python
12:36 - stuff and
12:37 - um even on top of it there is also like
12:40 - layers that
12:41 - give some you know a structure that you
12:43 - need to re-implement it
12:45 - uh lately they also release like data
12:47 - sets that help you to you know like
12:50 - since you already have um gpus right for
12:53 - like fast learning but in many cases
12:55 - like pre-processing the data is like
12:57 - getting like a bottleneck and say trying
12:59 - to build like a good uh wrapper on that
13:01 - to make it even faster um and on top of
13:04 - it there is like a keras that is also
13:06 - going to cover in the talks that gives
13:08 - like even higher level obstructions
13:09 - there
13:10 - and what is kind of relatively new is
13:12 - like kent estimators if you use
13:15 - a skylarkit or psychic learn
13:17 - it's kind of in a very similar format
13:19 - you can just create like dnn and
13:22 - say fit and it's like kind of magically
13:24 - works so um theoretically you can also
13:26 - use that but practically it feels like
13:29 - more that you know you're working on
13:30 - that if you're like defining something
13:32 - like customize and architecture-wise is
13:34 - also more helpful um
13:37 - if you give like a bit of concepts
13:39 - introduction right um
13:41 - so there is like tensorflow as a word
13:44 - right like it has like two different
13:45 - parts like one is like tensor and
13:47 - another one is flow right quite obvious
13:50 - obviously but uh so if you're talking
13:52 - about tensors right um
13:54 - so it's like two diff like different
13:56 - pieces right in mathematics there is a
13:57 - different definition of tensors um but
14:00 - in tensorflow world is basically you can
14:03 - define um you know different uh ways of
14:05 - i don't know in this case like constant
14:07 - right but multiplication is also going
14:09 - to be like a part of this operation or
14:11 - like in this case if you print it right
14:13 - first is going to be tensor
14:16 - oh sorry
14:17 - but the result is also tensor right so
14:20 - you can define your graph basically in
14:21 - those like tensors
14:23 - what is also interesting right that you
14:25 - know if you do like this multiplication
14:27 - here and we print result at the end of
14:30 - the day it doesn't really show us result
14:32 - right like why is it happening because
14:34 - all the concepts that uh you know
14:36 - tensorflow and this like scheduling
14:37 - engine it does it later so it's like
14:40 - lazy uh evaluation and um you know like
14:43 - it still can do some crazy stuff like
14:45 - how to optimize it because i mean for
14:46 - this case there is nothing to optimize
14:48 - but in general case there is something
14:50 - more advanced for that if you have like
14:52 - uh deep network but what uh is kind of
14:55 - essential for that that uh once you have
14:57 - tensorflow session right you can say
14:59 - okay there's a um you know this
15:01 - operation set or tensors that uh i would
15:04 - like to execute right and when you do
15:06 - session run it's kind of okay does some
15:08 - scheduling some magic in the background
15:11 - and only after it does evaluation and
15:13 - execution of this lazy formula that you
15:15 - had right
15:17 - and what you can do is basically it's
15:20 - kind of like a hacky way and not super
15:21 - visible right now but
15:23 - wait a second
15:24 - so once you define it like in the
15:26 - current scope of your script or jupyter
15:28 - notebook right you can also use a
15:31 - jupyter uh sorry with a tensorboard you
15:33 - can try to visualize it and since since
15:36 - this one isn't like sliding betting not
15:37 - really good we have this one that
15:39 - basically shows that uh for the
15:41 - operation that we were showing right
15:42 - it's going to have the graph like that
15:44 - right and um if you were surprised that
15:46 - this like multiplication doesn't look
15:48 - very you know comfortable for you you
15:50 - can still use like a different sign like
15:53 - depending like on what kind of
15:54 - multiplication you have um yeah but
15:56 - basically you have session session
15:58 - basically based on what um back-end
16:01 - you're using and uh like where to
16:03 - execute those things
16:04 - yes um what is kind of essential for
16:07 - that is also being able to you know pass
16:09 - some variables so like in this case we
16:11 - are saying that okay i'm creating like a
16:13 - placeholder right for x with um yeah
16:17 - some information that i'm going to be
16:18 - using afterwards and
16:21 - you can afterwards pass it inside of
16:24 - uh your session so that's how you're
16:26 - also going to be um like learning your
16:28 - models
16:30 - um yeah if we
16:32 - uh you know like go in direction uh of
16:35 - initializing parameters right because
16:36 - it's what we usually do in the beginning
16:39 - um
16:40 - it's where tensorflow is kind of like
16:42 - getting verbose right because every time
16:44 - when you okay i'm defining like a
16:46 - variable for my ways right and it's not
16:48 - like
16:49 - how you would do in production system
16:51 - but it's more like a visible like what's
16:52 - happening there right and uh
16:55 - when you're defining that you will also
16:57 - say okay like what is the shape of
17:00 - this part right and um
17:02 - in many cases like you need to okay sit
17:06 - and like understand what you're going to
17:07 - be doing there um but you know there's
17:09 - like some complexity with this part is
17:11 - happening and i will mention it like a
17:12 - bit later like why is it important um
17:15 - yeah and there's also like some fancy
17:16 - way like how you can do like proper
17:18 - initialization like this uh like uh
17:21 - javier utilization for instance and
17:22 - stuff like that but uh what i would like
17:25 - you to just like see that uh okay we
17:27 - initializing parameters and uh you need
17:29 - to know like uh shapes of the layers
17:31 - what you're going to be using right
17:33 - and when you were talking about uh you
17:35 - know um there's like a loss function
17:37 - like and how we evaluate all those
17:39 - things right before we were like
17:41 - implementing like our own right and uh
17:43 - depending like okay is it um what kind
17:45 - of classification is it like multi-label
17:47 - right you still need to do like your own
17:49 - uh jobs there right um with that case
17:52 - like you know because tensorflow is
17:54 - already like a framework right they
17:55 - already have all things like in place um
17:58 - and it's also kind of like just going
18:00 - like a bit ahead uh sometimes in keras
18:03 - you like missing some parts that uh um
18:06 - what they call like or um
18:09 - i can curse it's like a low level but uh
18:11 - even though for multi-level
18:12 - classification we have some issues that
18:14 - we need to like implement stuff um yeah
18:16 - but back to um
18:18 - this part so you can basically just use
18:20 - uh cross-entropy with sludges and in
18:23 - your code is basically gonna be pretty
18:25 - straightforward right you're getting um
18:28 - you know your labels your lodges and
18:30 - after you can just uh pass it like as a
18:32 - convention um
18:34 - yeah
18:35 - so it doesn't really go like super crazy
18:36 - right um we still you know like in
18:39 - original uh
18:41 - uh part with logistic regression we had
18:43 - some forward propagation and uh um
18:46 - that's basically what we have here right
18:48 - um we have like a separate uh uh you
18:50 - know the parts that has like our
18:52 - parameters right that you wanna pass on
18:54 - like if you do like inside of the batch
18:56 - but basically um what you do is pretty
18:59 - similar what you did like in numpy
19:00 - beforehand right
19:02 - just like it's different prefix
19:04 - um yeah and they already have like all
19:06 - kind of like activations like relu or
19:08 - leaky will lose that kind of like a part
19:10 - of the story for you
19:12 - um yeah if you feel like that you know
19:14 - you don't really know like what
19:16 - directions we should be like is it relu
19:18 - like or sigmoid or why are we talking
19:19 - about those things just like catch me
19:21 - afterwards and we can have like a long
19:22 - discussion like how
19:24 - i know things are helpful like for um
19:27 - you know gradient vanishing like an
19:29 - explosion like afterwards but i'm afraid
19:31 - that here on the stage you just like
19:33 - take it as a given and after you can
19:35 - always go deeper and see like why i
19:37 - don't know i'm using relu and uh um not
19:40 - uh like proper sigmoid here um but uh i
19:43 - wouldn't go like that much in details
19:46 - yes and after if you you know like um
19:49 - defining kind of uh the model like in
19:52 - tensorflow way right um besides like
19:54 - having the bullet plates that we kind of
19:57 - do some reshaping part right um
20:00 - we have like a placeholder like
20:01 - parameters that we showed before right
20:03 - but
20:04 - essentially it's pretty similar right
20:06 - you have like a forward propagation uh
20:08 - what you did before right you were like
20:11 - uh analytically computing like your
20:13 - gradient right and after trying to like
20:15 - implement it um what tensorflow gives
20:18 - you is they have like a set of like
20:20 - optimizers right that
20:21 - depending like okay is it going to be uh
20:24 - granny and descend or stochastic
20:25 - gradient descent or the one is momentum
20:28 - right um
20:29 - just like to you know for those of you
20:31 - who are not familiar with that just
20:33 - depending like how you you know you have
20:35 - a function that you're trying to find uh
20:37 - i don't know like maximum or minimum
20:39 - basically what you're optimizing for
20:41 - there's like a different uh um numerical
20:43 - way to do that and uh there are like a
20:45 - different behavioral things right so for
20:48 - instance um like adam might be do some
20:51 - adaptive stuff that this more
20:52 - sophisticated than just using like
20:54 - stochastic gradient descent um but
20:56 - there's somebody who just want to play
20:58 - around with that you just can you know
21:00 - like use
21:01 - like item optimizers like one of default
21:03 - ones and uh just get it from there and
21:05 - what you can do afterwards is okay
21:06 - you're providing like a learning rate
21:08 - and you can say like minimize my cost to
21:10 - define beforehand right
21:12 - and even if you remember like cost
21:14 - function was
21:15 - not that
21:17 - complicated to define right so it's just
21:18 - like a sigmoid cross entropy
21:23 - right now it's like a bit complicated
21:24 - but after we will like switch into keras
21:27 - when it's going to be like way simpler
21:28 - just like to show you also like a part
21:30 - of complexity
21:31 - um yeah and what you could do afterwards
21:34 - you have your sessions that you are
21:36 - running right um here they kind of like
21:38 - do some um
21:40 - like mini batch part but basically ideas
21:42 - that you have like a session that you're
21:43 - running with your uh optimizer and like
21:46 - cost right and uh um yeah essentially it
21:49 - just uh uh
21:51 - if you run this model it's going to be
21:53 - showing like okay like after every epoch
21:55 - and how is your loss is basically
21:58 - changing so it goes pretty far pretty
22:00 - good right
22:01 - and again um i'm gonna share uh jupyter
22:05 - notebook afterwards so you can like
22:06 - click those things and try to change the
22:08 - parameters and
22:09 - make them available
22:11 - yes um
22:13 - okay so we can write those things right
22:15 - but one of the problems why the things
22:17 - was not taking off is like neural
22:19 - networks right i mean they're like
22:20 - multiple theoretical things right that
22:22 - you are not able to train them deep
22:24 - enough right but another problem
22:26 - resources right i remember like back in
22:28 - i don't know 2007 i believe like when
22:31 - you're like using some neural networks
22:33 - for um like as a kind of a student
22:35 - project thing for uh
22:37 - i i think like detecting some faces and
22:40 - like classifying like other things right
22:42 - we had like a separate machine that was
22:43 - running like for quite some days and it
22:45 - was like training on like on its own
22:47 - right
22:48 - and uh you know it was like machined
22:50 - with cpu right so it's like gonna be
22:52 - like super slow but the problem is that
22:54 - as you know human individuals right or
22:57 - like your personal project hobby one
22:59 - it's like take some time right to train
23:01 - those things
23:02 - um hopefully for us like there are like
23:04 - a bunch of uh
23:06 - cool companies that invest in like a
23:07 - good amount of resources that make it
23:09 - available
23:10 - and they're also working like on
23:12 - building like a cool architecture so
23:13 - like in this case it's inception model
23:15 - from google and uh um you can like
23:18 - download already pre-trained models like
23:21 - you think like okay we say train for
23:23 - some cases right
23:24 - um but turns out that if you haven't
23:26 - just like like the players right um
23:29 - after having like a bunch of you know
23:31 - you have like a bunch of classes right
23:33 - and in this case i think they use like
23:35 - uh um in some cases like it's google net
23:37 - uh coolness sorry imagenet uh like data
23:40 - set with like hundred thousands of
23:41 - images google has their own data set but
23:44 - basically they learning you know to um
23:47 - uh understand like to classify different
23:49 - classes right and meanwhile network uh
23:52 - also learns different representations
23:53 - right so if before you were coming from
23:56 - computer vision background and you're
23:57 - gonna use like uh sift or serve feature
24:00 - descriptors right now you can just use
24:03 - uh one of those like networks and get
24:05 - depending like what uh you know like
24:07 - level of presentation already for you
24:08 - and you can do like crazy stuff that i
24:10 - will show in a second
24:11 - um and i mean there are like a bunch of
24:13 - like a different
24:14 - uh you know
24:15 - network architectures and they already
24:17 - pre-trained one of more famous one is
24:19 - like vgg16 and it's like also super old
24:22 - uh what i want to show like on this uh
24:24 - graph is basically uh especially if you
24:26 - want to port it like for mobile or like
24:28 - some low-level uh hardware and if you
24:31 - want to you know optimize for inference
24:33 - um you will see that you know like on
24:35 - one access you will see like number of
24:37 - operations so like how much you know
24:39 - time it takes and also uh resources and
24:42 - another one like accuracy right and uh
24:45 - turns out not the most you know like
24:46 - number of operations are getting like
24:48 - the highest accuracy right so uh
24:50 - sometimes you can pick up like us
24:52 - inception v3 that uh relatively or like
24:54 - resnet from microsoft that uh like in
24:57 - terms of operations it's like pretty low
24:59 - right but in terms of accuracy is pretty
25:01 - high so just like keep in mind that uh
25:03 - you know there is like a good uh
25:05 - comparisons of things and uh i mean
25:07 - which g16 is cool but there's like other
25:09 - free train network that you can be using
25:11 - and there's also like a nice paper on
25:14 - archive basically that you can read on
25:15 - those things
25:16 - yes um okay so imagine that google
25:20 - trains this network for you right can we
25:22 - make it easier and like use it for
25:24 - something from us right so in many cases
25:26 - they uh sharing their models like in the
25:29 - protobuffer definition um and you can
25:31 - just like load it as as we do like in
25:33 - this case right so uh you can define
25:35 - like a graph definition and you can like
25:37 - read a file but basically essentially um
25:40 - yeah if you load it again like it's
25:42 - tensorboard visualizations that shows
25:44 - you
25:44 - um how simplified it looks like if you
25:46 - click on those blocks they're actually
25:48 - going to be extending so it's going to
25:49 - be as original image
25:51 - inception model um but basically you get
25:54 - the thing is running right so
25:56 - we got the model right like and uh what
25:59 - we can do afterwards is just basically
26:01 - um
26:02 - if you know like you define uh your
26:04 - network right usually uh you will have a
26:07 - um okay just like different layers right
26:09 - if you're familiar with topic there's
26:11 - some convolution layers that also um
26:14 - take into account not only the value of
26:16 - the point right but also um you know
26:19 - proximity so you're basically having
26:20 - like a bigger high level features um but
26:23 - usually if it's you know like multiple
26:26 - classes and zen zones a day you're gonna
26:27 - use like soft max right as a like last
26:29 - layer
26:30 - and what's happening here right that
26:32 - before soft max you're gonna have some i
26:34 - don't know fully connected layer just to
26:36 - like learn some things there um and
26:39 - maybe some pulling like on top of it um
26:41 - and what you can do is basically use
26:43 - this information like as a feature
26:44 - descriptor right and in this case like
26:46 - i'm taking uh i don't know i think like
26:48 - one of these intro pictures actually um
26:51 - and uh passing like inside and i will
26:53 - get like a vector of uh
26:56 - i think like 2048 or something if i'm
26:59 - not wrong but basically this um
27:02 - a bunch of digits here is going to be
27:04 - like a really good
27:05 - feature descriptor for you so you can
27:07 - easily uh implement uh you know like if
27:10 - you again like go to tensorboard and you
27:12 - show some
27:13 - uh
27:14 - i think in this case it's like pca but
27:15 - you can also do like a disney it's just
27:17 - like a way how you can put like a
27:19 - multi-dimensional data like in three
27:21 - dimension in this case but basically you
27:23 - will see that you know images that uh
27:25 - kind of look alike right will have like
27:27 - a similar image vectors right so you can
27:30 - easily implement the image similarity
27:32 - without i don't know spending much time
27:34 - so i've been at this like hackathon in
27:37 - zurich like months ago right and we had
27:39 - like one of projects that we wanted to
27:40 - add like image similarity and it took us
27:43 - like there was like one girl who was
27:44 - doing uh i think like data science at
27:46 - yandex and she was like are going to be
27:48 - using like surf and shift and i was like
27:50 - okay and meanwhile i will try to use
27:52 - some feature description from inception
27:54 - and uh it was like way faster on my side
27:56 - because you know like with all this like
27:57 - opencv stuff that takes some time it
27:59 - didn't really help that much
28:01 - yeah
28:02 - and if you go like more in production
28:04 - direction with all this like image
28:05 - similarity there's a library called uh
28:08 - like annoy like very nice name but it's
28:11 - basically built by spotify and they do
28:12 - like approximate nearest neighbor
28:15 - oh yeah like cisco how they call library
28:17 - but the basic idea is that once you have
28:19 - those you know um
28:22 - feature representations of your images
28:24 - right you can have some um approximate
28:27 - like neighborhoods right and it's super
28:29 - fast basically to
28:30 - say like okay i have this image that
28:32 - like belongs somewhere here right give
28:35 - me like a neighborhood of images that
28:37 - look look alike right so you don't need
28:38 - to do like some k n um but you can just
28:41 - like extract it from this index so if
28:43 - you do it in production it's like super
28:44 - cool project
28:46 - all those are like a couple of tricks so
28:47 - if you're going to be using this just
28:48 - like ask me or i don't know like ping me
28:51 - i will tell you that
28:52 - um yeah so
28:54 - you know you have seen that it's getting
28:55 - easier right you don't need to implement
28:57 - stuff but it's still pretty robust right
28:59 - there's like much things happening uh
29:01 - fortunately for us uh yeah there was
29:03 - like this library keras right um and uh
29:06 - they make it even better so they like
29:09 - wrap up things like together and um they
29:12 - also like add some um you know like
29:14 - proper way to like handle you know the
29:17 - ways that you need to think that you
29:19 - need to implement tensorflow on your own
29:20 - but basically if you're building like a
29:22 - simple model is as simple as it is right
29:24 - you have like a layers um yeah that like
29:27 - could be convolutions like or max
29:28 - pooling or whatever else like you can
29:30 - you know i can uh tell you afterwards
29:32 - but basically what you have afterwards
29:34 - you have a model and you adding like all
29:36 - the layers like in between so you do
29:38 - need to think like okay what is uh a
29:40 - shape of the layer before like how do i
29:42 - connect them together it's like you're
29:44 - focusing on like more important parts
29:46 - than just like thinking about shapes so
29:49 - it's pretty good right and uh yeah you
29:51 - can also do like a pretty
29:54 - second learn approach of uh you know
29:56 - model fit with like all your data and uh
29:59 - it's pretty
30:00 - good yeah and after if you want to go
30:02 - more in details you can also do like a
30:04 - model summary that shows you okay what
30:06 - layers you're having like number of
30:08 - parameters if you want to like decrease
30:10 - number of parameters because you wanna i
30:11 - don't know move uh to like smaller
30:13 - device and you wanna replace some fully
30:15 - connected layers with convolution and
30:17 - stuff like that
30:18 - yeah and if you do like evaluation it's
30:20 - basically also pretty simple afterwards
30:22 - right
30:23 - um what you can do afterwards is also
30:25 - like saving this stuff so you know like
30:27 - once you train it you can get it yet in
30:30 - different format for keras here but
30:31 - basically um yeah it will generate you
30:34 - like uh one is uh like a graph
30:36 - definition and another one ways
30:37 - basically that you can easily load
30:39 - afterwards
30:41 - um
30:42 - yeah and it's like a way how you can
30:44 - load the stuff um and uh there was
30:46 - examples that i trained like on a news
30:48 - data set and uh
30:50 - yeah it was like at the end of the day
30:52 - if you um
30:54 - you have like original image and you can
30:56 - uh yeah model predict that gets your
30:59 - like image and you can reshape to the
31:01 - proper shape but basically it will show
31:03 - you that okay
31:05 - it's like fours basically class that has
31:07 - it so it's basically look like four
31:10 - um yeah and uh if it was not simple
31:13 - right you can make it even simpler so
31:14 - like keras in this case they have
31:16 - already like applications and like in
31:18 - this case it's deception victory right
31:21 - and from there you can just uh define it
31:24 - and uh you know like you can say like
31:26 - weights are coming from image snare
31:27 - drive and uh um yeah and you can have
31:30 - like a graph already like working here
31:32 - right
31:33 - and uh yeah if you have the graph and
31:36 - you can load it you can just use a
31:37 - prediction from there
31:39 - um and this example that we had this uh
31:42 - image and uh depending like on you know
31:45 - uh um
31:47 - classes that the imagenet already having
31:49 - it's gonna be good but what you can do
31:51 - is basically um freeze like entire
31:54 - architecture besides the last layer and
31:56 - it will um like retrain not entire
31:58 - network because it can screw up the ways
32:00 - but only like your parts that you know
32:02 - it's using like a feature
32:04 - representations and like mapping a
32:05 - feature representation to your own
32:06 - classes you can go like even as far as
32:09 - uh using like one shot learning as uh
32:12 - you know like having like very few
32:13 - images that you can train on top of it
32:15 - um
32:16 - yes
32:18 - and uh you know it's already given like
32:20 - a pretty good idea that if you really
32:22 - want to use it you don't need to you
32:24 - know like know all the details it's like
32:26 - a similar direction of you know as i was
32:28 - saying if you want to drive a car right
32:30 - you don't need to know how exactly your
32:32 - engine works right you can just be like
32:34 - studying the wheel and like making it
32:35 - working and it's basically what's
32:37 - happening with like many deep learning
32:38 - models right if you know like a couple
32:40 - concepts right how you get like image
32:42 - features right you can always like build
32:44 - on top of it so it's kind of a lego game
32:46 - right and one of examples is like image
32:48 - captioning i didn't really bring the
32:50 - code inside but uh i can share with you
32:52 - if you interested
32:54 - but ideas there is that you also have
32:55 - image right you have like some
32:57 - convolutional parts that might be based
32:59 - like or i know like one of well-known
33:01 - networks right and after you do some
33:03 - like uh um
33:05 - iron and part right that can also maps
33:08 - the part of the words that you are
33:09 - saying right and uh if you have like
33:11 - once a data set right you can say okay
33:14 - this image as a data set has some
33:15 - descriptions that i don't know like uh
33:17 - um
33:19 - this like fly or broad display
33:21 - um and after a network you will learn it
33:24 - right so it's pretty good and you can go
33:25 - like that crazy as you know like even
33:28 - combining like more advanced right you
33:30 - know you're getting like uh questions
33:32 - that you know goes through some lstm
33:34 - right um
33:36 - yeah and uh after you have the same like
33:39 - feature descriptors and after um if you
33:41 - don't use like sequential model but
33:43 - basically functional approach for keras
33:45 - you can just join it in the same model
33:46 - so it's more about data that you're
33:48 - having but uh your tool set is basically
33:50 - staying the same
33:52 - yeah and in terms of deployment since uh
33:55 - you know it was
33:56 - pretty fast and i think like many of you
33:58 - is like what's happening i need to check
34:00 - jupiter afterwards um there's like many
34:02 - ways to do that right like one is a way
34:04 - is your own kind of way and uh you have
34:07 - like tensorflow servings that optimize
34:10 - for you have your model and can run it
34:12 - like in the background and uh
34:14 - it has you can use like nvidia docker
34:16 - and some kubernetes that you already
34:18 - most likely see and talk about that but
34:20 - basically you will have your own
34:21 - infrastructure like on gpus that shows
34:24 - those things yeah
34:25 - um and for android people of you and
34:28 - even android things of you um there is
34:31 - also like a version of tensorflow right
34:34 - that you can train on your um like a
34:36 - separate cluster for instance and after
34:38 - just saves the weights um but
34:40 - essentially what you would do is you
34:42 - have like a grading dependency right and
34:45 - you will you know basically uh define
34:48 - like uh um
34:51 - yes it's a part like where your
34:53 - protobuffer model is lies right so you
34:55 - can put it into your resources and um
34:59 - oops
35:01 - um you can also define where you're
35:03 - fitting it so like all those network
35:04 - architecture right they have like a
35:06 - specific names right so you can say okay
35:09 - feed it in direction of like input right
35:11 - and give me results like of output right
35:13 - in this case we don't really use like a
35:15 - feature presentation but we use it like
35:17 - original glasses and uh um yeah and it
35:19 - will get you pretty much working um
35:23 - and uh yeah in this case you can run the
35:25 - same one for android or like a small
35:29 - android things device uh the only thing
35:31 - that i also don't cover here is like how
35:34 - to optimize it right um because if you
35:37 - optimize for inference on mobile phones
35:38 - there is like a bunch of like other
35:40 - steps it might be doing like reducing um
35:44 - um like you know like how many bits you
35:46 - are storing like per weights right
35:47 - because sometimes it's like
35:48 - representation is pretty high sometimes
35:50 - you can also be more efficient on uh um
35:53 - archiving those models so um you can
35:55 - easily you know like decrease the weight
35:57 - of the models that you saving like by a
35:59 - factor of like 20 i believe um so if you
36:02 - um like interested about this part being
36:05 - me on twitter like i should have like a
36:06 - slide from munich when i was talking
36:07 - about uh doing deployments like for
36:09 - android
36:10 - but overall it's basically um it's
36:13 - pretty straightforward um so what i
36:15 - wanted basically to say here is uh
36:17 - you know there are like many different
36:19 - pieces right you can go like pretty low
36:21 - level you can go like pretty high level
36:23 - right um but it's like your own choice
36:26 - right if you want you can go pretty high
36:28 - level with keras with some free training
36:30 - models and
36:31 - get results like in a matter of hours so
36:34 - don't be afraid of like trying that and
36:36 - you can always go deeper right then be
36:38 - you know like scared of that okay i need
36:40 - to do like you know all those like
36:42 - derivatives like partial derivatives and
36:44 - uh no like bunch of mathematics it's not
36:47 - that much of rocket science like you can
36:48 - always go on that level but for the
36:51 - beginning you can just do like clicky
36:53 - clicky stuff like combining models and
36:55 - it still looks pretty cool like if it's
36:56 - really working for you so
36:58 - um yeah like there was
37:00 - lots of pieces kind of missing and it's
37:03 - like was pretty fast but i hope it's
37:05 - kind of like give you like a road map
37:07 - right and um like a guide basically
37:10 - right what things are there and uh if
37:12 - you have particular questions on like
37:14 - similar topics just like catch me up and
37:16 - we can talk about all cool for
37:18 - cool cans like for one megapixel and
37:20 - stuff like that
37:21 - yeah with that i finished my talk please
37:23 - thank you
37:24 - [Applause]
37:27 - [Music]