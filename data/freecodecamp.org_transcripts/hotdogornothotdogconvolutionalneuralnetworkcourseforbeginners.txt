00:00 - Is this a hot dog? Or not a hot dog? What about this one?
00:04 - In this course, you will learn about convolutional neural networks.
00:07 - These are a class of deep learning neural networks that are particularly effective for
00:12 - classifying images. CNNs are also used for other applications such as natural language
00:18 - processing and time series forecasting, but they're most commonly associated with image processing.
00:24 - Kylie Ying teaches this course. Kylie is a software engineer and she is passionate
00:28 - about machine learning and artificial intelligence. So let's start learning
00:33 - after you determine if this is a hot dog. Welcome to this introductory course on convolutional
00:39 - neural networks. In this course, I'm going to be talking about how our computer can look at an
00:45 - image with a dog in it and say, Hey, this is a dog. So the secret behind that is exactly this
00:54 - convolutional neural networks. And that's what we're going to be discussing today.
01:01 - From me looking at this, clearly this is a hot dog. I don't think that's a hot dog. Can't
01:07 - really tell what that is. hummus, hot dog, garlic bread, hot dog, hot dog, oysters, and it looks like
01:15 - sausage and waffle. And now if we look at our labels, one means that our model thinks it's a hot
01:21 - dog. Zero means that it doesn't think it's a hot dog. So for the first row, we get yes, no, no. So
01:27 - we get hot dog, not a hot dog, not a hot dog. And then we get yes, no, yes. So hot dog, not a hot
01:34 - dog, hot dog. And then yes, no, no. So hot dog, not a hot dog, not a hot dog. And I think that's
01:41 - pretty awesome for a model that we are going to learn in this video today. It's ready. Please,
01:49 - God. What would you say if I told you there is an app on the market? We're past that part.
01:55 - Just demo it. Okay. Let's start with a hot dog.
02:09 - Oh, shit. Yes.
02:11 - How's that? My beautiful little Asiatic friend. I'm going to buy you the palapa of your life.
02:19 - We will have 12 posts, braided palm leaves. You'll never feel exposed again.
02:24 - I'm going to be rich. Do pizza. Yes, do pizza.
02:26 - Pizza. Not hot dog. Wait, what? That's that's it. It only does hot dogs. No, and not hot dog.
02:46 - If you guys have already seen a few of my previous free code camp machine learning videos,
02:51 - feel free to skip ahead to the section that actually discusses convolutional neural networks
02:56 - and then the co lab where we will be practicing how to actually implement this on a very exciting
03:03 - project. Okay, for those of you who are new here, stay tuned. We're going to cover the basics of
03:08 - machine learning and we will build up to understanding how a convolutional neural network
03:13 - works. Alright, so let's get started. This is the introduction to convolutional neural networks
03:20 - presented by me, Kylie Yang on behalf of free code camp. Make sure you guys go and check out my
03:26 - channel Kylie Yang for beginner programming content, as well as future courses on artificial
03:31 - intelligence. So with that being said, let's dive right in. What exactly is machine learning?
03:38 - Well, machine learning is a subdomain of computer science that focuses on algorithms, which help a
03:45 - computer learn from data without us programmers explicitly programming certain instructions. So
03:52 - basically, we want to be able to train our computer to understand or to comprehend or to draw some
03:58 - sort of conclusion to learn from certain data that we feed it. So there's a few different types of
04:05 - machine learning. The first type is known as supervised learning. In supervised learning,
04:11 - we use labeled inputs, which means that each input has a corresponding output label to train
04:17 - models and to learn outputs. So let's look at some examples. Basically, here, we have a few
04:23 - pictures, right? We have a picture of a cat, we have a picture of a dog, and we have a picture
04:28 - of this looks like a gecko. Now, our computer doesn't actually know these labels ahead of time,
04:34 - so we as humans have labeled these items. And we are familiar with pictures of cats, dogs and
04:40 - geckos. So we can label these in our head, but our computer only sees pixels. And so what we
04:46 - are doing in supervised learning is we are actually constructing a data set with these
04:52 - labels attached to them. So when we feed these pictures to our computer, we're saying, hey,
04:57 - this top left one is a cat. This right one is a dog. And this bottom one, okay, I labeled it as
05:03 - a lizard, but you get the point. Basically, we're feeding it a label when we pass it into the
05:09 - computer. Now, there's also unsupervised learning. And basically, this uses unlabeled data to learn
05:17 - about patterns in data. So here, if we have these images, well, you know, if we have multiple
05:24 - different images of cats, multiple different ones of lizards, geckos, these things, and then
05:30 - multiple pictures of dogs, then our goal is our computer would be able to learn from all of these
05:37 - and be able to pull out similar features and say, hey, you know, these all seem like they're one
05:43 - type of category, this seems like another category, and this seems like it'd be another category.
05:48 - So that's unsupervised learning where we don't necessarily provide the labels. And our computer
05:53 - is trying to draw conclusions from similarities that it finds in our data set. Now, the last type
06:00 - of machine learning is known as reinforcement learning. So in reinforcement learning, there's
06:05 - an agent that's learning in an interactive environment. And it learns based on rewards
06:12 - or penalties that it observes while it does some sort of action throughout this environment.
06:19 - So, for example, training your dog is a type of reinforcement learning. And we're essentially
06:25 - replacing this dog with a computer. So when we train our dogs, you know, if our dog sits, then
06:31 - we feed it a treat. And if our dog barks, we might yell at it and get angry and the dog will eventually
06:37 - hopefully stop barking. Sometimes my dog is not like that. But anyways, based on these rewards
06:43 - and penalties, the dog basically picks up intuition about what actions will be able to get future
06:51 - rewards and what actions will lead to future penalties. So that's reinforcement learning,
06:56 - we train our computer in a very similar way. But our reward for our computer might just be
07:00 - something like points. Today, we are focusing on supervised learning. So let's talk about supervised
07:08 - learning a bit more. Basically, in machine learning, we have some sort of inputs. So here we have
07:16 - inputs one through n. So these are all of our samples, all of our examples, and they go into
07:22 - some model, which we'll talk about in a second. And then it leads to some sort of output, some
07:27 - sort of prediction. Now, the terminology here is that all of our inputs, these are known as our
07:35 - feature vector. So each input that we give our model should be in the form of some sort of
07:42 - parsable data, which often means just a vector of numbers. Now, these features can be qualitative.
07:52 - So that typically means categorical data, there are finite numbers of categories, or groups. So
07:59 - one example of that might be the traditional way of defining gender. So female or male,
08:06 - this is qualitative, because there's only a certain number of groups. Another example might be, okay,
08:11 - what country do you live in? Well, there are only a finite number of countries out there. And so this
08:16 - is qualitative data, this is categorical, there's a finite number of categories. So this is known
08:23 - as nominal data, because there's no inherent order, it's not like a happiness rating, where,
08:29 - you know, zero is unhappy, and five is very happy, there's no ranking between either of these. Now,
08:37 - the other type of qualitative data might be something like age, right? So these are different
08:44 - categories of being, you know, an infant, and then a child, and then a teenager, an adult, etc. And
08:53 - as I just said, there might also be happiness ranking. So you know, 12345, five being really
08:59 - happy, one being not that happy. And this is known as ordinal data, because there's an inherent
09:07 - ordering to this data set. But basically, both of these are known as qualitative data sets,
09:13 - because they are like categorical, there's only a certain number of categories there. And now you
09:20 - might be wondering, okay, doesn't that encompass all of our data? No. So the other type of data
09:26 - is quantitative data. So that means it might be numerical value data. And it could be discrete or
09:33 - continuous. So some examples of that are okay, how long is something? You get a number, right? Like,
09:39 - my desk could be 5.289 feet long. Sorry, if you don't use the American measurement system,
09:48 - which is the rest of the world, but you get my point. It's an infinite length, it's a numerical
09:54 - system. Now, it can also be temperature. So for example, this might be, I don't know, 200 degrees
10:02 - Fahrenheit. Again, sorry, if you do not use Fahrenheit, which happens to be everybody,
10:08 - not in America. Or it could even be a discrete numerical value. So for example, if we're on an
10:14 - Easter egg hunt, well, it looks like we have something around like maybe 10 or so eggs in
10:21 - our basket. So that number might be 10, but that could be zero all the way to infinity, right? The
10:29 - basic point of this is that it's quantitative. So it's numerical data. And these two values are
10:34 - continuous, because you could have like, pi fee, right? But you can't really have pi eggs. So that's
10:43 - why this is discrete. It means that it only follows like 123, like counting numbers, whereas continuous
10:51 - doesn't. Okay, so those are our features. And so now let's talk about the types of predictions,
10:57 - the outputs of our model. So the different types of outputs that we can have the first type of
11:04 - task is called classification. And this means we're going to go and predict discrete classes.
11:10 - So for example, if we have a picture of a hot dog, a pizza and an ice cream cone, classification
11:17 - would say, okay, this is a hot dog, this is a pizza, and this is an ice cream cone, it give us
11:23 - three distinct categories and try to map something into one of those categories. This is known as
11:31 - multi class classification, because we have more than two types of classes. Now, if I were to
11:37 - classify these into hot dog, and then not hot dog, then that becomes binary classification,
11:43 - because there's only two options. So it's one or the other multi class is more than two. So I could
11:50 - have like 10 different types of food and try to classify into these 10 different types.
11:54 - Other examples of classification. So binary classification, if you have like positive or
12:01 - negative sentiment in a paragraph, or a picture might be a cat or a dog, or, you know, an email
12:08 - might be classified as spam or not spam. For multi class, you might have cat, dog, lizard,
12:14 - dolphin, etc, all the animals in the animal kingdom, you might have orange apple pear,
12:19 - or you might have all the different species of plants in the world. Now, the second type of
12:26 - supervised learning is known as regression. So in this case, we're trying to predict a continuous
12:32 - value. So here, we might be trying to predict the price of an asset, such as I think I took this
12:39 - a screenshot from like Ethereum or something. But we might be trying to predict the price of
12:43 - Ethereum, or we might be trying to predict how much snowfall we're going to have on some certain
12:49 - day. Or we might be trying to predict the housing market, how much will this house cost, you know,
12:54 - in two months, or two years, or 20 years. So these are all regression tasks, because we're trying to
13:00 - predict continuous values. Now let's dive a little bit into the model. Before we talk about the
13:07 - different types of models, let's kind of discuss how do we actually make this model learn? How can
13:14 - we tell whether or not it's actually learning? Let's talk about that. So let's take this data
13:21 - set. For example, this data set is a data set that I found online, it is a Pima Indian diabetes
13:26 - data set. And this was originally provided by the National Institute of Diabetes and digestive and
13:33 - kidney diseases. Let's talk a little bit about what we're actually looking at. So here we have
13:39 - the labels for the different columns, right? So number of pregnancies, glucose levels, blood,
13:44 - blood pressure, skin thickness, insulin, BMI, age, and then outcome, whether or not they have
13:51 - diabetes. Each row here represents a different sample in the data set. So each individual that
13:59 - this data was collected from, that's what each row represents, right? So this individual here
14:05 - had one pregnancy, and these were her glucose values, blood pressure, skin thickness, insulin,
14:10 - BMI, age, and then the outcome, whether or not this person has diabetes. And this row down here
14:18 - might tell a different story, it might be a different person. Well, it is a different person.
14:22 - Now each column, well, this is a different feature. So this specific feature is the blood sugar,
14:29 - or sorry, blood pressure feature. So this measures all the blood pressure levels amongst our entire
14:37 - data set. Except for this one over here, this is our outcome. So this is our output label. And here,
14:45 - specifically, our output label is ones and zeros, because we need to transform yes and no into a
14:51 - language that our computer can understand. Our computer is very, very good with numbers. So in
14:57 - this specific example, we're coming up with zero being negative, no diabetes, and then one being
15:06 - positive, which stands for they have diabetes. And this is a very, very common way of actually
15:12 - encoding yes or no for our labels, or actually for even our features as well. But anyways, this is
15:19 - our output label. Everything, all of our features minus our output label, this is what we would call
15:27 - a feature vector. Now this is what gets passed into our model. And then this over here, this is what
15:35 - we call the target for the feature vector. So essentially, if I pass my model these values,
15:41 - then I would want it to get as close to the target or the actual value, because remember,
15:46 - we're doing supervised learning, we would want these values to get as close to this target as
15:51 - possible. And same with any of these other samples, if I pass this value into our model,
15:58 - I would hope that it predicts zero, if I pass in this row, this feature vector in,
16:04 - I would want it to predict one. And when we put all of these feature vectors together,
16:11 - we call this the features matrix x. And this is only really important when, you know, you might be
16:17 - studying a bit of linear algebra, if you go on into more in depth machine learning. And this over
16:24 - here, this is our labels, or our targets vector, also known as y. So again, this is just something
16:32 - a little bit of terminology. So let's actually visualize this as a chocolate bar. So here we
16:39 - have this x matrix, which has all of our feature vectors. So imagine like, a row of chocolate is a
16:46 - feature vector. And these are all of our targets, the corresponding targets for each of those feature
16:52 - vectors. Alright, if I take a feature vector from my data set, and I pass it into this model,
16:59 - well, my model is going to output some sort of prediction. Right now, how do we use our actual
17:05 - output label in order to help us, you know, determine a better model. So what I can actually
17:11 - do is I can take the output, the actual value, the actual outcome, because we have that information,
17:18 - since this is supervised learning, and I'm going to compare my prediction with the actual output
17:27 - given to us in our original data set. Now, what I can do is I can take, you know, some sort of
17:36 - difference between these two say, okay, how far am I from this desired output, I'm going to use
17:42 - that data, and I'm going to train the model using that. Now, if we're inputting many different
17:47 - vectors into our model, getting the outputs of those taking the difference and training our model,
17:53 - then our model over time, as we train it, we'll get closer and closer to predicting, you know,
17:59 - the actual output down here. So this is our supervised learning data set, it's this chocolate
18:09 - bar with over here, our features vector, and then our output labels. What we normally do is we
18:18 - actually split it up into three different types of data sets. So we have this like training data set,
18:23 - which will be most of our data, we use our data in order to train our model. But now how do we
18:28 - actually determine how good does our model predict on stuff it hasn't seen yet? Because
18:34 - what we would ideally want to do is take it out into the real world someday, right and say,
18:41 - hey, here's a picture, what's in this. So in order to do that, we also need a testing data set. So
18:50 - that testing data set is just some data that we've removed from our original data set. And we're
18:56 - just going to use that in order to see how well our model can do on data that it hasn't seen yet.
19:02 - So it's part of our original data, but we're removing it, holding it off to the side so that
19:07 - when we finish our model, we can say, hey, now look at this new data. How well how well can you
19:13 - perform on this? Okay, so what is exactly is this validation data set here in the middle? Okay, so
19:20 - when you're actually building the model, suppose that you have a bunch of different models that
19:25 - you've come up with, how do you actually choose which one is the best? That's where the validation
19:30 - data set comes in. So imagine you are out buying a car, right, there's many different types of cars,
19:36 - some of them are just slightly better than the others, some of them just have a few things here
19:40 - and there change, just like small bells and whistles, right. So this is a test drive where
19:44 - you're going, you're testing out all the models, and you're picking out, okay, this one is the best
19:49 - and this is the one that I want to keep. Now, what's the difference between validation and testing?
19:54 - Well, validation is used on all the models, so you can pick out the best one, and then testing,
20:00 - you're using that model, and you're saying, okay, well, how well does this model do on data that I
20:05 - haven't seen yet? And these two, we both keep aside. So like, they're not used for training,
20:11 - but they have two different purposes. So remember that validation is test driving, picking out the
20:17 - best model, testing data set is used on that best model in order to get your final accuracy number
20:24 - or final metric about how well your model does. Okay, so let's visualize each of those. This
20:31 - training data set is passing the model, and the model produces some sort of prediction for each
20:36 - of the feature vectors in this training data set. So this training data makes some sort of prediction,
20:42 - and we're actually comparing it to the actual output. And when we take the difference,
20:48 - comparing the two outputs, that is what's known as the loss. Now, this loss can be used to actually
20:55 - make adjustments, which is known as training to this model. Now, this validation set, again,
21:04 - is used as a reality check during and after training to, first of all, ensure that the
21:09 - model can handle unseen data. And then also to say, okay, which model do we want to use? So again,
21:15 - this is a test drive. Here we have model A has a loss of 1.3. Model B has a loss of 1.5. Model C
21:23 - has a loss of 0.5. And Model D has a loss of 0.9. So which one is the best model? It's Model C.
21:33 - Now, finally, once we've selected Model C, we take our test set, we pass it through Model C,
21:39 - and we get our final performance between these two, our output and our actual label. And our test set
21:47 - is used to check how generalizable the final chosen model is. So that means how well can our
21:55 - final model perform on data it hasn't seen yet. All right. Let's talk about this loss function.
22:03 - Loss is basically a metric of performance, it tells our computer, hey, this is how well we're
22:09 - doing right now. And so if our prediction is further from the output, the greater the loss
22:16 - will be. So for example, this pink one, it's a slightly higher loss than that brown because
22:21 - it's further from that chocolate bar, right? Or if we have this blue, then that's really far from
22:27 - the chocolate bar, and we have a lot of correcting to do in our model. So these are what's known as
22:32 - loss functions. So for l one loss, basically, we have this absolute value shape. And l two loss,
22:40 - we have this quadratic shape, let's talk a little bit about what these actually mean. So here, the x
22:47 - axis is the difference between the predicted and the actual value. So if we go back to, you know,
22:55 - you know, these, this is talking about how far apart are these values. So the further from zero
23:04 - these are, the more different they are, right? And why over here, this is the penalty. So this is
23:12 - how much are we getting like penalized for being further away from our actual value. And you'll
23:20 - notice if you look at the scales here, l one is linear, right? So that means that if I'm like 10
23:27 - away from my actual value, then my penalty will just be 10. What this l two loss, on the other
23:34 - hand is quadratic. So that means if I'm 10 away, then I'm actually penalizing by 100. Right? So
23:41 - that's, I mean, that's, that's literally x squared. Now, that also means that the closer I am, so
23:48 - within one away, this absolute value of one away from the actual value, then my loss is going to
23:55 - be less penalty than l one. But anyways, what I wanted to clarify here, let's not get too deep
24:03 - into the math, it's just that there's two different types of loss functions, which will tell our
24:07 - computer, hey, this is how far off we are. There's also this thing known as binary cross entropy loss.
24:15 - So this is for binary classification. Oh, yeah, I should clarify that these l one l two losses are
24:21 - for regression. So that's when we're trying to predict a final output. And we're telling our
24:26 - computer, hey, we're kind of far from that output. Now, binary cross entropy loss is when we have
24:33 - binary classification. So we have two different categories that we're trying to classify. And
24:40 - we're not going to try and understand this equation. But what we do want to take away from
24:45 - this is that as the loss decreases, the performance will get better as our model does better at
24:54 - predicting the right output, this loss decreases. Okay, so metrics of performance that we can assess
25:04 - that will tell us how good our model is performing. The first one is accuracy. So for example, over
25:12 - here, I have a bunch of different fruits, right? I have apple, orange, apple, apple. And our labels
25:19 - are over here. So our actual labels are apple, orange, apple, apple. Now, let's say that these
25:26 - get passed into our model. Well, our model comes up with these predictions, apple, orange, orange,
25:33 - apple. So what is the accuracy of our model here? The accuracy of this model is three quarters,
25:41 - it's 75% because we've gotten three of the four correct. And generally, for now, for this
25:48 - introduction, we will be only sticking to accuracy in order to talk about how well our model is
25:55 - performing. Finally, let's talk about the model itself. In this video, I'm going to focus on
26:02 - neural nets just because it's a very common example and very powerful example of a model. But
26:08 - there's many, many different models out there. So neural networks look something like this, we have
26:14 - our inputs. And so these are all of our features. I know that I showed you guys previously with the
26:20 - feature vector horizontal, but now let's take that horizontal and let's turn it so it's vertical. So
26:27 - if we have, you know, some sort of age, glucose level, I forgot what the Pima Indian data set was.
26:36 - But if we have like age, glucose pregnancies, then now it's going to be age, glucose pregnancies,
26:43 - okay, and this is going to be our feature vector, it's going to be this way. These values will get
26:48 - passed into these hidden nodes. And what does that mean, we will dive into nodes just in a second.
26:55 - And these outputs of these cells will get passed into an output. And this output, these output
27:01 - cells will determine what the final output of this neural network looks like. So as promised,
27:07 - let's take a look at these specific nodes. Okay, so again, here I have my feature vector, but
27:17 - vertical instead of horizontal. So this is x0 x1, all the way until n. So basically, we have n and
27:25 - then plus one more, but n plus one different features over here. Okay. Now, all of these
27:32 - different values, they all get some sort of weight attached to them. So that might mean, okay, we
27:39 - want to emphasize x0 some more. So let's double the value of that. So this weight might be two.
27:46 - Or, hey, we don't really like, you know, x1 doesn't seem that important. Let's decrease the
27:52 - significance of that this weight might be 0.5. Okay, so essentially, we're multiplying this w with
27:58 - this x. And now the value the output of that goes into this neuron. And this neuron is just taking
28:06 - all of these, like products, and summing them together. On top of that, it gets something called
28:12 - a bias, which you can think of as like an x intercept. Basically, this is just saying, okay,
28:18 - add this specific number, whatever this number represents, add this number to the neuron. And
28:25 - then finally, the output of the sum of all of these, plus this one, gets passed into something
28:32 - known as an activation function. And that activation function, then whatever output of that,
28:39 - that is the output of a single node in our neural net. Okay, and then you have all these nodes,
28:46 - you can chain them together. So I know that I use circles to represent this. But this entire thing
28:52 - is basically encapsulated in its own circle. So that represent like this entire circle contains
28:59 - this entire thing, right? So each of these circles has their own outputs that go into different
29:06 - nodes, that, you know, it's doing the same thing, it's taking the product, then the summation. And
29:11 - then that gets output into like some sort of output layer. And here, this is the final output
29:17 - of the neural network. I kind of lost over this activation function. So let's go a little bit
29:26 - deeper into that. Let's talk about that. Okay, so the activation function, if all of these were
29:34 - just a product and a sum and a little bit of something added, then we get an output that's
29:42 - just a summation of products, right? And when we chain all those together, so without activation
29:49 - functions, this basically this entire thing just collapses into a linear model. And by linear model,
29:56 - what I mean from that is just we could have one coefficient per input. So we multiply those two
30:02 - together, and then we add a bias. And that would be our output, it would be essentially, if all of
30:07 - this entire network could collapse into one cell, which if we don't have activation functions,
30:12 - that's kind of what happens. So we do need activation functions. Now, what are they? Okay,
30:20 - these are three examples of different types of activation functions that we can use. So this is
30:26 - a sigmoid function, this is a tanh function, and this is a relu function, rectified linear unit or
30:33 - something like that. I can't remember what this stands for. What this actually means over here,
30:38 - it just means, okay, what is the output of the cell? The y axis here is the output. So whatever,
30:45 - you know, this output here is this y axis over here. And with sigmoid, essentially what we're
30:56 - doing is we're taking the product and the summation of all the products. So all the different things
31:02 - that come into this neuron here, so all of this stuff that gets summed up, whatever the value of
31:10 - that is, is this x axis down here. Okay, so actually, with all of them, whatever that value
31:16 - is becomes the x axis. And we just want to map that to whatever the y value is. And that will
31:22 - be the y output of a single cell. And again, the reason why we use these activation functions
31:29 - is so that we create some sort of nonlinear, we introduce some sort of nonlinear value
31:35 - into our neural net so that it doesn't all collapse into a linear function.
31:40 - So that's the importance of activation functions. Typically, I will use relu because that is just
31:45 - a very classic activation function that is known to work. All right. Now, how does
31:54 - this part the training actually work with a neural net? Let's talk about that box for a bit.
32:03 - Okay, suppose that we're using our l two loss function. Okay, so again, that's this quadratic
32:10 - value. And remember that these x axes are how far is our predicted value from our actual value?
32:20 - How far is that we can calculate a numerical distance for that? Then this y value is, okay,
32:27 - here's the penalty for being that far away. Now, if you're really, really close together,
32:31 - then that penalty is going to be really small. But if you're like, pretty far, that penalty
32:37 - is going to be even larger. So up here, the error is really large. And our goal is to decrease this
32:47 - loss. So our goal is to get somewhere down here, right, like ideally zero, because that would mean
32:52 - that we have a perfect prediction. But we want to get just close enough. Now, that means that we
32:58 - have to take the giant step in this direction in order to get to that value. And in order to do
33:06 - that, we can use something called gradient descent, which is a heavy mathematics concept that will
33:12 - also include some calculus. So we're not going to cover that in the scope of this course. But let's
33:17 - kind of just get a general sense for what gradient descent means. Basically, our gradient descent
33:24 - means okay, this is where we are. And so what is like the slope at this point? So at this point,
33:33 - the slope looks something like this. Down here, the slope looks something like this. And down here,
33:39 - the slope looks something like this. So basically just means like at your specific point, how much
33:45 - are you changing? So that's your slope. Okay, so now once we have that value for the slope gradient
33:51 - descent is saying, okay, well, let's follow that slope down, because we want to minimize our value,
33:57 - right? So we're just going to follow gradient descent down towards wherever it's going. So if
34:04 - we take a look at these different, like w values, because these are the ones that we can adjust in
34:10 - order to train our neural net. So these remember are what we're multiplying with our inputs in
34:16 - order to get that summed output, which then goes into the activation function. So we're taking a
34:21 - look at our w's, which are our weights. And maybe, you know, with our current model, with this weight,
34:30 - it's super far off from where we want it to be. And so what we can do is we can calculate
34:37 - this, like trajectory, and we can say, oh, we want to take a step this way. Now, in w one,
34:45 - we might be slightly closer, and we want to take a smaller step in this direction.
34:48 - And finally, you know, another one of the random weights might be even closer. And so then we only
34:54 - take a smaller step in this direction. But essentially, what backpropagation does what
35:00 - this gradient descent does is it's telling us, okay, we want to take a step in this direction
35:06 - in order to correct our weight, how much of an adjustment do I make? And in what direction?
35:12 - direction. Now, in order to get that new weight, I'm taking the old weight, and then I'm just
35:18 - tacking on some alpha. So just some like very small value, that's what alpha represents some
35:24 - very small value, we call that the learning rate, but some very small value times this step. Okay,
35:32 - so basically, our new value will be this old one, and then adjusted slightly by this. And this,
35:40 - as I mentioned, it's called the learning rate, this is typically a really small value, and it's
35:44 - just to make sure we don't like overshoot. And so with all of these different weights,
35:50 - we can take this value, and we can multiply it by our learning rate, and then calculate out this
35:56 - new value based on the old one. And you'll see that this magnitude of this vector is smaller
36:02 - than the one over here, which means that we're going to make a smaller step. And if you want to
36:06 - get really technical, then sometimes you'll see this as negative alpha times the slope. And that's
36:12 - only because or like the derivative, that's only because here, I'm I'm don't get too caught up in
36:17 - that. The whole point is we want to take a step down towards our goal down here. And here, I've
36:25 - already flipped the signs. So that's why there's a positive if you're wondering, if you had no idea
36:29 - what I just said, don't worry about it. Just get the general idea of this. And this is how like
36:35 - training neural networks, we adjust our weights based on how far we are from where we want to be.
36:41 - Okay, so the moment we've all been waiting for, let's talk about convolutional neural networks,
36:46 - otherwise known as CNNs. So here we have this handwriting in an image. And the whole goal of
36:56 - our let's say that, okay, so let's say that we are building a model to detect what number in
37:02 - handwriting is written in an image. So here we have an image where, to us, our human eye, we say,
37:08 - okay, I think that's a five, right? But our computer doesn't know that. How do we get our
37:12 - computer to determine that using supervised learning? So that's where CNNs, convolutional
37:19 - neural nets come in. Basically, the idea is we want to somehow pass this image into a neural
37:27 - network, what we just talked about, in order to produce some sort of output prediction for the
37:32 - number that's actually in this image. Well, this image doesn't really translate into a neural net
37:41 - too well, right? Because think about the Pima Inions data set, we had different values in each
37:46 - column, which means that every single sample, so this here, this five would be technically one
37:51 - sample, every single thing in our data set had like, this very nice vector of values to associate
37:59 - with it. But here in our image, we don't really have that nice vector, right? It doesn't really
38:05 - pass into this neural network too well. So how do we solve that? And the answer is using convolutional
38:13 - neural networks. So this area here, which we'll talk about, this is our convolution part. But
38:20 - essentially what we're doing here is we're trying to extract features. What that means is that we're
38:26 - doing all these operations so that we can get this input, boil it down to a vector that's easily
38:34 - passed into a neural net that can actually perform the classification. So all of this that we're
38:41 - going to learn in convolutional neural neural network is just tacked on to the beginning of
38:46 - a neural net. So we can take an image as is pass it through all these different layers.
38:51 - So we can finally produce an output vector for that input, and then pass it through the
38:57 - convolutional neural network. Okay, so something to notice is that images are actually numbers.
39:05 - So here I have an image of this x and you'll see that certain pixels are darker than the others.
39:11 - But our images are composed of arrays of pixels. So basically, we have this like 2d matrix, right?
39:18 - And each matrix, each cell has some number associated with it. The darker it is, the closer
39:25 - to zero it is. And the lighter it is the closer to 255 it is. So white is 255 and zero is black.
39:34 - And now you know, something that's gray might be in the 100s. But essentially, this maps to
39:41 - this over here. And now once we have this 2d array, we're going to pass something called a
39:49 - convolution over it. So a convolution, by definition is a mathematical operation
39:57 - on two functions that produces a third function. What that means in our image processing world
40:04 - is that okay, here we have some sort of input 2d array, which represents our image, right? Because
40:10 - our image again, is this 2d array, we have this 2d array. And then we have some sort of filter
40:17 - on that 2d array, right? So this filter is going to take these cells in its size. So like this
40:25 - filter is three by three. So it's going to take cells in a three by three grid on this input map,
40:30 - it's going to do some sort of operation, most likely summing up everything,
40:34 - and then mapping it to something on an output map. So it might take like, so basically, what
40:40 - you're going to do is take this thing and keep sliding it over every single possible three by
40:45 - three window on our input, project that onto this output. And that's a convolution. So here's a
40:53 - little example. Okay, so this is our filter. And we're just going to overlay this on each part of
40:59 - the matrix. These values are just extensions of this, because we don't have anything to fill it.
41:05 - But we're just going to keep sliding it over, summing all of these up, you can see the summation
41:09 - calculation down here, projecting it onto this output matrix over here. So we do that for all
41:17 - the different rows. And then we finally get this value, this output value, based on this convolution.
41:26 - Now, there's many different types of things that can come out of this filter, also known as a
41:33 - kernel. So here's one example, this is some sort of edge detection on this original input. So this
41:40 - edge detection will give us all the edges in the image, that is the convolutional layer of a
41:46 - convolutional neural net. Basically, what we're doing is we're taking our image, we're trying to
41:51 - toggle these filters so that they're able to extract some sort of meaningful information from
41:56 - our original images. So like here, these are edges, but like, in some cases might be looking for eyes
42:02 - in the image, right? And it's going to take it's going to make a filter in order to detect these
42:09 - objects and map it onto an output image. So that's a convolution and our convolutional neural net,
42:16 - we're essentially training that filter to be able to detect these important properties.
42:23 - Now, another important concept is pooling. So if we go back to our CNN image, you'll see that we
42:29 - have all these convolutions, and then we pool them. So what does this pooling mean? Okay, so
42:37 - pooling is essentially taking a larger input, and reducing it down to something smaller that might
42:43 - still represent the data in that original output. So if we use two by two pooling, basically what
42:49 - that's doing is taking the two by two cell in the original input, taking the largest, because it's
42:55 - max pooling, it's taking the largest value in these four cells, and projecting it down here.
43:02 - Over here, 184. So it's 184. And this two by two array, it's 12. So 12. And then over here, it's
43:09 - 45. So it's 45 down here. There's also a different type of pooling called average pooling, which
43:14 - instead of taking the maximum, we'll just take the average of the four values in the cell and
43:20 - project that. So what you need to know from pooling is just we're taking a larger array,
43:26 - we're condensing that information down into a smaller, more compact array. And so then we put
43:33 - those two together, and that becomes our CNN. Often, we usually have more convolutional and
43:39 - pooling layers. And then we also have more fully connected layers. But this is a good schematic of
43:44 - what's going on. This is a visualization that I got from this website, I will post these slides
43:49 - and the site in the description. But essentially, here, it's really cool, because what I did was I
43:56 - essentially drew this five. And this is a first convolution, this is what happens after the first
44:01 - convolution. This is what happens after the first convolution. Essentially, it's taking this five
44:06 - and projecting it towards many different onto, you know, different kernels and such. And then
44:12 - it's taking these and pulling these. It's doing another convolution on these pooled layers.
44:20 - And then pulling those once more, flattening it into some sort of, you know, linear thing that
44:27 - we can put into a neural network that goes into this neural network. And then the output of all
44:35 - of these cells will tell us what value it actually thinks it is. So let's click on that link. This
44:42 - is something of what it looks like. If I draw a one, you'll see that the first guess is one and
44:47 - the second guess is zero. And each one of these cells on here is taken from something down here.
44:57 - So like this specific cell is the output of these cells over here. Okay, so all of these
45:04 - are some sort of filter. So it actually shows you the filter if I click on it. So it takes
45:10 - the input image perform some sort of filter on that area, and then gets this value. So here,
45:17 - our input, while we see this like grid, and we see these two blue cells in our input,
45:25 - and the filter, we use that filter in order to get this blue cell over here. And you'll see that
45:31 - these are the pulling layer. So it takes multiple cells and then pulls them down to only like to
45:38 - smaller array. And then we perform some sort of convolution on these. And this might be the input
45:44 - of multiple different images. So like here, we're taking four images, and we're getting this cell
45:49 - over here, right? So we have all these inputs. And these are the filters on all of those. And it gets
45:56 - some sort of output based on that. Whereas here, you know, our inputs are filters, you get the
46:03 - point. But basically, it's like, it's just taking all these inputs, putting some sort of filter on
46:09 - it. So we're summing up all these different things. And then we have some sort. So they're using a
46:16 - tan function for their for their nonlinearity, that activation function that we talked about.
46:22 - And finally, this, like all of these, again, pooling, each of these cells is some sort of value
46:29 - from derived from all of these pooled values. And then finally, this is our fully connected neural
46:38 - net. And then there's an output layer, which is over here. So this is our output. And over here,
46:44 - it's saying the one is lit up, saying, hey, we think that this is a maximum value, which means
46:50 - that this is what we think is our prediction, you'll see that zero is negative point nine, six,
46:55 - seven is negative point nine, nine. Well, we think that this one is the max. So play around with
47:03 - this. This is a really cool, let's do like a four. Okay, so our first guess is for our second guess
47:10 - is one. And you'll see that floor floor over here is lit up. The big picture here is that we're
47:15 - taking this input, we're projecting it multiple times, we're doing some sort of like filter over
47:23 - each like grid, mini grid in this original input. And we're just doing a bunch of like,
47:30 - array filtering mechanisms, basically, putting that into a this layer here, which is essentially
47:39 - our feature vector for this image. And then putting that through a neural network in order
47:45 - to get our prediction. Okay, so we don't actually have to code all that, we just kind of have to
47:52 - have this understanding of how it works. Because the beauty of machine learning is that there are
47:57 - machine learning libraries, where we can actually implement our models. So what that means is that
48:04 - we have this model that we want to implement in machine learning. And it might look something
48:09 - like this. But what we can do is we can replace it with something that has already encoded all
48:15 - the different like, mathematics concepts behind each of these layers. And we can simply say,
48:21 - okay, it's a sequential model with, you know, two fully connected layers of 16 units using
48:27 - relu activations. And then we have this output. And that is the beauty of TensorFlow. So TensorFlow
48:35 - is an open source library that helps us develop and train machine learning models. And in this
48:41 - next example, let's actually take a look at how we can use TensorFlow and train a convolutional
48:46 - neural network on different images of food in order to produce predictions of whether or not
48:52 - a food is a hot dog. Now that we've learned about the basics of machine learning, neural networks
48:59 - and CNNs, let's actually look at an example and see how we can use TensorFlow in order to build
49:05 - a model, train a data set and use this model to actually evaluate outputs. So I'm going to go to
49:13 - colab dot research dot google.com. And I'm going to start a new notebook. And this notebook I'm
49:20 - going to title hot dog versus not hot dog example. Because today, what we're going to be classifying
49:32 - is pictures of food. And we're going to be labeling them as hot dogs, or not hot dogs.
49:37 - So let's dive into this. All right, the first thing that we want to do is import a few different
49:43 - libraries. So we can import NumPy as NP import pandas as PD import matplotlib.pyplot as plt.
49:57 - Let's import random, we can import import TensorFlow as TF. And from TensorFlow.keras, we're going to
50:14 - import data sets, layers and models. And then finally, we're going to actually get our data
50:21 - from TensorFlow underscore data sets. And we're going to import that as TFDS. So basically,
50:30 - these are some data analysis tools that we have. PLT is a plotting tool. This is just the
50:36 - random library. So if you need a random number generator or something, TensorFlow,
50:43 - that should be Keras. This is more TensorFlow stuff. And then this is finally the data set
50:48 - that we'll be looking at. So go ahead and run that cell, you can run it by clicking this play button,
50:54 - or you can use shift enter, and that will run a cell. So in this video today, we're going to be
50:59 - building a hot dog versus not hot dog classification model using TensorFlow to distinguish hot dogs
51:06 - from not hot dogs in food images. Alright, so now I'm going to add a citation. And you don't have to
51:14 - worry about this. But this is just so that we can give credit to the people who actually produce
51:20 - this, this data set that is. Alright, so let's talk about the data really quickly. So TensorFlow
51:26 - already has the food 101 data set. So we'll actually use that. And you can learn more about
51:31 - that by clicking this link here. Now, in this data set, the hot dog label is label number 55.
51:38 - So let's take a look at this data set itself. Okay, so the first thing that we need to do is
51:44 - actually import this data. And we can do that by using TFDS. So that, again, is our TensorFlow
51:52 - data sets over here. So if we do this dot load, and then we use the string food 101,
52:01 - then that actually TensorFlow will load the food 101 data set. And we're going to shuffle the files.
52:08 - And because we want this as a supervised data set, we're going to set this to true. And we'll
52:17 - just also include info in that as well. And here we this will actually return a tuple with the data
52:24 - set as well as the data set info because we have chosen to include that over here. Alright, so we're
52:30 - going to run this cell. And this cell will actually take a little while to run. So we'll just sit here
52:37 - and wait. And you can pause the video until that cell finishes running. Alright, so finally, our
52:46 - data set is loaded. So the first thing we're going to do is actually split up the data set into train
52:51 - and validation sets. So here, I'm going to get a train data set and a validation data set.
52:59 - And this is because this data set automatically comes with train and validation data sets split
53:08 - up. So I'm going to grab those. And then let's actually show some examples. So what I'm going
53:14 - to do is I'm going to use TSDS dot show underscore examples. And what I'm going to do is actually
53:23 - pass in the train data set and then the data set info, which contains all the different information.
53:28 - So if I hit enter there, we get, you know, pizza, chocolate cake, bruschetta, waffles, etc. And
53:39 - somewhere in there is hotdog. And actually hotdog, the label for that is number 55. I found that I
53:45 - think by just running this a bunch of times and seeing where hotdogs came up. One thing that you
53:50 - might notice here is that these images are all different sizes, right? They're not all square.
53:56 - So the first thing we want to do is actually we want to resize it. And then the second thing,
54:02 - you might notice that we have a bunch of different labels, right? But what we're interested in
54:06 - is hotdog versus not hotdog. So what I'm actually going to do is I'm going to take an image,
54:13 - actually, let's use this one, this chocolate cake image over here, I'm going to resize it so that
54:18 - it's 128 by 128. And then pixels, and then I'm going to cast the label, such that it either
54:26 - equals a hotdog. So that's one, or it doesn't. So that's zero. Okay, so the maximum side length that
54:33 - I want here is going to be 128. Then the hotdog class is equal to 55. So what I'm going to do
54:44 - is I'm going to take this training data set. And I'm going to use a map function. So what this map
54:52 - is doing is saying, all right, whatever function is in this map, that's how we're going to,
54:59 - we're going to apply that to every single item in our data set. And we're going to transform
55:04 - the data set that way. So by this lambda, well, this is basically our new function,
55:11 - lambda means, okay, what are the inputs, you have an image and a label in each data set,
55:16 - okay, so you have this image, and you have this specific label in each data set. Now, with that,
55:23 - we're going to get a new tuple. So our new image and our new label, and that new image,
55:30 - we're going to use TensorFlow image resizing. And we're going to pass in the original image,
55:38 - and then the actual size that we want. So this would be max side length by max side length.
55:47 - So basically, we are resizing this image, the original image into something that's a square
55:54 - pixel 128 by 128 pixels. And then that's going to be the first thing in our tuple in our data set.
56:01 - Now, for the label, what we're going to want is actually whether or not the label in this
56:12 - pass in label over here, whether or not that equals the hot dog class, right? So this becomes
56:19 - our new data set, we're basically resizing and then our label is just true or false, zero or one,
56:26 - I guess true is one zero is false. And that's just whether or not it's equal to the hot dog class.
56:34 - Now, one other thing is that TensorFlow will complain about the the type of data that's held
56:42 - in here. So one thing that we're going to have to do is TF dot cast. And then we're casting this
56:47 - output into TensorFlow int 32 outputs. And the same thing down here. Cast, we're going to cast
57:00 - that into TensorFlow in 32. All right, did we close all of our parentheses? Let me just double
57:12 - check. Okay, yeah, it seems like we did. So then we're going to do this exact same thing on the
57:18 - validation data set. So here, now we're, again, mapping the image into something that is a square,
57:29 - and then we're casting the label into whether or not it equals a hot dog class. So let's run that
57:35 - cell. And now we have our training and validation data set. And let's just verify to see if that
57:41 - works. So let's just show these examples. All right, now everything looks like it's a square.
57:51 - And all of these say apple pie, even though it's not really apple pie. And that's just because
57:57 - in this data set info, it's still 01. But this the zero just means that it is not a hot dog.
58:06 - As you can see, all of these are not hot dogs. Zero is just apple pie is just the default label
58:12 - for zero. But what zero means in our context is that it's not a hot dog. So if we actually refresh
58:17 - this enough times, we'll get maybe one example with a hot dog. Let's see. Yeah, okay, so I guess
58:25 - the default label for one is baby back ribs. So in our specific example, like, apple pie means not
58:32 - a hot dog. And then baby back ribs means hot dog. Okay, so essentially, you'll just see that anything
58:37 - that's not a hot dog is zero and something that is a hot dog has a label hot dog is a one. So now we
58:44 - have our data set in these square images, and they're all the same shape. And then we also have
58:50 - our zero and one label. Okay, so one thing that we're going to have to do is there's actually
59:01 - only 750 of each food in. Okay, so something that we're gonna actually have to do is rebalance our
59:12 - data set. So in our training data set, there's actually only 750 hot dogs in like the entire
59:21 - data set, there's actually 750 of each different category. But the limiting factor here is the hot
59:27 - dogs. So let's try to reshape this so that we don't have a bajillion not hot dogs, and then only
59:33 - a tiny little bit of hot dogs to train on. So here, the training hot dog size, and the validation hot
59:44 - dog size, I'm going to set this equal to 750 and 250. I just know that from like the documentation
59:50 - of the data set. Now, if I get train hot dogs, what I can do is take this training data set,
59:59 - put a filter on it. So whatever, I don't really care about the image.
60:07 - But I'm basically filtering this by the label being equal to one. Now, we can also train the
60:15 - not hot dogs. And this is equal to again, this image with the label, and the label now being zero.
60:27 - So this is going to significantly outweigh this one. So what I'm actually going to do is I'm going
60:33 - to up sample this by just repeating this three times. So I'm going to take that 750 and duplicate
60:40 - that a few times to construct a new data set. And I will actually do the exact same thing for valid
60:48 - validation. So our valid hot dogs will be taking the validation data set and running the exact
60:58 - same operation on it. Okay, cool. Now we split our data set into hot dogs and then not hot dogs.
61:08 - But the issue is that the not hot dogs data set like outnumbers the hot dogs data set by a lot,
61:14 - even though we repeated this hot dog data set. So how do we actually sample from each one
61:20 - and get a balanced data set. So that's what we're going to do here, we're going to take
61:26 - we're going to create this new training data set by using this function that we need to get. So
61:34 - in TensorFlow dot data dot data set, we can call the sample from data sets function. And here,
61:41 - we're going to pass in all the data sets that we want to sample from. So for training, that would
61:44 - be train hot dogs and train, not hot dogs. And the weights for each one. So the weights here,
61:56 - we want 50% from here and 50% from here. So I'm going to do 0.5 and 0.5. Okay. And then finally,
62:07 - we want to tell this that once we've reached an empty data set to stop, so there's this option
62:14 - stop on empty data set, oops. And we're going to set this equal to true. Okay. Okay, so now to get
62:24 - this training data set into something that we can actually pass into our neural net. What we're
62:29 - going to do is we're going to cache, then batch, then prefetch. And I'll explain that in a second.
62:34 - So let's just type that out first. So first, we're going to cache this. And then we're going to batch
62:42 - it by some batch size, which I will actually set up here to be 16. And then we are going to prefetch
62:51 - using the parameter auto tune. And now I'm also going to just paste this for validation.
63:03 - Oops, valid. Here, this should be the valid data set. All that still applies. And instead of the
63:12 - train hot dogs and not hot dogs, instead, this is valid. Okay. So what caching means is that we're
63:20 - going to cache the data set somewhere. So that means we're going to save it either in memory or
63:25 - local storage. And that will save some operations such as file opening, and data reading from being
63:33 - executed at the beginning of each cycle of running the neural net of training the neural net, sorry,
63:38 - we batch our data set, because instead of passing just one image at a time into the neural net,
63:43 - we can actually pass a bunch in and in this specific case, our batch size is 16. So in this
63:48 - case, we're actually passing in a whole batch of images into the neural net, so that the neural
63:53 - net can train it and then using all 16 of the images in the batch rather than just every single
64:01 - image and training on that. Now, finally, this prefetch over here, this is simply to save more
64:06 - time, it overlaps the time that the pre processing of the data is taking place, and the model
64:12 - execution of the training step. So basically, while the model is training, step s, the input
64:20 - pipeline is actually already reading the data for the next step. So this will just save us a little
64:26 - bit more time. Okay, so now our data pipeline is ready. And what we can actually do, let's run this.
64:33 - Alright, so now just for the sake of proving that this data is in the format that we want it.
64:39 - What I'm actually going to do is iterate through just like the first item in the this training
64:46 - data set. So I can do that by getting training data set dot take one. And so we can get the image
64:56 - batch and the label batch. And let's print out the image batch. And let's print out the label batch.
65:09 - And I need an in here for my for loop. Okay, so you'll notice that this image batch is kind of
65:17 - oops, useless, because it's just a bunch of tensors. So there's actually 16 images in this
65:23 - tensor. And the reason why I can confidently say that is because when I go down to the label batch,
65:30 - somewhere down here, it actually gives us a shape 16 vector of the different labels in zero in one
65:37 - form. So here zero, again, means not a hot dog. One means it is a hot dog. And look at how well
65:43 - balanced this is, there's approximately ish, like 5050 in this output, right? So that means that we
65:50 - have a decently well balanced data set. And with that, we can actually start the neural network.
65:57 - Oops, let's use text for that. We can start the neural net implementation.
66:06 - Alright, so I'm just first going to seed this so that certain results are reproducible.
66:13 - But we want a sequential model. So I'm going to say models dot sequential. And now this is where
66:21 - we're going to start building our CNN. The first thing that I'm going to do is I'm going to
66:29 - actually rescale the images so that we divide by 255 for each pixel. And now what that does is
66:36 - instead of the scale of zero to 255, for all of our colors, we now get zero to one. And one just
66:45 - means white, zero means black, or like if there's color for RGB or not. Now we're ready to add some
66:51 - convolutional layers. So here, the next thing that I want to add is layers.com 2d. And it's going to
67:00 - first ask for how many different filters do we want. So let's just put 128 for that, our kernel
67:07 - size, let's make this three by three. So that's the size of that filter that we're moving across
67:12 - that image. And then let's use a relu activation function, just because it's a classic. And our
67:19 - input shape. So our input shape here is equal to max side length, max, side length, and then three
67:32 - because we have colors. Alright, then we want to actually add a max point layer. And we'll just
67:43 - make that two by two. That's just pretty standard. Again, we'll add another convolution layer. And
67:50 - now instead, here, this will just be 64 filters, we're still going to use relu. And we actually
68:00 - don't have to pass in this input shape anymore. Now, let's add again, another max pooling layer.
68:07 - So actually, I can just paste that. And I'm going to go with another convolution layer. In order to
68:15 - get from the convolutions to our fully connected, we actually have to add a flattening layer. So
68:22 - here, I'm going to flatten that. And let's just add a dense layer. So that's just a fully connected
68:29 - layer. dense 128. So that means like each input goes to every single node. So 128. And let's make
68:38 - the activation again for this relu. And finally, the output of this because it's binary, because
68:45 - it's either zero or one, I only need one node at the very end that will tell us what it is zero or
68:54 - one. Okay, so this is the general gist of what our neural network will look like. So let's create
69:01 - this. And let's get started on training. So our learning rate will be 0.0001. And let's compile
69:12 - this model. Okay, so a very classic optimizer to use is Adam. And so that's what we're going to
69:19 - use here, you can kind of think of this as a tool to help us adjust the different weights,
69:27 - just like in the diagram that we showed earlier to go down that gradient towards that minimal loss.
69:36 - And our loss here will actually be something known as binary cross entropy. So we will use
69:45 - losses dot binary cross entropy. And the reason the reason why we use binary cross entropy is
69:53 - because we have only a single output and we're trying to do binary classification. So whenever
69:59 - it's binary classification, we use binary cross entropy. And here we have this from logits option.
70:09 - So the reason why we set from logits, we actually have to set this from logits to be true,
70:14 - because our final layer does not automatically project the output onto zero to one, which we
70:21 - would do using a sigmoid function or something like that. So down here, we have to set from logits
70:27 - to true to let our, I guess, loss function know that it's not already projected from zero to one.
70:34 - And finally, the metrics that we want to use to assess this might just be accuracy.
70:39 - Okay, so let's compile the model. Oops. Oh, okay, so I'm missing an S over here. That should be
70:48 - accuracy metrics equals accuracy. Okay, cool. So now my model is compiled. And I'm just going to
70:56 - set epochs equal to 50. And we'll collect the history from here. But we're essentially going
71:04 - to fit this model to the training data set, the validation data will equal the valid data set,
71:13 - epochs will equal this epochs parameter that we pass it. And then we're going to set verbose to
71:19 - one so that we can actually see things get printed out. So let's run this. All right,
71:33 - this will take a little bit of time, but you see that the accuracy starts off not so great,
71:39 - it started at like point three or something. Okay, now it's at 0.5. So the thing is,
71:46 - we expect just a random model to be at an accuracy of 0.5, because we have equal parts of the hot
71:53 - dogs and the not hot dogs in the in the data set. So we do expect initially that the accuracy would
71:59 - be around something like 50%. So our goal is to see that if we can improve that.
72:09 - Okay, so now now our model is done training, let's go ahead and take a look at the results.
72:15 - Here, this is each epoch. So essentially, an epoch just means an iteration where we go through
72:20 - the entire training data set. And we see that the loss each time as we train our model is decreasing.
72:28 - So this means we're getting closer and closer to our goal of matching up our predicted labels with
72:34 - the actual labels. And you can also see that reflected in the accuracy. So we start at somewhere
72:40 - around 50%, which is expected because our data set is comprised 50% of the hot dogs and 50% of
72:47 - not hot dogs. So initially, we would kind of expect it to be randomized. So our accuracy at first is
72:54 - 50%. And we see that it increases. And it actually does fairly well. After a while, it gets to an
72:59 - accuracy of 100%. Now, let's see if our validation data tells a different story. So remember, the
73:07 - validation data is not actually data that we pass into the training, our validation data is kind of
73:13 - this data that we set aside to evaluate how our model is performing in the process. So if I come
73:21 - over here, we see that our loss is starting to decrease. So then it actually kind of goes back
73:28 - up. And we also see that with our accuracy, okay, it starts to go up to maybe about 73%. And then
73:38 - it starts to decrease again, and it kind of stays steady. And our actually our loss also increases
73:46 - up to around 2.93. Even though our training loss is extremely small, and our training accuracy is
73:56 - 100%. So what is going on here? Chances are what we're doing is overtrading our model. Essentially,
74:04 - what that means is that we've passed so much data into this model so many times, that the model has
74:10 - actually remembered each piece of data. And that model, when it remembers each piece of data, it
74:16 - can actually predict all of your training labels 100% correctly. But when it sees new data, it can't
74:23 - really generalize. And so that's why you see this decrease in accuracy and loss. Alright, so what
74:29 - we're going to do is actually go back in this model and see if we can make any changes to make this
74:36 - more robust. Now, one thing that we can do is add something called dropout layer. So after each max
74:44 - pooling, I'm going to insert a layer called dropout. And I'm going to set this parameter to point to
74:52 - five. What this is doing is saying at, you know, just randomly, during the training, we're going
74:58 - to turn off 25% of the connections in between this layer, sorry, this layer, and this one. And so by
75:08 - turning off these connections, you're essentially training the model to be, I guess, susceptible to
75:14 - a little bit of randomness, you're trying to train your model, so that you, you know, might not have
75:20 - the exact same features every time, but you get the same output. So I'm going to go ahead and add
75:27 - this to some of the layers. Okay, so now I'm going to do this before we flatten. And that's going to
75:34 - be my dropout layers. One more thing that I wanted to add to this model before we actually ran it was
75:41 - some data augmentation as well. So I'm going to insert some code up here, and call this data
75:47 - augmentation. So here, I'm going to use tf.keras.sequential. This is going to be our data
75:55 - augmentation layer, which means that when the data when the image is passed into the model,
76:01 - we're actually going to perform some operations on it. So here, what I'm going to do is first pass in
76:10 - a random flip layer that will flip it along the horizontal axis. And then I'm going to pass in
76:22 - a random rotation layer. And then I'm going to pass in this random rotation and use the factor
76:30 - 0.2 to randomly rotate within the range of negative 20% times two pi and then positive 20%
76:39 - times two pi. So basically, when our image is passed in, after it gets rescaled, we can add
76:45 - model dot add this data augmentation layer, which will essentially perform these operations on our
76:53 - input data. Alright, let's take a look at how this data augmentation function actually does to our
76:58 - data. So I'm going to actually try to extract the first image from our original training data set.
77:04 - I'm just going to get that first image. And then let's actually show that image. Oh, no,
77:20 - that's not what I wanted. I wanted to take the first one. So I have this dot take there. Okay.
77:29 - And then let's show that image. Alright, cool. Let's run this again. Let's get a more square image.
77:42 - Okay, cool. So we have this like ramen over here. So now what I want to show you is what data
77:48 - augmentation does and how this is actually being rotated. So something that I'm going to do is I'm
77:54 - going to cast this to a batch so that we can actually put it through our data augmentation
78:00 - layer. Now what that means is I need to expand the dimension. So essentially, I just want a list
78:06 - where the only thing in the list is my image. In order to do that, I need to use expand dimensions.
78:14 - And I'm passing in the image, and I'm just going to expand it along the very first dimension. So
78:18 - that's what the zero is, it just saying, okay, like put this into an like a list holder. And
78:26 - I will actually cast this as well into float 32. And one more thing is that this currently holds
78:37 - values from zero to 255. But when we actually show the image, it's going to expect from zero to one.
78:44 - So I'm just going to right here divide this by 255. Okay. And now we can finally show what the
78:55 - figures would look like with the data augmentation. So if I create a figure with fig size equal to
79:02 - 1010 or something, I'm just going to plot this with nine rotations. And I can create an augmented
79:13 - image and call my data augmentation pipeline on this image. And now let's just plot that. So let's
79:23 - define the axes for the subplot. And it'll be a size three by three. And then I'm going to show
79:33 - this on the figure. So let's do the augmented image. And remember that the augmented image is
79:38 - a container that holds our image. So I actually have to index into that in order to get the
79:43 - image itself. And I'm just going to turn off the axes. Now if I run this, let's see what happens.
79:54 - Okay, so you see that we actually get different rotations of our food and maybe you know, some
79:58 - flips here. But essentially, it scrambles our data set a little bit, which is exactly what we
80:05 - need in order to build robustness, so that we don't get the same input data every single time.
80:10 - So I'm just going to add that as a layer right here. So let's run this, run this. And so essentially
80:19 - what I've done is I've added this data augmentation to my input data. And then I've also created these
80:25 - layers of dropout that will allow us to train with certain nodes and connections missing at,
80:33 - you know, a given training interval. Alright, so one change that I'm actually going to make
80:38 - from this original model is I'm just going to move this dropout down here. So as far as I know,
80:45 - when you're building your model, they're, you know, general architectures work well, but there's no
80:51 - good answer for where should you place these, you know, layers? How many nodes should you have in
80:55 - these layers? How many? What should the stride length be? A bunch of different questions that,
81:01 - you know, what activation function do you use? These questions are things that are kind of almost
81:06 - a little bit trial and error from what I understand. Essentially, a lot of times what people will do
81:12 - is simply just try to go through and try a bunch of combinations based on stuff that's worked in
81:20 - the past and see, you know, what will produce the best outputs for you. Alright, so one more thing
81:25 - that I wanted to add to this was actually a kernel regularizer. And what that does is just it limits
81:32 - how much we can change the weights of a given kernel. So how I would do that is I would just
81:39 - pass in this kernel regularizer parameter here. And I would set this equal to tensorflow.keras
81:46 - regularizers. And let's just use an L two, so that we like, create a bigger penalty for bigger
81:53 - changes. And I will use 0.01 as my hyper parameter here. Now I'm also going to add that down here.
82:03 - Oops, added a period over here. All right, so I added this kernel regularizer to each of these,
82:13 - except for this top one. And just keep in mind that the kernel regularization is meant so that
82:18 - we can, the weights of the filters that we're using in the convolutions that we're training
82:23 - in the convolutions, those don't change super fast. And for the purposes of this project,
82:29 - I'm actually going to also decrease the number of nodes that we have in each of these layers,
82:34 - just so that trains a little bit faster. So but these are actually parameters that you in your
82:40 - free time can go and play around with you can play around this parameter, this where you insert the
82:46 - dropouts, different types of regularizers, different type of activation functions,
82:51 - and filter sizes, etc. So let's run. So let's run this cell. And I'm going to get
83:02 - I'm going to compile the model. And then finally, let's train the model down here.
83:06 - Okay, so now it is a waiting game. And we will just wait. Okay, so our model is finally done
83:18 - training, let's take a quick look at the results. So here we go from a training loss of 1.6,
83:24 - all the way down to something around 0.57, 0.56. And we see that the accuracy goes from 0.5 to
83:34 - around like 70%. So 50% to 70%. And this is remember on the training set. So now if we take
83:44 - a look at the validation set, so remember, this is a data that our model hasn't seen yet,
83:51 - it goes from around 1.2 and also 50% accuracy to something around 60% validation loss or sorry,
84:01 - 0.6 validation loss and 70% accuracy. So we have shown that we are effectively training a model.
84:09 - I will say that throughout, you know, when I was creating this video, the best accuracy that I
84:13 - could get was something around 75%. So for you guys, if you go back, play with some hyper
84:18 - parameters, the layout of the model, different activations, regularizers, etc. And if you have
84:24 - an accuracy that's better than 75%, please do share it with everybody. I would love to learn from you.
84:31 - So what this means is our model can achieve something around 70% accuracy on classification
84:37 - of hot dogs versus not hot dogs on this image. And now ideally, we would have also had some sort
84:43 - of test data set that we could try this model on. But unfortunately, our data set did not come with
84:49 - that. And I did not create that. So that's okay. We're going to use our validation data set to
84:55 - actually just demonstrate that this works. So I'm going to paste here the the figure that we use in
85:01 - order to draw our data augmentation images. And instead of doing this, what I'm going to do is
85:09 - instead use image batches from our validation data set. So image batch and label batch. In
85:18 - our validation data set, take the first item, remember, it's a batch already of 16. So the
85:27 - images that we want to use are this image batch. And the labels that we want to use are this label
85:35 - batch. There's probably a better way to do this, but I couldn't get it working. So this will suffice
85:41 - for now. And then so let's run that. Okay, and then here. So in this range nine, instead of an
85:53 - augmented image, what I'm going to do is actually just plot the image so that we can see what it
85:59 - looks like. So instead, we're going to take the images and get the ith image from that. And let's
86:08 - print all of these. From me looking at this, clearly, this is a hot dog. I don't think that's
86:15 - a hot dog. Can't really tell what that is. hummus, hot dog, garlic bread, hot dog, hot dog, oysters,
86:23 - and it looks like sausage and waffle. And now if we look at our labels, one means that our model
86:30 - thinks it's a hot dog, zero means that it doesn't think it's a hot dog. So for the first row, we get
86:35 - yes, no, no. So we get hot dog, not a hot dog, not a hot dog. And then we get yes, no, yes. So hot
86:43 - dog, not a hot dog, hot dog. And then yes, no, no. So hot dog, not a hot dog, not a hot dog. And so
86:50 - our model actually in these nine images was able to classify all of them accurately. So we would
86:56 - literally be able to pass this image in, ask it, is this a hot dog or not, and it would be able to
87:01 - say yes, it is, which I think is pretty awesome. That concludes our introductory course on
87:07 - convolutional neural nets. Thank you guys all for being here with me today learning about the basics
87:13 - of machine learning, neural networks, how to train them, and finally, convolutional neural networks
87:19 - with our hot dog or not hot dog example. I hope that you guys learned a lot. And of course,
87:26 - post comments, let's help each other learn and we can all get better at ML together. Don't forget
87:31 - to subscribe to my channel Kylie Ying, I will actually be releasing a course on artificial
87:36 - intelligence later this year. So stay tuned. Transcribed by https://otter.ai