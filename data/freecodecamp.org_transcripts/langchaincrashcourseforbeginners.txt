00:00 - Lang chain is a framework designed to
00:02 - simplify the creation of applications
00:04 - using large language models it makes it
00:06 - easy to connect AI models with a bunch
00:09 - of different data sources so you can
00:10 - create customized NLP applications
00:12 - Rashad Kumar created this Lang sync
00:15 - course for beginners he is an
00:17 - experienced engineer and a great teacher
00:19 - let's learn about what langchin is
00:23 - sulang 10 is an open source framework
00:25 - that allows developers working with AI
00:27 - to combine large language models like
00:30 - gpt4 with external sources of
00:33 - computation and data the framework is
00:36 - currently offered in Python in
00:39 - JavaScript well typescript to be
00:41 - specific and you can combine large
00:44 - language models like gpt4 from open AI
00:47 - or hugging phase to your own application
00:50 - so it's an open source framework that
00:52 - allows you to build you know AI llm
00:54 - applications allows you to connect a
00:57 - large language model like tpt4 to your
01:00 - own sources of data and we are not
01:02 - talking about you know pasting a snippet
01:04 - of text into chat GPT prompt we're
01:07 - talking about referencing an entire
01:10 - database filled with your own data so it
01:12 - could be you know a book that's in PDF
01:15 - format that you have converted into the
01:17 - right format for these llms to use which
01:21 - are known as Vector databases and not
01:22 - only that once you get all this
01:25 - information you need you can have leg
01:28 - chain to perform a certain Action For
01:30 - You by integrating external apis so
01:33 - let's say you want to send an email at
01:35 - the end of you know whatever task you
01:38 - did with your given data set and this is
01:41 - where the kind of the main Concepts come
01:44 - into play for the Lang chain framework
01:47 - so I built this diagram to better you
01:50 - know kind of understand the concepts so
01:52 - you have three main kind of Concepts
01:56 - you have components chains and agents So
02:00 - within components you know we have llm
02:03 - wrappers that allow us to connect to a
02:06 - large language model like gpt4 or
02:09 - hugging face then we have prompt
02:11 - templates
02:13 - prompt templates allows us to avoid
02:15 - having to hard code text which is the
02:19 - input to LLS
02:21 - and then we have indexes that allows us
02:24 - to extract the relevant information for
02:27 - the other labs
02:29 - the second concept is change the chains
02:32 - allow us to combine multiple components
02:35 - which are these here
02:37 - together to solve a specific task and
02:41 - build an entire application
02:44 - and finally we have the agents that
02:47 - allows llm to interact with its
02:50 - environment and any of the external apis
02:52 - remember how I talked about the task you
02:56 - want to perform after you have retrieved
02:58 - the information there is a lot to unpack
03:01 - in Lang chain and new stuff is being
03:03 - added every day but on a high level this
03:06 - is what the framework looks like but I
03:09 - have built you know kind of a demo app
03:11 - as you know projects are the way that
03:15 - all of this information basically sticks
03:18 - talking about requirements for this
03:20 - course so you will need python installed
03:23 - and specifically version 3.8 or higher
03:26 - and pip which is python package manager
03:30 - a code editor so I'll be using visual
03:33 - studio code but you can choose whatever
03:35 - code editor of your choices
03:38 - and also an open AI account since we'll
03:41 - be using the open AIS llm today to build
03:44 - our link chain applications I'll be
03:46 - using a Windows machine so all of the
03:48 - commands you'll see in the terminal will
03:50 - be for Windows users but they are quite
03:53 - similar on Mac OS or Linux systems so
03:56 - let's start with the first thing which
03:58 - is you'll need an openai account and in
04:03 - order to sign up for an opening account
04:05 - you can go to openai.com and click on
04:08 - login this will take you to the login
04:10 - screen
04:11 - I already have an account signed up with
04:15 - my Google account so I'll go ahead and
04:16 - log in the reason why we need openai is
04:19 - we will be using open AIS llm and we
04:23 - need an API key so if you click on your
04:26 - user account on the top right hand
04:27 - corner you can click on view API Keys as
04:30 - you can see I have generated a few of
04:33 - them in your case you'll not see any API
04:35 - keys so you can click on create new API
04:38 - key
04:39 - and this will give you a new openai API
04:42 - key now remember to save that safely
04:46 - somewhere because as you can see you
04:48 - can't reveal the API key again so once
04:51 - you create a new one it'll be only
04:53 - revealed one time so save that and we'll
04:56 - be using it later as an environment
04:58 - variable in our code so now let me open
05:02 - up my terminal here and what I'm going
05:04 - to do is create the project directory
05:07 - where our code will reside so I want to
05:10 - make sure I'm in the right directory on
05:12 - my computer here which is GitHub and
05:16 - I'll create a new directory by typing in
05:18 - the command mkdir and we'll call this
05:21 - Lang chain Dash llm-app now let's change
05:26 - our directory to our project directory
05:28 - here and let me open it up in Visual
05:31 - Studio code which is the editor of my
05:34 - choice again you can use any code editor
05:37 - that you like okay now that we have of
05:39 - the project directory open in Visual
05:41 - Studio code I'm just going to open up a
05:44 - terminal in my visual studio code here
05:46 - what I want to do now is create a
05:49 - virtual environment so we'll be using
05:51 - Python and we'll be creating a virtual
05:54 - environment and you can do that by
05:55 - typing python Dash mvnv and then dot VNV
06:00 - so this is the command and then dot VNV
06:04 - is the directory where the virtual
06:05 - environment will exist and as you can
06:07 - see on the right hand side where my
06:10 - project directory is open we have a
06:13 - folder now called dot V EnV and once we
06:16 - have that prepared we'll need to
06:19 - activate this virtual environment and
06:21 - you can do that on Windows by typing in
06:24 - E and V scripts and then
06:27 - activate.ps1 which is a Powershell
06:29 - script that will activate our virtual
06:31 - environment as you can see there is a
06:33 - green virtual environment text in the
06:36 - front of the prompt so this means the my
06:38 - virtual X environment has been active
06:41 - and now we'll use pip which is a python
06:44 - package manager to install the required
06:46 - packages that we'll be using today so
06:48 - I'm gonna do pip install and then Lang
06:50 - chain openai streamlit and also python
06:53 - dot EnV so Lang chain allows us to you
06:57 - know work with Lang chain using python
06:59 - open AI since we'll be using open Ai
07:02 - zlnm and then streamlit allows us to
07:05 - build interface for python applications
07:08 - and you'll be seeing it how streamlit
07:10 - makes it so easy to build interfaces and
07:12 - then python.env allows us to use dot EnV
07:16 - file which is where our openai API key
07:19 - will reside safely as you know
07:21 - environment variables in our python code
07:23 - hit enter
07:25 - okay so after some time all the packages
07:29 - should be installed and you can see my
07:32 - terminal is giving me a warning that a
07:34 - new version of pip is available so if
07:36 - you get same burning you can either
07:38 - upgrade it or you can ignore the warning
07:39 - for now I'll just hit clear so that my
07:42 - terminal has a clear screen but also
07:45 - I'll close it for now what I want you to
07:46 - do is now create a main dot Pi file so
07:50 - now we have main.pi we are python code
07:54 - for the site so let's start by importing
07:57 - Lang chain on the top and we'll be using
08:00 - llms I want to use open AI again I'm
08:03 - using open AI I know it will cost some
08:06 - money and I'll show you in my openai
08:08 - dashboard how much of the API calls cost
08:10 - but it's in cents but it is the best one
08:12 - if you want to use some other ones like
08:16 - the open source hugging phase llm models
08:19 - you can do that too Lang chin supports
08:21 - it but right now I'm happy with openai
08:23 - and also what I want to do is use dot
08:27 - EnV the python.env package that we
08:29 - installed to load our environment
08:32 - variables and we can initiate that by
08:35 - typing in load.env now I can go ahead
08:38 - and create a DOT EnV file and save my
08:42 - open AI underscore API underscore key as
08:46 - an environment variable here and this is
08:48 - where you will paste the SK Dash key
08:51 - that was created in the openai dashboard
08:53 - so let me do that and I don't want to
08:55 - reveal my open AI API key okay so I
08:59 - copied my API key from my open AI
09:02 - account and pasted it in EnV file here
09:05 - so I'll close that now what I want to do
09:08 - with the first sample application here
09:10 - is generate pet names so let's say I
09:14 - have a pet dog and I want to generate
09:16 - some cool names for it and maybe we'll
09:19 - add few parameters where people can
09:22 - select what kind of pet it is and maybe
09:24 - color so let's to start with that
09:27 - function so you can define a function in
09:29 - Python by typing in Def and then we'll
09:32 - call this generate underscore pet
09:34 - underscore name and now we'll be using
09:37 - llm from our Lang chain library and as I
09:41 - said I'll be using openai today so this
09:43 - has few properties one of them is
09:46 - temperature now what temperature means
09:49 - is how creative you want your model to
09:52 - be so if the temperature is set to let's
09:54 - say 0 it means it is very safe and it is
09:58 - not taking any bets or risks but if it
10:01 - is set to 1 it will be very creative and
10:04 - will take risks and also might generate
10:07 - wrong output but it is very creative at
10:09 - the same time so I tend to set my
10:12 - temperature to be 0.5 or 0.6 so that you
10:16 - know it can get a little bit of creative
10:18 - so let's set that by typing in
10:20 - temperature
10:22 - and now what I want to do is use this
10:25 - llm to create cool names for my pet
10:28 - which is in my case a DOT so I'll type
10:32 - something like I have a dog pad and I
10:33 - want cool names for it suggest me five
10:36 - cool names so that's what our luncheon
10:38 - app is gonna be it'll suggest five cool
10:40 - names for your pet so let me type that
10:43 - out as a prompt okay so I have my prompt
10:46 - ready and this function will return the
10:49 - name and now what we can do is if name
10:53 - is equal to main which is you know
10:55 - boilerplate python code
10:58 - I wanted to print whatever that function
11:01 - generates so generate pet name will be
11:03 - printed in our console output so let's
11:06 - give this a try by opening up the
11:08 - terminal here and typing in Python main
11:12 - dot py so as you can see it gave me five
11:16 - names for my pet dog Apollo Blaze
11:20 - Hershey Kona and Maverick which are
11:23 - pretty good names and as you can see I
11:25 - ended up setting the temperature to 0.7
11:28 - so it's getting a little bit of creative
11:30 - again you can you know test this out by
11:33 - toggling this between 0 to 1 and see
11:37 - what temperature suits your needs but
11:40 - for me yeah 0.5 to 0.7 anything between
11:43 - that is good since I need my llm to be a
11:46 - bit creative so we just introduced one
11:49 - component of Lang chain which is llm the
11:52 - next thing that I want to introduce you
11:55 - to is promptemplate so prompt templates
11:58 - make it easy to generate these problems
12:01 - so you don't have to keep asking openai
12:05 - a different prompt every time right so
12:07 - we want to repurpose this so that people
12:10 - on the internet might be able to
12:11 - generate pet names so maybe we will
12:13 - create you know imagine that you want to
12:15 - create a web app where people can
12:17 - comment and read pet names we want to
12:19 - repurpose this prompt and also we don't
12:21 - want to hard code dog and if we want to
12:24 - have pet color as an option we don't
12:27 - want to hard code that so we want the
12:29 - ability to repurpose our llm prompt for
12:34 - different kind of animals and different
12:35 - kind of colors and the way we can do
12:38 - that is by using prompt templates so
12:41 - prompt template name let's just call it
12:44 - that and in Lang chain it's called
12:47 - prompt template and we will also have to
12:50 - import it from Lang change so going to
12:52 - the top let's import prompt templates
12:55 - okay so you're using Lang chin prompts
12:57 - and importing prompt template now you
12:59 - can see the squiggly line underneath it
13:02 - has gone so let's give it to let's give
13:05 - it an input variables so
13:08 - input variables are the parameters that
13:11 - can be dynamic so in our case it will be
13:14 - animal type right so animal underscore
13:17 - type and now we'll also have to add that
13:20 - as a parameter to our python function
13:22 - there we go so animal type is the input
13:25 - variable and the template that our
13:28 - prompt has is same as this so I'll copy
13:32 - this and instead of a dog pet I will use
13:36 - the input variable here which is animal
13:38 - underscore type so now you can imagine
13:41 - you can say hey I have a cat and some
13:45 - other person comes and says hey I have a
13:47 - cow pet and I want a cool name for it
13:49 - suggest me five cool names so that is
13:52 - what prompt templates allows you to do
13:54 - and now we'll have to also get rid of
13:57 - this and use chains as a concept so
14:00 - that's import chain from Lang chain from
14:03 - Lang chain dot chains import llm chain
14:08 - what llm chain allows us to do is put
14:11 - these individual components of Lang
14:14 - chain together so llm and Prime template
14:16 - in our case so llm chain llm is equal to
14:20 - llm in our case because we named it and
14:23 - prompt is equal to prompt template so
14:26 - I'll just copy this so prompt template
14:28 - name and instead of name let's call this
14:31 - name chain right since this is an llm
14:34 - chain and instead of returning name
14:36 - let's create a response here
14:40 - and that response basically will be name
14:43 - underscore chain and we'll be using the
14:46 - animal type parameter here right which
14:48 - is basically whatever the animal type
14:51 - the person specifies and will be
14:55 - returning the response here so response
14:58 - will be whatever this chain gives us the
15:01 - output has right now let's try instead
15:05 - of dog let's try cat right so we are
15:07 - using parameters to print five cool pet
15:11 - names using our name underscore chain
15:14 - which is the llm chain using openai and
15:18 - using this prompt template hit Ctrl s
15:21 - and going back to my terminal here
15:24 - let's run python main.py
15:27 - so now you can see we are getting a Json
15:30 - response with animal type which is cat
15:34 - and the text that we got is so these are
15:37 - the names that we got one is mochi or
15:40 - Moki nacho Pebbles tiger and whiskers so
15:46 - we got five names for our animal type
15:48 - cat similarly you can try cow here hit
15:52 - Ctrl s and run the python file again
15:55 - now it says animal type was cow and the
15:58 - text response is where our cow pet names
16:02 - are so one is hambone Daisy moo Moody
16:06 - Milky Way and give her hugs awesome so
16:09 - the other parameter that I want to add
16:11 - to our pet's name generator is the pet
16:15 - color because I think that is an
16:17 - important aspect when you name your pet
16:20 - right so pet color and so we'll add pet
16:23 - color as a parameter to our generate pet
16:25 - names function but also we'll have to
16:27 - add it as an input variable in our
16:30 - prompt template so let's add fat color
16:33 - over here there we go and now we'll also
16:36 - have to change the template itself so I
16:39 - have an animal type pet and I want a
16:42 - cool name for it and let's add it is
16:44 - whatever the color is so pet color
16:47 - so maybe it's black in color suggest me
16:50 - five cool names for my pet there we go
16:53 - so that is our new prompt
16:56 - hit control s and in the name chain
16:58 - we'll also have to add the pet color
17:01 - here so pet underscore color and that
17:05 - will be equal to whatever the pad color
17:07 - the person picks or says so now we can
17:12 - run this by saying cow and our cow color
17:15 - is black so let's let's try that out
17:18 - toggle back my terminal here and type in
17:20 - Python main.pi and you can see so we got
17:24 - animal type cow pet color is black and
17:28 - we received text response with those
17:30 - five names so one is Shadow second is
17:33 - midnight uh Starlight and we have Raven
17:36 - awesome so our pet's name generator is
17:40 - working as expected maybe I want to
17:42 - publish this as web app later right and
17:45 - that's where streamlib comes in
17:46 - streamlit will build us a web interface
17:49 - and we don't have to do much we can use
17:52 - our python file here to build that
17:55 - beautiful interface and then people can
17:58 - come in and select whatever pet kind
18:00 - they have and whatever pet color they
18:04 - have and it would output those five
18:06 - names utilizing the Lang chin app we
18:08 - built so in order to do that what I I
18:11 - want to do is instead of having all of
18:14 - this code in main.pi I want to create
18:18 - another file called Lang chain
18:20 - underscore Helper and this is where all
18:24 - our Lang chain code will go so I'm going
18:27 - to go into main.pi Ctrl a to select all
18:31 - the code and paste it in the langchin
18:34 - helper file here and then we can clear
18:37 - the main.pi so our main.pi is blank and
18:40 - I have moved all my code to Lang chain
18:43 - underscore helper.py hit Ctrl s so make
18:46 - sure you have saved that and in main.pi
18:49 - what I want to do is input our Lang
18:52 - chain helper Library so we can do that
18:55 - by doing Simple import statement on the
18:58 - top so I'm importing Lang chain helper
19:00 - as lch just short form so that I'll be
19:04 - able to call our generate pet name
19:07 - function by just using lch dot right
19:10 - also remember we did pip install
19:13 - streamlit in the beginning so we'll be
19:15 - using that here too and I'll be calling
19:18 - it throughout the python code AS SD
19:20 - which is just short for streamlit so in
19:23 - order to create our streamlit app you
19:25 - can use different text types and you can
19:29 - also use markdown which streamlit will
19:31 - render but one of the main things is
19:34 - having a title for our web interface and
19:37 - you can do that by doing St dot title
19:40 - and we'll call this pet's name
19:43 - generator
19:45 - right hit save and now I'll just show
19:48 - you how to run a streamlined app where
19:50 - you can do that is open the terminal and
19:53 - type in streamlit run main.py hit enter
19:56 - and let me open my browser on Port 8501
20:02 - there we go so as you can see
20:05 - right out of the box we have this
20:07 - interface that was built using streamlit
20:09 - and again if you haven't heard about
20:10 - streamlit it's an amazing tool you can
20:13 - go to streamlit.io and go through their
20:16 - documentation on how to even make your
20:20 - web app better since I'll be using some
20:22 - basic components from streamlit to
20:25 - display our pet's name generator
20:27 - beautifully so let's get back to our app
20:31 - here so back in our code editor I'll hit
20:34 - Ctrl C in my terminal to stop the
20:36 - streamlit app and bring my terminal down
20:39 - and now we need some variables and Logic
20:43 - for the ability for users to pick their
20:46 - pets and the pet color so one of them is
20:49 - the animal type right whether it's dog
20:51 - cat or a cow will give a sidebar
20:54 - selection for our users so SD dot
20:58 - sidebar dot select box will allow you to
21:01 - do that and you can input what the
21:04 - question is so what is your pet question
21:09 - mark and then you can include the
21:11 - options so it will be a drop down where
21:15 - people can select cat right dog and cow
21:19 - and maybe a hen right so think of all
21:22 - the pets then people that people can
21:24 - have maybe hamster is more popular I
21:26 - guess so cat dog cow hamster and then
21:29 - you can just keep going so that is the
21:31 - animal type and I can show you how this
21:33 - looks on our streamlit apps so streamlit
21:35 - space run space
21:38 - so you can see that and I can zoom in a
21:41 - little bit on the left hand side we have
21:43 - a sidebar now and you can select what
21:46 - kind of pet you have so what is your pet
21:48 - the next logic that I want to build is
21:51 - another option to select the color of
21:54 - your pet but I want it in a way that
21:56 - once you have selected the pad type so
21:59 - animal type right if it's cat it should
22:02 - say what color is your cat and we can do
22:04 - that by if statements so if animal
22:07 - underscore type is cat right I want pet
22:11 - color which is another variable we pass
22:14 - to our generate pet name function here
22:18 - you can say pet color is equal to and
22:21 - then we use the select box component
22:24 - from streamlit to ask what color is your
22:29 - cap now I feel like there can be
22:32 - different variations so you can't just
22:34 - put in black blue white orange
22:39 - you know since with cows and even cats
22:42 - and dogs you can have multiple colored
22:44 - pets right like a white dog with black
22:47 - spots on it so we can't have a select
22:50 - box let's just keep this as a text to
22:52 - you and I just thought of that as I was
22:55 - building this right so instead of a
22:58 - select box we have a sidebar with a text
23:00 - area that asks for what color is your
23:04 - cat and I also want to maybe have a
23:08 - limit of Maximum characters that people
23:10 - can put into this because remember we
23:13 - are calling the open AI API and the API
23:15 - calls depend on the amount of
23:17 - information you are sending in the
23:19 - prompt template so if our prompt gets
23:22 - bigger we'll be charged more so in order
23:25 - to limit that let's have a Max character
23:28 - property here again this is available on
23:30 - Shameless documentation and we'll use
23:34 - the label ER so the label is what color
23:36 - is your cat and the maximum characters
23:38 - that users will be allowed to put in is
23:40 - 15 and we can hit save what you can do
23:43 - is copy this over for dog cow so I'll
23:48 - put dog here and what color is your dog
23:51 - or dog for cow it will be what color is
23:54 - your cow and then I think we're left
23:56 - with one which is for hamster again I'll
23:59 - just copy this and paste for hamster
24:04 - okay there is an efficient way to do
24:06 - this but I'm just gonna copy the code
24:08 - that I already have go back to my
24:10 - browser here refresh my streamlit page
24:13 - and now you can see if we select dog it
24:16 - will say what color is your dog and you
24:18 - see the text area which has a limit of
24:20 - 15 characters similarly if you select
24:22 - the cow you can see it asks
24:26 - what color is your cup so both of the
24:28 - parameters have been set right now what
24:32 - I want to do is send this information to
24:36 - our Lang chain helper right because this
24:38 - is where it will generate those names
24:41 - and give it back to us so let's do that
24:44 - so after we have set the pet color
24:47 - right because that's the last question
24:49 - we ask our users what we want to do is
24:54 - have a variable here called response
24:56 - and response is equal to LC Edge which
25:00 - stands which is just short for Lang
25:02 - chain helper here and the function
25:06 - in the Lang chain helper is generate pet
25:08 - name
25:09 - so I'll copy that over so you do lch dot
25:12 - generate pet name so we are accessing
25:15 - that function animal type was the first
25:18 - parameter that we need again I'm using
25:21 - animal type as a variable here maybe we
25:24 - can
25:25 - say user
25:27 - underscore animal type and I'll have to
25:31 - change that over here
25:33 - over here over here and over here again
25:37 - just so that you're not confused so
25:40 - two parameters animal type and pet color
25:42 - and then I'm using the user animal type
25:45 - as a variable on our main.pi so user
25:48 - underscore animal underscore type and
25:50 - the second parameter is pet color again
25:53 - you can do the same here so user
25:56 - underscore pet underscore color and
25:58 - you'll have to update all of these here
26:00 - just to avoid confusion so we are
26:03 - passing these variables that the user
26:06 - said so user will say I have a dog and
26:09 - its pet color is white and we are
26:12 - passing those to our generate pet name
26:16 - function and then we'll just write that
26:19 - as a text field so our text Will field
26:22 - will just reply with response so let's
26:25 - save that
26:27 - now let's go back to our browser here
26:30 - hit refresh
26:31 - now let's select dog and type in the
26:35 - color black
26:37 - and you can hit Control Plus enter to
26:40 - apply
26:42 - and you can see we got a response
26:45 - with the five pet names right
26:49 - and
26:51 - what you can do to display this
26:53 - beautifully
26:55 - is set an output key right
26:59 - so let's go back to our Lang chain
27:01 - helper here and in the name underscore
27:04 - chain We'll add a third property called
27:06 - output key right and the output key is
27:10 - pet underscore name so basically instead
27:13 - of giving us a text output it will
27:16 - associate those five names that it
27:18 - generated to this output key and we can
27:21 - access this in our main.pi so instead of
27:25 - just returning the entire response so
27:27 - the whole text here see how it looks
27:30 - weird we'll just we'll just access the
27:33 - names that it generated and we can do
27:36 - that by doing response and then
27:38 - accessing that
27:40 - underscore name which was the Kiwi set
27:44 - so hit Ctrl s go back to our browser
27:47 - window and click refresh this time let's
27:49 - go with the cat which is white hit
27:52 - Control Plus enter to apply
27:54 - and you can see it displays the text now
27:58 - better right it looks beautiful and we
28:01 - have the recommendations here as snowy
28:04 - marshmallow cotton pull blizzard let's
28:07 - go over the brown hamster so hamster
28:10 - and brown Coco mocha Chestnut caramel
28:14 - biscuit
28:16 - love those names so now
28:18 - as you can see we have a streamlit app
28:21 - and we are using Lang chain to generate
28:23 - five cool pet names for the pets that we
28:27 - might have and we saw how you can use
28:30 - another lamp prom templates and the
28:34 - chain which are three main components of
28:38 - Lang chain but now the important one
28:41 - that's left is Agents right so agents
28:45 - allow llms to interact with the
28:48 - environment so think of apis or things
28:51 - you want to do after Gathering the
28:53 - information so going over the Lang chain
28:56 - documentation about agents the core idea
28:58 - of Agents is to use an llm to choose a
29:02 - sequence of actions to take in Chains a
29:05 - sequence of actions is hard coded in
29:08 - code
29:09 - whereas in agents a language model is
29:12 - used as a reasoning engine to determine
29:15 - which actions to take and in which order
29:18 - and there are several key components
29:20 - Langton provides a few different types
29:23 - of agents to get started even then you
29:25 - will likely want to customize those
29:27 - agents depending on the personality of
29:30 - the agent and the background context you
29:32 - are giving to the agent and then there
29:34 - are tools so tools are functions that an
29:37 - agent calls there are two important
29:40 - considerations giving the agent access
29:42 - to the right tools and describing the
29:45 - tools in a way that is most helpful to
29:48 - the agent so let's test it out so we
29:52 - already have a pet's name generator
29:55 - thing that's working for us right gives
29:57 - us a name for our pet
30:00 - now let me create another function here
30:03 - which will name Lang chain underscore
30:06 - agent and before we can interact with
30:10 - the agent we have to import the Lang
30:13 - chain Agents from the framework so you
30:15 - can do that by adding these three import
30:18 - statements on top so we are importing
30:20 - tools we are also importing the
30:23 - initialization of the agent and the
30:26 - agent type so coming back to our
30:28 - function here so first we'll Define the
30:30 - llm that we want to use and I still want
30:33 - to use the openai llm and the
30:35 - temperature will set it to 0.5 here and
30:39 - then we can load some tools
30:42 - that will perform the given action so
30:45 - there are various tools that are
30:48 - available and again you can go through
30:50 - the availability of tools or the list of
30:53 - tools on the link chain documentation
30:55 - but I'll be using Wikipedia which will
30:59 - be the first tool I want to use and I'll
31:01 - get to it why I want to use Wikipedia
31:03 - and the other one is llm matte because I
31:06 - want to perform some matte and this is
31:07 - to just showcase what agents can do
31:10 - right and then the llm that we'll be
31:14 - using is defined here which is the open
31:16 - AI so llm is equal to llm right and now
31:20 - we'll have to initiate the agent so
31:23 - agent and to initialize its initialize
31:27 - underscore agent
31:28 - and here you specify the tools that will
31:32 - be providing it which is stored right
31:35 - here which is Wikipedia and lmat the llm
31:38 - we want to use right
31:39 - and the agent type so one of the agent
31:43 - types that's available in the quick
31:46 - start guide for langchain is the react
31:49 - and you can go to the agent types
31:51 - documentation here so zero shot react is
31:55 - the one that I'll be using decision uses
31:58 - react framework to determine which tool
32:00 - to use based solely on the tools
32:03 - description so heading over to our code
32:06 - and the way you define that agent type
32:09 - is by setting it here and we'll set the
32:13 - verbose flag to True which means it'll
32:16 - show us the reasoning that'll happen in
32:19 - our console so that's the agent we want
32:22 - and we'll create a result here where we
32:26 - run the agent and now you can specify
32:29 - the tasks so you want to perform through
32:32 - this agent so since our app is solely
32:35 - based on pets let's ask it what is the
32:38 - average age
32:40 - of a dog and I'll ask it to do some math
32:44 - and that is the reason why I loaded the
32:46 - llm math tool here multiply the age by
32:50 - three and at the end we'll print result
32:52 - so that looks good and I will change
32:55 - this so I'll comment this out instead
32:58 - we'll print whatever this generates so
33:01 - Lang chain agent right hit save and now
33:04 - we can run this and just to demonstrate
33:07 - it I'll not be
33:09 - linking this to our streamlit app which
33:11 - was the web interface I'll just run the
33:14 - Lang chain underscore helper python file
33:17 - just to Showcase you how agent works so
33:20 - before I do that I have to make sure
33:22 - that Wikipedia is installed through pip
33:25 - so pip install Wikipedia will install
33:27 - that python Library so now if I run the
33:31 - langchin helper file we'll see the agent
33:34 - in action okay so you'll see that it
33:38 - finished the chain and the answer was
33:40 - the average of a dog is 45 years when
33:43 - multiplied by three but the final answer
33:46 - that it got was 15 right so the average
33:49 - age of the dog is 15 and then it
33:52 - multiplied by 3 which is 45. so you can
33:55 - see that it was able to grab the
33:58 - information from Wikipedia which is 15
34:01 - as the average age of a dog and it was
34:05 - also able to perform the math and get to
34:08 - this right and now since we set the
34:11 - verbose flag to true you can see the
34:13 - reasoning that went into it right and
34:15 - I'll increase my terminal and with no
34:18 - size here and get rid of the file
34:21 - explorer on the right so you can see
34:23 - I need to find out the average age of a
34:26 - dog action is Wikipedia action input is
34:30 - averages of talk and this is the
34:32 - observation that it found right so it
34:35 - did scan few pages on Wikipedia
34:38 - thought I now know the average age of a
34:41 - dog and the age of the oldest dog right
34:43 - and then action is calculator where it's
34:46 - trying to multiply 15 which is the
34:48 - average age by three because that's what
34:50 - we asked it to do awesome so that's how
34:53 - the agents work and I believe we have
34:56 - kind of covered almost all components
34:59 - within the langchin framework the only
35:01 - thing that's left is indexes right so
35:05 - what are indexes basically as you can
35:08 - see we are still working with the open
35:12 - AI llm but we are also not providing any
35:15 - of the custom knowledge right so we are
35:18 - still relying on open Ai and the
35:21 - information that they have gathered but
35:23 - with langchain you can also provide your
35:26 - own knowledge or knowledge base on which
35:28 - you can ask llm to do certain actions so
35:32 - think of a PDF file or even URLs that
35:36 - you can script or maybe you have a large
35:40 - PDF file with a lot of text and maybe
35:42 - you want to run an llm AI chat bot for
35:46 - your own document so you can do that
35:48 - with the help of language in the next
35:50 - project that I want to showcase you will
35:52 - exactly do that will take a long YouTube
35:55 - video so think of a podcast which is
35:58 - hours long or a long YouTube video right
36:01 - so what I have here is
36:04 - the Microsoft CEO certain dealer full
36:07 - interview on recode but it's 51 minutes
36:09 - long and what I want to do with Lang
36:12 - chain is the ability to ask questions to
36:16 - this video so the context that the llm
36:19 - would have is strictly of that video and
36:22 - I'll be using few libraries like YouTube
36:25 - transcript which basically converts
36:28 - whatever URL we provide for a YouTube
36:30 - video and gets its transcript right so
36:33 - let's build this YouTube assistant now
36:36 - I'm going to show you how you can create
36:37 - this assistant that can answer questions
36:40 - about a specific YouTube video so coming
36:43 - back to the concept of indexes I touched
36:47 - briefly on it but we also saw it in the
36:49 - Lang chain diagram but we know that
36:51 - these large language models become
36:54 - really powerful when you combine them
36:55 - with your own data and your own data in
36:58 - this scenario will be the YouTube
37:00 - transcript that we are going to download
37:02 - automatically but you can basically
37:04 - replace that transcript with any
37:07 - information in this approach so it could
37:09 - be a PDF it could be blog post URL right
37:13 - so what Langton offers is document
37:16 - loaders
37:17 - and I can quickly show you the YouTube
37:21 - transcript one so this is the YouTube
37:23 - transcript and basically it allows you
37:26 - to get the transcript which will be the
37:28 - text version of the YouTube video right
37:31 - but there are several other document
37:33 - loaders that you can see on the left
37:35 - hand side right so you can bring in an
37:38 - S3 file you could bring an Azure blob
37:41 - storage file you could do Hacker News
37:44 - posts or articles right so these are
37:48 - some of the document loaders that are
37:50 - supported by linkchin as of now and
37:52 - we'll be using text Splitters and Vector
37:55 - stores so we are going to use these
37:57 - three components to load our YouTube
37:59 - video transcript split it into smaller
38:02 - chunks and then store it as Vector
38:04 - stores so you can think of these as
38:06 - little helper tools that will make it
38:09 - easy for us to load the transcript which
38:12 - might be thousands of lines of text so
38:16 - to get us started what I have already
38:18 - done is created a YouTube assistant
38:21 - directory so not be using the pets
38:24 - generator directory that we had and what
38:26 - I have done is pretty similar to the
38:28 - pet's name generator right so I have
38:30 - main.pi which will hold our streamlit
38:33 - interface and then the langchin helper
38:35 - will have the length chain components
38:39 - and I've also created a virtual
38:41 - environment and installed all the
38:44 - necessary packages which is link chain
38:46 - openai YouTube transcript also I've I
38:50 - went ahead and created dot EnV file
38:52 - which holds my openai API key so pretty
38:56 - similar to the pet's name generator and
38:58 - now we can start with the lag chain
39:01 - helper first so the first thing that we
39:03 - are going to import is the YouTube
39:05 - loader that we saw right which is a
39:09 - document loader so from langtin dot
39:11 - document loaders we are importing that
39:12 - YouTube loader and the second important
39:15 - thing we need is the text splitter so as
39:19 - I showcased that the video that I have
39:21 - is 51 minutes long you could also pick
39:25 - up a podcast like Lex and they have
39:29 - podcasts that are three hours long and
39:32 - which means you'll have thousands of
39:35 - lines and that is where we'll use the
39:37 - the text splitter to break down those
39:41 - huge transcripts into smaller chunks and
39:43 - I'll show you how and for the rest of
39:45 - the inputs we are gonna input the lag
39:49 - chain components like the llm which will
39:51 - be open AI prompt template and llm chain
39:54 - the other thing
39:57 - coming back to indexes we'll be using
39:59 - Vector stores so I'll be using the phase
40:02 - library and
40:04 - I'll quickly show you what the face
40:06 - library is phase is a library by meta or
40:11 - Facebook for efficient similarity search
40:14 - and you might have heard of other Vector
40:17 - stores or databases like Pinecone or vv8
40:21 - right but I'll be using phase for this
40:25 - project so let's start with writing some
40:28 - code so I've done all the necessary
40:30 - inputs here the only input that's left
40:34 - is the dot EnV which will load our
40:37 - environment variables and I'll initiate
40:40 - dot EnV here also since I'll be using
40:44 - openai embeddings so we'll initiate that
40:47 - to here and I forgot to import those so
40:51 - I'll import the open aim bearings and
40:54 - now we can create our first function to
40:57 - create a function we know that in Python
41:00 - it's deaf and let's name this function
41:02 - that will be be creating a vector DB
41:08 - create Vector DB from YouTube so that's
41:11 - a pretty big function name right but I
41:14 - want to specify what we are doing and
41:16 - we'll be using phase here also for the
41:20 - parameter let's give this a required
41:22 - parameter which is the video URL right
41:25 - so we'll be pasting this video URL in
41:28 - our streamlit interface and that's what
41:30 - we'll be using and this will be a string
41:33 - right so the first thing we want to do
41:35 - is load the YouTube video from the URL
41:40 - right so we'll use loader which we
41:42 - imported on the top so YouTube loader
41:46 - Dot from YouTube URL and we'll pass the
41:50 - video URL parameter here after we have
41:52 - loaded the YouTube video I want to save
41:55 - this into the transcript variable so
41:58 - we'll create transcript here and we'll
42:00 - just do loader dot load and this should
42:04 - give us the transcript now we'll be
42:07 - using text splitter and I'll
42:08 - specifically tell you why so text
42:12 - splitter and we imported it here as
42:15 - recursive character text splitter you
42:18 - can specify few parameters
42:20 - when using this so the first one is
42:22 - chunk size
42:24 - which will set to 1000 and chunk overlap
42:27 - so chunk size is how much each chunk
42:31 - will contain so for me it will be 1000
42:34 - right and then overlap is once it has
42:37 - created those individual docs from the
42:40 - long transcript it'll have an overlap in
42:43 - every document so document one the last
42:45 - hundred words would also be included in
42:48 - the document twos first hundred words
42:50 - right so that is what overlap is
42:53 - and now we'll save them into a docs
42:56 - variable so text underscore splitter not
42:59 - split documents as the function and
43:03 - we'll provide the transcript that we had
43:06 - loaded from the YouTube url there we go
43:08 - okay
43:10 - now let's also initiate the phase so
43:14 - phase Dot from documents and we will be
43:19 - using docs which we stored here right
43:22 - docs and we'll be using the open Ai
43:25 - embeddings and we'll return this DB
43:29 - okay
43:30 - so now on to the explanation why we have
43:33 - to split the text so basically what we
43:37 - are doing at the text splitter is we
43:40 - have taken over thousands of lines and
43:43 - split up the documents so it has taken
43:46 - very large transcript over and split it
43:49 - up into chunks of 1000 so that is the
43:51 - first step now you might wonder right so
43:53 - we can't just provide thousand lines to
43:57 - the open AI API remember there is a
44:00 - token size or a limit on how much
44:04 - information you can send to open AIS API
44:07 - and that is why we have split the amount
44:10 - of context we'll be sending for for a
44:13 - YouTube transcript right because the
44:15 - model that I'll be using is the text
44:18 - DaVinci 003 and as you can see it can
44:22 - only take
44:24 - 4097 tokens so I cannot send the entire
44:28 - transcript to open aiz Ai and that is
44:32 - why we'll be splitting it and storing it
44:35 - into Vector stores
44:36 - again this is quite technical I'll not
44:40 - go into much detail but vectors
44:42 - basically are a numerical representation
44:45 - of the text we just created here right
44:48 - so the core responsibility of this
44:52 - function is to load the transcript right
44:55 - take all the text that's in the
44:57 - transcript split it into smaller chunks
45:00 - and then save those chunks as Vector
45:03 - stores again we can't just provide all
45:06 - of these Vector stores to the open AI
45:08 - right we can't just send over the 10 000
45:11 - or maybe even 50 chunks that we have
45:15 - created of smaller text that's where
45:17 - we'll use phase to do a similarity
45:20 - search right and that's what the next
45:23 - function will be and before I write that
45:25 - next function we'll see if this works so
45:29 - video underscore URL so I'm gonna hard
45:32 - code the video URL that we have for the
45:35 - podcast and see if we get the smaller
45:39 - chunk documents right so let's print
45:42 - this function at the end
45:47 - hit save and we'll open the terminal
45:50 - make sure your virtual environment is
45:53 - activated and you have installed the
45:56 - required packages again all of this will
45:58 - be available on GitHub for reference
46:01 - later but let's run the line chain
46:03 - helper python file again it'll take some
46:06 - time to do the computation
46:08 - I missed to write print so we'll have to
46:12 - print this whatever this function
46:15 - returns which should be the database
46:17 - that we created right so let's run it
46:20 - again and this time we should get the
46:23 - vector stores that were created and so
46:25 - instead of DB if I return docs you'll
46:29 - see those chunks
46:32 - so if I expand my terminal here you can
46:36 - see we have quite a few text here but
46:39 - here are the docs right so you can see
46:43 - that there's a document and then it
46:46 - starts with the content and you'll see
46:48 - multiple document chunks so these are
46:51 - the chunks that we created from the
46:53 - larger transcript so this is one right
46:56 - this is the second one
46:58 - and so on I know the formatting is weird
47:01 - so you can't really tell where the new
47:04 - document starts but yeah this is all the
47:06 - chunks that we have awesome so our
47:09 - function to create the vector DB from
47:11 - YouTube url is working as expected so
47:14 - I'll get rid of this print statement and
47:17 - full return DB here now for the next
47:19 - function which is going to be getting
47:22 - off the response on our query we have to
47:26 - ask this YouTube video right so let's
47:30 - create that function we'll name it get
47:32 - underscore response from query again
47:36 - pretty self-explanatory name for the
47:39 - function itself and we'll pass few
47:41 - parameters to this function one is DB
47:44 - the important one will be query which
47:47 - will be the question that the user asks
47:49 - and K which is another argument that
47:52 - I'll go over this is used for the
47:54 - similarity search that will do so keep
47:56 - in mind the amount of tokens that the
48:00 - text DaVinci 3 Model can take right so
48:03 - keep that in mind it's 4097 so I'll just
48:06 - add a comment here saying text DaVinci
48:10 - can handle 2097 tokens right now in
48:15 - order to do a similarity search we'll
48:17 - save that into a docs variable within
48:20 - this function so DB
48:22 - is what we'll use we'll perform a
48:24 - similarity search on the DB which is the
48:27 - database we created in the previous
48:29 - function so gb.similarity underscore
48:32 - search and the search will be basically
48:35 - the query so the first thing I want to
48:37 - do with this function is basically
48:39 - search the query relevant documents so
48:42 - let's say in this podcast they talk
48:45 - about a ransomware somewhere so right
48:48 - here they talk about ransomware right
48:50 - and if I want to ask a question saying
48:53 - what did they talk about ransomware so
48:54 - my query is just about ransomware that
48:58 - that they talked about in the podcast so
49:00 - it will only search the document that
49:03 - has details about ransomware so we'll
49:06 - not send the entire documents that were
49:09 - created but just the one that is
49:12 - relevant to the query that the user made
49:14 - I hope that makes sense and this is also
49:17 - where we'll pass the K as argument and
49:20 - I'll tell you what K is so remember that
49:25 - we can have
49:26 - 4097 tokens but our chunk size is 1000.
49:31 - so that means we can kind of send four
49:35 - documents right because each document is
49:39 - a size of thousand so let's set that
49:41 - value to four okay so we'll be sending
49:44 - four relevant docs based on the query
49:47 - that the user made now I'll create
49:49 - another variable called docs page
49:51 - content
49:52 - and what we'll basically do is join
49:55 - those four docs that we'll be sending
50:03 - okay so we got those four docs and we
50:06 - are joining them to create one dock
50:08 - because the Toca limit is 4097 and here
50:12 - we'll almost have 4 000 tokens being
50:15 - sent to the text DaVinci 3 mod awesome
50:18 - now let's work with the llm right so
50:23 - pretty similar to what we did with the
50:25 - pet's name generator we'll initiate the
50:28 - llm to be open Ai and
50:31 - as I said the model that I'll be using
50:33 - is text DaVinci 3 so let me go to the
50:37 - open AIS documentation copy this model
50:40 - name come back here and paste it and
50:42 - there is some white space at the end so
50:45 - we'll get rid of that and the second
50:46 - thing we did with the pets name
50:48 - generator was prompt right so prompt
50:50 - templates is the is another main
50:53 - component of Lang chain so we'll use
50:55 - that and this is variable define what
50:58 - the prompt should be for the open AI llm
51:02 - so the first thing would be to specify
51:05 - the input variables right so the first
51:08 - one is question or query right so
51:11 - whatever the question is being asked by
51:14 - the user in Docs
51:16 - so docs is basically the similarity
51:19 - search we did there we go now the
51:21 - template that we'll be using is a prompt
51:25 - that I've created here so I'm gonna copy
51:28 - this really quick since it's a long
51:30 - prompt okay so I've copied the prompt
51:32 - basically it says you're a helpful
51:34 - YouTube assistant that can answer
51:36 - questions about videos based on the
51:39 - videos transcript right
51:42 - answer the following question and this
51:44 - is where the input variable goes
51:46 - whatever the question the user is asking
51:48 - by searching the following video
51:51 - transcript which is the docs right so
51:53 - docs is basically the similarity search
51:54 - we did
51:55 - only use factual information from the
51:58 - transcript to answer the question if you
52:00 - feel like you don't have enough
52:01 - information simply say I don't know
52:04 - right because we don't want the AI or
52:07 - the llm to hallucinate your answer
52:09 - should be needed so that is basically
52:11 - the prompt that we'll be using to answer
52:14 - questions and now we'll be using another
52:17 - main component which is chain within the
52:20 - Lang chain so let's create an llm chain
52:23 - where llm is equal to llm because we
52:27 - specified it here that will be using
52:29 - openai model text DaVinci 3 and prompt
52:33 - is equal to prompt which we specified
52:36 - here using prompt template okay now
52:40 - we just have to learn the response so
52:43 - I'll create a variable call response it
52:45 - will do chain dot run which will
52:47 - basically run our chain since we had
52:49 - question as the input variable here
52:52 - we'll say that question is equal to
52:56 - query
52:58 - because that's what we were referring to
53:00 - it on the previous function and
53:03 - Docs
53:05 - is equal to docs page underscore content
53:09 - remember because we joined all the
53:14 - four documents because K is set to 4 to
53:17 - be one doc because we can we have the
53:20 - ability to send four thousand tokens and
53:22 - then response is equal to response
53:26 - dot replace and this is just some
53:29 - formatting that we have to do because
53:31 - if you remember in the pet's name
53:34 - generated to the response we were
53:35 - getting
53:36 - was in one line and it included new line
53:40 - characters so we'll replace that with
53:42 - some white space and we'll return
53:46 - response okay so now we can test this
53:50 - out as it is in the console by hard
53:53 - coding the question and the URL which we
53:56 - already did so let's get ready for that
53:58 - but also build the interface because
54:00 - it'll be really quick with streamlit so
54:03 - coming over to our main dot Pi let's do
54:06 - some inputs on the top so pretty similar
54:08 - to what we did in our pets named
54:10 - generator so streamlit I'm importing it
54:13 - as St and the langchain helper where are
54:17 - all of the Lang chain code is and I'm
54:19 - also importing text wrap basically it
54:22 - gives you the ability to wrap text so
54:24 - that you're not you don't have to scroll
54:26 - the page the title of this page will be
54:31 - YouTube assistant right so YouTube
54:34 - assistant
54:36 - and now on the sidebar we can have those
54:39 - parameters that we need from the user
54:41 - with sidebar I want to create a farm so
54:45 - we have a submit button at the end so SD
54:49 - dot form is how you do that
54:52 - and you also have to specify a key so
54:55 - key is my form again this is all
54:59 - streamlit stuff and let me know in the
55:01 - comments if I should create a course on
55:02 - streamlit on how to build you know cool
55:05 - python interfaces I love this tool
55:07 - because I don't have to care about
55:09 - building a front end and the first
55:12 - parameter we had in our length chain
55:15 - helper was the YouTube url right so
55:18 - we'll save that as video URL so YouTube
55:21 - url
55:23 - is equal to SD dot sidebar text
55:27 - as we used in the pet's name and we'll
55:30 - just say that the label is what is the
55:34 - YouTube video URL and we'll give a Max
55:37 - to maximum character limit of 50 because
55:39 - I don't think a video URL can exceed 50
55:42 - characters uh the other parameter we had
55:45 - was the question that the user can ask
55:47 - and we'll save it as query here so St
55:49 - dot sidebar dot text underscore area
55:53 - right and then the label will be asked
55:57 - me about the video so again you can have
56:01 - a limit here right so maybe you can only
56:05 - ask questions that are not long enough
56:08 - so we'll set max characters 50 here too
56:11 - and also set the key to query here okay
56:15 - and at the last since I created this as
56:18 - a form we'll give it a submit button and
56:21 - the label here will be submit now
56:25 - so if Kiri which is the question the
56:28 - user can ask and YouTube url exist right
56:32 - what I want to do is basically run this
56:36 - function to give us the answer right so
56:40 - we'll be as we are already importing the
56:43 - link chain helper on the top as LS lch
56:46 - so that's what we'll be using here so DB
56:49 - which is the database will be equal to
56:53 - so remember we have to pass the video
56:56 - URL uh to the create Vector DB function
56:59 - to create a new Vector database based on
57:03 - the transcript that we got so DB is
57:05 - equal to lch which helps which is
57:08 - basically that we are accessing this
57:10 - python file and then the create Vector
57:12 - DB from YouTube url function and we'll
57:15 - pass the YouTube url
57:17 - as the parameter because remember we
57:19 - just need the video URL here response
57:23 - comma docs is equal to and now we'll get
57:28 - a response which we can do by running
57:31 - this function which is get response from
57:33 - query and remember the parameters that
57:36 - will be passing so lch dot getresponse
57:40 - from query the first one is DB which we
57:42 - just created right and query is the
57:46 - question that I will be asking so
57:49 - um right here whatever the user asks
57:51 - will be the query
57:53 - so I am missing a comma here as I'm
57:56 - going through my code so I'll add that
57:58 - and now we'll save that response in our
58:02 - interface with streamlit so let me
58:05 - create a sub header here which will say
58:07 - answer right and below that we'll have
58:10 - St dot text
58:13 - and we'll wrap that text
58:15 - and this is where the text wrap library
58:17 - is being used you'll you'll see this in
58:20 - the interface once I run it so text wrap
58:22 - dot fill and whatever the response we
58:25 - get from the length chain function
58:30 - you can also set the width of this text
58:32 - area to be 80 let's go with 80 and see
58:36 - how that looks
58:38 - and that is basically it so two
58:41 - parameters for necessary one is the
58:42 - YouTube video URL and the question that
58:44 - the user asks right and we are passing
58:46 - so if the both of those parameters exist
58:49 - first we are creating the database from
58:52 - the YouTube video URL and then we're
58:54 - getting the response based on the
58:56 - question that the user asked using the
58:59 - llm so now we can run our streamlit app
59:02 - after saving the file so if I scroll
59:04 - down to the bottom here for my terminal
59:07 - expand this and run stream lit run
59:11 - main.pi
59:13 - hit enter
59:15 - it should load our web interface for our
59:18 - streamlit app awesome
59:21 - on the left hand side you can see we
59:23 - need to provide a YouTube video URL so
59:26 - I'll just go ahead copy this interview
59:29 - video URL paste it here
59:32 - ask me about the video so let's say what
59:37 - did they talk about rent somewhere is
59:42 - what I want to know
59:44 - and hit submit okay so we have got some
59:47 - errors saying input variables let's go
59:51 - to our terminal and see if we have any
59:53 - logging
59:56 - okay so I found the error I was just
59:59 - missing S I thought I typed it right
60:02 - so instead of input variable it needs to
60:05 - be input variables and we'll Ctrl C to
60:10 - stop our streamlit app and do streamlit
60:13 - run run main.pi again so after adding
60:16 - the S hit enter and now
60:20 - we need the same exact information so
60:22 - copy this
60:25 - and copy the question so the YouTube
60:28 - video URL and what did they talk about
60:31 - ransomware hit submit
60:35 - there we go we got our answer so it says
60:39 - they discussed how ransomware is
60:41 - difficult to track due to zero day
60:43 - exploits and how Microsoft is making it
60:45 - a mission to help with secure cloud
60:47 - backup for Enterprises better tracking
60:50 - of zero day exploits and helping with
60:52 - enforcements they also discussed the
60:54 - importance of public-private
60:55 - Partnerships in order to prioritize
60:57 - cyber security and create new standards
60:59 - such as those for nist so
61:02 - remember our prompt I asked it to be as
61:04 - detailed as possible also say I don't
61:06 - know if it doesn't know
61:09 - what the answer is based on the
61:11 - transcript we provided and not to
61:13 - hallucinate so I think this is a pretty
61:15 - good answer
61:17 - um that we got out of this 52 minute
61:20 - video again you can pick a longer video
61:24 - and ask about anything specifically
61:27 - longer from podcasts right maybe the
61:30 - video is four to five hour Longs and you
61:32 - need to know a specific detail I think
61:35 - that's where this tool or the app we
61:38 - build can be really handy
61:40 - right but yeah so we learned a lot about
61:44 - Lang chain today specifically the main
61:48 - three main components which is llm so
61:52 - any of the large language models that
61:54 - you can use like open AI or hugging face
61:56 - prompt templates right
61:59 - and chains so how you can combine these
62:02 - components into chains to perform the
62:05 - required task and agents right remember
62:08 - in the pets generator we talked a little
62:11 - bit about agents
62:13 - and how they have reasoning behind the
62:16 - tasks that they perform because we try
62:19 - to calculate average age of a dog and
62:22 - also multiply it by three so it used
62:24 - Wikipedia and llm math to get those
62:27 - answers but also we learned a bit about
62:30 - indexing and Vector stores so how you
62:33 - can split large
62:34 - documents into smaller chunks and store
62:37 - it as Vector which is basically you know
62:39 - numerical representation of the
62:43 - documents that we created and then
62:46 - passing those on to the llm since there
62:49 - are certain limits of how much context
62:52 - you can send to the API but yeah one
62:56 - other thing I would like to mention is
62:58 - if you are planning to make these apps
63:02 - public remember we were storing our
63:04 - environment variables in dot EnV file
63:07 - and you might be wondering every ship I
63:10 - also created an openai API key like how
63:13 - much all of this is going to cost so
63:16 - I'll go into my dashboard in into
63:18 - billing to see how much did it cost me
63:21 - to you know basically kind of build this
63:24 - course out so you can see
63:26 - um
63:28 - 10 cents and 30 cents so very close to
63:33 - less than a dollar like half of a Dollar
63:36 - close to 50 cents is what it costed me
63:39 - to make all of these queries to the
63:42 - openai llm the thing I was gonna
63:45 - recommend if you want to publish this
63:46 - app so that the public can use it
63:49 - is to have a field here uh you know with
63:54 - the sidebar saying open AI API key so
63:57 - that the users have to submit their
64:00 - openai API key with their app so you can
64:03 - have a text field here saying hey what
64:06 - is your open AI API key just so that you
64:09 - know you are not being charged and you
64:11 - can make that as a secret field so that
64:14 - the key is not displayed in the
64:16 - interface but you can use that key to
64:19 - make these queries you will just have to
64:21 - pass it in the Lang chain helper so
64:25 - whatever the variable name you decide
64:27 - maybe like open AI API key which you'll
64:32 - get the value from our streamlit
64:34 - interface you can pass that right here
64:37 - when you initiate the large language
64:40 - model so
64:42 - you'll specify openai API key as a
64:45 - parameter here and the value of that key
64:48 - which will be the variable you decide so
64:51 - yeah that's pretty much it for this
64:54 - course again we learned quite a bit
64:56 - about the langchin framework
64:58 - specifically in Python uh you know the
65:00 - models prompts indexes chains and agents
65:03 - or the five main Concepts within nag
65:06 - chain that I wanted to cover again I
65:09 - hope this helps you understand the
65:11 - framework itself and how you can utilize
65:14 - this information to build something
65:16 - really cool with the power of llms but
65:19 - if you would like to see a streamlit
65:21 - course again let me know in the comments
65:23 - but I hope you find this course helpful
65:26 - I'll see you in the next one peace