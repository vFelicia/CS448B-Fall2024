00:00 - you are about to master the core
00:01 - fundamentals of docker
00:03 - by building a node express app with a
00:06 - and redis database sanjeev teaches this
00:09 - course
00:09 - he starts at the absolute beginning and
00:12 - then takes you through a full production
00:14 - workflow
00:14 - what's going on guys so in this video
00:16 - i'm going to show you guys how we can
00:17 - set up a workflow
00:18 - for developing node.js and express apps
00:20 - within a docker container
00:23 - so the first thing that i want to do is
00:24 - i want to set up a quick and simple
00:26 - express app that we can use
00:28 - for demonstration purposes and the
00:30 - reason why i didn't actually prepare the
00:31 - the express app ahead of time is first
00:33 - of all this is going to be the quickest
00:34 - and simplest of apps we'll be able to
00:35 - knock it out within like a minute
00:37 - but i want you guys to focus on these
00:38 - steps that we need to actually
00:40 - create this app because they're kind of
00:41 - important because we're going to
00:42 - recreate those steps within the docker
00:44 - container as well
00:46 - so i've got my project directory i
00:47 - called it node docker already here
00:49 - and i've got it opened up in vs code so
00:51 - you know with any other express app the
00:53 - first thing that we have to do
00:54 - is get our package.json file so i'm
00:56 - going to do an npm init
01:00 - and that's going to create our
01:02 - package.json and since we are creating
01:04 - an express app we're going to have to
01:05 - install
01:06 - express i'm going to do an npm install
01:10 - express
01:14 - so now we've got our dependency uh the
01:16 - next thing that i want to do is also
01:17 - focus on the fact that we did
01:19 - uh create our node modules folder so
01:21 - that happened when we installed express
01:23 - and the final thing that we need to do
01:24 - is actually create the rx application
01:27 - so i'm going to create an index.js file
01:31 - and i'm going to import our express
01:34 - we'll do const express
01:36 - require express
01:40 - and then we can do const app equals
01:43 - express
01:47 - right then i'm going to specify the port
01:49 - that i want my express server to live on
01:51 - so
01:51 - i'm going to do const port so this
01:53 - variable is going to represent the port
01:54 - that it's going to be listening on
01:56 - and i'm going to set it equal to
01:58 - process.env.port
02:02 - pipe 3000 right so if you don't know
02:04 - what this line is it's basically saying
02:06 - that if the environment variable called
02:07 - port has been set
02:09 - we're going to set this variable to that
02:10 - value however if it's not set we're
02:12 - going to default to a value of 3000.
02:14 - usually common configuration and then we
02:17 - can do an app.listen
02:20 - and we'll listen on that port
02:23 - and when our server comes up we can say
02:26 - console.log
02:29 - listening on port and then we'll pass in
02:32 - that variable
02:37 - all right so now the last thing that i
02:39 - want to do is set up a quick route for
02:41 - testing purposes
02:42 - so i'm going to do app.get
02:45 - and we'll just say the root root path
02:48 - and then we'll do
02:49 - rec res
02:54 - and so if anyone sends a get request to
02:56 - this path
02:58 - uh we're just going to send back a
03:00 - simple response
03:01 - which is going to be uh we'll just send
03:03 - an h2
03:05 - that says hi there
03:15 - and i forgot the comma right here all
03:16 - right and so that's our entire express
03:19 - app
03:19 - uh i'm going to start this app real
03:23 - quick
03:23 - we're going to do uh node and then
03:26 - index.js
03:28 - and it looks like i forgot to save
03:31 - probably
03:35 - all right so it looks like i already had
03:36 - another express app listening on
03:39 - port 3000 so i deleted that so now if we
03:42 - do a node index.js it should start it's
03:44 - going to be listening on port 3000
03:46 - we can go to our web browser real quick
03:49 - and we can just go to local host
03:52 - colon 3000 and when we do that we should
03:56 - see it say hi there i'll zoom in for you
03:57 - guys so that you can see that
03:59 - and so that confirms our express app
04:01 - works so we've got our dummy express app
04:03 - so now we can go ahead and get started
04:04 - with
04:05 - actually integrating our express app
04:07 - into a docker container and setting up
04:09 - a workflow so that we can move to
04:11 - developing our application exclusively
04:13 - within the docker container
04:14 - instead of developing it on our local
04:17 - machine like we just did
04:19 - so now that we got our express
04:21 - application complete or the demo express
04:22 - application
04:23 - uh let's work on setting up our docker
04:25 - container now for this video i'm going
04:27 - to assume that you already have docker
04:28 - installed on your local machine
04:29 - if you don't go ahead and do that now
04:31 - just follow the instructions on their
04:32 - website
04:33 - it's fairly straightforward just make
04:34 - sure you follow the directions for your
04:36 - respective operating system
04:37 - but once you have docker installed on
04:39 - your machine head on over to
04:40 - hub.docker.com and i want you to just
04:42 - search for
04:43 - node within that search bar right there
04:46 - once that's finished loading you'll see
04:47 - that the first result is the official
04:49 - node docker image so this is a public
04:51 - image provided by the node team
04:53 - and it's a fairly lightweight image that
04:55 - basically has node already installed for
04:57 - us
04:57 - so that we don't have to do this
04:59 - ourselves and if you take a look at the
05:00 - documentation you'll see that we've got
05:02 - all of the various different versions
05:03 - that it supports so you can get
05:05 - version 15 version 14 all the way back
05:07 - down to
05:08 - version 10 if you really want and it's
05:09 - got directions for this
05:11 - image or any specific things that are
05:14 - relevant to this image when you want to
05:15 - deploy a container from it
05:17 - now this docker image right here is not
05:20 - going to have everything that we
05:21 - ultimately need for our application
05:23 - because the whole idea behind docker and
05:25 - an image is that the image is going to
05:27 - have
05:28 - every single thing that's needed for
05:29 - your application to work
05:31 - and so for our application we obviously
05:33 - need to get our source code into the
05:34 - image
05:35 - and we also need to get all of our
05:36 - dependencies like express and the other
05:38 - dependencies that our
05:40 - application may need
05:43 - so to do that what we're going to do is
05:44 - we're going to create our own custom
05:46 - image
05:46 - and we're going to base this custom
05:47 - image off of this node image so we're
05:49 - going to take this node image
05:51 - we're going to copy all of our source
05:52 - code into that node image
05:54 - and then we're going to install all of
05:55 - our dependencies like express
05:57 - and then that final image is going to
05:59 - have everything that we need to
06:00 - ultimately run our application
06:02 - so let's get started on doing that now
06:05 - okay so let's get started on creating
06:07 - our own custom image
06:09 - to create a custom image we need to
06:10 - create a docker file
06:12 - so the docker file is just going to be a
06:14 - set of instructions that docker's going
06:16 - to run
06:16 - to create our very own customized image
06:19 - so let's create a new file
06:20 - and we're going to call this docker file
06:22 - with a capital d
06:24 - now in our docker file it's going to
06:26 - have a set of commands
06:27 - that docker is going to run to create
06:29 - our own personalized image
06:31 - and the first command that we always
06:32 - have to do is we have to specify a base
06:33 - image
06:34 - so when you create a custom image what
06:36 - you're ultimately doing is you take a
06:37 - base image or a known image of some sort
06:39 - doesn't matter where the image from
06:41 - it can come from your own uh docker
06:43 - repository it can come from docker hub
06:46 - it can come from anywhere you just need
06:47 - a image that docker has access to
06:49 - and we're just going to tweak it a
06:50 - little bit so that uh it contains all of
06:52 - our source code
06:53 - it contains all of our dependencies and
06:55 - things like that so in this case
06:57 - you know we already found our um our
06:59 - base image it's going to be this node
07:01 - image because
07:02 - that's really the only thing that we
07:03 - need to run right we just need it to
07:04 - have node
07:05 - and anything else to run node so we're
07:07 - going to take this as our base image
07:09 - and the instructions here is going to
07:11 - show you how we can ultimately use that
07:13 - so
07:13 - here you just specify node and then you
07:15 - can do colon and then the specific
07:17 - version you want if you don't specify
07:18 - the version
07:19 - i forget what version it grabs but if
07:21 - you read the instructions it's probably
07:23 - going to say
07:23 - it grabs like version 14 or something
07:25 - like that or maybe the latest version
07:28 - right so what we do is we do from and
07:30 - we'll capitalize from
07:32 - and then we say node because that's the
07:33 - name of that uh image or our base image
07:36 - and then we can do colon and then the
07:38 - version we want so i'm going to specify
07:39 - version 15
07:40 - not that we need version 15 we can run
07:42 - 14 or really any version we're not
07:44 - doing anything specific to any new
07:46 - versions i just want to show you guys
07:47 - how to actually specify a version
07:50 - uh so that's something that's absolutely
07:53 - needed the next
07:54 - command is technically optional but it's
07:56 - still recommended and that's called the
07:58 - work dur command and i'm going to set
08:00 - that to slash app
08:02 - so what this command does is it sets our
08:04 - working directory of our container
08:07 - to be the slash app directory within the
08:09 - container
08:10 - so i know this slash app directory
08:12 - exists in the container because i've run
08:13 - the node image and i know it's got a
08:14 - slash app directory
08:16 - but setting the work directory is really
08:18 - helpful because anytime you run a
08:20 - command
08:21 - when you set the work directory it's
08:22 - going to run that command from this
08:24 - directory
08:25 - so we can put all of our application
08:26 - code in slash app
08:28 - and we can run node index.js on slash
08:31 - app
08:32 - and it's going to run it automatically
08:34 - in slash app without us having to
08:35 - specify
08:36 - uh so the working directory just uh is
08:39 - the directory where you run
08:40 - all your commands and it's also the
08:41 - directory where if you copy any files to
08:42 - your container
08:43 - it's going to by default send it to this
08:45 - directory so this is just recommended
08:47 - but it's not
08:48 - technically necessary now the next thing
08:51 - we want to do is
08:52 - uh we want to copy our package.json file
08:55 - which is this file which contains all of
08:57 - our dependencies and anything else that
08:58 - we need
08:59 - and we're going to copy it into our
09:00 - docker image so let's go to
09:02 - um so we can run the copy command and so
09:05 - we copy the path to the package.json
09:07 - file which is our current directory
09:09 - so we just do package dot json
09:13 - and then we have to specify the
09:15 - directory we want to copy it to
09:17 - in our image and so i'm going to do
09:21 - this dot which means the current
09:22 - directory and the reason why i do that
09:24 - is because we set our working directory
09:26 - up here to be slash app
09:28 - so when you do dot it's going to assume
09:30 - the slash app directory we could
09:32 - technically also just do slash app
09:34 - same result but since we have the
09:35 - working directory set we can just
09:37 - specify it relevant relative
09:39 - to that directory
09:42 - uh the next thing is once we have our
09:43 - package.json remember it's got a list of
09:46 - all of our dependencies we want to
09:47 - actually install our dependencies so we
09:48 - want to run an npm install
09:50 - so in our docker file to run a command
09:53 - we can do run
09:55 - and we can do npm install right so
09:58 - we now have our package.json file copied
10:00 - over and then we run npm install now
10:02 - we've got express installed for us
10:06 - the next thing we want to do is and this
10:08 - part's going to be a little bit
10:09 - confusing
10:10 - but we're going to copy the rest of our
10:11 - files so all of our source code
10:13 - everything else
10:14 - into our docker image so we'll do a copy
10:16 - again
10:17 - and here instead of specifying a
10:19 - specific file
10:20 - i'm going to say the current directory
10:22 - so it's going to grab every single file
10:23 - every single folder
10:24 - within our current directory and we're
10:27 - going to copy it to
10:28 - just like we did here where we just did
10:29 - a dot which is going to send to the
10:31 - slash app we're going to do the same
10:32 - thing so we can just do dot
10:34 - or dot slash same thing and right here
10:36 - you might be a little confused
10:37 - you might be wondering well why do we
10:39 - copy the package.json first
10:42 - and then copy all of the files over do
10:44 - we even need this step
10:45 - before if we're going to copy all of our
10:47 - files this should
10:48 - copy our package.json and it does the
10:51 - reason why i split it up into two
10:52 - different steps is a little bit of an
10:54 - optimization technique
10:56 - so let me explain how docker images
10:58 - actually work when you create an image
11:00 - from a docker file it takes each one of
11:02 - these steps and it
11:04 - it treats it as a layer of the image so
11:06 - you could think of an image as just
11:08 - basically these five steps or five
11:10 - layers so once you build all five layers
11:12 - you have the ultimate image or the final
11:14 - image
11:15 - so this first command creates one layer
11:17 - of the image
11:19 - this second command creates another
11:22 - layer of the image
11:23 - this third command creates the third
11:25 - layer the fourth layer and the fifth
11:26 - layer and they all kind of build on top
11:28 - of each other
11:29 - and what's important is that after each
11:31 - layer the docker
11:33 - docker actually caches the result of
11:35 - each layer
11:37 - and what i mean by that is when we run
11:41 - uh docker build when we actually build
11:42 - our image for the first time
11:44 - what's gonna happen is that it's gonna
11:45 - run this first step and it's gonna cache
11:47 - the result so it's gonna say
11:48 - hey look we uh downloaded the node image
11:51 - from docker hub and then we cache that
11:53 - result right we then set the working
11:55 - directory to slash app and we cache the
11:57 - result of that
11:58 - we then copy package.json we cop we
12:01 - cache the result
12:02 - we then npm install cache that result
12:05 - and then we copy all of our code and we
12:06 - cache that result
12:08 - and this is important because let's say
12:09 - we decide to uh
12:11 - rebuild the image again right if nothing
12:14 - changes
12:14 - docker is efficient it knows that
12:16 - nothing's changed in any of these layers
12:19 - and it just takes the final cache result
12:20 - of step five which is the last layer
12:22 - and it just gives that to you so if you
12:24 - run docker build which is the command to
12:25 - actually create the image
12:26 - the first time you run it it's going to
12:28 - take a long time because it's got to run
12:29 - all of these steps
12:30 - and especially the npm install if you
12:32 - have a lot of dependencies it's going to
12:33 - take quite a while
12:34 - but the second time you run it if
12:36 - nothing's changed you'll see it'll be
12:37 - done in less than a second
12:38 - and that's because it's cached all the
12:40 - results and the reason this is important
12:42 - and the reason why i split this up into
12:44 - two different steps is i want you to
12:46 - think about
12:47 - what happens during our development
12:49 - process right when we are
12:51 - actively working on our code what
12:52 - changes our package.json does not change
12:55 - very often
12:56 - right i mean we do occasionally add new
12:58 - dependencies that's normal but it's
13:00 - for the most part your source code
13:02 - changes but your package.json and your
13:04 - dependencies don't change very
13:05 - frequently
13:07 - and so by splitting this up into two
13:08 - different steps what happens is
13:10 - we cache each of these layers right
13:13 - and so we're going to cache uh the node
13:16 - image we're going to cache the working
13:17 - directory
13:18 - and in reality those two will never
13:20 - change right
13:21 - we're never really gonna change those
13:22 - two so uh we're always going to
13:24 - essentially catch the result from step
13:26 - two and onwards
13:27 - but the thing about docker is if any
13:30 - layer changes
13:31 - right say that layer three changes and
13:33 - what i mean by layer three changes is
13:34 - that
13:35 - if package.json ultimately changes uh
13:37 - where maybe we add a new dependency
13:39 - we have to rerun step three and all of
13:41 - the steps after that because we don't
13:43 - know how that's going to impact step
13:44 - four
13:45 - we don't know how it's gonna impact step
13:46 - five and so by caching
13:49 - by splitting these up into two different
13:50 - steps we can say that listen if
13:53 - package.json never changes
13:55 - then we're going to cache that result
13:58 - and since realistically when we're
14:00 - actually programming package.json is
14:02 - just not going to change so we're going
14:03 - to cache that result
14:04 - and since package.json is cached then
14:07 - we're going to also cache the result of
14:09 - npm install
14:10 - because nothing's really changing so we
14:11 - cache those results and so when we
14:13 - change any of our source code
14:16 - within our application the only step
14:18 - that really changes
14:20 - is layer five where we copy the rest of
14:22 - our code
14:23 - and so we only need to rerun step five
14:26 - however if we didn't have
14:28 - this split up into two different steps
14:29 - where we have a copy package.json and
14:31 - then copying the rest of our files
14:33 - uh what would happen is that anytime we
14:34 - changed our source code
14:36 - technically it would rerun everything
14:39 - including the npm install
14:41 - because it doesn't know that we only
14:43 - changed our source code
14:44 - it just sees that listen this step where
14:46 - we copy all of our files has changed
14:48 - we're going to have to rerun all of the
14:49 - steps after that so by doing this
14:52 - we know that package.json will always be
14:54 - the same so we can cache the result of
14:55 - these two steps and only make
14:57 - and only run step five which is the
15:00 - changing of our source code so it's a
15:01 - little bit of optimization
15:03 - if it didn't make sense i don't think i
15:04 - did that great of a job of explaining it
15:06 - but i'll show you guys this when we
15:08 - actually build our containers how it
15:09 - actually
15:10 - caches the results of each step and how
15:11 - it's a little bit of an optimization to
15:13 - actually do this and split this up into
15:14 - two different steps
15:16 - all right so the next thing that we want
15:17 - to do is uh we know our application is
15:20 - going to be listening on port 3000
15:21 - so let's do um expose so we're going to
15:24 - say our container is going to expose
15:25 - port 3000 and then finally
15:28 - when we start our container we want to
15:30 - tell it what command to run
15:33 - right and since this is a node
15:34 - application and our entry point into our
15:36 - node application
15:37 - is this index.js we have to tell it to
15:39 - run
15:40 - index.js so we do cmd
15:45 - brackets and we're going to do node
15:50 - and then index.js all right so when we
15:53 - deploy our container
15:54 - it's going to run in index.js so this is
15:57 - at runtime
15:58 - and this is at build time so hopefully
16:00 - you guys understand this so this is when
16:01 - we're building the image
16:02 - this is the command that's going to be
16:04 - assigned to the container when we
16:05 - actually run the container
16:07 - and so that's all we really need we're
16:10 - going to go ahead and actually create
16:12 - our image now so let's
16:13 - go to our terminal down here and i'm
16:15 - going to stop our express server because
16:17 - remember
16:18 - we're no longer going to be developing
16:19 - on our local machine we'll be developing
16:20 - on the docker container so make sure you
16:22 - stop
16:22 - your local instance of your application
16:26 - all right and let's build our docker
16:28 - container oh sorry our docker image
16:30 - we're building the image right now not
16:31 - the container itself
16:32 - so we'll do a docker build
16:38 - and then we're going to specify uh the
16:41 - path to our docker file it's actually
16:43 - called the context it's not necessarily
16:45 - the path of the file
16:46 - um it has a little bit more of a meaning
16:48 - to it with but i don't want to spend too
16:49 - much time going i just think about it
16:51 - as the path to the docker file so this
16:52 - docker file is in the current directory
16:54 - so we're just going to do a dot
16:55 - so let's run that and i realized i
16:57 - forgot to save my file so let's save
17:00 - that
17:01 - i'm going to rerun that and i want you
17:03 - to pay attention to the output
17:06 - notice what's happened and i think this
17:07 - is kind of important when you're trying
17:08 - to understand what's happening
17:09 - uh you could see that on step one of
17:11 - five it says we're going to grab
17:13 - uh the node image from docker diode io
17:17 - so it's pulling the image
17:18 - from the uh from docker hub right and as
17:21 - i said
17:22 - each one of these is a separate step or
17:24 - a separate layer right if we go down
17:26 - we go to step two and it says working
17:29 - directory is set to slash app
17:31 - you can see that it says cached so
17:33 - you're not going to see it say cached on
17:34 - your machine that's because i ran this
17:35 - as practice before i recorded this video
17:38 - but it's not going to say that it's
17:39 - cached when you ultimately run this
17:42 - so so keep that in mind but if you run
17:45 - this again
17:47 - if you run it again right what should
17:49 - happen is that it should cache all of
17:51 - the results right and so now
17:52 - all the ways down to step five it's
17:54 - cached so if you run it again like i
17:56 - said there's an optimization
17:57 - where it actually caches the results and
17:58 - the second time you run it it's going to
18:00 - be much much faster
18:02 - so now what we're going to do is we're
18:03 - going to do a docker image ls
18:06 - and you can see the new image it created
18:08 - this is the one without a name because
18:09 - we didn't specify a name you also see
18:11 - the node image that it pulled from
18:12 - docker hub
18:13 - which is node 15. now i don't like the
18:15 - fact that we didn't give this a name
18:17 - so let's do a docker image rm this is
18:20 - going to delete the image that we just
18:21 - created
18:22 - i'm going to pass in that image id
18:25 - and if we do a docker image ls you can
18:28 - see that it's gone now
18:30 - so now we're going to go back to the
18:31 - docker build command that we ran but
18:33 - this time we're going to pass in a
18:34 - specific flag
18:36 - so we'll pass in the dash t flag so here
18:39 - we can give it a name i'm going to call
18:40 - this node
18:40 - dash app dash image
18:45 - all right so once that's complete we'll
18:47 - do a docker image ls
18:49 - and now you can see we've got our image
18:51 - that we just created
18:54 - so now that we have our image let's go
18:56 - ahead and run it and let's test it out
18:57 - see if everything works
18:58 - so we'll do a docker run
19:03 - and we'll do node dash app
19:06 - image so here we're just specifying the
19:08 - image that we want to create a container
19:09 - from which is
19:10 - this image that we just created but
19:12 - before you hit enter there's a couple of
19:13 - flags that we got to pass so first of
19:14 - all
19:15 - i want to give my docker container a
19:16 - name so that i have some kind of way to
19:18 - identify it so we can pass in the dash
19:21 - dash name option and we'll call this
19:24 - node app
19:25 - so keep in mind that last uh the last
19:28 - entry in my command is the name of the
19:29 - image that we're creating a container
19:31 - from
19:31 - this is the name of the container that
19:33 - we're creating
19:34 - and then finally there's one more flag i
19:36 - want to pass which is dash d so that
19:38 - means it's going to run detach mode
19:39 - because by default when you create a
19:40 - docker container from docker run
19:42 - you're going to be attached to the the
19:43 - cli or the console or whatever it's
19:45 - called
19:46 - but here i can run in detach mode so
19:48 - that my command line's still free and
19:49 - open
19:51 - so let's hit enter and it looks like it
19:54 - successfully created my container
19:55 - um i can do a docker ps and we should
19:58 - see that there's a container open
20:00 - at the moment
20:04 - all right so let's test this out and
20:06 - what i'm going to do is let's just go to
20:07 - my local host colon 3000 hit refresh and
20:10 - let's see what happens
20:11 - all right so it doesn't look good it's
20:13 - spinning which most likely means there's
20:14 - something broken and it looks like there
20:16 - is
20:17 - don't worry guys i know exactly what's
20:18 - wrong i perfectly did this
20:20 - so let's tackle exactly what's wrong
20:22 - with our docker container in the next
20:24 - section
20:27 - so we were unable to connect to our
20:28 - docker container on localhost
20:30 - colon 3000 now why exactly were we
20:33 - unable to do that
20:35 - well let's take a look at our docker
20:36 - file and if we go back here
20:39 - uh we can see that uh we do have this
20:41 - command expose
20:42 - 3000 and i think naturally most of us
20:44 - would assume hey look we're exposing
20:46 - port 3000 so we should be able to access
20:48 - that well not exactly this
20:51 - line does absolutely nothing this is
20:52 - really more for documentation purposes
20:54 - if you delete this command
20:55 - and create a brand new image it will not
20:57 - impact our image or container
20:58 - at all in any way shape or form it's
21:00 - just so that when you share your docker
21:02 - file with someone else they'll know
21:03 - hey look this image expects you to open
21:06 - up
21:06 - port 3000 for everything to work so this
21:09 - line doesn't actually open up port 3000
21:11 - and the thing about docker containers is
21:14 - by default
21:15 - they can talk to the outside world so if
21:17 - a docker container wants to reach out to
21:18 - the internet
21:19 - or wants to reach out to any other
21:20 - devices in your host network
21:22 - uh it can do that however outside
21:25 - devices like the internet
21:26 - or your host machine or any other
21:28 - machine from the outside world by
21:30 - default cannot talk to a doc
21:31 - container this is almost like a built-in
21:33 - security mechanism
21:35 - right you don't want the outside world
21:37 - to be able to access your docker
21:38 - container but your docker container can
21:40 - outside can access them so how do we
21:42 - make it so that the outside world can
21:44 - talk to our docker container
21:46 - and keep in mind when i say outside
21:47 - world i don't just mean the internet i
21:49 - also mean our local host machine
21:51 - right and when i say local host machine
21:52 - i mean my windows machine right here
21:54 - right to actually uh talk to the
21:56 - container
21:58 - from my computer which is kind of seen
22:00 - as like an outside device
22:02 - we have to um poke a hole in our host
22:05 - machine
22:06 - uh and what i mean by that is that by
22:08 - default right
22:09 - our docker container nothing from the
22:11 - outside wheel can talk to our docker
22:12 - container
22:13 - so we have to basically say on our host
22:15 - machine hey if we receive traffic on a
22:17 - specific port
22:18 - we want to forward that traffic to our
22:20 - docker container
22:21 - and the way we do that is it's very easy
22:23 - first of all let's kill our container
22:25 - uh we don't need that anymore so i'm
22:26 - going to do a docker rm
22:30 - and then specify the name of our
22:31 - container we'll so we'll do node dash
22:32 - app
22:34 - and then i'm going to pass in the dash f
22:35 - flag so this is stands for force
22:38 - so by default usually you have to stop a
22:40 - container before you can delete it
22:41 - if you pass the dash f flag it'll allow
22:43 - you to delete a running container
22:46 - all right so now if i do a docker ps we
22:48 - should see an empty list
22:49 - so let's do docker let's rerun that
22:52 - command
22:53 - but here i'm going to pass in another
22:55 - another flag i'm going to pass in the
22:57 - dash p flag
22:58 - i'm going to specify uh this so let me
23:01 - explain what this is
23:02 - in a second so we've got port 3000
23:05 - and then colon 3000 so what exactly does
23:07 - this mean we've got two different
23:08 - numbers
23:09 - we've got the 3000 to the left of the
23:11 - colon and 3000 to the right of the colon
23:14 - so the number to the right let's start
23:16 - off with this one
23:17 - is the um basically the port that we're
23:19 - going to send traffic to on our
23:20 - container
23:22 - and our container remember our
23:23 - application is listening on port 3000
23:25 - so we want to send this to port 3000
23:28 - right
23:28 - if this was set to 2000 then we would
23:30 - want to set this to 2000 so whatever our
23:32 - container is expecting traffic on
23:34 - the number to the right of the colon
23:35 - should be set to that value now the
23:37 - number to the left
23:38 - represents um it represents traffic
23:41 - that's going to be
23:42 - uh basically coming in from the outside
23:44 - world so if another device on your
23:46 - network
23:47 - uh or even your local host machine right
23:49 - my windows machine
23:50 - if we send traffic to local host port
23:53 - 3000
23:54 - right we're going to take traffic that's
23:55 - coming in on port 3000 and sending it to
23:57 - port 3000 on our container
24:00 - but in this case even though the two
24:02 - numbers are the same they don't have to
24:03 - be so let's say
24:05 - we wanted to basically poke a hole so
24:07 - that anybody that sends traffic to our
24:09 - windows host machine here on port 4000
24:13 - we should then forward it to our docker
24:15 - container in that case we would change
24:16 - this to a 4000
24:18 - and we keep this to port 3000 because
24:20 - remember it's still listening on port
24:21 - 3000.
24:22 - however if this was 2 000 then we would
24:24 - change
24:25 - um this number to be 2000 here
24:28 - right so hopefully that makes sense i've
24:30 - set up a little quick diagram
24:32 - i don't know if you guys understood it
24:34 - at this point but hopefully the diagram
24:35 - makes it a little bit easier to
24:36 - understand so let me pull that up
24:39 - so here in this diagram i've got my host
24:41 - machine right which is this big blue box
24:43 - which is my windows machine
24:44 - and then i've got this node container in
24:46 - green right here
24:48 - and so what's going to happen is you
24:49 - know we've got those two numbers right
24:51 - basically what we want to do is when our
24:53 - host machine right our windows machine
24:55 - receives traffic on port 3000
24:57 - what we want to do is we want to take
24:59 - that and forward it to port 3000 on our
25:01 - node container
25:01 - so that's why we have 3000 colon 3000 so
25:05 - the first 3000 represents the red arrow
25:08 - and then the second 3000 represents the
25:10 - yellow arrow
25:12 - and this also applies when we send
25:14 - traffic from our host machine
25:15 - to the local host ip so to ourselves so
25:18 - if we send a
25:19 - traffic to local host port 3000 it's
25:21 - going to take that traffic
25:22 - and it's going to forward it to port
25:23 - 3000 and once again like i said before
25:26 - we don't have to do three thousand to
25:27 - three thousand we could change this to
25:29 - uh four thousand and then we would send
25:31 - traffic to local host four thousand
25:33 - and it would forward it to traffic on
25:34 - port 3000 on our node container
25:36 - because once again our node container is
25:37 - listening on port
25:39 - 3000 because that's what our express
25:41 - server is listening on
25:43 - all right so hopefully that made sense
25:44 - i'm going to run my container now
25:46 - so i'll hit enter and i changed
25:48 - everything back to 3000 column 3000
25:50 - because
25:51 - uh that's just a little bit simpler why
25:52 - not have both of those numbers match
25:53 - there's no need to unnecessarily
25:55 - complicate things
25:56 - let's do a docker ps all right
25:59 - and you'll see that we've got our
26:00 - container but we under this port section
26:03 - you can see that it looks a little
26:04 - different you can see that
26:06 - right here we've got basically 0.0.0.0
26:10 - on port 3000 with an arrow to 3000 slash
26:13 - tcp so what this is saying is
26:15 - any traffic destined to your host
26:16 - machine uh
26:18 - for uh you know my windows machine right
26:20 - here on port 3000
26:22 - is going to get forward to port 3000 on
26:23 - my container so now
26:25 - let's go back to their web page and
26:28 - let's do a refresh
26:29 - and you can see now it says hi there so
26:31 - we have successfully
26:33 - sent a request to our docker container
26:35 - on port 3000.
26:37 - before proceeding any further i do want
26:39 - to show you one thing real quick let's
26:41 - actually
26:42 - uh log into our docker container and
26:44 - take a look at the files in there
26:45 - so we can do that by typing in docker
26:48 - exec
26:49 - on it for interactive mode and then
26:51 - we'll specify the name of our docker
26:53 - container which is node
26:54 - app and then we want to pass in a new
26:57 - command instead of the usual node
26:58 - index.js
26:59 - we're going to passion bash so this is
27:00 - going to allow us to take a look at the
27:02 - file system of our container
27:07 - uh so here by default it's going to drop
27:08 - us in the slash app directory just
27:10 - because
27:10 - uh we set the working directory to be
27:12 - that uh and here i just want to type in
27:15 - ls so this is going to list all the
27:16 - files in that directory and so you're
27:18 - going to see all the files that are
27:18 - copied over so we've got our
27:19 - package.json we've got the package.lock
27:22 - we've got the node modules folder our
27:24 - index.js
27:26 - and we've got the docker file
27:29 - and you know the reason why i wanted to
27:31 - show you the file system is
27:33 - you may be wondering what is our docker
27:35 - file ultimately doing in our docker
27:36 - container
27:37 - right our docker file is there to create
27:39 - an image but we don't actually need it
27:40 - in our docker container
27:43 - and i also wanted to point out one more
27:44 - thing if you take a look at this copy
27:46 - command right here
27:47 - what it does is it copies everything in
27:49 - our current directory so every single
27:50 - file
27:51 - and it copies it into our container or
27:53 - our image
27:55 - and this is a bad thing because
27:59 - there are going to be files that you
28:00 - don't actually want copied into your
28:02 - container
28:03 - right just like our docker file that i
28:04 - mentioned we may also have an
28:06 - environment file that has a lot of our
28:08 - secrets
28:08 - that we don't actually want copied into
28:10 - our container potentially
28:12 - also on top of that we don't need to
28:14 - copy our node modules folder
28:16 - this is actually a waste of time because
28:18 - a lot of times this folder is actually
28:20 - fairly large
28:21 - and we don't need to do that because
28:22 - remember we're copying our package.json
28:24 - file and then we're doing an npm install
28:25 - so there is zero reason to ever have to
28:27 - copy this node modules folder
28:29 - into our container
28:32 - and on top of that we ultimately want to
28:35 - move away from developing on our local
28:36 - machine so
28:37 - moving forward we won't even have a node
28:39 - modules folder on our local machine
28:40 - it'll only ever exist
28:42 - within our docker container so why are
28:44 - we even copying it in the first place
28:46 - uh it could be stale we may not even
28:48 - have it so
28:49 - um we need to find a way to make it so
28:51 - that docker does not copy
28:52 - over files that we don't ultimately want
28:54 - copied over just like this docker file
28:56 - just like the node modules folder if we
28:58 - have git configured we definitely don't
29:00 - want that copied over
29:01 - uh and so we can do that by creating a
29:03 - docker ignore file
29:04 - right and that probably sounds a little
29:05 - familiar because if you work with git
29:07 - kit has a git ignore file
29:09 - for files that you don't want checked
29:11 - into your git repository
29:12 - same exact concept so let me exit out of
29:15 - my container
29:16 - so we can do exit to exit out of the
29:17 - file system and
29:19 - uh i'm going to kill that in that
29:21 - container so we'll do docker rm
29:24 - node app and then we'll do dash f for
29:27 - force
29:29 - and let's create a docker ignore file so
29:31 - i'll do a new file
29:35 - and i'm going to call this dot or period
29:37 - and then docker
29:38 - ignore
29:43 - and within our docker ignore file we're
29:45 - going to list out every single file
29:47 - and folder that we don't ever want
29:48 - copied into our docker container
29:50 - so the first thing is we don't want to
29:51 - copy our node modules folder because
29:54 - we're going to do an npm install from
29:55 - our package.json anyways there's really
29:57 - no need to ever copy it over
29:59 - we don't want to copy over our docker
30:01 - file
30:02 - now that we have a docker ignore file
30:03 - there's really no need to copy that into
30:05 - our docker container
30:10 - uh and then a few other things right if
30:12 - you have git you don't want to copy git
30:13 - you don't want to copy your
30:15 - git ignore uh for now i think that's
30:17 - good um
30:18 - you'll see later on in the video we'll
30:19 - add a couple more files but for now
30:21 - that's okay
30:22 - just do a save and now let's rebuild our
30:25 - image
30:26 - so let's find that build command so
30:28 - docker build dash t
30:29 - the name and then uh the path to the
30:33 - docker
30:33 - file so that's their current directory
30:35 - so i'll run that
30:37 - and just make sure i didn't change
30:38 - anything in my index.js
30:40 - if everything looks good so let's run
30:42 - that
30:44 - all right so that's done let's run our
30:47 - container from the new docker image that
30:48 - we just created
30:50 - so if we hit up for that docker run
30:51 - command let's see if i can find it here
30:53 - we go so docker run
30:55 - dash piece we're going to open up port
30:56 - 3000 run in detached mode
30:59 - we're going to give the container a name
31:00 - of node app and we're going to use the
31:01 - node app image that we just created
31:04 - all right so we did that let me just
31:06 - quickly double check to make sure i
31:07 - didn't break anything
31:08 - so hit refresh it looks like
31:10 - everything's working perfect
31:12 - now let's go into our docker container
31:14 - again so we can
31:16 - run that uh exec command and let's just
31:19 - make sure it didn't copy over any
31:20 - unnecessary files
31:21 - so let's do an ls and now it's perfect
31:25 - right
31:26 - we no longer see a docker file there's
31:28 - no docker ignore file
31:29 - i can't verify for you guys that we
31:31 - didn't copy over the node modules folder
31:33 - but
31:33 - just trust me this node modules folder
31:35 - is from running a uh
31:37 - an npm install on the fourth step and
31:40 - not because we copied it over from our
31:42 - local machine
31:44 - all right so let's exit out of that
31:47 - okay so now that we got our application
31:49 - working in a docker container and we can
31:51 - access it from our local machine
31:53 - uh let's see what happens when we change
31:55 - our code i'm gonna go back
31:57 - to my uh my index.js file
32:00 - and i'm going to just tweak something
32:01 - right here it says we're sending an h
32:03 - that says hi there
32:04 - i'm just going to add a couple of
32:05 - exclamation points we'll save that
32:11 - and i'm going to minimize this and let's
32:13 - hit refresh let's see what happens
32:16 - we hit refresh nothing happens we don't
32:18 - see the exclamation points so for some
32:20 - reason
32:20 - our code didn't get updated and i want
32:22 - you to think about
32:23 - why that is it's actually a really
32:26 - simple answer
32:27 - right uh basically what happens is first
32:30 - of all
32:30 - we have to take our docker file we have
32:32 - to build an image so we built an image
32:35 - and then we built a container from it
32:37 - now we changed our code
32:39 - to add the exclamation points but our
32:41 - image that we created from our docker
32:43 - file
32:43 - was run before we made these changes so
32:46 - the code in that image
32:47 - does not have the exclamation points and
32:50 - so basically our image has a stale
32:52 - version of our code
32:53 - which means our container which is
32:55 - running from that image has a stale
32:57 - version of our code
32:58 - and we can prove that if we do a docker
33:00 - exec and go into our code
33:02 - if i do an ls we can see our index.js
33:04 - file
33:05 - and i do a cat which is just going to
33:07 - print the contents of that file if i do
33:09 - an index.js
33:10 - you can see that there's no exclamation
33:11 - point so it's running a stale version of
33:13 - the code
33:14 - so how do we actually update that well
33:16 - it's actually very simple
33:17 - first of all make sure you change save
33:19 - all your changes
33:21 - and now what we're going to do is we're
33:22 - going to rebuild that image
33:26 - well first of all let's delete our
33:27 - container we don't need it anymore and
33:29 - let's rebuild the image
33:31 - so where's that build command so build
33:35 - right so now if you take a look uh
33:37 - you'll see that um because our source
33:39 - code changed it had to run step five
33:40 - once again
33:42 - uh so now if we do a docker image ls
33:44 - this new image
33:46 - which we named it is the same name as we
33:47 - had before
33:49 - now has the new exclamation points built
33:51 - into the image
33:52 - so if we deploy this image with a docker
33:55 - run command
33:56 - it's the same exact docker run command
33:59 - hit enter
34:01 - and now if we go back to our
34:04 - our web browser hit refresh we can now
34:07 - see the exclamation points
34:09 - so that explains why um our code didn't
34:12 - automatically get updated
34:13 - however i'm sure you're thinking well
34:15 - this is kind of a strenuous process
34:18 - uh for when you update your code right
34:20 - every time i make a change i don't want
34:21 - to have to
34:22 - uh rebuild an image and redeploy a
34:24 - container that's a very slow process
34:26 - that's going to slow down your
34:27 - development time
34:28 - uh and what i'm going to do is i'm going
34:30 - to show you guys how we can work around
34:32 - that because
34:32 - that's obviously not um sustainable you
34:34 - can't be rebuilding an image
34:36 - and re-running a container every time
34:37 - you make one tiny uh change
34:40 - in your code so what we're going to do
34:42 - is we're going to make use of something
34:44 - uh called we're going to make use of
34:46 - volumes so within docker we have
34:48 - volumes which allows us to have
34:50 - persistent data in our containers
34:52 - but there's a very specific type of
34:54 - volume called a bind mount
34:56 - in docker and this is a special this is
34:59 - special volume because
35:00 - what it allows us to do is allows us to
35:01 - sync a folder
35:03 - in our local host machine on our in my
35:05 - windows machine in this case
35:06 - it allows me to sync a folder or a file
35:09 - system
35:10 - to a folder within our docker container
35:13 - so what i can do is i can take all of
35:14 - these files
35:16 - and sync them into the slash app
35:18 - directory of our container
35:20 - so that we don't have to continuously
35:22 - rebuild the image and redeploy a
35:24 - container
35:24 - every time we make a change it'll
35:26 - automatically sync those two for us
35:28 - to really speed up the development
35:29 - process so let me show you guys how we
35:31 - can do that
35:32 - so we're going to delete our container
35:40 - and what i'm going to do is we don't
35:41 - need to rebuild our image the image is
35:43 - just fine
35:44 - but i'm going to hit up a few times so
35:45 - we can get to this run command so we're
35:47 - going to use the same exact run command
35:52 - and we're going to pass in a new flag it
35:54 - doesn't matter where you put it
35:56 - and it's going to be the dash v flag so
35:57 - this stands for a volume
35:59 - there's a couple of different volumes or
36:01 - different types of volumes but remember
36:02 - we're using the bind mount which is a
36:04 - special volume
36:05 - that allows you allows you to sync a
36:06 - folder from your local machine
36:08 - to a folder in your docker container
36:15 - uh and so the syntax for this is you do
36:18 - dash v
36:18 - and then you specify um
36:22 - the local folder or the path to the
36:24 - folder on your local machine so i'll
36:25 - just say
36:26 - path to folder on local machine
36:30 - on local and then we do colon and then
36:32 - we do path
36:33 - to folder on container okay
36:36 - so kind of like pseudo code just uh so
36:38 - you guys understand so this is going to
36:40 - be the location of
36:41 - this folder right because this is the
36:43 - folder that has all my source code and i
36:44 - want to sync that
36:45 - to a folder within our docker container
36:48 - and that's going to be in the slash app
36:49 - directory because that's where we're
36:50 - going to store all of our source code
36:52 - so let's hard code those values uh and
36:55 - so here unfortunately
36:56 - i can't just do a dot right here um it's
36:59 - not going to register that it's not
37:01 - going to work you have to actually pass
37:02 - in the whole path
37:03 - so if you're using vs code like i am you
37:06 - can
37:07 - right click here and then just select
37:09 - copy path
37:11 - and then you can right click and it's
37:12 - going to grab the entire path
37:15 - in my host machine to this folder
37:19 - obviously i'm going to delete the docker
37:22 - file section we just need to get into
37:23 - the node docker
37:24 - which is the name of the folder that
37:26 - houses all of my code
37:28 - and then we do call in and then we do
37:30 - the path to the folder in the
37:31 - container so what folder do we want to
37:33 - copy it to easy we want to copy it to
37:35 - slash app
37:38 - right and that's so that's all you have
37:39 - to do you hit enter and it's going to
37:40 - sync your code however
37:41 - i do want to show you a couple of
37:42 - shortcuts because that does look a
37:44 - little messy having to type all of this
37:46 - out
37:48 - and so what we can do is we can make use
37:49 - of um variables
37:52 - and so i'm going to delete this i'm
37:54 - going to show you guys what you can do
37:55 - instead instead of having to type out
37:56 - that whole nonsense
37:58 - and it's going to be different based off
37:59 - your operating system
38:01 - so if you're using windows and you're
38:04 - using the command shell
38:06 - then what we can do is we can type in
38:08 - percent
38:10 - cd percent so that's going to grab the
38:12 - current working directory
38:14 - so that way i don't have to copy that
38:16 - entire path and that only works on
38:18 - windows command
38:19 - shell if you're using windows powershell
38:22 - then you're going to have to type in
38:23 - dollar curly braces pwd closing curly
38:27 - braces
38:28 - that's going to grab the current working
38:29 - directory
38:31 - and if you're on a mac or a linux then
38:34 - you can type in dollar
38:36 - parentheses pwd uh and then close
38:39 - parentheses
38:39 - so that's just a shortcut or you could
38:41 - type out the entire path whatever is
38:43 - easiest for you
38:43 - feel free to do that so i'm just going
38:45 - to use
38:47 - my percent cd
38:50 - percent
38:55 - all right and so let's hit enter
38:59 - and uh you know depending on you know
39:01 - what uh operating system using if you're
39:03 - using windows
39:04 - anytime you're doing file sharing um you
39:06 - might get this warning there's a couple
39:07 - of optimizations that you can make
39:09 - i usually just ignore it for now all
39:12 - right so
39:13 - now theoretically it should be syncing
39:15 - this entire folder
39:17 - with the slash app directory in our
39:18 - container
39:20 - uh and so uh let's minimize this
39:24 - and let me just refresh this so you can
39:26 - see right now we've got the
39:28 - four exclamation points
39:32 - let's go back to our code and i'm going
39:34 - to delete the exclamation points
39:36 - all right and then after we delete it
39:38 - let's save it and let's see
39:39 - if i refresh this page does the changes
39:41 - take effect so let's hit refresh
39:44 - and it looks like it didn't so do you
39:46 - guys know why it didn't take effect
39:48 - well let's take a look right because
39:50 - theoretically this command
39:52 - uh this flag right here should sync the
39:54 - folder so we should see uh
39:56 - this file gets synced to our container
39:58 - so let's drop into our container
40:00 - and take a look at what the file looks
40:02 - like in the container to see if it
40:03 - actually updated
40:04 - all right because maybe i was lying to
40:05 - you guys and this does absolutely
40:07 - nothing and i wasted your time
40:08 - so we log in let's do an ls so we've got
40:12 - our index.js and let's print out the
40:13 - contents of the file by typing in cat
40:15 - and then index.js and if we take a look
40:19 - at that we can see that hey look
40:20 - it did actually sync our code it deleted
40:22 - the four exclamation points
40:24 - so why exactly did we not see the update
40:27 - in our web browser
40:28 - well this is easy for anyone that's ever
40:32 - worked with express applications i'm
40:33 - sure you might have an idea as to what
40:36 - exactly
40:39 - caused this problem remember
40:42 - anytime we make changes to code in any
40:45 - node or express application
40:47 - we have to restart the node process we
40:50 - did not restart the node process we just
40:51 - changed the code and we hoped that it
40:53 - would automatically work
40:54 - but we had to restart the node process
40:57 - right and um you know we could go in we
41:00 - can kill the node process start it again
41:02 - but obviously that's inefficient right
41:04 - we already have a solution that we
41:05 - already know
41:06 - is going to work and that is we're going
41:07 - to make use of nodemon
41:09 - right nodemon will always look at your
41:11 - code and if any changes take place it's
41:13 - going to restart the node process
41:15 - so that the changes are updated in real
41:16 - time so let's get that set up and
41:18 - installed
41:19 - i'm going to exit out here and we need
41:21 - to update our package.json file so let's
41:23 - get nodemod installed as a dev
41:25 - dependency
41:26 - and i'm going to do this on my local
41:27 - machine just so that we can have it set
41:29 - up in this file
41:30 - so i'm going to do an npm install
41:33 - nodemon
41:35 - save dev so this is going to be a dev
41:37 - dependency just because we don't need it
41:39 - to run when we actually deploy to
41:40 - production
41:45 - and remember i'm just doing this on my
41:47 - local machine right now just so that we
41:48 - can update my package.json file
41:51 - all right so we've got our dev
41:52 - dependency
41:54 - now let's go to my package well i'm
41:57 - already in my package.json
41:58 - but let's set up a few scripts
42:04 - so we'll do a start and this will just
42:06 - be the usual
42:08 - node index.js
42:12 - and then we'll have a dev which is going
42:15 - to be
42:16 - whoops which is going to be a nodemon
42:19 - index.js so
42:20 - by running nodemon in dev mode
42:23 - it's going to automatically restart uh
42:26 - index. it's going to restart the node
42:28 - process anytime there's any changes to
42:29 - our source code
42:31 - now as a heads up when i was uh doing a
42:34 - dry run of this demo
42:35 - i did run into some issues on
42:37 - specifically it looks like windows
42:39 - machines so if you're on a windows
42:41 - machine and for some reason
42:42 - later on in this video uh you run into
42:44 - some issues with nodemod not actually
42:45 - restarting
42:46 - you may need to pass in the dash l flag
42:49 - uh so that
42:50 - that kind of fixed most of the issues uh
42:51 - if you do run into the issue just try
42:53 - and
42:53 - try the l flag uh if you want to read up
42:56 - on it just
42:57 - just google the error message that you
42:58 - get or just google no not restarting on
43:00 - windows for docker
43:01 - and they'll give you an explanation for
43:02 - why you need to pass in that flag but
43:04 - i'm going to keep that in there because
43:05 - i'm running a windows machine and i did
43:07 - run into that issue
43:10 - so let's save all of that and let's uh
43:13 - let me kill the the docker container
43:16 - that we have so i think there should be
43:17 - one running so we'll do a docker rm
43:20 - node app dash f
43:23 - all right uh so now that we made changes
43:25 - to our package.json we're gonna have to
43:27 - rebuild our image now
43:31 - to do a docker let me see if i have that
43:33 - command cache someplace here we go build
43:36 - so we'll do the docker build
43:40 - and notice how it's taking a little bit
43:41 - longer this time and that's because
43:43 - our package.json file changed so it had
43:46 - to rerun step three where we copy
43:48 - package.json
43:49 - and then rerun step four and then we run
43:51 - step five because we have to run all the
43:52 - steps after that because we don't know
43:54 - if changes to this file change to any of
43:56 - the cache results
43:58 - so that's why it took a little bit
43:58 - longer this time but hopefully by now
44:00 - you guys get an understanding of how all
44:02 - the caching works in docker
44:05 - all right so now let's redeploy
44:10 - actually before we redeploy there's a
44:12 - couple of things that we have to change
44:13 - i realize i forgot to do this
44:14 - so um back in our docker file right
44:17 - we're not going to run node index.js
44:19 - anymore so
44:20 - in the development mode we're actually
44:22 - going to run
44:23 - if you take a look at our package.json
44:24 - we're going to run npm run dev
44:26 - so we can run node mod so let's go back
44:28 - to our docker file
44:30 - we'll do npm
44:34 - run and then
44:37 - dev save that sorry about that guys
44:40 - we're gonna have to rebuild our image
44:41 - again
44:42 - so let's uh rebuild it
44:49 - all right uh and so now let's run a
44:51 - container from that image
44:53 - uh and this time we want to do it with
44:55 - the bind mount again
44:56 - let's hit enter we've got our docker
44:58 - container
45:01 - let's quickly test this out okay so the
45:03 - exclamations are gone which is fine
45:05 - and let's make a quick change to our
45:06 - code i'm going to re-add the exclamation
45:09 - points
45:10 - save it all right and if i hit refresh
45:14 - look at that so it looks like nodemon is
45:16 - doing its job and anytime we make
45:18 - changes to our code
45:19 - it's automatically restarting the node
45:21 - process and our bind mount is
45:22 - successfully syncing the code from our
45:24 - local machine
45:25 - to our docker container
45:30 - now i want to do a quick little test and
45:33 - i'm going to do this because i suspect
45:35 - depending on how you guys followed along
45:37 - to this video so far
45:38 - you may have run into an issue in the
45:40 - most recent step
45:42 - so let me delete my docker container so
45:45 - let's do a docker rm node
45:48 - app dash f
45:52 - and what i'm going to do is i'm going to
45:53 - take this node modules folder on my
45:54 - local machine
45:55 - which i don't need anymore because we're
45:57 - not developing on my local machine and
45:58 - i'm just going to delete it
46:03 - all right so now that it's gone i'm
46:04 - going to redeploy the container
46:08 - i'm going to show you that we're going
46:08 - to break our application so if i
46:11 - it's now running and if i go to
46:15 - my web browser hit refresh you can see
46:16 - it spins and it's eventually going to
46:18 - crash
46:19 - let's give it a second there you go so
46:21 - what exactly happened well
46:23 - let's take a look so if i do a docker ps
46:26 - let's see if my container is running
46:27 - and look that's the first issue why is
46:29 - our docker container not even showing up
46:31 - on this
46:32 - well when you do a docker ps it's only
46:34 - going to show you running containers so
46:35 - let's do a docker
46:37 - i think it's ps minus af yep so this is
46:40 - going to show you all containers
46:41 - started or stopped and you could see our
46:44 - most recent container
46:45 - our node app container and it said it
46:47 - exited 30 seconds ago which means
46:50 - usually if it automatically exit it
46:51 - usually means something crashed
46:53 - so if you want to take a look at the
46:54 - logs to see why something crashed we can
46:56 - always do a
46:58 - docker logs and then you specify the
47:01 - name of the container so it's going to
47:02 - give you all the logs for that
47:04 - and this is going to show us some node
47:06 - or nodemon logs and you'll see right
47:08 - here it says nodemon not
47:10 - found so what exactly is happening we
47:14 - know for a fact
47:15 - that nodemon should be installed because
47:18 - we had everything working before
47:19 - the only change we made was we deleted
47:22 - the local
47:23 - node modules folder why should that
47:25 - impact anything because it was working
47:27 - before
47:28 - well let me tell you what happened so
47:32 - what happened was um you know we we
47:34 - create our docker image
47:35 - right where we copy our package.json
47:37 - file and then we run an npm install
47:40 - so at this point when we run mp install
47:42 - it should install nodemon for us
47:44 - and it is in there but then we copy
47:48 - um all of our files which once again not
47:50 - an issue actually
47:52 - i don't know why i kind of made it seem
47:53 - like it was but we copy all our files
47:55 - all of our source code uh and then um
47:58 - the command specified for the container
48:00 - is npm run dev
48:02 - now when we go back to our docker
48:04 - command that we used to actually create
48:06 - our container
48:07 - we created a bind mount so the bind
48:09 - mount
48:10 - syncs this folder with the slash app
48:13 - folder
48:14 - and this is where the issue occurred
48:16 - because it's syncing
48:17 - this folder since there's no more node
48:19 - modules folder in this folder
48:21 - it syncs that with the slash app folder
48:23 - so it ends up overwriting the slash app
48:25 - folder
48:25 - and deleting the node modules folder in
48:28 - the slash app folder of our container
48:30 - because it doesn't exist in our local
48:32 - our local directory and since we have a
48:34 - bind mount it's going to sync those two
48:35 - directories together
48:36 - that's the problem right because once we
48:38 - deleted the node modules folder
48:40 - from our local machine it will also
48:42 - delete it from our docker container
48:44 - and then without the node modules folder
48:46 - that container has no idea what the hell
48:48 - nodemon is
48:50 - so how do we get around this issue how
48:52 - do we prevent
48:53 - our local directory our local folder
48:57 - from overwriting the slash app directory
48:59 - and deleting the node modules folder
49:01 - well there's a simple little hack that
49:03 - we can do and that is we're going to
49:04 - create a new volume
49:05 - and we're going to create a volume
49:06 - that's called there's a couple different
49:08 - volumes like i said
49:09 - in docker a bind mounts one we also have
49:11 - an anonymous volume
49:13 - and volumes work based off of
49:15 - specificity so we've got a volume
49:17 - on our container for the slash app
49:19 - directory but we want to make sure that
49:21 - we preserve
49:22 - the slash app slash node modules so we
49:24 - want to make sure this bind mount
49:26 - doesn't override the slash
49:28 - node modules folder within the app
49:29 - directory and the way we can do that is
49:30 - we could just specify
49:33 - another um another
49:36 - uh volume so first of all let me delete
49:40 - our broken container
49:46 - all right and then we'll run that same
49:48 - command but i'm going to pass in
49:50 - another v flag for another volume and
49:53 - i'm going to say this
49:54 - volume which is going to be an anonymous
49:56 - volume is going to be that for the slash
49:58 - app
49:59 - slash node underscore modules
50:03 - this is a little hack that you can do to
50:06 - prevent the bind mount from overwriting
50:08 - the slash app slash node module folder
50:10 - because all volumes in docker containers
50:12 - are are based off of specificity so even
50:16 - though
50:17 - this bind mount should sync with the
50:19 - slash app directory
50:20 - we can see that we have another volume
50:21 - that uh that references the slash app
50:24 - slash node modules folder and you can
50:25 - see that since this is a longer path
50:27 - that's basically more specific so that's
50:30 - going to prevent
50:31 - this bind mount from deleting the node
50:33 - module folder basically
50:34 - this extra line is going to say hey
50:36 - don't touch this folder
50:38 - since it's a more specific more uh it's
50:41 - a longer path it's more specific so
50:43 - it overrides the bind mount the bind
50:46 - will still sync all of the other files
50:47 - it just cannot touch the node modules
50:49 - folder
50:52 - all right so now if we hit enter
50:56 - let's do a docker ps and it should stay
50:58 - running
50:59 - let's just make sure it didn't crash and
51:01 - it looks like it didn't
51:02 - so now if we go to the website let's hit
51:04 - refresh it's there
51:06 - let's make a few changes just to make
51:07 - sure nothing else broke
51:09 - we'll delete the exclamation points hit
51:11 - save
51:12 - and then hit refresh and it looks like
51:14 - everything's working
51:15 - everything looks perfect so far now
51:18 - there's one thing i do want to point out
51:20 - so you'll notice that we do a copy where
51:22 - we copy all of our files into our
51:24 - container
51:25 - uh at the build stage and you might be
51:27 - wondering well do we really need to do
51:29 - that
51:29 - if we have our bind mount and the thing
51:32 - is the answer is
51:33 - yes because the bind mount is really
51:35 - just for our development process
51:37 - uh we only use the bind mount when we're
51:39 - developing because that's when we're
51:40 - changing our code
51:41 - when we go to actually deploy in
51:43 - production
51:44 - there obviously isn't going to be a mind
51:45 - mount because why are we changing our
51:47 - code in production
51:48 - uh so we do we still need this copy
51:50 - command for when we deploy into
51:52 - production because there is no bind
51:53 - mount and we have to make sure all of
51:54 - our source code
51:55 - gets copied into the image for our
51:57 - production container
51:59 - all right guys so when it comes to
52:01 - docker volumes and bind mods i want to
52:03 - show you one last thing we're going to
52:04 - make one slight change
52:06 - it's not required but it's kind of best
52:08 - practice so what i want to do is
52:10 - i have a i have my container still
52:11 - running if you don't go ahead and just
52:13 - run this command again
52:14 - where you have the bind mount and the
52:16 - anonymous volume
52:17 - and i want to drop into bash
52:21 - so that we can take a look at the file
52:22 - system so docker exec dash it
52:25 - app and then bash
52:28 - all right so we're in our container and
52:31 - let's do an ls and so remember since we
52:32 - have the bind mount
52:33 - this directory is going to sync with the
52:35 - directory in our container
52:37 - however it's a two-way street so if i
52:39 - make changes here it's going to get
52:41 - updated here
52:41 - right if i do a new file i'll just say
52:44 - my file and i do an ls here
52:48 - right we can see my file however if i
52:51 - create a file within my container
52:53 - it's going to add it to my local machine
52:54 - as well so if you want to create a file
52:56 - uh just for demonstration purposes you
52:57 - can type in the command touch
52:59 - it's going to create an empty file and
53:00 - i'll just say test
53:02 - file so if i do an ls we created our
53:05 - test file
53:06 - and you can see the file showed up on my
53:07 - local machine i want you to think about
53:10 - a potential issue with that why is
53:14 - our docker container changing our our
53:16 - files
53:17 - do we ever need is there ever a scenario
53:19 - where you want your docker container to
53:21 - actually be making changes to your
53:23 - source code
53:24 - or any of the files associated with the
53:25 - source code probably not right it seems
53:28 - like almost like a security issue
53:30 - for it to even allow it to do that right
53:32 - there may be certain instances where
53:33 - your application actually creates files
53:35 - on the local machine and in that case
53:37 - you might want to allow it but for the
53:38 - most part
53:39 - you don't want your docker container
53:41 - being able to
53:42 - touch any of your files or make any
53:44 - changes to it because there's really no
53:45 - need to
53:46 - and so what we can do is uh we can take
53:48 - our bind mount that we created
53:50 - and we can make it a read-only bind
53:52 - mount which means the docker container
53:54 - will be able to read any of the files
53:56 - but it can't touch any files and it
53:58 - can't create any of the files right it's
54:00 - read only
54:00 - so let's get started on that we'll exit
54:02 - out of here and i'm going to kill this
54:04 - container
54:07 - and to make this a read-only bind mount
54:09 - it's very easy so let's run this command
54:11 - uh where'd it go there we go
54:15 - let's run this and all we have to do is
54:16 - specify
54:18 - uh colon at the end of slash app we do
54:20 - colon
54:21 - r o and that implies read only
54:24 - so we'll hit enter hopefully it's
54:27 - running
54:28 - uh and uh we're gonna go and drop into
54:30 - bash to our container
54:32 - all right and so now here let's create a
54:34 - file so we'll do touch
54:36 - new file and look at that it says this
54:39 - is a read-only file system it cannot
54:42 - make any changes it cannot create any
54:44 - new files it cannot edit any files
54:46 - everything is read only so this is a
54:47 - little bit of a
54:49 - an enhancement that we can make so that
54:51 - uh it protects our source code and it
54:52 - doesn't allow our docker container to do
54:54 - any kind of funny business
54:55 - with any of our source code all right so
54:58 - let's exit out of here
55:00 - and i'm just gonna do a little cleanup i
55:02 - don't need these files
55:08 - all right and now what i want to do is
55:10 - um i want to show you guys how we can
55:12 - start making use of environment
55:13 - variables within our docker container
55:16 - so if you go back to our index.js file
55:18 - and you remember our express app
55:20 - the port is going to listen on is going
55:22 - to be based off of an environment
55:23 - variable called port that we pass in
55:25 - uh if this variable is not set it's
55:27 - going to default to a value of 3000. so
55:29 - how do we make use of environment
55:30 - variables
55:31 - within docker containers first of all
55:33 - let's go to our docker file
55:35 - and we're going to specify a default
55:37 - value for our part variable so
55:39 - after our copy command it doesn't
55:42 - technically matter where you put this
55:43 - but we can say env so this is
55:45 - referencing environment variables we're
55:47 - going to create one called port
55:51 - and we're going to say the default value
55:53 - for this environment various port 3000
55:56 - and then we want to expose remember this
55:58 - is just merely for documentation
55:59 - purposes this command doesn't really do
56:01 - anything um
56:02 - instead of having to hard code 3000 what
56:04 - we can say is
56:06 - we can reference this port variable by
56:08 - passing in a dollar sign and the name of
56:09 - the variable support
56:11 - so if this gets updated this will
56:12 - automatically get updated as well
56:14 - so let's save that and what we want to
56:18 - do is uh
56:19 - let's see is do we have any containers
56:20 - running yep so let's just kill that
56:30 - all right and let's rebuild our image
56:32 - because we made a change to our docker
56:33 - file
56:35 - and we can do a docker build for that
56:42 - all right so now that those changes are
56:44 - made
56:46 - uh our application shouldn't really
56:47 - fundamentally change because
56:49 - now we're just setting our environment
56:51 - variable to be port 3000
56:53 - um before it was defaulting into a value
56:54 - of 3000 but now since the environment
56:56 - variable is set to 3000
56:57 - everything should theoretically work the
56:59 - same it's just now going through that
57:00 - environment variable
57:01 - but what i want to do is when we
57:04 - actually deploy the container
57:06 - we can specify what value we want that
57:08 - environment variable to be set
57:09 - because this is just the default value
57:10 - we can always override it
57:12 - so let's deploy a new container
57:16 - with the same exact command with both of
57:18 - our volumes
57:19 - but we can pass in an environment
57:21 - variable by passing in dash dash
57:25 - env or you can just do a single dash and
57:27 - the letter e
57:28 - so whichever you prefer i don't know why
57:29 - i prefer the double dash emv but
57:32 - uh whatever you prefer uh and then you
57:33 - pass in the name of the environment
57:34 - variable
57:35 - equals and then whatever value you want
57:36 - to be set to so let's say we want our
57:39 - express server
57:40 - to listen on port 4000 now it's going to
57:42 - change to 4000 however
57:44 - before we hit enter and actually create
57:46 - our container remember since our express
57:48 - application is listening on 4000
57:50 - we have to change uh the port that we're
57:52 - sending traffic to because right now
57:53 - we're sending traffic to our container
57:55 - on port 3000
57:56 - but our express app is listening on port
57:58 - 4000 so we have to change this to 4000
58:00 - or then our application is going to
58:01 - break
58:02 - uh we don't need to change um the port
58:04 - that we
58:05 - uh have to hit on our local machine we
58:07 - could technically change it to 4000 but
58:09 - it doesn't really matter
58:10 - uh you can pick any value really here
58:13 - so let's hit enter
58:20 - and let me just make sure it's running
58:22 - all right so it's running
58:24 - uh so now if i go to
58:27 - the web browser hit refresh it looks
58:30 - like it's working
58:31 - just to double check everything's
58:32 - working fine let's just make a few
58:33 - changes
58:34 - to add the exclamation points back save
58:38 - hit refresh it looks like everything's
58:40 - working uh just to double check
58:42 - i do want to make sure that the
58:43 - environment variable did get set
58:45 - so we can drop back into that container
58:47 - again like we always do
58:49 - where's that command docker exec
58:53 - so in a linux machine if you want to see
58:55 - the environment variables you just type
58:56 - in print
58:57 - env and so here we can see that the
59:00 - environment variable of port
59:02 - equals 4000 was set and so that confirms
59:04 - that when we ran
59:06 - our docker run command and passed in the
59:08 - dash dash env flag
59:09 - we were successfully able to overwrite
59:11 - the port variable or the port
59:13 - environment variable
59:14 - that was specified in our docker file
59:18 - now when it comes to your application
59:20 - you may have more than one environment
59:22 - variable actually you most certainly
59:23 - will
59:24 - and if you have a lot of environment
59:25 - variables uh you know we
59:27 - you can pass in the dash dash env flag
59:29 - as many times as you want
59:31 - so if you wanted to you can say where
59:37 - where'd it go here we go so if you
59:39 - wanted to pass in another one you can
59:41 - just do
59:41 - env and then whatever that variable is
59:43 - however if you've got like 10
59:45 - 20 environment variables that's kind of
59:47 - a little bit of an exhausting process
59:49 - and it's a little bit of a pain and so
59:51 - what you can do instead is we can
59:52 - actually create a file
59:54 - that stores all of our environment
59:56 - variables so here i'm going to call this
59:58 - you can call whatever you want but
60:00 - standard standard convention is dot env
60:04 - and here we can just specify port equals
60:07 - 4000
60:09 - right and so that's going to essentially
60:11 - do the same thing in here you could just
60:12 - provide a list of all of your
60:13 - environment variables
60:15 - and let's save that and i'm going to
60:19 - kill my docker container real quick
60:29 - and so now if you want to load uh
60:31 - environment variables from a file
60:33 - instead of having to pass
60:34 - each one line by line uh let's go to
60:37 - that docker run command and we can
60:38 - remove the dash dash env
60:44 - and we can pass in dash dash uh whoops
60:48 - dash dash env
60:50 - file and then the path to our
60:53 - environment fireball so
60:54 - from our local directory we do dot slash
60:56 - and then
60:57 - dot env and so that's going to grab this
61:01 - environment variable file and then all
61:03 - the environment variables stored in here
61:05 - i think i saved it yep and let's hit
61:08 - enter
61:09 - hopefully this works let's go docker ps
61:14 - alright it's running i'm going to log
61:15 - into the container
61:17 - and do a print nv let's just make sure
61:18 - that it's set and it looks like it's set
61:20 - so
61:21 - those are the two different ways to
61:23 - specify an environment variable and
61:26 - to set environment variables for your
61:27 - docker container so that your
61:28 - application
61:29 - can get the necessary data that it needs
61:34 - now one thing i want to point out is uh
61:36 - as you've been creating docker
61:38 - containers and deleting them
61:40 - if we do a uh docker ps uh you'll see
61:43 - that we just have one container running
61:45 - if you do a docker volume ls this is
61:48 - gonna list all the volumes that you have
61:50 - and you can see that we've kind of built
61:51 - up a couple of different volumes and you
61:53 - might be wondering
61:54 - what are these from and why are they
61:55 - building up as you keep creating
61:57 - containers and deleting containers
61:59 - they're going to slowly build up over
62:01 - and over and you'll eventually end up
62:02 - with hundreds
62:03 - uh and the reason for that is if you
62:04 - take a look at the command that we're
62:06 - running for our docker container
62:08 - this uh this volume that we specified
62:11 - right here for the slash app slash node
62:13 - modules hack
62:14 - uh this is anonymous volume so every
62:16 - time you delete your container it's
62:18 - going to preserve uh that node modules
62:20 - folder in here
62:22 - and uh we don't actually need to
62:24 - preserve it right because we're going to
62:25 - be deleting
62:26 - and creating new containers all the time
62:28 - so uh you can go in and manually delete
62:30 - the volumes
62:31 - right you can always do a docker
62:34 - volume rm and then specify the volume
62:37 - name
62:38 - or you can do a docker volume prune that
62:40 - should remove all unnecessary volumes
62:43 - but if you want to make sure that these
62:44 - volumes don't build up usually what i
62:46 - like to do is when you do the docker rm
62:48 - command
62:49 - um it's not going to delete the volumes
62:51 - associated with that container
62:53 - so if you want to delete the volumes
62:54 - which in our case we do
62:56 - there's obviously plenty of instances
62:58 - where you don't want to delete the
62:59 - volumes because the whole idea behind a
63:01 - volume is that
63:02 - it's persistent data you want to
63:03 - preserve it so like if you have if you
63:05 - have a postgres database or a sql
63:06 - database
63:07 - right uh you want to preserve uh all
63:10 - your database records so you would never
63:11 - want to delete that
63:13 - but in our case we just have an
63:14 - anonymous volume so that we can get
63:15 - around that limitation that we ran into
63:17 - before
63:18 - so when you delete a container just pass
63:20 - in the dash v flag
63:21 - when you pass in the dash v flag it'll
63:23 - make sure to delete the volume that's
63:24 - associated with that container
63:26 - so that it doesn't build up uh so for
63:29 - now
63:30 - i'm just gonna do a docker volume i
63:31 - think prune should work
63:33 - it's gonna say hit yes let's see if i do
63:35 - a docker
63:37 - volume ls uh you can see that it's
63:39 - deleted all but one and this is the
63:40 - volume that's associated with the
63:41 - container still running so
63:43 - if you want to do the docker that little
63:45 - trick i just showed you
63:46 - with the running container where is that
63:48 - here we go dash fv
63:51 - it's going to delete the container and
63:53 - it's also going to delete
63:54 - the volume as well so moving forward to
63:57 - do the dash
63:58 - f uh and then v so that you can delete
64:00 - the volume as well
64:02 - so now when it comes to um creating our
64:04 - container we've kind of set up a nice
64:06 - little quick workflow for
64:09 - developing a node or express application
64:12 - in a docker
64:13 - container however the command to run the
64:16 - docker
64:17 - container this command right here is
64:19 - kind of long
64:21 - and you know i don't want to have to
64:23 - rerun this command every single time i
64:25 - want to get my container
64:26 - up and running although i'm sure you're
64:27 - thinking well you can just hit the up
64:28 - arrow key so it's not a big deal
64:30 - and that is 100 true however keep in
64:32 - mind when you're actually developing
64:34 - uh you know like an express application
64:36 - or some kind of node application
64:37 - you're probably going to have more than
64:39 - one docker container right right now
64:41 - we're just building the
64:42 - uh the express server but in a
64:44 - full-blown application you might have a
64:46 - container for your
64:47 - database you might have an elasticsearch
64:50 - container you might have another
64:51 - container for redus you're going to have
64:53 - multiple containers
64:54 - right and each one of those containers
64:56 - you're going to have to run a command
64:57 - that's this long
64:58 - or potentially as long and at that point
65:00 - it starts to become a real hassle of
65:03 - getting your entire development
65:06 - environment up and running and even
65:07 - getting your production environment up
65:08 - and running
65:09 - because you're gonna have to run five or
65:10 - six docker commands you have to make
65:11 - sure there's no typos or anything like
65:13 - that
65:13 - so what i'm gonna show you guys is a way
65:15 - we can kind of automate all of these
65:17 - steps
65:17 - so that we don't have to run this
65:18 - monstrosity of command and we're gonna
65:20 - use a feature called docker compose
65:23 - where we can create a file that has all
65:25 - the steps
65:26 - and all of the configuration settings we
65:27 - want for each docker container so we can
65:29 - say like hey
65:30 - i want to create a node container using
65:32 - the image that i created
65:34 - and i want to create a volume uh for the
65:36 - bind mount and i want to create an
65:37 - anonymous volume
65:38 - i want to pass in the environment files
65:40 - and i want to open up these ports so you
65:41 - can pass in all these steps into a file
65:43 - and then you can just run one very
65:45 - simple command to bring up you know
65:47 - as many containers as you want so if you
65:48 - have like six or seven different
65:49 - containers in your development
65:50 - environment you can bring up all six or
65:52 - seven all at once with one command
65:54 - and bring them all down with one command
65:56 - so let me show you guys how to do that
66:01 - uh so what we're gonna do is we're gonna
66:02 - create a docker compose file
66:05 - and so we're going to do is we're going
66:06 - to do a new file we're going to call
66:08 - this
66:08 - docker compose dot yml so that stands
66:12 - for yaml
66:13 - uh it's a certain type of syntax that
66:16 - you use
66:17 - so what we want to do is with your
66:19 - docker compose file the first thing we
66:21 - have to do is specify the version that
66:22 - we're going to use
66:24 - now if you go to this website right here
66:27 - it's going to show you all the different
66:28 - versions of docker compose and the
66:30 - features that they support
66:31 - now we're not gonna do anything crazy so
66:33 - i'm just gonna use version three but
66:35 - if there's a specific feature that you
66:37 - need then you're gonna have to make sure
66:38 - you grab the specific version this is
66:39 - like a
66:40 - this web page has a list of all the
66:42 - features that each version supports so
66:43 - you can just take a look at this page
66:45 - and see what's the minimum version that
66:47 - you need to actually run all the
66:48 - specific
66:49 - features that you want but i just
66:52 - defaulted version three so we'll say
66:53 - version
66:55 - colon and then three
66:59 - now the next thing we want to do is we
67:00 - want to specify all of the containers
67:02 - that we want to create
67:04 - and so within our docker compose file
67:06 - each container is referred to as a
67:08 - service
67:09 - so we do services
67:12 - and then we just specify all of our
67:13 - services now this is very important with
67:15 - yaml files
67:16 - uh spacing matters okay so uh we're
67:20 - going under services and we're gonna
67:22 - provide a list of all the different
67:23 - services that we want so i want you to
67:25 - hit tab
67:25 - just once and then here we're going to
67:27 - provide our
67:29 - container our first container in our
67:31 - example we just have one container which
67:32 - is our node app
67:34 - and we want to give this container a
67:35 - specific name you can call it whatever
67:37 - you want
67:38 - we can say like oh my node app or
67:41 - we can call this node project whatever
67:44 - you want just give it a name
67:46 - i'm going to call this node app because
67:47 - that's what it is
67:50 - and then colon and then we're going to
67:51 - add in a specific
67:53 - configuration settings for that
67:55 - container uh so
67:57 - because we're gonna do configurations
67:58 - for that container i want you to hit one
68:00 - tab
68:01 - and then i want you to start adding in
68:02 - the the different
68:04 - um the different configuration settings
68:06 - so the spacing matters unfortunately so
68:08 - if i
68:09 - if i start moving things around you know
68:11 - it's going to break things so you want
68:12 - to do one space
68:14 - for each level and keep in mind if you
68:16 - have multiple containers let's say you
68:17 - have a postfish
68:18 - container you would add a postgres
68:20 - service if you had a redis
68:23 - reader service you'd add one here so
68:24 - this is how you add more containers or
68:26 - more services
68:27 - within a docker compose file we just
68:29 - have one so i'm going to delete these
68:32 - now under node app we have to specify
68:36 - um a build setting so what image are we
68:38 - going to use well
68:40 - we have to build the current docker file
68:43 - in our current directory so we can say
68:44 - build right and then we pass in a path
68:47 - to our
68:48 - docker file so it's going to be our
68:50 - current
68:51 - our current directory or whatever
68:53 - directory this docker compose file is
68:55 - so this is just um automating the the
68:58 - docker build command so that we don't
68:59 - actually have to do it doc
69:00 - compose will do it for us we just have
69:02 - to pass in the path to the docker file
69:06 - a couple other settings let me actually
69:08 - just hit up
69:10 - the up arrow keys to see all of the
69:12 - different options that we have so
69:15 - we do need to expose a port so let's
69:18 - open up a port so we can pass in the
69:20 - ports option
69:22 - so under ports one tab remember
69:25 - and here we can provide a list of ports
69:27 - we want to open so for our container
69:29 - we've only been opening up one port
69:31 - but theoretically you can open as many
69:32 - ports as you want
69:34 - so you do a dash because it's going to
69:36 - be a list of ports
69:38 - and then here we're just going to do
69:39 - 3000 colon 3000 you already know what
69:42 - that means i'm not going to rehash that
69:45 - if you wanted to add another port or
69:47 - open up another port you can do that so
69:48 - you can do like 4000
69:50 - colon 4000 as well but we're just going
69:52 - to open up one port so i'll delete that
69:55 - now i'm going to hit backspace again so
69:56 - we're lined up with built-in ports
69:58 - because once again we're still under the
69:59 - node app service
70:01 - and here we want to pass in all of our
70:03 - volumes so we'll do
70:05 - a volumes
70:08 - and we're going to pass in our two
70:09 - volumes and once again this is going to
70:10 - be a list so i want you to hit tab
70:12 - just once and then we're going to pass
70:13 - in a dash so the dash signifies a list
70:16 - so the first one is going to be um our
70:19 - um
70:21 - our bind mount and the great part about
70:23 - this is that when you use a docker
70:24 - compose file we can just do the dot
70:26 - syntax we don't need to use this
70:27 - variables that i mentioned before so we
70:29 - just do dot slash
70:31 - colon and then slash app
70:36 - and i think you can pass an ro if you
70:37 - want if you want to be read only i don't
70:39 - really care
70:40 - right and then we need to pass in our
70:42 - anonymous volume right which is uh this
70:44 - one right here and that's that little
70:44 - hack that we did to make sure that we
70:46 - didn't override our node modules folder
70:48 - so we'll do slash app slash node
70:51 - underscore
70:52 - modules
70:56 - and then last but not least i'm going to
70:58 - add my
70:59 - environment variable it doesn't really
71:01 - matter where you put it so
71:02 - once again line it up with build ports
71:04 - and volume so we do environment
71:12 - and we say dash and then here you
71:14 - provide a list of environment variables
71:16 - so we can do port equals 3 000.
71:20 - all right keep in mind in this case this
71:22 - would be like the equivalent of
71:24 - running um the
71:27 - environment variables one at a time uh
71:30 - so let me see if i can find an example
71:31 - so like this
71:32 - however we can pass in a file like we
71:34 - did down here
71:35 - if you want so that we can use the dot
71:37 - env file and the way to do that would be
71:39 - let me see you can go down here we can
71:41 - say uh
71:43 - env underscore file colon
71:46 - and then we can say dash you can provide
71:48 - a list of files
71:50 - and then the path to the dot env file so
71:52 - whichever syntax you prefer i'm just
71:54 - going to comment this out
71:56 - i'm just going to use this because we
71:57 - just have one environment variable so
71:59 - there's no need to
71:59 - import it in from an environment
72:01 - variable file
72:04 - all right so let's hit save this has all
72:07 - of the settings
72:08 - that we need for our uh node app service
72:11 - uh and once again you know if you're
72:13 - building a full-blown project you're
72:14 - gonna have multiple services so you're
72:16 - gonna see
72:16 - how this kind of really simplifies the
72:18 - entire process of getting your entire
72:20 - development set up
72:21 - uh and up and running and as well as
72:22 - tearing it down all within one command
72:26 - so make sure you save that
72:33 - and what we want to do is we're going to
72:35 - run the command docker compose
72:37 - so we do docker dash compose this is
72:40 - important right don't do
72:41 - docker space compose it's a different
72:43 - command we want docker dash compose
72:46 - and we want up so that's going to bring
72:48 - up everything that's in our compose file
72:51 - and then one important flag is if we do
72:53 - help let's see what options we have
72:56 - we do have a d flag right if you
72:58 - remember when we run our containers
73:01 - we have to pass in the slash d flag or
73:03 - then we'll automatically attach to our
73:04 - containers
73:05 - which we generally don't want so we can
73:07 - pass in the same thing for our docker
73:08 - compose
73:10 - so we can do docker compose up dash d
73:13 - so let's see if that works
73:17 - uh so first thing you're seeing is that
73:18 - it's actually building our image
73:21 - and so it's running uh oop looks like i
73:23 - ran into wait
73:24 - up that's just a warning don't worry
73:26 - about that
73:28 - i think that's a yeah new patch so
73:30 - that's just a vulnerability message
73:31 - don't worry about that
73:32 - uh so it built our image if we do a
73:36 - docker image ls
73:38 - you'll see that this is the image that i
73:40 - built
73:41 - uh and notice the naming convention what
73:44 - it does is it grabs the
73:46 - project directory which i called node
73:48 - docker and then it passes underscore
73:51 - and then node slash app so the note
73:52 - slash app is from the service name
73:54 - so it took the project folder did
73:56 - underscore and then the service name if
73:58 - we had one for postgres it'd be
73:59 - underscore postgres or whatever we
74:00 - called it
74:02 - all right so it built the image and then
74:05 - it also started our container so if we
74:07 - do a docker ps
74:11 - right you can now see that we have one
74:12 - container running and it called it once
74:14 - again
74:15 - take a look at the name node docker
74:17 - which is the project name
74:19 - underscore uh then the name of the
74:21 - service and then there's an underscore
74:22 - one
74:23 - i think if you have multiple if you spin
74:25 - up multiple node app services i think it
74:27 - goes like one two and three i think
74:28 - that's why the one gets appended
74:31 - um but let's test this out let's just
74:32 - see if everything works um so going back
74:35 - here if i hit refresh
74:37 - looks like it works and uh let's change
74:39 - our code
74:41 - and delete the exclamation points just
74:42 - to make sure it updates
74:45 - hopefully it works and it looks it looks
74:47 - like that guys everything works
74:48 - perfectly so hopefully you guys can see
74:50 - how easy it is now
74:52 - to actually bring up our entire docker
74:54 - environment which is one simple command
74:57 - and bringing it up is just as easy as
75:00 - bringing it down so now if you want to
75:01 - tear down everything
75:03 - we can do uh let's see we just do docker
75:06 - dash compose
75:07 - instead of up i'm sure you can guess
75:09 - what the command is it's just down
75:11 - and just like when it comes to deleting
75:13 - docker containers
75:15 - by default it will not delete those uh
75:17 - anonymous volumes so if you want to
75:18 - delete the anonymous volumes
75:20 - with the docker compose down we can do a
75:22 - dash v and that's going to delete
75:23 - all the unnecessary volumes that it
75:25 - creates so do dash v
75:29 - and you can see it's stopping the docker
75:31 - container it's then removing it
75:34 - technically when you run docker compose
75:35 - it creates a brand new network uh
75:38 - for all of your services don't worry
75:40 - about that it's kind of outside of the
75:41 - scope of this um
75:42 - of this video but it does automatically
75:44 - create a net us its own separate network
75:46 - so that it doesn't interfere with any of
75:47 - the other docker containers
75:49 - and you do get some extra features and
75:50 - perks when it comes to having a
75:52 - custom network like dns so that you can
75:55 - reference names within your project
75:57 - but don't worry about that for now so
75:58 - now if we do a docker ps
76:01 - you can see that the container is
76:02 - deleted and everything's cleaned up for
76:04 - you that's right one command and you can
76:05 - start and stop
76:07 - theoretically hundreds of containers
76:08 - right now
76:10 - there is one thing i want to tell you
76:11 - guys
76:13 - uh when we run the docker
76:16 - compose up command again what do you
76:19 - think is going to happen
76:20 - right because if you take a look at the
76:21 - steps uh that took place when we ran it
76:23 - the first time you can see it builds the
76:25 - image
76:27 - right it builds the image and then it
76:30 - starts the container
76:31 - now if we run this again i want you to
76:33 - tell me what you think is going to
76:35 - happen
76:35 - right your natural guess is going to be
76:37 - that it's going to build the image again
76:39 - and then it's going to run the container
76:41 - well let's figure that out let's see
76:43 - what actually happens if i run it again
76:46 - look at this the result was much quicker
76:48 - and that's because
76:49 - it skipped the entire build process it
76:51 - didn't build a brand new image
76:53 - all it did was it created the network i
76:55 - did tell you created a network and then
76:56 - it started our container
76:58 - and the reason for that is that what
77:01 - docker compose does
77:02 - is it looks for an image docker so if i
77:06 - do docker image ls it looks for the
77:07 - image based off of that the syntax that
77:10 - i told you which is
77:11 - project directory and then the name of
77:14 - the service and if it sees that that
77:16 - image already exists
77:17 - it's not going to rebuild it however
77:20 - even if we make a change right let's say
77:22 - we
77:22 - change the default port to be
77:25 - four thousand oops right this
77:28 - theoretically
77:29 - is now a different um is now a
77:32 - different um it's a different image
77:34 - right we've changed something
77:36 - fundamentally
77:37 - in the docker file so it should rebuild
77:39 - the image
77:40 - if we run it again so let me tear it
77:42 - down again
77:43 - let's do a docker compose down
77:49 - all right and i think i saved it i can
77:51 - never remember if i do that
77:52 - and let's do a docker compose up so
77:54 - let's see if it rebuilt the image
77:58 - and despite the fact that we made
78:00 - changes it did not rebuild the image
78:02 - so now we're essentially running a stale
78:04 - image right why is it doing that
78:06 - like i said there's just a simple dumb
78:08 - check that docker compose does all it
78:10 - does is just look for an image
78:12 - named this so if we do a docker image ls
78:15 - we can see there's an image there it has
78:17 - no idea that this is a stale image and
78:19 - that there's been an update it doesn't
78:20 - know it's
78:21 - docker compose is pretty dumb it has no
78:23 - idea
78:24 - so you have to basically tell it like
78:25 - listen i've made a change i want you to
78:28 - rebuild the image so how do we do that
78:30 - well first of all let me let me tear
78:32 - things down again and let's go back to
78:35 - the docker compose up command
78:37 - and let's do a dash help
78:40 - and there should be an option that
78:43 - causes it to force a build
78:46 - and let me see if i can find it
78:53 - here we go dash dash build so this when
78:56 - you run the dash dash build flag it's
78:58 - going to
78:58 - tell docker compose to rebuild the image
79:02 - it has docker compose is not smart it
79:04 - does not know when it needs to rebuild
79:06 - the image you need to tell it to
79:08 - all right so let's rerun this again
79:10 - we'll do docker compose up
79:12 - dash d dash dash build this will force a
79:14 - brand new build
79:18 - and there you go so now we built a new
79:20 - image i now
79:21 - created everything and everything should
79:22 - be working now
79:25 - all right so we can tear that back down
79:28 - uh we can we can tear that back down
79:31 - change the default port to 3000
79:33 - save that um just so that we don't break
79:36 - anything else
79:38 - and then if you want to you can rebuild
79:39 - it again with the dash
79:41 - build flag and so this will bring
79:43 - everything back up and rebuild it with
79:45 - the new default port and everything
79:46 - should be working so let's just double
79:48 - check
79:48 - and yeah everything's working perfect
79:53 - um but that's the idea behind docker
79:54 - compose there's nothing too
79:56 - fancy about it obviously
80:01 - and obviously you're gonna have to take
80:03 - a look at the documentation
80:05 - to see other things because eventually
80:07 - when you get a little bit more uh
80:09 - familiar with docker and there's other
80:12 - settings or options or flags that you
80:13 - want to pass in
80:14 - you're going to have to update the
80:15 - docker compose file to
80:18 - take in those parameters so i just
80:19 - covered the basic parameters
80:21 - but there's obviously plenty more within
80:23 - the docker universe
80:25 - now we're almost done however there's
80:29 - kind of one last thing this is kind of a
80:30 - big thing but you may have noticed
80:33 - that um we're running
80:36 - npm run dev right so how do we actually
80:41 - go into production right because right
80:43 - now when we run docker compose
80:45 - everything is with respect to our
80:48 - development environment because our
80:49 - docker compose
80:51 - it creates that bind mount which we
80:53 - would never want in production
80:54 - deployment right we don't need it to
80:55 - sync with anything it's our production
80:57 - deployment
80:58 - right and our production deployment
80:59 - might actually use a different variable
81:01 - or
81:01 - a different port uh that express listens
81:04 - on or could use the same one i don't
81:06 - actually know
81:06 - it's going to depend on your company or
81:09 - how you set up your project
81:11 - uh but mainly also within our docker
81:13 - file it's not going to run npm rom dev
81:15 - instead it's going to run either with my
81:17 - package.json it's going to run an npm
81:19 - start
81:19 - or we can just run nodeindex.js directly
81:23 - so in the next section i'm going to show
81:25 - you guys how we can
81:26 - set up our docker compose file so that
81:28 - we can have a separate
81:30 - set of commands for production and a
81:32 - separate set of commands
81:33 - for uh development
81:37 - all right guys so this is going to be
81:38 - the last section of the video and this
81:40 - is going to just round out the entire
81:42 - project i'm going to show you guys how
81:43 - you can set it up so that
81:44 - you can deploy your docker containers to
81:46 - both a development environment
81:47 - as well as a production environment
81:49 - because there are going to be some
81:50 - differences between those two
81:51 - environments
81:52 - and the easiest solution is you know you
81:54 - can obviously have a separate you can
81:56 - create multiple docker files there's no
81:57 - rule against it
81:58 - so you can have one docker file for
82:00 - development one docker file for
82:02 - um for production and then you can
82:04 - basically change out what you want so
82:06 - really the main change in our case is
82:07 - just the final command that we run
82:09 - npm run dev for development and npm
82:11 - start or
82:12 - node index.js for production depending
82:15 - on which one you want to use
82:16 - if you read online some people recommend
82:18 - not using the npm command within
82:19 - container because it's just another
82:21 - layer between node and the container
82:23 - so a lot of times they for production
82:25 - especially you may want to just run node
82:27 - index.js instead of running npm start
82:29 - um but i think different people have
82:31 - different opinions on that
82:33 - so we can create different docker files
82:35 - and on top of that we can also create
82:38 - different docker compose files so you
82:40 - might you could have one for production
82:42 - and you can have one for development uh
82:44 - there's also different
82:45 - differing opinions on on that some
82:47 - people like to condense as much into a
82:49 - single file
82:50 - and be able to kind of run both of them
82:52 - off of one file but it really comes down
82:54 - to personal preference
82:55 - so what i'm going to do is i'm going to
82:56 - show you guys how to
82:58 - um do everything as much in one file as
83:01 - possible so for we're going to use
83:03 - only one docker file but we are going to
83:05 - split up the code docker compose files
83:07 - into two different files
83:08 - um because um showing you how to do with
83:10 - two different docker files it's pretty
83:12 - easy right you just create two different
83:13 - docker files and then reference them
83:14 - when you actually run the build command
83:17 - and then so there's nothing really to
83:18 - that but i do want to show you how to do
83:20 - it with one file
83:21 - um just in case you want to know that
83:23 - because it was a little bit trickier we
83:24 - do create like a custom bash script that
83:26 - actually handles it so let me walk you
83:27 - through that
83:29 - so what we're going to do is i'm going
83:30 - to rename this docker compose file
83:32 - just for uh just so that we have this
83:34 - for reference but we're not going to use
83:36 - this anymore this is just i'm just going
83:37 - to rename it as backup or something
83:40 - dockercompose.backup.yaml
83:42 - and we're going to create a brand new
83:44 - dockerfile a brand new docker compose
83:46 - file
83:51 - and on top of that i'm going to create
83:52 - two more files
83:55 - so let's do a new file i'm going to call
83:56 - this one docker dash
83:58 - compose dot dev dot yaml so this is
84:01 - going to have
84:03 - the configuration specifically for our
84:04 - development environment and then we're
84:06 - going to create one more and i'm going
84:07 - to call this docker dash
84:14 - compose.prod.yaml
84:16 - uh so this is going to have all the
84:17 - configurations specific to our
84:19 - production environment
84:21 - and remember we're just going to have
84:22 - one docker file
84:26 - all right so we have three docker
84:28 - compose files
84:29 - and obviously if you have like a staging
84:30 - environment you can also create another
84:31 - one for that
84:33 - but sorry these are the three this is
84:35 - the backup just for reference if you
84:36 - guys want to take a look at that later
84:38 - but these are the three so the docker
84:39 - compose file now is going to have any
84:41 - configurations
84:43 - that are shared between both
84:44 - environments uh and what i mean by that
84:46 - is that
84:46 - uh like i said in an actual project
84:49 - you're gonna have
84:50 - you know six seven ten you might have a
84:52 - ton of containers so you'll see that a
84:54 - lot of the configurations
84:55 - for your containers are gonna be the
84:57 - same regardless of environment so
84:58 - there's no point in us
84:59 - copying and repeating all of those
85:01 - configurations across both of these
85:03 - files
85:03 - we're going to create a shared one for
85:05 - all the configs that will be shared
85:06 - between both environments
85:10 - so what i'm going to do is i'm going to
85:11 - do the same thing we're going to set the
85:12 - version
85:13 - like we normally do
85:17 - and then here services we've got our
85:20 - node
85:24 - app
85:26 - and i forgot to add that tab from spaces
85:29 - matter and yaml
85:30 - right and we're going to set the build
85:31 - to be the current directory like we did
85:33 - before
85:36 - and then for my production and for my
85:37 - development environment i'm just going
85:39 - to say they're both going to be
85:39 - listening on port 3000
85:41 - however keep in mind that maybe in your
85:44 - environment they're different so
85:45 - if they're different you don't want to
85:47 - put in this file because this file is
85:48 - only for when things are the same
85:50 - between your production and your
85:52 - development if they're different you're
85:54 - going to want to put them
85:55 - in their respective files this is only
85:57 - for shared configurations where they're
85:58 - the same in both environments
86:01 - so ports we'll set that equal to
86:06 - 3000 colon 3000 like we always have
86:12 - and then we'll also set an environment
86:13 - variable to be
86:16 - um port 3000.
86:22 - all right so this is the only
86:22 - configuration that's shared between both
86:25 - right so our development so in our
86:27 - development our production environment
86:28 - basically we're saying that
86:29 - the the final image is going to be the
86:31 - same ultimately
86:33 - uh that we build from our docker file
86:35 - because both
86:36 - environments are going to use the same
86:37 - docker file the ports are going to be
86:39 - shared so we're going to use port 3000
86:41 - and this environment variable that we're
86:42 - setting is going to be shared between
86:43 - both environments
86:47 - all right so now within our dev and our
86:49 - prod file we can actually go in
86:51 - into our services create a node app
86:52 - section and then overwrite anything that
86:54 - we wanted to so we could technically
86:55 - overwrite the ports
86:56 - we can add in extra configurations and
86:58 - so on so let's go to our dev
86:59 - environment
87:03 - and i'm actually going to go back to
87:05 - this and i'm just going to copy up to
87:06 - node app because it's going to be the
87:07 - same
87:08 - so we go into our dev and our node app
87:11 - and i'm going to set the volumes right
87:14 - because in our development environment
87:15 - we want
87:16 - our bind mounts as well as the extra
87:19 - anonymous volume
87:20 - for making sure our node modules folder
87:22 - doesn't get deleted
87:23 - so i'll do volume
87:29 - and we're going to do dot slash actually
87:32 - if i waste my time retyping that we can
87:33 - just copy this from here
87:35 - you just got to make sure the spacing's
87:37 - okay don't mess up the spacings
87:42 - uh and i think i messed it up hold on
87:45 - let's see
87:46 - so yeah one tab and
87:50 - one tab there we go
87:54 - all right and um since this is our
87:57 - development environment we're gonna pass
87:58 - in an environment variable
88:02 - did i spell that right that does not
88:04 - look right there we go
88:06 - and we'll say node
88:10 - underscore env so this is just common
88:12 - across node applications where
88:14 - in your development environment you're
88:15 - just going to set this to development
88:16 - and then in your production you would
88:18 - set it up
88:18 - you would set it equal to production
88:23 - all right and then the final thing is in
88:26 - our docker file i'm going to change
88:28 - this to default to um
88:31 - it doesn't really matter what we said
88:32 - here because we're going to overwrite it
88:33 - so i'll just set this to
88:34 - either npm start or index.nodeindex.js
88:38 - whatever you prefer
88:39 - i'm just going to set this to index.js
88:41 - by default and remember we can overwrite
88:43 - any of this in our docker compose file
88:45 - so in here we can override this that
88:47 - command
88:49 - with the command option and we can say
88:52 - npm
88:54 - well we do this on the same line npm run
88:58 - dev right because we have that script
89:01 - that's going to run node mod so that it
89:03 - restarts our code in our development
89:04 - environment
89:06 - let's save that or save everything and
89:09 - now let's move on to our compose
89:11 - prod file but copy the first three lines
89:14 - as usual
89:21 - now in our prod file what do we need to
89:24 - exactly change well let's take a look
89:27 - we don't in our development environment
89:29 - we had our volumes we don't actually
89:31 - need these
89:32 - the only thing i can think of is we need
89:34 - to change the environment variable to be
89:35 - production
89:36 - and we need to change the command to be
89:38 - either node index.js or npm start
89:41 - depending on what you prefer so let's
89:42 - add those in
89:45 - so we'll do environment
89:55 - and then we'll do node underscore env
89:58 - equals
89:58 - production and then our command is going
90:02 - to be set to
90:03 - node index.js once again you can do npm
90:06 - start whatever you prefer
90:08 - so that's pretty much what we need so
90:11 - let's test this out
90:13 - i'm assuming i've probably put in a
90:14 - couple of typos so we're probably going
90:15 - to have to do a little bit of debugging
90:17 - all right so what we want to do is the
90:18 - command's gonna be a little different so
90:20 - first of all
90:21 - uh do i have anything running yeah i do
90:23 - so let's uh let's do a
90:25 - docker compose down dash v to delete
90:28 - everything
90:31 - so docker ps docker images
90:37 - all right so um now how do we actually
90:40 - run this
90:40 - now that we are going to have to run two
90:43 - docker compose files right because when
90:44 - we want to run in production we're going
90:46 - to do the the base docker compose
90:48 - plus the dev and then when we want to
90:49 - work in production we do the base plus
90:51 - the prod
90:52 - well what we have to do is you do docker
90:54 - dash compose
90:56 - and then you pass in the flag for file
90:59 - and this is important the order actually
91:01 - does matter so the first
91:02 - file that we want to pass in is the base
91:03 - file so we do docker
91:06 - dash compose compose.yaml
91:10 - then we pass in the dash flag again to
91:12 - specify the second file
91:13 - so if we want to go into development
91:15 - we're going to pass in the docker dash
91:17 - compose.dev.yaml
91:21 - right and so that what's going to happen
91:22 - is it's going to load all the
91:23 - configurations from the base file
91:24 - and then it's going to load all the
91:27 - configuration from the dev file and then
91:28 - if it needs to it'll overwrite any of
91:30 - the configurations that it's been set to
91:32 - uh from the base and that's why we pass
91:34 - it in that order
91:35 - right and then we want to say we want to
91:36 - bring it up and then remember we want to
91:38 - run it in detached mode so let's test
91:40 - this out
91:41 - hopefully this works uh what did i mess
91:45 - up
91:45 - uh dockerdev.yaml what did i mess up uh
91:48 - must be a mapping not an array
91:50 - uh let's see oh yeah look i mean you can
91:53 - see i already messed the indentation the
91:54 - volume
91:55 - environment command need to be under the
91:57 - node app section so that's what broke
91:59 - let's tab everything up one section
92:05 - and now let's give that a shot
92:09 - all right looks like things are working
92:10 - so hopefully
92:14 - it looks yep everything looks good so
92:16 - let's just do a docker ps
92:19 - and we see our container running let's
92:21 - go to
92:22 - our application let's hit refresh looks
92:25 - like it's working
92:26 - let's just go to our code make a few
92:28 - changes
92:30 - to make sure that things are updating
92:31 - and that nodemon's doing its job so
92:32 - let's hit save
92:33 - let's go back hit refresh look at that
92:36 - so this is our development environment
92:38 - and it looks like everything's working
92:39 - perfectly
92:40 - and we can go ahead and shut that down
92:42 - so we'll do uh
92:44 - remember same thing we do down and we
92:47 - can pass in the dash v
92:48 - flag so we can delete those extra
92:49 - volumes
92:52 - and it should stop it uh now let's do
92:54 - the same thing
92:55 - uh we'll run that same up command but
92:57 - instead of running dockercompose.dev
92:59 - let's try the prod version now
93:04 - all right it should be the same exact
93:05 - command outside of specifying the yaml
93:07 - file
93:10 - so we hit enter perfect let's hit
93:14 - refresh
93:17 - all right so there's no exclamation
93:20 - that's just because we didn't rebuild
93:22 - the image um but we'll go over that but
93:23 - let's just try to change things
93:25 - well i guess there's no exclamation at
93:27 - the moment so let's hit save
93:30 - and let's see if it changes and it looks
93:32 - like it doesn't which is perfect
93:34 - all right we don't want any changes we
93:36 - add anything else here
93:38 - and then hit save remember we're in
93:40 - production so there is no bind mount and
93:42 - we shouldn't see any changes
93:43 - now just to make sure things are working
93:45 - i'm going to bring this down
93:48 - i'm going to do a down dash v
93:51 - and just like before right when we uh
93:53 - make changes
93:55 - to anything like our source code or
93:57 - anything else
93:58 - since we're in production environment
93:59 - and there's no bind mount anytime we
94:01 - make changes to our code we're gonna
94:02 - have to rebuild our image and we have to
94:04 - tell docker compose that we want to
94:06 - rebuild it
94:06 - so we'll do up so right now it's got all
94:10 - this nonsense in there so we do up
94:12 - dash d and then i think it's dash dash
94:14 - build it's gonna force a new build
94:17 - right because now we're changing our
94:18 - code there's no bind mount and so there
94:20 - so to actually see the update we have to
94:21 - rebuild the image
94:23 - right and so now if i hit refresh we see
94:25 - all of that nonsense
94:27 - and just as a double check let's delete
94:29 - the exclamations and let's delete all
94:31 - that nonsense right
94:32 - there hit save do we see any changes
94:35 - absolutely not because remember we are
94:37 - in production environment so this
94:38 - confirms
94:39 - that we now have set up a different
94:41 - docker compose file for our production
94:43 - environment and for
94:44 - our development environment to
94:46 - accommodate our specific needs for each
94:48 - environment
94:50 - now there is one last thing we got to do
94:53 - because uh there's a little bit of an
94:54 - issue
94:55 - and uh i'll show you why uh right now we
94:58 - what was the last commandment we're
94:59 - running in production mode right so we
95:01 - ran the docker compose.prod
95:04 - and i'm going to do a docker ps let's
95:07 - just quickly get the name of that docker
95:08 - image
95:09 - and i'm going to connect to this docker
95:11 - container so we'll do docker exec
95:13 - and copy that a name and then we'll do
95:16 - bash
95:20 - all right so here what i'm going to do
95:22 - is well first of all you'll notice that
95:24 - we copied a whole bunch of
95:25 - docker compose files and that's because
95:28 - in our docker ignore they're not in
95:29 - there so we can add those in there as
95:31 - well
95:35 - and we can just say docker dash compose
95:39 - star and that'll just ensure we don't
95:41 - copy anything
95:42 - uh or any file that starts with the
95:43 - docker dash compose so this is kind of a
95:45 - wild card for matching anything after
95:47 - that
95:48 - so we'll hit save on that but that
95:49 - wasn't really the main thing i wanted to
95:51 - address actually
95:52 - so if we go into our node modules folder
95:53 - this is kind of important if i do an ls
95:56 - this is going to show you all of the
95:58 - dependencies that we have all the
95:59 - packages
96:00 - and there's something very important if
96:02 - you look at this you can see that node
96:03 - mod is installed
96:04 - and you might be wondering why is that
96:06 - an issue and i want you to remember we
96:08 - are in production mode right
96:10 - and our in our package.json we can
96:13 - clearly see that
96:15 - nodemon is a dev dependency we don't
96:16 - need this when we run into production
96:18 - mode because we're never going to be
96:18 - using nodemod in production that's only
96:20 - for development so that it automatically
96:22 - restarts the note process
96:24 - when we are developing our project so
96:26 - how do we actually
96:28 - prevent nodemon and any other
96:30 - development dependency from getting
96:31 - installed because right now it's just
96:32 - taking up space and doing absolutely
96:33 - nothing
96:35 - well in our docker file you can see that
96:37 - we run an npm install
96:40 - if you want to actually deploy this to
96:41 - production right you would normally run
96:44 - a
96:46 - you would normally run i think it's a
96:48 - dash dash only
96:51 - equals production right and so that'll
96:53 - prevent any dev dependencies
96:55 - from getting installed um because you're
96:58 - running in production mode
96:59 - so what we have to do now is set up our
97:01 - docker file to be intelligent enough to
97:03 - know
97:04 - uh whether we are in development mode or
97:07 - production mode and then either run an
97:08 - npm install or an npm install dash dash
97:11 - only equals production
97:12 - depending on um if we are in our
97:15 - development or if we're in our
97:16 - production environment
97:17 - so how exactly do we do that well
97:21 - we're going to have to basically write
97:23 - an embedded
97:24 - bash script so here instead of this line
97:27 - right here what we're going to do is i'm
97:28 - just going to go under here
97:30 - and we're going to replace it with this
97:31 - i'm going to say run
97:33 - and we do an if statement
97:39 - and we're going to say if
97:43 - and then we're going to do brackets and
97:44 - this is important make sure you hit one
97:46 - space
97:47 - all right this this gave me all sorts of
97:49 - issues you want to make sure you put
97:50 - that space
97:51 - uh and then in quotations we'll do
97:52 - dollar sign node
97:54 - underscore env and then
97:57 - that equals development
98:02 - and this is also important hit one space
98:04 - afterwards i don't know why it required
98:06 - that but
98:06 - it did and i was troubleshooting that
98:08 - for a while so make sure you get the
98:09 - spaces just right
98:11 - uh so what we're saying is if we are in
98:15 - a development environment
98:20 - then we want to run an npm install
98:23 - however we're going to do an else
98:27 - if we're not in development so we're in
98:28 - production we're going to do npm install
98:32 - dash dash only equals
98:35 - production
98:39 - all right and then we end that if
98:43 - and we no longer need this run command
98:46 - okay so basically um you know we're
98:49 - referencing some kind of variable here
98:51 - called node env
98:52 - and then when it's set to development
98:53 - we'll do an npm install or else we'll do
98:55 - an npm install with
98:57 - dash dash only equals production now
98:59 - what exactly is this
99:01 - well this is an argument that we have to
99:03 - pass in so here
99:04 - we do arg node underscore env
99:08 - so this is an argument that gets passed
99:10 - into our docker file when it's building
99:12 - the docker image
99:14 - and we have to set this value in our
99:16 - docker compose file
99:18 - so under dockercompose.dev and dot prod
99:21 - we're going to have to pass that in so
99:23 - going to the dot dev file
99:28 - we are going to actually overwrite
99:30 - something in our um
99:32 - in our base docker compose file so
99:33 - instead of doing just build that
99:35 - we're going to have to change this up a
99:36 - little bit so here uh when we do the
99:38 - build command we're going to override
99:40 - that
99:42 - and instead of just doing dot uh instead
99:44 - of just doing colon dot we can actually
99:45 - break this down into a few more settings
99:47 - we can do build colon
99:49 - and then pass in two properties we've
99:50 - got the context
99:53 - and then we've got the args now the
99:55 - context
99:56 - remember when we did build dot and
99:58 - that's just specifying the location of
99:59 - the docker file
100:00 - that's what the context is so here we
100:02 - just specify the location of the docker
100:03 - file
100:04 - which is in the same directory so we
100:06 - just pass in dot once again
100:08 - and then here under args we pass in all
100:10 - the different arguments that we want to
100:11 - pass
100:12 - uh so here the only thing we care about
100:14 - right is the one that this docker file
100:15 - is using and it's called node underscore
100:17 - env
100:20 - so we do node underscore env
100:23 - i'm going to set this to development
100:24 - because we're in the development
100:27 - docker compose file and we're going to
100:30 - copy this
100:31 - and i'm going to do the same exact thing
100:33 - in my prod file
100:35 - and we're going to space that there we
100:37 - go i think that should be
100:38 - good yep and we're just going to change
100:41 - this to production
100:44 - and let's save everything
100:49 - and um let's just do
100:53 - i'm going to bring this down
101:15 - all right and let's just make sure we
101:16 - save everything again
101:18 - all right so now um it should
101:20 - theoretically
101:21 - you know run this if statement um
101:25 - when we want to do an npm install and it
101:26 - should be able to detect depending on
101:28 - what the arguments that's passed in so
101:30 - we're going to run a development fold
101:31 - first just to make sure everything's
101:32 - working and then we're going to run it
101:34 - in production mode after that just to
101:36 - make sure that that actually made the
101:37 - changes that we wanted
101:39 - so let's go back to my up command
101:43 - i'm going to start off with dev
101:48 - all right so it's building that
101:52 - remember i told it i passed in the dash
101:54 - dash bell flag because we made changes
101:56 - and
101:56 - docker compose is not an intelligent and
101:58 - it will not know that we need
102:00 - to actually rebuild it so i always pass
102:01 - in the dash build flag in that scenario
102:04 - and let's test this out so hit refresh
102:07 - just says hi there which is fine
102:09 - uh when we go to our index.js let's add
102:11 - some exclamation points
102:12 - hit save refresh
102:16 - perfect so just the fact that it
102:18 - restarted automatically and adopted
102:20 - those changes we know that nodemon was
102:21 - successfully installed
102:23 - and so we know that that if statement so
102:24 - far right here it ran in npm installed
102:27 - because it detected that we were in
102:28 - development mode so so far everything's
102:30 - looking good
102:31 - uh let's bring everything down
102:37 - with the with the dash v flag let's
102:39 - delete that volume
102:40 - uh and this time we're gonna bring it
102:42 - back up
102:43 - but i'm gonna do it in rod
102:55 - all right and let's just do a docker ps
102:59 - let's make sure everything's running
103:00 - perfect
103:01 - uh let's hit refresh
103:04 - perfect let me make changes to this code
103:08 - real quick just to make sure it doesn't
103:10 - adopt those changes so we'll hit save
103:13 - let's hit refresh no changes perfect
103:16 - the last thing that we wanted is let's
103:18 - log into the container and let's just
103:19 - make sure it did not install
103:21 - node mod just to ensure that it did
103:23 - successfully run the dash dash only
103:25 - production flag
103:27 - so we'll do docker exec i t
103:35 - and then bash
103:39 - right ls let's go into node modules also
103:41 - notice how our docker ignore file worked
103:43 - this time
103:44 - because it did not import any of the
103:46 - docker compose files
103:48 - but let's go into the node modules
103:49 - folder let's do an ls
103:51 - uh do you guys see anything with known
103:53 - mind it should be alphabetical
103:58 - right so if we go to m
104:01 - and uh see nothing with node mod so
104:04 - it successfully is in production mode
104:05 - and if you do a print nv
104:07 - uh we can see that
104:12 - uh i would have thought we would have
104:13 - set a node dmv set to production too so
104:16 - everything looks like it's working it's
104:18 - successfully only installed all of
104:20 - our um production dependencies
104:23 - and so guys that's all i wanted to show
104:25 - you it's just a matter of two commands
104:27 - uh whoops well looks like we're not
104:29 - actually gonna get out of the container
104:30 - but it's just two commands right so you
104:32 - do docker compose up docker compose down
104:35 - um and then if you're in production you
104:37 - pass in the prod if you're in
104:38 - development you pass in dev that's all
104:39 - you have to do you've got two different
104:41 - environments and we can easily spin up
104:43 - all of our containers
104:45 - and then also spin them back down with
104:46 - just two simple commands
104:48 - up until now we've only been working
104:50 - with one docker container
104:51 - and that is our node container which
104:53 - houses our express application
104:55 - however what i want to do is i want to
104:57 - add a second container
104:58 - because this course is ultimately a
105:00 - docker course i want to make sure that
105:02 - you guys are comfortable with
105:03 - adding in more than one container into
105:05 - your application
105:06 - so what we're going to do is we're going
105:07 - to add a database to our
105:09 - application
105:10 - this is going to make our app a little
105:11 - bit more of a real world type
105:12 - application
105:13 - because we'll finally be able to persist
105:15 - some data so let's head on over to
105:17 - docker hub
105:19 - and so here i already searched for
105:21 - mongodb
105:22 - but if i just search for again you'll
105:24 - see that the official image is going to
105:25 - be the first result so select that
105:28 - and this is going to have all of the
105:29 - instructions for working with the
105:30 - mongodb image
105:32 - and if we head on over to docker run
105:35 - example right here we can see that
105:36 - uh the name of the image is just
105:38 - so we can do and then the specific
105:40 - tag or version that we're looking for
105:43 - so let's go to our docker compose file
105:45 - and let's add in this new database
105:48 - and so first of all we have to figure
105:50 - out where we need to add it inside this
105:52 - docker compose file
105:53 - and so if you already forgot under
105:55 - services this is where we actually
105:57 - define all of our containers so each
105:59 - container
106:00 - is a different service so we have one
106:01 - service called node app which
106:03 - is our node container so logically if
106:05 - you want to add a mongodb container
106:07 - we're just going to create a new service
106:09 - so let's go here i'm going to do uh make
106:12 - sure it's just one tab from the base
106:14 - oh not one there you go so it's lined up
106:16 - with the node
106:17 - app and let's create uh our
106:19 - container so first of all we have to
106:21 - name our service we can call it anything
106:22 - we want
106:23 - we can call it database we can call it
106:26 - we can call it whatever we want i'm just
106:28 - going to call it because it makes
106:29 - sense
106:30 - it doesn't have to be though i just want
106:31 - to make sure you guys understand that
106:32 - the service is just for your reference
106:37 - and you'll see here that we have a the
106:39 - build
106:41 - argument and so in our node app right
106:44 - we're actually building our own custom
106:46 - image we're taking the uh the base node
106:48 - image and then we're copying our code
106:49 - into it
106:50 - however for the service right
106:52 - we're just going to use
106:53 - this built-in image this has everything
106:55 - we need we don't need to customize it so
106:57 - anytime you're just using another image
107:00 - we can use the image property
107:02 - so we call image and then we call in the
107:05 - name
107:07 - so that's going to grab this specific
107:08 - image and i don't really care about the
107:10 - version any versions fine so i'm just
107:12 - going to grab whatever the latest is
107:14 - and then in the documentation it's going
107:15 - to show us that we have to pass in some
107:17 - environment variables
107:20 - and so you can see here it looks like uh
107:23 - where is it it's going to be somewhere
107:25 - down here
107:30 - here we go so these are the two uh
107:32 - variables the environment variables that
107:34 - we have to pass in to make sure our
107:35 -  container
107:36 - works properly so we have to provide the
107:38 - root username and the root password
107:41 - so i'm going to copy these
107:54 - and feel free to set it to whatever you
107:55 - want i'm just going to call this sanjeev
107:59 - and then let's grab the password as well
108:07 - and i'm just going to say my password
108:10 - so let's save this and then let's do a
108:13 - docker compose
108:14 - up we don't need to do a dash dash build
108:22 - all right so now we can see that it is
108:24 - now creating our container
108:26 - and if i do a docker ps we should now
108:29 - see two containers we have our
108:31 - node docker container as well as
108:33 - our node app as well
108:35 - so now that we have our container
108:37 - up and running what i want to do is i
108:38 - want to connect into the container
108:40 - and just poke around a bit so let's do a
108:41 - docker exec
108:44 - it then the name of the
108:47 - container
108:50 - and then we'll do bash so we can take a
108:52 - look at the file system
108:53 - and so here since we're connected to the
108:54 - container we can actually connect
108:56 - into so if i type in and
108:59 - then we get a pass in a couple of flags
109:01 - uh that's gonna be for your user and
109:03 - password so if i do dash u you pass in
109:05 - your username and so that's gonna come
109:06 - from that environment variable that you
109:08 - set
109:10 - and we have to pass in p for the
109:12 - password
109:16 - and so now we're uh we're logged into
109:18 - our
109:19 - uh instance and i want to run just a
109:22 - couple of commands if we type in
109:23 - db this is going to show us what
109:25 - database we're connected to
109:26 - and so right now we're connected into a
109:28 - test database i guess creates a
109:29 - test database so that we have some
109:31 - database to log into
109:33 - and we can create a brand new database
109:35 - uh with the use commands if i type in
109:37 - use and then the name of my new database
109:38 - so i'm just going to call this mydb
109:42 - you can see that it's switched to our
109:43 - newly created database
109:47 - and we can run the command show dbs to
109:48 - list all the databases
109:50 - and you can see that mydb is not listed
109:52 - on here and that's just because manga
109:54 - won't list this database until we have
109:56 - an
109:57 - a document or an entry within that
109:59 - database
110:01 - and that would probably explain why we
110:03 - don't see test in that list as well so
110:04 - let's create an entry
110:07 - and let's just say we're making like a
110:10 - an application like a library type
110:12 - application that's going to store a list
110:13 - of books
110:14 - so we can do db then the name of the
110:16 - collection which is called books
110:18 - and then we'll just do an insert so here
110:20 - we have to pass in
110:21 - uh the properties of that entry so we'll
110:23 - say
110:24 - name is going to be
110:28 - harry potter
110:32 - all right and so this means we
110:33 - successfully wrote to our database
110:35 - and if i type in db.books
110:40 - this is going to list out all of the uh
110:43 - documents within
110:44 - our books collection so here we've got
110:47 - one entry and we can see the name is set
110:48 - to harry potter
110:49 - perfect and if we do a show dbs now we
110:52 - can see my dv is now listed on there
110:55 - so let me log out of here and let me log
110:58 - out of here
110:59 - and i do want to show you guys one thing
111:01 - real quick um so if you remember
111:03 - if your goal is to get into the
111:07 - shell or the cli instead of having
111:09 - to do a docker exec it
111:11 - and then bash and then run where is this
111:14 - command
111:17 -  dash u instead what we can do is
111:19 - we can skip the bash and just run
111:22 -  dash u then the username
111:26 - and then the password
111:31 - right so just a quicker way to get there
111:35 - um but now what i want to do is i want
111:38 - to tear down our container so let's do a
111:40 - docker compose down
111:42 - and i'm going to use the dash v like
111:44 - we've been doing to make sure that we
111:45 - delete that anonymous volume
111:51 - and then i want to bring it up and i
111:52 - know you're thinking like why did we
111:53 - tear it down just to bring it back up
111:55 - it's obviously so i can teach you guys
111:57 - something so let's do up
111:59 - dash d
112:02 - and let's give it a few seconds to fully
112:04 - boot up and then
112:05 - what i want to do is i'm going to log
112:08 - back into
112:09 - the mango shell
112:13 - and let's do a show dbs right and right
112:16 - there
112:17 - something looks odd right our our
112:19 - database that we created called mydb
112:21 - is now gone and you might be wondering
112:24 - well what exactly happened
112:26 - well think about it we had a container
112:28 - our container we ran a docker
112:30 - compose down
112:31 - which then deletes the container then we
112:32 - ran a docker compose up
112:34 - which then creates a brand new container
112:36 - so this is a brand new container
112:38 - everything that was in the previous
112:39 - container has been deleted and this is a
112:41 - major problem
112:43 - because this is our database you know we
112:45 - don't want to lose that information i
112:46 - mean
112:47 - if you're doing you know running like
112:49 - node tests and things like that
112:51 - then yeah maybe you'd want your database
112:53 - to kind of start from a fresh state each
112:55 - time
112:56 - but you know in a production environment
112:57 - and even in a development environment
112:59 - we want to keep all of our database
113:01 - information so that we don't have to
113:02 - keep recreating those entries
113:04 - and especially in a production
113:05 - environment uh if you lost your database
113:08 - you know that's
113:09 - all of your uh that's all of your
113:11 - application data that's just gone right
113:13 - at that point you've pretty much broken
113:15 - your website or whatever application
113:17 - you're building so you don't ever want
113:18 - to lose that information
113:20 - and so how do we actually save that
113:22 - information and i'm sure you guys
113:23 - already know this right we use
113:25 - volumes you know if you look at our
113:27 - docker compose file
113:28 - actually let's go to the dev file and
113:30 - for our node app you remember there's
113:32 - two different volumes here
113:33 - so this helps us persist data so let's
113:36 - do the same thing with our
113:38 - container so let me exit out here and
113:41 - let's do a docker compose down
113:49 - and let's go to docker compose.yaml
113:52 - and let's add some volumes
113:56 - and uh you know if we go back to the dev
113:58 - actually to the dot dev yaml
114:00 - you'll see that there's two different
114:01 - volumes that we covered we covered the
114:03 - bind mount which syncs
114:05 - the data within the container to a
114:08 - folder on your local drive
114:09 - and then we have an anonymous volume so
114:12 - you know we could theoretically use
114:14 - either one
114:15 - if you wanted to be able to poke around
114:18 - on the on your database data on your
114:21 - local machine
114:22 - then you use a bind mount but however i
114:24 - don't really care about looking at that
114:25 - data
114:26 - you know i can just log into the
114:27 - client and actually just run commands to
114:29 - see what i need
114:30 - i don't care about the file system so it
114:32 - looks like anonymous volume is a better
114:33 - choice however here's the problem
114:35 - uh if you have an anonymous volume and i
114:38 - think i have a few left so if i do
114:40 - docker
114:41 - volume ls right you know these are what
114:44 - anonymous volumes are right
114:46 - just a bunch of random numbers uh just a
114:48 - random string or id
114:50 - i have no idea what these are for uh and
114:52 - so when you have an anonymous volume
114:53 - there's a good chance that you may
114:54 - accidentally delete it
114:55 - and so i don't feel comfortable using an
114:57 - anonymous volume for the scenario
114:58 - because this is our application data
115:00 - right i want to make sure
115:01 - i know which volume is storing that data
115:03 - so what we can do is we can create
115:05 - a name to volume named volume is exactly
115:07 - the same as an anonymous volume except
115:09 - we can give it a
115:10 - human readable name so let me show you
115:13 - guys how to do that
115:16 - and let's go under our service
115:19 - and let's create a volume
115:27 - and so here just like an anonymous
115:30 - volume we have to pass in a path
115:32 - uh within our container and so to get
115:34 - that information we have to look at the
115:36 - docs
115:39 - and let's take a look so here we go it's
115:42 - probably under this where to store data
115:44 - and so you can see they created a volume
115:47 - and here they used a bind mount so they
115:48 - stored it on their local directory and
115:50 - they synced it with slash data
115:52 - db so this is the folder in the
115:54 - container that we're interested in
115:57 - so we want to do slash data slash db and
116:00 - at this point this is
116:01 - a anonymous volume you can to convert
116:04 - this to a named volume all we have to do
116:06 - is just do a colon
116:08 - and then just give it a name so i'm
116:09 - going to call this
116:12 - db so it's going to save this volume
116:15 - with the name of mongo-db
116:18 - right and just to show you the
116:19 - difference right a bind mount you
116:22 - provide a path on your local machine to
116:24 - a path on the container
116:25 - an anonymous volume you just provide a
116:27 - path to the container
116:29 - directory that you're interested in and
116:31 - then for a named volume you do a name
116:33 - colon and then the path within the
116:35 - container but there's one more gotcha
116:38 - actually let's save this and i'll show
116:40 - you what happens if we try to run this
116:42 - as is so let's do a docker compose up
116:49 - right and it says named volume is used
116:52 - in a service but no declaration
116:54 - was found in the volume section
116:56 - right so it's saying that we have to
116:58 - declare something and when it comes to
117:00 - named volumes we do have to declare this
117:03 - volume in another portion of our compose
117:06 - in our docker compose file and that's
117:08 - because a named volume can be used
117:10 - acro by multiple services so you know if
117:13 - we had a
117:14 - um you know like another instance
117:17 - or another service or any other
117:19 - service
117:20 - they can attach to the same exact volume
117:22 - just like this service does
117:25 - so all we have to do is at the bottom
117:29 - we just provide volumes and so here we
117:31 - just provide a list of all of our named
117:33 - volumes
117:34 - so here we just call this mongo-db
117:38 - that's all you have to do now let's do a
117:41 - docker compose up
117:51 - and let's continue uh let's connect into
117:53 - our client
117:57 - right remember everything's gone so
117:59 - let's create
118:00 - a new database and let's just insert
118:03 - that same exact entry
118:27 - all right perfect so now let's exit out
118:30 - of here
118:31 - and let's tear down our uh all of our
118:34 - containers with the docker compose down
118:35 - and let's bring it back up and let's
118:36 - just verify
118:37 - that our information saved so let's do a
118:40 - docker compose
118:42 - down now this is where we run into
118:44 - another issue and that's why i wanted to
118:45 - show you guys this
118:47 - so remember we're using this dash v
118:48 - volume uh this dash v flag
118:51 - to automatically delete this anonymous
118:54 - volume um because we don't need it it's
118:57 - just there for that one little work
118:58 - around for our node application
119:00 - however the problem is that this will
119:02 - delete not only anonymous volumes but
119:04 - also named volumes
119:05 - so if we pass in this v flag it's going
119:07 - to also delete
119:09 - this database our database a
119:11 - volume
119:12 - uh and so we obviously don't want to do
119:14 - that because we just went through all of
119:15 - this hassle so that we could save
119:16 - our database data so we unfortunately
119:19 - cannot use the dash v flag anymore
119:21 - so what you're gonna have to do is
119:23 - remove the dash flee flag
119:25 - and just do it down and after that
119:27 - finishes running
119:28 - if you do a docker volume ls is going to
119:31 - list out all of your volumes
119:33 - you can see we have our node docker
119:34 - mongodb volume so you can see it's given
119:36 - a nice name so we know exactly what this
119:38 - is being used for
119:39 - but we've got all of these um anonymous
119:43 - volume so you'll see
119:43 - over time they start to build up uh and
119:46 - you just have to delete them yourselves
119:48 - and so there's a nice easy command
119:50 - called docker
119:51 - volume i believe prune but don't run it
119:54 - yet instead what i recommend that you do
119:56 - is
119:56 - start up your containers so bring this
120:00 - back up
120:09 - and then do a docker volume
120:12 - and then do a dash dash help
120:17 - and so we have this prune command which
120:19 - removes all unused local volumes
120:21 - so all of the volumes that are being
120:24 - used right now by the running containers
120:27 - will not get deleted when we run the
120:29 - prune only the ones we don't need so
120:31 - as long as you start up your application
120:34 - then your mongodb and then whatever
120:36 - anonymous volume is associated with your
120:38 - application at the moment
120:39 - will not get deleted and we can just
120:40 - clean up all the rest of the data that
120:42 - we don't care about so if i do a docker
120:44 - volume prune we should be good to go
120:52 - and so now if i do a docker volume ls
120:56 - you'll see we've got significantly fewer
120:58 - volumes
120:59 - um these are just the ones being used by
121:00 - either running or stopped containers
121:02 - so just make sure you uh i believe you
121:05 - should start your containers but i could
121:07 - be wrong
121:08 - maybe it also saves uh stopped
121:10 - containers as well so
121:11 - you might want to double check on that
121:14 - within the documentation
121:15 - but i do want to highlight you know just
121:17 - make sure that only that you only delete
121:19 - stuff that you don't need all right so
121:22 - now let's uh let's do a docker ps
121:24 - we have our container and let's
121:26 - connect into that container again
121:31 - and let's just do show dbs and we can
121:33 - see that our data is still there
121:35 - and if i do a db.books.find
121:40 - oh i forgot to switch databases so we
121:42 - have to use mydb
121:43 - and then now we do this and there we go
121:45 - so we've now got persistent data for our
121:48 -  database
121:49 - so now that our database is up and
121:51 - running let's set up our express
121:53 - application
121:54 - to connect to our database
121:57 - and when it comes to interacting with
121:59 - our database
122:00 - we're going to use a library called
122:02 -  so it's going to make it a little
122:03 - bit easier to talk to our database
122:06 - and so here if we pull up the
122:08 - documentation for mongoose we can see
122:10 - to install it we just do npm install
122:12 - mongoose so let's do that right now
122:20 - all right and so once that's done first
122:21 - of all we installed a new
122:24 - package so we have to tear everything
122:26 - down
122:30 - remember no more dash v because we have
122:32 - our database so let's do down
122:35 - and now let's do an up again
122:39 - and we want a dash dash build
122:48 - all right and now going back to the
122:49 - documentation the first thing we have to
122:50 - do is we have to import mongoose
122:52 - so let's copy that line
122:56 - we'll paste that in there and then we
122:58 - have to connect to our database so here
123:00 - we just call the mongoose.connect method
123:02 - and then we have to pass in our url as
123:04 - well as some config
123:06 - options
123:09 - uh and so the full url if you pull up
123:11 - the actual documentation
123:14 - it's going to look something like this
123:15 - we do mongodb
123:18 - and then colon slash then your username
123:20 - your password
123:21 - the ip address of the host the port and
123:23 - then some options as well
123:29 - so under here we'll do mongoose.connect
123:35 - mongodb slash
123:38 - and then here you pass in your username
123:39 - so mine's sanjeev and then
123:42 - password's gonna be my password at and
123:45 - then here we have to give the ip address
123:48 - right and so this is probably where most
123:50 - of you guys are gonna get stuck
123:51 - because we have to figure out you know
123:52 - what is our ip address how does ip
123:54 - addressing work with docker containers
123:56 - well here's the thing you know docker
123:58 - makes it really easy to work with
124:00 - containers and it automatically assigns
124:02 - your containers an ip address so if you
124:04 - ever want to figure out what the ip
124:05 - address of a container is
124:07 - first of all do a docker ps uh get all
124:10 - your docker
124:11 - containers that are running and then
124:12 - here you can do a docker network
124:14 - actually sorry docker inspect this is
124:17 - going to give us more detailed
124:18 - information about a container
124:19 - and we can grab our container name so
124:21 - here i'm just going to grab our node app
124:22 - first
124:23 - just to take a look and so here you're
124:26 - going to get a ton of information
124:29 - and if we go all the way to the top
124:30 - let's take a look at what's up there
124:33 - a lot of a lot of random information
124:35 - that we don't really care about
124:37 - and i believe what we're interested in
124:38 - is going to be all the way at the bottom
124:39 - so let's scroll on down to the bottom
124:42 - and here there's a section called
124:44 - network settings so this is probably
124:45 - where we want to look
124:46 - and so if we keep going down
124:50 - you can see there's something called
124:51 - networks and so there's a concept
124:53 - of uh there's a concept within docker
124:57 - called networks where you can create
124:58 - uh more than one network and then put
125:00 - different containers within those
125:02 - networks so that
125:03 - only the containers within a network can
125:04 - talk to one another and they can't talk
125:06 - to containers in other networks
125:08 - so it looks like there's a container
125:09 - called node docker underscore default
125:12 - so you know this is this represents our
125:14 - uh
125:16 - our directory name so this looks like it
125:18 - was created by docker compose and it
125:19 - actually was so docker compose does
125:21 - create
125:22 - a brand new network just for your
125:24 - application so that all of the
125:26 - containers and services
125:27 - within your docker compose file will get
125:29 - placed into that network
125:31 - and you'll see here we have an ip
125:33 - address so this is the ip address of our
125:35 - node application
125:36 - and then here you can see its default
125:38 - gateway and so we want to grab the ip
125:41 - address of our container so let's
125:42 - do the same thing for our
125:43 - container
125:45 - and let's do a docker inspect and then
125:47 - grab the name of our container
125:53 - once again it's using that same exact
125:55 - network that was created
125:56 - and we can see here this is the
125:59 - 172.25.0.2 so this is the ip address
126:03 - and i'm just going to copy that we can
126:04 - paste it in here
126:10 - and then we want to put the port that we
126:11 - that's going to run on that mongo's
126:13 - running on so it's going to be running
126:14 - on the default port
126:15 - as long as you didn't change any of the
126:16 - default configs so 27017
126:22 - and then we're going to pass this one
126:26 - property auth source equals admin
126:31 - all right let's save that and then here
126:33 - we're going to call uh dot then
126:35 - so here we're going to pass in an error
126:39 - function and we're just going to say if
126:40 - we successfully connect to our database
126:42 - i just want to do a console.log and
126:44 - we'll just say
126:45 - successfully connected to
126:49 - database and if this failed we'll just
126:52 - do a dot catch
126:54 - and we'll say first of all we'll pass in
126:56 - the error
126:58 - and we'll just console.log error all
127:00 - right let's save that and let's see what
127:02 - happens so
127:04 - uh if we do a docker
127:07 - ps and then we're going to do a docker
127:10 - logs
127:12 - and we'll connect to that node
127:13 - application so here
127:16 - we can see that it said successfully
127:17 - connected to database
127:19 - so it looks like we've successfully
127:20 - connected to the database and
127:21 - everything's working
127:22 - however there's something i don't like
127:25 - right right now
127:26 - we had to go into docker inspect to get
127:29 - the ip address
127:31 - of our container and then put it into
127:33 - our code however
127:34 - you know if we stop and start our
127:36 - containers or if we do a docker compose
127:38 - down and then back up right first of all
127:40 - there's no guarantee
127:42 - that we get the same ip address and even
127:44 - if we could guarantee the same exact ip
127:46 - address the first time we run it we'd
127:47 - have to go in
127:48 - we'd have to get the ip address and then
127:50 - update our code and that's just a really
127:52 - sloppy way of doing things
127:54 - and so docker actually has a nice
127:57 - feature
127:57 - that allows us to make it easy to talk
127:59 - between containers
128:01 - right and that's and this feature only
128:03 - exists when it comes to
128:05 - custom networks that get created so if i
128:07 - do a docker network ls
128:10 - you'll see there's a couple of networks
128:11 - that we have we've got the bridge and
128:12 - host network
128:13 - so these are the two default networks
128:15 - that come bundled with docker
128:17 - and then i've got a couple other ones
128:18 - you may not have these but you'll see
128:20 - that we have one for
128:21 - our node docker default so this is the
128:23 - one docker compose created
128:25 - this is the custom one that created just
128:27 - for our application
128:28 - and when you have a custom network this
128:31 - only happens with the custom networks
128:32 - the ones that you create not one of the
128:34 - two default ones when you have a custom
128:36 - network
128:37 - we have dns so when one docker
128:40 - container wants to talk to another
128:42 - docker container we can use the name of
128:44 - that container or the name of that
128:46 - service
128:46 - to talk to that container and so if we
128:49 - go back to our docker dash compose file
128:51 - you'll see that the service for my node
128:53 - app is called node app and the service
128:55 - for my container is called
128:58 - so i can refer to this container's ip
129:00 - address
129:01 - based off of this service name so if i
129:03 - call within my node app
129:05 - it's going to automatically grab the ip
129:07 - address of our container
129:09 - so if i go back to our index.js
129:12 - i can change this to
129:16 - and then here if we do a docker logs
129:20 - and let me just do a pass in a dash f i
129:21 - think it's dash f for follow actually
129:23 - let me just
129:23 - do a help real quick uh
129:26 - yeah dash f follow
129:30 - and here if i save this
129:34 - you can see we still successfully
129:35 - connected to the database so
129:37 - because of dns we're able to resolve
129:39 - this name
129:40 - uh this host name to be you know
129:42 - whatever our container is
129:44 - and just to show you guys exactly how
129:46 - that works let's actually log into my
129:48 - node application container so if i do
129:51 - docker exec
129:52 - actually first of all do docker ps and
129:54 - we'll do docker exec
129:58 - it
130:02 - and here we'll drop into bash let's ping
130:07 -  let's see what happens
130:10 - look at that right it automatically uses
130:14 - dns to resolve the name of
130:16 - and it got the ip address of 172 25.0.2
130:20 - which is our container
130:21 - so that's how this whole dns process
130:23 - works so anytime you want one of your
130:25 - containers to talk to another container
130:27 - all you have to do is refer to its
130:29 - service name
130:30 - and it'll automatically be able to
130:31 - resolve it because dns is built into
130:34 - docker
130:34 - and keep in mind this is only applicable
130:36 - to networks that you create
130:38 - it does not work with the default
130:40 - bridged network okay
130:42 - and if you want to take a look at your
130:44 - networks we can actually do a docker
130:46 - first of all we'll do a dot or network
130:48 - ls and we can do a docker network
130:51 - inspect well first of all i have to grab
130:54 - the specific network i want
130:56 - so the one that's specifically my docker
130:58 - compose created
130:59 - and then we can do inspect
131:03 - and i messed up the order sorry about
131:05 - that
131:08 - it's going to give us some more
131:10 - information about this specific network
131:14 - so you can see here the subnet that all
131:15 - of our containers are going to use are
131:16 - going to use the 172.25
131:19 - 16. we can see what the default gateway
131:21 - is
131:22 - and then we can see under the container
131:24 - section all of the containers we have so
131:25 - we've got our container
131:27 - and we can see the ip address as well as
131:28 - the mac address of this container
131:30 - and then we can also see the container
131:32 - for our node application
131:33 - and so this has also got an ip address
131:35 - and a mac address
131:38 - and i believe and and don't quote me on
131:40 - this but it looks like
131:43 - yeah actually that's all i wanted to
131:44 - show you guys from here so i think
131:45 - that's going to wrap
131:46 - up this network section so in the next
131:49 - section
131:50 - we're going to make a few changes to our
131:52 - application so that it's a little bit
131:54 - easier to work with environment
131:55 - variables
131:56 - and we can kind of store them all in
131:57 - this same area and section
132:02 - all right so you know one thing i don't
132:04 - like in our application is that first of
132:06 - all we're hard coding the url into our
132:07 - application
132:08 - you never want to do that instead what i
132:10 - would rather do
132:12 - is have this url stored as an
132:15 - environment variable
132:16 - and so that way you know when we move to
132:18 - production you know there's nothing that
132:19 - we need to change we can just pull the
132:20 - environment variables
132:21 - that we set either in docker compose or
132:23 - on the host machine
132:25 - so what i want to do is uh within our
132:27 - base directory i'm going to create a new
132:29 - folder
132:30 - and i'm going to call this config and
132:33 - within here
132:34 - i'm going to create a new file called
132:35 - config.js so this is going to store
132:37 - basically a variable that holds all of
132:39 - our
132:40 - environment variables and so here i'm
132:43 - just going to do a module
132:44 - dot exports equals
132:48 - and then here i'm going to store all of
132:50 - our environment variables
132:52 - so if we go back to our url there's a
132:55 - couple of things we need to pull out
132:56 - here we need the username for our
132:57 - mongodatabase the password
132:59 - we also need the ip address uh we know
133:02 - with docker we can always use
133:04 -  so you know whether you're in
133:06 - development or environment for the ip
133:07 - address you can always use so
133:09 - technically we
133:09 - don't even need to save that as an
133:11 - environment variable but you know
133:13 - down the road you know you definitely
133:15 - want to think about the future
133:16 - there may be a time where you decided
133:18 - you know what i don't want to keep my
133:20 - database as a docker container
133:22 - maybe you want to use some kind of
133:23 - managed service so in that case
133:25 - we can no longer use dns because it's no
133:27 - longer running as a container so
133:28 - if you ever do decide to maybe move your
133:31 -  database
133:32 - to outside of the docker world and then
133:34 - have it hosted by
133:35 - aws or some some other hosting platform
133:37 - or cloud platform
133:39 - uh then you would need to pass in a the
133:41 - ip address as an environment variable so
133:43 - i like to just store everything as
133:44 - environment variables just so that we
133:46 - can plan for the future
133:48 - so we need those three in the port
133:50 - because who knows right the port could
133:51 - change in the future so
133:53 - let's go back to our config.js and i'm
133:55 - going to define a property called
133:58 -  underscore ip
134:01 - and then here this is going to grab
134:02 - process dot env
134:04 - dot underscore ip so we're going
134:07 - to make sure that our docker containers
134:09 - pass this environment variable in
134:12 - however if it's not set then we're going
134:14 - to default to
134:16 -  right so that's what the the
134:18 - double pipes mean so
134:19 - if this is set then we're going to use
134:21 - this value and ip is going to be
134:23 - stored
134:24 - to the value of this environment
134:25 - variable however if this is not set then
134:27 - this variable is going to be set to
134:29 -  right and so the reason i'm doing
134:31 - that is because
134:32 - you know we can always default to
134:34 - as our ip uh if
134:35 - if we don't pass anything in
134:39 - the next thing that i want to do is
134:41 - we'll grab the the manga port so i'll
134:43 - call this underscore port
134:45 - and we'll say process dot env dot
134:48 -  underscore port
134:52 - and then here we're gonna pass in uh the
134:54 - default value of two seven
134:56 - zero one seven
135:00 - uh then we want the manga user
135:05 - and we'll pass in the value uh of the
135:07 - environment variable of
135:08 -  underscore user
135:17 - and we don't need to default that and
135:19 - then we need password
135:34 - all right so now just make sure that
135:36 - we're exporting it and what i'm going to
135:37 - do is in our index
135:39 - dot js file we can then
135:43 - import those environment variables
135:46 - so here this is what i'm going to do is
135:48 - i'm going to change this to a
135:51 - uh to the template string and then we
135:53 - can
135:54 - then grab those values so here this is
135:57 - going to be the username so we'll just
135:59 - say
136:00 - dahlin and then we're going to grab in
136:03 -  underscore
136:04 - user right and then make sure we let vs
136:07 - code import it or manually do it
136:08 - yourself
136:09 - in the password we want to do the same
136:16 - thing
136:20 - then here we also want to pass in the ip
136:30 - address
136:32 - and then grab the port as well
136:36 - right and make sure to let vs code
136:38 - import all of these for you
136:41 - and that should be about it technically
136:43 - we could do the same thing right here
136:44 - for port
136:46 - i just like to kind of have a config
136:48 - file right here that holds all of my
136:49 - environment variables
136:50 - so i can know exactly where to look if i
136:52 - ever need to change anything
136:54 - and it's just kind of nice to have all
136:55 - of these in a central location but you
136:57 - know this
136:57 - section this part of the the video uh
137:00 - completely optional
137:03 - all right let's save all and then let's
137:07 - so now that we saved it let's go do a
137:09 - docker logs
137:13 - and it looks like we got an error so
137:14 - what happened here
137:16 - it looks like we got an authentication
137:18 - failed so we clearly messed something up
137:20 - let's just make sure we save this and
137:23 - right it's failing
137:24 - because well first of all we haven't
137:26 - passed in any of these uh environment
137:28 - variables so
137:29 - uh we don't have a user or a password
137:31 - right now so we have to pass that into
137:33 - docker compose
137:35 - okay and so here right now we've been
137:37 - using the base
137:38 - docker compose file for everything uh
137:40 - and
137:41 - that's just because i just wanted to
137:43 - start off with something simple but
137:45 - uh i think it's time we started kind of
137:46 - splitting things up between our dev and
137:48 - prod for so
137:49 - right now we're just working on our dev
137:51 - environment so let's uh
137:52 - copy all of the related stuff
137:54 - that's for our dev
137:56 - environment and move it into the
137:57 - dev.yaml so that we're not cluttering up
137:59 - the shared configs
138:02 - so for the environment variables let's
138:03 - copy those
138:06 - actually i can copy all of this for now
138:09 - and go into our dev and then here
138:13 - we can remove image because that's not
138:14 - going to change whether it's production
138:15 - or
138:16 - development we'll set these environment
138:18 - variables
138:19 - and then we also need to set the new
138:21 - ones as well
138:23 - so what is this underscore
138:27 -  underscore user
138:31 - this is going to equal same thing as
138:33 - this in this case
138:37 - and actually i'm making a mistake so
138:40 - this
138:41 - is going to go under our node app right
138:44 - this is an environment variable for our
138:45 - node application
138:54 - we'll set that to sanjeev and then here
138:57 - we'll set this
138:58 -  password
139:03 - equal to my password
139:09 - and that's all we should need um because
139:11 - the rest uh can default
139:13 - to what we're already using so we don't
139:14 - need to pass those in and then now
139:17 - i think we should still be tailing this
139:21 - and we actually have to rebuild the
139:22 - containers because we pass the new
139:24 - environment variables so let's stop this
139:26 - and we're gonna have to do a docker
139:27 - compose down
139:44 - and let's bring it back up
139:52 - and i realized it connected to the wrong
139:54 - container
139:59 - we want our node application
140:11 - all right perfect so now we can see
140:13 - we've successfully connected to the
140:14 - database uh and once again guys this
140:17 - part of the video was purely optional
140:18 - but i just kind of like having
140:20 - everything
140:20 - in a centralized location and i just
140:22 - want to make sure that we kind of think
140:24 - about
140:24 - what our application is going to look
140:25 - like in the future and make sure that we
140:26 - can handle making any changes
140:28 - to where our database is actually
140:30 - stored all right if we take a look at
140:32 - the logs right here you'll notice that
140:33 - we've got a couple of
140:35 - warning messages so to clean up these
140:37 -  warning messages as well as maybe
140:39 - kind of clean up our index.js file
140:42 - what i'm going to do is i'm going to
140:43 - actually store our url into a variable
140:49 - and so here i'm going to do const and
140:51 - then we'll call this
140:52 - url and i'm just going to store this
140:56 - url up here
141:02 - and then in the connect method i can
141:04 - just call url
141:09 - then to get rid of those warning
141:10 - messages i'm going to pass in a few
141:12 - properties
141:14 - don't worry too much about these i'm
141:15 - just it's not really going to affect the
141:16 - functionality of our application
141:18 - it's just going to make sure that we
141:19 - don't see those annoying warnings
141:36 - all right and so that's all the changes
141:38 - i wanted to make in this case i just
141:39 - wanted to clean it up just a little bit
141:41 - so let's save that let's make sure that
141:42 - we successfully connected and we should
141:44 - be good to go
141:46 - now when it comes to starting up our
141:48 - docker containers especially using
141:50 - docker compose
141:51 - we can run into some potential issues
141:53 - and that is when we spin up
141:54 - both our node container as well as our
141:56 -  container we don't actually
141:58 - know the exact order that these will get
142:00 - spun up on right docker is just going to
142:02 - bring them up at the same time or
142:03 - relatively close to the same time
142:05 - and that can lead to issues because if
142:07 - our node container spins up first
142:09 - it's going to run this code right here
142:11 - to try and connect to our database
142:13 - however if our database is not up it's
142:14 - going to throw an error and then crash
142:16 - our application
142:17 - so we need a way to kind of tell docker
142:20 - to
142:21 - load up our instance our
142:23 - container
142:24 - first so that we can ensure that when
142:26 - it's up and running only then does our
142:28 - node container connect to it
142:30 - and docker compose has a depends on
142:32 - field that we can use
142:34 - so if we go into our docker compose.yaml
142:36 - we'll use the shared one in this case
142:37 - because we would want the same behavior
142:40 - whether it's in our production or our
142:42 - development environment
142:43 - and under our node app service we'll say
142:47 - uh depends on depends underscore on
142:51 - and then we have to pass in the name of
142:53 - the service that we depend on so we'll
142:54 - do
142:55 - slash or dash and then the name of the
142:58 - service so in this case
143:00 - and so what this is saying is that
143:02 - because our node app service
143:04 - depends on we are going to start
143:06 - our container first
143:08 - all right so that kind of helps us so
143:10 - let's tear everything down
143:25 - and then let's bring everything back up
143:30 - all right now we can see that um our
143:32 -  container was started first
143:34 - and our node app was started second and
143:37 - uh keep in mind
143:38 - uh you know if you run this you know
143:40 - enough times you can confirm that it's
143:42 - always going to be the container
143:43 - first because it sees that
143:45 - our node app is dependent on our
143:48 - service however this still does not
143:50 - technically fix
143:51 - our issue because the only thing docker
143:54 - does
143:54 - is it spins up this container first it
143:57 - has no idea whether
143:58 -  has fully initialized it has no
144:00 - idea if the
144:02 - database is actually up and running it
144:03 - just spins up the container but it
144:05 - doesn't do any checks to verify that
144:07 - our database is up and listening
144:09 - for connections
144:10 - so despite the fact that we have depends
144:12 - on it doesn't necessarily
144:14 - solve our issue it helps a little bit
144:15 - but once again our application
144:17 - um you know we could end up catching it
144:20 - where the
144:21 - container is up and running but
144:23 - itself is still down and hasn't
144:24 - initialized and our node app is ready to
144:26 - connect to it right and then at that
144:28 - point our application crashes
144:30 - and so ultimately there's nothing docker
144:32 - can really do in this case
144:34 - or nothing specifically that docker
144:35 - compose can do maybe if you have an
144:37 - orchestrator you can kind of work
144:39 - something out but at the end they
144:40 - you shouldn't rely on docker or your
144:42 - orchestrator to handle that instead you
144:44 - want to
144:44 - implement some sort of logic in your
144:47 - application
144:48 - to handle this scenario where your
144:51 - database
144:51 - isn't up and running before your
144:53 - application starts
144:54 - and so usually that involves you know if
144:56 - you try and connect and you're unable to
144:58 - connect to it you want to keep retrying
145:00 - until you're able to successfully
145:02 - connect to it now mongoose in this case
145:04 - will actually try for 30 seconds
145:06 - automatically for you after 30 seconds
145:08 - you'll crash out but for 30 seconds
145:10 - it will just keep trying and trying and
145:12 - trying and that's what we want so it's
145:14 - great that mongoose has this out of the
145:15 - box
145:16 - but i just want to make sure that you
145:17 - guys understand that ultimately
145:19 - you need to implement some sort of logic
145:21 - in your applications to ensure that you
145:22 - can handle this scenario
145:24 - i'm going to show you a you know as an
145:26 - example of what something that you could
145:27 - do and i'm not saying this is best
145:28 - practice
145:29 - it most certainly is not it's probably
145:30 - not the best way to handle this
145:32 - but i just want to show you how we could
145:34 - somehow implement some sort of logic
145:36 - in our application to keep retrying
145:38 - until is up and running
145:40 - so let's go back to our index.js and
145:42 - what i'm going to do is i'm going to
145:44 - create a function
145:46 - i'm going to call this connect
145:50 - with retry
145:56 - i'm going to take this mongoose method
145:59 - right here i'm going to drag it right
146:00 - into my function
146:03 - and then under the catch section right
146:05 - here
146:07 - i'm going to remove this
146:11 - first of all actually i'll keep the
146:12 - console.log i don't know why i removed
146:13 - that
146:15 - but then if we error out for whatever
146:16 - reason i mean ideally we should
146:18 - check to see if it's because we could
146:20 - not connect to the server but let's just
146:21 - assume because it's trying to connect
146:23 - that any error we get is because we can
146:24 - connect to it
146:25 - we'll say set timeout
146:28 - and then we'll call the same exact
146:30 - function so we'll do connect
146:32 - with retry and then we'll just say after
146:35 - five seconds so what's going to happen
146:36 - is
146:37 - we're going to call this function when
146:38 - we start our application
146:41 - and then it's going to run it's going to
146:42 - try and connect and if we can't connect
146:44 - to it
146:45 - what we'll do is we'll wait five seconds
146:48 - so that's
146:48 - the purpose of the set timeout we'll
146:49 - wait five seconds and then we'll just
146:51 - call connect with retry so we'll just
146:52 - call this function again
146:53 - and then we'll try and connect and then
146:55 - we'll do the same thing we'll wait five
146:57 - seconds and just keep trying this so
146:58 - this is gonna loop forever
147:00 - until we can finally hit this then
147:01 - statement right which is when we
147:03 - successfully connect to it and then we
147:04 - can break out of this function
147:06 - uh so that's just an example of how you
147:08 - would implement something within your
147:10 - application i'm not saying it's a best
147:11 - practice i'm sure there's
147:12 - something there's some negative aspect
147:14 - as to the way i've implemented
147:16 - this and maybe it's not best practice
147:17 - i'm just here to try and
147:19 - kind of sell home the point that you
147:20 - need to make sure your application
147:22 - handles the logic don't rely on an
147:25 - orchestrator
147:25 - don't rely on docker or docker compose
147:28 - because none of them can truly guarantee
147:30 - you that your database is fully up
147:32 - and running
147:33 - uh before your application starts make
147:35 - sure your application is intelligent
147:36 - enough to handle that scenario
147:39 - and so the last thing that we got to do
147:40 - is we got to call that function so
147:42 - here we just do connect with retry
147:47 - let's save that and now
147:50 - to actually test this out uh first of
147:53 - all let's do a docker
147:55 - first of all let's tear everything down
148:09 - and now i'm going to show you a command
148:12 - that we have or
148:12 - an option that we have with our docker
148:14 - compose up so if we run up again
148:18 - with the dash v if we just run this like
148:20 - this it's going to start all of our
148:21 - container all of our services
148:23 - however we can tell docker compose to
148:25 - only start up specific services
148:27 - so in this case we would want to bring
148:30 - up
148:31 - our we would want to bring up
148:35 - just our node application so if i do a
148:37 - dash dash help you can see at the top
148:39 - we can just provide our service names
148:42 - uh where is it i think it's somewhere
148:44 - here it's listed somewhere if you check
148:45 - it but it'll
148:46 - list out uh you can specify just the
148:48 - services you want to start
148:50 - so if i do uh
148:53 - and first of all that shouldn't be dash
148:54 - v that should be dash d sorry so here i
148:56 - can type in
148:57 - node app right and so that's just coming
149:01 - from
149:01 - our service name and so this should
149:05 - start just our node application so if i
149:07 - hit that
149:08 - we see a little bit of an issue right it
149:10 - started our container so why
149:12 - exactly did it start our manga container
149:14 - well that ultimately comes down to the
149:16 - fact that we use this depends on flag
149:18 - so because this service depends on
149:21 - right it's going to start no
149:23 - matter what
149:24 - so let's tear this back down and i'll
149:26 - show you how we can start just our node
149:28 - application
149:33 - now here we do up dash d
149:39 - and then node app
149:44 - and let's do a dash dash help
149:48 - and let me do that before the name of
149:50 - our service so here
149:56 - and there should be a specific flag and
149:58 - that is no depth right here so that says
150:01 - don't start linked services or it's
150:03 - basically saying you don't need to start
150:04 - the dependencies so when we start up
150:06 - our node application despite the fact
150:08 - that we depend on
150:10 - it will not start up all of any of our
150:12 - dependencies so that's the exact flag
150:14 - that we want
150:15 - so let's hit an up arrow remove that and
150:18 - then the dash dash
150:19 - i already forgot what it was no
150:22 - no deps
150:25 - and then we want to call our service
150:26 - name which is no dash app
150:29 - all right so now it's going to start
150:30 - just our node application
150:33 - let me do a docker ps just to confirm
150:36 - perfect
150:37 - and then let's do a docker logs
150:40 - and then we'll call this
150:46 - and then dash f so let's take a look at
150:49 - our application
150:50 - and let's see what happens
150:57 - and i can't remember if i did a save all
150:58 - i mean let's just do a save
151:01 - there we go okay so we can see that
151:03 -  tried to connect
151:05 - right and it said connection timed out
151:08 - all right and so
151:09 - uh you know by default i think it
151:11 - waits like 30 seconds again afterwards
151:13 - or something like that
151:14 - so let's see uh if manga if my for loop
151:17 - actually wasn't a four lift but if my
151:18 - repeating function works so we should
151:21 - ideally see the same exact error message
151:23 - when it tries to reconnect in a few
151:26 - seconds
151:31 - and there we go so i don't know if you
151:32 - guys saw that flash before you but
151:34 - uh it spitted out the error once again
151:36 - so this confirms
151:38 - that uh my application is continuously
151:40 - trying to connect to
151:42 - so let's bring up our container
151:45 - now so we can do a docker compose up
151:47 - and then here we can remove all of these
151:50 - flags and just bring up our
151:54 - service
151:56 - and so now if i run the the docker logs
151:59 - again for our node application
152:02 - when it tries to retry once again it
152:04 - should then successfully connect
152:08 - and there we go so now we can see that
152:10 - we've successfully connected
152:11 - and this confirms that our node
152:13 - application is intelligent enough
152:15 - to handle a scenario where our
152:17 - database is not up and running
152:19 - at a specific moment in time so it will
152:21 - just continuously retry over and over
152:23 - and over and over again
152:24 - until the database is finally up and
152:26 - running
152:28 - so now that our node application can
152:29 - successfully talk to
152:31 - our mongodb instance i think it's time
152:34 - we started to build out a demo crud
152:36 - application i was trying to think of
152:38 - what would be the best example project
152:39 - and i
152:40 - and i realized that uh you know
152:42 - searching through youtube i could not
152:43 - find a
152:44 - single a tutorial that covered how to
152:46 - build a to do application so that's
152:48 - exactly what we're going to build
152:49 - i'm just kidding i would never build the
152:52 - most annoying application
152:53 - instead what i'm going to do is i'm
152:55 - going to build the second most annoying
152:56 - application which is a blog application
152:59 - so let's get started now keep in mind
153:01 - when we start building out the express
153:03 - side of things i'm going to move a
153:04 - little bit quickly
153:05 - just because i want to make sure this
153:06 - video focuses more on the docker side of
153:09 - things i'm going to expect you guys to
153:10 - have a little bit of background
153:11 - when it comes to express already so i'll
153:14 - move quickly
153:15 - if you have trouble keeping up you know
153:17 - i would recommend watching another
153:18 - tutorial on how express works
153:20 - and then coming back to this but i want
153:22 - to make sure that anybody watching this
153:23 - whether they're interested in express or
153:25 - node that they can follow along because
153:27 - the
153:28 - idea behind all of this is all about the
153:30 - docker side of things and how we can
153:32 - build a
153:32 - development to production workflow so
153:35 - let's start off by creating a couple of
153:37 - folders
153:38 - so the first folder we need is one for
153:40 - our models this is going to store our
153:41 - mongoose models
153:42 - i will create a new folder for our
153:44 - controllers as well
153:46 - and we'll create a new folder for our
153:48 - routes
153:50 - and so let's start off by building our
153:51 - models and i'm going to create a new
153:54 - file and we'll call this um
153:55 - our post model so this is a blog
153:57 - application so we need something to
153:58 - represent our blog posts
154:03 - and from here we want to import mongoose
154:12 - and we'll do const post schema
154:23 - and here let's think about the
154:24 - properties we want to give it so it's
154:25 - got to have a title
154:29 - and we'll say this is going to be a type
154:30 - of string
154:32 - and then we're going to say this is
154:33 - required
154:36 - and we'll set that to be true and if
154:38 - they don't include a title we'll say
154:40 - we'll throw an error and say post must
154:42 - have title
154:44 - uh the next next property you should
154:47 - have would be a body
154:48 - so this is going to be the content of
154:49 - the post so once again there's going to
154:51 - be a type of string
154:53 - and we'll say required as well
154:59 - and we'll say uh post must
155:02 - oops must have body alright so this is
155:05 - going to be our blog model
155:07 - fairly straightforward uh and then here
155:10 - let's just make sure we export it
155:33 - and now let's create our controllers so
155:36 - that we can handle
155:37 - creating reading updating and deleting
155:40 - our posts
155:43 - we'll call this post controller
155:49 - and so first thing we want to do is we
155:50 - want to import our post model so that we
155:52 - can actually
155:54 - you know interact with our database and
155:56 - create posts
156:09 - and then we'll do export and then we'll
156:11 - define our
156:13 - controller for retrieving all posts
156:14 - we'll do get
156:16 - all posts
156:20 - and this is going to have a request
156:22 - response and
156:24 - next as well though that's optional for
156:26 - a route
156:33 - all right and the way to retrieve all
156:35 - posts with mongoose is we can just say
156:38 - const posts equals
156:42 - post dot find so that's going to connect
156:45 - to our database and retrieve all of our
156:46 - posts based off of this model
156:48 - however there's a couple things we have
156:49 - to do first of all this is um an
156:51 - asynchronous
156:53 - method so we have to do async await
156:55 - sorry that should be a wait
156:57 - and then this function needs to be an
156:58 - asynchronous function and then
157:00 - anytime you're working with anything
157:02 - that could potentially error out we need
157:03 - to
157:04 - throw it in a try catch block so we'll
157:05 - do try
157:12 - and i'm just going to move this into the
157:13 - try statement
157:16 - and if it's successful we want to make
157:18 - sure that we send a response and we'll
157:20 - say status 200
157:26 - and here we'll say first of all status
157:28 - of success
157:36 - and we'll say results actually we'll do
157:38 - data
157:41 - and we'll just pass in posts
157:44 - and then also uh anytime we return an
157:47 - array of any kind i usually like to
157:48 - include a results count so we'll say
157:50 - uh posts dot length so however many
157:53 - posts we retrieve
157:54 - we also return that as well
158:02 - and then if there's an error let's just
158:03 - send a status
158:05 - 400 i probably not the correct error
158:08 - code but remember this
158:09 - the point of this video is not about the
158:10 - express side of things i just need to
158:12 - get something up and running
158:13 - just to show you guys how all of this
158:15 - integrates together
158:20 - and we'll say status fail
158:24 - and that's all right so we've got the
158:26 - logic for retrieving all
158:28 - posts let's get the logic for
158:31 - [Music]
158:32 - retrieving an individual post
158:42 - is also going to be an asynchronous
158:43 - method they're all going to be
158:44 - asynchronous
158:50 - and i'm going to just copy and paste
158:52 - this and we're going to just change a
158:53 - few things but for the most part
158:55 - all of this is going to be fairly
158:56 - similar and then here the only thing
158:58 - that we have to change is
159:00 - post dot find by
159:03 - id and then we need
159:06 - rec dot params dot id so uh you know
159:10 - when you're retrieving a post what we're
159:11 - gonna do is we're gonna have the user go
159:12 - to
159:13 - uh localhost you know colon
159:16 - 3000 or whatever and then say you know
159:19 - api
159:20 - v1 i'll skip that for now and we'll say
159:22 - they want to go under the posts
159:24 - and then here they would pass in uh
159:26 - whatever id so if they want the
159:28 - post with an id of five they would pass
159:30 - that and to retrieve that value we just
159:31 - do rec.params.id
159:33 - and you know within our route we're
159:35 - actually going to just do call and id so
159:37 - that we can pass whatever value
159:39 - the request is into the params.id
159:44 - so we retrieve that we don't need the
159:46 - results because it's not going to be an
159:47 - array
159:50 - and don't have to do this but we're
159:52 - going to only return an individual post
159:54 - so we'll just say post
159:58 - and that should be all so then the next
160:00 - thing we want to do is for creating a
160:04 - post
160:07 - and actually instead of writing this out
160:09 - let's just copy this exactly
160:15 - and we'll call this create post
160:18 - and then we'll remove this and we'll
160:21 - just say post.create
160:24 - and we want to just pass in rec.body so
160:26 - uh the
160:27 - title and the body that the that the
160:29 - front end sends it's going to be
160:31 - attached to our body property so
160:33 - that should be all that we need we can
160:35 - return the same stuff
160:36 - all of that looks good all of that looks
160:38 - good
160:40 - and then we just need two more we need
160:42 - update and delete
160:47 - and we're going to copy the get one for
160:49 - the update
160:56 - so this will be update post
161:00 - and the method we're going to use is
161:02 - find by id
161:04 - and update and so first of all we have
161:07 - to get
161:08 - we have to pass in what the id is so
161:11 - just like we did for
161:13 - uh get one post we can just pass in
161:15 - rec.params.id
161:18 - and then we have to pass in the body so
161:21 - rect.body which is going to have the
161:22 - content of our post
161:24 - and then a couple of other things that
161:26 - are optional
161:27 - so i forget what these do
161:30 - just pass it in i know run validators is
161:33 - going to ensure that even when you
161:34 - update
161:35 - it's going to um it's going to
161:38 - make sure that you know like we go back
161:41 - to the models
161:42 - even when we update it's going to check
161:43 - to make sure that we have a title
161:45 - uh as well as a body as well so it's
161:47 - just going to do all of the
161:48 - mongoose schema validation even on an
161:50 - update which it doesn't do by default
161:55 - and i believe this is to return the new
161:57 - post that gets created but i could be
161:59 - wrong
162:09 - and then lastly we want to do our delete
162:11 - so let's just copy this
162:16 - and we'll change this to delete post
162:21 - and all we have to do is let's delete
162:23 - all of this
162:29 - and we're going to call find by id and
162:31 - delete
162:32 - and we just pass in rec.params.id
162:40 - and in this case there's no data so we
162:42 - can just pass in
162:43 - null or just not even include that
162:46 - actually
162:50 - all right so we've got all of our crud
162:52 - methods done our controllers are set
162:54 - uh the next thing that we have to do is
162:56 - just define our routes so let's go into
162:58 - our routes
162:59 - and let's create a file called uh post
163:01 - routes
163:04 - dot js
163:10 - and in here we want to import express
163:22 - and let's import our post controller as
163:34 - well
163:40 - now let's create a new router
163:47 - right and then let's start defining our
163:48 - routes so we do router
163:51 - dot route and then the specific url so
163:54 - this is just going to be
163:55 - the slash url the slash path
163:58 - and then now we can chain in what we
164:00 - want for our get method
164:02 - and then what we want for our um
164:04 - [Music]
164:05 - our post method as well so get and post
164:08 - remember they're always going to be
164:10 - if we actually take a look at the url
164:11 - it's going to be you know localhost
164:14 - 3000 and then if you go to slash
164:18 - get then it's going to call this
164:20 - specific route and if you go to slash
164:22 - post
164:22 - it's going to create a new a new post
164:26 - so that's how that's going to work so
164:27 - let's uh add the controllers into here
164:29 - so
164:29 - the get method is going to call the um
164:33 - the post controller uh get all posts
164:37 - so post controller dot get all posts
164:40 - and then for the post method this is
164:42 - going to create a post so we'll do post
164:44 - controller
164:45 - dot create post
164:50 - then let's go to our router instance
164:52 - again and do route and then here
164:54 - the route is going to be actually slash
164:57 - colon id
164:59 - and so anytime you pass the id you're
165:01 - usually going to do a
165:03 - either an update or a delete
165:07 - or get one post or an individual post so
165:09 - here we'll do
165:10 - get and then we'll pass in our post
165:13 - controller
165:15 - dot uh get one post all right and then
165:18 - we'll also do a
165:20 - dot update no sorry not update patch
165:25 - and we'll call post controller dot
165:29 - and then we also want a delete which is
165:32 - going to be postcontroller.delete
165:41 - and then we'll do module.exports equals
165:44 - router
165:47 - and now let's go back to our index.js
165:50 - file and let's
165:51 - wire that router up
166:00 - so here we'll call it post router
166:03 - which equals require and then our path
166:10 - two routes and then post routes
166:21 - and then uh right under here we'll say
166:25 - app.use
166:29 - and then we want to pass in the url so
166:31 - here we can say
166:34 - slash posts and then
166:37 - post router so what is this what's
166:40 - actually what's actually happening here
166:41 - so
166:42 - uh basically if someone sends a request
166:45 - uh
166:45 - and it has uh and it looks like
166:48 - uh you know localhost call colin 3000
166:52 - slash posts so if that first keyword
166:54 - after 3000
166:56 - uh is posts it's going to send it to our
166:58 - post router
166:59 - and then that's going to go to here so
167:01 - this is where our post router is defined
167:02 - and so it's going to strip off that
167:04 - posts now and then we're just gonna
167:06 - be left with either uh colon three
167:09 - thousand slash or colon three thousand
167:10 - slash id
167:11 - so then it's gonna match one of these so
167:12 - that's all i'm trying to do however
167:15 - i usually like to do uh slash api slash
167:18 - v1 so here you pass an api so that
167:22 - you know that this request is for your
167:23 - api in case you're hosting your front
167:25 - end
167:25 - and your back end within the same domain
167:28 - and then i like to specify the version
167:30 - of our api so this way at least it keeps
167:32 - your different versions independent
167:34 - so you can start a second version and
167:36 - they can run side by side
167:38 - and so now basically if there's a
167:40 - request to api v1 slash posts
167:43 - it's going to go to our post router
167:51 - and let's save everything
167:54 - so looks like nothing's broken but let's
167:56 - test this out
167:58 - i'm going to bring up postman and let's
168:00 - just say api
168:02 - v1 posts
168:05 - and let's do a send and look at that so
168:08 - it looks like things are working so we
168:10 - can see it's a success we got no results
168:12 - because we haven't created anything
168:13 - uh so that works let's now try to create
168:16 - an entry so we'll do post
168:18 - and then go into our body and then let's
168:20 - do uh raw
168:21 - and then json and then here let's change
168:24 - this
168:26 - so we need a title i'll call this my
168:29 - first post
168:31 - and then we need a body
168:35 - and we'll say i don't know body of first
168:37 - post whatever
168:41 - let's send it looks like we
168:45 - got an error so let's see what happened
168:51 - now we went to post routes and under
168:54 - actually let's go to our controller
168:57 - where we create a post
168:59 - and then here let's just do a
169:01 - console.log
169:02 - e so that we can see exactly what's
169:06 - happening
169:11 - and it says oh post must have a body it
169:13 - does have a body
169:21 - and i realize i know exactly what
169:22 - happened so um
169:24 - to actually attach the body of a request
169:27 - onto our
169:27 - request actually i worded that weird um
169:30 - but
169:31 - for express to actually take the body of
169:33 - the actual request and attach it to that
169:35 - request object
169:36 - that our controllers have access to we
169:38 - actually have to pass in a middleware
169:40 - so let's define that middleware real
169:41 - quick
169:44 - under our index.js
169:50 - right here we'll just say
169:52 - app.usexpress.json so that's going to
169:54 - ensure that the body gets attached to
169:55 - the request object
169:58 - and now if i hit send we can see that it
170:01 - successfully created the post we got the
170:03 - id back from mongoose so that worked
170:05 - if i go back to the get and then get all
170:07 - of our posts we should see that show up
170:08 - perfect
170:09 - let's update now let's update that post
170:13 - so i'm going to do slash and then we got
170:14 - to copy the id of this post
170:19 - and i'm going to change this to my first
170:20 - post updated
170:22 - let's hit send and we can see that the
170:25 - title got changed to updated
170:27 - and if i do a get and remove that id
170:33 - my first post updated so we've
170:34 - successfully updated a post
170:36 - uh let's try to get an individual post
170:40 - so let's send that we got the individual
170:43 - post
170:44 - and then let's delete that post as well
170:46 - let's delete it
170:47 - success we do a get now nothing perfect
170:54 - uh let's just add a few entries just so
170:56 - that we can have something in our
170:57 - database so i'm going to go to post
170:59 - let's just create a couple so got one
171:03 - and change this to
171:06 - second post
171:10 - third post and then let's go back to our
171:14 - get
171:14 - method right here and let's send and we
171:17 - should get three entries perfect
171:19 - so now we've got a basic crud
171:20 - application
171:22 - and i think that's a good stopping point
171:24 - for this section
171:30 - okay so we got our basic crud
171:32 - functionality going with our blog posts
171:34 - however
171:34 - i want to start to implement a user sign
171:37 - up
171:37 - and login functionality and the reason i
171:40 - want to do this is because
171:42 - i want to introduce one more container i
171:44 - want to introduce a redis container
171:46 - so we're going to use redis for
171:47 - authentication but to do that
171:49 - we have to implement the whole user sign
171:52 - up and login
171:53 - uh flow so that we can actually get that
171:55 - wired up to our
171:57 - our docker application so let's quickly
171:59 - get started on that i'm going to
172:01 - try to blitz through it as quickly as
172:02 - possible once again so that i can show
172:04 - you how we can wire up a
172:05 - redis container
172:09 - and so you know just like we did with
172:11 - our posts
172:12 - we're going to create a user model
172:21 - we'll import mongoose
172:31 - and then let's define our schema so
172:33 - we'll do const user schema
172:44 - and there's going to be just two
172:45 - properties the username and password so
172:47 - we'll set user name
172:48 - is going to be a type of string
172:55 - and this is going to be required so
172:57 - we'll set require to be true
172:59 - and then if they don't provide it we'll
173:00 - give it an error of user must
173:03 - have a username
173:07 - then we have to pass in another property
173:09 - which is unique
173:10 - so we can't have two users with the same
173:12 - exact username so this is going to do a
173:14 - little bit of validation ensure that
173:16 - uh if we're creating a new user that
173:18 - that username is not already taken
173:20 - i'm going to copy this and for the
173:23 - second property it's going to be the
173:24 - password so i'm just going to change
173:25 - this to be
173:26 - password
173:30 - type string we don't need it to be
173:32 - unique required and we'll just say user
173:35 - must have a password
173:43 - so here we'll say const user
173:46 - equals mongoose.model
173:53 - user and then user schema
173:58 - and we'll just say module.exports equals
174:04 - user
174:06 - we've got a model let's actually set up
174:08 - the controllers now
174:09 - so we'll call this auth controller
174:17 - and let's import our user model
174:32 - and let's set up our controller for
174:33 - signing up
175:04 - and then within our try catch block
175:07 - let's uh let's do user dot create
175:12 - and we can just call in rec.body which
175:15 - should have the username and body
175:17 - and then we'll await this
175:21 - and we'll set that you to new user
175:26 - and then here we'll just do res status
175:31 - 201 json
175:40 - and we'll say status as success
175:44 - and will return the new user
175:56 - and if this fails we'll just do a res
175:57 - dot status 400
176:06 - and we'll say status fail
176:13 - so let's try this out well actually
176:15 - first of all we have to wire this route
176:17 - up
176:18 - so let's go to our routes let's create a
176:19 - new route we'll call this
176:21 - user routes
176:30 - and we'll say const express
176:33 - equals require express so that we can
176:35 - get that router object
176:38 - we'll do router equals express
176:41 - dot router
176:45 - and we'll say router.post
176:49 - and this will be for signup
176:53 - we get our auth controller so we have to
176:55 - import our auth controller
177:13 - and we'll call up the sign up method
177:19 - and then we'll export that
177:27 - and then we need to wire it up into our
177:34 - index.js
177:36 - so here we'll do const user router
178:07 - and just like we did before we're going
178:09 - to do app.use
178:10 - here let's specify the url that should
178:12 - get routed to so we'll go to
178:13 - slash api v1 slash
178:17 - uh we'll just say users and then we'll
178:20 - pass in that user
178:23 - router
178:26 - and let's save all files
178:31 - and let me just make sure that there
178:32 - aren't any errors so it looks like
178:34 - everything's good
178:35 - and let's try this out now
178:41 - i'm going to create a new request it's
178:43 - going to be a post this is one that's
178:45 - going to go to users
178:49 - slash sign up
178:53 - and then we need to pass in our body
178:57 - it's going to be json
179:01 - say user name is set to
179:04 - sanjeev
179:08 - password is set to
179:11 - password let's try this out
179:15 - and it looks like it worked it's perfect
179:17 - a couple of issues though obviously
179:19 - first of all uh you know i don't want to
179:21 - return back the entire user
179:23 - but really the bigger issue is is that
179:25 - first of all we're just storing this in
179:26 - plain text
179:28 - or password into plain text so let's fix
179:29 - that and so to do that we need to
179:32 - install a new library and that's going
179:34 - to be the bcraft library so that we can
179:36 - hash our password so i'm going to stop
179:39 - this
179:39 - for now i'm going to do an npm install
179:43 - bcrypt js
179:51 - and we got to do a docker compose down
179:53 - and then back up
179:59 - and we've got to do a rebuild as well of
180:01 - the image
180:03 - we'll do up dash d dash dash build
180:12 - all right so everything's back up and
180:13 - running so let's uh hash our password so
180:15 - if we go back up to the auth controller
180:17 - under sign up
180:22 - uh what i'm going to do is first of all
180:24 - i'm going to
180:26 - grab the username and property from the
180:28 - body
180:32 - with a little bit of destructuring
180:39 - and let's import bcrypt
180:53 - and then here we'll do const hash
180:55 - password
180:56 - equals and then we'll just do an await
180:58 - and then do bcrypt.hash
181:01 - and then here we're going to hash the
181:03 - password
181:05 - and then we have to pass in a value so
181:06 - this is going to be the strength of the
181:07 - hash we're just going to pass in a
181:09 - a value of 12 i think that's a standard
181:11 - number that people use
181:15 - and then when we do new user we have to
181:16 - change this now
181:18 - so we'll pass an object and the username
181:21 - will be set to username and then the
181:24 - password
181:26 - it's going to be set to a hash password
181:37 - let's try that out now
181:41 - so now if we sign up i'm just going to
181:43 - put a 1 here
181:48 - we can see now that it has a hash
181:50 - password so perfect
181:54 - now let's implement the login
181:56 - functionality so we're going to define a
181:58 - controller for login
182:10 - and once again we're going to
182:11 - destructure out the username and
182:14 - password
182:26 - and i realized first of all back in our
182:28 - sign up let's make sure we get this in
182:29 - our try catch block
182:31 - because this could fail as well
182:35 - and here we're going to find our try
182:37 - catch block as well actually
182:38 - i'm going to copy and paste it let's
182:40 - save us some time
182:48 - so first things first is let's delete
182:51 - this
182:52 - and what we want to do is we want to
182:54 - find uh you know we want to check our
182:56 - database to see if we have a user with
182:57 - that username
182:58 - so let's do const user equals await
183:02 - user.find1
183:05 - with a property of username
183:09 - and then we'll do an if statement to see
183:11 - if user was found
183:15 - actually we'll say if user was not found
183:18 - then we'll just send a res.status
183:21 - 400 well technically it would be a 404
183:23 - it doesn't really matter
183:25 - json and then we'll just say
183:28 - status whoops
183:32 - fail and we'll just say message
183:37 - user not found
183:40 - uh however if we did find a user
183:45 - actually we want to do a return
183:48 - uh but if we did find a user then we
183:50 - want to say we want to first of all
183:52 - check to see if the password's correct
183:54 - so when you hash a password what we have
183:56 - to do is we have the hash password
183:58 - stored in the database
183:59 - and then we have a the password that the
184:01 - user is trying to
184:03 - uh log in with so what we have to do is
184:05 - we have to hash the password the user
184:07 - tried to log in with
184:08 - and compare that hash with the hash
184:10 - that's stored in our database and if
184:12 - they equal the same
184:13 - then that means the user should be able
184:14 - to log in so we'll say
184:16 - bcrypt dot compare
184:20 - and we pass in the password that the
184:22 - user tried to log in with
184:24 - and then we pass in uh from our user
184:27 - object which it represents the entry in
184:28 - our database we'll say user
184:30 - and then grab the hash password within
184:32 - the database
184:33 - and we'll take this we'll do an await
184:35 - and then we want to store the result
184:39 - with into a variable called maybe is
184:41 - correct
184:42 - so that means his password is uh good
184:46 - and then we'll say if
184:50 - is correct
184:55 - we'll do a wreck res dot status
184:59 - 200 dot json
185:03 - and we'll say status success
185:08 - however if it's not correct
185:12 - then we'll just send a response status
185:15 - 400 again
185:16 - json and we'll say status
185:21 - fail with the message
185:26 - incorrect username or password
185:33 - and we'll remove this we don't need this
185:35 - anymore
185:42 - all right and let's save that
185:45 - and now let's go back to here so we did
185:47 - a sign up let's do a login
185:50 - and actually we have to define our
185:51 - routes so you can see here we just have
185:53 - a route for
185:55 - sign up let's copy this and let's create
185:58 - one for login as well
185:59 - it's going to be pretty much the same
186:00 - thing
186:03 - login it's also going to be a post
186:05 - method
186:06 - and then in this case there's going to
186:08 - be a login
186:11 - so we created a user with this username
186:13 - and this password so we should be able
186:15 - to just change the url to login
186:17 - and this should work so let's try this
186:19 - out and we get a status of success
186:22 - if i put in a different password
186:25 - incorrect username or password
186:26 - change it to the correct password and
186:29 - then uh change the username to
186:31 - something that doesn't exist and we can
186:33 - see user not found perfect
186:37 - all right so we've got our user we've
186:40 - got the
186:41 - user sign up and login working
186:44 - relatively speaking but the next thing
186:46 - that we want to do is we want to
186:47 - actually
186:48 - handle the authentication side of things
186:50 - so when the user logs in how do we
186:52 - actually store that state within our
186:53 - application
186:54 - and we're going to use sessions to do
186:56 - that so we'll tackle that in the next
186:57 - video
186:59 - all right so now let's actually go ahead
187:00 - and implement authentication in our
187:02 - application because right now a user can
187:04 - sign
187:04 - up and it can log in but how do we
187:06 - actually make it so that to
187:07 - you know retrieve posts maybe modify
187:09 - posts a user has to
187:11 - log in and authenticate first well we're
187:13 - going to use
187:14 - something called express session so
187:16 - there's really two different ways of
187:17 - handling authentication
187:18 - we can use sessions or we can use json
187:21 - web tokens
187:22 - i decided to use sessions because uh
187:24 - really i went through all of this
187:25 - process just to show you that
187:27 - that we can add in a redus database so
187:29 - we can use a readers database
187:31 - to store our sessions and you'll see
187:33 - that uh wiring up an express session
187:35 - to work with readers is dead simple uh
187:37 - if you actually scroll to the bottom
187:38 - it actually shows you uh all the other
187:41 - compatible session stores so if you want
187:43 - to store it
187:44 - within the database that we're
187:45 - already using you can do that if you
187:46 - want to store it within a postgres
187:47 - database
187:48 - if you want to store it in memory you
187:49 - can but what we're going to do is we're
187:51 - going to do it with
187:52 - rita so that i can show you how to
187:54 - deploy one more container
187:55 - so let's just search for redus and here
187:58 - you can see connect readers
188:00 - and this will walk you through the whole
188:01 - process of getting
188:03 - express sessions wired up with a readers
188:06 - database now what we're going to do is
188:09 - before we do that let's go ahead and
188:10 - actually get ourselves
188:12 - a reader's database so let's go to our
188:15 - images
188:18 - in our docker hub and i'm gonna search
188:20 - for reedus
188:22 - and there's the official image is gonna
188:24 - be the first result so let's add this so
188:26 - the name of the image
188:27 - is going to be redus so let's go to our
188:30 - docker compose
188:32 - dot yaml and let's wire this up
188:37 - so under
188:40 - under that service let's create a new
188:42 - one and give it any name you want but
188:44 - i think redus makes sense and then here
188:48 - we want to pass in the image and that's
188:49 - going to be read us and once again i did
188:51 - this in the shared file because both in
188:53 - our production
188:54 - and our development environment we're
188:56 - going to need a readers database
188:59 - now at this point you know right now if
189:01 - you take a look at my setup
189:02 - and i do docker ps you can see
189:04 - everything's running so uh you know
189:06 - normally you think that you would have
189:07 - to do
189:07 - a down and then
189:11 - and then an up right afterwards but
189:13 - there's a shortcut
189:14 - uh what we can do is since we made a
189:16 - change to docker compose.yaml
189:17 - we can do an up again even though
189:19 - everything's already up and running and
189:21 - docker compose is smart enough to know
189:23 - to detect any of the changes that we've
189:25 - made and spin up the necessary
189:27 - uh spin up the necessary services that
189:30 - we've defined so if we do up
189:31 - and then once again do dash d what's
189:33 - going to happen is it's going to see
189:34 - that we added that readers database
189:36 - and it's going to spin us a spin a spin
189:38 - up a reader's database
189:41 - all right and so you can see both of
189:43 - these are already up to date so it was
189:44 - able to tell that nothing's changed
189:45 - there
189:46 - but we did add the reader so it's going
189:47 - to go ahead and pull that up so you'll
189:49 - see moving forward i'm just going to do
189:51 - i'm just going to run the up command uh
189:52 - just to get make any changes
189:54 - take effect uh instead of having to do
189:56 - it down and then and
189:58 - up because that's just too long of a
189:59 - process
190:01 - all right so we've got our redish
190:02 - database uh now let's go back to here
190:05 - and let's see how we can
190:06 - wire up this connect we just express
190:08 - session so we have to do
190:09 - an npm install and then we have to
190:13 - install these three libraries so we have
190:15 - to install how
190:16 - redis because we are interacting with
190:18 - the reader's data space we do have to
190:19 - install express sessions because
190:21 - we're using the sessions functionality
190:22 - and then to wire those two up together
190:24 - we need the connect readers library
190:26 - all right so let's do a npm install
190:30 - i already forgot what libraries i need
190:32 - to copy this
190:37 - i'll install those
190:40 - and then now uh you know like i said we
190:43 - can do it down
190:44 - uh docker compose down and then do a
190:46 - docker compose up with the dash dash
190:47 - build because we did install
190:49 - new dependencies so we have to rebuild
190:51 - our node image
190:52 - however what we can do is just do an up
190:56 - dash d dash dash build
191:00 - but and that's going to you know rerun
191:02 - everything
191:03 - for us so we don't have to bring it all
191:04 - down however there's one more
191:06 - issue so if i do a dash dash help
191:10 - uh you're going to see that there's this
191:11 - renew anonymous volumes
191:13 - so when you have a a database
191:17 - sorry not a database when you have your
191:19 - containers already up and running
191:21 - and then you do another up and you want
191:23 - to rebuild the image what's going to
191:25 - happen is
191:26 - that the already running container for
191:27 - our node application is going to
191:29 - grab the old anonymous volume and the
191:32 - old anonymous volume has all of our
191:34 - old dependencies and packages that we've
191:37 - installed but we've installed some new
191:39 - dependencies like
191:40 - uh redus and so we need to force docker
191:43 - to renew a new anonymous volume so
191:46 - instead of using the old one we needed
191:47 - to create a new one
191:49 - and not use the old node modules folder
191:51 - that doesn't have redus
191:53 - or express sessions so you can just do a
191:55 - down and then an up with the dash dash
191:57 - build
191:57 - like you normally can or you can do just
192:00 - an up again
192:01 - with the dash dash build and then make
192:03 - sure you pass in the dash
192:05 - capital v to ensure that we create a
192:07 - brand new anonymous volume
192:12 - all right so we've got all of that let's
192:13 - take a look at the example you'll see
192:14 - it's pretty easy
192:16 - um we have to uh import radius
192:20 - uh sorry not radius redus express
192:22 - sessions we have to create a redis store
192:24 - and so you just it's literally just copy
192:26 - and paste up to here
192:27 - uh and then here under readers under our
192:30 - create client method we have to specify
192:32 - how to access our readers database
192:35 - and then we just pass in this specific
192:37 - middleware that we create
192:39 - so let's get to it so let's go back here
192:42 - and let's go to our index.js
192:45 - and we're going to import sessions first
192:47 - so we'll do a const session
192:49 - equals fire
192:52 - express that session
192:56 - then we need to import redus
193:04 - and then we have to define our vita
193:05 - store so we'll do uh let in this case
193:08 - so do let beat us store
193:12 - equals require
193:15 - and then we need connect dash redus
193:19 - and then we pass in session
193:25 - and then let's define our reader's
193:26 - client so we'll do let
193:28 - fetus client equals require
193:37 - sorry not require we want read us dot
193:41 - create client and then here we have to
193:43 - pass in two things we have to pass in
193:46 - uh the uh the url the host url as well
193:50 - as the port that the
193:51 - redis server is going to be listening on
193:53 - all right so let's um
193:55 - let's go to our config.js and let's
193:57 - define that here as an environment
193:58 - variable so we'll say
194:00 - uh redus underscore url when i say url
194:03 - this is just going to be the i p
194:04 - address so i'll just say process dot env
194:07 - dot redus underscore url
194:11 - and then if that's not set to anything
194:14 - we're going to default to
194:17 - redis right remember we have the dns uh
194:20 - at our disposal so uh you know anytime
194:23 - any one of our containers wants to talk
194:25 - to our readers database
194:26 - and it needs to know the ip address we
194:28 - can just reference redus
194:30 - so if i go back to config.js i'm just
194:32 - going to default to read us i'm
194:33 - you know in production and in
194:36 - development i'm never actually going to
194:37 - pass this url in
194:38 - it's just there so that in the future if
194:40 - i do decide to have a reader's database
194:43 - that's not a docker container and that i
194:45 - can't actually resolve
194:46 - using redus then i can just pass it as
194:49 - an environment variable and then i can
194:50 - connect to like maybe a managed
194:52 - avetis server
194:56 - so back here we'll pass in host
194:59 - as bdis underscore url
195:03 - and then we also have to pass in the
195:04 - port so what is we're going to use the
195:06 - default port for everything but let's
195:07 - define a
195:08 - environment variable for that so we'll
195:11 - call this redus
195:11 - underscore port and this is going to be
195:15 - set to process.env.redis
195:17 - underscore port
195:24 - and we're going to define we're going to
195:26 - default to whatever the default port is
195:28 - for redus which is 6379
195:33 - all right and then right down here
195:34 - before our first middleware here
195:37 - i'm going to define a brand new
195:38 - middleware for our
195:40 - sessions so here we'll then pass in
195:42 - session
195:45 - and then we have to pass in an object so
195:46 - the first thing that we do is we have to
195:47 - pass in our store
195:49 - so here we'll call it new reader store
195:58 - and then we have to pass in our client
196:00 - that we created so it's going to be
196:01 - client
196:02 - and then we're going to reference our
196:03 - readers client right here
196:11 - all right then the next thing that we
196:12 - have to pass in is a secret so this is
196:14 - just
196:15 - a random secret that we store on our
196:17 - express server
196:18 - uh that we use uh when we are handling
196:21 - the sessions
196:22 - so this can be any string so what i'm
196:24 - gonna do is i'm gonna create an
196:25 - environment variable for that as well
196:27 - so we'll go to back to our config
196:31 - and i'm going to create one and i'm
196:32 - going to call this a session
196:35 - underscore secret and we're going to
196:37 - grab this from process dot env
196:41 - session secret
196:48 - and so this is going to be session
196:51 - secret make sure you
196:52 - import that and then we have to pass in
196:56 - some properties for our cookie
196:58 - that we send back to the user
197:01 - and so if you want to take a look at the
197:02 - properties that we're going to pass in
197:04 - go to the original express
197:07 - session page and then here under the
197:09 - options
197:10 - for cookie you'll see the different
197:12 - options that we have so we've got uh
197:14 - expires so actually we don't even want
197:17 - that we want max age
197:18 - so i think it's somewhere here
197:21 - anyways i'm just going to pass in a
197:23 - couple of the ones that i'm going to use
197:24 - and then you know if you guys want to
197:26 - read up on that feel free to
197:27 - but it's not really that important from
197:29 - a docker perspective
197:32 - so we're going to do secure i'm going to
197:34 - just set that to false
197:36 - just to simplify our application resave
197:39 - set to false save initialized
197:56 - http only is going to be set to true
198:00 - and then max age this is going to be set
198:02 - to
198:03 - uh so this is set in milliseconds so i
198:05 - just want this cookie to last 30 seconds
198:07 - it's gonna be a little bit
198:08 - i want it to be that short just because
198:10 - it's easier to demonstrate how
198:12 - these cookies work i'm gonna do 30 000
198:15 - seconds sorry 30 000 milliseconds which
198:18 - equates to 30 seconds
198:22 - and i know http only this is just used
198:25 - for scenarios where
198:26 - uh your your javascript on the browser
198:29 - will not be able to access it so http
198:31 - only means that javascript can't access
198:33 - it
198:35 - all right so we've defined a couple of
198:36 - new environment variables so let's go
198:38 - back to
198:38 - our um docker.com docker compose file
198:43 - and uh well first of all let's go to dev
198:45 - anyways
198:46 - uh so this is going to be the
198:50 - the environment variables for our
198:51 - development environment so let's go down
198:52 - to redus
198:55 - and let's set our environment variables
199:02 - and once again i made a mistake these
199:04 - aren't set for the redis server this is
199:06 - going to be set for our node app
199:08 - and the only thing we need to pass in is
199:10 - our session secret so we'll do session
199:13 - underscore secret and then just pass in
199:16 - some string so i'm just going to call
199:17 - this
199:18 - secret why not it's just an arbitrary
199:21 - arbitrary string just think of it as
199:22 - like a password for your for your
199:24 - sessions
199:26 - and so now let's do a docker compose up
199:29 - however if we just do a docker compose
199:31 - up
199:32 - you'll see that nothing happens because
199:35 - well actually something did happen this
199:37 - is actually perfect so
199:38 - it recreated the container just because
199:40 - we changed a few things
199:41 - uh we changed our environment variable
199:43 - cell it was able to start that and let's
199:46 - do a docker
199:48 - ps we'll do a docker logs and then
199:51 - where's our node app right here
199:55 - and then we'll just do dash f
199:58 - and it looks like
200:02 - i forgot to import reader's url so if i
200:04 - go under index.js
200:07 - you know this was never imported well it
200:10 - actually is imported i just imported it
200:12 - down here so
200:13 - we just have to cut that out and then
200:15 - move it below this line
200:22 - and then on port 18
200:27 - i never actually imported so this is
200:29 - going to be set to
200:33 - port and let's import
200:37 - actually is that defined here we need to
200:39 - make sure yep we didn't we never oh it's
200:41 - regis underscore
200:42 - port okay
200:46 - import that so make sure you import it
200:48 - there and i think this should fix our
200:50 - issues
200:51 - uh looks like things are good so far so
200:54 - let's
200:56 - uh well actually technically nothing's
200:58 - done yet but
201:00 - all right so we've got our sessions
201:01 - wired up the next thing that we have to
201:03 - do is we have to
201:05 - create a session whenever a user logs in
201:08 - all right so now that we've got our
201:10 - sessions wired up let's try to
201:12 - log in again and see if anything's
201:14 - changed so i'm going to do a post
201:16 - request to our login route
201:18 - and i'm going to pass in the credentials
201:20 - to a user that's already been created
201:22 - and then we'll hit send we get a status
201:24 - success
201:25 - and you'll notice that under this
201:27 - cookies tab there's a one so this
201:29 - implies that we received a cookie
201:30 - with the value of one and so this is
201:32 - what our cookie looks like
201:34 - uh you'll see the domain is set to
201:35 - localhost because that's what our server
201:36 - is running on
201:37 - and then you'll see our expires section
201:38 - which is going to expire in 30 seconds
201:41 - and then some of the other properties
201:42 - like http only set to true
201:44 - and then secure secures um basically if
201:47 - you have set secure to true
201:48 - that means it will only work with https
201:51 - um
201:51 - i'm not going to go over how to set up
201:53 - ssl and https and all of that
201:55 - for this video but uh you know in a
201:57 - production environment you definitely
201:58 - want this set to true and then usually
202:00 - in development you just leave it set to
202:01 - false
202:04 - so let's log in what i want to do is i
202:06 - want to actually log in
202:07 - to our redis database and just show you
202:10 - what that looks like what that session
202:11 - looks like
202:12 - within the database so i'm going to uh
202:15 - we'll
202:16 - control c out of this
202:19 - and then let's just do a docker
202:22 - exec well first of all let's do a docker
202:24 - ps let's get the name of that container
202:27 - so
202:27 - read us and we'll do a docker exec
202:31 - it and we'll drop into bash
202:38 - and from here we can just type in redus
202:42 - or radius cli and so that's going to
202:45 - drop us into the
202:46 - into our regis database however once
202:48 - again just like we did with manga we can
202:50 - kind of shorten that and just do
202:52 - redus cli and so
202:55 - now we're in redus and to see all of the
202:57 - entries within our
202:58 - our readers database all we have to do
203:00 - is just type in keys and then star
203:03 - and you'll see that it returned an empty
203:05 - array and you might be wondering why
203:06 - they return an empty array we have a
203:08 - session
203:09 - well if you recall where i set
203:12 - some properties on my cookies and my
203:14 - sessions is that the
203:16 - that this is only going to last 30
203:18 - seconds so the session dies after 30
203:20 - seconds so what i'm going to do is
203:21 - i'm going to re-login this should create
203:25 - a new session
203:26 - and then now let's quickly run the same
203:28 - command and you can see we have a
203:29 - session right there and if you want to
203:31 - see the details for a session
203:32 - you can type in get and then the key for
203:34 - that so here we just copy that
203:38 - and i forgot the other
203:41 - quotes and there you go so this is the
203:43 - details of that session
203:44 - it's got some information about the
203:45 - cookie and a few other things
203:48 - but with this session we can add any
203:50 - information that we want into this
203:52 - session so
203:53 - what we ideally want to do is when the
203:55 - user logs in we want to store the user
203:57 - information
203:58 - within this session and so if that user
204:00 - information is
204:01 - in that session then we know he's logged
204:03 - in if it's not that means he's not
204:05 - logged in
204:05 - and the nice part about doing this is
204:07 - that we can store any information we
204:09 - want in the session
204:10 - even you know information that's
204:14 - uh should be private to the user because
204:16 - the user never gets to see the session
204:18 - this session resides in our readers
204:20 - database
204:20 - it never gets sent out to the web
204:22 - browser the user is trying to
204:24 - connect from so to do this let's go to
204:28 - our auth controller
204:30 - and it's very simple so let's go under
204:31 - our login section
204:33 - and right before we actually implement
204:35 - the logic for logging in
204:38 - so right under is correct what we can do
204:41 - is
204:42 - we can say rec dot session so this is
204:45 - how you
204:46 - um access this session object it's going
204:48 - to be attached to the
204:49 - request object and we can add in a new
204:51 - property called user
204:53 - we can create any property we want and
204:55 - we'll just set that to
204:58 - uh let's see where is the user we'll set
205:01 - it to user
205:02 - and so that's going to take the user
205:04 - object that we found from our database
205:06 - and only if our password our login is
205:10 - correct
205:11 - will we then log or we will assign this
205:13 - user object
205:14 - to our session so let's save this
205:19 - should restart our app and let's log in
205:22 - again
205:23 - and now i'm going to do keys star
205:28 - we have our session object and then i'm
205:30 - going to do
205:32 - a get
205:38 - and now take a look at this so here
205:40 - starting at this section right here this
205:42 - is our user object we've got the mongodb
205:44 - id that assigned it we've got the
205:46 - username and the password so this is how
205:48 - we tell
205:49 - that a user is logged in
205:53 - and then after 30 seconds you'll see
205:56 - that it goes away
205:59 - and so if we do a keys star it's gone
206:02 - now so now that you have an idea of how
206:04 - the sessions work let's go back into our
206:05 - index.js
206:06 - and just change this value because
206:08 - obviously 30 seconds is way too short
206:10 - uh we can change so i mean just add
206:12 - whatever you want i just added a couple
206:14 - of zeros
206:15 - however long you want a user to be
206:17 - logged in this is the value you set in
206:18 - there remember we use milliseconds of
206:20 - course
206:24 - and uh before we move on a couple other
206:26 - things so after a user
206:28 - signs up we also want to do the same
206:31 - thing so after he signs up we want to
206:32 - make sure that we log him in
206:34 - by doing rec.sessions.user
206:37 - and set that equal to new user
206:45 - and let's test that up so i'm going to
206:46 - go to sign in or sign up
206:49 - and we'll just do sanjeev five
206:54 - all right that worked we got a cookie
206:56 - let's do that and
207:00 - let's get the details for that session
207:04 - and we can see it did not work
207:08 - because i do not see any information
207:11 - about my user so let's take a look and
207:12 - see what
207:13 - we might have broke and i already see
207:16 - what i broke so it shouldn't be sessions
207:18 - it should be session
207:21 - and so let's sign up with a six this
207:24 - time
207:25 - we have a new user
207:34 - and so there we go so now we can see
207:36 - username sanjeev6
207:38 - so now whether we log in or sign up it's
207:40 - going to assign the user
207:43 - uh to our session and so now we can
207:45 - access that user whenever we want to
207:47 - access posts
207:50 - so now that we have our sessions
207:51 - tracking where their users logged in
207:53 - let's set up the logic to make sure that
207:55 - for a user to either create or delete or
207:58 - update a post
207:58 - or even get post depending on how your
208:00 - application works they have to be logged
208:02 - in
208:03 - and the way we can accomplish that is by
208:05 - using express middleware
208:06 - and a middleware is nothing more than a
208:08 - function that runs before your
208:10 - controller
208:11 - this function is going to have a little
208:12 - bit of logic and all it's going to do is
208:14 - it's going to check
208:15 - that sessions object to see if there's a
208:18 - user property attached to it
208:19 - and if there is a user property to it
208:21 - attached to it then
208:22 - it will then forward the request onto
208:25 - the controller so the controller can
208:26 - handle that logic
208:27 - however if there is no user object
208:29 - attached to it then it's going to return
208:31 - an error saying
208:32 - you know you're unauthorized to access
208:34 - that you must log in
208:36 - so let's create a new folder for our
208:38 - middleware
208:41 - and i'm going to just create a file
208:42 - called auth middleware
208:47 - and here we're going to create our
208:48 - middleware i'm going to call this
208:50 - protect
208:50 - because it's going to protect a route
208:52 - and ensure that the user is logged in to
208:54 - actually access that endpoint
208:56 - and with the middleware you get the same
208:58 - thing as any other controller you get a
209:00 - request response and then you also get
209:01 - the
209:01 - next object
209:05 - and so here what we're going to do is
209:06 - we're going to destructure out user
209:10 - from our session and we're going to say
209:13 - if
209:15 - user does not exist which means you know
209:17 - the user is not logged in because if
209:18 - there's no user attached to the session
209:20 - object
209:21 - then we know the user is not logged in
209:23 - we're just going to return a response
209:25 - that says
209:27 - first of all going to set the status to
209:28 - 41 and then we'll do json
209:31 - and then here we'll say status fail
209:35 - and then what we're going to do is we're
209:36 - going to send a message that's going to
209:39 - say unauthorized
209:46 - however if the user is logged in then
209:47 - we're just going to say next so when you
209:49 - call the next
209:51 - uh function then or the next method it's
209:53 - going to then just send it to the
209:54 - controller or the next middleware in the
209:56 - stack
209:57 - and one optional thing that you can do
210:00 - and what i like to do is instead of
210:02 - having all of the rest of our
210:03 - uh routes get the user off of
210:06 - rec.session.user
210:08 - i'd rather have it attached directly to
210:09 - the rec object
210:11 - so i'm going to say rec.user
210:14 - equals user so now if we ever want to
210:17 - get the information regarding the user
210:18 - we can just do rec.user instead of
210:20 - having to go to rec.sessions.user
210:25 - uh then we want to make sure we export
210:28 - this
210:30 - all right and so now under our post
210:32 - routes which is the routes that we want
210:33 - to protect let's
210:35 - import our protect middleware
210:47 - and to protect a specific route or
210:49 - endpoint let's grab the post
210:51 - method right here so this is going to be
210:53 - when a user wants to create a new post
210:55 - and all we have to do is just pass in
210:57 - protect here so what's going to happen
210:59 - is when a user hits this endpoint
211:01 - we're going to run our middleware
211:02 - function and our middleware function is
211:03 - going to verify if the user is logged in
211:05 - if he is logged in then we just call
211:07 - that next method
211:08 - which then goes straight to
211:10 - postcontroller.createpost and then
211:11 - and then all the logic for that gets run
211:13 - however if he's not logged in
211:15 - well our middleware is set to respond
211:17 - and send a response back
211:19 - and we call a return which means we
211:20 - don't go through the rest of the
211:22 - middleware or the
211:22 - or the controller at the end we just
211:25 - kill the signal and we send a response
211:26 - back
211:28 - so that's how authentication works uh
211:30 - and so the last thing i want to do is
211:31 - for index.js first of all i'm going to
211:34 - change this back to 30 seconds
211:37 - you can pick 60 seconds too actually
211:39 - let's do
211:40 - let's just do 60 seconds and let's save
211:44 - everything
211:46 - all right and what i want to do is first
211:48 - of all
211:50 - i'm going to log in let's delete all of
211:52 - our previous cookies just to make sure
211:53 - we don't have some kind of weird stale
211:54 - state
211:56 - and then let's log in so we'll log in
211:59 - and you'll see that this is set to
212:01 - expire in one minute that's in gmt i'm
212:03 - in est so it's gonna expire in one
212:05 - minute
212:05 - but we're logged in so let's actually
212:07 - create a new post
212:09 - and let's hit send and it looks like we
212:11 - are successfully able to create a post
212:14 - however if we wait one minute for our
212:16 - session to end
212:18 - let's then try to see if we can create a
212:20 - post and ideally we
212:22 - should not be able to so i'll see you
212:24 - guys back in one minute
212:26 - all right so it's been about a minute
212:27 - now let's test to see if we can still
212:29 - create a post
212:31 - so if i hit send again we should see
212:34 - that it failed and it says we're
212:35 - unauthorized
212:36 - and that's because our session ended and
212:38 - basically once your session ends you're
212:39 - essentially logged out
212:41 - so if we log back in it's going to
212:43 - create a new session we're going to be
212:44 - logged in for one minute
212:46 - we can then create another post
212:49 - all right so we've got our
212:50 - authentication set up we can just decide
212:53 - on what routes we want to protect
212:55 - so you can use the same middleware uh
212:56 - across your entire application so
212:59 - for uh deleting or updating we can add
213:01 - in protect as well
213:07 - actually let's just add let's just add
213:09 - it in for everything so even retrieving
213:11 - post you have to be logged in
213:21 - and you know for a real world
213:23 - application you ideally want to
213:25 - bump this up to something significantly
213:28 - higher
213:28 - um you know maybe a couple of hours or
213:30 - something like that or even a couple
213:32 - days
213:33 - i'm going to keep this actually at 30
213:34 - seconds just you know for testing
213:36 - purposes so as we keep going with our
213:38 - application i want to make sure that
213:39 - authentication doesn't break for
213:41 - whatever reason
213:45 - and so from a express point of view
213:47 - we're kind of done building an
213:48 - application i know it's not like a
213:49 - full-fledged application it was never
213:51 - meant to be
213:51 - i just wanted to have enough of an
213:54 - application so that i can show you from
213:55 - a docker perspective how everything
213:57 - works
213:58 - so uh this is all we're going to do i
214:00 - know we don't have like a
214:02 - logic to assign you know post to a
214:04 - specific user
214:05 - right now any user can create a post
214:07 - edit any post and so it's just one big
214:09 - global
214:10 - list of posts but you know remember the
214:13 - idea of this
214:14 - this tutorial series is not about the
214:16 - express application it's about docker so
214:18 - we finished the express application side
214:20 - of things we're going to get back to the
214:22 - docker side of things uh in the next
214:24 - video so we still got a ton of things to
214:26 - learn
214:27 - and we're also going to eventually move
214:29 - on to getting all of this deployed to a
214:31 - production setup and then show you guys
214:33 - some of the challenges we face when
214:34 - moving to a production environment
214:38 - all right guys so before we proceed any
214:40 - further i want to do a quick review of
214:42 - the
214:43 - architecture of our current application
214:45 - and then i want to show you guys what i
214:47 - ultimately want it to look like
214:48 - once it's done so here i've got a little
214:50 - diagram we've got our
214:52 - in the blue so this big blue box this
214:54 - represents our host machine so in this
214:56 - case this is my windows machine
214:58 - and so here we've got our express
215:00 - application
215:01 - that's listening on port 3000 and then
215:03 - we've got our database which our
215:04 - express application
215:06 - can talk to on port 27017 and if we need
215:09 - to actually send a request to our
215:11 - express application then we just send a
215:13 - a request to port 3000 to our local
215:15 - machine it'll then get mapped to port
215:17 - 3000 of our
215:18 - express application and so that's the
215:20 - current architecture
215:22 - and you know one of the things i wanted
215:23 - to point out especially when we started
215:24 - to add the database into our
215:26 - application is that
215:28 - we never opened up a port for our
215:31 - database
215:32 - right so just like we opened up port
215:33 - 3000 for our express server so that the
215:35 - outside world can talk to it
215:37 - we never did that for our database
215:39 - and i actually did that on purpose
215:41 - because
215:41 - you know we definitely could open up a
215:43 - port so that we can talk directly to the
215:45 -  database
215:46 - so we could open up you know port 27017
215:48 - on our local machine
215:49 - or really any port really and then map
215:51 - it to port 27017
215:53 - uh to our container and that would
215:56 - be perfectly fine
215:57 - uh if you needed to talk to their manga
215:59 - database however
216:00 - i want you to think about what that
216:02 - would ultimately mean because
216:04 - now we're letting the outside world talk
216:06 - to our database
216:08 - right the only thing that actually needs
216:09 - to talk to our database is our
216:11 - express application
216:12 - so there isn't really a need to open up
216:14 - that port and it's also a little bit of
216:16 - a
216:17 - security vulnerability because your
216:19 - database holds all of your critical
216:20 - application data
216:21 - it's got all of your user information
216:23 - it's got all of their emails it could
216:24 - have potentially other sensitive
216:25 - information like social security number
216:28 - passwords and other things like that so
216:30 - generally it's best
216:32 - not to make the container
216:34 - accessible to the outside world
216:35 - and i love how docker by default you
216:38 - know if we don't open up any ports
216:40 - it already isolates the container
216:42 - so the outside world can't talk to it so
216:44 - you can see that
216:44 - just by running with docker we've
216:46 - already added a little bit of security
216:48 - to our application because
216:49 - only our express application and our
216:51 - containers
216:52 - within that container within that
216:54 - network that docker compose makes
216:56 - can talk to that database no one
216:58 - else can so
216:59 - once again just to reiterate we aren't
217:01 - going to open up any ports
217:03 - to our database uh you know just
217:05 - like in our docker compose file right
217:07 - here
217:08 - you can see we open up the ports for our
217:09 - node app but there's no ports opened up
217:11 - for so we're not going to open up
217:12 - any ports
217:13 - we're going to make it so that only our
217:15 - application our express app our express
217:17 - container
217:18 - can talk to our database
217:21 - and so like i said you know we're not
217:23 - going to publish a specific port for our
217:25 -  database
217:27 - just for security purposes and there's
217:29 - really no reason to so
217:30 - we're going to actually remove that and
217:33 - so now what i want to talk about is
217:34 - scaling up
217:35 - our node containers so you know we
217:37 - talked about passing in that scale flag
217:39 - so that we can increase the number of
217:41 - node containers that we have
217:43 - so that we can handle an increased load
217:45 - in traffic
217:47 - so what we did was we would spin up
217:49 - another node express container
217:51 - which would then connect to our
217:53 - database using the same exact port
217:55 - and to be able to talk to this container
217:56 - what we would have to do is publish a
217:58 - different port
217:59 - so the first node container you can see
218:01 - that if we send a request to port 3000
218:04 - it would get to map to port 3000 of the
218:06 - first container
218:07 - and then we'd have to grab a different
218:09 - port on our local machine
218:10 - like 3001 and so any traffic that gets
218:13 - sent to
218:13 - our local host on port 3001 we get
218:15 - mapped 2.3 000
218:17 - on our second node container and if we
218:19 - wanted a third one we'd have to open up
218:21 - another port like 3002 and so on so if
218:23 - we had 50 containers
218:25 - 50 node apps we would need to open up 50
218:28 - different ports
218:29 - and you know like i said that's not a
218:30 - scalable solution
218:32 - you know our front end shouldn't have to
218:33 - be aware of the number of
218:35 - node containers that we're running on
218:37 - our back end so
218:38 - what we're going to ultimately do is
218:40 - we're going to add
218:42 - a load balancer so there's a couple of
218:44 - different options that we have
218:45 - uh you have things like hi proxy you've
218:47 - got traffic and then you got nginx so
218:49 - i'm going to walk you through how we can
218:50 - do this with nginx and you'll see it's
218:52 - really simple
218:53 - and it's a good skill set to have
218:54 - because you'll use nginx in other
218:56 - scenarios outside of docker as well
218:58 - it's a great web server as well so
219:00 - ultimately
219:01 - what our final architecture is going to
219:03 - look like
219:05 - is we're going to have a nginx container
219:08 - and this nginx container is going to be
219:10 - the entrance into our application so
219:12 - we're no longer going to publish any
219:14 - ports on our two node instances
219:16 - so we're no longer going to open up port
219:18 - 3000.3001 on our local machine
219:21 - instead we're going to publish one port
219:23 - for our nginx container
219:25 - and that port can be anything so we can
219:26 - continue to use 3000 like we have
219:29 - or we can pick any other port and you'll
219:31 - see that you know when we get to
219:32 - production we're just going to use port
219:33 - 80 because that's the default port for
219:35 - http
219:36 - as well as port 443 which is the port
219:38 - for https
219:40 - so we'll open up you know the port of
219:42 - our choice on our local machine and
219:43 - we're going to map it to port 80.
219:46 - reason we map it to port 80 is because
219:48 - that's the default port that nginx
219:49 - listens on
219:50 - technically that's fully customizable so
219:52 - we can tell nginx
219:53 - to listen on a different port but
219:55 - there's no need for the extra
219:56 - configuration i'd rather just leave it
219:58 - to the default port so you know 3000
220:00 - port 3000
220:01 - gonna get mapped to port 80. and then
220:04 - what our engine
220:05 - is going to do is it's going to act as a
220:06 - load balancer so every request that it
220:08 - receives it's going to load balance it
220:10 - to our two express instances and if we
220:13 - have
220:14 - four five one or a thousand instances
220:17 - nginx will be able to
220:19 - load balance all of those requests
220:20 - across all of our
220:22 - node instances and so this is a much
220:25 - cleaner elegant solution because first
220:27 - of all we only have to publish one port
220:29 - and then nginx which is you know highly
220:32 - efficient
220:32 - is going to be able to ensure that all
220:34 - of our node instances
220:35 - are adequately um balanced with regards
220:39 - to the number of requests that they
220:40 - receive
220:42 - all right and so that's all i wanted to
220:43 - cover in this section so uh in the next
220:45 - video we'll get started on adding that
220:47 - nginx container
220:50 - if you search for nginx on docker hub
220:52 - you'll see the official nginx image as
220:53 - the first result so this is the one that
220:55 - we're going to use
220:56 - and so let's get started on configuring
220:58 - this first thing that we need to do is
221:00 - i'm going to create a separate folder
221:02 - for our nginx configuration i'm going to
221:04 - call this nginx
221:06 - and we're going to create one file and
221:07 - that's going to be the default.com file
221:09 - so this is just going to be a basic
221:11 - configuration
221:12 - for our nginx server
221:17 - and within here we have to define a
221:19 - server block and so this is all just
221:21 - nginx specific configs nothing related
221:23 - to docker
221:24 - and here we'll just say our nginx server
221:25 - is going to listen on port 80.
221:29 - and then now this is where we actually
221:31 - set it up to redirect
221:33 - traffic to our express
221:36 - or our node containers so we say
221:38 - location
221:40 - and then we provide a a url so this is
221:43 - going to be the url of the request this
221:45 - nginx server receives
221:46 - uh and so here we could just do a slash
221:49 - and then put in all of our configs
221:51 - and then here we can say the most
221:53 - important one is proxy
221:55 - underscore pass and then here for the
221:58 - proxy pass field we specify the url
222:01 - of the servers that we want to uh you
222:04 - know
222:04 - proxy this traffic to so we want to send
222:07 - this traffic to our
222:08 - express application or our node
222:10 - containers so
222:11 - because our nginx server is also
222:14 - a docker container that's going to be
222:16 - running it has access to dns
222:18 - so what we can do is we can type in http
222:21 - colon
222:22 - slash and then we can say node dash app
222:24 - because remember
222:25 - we have that uh custom network that was
222:28 - created by docker compose
222:30 - and so within our docker compose file we
222:31 - can refer to any one of these services
222:34 - by their name so if i call node app it's
222:36 - going to load balance
222:37 - between all of the node app containers
222:39 - that we have
222:43 - and then we have to make sure that we
222:45 - send it on port 3000 because that's what
222:46 - our express servers are listening on
222:49 - now there's a couple of other properties
222:50 - that we need to set
222:52 - now because nginx is acting as a proxy
222:55 - when we actually
222:56 - proxy the original request to our
222:58 - express application
222:59 - the nginx server is going to strip off a
223:01 - few details and
223:02 - these details may actually be important
223:04 - depending on what your application is
223:05 - doing
223:06 - and one of the things that nginx does is
223:08 - uh you'll lose the
223:10 - original ip address of the sender so
223:13 - you know what was the ip address that
223:15 - originated that request so we can tell
223:17 - nginx to make sure that we forward that
223:19 - along to our node applications now our
223:21 - node application isn't actually making
223:23 - use of that
223:23 - but uh if you're doing any kind of like
223:25 - rate limiting per ip address
223:27 - these are all things that you want to
223:28 - need so it's always a best practice to
223:30 - configure this
223:31 - and so to ensure that we pass on
223:34 - the original sender's ip we do proxy
223:37 - underscore set
223:38 - underscore header and we do x
223:42 - dash real ip
223:46 - and then we do dollar remote
223:49 - underscore addr all right and then
223:52 - another thing that we want to do
223:53 - is uh we're going to pass in another uh
223:55 - another setting or flag
223:57 - that's going to provide us a list
223:59 - containing the ip addresses that every
224:01 - server
224:02 - the client has been proxied through so
224:04 - this is another thing that's just best
224:05 - practice
224:06 - i i definitely recommend you read up on
224:08 - nginx there's a lot of things that you
224:09 - can do and configure
224:11 - but i'm just trying to get you guys up
224:12 - and running with the base configuration
224:17 - and so i'm just going to copy this it's
224:18 - a little bit of a long line
224:21 - all right and so that's going to make
224:22 - sure all of those um proxy server ips
224:25 - are attached to the headers
224:27 - and then we're going to add in just a
224:28 - few other fields so we'll do proxy
224:30 - underscore set underscore header
224:33 - host and dollar sign http
224:37 - underscore host
224:40 - and then we're going to copy this again
225:12 - and so that's all the configurations we
225:14 - need however there's one minor tweak
225:16 - that i want to do in this case
225:18 - um basically all requests are going to
225:19 - get forward to our node app
225:21 - now you know for what we're doing we're
225:23 - just building a back end however if you
225:25 - wanted this nginx server to also handle
225:27 - serving your front-end assets what you
225:30 - would ultimately want to do
225:31 - is in your api and we've already kind of
225:33 - set this up is that
225:35 - for all of your routes you want to make
225:36 - sure that they are listening on
225:38 - api v1
225:42 - something so that way we know that the
225:44 - nginx server can actually specify that
225:46 - any request that starts with api is
225:47 - meant for our backend
225:49 - and then any request that's meant for a
225:50 - url that does not have the api
225:52 - um that's meant for our front end so
225:54 - since all of these requests are
225:55 - listening for
225:56 - uh api first well except for this one
225:58 - but we can add that real quick
226:03 - uh what we can do is we can go back to
226:04 - that configuration file and we can say
226:06 - slash
226:07 - api so in this case uh whatever
226:10 - is uh whatever url is passed for
226:12 - location this is going to specify
226:14 - uh what the
226:17 - request needs to look like for us to
226:19 - forward it to our node application so
226:21 - any request that comes in starting with
226:23 - slash api we'll send it to our node app
226:25 - and then anything that doesn't have
226:26 - slash api right now it's just going to
226:28 - drop
226:28 - but in the future we could configure it
226:30 - so that it can handle
226:32 - um you know redirect that traffic to our
226:34 - nginx
226:35 - sorry not our engine but like a react
226:37 - application or whatever our front end
226:39 - application is
226:40 - right now let's go ahead and go to our
226:42 - docker compose file and let's
226:44 - add our nginx service we can do nginx
226:52 - and then the image uh this is going to
226:54 - be nginx and then we can
226:58 - let me put a space nginx and then i'm
227:01 - going to grab the stable
227:02 - alpine version
227:06 - all right and so now um first of all we
227:09 - no longer have to
227:10 - publish ports for our node application
227:12 - so we can remove that
227:14 - actually and let's actually go into our
227:18 - devonprod make sure we've removed any of
227:19 - the ports being opened
227:20 - there as well and doesn't look like we
227:22 - have anything and prod looks okay
227:24 - and so let's go back to our docker
227:26 - compose
227:28 - and then here let's open up our port so
227:30 - we'll say ports
227:33 - and then let's pick the port that we
227:34 - want to publish so pick anything we can
227:36 - do 3000 still if we want
227:39 - and then we just want to make sure we
227:40 - map it to port 80 because that's the
227:42 - port that our nginx server is listening
227:44 - on
227:47 - and for production actually let's um i'm
227:49 - going to copy this
227:52 - for production it's going to be a
227:54 - different port so instead of opening up
227:56 - port 3000 we're going to open up
227:57 - port 80. and we can remove that image
228:01 - because we're not changing anything
228:08 - and actually why even have this here i
228:11 - can just copy this
228:12 - and put this in the dev section
228:24 - all right now the next thing that we
228:25 - have to do is we have to get our
228:26 - configuration file
228:28 - that we built out into our nginx
228:30 - container so there's a couple of
228:31 - different ways we can do this
228:32 - we can create our own custom nginx image
228:35 - that already has our configuration built
228:37 - in
228:37 - or we can just configure a volume
228:39 - specifically a bind mount and just have
228:41 - it sync those
228:42 - two files uh and so that'll i think
228:44 - that's the route we're gonna go we're
228:45 - just going to configure a bind mount
228:46 - then we don't have to worry about
228:47 - building a custom image and doing all of
228:49 - that nonsense
228:56 - so under volumes
228:59 - uh so you have to understand a little
229:01 - bit about where
229:02 - uh nginx looks for this config so nginx
229:04 - is going to look for this in the slash
229:06 - etsy slash nginx slash conf
229:09 - dot d slash default dot com file so
229:13 - that's where it expects the
229:14 - configuration
229:15 - and we're going to sync that with uh
229:19 - nginx default.com so we'll just go dot
229:21 - slash
229:22 - nginx slash default.conf
229:26 - and then uh on the nginx container side
229:29 - we're gonna make this
229:30 - read-only it does it should never have
229:32 - to change the configuration so a little
229:33 - bit of a security check
229:38 - and let's tear everything down
229:43 - and let's build it back up we're just
229:45 - going to do one instance just for now
229:47 - let's just make sure everything's
229:50 - working
229:56 - and let's try sending a request so we're
229:58 - going to try to log in again
230:02 - and let's let's go to the body here
230:06 - and it looks like we broke our
230:07 - application
230:11 - so let's take a look and see what
230:13 - exactly we broke
230:14 - alright guys so i made a stupid mistake
230:16 - i just forgot to update this to port
230:18 - 3000
230:19 - so i had left it at 3001 so make sure we
230:22 - change that to 3000 because that's what
230:23 - our engine x server is listening on so
230:25 - now if i log
230:25 - in we can see that it's successful and
230:28 - we did receive the cookie
230:30 - all right so it looks like we got our
230:31 - application up into a working state
230:33 - using nginx as a proxy so that i can
230:35 - load balance requests to all of our
230:37 - node instances but there's a couple more
230:40 - things that we got to do so
230:41 - so what i'm going to do is i'm going to
230:43 - pull up this web page right here so i
230:45 - just want you to search for express and
230:47 - then proxy and it'll be the first result
230:49 - you get and it just explains that we do
230:51 - have to add one extra configuration into
230:53 - our express application
230:55 - when whenever our express application is
230:57 - sitting behind a proxy
230:58 - and this isn't technically required for
231:01 - our example
231:02 - for our demonstration project but in a
231:04 - production grade project you probably
231:06 - will need to add this
231:07 - um the configuration right here is this
231:09 - app.set trust proxy
231:11 - and so all this is saying is that we're
231:13 - going to trust
231:14 - some of the headers that our nginx proxy
231:17 - is going to be adding onto the request
231:19 - and so remember we configure our nginx
231:21 - server to uh basically add the
231:22 - originating
231:24 - uh sender's ip address into the headers
231:26 - so that if our express application does
231:28 - need it
231:28 - it has access to it all all we're doing
231:30 - here is we're just
231:31 - telling express to trust whatever our
231:33 - nginx server is adding onto those
231:35 - headers
231:37 - uh so all we have to do is we have one
231:38 - simple configuration so uh if we go to
231:41 - our middleware we have our session
231:42 - middleware so right above this
231:44 - we're going to do app dot enable and
231:46 - then we just say
231:47 - trust proxy so that's the only thing
231:49 - that we have to do but this is really
231:50 - just in cases for
231:52 - when you need access to that ip address
231:54 - which we don't but if you're doing some
231:56 - sort of rate limiting it can be
231:58 - it's going to be necessary
232:01 - so now that we get that done the last
232:03 - thing that i want to do
232:05 - is i want to scale up our application
232:07 - again so i want to add a second
232:09 - node instance so what we're going to do
232:12 - is uh first of all i'm just going to
232:13 - tear everything down
232:29 - all right and then we're going to bring
232:30 - everything back up um but this time
232:32 - we're going to pass in the
232:33 - the dash dash scale flag and we're going
232:36 - to say node
232:37 - app equals two so we have two instances
232:47 - all right and the next thing i want to
232:48 - do is uh you know in one of our routes
232:50 - or one of our route controllers
232:52 - i just want to do a console.log
232:56 - and just have it say something it
232:57 - doesn't matter say yeah it ran
232:59 - the reason i want to do this is i want
233:00 - to verify that nginx is actually load
233:02 - balancing the request to all of our
233:04 - nodes
233:05 - all of our node instances so here i'm
233:07 - going to create a new window
233:10 - a new terminal actually and then i'm
233:11 - going to split screen this so the window
233:13 - on the left is going to represent
233:15 - the logs for node instance one
233:18 - the window on the right is going to
233:20 - represent the logs for node instance 2.
233:22 - so here i'm going to do a docker ps just
233:24 - so i can grab the name and so i'm going
233:25 - to say docker logs
233:27 - i'll say no docker node app this will be
233:30 - node app 1
233:31 - dash for follow and i'm going to copy
233:34 - this
233:36 - and then paste that here and just change
233:38 - this node app too
233:40 - and so each time we send a request i
233:41 - want to see a login generated here first
233:43 - because of this console.log
233:45 - and then ideally nginx should then send
233:47 - the next request to this one and we
233:48 - should see that log get generated here
233:50 - so i'm going to change this to api v1
233:54 - see if i could be a get request and
233:57 - let's hit send
234:01 - and i think i forgot to save it so let's
234:02 - save this there we go
234:04 - and now let's send the request all right
234:07 - so we can see it said yeah it ran on the
234:09 - left side so node app one
234:11 - then let's run it again and so then we
234:13 - can see it runs on node app two so it
234:15 - looks like it's successfully load
234:16 - bouncing let's just run it a couple more
234:17 - times
234:18 - to verify so ran on the left side right
234:20 - on the right side
234:21 - left right left right
234:25 - left right
234:28 - all right so we've got nginx up and
234:30 - running i think that's a good stopping
234:31 - point for this section
234:34 - alright guys so there's one last thing
234:36 - that i want to do
234:37 - before we actually start moving to our
234:40 - production server
234:41 - and so i want to enable cores and if you
234:43 - don't know what cores is it basically
234:45 - just allows
234:46 - your front end to run on one domain and
234:49 - your
234:50 - back end api to run on a different
234:51 - domain because by default
234:53 - let's say your front end is hosted at uh
234:56 - you know www.google.com
234:59 - right and let's say your front end sends
235:00 - a request to
235:02 - i don't say www.yahoo.com so let's say
235:04 - yahoo.com
235:05 - it's where our api exists well these are
235:08 - two different domains by default our api
235:10 - will reject that request from our front
235:11 - end
235:12 - so to allow these to be running on
235:14 - different domains we have to configure
235:15 - cores
235:16 - so that different domains can access our
235:18 - api um if you're running everything on
235:20 - one domain then you don't need it but
235:22 - i'm going to show you guys how to
235:23 - configure that real quick it's really
235:24 - simple
235:26 - and so we're going to use this library
235:28 - called cores and you'll see that
235:29 - configuring is very easy
235:31 - uh first of all uh we import cores and
235:33 - then we just configure it as a
235:34 - middleware that's it two lines of code
235:36 - and you're good to go
235:39 - so here i'm gonna do an npm install
235:40 - cores
235:42 - uh and so since we did add a new
235:46 - uh package to our package.json file a
235:49 - new dependency we're gonna have to
235:50 - rebuild all
235:51 - our image so here if we can do up
235:55 - dash d dash dash build
235:59 - so that's going to rebuild the image but
236:01 - remember
236:03 - by default when you run an up a docker
236:06 - compose up
236:07 - when you're already up and running if
236:09 - you
236:10 - have a anonymous volume like we do in
236:13 - dockercompose.yaml
236:14 - and we're using that for actually where
236:16 - is it it's under dev
236:18 - so we have this for our node modules
236:20 - what's going to happen is if we run an
236:21 - up when it's already up and running
236:23 - it's going to use our old anonymous
236:25 - volume that's going to have
236:26 - only the node modules before we ran the
236:28 - up command
236:30 - and so to get the new course package
236:31 - added in we need to make sure that we
236:33 - pass in the dash dash
236:35 - i actually have to figure out what it
236:36 - was i have to run help to figure it out
236:37 - we have to pass in the dash v
236:39 - so that's going to recreate a new
236:41 - anonymous volume so we'll do that
236:43 - dash v
236:48 - all right and so now if we go to our
236:49 - index.js let's import the
236:52 - course library
237:05 - and then right here under app.enable
237:06 - we'll just do app.use
237:09 - and then we just pass in cores
237:13 - and then here you have a config option
237:15 - uh a config object that you can pass in
237:16 - to kind of tweak the configuration for
237:18 - course
237:19 - we can just leave the default settings
237:22 - and let's just test this out just to
237:24 - make sure so
237:29 - all right that worked not sure why it
237:31 - took so long and then let's just make
237:32 - sure we send it to
237:34 - users login and let's see if this works
237:38 - all right status success perfect alright
237:40 - so guys so we are now good to go to
237:42 - start deploying this to production so
237:45 - now we're going to move on to deploying
237:47 - our application into production
237:48 - you're going to see in this section of
237:50 - the tutorial series
237:52 - we have a lot of things to cover still
237:53 - so there's still a lot of things that we
237:54 - need to learn about docker
237:56 - a lot of best practices so in the
237:58 - deployment section what's going to
237:59 - happen is
238:00 - i'm going to show you guys how to deploy
238:02 - it and we're going to start off by doing
238:04 - it the wrong way
238:05 - and then we're going to slowly correct
238:07 - each mistake one by one
238:08 - so that you know exactly why we are
238:11 - doing these things
238:12 - and then when we get to our final uh
238:14 - deployment scenario
238:16 - where we actually deploy our application
238:17 - the proper way and we
238:19 - know how to properly update our
238:21 - application you're gonna have a solid
238:23 - understanding as to
238:24 - why we are doing things the way that we
238:26 - are
238:29 - and uh so keep in mind for this
238:30 - deployment section we do need access to
238:32 - an a
238:33 - to a ubuntu server and i don't really
238:35 - care where this ubuntu server is running
238:37 - you can run it on digitalocean like i'm
238:38 - going to do
238:39 - you can run it on aws as an ec2 instance
238:42 - you can run it on gcp or azure as a
238:44 - virtual machine
238:45 - or you can just spin up virtualbox and
238:48 - then run a ubuntu instance on your local
238:50 - machine it doesn't really matter you can
238:52 - follow along
238:52 - and even if you can't i still recommend
238:54 - you finish the rest of this video
238:56 - because
238:57 - we still have a lot more things to learn
238:59 - and a lot more things to cover so don't
239:00 - think that this is just about the
239:02 - the final step and we just got a couple
239:04 - more things to do and then we're done
239:05 - with the video we still have a lot of
239:06 - things to learn so
239:07 - uh definitely stick to watching this
239:09 - video even if you can't follow along
239:11 - with all of the steps
239:13 - all right so let's now get our ubuntu
239:15 - server up and running and like i said
239:17 - we're going to deploy this on
239:19 - digitalocean as a droplet
239:20 - however if you want to use a different
239:22 - platform like aws or azure
239:24 - or even run it as a virtual machine on
239:26 - virtualbox on your on your local machine
239:28 - feel free to do that as long as you have
239:30 - an ubuntu server someplace
239:33 - you should be able to follow along with
239:34 - everything that i do
239:36 - um but i'm going to specifically do this
239:38 - on digitalocean so if you guys want to
239:39 - see these
239:40 - exact steps to do this on digitalocean
239:41 - it's pretty straightforward as well
239:43 - so i'm going to click get started with
239:44 - the droplet and then here i'm going to
239:46 - select ubuntu 20.04
239:48 - we'll select the basic plan and then we
239:50 - want to select regular intel with ssd
239:52 - because it's cheaper
239:53 - and then we select the cheapest option
239:54 - that we can find and then by default
239:57 - because i'm on the east coast it's going
239:58 - to default to the new york data center
239:59 - just pick whichever data center is
240:00 - closest to you geographically
240:03 - and then we want to select our password
240:04 - so put in your password here
240:12 - then we just hit create droplet
240:17 - and so we'll let this run for a couple
240:20 - minutes
240:21 - um it does take some time for
240:22 - digitalocean to spin up a new vm
240:24 - and then once that gets started we'll
240:26 - then install docker we do need to
240:28 - install docker on our production
240:29 - environment because
240:30 - that's how our application runs
240:32 - obviously
240:33 - um so i'll see you guys about i'll see
240:35 - you guys so i'll see you guys in a
240:37 - minute or so
240:40 - all right so our droplet was created we
240:42 - can see our public ip address so let's
240:44 - copy that
240:45 - and i'm going to open up my terminal
240:53 - make this bigger for you guys and then
240:54 - here we just do ssh root
240:56 - at and then that ip address and then
240:59 - we're going to say yes
241:00 - and then put in our password
241:07 - all right and so now we're logged in
241:10 - and the first thing that we have to do
241:12 - is get docker installed
241:14 - and so there's a couple of different
241:15 - ways to do this so if you pull up the
241:16 - documentation for installing docker
241:18 - engine on ubuntu
241:19 - they've got some very easy steps to go
241:22 - through it's just a couple of commands
241:23 - however there's an even easier method so
241:25 - if you go to get.docker.com
241:28 - right here there's actually a script
241:31 - that's uh on this hosted on this website
241:33 - that actually installs
241:34 - docker for you automatically so you just
241:36 - have to run one command
241:37 - so here under this section right here
241:40 - you just copy this curl command
241:42 - and so all you have to do is copy that
241:44 - paste it in here
241:45 - and then what that's going to do is it's
241:46 - going to download a file called
241:48 - getdocker.sh
241:50 - and then we can just say sh get dash
241:53 - docker.sh and so that's going to run
241:56 - through all the steps for getting docker
241:58 - and it's really just running the same
241:59 - exact steps here but
242:01 - this just requires two commands so i
242:02 - think it's a little easier and that's
242:03 - the route that i'm gonna go
242:11 - all right so it looks like it's
242:12 - completed let's verify that docker was
242:14 - installed by doing a docker
242:15 - dash dash version and we can see that it
242:18 - spits out a version which means docker
242:20 - was successfully installed
242:21 - now this only installs docker if you try
242:24 - to do docker dash compose
242:26 - dash v to get the version uh looks like
242:29 - docker compose is not installed by
242:31 - default so let's get that installed
242:32 - let's pull up the directions
242:34 - so we'll say docker compose install
242:38 - ubuntu and then here we can just select
242:40 - linux here
242:45 - and we just copy this command
242:49 - paste it in there
242:53 - and then copy this command
242:58 - so now if we do docker dash compose
243:03 - dash b we should see it return a version
243:07 - all right and so now we've got uh docker
243:10 - installed on our ubuntu machine
243:12 - in the next video let's set up a git for
243:14 - our application so that we can store our
243:16 - application
243:17 - uh in a git repository and then we can
243:18 - pull it into our production server
243:22 - all right so let's get started on
243:24 - creating a git
243:25 - repo for our application so on logged
243:28 - into github
243:29 - we're gonna hit this plus sign and we're
243:30 - gonna select new repository we'll give
243:32 - it whatever name we want i'm just gonna
243:33 - call this node docker
243:35 - and then you can make it public or
243:36 - private but for practice i'm just going
243:37 - to leave it as public
243:39 - we'll create repository and it's going
243:41 - to give us a couple of commands to run
243:42 - to initialize it
243:44 - so i'll walk you through that i'm not
243:45 - going to follow those exactly
243:47 - so we're going to do git actually before
243:49 - we get started first of all let's create
243:50 - a git ignore file
243:52 - so we'll say dot get ignore
243:55 - and we want to make sure that we don't
243:57 - uh include our node modules files
243:59 - because we don't actually need those in
244:00 - our git repo
244:01 - because we can just copy all of our
244:03 - source code and then just do an npm
244:04 - install
244:05 - and then based off the dependencies that
244:07 - we have listed in our package.json
244:09 - uh basically node will know exactly what
244:11 - uh packages to install so
244:13 - we don't ever need to actually push all
244:15 - of our node modules into github
244:18 - so we just say node underscore modules
244:22 - slash that's all save that we'll do a
244:25 - git
244:26 - init then we'll do a git add
244:30 - dash dash all so it's going to add all
244:32 - files
244:36 - and then we want to copy this git branch
244:39 - dash
244:39 - m actually we'll do a git commit first
244:45 - i will do git commit dash m
244:49 - first commit
244:52 - and then we'll do git branch m
244:56 - and then finally we'll copy these last
244:58 - two lines right here
245:04 - gonna set the remote repository and then
245:07 - we want to push those changes to our
245:08 - repository
245:15 - all right so all of our changes should
245:16 - get pushed out and so if you just
245:18 - click on this link right here you should
245:20 - see all of your files and everything
245:22 - looks good
245:24 - and so in the next section we're going
245:26 - to make a few we're going to make a
245:28 - couple of
245:28 - changes to our uh
245:32 - our docker configs for production so
245:34 - that it's ready
245:36 - to get deployed for our production
245:37 - server all right now let's open up our
245:40 - source code and let's go to our docker
245:42 - compose
245:44 - dev and so you'll see here that there's
245:46 - a couple of environment variables that
245:47 - we need
245:48 - in our application for it to work right
245:50 - so first of all we need the user
245:52 - the password in our node app
245:55 - and then we also need our session secret
245:57 - and then under our server we need
246:00 - a couple of things so we need the root
246:02 - user and then the root password so
246:04 - here we are hard coding it into our
246:07 - dockercompose.dev
246:08 - file because this is our development
246:09 - environment and so i these are all just
246:12 - for practice and for tests but you
246:14 - definitely don't want to accidentally
246:16 - um push any of your production
246:19 - secrets or configs or passwords into
246:22 - github right because if we put our
246:24 - our environment variables all here then
246:26 - all of our production passwords and
246:28 - secrets
246:28 - would automatically get pushed into
246:30 - github so the way around this
246:32 - is what we're going to do is we're going
246:35 - to get all of those environment
246:36 - variables
246:37 - from the machine the sir that docker is
246:40 - running on so from this ubuntu machine
246:42 - we're going to actually configure the
246:43 - environment variables and then from
246:45 - there
246:45 - docker will know what those values are
246:47 - docker will pull all those usernames
246:49 - those passwords
246:50 - those root users those root passwords
246:52 - from our host ubuntu
246:54 - machine and so from a configuration
246:56 - perspective right
246:57 - here we have all of these environment
246:58 - variables i'm going to copy this
247:00 - and we're going to tweak something so
247:03 - under environment
247:06 - we already have it right here actually
247:09 - we're gonna paste this
247:10 - we don't need the development one
247:11 - anymore because we're in production
247:13 - and so instead of hard coding into
247:15 - whatever our production username is and
247:17 - our production password is
247:19 - what i'm going to do instead is i'm
247:20 - going to just make one minor change i'm
247:22 - going to put a dollar sign
247:28 - then brackets remove this
247:31 - and then say underscore user
247:34 - and so what exactly is this saying it's
247:36 - saying that the environment variable
247:38 - called
247:38 -  user is going to pull this value
247:40 - from an environment variable named
247:42 - user on our ubuntu machine
247:44 - so if we define an environment variable
247:46 - on this abundant machine
247:48 - called user then docker will be
247:51 - able to pull it from there
247:53 - and so that way we never have to
247:54 - actually store our passwords in
247:56 - our docker file so we don't need to
247:58 - worry about it accidentally getting
247:59 - pushed up into github
248:01 - and so i'm going to change this as well
248:13 - and we're going to change the session
248:15 - secret as well
248:21 - and then we're gonna have to define the
248:22 - same thing for our service
248:34 - and we can see here we have this these
248:37 - two values right here so we're just
248:38 - going to copy this
248:54 - paste it in there and then do the same
248:56 - thing here
249:05 - all right and i want to quickly show you
249:07 - how we set an environment variable
249:09 - on a linux machine it's actually really
249:10 - easy all you need to do is we type in
249:12 - export
249:14 - and then the name of the environment
249:15 - variable so let's say as an example we
249:18 - set session secret right
249:23 - we can set session secret equal to
249:29 - some arbitrary value and i'll just say
249:33 - maybe hello
249:37 - and then if we do print nv so this
249:39 - command right here this is going to
249:40 - print out all of our
249:41 - environment variables so let's see if we
249:43 - can see our session secret and then we
249:45 - can see our session secret
249:46 - is set to hello so this value will then
249:49 - get pushed
249:49 - into this variable right here which will
249:52 - then get assigned as an environment
249:53 - variable into our docker container and
249:55 - so that's how we're going to handle
249:57 - environment variables
249:58 - within our uh production and
250:01 - for our production server all right so
250:04 - now let's get the rest of our
250:05 - environment variables onto our
250:07 - production machine
250:08 - so we could go one by one and just say
250:10 - you know export
250:11 - uh and then you know underscore
250:14 - init db and so on and just uh
250:16 - configure all of those manually however
250:18 - that's kind of a slow process
250:21 - and on top of that it won't actually
250:23 - persist across reboot so
250:25 - i want to show you my method of getting
250:26 - our environment variable set
250:28 - on our machine uh that'll actually
250:30 - persist through reboots if the switch
250:31 - goes down comes back up it's
250:32 - automatically going to load all of our
250:34 - environment variables
250:35 - and so the first thing that i want to do
250:37 - is i want to create an environment file
250:39 - that
250:39 - is going to store all of our environment
250:41 - variables so here i'm under my root
250:43 - folder
250:44 - i'm just going to make that file store
250:46 - that file here
250:47 - i'm not saying you should be doing
250:49 - anything under the root user
250:50 - you know i don't want to go into all of
250:52 - the security best practices you probably
250:53 - shouldn't be doing anything as a root
250:55 - user
250:55 - but i want to keep this video as simple
250:57 - as possible so pick a location
250:59 - in your system uh the location doesn't
251:02 - matter the only thing that i would
251:03 - recommend is don't put this anywhere
251:05 - near
251:06 - where your application code is going to
251:07 - get stored and so that way you don't
251:09 - accidentally ever push this up into git
251:11 - that's the only thing that matters so
251:13 - i'm going to store it under slash root
251:14 - and i'm going to say dot env so vi.env
251:17 - that's going to create our environment
251:18 - file
251:20 - and then here we just store all of our
251:22 - environment variables
251:23 - uh and so i'm just going to grab them
251:26 - from the dev file right here
251:27 - and we just copy the same exact syntax
251:30 - so
251:30 - this is going to be where we're going to
251:32 - set this to prod of course
251:41 - and then the last two are going to be
251:43 - the ones for
252:04 - and that's all we need to do so we've
252:06 - got our environment file
252:08 - uh then if i do a pwd make sure you're
252:10 - in your root folder and if i do an ls
252:12 - minus la
252:13 - this is going to show us this profile
252:15 - file so we're going to open that up
252:18 - and i'm going to go to the absolute
252:20 - bottom of that file
252:22 - and i'm going to create a simple config
252:25 - right here
252:25 - i'm going to say set dash o
252:29 - all export and then source
252:33 - and then we want to provide the path to
252:34 - that environment file so that's going to
252:36 - be
252:36 - root dot env
252:43 - and then we say set plus o
252:47 - i'll export all right and so what's
252:49 - going to happen
252:50 - is that it's going to loop through
252:54 - all of those environment variables that
252:55 - we set and it's going to set them
252:58 - on this machine
253:04 - let's save that
253:07 - and these changes won't take effect
253:09 - until we
253:10 - close out our terminal session and
253:12 - reopen it so i'm going to just exit out
253:13 - of here
253:14 - and take me back to my local machine i'm
253:16 - going to ssh back in again
253:24 - and now i want to do a print nv and
253:27 - let's make sure all of our environment
253:29 - variables are set
253:30 - so we've got our password perfect
253:32 - we've got our root user
253:35 - uh let's just i believe it should be
253:37 - actually let's just see uh
253:39 - if i do a cat.env there's a one two
253:43 - three four
253:43 - five six so we have six of them so this
253:46 - is one
253:47 - right here two three four
253:51 - five and then
253:54 - 6. all right so we've got all of our
253:56 - environment variables set uh you know
253:57 - i'm not saying this is the best method
253:59 - you can use whatever method you want
254:01 - some people don't like having a file on
254:02 - their machine with all their passwords
254:04 - uh they they may use some other method
254:06 - of assigning secrets so
254:08 - use whatever method you prefer i'm just
254:10 - showing you guys one example of how to
254:12 - do that
254:14 - all right so uh we've made some changes
254:16 - to our docker compose file in the last
254:18 - video
254:18 - when we assigned these environment
254:20 - variables to be whatever was set on the
254:22 - ubuntu server
254:23 - uh and so uh what we need to do is we
254:26 - need to add these to git so we'll do a
254:27 - git
254:28 - add dash dash all actually first of all
254:31 - let's make sure i save it
254:34 - it looks like uh i guess we pushed those
254:36 - changes after we made that i don't think
254:38 - we did but let's just say git commit
254:40 - dash m uh env changes
254:45 - okay so there we go so we made a couple
254:47 - of changes
254:50 - and then we want to do a git push
254:54 - and then let's go back to our git repo
254:57 - and let's open up my dockercompose.prod
255:00 - file let's just make sure the updates
255:01 - got taken
255:02 - and it looks like they did so perfect so
255:04 - now that we have our
255:05 - final application code within git let's
255:08 - go to our production server
255:10 - and let's uh first of all let's create a
255:13 - a folder to store our application so i'm
255:15 - going to create a folder called app
255:17 - and a cd into app
255:27 - and then we're going to click we're
255:28 - going to clone our git repo so
255:31 - copy this i'm going to say
255:35 - git clone and then clone it into our
255:38 - current directory
255:40 - and so now if i do an ls we should see
255:42 - all of our application files
255:47 - and so now just like we did on our local
255:49 - machine
255:50 - let's uh run a docker compose up and
255:53 - let's see if this works on our
255:54 - production server
255:56 - we're going to say docker dash compose
256:01 - and then we're gonna say dash f and then
256:02 - we'll do docker dash compose
256:04 - dot yaml and then dash f and then docker
256:07 - dot compose dot prod dot yaml
256:11 - we'll say up with the d flag
256:14 - and because there's no images already on
256:17 - this machine because we just installed
256:18 - docker
256:19 - it should automatically build our node
256:22 - image as well so let's run that
256:26 - and i realized i made a mistake so you
256:29 - can see here
256:30 - uh this should be indented one slot back
256:33 - i'm not sure what happened in my
256:35 - production example but that got a little
256:39 - rearranged so just move that over and
256:41 - that's why he was saying that there was
256:42 - an error on that specific line so we got
256:44 - that fixed
256:45 - now unfortunately we have to do a get
256:48 - add again
256:52 - and then a git commit
256:59 - and then i get push
257:02 - and then we go back to our server and we
257:04 - can just do a git pull
257:06 - alright and so now we've got those
257:08 - changes and now let's run that same
257:10 - command
257:14 - alright so it's building our image
257:22 - perfect
257:24 - right and now it looks like it's
257:25 - finished let's do a docker ps
257:27 - uh we can see that we've got all of our
257:29 - containers up and running
257:31 - and now let's go ahead and actually just
257:33 - send a request to our server so
257:35 - i'm going to pull up the ip address of
257:38 - my
257:38 - note of my uh digitalocean droplet
257:42 - and then let's go back to postman and
257:44 - i'm going to just create a new request
257:49 - so go to http colon slash put that ip in
257:54 - uh we don't need to put in the port
257:55 - because it's listening on port 80 so you
257:57 - could do that but it's the default
257:59 - and then here we want to go to slash api
258:01 - slash v1 slash
258:02 - uh let's just get that one let's just
258:04 - see if that works all right and we can
258:06 - see it says hi there so it looks like
258:07 - things are working
258:08 - but i also want to log in so we'll do uh
258:11 - users
258:13 - log in well actually we have to do sign
258:17 - up because remember
258:18 - we deployed uh this on a different
258:20 - server so there's nothing in our
258:22 - database so we have to actually sign up
258:24 - first
258:24 - and let's set our body we'll do raw then
258:28 - json and then here we'll say username
258:33 - sanjeev and then we'll say password
258:39 - password and this is going to be a post
258:43 - request
258:46 - all right and it looks like that works
258:49 - so it looks like i think
258:50 - it's pretty safe to say that our
258:51 - application is now working in our
258:53 - production environment
258:54 - and everything has been deployed
258:55 - properly
259:01 - all right so now we have successfully
259:02 - deployed our application to our
259:04 - production server and we can start
259:05 - receiving and handling production
259:07 - traffic um but how exactly do we go
259:09 - about
259:10 - uh pushing out changes to a production
259:12 - server you know let's say that a
259:14 - developer on our team
259:16 - either made some code changes or maybe
259:18 - even added a new feature
259:19 - how do we get those changes that we
259:21 - implemented in our development
259:22 - environment pushed out to our production
259:24 - environment
259:25 - well let's walk through the different
259:26 - steps that's going to be required
259:28 - so the first thing is i'm going to make
259:30 - a simple code change so under this dummy
259:32 - route that we have in our index.js file
259:34 - i'm just going to add a few exclamation
259:36 - points like i've done before
259:37 - so let's save that and the first thing
259:39 - that we have to do is we need to push
259:41 - that out to github
259:42 - all of these changes need to be pushed
259:44 - out to our repository so let's do a git
259:47 - add dash dash all and then we do a git
259:49 - commit
259:53 - we'll commit those changes and then
259:54 - we'll do a git push
259:58 - all right so those got pushed out to
259:59 - github let's just double check to see if
260:01 - those changes are there so i'm going to
260:02 - select the index.js file
260:04 - and if we take a look at our route we
260:06 - can see we have the extra exclamation
260:08 - points
260:09 - all right so now we have to go to our
260:11 - production server it looks like i lost
260:12 - connectivity so let me log back in
260:20 - make sure you use cd into your app
260:21 - directory and so here we need to
260:24 - pull in those new changes so we have to
260:26 - pull in the updated code so we just do a
260:27 - git pull
260:29 - and so once you do a git pull it should
260:30 - update that index.js file and if i do a
260:32 - cat
260:33 - index.js we should see those changes
260:36 - take effect and we can see that here
260:38 - all right and so now because this is our
260:40 - production environment it's not going to
260:42 - automatically
260:43 - sync our code or anytime our code
260:45 - changes we don't have nodemon to restart
260:46 - application
260:47 - we have to rebuild an image uh and
260:49 - create brand new containers
260:51 - so we have a couple of different options
260:52 - you know we can do a docker compose
260:54 - and then down and then after that we do
260:57 - a docker compose
260:59 - up or we can just do a docker compose up
261:02 - and i prefer just doing a docker compose
261:04 - up because it's a little bit quicker
261:05 - because the system
261:07 - or docker compose will actually delete
261:08 - the container and spin up a new
261:09 - container
261:10 - whereas when we do down it tears
261:12 - everything down and then until we
261:14 - run the up command it's going to keep
261:15 - everything down so when you do down and
261:17 - then up
261:17 - you face a little bit more of an outage
261:19 - so let's do docker compose and then
261:21 - let's pass in our files as usual
261:27 - and then let's do uh up and then dash d
261:31 - so let's see if this updates our code
261:36 - all right and so we could see here it
261:37 - looks like docker compose detected that
261:39 - the database
261:40 - is already up to date we don't need to
261:41 - change anything and that's expected
261:42 - because we didn't change anything with
261:43 - that
261:44 - same thing with the redis same thing
261:45 - with nginx however for some reason it
261:47 - did not update our node app right it
261:49 - says it's already
261:50 - up to date and remember that's because
261:52 - docker compose
261:53 - is very dumb right it just checks to see
261:55 - if there's an image
261:56 - named that it does not know that this
261:58 - image is out of date so what we have to
262:00 - do is
262:01 - we have to run the same command with the
262:02 - dash dash build
262:05 - so let's run that and this should
262:07 - rebuild the image
262:08 - and then since the image has changed
262:10 - docker compose is going to have to
262:11 - delete the old container
262:13 - and spin up a new node container
262:20 - and so you can see here it's now
262:21 - recreating that container because the
262:22 - image changed
262:23 - and it noticed that you know
262:25 - didn't change once again we just didn't
262:26 - change
262:27 - and nginx didn't change so if any one of
262:29 - those properties for any of these
262:31 - containers had changed
262:32 - as well then it would update those as
262:33 - well all right so the changes are done
262:36 - and uh let's go to our uh our postman
262:39 - and then let's send a request to that
262:41 - route so let's hit send
262:42 - and we can see that we got a response
262:44 - back with the extra exclamation points
262:46 - so we have now successfully pushed out
262:48 - changes to our production server
262:51 - however there's a couple of things i
262:52 - didn't like so first of all when you do
262:54 - this
262:55 - up dash d build it's going to check
262:58 - all of your containers all of your
263:00 - services to see if anything's changed
263:02 - now in our application we know the only
263:04 - thing that's going to be changing
263:05 - whenever we change our source code
263:07 - is going to be our node app container so
263:09 - is there any way that we can tell
263:11 - docker compose to not even bother
263:12 - checking these things because
263:14 - you know we don't want to accidentally
263:15 - maybe we put in a typo into our compose
263:17 - file and then we actually change
263:19 - uh some settings in our database
263:20 - and that causes our database to go
263:22 - down
263:22 - and then have to get rebuilt and then we
263:24 - suffer an even bigger outage
263:26 - how can we tell docker compose to only
263:29 - rebuild our node app and then recreate
263:31 - that container
263:34 - and then here what we can do is we can
263:35 - specify the service name so i could just
263:37 - say node
263:38 - app and that's just going to rebuild our
263:40 - node app server service let's test this
263:41 - out and see if this actually works
263:47 - and so it rebuilt our node app service
263:50 - and that's good so we built that image
263:51 - however once again it went and checked
263:54 - to see if
263:55 -  and as well as our other redis
263:58 - container probably somewhere in there
264:00 - needed to be updated so why exactly did
264:03 - it check that
264:04 - actually it looks like it just checked
264:05 - for so why did it check to see if
264:07 - our
264:08 - database was up to date well despite the
264:11 - fact that we provided the
264:12 - service here just as node app what
264:14 - happens is if you take a look at our
264:16 - configuration and go to our docker
264:18 - compose.yaml file
264:19 - you'll see our node app is dependent on
264:23 - so within docker compose anytime you
264:25 - specify
264:26 - a service and you need to rebuild that
264:28 - service it has no idea if all of its
264:30 - dependencies
264:31 - changed and when i say dependencies i
264:33 - mean under the depends on so
264:35 - it has to rebuild the container
264:36 - because it has no idea if the changes
264:38 - will impact
264:39 - mango or not so that's the reason why
264:42 - that's happening and there's a way
264:44 - around that
264:44 - what we can do is we can pass in one
264:46 - more flag
264:48 - we can pass in the dash dash
264:51 - no dash depths so we're basically saying
264:53 - no dependencies
264:54 - so we're not going to rebuild that
264:56 - dependency as well so if we run this now
265:00 - you can see that it successfully builds
265:02 - our image
265:03 - and then it rebuilds our container
265:07 - uh and you can see it's already up today
265:08 - because we didn't make any code changes
265:09 - so let's test this out one more time
265:11 - let's push out some changes
265:13 - so i'm going to go to my index.js i'm
265:15 - going to delete this
265:19 - i'm going to save that i'm going to do a
265:21 - git add
265:28 - and then we'll do a git push
265:32 - changes have been pushed let's do a get
265:34 - pull
265:35 - and then let's run this same exact
265:38 - command and let's just hope that
265:39 - only our node container gets rebuilt
265:43 - and recreated
265:50 - all right so it recreated our container
265:52 - and so now if i
265:54 - uh send a request to that route we can
265:56 - see that we don't get exclamation points
266:00 - now there may be an instance where maybe
266:01 - you just want to rebuild a container
266:03 - let's say we didn't make any
266:04 - code changes uh the image hasn't changed
266:06 - and we just want to
266:07 - rebuild a container for whatever reason
266:10 - uh there's a couple of specific flags
266:11 - that we need to pass in so let's do a
266:13 - docker compose up
266:14 - dash d and let's say we want to rebuild
266:17 - the node app service
266:19 - if we do this well here's the problem
266:22 - here's the problem right none of the
266:23 - images change so if we just run this
266:25 - it's not going to
266:26 - rebuild it because it's going to say
266:28 - that it's up to date so what we can do
266:29 - is if i do a dash dash help
266:34 - and i need to place that here
266:40 - we can do the force recreate so this
266:42 - will recreate containers even if their
266:44 - configuration
266:44 - and images haven't changed so let's try
266:47 - that out
266:49 - we'll just say dash dash force recreate
266:53 - and we'll say node app so let's see if
266:55 - this recreates our node container
266:58 - and two things happen well first of all
267:00 - it recreated our container
267:02 - that's not good and then it recreated
267:04 - our node app so remember it recreated
267:06 - our
267:06 -  container because in our docker
267:09 - compose file we say it depends on manga
267:10 - so because it depends on it
267:12 - we got to rebuild that also uh and so to
267:15 - get around that
267:15 - just like we did before we can pass in
267:17 - the no depth
267:19 - argument so we can say no dash depths
267:23 - and this is going to trigger a rebuild
267:25 - of that container
267:26 - and no other containers
267:34 - so i want to quickly summarize our
267:36 - overall development to production
267:38 - workflow
267:38 - and i want to quickly reiterate how we
267:41 - actually push changes
267:42 - uh from our development environment to
267:44 - our production environment
267:46 - so whenever we make any kind of change
267:48 - to our code base
267:49 - the first thing that we do is we push it
267:51 - out to github and then once we push it
267:53 - out to github
267:54 - our production server will log in and
267:55 - then we'll do a git pull which is going
267:57 - to pull
267:57 - that new code base in and then once we
267:59 - get the updated code
268:01 - what we're going to do is we're going to
268:02 - run the docker compose up dash dash
268:04 - build
268:04 - and that's going to trigger a rebuild of
268:07 - the node
268:07 - image and then once we build the image
268:09 - we can then rebuild a brand new
268:11 - node container using that new node image
268:15 - so there's a couple of different issues
268:17 - with this
268:18 - development to production workflow and
268:20 - the main issue is that we're building
268:22 - our image
268:23 - on our production server this is
268:26 - something that is never recommended you
268:28 - should never be building your image on
268:29 - your production server
268:31 - and that's because building an image
268:33 - takes resources
268:34 - it takes a cpu cycles and it takes
268:36 - memory
268:37 - and for our application it's obviously a
268:39 - tiny demo application so it doesn't
268:41 - take that much cpu horsepower to
268:43 - actually build that image but as your
268:44 - application grows
268:46 - right it's going to require larger and
268:48 - longer build times
268:50 - and so you know as that application
268:52 - grows you're going to see that when you
268:53 - build an image it's going to take more
268:54 - cpu and it's going to take more memory
268:56 - so if you do this on a production server
268:58 - you could end up starving
269:00 - your actual production traffic because
269:02 - all of the compute power
269:04 - and all of your memory is going towards
269:06 - building an image
269:07 - and your production server should only
269:09 - be meant for one thing and that is just
269:11 - to handle production traffic it should
269:12 - never be doing anything else
269:14 - so what i ultimately want to do is move
269:16 - away from this development workflow
269:18 - and work move towards a workflow that
269:20 - allows us to build an
269:21 - image on a machine that's not a
269:23 - production server
269:24 - so let's take a look at the production
269:26 - workflow that we're ultimately going to
269:28 - move to
269:29 - all right so in this workflow uh the
269:32 - main idea is
269:33 - that we're no longer going to build that
269:35 - image on our production server
269:36 - so what's going to happen is the
269:37 - engineer on the left he's going to build
269:39 - an image
269:40 - on his dev server so he builds it on his
269:42 - dev server using a docker
269:44 - compose up dash dash build and so that's
269:47 - going to trigger a build on his local
269:49 - machine
269:50 - once that's done he's going to push that
269:51 - brand new built
269:53 - image to docker hub so docker hub is
269:56 - just a repository of images
269:58 - you can use any docker repository it
270:00 - doesn't have to be docker hub
270:01 - you can use amazon's repo repository
270:05 - um but you know when we demo this we're
270:07 - just gonna use docker hub because it's
270:08 - free
270:08 - so we'll push that image to docker hub
270:10 - and then our production server
270:12 - we're gonna do a we're going to pull
270:14 - that brand new node image
270:16 - so we're pulling in the finalized image
270:18 - with all of the new code changes
270:20 - and then all we have to do is do a
270:22 - docker compose up
270:23 - docker compose is going to detect that
270:26 - there's a brand new image for our node
270:28 - container or our node service
270:30 - and that's going to trigger a rebuild of
270:31 - the node container using the brand new
270:33 - node image
270:34 - so this is the workflow that we are
270:36 - going to move towards
270:37 - and you can see that by building it on
270:39 - the dev server we no longer have to
270:41 - build it on our production server
270:43 - so next video we're going to actually go
270:45 - ahead and implement this and i'm going
270:46 - to show you guys
270:47 - how much better of a workflow this
270:49 - actually is
270:52 - all right so to implement our new
270:54 - workflow the first thing that we have to
270:55 - do is create an account on docker hub
270:57 - so if you haven't already done that go
270:59 - ahead and sign up to docker hub
271:01 - and then sign in so i'm going to log in
271:03 - real quick
271:09 - and so once we've logged in this is
271:11 - going to be uh you know where we store
271:13 - all of our repositories so i'm going to
271:15 - create a brand new repository
271:17 - and i'm going to give this name node app
271:21 - and i'm going to make this public so
271:22 - docker hub gives you one public repo
271:24 - sorry you get unlimited public
271:26 - repositories you get one private
271:28 - repository so i'm just gonna keep that
271:29 - as public for now
271:30 - and then we'll hit create
271:34 - and so now let's uh push our
271:37 - image that we have on our development
271:38 - server up to this repository so this
271:40 - repository can store
271:42 - our final image and so to do that the
271:44 - first thing that you have to do is let's
271:45 - go to our
271:46 - development environment and let's do a
271:48 - docker and then there's a command called
271:50 - push and let's just do
271:52 - help just to kind of poke around and see
271:53 - what options we have so it looks like we
271:55 - just do docker
271:56 - push and then we just do the name
271:59 - and then you know kotlin and then tag
272:02 - so if we do docker well first of all
272:04 - let's do docker image
272:05 - ls
272:11 - and let's grab our latest docker image
272:14 - for our node app which is this one right
272:15 - here so what i'm going to do is i'm
272:17 - going to do a docker
272:18 - push and then this and then if i don't
272:20 - pass in
272:21 - you know specific tag it's just going to
272:23 - assume to be latest so let's try that
272:27 - and we may have to do a docker login
272:29 - first
272:33 - all right so we're logged in let's try a
272:34 - push again and let's see if that worked
272:37 - and it looks like it's denied
272:38 - and so the reason for this is that uh
272:40 - when you push an image
272:42 - to docker hub it needs to have a very
272:43 - specific name
272:45 - so if we go here this is the name of our
272:47 - repository this is the name that we have
272:49 - to push it at so we have to do sloppy
272:51 - networks which is my username
272:52 - so you have to use your username
272:54 - whatever that is and then slash
272:56 - and then the name of the image so we're
272:58 - going to change that so how do we change
272:59 - the name of an image because right now
273:02 - if i look at my image
273:04 - it's called this and you can see i need
273:08 - to rename it to something like
273:09 - sloppy networks slash node app
273:12 - uh so to do that we have to do the
273:15 - command
273:16 - docker image and then there's a command
273:19 - called tag
273:20 - all right and so what we do is you grab
273:22 - the name of your current image that you
273:24 - want to rename
273:27 - and then you want to then pass in the
273:29 - name that you want to rename it to what
273:31 - it actually does is it copies the image
273:33 - and then gives the new copied image the
273:34 - name that you tell it so i'm going to
273:36 - name this
273:36 - my username make sure you put in your
273:39 - username
273:41 - slash and then we'll just say what was
273:45 - it called
273:46 - node app
273:53 - and now if i do a docker image ls
273:57 - scroll to the top we can see that we now
273:58 - have sloppy networks slash
274:00 - node app and it's got a tag of play just
274:02 - because we didn't give it a tag
274:04 - so let's push this up now so let's do a
274:05 - docker push
274:08 - copy that name
274:14 - and so now we can see that it's
274:15 - successfully getting pushed
274:21 - all right so now that that's complete if
274:22 - we go back to docker hub and refresh
274:24 - this page
274:25 - we should see that an image was
274:27 - successfully pushed and so we can see
274:28 - that we got an image that was pushed a
274:30 - few seconds ago
274:31 - uh and so now it's within this
274:33 - repository and our production server
274:35 - can pull that image
274:38 - however before our production server can
274:41 - actually pull this image we need to tell
274:42 - docker compose
274:44 - that we want to actually use this image
274:47 - for our application moving forward
274:49 - so how do we do that right because we
274:50 - still need to be able to build
274:52 - the uh build our image ourselves with
274:54 - docker compose but we also need to be
274:56 - able to tell it that you know when we
274:57 - want to actually run the application we
274:58 - want to use this specific image in this
275:00 - repository
275:01 - so what we have to do is let's go to
275:03 - dockercompose.yaml
275:06 - and under node app what we can do is we
275:09 - can pass
275:09 - under here an image property and here
275:12 - you just pass in the name of that repo
275:14 - so you do sloppy
275:15 - networks slash node app so once again
275:18 - your username
275:19 - and then the name of the project
275:24 - and so now when you do a docker pull
275:26 - it's going to pull this specific
275:28 - image and you can still technically
275:31 - build an image as well so you get the
275:32 - flexibility of being able to build an
275:34 - image
275:34 - as well as pulling the image from the
275:36 - repository
275:38 - now since we made some changes to our
275:39 - docker compose file we do need to push
275:41 - that to github and then pull those
275:43 - changes
275:44 - onto our production server so let's go
275:45 - ahead and do that right now
275:47 - i'm going to do a git add dash dash all
276:04 - and then on our production server we
276:06 - just do a git pull
276:10 - all right so now what i want to do is
276:12 - let's go ahead and do a docker compose
276:14 - up
276:16 - dash d and let's just see what happens
276:22 - all right so it rebuilt an image just
276:24 - because um
276:25 - now our image is actually called sloppy
276:28 - networks slash node app so when we
276:29 - actually build an image
276:31 - it's by default going to give this name
276:32 - so it built that image
276:35 - uh on the production server local
276:36 - machine it named it sloppy networks
276:38 - slash node
276:39 - uh dash app colon latest and then it
276:42 - recreated the
276:43 - application and nothing's changed so
276:46 - we've got it working now
276:47 - um but how exactly do we push those
276:50 - changes now so let's say
276:52 - uh in our development environment we
276:54 - make some code change so let's go back
276:55 - to
276:56 - index.js and let's make some changes
277:00 - i'm going to add some exclamation points
277:02 - so how do i actually push those changes
277:05 - right
277:05 - well remember what we want to do is we
277:07 - want to build an image
277:08 - on our local machine and then push it up
277:10 - to uh
277:12 - our uh our repository on docker hub
277:15 - and then once it's pushed out to a
277:16 - repository we'll then pull it onto our
277:18 - production server
277:20 - so how do we build an image well we
277:21 - already know how to build an image
277:23 - however we can use docker compose to do
277:24 - that as well
277:26 - so let's see if i can find the command
277:27 - so we'll do docker
277:29 - dash compose and you gotta do the dash f
277:32 - and everything again so we'll do docker
277:33 - dash compose
277:38 - dot yaml and then uh dash f once again
277:42 - and then docker dash compose dot
277:45 - prod dot yaml so we always want to do
277:47 - the dot prod because we're building the
277:48 - image for production
277:53 - and we want to run instead of up right
277:56 - if we do help we can actually do a build
278:00 - so just like when it comes to docker um
278:02 - like docker build
278:04 - or docker push and things like that we
278:06 - have all the same commands for docker
278:08 - compose so we want to do
278:10 - docker compose build that's going to
278:12 - build all of our services
278:16 - so we'll do build and what this is going
278:18 - to do is
278:19 - for all the services that you have and
278:22 - it looks like my terminal just crashed
278:24 - wonderful
278:27 - and do i still have and it's gone so i
278:28 - gotta rebuild that for a sec so give me
278:30 - one second
278:40 - and then we do build
278:43 - so what this is going to do is uh if we
278:45 - go to our docker compose it's going to
278:46 - look through all of our services
278:48 - that allow us to build an image right
278:50 - and so right now we only have one custom
278:52 - service where we have to build an image
278:54 - however if we had more than one uh maybe
278:56 - we had a couple of other
278:58 - uh services that required building
279:00 - images it would build the image for all
279:02 - of those services so if i do build now
279:07 - right it's going to go through that
279:08 - whole process
279:16 - it's built the image if i do a docker
279:17 - image ls
279:21 - you can see we have a sloppy network
279:22 - slash node app and you can see this one
279:24 - was built five seconds ago so this is
279:26 - the one that we're concerned with
279:29 - and so now that we have this image we
279:31 - can then push it up to
279:33 - uh docker hub however one thing i want
279:35 - to point out like i said it's going to
279:37 - build all of our services
279:38 - and in this case it's just our one node
279:40 - app service because we only have one
279:41 - service where we can build a custom
279:42 - image
279:43 - however in a production application you
279:45 - may have more than one service so let's
279:47 - say we only wanted to build
279:49 - uh the image for just one of our
279:51 - services
279:52 - is there any way we can specify that
279:54 - absolutely all you have to do is just
279:55 - pass in the name
279:56 - at the end of the service that you want
279:58 - to build for so here this is only going
280:00 - to build the node app service
280:03 - all right so we got our image the next
280:06 - thing we have to do is push the docker
280:07 - hub
280:08 - so just like we have a build command we
280:10 - also have a push command so we can say
280:11 - push
280:12 - and this is going to push it to docker
280:14 - hub and you have the option of pushing
280:17 - all of your images for all of your
280:18 - services which
280:20 - if i just hit enter right now it's going
280:22 - to do that or we can also specify just
280:24 - the services we want to push an image
280:26 - for so if i do no dash app
280:27 - it's only going to push the image that
280:29 - we built for this service but if we have
280:31 - more than one service then we could
280:32 - theoretically
280:33 - push all of them out if we just don't
280:35 - specify the name of a service
280:38 - so i'm going to just push out just this
280:42 - service
280:47 - and remember the change that we made was
280:49 - we added the extra exclamation points
280:55 - all right so we push that image we go
280:57 - back to docker hub
280:58 - hit refresh
281:03 - and you can see once again it was pushed
281:04 - a few seconds ago
281:06 - and if you wanted to see all of them
281:07 - it's going to show you that but let's go
281:10 - back
281:15 - and now let's go to our production
281:17 - server
281:20 - and instead of running it up we just do
281:23 - a dash dash help
281:25 - and let's see if there's a option to
281:27 - pull
281:30 - an image all right so now if we take a
281:34 - look at the list it looks like there is
281:36 - a way to pull a service image so let's
281:39 - try that
281:41 - i'm going to say pull
281:45 - and let's see what happens
281:51 - all right so it looked like it pulled
281:52 - all of our images so it it went back to
281:55 - docker hub and checked to see if there
281:56 - was a
281:57 - more recent redus image same thing with
281:58 - nginx same thing with
282:00 - and then it pulled our brand new node
282:01 - app image so if i do a docker image ls
282:05 - uh you'll see that this one was created
282:09 - about three minutes ago
282:11 - um i guess it didn't have to update this
282:14 - but i'm not sure why that didn't get
282:16 - updated but let's let's try it out
282:18 - anyways
282:20 - uh and so what we're gonna do is let's
282:22 - do a docker compose
282:24 - up now with the new image
282:28 - and just pass in dash d and let's let it
282:31 - run
282:33 - so we checked to see if these images
282:34 - were up to date and they were
282:36 - and it looks like we were running an
282:37 - older image so now that we got the new
282:39 - image it's going to rebuild
282:41 - our container
282:44 - and now it's running our latest image so
282:47 - if i hit send
282:49 - we can see that it now has the
282:50 - exclamation points all right so it looks
282:53 - like we now have somewhat of a better
282:55 - a development to production workflow by
282:57 - pushing and pulling images
282:59 - um but a couple of things to note so
283:01 - first of all it checked to see if all of
283:02 - these images were up to date
283:04 - um you know there may be times where we
283:05 - don't want to pull the latest image for
283:07 - those
283:08 - so just like we did before we can do up
283:11 - dash d
283:12 - and then we can say dash dash no dash
283:15 - depths
283:16 - and then we can specify we just want to
283:18 - uh
283:19 - we just want to specifically update the
283:22 - node app
283:24 - so in this case it's just going to try
283:26 - and update the node app in this case
283:31 - all right so let's run through this
283:33 - workflow one more time
283:35 - just to make sure you guys understand
283:37 - what we have to do so let's go back to
283:38 - our
283:39 - our development environment i'm going to
283:41 - change this back to here by removing
283:43 - those
283:45 - and so the first thing that we have to
283:46 - do is once we make those changes we have
283:48 - to build an image so we run a docker
283:50 - compose
283:51 - build right and we have the option to
283:53 - specify just one service or more than
283:54 - one service or all services
283:56 - i'm just going to specify this one
283:57 - service we'll hit enter it's going to
283:59 - build that image
284:01 - next thing we have to do is we have to
284:03 - push this brand new image that we
284:04 - created to docker hub
284:07 - and so we can do a let me hit the up
284:09 - arrow a couple of times
284:13 - so then we do a docker compose push
284:16 - and once again we can push all of our
284:17 - images or just one image so in this case
284:20 - we're going to push just the node app
284:22 - image so let's run that
284:24 - it's going to push it up to docker hub
284:26 - all right and so now once that's pushed
284:28 - up there let's go to our production
284:29 - server
284:30 - and then here we pull that brand new
284:32 - image
284:34 - so we do a pull and here you can also
284:36 - specify just the
284:37 - service that you want to pull an image
284:39 - for so i'm going to specify just the
284:40 - node app because that's the only thing
284:41 - we're updating
284:44 - and so now it's going to pull our node
284:46 - up
284:47 - and then we can run a docker compose up
284:50 - and specify just the services we want to
284:52 - change so if we run just an up
284:54 - this is going to try and uh it's going
284:57 - to check to see if there's changes for
284:58 - any of our services and if there are
285:00 - it's going to change all of those
285:01 - services however we didn't change
285:03 - anything with our databases so nothing
285:05 - technically needs to change but
285:06 - in a production environment if you know
285:08 - nothing should change um just
285:10 - you know i would just rather just hard
285:12 - code it to say i only want to update my
285:14 - node or express app just in case because
285:16 - i don't want to accidentally
285:18 - rebuild a database or my redis data
285:20 - store
285:21 - or any other important aspect of my
285:23 - application that doesn't need updating
285:25 - so i'm going to pass in the dash dash no
285:28 - dash depths and then specify node app so
285:31 - that we only
285:33 - can rebuild just that one service
285:37 - all right so we're recreating the
285:38 - container because we're using a brand
285:39 - new image that we pulled
285:48 - once that's done let's test it out and
285:50 - so now the exclamation points should be
285:51 - gone
285:52 - and now they're gone so that's our
285:54 - development workflow
285:56 - at the moment uh in the next video i'm
285:58 - going to show you how we can automate
285:59 - one of those steps
286:01 - and you'll see that um you know i'm not
286:03 - saying that you do want to automate that
286:05 - specific step that we're going to do
286:07 - um but it is an option i just want to
286:09 - make sure i cover everything in this
286:10 - video
286:11 - so in the last video i walked you
286:13 - through how we can implement our new
286:14 - development workflow by pushing
286:16 - and pulling images and one of these
286:19 - steps
286:20 - we can actually automate so uh you know
286:22 - when we push a new image
286:24 - to docker hub wouldn't there be wouldn't
286:26 - it be cool if there was a nice way to
286:28 - have the production server
286:29 - automatically detect that we pushed a
286:31 - new image and pull that new image well
286:34 - there is a tool that we can use called
286:35 - watchtower
286:36 - that will automatically check docker hub
286:38 - periodically for a new image
286:40 - and whenever an image gets pushed it'll
286:42 - automatically pull it to
286:43 - your production server and then restart
286:45 - a your container with the brand new
286:47 - image
286:48 - now some people you know like this
286:51 - feature
286:51 - some people don't right some people
286:53 - don't like to
286:54 - automatically push out changes to their
286:56 - production server because you know they
286:58 - want to mainly do it to manually do it
287:00 - so that they can verify that everything
287:01 - runs okay because you don't want it to
287:03 - accidentally pull an image
287:04 - and then you know have it potentially
287:06 - crash out with some error logs
287:08 - while you're not there at the command
287:10 - line so uh you know some people like it
287:12 - some people don't but i did want to show
287:13 - you guys how we can automate that step
287:18 - so here in google i'm just going to
287:19 - quickly search for docker
287:22 - watch tower
287:25 - and so here this is the github page for
287:28 - this
287:29 - and what we want to do is just go to the
287:31 - full documentation page
287:35 - and this is going to have a quick start
287:37 - for you so it's going to show you how to
287:40 - actually use this feature but it's a
287:42 - special container that'll just
287:43 - periodically watch docker hub
287:46 - for a specific image and if it sees a
287:48 - new image get pushed out it's going to
287:49 - pull that image automatically for you
287:51 - and restart the container so it's a
287:53 - container that handles the automation of
287:55 - your other containers
287:58 - and there's plenty of documentation but
288:00 - i'm just going to show you guys how to
288:01 - run this real quick
288:05 - and let's go to our production server so
288:07 - let's do docker ps
288:09 - you can see all the containers we have
288:10 - and that's just for application and
288:12 - we're gonna do is we're gonna do a
288:13 - docker run
288:14 - dash d there's gonna be a lot of flags
288:16 - by the way so let's give this container
288:18 - a name so i'm gonna say name
288:20 - a watchtower
288:26 - then we're going to pass in some flags
288:28 - some environment variables so we're
288:29 - going to
288:30 - call this watchtower underscore trace
288:34 - and if you're wondering where i'm
288:35 - getting these you know just take a look
288:36 - at the documentation so
288:37 - you can see under arguments i think it's
288:39 - under here you'll see all of the
288:41 - environment variables if i search for
288:44 - trace
288:46 - so it's going to show us you know this
288:48 - is just going to include trace mode with
288:49 - verbose logging so i like having extra
288:51 - logs
288:52 - and then we're also going to pass in the
288:54 - poll interval so this is going to tell
288:55 - us how long we how frequently
288:57 - we should pull docker hub
289:03 - so watch tower underscore trace is going
289:05 - to be set to true if you do want the
289:07 - trace on or you can set it to false
289:09 - then we're going to pass in one more
289:10 - environment variable called watchtower
289:15 - underscore debug equals true
289:20 - and then one more this is going to be
289:23 - watch tower
289:26 - underscore pull underscore interval
289:29 - this could be set to 50. i think that
289:31 - should be every 50 seconds we should
289:33 - check for a new image
289:36 - and then we have to set up this volume
289:39 - uh so this has just come straight from
289:40 - the documentation
289:41 - so we do slash var run
289:45 - slash docker dot sock
289:50 - and then call in slash var
289:53 - slash run slash docker dot sock
289:58 - and that should not be in all capitals
290:00 - by the way
290:09 - and then we have to specify the image so
290:11 - the image
290:12 - just comes from that repository but if
290:15 - you look at the
290:16 - home homepage you can see that the image
290:18 - is just container slash watch tower
290:20 - that's container with three r's by the
290:22 - way
290:31 - all right so now if we do a docker ps
290:33 - we've got our new
290:35 - container it's running and let's just do
290:37 - a docker
290:38 - logs and then just grab this container
290:42 - and then pass in the dash f flag
290:46 - all right so it looks like it's running
290:49 - the list of
290:51 - retrieved containers and i realized i
290:53 - made a mistake so
290:54 - there's a uh the one important thing
290:57 - that we have to pass into this docker
290:59 - run command
291:00 - is the list of services that we actually
291:01 - want to watch because right now
291:03 - it doesn't know which services we want
291:04 - to watch so let me stop this
291:08 - and let me just do a docker rm
291:16 - and then we'll just use a dash f flag to
291:17 - delete it
291:19 - and then we're going to run that long
291:21 - command again but here we have to
291:22 - specify the services
291:24 - or the containers that we wanted to
291:26 - watch out for
291:28 - so in this case we have this app node
291:30 - app1
291:31 - so we wanted to make sure that there's
291:34 - that if a new image gets pushed for this
291:36 - container
291:37 - to you to docker hub that it
291:38 - automatically pulls it
291:40 - right so you can specify as many
291:41 - different containers as you want so i'm
291:43 - just going to use just this one
291:47 - and then now let's do a docker logs
291:49 - watch
291:52 - all right so now retrieve running
291:53 - containers and then
291:56 - basically nothing's happening except
291:57 - it's saying that a check will be
291:59 - performed in 49 seconds
292:01 - uh so let's um make a change to our code
292:04 - and push an image
292:05 - so i'm going to add quotations and then
292:08 - some extra
292:09 - fun stuff we're going to do the two
292:12 - usual steps we're going to do a build
292:18 - and then we're going to do a push
292:27 - and then let's take a look at the logs
292:29 - and let's see um
292:31 - if after the time limit after the 50
292:32 - seconds it does successfully detect that
292:35 - there's an image
292:35 - and it rebuilds our container and look
292:38 - at that something happened what happened
292:40 - let's see uh so this is where we were
292:44 - all right then it's checking so the 50
292:46 - seconds end is going to check for
292:47 - containers for updated image
292:49 - it's retrieved the running containers
292:53 - all right trying to load authentication
292:54 - credentials no credentials for sloppy
292:57 - networks found
292:59 - and we were still able to get an image
293:00 - right so this remember this is the
293:02 - reason why it's checking for credentials
293:04 - is because
293:05 - there's a possibility that one of my
293:07 - images or one of my containers uses a
293:09 - image from a private repository so if it
293:12 - did
293:13 - use a image from a private repository we
293:15 - would have to make sure
293:16 - that we just did a docker login right so
293:19 - it would look like
293:20 - docker login and you would just do this
293:22 - on your production server
293:24 - and then you know if you aren't logged
293:25 - in it's going to actually ask for
293:27 - credentials so let me log out just to
293:28 - show you what that looks like
293:31 - so now if we do a docker login you would
293:34 - then put in your username
293:37 - and i already messed that up
293:42 - and then your password so if you have if
293:44 - you are using a private repository
293:46 - make sure to do that on your production
293:48 - server so that your production server
293:49 - can actually access it
293:51 - but so we don't actually need it not a
293:53 - big deal because it's a public
293:54 - repository
293:56 - we got the image that our container is
293:57 - using so our container is using sloppy
293:59 - network slash node app
294:01 - we're checking if pull is needed so now
294:02 - it's basically querying docker hub
294:06 - and then it's going to do a few other
294:08 - things a few other things
294:11 - a few other things i guess with like
294:13 - authentication and a few other things
294:14 - like that
294:16 - uh right so then it says it's determined
294:18 - that there is a new image so it's going
294:20 - to do a pull so it's pulling the new
294:22 - image
294:23 - uh then it stopped our container it's
294:26 - deleting our container it's creating a
294:27 - brand new container
294:28 - it's then starting the new container
294:32 - right and then after 50 seconds it's
294:34 - going to do all of the
294:35 - same stuff over again
294:38 - all right so let's test this out so
294:41 - remember we we didn't do anything this
294:42 - was all automated
294:44 - so if i hit send
294:47 - you could see all the changes that got
294:48 - pushed out so we've automated
294:50 - that last final step in our development
294:53 - to production workflow
294:54 - where we pull the image into our
294:56 - production server and we're letting our
294:58 - production server automatically do it
294:59 - for us
295:00 - using this watchtower container and
295:03 - let's just test it out just to make sure
295:04 - that it works fully again
295:06 - so i'm just going to delete these
295:12 - i'm going to do a docker build
295:17 - and then let's do a docker push
295:26 - and you can see during the last run it
295:28 - said no new images were found so
295:30 - uh you know it's it's pretty smart at
295:31 - being able to detect when a new image
295:33 - gets pushed
295:34 - so let's give it another 30 seconds or
295:36 - so and we should see those changes
295:38 - get applied so right now we're still
295:40 - using the old image because we still
295:41 - have all those extra characters
295:44 - but once we see this update we should
295:46 - then be able to send a request and get
295:48 - the updated code
295:51 - all right so it ran so it looks like it
295:52 - updated so it's stopping our container
295:55 - give it a few more seconds to create a
295:57 - brand new container
296:01 - all right and so now it's good to go so
296:03 - let's test this out hit send
296:05 - and there we go
296:08 - now if you haven't already done so go
296:10 - ahead and delete that watchtower
296:11 - container uh we're not going to use it
296:13 - moving forward i just wanted to show you
296:14 - guys how you could automate that last
296:16 - step
296:17 - so just do a docker rm watchtower f
296:24 - now one of the things i want to talk to
296:26 - you guys about is our current
296:28 - workflow and that is you know whether
296:30 - you're using watchtower to
296:31 - do the pulling of the image and
296:33 - restarting in the container or if you
296:34 - mainly do it manually
296:36 - doing it yourself by doing a docker
296:37 - compose pull and then an up
296:39 - at the end of the day we have to
296:40 - recreate the container so we have to
296:42 - tear down
296:43 - our current container we have to build a
296:46 - brand new container with a brand new
296:47 - image
296:48 - and then start that container and during
296:50 - that window of tearing down and building
296:52 - up
296:52 - we are going to experience uh a network
296:55 - outage essentially we are going to
296:56 - experience
296:57 - our application being down right our
297:00 - app's going to be down
297:01 - until that new container gets built so
297:03 - we are going to experience loss
297:05 - uh with our production traffic and
297:08 - i was trying to see if there was a way
297:10 - we could achieve
297:11 - basically rolling updates with daca
297:13 - compose so that we could somehow
297:15 - do this upgrade process or push out new
297:18 - changes to our production server without
297:20 - experiencing any loss
297:22 - and going through a whole bunch of stack
297:24 - overflow responses
297:25 - there were some hacks that we could put
297:27 - together right we could really hack up
297:29 - docker compose
297:30 - to do a few things so that we can almost
297:31 - achieve something that's similar to a
297:33 - rolling update
297:34 - um but ultimately you know these were
297:37 - hacks
297:37 - these were nothing more than hacks and
297:39 - they were not recommended
297:40 - to be run in a production network right
297:43 - because remember docker compose
297:45 - isn't meant for that docker compose is
297:47 - not a container orchestrator
297:49 - it is not meant to provide you a way to
297:53 - implement rolling updates or anything
297:54 - like that like at the core of docker
297:56 - compose right remember
297:57 - docker compose is just nothing more than
297:59 - a file that maps out to
298:02 - different docker run commands right
298:03 - because a service is nothing more than a
298:05 - container
298:06 - which gets created with docker run so
298:07 - this docker compose file
298:10 - just gives us a way to basically write
298:11 - down all of our docker run commands
298:13 - within a yaml file and then when we do a
298:15 - docker compose up it just runs all of
298:17 - the docker commands for us so that we
298:19 - don't need to actually type them out
298:20 - ourselves
298:21 - so it's not an orchestrator so what are
298:24 - some options that we have
298:25 - to help us achieve you know lossless
298:28 - upgrades and
298:30 - rolling updates well we can use one of
298:32 - the popular
298:33 - uh container orchestrators that we have
298:35 - and one of those is kubernetes so that's
298:37 - one of the purposes of kubernetes so
298:40 - that's what we're going to do we're
298:41 - going to cover kubernetes in the next
298:42 - section
298:43 - and i'm just kidding just kidding guys
298:46 - there's no way we're going to cover
298:48 - kubernetes in this next section i don't
298:50 - want this video series
298:51 - to end up being a 40-hour tutorial so
298:54 - instead
298:54 - what we're gonna do is we're going to
298:56 - use a built-in
298:58 - container orchestrator that comes with
299:00 - docker and that is docker swarm
299:02 - and i know some of you guys are
299:03 - disappointed um because i know you guys
299:05 - want to learn kubernetes
299:06 - and kubernetes is the new kid on the
299:08 - block but
299:10 - the reason why i wanted to show you guys
299:11 - how to do this with uh
299:13 - docker swarm is because first of all we
299:15 - already have at our disposal
299:16 - it's very easy we don't really need to
299:19 - spend too much time going over the
299:20 - theory
299:21 - and the main the main idea behind why
299:24 - i'm even showing you guys how to do this
299:25 - with docker swarm
299:26 - is to just show you guys what is the
299:28 - purpose of a container orchestrator
299:31 - right because the idea behind this whole
299:32 - video tutorial series
299:34 - is not to show you how all of these
299:36 - tools work
299:37 - and all the ins and outs and all the
299:39 - flags it's to show you how you put all
299:40 - of these pieces together
299:42 - why we need a container orchestrator and
299:45 - what it ultimately helps us achieve
299:46 - right so that's why i kind of walked you
299:48 - guys through all of these steps instead
299:50 - of just starting out with docker swarm
299:51 - because
299:52 - i wanted to show you why we need a
299:54 - container orchestrator so in the next
299:55 - section
299:56 - we're going to get started with docker
299:57 - swarm uh we're not going to spend too
299:59 - much time going through the ins and outs
300:00 - of docker swarm we're just going to get
300:02 - something up and running
300:03 - and just show how we can implement some
300:04 - sort of rolling update so that we can
300:06 - push out changes
300:07 - to a production network without
300:08 - experiencing any loss or at least
300:10 - experiencing only minimal amounts of
300:12 - loss
300:14 - i want to quickly highlight some of the
300:15 - differences between docker compose and
300:17 - docker swarm
300:18 - and we already discussed some of the
300:19 - limitations with docker compose and that
300:21 - is that it's ultimately not a container
300:23 - orchestrator
300:24 - so it can't handle some of the more
300:26 - important life cycle
300:28 - uh events when it comes to spinning up
300:30 - and deleting containers and
300:32 - being able to do rolling updates and
300:33 - things like that that's something that
300:35 - docker swarm can handle
300:37 - right docker compose is a very simple
300:39 - tool it's actually meant to only be a
300:41 - development tool that we can use to kind
300:42 - of spin up containers and then delete
300:44 - them but it can't do much else
300:46 - and it certainly can't do things like
300:47 - rolling updates and another important
300:49 - thing about docker compose is
300:51 - uh we can only use it to deploy
300:52 - containers onto one server
300:54 - so if i wanted to be able to distribute
300:57 - my express containers you know maybe
300:59 - five or six of them
301:00 - across multiple servers so that if one
301:01 - goes down we'll have some redundancy
301:04 - with the other service being able to
301:05 - pick up the slack
301:06 - i can't do that with docker compose
301:08 - that's where docker swarm comes in
301:10 - docker swarm is an orchestrator right so
301:14 - there's more logic behind docker swarm
301:16 - docker compose can only run just a bunch
301:18 - of docker run commands right it's just a
301:20 - bunch of docker run commands
301:22 - that's listed out in a yaml format
301:24 - docker swarm has logic has brains
301:27 - it gives us the ability to you know not
301:29 - only spin up containers
301:30 - but we can distribute them across as
301:32 - many servers as we want
301:33 - so we've got 510 production servers we
301:36 - can spread them out across all of our
301:37 - servers
301:38 - we can handle the update process so if
301:40 - we need to
301:42 - push a new image to our production
301:43 - server dr schwarm can then
301:45 - uh basically spin up new containers
301:48 - update those containers and then only
301:50 - once we verify those containers are up
301:51 - and running
301:52 - we can then delete the old containers so
301:54 - it gives us
301:55 - a little bit more flexibility when it
301:57 - comes to our production
301:59 - environment and giving us some more
302:00 - tools that docker compose
302:02 - doesn't provide us and when it comes to
302:04 - docker swarm like i said
302:06 - you know docker swarm gives us a
302:08 - multi-node environment which means we
302:10 - can use multiple servers
302:12 - to deploy our applications we don't need
302:13 - to run everything all on one server
302:15 - and so each server within a docker swarm
302:19 - is referred to as a node and we've got
302:21 - two different kinds of nodes
302:22 - got measure node we've got a worker node
302:25 - i'm not going to go too much into the
302:26 - details of it but just you know
302:27 - you i think just based off of those
302:29 - names you have an idea as to what each
302:31 - one does but a
302:32 - manager node handles all the brains
302:34 - behind everything right
302:36 - the manager node is the one that pushes
302:38 - out tasks to the worker nodes and the
302:39 - worker nodes
302:40 - carry out those tasks so the control
302:42 - plane is going to reside on the managed
302:44 - nodes and the worker nodes just
302:46 - run tasks that it receives and keep in
302:49 - mind
302:50 - a manager node can be both a manager
302:52 - node and a worker node and i think
302:53 - that's what the default configuration is
302:55 - so
302:55 - uh that is something to keep in mind but
302:57 - in our in this video series we're just
302:59 - going to have one server
303:00 - so we're just going to use docker swarm
303:02 - to spin up one
303:04 - individual node that's both a manager
303:05 - node and a worker node to deploy our
303:08 - application
303:08 - and you might be thinking well if we're
303:10 - just using uh onenote is there
303:13 - potentially any reason why we not we
303:15 - don't just go for daca compose
303:16 - well first of all you know things like
303:18 - rolling updates those are things that we
303:20 - can't do with docker compose
303:21 - and docker compose ultimately is not a
303:23 - production-ready tool it's a development
303:26 - tool so you shouldn't be using it for
303:28 - your production environment unless it's
303:29 - for like some fun
303:30 - little home project or things of that
303:32 - nature
303:34 - so let's get started with setting up
303:35 - swarm in our production environment
303:38 - and like i said before docker swarm
303:41 - actually gets
303:42 - shipped with docker so when you install
303:43 - docker you already have dockers form at
303:45 - your disposal
303:46 - the only problem is it's disabled by
303:48 - default if you do a docker
303:50 - info it's going to let you know whether
303:51 - swarm is uh enabled or not
303:53 - and we can see here swarm is set to
303:55 - inactive so
303:56 - to enable swarm all we have to do is
303:59 - docker
304:00 - swarm init that's going to initialize
304:02 - swarm
304:03 - and we're going to get an error and it's
304:05 - basically saying that
304:06 - you know we've got multiple ip addresses
304:07 - we have to tell what ip address we want
304:09 - to use for swarm
304:10 - so it looks like digitalocean gives us
304:13 - two ip addresses
304:14 - uh one on ethernet zero one on ethernet
304:16 - one let's just grab the one with the
304:18 - public
304:18 - facing ip and then we just need to pass
304:21 - that into the advertise
304:23 - dash addr flag
304:26 - let me copy my public ip
304:39 - all right and so now it says swarm is
304:41 - initialized and
304:42 - it defaults us into being a manager and
304:45 - keep in mind when you're a manager
304:46 - you're also
304:47 - a worker by default and if we wanted to
304:49 - add
304:50 - more nodes into the swarm
304:53 - uh the it provides us two commands so
304:55 - this command is going to
304:57 - allow us to add a new node into our
304:59 - swarm as a worker node
305:01 - and then this command down here is going
305:03 - to give us
305:04 - is going to allow us to add a new node
305:06 - into the swarm as a manager node
305:08 - but like i said we're going to stick
305:09 - with just one node for now just to keep
305:11 - things simple
305:16 - and you'll see that you know docker
305:18 - swarm is very similar to just doing
305:20 - regular docker commands like docker run
305:23 - docker create and things like that so if
305:25 - i do a docker
305:27 - help you'll see all the commands that we
305:31 - have so we can do docker create which is
305:32 - going to create a container
305:34 - we can do docker rm to delete a
305:37 - container
305:38 - you can do docker update to update the
305:41 - configuration for a container
305:43 - you got docker stop which is going to
305:44 - stop a container well
305:46 - docker's form isn't really any different
305:48 - right except instead of working with
305:49 - containers
305:50 - it works with services and a service
305:52 - remember is pretty much just a container
305:55 - so you'll see that there's a lot of
305:57 - similarity between docker containers
305:59 - just running individual docker
306:00 - containers and running
306:02 - swarm services so if i do a docker
306:06 - service so this is how you get access to
306:08 - all of the swarm related commands
306:11 - and i just do help you'll see the
306:14 - options we have so we have docker
306:15 - service create right very similar to a
306:17 - docker create which creates a container
306:20 - we have ls which is going to list out
306:22 - all the services we can delete a service
306:24 - and then a lot of the orchestration
306:26 - takes place with the rollback so you can
306:28 - you know revert changes
306:29 - you can scale up the number of instances
306:31 - for a service and then we can update
306:33 - specific details about a service so
306:35 - i just really wanted to highlight that
306:36 - you know there's nothing really that
306:37 - much different between docker swarm
306:40 - and just running regular docker commands
306:42 - and so we can do all the things we want
306:44 - to do
306:45 - by just running docker service commands
306:47 - however that's a little tedious
306:49 - just like running all of the docker run
306:50 - commands it's hard to remember all the
306:52 - necessary flags and things like that so
306:54 - if you remember or you recall when we
306:57 - wanted to kind of automate all of our
306:59 - docker run commands
307:00 - we just put all of our docker run
307:02 - configurations into a compose file
307:04 - and the nice part about docker swarm is
307:06 - that we can do the same exact thing
307:08 - we can put all of our configurations
307:09 - within a compose file
307:11 - and what's even nicer is that we get to
307:13 - use all of the
307:14 - we can use our compose files that we
307:16 - already have so we can use
307:18 - everything that we have already
307:19 - pre-configured and we could just add in
307:21 - a few extra fields that are swarm
307:22 - related
307:24 - so let's pull up the documentation to
307:26 - see the specifics form-related configs
307:29 - so if you go to the reference section
307:32 - under docker compose and just search for
307:35 - the deploy section this is going to give
307:37 - us a lot of the options that are
307:38 - specific to docker swarm uh it's going
307:42 - to give us all the information that we
307:43 - need
307:45 - and so skip endpoint mode that doesn't
307:47 - matter labels doesn't matter
307:49 - placement doesn't matter here's the
307:51 - first
307:52 - flag or option that we can add to our
307:54 - compose file that's a little bit
307:55 - interesting which is
307:56 - replicas so here the replicas defines
307:59 - how many instances of a specific service
308:01 - you want to
308:02 - run so if i set replicas to six like in
308:05 - this example for my node app
308:07 - service it's going to give us six
308:09 - containers so
308:10 - as our uh application demand grows
308:14 - we can just spin up more and more
308:16 - containers by increasing the number of
308:17 - replicas
308:19 - right there's a resources section where
308:20 - we can kind of constrain the resources
308:22 - that each
308:23 - you know container can use we're not
308:25 - going to do much uh
308:26 - regard with regarding that restart
308:29 - policy this is going to determine you
308:31 - know when and how we restart container
308:32 - you know if it crashes should we restart
308:34 - it
308:34 - if solo if so how long should we wait so
308:37 - let's add restart policy as well as
308:39 - replicas uh to our configuration
308:41 - so under our prod file because we only
308:44 - want to run
308:45 - compose sorry we only want to run swarm
308:47 - within our prod environment we don't
308:49 - actually want to run it in our
308:50 - development environment because in our
308:51 - development environment we can just use
308:52 - docker compose that's perfectly okay
308:55 - so let's go to our prod under node app
308:57 - we'll just add a section called
308:58 - deploy and then let's add
309:02 - in well first of all let's add replicas
309:06 - and let's set it to eight and then for
309:09 - our restart policy
309:12 - we can add a condition of any so we're
309:14 - going to restart it for any reason it
309:15 - goes down
309:33 - and we can set a delay between each
309:36 - restart attempt but i don't really care
309:38 - about that
309:39 - now this is where things get interesting
309:41 - rollback config and update config
309:43 - so let's go to the update config section
309:45 - this is kind of what we're most
309:46 - interested in because we're trying to
309:48 - create
309:48 - a way to update our application without
309:52 - experiencing any loss
309:54 - and so this section just tells you you
309:55 - know how do we configures how the
309:57 - service should be updated
309:58 - so useful for configuring rolling
310:00 - updates so this is exactly what we need
310:01 - this is
310:02 - kind of the real reason we wanted to go
310:04 - to docker swarm
310:05 - so here we have this flag called
310:07 - parallelism so this just sets the number
310:09 - of containers to update at a time so if
310:10 - you have eight containers and we gotta
310:12 - update the image of all eight
310:13 - what it's gonna do is if we set
310:14 - parallelism to two it's going to update
310:17 - two containers
310:18 - at a time so you know we can run two
310:21 - and then if at once those two are up
310:23 - we'll then move on to the next two
310:24 - containers
310:25 - and then the next two so uh you know
310:27 - when two containers go down the other
310:29 - six just pick up the slack until it
310:30 - comes back online
310:32 - the delay is a time to wait between
310:34 - updating a group of containers
310:36 - then we have a failure action so what
310:38 - should we do if an update fails we can
310:39 - either continue rollback pause
310:42 - and the default looks like it's pause
310:44 - maybe we want to do rollback if it fails
310:46 - so that it automatically rolls back for
310:49 - and then you can also set the order so
310:51 - there's a few other properties but
310:53 - let's just set up parallelism and delay
310:55 - for now
311:14 - we're going to set that to 2 and we'll
311:15 - set the delay to be 15 seconds
311:24 - and then there's a few other flags that
311:26 - you can probably search for but that's
311:28 - all we really need for docker
311:30 - for docker swarm you can see how easy it
311:32 - is to integrate it into your docker
311:34 - compose workflow we just had to add a
311:36 - couple of properties and we're good to
311:37 - go
311:39 - so we made a few changes uh to our
311:42 - docker compose file so we have to
311:43 - actually push these changes
311:45 - to our production server so we have to
311:47 - do a commit and get and then do a git
311:49 - push so
311:50 - i do a git add and then we'll do it
311:54 - again commit
312:02 - and then we'll do a git push
312:06 - right then in our production server
312:09 - i'm going to do a git pull
312:16 - so now we have the updated docker
312:18 - compose file
312:19 - and so now let's actually deploy it so
312:21 - first of all um
312:22 - if we do a docker ps it looks like we
312:24 - still have all of our containers that we
312:26 - deployed using docker compose so let's
312:28 - let me see if i can find that docker
312:30 - compose command right here
312:32 - up we'll just change that to down so we
312:33 - can delete everything
312:38 - all right so everything's down so now to
312:40 - deploy
312:42 - you know our application using docker
312:45 - swarm
312:45 - there's a command called docker
312:52 - and then stack so docker stack is how we
312:54 - actually use that
312:55 - and let's do the dash dash help and see
312:57 - the options we have and there's
312:58 - something called deploy so
312:59 - that's probably what we want so let's do
313:01 - that
313:05 - and let's see what options we have not
313:07 - many options
313:08 - but there is this compose file so we
313:10 - have to pass in the name of the compose
313:11 - file
313:12 - and so just like we did when we did
313:14 - docker compose we have to pass in both
313:16 - of our compose files
313:20 - but instead of using dash f we have to
313:21 - use dash c in this case
313:25 - and then let's do a dash dash help again
313:28 - and
313:29 - we want to do a that's about it actually
313:33 - so we have to well actually we have to
313:34 - give it a stack name
313:36 - so a stack name is just a name of your
313:38 - application right so
313:39 - when we create this stack which is i
313:41 - guess think of it as like
313:43 - all of your services bundled together
313:44 - what do you want to give it what do you
313:46 - want to name it as i'm just going to
313:47 - call it my app
313:52 - let's deploy that and so you can see
313:53 - it's creating all of our services so
313:55 - actually creates a network just like
313:56 - docker compose
313:57 - and then it's going to create our four
313:59 - different services
314:01 - and some docker commands or some docker
314:03 - swarm related commands you can do a
314:04 - docker node
314:05 - ls this is going to list out all of the
314:08 - nodes within our docker swarm and so you
314:10 - can see here
314:11 - this is this specific node we only have
314:13 - one node in this case
314:16 - if you do docker stack ls it's going to
314:18 - list out all of your stacks we just have
314:19 - one stack
314:20 - called myapp if we do a docker stack
314:26 - and then let's do help
314:31 - we can list out all the services in a
314:33 - stack so let's do docker stack
314:36 - and then services and then we call my
314:38 - app
314:39 - and it's going to list out the four
314:41 - different services so you can see
314:43 - the different uh images this is the
314:44 - equivalent of doing just like a docker
314:46 - ps
314:47 - right so we see you know the container
314:49 - name or the container id
314:51 - the name it's given how many times it's
314:53 - replicated so we only have one
314:55 - container and then what image it's using
314:57 - if you take a look at our node app
314:59 - container we have eight of them so we
315:01 - have eight
315:02 - individual containers for that and we
315:03 - can verify that by doing a docker ps
315:06 - and you can see most of these are node
315:08 - app containers
315:10 - eight of them specifically if you want
315:13 - to list out all of the services
315:15 - across all stacks you could do docker
315:16 - service ls however keep in mind we only
315:19 - have one stack so we see the same exact
315:21 - output as we saw before
315:23 - all right now we can also list out tasks
315:26 - right
315:26 - and i guess i didn't really go over a
315:28 - task but when it comes to
315:30 - creating a new service updating a
315:32 - service deleting a service
315:34 - docker swarm generates a task and then
315:36 - it pushes that task out to a worker node
315:38 - so that the worker then can actually
315:40 - perform that task
315:41 - so if i do a docker service
315:45 - sorry docker stack
315:50 - ps and then we let's do dash dash help
315:53 - and then we pass in the stack name it
315:55 - looks like so doctor psn so this is
315:56 - going to list out all of the
315:58 - tasks for my stack so it's going to be
316:00 - called my app
316:02 - and you can see all of the tasks that i
316:04 - created
316:06 - all right and so you could see a task
316:08 - out generated for each one of these
316:09 - containers so it looks like it's to
316:11 - provision
316:12 - uh all of our containers
316:15 - all right so now let's go ahead and make
316:18 - a change to our application and see if
316:20 - we can update
316:21 - our production server with those changes
316:23 - but with a
316:25 - rolling update methodology using docker
316:27 - swarm so that
316:28 - we experience minimal to no loss
316:32 - and so if i just first of all actually
316:34 - let's just double check to make sure our
316:35 - application still works
316:37 - and so here we got a response and we can
316:39 - see it says hi there
316:41 - let's go back to our code and i'm going
316:44 - to add some more exclamation points
316:47 - and a few other things let's save that
316:57 - in this case we want to do a build for
316:59 - our node app so we build a brand new
317:01 - image with those changes
317:05 - and then we want to do a push of our
317:08 - node app
317:09 - so we push it to docker hub
317:16 - all right and so now let's go to our
317:17 - production server
317:24 - and i'm just going to keep hitting the
317:25 - what happened there
317:31 - let's find that docker stack deploy
317:33 - command so let's see if we just run this
317:34 - again
317:35 - if it's able to pick up those changes
317:40 - and so it looks like it's updating our
317:42 - services so let's see
317:43 - docker stack ps
317:46 - node app sorry not node app my
317:50 - app it's going to list out all of our
317:53 - tasks
317:55 - and look at what's happening here it
317:57 - looks like we shut down
317:58 - two of our containers right and that's
318:00 - because of our parallelism right
318:02 - so if we go to dockercompose.yaml
318:06 - actually.prod.yml you can see we should
318:07 - only update two at a time
318:09 - and then after it's been updated we'll
318:10 - wait 15 seconds and then we'll wait for
318:12 - the next two
318:12 - so if i take a look at this and run this
318:14 - again to see all of our tasks
318:16 - you can see we now have what one oh
318:19 - sorry one
318:20 - two three four so two more of them got
318:23 - shut down and two new ones were created
318:25 - so let's then run this again
318:30 - and we should see two more
318:33 - and so there's just a couple more of our
318:35 - original eight containers that need to
318:36 - get updated so you can see it's just
318:37 - doing two at a time
318:39 - and while it's updating right now if i
318:40 - send it right you can see
318:42 - it's been updated for some of them let
318:44 - me see if i can hit one of them right
318:46 - and so i can hit one of them that hasn't
318:47 - been updated
318:48 - but it looks like most of them have been
318:50 - updated oh it looks like we
318:52 - received an error um like i said even
318:55 - with
318:55 - a orchestrator doesn't guarantee that we
318:57 - won't have
318:59 - no downtime but you can see this greatly
319:01 - minimized it
319:05 - and then let's try this again
319:09 - and we can see that for each one of our
319:12 - eight
319:14 - containers we had a previous task where
319:17 - we shut it down and then we have the new
319:18 - one
319:19 - that we're running and if i push these
319:22 - changes out again so if i do this whole
319:24 - process one more time delete this
319:29 - we'll do the same two things we'll do a
319:30 - build
319:34 - and then we'll do a push
319:43 - and then we can do a stack deploy we
319:45 - don't need to pass in any other
319:46 - arguments
319:47 - it'll check with docker hub to pull the
319:49 - latest image
319:53 - and so now if i do a ps my app um you
319:56 - can see that
319:56 - there's two of them that have been shut
319:58 - down so uh it's gonna do two at a time
320:00 - like i said and let's just
320:02 - run this again so you can see i get the
320:05 - exclamation still for
320:07 - a lot of the requests some of them i
320:08 - don't though because like i said two of
320:10 - those containers have already been
320:12 - changed and then by now it's probably
320:13 - four
320:20 - and eventually if i just keep doing this
320:22 - after about it's probably going to take
320:24 - about a minute
320:25 - but let's run this again
320:29 - and you can see most of them have
320:30 - already been changed
320:39 - all right so it looks like all of our
320:40 - containers have been updated we can
320:42 - verify that by just running this again
320:45 - and you should see that each one should
320:47 - be up in a running state after the
320:49 - previous one got shut down
320:51 - and so that's pretty much all i have for
320:53 - you guys for this video series
320:55 - hopefully you guys have a better
320:56 - understanding of how docker works and
320:58 - how we can
320:59 - develop a node and express applications
321:02 - using docker and how we can move from a
321:04 - development environment to a production
321:06 - environment and i really did want to
321:08 - emphasize
321:09 - a lot of the challenges that you face
321:11 - when going from development to
321:12 - production because
321:14 - docker it was created to simplify that
321:16 - process but even with docker there's
321:18 - still going to be plenty of challenges
321:20 - and so now that you guys have a basic
321:22 - understanding of how all of this works
321:24 - you know you can kind of take some of
321:25 - the ideas that i've taught you and kind
321:27 - of tweak it so that you can build your
321:28 - own
321:29 - uh development to production workflow
321:31 - obviously in this video
321:33 - i didn't cover anything with regards to
321:34 - you know building out like a ci cd
321:36 - pipeline
321:37 - uh that would be the logical next step
321:39 - so i'll probably make a
321:41 - video series showing you how we can
321:43 - actually build a full ci cd pipeline for
321:45 - a docker based application
321:48 - but i think this is a good starting
321:49 - point for people that just want to get a
321:51 - little bit more familiar
321:52 - with you know deploying apps and as well
321:55 - as getting familiar just with docker in
321:58 - general