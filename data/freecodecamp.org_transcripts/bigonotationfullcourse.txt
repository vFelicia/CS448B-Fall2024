00:00 - Big O notation is used to classify algorithms 
based on how fast they grow or decline. It is  
00:07 - very important to understand for many types of 
programming, Giorgio Thompson does a great job of  
00:12 - breaking down big O notation in this course. Hey, 
what's up everybody and welcome to my mini series  
00:17 - on big O notation. And this mini series, you'll 
learn everything that you need to know about big  
00:22 - O notation and how you can use it to improve 
your ability to create efficient algorithms.  
00:26 - I'll use whiteboard illustrations to help you 
visualize and understand concepts followed by  
00:31 - coding tutorials that you can follow along with 
to further solidify your grasp of the concepts  
00:36 - will answer the question what is big O notation? 
And why is it useful? So what is big O notation?  
00:42 - Big O notation is used to analyze the efficiency 
of an algorithm as its input approaches infinity,  
00:48 - which means that as the size of the input to the 
algorithm grows, how drastically do the space or  
00:53 - time requirements grow with it. For example, 
let's say that we have a dentist and she takes  
00:58 - 30 minutes to treat one patient. As her line of 
patients increases, the time that it takes for her  
01:03 - to treat all of the patients will scale linearly 
with the number of patients waiting in line.  
01:09 - This is because it always takes her a constant 
amount of time to treat each individual patient  
01:14 - which is 30 minutes. This gives us a general 
understanding of how long our dentist would  
01:19 - take to treat 10 patients 20 patients or even 
100,000 patients. This is because since we  
01:25 - know that the dentist takes a constant amount of 
time, which is 30 minutes to treat each patient,  
01:30 - we can always calculate the time it would take for 
her to treat any number of patients by multiplying  
01:35 - the number of patients times 30 minutes. With this 
in mind, we can categorize her efficiency as being  
01:41 - linear. Or as we would say in Big O terms big O 
of n, where n is equal to the number of patients  
01:48 - the time that it takes for her to finish her 
work scales linearly or proportionally with the  
01:53 - number of patients, we use the same technique 
to determine the efficiency of algorithms,  
01:59 - we can get a general idea of how functions 
time efficiency scales by categorizing a given  
02:04 - functions efficiency the same way that 
we categorize the dentist's efficiency.  
02:09 - Let's create an easily comprehensible 
function that scales similarly to the dentist.  
02:15 - So this function is in the same linear category 
as our dentist, let's step through it and find  
02:20 - out why. To start the input to our function 
is an array with seven items inside of it.  
02:26 - For each of those items, we will log this 
expression which multiplies 1000 times 100,000.  
02:32 - Now don't let these large numbers for you, it will 
always take the same amount of time to multiply  
02:37 - 1000 times 100,000. Therefore this line of code 
takes constant time. Which brings me to a very  
02:43 - important point, when considering the efficiency 
of a function. These lines that take constant time  
02:48 - do not matter. Well, at least for our purposes, 
they don't. This is because if our array were  
02:54 - some crazy length, like 200 million, changing this 
expression to something simpler, like one plus one  
02:59 - would have a negligible effect on the efficiency 
of the function as a whole, we'd still need to  
03:05 - iterate through 200 million items in an array. 
In fact, even if the function looked like this,  
03:11 - we would still ignore all of these constants 
and say that this function scales linearly or  
03:16 - is big O of n. Similarly, if we think back to 
our dentist example, we see that she took 30  
03:23 - minutes per patient. But even if she took three 
hours per patient, the amount of time it takes  
03:28 - her to see all of her patients will still scale 
linearly. This can be difficult to grasp at first,  
03:33 - but it starts to make sense over time. So in the 
last slide, there was a lot of talk about ignoring  
03:39 - the constants. But what exactly is a constant? A 
constant is any step that doesn't scale with the  
03:45 - input to the function. For example, the time to 
evaluate this expression does not change with the  
03:51 - input because both 101,000 are constants. That is, 
these values are always the same, this expression  
03:59 - always results in the same value. And it always 
takes the same amount of time or constant time  
04:04 - to return the same result. Just like we use big O 
of n to describe linear functions. We also have a  
04:10 - big O name for constant algorithms, which is 
big O of one. A good way to think about it is  
04:16 - every line of code is actually a function in and 
of itself, which is actually true. For example,  
04:22 - let's reintroduce this function. So this line 
of code is the reason why the entire linear func  
04:28 - function is O of n because as you can see as the 
size of n increases the number of iterations that  
04:34 - the for loop must traverse increases as well. But 
let's take this second line into consideration.  
04:39 - Let's for one second pretend that we have a 
function that contains only this line. Now as you  
04:45 - can see, with this function, we pass in an array, 
but the function does nothing with the array.  
04:51 - The only operation within the function is constant 
because it doesn't scale with any input. So  
04:56 - regardless of how large of an array is passed to 
this function, This line always produces the same  
05:01 - result. And this is the only line in the function. 
So therefore, this entire function is over one.  
05:07 - But wait. In this function, we have multiple 
lines that are over one yet we still prioritize  
05:12 - the line that is O of n and ignore the O of 
one operations. Why is this? Well, this brings  
05:18 - us to our last important note, in bego, we have a 
growth hierarchy, which looks something like this.  
05:24 - Now, don't panic, you don't need to understand all 
of these just yet. So let's only pay attention to  
05:30 - the ones relevant to this video, or even an old 
one. We'll learn about the other ones in following  
05:36 - videos for this series. This chart shows the 
efficiency categories in order from good to bad.  
05:42 - That is to say that this first case of one is the 
best case. And this last one is the worst case. In  
05:49 - big O notation, when determining the efficiency of 
an algorithm, we only care about the worst case.  
05:55 - So that means that the worst case where the 
highest order operation trumps the operations  
06:00 - that have better performance. So if we add the 
performance of all of these lines up, like so  
06:10 - all of the lines of code that are o of 
one get cancelled out because oh Vin is  
06:14 - the worst performing or highest order part of 
the function. And this, ladies and gentlemen,  
06:19 - is why we ignore constants, because we're actually 
just eliminating the non dominant items. Because  
06:25 - as a functions, input moves towards infinity, 
constants become less and less significant.  
06:31 - So to recap, when evaluating an algorithms 
efficiency, we must take into consideration  
06:37 - the efficiency of each step within the algorithm, 
we then find the highest order step, or the step  
06:43 - that has the worst performance, and prioritize 
it over all of the better performing steps,  
06:48 - steps that are constant, or that are over one 
or as good as it gets in terms of efficiency.  
06:54 - So we always ignore them, unless the 
entirety of the function is constant,  
06:58 - or o of one. And in that case, we would 
categorize the entire function as constant  
07:03 - or o of one. And that Ladies and gentlemen, 
is your answer to what is big O notation.  
07:18 - Okay, so to understand O of n square, we're going 
to need to take the function into consideration  
07:25 - in the function will look something like this. So 
what this function is doing is it's going to take  
07:31 - in a number in and it's going to iterate through 
this for loop starting with the number zero  
07:39 - all the way up until the number in and 
for every iteration of this top for loop,  
07:44 - we're also going to loop through this 
nested for loop. And this nested for loop  
07:49 - is doing the exact same thing that this for loop 
is doing. It's iterating through every number,  
07:54 - starting with zero up until the number in and 
within this nested for loop, we're console logging  
08:00 - the coordinates for a sell within a matrix. But 
to make things clear, instead of illustrating a  
08:06 - console log of the index i and j, I'm just going 
to draw a square where these coordinates should be  
08:12 - for every iteration of this nested for loop. So 
if it sounds confusing, just try to bear with me,  
08:17 - I promise it'll become clear. Okay, so let's say 
for example, that we call the square function with  
08:26 - the number four. So that means that we're going 
to iterate through this top for loop starting with  
08:31 - starting from zero, and then we're going to 
iterate all the way up until I is no longer  
08:36 - less than four, once I becomes equal to four, 
then we will stop the iteration. And then that's  
08:41 - only for this top for the for each iteration of 
this actual for loop, then we're going to loop  
08:45 - through the entirety of this nested for loop and 
do this console log. And instead of logging the  
08:50 - coordinates, like I said, we'll draw a square 
where the coordinates would be, so you guys can  
08:54 - visualize this better. So let's go ahead and get 
started. So for the first iteration, is going to  
08:58 - equal zero, and then we move on into this nested 
for loop. And then we're going to iterate through  
09:03 - the entirety of this nested for loop. So right 
now i and j are zero, so i and j are both zero.  
09:10 - So we're currently at the first iteration of this 
for loop in the first iteration of this for loop,  
09:14 - and we'll draw a square and then we move up one 
iteration of this for loop, so j becomes one and  
09:19 - we'll draw another square. And then j becomes two, 
it will draw another square and then j becomes  
09:25 - three, and we'll draw another square and now j is 
four. And since j is four, that means that j is no  
09:32 - longer less than n, because n is four, and j is 
four, and n is four. So j, and n are now equal,  
09:39 - so will no longer iterate through this for loop. 
So now we go back up to this for loop. And now  
09:45 - I is equal to one, so i is equal to one, and 
j is equal to zero, so we'll draw a square and  
09:52 - then i is equal to one is in j is equal to one 
so we'll draw a square and then i is equal to  
09:57 - one and j is equal to two. So draw a square and 
is equal to one and j is equal to three, it will  
10:04 - draw a square. And now back to this top for loop 
again, because j and n are now equal, we're back  
10:11 - up to this top for loop again, now i is equal to 
two, so i is equal to two, and j is equal to zero,  
10:17 - so we'll draw a square and then i is equal to 
two, and j is equal to one, so we'll draw a square  
10:24 - and i is equal to two, and j is equal to two. 
So we'll draw a square and i is equal to two,  
10:31 - and j is equal to three, so we'll draw a square 
and then now j is equal to four, which is our in,  
10:37 - so will no longer iterate through this nested 
for loop, and we move back up to the top of this  
10:43 - for loop, now, i is equal to three, i is equal to 
three at this point, and j is equal to zero again,  
10:49 - so we'll draw square is equal to three and j is 
equal to one. So we'll draw a square j is equal to  
10:56 - two, j is equal to three. And then j is equal to 
four. So we no longer iterate through this nested  
11:02 - for loop. And at this point, our i is now equal to 
four and our n is also equal to four. And we only  
11:09 - iterate through this top for loop as long as r is 
less than in but our eyes now equal to our in. So  
11:16 - now we stop iterating through this top four loop. 
And what we're left with is this matrix here. And  
11:22 - the reason why I said that these are coordinates 
for cells within a matrix is because this here  
11:30 - is a matrix. And these are rows. And these  
11:38 - are columns. So we can look 
at AI, as being our column.  
11:47 - And then we can look at j is being row. So for 
each iteration 0123 of our column, we also have an  
11:56 - iteration for row 0123. So coordinates being zero, 
and zero, were the coordinates for this square,  
12:05 - and then zero and one are the coordinates for this 
square, and zero, and two are the coordinates for  
12:11 - this square, and so on, and so forth. So what does 
all this have to do with oben square? Well, hey,  
12:17 - just one quick interruption. If you are finding 
this video helpful, or it's bringing you to some  
12:22 - type of understanding, please take the time 
to like and subscribe. If we think about it,  
12:27 - this is a square matrix, that is each side will 
be of the same length. And by length, I mean 1234.  
12:39 - This is of length four, and 1234. And this is of 
length four, and to find the area of a square,  
12:53 - we just need to multiply the 
length of one side by itself,  
12:56 - because every side of a square is of the 
same length. So if this were a rectangle,  
13:02 - we would multiply the width times the height, but 
for square, we can just multiply by itself because  
13:09 - the width and the height will be the same 
length. So to get the area of this square,  
13:17 - we're just going to multiply four times four,  
13:22 - four times four. And that's going 
to equal the number of cells  
13:31 - within this matrix, which also happens to be the 
number of times that we had to perform this code,  
13:37 - which is four times four is 16. And four 
times four is the same thing as four square.  
13:45 - So O of n square, our n is actually four.  
13:54 - And that is why typically functions with nested 
for loops, like a for loop and a for loop nested  
14:00 - within it like this function is considered 
over in square. I hope that makes sense.  
14:12 - Okay, so to understand all of in queue, let's take 
a function into consideration. This cube function  
14:21 - takes in an argument in which is a number. And 
it's going to iterate through this for loop and  
14:28 - for every iteration of this for loop is going to 
iterate through the entirety of this for loop. And  
14:35 - for every iteration of this for loop, we will need 
to iterate through the entirety of this for loop.  
14:41 - And I'm going to have to apologize ahead of 
time for my disappointing drawing skills.  
14:46 - But to illustrate this, I'm actually going 
to have to draw three dimensional shapes,  
14:51 - which is not something that I'm entirely good 
at But anyways, for now, let's just ignore this  
14:56 - image. For now. Let's focus on this function. 
So for the top level for We're going to be  
15:01 - iterating up until in. So 
if we pass the number four  
15:08 - to our cube function, we'll end up here 
at this first for loop. And we're going  
15:13 - to iterate starting from zero all the way up until 
n, which is four. So let's get started. So for our  
15:19 - first iteration of this top level for loop, I is 
going to be zero. Now for all the in cube, we're  
15:27 - adding in additional nested for loop. So there's 
no longer just a row and a column. Now we have  
15:34 - rows, columns. And we also have this third 
dimension here, which we'll just call height.  
15:49 - So we have the columns that go in this direction, 
the rows that go in this direction, and the height  
15:56 - that go in this direction. So at this point, 
we're working with a three dimensional array,  
16:01 - it's no longer a two dimensional array. And it's 
the same concept. So it's not as difficult as it  
16:08 - seems, we're going to draw it out now. So we 
would start with this initial for loop, and is  
16:14 - going to start off as zero, right. And we'll say 
that this initial for loop is representative of  
16:21 - our columns. So we can actually go ahead and write 
these numbers out just so you guys can see. So  
16:28 - we'll say that when I zero, this column is zero. 
When I is one, we're talking about this column.  
16:36 - When I say two, we're talking about this column, 
and one is three, we're talking about this column.  
16:43 - And of course, once I becomes four, we're 
no longer going to iterate through this for  
16:48 - loop because I is then no longer less than 
n, which is four, it will be equal to four.  
16:54 - And we can say the same thing for the rows. 
So we would say that row zero would be here,  
17:00 - row one would be here, row two would be here, 
and row three would be here. Now I apologize  
17:05 - if this is difficult for you to see, it's three 
dimensional. So it's not really easy to draw this,  
17:11 - but I hope that you guys can visualize what 
I'm trying to say. And then the same thing  
17:14 - for the height, the height would be represented by 
this for loop here. So okay, and let's actually,  
17:20 - I'm sorry, I should, I should actually just name 
these by the letter that we're using in the actual  
17:25 - function. So instead of calling this height, 
we'll call this K. Because it's representative,  
17:31 - this this for loop is represented as representing 
k here, so we'll just call this k as well.  
17:38 - And instead of calling this columns, we'll 
call it AI. And instead of calling this rose,  
17:48 - we'll call it J. So for every iteration of this 
for loop, we're going to be moving up this k  
17:56 - axis. So if we were to write in what the index 
is for K, it's going to kind of be hard to  
18:03 - see right now. But it will be 012. And 
three, so let's try to draw this out.  
18:14 - So let's do this step by step 
for a little bit to get you guys  
18:17 - understanding what's happening. So for this first 
iteration of this top level for loop, is going to  
18:22 - be equal to zero. So that means that I, this line, 
we're going to be here at the zero index of I.  
18:30 - And then for this nested for loop, J is also going 
to be equal to zero. So j is here. And we're going  
18:37 - to be at zero here. So we're still going to be 
here. And for K as well, this for loop here.  
18:45 - This x is here, we're also going to be at zero, 
which is here. So we're still going to be here.  
18:51 - So instead of console logging these coordinates, 
we'll just draw a square for this coordinate.  
18:57 - So this coordinate is 00, and zero, and 00, 
and zero, so we'll just draw a square here.  
19:08 - And again, you're going to have to excuse my poor  
19:12 - square drawing prowess. And since we continue with 
K until K is no longer less than n, we're going to  
19:19 - continue to iterate through this for loop. So to 
help you guys out, I can just tell, I can just  
19:24 - write I right now is equal to zero, J right now 
is equal to zero and K. It was equal to zero,  
19:32 - but we just do the square for K at zero. So now K 
is going to iterate it's going to increment one.  
19:40 - So K is now going to be equal to one. So when k 
is at one, and j is at zero, and is at zero, so  
19:48 - i j. k is at one, then we're going to go up 
another square and this is going to be kind of  
19:56 - hard to see because I'm literally trying to 
draw three dimensional space Whereas here  
20:00 - and I'm just like terrible at drawing, 
I'll do my best. Give that one more go.  
20:08 - Okay, so once we do that k increments one, 
so K is now two, two is here, and then  
20:16 - i and j are still zero, so we're still going to 
be at j here. So we're still going to be in this  
20:23 - section. So we'll draw another two dimensional 
square here. I mean, two dimensional cube, excuse  
20:32 - me, if I call a cube square, that's definitely 
not right cube. So there's another cube. And of  
20:39 - course, K is going to increment again. So then K 
is going to become three. And then at three here,  
20:46 - we'll drill another square, I mean, cube, sorry. 
And at this point, K is going to increment.  
20:58 - And then it's going to be equal to four. And 
once k is equal to 4k is no longer less than n,  
21:05 - because n is also four. So now k is equal 
to n. So this world is done. And now we  
21:10 - move up to this for loop. And this for loop will 
increment one and j will then be equal to one,  
21:17 - because for each iteration of this for loop, we 
go through the entirety of this for loop. So we've  
21:21 - gone through the entirety of this for loop. So 
now we can move up one iteration in this for loop.  
21:26 - And we can't move back up to this for loop until 
we iterate through everything within this for  
21:32 - loop. So we're still on so we're only incrementing 
the row and then we're going back into iterating  
21:38 - K. So now that j is equal to one is still zero, so 
we're still here, we're still here, because this  
21:45 - is the column and then I still zero, this is I and 
I still had zero. And we're still here, but j went  
21:53 - from zero to one. So now we're here. So we're back 
into k, and k is going to start off zero again.  
22:01 - So at I being zero, J being one 
and K being zero, because zero,  
22:07 - okay, this is K, and this is zero. 
And we're here we'll draw a square.  
22:18 - Sorry, once again, I said square Yeah, we'll 
draw q 10k increments. We'll draw another cube.  
22:30 - And then k increments, and we draw another cube.  
22:38 - And then k increments. 
Individual one more Q, because  
22:47 - once k reaches four, so yeah, K, okay, we'll 
increment one more time, and it'll reach four.  
22:52 - And now K is no longer less than in. So we go back 
up to RJ for loop, and that will increment one.  
23:01 - So this one will now become two. And it's pretty 
much the same thing. Throughout the entire  
23:12 - throughout the entire function, and it's 
getting hard to see the cubes that I'm  
23:16 - drawing here. But eventually, we'll 
get to a point where the entire cube  
23:23 - is filled in, which will look something like this.  
23:40 - So we'll get to a point where the entirety of this 
cube would be filled with these miniature cubes,  
23:46 - which are just the iterations of these 
four loops. So once we get to that point,  
23:55 - and thank you cube is completely filled in. At 
that point, that means that we have iterated  
24:07 - through the entirety of this top level for loop. 
And feel free to take the time to try and draw  
24:13 - this out on your own. But I basically went through 
as much as I could with the time that I have in  
24:17 - this video, but it's pretty much the same thing 
until the entirety of the cube is filled. So once  
24:23 - all these four loops have completed, you'll 
be left with the cube that looks like this.  
24:28 - And since this is a cube, that means that 
its height, and its length, and its width,  
24:37 - are all going to be of the same length. And 
that is to say that they're all going to be in  
24:44 - because if you look here we 
went through in iterations of J.  
24:52 - We went through iterations of AI 
And we went through in iterations  
25:05 - of K. And again, I'm sorry, for my poor drawing, 
I hope that you get the idea. So if n is four,  
25:14 - this is going to be four, this is going 
to be four, and this is going to be four.  
25:19 - And to get the volume of this cube, to get 
the volume, the space within this cube,  
25:26 - since we know that all of these are going to 
be the same, we only need to know one of them.  
25:34 - And one of them to get the volume we just do 
for this case for cube, and four cubed is 64.  
25:42 - And that will be the volume of this cube, which 
just means that there are 64 of those of these  
25:51 - miniature cubes within this larger cube. And 
that's the volume. So O of n cubed, r n is four.  
26:01 - So o of four cube, which equals 64, 
which is the volume of this cube.  
26:14 - which also happens to be the number of times 
we would perform this function console log the  
26:20 - coordinates, but in our 
case, we just do the squares.  
26:24 - And that is why this function is O of n cube  
26:36 - must first understand what a logarithm is.  
26:40 - Simply put a logarithm is the power that a number 
needs to be raised to to get some other number.  
26:46 - I know that doesn't make much sense out of 
context, but don't worry, I've got you covered.  
26:52 - Let's take the number eight into consideration. 
So we want to raise some number to some power to  
26:58 - get a PhD. In computer science unless specified 
otherwise, we can always assume that the number  
27:04 - that we want to raise to sum power is two. So 
let's rewrite this. So we want to raise two to  
27:11 - some power to get eight. So this same equation 
can be written like this, or this two here is  
27:17 - called the base. And let's not forget that 
in computer science, the base is always two.  
27:22 - So to find the answer to this, we 
just need to find the answer to this.  
27:29 - With that in mind, we can see that if 
we raise two to the power of three,  
27:33 - we get the number that we're looking for 
eight, so log base two of eight is three.  
27:40 - So with all of that in mind, let's move on to the 
meaning of Oh login. For this portion, we will  
27:46 - be using a very bare bones recursive function to 
visualize Oh login, but don't worry, I will walk  
27:52 - you through every step. Just stay with me. So we 
will start with a number and we will use eight so  
28:00 - that you can easily see how this relates to our 
explanation of logarithms in the previous slide.  
28:06 - So this variable in we will be passing to 
our recursive function that looks like this.  
28:13 - So this functions time complexity is Oh, log 
in, let's dig deeper to find out why. For now,  
28:20 - let's just ignore this first line and focus 
on what the function is actually doing.  
28:25 - So when we pass a number into this function, 
it divides in by two or splits it in half,  
28:30 - and then calls itself with the 
new half or divided number.  
28:35 - Let's visualize this using the graph. So we first 
call the function with the value eight, this  
28:42 - eight is then divided by two. The function then 
takes the result of the division and passes it  
28:48 - recursively to itself as the new value for n which 
in turn results in us going one level deeper.  
28:56 - We then do the same thing with 
our new value for n which is four,  
29:00 - that four is divided by two resulting in a new n. 
And the function then passes our new value for n  
29:06 - to a recursive call to itself again, 
resulting in us going one more level deeper.  
29:14 - We then do the same thing with our 
most recent value for n which is two,  
29:18 - we divide it by two and the function 
once again recursively calls itself  
29:23 - at this level we will stop is we can no longer 
divide in without getting fractions as the result.  
29:30 - Now we have arrived at the beginning of 
the secret to understanding Oh login,  
29:34 - so watch closely. If you look at our graph, you 
will see that we've gone one to three levels deep.  
29:43 - If you recall from our previous slide, the 
log base two of eight is three. Our input  
29:50 - in is eight and we've gone three levels 
deep. You will also notice that we have  
29:57 - to raise two to the power of three or multiply 
Two times two times two to get eight. And since  
30:04 - division is just the inverse of multiplication, 
we can see that when we do something like this.  
30:20 - So that means that this function has a time 
complexity of Oh, login. Why? Because our n  
30:26 - is eight. And in computer science, our base 
is always two. And we must have our n three  
30:32 - times or go three levels deep in our recursive 
function to get to a point where we can no longer  
30:38 - reasonably have our input in, which is another way 
of saying that log base two of eight equals three.  
30:47 - And that, ladies and gentlemen, is the secret 
to understanding Oh, login time complexity.  
30:53 - And as a quick note, this is not only 
applicable to recursive functions.  
30:58 - And if you're curious about that line 
of code that we covered up earlier,  
31:02 - all it does is make sure we stopped dividing in 
when n becomes one or otherwise, the function  
31:06 - would keep dividing fraction after fraction until 
we eventually exceed the maximum call stack.  
31:19 - So we'll start with a very simple function, which 
contains only a while loop that assigns a new  
31:24 - value to the variable in for each iteration. And 
for this example, let's imagine that we're passing  
31:30 - the value eight two hour in for this function. So 
that means we'll iterate through this while loop  
31:36 - as long as eight is greater than one. And 
for each iteration of this while loop,  
31:41 - we're going to divide our n by two and reassign 
it to n. So our n is going to be halved for each  
31:48 - iteration. So currently, our n is equal to 
eight, because we passed in eight as in and  
31:54 - while n is greater than one, we're going 
to iterate. So right now is eight, which  
32:00 - is greater than one. So we'll do this math dot 
floor n divided by two for our first iteration,  
32:13 - which would set our n equal to eight divided by 
two, which is four. And this math dot floor, all  
32:22 - it does is it floors the result of our division. 
So for example, if we have math dot floor,  
32:32 - five divided by two, we would get two here, 
instead of 2.5. So after this first iteration,  
32:41 - our in is now equal to four. So while 
n is greater than one, we're going to  
32:47 - do another iteration. So four is greater 
than one, so we're going to do this again.  
32:57 - And n is going to equal four divided by two, 
which is going to equal two. So now our n is  
33:05 - equal to two. And while n is greater than one, 
we're going to do this again. So in is currently  
33:11 - greater than one, two is greater than one. So 
we're going to do it again for third iteration.  
33:22 - So in is going to equal two divided by two, which 
is going to equal one. So at this point, our n  
33:31 - is equal to one. And we're going to go to this 
condition here again. So while in is greater than  
33:38 - one, we're going to do this. But right now n is 
equal to one, it's no longer greater than one. So  
33:43 - we're not going to continue with this while 
loop. So why is this function of login,  
33:49 - so our n is eight. So that means 
that this function should be o of log  
33:56 - eight. And if you remember from the previous 
video on old login complexity, this is just  
34:02 - the same thing as o of log base two, eight, which 
just means what power do we need to raise to buy  
34:13 - to get eight. And if we write this out, what power 
do we need to raise to buy to get eight, we see  
34:21 - that we need to raise two to the third power to 
get eight, because two times two times two equals  
34:29 - eight. So this three is what's important, because 
division is just the inverse of multiplication.  
34:36 - So if we need to multiply two times two times 
two to get eight, then we should also be able  
34:43 - to divide eight by two three times to get one. So 
there's 123. So that means that for this function,  
34:53 - when we pass in a value for n, we're always 
going to need to divide this value in By to  
35:01 - log in times before we can get one, which is 
just another way of saying that when we pass  
35:08 - into this function, we're going to 
iterate through this while loop,  
35:14 - log in iterations, before we get to the value 
one. So if you see here we have one iteration,  
35:24 - two iterations, three iterations. So there's 
three iterations here. So this is this three  
35:31 - is log in iterations. Because again, oh, all log 
in, just means Oh, log base two of eight. Because  
35:46 - our n is a, n, log base two of eight is three, 
because two to the power of three equals eight,  
35:54 - which is our n. And that is why this non 
recursive function is oh log in, because  
36:01 - there will be log in iterations 123. Before 
this while loop ends. I hope that makes sense.  
36:16 - To start, we should understand that in order for 
binary search to work, the array that you were  
36:20 - searching must be an ordered array, both ascending 
and descending order two arrays will work.  
36:26 - Let's start by visualizing our array. In practice,  
36:29 - this is much more useful as the size of an 
array becomes much larger, but we will stick  
36:34 - with an array containing nine elements to 
help us understand the concept more clearly.  
36:39 - So let's assume that we want to check our array to 
see if the value 100 exists inside of the array.  
36:46 - The naive solution would be to iterate 
through each element of the array  
36:50 - checking to see if the value is equal 
to 100, like so. But for this method,  
36:56 - we have to iterate through every element in the 
array up until the value that we're looking for.  
37:03 - What if we have to do this for an array containing 
1000, or 100,000, or even a million elements.  
37:11 - This is where something like binary search 
can be useful. So let's try this again.  
37:19 - So here, we're still wanting to check 
to see if the value 100 is in our array.  
37:24 - But this time, we'll use binary 
search to figure this out.  
37:29 - To start, we need to find the midpoint of 
our array, which is just the element in the  
37:33 - middle of our array, our midpoint is here. 
Now since our arrays in ascending order,  
37:40 - we know that anything to the rate of our midpoint 
will be a value that is larger than our midpoint.  
37:47 - And everything to the left of our midpoint 
will be a value that is less than our midpoint.  
37:53 - So we need to figure out if this number 100,  
37:56 - which we are searching for is greater 
than or less than our midpoint.  
38:00 - This will tell us which side of our array our 
numbers on. So if we simply write out 43 is  
38:05 - less than 100, we can actually see that the side 
of the array that our numbers on is this side.  
38:13 - To paint a full picture, let's for one second 
pretend that the number we are searching for is  
38:18 - two and not 100. In this case, two would be less 
than our midpoint 43. Therefore, it will be on the  
38:25 - left side. And this Ladies and gentlemen, is why 
binary search will only work on ordered arrays.  
38:31 - Because without the order, there would be no way 
to tell which side the number we're searching for  
38:36 - is on by comparing it to the midpoint. Now let's 
get back to the original number that we were  
38:41 - using for our example. So now that we know that 
100 will be on the right side of our midpoint,  
38:46 - we can completely do away with anything to the 
left of the midpoint including the midpoint.  
38:53 - So what we're left with is this,  
38:56 - what we've done is we've essentially cut the 
array in half. To put this in perspective,  
39:01 - let's imagine that we have an array with 1 
million elements and we divide it by two.  
39:06 - In just one step, we will have cut down the 
number of elements that we would need to search by  
39:11 - 500,000 elements as opposed to iterating through 
all 1 million elements and searching that way.  
39:17 - And it doesn't stop here. We will now do the 
exact same thing with this half of the array.  
39:23 - Let's remember that we are searching to see if the 
number 100 exists within our array, we will first  
39:29 - need to find our midpoint. Now don't be confused 
by the even number of elements in this array.  
39:35 - Although there won't be an even number of elements 
on each side of our midpoint, it does not actually  
39:40 - matter because we actually just need to split 
the array approximately in half. For example,  
39:46 - to find the mid and code we will do something 
like divide the length of the array which is four  
39:50 - by two. That resulting to we would use as the 
index of our mid. So let's write out the indexes  
39:57 - of this array remembering that arrays are zero 
Meaning that the starting index will be zero.  
40:07 - And if we take this resulting two 
and see what value it points to,  
40:11 - we see that our mid is 100, which is 
the number that we are searching for.  
40:16 - So in that case, we would be 
done, we have found our number.  
40:21 - But to prove that which one of these we choose 
to use doesn't actually matter, let's explore  
40:26 - what would happen if the mid 54 were used is the 
number that we're looking for greater than or less  
40:33 - than our mid 54. Our number is greater than 54. So 
that means that we can get rid of the left side.  
40:41 - And what we're left with is an array 
containing only two elements, which again,  
40:45 - is an even array. So we have no way of 
determining which one we should choose as our mid  
40:51 - let's see, what would happen if we use 124 is 
our maid is 124 greater than or less than 100.  
40:59 - It is greater than, so we can 
ignore the right half of this array.  
41:04 - Now we're left with an array containing only 
one element. So our so called midpoint can  
41:09 - only be this element. And this element is the 
number we're searching for. So we're done here.  
41:16 - So as you can see, regardless of if you 
have an auto array or an even array,  
41:21 - as long as it is ordered, the search for 
element will be found if it exists in the array.  
41:26 - And that Ladies and gentlemen, is how binary 
search actually works and why it is useful.  
41:38 - So let's just start by creating a file and we can 
call it log in dot j s. For binary search to work,  
41:44 - the array that we're searching must 
be in either ascending or descending  
41:48 - order. So you can't just have a randomly ordered 
array and use binary search on it. So that's just  
41:53 - something to keep in mind throughout the rest 
of this tutorial, our binary search function is  
41:58 - going to take in four arguments, it's going to 
take in an array, and the array is just going  
42:04 - to contain integer values, which will need to be 
ordered, so we will just do one through eight,  
42:14 - we'll also need to pass in the first index of our 
array to the function, we'll just call it start.  
42:22 - And that's just going to be zero. And we will 
need to take in the last index of our array,  
42:28 - which we'll just call end. And we can get 
that by getting the length of the array  
42:32 - and subtracting one from it. The reason 
we need to subtract one from the length of  
42:37 - the array is because the index is of the array 
are actually zero based, but the array itself,  
42:42 - the length is actually not zero based, it's just 
going to be the number of elements in the array.  
42:48 - So the array length is going to be eight, but 
the last index of the array of length eight  
42:52 - will be seven. So that's why we subtract the one. 
And then last but not least, we'll need to take in  
42:57 - a target value, which is the value that we're 
searching for. And we're going to just search  
43:01 - for eight. And then we can start building our 
function. And we'll just call it binary search.  
43:07 - And it'll take in the array 
start at the end and the target.  
43:13 - And this function is actually going 
to be a recursive function. So to  
43:17 - start this function off, we need to 
find the middle index of our array.  
43:30 - So you'll notice that we're using a 
built in function math dot floor here.  
43:34 - And the reason we're using this is 
because if we go to the definition,  
43:37 - it says that it returns the greatest integer 
less than or equal to its numeric argument,  
43:42 - which basically just means that if this the 
division expression within our parentheses,  
43:47 - within our function, parentheses return something 
like 5.5, the value assigned to MIT would only  
43:52 - be five, because we don't want to take into 
consideration anything after the decimal point  
43:57 - because we just want to find an index, which 
of course there wouldn't be an index 5.5. So  
44:03 - therefore, our mid would just be five. And 
the next thing we would want to do is check  
44:08 - to see if our midpoint is actually the number 
that we're searching for, which is our target.  
44:23 - So this would basically return true if the mid 
value of our array is actually the target that  
44:29 - we're looking for. So we're returning true because 
that means that the value that we're searching for  
44:34 - exists within the array, and we would be done 
here. And actually, I just realized I might  
44:38 - actually be confusing you guys by referring to 
our mid and our mid value interchangeably. So this  
44:44 - mid here is actually the index of our mid which 
we're trying to get we're trying to get the index.  
44:53 - so here we can just add index as well. So when I 
say our mid, I'm actually referring to the valley  
45:00 - So we actually want to return true if the value 
that's at our mid index is equal to our target  
45:06 - value. So if the value at our mid index is not 
equal to our target, we then want to go on to  
45:12 - check to see if the value at our mid index is 
greater than or less than our actual target. So  
45:35 - actually, this should be made index. 
Sorry about that. And actually,  
45:43 - we have another error here. So we'll start and 
then target should be here. That should work.  
45:56 - So yeah, let's take the time to understand 
what's happening in this line of code here.  
46:01 - So if the value at mid is greater than our target, 
then that's going to mean that our target is  
46:08 - actually in the left side of the array. Because if 
we look here, and we take into consideration that  
46:15 - five is going to be our mid in this situation, 
in the first execution of this function,  
46:19 - five is going to be our mid. And if five is 
greater than the number that we're searching for,  
46:25 - then that means number that we're searching 
for is going to be in the left side,  
46:28 - because if five were, if the number that we're 
searching for were greater than five, then it  
46:33 - would be in the right side of the array, because 
our array is in ascending order. So this is to  
46:39 - check to see if the item that we're searching for 
is in the left side of the array. And if it is,  
46:45 - what we're going to do is, we're going to pass in 
our start, which is going to remain the same. So  
46:51 - we're going to keep the same start, which is going 
to be in this case, it's going to be index zero,  
46:56 - and then our end is going to be mid minus one 
minus one, because we're going to actually do  
47:02 - away with our actual current mid and actually, 
well, this should be nid index as well. We only  
47:10 - need to assign the current mid minus one to our 
in variable, because our next execution of the  
47:16 - function would have this as our end, and then this 
as our start, and therefore we'd only be searching  
47:22 - 1234, which we would then in turn find the mid for 
1234. And then we would do the same thing. So now  
47:31 - what would happen if the target value that we're 
searching for is greater than our mid value? Well,  
47:37 - let's see. So in this particular case, the target 
value would be less than or mid. So that would  
47:44 - mean that the target value would be in on the left 
side of our right. But if that were not the case,  
47:49 - then if our target is larger than our midpoint, 
then we would do something like else return.  
47:58 - So we're still going to function 
still going to call itself of course,  
48:03 - but this time, we're going to pass in the 
array, the array, and instead of passing in  
48:09 - the original start point, we're 
going to be passing in the midpoint  
48:16 - index plus one. And that's going to be our new 
start point. And this is because we're starting  
48:23 - from the midpoint to the right side of the array, 
because the actual value that we're looking for is  
48:28 - in the right side of the array, and then at 
this point, our end can just stay the same,  
48:32 - because the end is just the end of the array. So 
let's let's have a look at this again. So so let's  
48:37 - again, pretend that for this execution, our mid 
is five and but this time, the actual value that  
48:43 - we're searching for is greater than our midpoint. 
So that means that it can't be on this left side,  
48:48 - because everything on the left of our midpoint 
is going to be less than because our arrays  
48:52 - in ascending order. So it's going to be on this 
right side. And if it's greater than our midpoint,  
48:57 - then of course, we don't need to take five into 
consideration, which is why instead of doing mid  
49:02 - index, and in instead of returning mid index and 
end to the function, we only need to return mid  
49:09 - index plus one, which is going to be this index 
here, it's going to be index, it's going to be  
49:16 - this value six at the index one index above 
our actual mid. Now at this point, we're only  
49:22 - searching our end and our mid plus one. And we're 
only searching these three elements in the array.  
49:30 - That's what both of these conditions cover. So 
this first condition covers if the item is to the  
49:36 - left of our method, which is over here. And the 
second one covers if the item that we're searching  
49:42 - for is in the right environment. And this is how 
binary search works. This is why binary search  
49:48 - is more efficient than say linear search. Because 
we don't need to check every element in the array  
49:52 - we can actually essentially eliminate half of 
the array by knowing whether or not the item  
49:57 - that we're searching for is less than or greater 
than The midpoint. So let's go ahead and see if  
50:02 - we can actually run this function and get it 
to work. And I'm going to tell you right now,  
50:07 - we're going to try and run it twice, we're going 
to try and run it searching for the actual value  
50:11 - that we know that's in the array. And we're going 
to try and run it searching for a value that's not  
50:15 - in the array. And you'll see that we're missing 
something in this function. So let's go ahead  
50:19 - and try and run it. Now to run it. Obviously, we 
have to invoke the function. So we'll go binary  
50:25 - search. And we're going to pass in array, start 
and end target. And we're going to save that.  
50:42 - So we will try and write it by 
just using node, login dot j s.  
50:50 - And we broke it. Nice. Got to add in the target 
here. So it caused the entire function to fail.  
51:03 - See it again. Okay, so let's see what 
happens if we actually return the value,  
51:12 - I mean, console log the 
return value of the function.  
51:19 - And we get true because eight 
is found within the array. But  
51:27 - what you'll see here is if we search for something 
that doesn't exist within the array, we're going  
51:32 - to break it again. So 10 does not exist. So let's 
try it again. And we got maximum call stack size  
51:38 - exceeded, because let me show you what it means 
maximum call stack size exceeded. So what we're  
51:45 - doing is, every time we don't meet this condition 
true, we're going to call binary search again,  
51:51 - which is we're calling the functions recursively 
calling itself again. And if we're, if we're  
51:57 - searching for a number that doesn't exist within 
the array, binary search is basically going to  
52:01 - keep calling itself recursively. And there's never 
going to be a point at which it stops. Even if it  
52:07 - doesn't find the item within the array, it's still 
going to continue to recursively call itself until  
52:12 - eventually we reach the maximum call stack size, 
which is basically you've exceeded the amount of  
52:17 - memory allocated to this particular application. 
So to solve this issue, what we want to do is we  
52:23 - want to add a base condition that will stop the 
function from recursively, calling itself after  
52:30 - it's checked the entirety of the array. So we can 
do if start is greater than and then return false.  
52:43 - So the reason why this works is because if the 
targets not in our array, it either means that  
52:49 - the target is larger than the largest value in 
our array, or it's smaller than the smallest  
52:53 - value in our array. So that means our function 
will keep checking our array until eventually  
52:57 - we get to either the largest item if the target 
is larger than the largest value in the array,  
53:02 - or it gets to the smallest item if the target 
is smaller than the smallest item in the array.  
53:07 - And at that point, the start and the end values 
will be equal and at the point where both the  
53:12 - start and the end values are equal passing 
our start in our into either this line,  
53:18 - or this line, well, in effect, make the start 
greater than the end. And now we can run this  
53:24 - again using this tin that doesn't exist within 
our array. And as you can see, we get false.  
53:32 - And if we even added negative here, negative 
10 doesn't exist. So we get false as well.  
53:44 - And let's see, what else can we try. just tried to 
we know two exists. And then and we get through.  
54:03 - So let's change this back to a to get a feel for 
why this function is oh log in, let's actually  
54:13 - let's go ahead and create a longer array here. 
So currently, our array only contains these eight  
54:19 - elements. And it's going to be kind of hard to get 
a general understanding of the way that our input  
54:26 - scales with such a small array, so we can go ahead 
and just just empty out our array, and we'll just  
54:36 - create our own array. So let's see, the trade our 
own array we can just do for i equal zero, i is  
54:48 - less than 1024 i plus plus. And then here 
for each iteration of AI, we can just do  
55:00 - grade up, push high. And let's 
think let's actually make eye one.  
55:08 - And then we'll make this less than 
or equal to. And then after that  
55:13 - we can console. log our array. And for now, 
let's just comment this out. And let's see.  
55:26 - Okay, so at this point, we have a longer 
array, which will hopefully help for you  
55:31 - guys to visualize how the input is scaling when I 
do some console log trickery here. So yeah, so we  
55:40 - don't need to log this anymore. Just delete that, 
actually. So we're creating a new array here.  
55:46 - And it's going to be an array that has elements 
from one to 1024. And for the purposes of this  
55:52 - example, I don't want us to find the element, 
I mean, the item in the array, so we're just  
55:57 - going to change this to something that doesn't 
exist within the array. So we'll just put it like  
56:01 - that 100,000 does not exist within our array, 
and also the end, and this is getting the end  
56:07 - from this current array. So we're going to need to 
bring this down to after we create our full array.  
56:13 - So this array is empty here, and then we're 
adding all of the values in this for loop and  
56:18 - then we get the end of the array. And the start, 
of course, can still be zero because it's zero.  
56:25 - And also, we can go down here and delete till 
the, we don't need to console log this anymore,  
56:31 - because we're going to do another 
console log. So we're going to  
56:33 - execute the function here. And then here is where 
we're going to try and make some magic happen.  
56:40 - So for each call to binary search, like each 
recursive call, we want to not just recursive  
56:46 - call the first call for the first call. And each 
recursive call, we want to log with the array  
56:53 - that we're searching through is looking like. 
So in the beginning, it's the full array,  
56:57 - which we just showed when we console logged in 
earlier. And then at each call to the function,  
57:03 - the rate is going to essentially be halved. So 
it's going to look something like let's see,  
57:08 - console dot log will do array dot slice. 
And we're going to do the start and the end.  
57:16 - So what that does is, it's only going to show 
the parts of the race from the start to the end,  
57:22 - it's not going to show the full array 
anymore. And let's see if that works.  
57:32 - so here we can do node, log in. Okay, and yeah, 
that worked. So maybe I can make this smaller.  
57:39 - So you can see, so when I make it smaller like 
this, it's kind of easy for you to see like,  
57:46 - well, at this point there is too long to show its 
entirety. But you can still see what's happening  
57:52 - here. So like since the value is greater than 
the left side of the array, you can see that  
57:57 - all these lower values are going to essentially 
be eliminated, and it continues to get halved  
58:04 - and have an halved. And here's where you 
can start to see visually what's happening  
58:09 - here like I can see that it's the ray is 
continuing to get smaller and smaller.  
58:21 - To understand ovan login, we will take 
this small function into consideration.  
58:26 - This function has a complexity of ovan login. 
Let's step through this code line by line so  
58:32 - that we may understand what is happening here. 
This function takes one argument in which for the  
58:37 - sake of this example will be for we then declare 
another variable y which we will set equal to n,  
58:45 - we will get to what this variable 
Y is for later. And at this point,  
58:49 - we have a while loop that iterates through n until 
n is equal to one. For every iteration through  
58:55 - in this code within the while loop is run. Let's 
visualize this. For the first iteration of the  
59:02 - while loop in starts off is four but we divide it 
by two, so n is now equal to two. Then we get to  
59:10 - this line of code which is the start of a for 
loop. This is where this variable y comes in.  
59:17 - The reason we declared this variable before 
the start of the loop is because n is getting  
59:22 - divided by two for each iteration. This in 
turn is reducing the size of the variable n.  
59:28 - But for this inner for loop we needed to iterate 
through the original size of our original n.  
59:34 - So we stored the original end in a separate 
variable. Okay, back to this inner for loop.  
59:40 - For each iteration of this for loop up until the 
size of n we will log or print the value for I.  
59:53 - Once this is finished, we move on to the next 
iteration of the while loop and repeat the process  
59:58 - going into this iteration In is now two, we 
start by dividing in by two. So n is now one.  
60:05 - And once again, we iterate through our 
inner for loop up until the size of y.  
60:15 - Now at this point, you will notice that our 
n is now one. If we check the condition of  
60:20 - our while loop, we see that we only want to 
iterate while n is greater than one. So the  
60:26 - while loop will now terminate, and the function 
is finished. Now, after all is said and done,  
60:31 - and with everything written out, we can 
see that there's a top level loop here.  
60:37 - And there's an inner loop for each 
iteration of the top level loop.  
60:44 - So this is where the magic happens. So pay 
close attention. For every iteration through  
60:49 - the top level loop, which iterates 
until n is one in is divided by two.  
60:55 - This means that this top level loop never actually 
iterates through the full size of our input  
61:00 - in the value for n is being split in half for each 
iteration, which is why we would say that this top  
61:07 - level loop has a complexity of Oh login. If you 
are confused about why this top level loop is Oh,  
61:13 - log in, let's take some time to prove it by 
writing it out. So this is Oh, log in. Let's plug  
61:21 - in some numbers. Now if you've watched my video 
on Oh, log in, you know that in computer science,  
61:26 - the base of a logarithm is always two unless 
stated otherwise. So this can be rewritten as log  
61:33 - base two of four, four, because we're replacing 
in with our actual input for n, which is four. And  
61:41 - log base two of four is two, because you need 
to raise two to the power of two to get four.  
61:47 - And as you can see, this makes sense, because for 
this top level loop, we only iterate two times.  
61:54 - So for this top level loop, we have log base two 
of four equals two. Now we need to take a look at  
62:02 - what is happening in each of the two iterations 
of the top level loop. For each iteration,  
62:07 - we loop through the full size of y, which is 
the original size of n. So that means that  
62:12 - each of these inner loops has a complexity of 
O of n, which just means that processing time  
62:18 - increases linearly with the size of n. Now 
this is where we bring everything together.  
62:25 - O of n log in really just 
means O of n times log in.  
62:31 - And if we plug in some numbers here, we get this. 
Because remember, log base two of four equals two.  
62:39 - And if you look at our visualization, it makes 
perfect sense, because for each iteration of the  
62:44 - top loop, we iterate through the entirety 
of y, which is our original value for n.  
62:50 - And that, ladies and gentlemen, is 
how you visualize all of in log in.  
63:00 - So we can start by creating a file, 
let's just call it merge sort,  
63:05 - well then create a function, 
which will also call merge sort.  
63:15 - The argument to this function is going to 
be the array that we're looking to sort  
63:19 - for the first portion of this function,  
63:21 - we'll need to make sure that the array that 
we're passing in has a length greater than one,  
63:34 - we will need to do this because if the array 
is only if length one and there's only one  
63:38 - element in the array, then it is already 
sorted. This will also be our base case,  
63:42 - as this merge sort function is going to be 
a recursive function. Next, we're going to  
63:47 - need to split our array in half. To do this, we'll 
first need to find the middle index of our array.  
64:01 - So with this math dot floor here does is it makes 
sure that we only take into consideration the base  
64:07 - number from the result of the division. So for 
example, if we divide a number that results in  
64:12 - I don't know, let's say 5.5, we wouldn't take 
into consideration the number after the decimal  
64:18 - point. So we would only return to the variable 
the number five. And this is because when taking  
64:24 - indexes into consideration, there is no index 5.5 
or 2.2 or 1.1, there would only be an index one,  
64:32 - five or two. So this is why we're using math dot 
floor here. And once we have the middle index of  
64:37 - our inputted array, we can then split the array in 
half and create a separate array for the left side  
64:42 - and a separate array for the right side. So we can 
do that by just creating a new array left array,  
64:50 - and then we can set left array equal to the input 
array dot slice, and then the indexes are going to  
64:57 - be the arguments that we passed. So basically 
slices from and to. So we want to slice from  
65:03 - the first index of our input array. And we want 
to slice up until the middle index that we just  
65:10 - that we just got. And that's because we want the 
left side of the array. So let's say for example,  
65:16 - the array looked like this. And we win, we went 
ahead and got our middle index, which would be  
65:24 - something like this three here. And then we want 
to create an array starting from this zero index,  
65:30 - up until our middle index, which 
would be the left half of the array,  
65:33 - and then we would go ahead and do the same 
thing for the right half of the array.  
65:37 - So we're going to actually go ahead 
and do the same thing for the right  
65:41 - half of the array, we'll just call it right array. 
And we'll do array dot slice again. But this time,  
65:48 - we're just going to do from the middle index 
all the way until the index, the last index  
65:52 - of the array, and the way we get the last index 
of the array is just by using array dot length.  
66:01 - And this here can actually be a bit confusing, 
because we know that array dot length gives us  
66:05 - the length of the array, which is the number of 
elements in the array. And we also know that array  
66:10 - index is zero based. So basically, if the length 
of an array is five, there will only be index  
66:16 - 0123, and four, there won't be an index five. So 
here, you might be wondering how this is actually  
66:23 - working. And it's because actually, there's an 
error. And this method method is not slicers, just  
66:28 - slice, but it's because this slice method slices 
up to in but not including in. So basically this  
66:36 - end value, it's not included in the actual array, 
slice, only the value before will be included.  
66:43 - So for example, if we have an array 
that looks like that looks like this,  
66:50 - the end that we would use for this array would 
be three, even though that there's only index 01.  
66:55 - And two, it will slice up until end not including 
in so this is why we don't need to subtract a one  
67:03 - from this because if we were to subtract one from 
array dot length, and use that as the last index,  
67:08 - or the end index that is passed to the slice 
method, then we actually wouldn't get the  
67:13 - full array, we would only get up until this 
one, but not including this one. So they were  
67:19 - able to only look like this in this slice. I 
hope that makes sense. It's a bit confusing.  
67:24 - And also keep in mind that with this example 
I just gave above, I'm actually not taking the  
67:30 - middle index into consideration. So for this 
array, in particular, it would look something  
67:34 - like array dot slice, well, slice and there will 
be zero index up until array dot length minus one.  
67:45 - Anyways, last but not least, for our actual emerge 
cert function, what we're going to need to do  
67:51 - is implement the recursive portion of the 
function, which is we're going to return  
67:55 - and bear with me, we're going to return a 
helper function that we haven't created yet.  
67:59 - And we're going to call it merge. And 
within this marriage helper function,  
68:03 - we're going to accept two parameters, which 
is going to be the left array and the right  
68:08 - array. And what we're going to pass to merge is 
going to be the recursive call to merge sort.  
68:15 - And then our left array, and we're also going to 
pass in the recursive call to merge sort, and our  
68:22 - right array. This is going to seem a bit confusing 
right now. But just bear with me, I will explain  
68:29 - how this is working. And I will try to make things 
clear for you. But for now, we don't actually have  
68:34 - this merge function, so we need to go ahead and 
create it. So let's go down here and create this  
68:41 - new helper function called marriage, which will 
take in the left array, and the right array.  
68:48 - Oh, sorry, and it's not merger, it's merge. Now 
this function is going to be the function that  
68:56 - actually merges the two arrays. So the way that 
Merge Sort works is we use a divide and conquer  
69:02 - approach in which the input array is basically 
halved until we have in arrays of length one, and  
69:09 - at that point, arrays of length one, as mentioned 
above, when we created this space case, here,  
69:15 - an array of length one is already sorted. So to 
visualize this, if we have an array, that is one,  
69:22 - there's only one element in this array, so 
obviously, this one is going to be the first and  
69:28 - last element in the array. So there's no need to 
sort it because there's nothing to compare it to  
69:33 - with. What we do in this actual merge function is 
we're going to bring these sorted arrays together  
69:40 - and compare them and then sort those individual 
one element arrays. So one thing to keep in mind  
69:46 - throughout the process of writing this merge 
function is that this merge function is always  
69:51 - going to take in two already ordered arrays, 
starting with the ordered arrays of length one.  
69:57 - So to start, we're going to To create a variable, 
which is going to just be the result array,  
70:04 - and it's going to start off as an empty 
array. So these all equals just an empty  
70:10 - array. And we're also going to define our base 
indexes for the left array and the right array,  
70:16 - but could index equal zero. Now 
we'll do the same thing for right.  
70:25 - Next, we'll create a while loop that's going 
to compare the two arrays element by element.  
70:44 - And actually stick here, this 
length. So within this while loop,  
70:50 - we're going to compare each element of both 
arrays and whichever element is less than  
70:54 - the other will get added to the result array 
will then increment the index of whichever  
70:59 - element got added to the result array because 
that element no longer needs to be compared.  
71:04 - If you're a bit confused by this, just 
bear with me, I'll actually create an  
71:08 - illustration for you to understand it better. 
But for now, let's just write out the code.  
71:43 - Let's imagine that the rays that we want merged 
look like this for the left array and this for  
71:47 - the right array. Now keep in mind that the 
merge helper function merges ordered arrays,  
71:52 - so it will not work on unordered arrays. In 
this example, we are merging two ordered arrays  
71:58 - of length three to show the entirety of the 
functions functionality, but this will also  
72:02 - work for naturally sorted arrays of length one. So 
for this while loop to continue, both left index  
72:08 - and right index need to be less than the length 
of their corresponding arrays. As you can see,  
72:13 - these indexes are incremented, every time that 
index is element is pushed to the result array.  
72:19 - So if we draw this out, it looks something 
like this. Here are the two arrays and their  
72:25 - indexes. In this next line, we check to 
see if the element at the left array index,  
72:29 - which is currently zero is less than the element 
at the right right index, which is also zero.  
72:35 - So it's three less than one. No. So that means we 
do what's in our else condition, which is push the  
72:40 - right array element at its current index to the 
result array and increment the right array index.  
72:47 - And now our right array index 
is one so we can move this.  
72:53 - And then once again, we do our comparison at 
the top of the for loop is three less than  
72:59 - six? Yes. So we push three onto our result 
array and increment our left array index.  
73:06 - And we can move this over as well. And 
back to the top of our for loop again,  
73:12 - is 12 less than six? No. So we're going to 
use the code in our else condition, which is  
73:18 - push the right array element six to the result 
array and increment the right index. And again,  
73:23 - we will move this and now is 12 less than 15. 
Yes, so we push the 12 from the left array to  
73:32 - the result array and then increment the left index 
as well as move this arrow to the new left index.  
73:38 - Now is 16 less than 15? No. So we move on 
to our else condition and push the 15 from  
73:45 - the right array to our result array 
and increment the right index by one.  
73:50 - Now at this point, this while loop will terminate 
because if you remember this while loop will only  
73:55 - continue if the left index is less than the 
left arrays length, and the right index is less  
73:59 - than the right arrays length. At this point, our 
right index is equal to the right arrays length.  
74:05 - As you've probably already noticed, there's 
still a 16 left in the left array that has  
74:10 - not yet been pushed to the result array. But the 
while loop is already complete. So what do we do?  
74:16 - After the while loop, we're going to add 
another line of code that looks like this.  
74:21 - So this return is going to return a single 
array that is a combination or concatenation  
74:26 - of three arrays the result array, a slice of 
the left array and a slice of the right array.  
74:32 - So this slice function if we 
only pass one index to it,  
74:35 - it will be used as the start of the slice and 
will slice up until the end of the array. Let's  
74:41 - break this down. So if you remember from the last 
slide, our result array currently looks like this.  
74:49 - And we're going to add to it a slice from 
the left array starting from the left  
74:53 - index that we incremented which is two which 
results in array containing only this part  
75:00 - And we're going to add to that a slice of the 
right array starting from the right index that  
75:05 - we incremented, which is three, which results in 
an empty array, because index three would be here.  
75:12 - And with all of those combined, the result being 
returned is an ordered array that looks like this.  
75:21 - Now let's go ahead and add in the return 
that we just discussed in the illustration.  
75:29 - And this completes our merge function. And 
now that the merge function is complete,  
75:33 - our merge sort function is also complete. And now 
we can go ahead and test this out. To test this,  
75:40 - we will need to create an array. And this array, 
we will need to pass to our merge sort function.  
75:56 - And there you have it, our sorted array. 
And if we take the time to go back in here  
76:02 - and have a look at the code, you'll see that 
within this merge sort function, we're dividing  
76:06 - the input array into recursively, which makes 
this Merge Sort portion of the function of log in.  
76:13 - And actually, this merge function is 
all event because it needs to touch  
76:17 - every element within both arrays to actually sort 
them. So with this merge function being old in  
76:27 - and the actual recursive merge 
sort function being of login.  
76:37 - For every level up until the depth of this 
recursive function, we're actually going to be  
76:42 - doing this merge, which is O of n. So 
to get the overall time complexity,  
76:47 - we would just have to multiply the depth 
of this recursive function by O of n,  
76:52 - which is O of n log in because of N log N 
is just multiplying in by log in and log in,  
76:58 - in this case will be the depth at which 
this recursive function needs to traverse.  
77:14 - So let's visualize this merge sort function, we'll 
go through the code line by line. So let's imagine  
77:21 - that we have an array that looks like this. So 
this array here will be our input array. So this  
77:33 - is the array that we're going to pass to our merge 
sort function here. So this array is this array.  
77:41 - So the first portion of the code here, it just 
checks to see if our array is greater than length  
77:48 - one, because an array of length one is already 
sorted. So if we get an array of length one here,  
77:53 - we're just going to return that array 
as an already sorted array. But if the  
77:58 - array is greater than length one, then we're 
going to move on to this portion of the code.  
78:05 - And this portion of the code is where the divide 
and conquer approach is implemented. So basically,  
78:12 - here, we're going to split our input array. 
By getting the middle index of the array,  
78:17 - we're going to split it into two separate 
arrays, which will look something like this.  
78:28 - And these individual arrays 
left array and right array.  
78:32 - After their split, they're going to be once 
again passed to the merge sort function.  
78:52 - Once again, we end up at this portion of the code,  
78:55 - because this array and this array are individually 
being passed to this merge sort function.  
79:03 - So for each of these, we end up at this portion 
of the code. And both of these arrays are  
79:11 - not less than length do, we have an array of 
length two, and we have an array of length three.  
79:17 - So they're going to move on to this portion of 
the code in which we use the divide and conquer  
79:21 - approach once again. And let's go ahead and write 
that in here actually, because it's important.  
79:33 - So once again, we're going to 
get the middle index of our array  
79:37 - and create a left right and a right array by 
splitting the single array on its middle index.  
80:17 - So you will notice that this array, this array and 
this array are already of length one. And as, as  
80:25 - we've seen here, we're going to pass these arrays 
of length one to merge sort, we're going to pass  
80:32 - these arrays in to merge sort, and then they're 
going to get to this conditional, and they're less  
80:37 - than length two. So we're just going to return 
these rays. So for these arrays, we can stop.  
80:47 - But this right here is of 
length two. So this array  
80:51 - is going to get to this portion of the 
code again, and we're going to split it.  
81:14 - And now, these arrays are of length 
one, so we can stop here as well.  
81:20 - So these calls to merge sort, are the same 
as these calls to merge sort. But we still  
81:27 - haven't called merge. And what merge is 
going to do is it's going to take two  
81:32 - already sorted arrays, and it's going to merge 
them together into one single sorted array.  
81:38 - And what that's going to look like 
is, it's going to be called here,  
81:45 - these results are going to be merged together 
into one sorted array. So these two sorted arrays  
81:52 - are going to be combined and returned 
here as a sorted array of length two.  
82:05 - And the same thing will be done 
here. We're going to merge.  
82:14 - And these two sorted arrays are going 
to be combined and returned here  
82:23 - as a single sorted array.  
82:30 - And we'll do the same here. Merge. And these 
two sorted arrays are going to be combined  
82:41 - and returned here as a single sorted array. And 
last but not least, we're going to merge here.  
83:00 - And these two sorted arrays 
are going to be combined  
83:05 - and returned here as a single sorted array.  
83:17 - And let's not forget our 
initial call to merge sort.  
83:26 - So that's how we can visualize 
recursive merge sort.  
83:29 - But you're probably still wondering what 
this merge function is actually doing.  
83:34 - So as mentioned before, this merge function 
takes two already sorted arrays, and it  
83:39 - combines them together into one sorted array. 
And that function looks something like this.  
83:46 - So as you can see, merge takes 
in a left array and right array,  
83:50 - both of which are sorted, and then it will return 
this result array, which is a combination of both  
83:56 - the left array and the right array sorted. So to 
understand the time complexity of merge store,  
84:02 - we'll take a array and array of 
length four into consideration.  
84:11 - So this input array will pass 
to the merge sort function.  
84:18 - And what that call to merge sort will do 
is divide the array approximately in half  
84:26 - and those halves will be passed 
to merge sort recursively  
84:59 - at this point, We have our arrays of length one. 
So we can't split these rays any further. And to  
85:06 - understand the time complexity of merge sort, we 
need to understand, oh, log in. So as we know,  
85:14 - in computer science, so log in is the same as log, 
base two in, and in this case, in is the length of  
85:23 - our array here, which is four. So in the 
reason you need to understand login, is because  
85:31 - this divide and conquer approach that we're 
implementing here is login. That is to say that  
85:38 - log base two, a four, which is our in our 
n is four equals two. And that's because  
85:49 - two to the power of two equals four, which means 
that for an array of length four, there will be  
86:01 - two levels to our recursive tree structure. 
And we can see that here, you have level one,  
86:10 - and we have level two. So this is a level, and 
this is a level. And for each one of these levels,  
86:20 - what we need to do is we need to touch every 
element of n, because we need to sort them.  
86:28 - And in order to sort them, if you 
remember from our illustration of merge,  
86:36 - within this merge function, the while loop within 
this merge function, needs to touch each element  
86:42 - to compare the elements and create the merged 
array. So that means that for each level,  
86:50 - we need to merge. And this merge function 
needs to touch every element of n.  
87:05 - So that means that each 
level is actually Oh, then.  
87:13 - And there are log n levels. So O of n times 
log in really just means Oh, of four, because  
87:33 - four is our in, in is for 1234. So four is our n 
times log, base two, a four. And as we seen here,  
87:42 - log base two, a four is actually just two times 
four. So the number of elements in the array,  
87:52 - and the number of levels that we need to traverse, 
so for every level, we need to touch in elements  
87:59 - in the array, which is two times four. And that's 
why mergesort has a complexity of O of n log in.  
88:17 - So we'll start by examining this recursive 
implementation of Fibonacci. So let's imagine  
88:21 - that we pass the number four to our fib function. 
So at this point four is our value for n.  
88:30 - So after we call this function, we'll end up 
at our first if block. And this if block just  
88:34 - returns zero if n equals zero, and then we move 
on to a second if block in the second if block  
88:40 - just returns one if n equals one. So once 
we pass the number four into our function,  
88:45 - we'll end up at this first if block. And both 
of these if blocks are base cases, because  
88:50 - as we know, with recursive functions, we need 
to have a base case so that the function doesn't  
88:55 - continue to call itself even after we're finished. 
So we pass the four into our fib function,  
89:00 - and four is not equal to zero, so we don't 
return zero, and four is not equal to one,  
89:05 - so we don't return one. So we end up here. And 
what this return does is it adds together the  
89:10 - result of two more calls to the Fibonacci 
function, this first Fibonacci function,  
89:15 - we're going to call with our n minus one, so four 
minus one, and the second one, we're going to  
89:21 - call with our n minus two, so four minus two. 
So let's have a look at what that looks like.  
89:37 - And as we can see, four minus one is just 
equal to three, so this would actually just be  
89:42 - three. And same for here. This would 
just be equal to two. So at this point,  
89:47 - we have to call to our favorite our Fibonacci 
function. One which we're passing three is our in  
89:53 - and one numerator passing two is our in. So for 
both of these calls, neither one of these will  
90:00 - Return at these IP blocks. So we'll end up back 
down here again, which will look like this.  
90:16 - And again, we can just do 
the math in the parentheses.  
90:33 - And let me just make this a little bit smaller. 
So at this point for these three calls to the  
90:39 - Fibonacci function, we're going to reach our 
base case, because we're passing zero for this  
90:44 - call. And we're going to just return zero at 
that point. And we're passing one for these  
90:48 - two calls. And we're going to just return one at 
those points. So these are going to be complete.  
90:56 - These ones are done. And for this function we're 
passing to is our n, which isn't equal to zero  
91:01 - and is equal to one. So at this point, we'll 
then again go down to this portion of the code.  
91:25 - And now these two have reached our base cases as 
well. And one more time, I'll need to shrink this.  
91:31 - So now we'll get into the reason why 
this recursive Fibonacci function is  
91:34 - an exponential function. First, let's start 
by observing this recursive tree structure.  
91:39 - So as we can see, here, we have one, two and 
three levels to this recursive tree structure.  
91:45 - So we can write that out level one, level two, 
and level three. And for this first level, here,  
91:54 - we're calling the fib function two times. 
So one, two, and for this second level,  
91:59 - we call our fib function four times 1234. So 
this level, we make two calls to the Fibonacci  
92:07 - function in this level, we make four calls to 
the Fibonacci function. And let's just ignore  
92:11 - this third level for now. And let's just focus on 
these top two levels. So two here is the same as  
92:17 - two to the power of one and four, here's the same 
as two to the power of two. And as you can see,  
92:23 - our exponents correlate with our levels. So 
actually, if these three functions were to make  
92:29 - their two additional calls to recursive Fibonacci, 
we would have something that looks like this. So  
92:35 - we have two calls here, two calls here, and 
two calls here. So we'll just write this out.  
92:50 - So let's imagine that these are also additional 
costs to the recursive Fibonacci function. And  
92:54 - let's just imagine that that's the case 
for one second, just so that we can get  
92:57 - a better understanding of why this function 
is of exponential time complexity. So now,  
93:02 - if we count the calls at this third level 
to our recursive Fibonacci function,  
93:07 - and keep in mind that these calls won't actually 
be made, only these ones will be made. But we're  
93:11 - just writing this out so that we can get a better 
visualization of what's happening here. So if we  
93:16 - counted out these calls to the Fibonacci function, 
it would be 12345678. So we would have eight calls  
93:26 - at this third level, and eight is the same as two 
cube or two to the power of three. And as you see,  
93:33 - once again, our exponent corresponds with our 
level. So that means that if our n is four,  
93:39 - we would go three levels deep. And at each level, 
the number of calls to our Fibonacci function  
93:44 - increases exponentially. But you might be 
wondering, since our n is four, and we stop  
93:51 - here, when it's two to the power of three, 
as opposed to two to the power of four,  
93:55 - how does that result in this function being off to 
to the end? Well, it's actually quite simple. So  
94:00 - in actuality, this Fibonacci function is O of 
two to the n minus one. And if we write this out,  
94:09 - you can see it's o of two to the fourth 
power minus one, which is just equal to O of  
94:19 - two to the third power, which is the same as 
the number of calls made at this third level,  
94:23 - right. And if you remember, in bego, we ignore 
constants. So if in actuality, this function is  
94:29 - O of two to the nth power minus one, and we 
ignore the constants, that means that we're  
94:35 - going to ignore this minus one, which results 
in the time complexity of this function being  
94:41 - o of two to the N. And at this point, you're 
probably wondering how we're able to add these  
94:47 - function calls in here. And in actuality, I only 
added these function calls in here to give you  
94:52 - guys a better visualization of what's happening at 
each level and why we're considering this function  
94:58 - to be off to to the internet. Because it's easier 
to visualize if we actually write out these  
95:03 - functions that we're actually not calling. And we 
can do that because with bego, as we've learned,  
95:08 - we're only looking for an upper bound, like we're 
not looking for a tight bound, we're not looking  
95:12 - to be very specific, we're only looking for you 
can say an estimation of the worst case scenario.  
95:17 - So as you can see here, on this left function, 
we're calling fib and then we're subtracting one  
95:24 - from n. And on this right one, we're calling 
fib and then we're subtracting two from n.  
95:28 - So this right side of the tree is always going 
to be shorter than this left side of the tree,  
95:33 - there's always going to be this empty space. 
Because on this right side of the tree,  
95:37 - at every level, we're subtracting 
two. And at this upside of the tree,  
95:41 - at every level, we're subtracting one. But 
when we're taking bego into consideration,  
95:45 - we don't need to worry about this. And regardless 
of what number we pass into this function,  
95:49 - at the bottom most level, there's always going 
to be a gap on this right side. But that's okay,  
95:53 - because we're only looking for an upper bound. 
So these are just here to help you visualize what  
95:57 - is actually happening and why this function is 
considered to be of exponential growth. And that  
96:01 - is why recursive Fibonacci is of exponential 
time complexity, I hope that makes sense.  
96:13 - We'll start with the function that will call F. 
And this function will be a recursive function.  
96:19 - So this first portion of the code is going 
to be our base case. So if the value for n  
96:25 - pass to this function is equal to zero, 
then we're going to print these stars.  
96:30 - And then we're just going to return but if we 
pass a value to n, that's not equal to zero, then  
96:35 - we will go down here to this for loop. So let's 
start with an example. So let's say that we pass  
96:42 - the number three to our function, what will happen 
first is we'll check to see if in which is three  
96:48 - in our case is equal to zero, which it's not. And 
then we'll move on to this for loop. And what this  
96:53 - for loop is going to do is, for every iteration 
of in, for every iteration, up until three  
97:00 - from zero up until three, which is our end, we're 
going to recursively call this function again,  
97:07 - this time using our n minus one. So let's, let's 
try to visualize this. So if we pass through to  
97:13 - this function, and we end up at this for loop, 
we can write it out like this. So for each index,  
97:26 - up until three, but not including 3012. And the 
reason we're only doing for each index 012 is  
97:36 - because here, I starts off at zero, and we're 
going to iterate through our input value in  
97:44 - up until AI is no longer less than in. So 
once I becomes equal to n, then we'll stop.  
97:50 - So if I were to be three, then we wouldn't go 
through this loop again. So that's why it's 012.  
97:58 - And for each of these iterations, 012, 
we're going to call this function again.  
98:05 - And that's going to look something like this.  
98:14 - So if you look here, we're subtracting one 
from in that we're passing to the function  
98:20 - at each iteration of this for loop. So 
if n is three here, for each of these,  
98:27 - n is going to be equal to two because we're 
going to subtract a one for each of these.  
98:45 - So these are actually going to be f two. And for 
each of these, we're going to do the same thing  
99:03 - that we did for the first call to 
this function to this f function.  
99:11 - But this time, we'll only iterate 
through indexes, zero, and one.  
99:27 - So each of these are their own individual calls to 
this recursive function, right. And each of these  
99:34 - needs to have their own for loop, which 
is this, this in this. So at this point,  
99:40 - f is two. So we're iterating up until I 
is no longer less than two. So we'll have  
99:48 - index zero and one that we're iterating through 
and for index zero and one, we're going to do  
99:53 - this and the same for this call to the recursive 
function for index zero and one or We're going  
100:00 - to do this and the same for this one. And I 
apologize if the writing here is getting too  
100:04 - small. But you'll see that this recursive tree 
gets very large very quickly. So I'll actually  
100:10 - need to shrink this down a little bit. So that 
we can have more room. So for each of these,  
100:18 - we're going to call the recursive 
function again. But this time,  
100:25 - the function is being called with two minus one, 
which is going to mean that our in is going to be  
100:49 - one. Let's make this a little 
bit smaller, actually. And again,  
100:52 - I apologize. So at this point, our for each 
is only going to happen once for index zero.  
101:08 - Man, this is getting really tiny.  
101:14 - Okay, so at this point, our F is one for all 
of these calls to the recursive function,  
101:19 - and AI starts off as zero. And as long as i 
is less than n, which is one, then we'll do  
101:26 - this code. And it's only going to be less than 
in when it's zero, which is this one iteration.  
101:35 - So for each of these calls to the recursive 
function, we're only going to call this function  
101:41 - once for this first iteration, which is zero. Now 
at this point, it's going to be f one minus one.  
102:00 - And f one minus one is actually going to be 
equal to zero. So it's going to be f zero.  
102:11 - So we're going to be passing 
zero as our in to the function.  
102:22 - And it's going to be a little bit difficult to see 
because it's small. But if we remember up here,  
102:28 - in the actual function, our base 
case is if n is equal to zero,  
102:33 - then we're just going to console 
log, and then we're going to return.  
102:38 - So for each one of these calls to the recursive 
function, we're going to perform this code this  
102:45 - console log code. And then after we perform 
this console log code, we're going to return  
102:49 - so it's going to be finished, this entire 
function will be finished, because all of  
102:53 - these are going to return, they're going to 
log the code, and then they're going to return.  
103:00 - And once all of these return, this entire function 
is going to be complete, it's going to terminate.  
103:05 - So instead of writing out console log, we'll just 
write that each of these functions performs log  
103:17 - n after the log, the function 
will return. So it'll stop.  
103:32 - So for the last time, I'm going to need to make 
this a little bit smaller. Alright, so what  
103:36 - we're left with when this function is finished 
is we're left with this tree structure. And  
103:42 - this tree structure shows how many recursive 
calls that we had to make to get to our base  
103:48 - case for each of these recursive calls. And if you 
look here, I'll go ahead and circle these so that  
103:54 - you can see them more clearly. If you look here, 
for each of these recursive calls to the function,  
104:03 - we had to perform this code, we 
had to perform this code here  
104:08 - for each of these recursive calls to the function. 
So at the final level, where our base case was,  
104:14 - we had to perform this code. And if you count 
these, you'll see that this is 123456. So six  
104:24 - times we needed to perform this code passing three 
into our function caused us to need to recall this  
104:32 - final recursive call to our function six times and 
perform this code six times. And that number six  
104:39 - is our key to understanding factorial 
time complexity, because if you look  
104:44 - here, we have oh three factorial. And the reason 
why is because our n is three, right? So it's,  
104:54 - we're just substituting so all three factorial 
right and three factors. Mario is six actually,  
105:02 - because to get the factorial of a number, you 
just multiply every number up until that number.  
105:09 - And if we multiply two times one, we get 
two. And if we multiply that two times three,  
105:16 - we get six. And, and again, we needed to execute 
this console log this code, we need to execute  
105:22 - 123456 times. And if we dig a little deeper, we'll 
see the three factorial is a result of multiplying  
105:33 - every number up until three, which is also the 
same as multiplying every number from three down  
105:40 - until one, which we can see if we look at how it 
progresses through our tree structure. Here, we  
105:46 - can see the first three is passed. So first three 
is passed. And then three times two is passed  
105:54 - three times. So times three times two is best. 
And the result of three times two is six,  
106:02 - and six times six times one is past. So six 
times 123456 times one is past. So this for  
106:13 - loop first passes to three times, so passes 
to three times 123, which is the same as 333,  
106:26 - times times two, three times 123, passing two. 
And when we've asked to to the function, we do  
106:36 - two iterations, so three times two 
iterations. So we're going to do this,  
106:41 - we're going to iterate through this for loop of 
two iterations, three times three times two, and  
106:47 - then three times two is going to be six, because 
we do two iterations for each of these three.  
106:53 - So this, these iterations plus these iterations, 
plus these iterations equals six iterations. And  
107:02 - for each of these six iterations, we're 
going to pass one to the function, so six  
107:07 - iterations, so six times will pass one to 
the function. So that's here, six times one,  
107:14 - six times one, and that is factorial 
time complexity. I hope that makes sense.  
107:31 - So to understand space complexity, we'll 
take this function into consideration.  
107:36 - And this is a recursive function, that basically 
just returns a call to itself with its input in  
107:42 - minus one, it's going to do this until 
we reach a base case where n equals zero,  
107:47 - and then it's going to just return and at that 
point, this function will be complete. So let's go  
107:51 - ahead and draw with the execution of this function 
would look like. So let's say that we passed the  
107:56 - number five to this countdown function. So with 
this first call to countdown with argument five,  
108:08 - we'll end up at this base case. And we'll see 
that our n five is not equal to zero. So we'll  
108:15 - move on to this part of the code, which is just 
calling this function again with five minus one.  
108:29 - And of course, five minus one is going to 
be four. And once again, we'll end up here,  
108:34 - and we'll call the function 
again with four minus one.  
108:46 - And we'll continue to do this until we 
pass zero as our end to the function.  
109:07 - And I will need to make this a little bit smaller.  
109:11 - And finally, we get to the call where we're 
passing zero as our into the function.  
109:19 - At this point, if n is equal to 
zero, that function will just return.  
109:24 - So to understand space complexity, it's actually 
quite simple. So since this is a recursive  
109:29 - function, each one of these calls exists on the 
call stack simultaneously. So that means that if  
109:35 - we call our countdown function with five, it's 
going to then call itself with four and at this  
109:41 - point, this initial call still exists on the call 
stack. And the same for when we call three. These  
109:48 - two calls still exist on the call stack, and all 
the way down until we reach our base case. Every  
109:54 - single one of these calls still exists on the call 
stack. And each one of these calls takes memory.  
110:00 - So each one of these calls existing on the stack, 
they take up memory. And this is how we come to  
110:06 - an understanding of space complexity using this 
recursive function as an example, because if we're  
110:12 - returning at this point, when we reach our base 
case, that means that it means that we have 123455  
110:22 - calls taking up space on our call stack, and five 
also happens to be our value for n. So that would  
110:28 - mean that this function, its space complexity is 
O of n. So this function has a space complexity  
110:37 - of obon. So the most important thing to remember 
here is that all of these recursive calls exist  
110:43 - on the call stack simultaneously. And each one of 
them takes up memory, which is why, if we have,  
110:50 - if we pass in five, two as our n, we'll have 
five calls existing in memory simultaneously,  
110:57 - which means that our space complexity is going 
to be over then it's going to scale linearly with  
111:02 - the size of the input. So if we increase the size 
of this input, the space required to execute this  
111:07 - function is going to scale proportionally with 
the size of this input. So now that we have an  
111:14 - understanding of space complexity, we can get into 
some common mistakes that people make with Bingo.  
111:27 - And the first one being that when you first 
start out with Viggo, you might see a function  
111:32 - that looks like this that has two for loops. And 
you might instinctively assume that this function  
111:38 - is of all of in square time complexity, because 
you see that there are two for loops here. So  
111:43 - that must mean observe in square. But actually, 
as we've learned O of n square actually means  
111:48 - that for each iteration, up until the size of our 
input, we're going to iterate all the way through  
111:54 - an additional for loop up until the size of 
our input. So what does it mean if we have  
111:58 - two for loops that aren't nested that aren't old 
in square, it's actually quite simple. So we have  
112:04 - one for loop here, and we have another 
for loop here. And as we already know,  
112:10 - this for loop would be O of n, time complexity. 
And this one would also be O of n. So this point,  
112:19 - we have to all events, so that could easily be 
translated to o of two in, which is just all  
112:28 - of two times in so two times we have all of in. 
But if we remember from our previous lessons, we  
112:34 - ignore constants. And in this case, multiplying in 
by two, two is just a constant. So we can actually  
112:40 - just drop this constant, in which case, this just 
becomes over then. But there's one important thing  
112:46 - that we need to recognize here. This is all then 
because we're iterating through the same input for  
112:52 - both of these four loops. So as long as our loops 
are acting on the same input, then this would be  
112:58 - the resulting complexity. But there's actually 
another common mistake that people make when  
113:02 - taking time complexity into consideration, 
which is somewhat related to this mistake.  
113:08 - And this common mistake involves having 
two separate inputs to the function.  
113:18 - So let's first take this two inputs add function 
into consideration. So if you remember from our  
113:24 - last example, we only had an input, we only had 
one input, which was a and the two for loops loop  
113:31 - through that same input. But for this one, you can 
see that we have two separate inputs here. So we  
113:37 - have an input a, which is loop through in this top 
four loop. And we have an input B, which is looped  
113:43 - through in this second for loop. And some people 
might make the mistake of thinking that this  
113:49 - is the same as the last situation where the result 
would be o of two in. But this is actually wrong.  
113:59 - Because in this particular situation, we have no 
way of knowing the difference in size of both of  
114:04 - these inputs, like all we know is that these are 
two separate inputs. So these two separate inputs  
114:09 - could be of either completely different sizes, 
or they could be of the same size. But from our  
114:15 - analysis perspective, we have no idea. so in this 
situation, when we have two inputs, and we have a  
114:21 - separate for loop for each input, we're going 
to need to keep track of both of the inputs.  
114:29 - So in this case, the time that it would take to 
loop through both these for loops is O of A plus  
114:37 - B, because we need to first loop through this one 
up until we reach the value of a and then we need  
114:43 - to loop through this one up until we reach the 
value of V of B and at this point, this can't  
114:48 - be simplified any further we need to acknowledge 
the fact that both of these inputs are separate  
114:53 - inputs. So this would be over a plus b. And here 
we have the similar situation where we have two  
114:58 - inputs, but this Time The four loops are nested. 
And a lot of people make the mistake of saying  
115:04 - that this a function that looks like this is O 
of n square. But that would actually be wrong as  
115:11 - well, because what does O of n square mean over 
n square means that for every iteration of one  
115:16 - input, we're going to iterate through that 
same exact input. But in this situation,  
115:23 - when we have a, we have two separate inputs. For 
every iteration of one of the inputs, we're going  
115:30 - to iterate through the other input. So what that 
means is, this is wrong. In actuality, it's o of A  
115:39 - times V, because again, we need to 
specify that these are two different  
115:43 - inputs. And these inputs could be of 
different sizes. And we need to make  
115:48 - that visible when we take our complexity into 
consideration. So that is space complexity  
115:54 - and some common mistakes that people make with 
big O notation. I hope that that makes sense.