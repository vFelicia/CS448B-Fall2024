00:00 - this mock interview will show you what a
00:02 - data science interview is like Keith
00:04 - Galley is an experienced data scientist
00:06 - and interviewer and in this video he
00:08 - interviews Kylie Ying Kylie has taught
00:11 - multiple machine learning courses on our
00:13 - Channel this is a great video for anyone
00:16 - currently in the job market for a data
00:18 - focused role it's also a solid video for
00:21 - anyone who wants a better understanding
00:23 - of the machine learning process they
00:25 - cover topics that include building a
00:27 - data set for training testing purposes
00:29 - feature vectorization and model
00:32 - implementation details consider pausing
00:35 - after the questions and thinking about
00:37 - how you would answer them hey what is up
00:39 - everyone and welcome back to another
00:41 - video in it I'm going to conduct a full
00:44 - length data science interview I think
00:46 - that this video is great for any of you
00:47 - that are in the process of applying to a
00:49 - data science or data analytics role and
00:52 - want to get a sense of what a strong
00:54 - interview looks like even if you're not
00:55 - actively applying for a role I think
00:57 - that this video is also great for anyone
00:59 - that wants to build a better intuition
01:01 - of the data science process and the
01:03 - steps involved in creating machine
01:05 - learning models in this video I will be
01:07 - interviewing Kylie Ying Kylie is a
01:10 - fellow Tech YouTuber who makes content
01:13 - on topics that include programming
01:15 - projects python tutorials and lifestyle
01:18 - vlogging Kylie has both her bachelor's
01:21 - and master's degrees from MIT and she
01:23 - has a track record of success in the
01:25 - interview process receiving offers from
01:28 - Top tier companies such as meta the
01:30 - format of the video will be roughly a 45
01:32 - to 60 Minute technical interview
01:34 - followed by a breakdown of how that
01:36 - interview went where both Kylie will be
01:39 - giving me feedback as the interviewer as
01:41 - well as I'll be giving her feedback as
01:43 - their interviewee some important
01:44 - contacts I have conducted dozens of
01:46 - interviews when I was a part of the
01:49 - founding team of Posh Technologies from
01:52 - roughly the size of just five people to
01:55 - all the way until we were just under 40
01:56 - people I participated in most interviews
01:59 - so I've seen the good I've also seen the
02:01 - bad the questions that we walk through
02:03 - in this video are an adaptation of the
02:05 - style that we used in one of our
02:07 - interviews for data science candidates
02:10 - at Posh so I try to make it as real
02:11 - world as possible
02:13 - welcome uh how's it going today
02:17 - good how are you I'm doing pretty well
02:19 - the weather's not been too bad so I
02:21 - can't really complain
02:23 - um
02:24 - exciting to meet you uh exciting that
02:26 - you're interviewing for this team great
02:28 - to meet you too uh we've been uh looking
02:30 - for you know someone to fill this role
02:32 - for the past couple weeks and I know
02:34 - excited by your resume and just excited
02:37 - to learn more about you and kind of uh
02:39 - you know walk you through the task that
02:41 - we'll be uh solving today so I guess to
02:43 - start off I'm curious you know I read
02:45 - your resume but
02:47 - um just tell me a little bit more about
02:49 - yourself and I guess what you're looking
02:51 - for in your next opportunity your next
02:54 - role yeah so I finished my masters and
02:58 - undergrad from MIT I was doing a lot of
03:02 - electrical engineering computer science
03:04 - along with physics and in my next role
03:08 - I'm just looking for something more
03:10 - quantitative something intellectually
03:12 - stimulating
03:14 - um and you know just somewhere I can
03:16 - learn a lot so I saw this job and I
03:21 - thought I'd apply because
03:25 - based on the job description it just
03:27 - sounded like everything that I wanted
03:28 - you know yeah definitely and and
03:30 - honestly from my experience like we have
03:33 - a really hard working team we're working
03:34 - on hard problems exciting problems so
03:36 - definitely like fits that category I
03:39 - guess just to break into that a little
03:40 - bit more like what you just I said a lot
03:43 - of things computer science uh you know
03:44 - electrical engineering and physics I
03:46 - guess what made you kind of study all
03:49 - these things I guess what uh excited you
03:52 - about just that you know spread
03:56 - um I
04:02 - I wanted to I was I had the super like
04:07 - I was very interested in Ai and Robotics
04:10 - and I just really wanted to be able to
04:13 - just someday create Jarvis like to have
04:16 - the tools to create Jarvis and uh which
04:19 - by the way is Tony Stark's superhuman AI
04:23 - um and so I thought you know with
04:24 - computer science I would be able to have
04:26 - the programming the AI part of that but
04:29 - then also with EE I would be able to
04:31 - literally build the Iron Man suit which
04:33 - would be pretty cool
04:35 - um and then with physics I think it's
04:37 - just I've always been really curious
04:38 - about
04:40 - the evolution of the universe like
04:42 - what's out there black holes the
04:44 - galaxies stars all that good stuff and
04:48 - so when I took a relativity course it
04:50 - just really blew my mind that there are
04:52 - all these things that I don't I just
04:55 - you don't even know that are out there
04:56 - right like light bends around stars
04:58 - because of gravity like that's so cool
05:01 - yeah no definitely it's fascinating like
05:05 - especially exploring outside of my realm
05:08 - I don't have that physics experience
05:09 - that I'll have that kind of uh you know
05:11 - uh space exploration all of that fun
05:14 - stuff experience but I am fascinated it
05:16 - by it as well and also a fun fact I'm
05:19 - sure you're aware but Tony Stark was
05:20 - also an MIT grad so you're in good
05:23 - company there well I wanted to go to MIT
05:25 - smart
05:28 - um okay so I guess before we get into
05:31 - like kind of the real bulk of this
05:32 - interview I mean I think you kind of hit
05:34 - on it a bit with that but I'm curious to
05:37 - just dig into this a bit more so I mean
05:39 - in the past year or two even just really
05:42 - like past like six months there's been a
05:44 - ton of developments in the artificial
05:47 - intelligence machine learning space I'm
05:50 - just curious if there's anything that
05:51 - kind of sticks out to you that you're
05:52 - particularly excited about and if so
05:54 - like what that is and what excites you
05:56 - about that
05:58 - yeah so I definitely think that what
05:59 - everyone's talking about right now is
06:01 - like check EBT right because it's super
06:03 - disruptive everybody's like Googling how
06:06 - to write their essays or how to code up
06:09 - this
06:11 - you know something script
06:13 - um which is awesome but I would say that
06:16 - you know this this AI stuff I mean I'm
06:18 - super interested in it but more
06:20 - specifically I think I'm really
06:23 - interested in reinforcement learning and
06:26 - um
06:27 - and just getting a computer to beat
06:31 - humans at certain things or robotics in
06:34 - the sense of like self-driving cars I
06:37 - think that's really interesting being
06:38 - able to teach a robot how to interact
06:41 - and basically do what a human would do
06:45 - um also things like superhuman chess AIS
06:48 - or superhuman poker AIS I think that's
06:50 - all really cool because it's
06:53 - it's beating humans at a game that you
06:56 - would think you know is only for humans
06:59 - like chat like uh poker is built on
07:02 - psychology math and Randomness you would
07:05 - never expect there to be this like Nash
07:08 - equilibrium like Optimum solution right
07:10 - but there is which is really cool yeah
07:13 - it gets really really interesting when
07:14 - you combine the psychology element of
07:16 - the human experience with machines with
07:19 - AI and I think that from my experience
07:21 - that's something that's often overlooked
07:22 - and it kind of bothers me that it's
07:24 - overlooked because it's so important to
07:27 - the concept of artificial intelligence
07:29 - if it's going to be that intelligent so
07:31 - yeah definitely I think those things are
07:34 - super exciting awesome uh let's uh
07:38 - switch gears and I guess to give you a
07:40 - little bit of context my name is geeth
07:42 - Cali I'm a senior data scientist uh here
07:45 - on the team uh so you know the question
07:49 - that we're going to kind of present is
07:50 - something that we're actively looking at
07:52 - um here so this is kind of the task
07:55 - right now
07:56 - um
07:57 - so you're working as a data scientist on
08:00 - the team here at glitter
08:02 - um you know our CEO Mr elong tusk
08:06 - it has been complaining a lot recently
08:10 - and where social media site may be
08:13 - similar to something that you might be
08:14 - aware of but
08:16 - our CEO has been complaining a lot
08:20 - recently about the serious bot issue
08:23 - that's kind of infiltrated our site or
08:25 - you know he kind of has mentioned has
08:27 - infiltrated our site and uh become a a
08:31 - serious issue that we want to look at we
08:33 - want to you know mitigate and and solve
08:35 - so you know some things that these
08:37 - thoughts are causing some issues are you
08:39 - know they're quickly responding you know
08:41 - when our CEO posts and you know within a
08:45 - minute there's you know hundreds of
08:47 - replies promoting some sort of you know
08:50 - site some sort of program some sort of
08:52 - you know money scheme so there's Bots
08:54 - that are doing these you know quick
08:56 - postings uh there's you know coordinated
08:59 - Bots that are all over that you know the
09:01 - ecosystem that are
09:03 - sharing propagandist messages and
09:06 - sharing fake news messages
09:08 - so that's a little bit of context I
09:10 - guess before I dive into like you know
09:12 - some of the specific kind of guided
09:13 - questions
09:15 - um
09:16 - does that make sense uh what I kind of
09:19 - presented and I guess first off a
09:21 - question to you just kind of uh this is
09:22 - you know not really a data science
09:24 - question but do you have any thoughts on
09:26 - like other issues you know bots on this
09:29 - social media site might cause and things
09:31 - that we should be thinking about you
09:33 - know when we're investigating this issue
09:36 - yeah so I definitely think that
09:39 - obviously Bots are annoying right like
09:41 - nobody wants to be tagged in a million
09:43 - things nobody wants their entire
09:46 - um
09:46 - uh what's it called notifications to
09:49 - just be Bots spamming them right and I
09:52 - also think that Bots take away from the
09:55 - real conversations that might happen on
09:57 - this platform so
10:00 - um to reiterate
10:03 - um your question is I guess the current
10:05 - issue that you're trying to solve is
10:07 - that there are all these bot attacks and
10:09 - you know immediately after posting
10:11 - things get really crowded with these
10:14 - coordinated messages and spam messages
10:17 - and you're asking like what else yeah
10:21 - just this is an exploratory question I'm
10:23 - just curious and you know it's not
10:25 - really data science it's more platform
10:27 - driven I'm just curious you know right
10:29 - pick your brain and see if you have any
10:30 - other ideas with like potential issues
10:32 - with having serious you know bot issues
10:35 - yeah well I mean I just think that it
10:39 - like
10:40 - like I think I think Bots are there to
10:43 - Target A specific group right like all
10:46 - these money making schemes like do you
10:48 - really think that they're making money
10:49 - or is it just trying to scam people and
10:52 - like I know that especially in a lot of
10:54 - the crypto world there's a lot of bots
10:56 - that might
10:58 - that that might just be links to these
11:01 - fraudulent sites which end up draining
11:03 - your wallets or stealing your nfts or I
11:05 - don't know all these different
11:07 - um
11:07 - malicious schemes and so that's
11:10 - definitely
11:11 - one reason why like Bots are bad right
11:14 - because it's not just that it's crowding
11:17 - things it's also that your users
11:21 - are literally being the ones scammed off
11:23 - of and that does not create a good
11:24 - reputation for your company
11:26 - yeah definitely I definitely agree and
11:28 - you know obviously that's what we're
11:31 - trying to avoid so also I'm going to get
11:33 - into more guided questions but also like
11:36 - given this context and just you know
11:39 - your background as a data scientist uh
11:41 - you know do you have any any initial
11:43 - thoughts about the problem anything that
11:45 - immediately sticks out like that you
11:47 - would want to investigate about you know
11:50 - this this high level I guess issue and
11:53 - we'll dive into you know guided stuff
11:55 - but I just kind of also want to just
11:56 - gauge your high level you know thoughts
11:58 - on on the situation
12:01 - um by like thoughts on the situation do
12:02 - you mean just like what my first
12:05 - thoughts are on how I would tackle this
12:07 - problem exactly exactly
12:10 - yeah so I definitely think that with
12:13 - these Bots you mentioned a few different
12:15 - things right that it's coordinated that
12:17 - it seems like they're filling up
12:19 - immediately after
12:21 - um a post has been posted
12:25 - um it seems like
12:27 - you know there might be links to certain
12:29 - things or
12:31 - um certain themes that the attacks are
12:34 - always about and so I would start maybe
12:37 - investigating a bunch of these things
12:39 - and trying to figure out certain
12:40 - features of these attacks or these spam
12:45 - messages
12:45 - that might
12:48 - be able to for us with certainty say
12:51 - whether or not this is a spot a spot a
12:54 - sambot attack yeah
12:57 - um
12:57 - and I I also think that you know there
13:01 - are certain other attributes such as if
13:03 - they tag a ton of people right or if a
13:07 - single account posts multiple times or
13:10 - maybe the account follows a ton of
13:12 - people but nobody follows them I think
13:15 - these could all be certain traits of
13:18 - a Spam bot
13:20 - um and when you have multiple of these
13:23 - things in conjunction with one another
13:24 - then that strengthens the case that this
13:27 - might be you know spam
13:30 - um so I think that those are all
13:31 - different things to consider and maybe
13:33 - we can train a model based off of that
13:34 - to classify whether or not a message is
13:37 - Spam awesome yeah and you're kind of uh
13:39 - I guess getting ahead of even what I was
13:41 - I guess planning on asking next but this
13:43 - is exactly kind of where the discussion
13:46 - is going and I think
13:48 - I think because you've already kind of
13:49 - hit on some of these points I think
13:51 - maybe it would be nice to kind of drill
13:52 - down a bit more on okay you know some of
13:55 - these features that we're talking about
13:57 - here so what I'm going to do just
13:58 - because I think it's helpful for both
14:00 - you know myself as the interviewer as
14:03 - well as you you know you know
14:04 - brainstorming and thinking about these
14:06 - things I'm going to share a Google doc
14:08 - and let's try to like I guess get some
14:11 - of this on paper and we might drill into
14:13 - some of these a bit further and then I'm
14:14 - going to kind of ask some additional
14:16 - questions about this process and we can
14:18 - dive into those aspects okay further so
14:20 - sounds great I will share it just
14:22 - through the um
14:26 - the zoom one sec the zoom chat
14:35 - oh no no
14:40 - is that uh can you see the screen yep
14:44 - um
14:46 - not on Zoom anymore oh not on Zoom
14:49 - interesting
14:51 - in line right now oh yeah there we go
14:54 - let's try that again I think it's
14:55 - because I switched uh where it was on
14:57 - the uh okay the screen I have two
15:00 - screens open I switched the screen you
15:02 - know how it is uh so can you see that on
15:05 - Zoom
15:06 - yeah cool all right so I guess let's
15:09 - just start off
15:11 - um
15:12 - hello as well I'm going to delete that
15:14 - quickly
15:15 - um
15:17 - what are some features we should
15:20 - investigate
15:22 - um
15:30 - so I I label the question as what are
15:32 - some features we should investigate you
15:33 - can kind of interpret that as you will
15:35 - just basically let's just drill down and
15:37 - just get some bullet points maybe of
15:38 - some of the things you just mentioned
15:40 - just because I think that'll be helpful
15:41 - for reference throughout
15:43 - yeah so I definitely think that when you
15:46 - look at some bot
15:48 - attacks I think that there's
15:52 - probably a few main things to look at
15:54 - but the two that stand out to me are the
15:56 - content of the specific
15:59 - um
16:00 - the specific posts so content of the
16:04 - post and then as well as the person or
16:07 - the account that's actually making the
16:08 - post
16:11 - so I think in terms of content of the
16:14 - post these are things such as
16:17 - um how many people do they tag
16:20 - how many tags or for example
16:23 - um timing of the post or words mentioned
16:28 - in the post
16:31 - um
16:33 - what are other things maybe links
16:36 - Maybe
16:38 - maybe images
16:41 - um
16:43 - let's see what else
16:46 - when I make a post
16:49 - I type something send it out maybe tag
16:52 - well okay by tags I mean accounts tagged
16:55 - but also I think like keyword tags could
16:58 - also be another thing to look at okay I
17:01 - should like hashtags versus accounts
17:03 - tags yeah yeah that makes sense yeah
17:06 - yeah hashtags
17:09 - um
17:10 - so I think that's that
17:12 - covers a lot of like what would be in a
17:15 - post and then the account making the
17:17 - post we might want to see like how many
17:19 - followers yep they have uh maybe
17:25 - the number of accounts following or
17:28 - followed yep so followers and following
17:31 - following
17:33 - um
17:34 - and I think maybe like looking at a
17:37 - ratio between that might be a good idea
17:39 - as well
17:41 - um say that one more time I missed that
17:43 - maybe like the ratio between okay the
17:47 - number of counts that they follow and
17:48 - then how many followers they actually
17:49 - have yep um I also think that if you
17:52 - want to look at the followers Maybe
17:56 - um who the followers are because for
18:00 - example if we've already labeled a few
18:02 - accounts as specific spam accounts then
18:05 - when we I mean if if one accounts
18:09 - followers are completely spam accounts
18:12 - that we've already labeled then
18:15 - it's very likely that that account
18:17 - itself is a spam account right so
18:20 - um are the followers spam accounts
18:26 - um
18:26 - and
18:28 - something else could be
18:32 - um
18:33 - like the types of posts that they make
18:34 - like how repetitive are the posts that
18:37 - they make
18:38 - so if the account is posting the same
18:41 - thing every time
18:43 - like hey check out my
18:45 - like yeah YouTube video and the same
18:48 - link every single time then it's likely
18:50 - that that's spam right
18:53 - um
18:53 - content of account posts
18:58 - and I think one more thing to consider
19:01 - could be like for the content of the
19:04 - post and the account like so I do think
19:07 - that
19:08 - you guys have probably a report spam
19:11 - feature correct yeah yeah we do
19:14 - okay so I would say like I mean
19:18 - something that we could do is how many
19:20 - times has it been reported spam
19:22 - [Music]
19:23 - um
19:25 - or like how many times is something
19:27 - similar been reported spam but I do
19:30 - think that is a big indication in terms
19:33 - of both the content and the account
19:35 - itself
19:37 - yeah definitely I think this is a good
19:39 - definitely a good starting list
19:42 - um
19:43 - anything else that you can think of and
19:45 - maybe kind of think a bit outside the
19:48 - box here
19:49 - it doesn't necessarily have to be
19:51 - outside the box but
19:53 - um
19:54 - I guess one thing that I immediately see
19:57 - is that you know all these things are
19:59 - very publicly facing I'm just wondering
20:02 - too you know being the system
20:03 - administrators here is there anything
20:05 - else maybe on a more internal level that
20:08 - we might be able to factor in on the the
20:11 - Bots
20:15 - well okay so I do think that one
20:16 - internal thing would be like this
20:18 - reported spam yeah definitely I also
20:20 - think maybe another could be you know
20:22 - you mentioned earlier that there were
20:24 - these coordinated attacks so I think if
20:26 - you see like across like
20:30 - if you see a spike in the number of
20:33 - posts being posted within like a five
20:35 - minute interval or something like that
20:37 - and the content on all these posts is
20:39 - somewhat similar like the I don't know
20:40 - document distance is someone similar or
20:42 - something then perhaps those would all
20:45 - be
20:46 - um
20:47 - though that could be like a coordinated
20:49 - attack right
20:50 - yeah yeah okay yep so like similarity in
20:54 - amount of posts so if you just see this
20:57 - massive Spike then basically that might
20:58 - be some sort of indicator so somehow to
21:00 - capture that Spike yeah as it is so
21:03 - maybe all
21:04 - yeah so maybe I'll add like a separate
21:06 - category and just be and this could be
21:08 - like
21:10 - um
21:11 - aggregated action
21:12 - [Music]
21:15 - uh or aggregated
21:17 - things
21:18 - so maybe one of them could just be
21:20 - similarity
21:21 - of posts
21:24 - um in small time frame
21:26 - [Music]
21:29 - um something else that
21:31 - Twitter might have access to or the
21:35 - platform might have access to uh
21:41 - okay let's see I have like
21:44 - well okay so things that are private to
21:47 - an audience but are public to internal
21:50 - uh Twitter might be the emails even
21:53 - email addresses of the account yeah so
21:56 - that could go under the account making
21:57 - the post so like email address
22:00 - um I don't know whether or not you
22:01 - require all these emails to be verified
22:03 - but maybe like
22:05 - maybe if it's
22:06 - not a common domain or maybe if
22:12 - um
22:12 - maybe if like there's a lot of random
22:15 - letters in the email like the prefix
22:19 - then those could all point to
22:23 - um
22:24 - more spam-like and I think that this
22:27 - could be a little bit tricky because
22:29 - you know back in the 2000s we all made
22:31 - like really dumb email addresses right
22:34 - uh so I think that this could get a
22:37 - little tricky but I definitely think
22:38 - that there are indications of whether or
22:40 - not something is more spam-like
22:42 - definitely and I think that you made a
22:44 - really good point there with domain name
22:47 - uh just you know for context here too
22:50 - like uh you know you're more likely to
22:53 - be able to trust a Gmail address maybe
22:55 - than a you know random address you've
22:58 - never heard of so like some sort of
22:59 - waiting scheme could be interesting here
23:01 - right uh I guess in a size yeah that's
23:05 - why I was kind of like hesitant about
23:07 - that as well was because like for
23:10 - example
23:11 - you might have your own domain name
23:13 - right yeah geethkali.com or something
23:16 - like that and so your email might be
23:18 - like info at this rent this like custom
23:21 - domain name in which case we would want
23:24 - to make sure that people using that
23:26 - email address that does not get caught
23:29 - up in this like spam filter and filter
23:30 - too harshly that just because of the
23:33 - email it's considered spam yeah I think
23:36 - the way that I would look at it and I
23:38 - think that you're kind of hitting on
23:39 - this is that
23:41 - it could be an indie like I think a good
23:43 - domain address could be an indicator of
23:45 - like a valid account whereas maybe a bad
23:47 - one doesn't say that much I think that's
23:49 - kind of the point you're making yeah
23:52 - interesting thing just to note about
23:53 - Gmail just because I've been through
23:55 - this experience Gmail very much limits
23:57 - the amount of accounts that you can make
24:00 - um for a certain IP address so that
24:03 - definitely would help you know capture
24:05 - some positive emails because they could
24:08 - only make so many easily uh cool I think
24:10 - this is a great list I think the only
24:12 - other things I might add here is just
24:14 - like post engagement but I think this
24:17 - kind of encapsulate is encapsulated in a
24:19 - lot of the other stuff like you know you
24:23 - post engagement likes retweets all that
24:25 - or yeah as well as looking at the the
24:28 - details of who is liking these things if
24:31 - it as you mentioned with the followers
24:32 - if it's always the same spam accounts
24:34 - that we've identified previously
24:36 - probably not good engagement not organic
24:38 - engagement so I think this is a great
24:40 - list for this portion I think we can
24:43 - kind of move on to some of the other
24:44 - questions about the task but we'll keep
24:46 - this here for reference so I'm going to
24:49 - go and scroll down a bit on this post
24:53 - um
24:54 - the next thing I want to discuss and you
24:56 - know you can maybe start jotting up some
24:57 - thoughts on this is like okay we have
25:00 - all this idea of what we're looking for
25:01 - I mean a big portion of building let's
25:04 - say our goal as a team was to build a
25:07 - model that could identify and
25:10 - potentially remove these Bots
25:13 - um you know a big portion in training
25:15 - that model is having you know a data set
25:18 - to work with so I think thinking about
25:21 - the concept of a data set here you know
25:23 - what might that data set look like and
25:25 - how would we go about
25:33 - one sec let me just write this out as I
25:35 - speak it out
25:40 - yeah
25:41 - and then how would you approach
25:46 - um collecting I guess that data
25:50 - so kind of an open-ended question but I
25:52 - think it's a good one to you know start
25:54 - discussing
25:56 - yeah
25:57 - yeah so
26:00 - um
26:01 - I guess to first answer this question I
26:04 - would
26:05 - kind of look at this first part of this
26:08 - question like what would a data set to
26:10 - train models look like okay well so what
26:13 - exactly are the models that we're trying
26:15 - to train right and I think that
26:18 - you know of a lot of the
26:21 - the models out there
26:24 - um I think many of them would look very
26:26 - similar
26:27 - and I think that
26:30 - specifically
26:32 - uh we want some sort of feature Vector
26:35 - to be able to feed into these models
26:38 - and that figure Vector well it should
26:41 - probably summarize all the things that
26:43 - we just mentioned above right
26:45 - so
26:47 - um I think in terms of
26:52 - so I think
26:54 - this question also comes down to are we
26:58 - trying to tag the post specifically like
27:01 - do we have a model that are detecting
27:03 - spam posts or spam accounts and those
27:07 - are two different questions that we're
27:09 - trying to ask right
27:10 - yeah actually yeah which I would say in
27:13 - the context of this question what I was
27:15 - thinking about was a I think that it's
27:17 - good to you know thinking about both
27:18 - because you know one model probably
27:20 - wouldn't work for the other use case but
27:22 - I was thinking specifically about bot
27:24 - accounts and trying to detect those bot
27:26 - accounts and then you know what the data
27:30 - set might look like to help train the
27:31 - model to you know predict and and detect
27:34 - unknown right you know accounts
27:37 - okay so if we're trying to specifically
27:41 - Target these accounts then I might focus
27:43 - on more of the attributes of the account
27:47 - making the post that we had listed above
27:49 - so that so uh the bullet points under
27:52 - that are such as number of followers
27:54 - number of accounts
27:57 - um that follow them
28:00 - so
28:03 - count yeah and then
28:06 - um are the followers also spam accounts
28:08 - maybe the content of uh the account so
28:12 - maybe we can look at the last few posts
28:17 - um how many times this account has been
28:18 - reported spam the email address of that
28:20 - account
28:21 - and
28:23 - I think that the most basic
28:28 - thing that we can do is
28:31 - just feed everything into kind of a
28:34 - neural net right
28:36 - um
28:37 - I'm Gonna Leave This
28:39 - so
28:41 - for certain attributes I won't mention
28:43 - them yet but like a feature Vector for
28:44 - that might look like a number of
28:47 - followers
28:48 - number accounts
28:51 - or I guess number following that would
28:53 - be a better way to describe it those are
28:56 - very
28:58 - um black and white numbers right so
29:01 - there's no question about whether or not
29:02 - we can beat that into a neural net yep
29:04 - or some other model
29:06 - um
29:07 - now this next question are the followers
29:09 - spam accounts
29:11 - so
29:13 - that's kind of this like almost circular
29:16 - logic so I will maybe leave that off for
29:19 - now
29:21 - um the content of the account I will
29:22 - come back to that and then how many
29:24 - times it's reported spam so number of
29:27 - spam reports on this specific account
29:29 - yeah
29:31 - um
29:32 - and then the email address okay so
29:36 - I think that
29:38 - this is a good start but obviously it's
29:40 - not enough so let's talk about maybe
29:43 - let's go with the email address first
29:45 - yep
29:48 - so the thing is in here I would want to
29:51 - maybe
29:51 - [Music]
29:52 - sorry letting the sirens pass
29:58 - [Music]
30:03 - can you hear it anymore I can't hear it
30:05 - before at all
30:07 - oh really I never heard of sirens oh
30:10 - oh okay
30:12 - um so right now we have three different
30:15 - things the number of followers number
30:16 - following and then the number of the
30:18 - spam uh reports but I also think that
30:20 - maybe there's some value that we can uh
30:25 - assign to the email address of whether
30:27 - or not it's
30:29 - more spam-like or whether or not it's
30:31 - safer right
30:33 - and well I I'm maybe you're gonna get
30:36 - into this but what might like a simple
30:38 - or you know model for that look like
30:41 - right so I think that
30:44 - I mean okay so a very basic basic basic
30:48 - model it could just be you have all
30:49 - these domain names that
30:52 - like you know of
30:55 - um that are popular that are common out
30:57 - there and we would want to get you know
30:59 - many different countries not just what's
31:01 - popular here in the US but suppose you
31:04 - have a bunch of
31:06 - like domain names that are popular then
31:10 - this could be a very simple like one
31:12 - zero like whether or not it has that uh
31:16 - opposite of prefix that like domain name
31:19 - in the email address right so like
31:21 - one for uh Gmail oh
31:26 - okay
31:28 - oh you can't see that okay but anyway
31:30 - one for gmail.com hotmail.com
31:33 - uh yahoo.com
31:36 - Etc yeah
31:39 - um and then zero otherwise yep
31:42 - so that would be a very basic
31:45 - value for email now to get into things
31:49 - that are maybe something a little bit
31:51 - more complicated
31:53 - um we could even train a classifier on
31:55 - just emails right if we had an entire
31:58 - data set of emails that are
32:01 - um that are good and bad that are you
32:05 - know not spam and spam
32:08 - um we could train a classifier on that
32:10 - which would spit out a probability or
32:13 - yeah which is put out a probability of
32:16 - You Know How likely it is to be spam or
32:19 - not spam and so maybe certain attributes
32:21 - of that email address could be in fact
32:23 - this domain name
32:25 - uh so maybe we have some sort of
32:29 - um one hot
32:31 - encoding system for these so one hot
32:35 - encoded uh domain name and then
32:39 - Maybe
32:41 - can you just quickly explain what a
32:43 - one-hot encoded domain oh yeah what
32:46 - would that would look like just so
32:47 - clarify yeah yeah yeah so uh let's say
32:52 - that so basically in
32:57 - zeros and ones to encode a certain value
33:00 - and so by that what I mean is let's just
33:03 - take these three Gmail Hotmail and Yahoo
33:05 - yeah and put them into like a list like
33:09 - this right so position one would be
33:11 - Gmail position two is Hotmail and
33:12 - position three is Yahoo so one hot
33:15 - encoding for this for like something at
33:19 - gmail.com this email address would then
33:22 - be encoded as one zero zero then maybe
33:27 - something at hotmail.com would be
33:30 - zero one zero and then something at
33:35 - yahoo.com would be zero zero one now if
33:40 - I had something at random dot ABC then
33:45 - this would actually get encoded to zero
33:47 - zero zero got it but basically what one
33:50 - hot encoding is doing is it's trying to
33:52 - assign a numerical value to something
33:56 - that is not numerical because our
33:57 - computers are very good at understanding
33:59 - numerical values right trying to assign
34:02 - something numerical to something that is
34:04 - not
34:06 - um and it's trying to make it so there's
34:07 - no association with one another so
34:10 - something that you might be asking is
34:11 - why can't we do one
34:14 - two three four and just call that a day
34:17 - right that's because this is telling us
34:19 - okay one is closer to two numerically
34:22 - than it is to three but it shouldn't
34:26 - matter in our case because Gmail should
34:29 - not be closer to Yahoo than Hotmail is
34:31 - to Yahoo right they're just different
34:33 - categories they're not more similar or
34:35 - less similar so that's why we're using
34:38 - this one hot encoding got it cool
34:42 - um
34:43 - and something else that we could do so I
34:47 - do want to use like the characters in
34:52 - the email itself yeah for this
34:54 - classifier
34:56 - um I'm trying to think of like how I
34:59 - would do that I might
35:01 - well also I do think that
35:04 - if there's a name or
35:07 - a word yeah in the email it's probably
35:10 - more likely to not be spam yep right so
35:14 - I think that maybe like having a list of
35:17 - common names and common
35:20 - um
35:22 - common words yeah
35:24 - that we could check that again so that
35:26 - could just be like a zero one binary
35:28 - encoding for whether or not common names
35:32 - or words up here
35:34 - in email and I think this one's also
35:37 - kind of tricky because I do think that
35:39 - you have to consider different languages
35:41 - right and
35:45 - and so this this would be something to
35:48 - think about if we were actually building
35:50 - this model is like we would need to
35:51 - think about the different languages and
35:53 - different names in different languages
35:55 - and stuff like that
35:58 - um
36:00 - so
36:01 - for now what I might do is just this
36:04 - simple encoding scheme where we just get
36:06 - a bunch of common address
36:10 - um domains and then zero or one for that
36:13 - I think that would suffice for now yep
36:17 - um
36:18 - now in terms of this now let's go back
36:21 - to this like content that the account is
36:23 - posting
36:24 - so
36:26 - I do think it makes sense to not scrape
36:29 - the entire like Post history of the
36:32 - account because I think that would that
36:33 - might be excessive like I think if it's
36:35 - a true spam account then like the first
36:38 - five or ten should suffice
36:40 - right so I think what we could do is in
36:43 - here have certain
36:47 - features for like post number one yeah
36:49 - post number two
36:52 - Etc to post number let's say we do 10.
36:55 - yep
36:56 - and now scrolling down a little bit
37:00 - um
37:01 - the indent all of this
37:08 - why did it make a bullet list what was
37:11 - it a bullet list I guess some of it was
37:13 - no but I I made it I did that nice yeah
37:18 - um just for organization yeah I
37:20 - appreciate organization
37:23 - yeah
37:26 - so this is basic including
37:31 - something
37:34 - more complex would be this okay so now
37:37 - let's think about the posts
37:40 - so with the posts
37:43 - um that would be a lot of this stuff
37:45 - from up here which I'm just going to
37:47 - copy and paste down here
37:50 - Okay so
37:53 - the first one could be accounts
37:56 - tag okay what are the simple ones the
37:58 - simple ones are things such as
38:02 - um how many times
38:04 - number of spam reports for that specific
38:06 - post yep
38:08 - um
38:09 - Maybe
38:11 - okay the time timing of posts I think
38:15 - that can be easily converted to uh like
38:21 - an Epoch value or something
38:24 - um and the only reason why I want to
38:26 - consider the timing of the post is
38:28 - because
38:30 - if for example the last 10 posts were
38:32 - posted within like one second of each
38:35 - other yeah that probably indicates a
38:37 - Spam bot right
38:39 - um so that's the only reason why I want
38:40 - to consider this timing and I think that
38:42 - it would make sense to maybe use some
38:45 - sort of integer representation so maybe
38:47 - like seconds or milliseconds since Epoch
38:51 - um
38:52 - like
39:00 - so yeah
39:01 - uh and then next I would think about
39:07 - and just uh just because you know with
39:10 - our team we have to communicate these
39:11 - things to you know business stakeholders
39:14 - that sometimes don't understand some of
39:16 - these details could you just kind of a
39:18 - very I guess simple terms what is it
39:21 - mean milliseconds since epoch
39:27 - it's like I think it's January 1st at
39:30 - midnight on in 1970 or something like
39:33 - that
39:35 - um but you can think of it as literally
39:38 - just like number of seconds or number of
39:40 - milliseconds since a certain time period
39:43 - like 30 no 50 oh man 50 years ago yeah
39:48 - um
39:49 - yeah so it's basically
39:51 - discretizing time such that we can
39:54 - measure it as an integer
39:56 - yep
39:59 - um okay so then next I think we have to
40:02 - think about all these tags and the
40:04 - content in the post right
40:07 - um I do think that
40:09 - one easy thing to do could be like for
40:14 - the words mentioned in the post
40:16 - uh to have some sort of
40:20 - again like one hot encoding for very
40:24 - common spam words yeah so so just like
40:30 - um claim free uh
40:36 - can't think of all the ones but yeah
40:39 - yeah yeah I'm not I'm not a Spam bot
40:42 - yeah but that's good that's good we're
40:44 - not hiring spam Bots right now so yeah
40:48 - so maybe like a one hot encoding of
40:50 - common spam words
40:52 - cool
40:55 - um
40:56 - and I think that maybe this could also
40:58 - be similar for like the hashtags as well
41:01 - but
41:03 - I think that this could Encompass the
41:05 - hashtag right because if we're just
41:07 - looking for whether or not these words
41:08 - appear in the entire string of of words
41:13 - then like that would cover the hashtags
41:16 - as well cool and I think honestly I'm
41:19 - just looking at the time here I I do
41:21 - want to kind of switch gears a bit I
41:22 - think this is a good you know high level
41:24 - description of it implementation I do
41:27 - want to just ask some kind of follow-up
41:29 - questions to these things yeah so I
41:31 - guess just circling back first I think
41:32 - that really you dove into the details of
41:34 - implementation I think that this is a
41:36 - solid approach using this feature
41:39 - vectorization approach and kind of you
41:41 - know I think you did a good job
41:42 - explaining some of these details but I
41:44 - do want to revisit kind of the uh one of
41:47 - the initial questions which was you know
41:49 - we have this way of building this model
41:51 - with these feature vectors but you know
41:54 - at the end of the day we need to train
41:55 - these models and we need a data set to
41:57 - train these on so I guess I just really
41:59 - want to drill down specifically on that
42:01 - like what would the data set that we
42:04 - need to use this approach maybe look
42:06 - like and just any I guess thoughts on
42:09 - that and I'm going to just break this
42:11 - apart real quick and just say
42:13 - um implementation approach or something
42:16 - like that
42:17 - to separate it a little bit visually
42:19 - does that make sense what I'm asking
42:21 - yeah yeah so you're just asking like how
42:24 - would I collect that data yeah the data
42:26 - that I just described well well yeah so
42:28 - I guess what I'm thinking about is the
42:30 - data you just described I think is
42:31 - fairly straightforward to collect but at
42:33 - the end of the day we need a I guess the
42:35 - two questions I want to drill down on is
42:37 - what makes an account a human and what
42:40 - makes an account a bot like how do you
42:43 - I guess get data on bot accounts and
42:46 - bought and maybe human accounts like
42:48 - because at the other day we need that to
42:50 - make this a meaningful model
42:53 - right so I do think that
42:57 - um
43:00 - well okay so at the end of the day who
43:02 - is the person who can distinguish the
43:04 - bot right it's humans it's humans
43:06 - because when we get annoyed at seeing
43:09 - spam or something like that like that's
43:11 - when that's that's what makes
43:14 - that's what literally makes this a Spam
43:16 - post it's once some human it decides I
43:19 - don't want to see this content and this
43:22 - is spam
43:23 - so I actually think that one of these
43:26 - things that I kept mentioning which was
43:28 - how many times has this been recorded
43:30 - spam I actually think that that could be
43:32 - our label right for whether or not
43:36 - the account is Spam or not yeah so
43:40 - um
43:42 - this
43:45 - this is how we can label spam because at
43:49 - the end of the day this is a this is a
43:51 - classification problem it's is it spam
43:53 - or is it not spam
43:56 - um
43:57 - and what our data is collecting is we're
43:59 - collecting all of these features
44:01 - but then we need a label for that
44:03 - feature right and
44:06 - that label we want two different
44:09 - categories is it spam or is it not spam
44:11 - yeah
44:12 - um
44:13 - and obviously the more time something
44:15 - has been reported spam the more likely
44:17 - it is to be under category one yeah
44:19 - right so
44:22 - I think one of the most basic ways to do
44:25 - this uh could just be if it's reported
44:29 - spam over blank number of times then
44:33 - make that like
44:36 - then label that as spam
44:40 - so naive labeling system could be
44:49 - reported spam
44:51 - X number of times
44:54 - then label spam
44:58 - and this X
45:00 - this is really up to
45:02 - like what you're like how much data do
45:04 - you want to collect right because you
45:06 - don't really want to kind of fake that
45:09 - data because you know as I was trying to
45:11 - come up with these things down here it's
45:12 - it's pretty hard to fake being spam if
45:15 - you're not spam yourself yeah
45:17 - um
45:19 - and then for the non-spam I would just
45:22 - do like if no reports of spam then uh
45:28 - label as not skin and also I think that
45:31 - these no reports and this reports fam
45:33 - like I think that you should put some
45:35 - sort of time
45:37 - frame on this so like since account
45:39 - creation uh
45:42 - for longer than a week or something like
45:45 - that if it's never been reported spam or
45:48 - if it has been reported spam then I
45:50 - think that can give you a good
45:53 - um
45:54 - indication or maybe not a week you would
45:57 - have to set the threshold right yeah but
45:59 - you don't want like a brand new account
46:01 - to be part of this system
46:05 - definitely makes sense okay I I you know
46:07 - I think this makes sense as a naive
46:09 - labeling system you know my big concern
46:12 - is here it is like I guess what are the
46:15 - problems potentially with this approach
46:16 - like you know how could we build this
46:18 - make this more robust I guess either you
46:20 - know maybe identify what could
46:22 - potentially be a problem here or
46:25 - potentially just mention an idea or two
46:27 - about how could we make this more robust
46:31 - yeah so I definitely think that this is
46:34 - relying a lot on user feedback right
46:37 - it's relying a lot on whether or not
46:38 - somebody has reported something as spam
46:42 - yeah
46:43 - um
46:44 - I do think
46:46 - like
46:48 - I mean okay so one
46:50 - slow but
46:53 - sure way that you could label uh certain
46:57 - things a Spam or not spam is that you
46:59 - could just have like
47:01 - like you could just hire people to go
47:04 - through different posts and different
47:06 - accounts and say oh this one is Spam
47:08 - like we should use this as
47:10 - um a Spam account to model
47:14 - to model after
47:15 - or to include in our data set sorry
47:18 - but that would then be also kind of
47:21 - tedious slow
47:24 - um you would have to pay more just to
47:26 - collect data that you already have
47:28 - um another system might be
47:32 - hmm
47:36 - um
47:37 - sorry let me think for a second no
47:40 - problem
47:45 - so I really I do think that this like
47:49 - this reporting spam is a good indication
47:52 - because it's similar to how like waves
47:54 - works yeah right how like
47:58 - oh is there
48:01 - well okay one thing that you could do is
48:03 - you could just Implement something that
48:05 - makes it more incentivized for user to
48:07 - correctly label things as spam or not
48:11 - um so for example
48:14 - uh you could have a larger
48:18 - an easier system of reporting spam or
48:22 - um you could have
48:24 - literally a direct question of whether
48:26 - or not something is Spam or not yeah
48:29 - um
48:30 - because I do think user feedback is
48:33 - probably one of the most important
48:37 - because after all you're building a
48:38 - product for your users right and like
48:40 - their feedback their classification of
48:42 - whether or not something is Spam or not
48:43 - that's going to be what's important
48:46 - um
48:48 - so
48:50 - maybe like if there's some
48:53 - in like maybe we can
48:56 - start tracking some of these things and
48:58 - just coming up with something naive like
49:00 - things that are obvious as spam accounts
49:04 - um if those specific attributes pop up
49:07 - then we could automatically just be like
49:10 - oh do we think that this would be
49:12 - spam like you could have a poll that
49:16 - presents to the the user that would make
49:19 - it easier to label a Spam or not
49:21 - yeah
49:23 - um I think I think that that suffice
49:24 - because that kind of answers my question
49:26 - I think the only details that I would
49:28 - add from my end here is that you got to
49:31 - keep in mind that there's a lot of
49:32 - trolls on social media a lot of people
49:34 - that are Bad actors and when we're
49:36 - designing a system like this we need to
49:38 - keep that in mind there might be
49:39 - targeted attacks people labeling someone
49:41 - they don't like as spam so we also need
49:44 - to factor that in and so that would be
49:45 - one component I would add here another
49:47 - thing I would just quickly mention too
49:49 - is I I don't think it's actually a bad
49:51 - thing to do a little bit of human
49:52 - annotation I think a lot of you know
49:54 - tasks sometimes require that I think the
49:56 - important thing is we want to
49:58 - cross-reference our annotations because
50:00 - we might be paying a group we might not
50:02 - be monitoring them super closely so we
50:04 - want to make sure that they are not just
50:05 - taking a random box so you know
50:07 - something just think about right there
50:09 - right cool well I also do you want to
50:11 - add one more thing to this is like maybe
50:14 - your threshold should not be like number
50:16 - of times but maybe it should be like
50:18 - ratio of like spam reports to engagement
50:22 - or something like that right yeah
50:24 - um because even if there are many Bad
50:27 - actors I do think that most people
50:30 - uh would act the way that you yeah would
50:34 - think that they act so I think like
50:35 - there can't there probably aren't more
50:36 - than like 10 or 20 percent like people
50:38 - who would deviate from that expectation
50:41 - so for example if like I think that's
50:44 - that's the importance of this threshold
50:46 - right that's the importance of saying
50:48 - well how strict do I want to be such
50:51 - that
50:52 - um like do I want the the stricter I am
50:56 - with this threshold the more confident I
50:58 - am that this has to be spam yeah right
51:01 - and so that's that's the importance of
51:04 - this labeling system is how strict do
51:05 - you want to be because the stricter you
51:07 - are the less data you have to train on
51:10 - is another consideration yeah okay that
51:13 - yeah that makes sense and I I think that
51:15 - that ratio idea is an interesting idea
51:17 - and you know the only really way to know
51:19 - is to actually try this out test it so
51:21 - it's hard to know with certainty but I
51:23 - think the important thing is having
51:24 - these different ideas that are worth
51:26 - playing around with and uh attempting
51:28 - okay uh I'm gonna ask one just because
51:31 - we're running uh up on time I'm going to
51:33 - ask I think maybe just one last question
51:35 - on this problem I'm going to stop
51:37 - sharing the screen you don't have to use
51:38 - the document anymore we can kind of just
51:39 - chat about this I'm just you know from a
51:43 - you know let's start thinking a little
51:45 - bit more about implementation of this
51:48 - um you know thinking about Python and
51:51 - maybe the larger Cloud ecosystem like
51:53 - you do kind of have a high level feel of
51:56 - how you might approach the actual
51:57 - technical implementation of you know
51:59 - building this model
52:01 - or anything that keeps comes to mind so
52:03 - maybe certain libraries certain uh
52:06 - Frameworks certain just like Cloud
52:08 - resources Etc I'm just curious you know
52:10 - from a implementation standpoint
52:12 - anything that kind of sticks out that
52:14 - you know you'd probably do from approach
52:17 - yeah so I would definitely say I'm
52:21 - probably the most familiar with like
52:22 - tensorflow so a lot of
52:26 - um how I would be modeling this is I
52:27 - would probably start with my data set
52:29 - and then I would probably go into like a
52:31 - Jupiter notebook or
52:33 - um a collab notebook and I would try to
52:36 - mess around with it just to see you know
52:39 - what what is the simplest model that I
52:41 - can make to to have some sort of
52:43 - okay-ish
52:45 - um
52:46 - classification rate right and a few
52:50 - things that you could use in order to
52:53 - figure out how well your model is
52:55 - training like it depends on how
52:57 - important to you
52:58 - false positives or false negatives
53:02 - are right
53:04 - um
53:05 - and
53:07 - like more so than accuracy like I think
53:09 - those are things that you should be
53:10 - looking at and also I think that
53:15 - um
53:16 - yeah anyway sorry to get back to your
53:18 - original question is that's how I would
53:19 - start this and then in order to deploy
53:23 - this I'm actually not that familiar with
53:25 - deploying uh certain models but I would
53:28 - assume that you use some sort of like uh
53:30 - GPU to accelerate the training and then
53:34 - um or yeah sorry this is during still
53:36 - the training phase but maybe you're
53:37 - training a much larger model than the
53:40 - initial one that we came up with in our
53:42 - notebooks yeah so you would use like GPU
53:44 - some other resources to train it to
53:46 - accelerate that training process you
53:48 - would parallelize
53:50 - um
53:51 - and then when you actually deploy it I
53:53 - mean everybody uses like Cloud
53:55 - technology these days so I I feel like I
53:57 - just deploy it to some
53:59 - Cloud that serves the model and
54:03 - um
54:04 - and every single time we have a new post
54:05 - we can just filter it through
54:08 - or not a new post but maybe
54:11 - um some new account that's flagged or I
54:13 - don't know something like that we can
54:14 - just go through this model and say oh
54:16 - this might be a Spam account
54:18 - yeah would we want to do it a single
54:20 - post or would we want to like
54:22 - I I guess I'm just trying to think about
54:24 - that detail as like you know each post
54:26 - goes through this or is any other things
54:28 - that we might want to do here
54:30 - well so the way that we implemented this
54:32 - it would be the specific accounts okay
54:34 - right
54:36 - um so I I do think that you would maybe
54:39 - wait for an account to have
54:41 - a few posts but then
54:45 - well so how I think the tricky part is
54:49 - how do you catch a Spam account before
54:51 - it posts any spam
54:54 - right and so the way that we've set this
54:57 - up it's it's to kind of go through
54:59 - existing users and label them as fam or
55:02 - not
55:03 - I do think it could be interesting for a
55:06 - future model to to maybe assess the
55:09 - first
55:10 - post that an account makes and determine
55:13 - whether or not it's a spam
55:16 - uh Post Yeah and then from there you
55:20 - know if it's if it determines that it's
55:22 - not and there's no way like maybe these
55:25 - newer accounts should just be ones that
55:27 - you keep monitoring for a while and you
55:29 - keep reassessing whereas older
55:32 - I guess you would say Legacy accounts
55:34 - might have
55:36 - um
55:37 - might have more lenience right
55:40 - yeah unless maybe a ton of people start
55:42 - flagging it yeah but uh but hopefully
55:44 - our hopefully our other implementation
55:47 - would be able to catch that yeah that I
55:50 - think that makes sense to me cool I
55:53 - think that's all I have on this prompt
55:55 - uh this was an enjoyable discussion uh I
55:57 - think you know it's interesting to think
55:59 - about I think there's a lot of different
56:00 - Avenues you can go so right I know we're
56:03 - running up on time I do want to just I
56:05 - guess quickly pause and uh just see if
56:08 - you have any questions for me before we
56:10 - kind of conclude this uh interview
56:14 - yeah definitely so I'm just wondering
56:17 - um like what are your favorite and least
56:20 - favorite aspects of you know your role
56:22 - as a data scientist at this company so
56:24 - far yes I think the big one is I
56:27 - mentioned it at the start of the
56:28 - interview is just
56:30 - um the team the team is really
56:32 - impressive you know it's a diverse set
56:35 - of backgrounds both people you know PhD
56:37 - type people from Harvard MIT but also
56:40 - just some really really brilliant
56:42 - self-educated kind of just learned the
56:44 - stuff on their own bring a different
56:46 - perspective to the table people that are
56:49 - on this team so you know from my
56:52 - perspective you know one of my biggest
56:53 - goals you know in this role is I want to
56:55 - continue to grow I want to continue to
56:57 - develop you know certain skills that I
56:59 - have like I come from a natural language
57:01 - processing background you know I can
57:03 - apply those skills but I don't have as
57:05 - much of that systems background I don't
57:07 - know how to you know deploy this on a
57:09 - production scale so you know what I
57:11 - enjoy
57:14 - um you know most I think about this role
57:16 - is just the opportunity to gain you know
57:19 - those insights to learn from people that
57:21 - have expertise and skill sets I don't
57:23 - because I think that that is helping me
57:25 - become a more rail rounded
57:28 - um you know member of the team I guess
57:30 - on a separate note like that's very much
57:31 - like team based but also there's just a
57:33 - lot of flexibility to move around in the
57:36 - role like I've kind of stepped into more
57:38 - of a managerial type role recently
57:40 - whereas I very much was more of an
57:42 - individual contributor writing code you
57:44 - know on the front lines previously so I
57:46 - like that too uh on the flip side I
57:49 - think at least uh what I enjoy at least
57:52 - uh you know this is I guess love hate
57:55 - relationship but you know work here is a
57:58 - bit of a grind like we work hard hours
58:00 - we you know it's uh you know to be
58:03 - classic and cliche you know Work Hard
58:04 - Play Hard wait sorry yeah Work Hard Play
58:07 - Hard that's the saying
58:09 - um so I mean it's
58:10 - uh we put a lot of hours in there's late
58:14 - nights sometimes but I think with that
58:16 - you you do get that learning but it's
58:18 - just like sometimes it's a balance it's
58:19 - like just making sure you know when to
58:21 - step back and and reassess and just like
58:23 - not get too burnt out so uh love hate
58:27 - relationship on that side but I think
58:28 - that overall I would take that over not
58:30 - being challenged yeah okay
58:33 - awesome
58:34 - um and how long have you been working
58:36 - there so far uh I think this is my fifth
58:39 - year so you know it's been a little
58:41 - while so you know I've yeah because I've
58:44 - had the ability to kind of switch around
58:45 - my role I think I've
58:47 - stayed
58:48 - kind of engaged and yeah I've just had
58:52 - opportunities to learn different stuff
58:53 - and I think that's kind of what has
58:54 - helped me stay this long right yeah yeah
58:57 - awesome because my follow-up question
58:59 - was going to be like what opportunities
59:01 - for growth are there like within the
59:04 - company and how how does the company
59:07 - support that growth yeah
59:09 - yeah
59:10 - um
59:11 - I mean there's a couple things I think
59:13 - just in general from from being in a
59:15 - team environment where there's a lot of
59:17 - just driven people that want to know the
59:20 - latest you know the state of the art
59:21 - like sometimes it just naturally kind of
59:23 - comes out during lunch discussions and
59:25 - whatnot some people are working remotely
59:26 - some are at you know the office but you
59:29 - know both channels like you know if I'm
59:31 - at the office we go out and you know
59:32 - some of this just the discussions just
59:35 - happen naturally you know at lunch or we
59:37 - sometimes host remote kind of like you
59:40 - know Zoom lunches where we all kind of
59:41 - just hang out and you know chat about
59:43 - things so that's like kind of an
59:45 - informal way from a formal perspective
59:47 - like
59:49 - we try to you know make sure that
59:51 - everyone that's here is Happy uh we you
59:54 - know have routine
59:58 - um you know performance kind of
60:00 - check-ins and perform like I don't I
60:02 - don't say performance as a like you know
60:04 - very strict like if you don't meet
60:06 - certain bar you're out but it's very
60:08 - much a constructive process where
60:09 - everyone on the team no matter who you
60:11 - are whether you're you know the CEO or
60:14 - if you're you know a junior engineer
60:16 - like everyone has performance reviews
60:18 - someone on the team is tasked with
60:20 - evaluating and having that conversation
60:23 - what you're doing well what could be
60:25 - improved so there's like constructive
60:27 - feedback across the board and we try to
60:29 - do that
60:30 - um awesome either every quarter or every
60:33 - other quarter typically every quarter we
60:35 - try to have something yeah sometimes
60:36 - it's more formal sometimes a little bit
60:38 - less formal but everyone's critiquing
60:40 - everyone no matter if you're the you
60:42 - know CEO uh or you know you're more
60:45 - Junior
60:47 - awesome
60:48 - um and then for my final question just
60:50 - how like what what would my first maybe
60:53 - six months kind of look like what would
60:55 - uh be some of the projects that I'm
60:57 - working on look like yeah
60:59 - so I mean I think one of the most
61:01 - important things from my perspective for
61:04 - anyone joining the team is we don't want
61:07 - to have new team members be siled we
61:09 - want to make sure that they are exposed
61:12 - to what we have kind of out there on not
61:15 - just my team but you know surrounding
61:17 - teams so a couple of things that you'll
61:19 - be kind of doing is first off you'll be
61:21 - you know assigned immediately upon
61:23 - arriving a mentor that can kind of help
61:26 - guide you and
61:28 - um you know you'll specifically like
61:30 - this is a role for you know my team so
61:32 - like they would be kind of introducing
61:33 - you to our systems walking you through
61:35 - the code base you know introducing you
61:37 - to the other people on the team so one
61:40 - of the big things is like you have this
61:42 - Mentor that's kind of there to guide you
61:43 - everywhere every step but another
61:45 - important point is like we try to make
61:47 - sure you get one-on-ones with everyone
61:49 - on the team within the first month
61:52 - approximately at least within our small
61:54 - team so like you get to meet everyone on
61:56 - the team you get introduce the code base
61:58 - so it's really just kind of getting
61:59 - warmed up getting comfortable seeing
62:01 - things yeah probably you know
62:03 - end of month one to like you know month
62:06 - three a big part of it will be you know
62:09 - tackling some kind of more entry level
62:11 - tickets on the systems really get your
62:14 - hands dirty plug in and and you know
62:18 - they won't be the most complex you won't
62:19 - be designing a system from scratch but
62:21 - taking our existing systems you know
62:23 - ironing out some bugs all that get more
62:25 - comfortable right uh after that you'll
62:28 - be kind of more potentially leading not
62:30 - leading but like kind of help co-lead
62:33 - certain initiatives yeah and that has a
62:35 - little bit more flexibility you can kind
62:36 - of get different ways whether you want
62:38 - to be really the one grinding out the
62:40 - code or you want to be more thinking
62:41 - about the design and all that and I
62:43 - think the only other thing is like kind
62:44 - of throughout this process we try to
62:46 - also introduce you to some of the teams
62:48 - that we work closely with so you'll
62:49 - definitely have some interaction with
62:50 - them but that does that answer your
62:52 - question
62:53 - yeah for sure yeah awesome well I don't
62:57 - have any other questions awesome so I
62:59 - think next steps from here is there's
63:00 - going to be a software engineering uh
63:03 - interview so that will test more your
63:04 - python skills and then also
63:07 - um
63:08 - likely it would be like a behavioral
63:09 - interview as well where uh just great
63:12 - engage a little bit more of your career
63:13 - interest and all that so next steps
63:15 - you'll hear back with us in the next few
63:17 - days probably and we'll go from there
63:20 - okay awesome well thank you so much for
63:23 - taking the time
63:24 - yeah it was a pleasure and uh nice
63:26 - meeting you and enjoy the rest of the
63:27 - day
63:28 - yeah you too thank you see ya bye
63:32 - all right end interview I'm not Keith
63:35 - Cali anymore I'm Keith galley
63:38 - you put me on the spot answering uh some
63:41 - of those questions at the end I had to
63:43 - tap into my uh intro to acting skills to
63:47 - like fill it but I mean honestly I feel
63:48 - like I could answer it how I would
63:50 - answer it if I was in that situation and
63:52 - kind of from prior career experience but
63:55 - I yeah guess what were you saying well I
63:58 - feel like a critical part of interviews
64:00 - is asking questions to look engaged and
64:04 - uh and like genuinely interested in the
64:07 - role right so I didn't want to be like
64:10 - yeah yeah yeah though that's fair and
64:13 - the reason I asked that is because that
64:14 - is an important point so I I just I
64:18 - wasn't I guess preparing to be on my
64:20 - toes and like getting ready to answer
64:21 - these but I think it was good that you
64:23 - did ask those questions and I think one
64:25 - thing that might be interesting is for
64:26 - you to like evaluate kind of my
64:28 - breakdown my responses and stuff and
64:30 - what you're looking for because I think
64:32 - one thing that I think about in these
64:34 - interview settings and one thing I think
64:35 - is important to keep in mind is like I
64:38 - very much it's an interview for you but
64:40 - I'm very much also like you're
64:41 - interviewing me and like for me when I
64:44 - was doing a lot of these interviews like
64:45 - I definitely got stressed out when I was
64:47 - interviewing certain people that I knew
64:48 - were like high level we really wanted to
64:49 - land this person so I feel like uh like
64:52 - keeping that in mind as an interviewee
64:54 - that like you know this is not a one
64:56 - directional thing like they're like I
64:58 - had nerves you know going into this even
65:00 - though this is a mock interview because
65:01 - like I wanted to ask the right questions
65:03 - I wanted to get the conversation
65:04 - patients doing the right way and like
65:06 - that's definitely how I felt in real
65:08 - world situations as well where it's like
65:10 - it's definitely both directions
65:11 - especially if you really are looking to
65:14 - land a top candidate yeah so I
65:17 - definitely think that like overall I
65:19 - mean I enjoyed the interview I thought
65:21 - it was pretty like conceptual which is
65:23 - good I don't like when a lot of it's
65:25 - just memorization yeah
65:27 - um and I think that in terms of the
65:29 - questions well okay to be honest I
65:31 - wasn't like 100 listening that much
65:33 - because it's not a real company yeah um
65:36 - but I do think that
65:37 - I do think that being like concise and
65:40 - your answer is probably uh something
65:43 - good to practice so I do feel like
65:45 - um you did talk about a lot of things
65:48 - where you could have just said well I
65:49 - think your favorite thing is this
65:51 - because I have a lot of flexibility and
65:53 - like I have a lot of growth
65:54 - opportunities and uh that's really
65:57 - helped me Propel my career whereas a
66:00 - negative is just that I feel like you
66:02 - know work is kind of a grind sometimes
66:04 - but like
66:05 - but we're all here because we're really
66:07 - passionate about the product and so like
66:09 - we're always like we want this to work
66:12 - and succeed and I want to be a part of
66:14 - that team so like we work hard to make
66:15 - that happen just like being more concise
66:18 - with those responses
66:21 - um and I feel like you know I feel like
66:24 - when I ask these questions it's a lot of
66:26 - times me evaluating whether or not it's
66:28 - been somewhere I'd want to work right so
66:30 - like if somebody does say like oh the
66:32 - work is a grind then it might like that
66:34 - is probably one thing that I'm
66:36 - prioritizing is that like I want a
66:37 - work-life balance or yeah
66:40 - um so I guess like as an interview or
66:42 - something tricky that you could do is
66:44 - like before
66:46 - asking before being like Oh do you have
66:48 - any questions
66:50 - to kind of get a feel for what they're
66:52 - looking for and then yeah your response
66:54 - to that but also at the same time I feel
66:56 - like then it's not very
67:00 - like as an interviewee I want people to
67:03 - be honest and genuine with their answers
67:04 - right like I want to be able to evaluate
67:07 - for myself like
67:09 - like oh I I'm gonna expect to work nine
67:11 - to six every day and then have the rest
67:13 - of my time I'm gonna expect maybe once
67:16 - every once in a while to have to be on
67:18 - call
67:19 - but not every night and if then the
67:22 - reality is different from that then I
67:24 - would be very disappointed right yeah um
67:26 - and I would want to leave and so I think
67:29 - that those are things to think about but
67:32 - I do think like honesty is the best
67:33 - policy
67:35 - yeah
67:36 - um this is interesting because in all
67:39 - the interviews I did I never really got
67:40 - the chance to ask that type of question
67:43 - of like you know evaluate my own
67:45 - responses and trying to impress a
67:47 - candidate yeah well I definitely think
67:49 - uh one thing is like even when you're
67:52 - interviewing uh you think you like add a
67:55 - lot of fluff and things so I think that
67:57 - for example when you ask me things like
68:00 - oh did you get the question like you
68:02 - didn't even ask a question yeah at that
68:05 - point when you were like detailing the
68:06 - problem
68:07 - and I think maybe just adding more
68:10 - breaks in between kind of your monologue
68:13 - in a way like just being like oh does
68:15 - that make sense to give the interviewer
68:18 - you know some more engagement also a
68:19 - chance to ask questions is probably good
68:21 - and I don't think you have to rephrase
68:23 - something multiple times like when you
68:24 - ask what are some features that we
68:25 - should investigate regarding the bot
68:27 - issue just ask that and then if they
68:30 - have any questions they'll like ask
68:32 - specifics right
68:34 - yep that makes sense and I feel like I
68:38 - goofed there I definitely even in my
68:39 - notes I kind of wanted to pause and just
68:41 - like see if you understood the like
68:43 - overall I guess like foundation of the
68:46 - the it wasn't a question that was the
68:47 - issue I specifically didn't write
68:49 - question there like the premise of like
68:51 - the context of the uh the problem
68:52 - context I guess that was it there was no
68:54 - like question yet but I even though I
68:57 - wrote in my notes that I fixed I removed
68:58 - question it just did like problem
68:59 - context I think I said it out loud again
69:02 - so it's like good to know I think it's
69:03 - good to know to not be too fluffy I
69:05 - think I like doing that
69:07 - um so this is good insights from my
69:08 - perspective I do want to just like as
69:11 - part of the uh video also like give you
69:13 - some feedback I guess last question
69:15 - before I do that is like
69:18 - I guess any other feedback on I guess
69:20 - the premise of the question and like
69:23 - just the flow of that type of interview
69:27 - um
69:28 - no I do think this was a very
69:30 - interesting interview because it's not
69:31 - straightforward right it's not like I
69:33 - can just mention the various features
69:35 - that I would put into a model like I do
69:38 - think that it required some time to
69:40 - think about
69:41 - um I do think it was very open-ended and
69:43 - I think that's good in some ways because
69:45 - it forces
69:46 - me at the interviewee to ask for
69:50 - specifics and
69:52 - um and you can you can tell a lot about
69:54 - a candidate by the questions that they
69:57 - do ask and I also think that for example
69:59 - when I was trying to go through you know
70:01 - what would this data set look like or
70:02 - how would you approach collecting that
70:04 - data like I do think that
70:08 - um the one tricky part that I kind of
70:10 - faced was after I did this like naive
70:12 - labeling system you're like well what is
70:15 - what is wrong with that and in my head
70:17 - I'm like well obviously you can do
70:19 - something more complex but like I think
70:20 - as a baseline like there's nothing wrong
70:22 - with like what I said right because it
70:25 - just depends on where you set that
70:26 - threshold so I would actually unless an
70:29 - interview interviewee is like blatantly
70:31 - wrong I think from the perspective of an
70:35 - interviewee like I don't like I'm also
70:38 - under stress right like I don't want to
70:40 - just
70:40 - I don't want to hear like oh that's
70:42 - wrong yeah
70:44 - um
70:45 - you did say it was like wrong but you
70:47 - just said oh there might be some flaws
70:48 - with that like
70:49 - like can you think of anything and so I
70:52 - tried my best to think of some things
70:54 - but I do think that like maybe if you
70:56 - had said well this you know user
70:58 - feedback is really great but can you
71:01 - think of anything specifically with like
71:04 - this specific part of that that
71:07 - things might go wrong or something like
71:09 - that yeah I think the ish the challenge
71:11 - is a balancing act it's like on the one
71:13 - hand I don't want to be leading I don't
71:16 - want to like be like hey you could think
71:17 - about this specific thing so I try to
71:19 - like I think maybe I could be more
71:21 - positive instead of saying what's wrong
71:23 - you know just saying how can you improve
71:25 - this and just leaving it at that
71:28 - I think that would also be good because
71:29 - I think when you said like
71:31 - like there are some flaws here it made
71:34 - me think like oh this system is just
71:35 - like yeah like I should just not be
71:37 - using
71:39 - um like reports of spam but like I think
71:41 - that you genuinely should be using
71:44 - reports of spam if you're trying to
71:45 - label your data right so I think like I
71:48 - think if you had asked like oh what's a
71:50 - way to improve upon the system that
71:53 - would make me think okay I'm on the
71:54 - right track but yeah what are some flaws
71:57 - that I can think about there
71:59 - yeah I definitely agree with that I
72:01 - think just one note to add to I think
72:04 - that from an interview's perspective I
72:06 - think that that's the best approach that
72:07 - you what you mentioned from your
72:09 - perspective one thing that you could
72:10 - potentially employ and whether or not
72:13 - you want to do this it's kind of up to
72:14 - you I've seen this before in real
72:16 - interviews that I've done is like you're
72:18 - welcome to push back at that if you do
72:21 - it in like a you know a
72:23 - I don't friendly is maybe not the way
72:25 - but like in a professional way and say
72:27 - actually I think that this is a fine
72:29 - like I don't think there's anything
72:30 - inherently wrong with this I think this
72:32 - is a good Baseline approach we can
72:33 - improve it like you can kind of spin it
72:35 - that way too obviously with nerves and
72:37 - stuff it's tough to do that but like
72:39 - I've been at an interview where we like
72:41 - we kind of got into a debate but in that
72:43 - I learned a lot about how they think
72:45 - that they're willing to stand up for
72:47 - what they believe in and like they
72:49 - weren't ever aggressive but they were
72:51 - able to like stand their ground argue
72:54 - their points but be willing to listen to
72:56 - my side and like kind of we could come
72:58 - to an agreement so whether or not you
73:00 - want to play into that you know is up to
73:03 - you sometimes interviewers might be
73:04 - cruel and they might purposely get your
73:06 - nerves and be like make you think you're
73:07 - doing something wrong even though you're
73:09 - not but uh yeah it's an interesting I
73:12 - think from both sides the right you know
73:14 - it's a chess match a bit there
73:16 - um yeah no I agree
73:19 - okay I don't have anything else yeah so
73:22 - from my perspective just to add some
73:24 - details I guess I mean overall like
73:28 - I mean some high level things like the
73:29 - reason that I would approach an
73:30 - interview like this
73:32 - is because if this is like a high level
73:34 - position I assume you know how to code I
73:37 - assume that you know like the
73:38 - fundamentals that you can program that
73:40 - I'm not worried about that as much I'm
73:42 - worried about how you are as a thinker
73:45 - and not even like how you are as a
73:47 - thinker but also how organized are you
73:49 - as a thinker because I could potentially
73:52 - interview someone that's very brilliant
73:53 - but they might just kind of ramble on in
73:55 - a way that I can't follow
73:57 - and I just like even though I understand
73:59 - they know that they're talking about I
74:01 - just I need to think about it in the
74:03 - context of a bigger team
74:04 - and if they're not being straight to the
74:07 - point and like being able to flesh out
74:10 - in a way that's easy to follow their
74:11 - points then that's not probably someone
74:13 - I want to work with even if they're
74:15 - brilliant so I think you know some of my
74:16 - first comments is that I think you did a
74:18 - great job at like not only explaining
74:21 - your points but also like being able to
74:23 - uh explain your points concisely I think
74:26 - once you started having to write down
74:28 - the Google Doc one thing I really
74:29 - appreciated and I don't always see is
74:31 - like you are very cautious to format it
74:33 - nicely which is a big thing for me as a
74:35 - reviewer it's like a small detail but I
74:37 - think it goes a long way where it's like
74:38 - it makes me it makes it easier for me to
74:41 - understand things it makes it easier for
74:43 - me to under like follow up on certain
74:45 - points so like structure there is good
74:46 - solid like formatting and all of that so
74:49 - like
74:50 - yeah all solid there I think overall
74:53 - like I think a lot of just good
74:54 - discussion I think you got to a lot of
74:56 - points without me even having to prod to
74:59 - that it's like you kind of got to some
75:00 - of the like Crux of like oh these are
75:02 - the features I want to do a uh you know
75:04 - build a feature Vector of all this stuff
75:05 - and like I had specific questions hoping
75:08 - that you would get to feature vector and
75:09 - stuff but you kind of just brought it up
75:11 - on your own which was solid I think it
75:13 - was a good use of like thinking out loud
75:16 - like making sure that you're going
75:18 - through your thought process and like
75:21 - you know saying what you're thinking as
75:22 - you're you know writing it out as you're
75:24 - saying it just it allowed for more
75:25 - discussion allowed me to just see how
75:27 - you think well I definitely think that
75:30 - like so because it's being put on
75:32 - YouTube I definitely think that one
75:33 - thing to mention that like people who
75:35 - are kind of newer to Tech interviewing
75:38 - and stuff like that like
75:40 - I I don't think it's common knowledge if
75:43 - you're new to the space to talk out loud
75:45 - during these interviews like I I don't
75:47 - think I think a lot of people just think
75:49 - oh they asked me this question I just
75:51 - need to give the answer no like you need
75:53 - to
75:54 - um
75:55 - like what they really want to know is
75:56 - how you think right not whether or not
75:58 - you'll get to the right answer because
76:00 - what an interview what an interviewer
76:03 - hopefully should be doing is if you're
76:05 - going on a completely wrong path kind of
76:07 - guide you to the like right answer right
76:11 - and I really enjoy interviews where it's
76:13 - more like a conversation where I'm not
76:15 - just talking to myself where I can
76:17 - bounce ideas back and forth because that
76:20 - also shows me like this is what it would
76:22 - be like to work with this person on a
76:24 - team
76:25 - um so you really want to be able to
76:27 - display how you think and how you arrive
76:31 - at the answer rather than just saying an
76:33 - answer and then justifying
76:35 - it yeah
76:36 - yeah definitely yeah I think that's
76:38 - great to pull you know to bring up I
76:40 - think that it is kind of weird it's kind
76:42 - of different and new same thing with
76:44 - like writing things down during an
76:45 - interview like we use Google Docs here
76:47 - but like traditionally if this was in
76:49 - person like it'd be a whiteboard or
76:50 - something I'm like I think some people
76:51 - aren't prepared for that too so like
76:53 - knowing that this might be what you have
76:55 - to do but I think yeah speaking out loud
76:57 - is super important
76:59 - um let's see what other notes do I have
77:01 - here so some like small details like
77:04 - overall like from my perspective as an
77:06 - interviewer like I thought you had a
77:08 - solid performance like I I like good
77:11 - performance like I'd be excited as an
77:13 - interviewer to come out of that
77:14 - interview like like this person hit the
77:16 - main bullet points that I had so like
77:18 - you know it would really come down to
77:20 - what do the other candidates look like
77:21 - but like definitely you know like
77:23 - sometimes you come out of interview you
77:25 - just immediately know like this
77:26 - candidate was not right uh sometimes you
77:29 - come out of it and you're like uh you
77:31 - know maybe like I definitely came out of
77:33 - this interview and I was like yeah that
77:34 - was a solid performance like this person
77:36 - knows what they're talking about they
77:37 - think clearly so like good from there so
77:40 - like I'll be nitpicky on things because
77:42 - like overall good performance uh one
77:45 - thing that you kind of did and It
77:47 - ultimately was my next question but like
77:49 - I would have liked to think a little bit
77:51 - more discussion when I brought up the
77:52 - data set you kind of skipped to the
77:54 - model implementation
77:56 - um
77:57 - and so like I didn't stop you I didn't
77:59 - pause you didn't bring you back because
78:01 - that was the next question but just kind
78:03 - of keeping in mind what the question was
78:04 - at hand whereas you ended up focusing on
78:07 - implementation which was important was
78:08 - the next question but I think like I
78:11 - would have liked to walk through that I
78:12 - guess in a specific manner so small
78:14 - nuanced detail like kind of annoying me
78:16 - being annoying but like just something
78:18 - to consider just keep in mind are you
78:20 - answering the question that was asked
78:21 - another detail this is kind of at the
78:24 - end and there is like little things that
78:26 - I'm like bringing up uh it's not like a
78:29 - ton of I think things one thing at the
78:31 - end I think I think it was good that you
78:33 - mentioned like hey I don't have that
78:35 - much information like knowledge in the
78:37 - system side of things like you shouldn't
78:39 - try to lie to your interviewer like I
78:41 - think it's really impressive when
78:43 - someone knows when to say hey I don't
78:45 - know that much about that so like I
78:47 - think it was good by like stating that
78:49 - explicitly and not trying to like you
78:51 - know spin off some information on random
78:53 - cloud services that you actually don't
78:54 - know much about because I might ask you
78:56 - details about those and then you might
78:58 - be like I have nothing so it could catch
79:01 - you in a weird situation
79:05 - I brought it up there was because you
79:06 - asked a specific question about the
79:09 - deployment of this right like yeah I
79:10 - would never have said it myself like I
79:13 - don't know that much about this but it
79:15 - was literally just because you asked the
79:17 - specific question that I did not know
79:19 - the answer to that I brought this up and
79:21 - like I don't think like I I think that
79:23 - at least to me when I used to interview
79:26 - people like to me it's it's okay if
79:30 - somebody doesn't know something right
79:31 - like what I want to see is that they're
79:33 - teachable and that they can learn and
79:36 - that they can think so yeah and I think
79:39 - you bring up a good point though because
79:41 - you're kind of the point is I asked you
79:42 - about it and you said I don't know much
79:44 - you don't want to call attention to
79:46 - things that weren't brought up you don't
79:47 - be like Oh I'm actually like a junior
79:49 - engineer like I don't actually like know
79:50 - that much code like don't bring up
79:52 - things yeah
79:56 - um I definitely see that uh sometimes in
79:59 - like interviews that I do bringing up
80:00 - things that they should bring up like be
80:02 - very confident professional like know
80:04 - your stuff fake it till you make it and
80:06 - if they like bring up something specific
80:08 - that you know you can't talk that much
80:10 - about be honest but don't throw that out
80:13 - on your own like let them bring it up so
80:16 - some things that could improve on that
80:18 - idea I think that it was good mentioning
80:20 - of like you know obviously we're gonna
80:21 - probably use a GPU probably gonna like
80:23 - paralyze things I think one thing that
80:25 - might have been interesting to say upon
80:27 - that type of answer to dive into some of
80:29 - the more technical details is I think
80:32 - that
80:33 - we would
80:35 - maybe just explicitly kind of mentioning
80:36 - like tokenizing maybe some of these
80:39 - tweets and whatnot or whatever you want
80:41 - to pass into the system
80:43 - um but also I think a big thing that you
80:45 - could have brought up was like batching
80:48 - and just explicitly mentioned like you
80:50 - probably don't want to take one tweet at
80:51 - a time because that's gonna like
80:53 - like if we think about all of glitter
80:56 - as a parallel to Twitter obviously uh
81:00 - there's so many tweets happening there's
81:02 - so many potential bot accounts that if
81:04 - we were trying to handle these on an
81:06 - individual level like it would just be
81:08 - in crazy and like intense processing so
81:11 - we would need to like you know maybe we
81:13 - have a window open for five seconds or
81:15 - something that like collects a big batch
81:16 - of these and we have our model set up in
81:19 - such a way where it can process that
81:22 - full batch and spit out that output and
81:24 - then we have to parse that output so
81:26 - that would be like I think one way to
81:27 - improve that but I think it is on the
81:29 - deployment side uh that is you know
81:30 - maybe not your expertise but I think the
81:32 - batching could have been something
81:33 - interesting to bring up
81:35 - um I'm trying to think of other specific
81:37 - components I think the challenges I like
81:40 - when I'm in an interview with two people
81:41 - where one person's writing the notes and
81:43 - one person's really leading the
81:44 - interview uh because I think one thing
81:46 - that's challenging sometimes is uh
81:48 - writing those notes down as you're
81:50 - trying to listen and let me see
81:54 - I don't have too much like
81:56 - I guess specific like criticism that I
81:59 - wrote down I might like review
82:00 - afterwards and provide additional things
82:02 - other like positive notes you know for
82:05 - people listening in whatnot
82:08 - um like I I appreciated when we talked
82:11 - about like you know anything that is
82:12 - exciting to you I appreciate it that you
82:14 - kind of like didn't just go oh chat GPT
82:17 - you kind of like mentioned chat GPT
82:18 - because I feel like that's right now
82:20 - what I expect everyone to say so it was
82:23 - nice to see some interest that was aside
82:25 - from that
82:26 - that was unique and different so like
82:29 - you know you don't want to blend in with
82:31 - every other candidate even if you want
82:33 - to say something like chat GPT offer
82:34 - something unique and different that
82:36 - someone's going to Remember You by and I
82:38 - think that talking about reinforcement
82:40 - learning talking about you know
82:42 - superhuman chess AI poker AI
82:45 - spins up a more unique conversation
82:50 - uh other I guess potential thing that
82:53 - could have maybe improved things a bit
82:55 - and maybe this was lack on my part of
82:57 - like I call this a question was it
82:59 - wasn't a question so it wasn't super
83:00 - clear but I think there are some other I
83:02 - think
83:04 - um problems with Bots that you maybe
83:06 - could have brought up I think you didn't
83:07 - add that much new details and this
83:10 - wasn't a data science question but from
83:13 - my perspective as an interviewer I'm
83:15 - going to challenge your domain knowledge
83:16 - like if you're at a company I expect you
83:18 - to know a bit about the company right
83:20 - um so like some of the things I think
83:22 - that
83:23 - potentially I think there could have
83:25 - been other I guess problems with Bots
83:26 - that could have been brought up that
83:27 - were kind of specifically unique and
83:30 - different from things that I brought up
83:31 - uh like one thing you could have even
83:33 - mentioned is like it might hurt our
83:35 - metrics we might you know if we have all
83:37 - these Bots like it's hard for us to
83:38 - report accurate metrics to people like
83:40 - advertisers that you know might need
83:43 - these accurate metrics to you know be
83:45 - able to budget properly so that could
83:46 - cause those problems down the road it's
83:48 - outside the box it's different but it
83:49 - might have been something interesting to
83:51 - bring up just to show you're really
83:52 - thinking about this uh other things like
83:55 - you know Bots
83:57 - and this kind of came up with the
83:59 - following followers and who people
84:01 - follow so it was kind of indirectly
84:02 - answered this but like if Bots are
84:05 - liking people's stuff really quickly on
84:08 - like let's say there's a reply and maybe
84:10 - a bot didn't reply to it maybe a human
84:12 - replied but that human account had a
84:15 - bunch of bots that immediately liked it
84:16 - it might give undeserved prominence to
84:18 - that reply uh tweet or whatnot as a pod
84:22 - issue so you know these are small things
84:24 - I'm poking at
84:25 - um
84:26 - but just it just takes things I guess to
84:29 - improve further
84:30 - uh yeah I don't think I have anything
84:32 - else
84:33 - yeah I don't have anything either all
84:36 - right that's all we're going to cover in
84:38 - this video If you enjoyed make sure to
84:40 - throw this video a big thumbs up and
84:42 - also subscribe to not miss any future
84:44 - videos if you have questions about the
84:46 - job interview process or have feedback
84:48 - on this video make sure to leave a
84:50 - comment down below huge shout out to
84:52 - Kylie for joining and making this video
84:55 - possible that's all I have for this
84:58 - video as always thank you for supporting
85:00 - the channel and until next time
85:03 - [Music]