00:00 - the great thing about this opencv course
00:02 - is that you can follow along from any
00:04 - computer without installing any software
00:06 - by using google colab in your browser
00:09 - mspa who teaches this course makes it
00:11 - super simple to follow along if you
00:13 - already know some python hello everyone
00:15 - welcome to this opencv tutorial series
00:17 - here we will be using python in google
00:20 - collab to create opencv projects
00:22 - understanding the basics of opencv we
00:25 - will understand the color profiles doing
00:27 - edge detection image manipulation these
00:30 - are all simple applications of opencv
00:33 - and then gradually move into the
00:35 - intermediary applications like color
00:37 - detection writing drawing shape
00:39 - detection we'll also try to do some
00:41 - projects using the knowledge that we
00:43 - have embossed in this particular
00:45 - tutorial to create ball tracking face
00:48 - recognition and so on this tutorial
00:51 - series is designed for people who are
00:52 - beginners intermediary and people who
00:54 - just want to enhance their knowledge in
00:56 - the opencv field we are using golab
00:58 - which will allow us to create these
01:01 - applications right off of the website on
01:03 - the google collab library we don't need
01:06 - to worry about downloading some
01:07 - dependencies installing libraries making
01:10 - sure things run or not having it on
01:11 - collab makes it very easy plug and play
01:14 - for us with that let's get started
01:18 - hello welcome to lesson one i'm going to
01:20 - quickly make the screen big and i will
01:23 - also
01:24 - upscale this thing so the visibility is
01:26 - right good for you
01:28 - in the description you can open up this
01:30 - link and it will take you to this page
01:32 - and the basically the first step we're
01:34 - going to do is simply run this clone
01:37 - so we're just cloning the repository
01:39 - we're just downloading all the files
01:41 - that we need for this program
01:43 - it makes our lives easy if you go into
01:46 - this folder you'll see this opencv
01:47 - tutorial folder created for us and it
01:50 - has some sort of images that we will be
01:52 - using for this particular set
01:55 - so the first step the first lesson we
01:57 - want to look into is changing a color
02:00 - profile of an image so the first thing
02:02 - you want to do is import
02:05 - opencv and that's the mother father of
02:08 - everything of all the images you want to
02:10 - download opencv first make sure opencv
02:14 - is happy and it's take case takes care
02:16 - of all our images to the best of its
02:18 - extent now we also want to display the
02:21 - images and since we're using google
02:23 - colab it's in order to display it right
02:26 - in the browser there is a different
02:28 - function and for that purpose we will
02:30 - import
02:31 - from google because google had created
02:34 - this
02:35 - patch for opencv
02:37 - and you say google collab
02:40 - dot patches
02:42 - so you have patches
02:44 - from google cola patches import cv2 i am
02:48 - show
02:49 - then the purpose of this guy cv2 im sure
02:52 - is just to take your image and display
02:56 - it on the browser
02:58 - as simple as that now you have opencv
03:01 - and you have opencv
03:02 - i am sure now what do you need
03:05 - you need the images to work on so the
03:08 - first thing is to
03:10 - read the image and i'll say okay i have
03:13 - an image and
03:15 - show me how i read the image
03:17 - so opencv
03:19 - has this command called i am read and
03:23 - this is basically stands for image read
03:25 - this image read guy can
03:28 - take whatever image you have and just
03:31 - read it in the program in this python
03:33 - application what does imd need from you
03:37 - it only needs the path of the image file
03:40 - so where is our image located our image
03:43 - is located this is the color.jpg this is
03:46 - the image that i am interested in and it
03:49 - is available inside this images folder
03:52 - of color.jpg so we will say
03:55 - okay
03:57 - i have my image
03:59 - it is in the images folder bracket and
04:01 - then you slash and you put down color
04:04 - dot jpeg but that is my image so i am
04:07 - read just needs for you to guide and let
04:10 - them know where the image is stored i'm
04:13 - just saying it's under images color dot
04:15 - jpeg
04:16 - so it's as simple for now now
04:20 - let's try to read this image let's try
04:22 - to display this image for now
04:25 - so we can use this i am cv to im show
04:28 - command
04:29 - and will do
04:30 - i am show
04:31 - and this i am show only needs you to
04:33 - tell what image you want to show
04:36 - and in our case we just want to display
04:38 - this image
04:39 - so we see this is the image you want to
04:42 - show us
04:44 - once you have this just go ahead and run
04:46 - this
04:47 - and it should open up the image for us
04:50 - you can see it's a very colorful very
04:52 - vibrant
04:54 - display
04:55 - image for us right here in the browser
04:58 - now
04:58 - i am interested in what is the
05:01 - dimensions of the image what are the
05:03 - properties of the image and for that
05:05 - purpose let's not display it again
05:08 - we write a opencv
05:11 - tell me what is the dimension what is
05:14 - the property of the image
05:16 - that is stored under the function under
05:19 - the variable called shape so i will run
05:22 - this
05:23 - and it displays this
05:25 - function in this number and what is this
05:28 - what what does this stand for so 476 and
05:32 - 640 are nothing but the number of rows
05:35 - and number of columns or the width and
05:37 - the height of the image
05:39 - and this number three represents the
05:42 - number of channels that are available in
05:44 - the image now since this image is a
05:47 - colorful image it has three channels
05:50 - which is nothing but the red
05:52 - green and blue channel
05:55 - and that is what defines a colorful
05:58 - image so this is basically
06:00 - a colorful image
06:04 - now
06:05 - the first thing we will look into since
06:08 - we are talking about colorful profiles
06:10 - or changing the color of the profile of
06:12 - the image the first thing we will look
06:14 - into is
06:16 - making an image grayscale
06:20 - now
06:21 - grayscale image what is this
06:24 - it's basically a black and white image
06:26 - now let's see how opencv can do it for
06:29 - us
06:30 - we will call a new image called gray and
06:33 - we will say hey grey image
06:36 - make this colorful image turn into gray
06:39 - for us
06:41 - how would you do it
06:42 - you just going to open cv2
06:45 - and opencv has this amazing function
06:48 - called as cvt
06:50 - color
06:52 - and this color function is capable of
06:56 - converting the color of any image that
06:58 - you give
06:59 - so you need to just let the function
07:02 - know what image that you need to provide
07:05 - in this case you say our colorful image
07:08 - from the previous section
07:10 - please convert that into gray for us so
07:13 - we say image
07:15 - but it also needs to know what kind of
07:17 - color you want
07:19 - yes i know you have given me the image
07:21 - the colorful image but what do you want
07:24 - in return from me
07:26 - so for that purpose we say
07:29 - open cv
07:30 - convert it into a color from color to
07:33 - gray so we say convert
07:37 - color
07:38 - in caps luck
07:40 - and then underscore
07:42 - we say hey opencv
07:44 - convert it from bgr
07:47 - to
07:48 - gray
07:50 - we just say this
07:51 - and it converts it for us and we see bgr
07:54 - because our original image is in the
07:57 - format of blue green red all the three
08:00 - channels separate
08:02 - and we convert it into a grey image
08:06 - coming down let's display this image for
08:09 - once again
08:10 - now let's see what does the gray has in
08:13 - store for us
08:15 - and let's run this and voila
08:19 - our colorful image is now turned into a
08:21 - grayscale
08:23 - now you might ask hey mister you had a
08:26 - very beautiful colorful image why did
08:28 - you bother converting it into a
08:30 - grayscale image why does why do you even
08:33 - need to do that aren't you spoiling the
08:35 - image why aren't you going to spoil the
08:37 - program
08:38 - what is the purpose of converting into a
08:40 - grayscale image
08:42 - the purpose for that is these three
08:44 - channels
08:46 - you can see the colorful image had three
08:49 - channels
08:50 - and these three channels store
08:52 - information about the red color green
08:55 - color and blue color
08:57 - that is a lot of information for us
09:01 - when you're going to be using opencv
09:03 - algorithms and computer vision programs
09:07 - you have to do complex processing pixel
09:10 - level processing you're going to be
09:12 - opening each bit each and every bit of
09:14 - the image and that's too much of
09:16 - information for us
09:18 - so in order to reduce that one of the
09:21 - techniques is to reduce the number of
09:23 - channels so like this colorful image had
09:26 - three channels
09:27 - if you were to display
09:30 - and
09:30 - ask opencv hey opencv give me the number
09:34 - of what is the shape of this gray color
09:36 - shade gray color image
09:39 - and if you print this
09:41 - you can see that the
09:43 - colorful image had three channels
09:46 - and the
09:47 - black and white or the grayscale image
09:49 - has no channels
09:51 - you can see there is nothing available
09:53 - here because it's only one one matrix
09:57 - all by itself it doesn't have any
10:00 - channels
10:01 - you have reduced you have compressed all
10:04 - those three channels into one channel
10:06 - which is defined by a gray color profile
10:10 - so you have reduced information you have
10:13 - reduced the number of pixels you have
10:15 - made opencv happy because now it doesn't
10:18 - need to handle three different channels
10:20 - for your images just one image this is
10:23 - one channel and that's all it needs to
10:25 - take care of so you're making opencv
10:27 - happy you're making your computer happy
10:29 - because it doesn't have to load so many
10:32 - bits of information for you
10:34 - and this makes life easy for you and for
10:37 - the program
10:39 - so let's go into the
10:42 - basics
10:43 - now we have the grayscale image let's
10:46 - look into another print another type and
10:49 - that is the hsv image
10:53 - now you might ask okay so we have
10:56 - we
10:57 - took out all the color profiles we took
10:59 - out everything we needed from the color
11:01 - images now we brought them into a gray
11:03 - image but what if i was interested in
11:06 - color i'm a colorful person and i am
11:09 - interested in identifying different
11:12 - colors in my image and that is my
11:14 - project but you made it into grayscale
11:16 - now how do i how am i going to work on
11:18 - it
11:19 - well to answer it for that is your hsv
11:23 - image
11:24 - and this hsv image or this hsv channel
11:27 - is capable of holding
11:30 - all the color profiles
11:32 - under one channel
11:35 - now what do i mean by that
11:37 - to appreciate that fact remember this
11:40 - your colorful image had three channels
11:44 - right
11:44 - blue green and red
11:47 - the hsv image will also have three
11:50 - channels but the channel that defines
11:54 - the color is only present in one bit so
11:58 - i'll explain what that means
12:00 - but let me say hey opencv i'm going to
12:02 - create a new image called hsv
12:06 - and for that purpose i want you to
12:08 - convert my original image i'm going to
12:11 - use again this convert color profile
12:14 - function and i'm going to pass opencv
12:17 - the colorful image that we had
12:19 - image
12:21 - and we're going to let hey opencv
12:23 - this original image that i have
12:25 - converted into a
12:28 - hsv image
12:30 - hsv
12:32 - color
12:35 - bgr
12:37 - to hsv
12:39 - and if i just print
12:42 - the shape of this hsv hsv dot shape
12:47 - and let's run this
12:50 - so you can see hsb also has three
12:52 - channels
12:53 - so
12:54 - what are we doing then
12:56 - well
12:58 - hsv stands for hue saturation and
13:02 - variance
13:03 - and the hue
13:05 - is defining all the color
13:08 - profile in the image all the colors that
13:11 - are available blue green red everything
13:14 - all the colors of the rainbow are going
13:17 - to be available in this just one channel
13:20 - called each
13:22 - so if you can control if you can
13:25 - pinpoint h to give you red color you can
13:29 - also pinpoint it to give you yellow
13:31 - color green color blue color so this hsp
13:36 - guy the hatch channel of this guy can
13:38 - hold all the colors of your image so
13:41 - previously this colorful image had three
13:44 - channels and in order for you to define
13:47 - a color yellow you would need all the
13:50 - three channels to define what a yellow
13:53 - color looks like
13:54 - but
13:55 - a hsv image can only use your h channel
13:59 - to define what color you need
14:02 - and that makes your life in detecting
14:06 - colors
14:07 - very simple
14:09 - very easy and very very easy for the
14:12 - computer to process so your complex
14:14 - algorithms that we will look into the
14:16 - future will be very easy to run you
14:19 - might ask
14:20 - how does this hsv image look like
14:23 - well you don't want to see it but i'm
14:26 - going to do it anyways
14:27 - and
14:28 - you might regret let's run this
14:32 - and you can see that this hsv image
14:36 - looks
14:37 - nothing like the colorful image nothing
14:40 - like the grayscale image it has its
14:43 - own
14:44 - legend
14:45 - and it's it's running it's it has an own
14:48 - property it has its own way of
14:50 - displaying images
14:52 - and that is
14:53 - what we are interested in we are going
14:56 - to look into the h value the s value and
14:59 - the v value separately to define the
15:02 - color that we are interested
15:07 - with that we come to the conclusion of
15:09 - our first chapter which is changing the
15:11 - color profiles and these are the color
15:13 - profiles that are going to help us in
15:15 - our later projects welcome to lesson
15:18 - number two here we're going to look into
15:20 - what edge detection is all about so the
15:23 - first step is to go ahead and import
15:25 - opencv
15:26 - so we can see we can take care of all
15:28 - our manipulations image manipulation
15:30 - that we're going to do right now
15:32 - and we have this image which is right
15:35 - under this directory if you go into
15:37 - opencv tutorial
15:38 - you have this images folder and under
15:41 - images folder you have this image
15:42 - color.jpg we will work with that image
15:45 - today
15:46 - we will say hey opencv i want to read
15:49 - this image and i want to save this in
15:51 - this variable called image so image is
15:55 - equal to cv2
15:57 - im read
15:59 - and you need to tell opencv
16:01 - what is the
16:02 - image
16:03 - file path so in our case we saw that it
16:06 - was under the images folder
16:08 - and it's called color.jpg that is the
16:11 - file path for us we just go ahead and
16:14 - write down the image path name which is
16:16 - under images
16:18 - bracket
16:19 - and just specify what to stay after the
16:21 - slash
16:22 - and you say color dot jpeg
16:26 - you are now specifying what is the image
16:28 - that you want to read once you have this
16:30 - if you want to just simply display it
16:32 - you can use cp2 i am show
16:35 - and that's how you display it but since
16:38 - we are not able to use we are using the
16:41 - collab version we cannot directly use
16:43 - cv2 dot i n show and for that purpose we
16:47 - will import something called as or from
16:51 - google
16:53 - google has this patch that created in
16:56 - order for us to use the cv to imp i am
16:59 - show
17:00 - we will use google
17:01 - collab
17:02 - dot patches
17:04 - import cv2
17:06 - i am shown
17:08 - we are just importing cv to im show and
17:10 - we will say hey cv2 i am sure please
17:14 - display the image for us we just specify
17:18 - the image and if we run this it will
17:21 - display the image for us right here in
17:23 - the browser we can see our colorful
17:26 - image is right up and running for us now
17:29 - let's understand let's go into the edge
17:31 - detection
17:33 - so we have this image you know let's for
17:36 - now we'll
17:37 - comment it now let's make it into a
17:39 - canny image
17:40 - we say can image
17:43 - and the scanning image is nothing but
17:45 - the edge detected image we're going to
17:47 - be using a edge detector called scanning
17:50 - edge detector i'm going to be using this
17:53 - function from opencv
17:55 - which says
17:56 - a opencv
17:58 - pv2
18:00 - please do the kanye edge detection on my
18:02 - image so opencv has this function called
18:06 - kanye you just need to specify what is
18:08 - the image
18:10 - okay i have the image the canon edge
18:13 - detection also requires you to specify
18:17 - the size of the filter that you're going
18:19 - to be using
18:20 - so the filter size in our case will
18:22 - specify hey let's go to be 150 by 200 it
18:27 - doesn't matter what filter you're using
18:29 - you can always test it out and see what
18:31 - kind of a result are you getting so if
18:33 - there's no hard and fast rule behind the
18:35 - 150 and 200 which i mentioned here you
18:38 - can always test it out and see
18:40 - and now we can simply display this
18:43 - but before we display there is an issue
18:46 - canning image does not run
18:49 - does not run by its own it needs to run
18:52 - on a grayscale image like the grayscale
18:55 - image that we learned in the previous
18:57 - lesson where you are converting the
19:00 - grayscale using the color bgr to gray we
19:03 - need to convert our image into a
19:06 - grayscale image before we do anything so
19:09 - let's copy this
19:11 - let's copy this line from here and come
19:14 - back to our can edge detection now we
19:16 - know what is the purpose what is what is
19:18 - one of the uses of grayscale image
19:21 - we save this here and we convert our
19:24 - image into a gray image and we specify
19:26 - the gray image to canon because scanning
19:29 - is only able to
19:31 - work on grayscale image it only assumes
19:35 - that the image has one channel and for
19:37 - that purpose we need to make sure you're
19:40 - only providing one channel grayscale
19:42 - images
19:43 - and let's see how this image runs out to
19:46 - be
19:47 - now you can see the whole image is gone
19:50 - and it's only specifying the edge
19:53 - profiles of the image isn't that amazing
19:57 - that is what the canon edge detection is
19:59 - capable of
20:01 - there are a few more adjectives there
20:03 - are a few more things that we can do
20:04 - with this we have the candy image and it
20:07 - has it's able to detect all the linings
20:10 - able to detect everything all the edges
20:12 - that are available in the image
20:14 - but say we were not interested in
20:16 - everything we were only interested in
20:19 - the highlighting features of the image
20:20 - because right now it's very difficult to
20:22 - understand what this object is even
20:24 - about
20:25 - so we can use some filtering methods and
20:28 - for that purpose let's import numpy
20:32 - import
20:33 - numpy as np and numpy is our brother to
20:37 - opencv who is able to do some matrix
20:40 - manipulations for us
20:42 - which is also very very much similar to
20:44 - what opencv does in fact
20:47 - np can also be
20:49 - uh another format of opencv because it
20:52 - does also works with matrices but opencv
20:54 - has already made very things very easy
20:57 - for us but we are not going to ditch it
20:58 - we're going to use it simply and run our
21:01 - application with the help of opencv
21:04 - now you have np
21:06 - the next step we're going to look into
21:08 - and understand
21:10 - erosion and dilation we'll say erosion
21:14 - and dilation right here so let's first
21:18 - do erosion of our image
21:20 - now we can do erosion by saying hey
21:25 - erode my image
21:27 - which image the canon image
21:30 - eroded so that you can remove some of
21:33 - the filters that i'm not interested in
21:35 - you wrote the image by using opencv's
21:38 - your road function and this erode
21:41 - function is capable of taking your image
21:44 - which is the
21:45 - canon image
21:48 - you have the kanye underscore image but
21:51 - it also needs for you to specify
21:54 - a window size
21:56 - because this window is going to
21:58 - move over your image and wherever that
22:01 - window matches or
22:04 - falls into the property of erode it will
22:06 - eradicate it
22:08 - oh you know what i just found my mistake
22:10 - so i missed the e over there and we are
22:13 - also needed to specify the window size
22:16 - which is also called as the kernel
22:18 - the kernel equal to
22:21 - np which since we are going to be using
22:23 - numpy to create our matrix then kernel
22:26 - is a small window a small matrix
22:28 - and it's going to be a matrix of ones
22:31 - and we'll give it a size of maybe
22:34 - pi by 5
22:35 - and we'll say np is of
22:38 - unsigned integer of bit size eight
22:42 - but that's basically specifying what our
22:45 - image is going to be looking like
22:47 - and this five space five by five is
22:49 - nothing but the tuple so it should be
22:50 - under brackets and you have your kernel
22:54 - defined right here
22:56 - we use the kernel into our erosion
22:58 - format we say kernel
23:01 - and it can also take you can
23:04 - move the window over the image multiple
23:06 - times
23:07 - right now we're just interested in one
23:09 - time so we'll say iterations equal to
23:12 - one
23:13 - so erosion
23:14 - going back to the function there are a
23:16 - few things happening so the erosion
23:18 - function is able to take the image that
23:20 - you're interested in it also needs the
23:22 - kernel and it also needs the number of
23:24 - iterations you are going to specify it
23:28 - so let's display this image as well
23:31 - pb2im show
23:35 - erode
23:36 - image
23:37 - so let's
23:39 - erode image and now run this
23:42 - so we are going to run this image and
23:45 - for some reason we're getting an error
23:47 - and the error for here it says that as a
23:50 - substitution consider cv to underscore i
23:53 - am show and we
23:55 - as the user of opencv on the desktop we
23:57 - used the dot i am show function let's
24:00 - convert that into the underscore and
24:03 - let's run this
24:04 - and you have a new image which is which
24:07 - has nothing but basically eroded
24:09 - everything
24:11 - so let's reduce the kernel size
24:14 - and say two by two
24:17 - and let's see what kind of a result we
24:19 - will get
24:23 - so it has some information you can see
24:25 - some dots available
24:27 - of course it's
24:29 - taking out most of the information and
24:32 - now you might ask why do we why do we
24:34 - even need to do this because it's
24:36 - taking out all the information that is
24:38 - available in our image let's make it by
24:41 - one by one
24:42 - and see if it can display some more
24:44 - information
24:45 - yes it's displaying a little bit of more
24:47 - information but if you compare with the
24:48 - previous image there is not much of a
24:50 - difference
24:51 - and it makes
24:53 - us think or doubt ourselves about why do
24:56 - we even use erosion
24:58 - well erosion is used in order to reduce
25:01 - the noise level in the images
25:04 - and it also comes and it's very much
25:07 - useful when we are when we can pair it
25:09 - with dilation
25:11 - so let's look into what dilation
25:13 - stylation is nothing but the opposite of
25:15 - erosion so let's go into dilation
25:19 - uh let's uh
25:21 - maybe comment this out for now
25:24 - and we say this is
25:26 - erosion
25:29 - and this is going to be dilation so
25:32 - dilation also needs the kernel
25:34 - yes so we can put maybe the kernel on
25:36 - the
25:38 - edge side so we'll put the kernel
25:41 - right before everything so it's the main
25:43 - guy because it uses it uses both erosion
25:46 - and dilation so we'll have kernel in
25:48 - both now we say hey dilated image
25:53 - use open series dilate function
25:56 - dilate
25:57 - and use your can image
26:02 - let me move this out of the way so
26:04 - you're using opencv's dilate function
26:07 - and it also requires the kernel that we
26:10 - created
26:11 - the kernel and we also use
26:14 - the iterations
26:16 - equal to one
26:19 - so what we did is we're using the dilate
26:22 - function which is very similar to what
26:23 - the arrows function is
26:25 - now we are using it again on the canning
26:27 - image we are making the kernel where
26:29 - you're making use of the same kernel and
26:31 - we are using iterations of one by one
26:35 - let's see what we can get if we have the
26:37 - kernel size of five by five
26:41 - and let's display this for us
26:45 - i am sure opencv
26:47 - dilate image
26:49 - let's run this and we can see this is
26:53 - the any kanye edge detection image
26:56 - and this is the dilated tv what is
27:00 - happening here
27:01 - you can see that the edges or all the
27:04 - edges that were visible here
27:06 - now they have been
27:07 - emphasized they are made more they are
27:10 - increased or you can say dilated
27:13 - they become very big now
27:16 - now if we were to use erosion after
27:19 - dilation let's uh let me remove this
27:22 - kernel we don't need the kernel or we
27:23 - can keep it for your purpose
27:26 - that's fine
27:27 - and let's
27:28 - do erosion after dilation so we have
27:32 - here dilated image and we'll use the
27:34 - dilated image instead of the canning
27:36 - image
27:37 - and then display our eroded image
27:41 - so let's run this
27:44 - so you have for the original can image
27:46 - again
27:48 - then you have going down
27:50 - you have your dilated image and now you
27:53 - have your eroded image so you can see
27:56 - there is a difference between the
27:58 - canyh image and the eroded image but
28:01 - there's a little bit of doubts here
28:04 - so
28:05 - if we increase
28:07 - let's see what else we can do to make it
28:09 - more simpler for us to understand
28:11 - we have the canning image in the eroded
28:13 - image we are basically converting we are
28:16 - basically
28:17 - making
28:18 - or displaying them
28:20 - one after the other
28:22 - what if we do it horizontally stacked so
28:25 - we have this np dot head stack
28:28 - we use display this is the image that is
28:31 - going to be displayed and
28:33 - numpy has this function called hedge
28:35 - stack
28:36 - and h stack is going to take three
28:38 - values and our values are
28:41 - the can
28:42 - image we have the dilated image
28:47 - and we have the eroded image
28:50 - we use all these display images and we
28:53 - say cv2 i am sure
28:57 - display
28:58 - this image instead of displaying
29:01 - the
29:02 - eroded image instead of displaying the
29:04 - dilated image instead of displaying the
29:07 - canning image altogether we will display
29:10 - all of them under one horizontally
29:12 - stacked
29:13 - we just run this and we can see all the
29:16 - three images right here in front of us
29:18 - so you can easily compare what is
29:20 - happening to the original canon image
29:22 - the edge detected image has made it
29:24 - dilated so it becomes big and now you're
29:27 - eroding some parts of it so it can
29:29 - become more and more visible and you're
29:32 - just trying to basically erode some of
29:34 - the more abundant information available
29:37 - here
29:38 - so this is more about erosion and
29:40 - dilation and the number of the number
29:43 - one use of anti-age detection with use
29:46 - of erosion and dilation is in the
29:48 - process of
29:50 - making lane detection application so you
29:53 - you have a row you have a picture of a
29:55 - road or you have a video of a road and
29:57 - you are interested in understanding
29:59 - where the lanes are available and for
30:01 - that purpose you want to use the line
30:03 - detection
30:04 - the edge detection and then provide
30:07 - dilation and erosion if you if there are
30:10 - any kind of noise you want to remove so
30:12 - the erosion and dilation is nothing but
30:14 - to use or work with
30:17 - noise for our purpose and uh that helps
30:20 - us that helps us in making the image
30:22 - more visible so that you're not
30:24 - focusing on the un necessary information
30:27 - but focusing on what we need maybe it
30:30 - could be the edges maybe it could be a
30:32 - certain region within the image so you
30:34 - can specify your filter size and then
30:37 - focus on the area that you are
30:38 - interested in hello everyone how's it
30:41 - going today we're looking into image
30:43 - manipulation
30:45 - now image manipulation has a variety of
30:47 - things that you can do if you're just
30:49 - going to open cv and type in image
30:52 - manipulation
30:53 - you'll open up this open cvs program and
30:57 - let's look at image calculation of
30:59 - opencv
31:00 - if you just go into image processing and
31:02 - open
31:03 - you will see that it consists of color
31:06 - spaces changing color spaces doing some
31:08 - sort of geometric transformation
31:10 - thresholding smoothing of images which
31:12 - is nothing but
31:13 - all these noise and blurring images
31:16 - morphological operations which include
31:18 - of erosion dilation and opening closing
31:20 - etc
31:21 - erosion dilation is something if you
31:23 - recall in the previous video if not if
31:26 - you haven't seen them i'll put the link
31:28 - in the description uh you can look into
31:30 - this erosion and dilation and this will
31:33 - be this is
31:35 - basically removing the noise or adding
31:37 - or emphasizing those pixel values
31:40 - similarly you have image gradients you
31:42 - have canny edge detection uh you also
31:44 - have image parameters so these are all
31:46 - different types of image manipulations
31:48 - that you can do and we will look into
31:51 - some of these important ones which we
31:53 - need to know for sure yeah into our
31:55 - subsequent uh chapters but right now
31:58 - let's look into one particular aspect
32:00 - which is denoising or which is also
32:02 - called as removing the noise removing
32:05 - the issues that you across you come
32:07 - across in these images
32:09 - now
32:10 - in order to run this once you open the
32:12 - collapse link you can go ahead and run
32:14 - this code which is in the very top and
32:17 - it's basically the github clone and
32:19 - you're just cloning the repository that
32:21 - we need here so it will take a few
32:22 - seconds and we'll clone the repository
32:24 - and if you open up this folder which is
32:26 - the directory folder you'll have this
32:28 - opencv tutorial and it'll have this
32:31 - images under images today we have this
32:34 - new image called the lion image lion.jpg
32:37 - image and the reason we have this
32:39 - lion.jpg image images because i
32:43 - i wanted to choose i wanted to get a
32:45 - very grainy and a very noisy image and
32:49 - yeah animals because of the
32:52 - amount of hair present on them it seems
32:54 - to be very noisy on a camera especially
32:57 - line with all the big hair available on
33:00 - it it becomes very nice we'll look into
33:02 - the code and see how this image really
33:04 - looks like so we have we're going into
33:06 - lesson number three image manipulation
33:08 - and let's read this image for us
33:11 - so we are importing opencv we're
33:14 - importing cv to our underscore i am show
33:16 - and we are also importing numpy
33:19 - now let's look into displaying this
33:21 - image first the image equal to cv2
33:26 - dot i am read
33:27 - and we want to read the image
33:30 - under the opencv folder because our
33:33 - image is under the opencv folder urban
33:35 - cv
33:36 - lion dot jpeg let me maximize this a
33:40 - little bit so it's easier for you to
33:42 - read
33:43 - in fact i can close this as well now we
33:45 - know it's under the opencv images
33:49 - i think we are already under the email
33:50 - opencv folder we just need to be under
33:53 - the images folder
33:55 - because we already changed the directory
33:57 - right on the beginning if you see we
33:59 - have changed the directory to opencv
34:01 - tutorial so the cursor is somewhere in
34:04 - here we just want to go under the images
34:07 - folder so for that purpose i'm telling
34:09 - the images that image which i'm opening
34:12 - it's under the images folder the images
34:15 - then you have the line.jpg so this image
34:19 - should be read into this folder in this
34:21 - variable called image and once we have
34:24 - this image we will now
34:26 - display it we will say cv2 underscore i
34:29 - am show
34:31 - image
34:32 - and if we just run this
34:35 - it should display the line image for us
34:38 - you can see it has this big image and it
34:40 - has so many hair on it and it seems very
34:43 - noisy if you look it from a camera
34:45 - perspective from image perspective of
34:47 - course those are the definitions of uh
34:49 - the hair of the alliance i don't know
34:52 - what it's actually called but
34:53 - you can see the number of grains the
34:55 - number of noisiness available here now
34:59 - consider that okay
35:01 - this is something a noisy picture and
35:03 - you're not interested in looking at all
35:05 - this
35:05 - images looking at all these hair
35:07 - profiles of the line how do you remove
35:09 - this thing how would you remove or blend
35:12 - all these hair profiles into one
35:15 - and for that purpose we have something
35:17 - called as fast error mean
35:20 - denoising color and this is a part of
35:22 - open series denoising profiling so if i
35:25 - go under opencv image denoising you can
35:28 - see that it's taking a grainy image and
35:30 - this is from the website or this is from
35:32 - the opencv's website so it is a very
35:35 - grainy image you can see the amount of
35:37 - noisiness that's available and
35:40 - once you apply the denoising filter on
35:42 - it it removes the noise to a
35:45 - large extent and how it's doing it is
35:47 - because it's averaging the pixel it is
35:50 - taking the mean of the pixel in that
35:51 - area and whatever is available which is
35:54 - more important it then denoises it and
35:56 - just takes out what is important for us
35:59 - and this is what the denoising takes
36:02 - care of first we'll come here and we'll
36:04 - apply the same denoising filter on our
36:06 - image
36:08 - and uh the denoising filter is looks
36:10 - like something like this fast and
36:12 - means denoising colored and it's the
36:15 - reason we are putting colored is because
36:17 - this is colored image similarly opencv
36:19 - has something for grayscale where you
36:21 - can do more about binary images where
36:23 - it's only black and white and they have
36:25 - their own functions which will act in a
36:27 - separate way in this case we're using
36:29 - the colored profile and we need to
36:31 - provide the image that we want to do in
36:33 - our case it is image
36:35 - and these are all the filters that are
36:37 - available so because this is it's kind
36:40 - of a
36:41 - filter it's kind of a window that goes
36:43 - over all across the image and it
36:46 - displays all these images for us
36:49 - so uh there is a filter which basically
36:52 - goes through all these images
36:54 - and then this is the size of those
36:56 - filters the these are the threshold
36:58 - values so
37:00 - all these values are something right now
37:02 - at this point you don't need to remember
37:03 - what this is about but when you're using
37:06 - this program this particular
37:08 - this particular function in your
37:10 - real-time code or project that may just
37:13 - play around these values until you get
37:15 - the result that you want now there is no
37:17 - hard and fast rule in knowing what is
37:19 - correct and what is wrong because every
37:21 - size of every image is different the
37:23 - project that you're working is different
37:25 - the type of uh images that you're using
37:27 - is different the size of the images are
37:29 - different as well so all these values
37:31 - will differ from the different images
37:33 - that you're using in my case for this
37:35 - particular image that i'm playing with
37:36 - today if this particular value is worked
37:39 - out and uh but it could be different for
37:41 - different and we'll see how this thing
37:43 - works a little bit as well now coming
37:44 - down here
37:46 - uh let's display this image so you have
37:48 - the original image which is the image
37:51 - and the destination image which is dst
37:53 - now you let's use a numpy to create a
37:57 - horizontal stack of this so we'll create
37:59 - a horizontal stack which we will be
38:01 - displaying and we'll call it as a
38:02 - display and horizontal stack is
38:04 - basically
38:05 - adding both these two images destination
38:07 - and image and making it look like one
38:10 - image so
38:11 - the numpy has a function called h stack
38:14 - and it can take
38:16 - two variables or two or many variables
38:18 - of similar size similar matrix size so
38:20 - we can say okay hey uh
38:23 - i want to add the image
38:25 - and i want to add add the destination
38:28 - together and both of them please combine
38:30 - and give it to me under this variable
38:32 - called display so we have display come
38:35 - down here and we will use open cvs
38:38 - underscore iron show display
38:42 - and it will display this for us let's uh
38:45 - comment this thing so we don't we're not
38:46 - displaying it two times because already
38:48 - we are displaying the image and the
38:50 - destination here for our case now let's
38:53 - come here let's play this
38:56 - and it should run both the commands and
38:59 - it should give us the output right here
39:02 - oops
39:03 - jumped up okay so you can see both the
39:05 - images are available here and this is
39:08 - the original image which has all this
39:09 - grainy profile of the lion in this case
39:12 - you can see that all the greens all the
39:15 - hair are blended and they're joined and
39:18 - you can only see the gradient color out
39:20 - of it and all the hair profile which was
39:23 - basically defining the features of the
39:24 - line here are gone and it's only
39:27 - emphasizing the gradient profile of this
39:29 - so it's basically considered
39:31 - considering all these hair profile as
39:33 - noise and removing them and giving it
39:35 - out to us so it looks like a more of a
39:37 - cartoonish cartoonish
39:39 - display of an image and converting it or
39:42 - cartoonizing the image but it's kind of
39:44 - a
39:45 - representation of those images here for
39:47 - us
39:48 - so uh now coming down here let's play
39:50 - with these values a little bit so you
39:52 - have 20 let's see what happens if we do
39:55 - it as five
39:56 - and let's run this again and we'll see
39:58 - what kind of an output we get here and
40:01 - since we reduce the size of the window
40:03 - you can see that the grains are now much
40:05 - more visible there is of course a little
40:07 - bit of
40:09 - blurriness available here you can see
40:11 - this
40:12 - portion here and this portion is
40:13 - different whereas the long hair
40:16 - available here are also available here
40:18 - because the size of the filter reduced
40:20 - and it's only now removing small small
40:22 - amount of noises because the texture you
40:25 - see here on the nose it has small noises
40:28 - and those noises are being blurred out
40:30 - however the big hair profiles that are
40:32 - visible that are still visible in this
40:34 - final image and that's because you have
40:36 - reduced the amount of the filter
40:39 - similarly if we increase to this thing
40:41 - say for example we were to do 50. let's
40:44 - see what kind of an image we make we may
40:46 - get uh let's see even if we can even
40:48 - recognize whether it's a image of a line
40:50 - or not and you can see that it's fully
40:53 - blurred out there you can hardly
40:55 - identify any kind of features uh in this
40:58 - image and it looks like more of a
41:00 - painting
41:02 - without much uh without much definition
41:04 - of the original character and uh you can
41:07 - see this this is this thing more looks
41:09 - like uh something from a 3d or something
41:12 - from a cartoonish
41:13 - drawing and all these features all these
41:16 - things has been blurred out and it's
41:18 - only showing the gradient of it and
41:20 - that's how it affects all these filters
41:22 - all these values
41:24 - affect the value and similarly you can
41:26 - play with all the other values and see
41:28 - what kind of an image you get out and uh
41:30 - this is
41:31 - basically helpful when you're doing some
41:33 - sort of image
41:35 - or foreground extraction or background
41:37 - removal where you want to
41:40 - specifically
41:41 - segment or specifically emphasize on the
41:43 - objects and remove all the types of
41:45 - noise available in the image and uh
41:48 - that's how it's very helpful so the way
41:51 - that with that we come to the conclusion
41:52 - on
41:53 - image noise removal
41:55 - hello everyone welcome to lesson number
41:57 - four
41:58 - here we're gonna try how we can draw
42:01 - shapes and write text on images so
42:04 - opencv has their own drawing functions
42:07 - and own writing functions and we'll see
42:09 - how we can use that to our own images
42:13 - the first thing you want to do here is
42:15 - import
42:16 - our opencv so you can see we can take
42:19 - care of all of our opencv overall
42:22 - manipulation functions
42:24 - once you have image
42:26 - maximizes a little bit
42:29 - once you have open cv the next thing
42:31 - you're going to be using in this project
42:33 - would be numpy
42:35 - import numpy as np and i'll go into why
42:38 - we're using numpy in a little bit
42:42 - we're also going to be using google
42:44 - collabs cv2im show so that we can use
42:48 - and display the images right here in the
42:51 - browser for us
42:53 - we are importing from google collab
42:56 - patches input cv2
43:00 - underscore im show
43:04 - so we have all these three libraries
43:06 - right here
43:07 - now
43:08 - normally we go into the directory and
43:12 - right
43:12 - try to open one of the existing images
43:15 - but in this case we will create an image
43:18 - from the scratch from the basics so the
43:21 - first thing we will do is we will use
43:24 - numpy to create a matrix for ourselves
43:28 - so we'll call a matrix called img
43:31 - okay so this is our matrix with img and
43:35 - now what is numpy going to create a
43:37 - matrix for us
43:38 - a numpy
43:40 - has this function called
43:42 - zeros
43:44 - and this zeros function is capable
43:47 - of
43:47 - creating a matrix of just zeros
43:51 - so the zeros function is going to create
43:54 - return a matrix which is just filled
43:56 - with zeros and with opencv language
44:00 - 0 is nothing but black color
44:04 - so
44:05 - now since we could be using a colorful
44:07 - matrix
44:08 - we will
44:10 - create a three channel matrix i'll go
44:13 - into that right now
44:15 - so let's first define the size of the
44:18 - matrix we'll say okay let's call it a 5
44:22 - by 12 and 5 by 12 matrix so it has about
44:26 - 5 12
44:27 - rows and 5 12 columns so that's the
44:30 - definition of our matrix
44:32 - and this matrix is also going to have
44:36 - three channels these three channels are
44:39 - representing
44:40 - the red
44:42 - green and blue color of a colorful image
44:46 - but in this case we know we are
44:48 - initializing it with zeros so all those
44:51 - three channels will basically be
44:53 - zero at the moment but we want that and
44:56 - the reason we want that is later on we
44:58 - can fill in the colors that we want
45:02 - so we have our matrix which is 5 by 12 5
45:06 - by 12 and 3.
45:08 - and we are also going to say okay numpy
45:12 - this matrix is going to have a property
45:14 - where the numbers are going to be
45:16 - unsigned integer
45:19 - of byte size 8 now what does that mean
45:23 - unsigned
45:24 - integer of byte size 8
45:27 - means the range of the values inside the
45:30 - image or inside the matrix are going to
45:33 - be anywhere between 0
45:35 - to
45:36 - 255
45:38 - that is the meaning of unsigned integer
45:42 - so basically you're just defining
45:45 - matrix and you're telling that this
45:46 - matrix is yes it is zero in color but
45:50 - later on in the future when you're going
45:52 - to be
45:53 - adding new colors it's going to add in
45:57 - this range only and it can take a range
46:00 - of values only between this
46:02 - 0 to 256.
46:06 - that's because colors are represented in
46:08 - a 256 range which starting from 0 goes
46:11 - to
46:12 - 255. so you're just defining
46:16 - that this is unsigned integer okay
46:19 - now let's display this let's see how
46:22 - this
46:22 - image looks like we've been talking
46:24 - about zeros we're talking about see
46:27 - black in color but let's actually see
46:30 - how this function works oh you know what
46:32 - it should be i am sure
46:35 - we have our image let's display this
46:39 - we have run this and you can see it's
46:41 - nothing but a black and black color
46:43 - image not even white black
46:45 - black image altogether
46:48 - so we have taken care of the image
46:50 - and now our image is present
46:52 - so let's try to do some manipulations on
46:55 - it like some drawing functions
46:59 - so opencv has couple of drawing
47:01 - functions it can do draw or draw a
47:03 - circle for us it can draw a line for us
47:06 - a rectangle it can put text so the
47:09 - couple of things that opencv allows us
47:11 - to do now let's see how we can go about
47:14 - doing that
47:16 - opencv has a function called
47:19 - circle so we'll use the circle function
47:22 - ros will call it as draw a circle
47:26 - let's see how we can do that
47:28 - opencv has this function called circle
47:32 - cv2 circle
47:34 - and this function can define you can see
47:37 - it takes the image name
47:40 - the center of the circle
47:42 - the radius of the circle the color the
47:46 - thickness the type of the line shift and
47:49 - then it defines gives out the result in
47:51 - your image function so this is what the
47:54 - circle function does
47:56 - now let's define
47:58 - the circle function needs the image
48:00 - which is the img
48:02 - it also needs the center of the
48:04 - coordinate of the image so we will say
48:07 - okay
48:08 - the center of our image in this case is
48:11 - going to be at
48:13 - maybe 100
48:16 - and 100 so x and y are both hundred okay
48:20 - good
48:21 - we have this
48:23 - then let's the next step you want to put
48:25 - down is the radius
48:27 - we have the radius let's say maybe 50
48:30 - okay we have a radius of 50.
48:33 - next thing you want to do is the color
48:36 - so you want the color now color is
48:38 - represented by three variables which
48:41 - represents the bgr value so in this case
48:45 - let's make it
48:46 - uh
48:48 - green color circle we'll call it as
48:50 - because since it's represented as bgr
48:53 - where
48:54 - b is for blue g is for green r is for
48:57 - red we will call it as
49:00 - zero
49:00 - and since we want green color we'll put
49:03 - green as 255 which is the highest value
49:06 - and the red is again
49:08 - 0.
49:10 - once you have the color defined the next
49:13 - thing you want to do is the thickness
49:15 - the thickness of the line so the
49:17 - thickness is also something you can
49:19 - define and we will call in our case a
49:22 - thickness of size
49:24 - 10
49:25 - okay
49:26 - so let's see how this function works for
49:28 - us and then immediately after that we
49:31 - are going to display our image
49:33 - and let's run this
49:35 - and you can see
49:37 - that now we have a circle
49:40 - it's a circle which is green in color
49:42 - and it has a thickness of about size 10.
49:46 - so
49:47 - that's about drawing the circle you can
49:50 - always play with these values these are
49:51 - nothing too crazy about you can make it
49:53 - a size thickness of five and you can see
49:56 - the thickness as radius from the circle
49:59 - so that's pretty much about this drawing
50:02 - a circle
50:03 - once you have drawn the circle
50:05 - let's see how we can draw a rectangle
50:09 - again principally has a function called
50:11 - rectangle
50:13 - cv2 rectangle
50:15 - and this function also takes something
50:18 - similar it takes the image it takes the
50:22 - points of the rectangle and it takes the
50:25 - color the thickness of course the line
50:28 - time and shift and we can then draw the
50:31 - rectangle now point one and point two it
50:34 - says that it draws the rectangle the
50:38 - between the two opposite points so point
50:41 - one is on the
50:42 - top left corner of the rectangle point
50:44 - two is on the bottom right corner of the
50:47 - rectangle
50:49 - coming back here we will see
50:51 - cv2 rectangle yes you want to draw the
50:54 - rectangle on the image img
50:56 - and you want to define the point one in
50:59 - our case the point one is going to be
51:04 - should we draw at
51:05 - 100 by 100 no but that'll be
51:08 - intersecting with the circle so let's
51:11 - bring it a little bit away from the
51:13 - circle we'll call it as 200 by 200 okay
51:17 - so it's a little bit further than the
51:19 - circle
51:20 - and we are going to say that it's going
51:23 - to end
51:24 - at maybe 400
51:26 - by 500 this is just random you can
51:29 - choose whatever you want to draw the
51:31 - point here is just to understand
51:33 - how we can draw these parameters these
51:36 - rectangles and geometrical shapes on the
51:39 - images so we have point two defined now
51:41 - we want to define the color
51:44 - let's make this a red color rectangle so
51:47 - we'll call it as
51:48 - zero for blue 0 for green and 255
51:54 - for
51:55 - red
51:59 - let's minimize this a little bit so we
52:01 - can see what's going on in the other
52:03 - part of the stream
52:04 - so we have 255 we also want to specify
52:08 - the thickness of the rectangle the
52:11 - thickness of the rectangle is going to
52:12 - be
52:13 - five
52:14 - for example
52:16 - let's run this and see what we can do on
52:18 - the image
52:20 - and now you can see that there is a
52:21 - rectangle coming up and this rectangle
52:24 - has about the same thickness as we had
52:26 - for the circle because both of them are
52:28 - 5.
52:29 - so once we have this circle let's let's
52:32 - see what happens if we put the same
52:34 - coordinate as the circle
52:36 - 100
52:38 - by 100
52:41 - same
52:42 - 0.1
52:43 - and let's see what we get and you can
52:46 - see a rectangle that is intersecting the
52:49 - circle
52:50 - and then it's also
52:52 - bigger in size because the point two has
52:55 - not shifted
52:56 - let's bring it back to where we are
52:59 - so it doesn't messes you up when you are
53:02 - trying this code on your own
53:04 - okay so we have the rectangle we have
53:06 - the circle what are we missing
53:09 - the line function let's draw a line
53:14 - so opencv has this function
53:16 - called
53:18 - let me put down the comments here
53:20 - so we know what we're doing here
53:23 - draw a rectangle
53:29 - draw a line
53:31 - okay so cb2 has a function called nine
53:34 - now line can also draw something on the
53:37 - image and
53:39 - uh you know a line can be defined
53:42 - between point one and point two so as
53:45 - long as you know where the points are
53:47 - you can draw a line
53:49 - so you are going to be using the image
53:51 - the point one the point two the color
53:54 - the thickness by now you might get the
53:56 - pattern so it first takes the image it
53:58 - takes the parameters of the coordinate
54:00 - of the geometrical shape
54:02 - and the color and the thickness the line
54:05 - temperature is something that we're not
54:06 - looking into but you can have a dashed
54:09 - line you can have a broken line a dotted
54:11 - line for different types of lines by
54:13 - default it will take a solid line
54:16 - come down to cv2 line so it takes the
54:20 - image
54:20 - and it takes the point one and we'll
54:23 - call 0.1 is
54:25 - some random value
54:26 - 160 by 160. okay
54:30 - now what is 0.2
54:32 - 0.2
54:34 - let's put it as a random value of 359
54:37 - 29
54:38 - so you have 0.1 and 0.2 and this time we
54:42 - will give it a color of
54:44 - blue color so we'll see
54:47 - 255 for blue
54:49 - 0 for green
54:51 - zero for red
54:52 - so you have the blue color and we'll
54:54 - give it a thickness of again maybe three
54:59 - and let's see how we can run this
55:03 - we run the play button and there seems
55:05 - to be an error because we've missed the
55:08 - comma between the thickness and the
55:11 - color
55:12 - so we've specified that
55:14 - and now we can see there is a line drawn
55:17 - right here between point one and 0.2
55:21 - so
55:22 - we have the line drawn we have the
55:24 - rectangle we have the circle
55:27 - coming down to the last point is
55:30 - how to write a text
55:32 - on the image
55:34 - and we can draw a text or we can put
55:37 - down a text on an image
55:39 - by
55:40 - using
55:41 - cv to
55:43 - put
55:44 - text
55:45 - so it has a cv2 dot put text function
55:49 - and this function can put down this
55:52 - the text that we want to put down
55:54 - so this also takes the information
55:57 - where it's going to be putting it's
55:59 - going to be putting on the image
56:00 - it's going to take the text
56:03 - the text you want to be putting down the
56:05 - origin of the text so the initial
56:07 - coordinate of the text
56:09 - the type of font you're using
56:12 - the size of the font the color of the
56:15 - font
56:16 - the thickness of the font and then it
56:19 - draws the text for us
56:21 - and this text right here is going to be
56:23 - a string
56:25 - it's going to take a string value and
56:27 - then display it on the image for us
56:31 - so let's come down to cv2 put text and
56:34 - we will say okay the image img is going
56:37 - to be using to display the text
56:40 - and the text is going to be
56:42 - open
56:43 - cv
56:45 - and the next step is going to define the
56:47 - origin of the text
56:49 - and let's say you don't want to be
56:51 - putting it at
56:53 - 280
56:55 - by
56:56 - 150 so
56:58 - we have defined the origin of the text
57:02 - now we're going to be defining the font
57:05 - phase the opencv has some default fonts
57:09 - that we can use
57:10 - at the same time if you want to use your
57:12 - own font
57:14 - yes opencv does allow us to use some
57:16 - external fonts but you can see that it's
57:19 - giving me an option of putting down
57:22 - font underscore hershey
57:24 - complex
57:26 - small duplex plane so it has couple of
57:29 - options
57:30 - let's go with what we have here
57:33 - and we can put down okay font hershey
57:36 - complex
57:37 - you're ready for us
57:39 - and the next thing you want to put down
57:40 - is the scale now the scale is the size
57:42 - of the font
57:44 - and we will put down just for the safety
57:46 - we'll say 2 because we don't know how
57:48 - big this text is going to be
57:50 - we have 2 and then the next thing is the
57:52 - color
57:54 - now we've already used blue green and
57:56 - red you can see the
57:59 - blue is for
58:01 - the line the green is for the circle and
58:03 - the red is for the rectangle let's use
58:06 - something different now
58:08 - well we can put down blue as zero
58:12 - we can have green we can also have red
58:16 - i wonder what kind of a color this might
58:18 - give out
58:19 - now the thickness let's say the
58:21 - thickness is two
58:24 - and we can now
58:26 - display this and see how we can what
58:28 - kind of an output we can get
58:30 - so you can see that it is generating
58:33 - this text opencv
58:35 - it's starting from the origin that we
58:37 - have specified
58:38 - but it's going beyond the size of the
58:41 - image
58:42 - that's because opencv does not know
58:45 - from especially the font function does
58:47 - not know where the image is ending so it
58:50 - keeps continuing printing the text on
58:53 - the image and if the text is beyond it
58:55 - simply truncates it but it does not
58:58 - raise any errors
59:00 - so the only solution for that is you
59:03 - reduce your image you reduce your text
59:06 - so you can either make it as small as
59:08 - text by making a size of one
59:11 - okay if you made the font size is one so
59:13 - it's within the scale or you can also
59:16 - use or move your origin
59:19 - instead of 280 you can say okay
59:21 - we'll put it at the same point where the
59:23 - line is so we'll say 160
59:26 - by 160.
59:29 - oops
59:30 - 160 and let's close the bracket right
59:33 - here and we'll put the form scale back
59:36 - to size now let's see
59:38 - you can see that's not generating the
59:40 - opencv it's of course on top of the line
59:43 - original line but it is at least within
59:46 - the image per se i guess that does the
59:49 - job for us
59:51 - in the last
59:52 - here we are displaying
59:54 - the image for us
59:56 - so that's the simple function these are
59:58 - simple functions that can be used but
60:00 - again they help us in displaying the
60:02 - data on the images for us we'll see in
60:05 - the future projects how we're going to
60:06 - be using these functions in our
60:08 - real-time projects hello everyone
60:11 - welcome to part two which is
60:13 - intermediate exercises of this opencv
60:15 - tutorial series and we are going to look
60:18 - into lesson number one which is color
60:20 - detection
60:22 - the first thing you want to do is come
60:24 - under the top of the most the earliest
60:26 - thing
60:27 - come here
60:28 - where it says cloning the repository and
60:31 - also changing the directory let's run
60:33 - this function by itself and we are only
60:36 - interested in this just because we do
60:38 - need this opencv tutorial folder and it
60:41 - has certain images and we're going to be
60:43 - using one of these images here for our
60:45 - project
60:46 - so let's come down here
60:48 - and let's look into the intermediate
60:51 - exercises
60:52 - and we are under color detection the
60:55 - first thing you want to do is import all
60:57 - the libraries that we need
60:59 - and we need import cv2
61:02 - we also need numpy
61:04 - as np let me maximize this a little bit
61:08 - so it's
61:09 - easy to read
61:10 - so import numpy as nb we are also going
61:14 - to be importing the google collab
61:16 - library
61:18 - for our display we'll say from google
61:21 - dot co
61:23 - patches
61:25 - import
61:26 - pv2
61:28 - underscore
61:29 - i am sure
61:31 - let me show you what i have done here so
61:33 - from google collab patches we are
61:34 - importing pv to underscore i n show
61:39 - now we have all these images we have we
61:41 - have everything in our folder if you go
61:44 - back to this directory and under the
61:46 - opencv tutorial folder under the images
61:49 - you have certain images and we are going
61:51 - to be using this image called shapes.png
61:56 - so coming back here
61:57 - we will say okay i open cv
62:00 - you know what i have this image called
62:03 - shapes.png and i want you to read it for
62:06 - opencv to read this image we use opencv
62:09 - cv2
62:11 - dot i am read
62:13 - so opencv will tell me okay i'm going to
62:16 - use i am read to read but give me the
62:18 - file name what's the file name okay the
62:21 - file name is going to be
62:23 - shapes.png
62:26 - but this shapes.png is inside the folder
62:30 - called images so i will also need to
62:33 - provide the folder path
62:35 - this images with the slash
62:38 - images that
62:40 - shapes.png
62:42 - is where the image is available for us
62:46 - okay so that will read the image and it
62:48 - will save the image under the image
62:51 - folder variable
62:52 - now let's display this image by using
62:55 - cb2 underscore i am show
62:58 - image
63:00 - and we just display this image here for
63:03 - us so we're just reading and displaying
63:05 - the image okay good
63:07 - let's run this and we can see that it is
63:10 - displaying this set of image it's a big
63:13 - image and which has all the shapes
63:16 - and different colors present in here
63:18 - okay good
63:19 - now coming back to the code
63:22 - so we have
63:23 - the image right now and we are just
63:25 - displaying it now see if i was only
63:28 - interested in particular colors i have
63:30 - this blue color here let's let's say
63:33 - that i'm only interested in this blue
63:34 - color for now okay so we come here
63:38 - uh the easiest way to select blue color
63:41 - is to first convert it into a new
63:44 - hsv image instead of a bgr image
63:47 - currently image is a bgr image
63:52 - it is represented
63:56 - in blue
63:57 - green
63:58 - and red channels
64:05 - okay
64:07 - now we want to convert this image into a
64:10 - hsv image
64:12 - so we have okay coming here
64:16 - let's come down here let's convert this
64:18 - into an hsv image and we'll call it hsb
64:21 - image equal to
64:23 - pv2 convert color we used this function
64:27 - in i believe it was lesson number two
64:31 - it was right here in the
64:34 - lesson
64:36 - number one i believe yes
64:38 - it's changing the color profiles
64:43 - we used it here for our convert color
64:46 - bgr to gray bgr hsv if you haven't
64:49 - watched that part go back to the page
64:51 - where it displays the hsp image we have
64:54 - given description of what hsp images are
64:57 - and how do they look like
64:59 - coming back to the color detection
65:01 - aspect coming here we are just using the
65:04 - convert color function to convert our
65:07 - bgr image to a hsb image and this
65:10 - convert color function requires
65:12 - us to tell what's the original image
65:15 - original image is the image variable
65:17 - right here
65:18 - and we specify the image
65:20 - one after that we do need to provide
65:23 - what kind of a conversion you're doing
65:25 - now since we're going to be using bgr to
65:28 - hsv we're just going to say convert
65:31 - color
65:33 - bgr
65:34 - to ray so we have p g r
65:39 - two h s v i'm sorry v g r two h s v
65:44 - this function right here h s v
65:47 - is going to be converting a bgr image to
65:49 - an hsv image
65:52 - now we have the hsv image
65:54 - let's do you want this do you want to
65:56 - see the hsp image
65:58 - if you have watched the previous video
66:00 - you don't want to do it but just for the
66:02 - sake of understanding
66:04 - let's run this
66:08 - there seems to be a function error yes
66:10 - because we use the underscore
66:13 - uh we did not use the underscore instead
66:15 - we use the dot version so you can now
66:17 - see
66:19 - that this hsv image is different it's
66:21 - different to what's available here this
66:24 - this original image has different colors
66:26 - for the different shapes but here it's
66:29 - almost the same but it's not the same uh
66:31 - mind you on that it's a little bit
66:33 - different yes it is in yellow in color
66:35 - but they have different color profiles
66:37 - different ranges but oh and we'll see
66:39 - how we can utilize that factor
66:42 - okay let's remove this
66:45 - just play this so we have our color
66:48 - image here okay now what is the next
66:50 - step
66:51 - the purpose of hsv is because you are
66:54 - converting a bgr a three channel image
66:57 - into a hsp image where hue saturation
67:01 - variance you represents the color
67:04 - profile
67:05 - so you can
67:06 - now
67:07 - control the value of hue to display what
67:10 - color you want so i will say
67:13 - okay i have this image it has different
67:15 - colors and i'm only interested in this
67:17 - blue color so i can isolate this blue
67:20 - color in the hsv range by saying okay
67:24 - my lower
67:25 - blue
67:26 - color so you need to provide the range
67:28 - of your blue color values and i'm going
67:30 - to say okay my lower blue color it's
67:33 - under the array
67:35 - it's going to be an array
67:37 - and this blue color array is going to
67:39 - have a value of
67:43 - say
67:47 - 65
67:50 - 0
67:52 - and 0.
67:54 - and i'm going to supply another upper
67:57 - range now stay with me on this and
67:59 - explain you what this is what's
68:00 - happening here
68:02 - and i'm specifying another array
68:04 - and this array is going to have a value
68:07 - upper bound of 1
68:11 - 255
68:13 - 255.
68:16 - so i'm having
68:18 - two upper right so i have a lower bound
68:20 - and an upper bound
68:22 - and i use this lower and upper bound to
68:26 - pick out or extract just the blue color
68:29 - basically what i'm saying here is
68:32 - okay i have an image and i'm only
68:34 - interested in the blue color which is
68:37 - between these two values lower blue and
68:39 - upper blue and this lower blue is
68:42 - specified by the hue value between 65
68:46 - and 110
68:47 - so my blue color is between 65 and 110
68:51 - and the rest the saturation and the
68:54 - variance is maybe between 0 to 255 i
68:57 - don't care right now i'm only interested
69:00 - in my
69:01 - u value which specifies the color and my
69:04 - color which is the blue color is between
69:07 - 65 to 110
69:10 - and this is what opencv will look for
69:13 - anywhere where blue color or the hue
69:16 - value is between 65 and 110 it will
69:19 - extract that and ignore the rest
69:23 - basically the value of on this color can
69:26 - go anywhere from 0 to 255
69:28 - 0 to 180 but we are only interested in
69:32 - 65 to 110 okay so we have decided to
69:37 - find the boundaries of our blue color
69:39 - now we are going to be using
69:41 - a
69:42 - range function to create a mask
69:45 - okay i am creating a new mask now this
69:47 - mask is going to have the value only of
69:50 - the blue color
69:52 - the opencv has this function called in
69:54 - range
69:56 - in range and this range can take these
69:59 - lower and upper bound range and return
70:02 - the pixels that lie between these ranges
70:05 - this range so i say cv2 in range
70:10 - and i you want to find the range between
70:13 - in the hsv image using
70:17 - the
70:17 - lower bound and the upper bound you can
70:20 - see the source image the lower image
70:23 - lower bound and the upper bound
70:25 - coming back we've supplied the image
70:27 - which is the hsb
70:28 - we are now supplying the lower bound
70:30 - which is lower
70:32 - blue and we are also supplying the upper
70:35 - bound
70:36 - which is the upper blue
70:39 - and it's it will create the mask for us
70:41 - let's generate this and we can see how
70:45 - the mask looks like
70:47 - it's it'll be a black and white image
70:49 - which will only consist of blue color
70:52 - so you can see that
70:54 - this is this is the original image right
70:56 - from here in the bottom but the upper
70:59 - image only is specifying the triangle
71:02 - which represented the blue color
71:04 - original
71:05 - so it's now creating that mask is
71:07 - created where it's only representing the
71:10 - triangle now i mean let's
71:14 - not display the i am show original image
71:17 - so if we don't we don't get confused we
71:19 - can see the image now only is creating a
71:22 - mask around the blue color rectangle
71:25 - okay so good now the next step is to
71:28 - create to use this mask to extract the
71:32 - original blue color from the previous
71:35 - image so we can use a bit wise operation
71:38 - on this we can say hey result
71:42 - equal to
71:44 - cv2
71:45 - bitwise
71:47 - oh
71:47 - did i move out of it
71:50 - now i hope it's visible now so we have
71:53 - bit wide and
71:55 - and wherever
71:57 - your original your mask has an image
72:00 - wherever your mask is white in color
72:02 - like this case wherever the mask is
72:05 - white color it should return the
72:07 - original color of the image and wherever
72:09 - it is black it should just ignore that
72:12 - that's what the bitwise hand is going to
72:14 - do wherever white color is present it
72:17 - will give out the original color and
72:19 - wherever it's black it will ignore that
72:21 - area
72:22 - so we'll say okay you're going to be
72:24 - doing bitwise and on my image
72:27 - and you're also going to be pre
72:30 - you're also going to return the image in
72:32 - my same image folder
72:34 - and
72:35 - we are going to use a mask which is
72:38 - given by
72:39 - our variable
72:40 - here mask
72:43 - this is my function and we have defined
72:45 - the result image now let's display this
72:48 - result image
72:52 - okay we are displaying this result image
72:54 - now
72:55 - let's run this
72:59 - and let's minimize this a little bit so
73:01 - we can see so you can see the original
73:02 - mask looks like this and the final image
73:06 - looks like this where it has extracted
73:09 - the original part of the image
73:12 - it has the blue color
73:14 - similarly if you were interested in the
73:17 - different types of colors you need to
73:19 - specify the different
73:21 - lower and upper range values so like we
73:24 - did lower blue here instead of blue we
73:26 - can say lower hue
73:29 - and upper here
73:31 - because we are actually converting or we
73:34 - are actually using
73:36 - our playing with the hue values so we'll
73:38 - say upper hue and lower hue
73:41 - so let's run this back again to make
73:43 - sure our code is fine we did not break
73:45 - anything yes everything seems to be
73:47 - working fine
73:48 - and we also don't need to display the
73:50 - mask anymore
73:52 - since we know how the mask looks like
73:54 - basically a black and white image and
73:56 - you can see that this image is only
73:58 - representing the blue color rectangle
74:01 - similarly our original image had
74:03 - different other colors
74:05 - like it had the red color the yellow
74:07 - color and we'll see how we can extract
74:10 - the different colors with this lower and
74:12 - upper bound range we find the blue color
74:16 - triangle
74:20 - now similarly there are different other
74:23 - color profiles which can represent
74:25 - different other colors that you might be
74:28 - interested in
74:29 - similarly like we have blue we have the
74:32 - red color
74:33 - red color
74:36 - and you can use the red color by conv by
74:39 - using our lower
74:40 - view and our lower q is equal to
74:45 - again with the np dot array
74:48 - and this array is going to have a range
74:51 - of values between
74:53 - 0 to 20
74:55 - because this
74:57 - red color is basically
74:59 - zero by zero it's in the original
75:02 - spectrum of it's in the initial spectrum
75:05 - of the hue value similarly we are also
75:07 - specifying upper hue
75:10 - equal to np dot array
75:13 - and this function goes from 0 to 20
75:16 - u is between 0 to 20 and our saturation
75:20 - and variance we don't care it can be
75:23 - anywhere between 0 to 55.
75:26 - once we have this let's
75:28 - comment this it doesn't affect our
75:30 - original part so we have the blue and
75:32 - now we're looking into the red color
75:35 - let's run this
75:36 - and you can see now that it's only
75:38 - showing the red color circle so it's
75:41 - extracting it's only
75:43 - isolating the red color from the
75:45 - original image
75:47 - similarly there are different other
75:49 - profiles so we had the red color now we
75:52 - can also look into green colors now
75:55 - green color also has its own
75:58 - lower and upper hue which is given by np
76:01 - dot array
76:03 - and this function of green color goes
76:05 - from 46 to 91. now you might ask how am
76:11 - i getting these values how do i know
76:14 - that red color is between 0 to 20 well
76:16 - how is blue color between 65 to 110
76:20 - similarly
76:21 - how is the upper range of green color
76:24 - between
76:27 - 46 to 91 this is more with trial and
76:31 - error and again opencv also has a
76:35 - function called trackbar now i'll show
76:38 - you what it looks like cv2 trackbar
76:41 - and this track bar it's something which
76:43 - cannot run on a collab
76:45 - but you can also but you can run it on a
76:47 - standalone desktop application so this
76:50 - track bar basically creates this kind of
76:52 - a range track bar and you can change the
76:55 - values of your color the red the green
76:58 - and the blue and you can see what kind
77:00 - of an output you're getting
77:02 - and that output then you can take that
77:05 - and then represent it in your own code
77:08 - so you know what the upper and the lower
77:10 - bound limits are using this trackpad you
77:12 - can always play with it it's something
77:14 - which is not too complicated to work
77:16 - with we will see it in the later future
77:18 - projects if we ever get to use it
77:21 - but uh if in case you're interested in
77:23 - identifying what kind of
77:25 - upper and lower bounds are you can
77:27 - always use a track part to run with it
77:29 - so
77:31 - looking into green color pink color is
77:33 - between 91
77:35 - and we are again not interested in
77:37 - the saturation and various values
77:40 - we have let's comment the red color now
77:43 - and let's run this just for the green
77:46 - color so you can now see its green color
77:49 - is being displayed very nicely
77:52 - uh now say if i were to display all the
77:55 - three colors
77:57 - or maybe red color and green color
77:59 - together you know the red color starts
78:01 - from zero and ends at 20 and the green
78:04 - color on the other hand starts from 46
78:06 - and goes to 91. so if i were to say okay
78:09 - instead of 46 let's put zero it should
78:12 - give us both the red and the green color
78:14 - and maybe some other colors also yes you
78:17 - can see it can give out the red color
78:19 - the green and also the colors between
78:22 - both of them
78:23 - you're getting this color also
78:26 - let's let's change this back again to
78:28 - where we were so we have
78:30 - 46 to 91. now let's come back and now
78:34 - try to define try to
78:36 - discuss or identify where the yellow
78:39 - color is
78:42 - now again lower blue lower hue
78:45 - which is given by an np array
78:48 - and this array
78:50 - this is a numpy array
78:52 - and you're defining this numpy array
78:54 - between 21
78:58 - 0 for saturation 0 for variance and you
79:01 - also have an upper
79:03 - u
79:05 - and np array which has
79:09 - 21 to 45
79:12 - and
79:13 - 0
79:14 - 255
79:15 - and 255
79:18 - so you can see it's ending up at 45 and
79:20 - then starting at 46 for green color
79:22 - that's the reason you had both when you
79:25 - tried to represent between 0 to 91 so
79:28 - you were getting yellow color as well
79:30 - okay let's
79:32 - comment this and let's run this
79:35 - and this yellow color
79:36 - is now being extracted or isolated so
79:40 - you can see again if i were to change
79:42 - instead of the 21 if i were to put down
79:45 - zero it would give us the value
79:48 - of all the three colors which is the
79:51 - green
79:52 - the red yellow
79:54 - and
79:55 - the green now why is the green missing
79:57 - because the upper bound is 45 whereas
80:00 - the green color is starting at 46 so if
80:03 - we were to say okay instead of 0
80:06 - 45 let's say 0 to 91
80:08 - and if we were to display this you can
80:11 - see that it's also giving all the three
80:13 - colors what if we needed the blue color
80:15 - as well again you can play this value
80:18 - you can see that the blue color starts
80:20 - at 65 and ends at 110. so if we were to
80:23 - change the upper bound limit to 1 1 0
80:27 - and if you just run this it should
80:29 - include all the four colors that we
80:31 - wanted
80:32 - so any any color that you're playing
80:34 - with any color that you're interested in
80:36 - in your own images will lie between that
80:39 - range 0 to 180 so identify whatever
80:42 - color you are interested in and then
80:44 - work accordingly
80:46 - okay let's convert this back again to
80:48 - what we wanted so we needed
80:51 - the yellow color and the yellow color is
80:53 - between 21
80:54 - and 45.
80:57 - so if we just needed the yellow color
80:59 - let's run this
81:00 - and you can see that it's only giving us
81:02 - the yellow color hello everyone welcome
81:05 - to this face detection
81:07 - intermediate lesson number two under the
81:09 - opencv tutorial series
81:12 - in this tutorial we're going to see how
81:13 - we can do face detection
81:15 - and the first thing you want to do is
81:17 - come here where it says table of
81:18 - contents
81:20 - open part one and just before part one
81:23 - the list is cloning of repository this
81:25 - is basically just copying all the files
81:27 - that we need for this project so we just
81:29 - click on the play and it will download
81:32 - all the files that we need so if you
81:33 - come down to the directory folder you
81:35 - can see there is this folder called
81:37 - opencv tutorial created for us and under
81:40 - that there is a file section so this
81:42 - file section has this hard cascade file
81:46 - if i maximize this a little bit you can
81:48 - see that it's showing her cascade
81:50 - frontal face default xml this is
81:53 - basically a cascade classifier that we
81:55 - are going to use in order to do our face
81:57 - detection coming back to the table of
81:59 - contents going to part two intermediate
82:02 - series lesson number two
82:04 - now under lesson number two here we're
82:07 - going to code our simple face detection
82:09 - application it's a simple 4 5 line code
82:12 - very easy to follow so just stay along
82:14 - with me
82:15 - now the first thing you want to do is
82:17 - import opencv so you can see we can do
82:19 - all the image manipulation for us i'm
82:21 - going to maximize this a little bit and
82:24 - remove this so that's easy for you to
82:26 - see so you have open cv the next thing
82:28 - you want to do is import cv to
82:30 - underscore im show from google so that
82:33 - we can display our images right here in
82:35 - the pod back in this browser
82:38 - you have google
82:40 - collab dot patches
82:44 - import
82:45 - oops
82:46 - cv2 underscore
82:48 - i am show so you have underscore then
82:51 - you have all the libraries that we need
82:53 - the next thing you want to do is you
82:55 - want the library for cascade classifier
82:59 - and that's cascade classifiers who are
83:01 - going to help us in do our face
83:02 - detection so let's initialize that
83:05 - and face cascade
83:09 - is a variable that's going to hold the
83:11 - cascade classifier for us we'll call it
83:14 - as cv2
83:15 - dot
83:16 - cascade okay face cascade now you are a
83:19 - classifier so opencv has this function
83:22 - called cascade classifier and you just
83:25 - need to specify opencv hey opencv you
83:28 - got the gasket classifier for us but i
83:30 - also need to tell you where my cascade
83:33 - classifier is located but we saw that it
83:36 - was under this file section under the
83:38 - hard cascade frontal face now this is a
83:40 - very big name so you can see it's called
83:43 - our cascade frontal face with a bunch of
83:46 - underscores in between very difficult
83:48 - for me to remember so i will just go
83:51 - ahead and say rename file now press my
83:54 - control c to copy the file name
83:57 - and i'll close this
83:59 - now i do need to specify okay i got
84:02 - cascade classifier frontal face here
84:05 - however
84:06 - we knew that was not just
84:08 - the by itself it was inside this folder
84:11 - called files so i didn't do need to
84:13 - provide the file path name as well
84:16 - which is files so view you have
84:19 - specified that okay the cascade
84:20 - classifier is inside the file section
84:23 - files not just file the file section and
84:26 - under this hard cascade for
84:28 - default dot xml
84:31 - so you can do a lot of mistakes here so
84:33 - just pay attention so you have files and
84:36 - then you're specifying this thing one
84:38 - last thing is you want to specify this
84:40 - as a string
84:41 - because cascade classifier is expecting
84:44 - this as a string
84:46 - you want to specify under quotation
84:48 - marks
84:49 - and that's done with the fair
84:51 - face cascade classifier
84:54 - okay so that's done with the cascade
84:56 - classifier and trust me i think that's
84:57 - the
84:58 - most complex part everything else
85:00 - moving forward is very easy
85:03 - now the next step is to read one of the
85:06 - images that we have now under this
85:08 - directory here
85:09 - under the images folder there is a
85:12 - couple of images and this image with
85:14 - your person.jpg is basically a human
85:16 - face and that's the face that we are
85:19 - going to use
85:20 - to test our face detection today
85:23 - we'll call it as image
85:24 - okay image now opencv you have this
85:28 - function called i am read please read
85:31 - the image for me and the image is inside
85:34 - this images folder
85:36 - and it's called
85:38 - person dot jpg
85:41 - going back showing you images
85:44 - person dot jpeg which is specifying that
85:47 - okay it's an
85:48 - images.person.jpg file and once you have
85:51 - specified the image let's simply display
85:55 - the image so we know
85:56 - everything is working out perfectly so
85:59 - far
86:00 - so let's run this
86:02 - and it's able to display a person's
86:04 - image right here in the browser for us
86:07 - coming back here
86:09 - let's the first step you want to do is
86:11 - convert this colorful image into a
86:14 - grayscale image because this cascade
86:17 - classifier is designed only and only to
86:21 - run on grayscale images so you have to
86:24 - convert that into a grayscale image and
86:27 - how you do grayscale image conversion
86:30 - going back to our table of contents you
86:32 - have changing image color profiles if
86:36 - you click on that
86:37 - this section where we learned
86:40 - the conversion of color this color bgr
86:43 - to gray this is what we are going to use
86:46 - today in order to convert our bgr image
86:49 - to a grayscale image
86:52 - so we'll use that same thing we covered
86:55 - that in the previous lecture
86:57 - going back to face detection let's use
87:00 - our convert color
87:02 - function so we'll call it as a grayscale
87:04 - image gray image
87:06 - and we will use opencv's convert color
87:10 - function to help us convert our colorful
87:13 - image to a
87:15 - grayscale image so you want to specify
87:18 - the image that you are using
87:21 - you also need to specify the type of
87:24 - conversion you're doing so since you're
87:26 - doing pgr to create you are going to let
87:30 - opencv know that it is
87:33 - a color conversion and it's converting
87:36 - from bgr
87:37 - to gray
87:40 - so this right here is what we are going
87:42 - to use
87:43 - and now gray is going to be nothing but
87:46 - a grayscale image so if i change this
87:49 - img
87:50 - and instead of that we display this gray
87:52 - it should be a grayscale image for us so
87:55 - you can see now yes it's a grayscale
87:58 - image displaying for us
88:00 - so very simple
88:02 - now this grayscale image is going to be
88:04 - sent to this face cascade classifier and
88:08 - this guy has been waiting for us to do
88:10 - our face
88:12 - detection so we'll say okay
88:15 - no more waiting you're ready to do our
88:17 - face detection
88:19 - so this face detection
88:22 - is going to be run through this face
88:24 - cascade and this face cascade
88:27 - is now since it's a cascade classifier
88:30 - it has its own functions it has its own
88:32 - built-in functions you see the moment i
88:35 - put the dot it's giving me a couple of
88:37 - options convert detect multiscale detect
88:40 - multiscale 2 3 mt
88:43 - these are all built-in functions that
88:45 - the face cascade classifier can perform
88:48 - for us
88:49 - in our case we are simply going to be
88:51 - using this detect multiscale and this
88:53 - multi-scale is nothing but a detection
88:56 - function which can do image detection
88:59 - for us
89:00 - so let me go back close this back again
89:02 - i'll show you a few things so the moment
89:05 - you go into that function this function
89:07 - is going to take the size of the image
89:10 - also the image
89:12 - file name whatever image you want the
89:14 - scale factor basically you're trying to
89:17 - tell how big your image is compared to
89:19 - the original training images the number
89:22 - of neighbors that it can have a couple
89:25 - of other flags minimum size maximum size
89:27 - which are not so much of concern but the
89:30 - image the scale factor and the minimum
89:33 - neighbors are what we are very much
89:35 - interested in
89:37 - go back here
89:38 - now you are specifying the image which
89:41 - is the grayscale image then now you are
89:44 - specifying the scale factor so the hard
89:47 - cascade classifier was trained on a
89:49 - couple of images
89:51 - a group a lot of group of images in the
89:53 - past but it was
89:56 - those images were of certain size
89:58 - certain colors certain shape
90:00 - so the
90:01 - those training images were of a
90:03 - different property and it's very
90:05 - different to what we are using right now
90:07 - so you're just specifying that okay
90:10 - my new image could be of a scale factor
90:12 - of 1.3
90:14 - well it could be anything else
90:16 - this is just a random number that i
90:18 - chose and it seems to be working but if
90:20 - you notice that this number is not
90:22 - working for your own images just change
90:25 - that a little bit and play around you'll
90:27 - get the right resource
90:28 - next thing is you're specifying the
90:30 - number of neighbors in our case we do
90:32 - have we don't have any other faces in
90:34 - this image it's only one face here but
90:37 - we're specifying okay this could have
90:39 - five because we're going to be using the
90:41 - same code to do some group detection as
90:43 - well so it seems to be five is working
90:45 - out even for a single image but
90:47 - we'll see
90:48 - we have the faces now we use the face
90:50 - casket classifier to detect all the
90:53 - faces that are available in the
90:55 - grayscale image
90:57 - and this faces has information about all
91:01 - the faces so this function is a very
91:04 - important function this variable has
91:06 - information about all the faces
91:09 - and let's draw those faces
91:12 - now we are going to be using another
91:14 - function another system that we learned
91:16 - in the past and this lesson where we saw
91:19 - lesson number four under the basics fold
91:22 - section drawing shapes and text so if
91:25 - you come here
91:26 - we learned how to draw a rectangle a
91:29 - line even putting a text so we'll use
91:32 - one of these functions to do our
91:35 - face
91:36 - detection
91:37 - coming back to the directory oops table
91:40 - of contents coming down to the face
91:42 - detection aspect let's come down here
91:45 - now we will use these faces to draw
91:49 - the information about where the face is
91:52 - so this faces has nothing but
91:54 - the coordinates so if i print this print
91:58 - faces
92:00 - let's
92:01 - comment this it will have information
92:04 - about the coordinates of where the face
92:07 - is but these coordinates are nothing but
92:09 - the pixel values of where the bounding
92:12 - box of the face is
92:14 - so let's come back here
92:16 - now let's we don't need to print this
92:20 - we will now use these coordinates to
92:23 - draw our bonding rectangle
92:26 - but we'll say okay
92:30 - for
92:32 - x y
92:34 - w h
92:35 - so
92:37 - this information in faces
92:40 - so what what is that i'm doing here so
92:43 - this x y w h is nothing but the
92:46 - coordinates that are available inside
92:48 - the faces so the 208 and 73 are nothing
92:53 - but the x and y location of the top left
92:57 - corner of the rectangle and this 161 161
93:01 - is nothing but the width and the height
93:04 - of the rectangle of the bounding box
93:06 - which houses the face
93:09 - so coming back here
93:12 - we'll say hey cv2 you have this
93:14 - rectangle function which
93:17 - we saw in the previous lecture and this
93:19 - rectangle function is able to take the
93:21 - image the point one and the point two
93:24 - which is the top left corner of the
93:25 - rectangle and the bottom right corner of
93:28 - the rectangle the color the thickness
93:30 - and the line type line time it's not
93:32 - something we're interested in we'll go
93:34 - under the path of thickness
93:36 - so yes so we have cv2 rectangle and you
93:40 - are going to be drawing it on the main
93:42 - colorful image which is the img image
93:46 - instead of the green scale image
93:48 - now you are also going to specify the
93:50 - point 1 which is given by x and y
93:53 - and you're also going to specify the
93:55 - point 2 which is given by
93:58 - x plus w
94:01 - y
94:02 - plus
94:02 - each
94:03 - so you're just going and pointing it out
94:05 - to the bottom left bottom right corner
94:07 - of the rectangle
94:09 - so once you have specified the points
94:11 - you also need to specify the color and
94:14 - we'll say okay let's use
94:17 - green color it will say zero 255 for
94:21 - green
94:22 - and zero for red everything else is
94:24 - green is zero except the green color
94:26 - which is 255 we will also give it a
94:29 - thickness of size 3
94:32 - pixel level 3 and it should now draw the
94:35 - rectangle on the face for us so let's
94:38 - run this
94:41 - oops we are still displaying the
94:44 - grayscale image instead of the grayscale
94:46 - image now we can display the img image
94:49 - which should hopefully have the face
94:52 - detection for us you can see that it's
94:54 - automatically detecting the face of the
94:56 - person and it's also drawing the green
94:58 - colored rectangle that we wanted in this
95:01 - chapter
95:02 - so it's a very simple chord you can see
95:04 - it's a hardly a few lines the only thing
95:07 - you're doing is you're doing some
95:09 - cascade classifier you're initializing
95:11 - the cascade classifier you're reading an
95:13 - image you're converting it into a
95:15 - grayscale image then you're using the
95:17 - cascade classifier to detect the faces
95:20 - that are available
95:21 - normally if you have multiple faces it
95:24 - will go through all the faces
95:26 - in the face section
95:28 - and then draw the rectangle on all the
95:31 - faces but in this case in this
95:32 - particular image the person.jpg image
95:35 - that we used it it's only of it it has
95:38 - only one person in it and that's the
95:40 - reason you're you don't need to go
95:42 - through all the faces but if you had
95:44 - more faces this function will just loop
95:47 - through all the faces draw all the
95:49 - rectangles and then display the output
95:52 - for us
95:53 - so that's where the phase cascade
95:55 - classifier comes in i also have another
95:58 - image called group.jpg
96:00 - i'll quickly run this for you so let me
96:03 - change this
96:05 - in fact let me copy this
96:08 - and
96:09 - oops
96:11 - let me copy this
96:12 - so i don't mess up your original code in
96:15 - case you're going to be running this
96:17 - and here i'm going to change it to
96:20 - group
96:22 - dot jpg the group.jpg is now a different
96:25 - image which has a couple of people in it
96:28 - instead of just one person but let's see
96:31 - how this function operates it's this one
96:33 - is going to take a little bit more time
96:34 - just because it has too
96:36 - many faces in it and you will see
96:39 - that how what's the kind of output
96:40 - you're going to get here i'm going to
96:42 - skip this a little bit
96:47 - so now we can see that the image has
96:49 - come up here you can see the amount of
96:52 - images amount of people are present here
96:55 - and the face detection that is running
96:57 - through it
96:58 - let me maximize just a little bit
97:00 - you can see
97:02 - the intricacy of the face detection this
97:05 - is a very noisy image it has so many
97:08 - information there's so much of
97:09 - information here but it's still able to
97:11 - detect the faces
97:13 - in this image and this cascade
97:15 - classifier is very lightweight it used
97:18 - to be run in the old
97:21 - camera phones the camcorders the old
97:23 - camera phones which did not have any
97:25 - much computing power unlike the phones
97:28 - that you'd use now
97:30 - this gasket classifier was capable of
97:32 - running face detection in those small
97:35 - low end profile
97:37 - you can see the accuracy the level of
97:39 - accuracy
97:40 - that's able to detect yes there are some
97:42 - misses there are some people who are not
97:44 - being detected and some errors and
97:46 - mistakes here but the most part it is
97:49 - able to give out the right information
97:52 - hello everyone welcome to lesson number
97:54 - three of intermediate opencv tutorial
97:57 - series and here the first thing you want
97:59 - to do is
98:00 - clone this repository by running this
98:02 - command over here it will clone the
98:03 - repository all the images that we need
98:05 - for this project so once everything is
98:08 - done
98:08 - go back
98:09 - and open this table of contents and go
98:12 - under the lesson number three shape
98:13 - detection that is what we are going to
98:16 - work on today
98:17 - so let's import let's start the project
98:20 - by first importing all the libraries
98:22 - that we need we need opencv we need
98:26 - numpy
98:28 - which will import us numpy and b and we
98:31 - also need the collab version for cv to
98:34 - underscore im show we'll use google
98:37 - collab
98:38 - dot patches
98:40 - import cv to underscore im show so this
98:44 - function i am sure is just for
98:45 - displaying the images for us
98:48 - let me increase this a little bit so
98:50 - it's easy for you to see we will also
98:53 - make it full screen so we can clearly
98:55 - see what's going on
98:56 - so we have the shape detection and we
98:58 - are just specifying all these libraries
99:00 - right here the first thing is let's read
99:02 - the image and the image is inside this
99:05 - folder opencv
99:07 - images and shapes.png
99:10 - so this is the image that we are
99:12 - interested in today and we'll do that by
99:14 - reading this image for us so we'll say
99:16 - opencv please read an image and save it
99:19 - into this variable called img
99:22 - and you want to use opencv's i am read
99:24 - function and this function just needs
99:27 - the name of the file the file name and
99:29 - the file path wherever it is located
99:32 - so it's located inside the images folder
99:34 - in the directory and we call it as
99:37 - shapes.png
99:39 - so this will just read the image for us
99:42 - we can always test the image whether or
99:44 - not it read the right image by
99:46 - using the cv2 im show function and we
99:49 - just run this
99:51 - and we see there is an error right here
99:54 - so it looks like we missed something uh
99:56 - google collab patches
99:58 - from so we need to import
100:01 - from google collab patches import cv to
100:04 - underscore image no worries we fixed it
100:07 - now we can just simply rerun this and we
100:09 - can see that it's able to read the image
100:12 - and it's displaying it here for us so
100:14 - good
100:15 - now the first thing you want to do is
100:17 - since we're doing shape detection we
100:19 - wanted to discuss and identify what kind
100:21 - of shape it is so we know i mean from a
100:23 - human eye that is this one is a circle
100:26 - this is a hexagon
100:28 - this one right here is a square this is
100:31 - right here a triangle so we from a human
100:33 - perspective we know what these images
100:35 - are but if you were going to give this
100:37 - control to a computer program how would
100:40 - the computer read through all these
100:42 - colors and identify
100:44 - these images so of course we need some
100:46 - sort of algorithms in order to do this
100:48 - and we'll see how we can do that so
100:50 - we'll try to read these shapes and
100:52 - images through opencv or image
100:55 - processing perspective
100:57 - so the first thing you want to do is
100:58 - convert this into a grayscale image and
101:01 - we'll use opencv function convert color
101:06 - so convert color cbt color this is just
101:09 - going to convert the color from whatever
101:11 - color we want to whatever color profile
101:14 - we want so you need to specify the image
101:16 - that you want to convert this to so img
101:19 - is the original image and we also need
101:21 - to specify what kind of conversion you
101:23 - are doing so we are going to convert
101:25 - from
101:26 - color to grayscale so we are going to
101:28 - use cvt
101:30 - color
101:32 - bgr
101:34 - to
101:34 - gray you have bgr to gray and this color
101:38 - profile is just going to convert the
101:40 - colorful image into a grayscale image we
101:43 - can always use the cv to im show
101:45 - function to see what kind of an output
101:48 - we get and you can see that it's already
101:50 - converted all the colors into a
101:52 - grayscale profile it does have the shape
101:54 - and the boundaries of the image but it's
101:57 - all grayscale
101:58 - okay so we have the grayscale image now
102:01 - now the next thing we want to do is
102:03 - understand some of these functions some
102:05 - of these images some of these values in
102:09 - a more clearer way and for that purpose
102:11 - we'll use open series thresholding
102:14 - function
102:15 - this thresholding function is
102:16 - responsible for converting anything that
102:19 - you are interested in anything that your
102:22 - your profile is interested in into white
102:25 - and then the rest into black in color so
102:27 - this is basically a filter and you can
102:30 - say hey okay okay open cv anything which
102:33 - is light like this hexagon the circle
102:36 - the square the triangle these are all
102:38 - lighter colors compared to the
102:39 - background which is black so anything
102:41 - which is light
102:42 - please make that into white in color
102:45 - and everything else black so i'm not
102:47 - interested in them i'm only interested
102:49 - in the white in color profile for that
102:51 - purpose we use opencv thresholding
102:53 - function and we'll call hey threshold
102:57 - used this opencv function called
102:59 - threshold
103:01 - this threshold function is a built-in
103:03 - function from opencv which can take the
103:05 - source and threshold value and the
103:08 - filters and then convert that into a
103:10 - black and white image so it basically
103:13 - filters the image to the values that you
103:15 - are interested in so you specify the
103:18 - image which is our grayscale image now
103:20 - you want to specify the threshold values
103:22 - so we'll say okay anything which is
103:25 - between 50 to 255
103:27 - because we know white color is 255 so
103:30 - anything which is 255 and 50 is the
103:32 - lower end
103:34 - and we'll see 50 should be okay in our
103:36 - case and we are also specifying the type
103:40 - which is not too much of an initial we
103:41 - just specified one and we take care of
103:44 - this now let's see if we can
103:47 - display this image here for us
103:49 - so cv2 i am sure thresh
103:53 - let's
103:54 - see how this kind of an image looks like
103:56 - and you can see that it's already
103:59 - converted everything into black and
104:01 - white
104:02 - and yes it's everything that we are
104:04 - interested in it's all
104:07 - converted into one color and the
104:08 - background is in another different color
104:11 - so this threshold function has already
104:14 - used a filter and everything that we're
104:16 - interested in it has specified them into
104:18 - one color and the background into
104:21 - another color so that's the purpose of
104:23 - this shoulder so it's converting that
104:25 - into two different values and now we can
104:28 - use that to our advantage so now we have
104:31 - all the
104:33 - functions that we are interested in we
104:35 - have all the
104:36 - images that we're interested in now
104:38 - let's start reading these different
104:40 - values from an opencv perspective so
104:44 - opencv has a good function called as
104:47 - find contours so this find contours
104:50 - function is a type of function that's
104:52 - able to go through all these images and
104:55 - go through this
104:57 - right here you can see the circle and it
104:59 - will find all the contour the outer
105:01 - contour which differentiates these two
105:04 - colors the black color and the white
105:06 - color these are differentiated by this
105:08 - circle right here and it will find that
105:10 - contour which is differentiating these
105:12 - two colors so these two color pixel
105:15 - values that are being
105:16 - changed or
105:17 - being differentiated it will identify
105:19 - the border of these pixels so we'll use
105:23 - this function called
105:25 - contours
105:26 - and these are just the h and this thing
105:28 - is nothing but just specifying the
105:30 - history and the flag values so we're not
105:33 - interested in that we're just interested
105:35 - in the contours and the threshold
105:37 - so cd2 find contours
105:42 - and
105:42 - contours is given by contours so you're
105:45 - just specifying the different types of
105:46 - contours that we are looking into and we
105:49 - are specifying okay the contour should
105:51 - be taken out from the threshold image
105:54 - and you're also going to specify what
105:56 - kind of contours you're interested in
105:59 - and this is of course a binary image
106:00 - since we can we use the threshold
106:02 - function and we are now you're going to
106:05 - use different types of
106:07 - filter and pixel values you're saying
106:09 - okay it's going to be between one and
106:10 - two and uh right now you don't need to
106:12 - understand you know
106:14 - these two values it's it's as long as
106:16 - you're putting one into it will work
106:18 - fine you don't need to worry about why
106:20 - or not
106:21 - so let's go into understanding what
106:23 - these contours are so these contours are
106:26 - just specifying all these outer boundary
106:29 - of the pixel value of the shapes
106:31 - when we have the contours detected
106:34 - these contours are specifying
106:36 - information about the circle this
106:38 - hexagon the square and the triangle so
106:41 - it has information it has the contours
106:43 - for all these shapes that we see here
106:46 - and we will just loop through all these
106:49 - contours and go through the contours
106:51 - that we are interested in
106:53 - so we'll say okay
106:55 - for
106:56 - ponds which are contours or the contours
107:00 - or for a counter
107:02 - or
107:03 - inside these contours
107:07 - for a counter which is so we're just
107:09 - looping through all the contours
107:12 - one by one by using the for loop and you
107:15 - want to
107:16 - identify what kind of what are the
107:19 - points that are specifying the contours
107:22 - so these these are the points in case of
107:25 - a circle there are too many points since
107:27 - it's a circular
107:28 - image but in case of a hexagon you can
107:31 - see that there are six points that you
107:33 - need in order to define a hexagon so
107:36 - this
107:37 - we use a function called as approximate
107:40 - poly dp which is able to identify the
107:44 - number of coordinates or the number of
107:46 - points that you need in order to define
107:49 - your contour so whatever shape you're
107:51 - working with whatever it could be how
107:54 - many points do you need in order to
107:56 - identify or in order to draw your shape
107:59 - so we have this function called as
108:01 - approximate quality b which can
108:04 - give us an approximation of how many
108:07 - points
108:08 - we need in order to define our image or
108:11 - shape so we have this function's name is
108:13 - aprox
108:15 - poly dp
108:16 - and this dp
108:18 - this dp is defined the dp is actually
108:21 - the name of the person who invented this
108:22 - algorithm and uh his first name starts
108:25 - with a d and his last name starts with a
108:27 - p i believe is daniel pickard
108:30 - if i'm not mistaken
108:32 - uh my might maybe i'll put it in the
108:35 - i'll put some text here to identify
108:37 - what's the right name of the person but
108:39 - uh this approximate poly is able to
108:42 - give out the nerd minim on the number of
108:45 - points that you need in order to
108:46 - identify your contour so this
108:49 - approximate poly just needs the
108:51 - information
108:53 - about the contour that we are working
108:55 - with and it also needs some sort of an
108:57 - epsilon value this epsilon value is
108:59 - nothing but the error or the amount of
109:03 - error oh you know what they have the
109:05 - name here it's douglas pecker the
109:08 - douglas specker is the name of the
109:09 - person who invented this algorithm and
109:11 - that's why it's called aprox polytp
109:15 - so this function takes this information
109:17 - called as an epsilon this epsilon is
109:20 - nothing but the approximation value or
109:22 - it could you could take it as an amount
109:24 - of error that you're
109:26 - you're okay with when you're identifying
109:28 - this function so uh it's one of the best
109:31 - ways of identifying or one of the best
109:33 - ways to
109:34 - denote the function or the epsilon value
109:37 - is by using the arc length and the arc
109:39 - length if you multiply it by 0.01
109:42 - whatever value you get it will be more
109:46 - or less acceptable for our error
109:48 - purposes so as for now just understand
109:50 - we're just converting this
109:53 - we're just specifying the amount of
109:55 - error that we are okay with and we say
109:57 - okay arc length and
110:00 - we see we tell the counter name
110:03 - and true
110:06 - so let me encode this on this side so
110:08 - you can see what's happening so we
110:10 - specified the contour this we are
110:12 - specifying the epsilon value which is
110:14 - given by this and we're just giving by
110:17 - the arc length of that contour and based
110:20 - on that now we need to just specify okay
110:23 - maybe it's just going to be
110:24 - whether it's a closed curve or an open
110:27 - curve in our case all the curves are
110:29 - closed so we'll just say true for close
110:32 - or closed so we are now specifying all
110:35 - the approximate value and this
110:37 - approximate will be able to read all
110:40 - these
110:41 - contour values and give us the value of
110:43 - the each and every shape
110:46 - so let's
110:47 - print this so we'll see what what is
110:50 - happening here so we'll run this
110:54 - and you can see that it's able to go
110:56 - through all of these and it's giving us
110:58 - the points for each and every contour so
111:02 - now let's see
111:04 - okay we have the up approximate which is
111:06 - giving us the
111:08 - coordinates of the shape of the points
111:10 - and let's uh and these are you can see
111:12 - it's form of an array it's an array
111:15 - which is going through all of these
111:16 - points and giving us so if we go through
111:19 - the length of the array
111:22 - instead of printing the whole array if
111:24 - you just print the length of your array
111:26 - you can see that's giving 4 6 3 16 4.
111:30 - and i wonder what that is so let's go
111:33 - back and print this image or read this
111:35 - image for us
111:37 - cv to underscore im show
111:39 - and threshold
111:42 - and just rerun this again so you can see
111:44 - that this is a shape and it's giving us
111:47 - four points which probably represents a
111:49 - square
111:50 - and it's giving us six points which is
111:52 - probably representing the hexagon here
111:54 - then three points for the triangle and
111:57 - 16 points for the circle because circle
112:00 - is you need too many points in order to
112:02 - define the circle
112:04 - and the last is again four points and
112:07 - these four points is nothing but the
112:09 - outer image the whole bigger the bigger
112:12 - boundary of the image which it's not
112:14 - visible here since we the background of
112:16 - the code and this thing is all inviting
112:18 - color but that's the outer boundary so
112:20 - it's given by four here so good now you
112:24 - are able to differentiate and you're
112:25 - going to identify okay approximate is
112:28 - able to give us the length of the
112:29 - coordinates
112:30 - not only the length of the quadrant also
112:32 - specify the coordinates of the points
112:34 - that can define your shape
112:37 - so you have approximation and now you're
112:40 - going to say okay if the length of
112:43 - approximations or we can say
112:46 - okay number of points n is equal to
112:49 - length of approximate so if
112:53 - if n is equal to
112:55 - 4
112:57 - then this is a square
113:02 - so you are reading a square so
113:06 - once you have the square written you can
113:08 - draw the contour across the square and
113:12 - you have this function
113:14 - called as
113:15 - cv2
113:17 - draw
113:18 - contours
113:20 - and this contours function can draw a
113:22 - contour of
113:24 - whatever size or whatever shape you want
113:26 - based on the values that you are
113:27 - interested in so draw contours
113:31 - using the for you know on the image
113:33 - called img and we have since we had this
113:36 - image right here the original image img
113:39 - we will draw the contour on this image
113:42 - we'll say img
113:43 - please draw the contour using the
113:46 - contours that we have
113:48 - with inside the cnp function inside this
113:50 - in the
113:51 - variable and once we have this
113:54 - specify
113:55 - what where or whatever the size or shape
113:58 - of the contour is
114:00 - so we'll say zero
114:02 - the contour index and the color which is
114:05 - 255 for our case and then the thickness
114:08 - where we're just specifying what kind of
114:10 - contour image or what kind of a
114:12 - thickness it is but we'll say okay for
114:14 - now we're only detecting the square and
114:17 - drawing the contour across the square
114:19 - and then displaying the image for us so
114:21 - we'll say cv2
114:23 - underscore i am sure
114:25 - img
114:27 - okay we don't need the i am show
114:29 - threshold function we're just interested
114:32 - in the img function and let's run this
114:35 - so you can see that it's now fully black
114:38 - in color and the reason for that purpose
114:41 - is we are not able to
114:44 - read the image
114:46 - we have already converted that into a
114:48 - image here for us
114:50 - and we are also
114:52 - drawing the image
114:54 - with the minus one and this minus one
114:57 - has basically drawn uh it's it's uh
115:00 - filled the whole image with the color
115:03 - that we were interested in
115:06 - and the image the square was the big
115:09 - rectangle the big boundary box of the
115:12 - image and for that purpose it has
115:14 - colored everything
115:16 - into that a black black color or blue
115:18 - color value
115:19 - now if we were to say instead of minus
115:21 - one
115:22 - let's say five let's see what kind of an
115:24 - output we get you can see there's a
115:26 - boundary right here which is almost blue
115:28 - in color and it's specifying that it's a
115:31 - thickness of about five if i were to put
115:34 - 50 maybe
115:36 - let's run this you can see there's a
115:38 - bigger boundary which is much more
115:39 - visible and it's all there's also a
115:42 - boundary right across this right this
115:44 - square box here and you can see that it
115:47 - has a boundary of about blue color right
115:49 - across the
115:51 - square which is green in color
115:54 - and also
115:55 - across the big square of the image
115:58 - now
115:59 - you have the square if we were to say
116:02 - okay instead of the four instead of the
116:03 - square i'm interested in the boundary of
116:05 - the
116:06 - hexagon let's run this
116:08 - and you can see that it's drawn a
116:10 - boundary across the hexagon so we are
116:14 - using the approximate function using the
116:16 - length of the approximate you can
116:18 - identify whether it's a hexagon or a
116:20 - square or whatever it is since we put n
116:24 - is equal to six we'll say it's a
116:26 - hexagon and we'll reduce the thickness
116:29 - of this say to maybe
116:31 - 10
116:33 - and we'll rerun this
116:35 - and it's able to draw our contour across
116:37 - the hexagon and it can also write down
116:41 - that yes
116:42 - print
116:44 - this is a hexagon
116:47 - so this function can now
116:50 - tell us that this is a hexagon now once
116:53 - we have this
116:55 - i will say we
116:57 - have a hexagon
117:00 - here
117:03 - so we have a hexagon here now it's able
117:05 - to decide tell us that this is a hexagon
117:08 - okay good now let's go through all of
117:10 - these so if lf
117:13 - n is equal to
117:16 - we had the triangle which is given by
117:17 - three variables
117:19 - you say okay this is a
117:22 - triangle
117:25 - and we can print triangle okay we found
117:28 - a triangle
117:31 - and we can also draw the triangle by
117:34 - using the contours function
117:37 - and on the same image
117:40 - with the contoured value that we found
117:43 - and here in this case we will use a
117:45 - different color we'll say okay
117:48 - maybe you can specify the contour index
117:51 - and we will use a different color so 0
117:55 - comma
117:56 - 255
117:59 - 2 0 so it'll be a green color contour
118:01 - for a triangle and is there a triangle
118:04 - blue in color yes so we can use a green
118:06 - color rectangle triangle and we'll give
118:08 - a thickness of about maybe three size
118:11 - and let's run this
118:13 - and see if we can see a green color
118:16 - boundary across the triangle so yes
118:19 - there is a boundary of green color right
118:21 - across the triangle which is very good
118:23 - now once you have the image
118:26 - now you're specifying okay so lf
118:30 - if n is anything greater than
118:33 - or n is equal to or nine so that's
118:35 - basically your circle
118:38 - so this is a circle
118:42 - and print
118:44 - we found a
118:46 - circle cv2
118:49 - dot draw contours
118:53 - circle on the img image function
118:57 - using the contours that we are
118:59 - interested in
119:02 - and then you just specifying the index
119:04 - we'll put it as zero
119:05 - no nothing nobody's on that and then the
119:08 - color profiles in this case we will
119:10 - maybe use 255
119:13 - 255 i think this is a pink color let's
119:15 - see what kind of an output we get
119:18 - and let's run this
119:20 - you can see oh it's giving us a yellow
119:22 - color circle boundary right across the
119:24 - circle so you have everything just the
119:28 - square is left so square we will say
119:31 - okay
119:34 - lf n is equal to four which is given by
119:38 - square
119:40 - this is a
119:41 - wire
119:43 - say print
119:45 - e
119:48 - okay good
119:50 - we are also going to draw the function
119:53 - contours
119:55 - img
119:58 - c and d
120:03 - c and d and you specify the index now
120:06 - you're also specifying the color we want
120:09 - we say 255 comma 255 comma 0
120:13 - and a thickness of 3 size
120:17 - let's run this
120:19 - and it's giving the sums of an error
120:21 - because we missed the bracket here
120:24 - instead we put it to here so it should
120:26 - be fine now and yes you can see there is
120:29 - a boundary right here and there is a
120:32 - boundary over here as well
120:34 - so you are specified you are able to
120:36 - differentiate all these colors and it is
120:38 - able to differentiate and see what kind
120:41 - of a shape it is and you can identify
120:43 - what kind of shapes that we are working
120:45 - with in this particular image
120:48 - so the
120:50 - if we do a quick recap on this we did a
120:52 - quite a bit of things in this lesson we
120:55 - looked into the thresholding value so
120:57 - where we can threshold we can filter the
120:59 - image of
121:00 - a grayscale image into whatever color
121:02 - profiles that you are interested in and
121:05 - you can also use the find contours
121:07 - function which can go through the image
121:09 - and find all the different types of
121:11 - contours that are representing the
121:14 - shapes in the image and then using the
121:16 - approximate poly dp you are able to
121:18 - identify the points the approximate
121:21 - points that you need in order to
121:23 - identify in order to draw your contour
121:25 - once again
121:26 - and once you have the contours then you
121:28 - go through all of the
121:30 - length of the approximation and based on
121:32 - the length of the approximation you're
121:34 - identifying what kind of a contour with
121:36 - is it if it's a six
121:38 - you know
121:39 - if it's a six coordinate contour it's a
121:41 - hexagon if it's a three
121:43 - coordinate contour then it's a triangle
121:46 - similarly
121:47 - you can identify it with a circle or
121:49 - square so this is basically helping us
121:51 - to identify the different types of
121:52 - shapes from an opencv from an image
121:55 - processing perspective hello everyone
121:58 - welcome to this part three of the opencv
122:01 - tutorial series here we are going to try
122:03 - and attempt to do a project
122:06 - this is about tracking a ball you can
122:08 - see this video in front of you
122:11 - the ball is moving around and the idea
122:13 - is
122:14 - to track the movement of the ball
122:17 - at any point
122:20 - from a human perspective we know where
122:21 - the ball is moving it's moving right
122:23 - left right in random fashion but how
122:26 - would you do that
122:28 - from a computer vision perspective how
122:30 - would you make a computer understand
122:32 - where the ball is moving so let's get
122:34 - into that
122:36 - so the first thing you want to do is of
122:37 - course import
122:39 - opencv
122:42 - let me make this a little bit
122:44 - big maximized is everything
122:48 - so it's very easy for you to read okay
122:51 - we have
122:52 - import cv2
122:55 - import numpy as nd
122:58 - and from google
123:01 - collab
123:02 - patches
123:04 - import
123:05 - cv to
123:06 - underscore the intel
123:08 - before we do all this let's go ahead and
123:11 - clone the repository if you go into the
123:13 - table of contents
123:15 - and open cv six
123:17 - the first step just above the part one
123:20 - is where the github repository is and we
123:23 - do want to clone this repository
123:26 - this will allow us to access some of the
123:29 - project files that we are going to be
123:31 - using
123:32 - in this particular project so you have
123:34 - the opencv tutorial folder and inside
123:37 - this you will see this videos folder
123:41 - and in this videos folder there's a
123:42 - video file called video.mp4
123:45 - and this is what the file or the
123:48 - ball tracking file is that we'll be
123:51 - using
123:52 - okay let's come back to the table of
123:53 - contents let's go into a project which
123:56 - is the tracking above
123:58 - let's continue our coding so right now
124:00 - we have just imported the libraries that
124:02 - we need
124:04 - the next thing is
124:05 - let's open the video file that we just
124:08 - saw so we can call opencv has this
124:11 - function called video capture
124:14 - which is basically able to read a video
124:17 - file for us so we'll create a capture
124:19 - variable called cap
124:21 - equal to
124:22 - cv2 video capture
124:26 - and this video capture is able to read a
124:29 - video file or even a webcam for that
124:32 - matter if you wanted to read a webcam of
124:34 - course you can't do this on a collab you
124:36 - can do this on your own desktop computer
124:39 - and if you just put down zero
124:41 - it will start reading the default webcam
124:43 - that's connected to your computer
124:45 - but instead of that
124:47 - let's read a video file that we have
124:49 - here in this call app so we have it
124:52 - another folder called videos
124:54 - slash video.mp4
124:58 - so coming back again just to make sure
125:00 - we are under the opencv tutorial folder
125:02 - and inside that there is this videos
125:05 - folder
125:06 - slash
125:07 - video.mp4
125:09 - that's the file that we are going to
125:11 - read through our capture variable this
125:13 - capture variable is capable of reading
125:16 - through every frame of the video file
125:19 - for us and the way we do that is
125:22 - by reading
125:24 - hey capture
125:25 - give me a frame from your video file
125:28 - and cap has this function called
125:32 - read
125:33 - this read function is able to read
125:35 - through the video files and then
125:38 - give out the frame that we want
125:41 - but now a video file is consist of
125:45 - multiple frames it has millions of
125:48 - frames hundreds thousands many frames
125:51 - that are stacked on top of each other
125:54 - then when they play in a sequential
125:56 - format it looks like a video
125:59 - so if we just read it once it'll just
126:01 - give you the first frame if you read
126:03 - again
126:04 - frame equal to cap dot read it will read
126:08 - the second frame similarly if you read
126:11 - it again it'll read the
126:14 - third frame so you have to keep going
126:16 - and throwing and reading through all the
126:18 - video frames that's a very cumbersome
126:21 - format and you really don't know how
126:24 - many frames there are
126:26 - so instead of reading them individually
126:28 - we will read them through a vial
126:31 - and we will open up a while loop will
126:34 - you say hey while loop please start
126:37 - reading the video file for us
126:39 - but you want me to you want to read the
126:42 - video files
126:43 - only and until the videos
126:46 - start
126:48 - or spitting the frame files so it should
126:51 - read only until the videos have enough
126:54 - frames to read and once the video comes
126:57 - to the end of it file you should stop
127:00 - reading otherwise you'll be running in
127:02 - an infinite loop so we'll say file
127:05 - cap
127:06 - is open
127:10 - and this flag is capable of reading
127:13 - whether or not there is something
127:15 - reading through the video file or not
127:19 - and then now we will read the frame
127:22 - we'll say frame
127:24 - equal to
127:25 - cap dot read
127:27 - so it will read through all the frames
127:30 - of this particular read function it will
127:33 - go through all the frames that are
127:34 - available in the video file and then
127:37 - give it in our frame folder
127:39 - now opencv also allows us to do some
127:42 - debugging it allows us to make sure what
127:46 - we read is good or not so it has a flag
127:49 - and we'll call this the red fact flag
127:52 - and this flag is capable of letting us
127:55 - know whether or not there was a frame
127:58 - read or not
127:59 - so if
128:01 - there was a good frame and if a real
128:03 - frame came out of this video file then
128:06 - this red will be equal to true
128:09 - otherwise it will be false
128:11 - stating that no there was no frame red
128:14 - so you don't need to take care of
128:16 - anything the frame is nothing
128:18 - so this red flag helps us also keep a
128:22 - checkpoint stating that a
128:24 - if is there a frame or not and if there
128:26 - is a frame continue with the next of
128:29 - next process of the project but if there
128:31 - is no frame then don't bother
128:33 - so we'll keep a if statement will say if
128:36 - red
128:37 - is false
128:39 - don't bother
128:40 - don't bother the while loop
128:42 - don't bother continuing with the project
128:44 - just break out of it
128:46 - and this is
128:48 - a condition that we will create
128:51 - just reading the red flag this flag is
128:54 - able it's whether or not there was a
128:56 - success or not of whether a frame is red
128:58 - or not that's all we're doing here and
129:01 - this frame is now going to be read
129:03 - through all the frames of the video file
129:06 - and subsequently sequentially it will
129:08 - have all the frames one by one
129:11 - now let's see what we what we should be
129:13 - doing with this frame file
129:17 - this frame file we are interested in
129:19 - identifying the color
129:21 - of the object and we are identifying it
129:24 - we are also interested in identifying
129:26 - where the object is in the video
129:29 - so we lit in the previous projects
129:32 - in the previous lessons we looked into
129:35 - color detection
129:36 - in this color detection we saw how we
129:38 - could
129:39 - detect particular colors
129:42 - like you had the yellow color the green
129:44 - color the red color now we know our ball
129:46 - in this particular video is of yellow
129:48 - color so we can maybe use this
129:51 - particular chord we can create a mask we
129:53 - can do some bit wise and and find the
129:56 - position or where the yellow color is
129:59 - located that's a cool cool thing to look
130:01 - into now coming back
130:04 - we'll use that same system for our
130:06 - current project and we will do some
130:08 - yellow color detection
130:10 - and for that purpose what do we need to
130:12 - do
130:13 - first thing we have to do is convert the
130:15 - color into a hsv image
130:20 - again the reason i'm going through this
130:22 - is because we have already covered this
130:24 - in the previous lessons and if you need
130:26 - you can always go back to the color
130:28 - detection color changing profiles and
130:30 - you will understand what we are doing
130:31 - here
130:32 - so we are now converting it into a hsp
130:34 - image
130:35 - and we use cv2
130:38 - color
130:39 - bgr2hs
130:44 - you bring it here so you can see that
130:47 - it's now converted into a hsv image from
130:50 - a rgb or a bgr image in opencv format to
130:54 - hsv image this hsv is now able to help
130:59 - us detect the yellow color specifically
131:02 - and we saw there was a lower bound and
131:04 - upper bound of u and we will use that
131:07 - here
131:08 - so let's go back to this code and you
131:10 - have the color detection
131:12 - and it's easy to copy and paste the
131:14 - colors that we saw here
131:16 - we have the lower hue and the upper hue
131:19 - and we'll copy this i'll press the ctrl
131:21 - c
131:22 - button and coming back to where we were
131:26 - oops the table of contents we want to go
131:28 - into the project folder
131:31 - and here we will paste what we need here
131:35 - this needs to be a little bit indented
131:37 - so here lower hue is representing the
131:40 - lower bound of the yellow color and the
131:42 - upper hue is representing the upper
131:45 - bound of the yellow color
131:48 - the next step we want to do is create
131:50 - the mask and the mask would be given by
131:53 - using the cv2 in range function so in
131:57 - range is going to look into the image
132:00 - and wherever the hue value lies between
132:02 - these two ranges
132:04 - and the hue saturation and various
132:06 - values lies between this range it will
132:08 - give out
132:09 - all those pixels in a different color so
132:12 - it will highlight those pixels for us
132:14 - particularly so we'll say okay cv2 in
132:17 - range function
132:19 - do your in range magic on my hsv image
132:24 - using the lower heel
132:26 - and the upper hue range that i have
132:30 - created for you
132:32 - so good job you have created the mask
132:35 - you've now identified the yellow color
132:37 - specifically in the video good now what
132:40 - is the next step next step is to
132:42 - identify where
132:44 - this
132:45 - yellow color is residing and for that
132:48 - purpose we used a function called
132:51 - find contours and we did fine contours
132:54 - just in the previous function
132:56 - if we go right here
132:59 - in the previous function where we did
133:01 - draw contours draw contours
133:03 - fine contours
133:05 - so this this is the previous lesson that
133:07 - we covered where we were doing shape
133:08 - detection when we were using fine
133:10 - contours to identify the different
133:12 - shapes that are available different
133:13 - colors and then also draw those contours
133:16 - and we will use some of these functions
133:18 - in our project as well so coming down
133:22 - coming back to the table of contents
133:24 - project
133:26 - coming back to this place so we have the
133:29 - mask
133:30 - and we have now going to create all our
133:34 - contours so the contours function we
133:37 - will create okay
133:38 - contours
133:40 - and on whatever x
133:43 - the contours function is able to give us
133:44 - we're not interested we are only
133:46 - interested
133:47 - in the contours that find contours
133:49 - function is going to help us find
133:51 - so there is a function called cv2
133:54 - find contours
133:57 - contours function is now going to help
133:59 - us in identifying the different contours
134:01 - that are available in the image and this
134:04 - function needs the mask that we just
134:07 - created
134:08 - it also needs some sort of functions
134:11 - that are inter that are going to specify
134:14 - what kind of a contour detection it's
134:17 - going to do so in this case we are going
134:20 - to be using the pre function
134:23 - and we call it as the cvt
134:26 - retr tree this is just understanding
134:29 - these are different types of contour
134:31 - detections and we're just using a
134:33 - specific type for our project it doesn't
134:34 - matter it's it's a simple contour
134:36 - detection that we're doing here
134:38 - and it's not going to affect what type
134:41 - of contour detection you use and this
134:43 - the approximate
134:46 - approx
134:48 - simple
134:50 - so these are different types of filters
134:52 - that are used a different algorithm
134:54 - altogether and we will be just using
134:57 - that to detect our contours once we have
135:00 - the contours detected
135:01 - well good the next thing we want to do
135:04 - is then try to identify these contours
135:07 - are so we'll say okay for now i don't
135:10 - know where the contour is so i'll say
135:12 - that contour has a center point which i
135:15 - don't know and for now i'll put it as
135:17 - just none
135:19 - now if my frame has contours so if my
135:23 - length of contours
135:26 - is greater than zero
135:28 - which means that i have contours in this
135:31 - otherwise it will be zero so if my
135:33 - contours is greater than zero yes
135:36 - let's go about and identify where my
135:39 - contours are located
135:40 - and for that purpose we will first
135:43 - identify
135:44 - which is the maximum the biggest contour
135:47 - in my image
135:48 - and for that purpose we'll say hey c
135:50 - which is the maximum contour
135:52 - use the max function of python to detect
135:55 - which is the biggest contour
135:58 - of all the contours and you can use
136:01 - the key function
136:03 - when for how do you identify which
136:05 - contours are big
136:06 - the biggest you are going to use the cv
136:09 - contour area function
136:11 - the cv2 contour
136:14 - area is able to give a give you out the
136:17 - different types of contours and their
136:19 - areas and it will give out the maximum
136:21 - size of the contour and you can store
136:24 - that under this variable called c
136:27 - once you know which is the biggest
136:29 - contour good now let's find out where
136:32 - this contour is located so we in
136:35 - initially we detected that it's the
136:36 - center of none but now let's try to
136:39 - identify where exactly what is your
136:41 - coordinate
136:43 - so now
136:44 - we can use a tuple called x comma y
136:48 - which is going to be the center
136:50 - coordinate and the radius
136:52 - and
136:53 - opencv has this function called
136:56 - minimum
136:57 - enclosing
137:00 - circle
137:02 - and this minimum enclosing circle can
137:05 - take a contour whatever contour you give
137:07 - and in our case we're going to keep this
137:09 - contour called
137:10 - c
137:11 - and it's going to take that contour and
137:14 - identify what would be that circle
137:18 - what would be that minimum circle that
137:20 - can enclose the whole contour and what
137:24 - the circle is defined is by
137:26 - defined by the center point and the
137:29 - radius that is the circle which will be
137:31 - enclosing this conduit that we have here
137:34 - so now you know where the center is you
137:36 - know where the radius is so very good
137:40 - now we also i want to identify
137:43 - where exactly the moment file is so we
137:47 - have the moments which can be given as
137:50 - m
137:51 - equal to cv to
137:54 - moments so this is another way where you
137:56 - can identify the center of the quad in
137:58 - the contour by using moments moments is
138:01 - nothing but uh specifying where the
138:04 - center of the mass is where the centroid
138:07 - or where the main center of the
138:09 - contour is located
138:11 - and for that purpose we'll use a try
138:13 - function because it's prone to errors
138:15 - and we will say hey try to find the
138:18 - center and i'll say center is equal to
138:22 - there is this
138:23 - formula and it's going to be it's going
138:25 - to sound a little bit confusing here but
138:28 - stick with me what you're just basically
138:31 - identifying is the moments of different
138:34 - types of contours of different location
138:36 - of the different coordinates of the
138:37 - contour
138:38 - and based on that it can identify where
138:41 - the center or where the centroid of that
138:43 - contour is located and that formula is
138:45 - given by
138:47 - int
138:48 - moment
138:53 - and this is an array
138:55 - which is given by 1 0 which is nothing
138:58 - but the corner one corner
139:01 - and then you are also dividing this by
139:05 - moment which is given by
139:10 - m 0 0 so these are two moments which we
139:13 - are just defining and that's the x
139:15 - coordinate
139:16 - similarly the y coordinate is given by
139:19 - in
139:23 - moment
139:27 - and specifying which moment is this the
139:30 - next coordinate
139:32 - and then you're also dividing this by
139:35 - the base
139:36 - which is given by
139:39 - m
139:42 - and you have m
139:44 - 0 0. you're just defining where the
139:46 - center of the coordinate is but once you
139:49 - have the center now you can also
139:52 - identify
139:53 - where to draw these centers so we can
139:56 - draw the center
139:57 - cv2 circle
140:00 - good
140:01 - and your frame you're going to draw on
140:03 - the frame the original frame that we had
140:06 - and we're going to draw using the center
140:09 - of the image
140:10 - good
140:11 - so we have the center
140:13 - and
140:14 - we're going to say okay the radius of
140:16 - this
140:17 - circle is going to be say 10
140:21 - and we are going to give a color of
140:24 - maybe blue color
140:26 - 255 0
140:28 - 0. and we're going to fill this
140:32 - for the thickness
140:35 - thickness is going to be minus 1 which
140:38 - is nothing but
140:39 - specifying that the whole car the whole
140:42 - circle should be filled with this color
140:45 - okay good so now we have drawn the
140:47 - circle
140:48 - now this circle this center is
140:52 - specifying
140:53 - one location one point of the
140:56 - ball now we are interested in
140:58 - identifying all the different types of
141:01 - contours that can be available
141:03 - so uh we want to store the center of
141:06 - this
141:07 - ball at every instance so for that
141:10 - purpose let's define an array an open
141:13 - array will say
141:15 - ball
141:16 - is equal to an open array right now we
141:19 - don't know what this ball is going to
141:20 - have but this ball is supposed to have
141:24 - all the coordinates of the center of the
141:27 - ball at any instant of the video so this
141:30 - ball
141:31 - array is going to host or have
141:34 - the center coordinates of the ball
141:36 - wherever or whenever it is moving in the
141:38 - video so we'll say ball
141:41 - dot
141:42 - append
141:43 - append is just adding to the array
141:48 - append the center which is the
141:50 - coordinate of that ball so you just
141:52 - right now storing storing the location
141:55 - of the center into the ball array
141:59 - so good
142:01 - and
142:02 - if there is an exception
142:04 - go ahead and pass we don't want to
142:06 - bother about it now we have the center
142:08 - of the coordinate we drew the circle at
142:10 - that instance and we are also appending
142:13 - the center which is very good
142:16 - now let's use this ball
142:19 - array
142:20 - to draw
142:21 - the
142:22 - track or the movement of the ball so for
142:25 - that purpose we'll say if the length
142:28 - of ball is greater than 2
142:31 - because the reason i'm saying greater
142:33 - than 2 is because you want to draw a
142:35 - trap a track is nothing but a line
142:38 - and the line can be defined only by two
142:40 - points a minimum of two points so in
142:43 - order to draw a line you need to have at
142:45 - least two points and for that purpose
142:47 - i'm saying i'm asking hey ball are you
142:51 - length of 2 or greater
142:53 - if you're 2 or greater let's go ahead
142:55 - and draw
142:57 - so i'm just going to draw this
142:59 - now
143:00 - for i
143:03 - in range
143:05 - of i
143:10 - in range 1
143:11 - to length of ball
143:15 - so i'm just going to loop through all
143:18 - the elements all the center coordinates
143:20 - of the ball
143:21 - right from zero
143:22 - to the length of the ball
143:25 - and we're going to say
143:27 - let me put the
143:28 - colon here
143:30 - and we'll say draw the line or the track
143:33 - that i'm interested in on the frame
143:36 - using ball's initial coordinate which is
143:38 - the minus one which will be the zeroth
143:42 - or the index zero
143:44 - and the next point which is the ball
143:48 - ball
143:49 - i
143:50 - between these two coordinates between
143:52 - these two center points go ahead and
143:55 - draw
143:55 - the line that i need
143:58 - and give me a color of
144:00 - red i will say zero zero 255
144:04 - and a thickness of say five
144:08 - okay so now you're able to draw a line
144:10 - perfect now this is where
144:13 - we are able to show that yes our opencv
144:16 - project is able to draw not just detect
144:19 - where the circulars but at the all at
144:21 - the same time also draw the line
144:24 - showing where the ball has moved so very
144:27 - good now how do we
144:29 - take this information how do we show it
144:31 - to the end user that we were able to do
144:34 - this
144:34 - since it's a video file if you start
144:37 - displaying it here on cola it'll be a
144:39 - big mess instead of that we will
144:42 - not only we will read this video file
144:45 - but we'll also save it as a video file
144:48 - and opencv allows us to create videos
144:51 - so using a video writer function
144:55 - so we'll call it call a variable like we
144:57 - call the variable capture to read videos
145:00 - we'll call a variable called output or
145:03 - out
145:04 - and we'll say opencv use your video
145:07 - writer function
145:08 - to write a video file for me
145:11 - and for that purpose you're going to
145:13 - create an output avi file
145:18 - and this output api file is going to
145:20 - have the type of the video that we are
145:23 - interested in you're going to store all
145:25 - the new frames that you just created
145:27 - into that
145:29 - so we'll say okay very good i'm going to
145:31 - create this output.avi file but what
145:33 - kind of a video file do you need
145:35 - different types of video files there's
145:38 - the there's different types of
145:39 - compression of video files i should say
145:41 - so there are there is the mg mjpg which
145:44 - is nothing but moving jpeg moving jpg
145:48 - images
145:49 - so we'll use that and there are
145:51 - different other types of compressions
145:53 - and we will use
145:55 - mjp g which is moving jpeg we're going
145:59 - to say cv2 video
146:02 - writer
146:03 - and this
146:05 - 4cc
146:08 - oops for
146:11 - 4 cc
146:13 - this 4cc is nothing but the video codec
146:15 - that we are interested in and in our
146:17 - case we'll say m
146:20 - j
146:23 - b
146:30 - g
146:31 - oops
146:32 - capital g
146:33 - so we have mjpg which is the type of
146:36 - video coded that we are interested in we
146:38 - are also going to specify the number of
146:40 - frames per second in our case it will be
146:42 - 10 and we also need to specify the size
146:45 - of the video
146:46 - and the original video that i had
146:49 - created the video.mp4 that we used that
146:52 - was at a resolution of
146:53 - 1920
146:55 - by
146:56 - 1080 so this create the same video file
146:59 - same size you can use whatever size you
147:02 - want but just so because i'm doing a
147:04 - screen recording if i do something lower
147:06 - it might come out very bad on the screen
147:09 - so i'm saving it as a 1920 by 1080. now
147:13 - this output file
147:16 - oops
147:18 - it's jumping out okay so this output
147:20 - file is able to
147:22 - write whatever frame that you are
147:25 - interested in in this output.avi folder
147:28 - or avi file video file so we have this
147:32 - output function like we use the capture
147:35 - function and we use capture.read to read
147:38 - through all the frames similarly this
147:41 - output function is capable of writing
147:44 - the frames so we can say out dot write
147:48 - frame and this out dot right will just
147:51 - simply write the frame that newly
147:54 - created here
147:55 - into the output.avi file
147:58 - and it will loop through all the frames
148:02 - until this while loop is finished until
148:04 - the red flag saves no more frames
148:07 - available you went through all the
148:09 - frames so you're done now until it does
148:11 - that it will go through and write all
148:14 - the output frames for us and once
148:16 - everything is done it will go ahead and
148:19 - you can release the output file
148:22 - i think this should be indented a little
148:25 - bit on the left side because you're
148:26 - doing it in the if length contour side
148:29 - if you want to do this
148:31 - once it's out of the if statement at the
148:35 - final end of the while loop once you've
148:37 - done all the manipulations that you want
148:39 - to do on the frame and then just simply
148:43 - write the file
148:45 - onto the output.avi
148:48 - good now let's go ahead and run this
148:50 - let's see if we come across any errors
148:54 - and it's taking a few seconds it's
148:56 - running through all the frames for us
149:01 - okay so it seems to have run and we can
149:04 - now open this file and we can see under
149:07 - the videos not only the videos under the
149:09 - output main or opencv tutorial folder
149:12 - you have the output.avi and i can simply
149:16 - click here and press download and it
149:19 - will give you this output for us
149:43 - hello everyone welcome to project number
149:45 - two of our opencv tutorial series here
149:49 - we are going to try to attempt face
149:51 - recognition
149:52 - so for that purpose the first thing you
149:54 - want to do is going to run time and this
149:57 - is the link which will already be there
149:59 - in the description for you just go ahead
150:02 - and click on change run time
150:05 - and you want to make sure you are under
150:07 - gpu and then just save because for this
150:10 - purpose we would be using
150:12 - open
150:13 - the
150:14 - gpu cloud from the collab
150:16 - and i'm going to maximize this a little
150:18 - bit so in order for you to go into the
150:21 - project too if you're going to the
150:22 - contents page and you have projects
150:25 - right here on the part 3 section and we
150:27 - are under
150:29 - paste recognition part
150:30 - so once we are in this section
150:33 - we want to run this particular code here
150:36 - we are basically cloning the repository
150:39 - the face recognition repository and we
150:41 - have some images and some files that we
150:44 - are going to be using for this
150:45 - particular project
150:47 - we are also going to be installing the
150:49 - face recognition api
150:52 - and this was i believe designed by adam
150:55 - gateke that's the name of the person if
150:57 - you just google face recognition
151:00 - i'm just going to google
151:02 - and we'll do adam
151:04 - base
151:05 - recognition
151:07 - so this is considered to be one of the
151:09 - one of the easiest one of the fastest
151:11 - and one of the most accurate face
151:13 - recognition libraries out there and it
151:15 - was developed by this gentleman and we
151:17 - are going to be using it in our project
151:19 - right now
151:20 - so
151:21 - coming down here uh once we run this
151:24 - thing it will go ahead and clone the
151:26 - repository it will also install the face
151:28 - recognition library for us and we are
151:30 - also asking collab to change the
151:33 - directory to face recognition that we
151:36 - can access the files directly
151:39 - so it'll take a few seconds and here in
151:42 - this section now you can see there is a
151:44 - face recognition folder
151:47 - and right here in this section you can
151:50 - see all these files are now available
151:52 - for us to test
151:54 - so this project is basically divided
151:56 - into three steps
151:58 - one is cloning the repository
152:01 - installing all the dependencies that you
152:02 - need for this project
152:04 - the second is encoding finding the
152:07 - encoding profile of the face images
152:10 - the third is using those encoding
152:13 - profiles
152:14 - to now detect unknown faces
152:18 - so we'll go into the basics of each of
152:20 - them and try to understand what it is
152:23 - so basically a face
152:25 - has its own properties a human face the
152:28 - way a person looks is defined by their
152:31 - eyes the shape of the eyes the distance
152:33 - between the eyes the nose the size of
152:35 - the lips the
152:38 - play of placement of the ears compared
152:40 - to the rest of the face so these are all
152:43 - features that define a person's face and
152:46 - encoding is just using those features in
152:49 - order to create a profile for a person
152:52 - and those encoding details are
152:55 - specific to that person
152:57 - so it's not going to be common it's not
152:59 - something which can be replaced with
153:01 - another person's encoding a person's
153:03 - encoding profile is his own his or her
153:06 - own encoding profile and we are going to
153:09 - be using that for our project today
153:12 - so the first thing you want to do is
153:13 - import
153:14 - face recognition library that we
153:16 - installed up there
153:18 - we are also going to be using numpy
153:21 - today
153:22 - numpy as nb
153:23 - and before we go into further details
153:25 - let me maximize this a little bit also
153:28 - move this guy up so it's much more
153:31 - readable for us
153:33 - a little bit more i think okay
153:35 - perfect so import numpy as np
153:38 - we are also be queuing could be using
153:40 - google collapse cv to underscore im sure
153:43 - so that we can display the images here
153:45 - in the collab and for that purpose we
153:47 - will be using google
153:50 - collab
153:51 - patches
153:52 - and from there import cv to
153:55 - underscore im show
153:59 - we might also use of course opencv so
154:02 - don't forget about opencv that's the
154:05 - bread and butter of this project so once
154:07 - we have opencv and all these libraries
154:11 - imported for us we will now go ahead and
154:13 - create the encoding profiles for each
154:16 - face images so if you go into the
154:19 - project folder under the face
154:20 - recognition you can see there are some
154:22 - images like the donald trump image elon
154:25 - musk image earthworld
154:28 - jeff bezos and these are all images of
154:31 - people who we already know
154:33 - and these
154:34 - other set of images right here unknown
154:36 - unknown unknown unknown these are all
154:39 - images that the computer or the program
154:42 - does not know and we will be using these
154:44 - images to use for face recognition in
154:47 - the next step
154:48 - so now for now we will use donald
154:50 - trump's image and elon musk image and
154:54 - jeff bezos image to create the encoding
154:57 - profile
154:59 - so the first step is creating the
155:02 - encoding
155:04 - profiles and for that purpose let's
155:06 - create the encoding profile for face one
155:09 - face number one and let's call this
155:11 - maybe elon musk's face number one and we
155:15 - will call the facebook ignition library
155:18 - up there hey face recognition library
155:21 - please come to our help and we want you
155:23 - to imme load this image file of elon
155:26 - musk
155:28 - i have elon musk in my project folder
155:31 - and it's called
155:32 - elon it does let me come back here it's
155:35 - called elon dot jpeg
155:38 - and you just use elon jpeg
155:41 - to load the image file for us
155:44 - and
155:45 - good good job
155:47 - okay so once face recognition has loaded
155:50 - the image file now we will also request
155:52 - our face recognition library to create
155:55 - the encoding profile for us
155:57 - we will say phase one
156:00 - your encodings
156:02 - are given by
156:04 - face recognition
156:06 - please face recognition library come
156:07 - back again and we need your help this
156:10 - time to create space encodings
156:15 - and codings and for that purpose we will
156:18 - call phase one use the encoding profile
156:21 - from face one
156:24 - and once we have face one you're gonna
156:26 - call okay
156:29 - only use the
156:31 - add a zeroth element of the face one
156:34 - that's now created the encoding profiles
156:37 - of phase one encodings
156:40 - perfect
156:41 - similarly let's create the face encoding
156:43 - profiles for the other gentlemen and for
156:46 - that purpose we'll just copy the code
156:48 - from here and paste it here
156:52 - do another paste here
156:54 - now this one we will call phase two
156:57 - okay paste three
157:00 - base three
157:01 - we will change this to phase two it will
157:04 - change to phase three and instead of
157:07 - elon we might say
157:09 - donald trump
157:12 - and that's the file name donald trump
157:14 - the next is jeff bezos given by this
157:17 - spelling
157:18 - so come back here
157:20 - and instead of this we'll call jeff
157:23 - bezos dot jpg so it has now created the
157:27 - encoding profiles for all the three
157:30 - images let's bring them in an array so
157:33 - that the program can later call them
157:35 - individually so we'll we'll say i will
157:38 - create an array called known face
157:41 - encodings
157:42 - so these are the encodings that the
157:44 - program already knows and we will call
157:47 - them
157:48 - inside an array
157:50 - okay so under this profile we'll call
157:53 - face
157:54 - one encoding
157:57 - comma phase
157:59 - 2
158:00 - encoding
158:02 - comma face
158:04 - 3
158:05 - encoding good
158:07 - so this is my known face
158:09 - encodings now i will also give these
158:12 - encodings names in the same order
158:15 - so we'll say known
158:17 - face
158:19 - names and these are the names of our
158:22 - people who we are training them oops
158:25 - okay come down here
158:26 - so we'll say the first guy
158:29 - is elon musk
158:32 - the second person is donald trump
158:36 - and the third person is
158:40 - jeff
158:41 - pesos
158:42 - okay so we have all the three images we
158:46 - have created the encoding profiles and
158:48 - now we have all the image names also
158:51 - inside an array so whenever this
158:53 - encoding one is called it will refer to
158:56 - elon musk whenever encoding two is
158:58 - called it will refer to donald trump
159:00 - similarly for check pesos so in this
159:02 - section we only created the encoding
159:05 - profiles now coming down to the next
159:07 - section this is creating the run face
159:11 - recognition so we are now going to use
159:13 - those encoding profiles to create and
159:16 - start running the face
159:18 - recognition aspect so let's call let's
159:22 - use one of the unknown images that we
159:24 - have we will probably use unknown el and
159:28 - el is basically the abbreviation for
159:30 - elon musk do is donald trump er is earth
159:33 - rule from here and je is jeff bezos i
159:38 - don't know why i left it as je and you
159:40 - might also
159:41 - notice a spelling mistake here just be
159:44 - mindful of this particular image it's
159:46 - already already an error so
159:49 - i'll try to remove it in the repository
159:51 - later on but for now for the purpose of
159:53 - this video we'll roll with it
159:55 - now the first file name we will call
159:59 - okay let's read the first file and we'll
160:02 - call the
160:04 - elon musk's
160:06 - image which is to one here unknown el
160:09 - dot jpeg
160:10 - and we'll call unknown el
160:13 - camino we're gonna test you and to see
160:16 - your who you are and whose name you
160:19 - carry so you have file name
160:22 - and we'll say this unknown image
160:27 - is right here for us
160:29 - oh it looks like colab doesn't like us
160:32 - to use gpu runtime
160:34 - it's giving us an error but don't worry
160:36 - because very soon we are going to be
160:38 - using your gpu collab and at that point
160:42 - point they won't be so angry with us
160:44 - but let's come down so we are now
160:47 - reading this unknown image of elon musk
160:50 - and we will use
160:52 - face recognition
160:56 - dot load image the same thing that we
160:59 - did here
161:00 - in fact we might copy this whole section
161:02 - from here and we will just
161:04 - load this image that we grow this
161:07 - function we have here
161:08 - so we'll say load image
161:14 - file and we'll use the file name that we
161:17 - created up here
161:20 - perfect
161:22 - now we have unknown
161:25 - image to draw
161:27 - recording calls this image as
161:29 - something that we are going to be using
161:31 - to write down
161:32 - in fact we don't need to draw this image
161:34 - let's call the encoding profile for this
161:37 - guy so we'll say okay where are your
161:40 - face
161:40 - locations and where are your face
161:42 - encodings so you have your face
161:45 - locations which are given by face
161:48 - recognition
161:50 - dot
161:51 - face
161:52 - locations
161:55 - using the unknown image that we have up
161:59 - here
162:04 - now we are also going to be creating the
162:06 - encodings
162:08 - and we'll use the encoding
162:10 - function face
162:11 - encoding so this new image that we just
162:14 - uploaded is going to have
162:16 - face recognitions encoding
162:18 - and face recognition
162:22 - face encoding
162:27 - unknown image
162:32 - and face locations
162:37 - okay
162:38 - so we have now created the encoding for
162:41 - this unknown image
162:43 - very good
162:44 - so let's now try to compare this face
162:47 - encodings with the encodings that we
162:49 - already have here
162:52 - for that purpose we will now use a
162:55 - for loop for
162:57 - and we'll first zip the face locations
163:00 - and the face encodings so we'll do zip
163:04 - face locations
163:07 - and face encodings the reason for that
163:10 - is because we want to compare both of
163:12 - them together
163:14 - so we have face encoding
163:18 - and
163:19 - these face locations and face encodings
163:21 - can be compared to two different formats
163:23 - also so we'll say
163:26 - face locations will give us
163:28 - the top
163:30 - the right
163:32 - so these are the
163:33 - top
163:34 - right bottom and left corners of the
163:37 - face so you have bottom
163:40 - and left
163:41 - so this is referring to the face
163:43 - locations which we will get it from this
163:46 - zip file
163:47 - and we also have the face encoding
163:51 - for individual
163:55 - you have the face encoding and the face
163:58 - locations including this for the
164:00 - individual phases and this is just the
164:02 - array called face encoding so you're
164:04 - reading through each one of them looping
164:06 - through the for loop
164:08 - once you have that now we will try to
164:10 - create a match and we try to compare our
164:13 - face encoding from here to the face
164:16 - encodings that we already know
164:18 - from here
164:20 - so let's go ahead
164:22 - do that for us
164:23 - we'll say matches and matches is equal
164:26 - to the comparison between the face
164:29 - encoding of this new image versus the
164:31 - face encoding of the images that we know
164:34 - already
164:36 - come here
164:38 - face
164:39 - recognition
164:41 - dot com here and this is
164:44 - space
164:45 - function
164:46 - so it's going to compare the faces
164:49 - from our known face encodings
164:56 - and the face encoding that we have here
165:00 - perfect
165:02 - now initially we will call our face your
165:06 - unknown phase
165:08 - as unknown unknown i don't know
165:11 - initially we call it as unknown because
165:13 - later on once the program is able to
165:16 - identify or recognize whose face it is
165:18 - it should automatically replace this
165:21 - name with one of the names that we have
165:23 - here
165:25 - okay coming back
165:27 - now we are trying to compare the
165:28 - distances
165:30 - from the comparison that we created here
165:32 - and say face distances
165:35 - which is equal to face
165:38 - recognition
165:39 - dot phase
165:41 - distance
165:45 - known
165:46 - space
165:47 - encoding
165:50 - comma phase encoding
165:52 - now here we're just creating again
165:55 - that distance and then now we'll drive
165:58 - using this distance we will try to now
166:00 - identify which one is the best for
166:02 - ourselves coming down here
166:04 - we'll say
166:05 - the best match index
166:08 - now this is the index of these three
166:11 - images so this is zero one
166:13 - two so you're just identifying which
166:15 - index items
166:18 - we will say
166:19 - it is given by the
166:21 - numpy
166:23 - of minimum distance
166:25 - between the face distances so all the
166:28 - phase differences
166:30 - but it's identifying all the phase
166:31 - differences and now it will give us the
166:34 - least face distance
166:36 - we'll say okay the least face distance
166:39 - from the face distances array
166:42 - will be my best match index
166:45 - okay perfect now if matches best
166:49 - match index is available give me the
166:52 - name
166:53 - of our
166:55 - known face names
166:57 - so we'll call you just call this known
166:59 - face names and we'll say the best match
167:03 - index is your new name
167:06 - so this is basically the space
167:08 - recognition aspect so you're first
167:10 - identifying the phase distances and from
167:13 - the phase distances you will come to
167:15 - know which is the minimum which is the
167:17 - least distance between the original
167:19 - phase and the unknown phase
167:21 - that distance will be considered as our
167:24 - will come to know our index and we will
167:26 - use the matches that we use here
167:29 - to then call
167:31 - that particular face name and we'll use
167:33 - our known face names array to iron to
167:36 - get the name of the real person
167:39 - once we have the name of the person now
167:41 - we can go ahead and draw the bounding
167:44 - box on the face and also put the text so
167:48 - we as the user can identify who this is
167:52 - so you we will use opencv's draw
167:55 - functions which is the rectangle and the
167:57 - put text function to put down the text
168:00 - in the bonding box on our image
168:03 - we'll say cv2 rectangle
168:08 - unknown and you're drawing it on the
168:10 - unknown face here the unknown image in
168:13 - fact let's read the unknown image that
168:16 - we have here
168:18 - we're reading it through the file name
168:19 - we will also read it through opencv
168:22 - we'll say unknown
168:24 - image to draw
168:26 - and this function that we will use
168:28 - cv2
168:32 - file name
168:35 - here we are reading it in the opencv
168:37 - format so opencv we can use this image
168:40 - to draw our rectangle
168:43 - open cv here
168:45 - come here
168:46 - put it down here
168:47 - once we have the opencv image you can
168:50 - draw the rectangles and the rectangles
168:51 - are defined by the bottom left or the
168:54 - top right corner so we say left
168:57 - top
168:59 - right bottom
169:02 - perfect so now you're defining the color
169:06 - you'll say green color 0 to 55 0 and a
169:11 - thickness of 3 it will take care of the
169:13 - drawing of the rectangle for us
169:15 - similarly we'll now draw the
169:18 - write the text of the person that we
169:20 - know
169:21 - we'll use the unknown image to draw
169:24 - here and we'll write the name whatever
169:28 - name that we want to put by using this
169:30 - name string
169:31 - we'll say name
169:34 - and we will say let's write it on the
169:36 - top left corner of the
169:38 - rectangle which is given by left
169:42 - top but we will give it a little bit of
169:45 - indent on the top so we'll say minus 20
169:48 - it's just above the top left corner of
169:51 - the image
169:53 - and opencv has certain fonts that we can
169:55 - use so we'll use the basic font which is
169:58 - the font hershey simplex one zero
170:02 - color we'll give it as maybe red color
170:04 - and we will use the thickness of two
170:07 - and the line format of
170:09 - double a
170:10 - cv2 line
170:12 - underscore
170:14 - this will just simply write the text for
170:16 - us
170:17 - once everything is done
170:19 - once the for loop is also completed we
170:21 - will ask our collab to please go ahead
170:24 - and display this unknown image to draw
170:27 - that we just created here
170:30 - so once we have this thing opencv should
170:32 - go ahead and run this so we'll go ahead
170:35 - and run this
170:37 - and it looks like there is an error here
170:40 - the error says invalid syntax
170:43 - and it is probably because we did not
170:46 - say where are we getting this from so we
170:49 - should say face encoding top right
170:51 - bottom
170:53 - in
170:54 - z
170:56 - we have to say in
170:58 - zip and that should take care of our
171:00 - error
171:01 - looks like there is still an error and
171:03 - they are not happy because
171:05 - we put down too many rectangles at most
171:08 - six arguments and it looks like we gave
171:10 - them eight arguments
171:13 - how come do we have the unknown image oh
171:15 - did we say rectangle instead of
171:18 - rectangle we should have put put text
171:21 - because we're putting up a text here
171:24 - and that should take care of our thing
171:26 - so we can now see that it is able to
171:28 - detect
171:29 - the person and it's also able to put the
171:32 - bounding box on it and if you go ahead
171:34 - and open this folder and open the
171:37 - unknown el folder here
171:39 - you can see the original image
171:43 - is right
171:44 - here and this is the
171:48 - face recognition image so let's try some
171:51 - other image we have a couple of other
171:53 - options
171:54 - we'll open the unknown which is
171:56 - basically donald trump's image and we'll
171:58 - see if the file is able to detect it for
172:00 - us
172:01 - we will say unknown do here so it can
172:04 - read this new image
172:07 - and it's able to draw
172:08 - the bounding box on donald trump's face
172:11 - this is able to do the face recognition
172:13 - aspect and you can see it's pretty fast
172:14 - it's able to do it almost in real time
172:17 - now this is something which is done in
172:19 - collab now if you want to do the same
172:21 - thing on a
172:22 - desktop or through a webcam the same
172:24 - thing can be applied where we are
172:26 - reading a file name instead of that you
172:27 - will be supplying it through a webcam
172:30 - and you can use a file a while loop
172:33 - a true while loop which would
172:34 - continuously loop through all the images
172:37 - of the webcam and then pass this as a
172:39 - function this whole code right here can
172:41 - be made as a function
172:43 - we will say okay
172:47 - def
172:48 - and you can say function some function
172:51 - and you can pass the image that we want
172:53 - and instead of this image we'll say file
172:55 - name so we can then replace this file
172:57 - name with here
172:59 - just uncomment this instead of taking it
173:02 - from here we just call this as a
173:03 - function you bring everything in this
173:06 - as part of it as part of this particular
173:08 - desk function
173:10 - so we'll say okay you're part of this
173:12 - dev function and once we have it here we
173:15 - can now instead of show displaying it
173:17 - here on the browser for ourselves we can
173:19 - then return this variable
173:22 - and that will go to go back to the
173:24 - desktop where who's that while loop
173:27 - who's calling
173:28 - the images to return
173:31 - go back and
173:34 - undo our changes
173:35 - because that is something which we
173:37 - cannot do here in cola
173:39 - but
173:40 - just an idea if in case you are
173:42 - interested