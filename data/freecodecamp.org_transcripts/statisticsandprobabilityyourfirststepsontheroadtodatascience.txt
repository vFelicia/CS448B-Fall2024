00:11 - all right
00:12 - welcome everybody my name is joe merlo
00:15 - we're going to go through real quick
00:16 - some of the install instructions and
00:18 - then we'll get through and start doing
00:20 - some
00:21 - expectation management those kinds of
00:23 - things
00:25 - most of you have probably done the
00:26 - install instructions already so i'm just
00:28 - going to cover those briefly a couple
00:30 - tools we want to have on our systems i
00:33 - tend to prefer using
00:34 - a tool called conda to help me do
00:37 - package management
00:39 - some specific libraries that we're going
00:40 - to install we'll walk through those
00:42 - we'll go through how we test for
00:44 - installation and talk a little bit about
00:46 - why we're doing things with this way
00:48 - [Music]
00:50 - one of the things that i often recommend
00:51 - read all the steps ahead of time get a
00:53 - sense that you understand what the steps
00:55 - mean some steps may say install thus and
00:58 - turns out you already have it installed
00:59 - so you may not have to do that
01:03 - for this tutorial i highly recommend
01:05 - using cond as a package manager because
01:07 - there are some libraries that are kind
01:09 - of sucked into this process that are not
01:11 - necessarily python libraries so some
01:13 - python package managers may not be real
01:15 - good for this
01:18 - conda has a virtual environment manager
01:20 - to help manage your virtual environments
01:22 - we'll talk a bit about what that means
01:25 - the material for this has been tested
01:26 - using conda but it has not been tested
01:28 - with pip it has not been tested with
01:30 - virtual and etc
01:32 - if you already have conda installed you
01:35 - can test that by typing conda on the
01:37 - command line and if you get something
01:39 - back that says usage conda
01:42 - you're good
01:43 - if not the instruction should walk you
01:45 - through it
01:46 - for this course material we're using
01:48 - python version 3 dot x
01:51 - when you say python equals three and one
01:53 - of the commands we'll do in a minute
01:54 - it'll give you the latest version of
01:56 - python
01:57 - um
01:59 - from my experience the most common
02:01 - problem that i see when people start to
02:03 - do this
02:04 - is they they miss a step right our eyes
02:06 - tend to glaze over and we miss things so
02:09 - if you have a problem uh
02:12 - scroll back check to see if you've done
02:13 - all the things if not we have a set of
02:16 - mentors in the room uh and myself we can
02:19 - walk around and help you especially
02:20 - during the part where we do exercises
02:22 - all right
02:24 - there are a set of instructions for
02:25 - doing this in windows and mac and linux
02:30 - you can confirm whether conda's been
02:31 - installed
02:32 - by doing conda or condoles
02:46 - this is high tech guys
02:49 - all right
02:53 - next
02:55 - all right so let's talk a little bit
02:56 - about what we're doing when we're
02:57 - installing python and some of the other
02:58 - things you're going to make a directory
03:00 - called stats you're going to change into
03:02 - that directory so now you're inside that
03:04 - folder
03:05 - and we're going to create a virtual
03:07 - environment
03:08 - at the bottom of this material i have
03:09 - kind of a write-up as to why virtual
03:11 - environments are important and how they
03:12 - can be useful to you and i'll leave that
03:14 - up to you to read it but the the big
03:16 - picture for virtual environments and why
03:17 - you might want to use one is that it
03:20 - creates a sandbox
03:21 - some of you have python already
03:23 - installed in your computers and you
03:24 - maybe use it for work and you don't want
03:26 - to corrupt or mess up your existing
03:28 - version of python or your existing
03:29 - libraries that use with python so the
03:31 - virtual environment makes a sandbox what
03:33 - we do goes in the sandbox and it doesn't
03:35 - interfere with anything that happens
03:37 - right
03:39 - once we've made a virtual environment we
03:41 - have to activate it and if you've
03:43 - activated a virtual environment you're
03:44 - going to see these little parenthetical
03:46 - off to the side to say you're now using
03:49 - that virtual environment and now using
03:50 - the version of python that you installed
03:52 - for that environment
03:54 - and then next we can say conda install
03:57 - and you can tell it all the libraries
03:59 - that you would like to use in this case
04:01 - we have five main libraries that we
04:03 - intend to explore
04:05 - all right
04:06 - once you've installed those
04:08 - we'll type jupyter space lab
04:11 - and hopefully a lab environment will
04:13 - open up if you do not have one let us
04:16 - know and we'll get you get you taken
04:18 - care of
04:19 - you kind of raise your hand i'm going to
04:20 - pass out some stickies as well in a
04:22 - little bit
04:23 - all right
04:24 - next we have class material it is up on
04:26 - github
04:28 - i'll put the links back up for those in
04:30 - a second you guys can go look for that
04:33 - all right
04:35 - as we go through the process you'll see
04:37 - these green post-it notes in the
04:38 - material
04:39 - all the stuff i want you to do
04:41 - basically stops there if you want to
04:43 - keep reading you can go ahead but
04:45 - you can typically stop wherever a green
04:46 - post-it note is
04:48 - for those who really want to know more
04:49 - details about all of these things
04:52 - at the bottom of this lesson i have a
04:54 - big picture description of why we use
04:55 - virtual environments what is conda doing
04:57 - why are we using it and all that stuff
04:59 - and so you can scroll through and read
05:01 - all of all of that content at your
05:03 - leisure we're not going to go into it
05:05 - all right
05:07 - so with that in
05:08 - mind all right
05:11 - i'm going to walk you through a little
05:13 - bit about kind of how this class itself
05:15 - is going to play out and the types of
05:17 - things that we want to do
05:19 - all right
05:21 - first off i appreciate
05:23 - pycon
05:25 - my family friends who suffered through
05:27 - me trying to get this material ready
05:29 - my company that helps to get me here
05:31 - booz allen hamilton
05:33 - the pycon tutorial selection committee
05:35 - the mentors who are here in the room who
05:37 - are going to be helping you guys and
05:38 - especially you for being willing to come
05:40 - out and go through this statistics and
05:43 - probability exploration with me
05:46 - to give you an idea of what to expect
05:48 - and what not to expect right
05:50 - we'll do an overview of some probability
05:52 - and statistics print
05:54 - so it's a tough word right it's hard
05:56 - english is tough um we're going to do an
05:58 - overview of probability and statistics
06:00 - principles and techniques
06:02 - we will have some snippets of python
06:04 - code i'm going to warn you right now the
06:06 - code that chalmer wrote for here should
06:09 - never be used
06:10 - in a production environment
06:13 - the things that i wrote are more to demo
06:15 - principles to give you an idea of how
06:17 - things work kind of under the hood they
06:18 - are not for true statistical analysis
06:21 - and i'll prove it i'll show you why
06:23 - there's going to be plenty of
06:24 - opportunities for you to level up your
06:26 - skills we'll have exercises that you
06:28 - guys can walk through and we'll give you
06:29 - a certain amount of time in this
06:31 - tutorial to work on those myself and the
06:33 - mentors will help you
06:36 - i will highlight a few of the gotchas to
06:38 - look out for things that you might be uh
06:41 - experiencing as you go through this
06:42 - journey on your own when you get back to
06:44 - your house etc
06:46 - and we're going to provide some
06:46 - resources to help you continue your
06:49 - learning journey when you go home what
06:50 - are some good books to read or were some
06:52 - good things to look at et cetera
06:54 - so what not to expect
06:56 - if you think this through a typical
06:58 - college class is about 40 some odd hours
07:02 - of sitting in a lecture hall
07:04 - lots of homework in between sitting in
07:06 - lecture halls
07:07 - we have three and a half hours and if we
07:09 - bring biology and taking breaks and
07:11 - stuff into this story we have about
07:13 - three hours
07:14 - right
07:15 - so you're not going to get
07:17 - a whole lot out of this my hope though
07:20 - is that
07:21 - you will get
07:23 - a flavor and that flavor will drive you
07:25 - to go home and keep learning
07:27 - um you are not going to get out of
07:28 - chalmer robust industrialized code we
07:31 - spoke about that
07:32 - and in terms of deep dives we're not
07:34 - going to have the time so some folks may
07:36 - ask some questions like hey i want to
07:37 - know a little bit more about these types
07:39 - of distributions and how these are
07:40 - related to that we're probably not going
07:42 - to have the time for a lot of that
07:45 - we could have maybe conversations about
07:47 - that outside of this i really want to
07:48 - give you guys this nice high level
07:51 - overview
07:52 - in terms of logistics
07:56 - pair practice is used in some tutorials
07:59 - because working closely with a partner
08:01 - helps you kind of identify what's going
08:02 - wrong and helping each other out i'm not
08:04 - going to force that upon anyone
08:06 - if you want to work with someone who
08:08 - sits next to you and say hey why don't
08:09 - we work on the code together or why
08:10 - don't we work through these exercises as
08:12 - a pair i'll leave that up to you and
08:14 - your level of comfort
08:16 - we're going to distribute out some
08:18 - post-it notes for you when you get to
08:20 - the end of a period of exercises you put
08:22 - your post-it note at the top of your
08:24 - monitor so i can look out when i see a
08:25 - sea of green i know it's time to kind of
08:28 - move on
08:29 - if you run into a problem you'll have a
08:31 - red post-it note that will hand out to
08:33 - you you put it on your monitor myself or
08:35 - the mentors will look out and go oh red
08:37 - post it red post it and we'll come to
08:39 - you right so you don't have to do this
08:40 - whole embarrassing hey i got a problem
08:41 - thing
08:42 - um there will be a survey and i'll get
08:44 - you the link to that later i really want
08:46 - to get your feedback okay
08:48 - so how do we get the most out of this
08:50 - experience
08:51 - um i love this picture and let me zoom
08:54 - down so you can kind of see it
08:56 - the top and i apologize it's a small
08:57 - font it says how do you actually learn
08:59 - any new programming concept
09:01 - by changing stuff and seeing what
09:03 - happens
09:04 - one of the cool things about python
09:07 - is that you can try something run it and
09:10 - see what happens you go wow that was
09:12 - cool let me change this number or let me
09:14 - do this thing and you run it again and
09:16 - you get an instantaneous kind of
09:18 - response
09:19 - so i heavily encourage you play with
09:22 - things when you do an exercise and you
09:23 - get done a little early try and go back
09:25 - and do it again tweak something
09:29 - you're gonna have questions that might
09:30 - come up like hey
09:31 - chalmer what if or what will happen if
09:33 - we do this
09:35 - and i love to hear those questions those
09:37 - are great
09:39 - i will caveat that though with i also
09:41 - love to see folks have that question in
09:44 - their head and they go try it themselves
09:46 - because sure i can demo it for you but
09:49 - man how much fun and excitement it is to
09:51 - try it and see some cool response
09:54 - some people say well i don't want to
09:56 - break anything i don't want to do it
09:57 - wrong
09:58 - and that's a legit fear so i'm not going
10:00 - to minimize that
10:01 - but generally with python you're not
10:03 - really going to break much
10:04 - and if you do you can kind of reboot
10:07 - and often if you do quote unquote break
10:09 - a thing there's going to be some error
10:11 - message and you're going to skim it and
10:12 - maybe it's confusing but you're going to
10:14 - see new words new terms and you're going
10:16 - to start to learn things because those
10:17 - error messages as scary as they might
10:20 - look will often teach you things
10:22 - especially when you see them over and
10:23 - over again so
10:25 - try not to be scared
10:28 - there's a couple other things in here
10:29 - and i'm not going to go through them in
10:30 - the interest of time but
10:32 - they're there and they talk about the
10:34 - psychology of learning stuff
10:37 - but this quote here is kind of neat
10:40 - being a programmer basically requires
10:42 - you to deal with these extended periods
10:43 - of feeling like a complete
10:46 - punctuated by very brief periods of
10:48 - feeling like a genius right
10:50 - um
10:51 - that's my life every day i'm standing up
10:54 - here trying to teach you guys a thing
10:55 - but most of my life is i don't know how
10:58 - to get my code to do this thing and i
10:59 - don't know why and then all of a sudden
11:01 - it works
11:02 - and i feel like that guy on the titanic
11:05 - no
11:06 - right and i feel great and then my boss
11:09 - is like we'll solve this other problem
11:10 - now that that's done
11:12 - okay so let's get rolling
11:15 - let's talk about statistics
11:18 - all right so this is kind of the the
11:20 - main meat of the thing
11:21 - um i'm going to disappear behind the
11:23 - podium and grab those post-its and have
11:24 - one of my colleagues pass them around
11:27 - all right
11:28 - and then i'll come back
11:33 - i'm still here
11:36 - voila
11:37 - all right
11:38 - everybody gets one green one red
11:40 - not one pad one green post-it one red
11:43 - posted
11:44 - you don't know what he's going to do
11:46 - all right
11:48 - so let's get started this first
11:50 - conversation is going to talk about
11:52 - statistics right
11:54 - and what we can do with that and then a
11:56 - little later on we're going to move into
11:57 - probability okay
11:59 - um
12:00 - our main goal right now for this first
12:03 - little bit
12:04 - is to understand you know some
12:06 - techniques for counting things
12:08 - determining what the minimum value is
12:10 - maybe in a data set figure out what the
12:12 - maximum value is
12:14 - and then we will look at these things
12:16 - that we call central tendencies
12:18 - that the fast version is what's the
12:20 - average and we'll explore different ways
12:21 - to look at at that
12:23 - and then we will talk about well how
12:26 - widely does stuff kind of deviate from
12:28 - that average is my data really spread
12:30 - out or not okay
12:34 - let me try and blow this up a little bit
12:35 - maybe okay
12:37 - um
12:38 - we're going to look at the data and
12:39 - we're going to look at these techniques
12:40 - and these processes through a couple
12:42 - different tools we're going to start off
12:43 - with some simple data sets just a couple
12:46 - numbers so we can kind of visually see
12:47 - what the thing is
12:49 - we will then go through a little bit
12:50 - larger data set a little more
12:52 - sophisticated
12:53 - we're going to have some hand developed
12:55 - code that's chalmers
12:57 - do not use this in production code
13:00 - and then i'm going to walk you through a
13:01 - couple of standard libraries that have
13:03 - some functions that do what my code does
13:06 - but does it way better all right
13:09 - to kind of get us in the right frame of
13:11 - mind
13:12 - i'm going to use a
13:14 - i'm going to use that big data set that
13:15 - i mentioned we'll look at it and we'll
13:18 - display it on the screen in a graph
13:20 - and then we're going to use tools to
13:21 - kind of
13:22 - figure out what some of those data
13:24 - points are
13:25 - okay by hand as it were
13:27 - all right
13:28 - so let's pretend i'm a manufacturing
13:30 - plant and you know every day i produce a
13:33 - new batch of stuff
13:35 - on some days my machinery is well tuned
13:38 - and the number of batches that i produce
13:40 - or the batch that i produce has very few
13:43 - defects in it
13:45 - but other days my machinery is starting
13:47 - to fall apart things are breaking and
13:49 - all of a sudden i get larger quantities
13:51 - of defects so i may want to track these
13:53 - on a day-to-day basis
13:54 - all right so i have this data and it is
13:57 - this number of defects
13:59 - i purposely kind of organized it so it's
14:01 - kind of bigger numbers at the top
14:03 - smaller numbers at the bottom they're
14:04 - not quite sorted but
14:06 - so we see some things like there's a 99
14:08 - there's a 52 there's a 42.
14:11 - uh
14:12 - at the bottom we have some twos and
14:14 - threes and fours i don't know there's
14:16 - like 208 or some some odd numbers we'll
14:18 - figure that out
14:21 - i will warn you we're not going to do a
14:22 - deep dive into matplotlib i'm going to
14:24 - gloss over this real quick
14:26 - i just wanted to give you a graph but
14:29 - i use matplotlib here to import
14:32 - some capabilities that will enable me to
14:35 - make a very basic plot
14:37 - i also have a tool called the counter
14:40 - tool and we'll talk a bit about it in a
14:41 - minute
14:42 - that's going to help me count things
14:45 - and now i want to make a simple
14:46 - histogram a simple graph
14:49 - what we're going to do is try and start
14:51 - off by making this display and we're
14:53 - going to use a tool called most common
14:56 - which is found in the counter object and
14:58 - you'll see how that works out
15:00 - all right so
15:02 - i start off by taking all of those
15:05 - values that i had number of defects
15:08 - and i drop it into my counter object and
15:10 - that's going to produce a thing that
15:11 - looks like a dictionary but it's not
15:12 - quite
15:13 - and so i call it defect counts
15:16 - and then i say all right
15:19 - show me the five most common values that
15:21 - occurred in
15:23 - all of my number of defects so we run
15:25 - that code
15:26 - and so the number 8 showed up 24 times
15:29 - the number 6 showed up 24 times
15:32 - and the number 7 showed up 18.
15:34 - all right
15:35 - i mentioned that counters look a little
15:37 - bit like dictionaries
15:39 - there's two nuances that you should know
15:41 - they have this kind of extra method that
15:42 - we just saw called most common
15:45 - that allows us to find out what are the
15:46 - most common things and i can tell that i
15:48 - want to see the two most common items
15:51 - and it'll give me that or i can say i
15:52 - want to see the five most common items
15:54 - it'll give me more
15:56 - right
15:57 - but
15:58 - one other nuance that is fun is that if
16:00 - you've ever played with a dictionary and
16:02 - you try and
16:06 - access a value that doesn't access a key
16:08 - that doesn't exist your dictionary will
16:11 - vomit on you and it throws up this
16:12 - little error and says hey you tried to
16:14 - look at something that doesn't exist
16:16 - counters are cool that they don't do
16:18 - that
16:19 - if i try to access the number 77 which
16:22 - is not
16:23 - in my defect count
16:25 - it goes that's fine and it just gives me
16:27 - back a zero
16:29 - if i try and access a number that does
16:31 - exist like an eight it'll look into the
16:33 - counter and go oh there's a 24 stored
16:35 - there and it'll give me back at 24.
16:37 - so this is kind of cool and we'll take
16:39 - advantage of that particular
16:41 - functionality in a second
16:43 - all right so i want to create a list of
16:45 - x values to go on the bottom of my chart
16:47 - and i want to see
16:49 - all of those y values that are in my
16:52 - defect count
16:54 - the 8 or the 24 and the 24 and those
16:56 - things
16:58 - and i want to store them in two separate
17:00 - lists so i can dump them into matplotlib
17:03 - so
17:04 - for those who haven't seen it this is a
17:06 - list comprehension syntax i'm not going
17:08 - to go into it but
17:11 - it's very useful for doing analysis
17:14 - i'm not going to talk about these these
17:16 - are all just the things that we use for
17:17 - matplotlib and it's going to take all of
17:20 - the x values
17:21 - that we just made and all of the y
17:23 - values that we made and it's going to
17:25 - plot them all right
17:26 - and so we get
17:29 - this nice little chart
17:32 - and a couple things that we can see
17:33 - right off the bat
17:34 - where are most of the things
17:40 - low end right
17:43 - there appear to be two little spikes
17:45 - do you guys remember what numbers those
17:47 - spikes were at what were the most common
17:49 - values
17:52 - six and eight
17:54 - right
17:55 - um when we looked at the data and i said
17:57 - hey i got this stuff kind of organized
17:59 - there was a big number at the front it
18:01 - was a 99 and sure enough we see there's
18:03 - a little spike over there by the 99
18:05 - turns out maybe that's an outlier
18:07 - maybe not right
18:09 - okay
18:11 - so this visually shows us a lot of cool
18:13 - things i want to figure out how do we
18:15 - get to some of these data points using
18:16 - code
18:20 - we'll start off with
18:22 - using count maximum and minimum
18:26 - what function do we use to count things
18:27 - in python
18:30 - len right stands for length
18:33 - so if i have number of defects and i
18:35 - drop it into the len function
18:38 - it will tell me that i have 204 data
18:40 - points and you can essentially count
18:41 - just about anything in python using len
18:44 - all right if i want to find the biggest
18:46 - value in a set or the smallest value set
18:48 - what what functions do i use
18:51 - max and min all right so let's do that
18:54 - let's take number defects we'll drop it
18:56 - into max drop it into min
18:58 - and we get that big value of 99 and our
19:01 - smallest value happen to be a two
19:03 - sweet
19:04 - all right
19:09 - a lot of statistics is basically telling
19:12 - you stuff about your data
19:15 - how many pieces of data do i have
19:17 - what is the highest thing what's the
19:19 - smallest thing
19:22 - one of the things that we often talk
19:24 - about like what's the average grade in a
19:25 - class or what's the average weight of
19:27 - people in doing this thing right what's
19:30 - the average of age of folks in a
19:31 - particular group
19:33 - python has tools to to look at that
19:36 - and when statisticians look at that kind
19:39 - of information they typically point to
19:41 - three main things
19:43 - mean median and mode
19:46 - mean is also often referred to as
19:48 - average and it's probably the one you're
19:50 - most commonly associated with
19:52 - so i'm going to walk you through how we
19:53 - can calculate means medians and modes
19:55 - using my lousy code
19:58 - all right
19:59 - so here we'll start off with calculating
20:01 - a mean
20:02 - if i drop a series of values into this
20:04 - particular function
20:05 - it will try and figure out a
20:08 - what is all of the a values added
20:10 - together and then it will divide it by
20:12 - how many values do we have
20:14 - okay
20:15 - so do that
20:17 - and
20:18 - so let's just use a really simple set of
20:20 - values these four things the average
20:22 - should be like two and a half
20:24 - if my math is right and if i do this one
20:27 - the average should be three right pretty
20:29 - straightforward
20:32 - anyone want to take a guess what the
20:33 - average is for
20:35 - our bigger data set
20:38 - any thoughts
20:43 - wow
20:46 - that's amazing well done
20:49 - all right
20:53 - all right
20:55 - now
20:56 - i'll show you in a little bit some other
20:57 - libraries that walk you through doing
20:59 - means and we'll talk about some of the
21:00 - benefits of using those all right but
21:02 - now i basically have an idea of kind of
21:06 - where is
21:07 - the average number and it's somewhere in
21:09 - here between 9 and 10. okay
21:12 - now let's go look at medians
21:15 - so median is a little interesting
21:17 - uh the point of medians is to find the
21:21 - center-most value
21:23 - if i've got 11 things it'll find
21:25 - whatever's at position six if i've got
21:27 - five things it'll find whatever is at
21:29 - position three right
21:30 - it doesn't really care if it's big
21:32 - little tiny whatever it just says you've
21:34 - got this number of things let me find
21:36 - whatever's stored in the center
21:39 - all right but there's a caveat
21:41 - if i have an odd number of things like 1
21:44 - 3 and 5 the 3 is clearly in the middle
21:47 - but if i have 1 3 5 and 7 what's in the
21:51 - middle
21:52 - and how we typically solve this is we
21:54 - take an average of whatever the two
21:55 - things are in the center and so my code
21:57 - will do that
22:01 - the nuance here is before you find
22:04 - whatever's in the middle you need to
22:05 - sort them so we're going to sort all the
22:07 - values we'll calculate how many values
22:10 - we have we'll figure out what is the
22:12 - midpoint
22:13 - and then we will return it if we find
22:17 - out that there are an even number of
22:18 - values we're going to do this thing
22:20 - where we
22:23 - we average we find out there's an odd
22:25 - number of values we just give you the
22:26 - center point
22:28 - all right so i'm not going to walk you
22:29 - through the code in too much detail you
22:31 - can take time to look at that if you
22:32 - want but let's just see if it works sure
22:34 - enough it gives me a 2.
22:36 - this one remember we have to sort first
22:39 - so it's going to move the 42 to the end
22:43 - and it'll find whatever's between the 5
22:45 - and 6 which is a 5.5
22:47 - all right
22:48 - and
22:50 - i know this guy's already done the math
22:52 - in his head right he knows what the
22:54 - number of median number defects it's an
22:56 - 8.
22:57 - okay
22:59 - so we can take an average which you're
23:01 - used to we can take the median find the
23:03 - middle most point
23:04 - mode
23:05 - finds whatever shows up most frequently
23:09 - all right
23:10 - for this library i'm also going to use
23:12 - counter to help us with this
23:14 - we're going to count all the values
23:16 - we will find whatever value shows up
23:19 - most frequently
23:21 - how many times it shows up
23:23 - and then we will go in using another
23:25 - list comprehension and if you're not
23:27 - familiar with these i highly recommend
23:28 - you go figure them out because they're
23:30 - really awesome
23:31 - we'll go and say all right the maximum
23:33 - number of things was 24 things showed up
23:35 - let's go see how many items showed up 24
23:38 - times and this list comprehension will
23:40 - give me every value that had 24 entries
23:43 - in my count
23:44 - so let's go take a look
23:46 - here
23:47 - the number four is going to show up
23:49 - three times so it will show up most
23:50 - frequently so we should get back a four
23:53 - um notice
23:55 - just a nuance here
23:56 - with mode i choosing to return a list of
23:59 - uh of items
24:02 - because sometimes
24:04 - certain things more than one thing may
24:05 - show up most frequently like this list
24:08 - one shows up three times five shows up
24:11 - three times so i want to get both of
24:12 - those back
24:14 - so it's going to return a list with both
24:16 - of the things that showed up most
24:17 - frequently
24:19 - the one and the five
24:21 - um
24:22 - just a nuance about that right
24:25 - we talk about kind of the average
24:27 - most the time in our heads we tend to
24:29 - think of there is only a single average
24:31 - when you start talking mode you can have
24:33 - bimodal or trimodal data sets where
24:36 - spikes of things occur
24:38 - there's a book that uh that i kind of
24:40 - like for folks who are new to statistics
24:43 - head first statistics and they talk
24:45 - about this ages for this group of folks
24:48 - in this class
24:49 - and it's a class for adults and children
24:52 - to do like swimming together or
24:54 - something i don't know
24:55 - and when you look at the ages the
24:57 - average ages you have these very young
24:59 - children and you have these older adults
25:02 - and so your average age is very
25:03 - different and it's split
25:05 - right so that's the thing that you'll
25:07 - see in many cases with mode
25:09 - all right so let's go look at the
25:11 - most frequent values in number of
25:13 - defects it was 8 and 6 just like we saw
25:15 - earlier
25:16 - all right
25:17 - so a couple of nuances of when we might
25:19 - use these and and some of the the
25:21 - benefits of using them i've got a little
25:23 - table here
25:24 - mean
25:25 - you do this sum of the values and you
25:27 - count how many values you have you do
25:28 - the math
25:30 - this is
25:32 - most commonly used when your data kind
25:34 - of has
25:35 - symmetry to it and it has a single trend
25:38 - one single spike
25:40 - the median is often used with data that
25:42 - might be skewed a little bit to one side
25:45 - or the other and might have some
25:47 - outliers it's kind of a way of of
25:49 - dealing with the fact that your outliers
25:51 - will throw off some of your results
25:54 - and then mode it's different from some
25:57 - of the others because you can actually
25:58 - use mode with things that are called
25:59 - categorical data and you'll hear that in
26:01 - statistics what categorical data means
26:04 - is it doesn't have a number value
26:06 - like if i had a list of data and the
26:08 - data just simply said
26:10 - male female or the data said you know
26:14 - part a part b part a part a part b part
26:17 - b those are all categories right and so
26:20 - modes can show us what is the most
26:21 - frequent part that showed up
26:23 - what is the most frequent
26:26 - examples of things and you don't have to
26:27 - have a number for them so categorical
26:29 - data can be done with modes
26:31 - and it's also good for things as we
26:33 - mentioned that have more than one trend
26:36 - all right
26:39 - we did a fancy histogram graph but
26:42 - sometimes just having a quick frequency
26:43 - table can be really useful
26:45 - and so a frequency table would be
26:48 - something like this
26:50 - where it shows hey the value 9 showed up
26:52 - 3 times the value 6 showed up twice
26:55 - it's much like that counter example we
26:56 - looked at
26:58 - if we look at
27:00 - our defect counts
27:04 - the frequency table is not specific to
27:06 - mode it is the counts of all your values
27:09 - mode is highlighting the things that
27:11 - show up most frequently the frequency
27:13 - table shows up the values of all of them
27:15 - notice
27:16 - where did it go
27:18 - in my frequency table it showed up that
27:19 - eight appeared only once where mode is
27:22 - going to show me the things that
27:23 - appeared most frequently mode would give
27:24 - me the value 9 showed up three times
27:27 - or would give me the value 8 and 6
27:29 - showed up 24 times does that help
27:32 - good
27:33 - all right
27:36 - so what i'd like you guys to do and i'm
27:37 - going to
27:38 - shrink this down
27:39 - give you guys a few moments to kind of
27:41 - start to wrap your head around some of
27:42 - these things
27:43 - um
27:44 - i'd like for you to calculate and you
27:46 - can use my functions if you'd like
27:47 - they're good enough for government work
27:49 - here
27:50 - and go through this calculate the mean
27:52 - the mode the median
27:54 - do a count on these things
27:55 - and go through the exercises and we'll
27:57 - give you guys a few minutes to do this
28:01 - i want to caveat this for just a moment
28:03 - though some people may not finish all
28:05 - the exercises in the time allotted
28:07 - that's totally fine
28:08 - go home re-read the material do the
28:10 - exercises again finish the exercises you
28:13 - didn't finish that's all good
28:16 - just a little back story here right
28:19 - and i'll show you my list of books that
28:21 - i've read i've read the statistics books
28:24 - of various sorts
28:25 - over and over again
28:27 - and even in the course of preparing this
28:29 - particular
28:30 - set of material
28:33 - last night in my hotel putting final
28:34 - touches on i was still picking up
28:36 - nuances that i had not seen before and
28:38 - still learning new facts and details
28:40 - that had kind of escaped me so there's a
28:42 - lot to cover as we get further on in
28:44 - this in this conversation so don't hand
28:46 - if you're like oh man i didn't get all
28:47 - of it i didn't capture it yeah i still
28:49 - go back and reread some of these books
28:50 - and catch nuances so all right
28:53 - um we'll give you guys probably about 10
28:54 - minutes or so
28:56 - and we'll wander around and ask answer
28:58 - questions
29:42 - uh
30:00 - again if you guys run into any snags
30:13 - is
31:10 - sure
31:11 - so
31:12 - when you have
31:14 - just one heavy
31:38 - some of your things
33:17 - notes
33:46 - all
33:50 - desiring right
37:14 - so i think it's been about 10 minutes
37:23 - all right
37:24 - the little microphone appears to be back
37:27 - all right
37:28 - i'm not going to do the entire exercise
37:29 - i'm just going to highlight one or two
37:31 - things
37:34 - so mean
37:36 - let's see grab some of these guys
37:40 - and
37:42 - say values
37:44 - right
37:45 - and this was a nuance that i think jeff
37:47 - had mentioned
37:52 - right
37:53 - if
37:54 - you have two commands in a single cell
37:58 - both of the commands will run but only
37:59 - the last command will display to the
38:02 - screen
38:03 - so if you wanted to
38:06 - have both of these display you have two
38:08 - options you could either put each of
38:09 - them mean and median in two separate
38:11 - cells that works fine that works fine
38:15 - or
38:16 - you can do some of that extra typing
38:18 - and you can put the word print in here
38:21 - for the first one
38:23 - and
38:24 - it will print
38:26 - and you can put median values
38:28 - so it will print the first one and then
38:30 - it will execute the second one
38:33 - notice we get a slightly different
38:35 - output
38:36 - print actually displays to the screen
38:39 - median values actually executes and is
38:43 - released as an output but that's a
38:45 - nuance
38:46 - all right
38:48 - so let's see
38:49 - let's talk about
38:51 - measures of dispersion
38:53 - how widely spread is your data is your
38:55 - data really tightly clustered or is your
38:57 - data just all over the map
39:00 - okay
39:01 - you will sometimes hear in statistical
39:03 - books about things like measures of
39:04 - variability how much does the data vary
39:06 - or measures of spread they all
39:08 - essentially mean the same thing
39:11 - a fast and dirty measure of
39:14 - spread is simply let's look at the
39:16 - minimum look at the max and see how far
39:18 - apart they are
39:19 - right and so that's what this does my
39:21 - data range function just says what's the
39:23 - max what's the min
39:24 - and divide or subtract one from the
39:27 - other and so with my little data set
39:29 - five three four two and one the smallest
39:32 - thing was a one the biggest thing was a
39:34 - five and the spread is four points
39:39 - notice with my batch defects the
39:42 - smallest value was a two the biggest was
39:43 - a 99 so my spread is 97. that's a lot
39:48 - remember that 99 is potentially even an
39:49 - outlier or something so here i can see
39:52 - that my data is really far away from the
39:54 - median and the mode and the mean right
39:57 - so this may be a flag or maybe something
39:59 - of interest
40:01 - it will depend on your data
40:04 - all right
40:05 - a couple of the downsides though of
40:06 - using simple spread are the fact that
40:09 - they are very susceptible to outliers
40:11 - here i have two data sets that are
40:12 - almost identical except for the last two
40:14 - values the 8 and the 99 you would
40:16 - probably say these these data sets are
40:18 - are pretty much the same
40:20 - and so when i have this one thing with
40:22 - this minor outlier man it throws
40:24 - everything completely out of whack
40:26 - and it makes it really hard for me to
40:28 - realize or to know that essentially
40:31 - these data sets are basically the same
40:34 - all right so how do we get past that
40:37 - that's where things called quantiles
40:40 - and interquartile ranges come into play
40:44 - let me zoom in on this just to smidge
40:46 - all right
40:47 - so you're going to hear some of these
40:48 - words
40:50 - these are the words that that really
40:51 - bothered me i never knew what they meant
40:52 - for a long time
40:53 - um
40:56 - a quantile
40:58 - is
40:58 - it's a cut point or a dividing point
41:00 - right in a sequence of values
41:04 - and those cut points will break those
41:05 - values up into what we call contiguous
41:08 - intervals or
41:09 - intervals that butt right up against
41:11 - each other so they have a nice
41:13 - continuous flow
41:14 - and
41:15 - those cut points are de defined
41:18 - essentially
41:19 - so that they break up all of your values
41:21 - into equal probabilities the stuff in
41:24 - this lower quantile has as much
41:26 - probability as appearing as the stuff in
41:27 - the middle et cetera et cetera
41:30 - quartiles
41:31 - are values that cut your data into
41:33 - quarters they are essentially a quantile
41:35 - that breaks things up into every 25
41:37 - percent
41:39 - an interquartile range
41:41 - is a range between
41:43 - your
41:44 - lower quartile and your upper quartile
41:46 - normally that's between 25 and 75
41:50 - although you might see them with
41:51 - different values
41:52 - all right so let's put this into
41:53 - practice and see what we got
41:55 - all right quantiles
41:57 - so again these are kind of these cut
41:58 - points
41:59 - um if i have six values and i've got a
42:01 - cut point in the middle
42:03 - it breaks my values into two sections
42:06 - that middle in our case would be the
42:08 - median
42:10 - if i have a lot more values i have a
42:13 - value 1 and 62 63 and 64 65 and 70. this
42:18 - breaks up my range of values into 10
42:20 - quantiles
42:22 - and potentially if i want to kind of
42:23 - weed out some of those outliers i could
42:26 - say i really only care about all the
42:27 - things that fit between this lower
42:30 - quantile and this upper quantile
42:33 - and so i kind of filter out whatever's
42:35 - on on each end and that gets rid of the
42:37 - one it gets rid of the 99
42:41 - all right so let's make a function that
42:42 - helps us calculate where a given
42:44 - quantile falls
42:48 - so i make this very simple function
42:50 - give it a handful of values
42:54 - and tell it where you'd like your your
42:55 - quantile to break
42:57 - and it will then figure out in a list of
43:00 - values or sequence of values where does
43:02 - that fall
43:03 - what is the index of that point and it
43:05 - allows you to get back a value from your
43:08 - list or your sequence
43:09 - again this is not robust code do not
43:11 - ever qualify this or use this in
43:13 - production but it's good enough for for
43:15 - what we need to do here
43:17 - all right so i've got a list of like
43:19 - school grades there's 10 values and i
43:21 - say hey i want to find
43:23 - the break point whatever is in the
43:25 - middle essentially
43:27 - trying to find a almost a median
43:29 - it sorts everything first
43:32 - 55 ends up at the bottom 96 at the top
43:35 - and then it roots through
43:37 - i'm going to caveat this right
43:39 - this code was not sophisticated enough
43:41 - to realize that if i have even numbers i
43:44 - should take an average between the two
43:45 - this is again just to give you guys a
43:47 - demo
43:49 - if i had
43:50 - an odd number of values 11 in this case
43:56 - we can use that as well but again it's
43:58 - not going to be very precise
44:00 - all right
44:02 - what if i want to find those quartiles
44:04 - the 25 value and the 75 value i take
44:08 - these grades and i say hey look for
44:10 - whatever grade is closest to 25
44:13 - of this sequence of values
44:16 - and give me whatever is closest to 75
44:19 - and so 67 is kind of the lower lower
44:21 - bound of the lower 25 percent of my
44:24 - students and 91 is kind of the upper
44:26 - bound of the
44:27 - upper 25 percent of my students
44:30 - now
44:34 - all
44:34 - right if i want to kind of see where my
44:38 - defects break out using a variety of
44:40 - percentiles
44:41 - like the lower 10 percent the lower
44:43 - quarter the upper quarter 90 95 and 99
44:48 - i can do that
44:49 - and so
44:50 - the value of 4 is right at the boundary
44:53 - of the lower 10 percent value of 6 is at
44:55 - the boundary of the lower 25
44:59 - we notice that value of 99
45:01 - is way above
45:03 - the 95 percentile
45:05 - okay
45:06 - so if i were to say i only want to see
45:08 - stuff between the 25 and 75 i filter out
45:11 - all the lower end stuff i filter out all
45:13 - the high-end stuff and this is a great
45:15 - way to kind of
45:16 - get a sense of what the middle of the
45:18 - pack looks like
45:19 - so let's do that
45:21 - we'll apply what we just created to to
45:24 - look at some interquartile ranges um
45:26 - commonly you'll see like 10 and 90 20
45:28 - and 80.
45:30 - depends on what you need
45:33 - in our case
45:34 - we'll have a lower quartile boundary an
45:36 - upper quartile boundary
45:38 - and
45:41 - i tell it hey here's the values we're
45:42 - going to give
45:43 - it's going to use my function quantile
45:45 - for a minute ago and say
45:47 - 75 is my default value 25 is my not
45:50 - default or my lower boundary
45:52 - and let's see how this works
45:55 - it says chalmer if you give me these 10
45:57 - values
45:58 - 3 is roughly around 25 percent of the
46:00 - way up and eight is roughly 75 percent
46:03 - of the way up
46:04 - all right
46:10 - if i want to then do that math and say
46:13 - how big a spread is this i just subtract
46:15 - one of them from the other
46:17 - and we see that
46:19 - 8 minus 3 is 5.
46:22 - so let's do that with my batch of
46:23 - defects
46:25 - and it says hey chalmer if i'm only
46:27 - looking at 25
46:28 - and 75
46:30 - your range of values was only six
46:33 - it's only a spread of six
46:35 - right
46:37 - now that function i created seems a
46:39 - little weak because it's built in it
46:41 - hardwired in 75 and 25.
46:44 - so let's
46:46 - build upon our function a little bit and
46:48 - let's give ourselves the option now
46:50 - of adding an upper bound of our own
46:52 - choosing in the lower bound of our own
46:54 - choosing okay
46:56 - and so i'm going to look at my number of
46:57 - defects but this time i want to look at
46:59 - everything from 10 percent all the way
47:01 - up to 90 percent i'm going to see how
47:03 - big a spread that is
47:05 - and here that spread is a little bit
47:07 - bigger a little bit wider all right
47:12 - so what are the downsides of using an
47:13 - interquartile range it seems like hey i
47:15 - can kind of filter out those those
47:17 - outliers that's good
47:21 - interquartile ranges
47:23 - they only tell you really the difference
47:25 - between a high value and a low value
47:31 - how far apart are they
47:32 - they don't really tell you how closely
47:35 - they
47:35 - are knit to things
47:37 - it doesn't tell you how frequently those
47:39 - high values occur or how frequently the
47:41 - low values occur
47:42 - versus how frequently the stuff in the
47:44 - middle occurs
47:46 - so we would theoretically want a method
47:48 - to more accurately measure variability
47:49 - and we'll look at that in a minute so
47:51 - we'll give you guys a break
47:53 - if people need to walk around stretch
47:54 - whatever you can do that as well
47:57 - spend a couple minutes here
47:59 - say five
48:01 - walk through calculating a simple spread
48:03 - calculating some quantiles
48:05 - and then calculate an inner quantile
48:07 - range for these numbers
48:08 - and of course i'll ask questions or i'll
48:10 - answer questions
48:11 - one nuance for this second one you guys
48:13 - should pay attention here
48:16 - we're going to use the range function to
48:19 - create a sequence of values from 200 all
48:21 - the way up to
48:22 - but not including 300. so if you've
48:24 - never used the range object to create a
48:26 - sequence of numbers for you
48:28 - we have that here this is how you would
48:30 - do it
48:31 - all right
48:33 - and we'll cut you loose
48:35 - when you're done put up your little
48:36 - green stickies if your green sticky is
48:38 - still up take it down
56:58 - all right
56:59 - let's get started
57:07 - awesome
57:08 - all right folks
57:26 - so if i want to bang out an
57:27 - inter-quartile range for
57:32 - all these guys i can say range
57:35 - 200
57:37 - to 300
57:39 - with a step of 5
57:42 - for those who are not familiar with the
57:43 - range function
57:45 - the second value that you put
57:47 - range will go all the way up to it but
57:48 - it will not include that value
57:51 - and this third number you can give the
57:53 - range function tells you what step to
57:54 - take
57:55 - and let's see to calculate my
57:57 - interquartile range i want a
57:59 - 0.25
58:02 - and a 0.75
58:04 - but those are the defaults
58:07 - so heck with it
58:09 - let's delete that and we should get back
58:11 - a 50.
58:13 - and that sounds about right because
58:14 - there's about 100 difference between the
58:16 - two
58:17 - all right
58:18 - so let's talk about something way more
58:19 - fun
58:21 - let's talk about variances in standard
58:22 - deviation
58:24 - all right
58:25 - so there's a couple of different
58:26 - techniques that we can use to evaluate
58:28 - the spread of data that's a bit more
58:30 - effective than simple interquartile
58:31 - ranges or simple spreads
58:34 - interquartile ranges is good for fast
58:36 - and dirty it's very nice but variance
58:38 - and standard deviation are
58:40 - one of the the workhorses for
58:42 - statistical evaluation um
58:45 - one thing that you may be tempted to say
58:47 - is well if i want to get kind of figure
58:49 - out how much things vary i could take
58:51 - the average of
58:52 - you know what is
58:56 - i take the average and i could subtract
58:57 - that from each of my values and i get
58:59 - this average difference from the mean
59:02 - and that may look like it'll work
59:04 - but what ends up happening is all of the
59:06 - things that are above your mean and all
59:08 - things that below your mean cancel out
59:10 - i'll let you guys read the details we're
59:11 - just going to skip right by that
59:13 - let's talk more about variances okay
59:16 - um
59:18 - with a variance we do something very
59:20 - similar
59:21 - we have
59:23 - an average
59:25 - and then we subtract
59:27 - the first value from the average the
59:29 - second value from the average the third
59:30 - value from the average
59:32 - and we square that
59:34 - to get some sequence of numbers
59:37 - the benefit of squaring which doesn't
59:40 - happen in that previous
59:42 - thing that i skimmed over is that these
59:44 - all end up being positive numbers now
59:46 - they can't cancel each other out because
59:48 - some are positive and some are negative
59:50 - and so in this case i have these three
59:52 - numbers
59:53 - one two and nine
59:55 - the average is a four
59:56 - i calculate what's called the variance
59:58 - and i get this number 38
60:01 - and that gives me some sense of
60:05 - how much or gives me a total 38 and then
60:07 - i divide it by 3 sorry math is hard i
60:10 - divide by 3 and i get a 12.6 so it gives
60:13 - me some sense of what the variance is
60:16 - and you may look in your head and you go
60:17 - i don't even understand what variance
60:19 - means because
60:20 - how did i get a 12.6 to tell me how much
60:23 - stuff spreads
60:25 - when my numbers don't even get up to 12.
60:29 - i have a one two and a nine and you're
60:30 - going to tell me quote unquote the
60:31 - variance is this 12.6 thing
60:35 - and so some of you are sitting there and
60:36 - you have this quizzical look on your
60:37 - face and that's the same critical look
60:39 - that everybody has which is why we go
60:42 - one step further we use a thing called
60:43 - standard deviation
60:46 - before i talk about standard deviation
60:48 - the nuance here though that you can get
60:50 - is if i were to change
60:53 - these numbers
60:54 - and spread them out a little further
60:56 - potentially my variance may get bigger
60:59 - my variance gets smaller so if i have
61:01 - two sets of data and one variance is
61:03 - large one variance is small
61:05 - the one with a larger variance is spread
61:08 - out more the one with the smaller
61:09 - variance is spread out less
61:11 - so the number itself may not jump out at
61:13 - you and you go that means something
61:15 - but numbers or variances from separate
61:18 - data sets can give you a sense of one
61:20 - spreads out more than the other
61:22 - but again variance is kind of this
61:24 - nuanced thing like people like i don't
61:25 - even know what that means
61:27 - so
61:28 - we'll we'll do a function we'll look at
61:29 - this happening and working and then
61:31 - we'll move on to standard deviations
61:33 - all right
61:34 - so
61:35 - i calculate
61:37 - this by using
61:39 - the total number of values i have a
61:41 - function that calculates the difference
61:43 - between the means i square them i will
61:45 - let you guys do this again this is not
61:47 - production code this is chalmers sitting
61:49 - in a hotel room
61:50 - um all right
61:53 - well let's try and detect or determine
61:55 - what the number the variance is for our
61:56 - number of defects and we need some
61:58 - bizarre number
62:00 - our variance is 80 and again that means
62:02 - nothing to me right i don't have a sense
62:04 - for what that means
62:08 - because no one gets a sense some folks
62:10 - thought this through and they're like
62:12 - is there maybe a better way and standard
62:14 - deviation is a potentially better way
62:16 - and i'll show you some examples of why
62:18 - to get the standard deviation you
62:19 - calculate the variance and then all you
62:21 - do is you take the square root of it
62:23 - it's pretty straightforward
62:25 - so i calculate the variance
62:28 - same way i get 38 divide that by the
62:31 - total number of items i get a 12.6 and i
62:34 - take the square root of that and i get
62:35 - 3.55
62:37 - and again you kind of may be saying in
62:38 - your head i don't understand what that
62:39 - means
62:41 - the nuance is that as your standard
62:43 - deviation gets bigger
62:44 - it means it spreads more as it gets
62:46 - smaller it spreads less but
62:49 - we'll see some graphs related to this
62:50 - later that standard deviation
62:53 - fits very nicely on your graphs in a way
62:55 - that helps you to get a good sense of
62:57 - how things play out
62:59 - all right
63:04 - when we use data sets and we calculate a
63:06 - standard deviation
63:11 - one thing that they have found is that
63:13 - on a typical kind of bell-shaped
63:15 - distribution a normal distribution
63:17 - and a lot of data tends to fall into
63:19 - that category
63:20 - if i calculate the standard deviation
63:23 - kind of how wide is the spread away from
63:25 - the mean
63:27 - 65 percent of all of my values are going
63:30 - to be within one standard deviation of
63:32 - my mean
63:33 - 95 percent of all my values are going to
63:35 - be within two standard deviations
63:37 - and 99 will be within three standard
63:40 - deviations so let me shrink this down
63:42 - just a smidge
63:43 - so we can see this all on the screen
63:45 - there all right
63:47 - so
63:48 - i have an average i have a mean in the
63:50 - middle i've got some sort of bell
63:52 - shapish curve
63:54 - and if i can calculate my standard
63:56 - deviation
63:57 - right here
63:58 - standard deviation
64:00 - above the mean and one standard
64:01 - deviation below the mean everything in
64:03 - this gap is going to be 65 of all of my
64:06 - numbers
64:07 - will fall right there in that that
64:09 - middle zone
64:11 - if i stretch out two standard deviations
64:13 - above the mean and two standard
64:14 - deviations below the mean
64:16 - 95 of every one of my numbers is going
64:19 - to fit nicely in that little that little
64:21 - grouping
64:22 - and
64:23 - if i calculate out three standard
64:24 - deviations 99 of stuff say well how do i
64:27 - use this what does this mean
64:29 - well much like we use the interquartile
64:31 - range to say let's drop all the values
64:33 - that are 25 percent or below all the
64:35 - values that are 75 or below or above
64:38 - we can use standard deviations to say i
64:41 - only want to see
64:43 - the 99 of the values that are closest to
64:45 - the mean and any of these little
64:46 - outliers that are way out there in the
64:48 - far corners let's ditch those
64:51 - or i really want to get kind of a little
64:53 - closer and i want to see 95 of my values
64:56 - that are closest to the mean and so
64:58 - standard deviations can help us
65:01 - grab those when we're using something
65:03 - like a normal distribution
65:04 - this may not apply with other
65:06 - distributions but it works quite nicely
65:07 - with normal distributions these
65:09 - bell-shaped curves
65:10 - all right
65:14 - let's see
65:16 - this first picture kind of spiky
65:19 - the data is fairly closely clustered on
65:21 - the average
65:23 - this next picture a little less spiky
65:28 - it's a little wider
65:30 - and in this case because the graph is a
65:32 - little less spiky
65:34 - my standard deviation happens to be
65:35 - bigger
65:36 - and so remember i mentioned that like if
65:38 - you're looking at two different data
65:39 - sets and a standard deviation is bigger
65:41 - it means that data set spreads out more
65:44 - and so because this spreads out more my
65:46 - standard deviation is bigger but the
65:48 - same rule applies even though this
65:49 - spreads out more if i want to get 99 of
65:52 - all my numbers and drop off the one
65:54 - percent outliers i measure out three
65:57 - standard deviations and boom i've got
65:59 - the 99 that i care about
66:02 - okay
66:04 - all right so i've got a fairly
66:06 - straightforward
66:08 - and let me make sure i ran the variance
66:10 - formula earlier
66:12 - let's see
66:15 - so i got a fairly straightforward
66:17 - standard deviation calculation here
66:20 - it uses my variance function that i
66:22 - created earlier
66:24 - does the math
66:26 - i have a fairly narrow data set all the
66:29 - stuff's pretty close together the mean
66:31 - is five we have another one that's a
66:33 - little bit broader it goes from one to
66:35 - nine but the mean is also still five
66:39 - and so let's look at how these two
66:41 - things calculate out
66:43 - the mean is five
66:45 - my standard deviation was 1.4
66:48 - this is a little bit broader data set
66:50 - still has the same average but my
66:52 - standard deviation is a bit bigger so
66:54 - now i can immediately go this one is a
66:57 - flatter bell than this one potentially
66:59 - right
67:01 - all things being equal
67:04 - okay
67:06 - how do you interpret that
67:09 - what does it mean
67:11 - all right
67:13 - the nuance here essentially is that
67:18 - when you're looking at your data and you
67:20 - want to kind of know
67:22 - i have an average
67:24 - how much does stuff spread out on one
67:26 - side or the other or both the standard
67:28 - deviation is going to
67:30 - point you in the right direction to say
67:32 - this is really close to the mean
67:34 - or these are very far from the mean
67:38 - and so in this case
67:40 - you know my numbers start at three they
67:42 - go to seven they're all really tightly
67:44 - clustered around the mean this one
67:46 - starts at one it goes up to nine they're
67:48 - spread further out i can immediately
67:50 - tell that there's a bigger spread
67:51 - between two data sets
67:53 - just looking at one data set and knowing
67:55 - that okay the standard deviation is 1.4
67:58 - may not tell me a lot about that one
67:59 - data set
68:02 - but being able to compare them is really
68:04 - useful
68:06 - another thing you know as that number
68:08 - gets smaller and smaller it means your
68:09 - your
68:10 - your spike is a little spikier right
68:12 - things are narrower things are closer
68:16 - uh
68:17 - and a key role for the standard
68:19 - deviation again is kind of helping you
68:21 - figure out how do i get rid of some of
68:22 - those outliers
68:24 - how do i look at my data set and say i
68:26 - only want to see the stuff that's
68:29 - from like one percent all the way up to
68:31 - 99 and not look at the things outside of
68:33 - it or
68:35 - where should my cut points be to look at
68:37 - just the 95 percent where should my cut
68:39 - points be look at just 65 percent of the
68:41 - data
68:42 - and so standard deviation can help you
68:43 - with that
68:45 - all right
68:47 - did that help
68:49 - good
68:54 - let's talk about how real pythonistas
68:57 - calculate standard deviations and
68:58 - variances and those types of things
69:00 - using real python libraries instead of
69:02 - my
69:03 - hotel code
69:05 - okay
69:06 - we're going to look quickly at four
69:07 - different libraries
69:09 - and
69:10 - i will highlight a gotcha
69:14 - that may strike if you do not pay
69:16 - attention and if you don't kind of dive
69:17 - into the nuts and bolts so the four
69:20 - libraries we're going to look at there
69:21 - is a statistics library this is brand
69:23 - new in python as a version 3.4
69:27 - it incorporates a sequence of
69:29 - statistical functions
69:32 - and it comes with python so if you
69:34 - download python all by itself you've got
69:35 - it you don't need to get any third-party
69:37 - libraries which is quite nice
69:40 - we'll look at numpy
69:41 - numpy allows you to build
69:44 - these array objects and allows you to do
69:47 - various fist calculations on these types
69:49 - of objects that are very fast
69:53 - as techniques and tools for integrating
69:54 - c and c plus plus libraries and fortran
69:57 - code again to get closer to the bare
69:59 - metal and make your code more efficient
70:00 - and more
70:02 - faster
70:03 - it has techniques to be able to
70:05 - broadcast
70:09 - calculations and evaluations against
70:11 - large arrays of data
70:13 - without having to write for loops and
70:15 - stuff
70:17 - and it's useful for like linear algebra
70:18 - and those types of things
70:21 - scipy library
70:23 - has a collection of mathematical
70:25 - algorithms it's got some convenience
70:26 - functions that are built on top of numpy
70:28 - because it uses numpy under the hood
70:30 - adds a lot of power to your python
70:32 - sessions
70:34 - and then we'll look at pandas which is a
70:35 - common data science
70:37 - library does data analysis and those
70:39 - types of things all right
70:42 - so we'll start off by importing each of
70:44 - these
70:45 - for some of these libraries it's fairly
70:46 - common to import them with an alias like
70:48 - import numpy as np it makes it easier to
70:51 - type some of the commands you might want
70:53 - to use later
70:54 - all right
70:56 - i'm going to start off by creating a
70:57 - simple numpy array
70:59 - and we're going to use my defects batch
71:02 - file okay
71:03 - [Music]
71:05 - one of the things that i often mentioned
71:07 - to students
71:08 - who are using a new tool a new library
71:10 - and they're making new data types
71:13 - i often recommend to them that they do a
71:15 - couple of things
71:17 - when you make a new object often tell
71:18 - them
71:19 - go find out what the heck this thing is
71:21 - that you just made
71:22 - and so i say hey what is defects
71:25 - and it says hey chalmer defects is a
71:27 - numpy array
71:29 - and
71:31 - if i've never used a numpy array i maybe
71:34 - need to figure out what that means if it
71:36 - spat out and said hey chalmer you just
71:37 - made a list i'm pretty familiar with
71:39 - lists
71:40 - because this is a numpy array and i
71:42 - don't really know a lot about what numpy
71:44 - rays right
71:45 - i might want to try and get a sense of
71:47 - what types of functions or methods are
71:49 - available to me so we're going to use a
71:51 - technique called tab completion
71:53 - and this is really useful in jupiter
71:54 - notebooks
71:56 - i type out defects i put a dot
71:58 - and i hit tab
71:59 - and it brings up this list of all the
72:01 - types of methods and functions that are
72:03 - available to me
72:05 - all right
72:06 - there we go
72:08 - nothing like moving your laptop in the
72:10 - middle of a talk
72:12 - okay
72:13 - um
72:14 - notice this is in alphabetical order
72:16 - right so it says things like all and any
72:18 - and da da da and there now we're going
72:20 - to the b's and the c's and the d's and
72:24 - this is a huge list of things
72:26 - that you if you are mathematically and
72:28 - statistically minded can do with a numpy
72:30 - array you can't do these with lists etc
72:33 - um we are not going to go into the
72:35 - depths of this i'm just going to kind of
72:36 - scroll through
72:38 - get a sense there's a lot of things here
72:41 - notice they do have a method in here
72:43 - called std
72:45 - short for standard deviation
72:47 - they have a method called var which is
72:49 - standard for vary or short for variance
72:51 - all right
72:54 - i'm going to start off simple and i'm
72:55 - going to say hey let's use the mean
72:56 - function
72:57 - and so we'll calculate mean
72:59 - and sure enough the average is 9.96 as
73:01 - this fine gentleman mentioned earlier
73:06 - a wheel caveat there is no median
73:08 - function associated with an numpy array
73:12 - the numpy library has a median function
73:15 - and you can drop your array into the
73:18 - median function but there is no median
73:20 - function that hangs off of your array
73:22 - which i found very interesting as i was
73:24 - researching this
73:25 - um so we say give me the the median and
73:28 - sure enough it spits out an 8 and that's
73:30 - quite nice
73:31 - if i want to look up the variance and
73:33 - the standard deviation without using
73:34 - chalmers crappy code we get an 80.8 and
73:37 - we get an 8.9
73:39 - awesome
73:42 - let's turn to scipy
73:44 - i'm going to run all four of those mean
73:46 - median var and standard deviation
73:49 - um
73:51 - we get 9.96 we get an 8.0 80.8 and 8.9
73:56 - looks good
73:58 - one thing you should know as i mentioned
74:00 - sci-fi kind of rides right on top of
74:02 - numpy
74:03 - so if i go in here and i say
74:06 - i like this numpy mean method but i'm
74:09 - not real sure how it works i'd like to
74:11 - know more about it you can ask this
74:12 - question mark and you put the question
74:15 - mark in there and they'll give you the
74:16 - help file for it so look at that
74:19 - and now we have access to
74:21 - all of the
74:23 - arguments that i can give it i give it
74:24 - my array and if i want to do certain
74:26 - things i can have it change its behavior
74:30 - i don't know what any of these mean
74:32 - right axis d type what is all of that
74:34 - well i can scroll through and it will
74:36 - define for me oh here's what axis means
74:38 - and here's what d type means and so i
74:40 - can figure some of those things out
74:42 - tells me what it gives me back it says
74:44 - i'm going to give you back
74:46 - this that or the other and you can kind
74:47 - of get some sense of what's going on
74:49 - might give you some notes as to other
74:51 - things you might want to look at
74:53 - to see if other types of calculations
74:55 - might be useful to you that's cool
75:00 - happens to be really nice and give you
75:01 - some sample code
75:03 - if you tried to get it to work and it
75:05 - failed maybe you look at the sample code
75:06 - and it helps you out that way
75:09 - all right
75:10 - gives you some caveats in certain cases
75:13 - this might be slightly inaccurate buyer
75:15 - beware
75:17 - okay
75:18 - it tells you where it pulled it from and
75:20 - it said hey you know what
75:21 - we got this out of the numpy library and
75:24 - it's from this thing called
75:25 - fromnumeric.pi which is awesome
75:28 - if i were to do this same thing with
75:29 - scipy.mean
75:31 - we see
75:32 - i can call psi pi.mean
75:35 - but
75:36 - interestingly enough all the
75:38 - documentation is exactly the same and
75:40 - when i get down to the bottom
75:41 - sure enough it actually just calls numpy
75:43 - under the hood so
75:45 - um
75:46 - like i said your mileage may vary okay
75:50 - the statistics library
75:52 - statistics library has mean median
75:55 - variance and standard deviation
75:57 - notice the spelling is different
76:00 - right they actually call it variance
76:01 - instead of r they call it stdev instead
76:05 - of std
76:07 - all right
76:08 - and if i run that
76:11 - what's wrong
76:15 - my numbers are different
76:17 - in particular which two numbers are
76:18 - different
76:21 - the variance and the standard deviation
76:23 - here are not the same as the ones we saw
76:24 - before so let's go take a look
76:27 - 81.2 and 90.0
76:30 - oh there's a lot of stuff here
76:32 - and we had 80.8 and 80.9 8.9 so they're
76:37 - different
76:39 - all right
76:41 - why
76:42 - anyone know why
76:48 - yes
76:50 - he mentions there's a difference between
76:51 - population variance or population
76:53 - standard deviation and sample variance
76:56 - or sample standard deviation
76:58 - all right so now that our heads explode
77:00 - let's go take a look at what that means
77:04 - when you calculate a what's called a
77:06 - population standard deviation
77:08 - you are looking at
77:11 - the amount of dispersion for an entire
77:12 - population and we use a particular
77:15 - formula for that
77:17 - this formula
77:19 - we take
77:21 - the difference from the mean for every
77:23 - one of our values
77:25 - take the square
77:26 - we divide by n
77:29 - and we
77:30 - then take the square root so n is this
77:33 - denominator
77:35 - and in this case for population standard
77:37 - deviation the n is a larger denominator
77:40 - than the next example we'll look at
77:42 - all right and for your convenience and
77:44 - later reading i spell out what each of
77:45 - the symbols is and why they're there
77:47 - let's go look at a sample standard
77:49 - deviation
77:50 - a sample standard deviation is just a
77:52 - sample that estimates
77:54 - what your deviation for a bigger
77:56 - population should be
77:58 - if we take a random sample out of that
78:00 - bigger population
78:01 - and it uses a slightly different var
78:04 - value as the denominator
78:07 - and minus 1. because n minus 1 is
78:10 - smaller than n
78:12 - the size of this standard deviation
78:14 - tends to be a little bigger than
78:17 - for populations
78:19 - all right
78:21 - so when do we use population versus
78:23 - sample
78:26 - we tend to use the population when we
78:28 - know the entire population we have all
78:30 - of the data in our hands we use the
78:32 - sample version if we are looking at a
78:34 - subset of a much bigger
78:36 - group of folks so if i'm a teacher and i
78:38 - have 25 students and i have all 25
78:41 - grades
78:42 - i can use the population because i know
78:44 - everybody's grades
78:46 - if
78:47 - i am looking potentially at
78:50 - my students grades as some sort of a
78:52 - sample of the grades across the school
78:54 - or across the school district i don't
78:56 - have all the grades for the larger
78:58 - population i just have my sample so i
79:00 - have to use the sample standard
79:01 - deviation
79:03 - all right
79:04 - another example if i'm a researcher and
79:07 - i'm looking at the relationship between
79:08 - women exercise and blood pressure right
79:11 - i might use a sample standard deviation
79:13 - because i only have a subset of folks
79:15 - that i
79:16 - polled or surveyed or researched on i
79:18 - don't have all the folks in the world
79:20 - right
79:21 - okay so that's why we have this
79:23 - difference because that silly
79:25 - denominator at the bottom is off by a
79:27 - smidge because we're either looking at a
79:29 - sample or looking at a population all
79:31 - right
79:32 - the numbers are typically very very
79:34 - close together
79:37 - if you're doing comparisons one to
79:39 - another but you use the same formula
79:41 - your comparisons will give you an order
79:42 - of magnitude
79:44 - difference
79:45 - all right
79:47 - if you were in a competition like a data
79:48 - science competition and you need to have
79:50 - the right answer you may want to choose
79:52 - the right function
79:54 - all right
79:55 - so let's go look at one last example
79:57 - this is the pandas library and it has
80:00 - mean median var standard deviation
80:02 - notice they went back to this kind of
80:04 - spelling of var and std
80:06 - let's run these guys
80:09 - it uses that same version
80:12 - of variance and standard deviation that
80:14 - the statistics library did okay all
80:18 - right so just a nuance be aware that it
80:19 - happens
80:23 - oh sweet
80:25 - for those who don't know
80:27 - pandas in this library allows you to
80:29 - create a set of data
80:31 - and
80:34 - i take a list i drop it into this series
80:36 - function
80:38 - and i ask python
80:39 - what do i get back pd
80:42 - i say hey you have a series and you go
80:44 - okay so what is a series
80:45 - a series essentially is a column
80:49 - in a data set you can imagine a series
80:51 - being like a column in an excel
80:53 - spreadsheet
80:54 - so it takes this list of things and
80:55 - throws it into a column you say what
80:57 - does that look like in real world
81:00 - defects pd
81:03 - printed out
81:04 - and so it says hey row 0 had a 99 in it
81:08 - row 1 had a 52 row 2 had a 42 and it's
81:11 - got all 204
81:13 - pieces of data
81:15 - this is not a pandas class but
81:18 - with a panda series you've got all sorts
81:20 - of capabilities like you can do
81:22 - aggregations and you can do groupings
81:24 - and you can calculate means and medians
81:26 - and all sorts of other things there's
81:28 - about 224 different types of things you
81:31 - can do to a panda series to help you do
81:33 - your data analysis you can break it up
81:35 - by quantiles they have a whole library
81:37 - for helping you with a whole module for
81:38 - helping with quantiles and stuff
81:40 - it's a lot of cool things
81:42 - all right did that help
81:46 - okay
81:47 - two more questions go
81:49 - how
81:59 - um
82:10 - so what if your data set for example
82:12 - doesn't fall into kind of a nice normal
82:14 - bell-shaped curve
82:15 - all right
82:18 - so that's that's a really good question
82:20 - that i do not know the answer to of how
82:22 - well your data needs to fit in in the
82:24 - normal the normal distribution for that
82:26 - to work well
82:27 - um
82:28 - i don't know if alan has any insight
82:30 - into that the question essentially is
82:33 - yeah
82:34 - there's there's lots of curves but the
82:36 - question was when you have a data set if
82:39 - it's not necessarily a nice bell curve
82:41 - and i try and do a standard deviation
82:44 - how easy is it to basically shoot myself
82:46 - in the foot right if if my data doesn't
82:48 - fit a normal curve is my standard
82:49 - deviation just going to give me really
82:51 - wonky answers
83:09 - sure
83:20 - so
83:22 - that is one of those nuances that
83:24 - regularly using
83:26 - these tools and reading about it again
83:29 - this is a three-hour class right right
83:31 - diving into this um
83:33 - one of the great things that you'll see
83:35 - when you start looking at research
83:36 - papers where people are using statistics
83:38 - to prove a point is they use statistics
83:41 - incorrectly
83:43 - and the point they're trying to prove is
83:45 - not what the data really shows right and
83:47 - it's not because necessarily that
83:50 - they're being malicious just because
83:51 - they're trying to apply a thing you know
83:53 - round peg into a square hole kind of a
83:55 - thing and that just doesn't work
83:57 - so it takes time it takes effort to dive
83:59 - into this research it figure it out i
84:02 - will show you
84:03 - some of the things that are available to
84:04 - us in some of the tools like scipy and
84:07 - just it is mind-blowing the number of
84:09 - options that we have available to us and
84:11 - so that would play into kind of your
84:13 - question
84:15 - yeah you had a question too
84:29 - all right so if a standard deviation is
84:31 - larger
84:32 - it tends to be
84:34 - sample if it is smaller use population
84:37 - so let's go back and look
84:40 - right
84:42 - well if i if i dump the same data set
84:45 - and i'm going to let me get rid of this
84:46 - guy clear output
84:48 - if i have the exact same data set which
84:51 - i do i i'm using num defects and i drop
84:54 - it into scipy
84:55 - i get a slightly smaller value
84:58 - than i got
85:00 - when i
85:04 - put it into
85:06 - the statistics library
85:08 - so
85:08 - a smaller value
85:11 - means a library is using population
85:13 - standard deviation a larger value means
85:15 - as being sample but having said all that
85:17 - there are ways to tell the library to do
85:19 - the thing that you want so let's take a
85:20 - quick look at that
85:21 - all right
85:27 - okay so
85:28 - [Music]
85:30 - psi pi dot
86:00 - in the scipy library for standard
86:02 - deviation they have a thing called this
86:05 - delta degrees of freedom and it
86:08 - identifies the divisor that you want to
86:10 - use
86:11 - and so you can have n minus something
86:13 - and then the normal is n minus one right
86:16 - the default that they use is zero so if
86:18 - i needed
86:19 - psi pi to do
86:21 - the reverse of what it normally does i
86:23 - can simply go into the function and i
86:26 - can set this
86:28 - degrees of freedom to be 1 versus 0
86:30 - which is the default
86:32 - all right so again it's just a matter of
86:33 - you need to know that it's there you
86:35 - need to know it's kind of a problem that
86:36 - you have to kind of answer
86:38 - um
86:41 - so all right let's see what else we got
86:43 - um
86:44 - i think in the interest of time holy cow
86:48 - how did the day go by this quickly we're
86:50 - going to skip the exercises
86:52 - here's a list of cool books
86:55 - and i start from
86:57 - the lower end of the scale to the higher
86:59 - end of the scale my first book i ever
87:01 - read on stats outside of high school was
87:03 - this cartoon guide uh it was a low
87:06 - pressure guide to statistics it covers
87:09 - way more than we're going to cover in
87:10 - these three hours the manga guide i got
87:12 - from my kid he liked it
87:14 - head first statistics by o'reilly
87:17 - is a book that um
87:20 - spells things out in a way that i find
87:22 - to be really really uh useful
87:24 - naked statistics is a little less about
87:28 - how one does it and the maths and more
87:30 - about oh my gosh how do you not do it
87:33 - wrong
87:34 - um and he talks about a lot of good kind
87:36 - of case studies and examples of people
87:38 - using statistics in the pros and cons
87:40 - he's very light on the math more on the
87:42 - this is awesome statistic-ness so this
87:44 - is a great read statistics in a nutshell
87:47 - that's fairly dense
87:49 - it's a good reference book
87:51 - i like it because it puts all the stuff
87:52 - in a small amount of space
87:54 - but i found that
87:56 - had i read it before i read maybe head
87:58 - first or even the manga guide that might
88:00 - have been a little too intense for me
88:03 - i think stats think python and think
88:05 - bays are great and for those who don't
88:07 - know
88:08 - that guy over there
88:10 - he wrote them
88:12 - and
88:14 - this one um
88:17 - is a little wonky and if you go to
88:18 - amazon and you look at the cover of this
88:20 - you're like oh my gosh
88:21 - but it is very compact and it spells out
88:24 - a thing called bayes theorem and it
88:26 - spells it out in a way that's kind of
88:27 - visual and it was quite nice
88:30 - all right
88:31 - and for the record
88:32 - uh mr allen
88:34 - uh
88:35 - who literally wrote the book yesterday
88:37 - we're talking he's like hey do you want
88:38 - a mentor in your class
88:39 - and i'm like yes
88:43 - okay
88:44 - so he's judging me by the way
88:46 - all right thanks
88:48 - um
88:50 - so let's move on to the next thing and
88:52 - let's cover this let's go through this
88:55 - we're going to shift gears
88:57 - we're going to talk about probability
88:58 - now the likelihood of something happen
89:04 - we're going to
89:05 - figure out how we can calculate the
89:06 - probability of something happening
89:09 - we will
89:10 - explore probabilities using what we call
89:12 - venn diagrams
89:14 - we'll explore probabilities using
89:15 - probability trees
89:17 - and we will talk about the principles
89:18 - behind the law of total probability and
89:21 - behind bayes theorem and we'll see a
89:22 - couple of examples of that
89:25 - all right
89:26 - uh i like the definition from sarah in
89:29 - statistics in a nutshell probability
89:31 - tells us how often something is likely
89:33 - to occur
89:34 - if we repeat an experiment right
89:38 - so let's expand our understanding of
89:40 - probability with a couple of definitions
89:43 - you'll hear reference such a thing
89:44 - called trials or experiments or
89:46 - observations
89:48 - a trial is some event
89:50 - where you don't yet know the outcome
89:53 - trials can be crazy easy i'm going to
89:55 - flip a coin i'm going to roll a dice or
89:58 - it could be
90:00 - someone has a low birth weight
90:03 - will they
90:05 - graduate from college 22 years later
90:08 - right
90:11 - sample space
90:12 - is essentially all of the possible
90:15 - outcomes of a trial so i have a six
90:17 - sided die
90:18 - i roll it all the possible outcomes are
90:21 - one two three four five and six
90:25 - say i drop four coins in a bag
90:27 - i've got a quarter a dime nickel and a
90:29 - penny if i draw one of those out my
90:31 - sample space will be quarter dime nickel
90:33 - and penny
90:35 - an event is the actual outcome of a
90:38 - trial
90:40 - events could essentially be singles or
90:42 - could be groups of things we will often
90:45 - designate an exam an event with an e
90:48 - so
90:49 - if i roll a die
90:51 - and
90:53 - my event is that i get a one on my die
90:56 - e would be this set with one in it
91:00 - if i want to specify that
91:03 - um
91:04 - my event is that i get an even number
91:07 - my e would be a 2 a 4 or a 6 when i roll
91:10 - that die so you can have more than one
91:11 - thing in your event
91:14 - now if i'm going to calculate a
91:15 - probability this is pretty
91:16 - straightforward
91:17 - i take how many elements are in my event
91:21 - divide that by how many elements are in
91:22 - the sample space and i get the
91:24 - probability
91:26 - so the probability of rolling a one on a
91:28 - six-sided die
91:29 - is one divided by six
91:32 - and that math turns out to be like
91:35 - 0.16 or something
91:38 - so let's throw together a pretty
91:39 - straightforward
91:42 - function that'll help us do this
91:44 - for those who do not play d and d in
91:46 - those types of games a d6 means that
91:48 - your die has six sides a d8 means it has
91:51 - eight sides
91:52 - so let's make a real quick function that
91:55 - returns a one on a d6 and so i would
91:58 - calculate 1 divided by 6
92:01 - and i get back sure enough
92:04 - to do
92:06 - 0.16
92:07 - and that's crazy limited you would never
92:09 - want to write multiple functions
92:11 - for every single case so maybe we want
92:13 - to expand this a little bit make our
92:14 - probability function
92:18 - better able to handle a large sample
92:20 - size
92:21 - or better able to handle an event
92:24 - so i set my count to be one
92:27 - and i divide it by the sample size
92:32 - all right so if my event was i roll a
92:34 - four on a six sided die the probability
92:37 - of a four showing up is this the astute
92:40 - observer though goes wait wait chalmer
92:43 - we dumped in event but we never actually
92:45 - used it that's screwy let's go fix that
92:48 - all right
92:51 - if my event is composed of more than one
92:54 - thing
92:55 - i want to determine if i get a 2 a 4 or
92:57 - a 6.
92:59 - we need to have a way to determine that
93:04 - all right
93:05 - so i'm going to make a small list
93:08 - let's say my event is i roll less than a
93:11 - four i roll one two or three on my die
93:14 - um
93:15 - i start off with saying hey let me check
93:17 - did chalmer just give me a list or a
93:18 - tuple or did it give me a single value
93:20 - if he gave me a list we'll count how
93:22 - many events are in it one two three
93:24 - and we'll use that to do the math
93:26 - if he gives me a single item then we'll
93:28 - just call it one it's all good
93:31 - all right so
93:32 - one thing that we often do in in python
93:34 - is alias things maybe give them shorter
93:37 - names i do not want to type probability
93:39 - a lot so
93:40 - i'm going to give that function a new
93:42 - name called p so it'll make it easier to
93:45 - type stuff
93:46 - so if i have a six sided die i have six
93:48 - items in my sample space and i'm looking
93:51 - for a two
93:54 - the probability is point one six
93:58 - on the other hand if i'm curious like
94:01 - what what is the probability of getting
94:02 - a four five or a six
94:05 - out of a sample space with six items
94:09 - that's one half
94:13 - all right
94:14 - if i'm looking for odd numbers on a six
94:17 - sided die one three and five
94:20 - again i have a 50 chance of getting an
94:22 - odd number
94:28 - alrighty
94:32 - out how many items are in a six-sided
94:34 - die is pretty straightforward
94:36 - but when things start to get a little
94:37 - more complicated
94:39 - that's where venn diagrams come in and
94:40 - you guys have probably all seen these
94:43 - we use these to represent elements in
94:45 - your sample space using very simple
94:48 - pictures
94:50 - so i'm going to show you a
94:50 - representation of rolling the odd
94:52 - numbers on a d10
94:57 - all right
94:58 - so i've got a d10
95:01 - it is fairly common in venn diagram land
95:03 - to put some sort of a rectangle in that
95:05 - rectangle represents all the possible
95:07 - values that you could have
95:09 - it is also fairly common to draw some
95:11 - sort of an oval or something or a circle
95:13 - to show the things that you really care
95:14 - about and in this case i only care about
95:16 - odd numbers and i go ahead and i label
95:19 - those one three five seven and nine
95:21 - um
95:23 - i meticulously went ahead and said
95:25 - everything outside of that oval is all
95:27 - the other stuff
95:28 - i do that for clarity but most the time
95:31 - we don't bother right
95:33 - it is presumed or assumed that
95:35 - everything in the rectangle is all the
95:36 - other stuff if i need more than one oval
95:40 - to represent two kind of related
95:42 - events that i care about i can put more
95:44 - than one over we'll see that in a bit
95:46 - um make sure to miss any of the things
95:49 - okay
95:55 - i'm going to have you guys go through
95:57 - your little notebooks etc
95:59 - um
96:00 - sketch out a couple of simple venn
96:02 - diagrams you don't have to make them
96:03 - huge or anything
96:05 - start wrap your head around this idea
96:08 - so this first one for example we're
96:10 - going to have one thing that we care
96:11 - about out of a list of 20 items on a d
96:15 - 20.
96:16 - and then i would like you to do is put
96:19 - together some python code that
96:20 - calculates the probability of getting 1
96:22 - on a d20 this next event is a little
96:25 - bigger i'm looking at just the odd items
96:27 - on a d10
96:30 - i've got an example i want you to
96:31 - consider what would we put together to
96:33 - represent
96:35 - i think it's all of the
96:38 - aces
96:40 - oh picking a single ace out of a deck of
96:43 - 52 cards
96:45 - right
96:46 - and so write some code to do that
96:49 - you have to figure out what your event
96:50 - space looks like or your your um
96:53 - your event looks like and what your
96:54 - sample space looks like so spend a few
96:55 - minutes do that
96:58 - and put your green stickies up when you
97:00 - get done
97:01 - there's about five or six
97:03 - i think what we'll do is we'll give this
97:04 - about
97:06 - seven minutes
97:08 - and then we'll roll on
97:11 - so i'm gonna set a timer
97:13 - seven minutes
97:34 - all right
98:11 - okay
101:46 - um
102:20 - yes
102:38 - got about two minutes left then we'll
102:40 - roll on
103:33 - don't panic right
103:39 - none of us is walking out of this room a
103:41 - guru
103:42 - except for that guy
103:55 - thing is though he walked into the room
103:57 - a guru so
103:59 - he had a leg up on all of us
104:11 - about 23 seconds
104:28 - all
104:32 - right so let's take a quick look at this
104:36 - i'll look at the one that kind of raised
104:38 - the most questions numerous people asked
104:40 - about this
104:41 - so p
104:41 - [Music]
104:43 - say i have 52 cards in my sample space
104:47 - and i have four items in my event number
104:50 - of people typed in 52 comma 4.
104:53 - our code is not yet sophisticated enough
104:54 - to deal with that our code blocks
104:57 - what we need in our code at the moment
104:59 - is to put in a list of items right so
105:02 - you know an
105:05 - ace of clubs a
105:08 - ace of hearts
105:09 - and ace of spades
105:13 - typing is a horrible thing in front of
105:14 - people and an ace of diamonds right
105:18 - and i'd say hey
105:19 - it's about a seven percent chance of
105:21 - getting an ace out of a 52 card deck
105:24 - right
105:25 - if i were to type in a four
105:28 - get a much lower percentage
105:30 - and the reason being if we go back and
105:31 - look at the code
105:34 - the code said
105:36 - if it's a list tell me how many elements
105:38 - are in the list
105:39 - if it's just a number
105:42 - we're going to consider that to be a one
105:44 - um
105:45 - so we've discovered kind of weakness in
105:47 - the code like hey this this doesn't
105:48 - quite play nice let's go fix that
105:51 - all right
105:52 - but the long story short of these
105:54 - problems here
105:55 - and these are kind of one dimensional
105:56 - style problems is what's the size of my
105:58 - sample space and how many elements are
106:00 - in
106:01 - my event space
106:04 - all right so let's go look at our code
106:07 - to do that though we kind of want to
106:09 - expand on a few other things and then
106:10 - we'll get there let's talk about
106:13 - exclusive events and intersections
106:18 - most of what we looked at are just very
106:20 - simple venn diagrams little circle with
106:22 - a certain number of things in it
106:23 - there are some cases though where as i
106:25 - potentially try to create a venn diagram
106:27 - i might notice that wait i'm looking at
106:29 - maybe two different types of things and
106:33 - trying to lump them together in my
106:36 - event
106:38 - for an example
106:40 - say i had a d10 dice
106:43 - and
106:45 - want to know the probability of rolling
106:46 - an even so i have 10 sides
106:49 - evens are 2 4 6 8 and 10. that's 5. so
106:54 - that's 50 chance of getting an even
106:57 - chance of getting an odd is also 50
107:01 - so the chance of getting either an even
107:03 - or an odd is
107:04 - a guarantee
107:06 - if i roll my dice i will get either an
107:07 - even or odd and so i can very nicely add
107:10 - these two things together and boom i can
107:12 - calculate what are the odds of getting
107:13 - or what is the probability of getting an
107:15 - even or odd
107:16 - so yes i have my little odd circle my
107:19 - little even circle and there's a total
107:21 - of 10 things in it
107:23 - my s
107:25 - space has got 10 things so it's all good
107:28 - but what happens
107:30 - if i do something slightly different
107:33 - what is my probability of getting
107:34 - something that is greater than a five
107:37 - when i roll that ten sided dice i have a
107:39 - six seven eight nine or a ten
107:42 - what is my probability of getting a
107:43 - number that is even two four six eight
107:45 - or ten
107:48 - my sample space is 1 through 10.
107:51 - notice
107:52 - greater than 5 and even have these kind
107:55 - of overlapping spots where 6 8 and 10
107:58 - fall into both of those ovals
108:03 - if my probability getting greater than
108:05 - five
108:06 - is fifty percent my probability getting
108:08 - even is fifty percent and i add those
108:11 - together
108:13 - that answer is not
108:15 - right
108:16 - it would say that i have a probability
108:18 - of getting
108:19 - or i have a guaranteed probability of
108:21 - getting one of those two things and we
108:22 - know that's not quite true
108:24 - the correct answer of getting either
108:26 - greater than five or even is actually
108:28 - about point seven
108:30 - and i use the word about and it's quite
108:32 - literally exact right
108:34 - i have seven things in this kind of
108:36 - conjoined
108:38 - event one two three four five six seven
108:42 - my total sample space is ten so seven
108:45 - divided by 10 is 0.7
108:48 - so what went wrong
108:50 - our original kind of let's add these two
108:53 - things together
108:55 - ignored unfortunately the fact that
108:57 - there's a little bit of overlap so we
108:59 - have this very cool formula that allows
109:00 - us to account for overlap
109:03 - i have the number of things in one event
109:05 - the number of things in a second event
109:07 - and if there's any overlap i just
109:09 - subtract out how many things overlap so
109:11 - i don't double count that ensures that i
109:13 - single count those
109:15 - divide that by the sample space and i
109:17 - get
109:18 - the union or the or
109:20 - of a and b
109:22 - all right so that's generic formula
109:24 - you notice i have this kind of u shape
109:26 - thing and i've got this fun of uh
109:28 - upside down u
109:31 - the upside down u means the intersection
109:34 - where things overlap
109:35 - uh sometimes you'll see that referred to
109:37 - as a cap
109:40 - so the number of things that are
109:42 - intersected between a and b
109:44 - this u
109:46 - stands for union it's kind of an or
109:48 - this is the number of things that are
109:50 - included
109:52 - in a or b
109:54 - all right
109:55 - so sure enough we do the math
109:58 - greater than 5 is a 50 chance there are
110:00 - five elements there
110:02 - odd is five elements there's an overlap
110:04 - of three we do the math we get seven
110:06 - over ten
110:09 - okay
110:11 - so let's start to explore this in
110:12 - practice we use my little python
110:14 - probability function
110:16 - i put in anything that's greater than 5
110:18 - anything that's even and we subtract
110:21 - manually the things that we know overlap
110:24 - and let's get an answer
110:26 - and sure enough we get 0.7
110:30 - so what's the probability of drawing a
110:32 - single red card from a standard deck
110:36 - or drawing a king
110:39 - well if i were to put that into my
110:41 - probability function
110:43 - we would see very quickly that this
110:45 - would just suck
110:46 - because i'd have to type out this big
110:48 - giant list with ace of diamonds two of
110:51 - diamonds three diamonds four diamonds
110:54 - etc and nobody wants to type that that's
110:56 - lame
110:58 - so
110:58 - let's tweak our probability function to
111:00 - say
111:01 - my sample size is maybe 52 cards
111:06 - my event
111:08 - could be a single element or if i
111:09 - already know how big the event is i can
111:11 - give it the event size
111:13 - there are 26 red cards i'll just say
111:15 - that the event size is 26.
111:18 - and then we add a little nuance in here
111:19 - it says hey
111:20 - if event size is a list count how many
111:23 - things are in the list so we still have
111:25 - that functionality if event size is an
111:28 - integer
111:29 - just use that as my count so we used a 4
111:32 - before right
111:33 - all right so let's run this boom
111:35 - probability of a red card or a king
111:39 - there are 26 red cards in a standard
111:41 - deck
111:42 - there are four kings in a standard deck
111:44 - two of those kings are red
111:48 - boom
111:51 - let's go take a look at the answer
111:55 - before we get to the answer though
111:57 - sure enough with 26 red cards out of 52
112:00 - i have a 50 chance of getting a red card
112:03 - with four kings out of a deck i have a
112:06 - 0.7 chance of getting a king but that
112:08 - little bit of overlap that we kind of
112:09 - have to suck out of there that's 0.3
112:13 - and i get an answer of
112:16 - there we go
112:17 - my chances of getting either a red card
112:19 - or a king are 0.53 it's a little bit
112:21 - above half which is what we expect
112:24 - all right
112:26 - so what's the probability of drawing a
112:28 - red card or getting a face card a king a
112:31 - queen or a jack
112:33 - well how many king queens and jacks are
112:35 - there in a standard deck
112:40 - how many jacks queens and kings
112:43 - 12.
112:44 - all right so i say hey i've got 12 here
112:47 - there's 26 red cards
112:50 - how many jacks kings and queens
112:53 - are red
112:56 - six so i want to get rid of those
112:58 - because we do not want to double count
112:59 - them
113:00 - and sure enough
113:02 - it's a little bit higher because now
113:03 - we're looking at a few extra cards
113:06 - all right now you might say but chalmer
113:10 - why do i want to do all this math and
113:11 - write all this code because if we think
113:13 - about it
113:16 - all i need to know is how many reds are
113:18 - there
113:19 - how many
113:20 - face cards are there and take away
113:23 - how many duplicates and i get 32. so i
113:25 - can actually just say
113:27 - my sample space or my my event space is
113:30 - 32
113:32 - cards are either red
113:34 - or they're kings queens and jacks
113:37 - and so i don't necessarily have to do
113:38 - this if i can kind of do it in my head
113:41 - or or do it manually you just got to
113:44 - make sure that you get event a event b
113:46 - and you eliminate that duplicate and
113:48 - boom we get the same value awesome
113:53 - so i'm gonna
113:56 - for those who don't know
114:01 - pycon has open spaces where people can
114:04 - gather with folks who do things that
114:06 - they like to do and one of those open
114:07 - spaces is board gaming
114:09 - alright so here's a board gaming example
114:11 - i have three games i have pandemic i
114:13 - have clank and i have carcassonne
114:15 - and in my board gaming group
114:17 - we have a number of folks who play
114:19 - pandemic a number of folks who play
114:21 - carcassonne
114:22 - the pronunciation of this french word is
114:24 - probably mangled by me my apologies and
114:27 - then we have clank
114:30 - some of these folks
114:31 - happen to be
114:33 - players of pandemic and carcassonne some
114:36 - of them play clank and carcassonne
114:38 - i have no duplicates or overlap between
114:40 - these two games
114:42 - now everybody in this oval this 12 and
114:45 - this six they're all part of a group so
114:46 - there's actually 18 people in this group
114:49 - this group has how many folks in the big
114:51 - circle
114:54 - 16 plus
114:57 - 26 and then the clank group has how many
115:00 - people in it
115:04 - 12.
115:05 - right
115:06 - um
115:07 - when i was putting this example together
115:08 - in my head i kept forgetting that these
115:11 - six folks were with these six folks and
115:13 - so my math was always wrong it was very
115:15 - annoying um that's why i pointed out
115:18 - pandemic folks there's 18 of them there
115:20 - are 12 clankers but some of them
115:23 - play more than one game all right
115:26 - so what is the probability of finding a
115:28 - pandemic player in my board gaming group
115:30 - who is also a carcassonne player
115:33 - huh okay well there's 18 of the
115:38 - pandemicers there's 26 carcass owners
115:41 - and then there's this nice little
115:43 - overlap of six we do the math
115:45 - and about 86 percent of my board gamers
115:48 - play those two games
115:51 - um
115:52 - but again if i don't want to type all
115:54 - this nonsense as long as i do the math
115:56 - 18 plus 26 minus 6 gives me a 34. we're
116:00 - all good all right there we go
116:02 - and the math failed epically for some
116:04 - reason why did that fail
116:07 - [Music]
116:09 - 18 26 is
116:12 - 34.
116:18 - my event size is 36.
116:21 - there we go
116:23 - that didn't work either
116:28 - 18
116:30 - is 26
116:31 - minus 6.
116:35 - 18 plus 26 is what
116:38 - 38.
116:42 - all right
116:46 - this is awesome
117:03 - i'm gonna come back to this this is
117:04 - great
117:06 - all right
117:11 - based on the fact that the code may be
117:14 - horribly wrong in some incredibly
117:15 - awesome way we're just going to skip
117:17 - those exercises and move on let's talk
117:19 - about conditionals
117:22 - all right
117:25 - during the next break i'll take a look
117:26 - at that and try and figure out what what
117:27 - where where my math and and all of that
117:29 - stuff went to rye all right
117:31 - let's talk about conditionals because
117:33 - this is going to lead to some fun stuff
117:36 - um
117:40 - one of the things that we really want to
117:42 - do when we start looking at
117:43 - probabilities
117:45 - is not just know when things kind of
117:46 - overlap but
117:47 - we want to understand
117:49 - if one thing occurs what is the
117:52 - probability that something else is going
117:54 - to occur
117:56 - if i exhibit certain symptoms
117:59 - cough cough hack hack
118:01 - sniffle sniffle what is the probability
118:03 - that i have a cold versus i have the
118:05 - what's the probability of i have the flu
118:07 - or the probability that if i have a
118:09 - tummy ache and some cough cough that i
118:12 - might have
118:13 - um food poisoning or something right
118:15 - so if you have one condition what is the
118:18 - probability that you have something else
118:22 - when we talk about probabilities we
118:24 - often hear the word given so if i
118:26 - know
118:28 - that a particular card
118:30 - is black
118:31 - what is the probability if i'm given
118:33 - that it is black what is the probability
118:35 - that it is also a king
118:37 - so i take a card out of a deck and i say
118:39 - it's black
118:40 - you can tell me what the probability is
118:43 - that it happens to be a king
118:45 - if i tell you i rolled a ten sided die
118:48 - and the number came back and it was a an
118:50 - even number you can tell me the
118:52 - probability that it was a 10. right
118:55 - to help us do that venn diagrams
118:56 - sometimes break down a little bit
118:58 - so a really useful feature or really
119:00 - useful thing that people will point to
119:02 - is this idea of a probability tree
119:05 - so for example
119:07 - i have a deck of cards
119:09 - they have 52
119:12 - cards total some of them are black some
119:14 - of them are red
119:15 - i know that 26 out of 52 are black 26
119:18 - out of 52 are red
119:22 - if i tell you that a particular card is
119:25 - black
119:26 - and i want to know what is the
119:27 - probability that it is a king
119:29 - i know that out of all of my black cards
119:32 - i have some that are kings and some that
119:34 - are not kings there are two black kings
119:36 - so there's two out of 26
119:39 - right and there are 24 out of 26 that
119:41 - are not kings so there's 26 black items
119:44 - and they kind of fall out in this way
119:46 - same thing with red kings
119:50 - a couple of things
119:53 - we often talk about kind of levels on
119:54 - the probability tree
119:59 - so we have one level of my probability
120:01 - tree we have a second level
120:03 - with any
120:04 - set of branches
120:06 - here or a set of branches here
120:09 - the math always has to add up so that
120:12 - the total probability on that set of
120:14 - branches is 1.
120:17 - all right
120:19 - so for example
120:21 - 2 out of 26 plus 24 out of 26 is 1.
120:25 - right 26 out of 52 plus 26 out of 52 you
120:28 - add that up you get one
120:30 - you can have more than two branches if
120:32 - you play roulette
120:34 - you'll know that the squares on a
120:36 - roulette table are red they are black
120:38 - and there's two of them thrown in there
120:39 - for good measure that are green so i
120:41 - could have a roulette table probability
120:43 - tree that might say black square red
120:44 - square green square and i could have
120:46 - three branches but nonetheless the
120:48 - probabilities will all add up to be one
120:50 - on any individual level with a grouping
120:52 - of of branches okay
120:56 - to solve kind of across a single branch
121:00 - to figure out what is the probability of
121:01 - getting to the end of a branch you
121:03 - multiply the probabilities together
121:06 - so if i want to say
121:08 - i have a deck of cards what is the
121:09 - probability that i will have a black
121:11 - king i multiply 26 over 52 by 2 over 26
121:17 - and that will tell me the probability
121:19 - that i'm holding one of the two black
121:21 - kings
121:22 - so 26 over 52 times 2
121:25 - over 26 and i have a
121:28 - roughly 3 4 chance of holding a black
121:30 - king
121:36 - and so
121:37 - if
121:38 - 52 items 26 multiply that by 26 and 2
121:43 - i get this
121:45 - now
121:47 - the rest of the branches play out the
121:49 - same way
121:50 - black and not a king
121:52 - red and a king
121:54 - red and not a king
121:56 - the cool thing is
121:57 - the probabilities at the end of each of
121:59 - the branches
122:02 - the probability is way out here
122:05 - three percent three percent
122:08 - and then
122:09 - like 47 and 47
122:12 - they all add up to be one as well
122:15 - right
122:16 - so 46
122:18 - it's about three or four percent another
122:19 - 46. and so when we add this up and we
122:21 - round it because you know math being
122:23 - hard
122:24 - um the total probability for any single
122:26 - branch when you add them all up is a
122:28 - total of one and that makes sense
122:30 - right
122:33 - okay
122:34 - now
122:35 - when we draw probability trees sometimes
122:38 - we throw out generic probability trees
122:41 - that other one was kind of specific king
122:43 - not king
122:44 - so you'll see this kind of nomenclature
122:46 - and syntax
122:48 - if i care about all the elements in a
122:51 - group called b
122:52 - anything that's not in that group
122:54 - you'll often see it referred to as b
122:56 - prime
122:58 - you might also see tilde b it just means
123:00 - anything that's not b
123:03 - so here
123:05 - probability that i get a b
123:07 - probability that i don't get b
123:09 - this is b this is not b
123:12 - um there's an a up there not a a and not
123:14 - a
123:18 - let's shrink this down a little bit
123:20 - all right all right so you'll see b
123:23 - prime a prime
123:24 - um
123:26 - you'll also see this nomenclature here
123:30 - that nomenclature is read in the
123:31 - following way
123:33 - probability of a
123:35 - given b
123:37 - so what is the probability that i get an
123:38 - a given that i'm on the b branch is
123:41 - essentially what that means
123:43 - here what is the probability to get an a
123:44 - if i'm on the
123:46 - not b branch or the b prime branch right
123:48 - so probability of a given b given not b
123:53 - okay
123:55 - and all that's spelled out in the text
123:58 - all that leads us to a formula
124:00 - if i want to know what is the
124:02 - probability
124:03 - that i get an a
124:05 - if i'm given a b
124:07 - i can calculate for
124:09 - the union of a and b or the intersection
124:12 - of a and b and then divide that by b
124:16 - if we pull out our algebra hats and we
124:18 - spin that around
124:21 - the probability of a or b
124:25 - is the probability of a given b times b
124:28 - say okay what does all that mean
124:32 - all right
124:36 - if i want to know
124:38 - the probability across a branch i simply
124:41 - multiply one of these by the other and
124:43 - i'll get the probability for that branch
124:46 - and this is going to be really useful to
124:47 - us in a second but that's what this
124:49 - second formula means to get to the end
124:51 - of the branch i multiply the first level
124:54 - times the second level for the branch i
124:56 - care about
124:57 - now
124:58 - a lot of times when we're given data and
125:01 - we're going to try and make this really
125:02 - cool probability tree we're not given
125:03 - all the data that'll be way too easy so
125:06 - there's a couple of rules and helpful
125:07 - hints that allow us to build out a tree
125:11 - first rule is or the first step we want
125:13 - to take is try and define the level of
125:16 - the tree
125:18 - in my black card red card king not king
125:22 - my definition of levels was okay i could
125:24 - get a black or a red it's a first level
125:27 - i can get a king or not king i could get
125:28 - a king or not king and i defined each of
125:30 - the branches
125:32 - if i have facts go ahead and fill them
125:34 - in
125:35 - put them down on the paper i'll show you
125:37 - an example that with a couple of
125:38 - pictures here in a sec
125:40 - once i've filled in all the facts i know
125:42 - i can do a little bit of simple math and
125:44 - fill in a few of the facts i don't know
125:46 - and then i can start to complete the
125:48 - branch groups
125:49 - knowing that the probabilities always
125:51 - add up to one
125:52 - and i can use that cool formula to then
125:56 - figure out the last remaining
125:57 - probabilities so let's see how this
125:58 - works
126:03 - i go out with a bunch of my friends at
126:04 - work some of them eat burgers some do
126:06 - not some eat dessert some do not
126:09 - right so maybe i want to figure out the
126:11 - probabilities associated with each of
126:12 - the branches given that some of the
126:14 - folks in the company eat burgers or
126:15 - don't eat burgers eat desserts don't eat
126:17 - desserts and i'm given three initial
126:19 - pieces of information
126:21 - the people who eat burgers
126:23 - two out of every three people eat
126:25 - burgers
126:27 - given
126:28 - that somebody is not a burger eater
126:31 - and they eat dessert that happens in one
126:33 - out of four cases
126:35 - and
126:36 - given somebody eats burgers and dessert
126:39 - that happens eight out of 15 cases so
126:41 - let's start to fill this in
126:44 - all right
126:45 - picture
126:50 - probability of eating a burger
126:51 - given that they don't eat a burger
126:54 - that you desert
126:55 - and then probability across a branch
126:58 - they eat burger and dessert
127:00 - so as i start to fill this in
127:03 - probability eat a burger is two-thirds
127:06 - probability that they didn't eat a
127:08 - burger but they ate dessert is
127:09 - one-fourth
127:10 - and the probability that they had a
127:12 - burger and dessert was eight fifteenths
127:15 - we know
127:16 - that this and this have to equal one so
127:18 - i go ahead and start to fill this in
127:20 - we know that this and this must equal
127:22 - one so i fill in the extra value so
127:25 - we're moving along making good progress
127:31 - one thing that we're kind of missing
127:33 - is this guy out here
127:37 - i know this and i know this and i know
127:39 - if i multiply this by this i get that
127:42 - so i can back out and figure out what
127:44 - this piece is if i know him and him and
127:46 - it's just algebra and when i say just
127:48 - algebra some folks suffer with algebra
127:50 - in high school etc don't panic
127:54 - just takes a little bit of practice
127:57 - so i don't mean to say that algebra is
127:59 - crazy easy
128:00 - all right
128:04 - so my formula says
128:06 - if i'm trying to figure out
128:09 - what is the probability of dessert and
128:11 - burger
128:12 - if i know he ate a burger and we know
128:14 - that uh
128:15 - he hit dessert and we multiplied that by
128:17 - the probability of burger
128:19 - this doesn't help me because i'm kind of
128:20 - missing something in the middle right
128:21 - i'm missing this guy
128:23 - but i know
128:25 - 8 15 i know two thirds
128:27 - we can do the algebra flip this over and
128:29 - put him on the other side and now when i
128:31 - multiply 8 times 3 and 15 times 2
128:35 - i round it all down i end up getting a 4
128:38 - out of 5.
128:40 - so i put 4 out of 5
128:42 - up here
128:44 - and if we kind of go back and double
128:46 - check our math right
128:47 - 2 times 4 is eight three times five is
128:51 - fifteen it worked out just the way we
128:53 - wanted
128:54 - i know these two have to add up to one
128:56 - so
128:57 - i figure out what that is
128:59 - now i have
129:01 - all of the probabilities for every
129:02 - single branch i know i can multiply this
129:05 - by that to get here
129:06 - this by that to get here and there so
129:09 - now i can fill out the probabilities
129:11 - all the way across the branch
129:14 - okay
129:15 - so this is useful
129:19 - i now know
129:21 - that
129:22 - if somebody bought a burger
129:25 - and they didn't have a dessert that
129:27 - happens 2 out of 15 of my friends
129:31 - if somebody didn't buy a burger and they
129:32 - didn't get a dessert three out of 12 of
129:34 - my friends are in that horrible horrible
129:36 - group where they don't eat burgers and
129:37 - they don't eat desserts
129:39 - all right
129:40 - okay
129:42 - so let's do some math here with our our
129:43 - script
129:46 - right
129:52 - here i pulled all the values off that
129:54 - chart and i started to drop them in here
129:56 - for branch one
129:58 - probability
130:00 - of burger knot burger was two out of
130:02 - three so two out of three
130:04 - one out of three
130:06 - probability of dessert not dessert four
130:07 - out of five one out of five one out of
130:09 - four three out of four
130:11 - and if i add up all of these
130:15 - it should turn out to be one
130:18 - and sure enough it does
130:20 - all right so i have a reasonable level
130:21 - of confidence that my numbers came out
130:23 - the way we expected
130:25 - all right
130:27 - and this is going to set us up for a
130:28 - situation in a little bit where we can
130:30 - now move beyond this and we can answer
130:32 - some really interesting questions
130:34 - all right
130:36 - but for now we'll take a little bit of a
130:38 - break you guys kind of turn through this
130:40 - um
130:42 - what time does this thing end i always
130:45 - forget
130:47 - 4 20
130:50 - for something
130:52 - 4 40. sweet so we have a little bit of
130:54 - time
130:55 - all right so i'm going to turn it over
130:56 - to you folks
130:58 - all right
130:59 - i want you guys
131:01 - to take
131:03 - some of these pictures i produced for
131:04 - you
131:05 - and this is going to mirror exactly what
131:07 - we just went through
131:08 - you'll have some data i want you to
131:10 - maybe put on a piece of paper or
131:11 - whatever start to sketch this out fill
131:13 - in the things that you know start to
131:15 - fill in the things you don't and then
131:17 - we'll go from there
131:19 - meanwhile i'm going to go back and look
131:20 - at those
131:21 - those two functions and figure out why i
131:23 - suck at math
131:28 - okay
131:29 - why did this fail
131:37 - 52 sure supposed to be a 46. you are
131:39 - totally right
131:41 - i could have swore i changed this
131:42 - because i saw it and i could have swore
131:44 - i changed it
131:46 - yeah that's it
131:52 - i'm good thank you sir
131:58 - so everybody just fled the room
132:02 - but they left their laptops which means
132:03 - it's open season on
132:05 - unattended laptops pick the ones you
132:07 - want
132:09 - and i'll come back with your question
132:16 - turn this off
132:35 - two thirds
132:52 - the reasons
133:02 - um
133:18 - this is
133:34 - uh
134:27 - right
134:44 - okay
135:57 - oh
136:59 - uh
137:29 - um
140:47 - foreign
140:59 - um
141:31 - uh
142:18 - so the whole way down
143:07 - wouldn't i wouldn't give for microsoft
143:08 - paint
143:42 - all right
143:55 - so when i first started going down this
143:56 - road
143:58 - um
143:59 - i'm gonna be perfectly honest
144:01 - lots of swiggly lines lots of slashes
144:03 - parentheses
144:05 - crazy letters and numbers and things
144:07 - that mean absolutely nothing yeah my
144:09 - mind exploded
144:10 - um
144:12 - it took doing this multiple times
144:16 - over and over again
144:17 - reading the topic in book a
144:20 - rereading the same topic because they
144:22 - didn't understand it in book b
144:24 - and then maybe sometimes rereading the
144:25 - same topic in book c and going ah
144:28 - i see what you did there
144:30 - right
144:31 - um
144:32 - so
144:33 - having said all of that right if you're
144:35 - trying to go through things and maybe
144:36 - you're drawing little probability trees
144:38 - and you're like i don't know what number
144:39 - goes where
144:40 - you're in good hands half the people in
144:42 - this room might have been in that very
144:44 - same same thing
144:46 - and be willing to admit it there's a
144:48 - bunch of other people in the room who
144:49 - are in the same boat but we're not
144:50 - willing to admit it
144:51 - okay
144:54 - in some of our examples thus far right
144:59 - we were given things here's a
145:01 - probability
145:03 - here is a probability of something
145:06 - happened given that i have
145:07 - a precursor i have a condition
145:10 - and then we have the probability that
145:13 - two things happen this n is kind of like
145:15 - an intersection it means and probably
145:16 - the guy had a dessert burger and a
145:18 - dessert
145:20 - if we
145:21 - picture this
145:22 - and this just those two for right now
145:26 - single probability and a probability
145:28 - with this given symbol in the middle of
145:30 - it
145:31 - and we scroll back up here
145:34 - when i just have a probability it goes
145:37 - first
145:38 - when i have a given it goes second
145:42 - and so this given probability is up on
145:44 - this upper branch because it's telling
145:46 - me
145:47 - this probability of not getting an a
145:49 - only applies if i'm on the b branch
145:52 - this probability of getting an a only
145:54 - applies if i'm on the not b branch so
145:57 - this given statement helps you figure
145:59 - out where that
146:01 - particular
146:02 - value fits in any one of these four
146:05 - things
146:08 - and then
146:09 - the
146:11 - intersection
146:15 - of hey my friend
146:17 - adaberger andy also or she also ate a
146:20 - dessert
146:21 - that intersection is at the end of our
146:24 - chain
146:28 - if i know the probability ate a burger
146:30 - and i know the probability had a dessert
146:32 - given that they had a burger i can
146:34 - figure out
146:36 - that intersection
146:38 - so kind of mental model where these
146:40 - three things fit
146:42 - probability
146:44 - probability given that i'm on a
146:46 - particular branch
146:47 - and then the intersection and so
146:49 - hopefully that will help you start to
146:50 - flesh out where these things go but
146:52 - again i read book after book looked at
146:54 - it multiple ways some authors are really
146:56 - horrible at explaining stuff some
146:58 - authors are really good
147:00 - some authors are genius
147:03 - all right so
147:05 - yep
147:07 - right there
147:09 - this picture
147:10 - yeah
147:23 - yes
147:24 - the reason they would equal one is i
147:26 - have four possible options
147:29 - there's no other options that my friends
147:31 - could have went down they had a burger
147:33 - didn't have one they had dessert they
147:34 - didn't so four possible options
147:37 - i have to fit into one of those four
147:39 - categories and so the probability of
147:41 - getting any of them is going to be one
147:44 - all right
147:45 - and
147:46 - here when i solve for the probability of
147:48 - branch 1 branch 2 branch 3
147:50 - and then i
147:52 - add up all four probabilities sure
147:54 - enough i get a 1.
147:56 - all right so that's that
148:02 - so
148:03 - let's wrap up this conversation here
148:04 - with this idea of the law of total
148:06 - probability and the law of bayes theorem
148:08 - our bayes theorem all right
148:12 - when we looked at those first
148:13 - probability trees
148:15 - it was fairly easy to kind of hop from
148:17 - one step to the next
148:19 - um
148:20 - hey my friend had a burger and
148:23 - you know
148:25 - 10 of my friends who ate burgers all ate
148:27 - desserts that's great
148:30 - but
148:31 - how do i reverse that question
148:34 - if
148:35 - i'm talking to a friend
148:38 - and my friend says to me
148:40 - you know what man i went to the
148:42 - restaurant i had this awesome dessert it
148:44 - was crazy good a little pecan tart
148:48 - how do i figure out
148:50 - whether my friend ate a burger or didn't
148:53 - how do i determine the probability of
148:55 - whether he ate a burger or didn't
148:58 - because if he says or she says i ate a
149:00 - dessert i may know this value like my
149:03 - friend is either on this branch or my
149:05 - friend is on this branch but i don't
149:08 - want to pry
149:09 - i would like to just kind of figure out
149:11 - the likelihood that they ate a burger
149:13 - how do we get back to that
149:16 - and that's where the law of total
149:18 - probability and bayes theorem come into
149:19 - play
149:20 - so let's start with looking at the law
149:22 - of total probability
149:24 - i'm going to apologize right there's
149:25 - lots of mathy symboly things so again
149:27 - you're going to have to go back review
149:29 - this look at this
149:31 - and kind of work through this
149:33 - i'll blow this up a little bit so the
149:34 - font is slightly larger
149:37 - okay
149:38 - so let us presume that i want to solve
149:40 - the following problem
149:42 - given that my friend said yep that
149:44 - dessert was tasty
149:45 - how do i determine the probability they
149:47 - ate a
149:48 - burger all right
149:51 - we know
149:53 - that to solve for this
149:55 - i need to know these two things it's a
149:57 - formula we had further up on the page
150:00 - what is the probability of the ada
150:01 - burger and dessert divided by the
150:03 - probability that they ate a dessert
150:08 - we may look at this and say well chalmer
150:10 - already gave us a formula to kind of
150:12 - figure this out
150:13 - if i want to know what that is
150:15 - i just need to figure out what's the
150:16 - probability ada dessert given the head
150:18 - of burger times burger that's exactly
150:20 - what we just did a few minutes ago
150:22 - so okay check we can we can solve this
150:25 - it's going to take a little math but we
150:26 - can solve that
150:29 - how do i figure out the probability they
150:31 - had a dessert
150:34 - so that's something we're going to have
150:35 - to kind of figure out
150:39 - if i take
150:44 - that little bit and replace
150:46 - whatever was in the numerator before
150:49 - okay
150:50 - if i replace this with this so
150:53 - we're going to make a little bigger
150:54 - formula but again we kind of know all of
150:56 - these values here we still don't know
150:57 - what dessert is quite yet um but we're
151:01 - getting there we're filling this in with
151:03 - things that we can answer
151:04 - i can look up the probability one of my
151:06 - friends normally eats burgers and i can
151:08 - figure out what the probability is that
151:10 - they had dessert if they had a burger
151:12 - to figure this part out
151:14 - i simply go out to the ends of each of
151:16 - the branches and i look at the two
151:17 - branches that say dessert on them and i
151:19 - say what's the probability that somebody
151:22 - had a burger and had a dessert what's
151:23 - probably they didn't have a burger and
151:25 - they had dessert and just add those two
151:26 - things together if i can add those two
151:29 - together i can get the overall
151:30 - probability that one of my friends ate a
151:32 - dessert
151:34 - now
151:36 - the magic becomes
151:43 - these
151:44 - break them out a little bit and we can
151:46 - solve for what
151:48 - the probabilities they desert
151:50 - and that is the law of total probability
151:53 - all right
151:57 - let's take a quick look at this for a
151:58 - sec
152:09 - so
152:14 - knowing what we know we can go through
152:16 - and do the same process and start to
152:17 - fill in the little blocks we can start
152:19 - to multiply things out
152:21 - we figure out the probabilities that i
152:23 - received spam or didn't receive spam
152:25 - probabilities that there were keywords
152:27 - in the email or there wasn't keywords in
152:29 - the email
152:30 - probability that something went all the
152:32 - way across a branch when you figure out
152:33 - these numbers at the end
152:35 - and with all of those things
152:39 - i can go back
152:45 - too big
152:47 - and i can start to fill in
152:51 - this part of this this equation and
152:54 - figure out what the probability is the
152:55 - guy had to desert
152:56 - okay
152:58 - once you know that
153:04 - we can take that value
153:06 - probability they had a dessert replace
153:08 - it with all this nonsense
153:10 - and now on this side of the equation
153:13 - i can essentially go and look at my
153:15 - chart that i sketched out
153:17 - and i can start to put a number in every
153:20 - single one of these spots
153:22 - hey he had a burger i know what is does
153:24 - how much a probability he had dessert
153:27 - i know the probability they had burgers
153:29 - these two guys are exactly the same
153:32 - i know he didn't have a burger and i
153:33 - know the probability they had dessert et
153:35 - cetera and so you can start filling all
153:36 - those things
153:37 - and if you can get those six values
153:42 - i can now tell precisely the odds that
153:44 - my friend says they had a dessert i know
153:46 - they had a burger it didn't right
153:48 - so let's put this to the test
153:52 - there's a lot of things going on there
153:54 - let's take a quick look
153:58 - given that a
154:00 - spamish style keyword
154:02 - was found inside of a message
154:05 - what is the probability that is
154:07 - classified as not really being spam
154:09 - right so given a keyword is present what
154:11 - is the probability that it's not
154:13 - classified as spam you say well that
154:14 - seems kind of weird if there are bad
154:16 - spanish words in there doesn't that
154:18 - automatically mean it's spanish
154:20 - not necessarily my friend says hey
154:22 - chalmer here's a great book on getting
154:26 - rich quickly
154:27 - right
154:28 - um he's not spamming me he's sharing
154:30 - something that he found whereas if i got
154:32 - an email from somebody
154:34 - you know in a foreign country hey you
154:35 - want to get rich quick
154:37 - maybe that's spam
154:38 - okay so you could have keywords but the
154:41 - email may not necessarily be spam
154:43 - all right
154:45 - so i start off i've got some values
154:48 - we know from some of the research we've
154:50 - done that
154:52 - [Music]
154:53 - seven tenths of the email that comes in
154:55 - is going to be nutspam
154:57 - so i have a number to go with not spam
154:59 - we know that if something is on the not
155:01 - spam branch
155:03 - the probability that a spammish keyword
155:06 - is there is one-tenth
155:08 - and if we know that
155:10 - or we can also calculate that given
155:12 - something is spam and doesn't have any
155:15 - keywords is three out of a hundred
155:18 - things so let's start to fill in that a
155:20 - little bit
155:22 - all right
155:23 - so we start to put numbers down
155:25 - seven tenths of my emails not spam three
155:27 - tenths of spam
155:29 - uh
155:30 - something was classified as spam but it
155:32 - didn't have any keywords maybe they're
155:34 - starting a new spam trend to write
155:36 - only three out of ten things are spam
155:38 - but don't have any keywords
155:40 - um
155:42 - this one is
155:45 - keyword given the fact that it wasn't
155:47 - spam only one tenth of the things that
155:50 - aren't spam have those keywords
155:52 - so
155:53 - now we do
155:54 - all the things right
155:56 - make sure each of these branches is
155:58 - equal to one these branches are equal to
156:00 - one these are equal to one
156:02 - we back this number out from there
156:05 - and we start to fill this in
156:09 - all right
156:10 - and then we do the last bit of the math
156:12 - we multiply
156:13 - this times that so 3 times 9 gives me 27
156:17 - 10 times 10 gives me a hundred
156:19 - 7 times 1 gives me 7. 10 times 10 gives
156:22 - me 100. fill in all these
156:24 - all right
156:27 - with every one of these values filled
156:29 - out like this
156:31 - and it's
156:32 - as we practice and as we get used to it
156:34 - it becomes fairly straightforward to get
156:36 - to this point
156:39 - apologize for the small fun i can
156:41 - essentially pluck values right off this
156:43 - chart and start going boom boom boom
156:45 - boom boom boom boom and i can fill in
156:46 - all six values and now i can tell you
156:49 - if i got an email that had some really
156:51 - cool spammish keyword what's the
156:53 - likelihood that it really isn't spam
156:56 - all right
156:58 - so let's blow this up a little bit
157:02 - so on the top i say let's go find out
157:07 - if it isn't spam
157:09 - and there's a keyword present what is
157:10 - that
157:12 - so that is
157:14 - one out of ten
157:16 - so i put my event size is one i have 10
157:19 - items
157:20 - uh
157:21 - if it is not spam that's a 7 out of 10.
157:24 - this is a 1 out of 10 7 out of 10
157:27 - and i fill in all six of these
157:30 - and there we go
157:32 - if there is a spammish keyword in my
157:35 - email inbox get rich quick
157:38 - uh
157:39 - cialis viagra
157:41 - the odds that it is not spam in this
157:43 - made up example is 20 percent
157:49 - and so with bayes theorem
157:51 - this is a way to answer questions that
157:53 - might otherwise seem very difficult to
157:55 - get to
157:58 - my friend tells me they had a dessert
157:59 - what are the odds
158:01 - um
158:05 - another place where
158:06 - something like this might be used would
158:09 - be maybe like a b testing i give you one
158:11 - version of a website i give somebody
158:13 - else a different version of the website
158:14 - and we get a sense of if they picked
158:16 - something here what is the chance they
158:18 - were using this version of the website
158:21 - if they bought a thing or they clicked
158:22 - on an ad what is the probability that
158:24 - they were looking at a particular type
158:26 - of ad
158:27 - so here's an exercise for you folks
158:32 - i give you basically the same three
158:34 - types of data
158:35 - sketch out your little probability tree
158:37 - start to fill out the tree until you
158:39 - have all the values populated
158:41 - and then
158:45 - much like we did up here go ahead and
158:47 - work out those six items in the formula
158:51 - and answer the question
158:54 - after some of my friends played two
158:56 - different versions of a board game
158:59 - talking to my friend the friend said hey
159:01 - i really want to buy this game
159:03 - what is the probability that that tester
159:05 - played version b of the game versus
159:07 - version a
159:14 - i'll give you guys a few minutes to go
159:15 - through that
159:17 - give you about seven eight minutes
159:29 - all right
159:44 - oh my gosh
160:05 - you
160:33 - you
161:57 - you
164:01 - if you get this finished put your little
165:41 - questions
167:26 - okay
167:54 - all right
167:57 - okay
168:02 - the big sticking point here
168:04 - is figuring out what each of these
168:06 - things are
168:08 - just as i kind of walked around and
168:10 - talked to a couple people and listened
168:12 - to some of the comments right
168:14 - the process of getting from point a to
168:16 - point b
168:20 - is essentially the hard part
168:23 - and how this will normally play out in
168:25 - these types of examples
168:29 - you will potentially be given
168:31 - one of these two values on a branch so
168:34 - you have to do the math
168:35 - to get the other
168:37 - you'll be given
168:39 - two values here and you can get the
168:41 - third you'll be given two values here
168:43 - and you need to get the middle one those
168:45 - kinds of things
168:47 - and so as you get practice and you get
168:49 - practice by doing right you do this over
168:51 - and over again
168:52 - um
168:54 - you will grow accustomed to oh i've got
168:56 - these three facts or these four facts
168:58 - and i can start to fill in
169:00 - and then once you get this down and
169:02 - things are working out really well
169:04 - then you can start to apply this to real
169:06 - world problems
169:07 - okay
169:09 - but once this chart is filled in
169:12 - the next step becomes
169:14 - take each one of those things put them
169:16 - into the six spots and then the math
169:18 - should theoretically work out
169:20 - all right
169:23 - i'm going to let you guys read this
169:25 - section on independent events and we're
169:26 - going to move on to lesson 3 in the
169:28 - interest of time
169:30 - so you guys can go back and read that on
169:31 - your own
169:33 - we want to look really quickly at what
169:35 - we call discrete probability
169:37 - distributions
169:39 - and then we want to understand a little
169:40 - bit about factorials well
169:43 - permutations and combinations and what
169:44 - those are for and what they mean
169:47 - in the middle of this we're going to do
169:48 - a field trip i'm going to take you guys
169:50 - out onto the wild wild internets and we
169:53 - will look at some things that are out
169:55 - there that might be of interest and use
169:56 - to you
169:58 - and we'll talk a little bit about how
170:00 - this discrete probability distribution
170:02 - can apply to other things but let's get
170:04 - started with the discrete probability
170:06 - distribution
170:08 - one of the kind of the classic i guess
170:10 - examples of a discrete probability
170:13 - distribution
170:14 - is related to slot machines
170:18 - by discrete we mean it's broken up into
170:22 - individual components as opposed to like
170:25 - a nice curve right
170:28 - [Music]
170:30 - with this slot machine example i have
170:33 - three slot machine wheels
170:35 - every wheel has certain symbols on it it
170:37 - might have an apple it might have an
170:39 - orange it might have a quarter might
170:41 - have other random things
170:44 - depending on how the slot machine plays
170:46 - out if i were to get
170:49 - an a and a and a and apple and apple and
170:51 - apple on the three wheels
170:53 - i get four dollars
170:55 - i had to pay 20 cents to play so my gain
170:59 - is going to be 3.80
171:02 - if
171:03 - i got an apple apple orange
171:06 - they give me three bucks but again i
171:08 - spent 20 cents to play so i really only
171:10 - gained two dollars and 80 cents orange
171:12 - orange orange i get two dollars
171:16 - i want to highlight this bit
171:18 - this apple apple orange is any order
171:21 - if i got an apple an orange and an apple
171:25 - that still qualifies i still get my
171:26 - three bucks woohoo
171:28 - all right they're still ripping me off
171:30 - okay now on any given wheel i have a
171:34 - certain number of oranges i have a
171:35 - certain number of apples a certain
171:36 - number of quarters and stuff on that
171:38 - wheel and the probability of getting an
171:40 - apple is one in ten
171:42 - the probability of getting an orange on
171:44 - a single wheel is going to be two out of
171:46 - ten probability getting quarters two out
171:48 - of ten and all the other symbols the
171:50 - cruft
171:51 - that's
171:52 - fifty percent probability of getting
171:53 - some other random symbol okay
171:57 - what i'm going to start doing here is
171:58 - i'm gonna start building out a table of
172:00 - details
172:01 - i'm going to go kind of step by step
172:03 - building out the table and it's going to
172:04 - take me to a point where i can figure
172:06 - out
172:07 - what is my average win at the casino
172:10 - air quoting the word win what is my
172:12 - average loss at the casino
172:14 - so here are my wheels
172:17 - here's how much they pay
172:19 - here's how much i get
172:22 - or how much i pay so
172:24 - normally when i screw up and i get
172:25 - nothing none of the wheels helps me i'm
172:27 - gonna immediately lose 20 cents if i get
172:29 - three quarters
172:31 - i get back 80 cents because i've spent
172:33 - 20 to get there
172:35 - um we know the probability of getting an
172:37 - orange
172:39 - so
172:40 - 2 percent
172:41 - or
172:42 - 20 probability of getting an orange 20
172:44 - probably getting another one 20
172:46 - probability getting a third the chances
172:48 - of me getting three oranges in a row is
172:51 - eight out of a thousand
172:53 - um similarly i can do the math to figure
172:55 - out what is the probability of getting
172:57 - all apples that's one in a thousand
173:00 - probability of getting all quarters is
173:02 - eight out of a thousand
173:04 - and the probability of being a sucker
173:07 - is
173:08 - 996 times out of a thousand i lose cash
173:13 - straight up
173:15 - all right if you are a gambling
173:16 - aficionado please don't be insulted when
173:18 - i say sucker that's a colloquialism all
173:21 - right
173:23 - so if i translate gains and losses
173:27 - um we can assign a probability of
173:29 - getting any specific gain and here
173:33 - i'm going to stop calling them gains and
173:34 - losses i'm going to say x
173:36 - so i have a capital x and a lowercase x
173:39 - x is
173:41 - this random variable
173:43 - um
173:44 - and the little x is any individual item
173:47 - and i've only got four or five options
173:48 - here so out of these five options that
173:51 - fall into this big random variable
173:54 - and so i know the probability of getting
173:56 - any of those
173:57 - five options and i know how much money i
173:59 - get
174:01 - and that's going to help me figure out
174:02 - my average win or loss
174:05 - all right
174:07 - in our previous discussions we talked
174:09 - about averages we use the word mean
174:11 - when we talk about these distributions
174:13 - we use the phrase expectation
174:15 - little mood lighting sweet is somebody
174:17 - leaning on a light
174:18 - switch all right
174:23 - it was getting crazy cozy in here
174:26 - all right
174:30 - so
174:31 - given any particular trial i might lose
174:34 - i might win is there a way to figure out
174:35 - my average and that is using expectation
174:39 - to figure out our expectation
174:41 - we use a formula much like we had before
174:43 - we say all right if i have a particular
174:46 - x
174:47 - what is the probability that i'll get
174:48 - that x
174:50 - and let me add up all of those
174:52 - and that will give me my mean
174:57 - e
174:58 - x is called expectation but we also
175:00 - often call it mean so you'll run into it
175:02 - as both and matter of fact we might use
175:04 - the symbol for mean which is this
175:07 - uh
175:09 - this greek mu
175:10 - all right
175:11 - so for starters i multiply the
175:13 - probability
175:15 - times the
175:16 - the value of the variable and i get
175:18 - these results
175:19 - a bunch of them come out positive
175:21 - and then we have this suckers category
175:24 - which comes out very negative
175:26 - and if i do all the math and i add all
175:28 - five of those results up my average loss
175:31 - every single time i play this game if i
175:33 - played it a lot of times my average loss
175:35 - will be 16 cents every time i play this
175:37 - game
175:40 - all right
175:41 - sure i might win four bucks
175:44 - once in a while but on average i'll lose
175:46 - 16 cents every time i play
175:48 - all right
175:51 - now
175:52 - knowing the mean is kind of cool but we
175:54 - also often want to know how broad that
175:57 - spectrum is
175:59 - is there a possibility i might have a
176:00 - really broad spectrum and maybe i'll get
176:02 - really lucky on one end of the spectrum
176:04 - to solve that we essentially solve for
176:06 - variance
176:07 - right so the variance of any given
176:09 - probability distribution
176:11 - is the expectation of
176:14 - the value
176:15 - minus
176:16 - the average squared
176:19 - right
176:21 - so let's get in here
176:24 - this is essentially the same chart we
176:26 - had before but i take
176:29 - the value
176:30 - minus the average
176:32 - remember the average was negative i'm
176:34 - losing money on this so i subtract a
176:36 - negative value
176:38 - and i get this
176:41 - um
176:43 - once i have taken the average and
176:45 - subtract it from all five values i'm
176:47 - gonna have to go back and square it
176:50 - so we jump in here
176:52 - we take each of those values we just
176:53 - calculated a second ago we go ahead and
176:55 - square them all
176:56 - and once we have a square
176:58 - we multiply it by the probability and we
177:00 - get all these things
177:02 - again you go back reread this kind of
177:04 - absorb it take your time
177:06 - but ultimately
177:08 - once i've multiplied
177:10 - the square value times the probability
177:13 - i can get a variance and i can tell with
177:15 - this particular data set
177:18 - it's wide it's narrow things are really
177:20 - close to the mean a lot of times things
177:22 - are far away from the mean a lot of
177:23 - times but again variance is such an ugly
177:25 - number nobody likes variance
177:27 - so we have standard deviation and that's
177:29 - just the square root of the variance
177:31 - all right so your first question might
177:33 - be
177:34 - holy cow how do we write code that does
177:36 - all of that
177:38 - well we're not going to we're going to
177:39 - skip that part right and we're going to
177:40 - go on a field trip we're going to look
177:42 - at some libraries these are your
177:44 - takeaways these are things you can go
177:46 - home and play with and explore and
177:47 - consider i'm going to look at a couple
177:49 - of libraries
177:51 - and figure out how the pros
177:53 - have put these things together for our
177:54 - use
177:55 - um the first place we're going to start
177:57 - is the stats field trip and for your
178:00 - reference don't try to like read out the
178:02 - the url because that's that's just going
178:04 - to like blind your eyes
178:06 - all of these are linked at the bottom
178:08 - and so i have all the urls to get to
178:10 - each of these down at the bottom okay so
178:12 - let's start with the sci-fi stats
178:14 - library
178:15 - load this up a bit
178:17 - okay
178:19 - [Music]
178:20 - the sci-fi library itself
178:23 - has some tutorials that'll kind of walk
178:25 - you through a series of things certain
178:27 - basic functions they might have or
178:29 - statistical functions that are present
178:31 - etc
178:33 - i'm going to dive into
178:35 - the scipy.stats library
178:38 - i'm basically going to kind of scroll
178:40 - through this and point out a few things
178:42 - the nuance here that i want you to walk
178:43 - away with is there's a heck of a lot of
178:45 - good work that's been put into solving
178:47 - some of these statistical problems that
178:49 - i should take advantage of instead of
178:50 - using chalmers crappy code
178:52 - all right
178:54 - we mentioned a minute ago discrete
178:55 - probability distributions where things
178:57 - take certain values
178:59 - a 3.80 return a 2.80 return well there's
179:03 - other distributions called continuous
179:05 - and so i'm going to kind of scroll
179:06 - through this right they're all
179:08 - alphabetical order a so we got alpha
179:10 - arcsin
179:11 - these are all continuous distributions
179:14 - and a lot of work has been done to try
179:16 - and create
179:18 - these objects in python that you can use
179:21 - to look at distributions of data in
179:23 - various ways and we'll dive in on one of
179:25 - these in a few moments
179:27 - but there's a lot right
179:30 - so when we talk about you starting your
179:31 - statistics journey
179:34 - this is step one this is the first three
179:36 - hours or something of a 40 hour college
179:38 - class on intro to stats and this is you
179:41 - know graduate level whatever right but
179:43 - there is a destination you can get to
179:45 - and in many cases you don't have to go
179:47 - all the way you don't know and memorize
179:48 - every one of these none of us have that
179:50 - memorized
179:52 - we build on the basics and then when we
179:55 - need something particular we go and try
179:57 - and hunt down the thing that will help
179:58 - us
179:59 - we have what's called multivariate
180:00 - distributions that look at various types
180:02 - of
180:03 - multiple variables that correlate with
180:05 - things we have some discrete
180:07 - distributions which is what we were
180:09 - looking at a moment ago there's various
180:11 - ways to handle particular types of
180:13 - discrete distributions
180:15 - and then of course they've got
180:17 - a whole slew of statistical functions
180:20 - like mode
180:21 - and
180:24 - calculating for skew and for variation
180:26 - and
180:27 - standard deviation etc so let's go dive
180:30 - in on one of these
180:32 - this is in the stats library and this is
180:34 - related to a particular discrete random
180:36 - variable it's called the binomial
180:38 - discrete random variable
180:40 - and
180:43 - the way to calculate certain values that
180:45 - come out of this they have this really
180:46 - funky formula we're not going to spell
180:48 - that out i'll let you guys figure it out
180:50 - but you provide it with
180:51 - a couple of values and it will allow you
180:53 - to build
180:55 - kind of this body of information that
180:56 - you can then go
180:58 - and explore
181:00 - and your exploration might lead you to
181:02 - making graphs that kind of show patterns
181:04 - in the behavior
181:07 - and if you want to know specific details
181:09 - about the data that you could use to
181:11 - make that graph they have a whole slew
181:14 - of additional kind of nested functions
181:16 - that allow you to dig right into
181:19 - that distribution and understand more
181:21 - about it etc right i'm not going to walk
181:24 - you through all these things but they're
181:25 - there
181:27 - so that's the first part of the field
181:28 - trip sci-fi stats the next part of the
181:31 - field trip
181:33 - we mentioned a library called numpy
181:36 - numpy's got
181:38 - much like the scipy library
181:40 - an incredible set of documentation where
181:42 - you can start to dive into particular
181:44 - things that interest you and we're not
181:46 - going to explore this one the way we did
181:47 - sci pi stats
181:48 - pandas also has
181:50 - again kind of this incredible wealth of
181:53 - information about how you can calculate
181:56 - information using data
181:59 - the python statistics library
182:02 - a couple of us were looking at this a
182:03 - few minutes ago there's really only
182:05 - about
182:06 - 10 or 12 different types of functions
182:08 - here this is more the
182:11 - uh
182:12 - the meat and potatoes kind of things
182:13 - that you're most regularly and
182:14 - frequently might use this does not get
182:17 - into any of the details like sci-fi
182:18 - stats and and numpy and stuff will allow
182:20 - you um but it's there and you don't have
182:22 - to import it you don't have the weight
182:24 - of importing a lot of things from
182:25 - third-party libraries so this is still
182:27 - useful for the things that show up most
182:28 - frequently
182:30 - all right so with that
182:33 - so that was our field trip
182:38 - i mentioned this idea of these discrete
182:40 - probability distributions you go home
182:43 - you start to wrap your head around that
182:45 - one of the really cool things that you
182:46 - can do once you have a good
182:48 - understanding of a discrete probability
182:50 - distribution
182:51 - is that you can apply what we call
182:53 - transforms
182:55 - in order to get to kind of this point
182:58 - i had to multiply certain things by
183:00 - hey this this is the probability that
183:02 - something's going to happen or this is
183:04 - the gains and the losses et cetera well
183:06 - what if
183:07 - my slot machine owner says hey we're
183:09 - going to upgrade your slot machine and
183:10 - it's no longer going to be four bucks if
183:12 - you win this but everything is going to
183:14 - be increased by a quarter you'll earn
183:16 - four dollars and a quarter three dollars
183:18 - and a quarter um instead of having to go
183:20 - back and redo this these transforms will
183:22 - allow me if you guys study up on this to
183:25 - very simply
183:27 - reevaluate my variances without having
183:29 - to do a lot of crazy math so that's
183:30 - pretty cool
183:32 - um so you'll want to research
183:34 - transforms
183:36 - on discrete probability functions
183:39 - so we've got 10 minutes i'm going to
183:40 - walk you through combinations and
183:42 - permutations with a sprinkling of
183:44 - factorials
183:46 - if you recall a few minutes ago
183:49 - i said hey look at this
183:51 - if i get an apple an apple and an orange
183:56 - i'm going to win something
183:58 - but i also illuminated the fact that it
184:01 - really really wasn't
184:03 - just apple apple orange it was any order
184:06 - of apple apple orange so i get orange
184:08 - and then an apple on the second wheel
184:10 - apple on the third wheel
184:12 - and when i calculated the probabilities
184:14 - for this i took that into account so i
184:16 - got apple apple orange plus apple orange
184:19 - apple plus orange apple apple say that
184:22 - three times quickly
184:24 - um
184:25 - this was easy because it was only three
184:27 - things i only had like kind of three
184:29 - combinations of this
184:30 - or three arrangements of it sorry it's
184:32 - probably a better term
184:35 - but what if i had lots of things
184:37 - and i had all sorts of arrangements
184:39 - is there a way to do that mathematically
184:41 - and do it easier that's where factorials
184:44 - combinations and permutations come into
184:46 - play
184:47 - all right
184:49 - we'll start off with factorials
184:52 - you might have seen this button on your
184:53 - calculator never known what it does
184:54 - there's often on calculators a button
184:57 - that will have something like x with an
184:58 - exclamation or an n with an exclamation
185:01 - that represents a factorial and what a
185:03 - factorial is is simply
185:05 - i will take whatever number you give me
185:06 - and multiply it by all the things that
185:09 - are decremented down by ones so a 2
185:11 - factorial
185:13 - is 2 times 1 a 4 factorial is 4 times 3
185:16 - times 2 times 1
185:19 - 10 factorial is spelled out
185:23 - it's a nice way
185:24 - of
185:26 - very simply creating
185:27 - very large numbers
185:30 - that are composed of things
185:33 - you might say well what kind of use
185:35 - would this be
185:36 - let's say that i have
185:39 - four books for example
185:42 - um and i want to put them on my
185:43 - bookshelf and i'm kind of particular
185:44 - about what order i put them in with the
185:46 - four books in my hand i could pick my
185:48 - first book i have four choices and i
185:50 - throw the first book down how many
185:52 - choices do i now have left in my hand
185:56 - i have four books to start with and i
185:58 - put one on the shelf how many choices do
186:00 - i have left how many books do i have
186:00 - left in my hand
186:02 - three
186:03 - so now i pick one out of the three and i
186:05 - put that on there how many choices do i
186:07 - have left in my hand
186:08 - two right so these factorials are often
186:11 - used in these kind of things we need to
186:12 - organize and arrange things
186:15 - if i have a bunch of horses and they're
186:16 - in a horse race
186:18 - by the way chalmers not a gambler but
186:19 - yes say i have horses and they're in
186:21 - horse race
186:22 - i have 20 horses
186:24 - which horse could come first have 20
186:26 - options which horse could then come in
186:28 - second i only have 19 options which
186:30 - horse could come in third i only have 18
186:32 - more options right so that's where
186:34 - factorials come into play
186:36 - a great thing about factorials is that
186:38 - if i have to do division of one
186:40 - factorial by another it's pretty easy
186:43 - because
186:44 - three times two times one over three
186:45 - times these cross out and i'm just left
186:47 - with five times four so it makes the
186:50 - math pretty pretty straightforward
186:52 - um
186:54 - i've got a little function here we'll
186:56 - calculate this calculate that
186:58 - and so
186:59 - i'll let you figure out the details of
187:01 - the function but i've got a function
187:02 - that will calculate factorials for us
187:05 - i want to highlight
187:08 - in vivid terms what i meant by chalmers
187:11 - code sucks and other code is better
187:13 - by looking at a real-world solution
187:16 - the calculation of factorials looks like
187:18 - it's pretty straightforward
187:20 - but
187:22 - there's a lot going on to the hood
187:24 - for example if you're on a 32-bit piece
187:27 - of hardware
187:29 - the size of an integer maxes out at
187:31 - about 12 factorial if you're on 64-bit
187:34 - hardware it maxes out around 20
187:36 - factorial maybe your computer might want
187:39 - to build or calculate something larger
187:40 - than that so you might use floating
187:42 - point approximations or representations
187:44 - of those values and that will nudge you
187:46 - a little bit past those points
187:48 - or maybe in terms of speed
187:51 - you don't want to calculate
187:54 - 40 times 39 times 38 you might want to
187:56 - have a lookup table for certain low
187:58 - level factorials and then do the
188:00 - calculations on higher ones
188:03 - or you may not want to do the
188:04 - calculations at all so you might use an
188:06 - approximation like sterling's formula to
188:08 - figure this out
188:09 - so real world functions not chalmers
188:12 - will do things to help improve the speed
188:14 - or the reliability of it
188:16 - and i just want to show you what we mean
188:17 - by the speed of
188:18 - it so i created a factorial function we
188:21 - just looked at it a second ago but there
188:23 - is actually in python's math library
188:26 - a function called factorial and i'm
188:27 - going to import it as f so that the two
188:29 - names don't don't overwrite each other
188:31 - and if i calculate the factorial of four
188:34 - it's going to give me back some number
188:37 - and so let's go look at that make sure
188:38 - we get something back
188:40 - we get 24.
188:43 - returns 24 as expected there we go
188:47 - if you've never used jupiter to do this
188:48 - it's kind of fun
188:50 - there is the ability to time certain um
188:55 - statements or expressions etc in in
188:57 - python so i'm going to say use chalmers
189:00 - factorial function and calculate 40
189:02 - factorial and time it and show us how
189:05 - long it takes to do this and then we'll
189:07 - use
189:08 - the library in or the function in the
189:10 - math library and we'll see how well it
189:11 - works
189:12 - so we'll run that
189:14 - the time it functions kind of cool
189:16 - it will run this multiple times and
189:19 - every time it runs it it will do it some
189:21 - number of times like a hundred thousand
189:23 - times
189:24 - so it took
189:25 - about seven micro seconds to do it with
189:28 - chalmers crappy homegrown code
189:34 - and it took
189:36 - 300 nanoseconds
189:39 - to do it
189:40 - with legit code that is really good at
189:42 - this and optimized for this right that
189:45 - is a massive difference like a thousand
189:47 - times difference right something like
189:48 - that
189:49 - or ten times difference whatever it is
189:51 - math is not my thing
189:53 - don't trust me for your maths all right
189:56 - three seconds or three minutes to go
189:58 - good grief
190:01 - we'll talk about permutations
190:02 - combinations and products
190:06 - um
190:13 - with permutations
190:16 - we will look at how we can arrange
190:18 - things for example
190:20 - how many ways can i arrange four out of
190:22 - five books on my shelf got five books i
190:25 - only have room for four let me figure
190:27 - out which four i want to pick
190:29 - or
190:30 - if i know that i care about three of the
190:32 - ten horses that win because i'm going to
190:34 - bet on three of them
190:36 - how many different options are there
190:38 - that three will cross the finish line
190:39 - right
190:41 - combinations on the other hand
190:44 - are things where
190:46 - we don't have to worry about the order
190:49 - of them with the horses right if if
190:51 - sally blue finishes in front of you know
190:53 - denver dan
190:55 - versus denver dan finishing first the
190:56 - order was crazy important with that
190:57 - permutation
190:59 - but with combinations order doesn't
191:00 - matter
191:01 - what did you have in your salad i had
191:03 - walnuts i had romaine lettuce maybe i
191:05 - didn't have iceberg
191:07 - had croutons the order doesn't matter if
191:10 - i said croutons and iceberg lettuce it
191:12 - doesn't matter
191:14 - products are a lot like permutations
191:17 - but
191:19 - you not only care about the order but
191:20 - you start to replace things
191:23 - so for example i pull a ball out of a
191:25 - lottery cage i read the ball i throw the
191:26 - ball back in and i have the chance of
191:28 - pulling that same ball out again but the
191:30 - order of the numbers matters and then
191:32 - combinations with replacements it's the
191:34 - same as combinations but i put stuff
191:36 - back in the pool so i got a handy little
191:38 - chart here do i replace stuff yes or no
191:41 - with those books i couldn't replace them
191:43 - because i only have one copy of each
191:44 - book
191:45 - um
191:46 - with the lottery balls i could put the
191:47 - lottery ball back in the in the in the
191:49 - bucket right order matters order doesn't
191:51 - matter
191:56 - right so we can calculate permutations
191:58 - combinations products
192:00 - and stuff
192:03 - one thing that i'll leave you guys with
192:04 - and then we're pretty much done
192:07 - again rolling your own not so good
192:10 - there is
192:12 - a library called intertools that has a
192:14 - function built in to do each of these
192:16 - and real quick we'll look i have three
192:18 - things
192:19 - i want to figure out kind of groupings
192:22 - or arrangements of them two at a time
192:26 - when
192:27 - order doesn't matter i only have three
192:29 - possible arrangements but if order does
192:31 - matter
192:32 - did one come before two or did two
192:35 - come in front of one
192:37 - et cetera
192:38 - all right i'll skip all of that
192:41 - there we go
192:42 - and those are the links to all the
192:44 - libraries
192:45 - you folks have been amazingly patient
192:47 - through the day
192:49 - brains are all fried by now i'm sure
192:52 - i'm glad you came
192:54 - i appreciate any feedback i will get a
192:57 - survey link up on
192:59 - the screen here
193:01 - i
193:02 - urge you to go to
193:04 - this particular location and give me
193:06 - feedback because feedback is something
193:08 - that
193:09 - i need
193:11 - so
193:12 - let's see
193:14 - www.surveymonkey.com
193:20 - and if i remember right i think
193:22 - surveymonkey's done in python
193:25 - all right and this is a capital hk
193:28 - 8 2
193:30 - 6
193:31 - 8.
193:33 - let me make sure i got this right
193:34 - surveymonkey.com
193:36 - r
193:37 - h g k
193:38 - 8 2 6 8.
193:41 - all right
193:42 - um
193:44 - if you guys need to get a hold of me
193:46 - i've sent you guys some emails and they
193:47 - have like my twitter handle in them you
193:48 - can reach out to me that way
193:50 - my email is there you can reach out to
193:52 - me if you want to ask questions
193:54 - please please fill out the survey
193:56 - that'll help me be better
193:58 - and i appreciate your time glad you came
194:00 - thank you
194:02 - [Applause]