00:00 - welcome to this comprehensive video
00:01 - course on MIM cached an inmemory caching
00:05 - system known for its Simplicity and
00:08 - Effectiveness in reducing database load
00:11 - in this course Hussein will teach you
00:13 - about MC's architecture and design
00:16 - choices and he'll conclude with a
00:18 - Hands-On demo using Docker and telnet
00:21 - get ready to deepen your understanding
00:24 - of this transient cache system mimc D is
00:28 - a simple inmemory key e Value Store
00:32 - written in c h it was originally I think
00:34 - written in Pearl and then Rewritten in C
00:37 - this is what back in 2003 so it's been a
00:41 - while and it has been popular with
00:44 - companies such as Facebook Netflix
00:46 - Wikipedia Facebook I think pushed it to
00:49 - its limit you know and the most uh and
00:53 - the reason it's why popular is because
00:56 - of its Simplicity and we're going to
00:58 - talk about that I know we throw the word
01:00 - simple a lot these days but MIM casd is
01:03 - truly simple I
01:06 - mean if you're looking for advanced
01:08 - features it's not here it was designed
01:11 - to be simple solve the problems of the
01:14 - web back in 2003 which is we want to
01:17 - help alleviate the queries to the
01:19 - database we're we're you know the
01:22 - databases are taking a hit you know so
01:24 - let's cash things although I usually do
01:27 - not agree with having a cash to solve a
01:32 - slow query because I think personally I
01:35 - think it's a cop out you know to to just
01:37 - add a cash when you have a slow query
01:39 - you have to understand why it's slow you
01:41 - have to understand why it exactly taking
01:44 - time why there are a lot of logic reads
01:47 - and how to minimize it and that's
01:49 - another story for another day but
01:51 - sometimes you need a cash of course
01:52 - right and then MIM casd was born right
01:55 - of course there are alternatives such as
01:57 - redus I made a video about it but this
01:59 - this video is to is a crash course of
02:03 - mhd we're going to dive into the agenda
02:06 - here you're watching this on YouTube
02:08 - there will be uh chapters where you can
02:11 - jump into the interesting part of the
02:13 - things but it's an inmemory database
02:15 - we're going to talk about memory
02:17 - management you might say why well we're
02:20 - going to find out memory management is
02:21 - not easy at all you know it's not just
02:24 - like hey just throw things in memory and
02:26 - then read it it's a little bit more
02:28 - complicated than that going talk about
02:29 - the Ario the least recently used uh
02:32 - which was designed to
02:35 - avoid growing the memory of this
02:38 - instance unlimitedly right CU you have
02:41 - to have a some sort of a a mechanism to
02:45 - evi all entries that has been never used
02:49 - that's why you cannot really rely on MIM
02:51 - cash D to have a value always there it
02:54 - was never the goal of this cash right
02:59 - unlike Reddit right is if you if you
03:00 - store something is going to be there and
03:02 - you told it to be there forever it's
03:04 - going to stay forever it will make sure
03:06 - to stay forever MIM casd does not
03:08 - guarantee that and you can argue that
03:10 - this is actually a feature and you can
03:11 - argue that this is something you don't
03:13 - want you know
03:15 - so tread
03:17 - lightly thread we're going to talk about
03:19 - the threading model cuz you have to have
03:21 - multiple threads if you want to serve a
03:24 - lot a lot a lot of clients with a lot a
03:27 - lot a lot of TCP connection connected to
03:29 - this thing read and WR we're going to go
03:31 - through examples of a read example for
03:33 - the write and okay kind of uh open the
03:37 - hood and look what is inside this
03:40 - beautiful
03:41 - thing locking model obviously uh two
03:45 - people trying to write in the same item
03:48 - it's not as advanced as acid obviously
03:51 - where you have isolation levels now it's
03:54 - a serialized model where we try not to
03:58 - have two people read the thing item at
04:00 - the same time or write uh the same item
04:02 - at the same time so locking and we're
04:04 - going to talk about the old model and
04:06 - the new model that's where you really
04:09 - try to understand what how things are
04:12 - built is completely different from the
04:14 - way we explain it distributed cach I
04:16 - know they say it's a distributed cach
04:18 - but I kind of don't like to say that
04:21 - because in itself MIM casd is not
04:24 - distributed it's just when you spin up a
04:26 - m casd instance three M casd instance
04:29 - they don't know about each other and
04:30 - they will never be right the client is
04:33 - responsible for the distribution so I
04:35 - kind of reluctant to say it's a
04:36 - distributed cash I know people call it a
04:38 - distributed cach I don't like to do that
04:40 - but hey it is a distributed cache if you
04:44 - if you if you put the distribution at
04:45 - the client side and I think this is part
04:48 - of the beautiful simple design they
04:52 - they on purpose they didn't make it
04:54 - distributed to make it simple and then
04:56 - we're going to go through a demo we're
04:58 - going to use Docker because you can spin
05:00 - up a lot of instances in in Docker
05:03 - really easily let's do that so in memory
05:07 - key value St what's that really uh we're
05:09 - going to talk about some terminology
05:11 - here specific to mkd an item that's what
05:14 - they call it an item is really what
05:17 - consist of a key and a value a key is
05:19 - usually should be unique right and a
05:21 - value could be literally anything a key
05:25 - has to be a string and it maxed out at
05:28 - 250 character you can see the limits
05:30 - right that's why I think uh redis kind
05:33 - of won the cash game when it comes to
05:36 - this thing because MIM Cas has a lot of
05:38 - limits and uh this kind of uh you know
05:43 - crippled some people from using this
05:46 - cache because of these limits right but
05:48 - you can Ario also the Simplicity of this
05:51 - design and if you can work around the
05:53 - the design to use MIM
05:56 - casd it it's actually pretty nice right
06:00 - when when they key as a strength they
06:02 - did that for a Simplicity reason to
06:05 - right if if you support like dates uh or
06:08 - or I don't know like blobs as Keys then
06:10 - Things become really complicated and
06:12 - there shows in the architecture and if
06:15 - there is a bug it's really hard to track
06:18 - down right and the value can be any type
06:21 - h it's by default one megabyte again
06:24 - another limitation in MIM casd yeah you
06:27 - can see that I I talk about limitation
06:29 - but these limitations technically to me
06:31 - I I see them as features you know
06:34 - because they didn't claim to be like the
06:36 - best in the world they said hey we are
06:38 - designed to be simple and I appreciate
06:40 - and I completely love that you know when
06:44 - you say I want to build something simple
06:47 - the simple thing has limitations right
06:49 - the simple thing will by Design have
06:52 - limitation when you look at the big
06:54 - picture right it's not going to have
06:56 - like tons of features right so yeah you
06:59 - can configure this to to increase it but
07:01 - again it's not really a good idea all
07:03 - the time uh Keys have exploration date
07:05 - ttls right time to Liv and uh even that
07:09 - don't rely on that right even if you put
07:11 - like a key that has like a 1 hour and
07:14 - your memory is filled the lru will can
07:17 - kick in and if you never use that key
07:20 - it's going to get affected and they tell
07:21 - you that right hey mkd is a transad
07:25 - we're not going to make sure that it's
07:27 - actually persisted it's not supposed to
07:30 - be that
07:31 - right again always go back to the the
07:34 - requirements here they never meant right
07:37 - for this to be a persisted cash forever
07:40 - right you don't rely on that you kind of
07:44 - use it to help you avoid expensive
07:47 - queries but yeah be ready at any time
07:50 - that this value is not going to be there
07:51 - everything is stored in memory right
07:54 - that's why it done cash MIM Cas D again
07:56 - don't confuse MIM Cas D with MIM Cas DB
07:59 - that's a completely different project
08:01 - and I think it's abandoned since 2019
08:04 - 2009 right but yeah m casd is still
08:06 - going and Facebook and I think Mark
08:10 - Zucker give a presentation about M casd
08:12 - as well at some point how they tuned it
08:15 - to its maximal values let's talk about
08:18 - memory management here's the memory
08:20 - right when you allocate items you know
08:22 - when you say hey I want to allocate an
08:24 - array and iate an integer and I want
08:26 - tocate a here's a block of M you know
08:30 - these items that you allocate and even
08:33 - you new program today they going to go
08:35 - in random places now they yes the
08:38 - process has a dedicated memory area but
08:41 - when you allocate these things go random
08:43 - so the grain is allocated they're going
08:45 - to go to random places right yeah
08:48 - initially they might be consequent but
08:51 - as you uh remove and free items you're
08:54 - going to end up with these gaps so you
08:56 - might say what's wrong with these gaps
08:58 - the problem is like this this is called
08:59 - the fragmentation what's wrong with
09:01 - fragmentation well you're going to have
09:03 - like a little bit of few bytes here few
09:05 - bytes here few bytes here few here but
09:07 - if you want like a big bulk of memory
09:10 - location consent like you want one Meg
09:13 - you have one Meg but it's fragmented and
09:16 - guess what if it's fragmented you cannot
09:18 - use it you cannot just allocate here oh
09:20 - my part and then part here and this part
09:22 - here I think that the operating system
09:25 - allows you to do that maybe but then it
09:27 - will it will crash left and right to
09:30 - collect what you have right we had the
09:32 - same problem with hard drive I guess
09:35 - right back in the days with
09:37 - fragmentation where the the seek you
09:39 - know the the needle has to to go
09:42 - multiple places to fit your files
09:44 - because it's a circle right this this
09:47 - desk and has the if if you store a file
09:50 - and you start editing the file the files
09:52 - will go to multiple sectors and to read
09:55 - that file back you have to go sector one
09:58 - sector two
09:59 - this was supposed to be like a rotating
10:02 - disc I failed miserably but you get
10:05 - point right so memory fragmentation is
10:07 - bad we try to avoid it right new items
10:09 - can can no longer fit so what what did
10:11 - they do so me casd at least what they
10:13 - did is they allocate pages instead even
10:19 - if they don't use it they say hey when
10:21 - you
10:22 - start I look at the whole page one Meg
10:25 - again that's that's the design right
10:29 - that that's the reason why we have one
10:31 - value up to one megabyte you cannot go
10:33 - beyond that so they say hey let's start
10:35 - with one Meg so if they allocate they
10:37 - allocate at one Meg the whole thing they
10:39 - don't use it technically to the
10:42 - operating system you the cash has used 1
10:46 - Megabyte it doesn't know it right that
10:48 - it's not actively using it that client
10:52 - us connecting to M casd we're not
10:54 - probably we're using like part of that
10:56 - memory does that make sense but this
10:58 - avoids frag M mentation right cuzz now
11:01 - all of this just one big page with a lot
11:04 - of empty space right but it is
11:07 - elated and then there is this idea of
11:09 - chunks right so the pages are broken
11:13 - down into equal size of they call chunk
11:17 - so um keep these in mind the terminology
11:20 - in mind the chunk is a fix size and what
11:23 - determines the chunk size is actually
11:25 - something called a slab class right and
11:28 - the slab is think of a slab every time I
11:31 - hear the word slab I remember Dark Souls
11:33 - you know it's a video game where you
11:35 - have the last item that you require in
11:38 - order to upgrade your weapon it's called
11:40 - a titanite slab where it's say like
11:43 - really large rock that you use in order
11:47 - to upgrade your weapon it's a it's it's
11:49 - basically a a a big thing a slab of meat
11:52 - they say right it's just a big thing
11:54 - that's what it means so this idea of
11:56 - slab and slab classes will always show
11:58 - up up here so it's like a b big portion
12:02 - of memory a slab class is what define
12:05 - the chunk size right so there is there
12:07 - will be a slab class of 40 bytes there
12:10 - will be a slab class of a one Meg so the
12:13 - chunk sizes will be 44 bytes right and
12:17 - the chunk sizes for a slab class of that
12:20 - type is one Meg so we're going to show
12:22 - an example to cons to to show that of
12:24 - stuff and the pages consist of fixed
12:26 - chunk size right items are in chunks
12:29 - here's the a very important item so your
12:31 - item will be stored in the chunk your
12:34 - chunk size could be let's say uh 100 BYT
12:37 - right if it's 100 BYT and your item
12:41 - which includes the key and the value is
12:43 - less than 100 you're going to include
12:45 - the whole chunk right so if it's 90 byte
12:48 - you lost 10 byte within that chunk
12:51 - nothing to do about it sorry right
12:53 - that's one limitation here so there
12:56 - there will be a free space a tiny free
12:58 - space in the chunk chunk and obviously
12:59 - each slab class has a fixed chunk size
13:02 - so that's how they are determined it's
13:04 - going to be clear as we go through them
13:06 - obviously avoid memory fragmentation
13:08 - here's an example right so here we have
13:11 - a slab class with a chunk size of 72 at
13:15 - subass one and slab class 43 for example
13:19 - the chunk size is one Meg so you have in
13:22 - a single page right so slap class have
13:25 - multiple pages and sometimes they call
13:28 - them also the is called slabs the word
13:30 - slab in the documentation is so
13:32 - overloaded and I've seen people use it
13:34 - one over the other so I avoid using it
13:37 - the word slap so a slap class and there
13:39 - are pages right so this page in this
13:43 - case we said one Meg right and the
13:45 - chunks are 72 divided that means we have
13:47 - one
13:50 - 14563 chunks per page but each chunk is
13:54 - 72 byte right so if you have an item
13:56 - around 72 byte fits nicely in this right
14:01 - but if your item is larger let's say
14:04 - 900k then oh it doesn't fit this slab
14:07 - class so we need to let's let's find out
14:11 - what is the subass for this item oh
14:13 - subass 42 because the closest one Mig
14:16 - and guess what the
14:17 - one the one Mig
14:20 - class slab class has this entire page is
14:25 - one chunk right so this is really
14:29 - important to understand here right so
14:31 - that's how they allocate memories this
14:33 - we're looking at the internal
14:35 - architecture of M casd here right let's
14:38 - go example new item 40 byte 40 byte the
14:42 - closest thing is this guy right slab
14:44 - class one let's allocate memory and then
14:47 - Boop no we don't allocate memory that
14:49 - this memory is already allocated right
14:52 - we just store the item right in this
14:56 - chunk and then we start adding pointers
14:58 - and stuff stuff like that here so now
15:00 - our item is right here we're going to
15:03 - talk about the hash table and stuff like
15:05 - that but this is just again memory
15:06 - management let's say I have a new item
15:09 - 900k oh this fits right here so one big
15:12 - chunk in one page right so that's
15:15 - interesting let's say another new item
15:18 - 40 byte but guess what slab slab class
15:22 - one because that's the what the chunk
15:25 - size is fits it nicely but guess what we
15:28 - have two pages they're all completely
15:32 - full so I cannot insert this what do we
15:35 - do create a brand new page put that
15:38 - thing here does that make sense so we
15:41 - allocate the new page and when you go to
15:43 - the demo we're going to see all this
15:44 - stuff right we're going to do a stats
15:46 - and see like oh how number of pages
15:48 - allocated is this right so it's just I I
15:51 - absolutely love how they did this it's
15:53 - interesting obviously doesn't doesn't
15:55 - have limitation of course but you're
15:57 - going to see that depends on the sizes
15:59 - of the item you say and once you really
16:02 - understand how things work you you can
16:06 - architect your application specifically
16:08 - the back end here frontend doesn't
16:10 - really talk to M casd at all right the
16:13 - back end here can be architected so that
16:15 - you can choose the perfect items right
16:19 - to fit this entire thing right you're
16:22 - not going to just choose hophazardly
16:24 - right that's how you know your craft
16:27 - effectively all right let's get to the
16:29 - meat lru least recently used you know
16:34 - the main problem with memory is it's
16:37 - limited you know and even if MIM casd
16:40 - allocated certain amount of memory if
16:42 - you store a lot a lot a lot of keys even
16:45 - with good expiration date memory can get
16:48 - full what do you do do you
16:51 - block new
16:53 - inserts I would say that's that's one
16:56 - feature that you can add I suppose
16:59 - but but mimk they don't allow you to do
17:02 - it they won't let you go to that state
17:04 - you if the memory is be about to be full
17:09 - then anything that hasn't been used for
17:11 - a very long time they will release it
17:15 - that's another reason where REM Cas D is
17:17 - a transient memory it do not rely on a
17:21 - key even if you said the expire for an
17:23 - hour do not rely to that key to be to be
17:26 - there in an hour it can go any any time
17:29 - right that's another limitation that's
17:31 - another feature right I say limitation
17:35 - and a feature at the same time because
17:36 - it is it is a feature right and it's to
17:39 - some people it's a limitation and how do
17:41 - they do that right they use something
17:43 - called the link List have you ever heard
17:46 - about this before and 20 years ago 21
17:49 - years ago uh in the University I took a
17:52 - course and the Cs CS 101 they talked
17:56 - about link list and that is pretty much
17:58 - the the only time in my entire
18:00 - professional career I ever used a link
18:03 - list that's probably I'm not saying
18:05 - that's just the case with my the
18:07 - application I wrote is all high level
18:09 - languages I never had to write a
18:11 - database or a m cache you know so I
18:14 - never used the link list right so
18:16 - doesn't doesn't mean that it's it's a
18:18 - useless structure but it is it's a
18:21 - important data structure why cu the
18:25 - least recently used is a link list
18:27 - there's a head and there's a tail and
18:30 - every item is linked to each other so if
18:33 - all these items that you add are the in
18:36 - this architecture right they are in the
18:38 - link class and there is every slap class
18:40 - has its own lru right so if I for
18:44 - example access an item that happens to
18:46 - be in the tail it will be popped and go
18:48 - back to the head so there is a cost to
18:51 - accessing an item there is a cost there
18:54 - is a cost of removing this chain put it
18:57 - that back pull the head to this pull
19:00 - this guy to this guy pull this guy to
19:01 - this guy that's how you do linkless
19:03 - right so every time you access an item
19:06 - it goes back to the head so items that
19:09 - are not used they will automatically be
19:12 - pushed down to the tail and if the
19:14 - memory is Out Of Reach basically these
19:17 - items will be removed from the tail but
19:21 - also another thing with with this link
19:23 - list is like with threads if you with
19:26 - which MD is is multi-threaded app how
19:30 - can you have multiple threads read at
19:32 - the same items right you can't you have
19:35 - to lock this structure you know if
19:38 - people who done multi-threading you have
19:40 - to you have to lock it right and the
19:42 - moment you do locking if you if you know
19:44 - about something about databases which I
19:47 - a course on database engineering check
19:49 - out check it out it's actually right
19:51 - here database. husin as.com I talk about
19:54 - all this stuff you know in details in
19:57 - fundamental details you know so don't
19:59 - expect like SQL syntaxes in my courses
20:01 - not like that I talk about fundamentals
20:04 - which which should then build up and see
20:07 - how the client is built out right but
20:10 - yeah locks is a very critical concept
20:12 - here you have to lock it to avoid this
20:15 - you know mutation you know corruption
20:18 - right but yeah it's a cost and there's
20:21 - an a you CLW crawler and a demon that
20:24 - does the cash inection from the tail
20:26 - right and again every time it kicks out
20:28 - have to lock and then if it's locked
20:30 - people cannot read people threads cannot
20:33 - read and if threads cannot read latency
20:37 - right block
20:39 - slow right all of this you got to
20:42 - understand when things happen this is
20:44 - why and I'm going to share my opinion
20:46 - about the lru right and I think this is
20:50 - a good time by the way there is an L
20:52 - cache per slab class I think I mentioned
20:54 - that so the one Meg slab class right
20:57 - which has like pages of one Meg and the
20:59 - chunk sizes of one Meg has its own laru
21:02 - and each other sub slab class has its
21:04 - own L by the way I don't make I'm not
21:06 - making any of this up I'm I had to read
21:10 - frankly maybe 20 different documents to
21:12 - collect this information and and kind of
21:14 - present it in a summarized manner here
21:16 - right because there is no one dog to
21:18 - explain all that unfortunately right
21:20 - it's it's not incomplete unfortunately
21:22 - that's what I noticed and
21:25 - outdated so my opinion about the lru in
21:28 - my in my personal humble opinion is I
21:32 - wish MIM casd actually disa this by
21:35 - default you know L is a feature right
21:40 - and they the reason they added it
21:42 - because memory is limited especially
21:43 - back in 2003 when they first built this
21:46 - thing memory was so scarce or scarce is
21:50 - it scarce or scarce scarce right it's
21:52 - very limited and when you do that you
21:55 - don't want to run out of memory right so
21:58 - if you allocate certain amount of memory
21:59 - for M casd it can easily run out right
22:02 - if you have a lot of keys so how do you
22:04 - manage that they say hey we're going to
22:06 - remove we're going to build an
22:08 - laru least recently items K get kicked
22:11 - out from my memory that's a fine but I
22:15 - wish they disabled that by default or
22:17 - give us an option to disable it because
22:19 - the overhead of managing AIO and you can
22:22 - see from the papers I'm going to
22:23 - reference is so large the locks that
22:27 - they have to maintain slows down
22:29 - throughput right and comp and complicate
22:32 - the application so I think they stuck
22:37 - whoever built this 20 in 2003 MIM casd
22:40 - Brad Fitzpatrick who is the original
22:42 - developer of MIM casd he built this for
22:44 - his website live Journal you know I wish
22:48 - he disabled this by default I really
22:50 - wish because his original design is so
22:53 - simple and so elegant I absolutely love
22:56 - it you know you build something so
22:58 - simple with its featur stripped there
23:01 - are no much features
23:03 - U made it not simple unfortunately yeah
23:07 - cool have this a feature but disabled by
23:10 - by
23:11 - default or have an option to disable I
23:14 - don't know if there's an option to
23:15 - disable maybe there is but hey I want to
23:18 - take the responsibility as a client
23:21 - right if I'm going to allocate certain
23:23 - amount of memory cuz I'm responsible I'm
23:24 - going to give uh MIM cash D 5 gig 10 gig
23:29 - and my application is smart enough to
23:33 - know to set expiry date right for this
23:36 - item and yeah if I'm going to get errors
23:38 - if it's failed out it's on me I want to
23:41 - delete an items I want to do this
23:42 - management this
23:45 - way for 95% of the users who want simple
23:50 - things they're going to get it l are you
23:52 - in my personal opinion again this is
23:54 - just my personal opinion you can agree
23:56 - or disagree I think you should this this
23:58 - should have been disabled because now
24:01 - they they created a new lru which is
24:03 - like has hot and warm and cold and and
24:07 - they move stuff around because they have
24:08 - a lot of problems with lru like moving
24:11 - stuff around all the time is so
24:13 - expensive you know so it it has a cost
24:17 - so let us just how about eh give me an
24:21 - option not to use it and go back to a
24:24 - simple model of course I I don't I don't
24:27 - mind if two items two users trying to
24:29 - access the same two threads trying to
24:31 - access the same item at the same time
24:33 - let them be serialized that's fine right
24:36 - but lru as a whole thing I think it's a
24:38 - it's just to me over engineering that's
24:41 - just my opinion you can disagree here is
24:43 - how it looks like by the way aot you in
24:45 - the big picture again this is all
24:46 - drawings I made it uh I could be wrong
24:50 - in small details because I don't I don't
24:53 - know the actual architecture so this is
24:54 - I derive this from reading the source
24:56 - code and the doc so this is how it looks
25:00 - like so this is this is where we talk
25:01 - about the pages right and the chunks so
25:03 - the chunks or the items is what being
25:07 - lru right so the head is right here and
25:10 - this is linked to this item this is link
25:12 - to this item this link to this item this
25:14 - this is the tail so this is how it looks
25:16 - like every item here is actually linked
25:20 - to the next to the one next to it right
25:23 - this is think this of this as a snapshot
25:26 - after many many usages right gets and
25:29 - red that so so things will move to the
25:32 - head and the tail obviously I didn't
25:34 - draw every particular thing because it's
25:36 - going to be a mess of a drawing but you
25:38 - get the point right that's that that's
25:40 - how the L you and you can see how
25:42 - complex things get so let's talk about
25:44 - threading so this is one of my favorite
25:46 - Parts I know uh I absolutely have um I
25:51 - absolutely love networking and if you're
25:53 - interested I have a networking course
25:56 - and and this part is is all about
25:59 - sockets connections the way listeners
26:03 - work the way the TCP connection works I
26:07 - talk this about this in detail in my
26:09 - network course if you're interested go
26:10 - to network. hus n.com learn more about
26:13 - that again network.has nasa.com this URL
26:17 - redirected immediately to UD me with the
26:20 - latest coupon applied so uh you're going
26:23 - to get a discount and you're going to be
26:24 - supporting this channel this work thank
26:26 - you so much there's here's the threading
26:28 - model for uh for mam casd right because
26:32 - it accepts clients it has to have
26:35 - networking right so what they do is they
26:38 - listen on a TCP Port right so that means
26:41 - they support transmission control
26:43 - protocol that's the native transport
26:45 - that they support they also support UDP
26:48 - which I didn't mention here but UDP has
26:51 - been now disabled by default because of
26:53 - an attack that happened 4 years ago 2018
26:56 - uh reflection attack actually right with
26:59 - with MIM casd public servers so it was
27:02 - the cloud flare actually reported that
27:04 - so UDP has been disabled by default but
27:06 - yeah you can use it if you want but yeah
27:07 - let's stick with TCP right now TCP Port
27:11 - 11211 and there is a listener thread so
27:14 - one spin up listener one thread that
27:18 - spins up it listen to Port 11211 so that
27:21 - creates a socket right in the operating
27:23 - system speak right and that basically
27:26 - creates its own accept Q it's on syn Q
27:30 - this is how the application start
27:33 - accepting connection right so
27:36 - everything every single connection that
27:38 - is happening The Listener thread will
27:42 - accept it so there is a loop infinite
27:44 - Loop here literally all application has
27:47 - this Loop where it's constantly
27:48 - accepting uh connections one thread
27:52 - right so all the connections goes to
27:55 - this thread so once it accept the
27:58 - connection it gets the file descriptor
28:00 - we call it right which actually
28:01 - represents the connection and now what
28:04 - what mimk does is spins up a new thread
28:08 - gives that file descriptor to that
28:10 - thread now if a stream of data if a
28:15 - request to get a
28:16 - key was sent to this connection it will
28:20 - the operating system knows to send it to
28:22 - this thread well technically what
28:24 - happens is the thread pulls the
28:27 - descriptor right this is now this thre
28:29 - is responsible for this connection This
28:32 - Thread is responsible for this
28:33 - connection This Thread is responsible
28:34 - for this connection so you can see
28:37 - that now this model just blows up right
28:40 - if a one connection PA of thread if you
28:42 - have so many connections you can R run
28:45 - out of threads right or that kind also
28:48 - blows your memory and CPU so be careful
28:51 - with that as well I think they put a
28:53 - limit number of connections M casd I
28:55 - might be wrong there but yeah so this is
28:57 - basically explains all of that now the
28:59 - moment you have threading now the beauty
29:02 - here is you don't have bottleneck right
29:05 - if you have one thread that is
29:07 - responsible for all the connections and
29:09 - listening you you will be blocked right
29:13 - one user will send a key and then
29:14 - another user will send a key they won't
29:16 - be served right they have to be
29:18 - serialized because there's one thread
29:21 - actually executing them one by one right
29:23 - but here if one user executes a sends a
29:26 - key request to get a key and this guy
29:28 - want to write they can happen at the
29:30 - same time right this thread will read it
29:32 - and this thread will read it they are
29:34 - different processing this could be in a
29:36 - core this could be in a completely
29:38 - different core that could be also
29:41 - possible versus it's one thread then
29:43 - becomes really a a problem so we had to
29:46 - go with multi- threads what's the
29:48 - problem with that well the problem is
29:51 - these threads will try to access what we
29:53 - call the laru and the items and the
29:56 - memory so everything is shared between
29:59 - all these threads but you can't have two
30:02 - threads right to the same location
30:04 - that's a problem that's why the original
30:08 - design had one Global lock it was
30:12 - serialized so in this case yeah the
30:14 - threads kind of helped with the
30:17 - connection but but you were serialized
30:20 - at the Locking model so nobody can even
30:23 - access two different items has nothing
30:25 - to do with each other they were serious
30:27 - they were locked so one thread has to be
30:29 - served after the other they they fixed
30:32 - that they completely red that now it's a
30:35 - pair item log so if two threads try to
30:38 - access the same item then there will be
30:39 - SSE that's good that's okay I'm okay
30:42 - with that right but yeah if I am
30:44 - accessing item one key number one and
30:47 - then another thre access key number two
30:49 - at the same time they should be served
30:51 - at the same time what there is no reason
30:53 - for locking and the only reason we lock
30:56 - is because we want to update the lru
30:58 - again so there is so much stuff that
31:01 - comes back always to the lru it's like
31:02 - oh really we did we really need an lru
31:05 - why what if we disabled by default right
31:09 - okay that's just me let's go through an
31:11 - example read and this is something we
31:14 - never talked about here which is the
31:16 - hash table if you think about it if you
31:19 - have a key how do you actually find
31:21 - where this key lives right if you think
31:23 - about it you need hash tables so what
31:26 - you do and I talked about hash table in
31:27 - my YouTube channel uh look up hashing
31:31 - and consistent hashing I talk about
31:33 - details hash table is nothing but an
31:35 - associative array it's really just an
31:37 - array and the beauty of an array is if
31:40 - you have an array right let's talk about
31:42 - arrays a little bit if you have an array
31:44 - from an array has to be consecutive if
31:46 - you allocate an array of a thousand
31:49 - elements accessing element number seven
31:52 - access an element number
31:56 - 10243 is biger of one is fast because
31:59 - you know the index once you know the
32:01 - index and you know the head of the array
32:04 - you add the address to the index voila
32:06 - you have the address and the memory of
32:08 - the CPU can immediately go to that
32:10 - location that's the beauty you have an
32:12 - index with hash tables you don't have an
32:15 - index you have a key the trick is to
32:17 - convert the key back to an index that is
32:20 - all what it is a hash table nothing
32:23 - fancy it's just an array so we take that
32:25 - what we do is the do a hash on the key
32:28 - right let's say I'm going to R test key
32:30 - right and then do a hash and then do
32:33 - modul n where n is the size of this
32:35 - array or the hash table right and then
32:38 - you're going to get a value between zero
32:39 - and N minus one I guess right so now
32:42 - okay let's go point it and that's big of
32:45 - one plus the cast of The Hash right now
32:48 - you got here found it now what you do is
32:53 - you're going to get a pointer which
32:55 - takes you to the the page on that
32:59 - specific slab class for that item which
33:02 - is happened to be D in this case that's
33:05 - how a read works so it's a big off one
33:08 - you can argue that this is one read and
33:10 - this is a second read yeah I suppose
33:13 - that works too right I think the the new
33:16 - model have kind of two hash tables if
33:18 - I'm mistaken but I couldn't find detail
33:21 - docs about this so I explain this so I
33:23 - apologies if this is a little bit out of
33:24 - date but this gives you the idea here
33:27 - the new two hashes I think uh they were
33:29 - provided to provide a pair item lock and
33:32 - obviously what happened here is this is
33:35 - the lru you access the item the D is
33:38 - pushed to the head right so now you have
33:40 - a b c d a is now the least recently used
33:44 - item is in the tail and a points to b b
33:46 - points to C C points to D and obviously
33:49 - it's a revers length as well so D point
33:51 - to c c points to B P point to a right so
33:55 - that's how they allot you actually what
33:56 - you if you think about it the the
33:58 - pointers are right here in the item
34:01 - itself right but I drew it this way for
34:03 - Simplicity otherwise it's not readable
34:05 - at all read two this is another example
34:09 - for read I'm going to read Buzz hash the
34:12 - buzz get the N whoa get the item Boop
34:17 - get a c nice now when we get a c the C
34:21 - is pushed to the Head D is slightly
34:23 - pushed and then obviously the allario is
34:25 - updated and that's another lock right
34:27 - you have to do a lock to do that so if
34:30 - buzz and whatever the value before a
34:32 - test was read at the same time they are
34:34 - serialized at the lru level if they
34:38 - belong to the same slab class again this
34:42 - might have change with the new
34:43 - architecture they changed that a little
34:45 - bit so I think that you can you can play
34:48 - with that a little bit but again to
34:50 - update the L you have to you have to
34:52 - kind of acquire a lock so you're going
34:54 - to be serialized right here yeah
34:57 - let's go through a write I'm going to
34:59 - write key new of a value with
35:04 - 44 whopping bites let's do that well to
35:08 - write we need to obviously find the hash
35:11 - right where to write it hash module in
35:14 - get that puppy find where to write it oh
35:18 - happen to be an empty location sure
35:20 - that's good right and now you have
35:22 - questions what if what if I happen to
35:25 - have something that is already written
35:26 - you can you can have collisions and
35:28 - we're going to talk about collisions in
35:29 - a minute right it's a problem of hash
35:32 - tables hash tables are fun and good but
35:34 - the moment they you run into collisions
35:36 - and you want to resize it it falls apart
35:40 - but now I create a new pointer this
35:43 - pointer now I need to allocate a slab
35:46 - class not slab class I need to allocate
35:49 - a a chunk where going to put my item in
35:52 - and that chunk goes into a specific slab
35:54 - class well 44 bytes pick a a slab class
35:57 - right and even the slab classes guys by
36:00 - the way it's not really fixed you can
36:02 - play with those the other configuration
36:04 - called the Chun the chunk Factor growth
36:08 - size I'm not going to mention it here
36:10 - it's just going to make the course a
36:12 - little bit longer but you you get the
36:14 - point there are so many tweaking you can
36:16 - play with right tweak these chunk sizes
36:18 - but yeah I look at a new memory location
36:21 - in this specific page in an empty page
36:24 - in a fit a fitting chunk right because
36:27 - you want to pick a chunk that is almost
36:30 - fits right in the chunk right not too
36:33 - small obviously cannot be larger than
36:36 - the chunk SI I have to fit right into it
36:38 - right but then that's the the that's
36:40 - what the what MIM casy does all right
36:44 - let's spice things up let's say I'm
36:46 - going to write a key called Nanny which
36:48 - is a new key I don't have it before and
36:51 - value 44 but it happened to clash with
36:54 - another existing key because that's
36:58 - hashes always do that right so when you
37:00 - do that you hash Nan and happen to be
37:03 - fitting on a entry that already have a
37:07 - pointer what do we do do we overwrite it
37:10 - no what they did is this is called a
37:12 - bucket by the way right they add more
37:15 - item to the bucket you know we have one
37:17 - item let's call it I don't know test or
37:20 - something all right and then we have
37:21 - Nani which fits right in the same bucket
37:26 - what we do is just we make it into a
37:28 - chain this chain of buckets right
37:31 - actually one bucket with two items I
37:33 - don't know right whatever the
37:34 - terminology doesn't really matter you
37:36 - just read to understand let's turn back
37:39 - the laser here and yeah we're going to
37:41 - add it here and then just do the pointer
37:45 - and do the do your thing now obviously
37:48 - we need to talk about a collision what
37:50 - happen to Collision I want to read the
37:53 - keani right go here hash it obviously go
37:57 - here oh we have two which one
38:02 - Ah that's the cost you have to go one by
38:06 - one through all of them right why
38:08 - because now we have a hash you don't
38:10 - know one of which one of these are
38:12 - actually Nanny what you do is read the
38:15 - first one right check it compare the key
38:19 - oh because if you go to the item you're
38:21 - going to find the actual key right
38:23 - that's stored here so you're going to
38:25 - find it and say oh that's not 90 that's
38:27 - something else right let's go through
38:29 - the bucket go to the next one there you
38:32 - go that's my item
38:34 - so here is a completely different paper
38:37 - that you can write here this P people
38:40 - take phds in this stuff by the way guys
38:42 - you know this is called the the the
38:45 - scale factor you know mimc D measures
38:49 - this growth and if it's too much based
38:53 - on a certain percentage if you're
38:54 - overloading then then you're going to
38:56 - still see performance problems right
38:58 - reading a key is going to have to go
39:00 - through multiple reads to find the
39:02 - actual key versus if it goes right here
39:05 - hey the key is right here of course
39:06 - there's one entry it has to be it right
39:09 - but if there's
39:10 - multiple yeah then it's a problem right
39:14 - I mean you can you can think about it
39:16 - you can argue that you can hash a key
39:18 - that happened to get to a value that is
39:20 - not there so technically you have to
39:22 - read it and compare because your key
39:25 - might not exist but it happened to Hash
39:27 - to a value that does right so you have
39:29 - to read it so there is a cost to reading
39:32 - so that's the problem of hash table so
39:34 - and if that's the case then they do a
39:37 - hash
39:38 - resize and boy when you rehash your
39:41 - table they have to shift everything
39:43 - around and I believe this is when they
39:45 - use the consisting hashing which is this
39:48 - ring concept which I talked about in
39:50 - another video and that just gets really
39:53 - complicated right because they know now
39:56 - the moment you resized your hash table
39:58 - you need to move stuff around because
40:00 - Nanny will not be this index number one
40:03 - anymore it going to be index number 7700
40:06 - something like that right 1700 is not a
40:08 - number I think I'm going to skip this
40:10 - because we talked about locking in a
40:11 - minute we talk about thre threads and
40:13 - then accessing the lru and how it was a
40:16 - global lock and then it changed to a
40:18 - pair item lock and then still we have
40:20 - ref counting you know every time you
40:22 - read an item you increase the ref count
40:24 - you know and when you release it you
40:26 - decrement the rount this is for so the
40:28 - garbage collection can the garbage
40:31 - collection is written in C there's no
40:33 - garbage collector but the the the the
40:37 - ephemeral application Level garbage
40:40 - collection when Elio kick in can remove
40:44 - the item because you cannot just remove
40:47 - the item if if someone is referencing it
40:49 - that's the definition of meem memory
40:52 - leaks right all right let's talk about
40:54 - distributed cach and how it's uh MIM
40:56 - casd is actually not a distributed cash
40:59 - in my opinion mimc D servers when you
41:01 - spin up a mimc d server mcash D server
41:04 - they are completely isolated you cannot
41:08 - link a server to another server there is
41:09 - no mechanism to do that right when you
41:12 - spin up a mimc d server it's a mimc d
41:15 - server it doesn't talk to another
41:17 - servers and I absolutely love this
41:20 - design how simple and elegant this is
41:23 - put the responsibility if you want to do
41:25 - distributed well the apis at the client
41:28 - side has to do that and that's what
41:31 - we're going to show in the in the code
41:33 - section where we're going to write our
41:35 - own uh we're going to use a nodejs
41:38 - application to do that of course we're
41:39 - going to use also tnet to connect to
41:41 - that and write stuff right but we're
41:44 - going to go through all this stuff now
41:46 - but yeah what happens here is the client
41:48 - actually knows about all the servers it
41:51 - has knowledge so the client site
41:54 - actually does the distribution right so
41:56 - it's like okay key number one go here
41:58 - key number two go here key number three
42:00 - go here so there's a hashing going on
42:02 - consistent hashing to be specific you
42:05 - can build your own mimc D client that
42:09 - does whatever you want right and then
42:11 - distribute that stuff well what happen
42:13 - if I if I add a if I add a server well
42:18 - your client can start Distributing the
42:21 - keys I would
42:24 - definitely not be with that that because
42:27 - why would you distribute the keys for in
42:29 - a transient cash anyway who cares at a
42:32 - server is like oh yeah if if the kid is
42:34 - not there you're going to query the
42:35 - database and pull it up right it's it's
42:38 - not worth it to do this this chattiness
42:41 - to move items around from one server to
42:44 - another that's just a bad idea I don't
42:46 - know if clients do it maybe they do but
42:49 - I don't think it's it's required it's
42:51 - just thrashing for the case thrashing D
42:54 - B Shing
42:56 - again you you might if you know this
42:58 - channel you know that I'm I try as much
43:01 - as possible to push it as the last
43:03 - resort I do not like distributed
43:07 - stuff especially so complex to deal with
43:11 - right I like Simplicity I'm a simple
43:13 - man right but yeah sometimes you
43:17 - go you have you go to the YouTube scale
43:21 - and Google scale then you don't have a
43:23 - choice one machine cannot possibly
43:26 - handle everything I would I would go
43:28 - with raid replicas I would go with
43:31 - partitioning horizontal
43:34 - partitioning in the server itself
43:37 - minimize that as much as possible I
43:39 - would go with raid you know distributed
43:42 - dis storage but the application remain
43:46 - as a single writer the moment you have
43:48 - multiple writers and you have to deal
43:51 - with the Shing it becomes really complex
43:55 - you know if you want to deal with the
43:57 - complex complexity sure but yeah that's
43:59 - that's the idea of distributed
44:01 - cash okay let's do a demo we're going to
44:03 - do a demo we're going to spin up a bunch
44:06 - of MIM cash D Docker instances so for
44:10 - this exercise just install Docker and
44:13 - you're good to go and you have to have a
44:15 - Docker H you have to have a Docker
44:18 - account because somehow they are locked
44:20 - behind an account M casd I have no idea
44:22 - why did that they did do they do that
44:24 - sometimes right so you just just create
44:26 - an account do a Docker login you're good
44:29 - to go right once you do that you can
44:30 - download the image and you can spin up
44:32 - as many MIM cash G instances as you want
44:35 - so we're going to do that I'm going to
44:36 - use tnet because I love the Simplicity
44:39 - of MIM casd you know how many clients
44:42 - these days that you can actually just
44:43 - til it and run commments to they can be
44:45 - counted on one finger you know they
44:48 - don't exist anymore the Simplicity is
44:50 - gone from
44:52 - these from today's applications right
44:55 - the good old days of you just telling it
44:57 - and run and one thing I didn't mention
45:00 - is M casd doesn't have security by
45:02 - default so that might be a deal breaker
45:04 - for you right so you have to you can
45:06 - Implement authentication which doesn't
45:08 - exist by default sassel I believe they
45:10 - call it you can Implement TLS if you
45:12 - want but by defa they don't have any of
45:15 - that stuff right so take it with a grain
45:17 - of salt right they they said simple it
45:20 - is simple right but you have to be
45:22 - careful in a cloud environment when it
45:23 - comes to MIM casd you have to TLS it
45:26 - right they support that there is a
45:28 - support for that and obviously we're
45:30 - going to use no JSM Cas D for this
45:32 - consistent hashing and we going to put
45:34 - all our Docker containers and and play
45:36 - with that a little bit how about we do
45:37 - that so I have Docker installed here on
45:40 - my Mac you can have Windows and install
45:42 - Docker on top of it you can have Linux
45:43 - install Docker on top of it that's why I
45:45 - always like to use Docker just it's an
45:47 - agnostic whether whe whatever your
45:50 - application is you know whatever your
45:52 - operating system Docker works you know
45:54 - we have it on top of all all of this
45:56 - stuff so let's go ahead and spin up a
45:59 - Docker container that have a mimc d
46:02 - instance one MIM casd instance right so
46:05 - Docker run you do das Das name let's
46:08 - give it a name uh let's called it M1 M
46:10 - casd or M1 right you don't have to give
46:13 - it a name but I like that so that we can
46:15 - find it and delete it later
46:17 - easily and then you can expose the port
46:20 - uh by default
46:22 - 11211 right
46:24 - 11211 so this is what is running in the
46:27 - container this is what is exposed in my
46:30 - host right cuz I'm going to hit my host
46:33 - which is Hussein Mac which is that's the
46:35 - actual host that is running Docker and
46:37 - then I'm going to hit that Port which
46:39 - will be Port forwarded to this Con
46:42 - container and I'm going to spin up
46:44 - another one with 11 211 11 212 and 1121
46:50 - three right later we're going to spin up
46:52 - multiple ones and then finally we're
46:54 - going to do MIM cache d right if you do
46:58 - just like that this will block the uh
47:01 - the terminal you know and it's going to
47:03 - be just work so I I suggest you do that
47:06 - first I know it's going to work for me
47:07 - because I I did it before but I like to
47:09 - do dashd right- d means just hey detach
47:12 - it because I'm going to use this
47:14 - terminal for something else later right
47:17 - so just go just like that we created a
47:18 - container it can do Docker PS to make
47:20 - sure that the container is running
47:22 - obviously if the image is not there it's
47:24 - going to download it for you and you
47:26 - have to do Docker login to do all that
47:28 - stuff so do all of that log to your
47:30 - account and uh all that stuff all right
47:34 - so let's test it
47:35 - out how do you test it tell it what are
47:39 - we telling it into Hussein Mac which is
47:41 - my host and which Port 11211 again this
47:43 - is the port that I exposed that happen
47:45 - to be the same doesn't have to right if
47:48 - I do that all of a sudden I'm logged in
47:51 - how do I do that well let's do a stats
47:55 - give me your stats and this is the stuff
47:57 - that most of the stuff here we talked
47:58 - about currently right up time what's the
48:01 - version of MCD the pointer size maximum
48:04 - number of connections 1024 we talked
48:06 - about that right there's a maximum
48:08 - number of connections uh how many times
48:11 - you run a get how many times you run a
48:13 - set how many times you
48:15 - incremented uh the threads how many
48:17 - threads you have here right eviction how
48:20 - many times they allow you kicked in and
48:22 - evicted stuff and then you can do like
48:24 - stats uh Slack I think which going to
48:27 - give you like how many slabs were active
48:31 - how many is actually allocated obviously
48:33 - we don't have anything because we didn't
48:34 - do anything right so let's go ahead and
48:36 - set something so to set a key you do set
48:39 - and then you do the key let's call it Fu
48:41 - and then um the flags zero I don't have
48:44 - any Flags here Flags you can do further
48:47 - controls over here and the second
48:49 - parameter here is the expiration so
48:51 - let's say it's 3,600 which is an hour
48:54 - right you can set it for for an hour you
48:57 - can say it for a minute you can say it
48:58 - for a second if you want right that's
49:00 - the expiration so if your item ever get
49:03 - to after an hour it will be Eed it will
49:08 - not be returned to you not necessarily
49:10 - will be Eed until the lru kicks in and
49:13 - that actually physically removes it
49:16 - right and then finally we're going to uh
49:18 - put the data length how how how big is
49:21 - the value that you're going to set let's
49:23 - say two characters here right so I'm
49:25 - going to do high you have to exactly
49:28 - match it right otherwise it's going to
49:30 - be uh it's not going to fit nicely right
49:33 - so now we sto the value so let's read
49:35 - that value give yay I know this is just
49:40 - very simple stuff but you get the point
49:42 - right you can you can uh increment you
49:45 - can you can delete that key right and if
49:47 - you delete it you can read that it's not
49:50 - there so very simple stuff I don't
49:52 - really care about the API more I want
49:54 - more to talk about the architecture of
49:56 - stuff here right and that's what matters
49:58 - here there's there are actually two
50:00 - protocols command set this is the old
50:03 - one and there's the new one which is
50:05 - starts with mg like two characters and
50:08 - there's like a different set of syntax
50:10 - right there are two syntaxes here syntax
50:13 - can you say syntaxes I I guess you do
50:15 - you can but you can play with this it's
50:17 - very simple you connect to that and you
50:20 - see I didn't log in there's no accounts
50:23 - or anything like that there's no
50:24 - collection that you create it's just a
50:26 - free floating right some people might
50:29 - like that some people might not like
50:31 - that cuz they want partitioning hey let
50:33 - me create a table or collection let me
50:36 - play with that key value right there so
50:38 - it's a it's a freefor all if I if I
50:41 - destroy this connection so if I destroy
50:43 - it and I connect it again right and I do
50:45 - get F obviously it's not there because
50:47 - we deleted it so if I set it again um
50:51 - black zero let's said it for 10 seconds
50:54 - or or 2000 seconds
50:56 - whatever and then to high stored get Fu
51:01 - right if I killed it now let's kill the
51:03 - session right quit and then do again
51:08 - connect and then get Fu the value is
51:10 - still there obviously right cuz it's
51:13 - it's stort in memory right even if I
51:15 - connect it as a different TCP connection
51:17 - right and now that we did that if you do
51:19 - stats slabs you can see some interesting
51:23 - values that we talked about here right
51:25 - let's chunk size right so we have this
51:27 - number one which is this represent the
51:29 - slab class that we talked about right so
51:31 - we happen to have one slab class because
51:33 - my value is so tiny right if I created
51:36 - another chunk with a large value the
51:39 - large item another slap class will be
51:41 - created and that will have its own
51:44 - configuration so the chunks per page
51:46 - which we talked about
51:49 - 10,922 we have one page only as we add
51:52 - items we can just increase that if we
51:54 - want how many is in used one chunk how
51:57 - many is free 21 109 21 so that's the
52:01 - total we used one how many time we read
52:03 - it how many time we said it how many
52:05 - time we delet it everything here is
52:08 - actually uh accounted for active slabs
52:11 - we have one slab right here effectively
52:15 - active and this is the memory allocated
52:17 - right so it's like
52:20 - what that's like uh one Meg exactly
52:24 - right that's the make is that is
52:25 - allocated we talked about
52:27 - that so yeah so you can start playing
52:30 - with that and add M multiple data points
52:34 - and and look at the stats and play with
52:37 - it a little bit so let's
52:39 - control this and quit so now that we
52:42 - talked about tillet how about we
52:44 - actually go to nodejs and build our
52:46 - beautiful interesting application here
52:49 - all right so I created this I went to my
52:51 - project folder here I'm going to go Ahad
52:53 - and create a directly called no mod M
52:56 - right and I just go ahead and do that
52:59 - right do an mpm init Dy right I have
53:04 - nodejs of of course installed right here
53:06 - to do all this stuff right and then um
53:09 - let's create an index.js file and we're
53:13 - going to do const MIM cached equal I
53:19 - believe it just do require MIM cache
53:22 - literally and that's the library we're
53:23 - going to install so
53:25 - once we have this Library we can call it
53:29 - right how can I call it const um let
53:33 - call it server and then we're going to
53:35 - create a new MIM cached and here's the
53:38 - interesting thing you can pass in an
53:39 - array of servers and you can pass in a
53:42 - string you can pass in an array or you
53:44 - can pass an object if you pass an array
53:47 - then the uh the the keys will be evenly
53:51 - distributed between all these instances
53:54 - today I have only one server so Hussein
53:56 - Mac
53:57 - 11211 all right close the array we're
54:00 - going to add more servers later but
54:02 - that's that's it basically because
54:04 - server I guess server pool is a better
54:07 - name huh let's let's call it server pool
54:09 - because that's what it is it's a server
54:11 - pool here let's create a function called
54:13 - run and this function will be called in
54:17 - right and this function we're going to
54:20 - use the server pool and we're going to
54:22 - set a value so here's how we set a value
54:24 - set pool uh server pool do set and you
54:27 - give it a key say F right and then the
54:30 - value bar right and then expiration day
54:34 - an hour and then the final one is a call
54:37 - back which gives you like in case of an
54:38 - error I'm not going to set it because I
54:41 - trust that it's going to just work so
54:43 - all we have to do is
54:45 - uh do that and this will just set the
54:48 - value but for the sake of time I'm going
54:52 - to actually set 10 values 3 4 5 6 S 8
54:56 - nine for those who know JavaScript we
54:59 - can do this trick like for each I I
55:02 - think you can do a better job at this
55:04 - than I will but I think this works right
55:07 - this this should work
55:11 - right I like that that so they will have
55:14 - a different
55:15 - key a and the bar will have a this way
55:19 - we'll set what 10 values in this case
55:22 - and each value will have the full a for
55:25 - one and bar one for two bar two the
55:29 - reason I do this is because I want to
55:30 - actually see the I'm not going to read
55:32 - it from here all of us going to do that
55:34 - is just run and I'm going to read it
55:36 - from tnet right that's how I'm going to
55:38 - do it let's go ahead and do save mpm
55:42 - install MIM
55:45 - casd and then
55:47 - npm that's it node index. GS hopefully
55:50 - it
55:51 - runs and of course the moment I say that
55:53 - I have an error so let's go ahead and
55:55 - and check the error here so I going to
55:58 - see what the error is for
56:04 - each so let's go ahead and just add that
56:07 - okay this is going to print the error in
56:10 - case there is an error just in case all
56:14 - right try it
56:16 - again node index
56:19 - toj all right now works I had like a
56:24 - typo so I had effect but look at this
56:26 - get full three get full four get full
56:29 - five we're getting all the values that
56:32 - is pretty cool you guys right it's
56:34 - pretty cool so here's what I'm going to
56:35 - do now let's control exit here quit
56:40 - here's what I'm going to do now I'm
56:41 - going to spin up
56:44 - more containers so it's going to do run
56:48 - Das Dash name MIM 2 right they call it-
56:53 - p1212 2
56:57 - 11211 again this is the actual Port will
57:00 - this will not change this is what's
57:02 - changing here right right here right
57:04 - detach MIM cash d right got to do the
57:09 - same thing or
57:12 - three
57:14 - three that is pretty neat right and uh
57:19 - for for sake of completing let's add so
57:21 - four servers why servers are free we can
57:25 - we can spin up as much as we want now
57:28 - let's edit our application right here
57:31 - and uh what we're going to do
57:33 - is literally just add a comma say hey
57:37 - hin Mac 11212 is another server right
57:42 - there's another one too hin Mac all they
57:44 - are living in the same server if you
57:47 - think about it right it's just different
57:50 - Services right J say mac 11214
57:55 - that is awesome nothing changes right so
57:58 - I'm going to do it again and then node
58:01 - index.js I don't want you to pay
58:03 - attention to what will happen now The
58:05 - Client app now distributed all the stuff
58:08 - to all the servers so now my foods will
58:11 - be all over the place Let's test it out
58:14 - tet Hussein Mac uh
58:19 - 11212 right let's connect to
58:22 - 11212 the second server and then get f
58:25 - one it's right there get F two not there
58:29 - get F three not yeah it's right there
58:31 - good F four it's not there get it
58:34 - because now the distribution is up to
58:36 - the cine I have no idea how how this
58:38 - will be distributed probably round robin
58:41 - but uh could be something else right so
58:44 - if I pick now another server right three
58:49 - let's do that get f one not there get F
58:52 - two not there get F three not there good
58:55 - full four not there good full five right
58:59 - there so it took us like five five is
59:02 - there right and and you get the idea
59:04 - these keys are now distributed
59:07 - everywhere and when you ask about it now
59:10 - I'm going physically to the server
59:12 - itself to ask about it but if I ask the
59:15 - nodejs app it's going to give me these
59:18 - values right so here's what I'm going to
59:21 - do next right I'm going to do index.js
59:25 - after I run all these which is I'm not
59:27 - going to run it anymore right uh cuz I
59:30 - already store these for an hour I'm
59:32 - going to just go a loop and read right
59:35 - going to create a function that reads
59:37 - and exactly
59:39 - similar uh
59:41 - YY p and then just do a get right the
59:47 - get is slightly different what we going
59:49 - to do is that you don't need a value
59:51 - right you don't need an expir date but
59:54 - it's going to give you a function a
59:56 - callback where it's actually two places
59:58 - error and data right and then we just
60:01 - print the data CU that's what we're
60:03 - interested in assume there are no errors
60:05 - here again this is a very simple app
60:06 - here and then's just go ahead and read
60:08 - so in this case you're talking to the
60:11 - pool directly you're not talking to
60:13 - individual machines so we know that the
60:15 - keys were actually evenly distributed
60:17 - between the servers because we ta
60:19 - knitted into each servers and tested
60:21 - that out right so now what we're going
60:23 - to do is let's run and see node
60:27 - index.js look at beautiful Bar Nine bar
60:30 - two bar four bar three bar six Bar Seven
60:33 - bar eight bar one bar five why do we get
60:36 - the different values it's very easy
60:38 - because we we're we're running
60:40 - asynchronous job we have no idea yeah we
60:43 - executed f one first right but Fu right
60:47 - we we what do we did is like we looped
60:50 - and sent all the 10 request at the same
60:53 - time right
60:56 - all this is what we did we looped and
60:58 - all the 10 request but these are
61:00 - asynchronous so Bar Nine F9 might get
61:05 - give us a result before f8 right all of
61:08 - these are just this is how no GS works
61:10 - it's single threaded and it sends all
61:12 - these request and just Loops through the
61:15 - its main um the the main Loop the the
61:18 - main thread Loop right and looks for the
61:20 - result it depends on the server how fast
61:22 - is going to respond right so is going to
61:24 - send all these things and then hey the
61:26 - server responds for this respond for
61:27 - this for this we just do all this stuff
61:30 - so the client here it really depends
61:32 - what it does as well right so the client
61:36 - really depends on this it took the hash
61:39 - right of the f one determine that F1
61:43 - should exist on This Server connect it
61:45 - to the server asked for the value pull
61:48 - that value and then return it so you
61:50 - have no idea how fast these servers will
61:52 - reply right and the number number of
61:54 - connections to each server also really
61:57 - matter right so that's basically uh it
62:00 - for the demo guys and kind of explained
62:02 - all this uh idea of MIM casd let's go
62:05 - ahead and summarize this course all
62:07 - right we did the demo let's summarize we
62:09 - talked about memory management memory is
62:11 - fragmented if we didn't do the slab
62:13 - Pages concept then we're going to be
62:16 - allocating values left and right right
62:18 - and that as a result uh becomes
62:21 - fragmentation and fragmentation is bad
62:23 - because now you have all these beautiful
62:26 - gaps of free space that we cannot use
62:28 - unfortunately right because our items
62:30 - might not necessarily fit these gaps
62:33 - right so we need memory management lru
62:36 - again uh very in unpopular opinion I I
62:39 - would like for this to be an option to
62:41 - be disabled so that I don't get locked
62:45 - right and keep my application simple and
62:48 - if someone want to build Anu why don't
62:50 - they build it themselves right or just
62:52 - have the client have the control I wish
62:54 - they stayed simple and didn't implement
62:56 - this just that's just my only this
62:59 - criticism of the MIM casd they they
63:01 - stayed simple they stick to their rules
63:04 - this is to in my opinion I think it's an
63:06 - Overkill right threads I love this
63:08 - design yeah we can work with money
63:11 - threads of course there is a limit for
63:14 - there is another problem with the
63:15 - threads design here is that let's assume
63:18 - you have multiple threads all right and
63:22 - each thread is a connection right let's
63:23 - say about that right and and when we
63:26 - looked at the data I think when we
63:28 - looked at the stat we saw that there is
63:29 - a fixed number of threads right and I
63:31 - don't know if this if MIM casd
63:34 - share connections on a given thread like
63:37 - have multiple connection on thread I
63:39 - don't know that maybe because otherwise
63:41 - it's going to run out of threads right
63:43 - so in this case what you you you can end
63:46 - up with is a thread with a connection
63:49 - that happen to have a very aggressive
63:51 - client a client that sends a lot of d
63:54 - data to the thre you know so in this
63:57 - particular thing you create a bottleneck
63:59 - and that
64:00 - bottleneck really there is no solution
64:02 - to it because you don't know if a
64:04 - connection is going to be aggressive or
64:05 - light waight right you can you can
64:07 - change that complete model to a
64:10 - centralized thread model where is a
64:13 - center thread that takes the messages
64:15 - these requests and these requests will
64:17 - be distributed evenly right you can do
64:19 - that but then the bottleneck is moved to
64:21 - a single thread you lose either way
64:24 - right there is no solution the best
64:25 - solution that's when you when you when
64:27 - you go into deep these things like it's
64:29 - it's fascinating to me I absolutely love
64:32 - it we talked about read and write talked
64:34 - about locking about distribution cach
64:36 - which is completely client side guys I
64:38 - hope you enjoy this uh crash course Deep
64:41 - dive level into MIM casd absolutely uh I
64:45 - enjoyed researching this talk me a lot a
64:47 - month to research this entire course uh
64:50 - absolutely love it uh if you want to
64:52 - support the channel become a member
64:54 - there is a lot of uh member exclusive
64:56 - content in this channel uh if you want
64:58 - to support
64:59 - otherwise there is the there's uh I have
65:03 - a lot of UD me courses uh there's
65:04 - discount coupons check it check them out
65:07 - and that supports the channel I
65:08 - appreciate you so much and thank you all
65:11 - for your wonderful messages hope you
65:13 - enjoy this course I'm going to see you
65:15 - on the next one you guys stay awesome
65:16 - goodbye