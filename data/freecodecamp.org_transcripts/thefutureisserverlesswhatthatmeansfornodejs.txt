00:00 - i'm chris anderson i'm a program manager
00:01 - on the azure functions team um i
00:03 - actually
00:04 - started the functions project about two
00:06 - years ago and it was mainly kind of the
00:09 - background was as i was working on a
00:11 - product that was called web jobs which
00:12 - was for kind of doing background jobs in
00:14 - the cloud and it was mostly just an sdk
00:17 - framework you deployed onto your own
00:19 - you know instances your own vms you had
00:21 - to manage everything yourself
00:22 - and
00:23 - one day we tried to add node.js into it
00:26 - and ended up making it really really
00:27 - hard to manage it actually made it worse
00:29 - but the end product was really really
00:31 - cool in terms of what you wrote and so
00:32 - we discovered if well if we just run
00:34 - this as a service we'll end up with a
00:36 - better product and i'll kind of talk
00:37 - about why we ended up going with node.js
00:39 - as far as how that goes
00:41 - so
00:42 - serverless node.js
00:44 - i choose you
00:46 - there's really i think two kind of big
00:48 - things it also had to do a lot with
00:50 - javascript and then we'll also talk
00:52 - about node.js
00:53 - javascript i like to say is kind of the
00:55 - english of programming languages a lot
00:58 - of people can speak at least a little
00:59 - bit of it even if it's bad right it's
01:01 - not necessarily the perfect language but
01:03 - it's a language which is relatively easy
01:04 - to learn for a lot of people um it might
01:07 - not even be the most widely used
01:08 - language but it's used by a good section
01:10 - of the developer community out there
01:11 - especially in the kind of web
01:14 - application space so it's a very very
01:16 - useful language for us to choose it
01:18 - doesn't require any compilation which
01:20 - means that a lot of the goal that we had
01:22 - was for people to go ahead and get cloud
01:24 - running in the cloud as fast as possible
01:26 - our goal was that you were basically in
01:28 - the editor doing something in like 30
01:30 - seconds and that you were actually
01:31 - walking away within five minutes having
01:33 - done something and have a service up and
01:34 - running in the cloud that meant that we
01:36 - having compilation having build even
01:38 - having an ide meant slow down to that
01:40 - time and so we really focused on that
01:42 - quick path first since then we've
01:45 - kind of gone back and said okay for
01:47 - people who do want to work in an ide for
01:48 - people who do want to have build and
01:50 - compilation they still can but we
01:52 - started that initial goal of cl of code
01:55 - in the cloud as fast as possible
01:57 - um
01:57 - and then yeah there's just a giant great
01:59 - community of which you guys are all a
02:01 - part of of course which made it easy for
02:03 - everything that we needed to kind of
02:04 - work out of the box or we have available
02:06 - to us
02:07 - and then node.js
02:09 - node.js is a great platform in the case
02:11 - of serverless because it's a very very
02:13 - lightweight framework
02:15 - when you go and just measure how fast it
02:17 - is for node.js to come up and start
02:18 - running for the first time versus how
02:20 - fast it is for say like java or even you
02:22 - know c-sharp in some cases to come up
02:23 - and run for the first time it's much
02:25 - faster and for the general case and
02:28 - that's really useful because in
02:29 - serverless
02:30 - it's actually not serverless there's
02:32 - servers back there but those servers
02:34 - have to come up basically when your
02:35 - request comes in or when the event shows
02:37 - up you know for asynchronous messages
02:39 - it's not the worst thing in the world if
02:40 - there's like a a second or two or you
02:42 - know a couple seconds of you know
02:44 - latency coming up but a lot of the times
02:46 - people are using these functions in http
02:48 - scenarios in which case any latency of
02:50 - bringing the instance up is impacted by
02:53 - the user that's trying to use that
02:54 - function and we know that in the case of
02:56 - like websites latency as far as like
02:59 - responding to the request can mean lost
03:01 - users and so we know that it's critical
03:02 - for things to come up as fast as
03:03 - possible and node.js is already kind of
03:05 - designed to come up nice and quickly so
03:07 - it was a great platform out of the box
03:08 - there and the other nice thing was that
03:10 - it was very
03:12 - widely used at microsoft we make sure
03:14 - that we kind of reach all developers
03:16 - developers running on windows max linux
03:18 - and linux and node.js was already really
03:20 - really good at running in all those
03:22 - places and so we know that we'd have the
03:23 - best support across all those various
03:25 - places we needed to run
03:29 - so what can serverless do for node.js
03:31 - developers you know we kind of chose
03:34 - node.js to go out with in the first
03:36 - place
03:37 - um
03:38 - because it was very easy for us to get
03:39 - going and we wanted to kind of get
03:40 - started we wanted people to be able to
03:42 - use it easily but for people who are
03:44 - just kind of already using node.js
03:46 - already used to using it why is
03:48 - serverless a useful thing
03:49 - well one of the things that i came
03:51 - across frequently when i was building
03:53 - node.js applications was
03:55 - while going ahead and you know building
03:56 - my server is really easy kind of doing
03:58 - background process of messages can be a
04:00 - little bit less easy to manage and
04:02 - maintain there's a lot less tools out
04:04 - there which understand frameworks for
04:05 - doing background processing and i also
04:07 - have to kind of manage the scale for
04:09 - those background processing it's really
04:10 - easy to scale on like http request
04:12 - messages in a lot of platforms
04:14 - but you know cues and things like that
04:16 - that can be a little bit trickier to get
04:17 - right and so serverless makes it so i
04:19 - can basically go ahead and have a
04:20 - function up and running and it scales
04:22 - dynamically to
04:24 - whatever i need to and since you pay for
04:26 - execution and most serverless frameworks
04:27 - out there
04:28 - you don't really have to ever overpay
04:29 - for your system
04:31 - it also means that things are much
04:32 - lighter
04:34 - end-to-end frameworks become a lot less
04:36 - necessary since all i'm really
04:37 - necessarily having to go ahead and push
04:39 - is just a function
04:41 - i'm not having to worry about like
04:43 - having that full stack of things that's
04:44 - going to manage like the various http
04:46 - entry points i'm not having to go
04:48 - through there and worry about a lot of
04:49 - extra code
04:50 - a lot of the times especially if you
04:52 - take advantage and for instance at
04:53 - microsoft we have azure functions where
04:56 - we have actually bindings to various
04:57 - services you never actually have to
04:58 - bring in the sdks to talk to for
05:01 - instance like cosmos db
05:03 - which is a giant you know
05:05 - document based database that we have you
05:07 - can actually use our bindings and just
05:09 - return a json object from the function
05:10 - and it'll get stored to the database for
05:12 - you so you never actually have to deal
05:14 - with working with those sdks it makes it
05:15 - very quick
05:16 - and of course horizontal scaling high
05:18 - scale is easier than ever basically with
05:20 - functions we just keep on throwing new
05:22 - instances at you and you never actually
05:23 - have to see the instance account worry
05:25 - about managing the vms worry about
05:26 - patching things it just keeps on scaling
05:28 - and then as soon as you have no more
05:29 - traffic on your service the vms
05:31 - disappear and you don't really worry
05:33 - about when they're there and when
05:34 - they're not
05:35 - you'll just kind of scale out when you
05:36 - actually have requests when you actually
05:38 - have usage this has turned out to be
05:40 - really useful in a lot of cases one of
05:41 - the first places that someone came up to
05:43 - me and it's like oh yeah azure functions
05:44 - it was really useful because of that
05:45 - whole kind of scaling thing was actually
05:47 - at a conference someone had built the
05:48 - conference app using functions and it
05:51 - was really great because they got a lot
05:52 - of like random requests especially like
05:53 - the week leading up to the conference
05:55 - from the various project managers trying
05:56 - to do the conference and he would just
05:58 - go through there and add a random
05:59 - function to serve that purpose and then
06:00 - after the conference was done he'd have
06:01 - to worry about scaling down the vms or
06:03 - anything like that he just kind of
06:04 - walked away and he left it there in case
06:06 - people wanted to use it randomly and
06:07 - then he didn't get charged anything for
06:09 - those functions running in the meantime
06:10 - so it's very useful for those kinds of
06:11 - use cases
06:12 - um and just to give you a sense before i
06:14 - kind of move on to
06:15 - what can node.js do for serverless i
06:17 - just wanted to give you a simple sense
06:18 - of how this can work
06:20 - here i actually have the functions
06:21 - runtime running locally on my machine
06:24 - this is the simplest kind of demo of
06:27 - hello world so i've got the very classic
06:29 - case here your function in this case let
06:32 - me pull up this one
06:33 - your function in this case is just going
06:35 - to be exporting a function from the
06:36 - module so i've got a context object
06:39 - coming in a request object coming in i
06:41 - can go ahead and do some log statements
06:43 - i'm able to access it we actually
06:46 - purposely made the request object look
06:48 - like a connect or an express object so
06:49 - that way if you wanted to use connector
06:51 - express middleware those things can
06:53 - still work with inside of your function
06:54 - without having to do too many tweaks
06:56 - and then my response here i'm just able
06:58 - to add headers straight to the message
07:00 - do my body here and it just kind of
07:02 - works like normal and so here let's just
07:05 - kind of reset the demo
07:07 - you'll see here in the bottom right that
07:08 - i'll see various um kind of things
07:10 - scroll by here the way that i got this
07:12 - running
07:13 - is i just run funko start you can
07:15 - actually do npm install
07:18 - azure dash functions dash core dash
07:20 - tools dash d and then you'll have
07:23 - functions running on your local machine
07:25 - and you can run funk knit funk new
07:27 - function and then do funko start once
07:28 - you have your project going so that
07:30 - spins up it's listening on 7071 we can
07:33 - see our api hello function that's been
07:35 - hung out there because this function is
07:37 - called hello based off of the folder
07:39 - path
07:41 - and i can go ahead and run and it sees
07:43 - says please pass the name on the
07:44 - correction on the request body if we
07:45 - want to inspect why we got that logic
07:47 - back we can actually go ahead and just
07:48 - hit attach in vs code when you use
07:50 - functions we go ahead and actually drop
07:52 - a vs code file there with the
07:53 - launch.json which is pre-configured to
07:55 - talk to your local functions runtime so
07:57 - there's no setup there to get debugging
07:59 - working it just automatically drops that
08:01 - launch.json file there so now that i'm
08:03 - connected i can go ahead and hit enter
08:05 - again and you see that i've got this
08:06 - breakpoint set up here i can now go
08:08 - ahead and inspect the request object
08:09 - look at the query object and i see that
08:11 - it's actually empty there's nothing on
08:13 - there a query object which is why it's
08:15 - falling into this else statement which
08:16 - is saying please pass the name on the
08:18 - query string or the request body
08:20 - so we can fix that real quick
08:25 - and now when i do that i can go ahead
08:27 - and see the query object now has chris
08:28 - on it and name is now equal to chris and
08:30 - so if i go ahead and continue we now see
08:32 - hello chris with a question mark at the
08:34 - end of it
08:35 - and it's still really fast to develop
08:36 - this i don't need to go ahead and hit
08:38 - funko start every single time that i've
08:39 - got to change to my function i can go
08:41 - ahead and let's get excited rather than
08:43 - kind of
08:44 - asking questions about it hit enter
08:47 - and you can see there i go i got my
08:48 - exclamation mark so the host is sitting
08:50 - there constantly listening to file
08:51 - changes so it's very easy to just write
08:53 - some code change write some code change
08:55 - um the only nice thing with this is it's
08:56 - not just http though i'm using http
08:58 - right now because it works entirely
08:59 - locally and the internet's been kind of
09:01 - like in and out throughout the
09:02 - conference but it can also still listen
09:04 - to all your q services it'll listen to
09:05 - event hubs in fact if you configure it
09:07 - to listen to your production services
09:09 - you'll actually kind of end up with n
09:11 - plus one things because it'll actually
09:13 - collaborate in real time with the
09:14 - cloud-based instances the same way that
09:16 - all the cloud instances themselves
09:17 - collaborate with each other using a
09:19 - storage account with the covers
09:21 - so now i just kind of understand what
09:23 - this you know this is kind of what led
09:24 - us to you see how easy it is to go ahead
09:26 - and write this code if this was you know
09:28 - a language that required building for
09:30 - instance like you know java this would
09:32 - still be relatively easy to be a build
09:33 - step and then i'd have to go and hit run
09:35 - but because i can script it and i can
09:36 - live edit things we get a really nice
09:38 - kind of fast inner loop in terms of
09:39 - developing goes and then i can just
09:42 - deploy it up to the cloud or even do
09:43 - this from the portal itself if the
09:45 - internet was working a bit better
09:48 - so from there let's kind of kind of talk
09:50 - to about the next phase of things in
09:51 - terms of what
09:52 - has been weird about running node.js and
09:54 - serverless together and what can the
09:56 - node.js ecosystem do to think about
09:58 - serverless when
10:00 - you know we're doing the things that our
10:01 - community does um
10:04 - one of the things that i really liked
10:06 - about node.js and javascript was how
10:08 - easy it was for you know new developers
10:10 - kind of walk up and get started with it
10:11 - one of the nice things about node.js and
10:13 - javascript is since there's a lot of
10:14 - client developer client-side developers
10:17 - kind of already knowing javascript
10:18 - already used to how that language works
10:19 - it's very easy for them to walk up to
10:21 - node.js to have them start building
10:23 - their own backends if they needed to do
10:24 - that
10:25 - serverless in some ways kind of has a
10:28 - similar kind of thing about it where
10:29 - serverless is very easy to walk up to
10:31 - and start building a cloud service and
10:33 - get up and running you don't need to
10:34 - worry about setting up a vm and managing
10:35 - it you don't need to worry about
10:36 - anti-virus software you don't need to
10:37 - worry about firewalls all that's done
10:38 - for you by the managed service so now
10:40 - those same cloud you know those same
10:42 - developers who might be able to get up
10:43 - that single vm but couldn't really reach
10:45 - scalable systems can now use serverless
10:47 - technology to deploy systems at scale
10:50 - for both you know front-end facing http
10:52 - applications but also back-end systems
10:54 - that might have even been farther away
10:56 - from their area of expertise it's a very
10:57 - accessible thing to get up to so because
10:59 - node.js is already kind of the star
11:01 - language of serverless we're going to
11:03 - see serverless as it's becoming more
11:04 - popular bring even more people into the
11:07 - server into the node.js ecosystem
11:10 - but there's a couple of gotchas that
11:12 - those new people coming into the node.js
11:13 - ecosystem are going to have to deal with
11:15 - and some of them is that
11:17 - node.js
11:19 - kind of started ignoring some of the
11:20 - lessons that we learned from the web
11:22 - space and that we got kind of very
11:24 - comfortable with the fact that since
11:25 - these things are going to be long
11:26 - running on servers it doesn't matter if
11:28 - our packages are huge and we load
11:29 - everything in the world and through that
11:31 - process and you know as long as it's not
11:33 - taking up too huge of a memory footprint
11:34 - like who cares how many tiny little
11:36 - files that we have and things along
11:37 - those lines
11:38 - well as i kind of mentioned before about
11:40 - node.js is actually great because for
11:41 - the simple cases it comes up very
11:43 - quickly
11:44 - for the cases where you decide to go
11:46 - ahead and you know import low dash and
11:48 - import every single giant
11:50 - framework that you can think of into
11:52 - memory it takes actually a while to even
11:53 - just read those things from disk and the
11:55 - memory footprint then means that people
11:57 - who are using those libraries inside of
11:59 - functions have to pay more because they
12:01 - have to pay for that memory footprint to
12:03 - actually exist so if you load giant
12:05 - libraries into memory
12:07 - more than ever you're not having to pay
12:08 - for that if i can choose a library which
12:10 - is you know one megabyte versus a
12:12 - library which is you know maybe 30
12:13 - megabytes that could mean big
12:15 - differences for my end of month bill in
12:17 - the case of serverless and so now as you
12:19 - know any package authors who are
12:21 - listening to this talk or here in the
12:22 - audience it really pays to be thinking
12:24 - about how can we go ahead and reduce
12:27 - what actually gets loaded there's lots
12:28 - of things that can help with this you
12:30 - know if we're now using you know the new
12:31 - kind of uh you know common gs stuff for
12:34 - it it'll only load the parts that it
12:35 - needs to in memory those are really good
12:37 - things i actually wrote a tool that's
12:39 - called azure functions pack which i
12:41 - actually go through there and web pack
12:42 - your code all together it doesn't
12:44 - necessarily do as much to reduce memory
12:46 - footprint for that you'd want to go
12:47 - ahead and run uglify on top of that the
12:49 - result of that web package
12:51 - but it does reduce the load time i
12:53 - actually did a lot of kind of testing of
12:56 - various impacts of i took the four
12:58 - largest node modules i could find i put
13:00 - them into a function and measured it on
13:02 - an i7 with an ssd so very very fast
13:04 - system it still took about two seconds
13:07 - for that function to come up for the
13:08 - first time because i had to start
13:09 - node.js and node.js had to read all that
13:10 - stuff into memory
13:11 - when i web packed it it actually
13:14 - took about 100 milliseconds so it's a
13:16 - giant improvement and when you're
13:18 - running inside a serverless on maybe a
13:19 - little bit more of commodity hardware
13:21 - you're going to be running it's going to
13:23 - take even longer to load those modules
13:24 - into memory so
13:26 - and a lot of the sales providers
13:28 - actually have limits on the amount of
13:29 - content you can actually put up there in
13:30 - the first place
13:32 - in the case of functions we don't
13:33 - actually have any file in the sizes we
13:34 - haven't hit those issues but they have
13:35 - existed in other platforms and so it's
13:37 - important to think as we're writing
13:39 - these packages especially if we want
13:40 - these packages to work instead of
13:41 - serverless um
13:43 - we need to be thinking about what those
13:45 - things are going to do there's actually
13:46 - a couple of examples of this out there
13:47 - in the wild already beyond just like
13:49 - things that i've seen as i've tried to
13:50 - work with customers using functions um
13:52 - like on postgres one of the bigger
13:55 - angular threads there for the the pg
13:57 - module is someone talking about hey this
13:59 - thing
14:00 - started consuming a lot of sockets
14:02 - without me realizing it because my
14:03 - function was kind of coming in there and
14:04 - using it and using it using it and
14:05 - opening up sockets and not closing them
14:07 - and to be fair they were misusing the
14:09 - library they didn't read the
14:10 - documentation properly they weren't kind
14:12 - of using it the way they thought it to
14:13 - but they used it the way that it felt
14:15 - natural to use it inside of their
14:18 - function and so we might want to think
14:20 - of especially for writing a package
14:22 - which we know will be harmful and to use
14:24 - wrong in serverless to include a section
14:26 - about hey if you're trying to use this
14:27 - inside of one of the service platforms
14:29 - like you know here's instructions on how
14:31 - to create a singleton instance of it
14:32 - outside the function so it stays in
14:34 - their memory here's how to write yours
14:35 - through the code for it to go ahead and
14:36 - close its connection before the
14:38 - function's completed and you know some
14:40 - examples can really help a long way with
14:42 - making sure that anyone news coming to
14:43 - this ecosystem from serverless into
14:45 - node.js has a good time
14:47 - because it'll pay to make sure that
14:48 - people are you know successful in that
14:50 - way
14:52 - and then there's one other thing that we
14:53 - should be kind of mindful of is that you
14:55 - know node.js and serverless and
14:57 - javascript has really gotten very far
14:59 - and the community's been doing really
15:00 - well because i think of the strong open
15:02 - source nature of things and how easy it
15:05 - is to get access to the parts the system
15:07 - runs on you know the even the core
15:09 - brains of like you know
15:11 - you know chromium and things like that
15:12 - or open source it's really really great
15:14 - just how fast and how much all of us are
15:16 - empowered to contribute to the platforms
15:19 - that we run on um and since a lot of the
15:21 - service implementations today are very
15:22 - vendor specific there is some risk there
15:24 - so it's something that's worth keeping
15:25 - in mind there's you know people out
15:26 - there that are thinking about problem uh
15:29 - ways to address some of these problems
15:31 - um like service framework is one of
15:33 - those cases there's you know apex which
15:35 - is more of a go-based one from tj
15:38 - a couple different examples um so one of
15:40 - the things that we're trying to do from
15:42 - the function side of things is even
15:43 - though we're a vendor and we are
15:44 - building a specific implementation
15:46 - that's mainly designed to run on azure
15:48 - it is all open source and we are working
15:50 - really hard to try to build it so it is
15:52 - a bit more of a portable system and so
15:54 - we really do want to make sure that you
15:55 - don't really feel like you're
15:56 - necessarily locked in even though it's
15:58 - built to run really well on azure we are
16:00 - trying to make sure that we at least
16:01 - build it in the open source and
16:02 - eventually we can work towards a way
16:03 - where it's even open platform
16:05 - so
16:06 - um with that in mind the future is now i
16:08 - encourage all of you guys who are
16:10 - thinking about trying to deploy services
16:11 - out into the cloud to consider
16:13 - serverless from you know whatever vendor
16:14 - that you feel is good it's all about
16:16 - trying to improve the agility with which
16:18 - we can deploy services and build
16:20 - services which we can trust will operate
16:22 - well at scale
16:23 - um node.js can build more with
16:26 - serverless since you're already in good
16:28 - shape because you know the language of
16:29 - choice on this platform so you're
16:30 - already kind of ahead of the game
16:32 - and
16:33 - i think
16:34 - serverless has taken advantage of the
16:36 - fact that node.js and javascript already
16:38 - had this great big open community and we
16:41 - should try to do our best to encourage
16:43 - that community as node.js you know
16:45 - community members to stay open so
16:48 - um thank you everyone for listening
16:50 - thank you for microsoft for paying for
16:52 - me to come here um and if you ever want
16:54 - to learn more about what i do for my day
16:56 - job check out functionsasher.com or
16:58 - tweet at me with candycodes thanks
17:00 - everyone
17:05 - you