00:00 - linux is a popular operating system for
00:02 - server administration because it's
00:04 - secure stable and flexible in this
00:06 - course sean powers from cbt nuggets will
00:09 - detail every part of configuring
00:11 - monitoring and supporting a server setup
00:14 - that runs the linux operating system
00:16 - this course will teach you everything
00:18 - you need to know to configure linux
00:20 - servers including the boot process
00:22 - kernel modules network connection
00:24 - parameters localization groups and more
00:28 - let's get started
00:31 - [Music]
00:34 - bios and uefi are two tools that
00:36 - basically do the same sort of thing but
00:39 - they can be a little bit confusing when
00:42 - it comes to how do you know which one to
00:44 - use on a computer and and do i need to
00:46 - support one or the other or both or the
00:49 - nice thing is you usually either have
00:51 - bios or uefi now bios is an older
00:55 - program it just stands for basic input
00:57 - output system whereas uefi is the new
01:00 - kit on the block and this stands for
01:02 - unified extensible firmware interface
01:05 - which sounds confusing but really it's
01:08 - just the the way that we can interact
01:10 - between the hardware and the operating
01:12 - system now let's say that we have two
01:15 - different vehicles now these are two
01:17 - obviously very very different vehicles
01:19 - one of them is a sports car and one of
01:22 - them is an awesome yellow volkswagen
01:24 - beetle i actually have a volkswagen
01:27 - beetle that's yellow like this and it's
01:29 - awesome but nonetheless you could be a
01:31 - sports car person either way even though
01:33 - they're ridiculously different vehicles
01:35 - they both have some common interfaces
01:38 - right they're both going to have brake
01:40 - pedals they're both going to have
01:42 - steering wheels
01:44 - they're both going to have windshields
01:46 - and those interfaces are fairly common
01:48 - across all vehicles now the brakes in
01:51 - the underlying system are going to be
01:52 - different this sports car probably has
01:54 - really nice disc brakes whereas these
01:56 - old volkswagens have drum brakes now
01:59 - drum brakes aren't as good but the
02:00 - interface itself is very very similar
02:03 - you push the brake pedal and you stop
02:05 - and that's kind of what bios and uefi
02:09 - are they're interfaces between the
02:11 - hardware and the operating system itself
02:14 - now they do work a little bit
02:15 - differently so here we have our hard
02:17 - drive on our system now using bios like
02:20 - the old method of booting a computer you
02:23 - would have like the very first sector on
02:26 - the hard drive would be the boot sector
02:28 - and that's where the mbr the master boot
02:30 - record would live and then that would
02:33 - tell the computer where the partitions
02:35 - are and point it to where to boot now
02:37 - there's a lot of limitations with bile
02:39 - so you could only have
02:41 - four partitions using the bios and mbr
02:43 - combination there are some hacks to get
02:46 - around that you know they would take a
02:47 - partition and do extended partitions
02:49 - inside that but that's a whole nother
02:50 - nugget still there was this limitation
02:52 - also a limitation of size with the drive
02:55 - how much this boot sector or this master
02:58 - boot record can actually reference it
02:59 - can be a small amount like two terabytes
03:01 - instead of exabytes of data and so uefi
03:05 - is a replacement for the bios technology
03:08 - and rather than just have the single
03:11 - boot sector what it does is there's an
03:12 - entire partition
03:14 - on the system and that partition is
03:18 - where all of the boot code is for
03:20 - whatever operating systems might be on
03:22 - the computer so rather than just the
03:23 - boot sector pointing to
03:25 - you know the rest of the hard drive this
03:26 - is an actual
03:27 - specialized partition
03:30 - on the computer and that's where the
03:32 - uefi code is stored also it uses a
03:35 - different partition scheme so you can
03:37 - have tons and tons of partitions and it
03:39 - can address a much larger hard drive
03:41 - there's also other things like secure
03:42 - boot that uefi supports that bios
03:45 - doesn't basically just know that uefi is
03:48 - the replacement for bios it replaces the
03:51 - functionality of connecting the hardware
03:54 - to the software of the operating system
03:56 - now the good news is if you have a
03:58 - computer that's older or even some new
04:00 - ones so come with bios you can still get
04:02 - around a lot of the limitations because
04:04 - there are hacks that will let you use
04:06 - really big hard drives or hacks that
04:08 - will allow you to do some of the things
04:10 - that you can't normally do out of the
04:12 - box but most computers now are coming
04:14 - with uefi and from a from an installer
04:18 - point of view there's very little you
04:20 - have to do because the operating system
04:22 - is going to say okay i was booted using
04:24 - uefi so i'm going to create a partition
04:26 - a uefi partition and i'm going to put
04:28 - all the boot code in there so from your
04:31 - standpoint from the end user or the
04:33 - installer standpoint there's very little
04:35 - difference but under the hood a lot of
04:38 - new cool stuff is going on and that's
04:40 - why uefi is kind of the way of the
04:42 - future
04:44 - remember when you were a kid and in the
04:46 - doctor's waiting room there were these
04:48 - magazines and one of the games inside
04:50 - the magazines was that you had to find
04:53 - the difference in one of a bunch of
04:55 - similar looking
04:57 - figures like for example here are what i
04:59 - have nine different jokers and one of
05:02 - them is a little different now it's not
05:04 - terribly difficult to see which one is
05:06 - different here if you watched while they
05:07 - appeared this one has a tiny little spot
05:10 - right there on his shirt that's
05:12 - different than all the others so we've
05:14 - been able to identify it but you can see
05:15 - they're very very very very similar well
05:18 - the same thing is true about grub
05:21 - and grub 2 which of course is the next
05:24 - iteration of grub now grub stands for
05:26 - grand unified boot loader but really
05:28 - it's just the way that the computer
05:30 - transitions from bios or uefi booting up
05:33 - conditions into the actual operating
05:35 - system itself it's what tells the
05:37 - computer okay where's my partitions and
05:39 - stuff like that it's very easy to
05:41 - confuse which is which on your system
05:44 - which seems silly but it can be very
05:46 - very embarrassing when you sit down at a
05:48 - system you're like okay so is this
05:50 - running grub or grub 2 because they do
05:54 - the same thing right they both boot the
05:56 - computer but they do have some minor
05:58 - nuanced differences grub of course is
06:01 - older you probably guessed that by it
06:03 - not having a 2 at the end of its name
06:05 - but grub is often called grub legacy
06:07 - because it is older but it's still on a
06:09 - few operating systems not many but a few
06:12 - i think slackware still uses grub legacy
06:14 - now the biggest and easiest way to
06:17 - figure out if you're dealing with grub
06:19 - or grub 2 on your system is to look
06:22 - inside the boot grub folder and if you
06:26 - see
06:27 - menu.lst
06:29 - or grub.com that means you're running
06:33 - grub legacy because grub 2 does not have
06:36 - those configuration files grub 2 has
06:38 - this configuration file grub.cfg
06:41 - now it's easy to confuse
06:44 - cfg.com so i always just look for
06:46 - menu.lst if that exists you're on grub
06:50 - legacy now the thing about grub is it's
06:52 - kind of difficult to modify it was uh
06:54 - it's very easy for automated systems
06:57 - like when you install a new kernel to
06:58 - figure out how to put how to you know
07:00 - update the menu and update the boot code
07:02 - but it's really difficult for the end
07:03 - user to modify that stuff and the boot
07:06 - menu usually when it's booting up it
07:08 - says you know press something in 10
07:09 - seconds in order to change the way it
07:12 - boots so this usually just appears for
07:13 - you and you can see it now grub 2
07:16 - is a lot more customizable in fact if
07:18 - you go into the etc default grub file
07:21 - this is a configuration file that's easy
07:23 - to read and it's going to allow you to
07:25 - change the way that it looks when it
07:26 - boots up now grub 2 also has a ton of
07:28 - other cool features it can boot from an
07:31 - iso file from a usb disk it can name or
07:34 - it can identify hard drives based on
07:36 - their uuid or their device like dev sda
07:38 - so it's a lot more advanced than grub
07:41 - one but one of the you know the
07:43 - advancements that's also a frustration
07:45 - is that boot menu that i talked about
07:46 - that comes up with grub it's hidden with
07:49 - grub 2. so it just goes right to the
07:51 - login screen you never see anything from
07:53 - grub 2. and if you don't know this
07:55 - little trick it can be a real bugger to
07:57 - get into that menu if you want to change
07:59 - something during boot so be sure to just
08:01 - hold down the shift key when the
08:02 - computer is booting up and then boom all
08:04 - of a sudden you're going to get into the
08:06 - grub 2 interactive menu that you can
08:09 - change boot code things on the fly it's
08:11 - really really cool i'll show you what i
08:13 - mean but it's not difficult once you
08:15 - know if you have grub or grub 2 grub 2
08:18 - which allows you to do a lot more
08:19 - configuration stuff now i'm here on an
08:21 - ubuntu system this has grub 2 and if we
08:24 - were to look at let's just look at it
08:27 - etc default
08:29 - grub we're going to see this is just a
08:31 - configuration file we can change these
08:33 - things once you make a change you do
08:35 - have to do sudo
08:37 - update grub you do that it's going to
08:40 - update the boot code inside the boot
08:42 - folder and if we look in that boot
08:44 - folder so go into boot
08:47 - grub type ls i look at that grub dot cfg
08:50 - there's no menu.lst so we know that this
08:53 - is grub 2. so that's how you manage
08:55 - things in grub 2. i'll show you really
08:57 - quickly before we end this is a computer
08:58 - that's turned off if i start this
09:00 - computer and hold down the shift key as
09:03 - long as i hold down the shift key boom
09:05 - we get this menu but if i don't hold
09:06 - that we don't see any menu
09:08 - for us to interact with grub at all now
09:11 - figuring out if you have grub or grub 2
09:13 - can be a little bit challenging if you
09:15 - don't know that simple trick to look for
09:16 - menu.lst but they both do the same thing
09:20 - they tell the computer how to boot up
09:22 - and how to mount its different
09:23 - partitions it's just that grub 2 is
09:25 - definitely an advancement it's more
09:27 - configurable it does more things and
09:29 - it's easier for the end user to manage i
09:31 - hope this has been informative for you
09:33 - and i'd like to thank you for viewing
09:35 - linux is so flexible it can boot from an
09:38 - incredible number of
09:40 - methods or sources now there are several
09:43 - different things we need to understand
09:44 - about the boot processes like is it
09:46 - hardware based or is it software based
09:48 - and i'll tell you what i mean about that
09:49 - in a minute but there are just this
09:51 - multitude of ways that a linux system
09:54 - can boot it can boot over pxe or pxe
09:56 - boot if you haven't seen that it's just
09:57 - the coolest thing ever it's when it
09:58 - boots up completely over the network we
10:01 - can boot from usb from cd ipxc is a more
10:04 - advanced version of pixie i'll talk
10:05 - about that too and then iso images just
10:07 - like the dot iso file you can actually
10:10 - make a grub 2 entry that will boot
10:12 - directly from the iso even though you
10:14 - don't have it burned to a disk or to a
10:16 - usb drive it can live on your system and
10:18 - you can have a grub menu item that boots
10:21 - directly to that iso image it's really
10:23 - flexible what it can do but that
10:25 - hardware software thing i wanted to talk
10:26 - about because where the boot process is
10:28 - taking place is really important some of
10:31 - it is linux specific some of it is not
10:33 - so first of all let's talk about the
10:34 - hardware things now when i say hardware
10:36 - i mean the bios or the uefi the part
10:39 - that takes place before linux is ever
10:41 - introduced and pxe is one of those
10:43 - things pxc which stands for pre-boot
10:46 - execution environment is the way that
10:49 - the hardware says okay i don't see a
10:52 - hard drive or i'm not set up to use a
10:54 - hard drive so i'm going to query the
10:56 - network and it just queries a dhcp
10:58 - server and the dhcp server responds with
11:02 - not only an ip address which is what
11:04 - dhcp servers normally do but also a boot
11:07 - file in a tftp location a tftp server is
11:11 - just a place you can store files on a
11:13 - network and then basically the computer
11:16 - then downloads that
11:18 - image that boot image from the tftp
11:21 - server and that's where linux comes into
11:22 - play that kernel or that boot file is
11:25 - the linux kernel so it downloads it off
11:27 - the internet or off the internet um off
11:30 - of your local network and then it puts
11:33 - it in memory and boots itself from there
11:35 - so pxe starts as just a hardware thing
11:38 - and then turns into a software there's
11:40 - also ipxc which is very similar but
11:43 - instead of using tftp to download that
11:46 - thing it allows you to use http which is
11:50 - faster and usually more reliable than
11:52 - the old-fashioned tftp but it's very
11:54 - similar in concept ipxc if your computer
11:57 - supports it then usb this is also right
11:59 - on the hardware now the hardware
12:01 - determines exactly how to boot from the
12:04 - usb but on the usb itself is where the
12:07 - linux code is right so the hardware
12:09 - knows that it can boot from usb same
12:11 - thing with cd and to be quite honest
12:13 - same thing with a hard drive right the
12:15 - hard drive is booted too because the
12:18 - computer itself understands how to do
12:20 - that but when linux comes into play
12:23 - we'll say the software side of things
12:25 - this is once it loads into linux linux
12:28 - does some things on its own like the iso
12:31 - booting with grub2 that's after linux
12:33 - starts right or after grub starts it
12:35 - says okay i'm in grub now what are we
12:38 - going to do we're going to either mount
12:40 - a partition or we're going to look at
12:42 - this iso file and actually use that as
12:45 - our operating system just like it was
12:47 - burned to a cd so some of this stuff is
12:50 - software this is where you like select a
12:52 - kernel this is where you can have mem
12:54 - test so a lot of the stuff is done in
12:56 - software but most things actually all
12:58 - things have to start in the hardware
13:00 - otherwise you're never going to you know
13:02 - get to the point where the software
13:03 - takes control but it's important to know
13:05 - that pxe
13:06 - ipxc these are not linux specific boot
13:10 - methods these are boot methods the
13:11 - computer supports that linux also
13:13 - supports in that they can provide the
13:15 - boot file so i don't want you to confuse
13:17 - pxe network booting with something
13:19 - specific to linux same with usb and cd
13:22 - we can boot windows from usb or cds
13:25 - and it works you know because the
13:27 - hardware supports it if i'm honest
13:29 - probably the most fun way to boot a
13:31 - computer is using pxe only because
13:34 - there's no media right it just boots
13:35 - directly off the network and for some
13:37 - reason that's just really awesome to to
13:39 - be a part of it's really awesome to see
13:42 - but there are multiple ways that you can
13:44 - boot linux and it's important to know
13:46 - that they're all there it's okay if you
13:48 - don't know exactly how to you know boot
13:50 - from an iso file using grub 2. anybody's
13:53 - going to have to google the specifics of
13:54 - that in order to make it work but
13:56 - knowing all these different processes
13:58 - exist for booting a computer that's
14:01 - vital because that will help you learn
14:03 - and help you troubleshoot when you run
14:05 - into a booting issue when it comes to
14:06 - actually booting the linux kernel there
14:09 - are a lot of problems that need to be
14:12 - solved and it's sometimes sort of like a
14:14 - chicken and an egg scenario you have to
14:16 - do one thing but you can't do that thing
14:18 - until the other thing is done and what
14:19 - do you do first and how do you do it
14:21 - it can be really confusing but basically
14:23 - we want to get the full kernel with all
14:25 - of its modules running so the boot
14:28 - process is very complicated and it might
14:31 - seem over complicated but the issue is
14:33 - to try to get the kernel running and
14:36 - then allow it to access the modules that
14:39 - are stored on the hard drive on your
14:41 - system and it ends up being
14:43 - like i said fairly complicated and if
14:45 - i'm honest i've been a
14:48 - system administrator for over 20 years
14:50 - i've passed lots of certification tests
14:53 - and i have never fully understood every
14:56 - step of the process of booting the
14:58 - kernel so you're going to be like the
15:00 - king of the next nerdy party that you go
15:03 - to because you're going to you're going
15:05 - to know all the trivial pursuit answers
15:07 - when it comes to linux kernels so let's
15:09 - look and see what the boot process
15:11 - actually is and then i'll show you on a
15:14 - system where those files live so i have
15:16 - sort of a little flow chart here now a
15:18 - lot of these steps we probably are
15:20 - already familiar with first the computer
15:21 - either has bios or uefi and that's the
15:24 - hardware on the computer which looks for
15:27 - something that grub or grub too it's one
15:29 - or the other here will provide and then
15:32 - that boot code of you know that grub
15:34 - uses points us to the kernel now this is
15:38 - the stuff where it starts to get a
15:39 - little not confusing so much but
15:41 - complicated it's almost like this fine
15:43 - dance that has to be done now norm what
15:46 - the process is normally is we have the
15:48 - actual linux kernel itself which is a
15:52 - file one file and it's called vm linux
15:56 - or you probably currently see it called
15:58 - vm linus with the z and the only
16:01 - difference here these are the same file
16:04 - the pr the only difference is that this
16:06 - is compressed right it's the z means
16:08 - that it's compressed so it's just a
16:10 - space-saving method uh so usually we use
16:13 - vm linus just to save some room on the
16:16 - system and then this is the the kernel
16:19 - itself with no modules right so there's
16:22 - no modules this is just the base kernel
16:24 - and then
16:25 - once the kernel boots up it will mount
16:28 - all the file systems and then it will
16:30 - have access to all of the modules that
16:34 - it needs to insert to make things work
16:36 - like you know your usb
16:38 - mouse and your keyboard and your monitor
16:40 - and your video card all those things are
16:42 - modules that are loaded
16:45 - into the kernel they're not part of the
16:48 - the static kernel right i mean we could
16:50 - build this huge kernel that includes
16:52 - everything but that's just a waste of
16:54 - resources and so we have this
16:57 - stripped-down kernel that has just
17:00 - enough stuff to make sure that we can
17:02 - mount the file system so that it can
17:03 - have access to all of its modules and
17:06 - then become the full running kernel on
17:08 - our system there's a few problems what
17:10 - if this full kernel
17:13 - and all the modules yeah so basically
17:15 - what if all the modules here are on a
17:17 - file system
17:18 - that this stripped down kernel doesn't
17:21 - know
17:22 - how to mount right it's like well i
17:24 - don't know how to get onto a raid device
17:27 - or i don't have any idea how to mount
17:30 - this fancy new ssd drive that you put
17:33 - into the pcie slot or something well
17:35 - that's where init rd or init ram disk
17:38 - comes into play this is just enough
17:42 - information
17:43 - like module information and driver
17:47 - information to be able to have the linux
17:50 - kernel
17:51 - access the file system so that it can
17:54 - get to its modules so rather than make
17:57 - you know a custom
17:59 - bigger kernel for every specific system
18:02 - what we've done is we have a generic
18:04 - strip down kernel and then this init rd
18:08 - has the stuff we need in order to load
18:12 - the modules
18:14 - by mounting the hard drive or you know
18:16 - whatever we need maybe this is stored in
18:18 - a network drive so we have to have the
18:20 - nfs stuff in order to mount a remote
18:23 - disk on the on the computer so it can
18:25 - access its module so this is just like
18:27 - the the temporary staging area for
18:29 - kernel stuff that we need and this is
18:31 - kind of inserted right into this
18:35 - running stripped down kernel okay now i
18:38 - want to mention this because a lot of
18:40 - people confuse the init ram disk with
18:43 - the init ram file system and they seem
18:47 - similar conceptually they are fairly
18:49 - similar conceptually except that the
18:52 - init ram fs is actually part of the
18:55 - actual kernel itself it's part of this
18:57 - vm linus or vm linux kernel and this is
19:00 - just like it says it's a file system
19:03 - that it creates and mounts in ram and i
19:06 - want to mention this tool even though
19:07 - we're not going to go into it much
19:08 - dracut is a tool that has made this
19:10 - extremely generic using udev and and
19:14 - stuff like that so that it's very
19:15 - flexible but this is basically the tiny
19:18 - little file system that the linux kernel
19:20 - uses in order to do what it needs to do
19:23 - to get to the point where it can load
19:25 - the full kernel by loading modules so
19:28 - init ram fs is a file system that it
19:30 - loads into ram but that's part of the
19:32 - kernel itself this init rd is a ram disk
19:35 - that is mounted alongside of the kernel
19:38 - that allows it to get to the point so it
19:40 - can use the full kernel and knit ram
19:43 - disk is not used after the system is
19:45 - booted up this is just like a temporary
19:47 - staging ground to get to the full kernel
19:51 - wow that was a lot of information but
19:53 - it's really
19:54 - fairly straightforward when you see why
19:56 - it's doing all of those complicated
19:58 - things now i want to show you really
19:59 - quickly some of the files that we talked
20:01 - about so here i am inside ubuntu and
20:04 - this is the boot folder and we can see
20:06 - we have here's the init ram sure enough
20:08 - and this is i have a couple different
20:10 - kernels in here there is an update but
20:12 - the kernel numbers are listed here but
20:14 - here's the init ram disk and here is the
20:17 - actual kernel file itself there's a
20:19 - couple other files the system map
20:21 - actually tells the kernel where on the
20:23 - file system all of its modules live and
20:26 - then config this is the configuration
20:28 - file when the kernel was actually
20:30 - compiled so if you want to see the
20:32 - options that were used there but those
20:34 - are the main files that are on the
20:36 - system one other thing i want to show
20:37 - you is this system.map tells the kernel
20:40 - to look in
20:41 - lib modules and then the name of the
20:44 - actual running kernel and inside there
20:47 - is where you'll see the actual different
20:49 - modules okay and this is where the
20:52 - modules that are going to be loaded in
20:53 - to get that full kernel live so that's
20:56 - the basic uh basics of starting a linux
20:58 - kernel on your system now i know we
21:01 - covered a lot of things and a lot of
21:03 - terms and a lot of concepts but they
21:06 - should make sense once you go through
21:07 - that flowchart of what's happening and
21:09 - why it's happening and in the end which
21:11 - comes first the chicken or the egg well
21:12 - it depends on what you need to do right
21:14 - if you need an egg then the egg comes
21:16 - first if the chicken can handle it on
21:18 - its own no eggs are needed
21:20 - now a kernel panic certainly seems like
21:23 - a really good time to panic but i assure
21:25 - you just because the colonel panics
21:27 - doesn't mean you should soldier but
21:30 - really kernel panic just means that
21:32 - something went wrong with the kernel now
21:33 - there's a couple common causes and
21:35 - there's a couple things we can do
21:36 - depending on what the root cause is now
21:38 - if all of a sudden you're starting to
21:40 - get kernel panics and you haven't done
21:42 - any system updates recently
21:44 - and it's kind of hit or miss it'll
21:46 - happen it won't happen it happens when
21:48 - you're doing something but not another
21:50 - chances are you may have a piece of
21:51 - faulty hardware and this is one of the
21:53 - really common ways that you can
21:55 - experience a kernel panic
21:57 - if you have an overclocked cpu for
21:59 - example that can sometimes cause kernel
22:01 - panics a bad stick of ram is another one
22:03 - that'll really do it and you know some
22:05 - add-on card like video cards are
22:07 - sometimes you know guilty of doing this
22:10 - really anything on your system any
22:11 - hardware if it fails it can cause a
22:14 - kernel panic there's a couple ways to
22:16 - you know try different things especially
22:17 - if you have multiple sticks of ram
22:19 - sometimes you can pull out a stick of
22:21 - ram see if you still get a kernel panic
22:23 - if you do then put that stick back in
22:25 - and keep pulling them out one at a time
22:27 - and see if the kernel panics
22:28 - automatically go away when you remove
22:30 - one certain stick hey chances are that's
22:32 - what's wrong with you know that certain
22:34 - stick is a bad stick of ram it can be
22:37 - frustrating to track down hardware
22:39 - related kernel panics but there's also
22:41 - another very common kind of kernel panic
22:43 - that happens and that's when you upgrade
22:45 - your system so let's say that you just
22:48 - ran a system update on your system and
22:50 - it installed a new kernel you reboot the
22:53 - computer and then boom it says something
22:55 - like failure to init or kernel panic
22:57 - blah blah blah blah if that happens
23:00 - there is something that you can do which
23:02 - is fairly easy to do and you can you
23:04 - know rescue your system so to speak so
23:07 - when it boots up we're just going to go
23:08 - into grub and we're going to pick an
23:10 - older kernel because when you update a
23:11 - system
23:12 - it keeps the older kernel for this exact
23:15 - reason if something goes wrong you can
23:17 - pick a different kernel and boot the
23:18 - system and then fix it so i'll show you
23:20 - what i mean
23:21 - here we are on our ubuntu system and
23:24 - let's say i just recently updated it and
23:26 - during the update it says now i need to
23:29 - restart my system so i'm going to
23:30 - restart the system and everything should
23:32 - go well blah blah blah blah
23:35 - and then boom we get a kernel panic now
23:37 - this doesn't actually give us the words
23:38 - kernel panic because i did something
23:40 - fairly simple to simulate what would
23:42 - happen if there was some corruption in
23:44 - the kernel uh but it says here you know
23:46 - it's unable to find the init rd
23:48 - sometimes you might see kernel panic
23:49 - init
23:50 - or unable to kill init or something like
23:52 - that it says press any key to continue
23:54 - but
23:55 - there's nothing that's going to happen
23:56 - right it's kind of locked up on me
23:58 - because it aired out there's no init rd
24:00 - so what we're going to do is restart the
24:02 - system and when we do that we're going
24:03 - to initiate the grub menu by holding
24:05 - down the shift key so first of all we do
24:08 - need to restart the computer i'm going
24:10 - to hold down the shift key and we should
24:11 - get presented with a grub menu sure
24:13 - enough here's our grub menu
24:16 - advanced options and we're going to see
24:18 - here we have multiple kernels
24:20 - this is the kernel the newest one is the
24:22 - one that it tried to boot by default so
24:24 - i'm just going to go back to the last
24:26 - successful kernel that we had
24:28 - press enter and it should boot this up
24:30 - and our system should be just fine then
24:31 - all we need to do is remove that kernel
24:34 - package with the failed thing using our
24:36 - app system reinstall it again you know
24:39 - do an update so it reinstalls and then
24:41 - it should install that init rd back in
24:43 - place and we should be fine so it's nice
24:46 - that linux keeps a few of the older
24:49 - kernels kind of in line so that we can
24:51 - do exactly this if something goes wrong
24:53 - with one kernel
24:55 - or we've deleted modules or just
24:56 - something doesn't load or we get a
24:58 - kernel panic we can select a previously
25:01 - successful kernel and then here we are
25:03 - on our system working perfectly and now
25:05 - we can go through and remove that
25:07 - package and fix it etcetera etcetera
25:09 - etcetera so if you do get the kernel
25:11 - panic especially on a production system
25:14 - oh it can be really scary but know that
25:16 - there are ways
25:17 - you know to fix it if it's just a kernel
25:19 - corruption you can boot to a previous
25:21 - kernel if it's a hardware issue it's a
25:22 - little harder to troubleshoot but you
25:24 - can also do something like boot from a
25:26 - usb drive or a cd and at the very least
25:29 - you'll be able to access the hard drives
25:31 - so that you can get stuff off of your
25:33 - computer if it is a hardware failure
25:36 - that's causing the problem and then
25:38 - you'll have your data to put onto a new
25:40 - computer but kernel panics are no reason
25:42 - to panic it's just one more thing that
25:43 - we need to understand how is working so
25:45 - we can fix it or troubleshoot the
25:47 - problem and move on from there
25:50 - we know that the linux kernel is modular
25:52 - in that it doesn't load all of the
25:54 - drivers that it could possibly ever need
25:57 - automatically by default it has these
25:59 - modules that it dynamically loads when
26:01 - it discovers that it needs like a driver
26:03 - for a certain sound card on boot now we
26:05 - can configure it to automatically load
26:08 - those modules by setting it up in a
26:10 - config file which we're going to look at
26:12 - now what happens though is it'll load
26:14 - that module but then on behind the
26:16 - scenes there's some incredible
26:17 - dependency checking going on and that
26:20 - dependency checking is really really
26:23 - good at knowing what modules one you
26:26 - know a particular module will depend on
26:29 - there may not actually be a robot called
26:31 - modbot in your system or even in my
26:33 - system i just like to think of a cheesy
26:35 - robot plugging in different modules in
26:37 - my computer but nonetheless the computer
26:40 - is really good at finding
26:42 - dependencies in fact sometimes it's too
26:44 - good and we need to blacklist certain
26:47 - modules so that modbot doesn't say oh
26:49 - this one will work and put it in i'm
26:51 - going to show you why we would do that
26:53 - and also how to do that but we're
26:54 - looking at two concepts today how to
26:56 - automatically load a module on boot and
26:58 - how to make sure that the wrong module
27:00 - isn't loaded on boot automatically by
27:02 - the system detecting a dependency that
27:04 - you don't want it to use
27:06 - now here on our this is an ubuntu system
27:08 - but all linux distributions have kernels
27:11 - we're going to go into the etc folder
27:14 - and there's a file here called modules
27:16 - so we're going to look at that
27:18 - we can see right now it's empty it says
27:20 - kernel modules to load at boot time this
27:22 - contains the names of the kernel modules
27:24 - that should be loaded at boot time one
27:26 - per line lines begin with this are
27:28 - ignored so what we would do is put the
27:30 - name of the module
27:33 - and we would add something like e
27:35 - 1000 which is the name of an intel
27:37 - network card module now normally the
27:40 - system automatically detects the
27:42 - hardware and it knows what to load but
27:44 - we want to i'm going to give you an
27:45 - example of how you can manually load a
27:47 - kernel module and have it done
27:49 - automatically on boot even if the system
27:51 - doesn't you know detect it on boot like
27:53 - oh i have new hardware i need this
27:55 - particular module so this is how you
27:56 - would manually do it right now we're not
27:58 - actually going to save this because i
28:00 - don't want to load that module but let's
28:02 - say that's loaded now if there are
28:03 - dependencies it will also load those
28:06 - dependencies let's say that the intel
28:08 - e1000 network card also requires the pci
28:11 - bus to work well then it would load the
28:12 - pci bus
28:14 - module so it's really smart but let's
28:16 - say that there are two different pci
28:18 - modules there's like uh pci version one
28:21 - and pci version 37 and by default it's
28:24 - going to load pci version one and we
28:26 - don't want that so what we would do is
28:28 - blacklist it so if we go into
28:30 - etc mod probe.d first i want to show you
28:33 - there's a bunch of files in here
28:34 - anything with dot conf is read in right
28:36 - so it doesn't matter which one you put
28:38 - it in there's just some conventions here
28:40 - anything we're going to manually put in
28:41 - we're going to put into blacklist.com so
28:44 - let's actually edit that file
28:47 - and we're going to see there are a bunch
28:49 - of things that are already blacklisted
28:51 - now what this does it just makes it so
28:54 - that the kernel doesn't automatically
28:57 - load it like here's a let's look at this
28:59 - ethernet one okay so this is an e1394
29:02 - this is a firewire network device all
29:05 - right it's saying here we never want to
29:07 - use a firewire network device so if you
29:10 - detect a firewire device i do not want
29:12 - you to load the e1394
29:15 - or the ethernet module for a firewire
29:18 - port so if we put blacklist here it's
29:21 - not going to load it even if we put in
29:23 - the firewire module itself so that it
29:26 - activates that port this will make sure
29:28 - that the kernel or modbot or whatever
29:30 - however you like to visualize it doesn't
29:32 - say oh well you're putting that in why
29:34 - don't we also activate the ethernet
29:36 - ability of that port we don't want that
29:37 - so we put blacklist in here same thing
29:39 - like that i've i've done this the most
29:41 - with sound cards because there are like
29:43 - 150 different sound card drivers for the
29:46 - ac 97 model of sound cards so a lot of
29:50 - times you have to blacklist a bunch of
29:52 - different models and see there's a
29:53 - blacklisted sound card right here right
29:55 - this is saying don't load this module
29:57 - that's not what i want and this looks
29:59 - like it's because of an ubuntu bug all
30:01 - right so anyway this is where we tell it
30:03 - what not to load even if it's compiled
30:05 - in and it's part of the module we would
30:06 - put it in here or any of the files in
30:09 - this folder
30:10 - anything that says blacklist space blank
30:12 - is going to be blacklisted honestly like
30:15 - i mentioned the linux kernel is usually
30:18 - really good at automatically detecting
30:21 - hardware and loading all of the modules
30:23 - all on its own by detecting new hardware
30:26 - on the system but if there are times
30:28 - where you want to manually load
30:30 - something but you want it to be done on
30:32 - boot that's where we would put it in the
30:33 - etc modules file and then blacklisting
30:36 - is really important especially if you're
30:37 - having problems with something like uh
30:39 - it just doesn't work with this kernel
30:40 - module let me blacklist that so the
30:42 - kernel will pick another
30:44 - module and try to activate that one
30:48 - one of the things that makes the linux
30:50 - kernel very special is that it's modular
30:52 - so we don't have to install all of the
30:55 - drivers for all the potential hardware
30:57 - in a system we just installed the
30:58 - drivers and the modules for the things
31:00 - that exist it makes the linux kernel
31:02 - very efficient because we don't have all
31:04 - that bloat all those unneeded things
31:07 - sitting in memory where they're never
31:08 - going to be used so the kernel can be
31:10 - very very efficient because of its
31:12 - modular design but in order to take full
31:15 - advantage of that we have to make sure
31:16 - that we're putting the right modules in
31:19 - the right place with all the
31:20 - dependencies so we don't end up with a
31:22 - kernel looking like this right with
31:23 - pieces that don't belong thankfully
31:25 - there are a handful of tools that we can
31:27 - use to properly manipulate the kernel
31:29 - modules and the first two i want to look
31:31 - at are ins mod and mod probe because on
31:34 - the surface they appear to do the same
31:35 - thing insert modules into the running
31:38 - kernel this is after we're booted it'll
31:40 - insert them into the running kernel so
31:42 - let's compare them to scientists right
31:44 - so ins mod is a very basic program you
31:48 - have to give it the full path of the
31:50 - kernel module that you want to install
31:52 - it doesn't do any dependency checking it
31:54 - just kind of slams it into the running
31:56 - kernel and if the kernel doesn't work
31:59 - like it's the wrong kernel version or it
32:01 - doesn't have the proper dependencies
32:02 - it's just going to fail and it's not
32:04 - going to give you an explanation as to
32:06 - why it's just going to say well i
32:07 - crammed it in there and it didn't work
32:09 - boom
32:10 - but mod probe on the other hand is a
32:12 - more advanced program it's a more
32:14 - efficient model and what it does you can
32:17 - give it just the name of the kernel
32:19 - module you don't have to give it the
32:20 - full path you can give it the just the
32:22 - name of the module itself it will look
32:25 - and determine all of the dependencies
32:27 - that that module needs so if one module
32:29 - needs you know depends on another module
32:31 - it will say oh let's load that other one
32:33 - first it does a really good job now it
32:35 - does need us to have a map of all the
32:37 - all the needs and dependencies on a
32:39 - system but there's a program to do this
32:41 - we just make sure we type dep mod when
32:44 - we're done installing a new kernel
32:45 - module and it will recreate that map so
32:47 - modprobe knows where to you know find
32:50 - the dependencies now you might be
32:51 - thinking okay well obviously i'm going
32:53 - to use modprobe when i insert modules
32:55 - and exactly that's what you should do
32:57 - why does insmod even exist well here's
33:00 - the deal mod probe
33:02 - actually knows what modules to install
33:05 - and then behind the scenes it uses ins
33:08 - mod to do the actual inserting so mod
33:10 - probe is really kind of a front end
33:12 - that's very intelligent about what to do
33:14 - on the system but that's why insmod
33:16 - still exists it's still the you know the
33:18 - basic tool that is used to cram modules
33:21 - into the running kernel modprobe just
33:23 - knows which kernels to load and in what
33:25 - order to load them so modprobe is what
33:27 - the humans use and ins mod is what
33:30 - modprobe uses if that makes sense
33:32 - it's really easy to see that in action
33:34 - on our system so i'm root on ubuntu here
33:37 - and let's go into lib
33:39 - modules and we're going to see we have
33:41 - folders for each of the kernels
33:43 - installed on the system we're going to
33:44 - go into the one that we're currently
33:45 - running which is the latest one
33:47 - and inside here we'll see this is where
33:49 - we have a lot of like the map files for
33:51 - the mod probe so it knows where the
33:53 - kernel modules live let's go into the
33:55 - kernel folder where the modules live
33:58 - type ls let's go into the drivers folder
34:01 - type ls again oh there's still a lot of
34:03 - drivers let's go into the net folder all
34:05 - right there we actually see some kernel
34:07 - modules here okay so uh we're gonna play
34:09 - with thunderbolt
34:10 - net but let's say we wanted to load this
34:12 - in so we could use thunderbolt as a
34:14 - network device if we wanted to use ins
34:16 - mod we would say
34:18 - ins mod lib
34:21 - modules
34:23 - generic kernel
34:26 - drivers net
34:28 - thunderbolt net because we need the
34:29 - entire path we're going to press enter
34:31 - and it's going to say well i can't do
34:33 - that unknown symbol in module it doesn't
34:35 - work blah blah blah it has a dependency
34:37 - it doesn't tell us what the dependency
34:38 - is but if we were to use mod probe and
34:40 - we were to say
34:41 - mod probe i want you to put in
34:44 - thunderbolt
34:46 - net and that's all we don't have to say
34:48 - a path we don't have to put ko at the
34:49 - end just press enter
34:51 - boom it's automatically installed how do
34:53 - we know well one we didn't get an error
34:55 - it just installed it but if we type ls
34:56 - mod
34:57 - will show us all the installed modules
34:59 - and if we scroll a bit to the top we're
35:01 - going to see well look at that
35:03 - thunderbolt net is installed into the
35:05 - running kernel and we can see the
35:07 - dependency was thunderbolt but modprobe
35:10 - knew to do that and it installed it now
35:12 - there's another tool for removing them
35:13 - and that's rm mod now there's no super
35:15 - smart
35:16 - version and dumb version of these rm mod
35:19 - is kind of halfway between because if we
35:21 - were to say rm mod thunderbolt it's not
35:24 - going to do it it's going to say i can't
35:25 - do that it's in use but at least it
35:27 - tells us what it's in use by right
35:30 - thunderbolt underscore net which that's
35:32 - a little strange because the name of it
35:34 - doesn't have an underscore right if we
35:35 - want to get rid of this we could say
35:37 - first we have to rm mod
35:40 - thunderbolt dash net
35:43 - okay no errors and now if we do the up
35:45 - arrow twice now we can rm mod the
35:47 - thunderbolt module
35:49 - and again no problems because we we got
35:51 - rid of that dependency first so now if
35:54 - we do ls mod we're going to see if we
35:55 - scroll up that they're not in there
35:57 - anymore they're not installed into the
35:59 - running kernel and that's how you can
36:01 - manipulate kernel modules on your system
36:04 - some of the tools are smarter than
36:05 - others but it's really important to
36:07 - understand why they're smarter and like
36:09 - insmod is important still even though
36:11 - you don't want to use it on the command
36:12 - line for doing very much at all now one
36:15 - more thing i just want to tell you about
36:16 - is if you install a new kernel module
36:18 - like you download a piece of hardware
36:21 - and it has its own kernel module and you
36:23 - compile it and so then you have the
36:25 - kernel module that's put in this folder
36:26 - you know so that it's in our current
36:28 - running modules folder you have to type
36:30 - depmod in order for it to update that
36:34 - database or that system map so that
36:36 - modprobe knows where
36:39 - it lives and what dependencies it might
36:40 - have
36:41 - it takes a while and now we have it
36:43 - updated so now we can install that new
36:45 - kernel module because it knows all the
36:47 - dependencies on the system now i know in
36:49 - the picture here i have these you know
36:51 - wrong puzzle pieces put into the puzzle
36:53 - this is actually a lot harder to
36:54 - accomplish than you would think because
36:56 - the tools just fail right they say oh
36:58 - this won't fit or this is the wrong
36:59 - kernel module some of them are smarter
37:01 - about it than others but it's really
37:03 - difficult to put the wrong kernel module
37:05 - into a running kernel but i want to make
37:06 - sure that you understand all of these
37:08 - tools exist how they work what they look
37:10 - for and the difference between them
37:13 - first off we're talking about network
37:15 - connectivity today and the first thing i
37:17 - want to show you is
37:18 - always check the cable now it seems
37:21 - silly right of course the cable is fine
37:22 - this is plugged in just fine however
37:26 - ah see it wasn't plugged in tight and
37:28 - whether it's a jokester in the office or
37:31 - somebody who ran over a cable with a
37:33 - vacuum cleaner or something sometimes it
37:36 - is the cable and you can spend a ton of
37:37 - time on the command line and be very
37:39 - frustrated to discover that it was just
37:41 - a bad cable so that's just a pro tip
37:43 - check the cable make sure it's plugged
37:45 - in tightly and that the little lights on
37:47 - the back are flashing and doing their
37:48 - thing
37:49 - now we could probably do an entire
37:51 - course on troubleshooting a network
37:53 - connection that's not working or not
37:55 - working right but today i want to go
37:56 - over just a couple quick tools so you
37:58 - can determine very quickly what your
38:00 - issue might be on the network so i want
38:02 - to look at ping and then just to check
38:04 - out our address on our computer and so
38:06 - the first thing i want to do is give you
38:07 - this scenario we're on the computer and
38:09 - we're trying to go somewhere like google
38:11 - and it says unable to connect oh we
38:13 - can't get online so the first thing i
38:15 - would do is open up a command line
38:17 - window and i would say let's try to ping
38:19 - google so ping
38:20 - google.com network is unreachable okay
38:23 - well i know that the google dns server
38:26 - has an ip address of 8.8.8.8 so that's
38:29 - the next thing i would do to eliminate
38:32 - whether it's dns right maybe it's dns
38:34 - that's not working so i want to see if
38:36 - my network itself is working so i'm
38:37 - going to say ping
38:39 - 8.8.8.8
38:40 - ah network is still unreachable okay so
38:43 - there's an issue with more than dns that
38:45 - means that there's a problem with my
38:47 - network so let's look and see what our
38:49 - network address looks like now there's a
38:51 - couple tools you can try to type
38:53 - ifconfig if this doesn't work yes see
38:55 - it's not on my system it's a newer
38:57 - system so type
38:58 - ipad for address
39:01 - and it will give you the ip addresses on
39:03 - your local computer for your network
39:06 - devices so this is the localhost
39:09 - 127.0.0.1 this is just like a virtual
39:11 - host that says it's it's local so we
39:13 - don't want to use this one but this is
39:14 - our ethernet port right eth0 and it
39:17 - looks like we have an address of
39:18 - 10.10.10.10.
39:20 - so i would say let's ping that so let's
39:22 - make sure that you know our network
39:24 - stack itself is working okay so this is
39:26 - working i can ping my own ip address so
39:29 - the ip stack itself is working i'm going
39:31 - to hit control c
39:33 - but for some reason i'm unable to ping
39:35 - out of the network now let's assume that
39:37 - my
39:38 - gateway address is 10.10.10.1
39:41 - ping 10.10.10.1
39:45 - okay i can ping other computers on my
39:48 - network so it's not well first of all we
39:50 - know it's not my computer cable right
39:52 - because i can ping a different computer
39:54 - that's across the network but i'm still
39:57 - unable to ping google so for some reason
40:00 - my internet connection is down
40:03 - well let's look at our ip routing
40:05 - information i'm going to type ipspace
40:09 - route
40:10 - and press enter
40:12 - alright it looks like
40:14 - 10.10.10.0-24 so this network is
40:17 - directly accessible via eth0 okay so
40:20 - that's working that's why we could ping
40:21 - this up here but if you'll notice now
40:24 - you might not notice but there's a line
40:25 - here that's missing we don't have a
40:28 - default route set so that means that the
40:30 - computer while it can access other
40:33 - network or other computers on our local
40:34 - network it doesn't know where to send
40:36 - network or where to send packets that
40:38 - are destined for another network there's
40:40 - no
40:41 - ip routing information here now if this
40:44 - is an ip routing nugget i could say okay
40:46 - let's add a route manually but this is
40:48 - more of a troubleshooting nugget so
40:49 - here's the deal probably when we got our
40:52 - dhcp address we didn't get all the
40:54 - information or something fell apart the
40:56 - first thing you do is either turn it off
40:58 - and turn it back on right that's that's
41:00 - the standard it guy response right well
41:02 - in this case it might work or we could
41:04 - actually go and just go to our wired
41:07 - network interface here turn just the
41:10 - network interface off
41:13 - connect again turn it back on and now
41:16 - let's well let's just look and see what
41:17 - our ip route information looks like
41:19 - hahaha look when we brought our network
41:22 - interface down and back up now we have a
41:24 - default route added so now let's see if
41:26 - we can ping google.com
41:29 - boom we're able to ping it we go over
41:31 - here and we should be able to access
41:34 - google as well and sure enough there's
41:36 - google so we've successfully
41:38 - troubleshooted the problem with our
41:39 - network connection in our case it was a
41:41 - route thing and really just turning off
41:43 - the network interface and turning it
41:44 - back on was the way to solve it but the
41:47 - important part is going through the
41:48 - process of determining where the problem
41:50 - is we knew it wasn't a network line or
41:52 - that network cable because we were able
41:54 - to ping other computers on our network
41:57 - so it's just a matter of troubleshooting
41:59 - and going down the list of where can i
42:01 - connect where can i connect and what
42:03 - might cause those issues figuring out
42:05 - connectivity problems is sometimes more
42:07 - of an art form than it is a science you
42:09 - just have to kind of put yourself in the
42:11 - mindset of a packet and say okay what
42:13 - information do i need to go from point a
42:16 - to point b and what is stopping me from
42:19 - getting in between there tools like ping
42:21 - were are able to make sure that you can
42:23 - or can't connect to remote computers and
42:25 - then using the ipadd you can see what
42:28 - your address is we also used iprout
42:32 - to look at the ip route information and
42:34 - that's where we discovered we didn't
42:36 - have a default route but tools like this
42:38 - are what you can use to troubleshoot
42:39 - your connectivity to figure out what's
42:41 - going on but don't forget always check
42:43 - that cable because sometimes it's just a
42:45 - physical cable unplugged
42:48 - dns or domain name system is the way
42:52 - that your computer converts a url or a
42:54 - domain name like google.com into the
42:58 - numbers the ip address that the actual
43:01 - computer knows how to connect to using
43:03 - ip routing so google.com
43:06 - isn't really helpful for anything except
43:08 - for dns really what the computer needs
43:10 - is that ip address so that it can get
43:11 - there now there's a couple tools that we
43:13 - can use to test dns on our system one of
43:15 - the most common is ping right you just
43:17 - ping and see if it can reach it if it
43:18 - can reach it and get a response hey it's
43:20 - working great but there are three other
43:22 - common tools that i want to cover dig
43:25 - nslookup in host and let's actually look
43:27 - at those individually because they all
43:29 - do about the same thing but they do it
43:31 - in a slightly different way now dig is
43:34 - the program that i use most often only
43:36 - because it has a cool name right there's
43:38 - really no reason that i use it other
43:39 - than the word dig is just kind of cool
43:41 - so
43:42 - dig
43:43 - you type dig and then you can just type
43:45 - the host you want to look up like dig
43:47 - google.com and it will use your default
43:50 - dns server and look it up if you want to
43:52 - specify a dns server for it to use
43:55 - instead of the one that your system is
43:57 - currently using which is a way that you
43:59 - can test your particular dns server you
44:01 - you put the at symbol and then the ip
44:04 - address of the server that you want to
44:06 - query now the other two programs can do
44:08 - the same thing they just do it in a
44:09 - different order you can say nslookup and
44:11 - the host you want to look up and then if
44:14 - you want to specify a server again you
44:15 - don't have to but if you want to then
44:17 - you put the server after that same thing
44:19 - with the host command you put type host
44:22 - the host name you want to look up and
44:23 - then if you want to specify a server you
44:25 - put it there if you leave it off it'll
44:27 - use your default and they all like i
44:29 - said do kind of the same thing so let's
44:31 - look at them really quickly and then
44:33 - i'll talk about how to query different
44:35 - servers and do just a little bit of
44:36 - troubleshooting on your system because
44:38 - testing dns is kind of vital if you want
44:41 - things to work on your system and they
44:43 - don't seem to be so first of all let's
44:45 - look at them all
44:46 - how they function just by default so i'm
44:47 - going to say dig
44:49 - google.com
44:50 - all right and this is the response i get
44:52 - it's queried my default server and we
44:55 - can look my default server is listed
44:57 - right here
44:59 - 8.8.8.8 so that's pretty awesome and
45:02 - this is the response it gets there's a
45:03 - bunch of a records for google.com now
45:06 - let me clear the screen we can do the
45:08 - same thing with ns lookup
45:10 - google.com and this is going to give us
45:12 - a little bit different format right it
45:14 - says our server right here this is the
45:16 - oop i missed i highlighted the wrong
45:18 - line that's our server the same server
45:20 - of course it's our default server and it
45:22 - gives us all the addresses these are all
45:24 - the a records a little less detail but
45:26 - it gives us the same information now if
45:28 - somebody tells you that nslookup is
45:30 - deprecated and it's not used anymore and
45:32 - it's going to be abandoned if there's a
45:34 - weird case with nslookup that that's
45:36 - true
45:37 - until it wasn't they were going to get
45:39 - rid of nslookup and replace it with dig
45:42 - but then they came out with bind 9.3 and
45:45 - for some reason decided that ns lookup
45:47 - was going to stick around so we have
45:49 - nslookup and dig and lastly let's clear
45:51 - the screen again we can just say host
45:54 - google.com and this will give us
45:56 - information as well it actually doesn't
45:58 - tell us what default server it's using
46:00 - but it gives us a lot of information
46:01 - these are all of the a records for it
46:03 - these are all you know the ip addresses
46:05 - this one actually also tells us the mail
46:07 - handlers the mx records for google.com's
46:10 - domain which is kind of interesting as
46:11 - well so just pick the one that you like
46:13 - the best and that's what you can use and
46:16 - the reason that it's important to
46:18 - pick one that you like and use it often
46:20 - is so that you're comfortable with it
46:21 - right like i said i usually use dig and
46:23 - that's weird i know because it's the
46:25 - least like common way to
46:27 - handle specifying a server right the
46:29 - other two you do you know like nslookup
46:31 - what you're looking up and then a server
46:33 - with dig you say dig
46:35 - at and let's say
46:38 - 127.0.0.1 that's localhost right so dig
46:41 - at localhost
46:43 - for google.com
46:45 - and we got a response okay google.com
46:49 - and it gave us this address which is
46:51 - different but it came from our local
46:54 - server now it did not get all the same
46:56 - responses that we got from the
46:58 - 8.8.8.8 domain server you know our
47:00 - default domain server if we were to say
47:03 - dig
47:03 - at 8.8.8.8
47:07 - google.com we would get a totally
47:09 - different
47:10 - set of ip addresses so that's why it's
47:12 - really important to be able to query
47:14 - different servers so that you can get
47:16 - different responses because on this
47:17 - computer if we try to ping
47:19 - google.com
47:21 - it's going to try to ping that other
47:22 - address and time to live exceeded it's
47:24 - not ever going to work so there's
47:27 - something wrong with the dns server
47:28 - running on localhost now i'll show you
47:31 - what the problem is
47:34 - the hosts file i've actually sabotaged
47:36 - here this is the etc hosts file this is
47:38 - where your computer will look first for
47:41 - any dns lookups and sure enough i've
47:43 - kind of bamboozled it here i put the the
47:46 - wrong ip address for google.com so i put
47:48 - that in there
47:52 - now if i restart our local server
47:55 - now if i try to ping google.com
47:58 - it's going to be just fine because it's
48:00 - going to actually use the real address
48:01 - that it looked up on the internet but
48:03 - that's how you can use the different
48:05 - tools to specify not only what host you
48:07 - want to look up but what server you want
48:09 - to query when you look it up so
48:12 - whichever one of these makes the most
48:13 - sense to you or whichever formatted
48:16 - results you like best just pick one and
48:18 - use that because you can specify a
48:19 - server for each of the different
48:21 - commands but knowing how to use them is
48:23 - important because troubleshooting
48:25 - usually means querying more than one dns
48:27 - server so you can figure out what the
48:29 - heck is going on
48:31 - one of my favorite things about linux is
48:33 - that everything is configured with text
48:35 - files right it's just plain text files
48:38 - it's awesome and the network is no
48:40 - different it's configured with text
48:42 - files now there are a few differences
48:44 - when it comes to distributions if you're
48:45 - on debian or if you're on centos there
48:48 - are going to be some configuration files
48:49 - that are different because they
48:51 - configure their networks different now
48:53 - there's nothing wrong with being unique
48:55 - i really like the differences in the
48:57 - distributions but there are some files
49:00 - that are consistent regardless of what
49:02 - distribution you're using we're going to
49:04 - call those the common files and that's
49:06 - what we're going to look like look at in
49:07 - this nugget
49:09 - these files here are consistent across
49:11 - the board they're just kind of standard
49:13 - linux files so i want to show you what
49:15 - they are and and where they live and how
49:17 - they are configured and what they do and
49:19 - that's again just the common files
49:21 - there's going to be specifics in the
49:22 - different distros but we're just looking
49:24 - at the files that are common to linux in
49:26 - general in this case we're going to look
49:28 - at the files in ubuntu and the first one
49:30 - i want to look at is the etc hosts file
49:33 - so let's actually become root if we want
49:35 - to edit them we have to be root to do so
49:37 - so i'm going to look at etc hosts
49:39 - there's no extension at the end it's
49:41 - just etc hosts
49:43 - and this is a file that acts kind of
49:45 - like the first resort dns lookup so
49:49 - before a system even looks things up via
49:52 - dns it looks in here and there's a
49:54 - couple things here like localhost and
49:56 - ubuntu this is our hostname are set up
49:58 - in here but we can add something we can
50:00 - say what if we wanted to make sure users
50:02 - were never able to go to google we could
50:04 - say okay
50:06 - 127.0.0.1 which is our localhost is now
50:09 - going to be
50:10 - google.com so if somebody tries to go to
50:12 - google.com they're going to try to hit
50:14 - our local machine and we don't have a
50:16 - web server at all so it's just going to
50:17 - error out so if we save that
50:20 - now on our computer if somebody tries to
50:22 - go to google it's going to fail
50:24 - so google.com
50:26 - unable to connect even though our
50:28 - network is working just fine we could go
50:30 - to yahoo if we wanted
50:33 - it's just a matter of that dns entry in
50:35 - the et cetera hosts file that we kind of
50:37 - broke all right so another place we can
50:39 - look is in the etc ns
50:42 - switch.conf
50:44 - file now this configures a bunch of
50:45 - things on our system like group and
50:48 - password files but what i want to show
50:49 - you specifically here
50:51 - is the hosts line so this is saying
50:53 - where does it look for dns lookups to
50:56 - you know find what the host's ip
50:58 - addresses are the first one is called
51:00 - files this points to etc hosts if we
51:03 - have this listed first that means before
51:06 - it queries a dns server it's going to
51:09 - query that file it's going to look in
51:10 - that file first and then in order these
51:13 - are what it's going to do from there
51:14 - it's going to do you know the mdns for
51:17 - local lookups and then it's going to use
51:19 - a dns server so this is the order that
51:21 - it's going in but the first one it looks
51:23 - in is the files specifically that etc
51:26 - hosts file
51:27 - so you can change the order of that i
51:28 - don't recommend changing the order
51:30 - because that's kind of what we wanted to
51:32 - do but one more thing i want to show you
51:34 - is etc
51:37 - resolve.conf and this is a little bit of
51:39 - a confusing file because while this
51:42 - tells the computer what name server to
51:45 - use you'll notice up here it says do not
51:48 - edit this file now back in the day you
51:50 - would just put name server and then the
51:52 - name server you wanted to use on your
51:54 - system but now this is all handled with
51:56 - the
51:57 - systemd resolve d service and and it
52:00 - creates this file on the fly so really
52:03 - we do not edit this at all network
52:05 - manager handles all of the name server
52:08 - entries in here um or whatever your
52:10 - distribution uses for configuring the
52:12 - network so we don't actually edit this
52:14 - but if you want to see what server your
52:18 - your particular computer is using you
52:20 - can look in here and it looks like it's
52:22 - it's querying
52:24 - 127.0.0.53 which is another ip address
52:26 - to our local computer so that means that
52:29 - it has some sort of local caching dns
52:31 - server and it's not querying directly to
52:34 - the internet
52:35 - now you probably noticed that all of
52:37 - these common files have to do with dns
52:40 - and that's fine but it's it's
52:42 - interesting that dns is kind of commonly
52:45 - configured
52:46 - across the distributions when it comes
52:48 - to actually configuring the individual
52:50 - network
52:51 - devices that's drastically different
52:54 - from one distribution to the next but
52:56 - the common files are generally dns files
52:58 - and that's what we looked at in this
53:00 - nugget
53:01 - ubuntu is one of the most common
53:03 - distributions out there but it's based
53:05 - on and built upon debian so when we look
53:08 - at configuring one it's very similar to
53:10 - configuring the other and that's the
53:12 - case with network files now i want to
53:14 - show you where to find the different
53:15 - network files on an ubuntu or debian
53:18 - system but it's important to note that
53:20 - in the last
53:22 - iteration of their long-term support for
53:24 - ubuntu that's when a change has been
53:26 - made to how the network is configured
53:29 - and what files are used and how those
53:31 - files are configured now there is one
53:33 - commonality between them and that's if
53:35 - you use network manager to manage your
53:37 - network instead of editing the
53:38 - configuration files that hasn't changed
53:40 - you can still use that across all the
53:42 - versions that are current with ubuntu
53:44 - and debian but these two ways have
53:47 - changed so first i want to look at the
53:48 - older version of ubuntu and when i say
53:51 - older i mean one that's still valid to
53:53 - use as of the date today you can still
53:55 - use version 1604 let's see what version
53:58 - this is etc os release so this is ubuntu
54:02 - 1604.1
54:04 - lts long term support and this is still
54:07 - as of today a valid version of ubuntu to
54:10 - use in production but this is configured
54:12 - by going into the etc
54:15 - network directory and there's a single
54:17 - file in here called interfaces so if we
54:20 - look at
54:21 - interfaces we're going to see this is
54:23 - how you configure a network interface
54:25 - with an older version of ubuntu or
54:27 - debian now this is pretty much the
54:30 - stanza that you configure there's
54:31 - usually something in here you can look
54:32 - at and base it off of but this is the
54:34 - format for it we're not going to go
54:36 - through the you know configuring
54:37 - different things it's pretty
54:38 - straightforward you don't have to indent
54:40 - this is just for
54:41 - ease of readability but this is how you
54:44 - configure a network interface via the
54:47 - configuration files now we could still
54:49 - use the um network manager if we were on
54:52 - a gui system like this is a gui system
54:54 - we could use that but i'm actually ssh
54:56 - into a server that doesn't have a gui
54:58 - interface and that's where we use these
55:01 - network files to configure it so let's
55:03 - quit this one this is how you configure
55:05 - an older version but a modern version
55:06 - like
55:07 - 1804 or the most modern version of
55:10 - debian uses a completely different
55:12 - network configuration system now here
55:15 - we're on a newer version of ubuntu this
55:17 - is actually 1804. let's check that out
55:20 - so this is
55:21 - 18.04.1 another long-term support
55:24 - release of ubuntu and this one uses the
55:26 - net plan system for configuring network
55:29 - interface so if you go into etc net plan
55:33 - and you look in here depending on what
55:34 - kind of system you have you're going to
55:36 - have some sort of file in here it's
55:37 - either going to be like zero one
55:38 - networkmanager.yaml
55:40 - or 50 cloudanit.yaml if it's a server
55:43 - the thing about yaml files though let's
55:45 - look at this
55:47 - yaml files do depend on indentation in
55:50 - order to be properly configured so while
55:53 - with the etc network interfaces of the
55:55 - old ubuntu system it didn't matter how
55:57 - things were indented here it really
55:59 - really does and so here this is where we
56:01 - would configure like a static ip address
56:03 - and we you know here's our ip addresses
56:05 - gateway name servers the format's a
56:07 - little different but it's fairly similar
56:09 - conceptually to the old system like i
56:11 - said except for that white space that's
56:13 - really important that it's indented
56:16 - properly so if you make a change to this
56:18 - then you just would do sudo netplan
56:22 - apply and then it will activate the new
56:25 - changes that you made now i do want to
56:26 - point out again this is a gui system so
56:28 - it has network manager but there's also
56:31 - nmtui
56:33 - which is network manager text user
56:35 - interface and then you can edit
56:36 - interfaces using just the text boxes on
56:40 - your screen if you don't have a gui
56:41 - system installed so that's just one more
56:43 - way that you can edit your file in
56:45 - ubuntu or debian if you don't have a gui
56:47 - but you want to use network manager as
56:49 - opposed to just configuring those files
56:51 - on your own whether you have an older
56:53 - system using etc network interfaces or a
56:56 - newer system using configuration files
56:58 - and etc netplan configuring the network
57:00 - on debian and ubuntu is not difficult
57:02 - and you know it's usually just a matter
57:04 - of changing what's existing but if you
57:06 - want to use the network manager to
57:08 - manage all those interfaces either using
57:10 - gui or text tools you can do that as
57:12 - well it's very flexible and even with
57:14 - the change in versions it's not a whole
57:16 - lot more difficult to do one over the
57:19 - other if we've been learning together
57:20 - for a while you know that i prefer
57:22 - debian based distributions and ubuntu is
57:25 - my jam
57:26 - but i have to admit when it comes to
57:28 - network configuration files centos or
57:31 - red hat they really have an elegant
57:33 - solution for how to configure the
57:35 - network and there's no confusion between
57:37 - if you're using the gui network manager
57:40 - or if you're just using the
57:41 - configuration files in the etc config
57:44 - folder let me show you what i mean
57:45 - because centos is just so awesome when
57:48 - it comes to network configuration now
57:50 - here we are on a centos system and it
57:52 - doesn't matter which way you configure
57:54 - the network interface you can go up here
57:56 - and go into the network manager to
57:59 - configure it or we can go directly into
58:01 - etc sysconfig and i just wanted to show
58:04 - you quickly inside the sysconfig folder
58:06 - and sent to us is where all of these
58:08 - configuration things are this is kind of
58:10 - unique to centos and red hat they put
58:12 - most of their configuration inside this
58:14 - etc sysconfig folder but inside here
58:17 - there's also another folder called
58:18 - network scripts and that's where our
58:20 - networking is configured if we look in
58:22 - here we're going to see there is this
58:23 - configuration file for our interface
58:26 - ifconfig dash eth0 so let's look at that
58:30 - if we edit this it's going to change the
58:33 - way our network interface comes up like
58:35 - if we were to change boot proto from
58:37 - dhcp to
58:39 - static and then we were to add a line
58:42 - ipaddr equals let's say 10.10.10.111
58:47 - which is not currently the ip address if
58:49 - we were to do that and save it
58:52 - and then just do a quick sudo service
58:55 - network restart
58:57 - we would be able to restart our service
58:59 - and if we were to do ifconfig
59:02 - we're going to see scroll up here sure
59:04 - enough that is our
59:06 - ip address now now there are a couple
59:07 - problems we didn't add like netmask or
59:09 - anything so let's go up into
59:11 - network manager
59:13 - wired settings
59:15 - click on the configuration thing so
59:16 - we're to edit this in network manager if
59:18 - we go over to ipv4 we can see it went
59:21 - from it used to be dhcp now it's manual
59:24 - this is the ip address i put in and it
59:26 - just guessed this netmask because the 10
59:29 - range is a class a ip address so it
59:31 - guessed that i wanted to use a class a
59:33 - netmask but i don't i want to use
59:35 - 255.255.255.0
59:38 - and i didn't supply a gateway so let's
59:40 - do that now 10.10.10.1
59:43 - and i didn't supply any dns server so we
59:45 - can do that here
59:47 - 8.8.8.8
59:48 - and now we'll save this we'll click
59:50 - apply
59:51 - if we go back and edit that script sudo
59:53 - vi
59:55 - we're going to see that some changes
59:56 - have been made now this stuff is still
59:58 - the same boot proto equals static ip
60:00 - address but look down here it added the
60:02 - gateway address that we added it added
60:03 - the dns server that we added and it
60:06 - added the prefix 255.255.255.0
60:09 - translates to
60:11 - 24-bit netmask so put that in there just
60:13 - use a different form and we can see that
60:15 - it made the changes to the actual
60:17 - configuration files rather than having
60:19 - like two different systems and you have
60:21 - to decide which one you want to use
60:23 - centos allows us to make changes in one
60:25 - place and whether we're using the gui
60:27 - interface or just this text-based
60:29 - interface it's going to allow us to make
60:31 - those changes i love that it has all the
60:34 - change places in a single file as
60:36 - opposed to
60:37 - conflicting and trying to decide which
60:39 - method you're going to use if you use
60:41 - network manager you you're using this
60:43 - configuration file if you don't use
60:44 - network manager you're using this
60:46 - configuration file so it's a really
60:48 - elegant way to handle network interface
60:51 - configuration like i said at the
60:52 - beginning i'm a debian ubuntu man that's
60:54 - what i usually use in my server
60:56 - situations but when it comes to
60:58 - configuring network interfaces man
61:00 - centos has really stolen the show they
61:02 - have an elegant way of doing it either
61:04 - using network manager gui tools or using
61:07 - the scripts inside the network scripts
61:08 - folder of etc sysconfig
61:12 - network bonding in linux is really just
61:15 - a way to utilize computers that have
61:17 - more than one network port and most
61:18 - servers nowadays come with that let's
61:20 - say you have a server and it has
61:23 - three network ports built into it well
61:26 - if you have to connect it to a switch
61:30 - all each of these connected to a switch
61:33 - you would ideally like to use all of
61:35 - that bandwidth and you don't want to
61:36 - have to supply three different ip
61:38 - addresses to the computer you just want
61:40 - to use all of the available bandwidth on
61:43 - all three of those wires and that's
61:45 - where network bonding comes into place
61:47 - now there's basically two different
61:49 - kinds of network bonds that we're going
61:51 - to look at those that require special
61:53 - switch support and those that are
61:55 - generic and don't require the switch to
61:57 - know at all what's going on now linux
62:00 - does provide some pretty cool options
62:02 - when it comes to there but the options
62:03 - can be a little overwhelming i mean this
62:05 - screen is like oh my goodness there's so
62:06 - many choices well that's okay because
62:08 - your choices are going to be fairly
62:10 - limited once you learn what all of these
62:12 - are now the first thing i want you to
62:13 - look at when we're looking at this list
62:15 - is does it require switch support and
62:17 - what i mean by that is a lot of switches
62:20 - especially layer 3 switches or smart
62:22 - switches they're sometimes called will
62:24 - support link aggregation and different
62:26 - vendors call it different things but
62:28 - it's going to be either link aggregation
62:30 - or lacp or ether channel the idea is a
62:33 - smart switch will have built-in code
62:35 - that will allow them to work together so
62:38 - if you have a smart switch chances are
62:40 - that you have the ability to use link
62:42 - aggregation now some of these require a
62:45 - switch that supports that i'm going to
62:47 - start with the confusing one here so
62:49 - balance round robin basically how
62:51 - balanced round robin works is you have
62:53 - multiple ports and it says okay when i
62:56 - transmit packet 1 i'm going to use this
62:58 - port packet 2 is this port packet 3 is
63:00 - this port packet four is this port
63:02 - packet five is this port packet six is
63:04 - this and it just keeps going through
63:07 - packet by packet and transmitting across
63:10 - all of your interfaces now the reason i
63:12 - said it sorta requires switch support is
63:15 - if you're plugging these into a switch
63:18 - it does require a switch that supports
63:20 - link aggregation but what a lot of
63:22 - people do is they'll use this balanced
63:24 - round robin and they will connect two
63:27 - servers together with crossover cables
63:30 - and actually with gigabit we don't need
63:31 - crossover cables anymore but they'll
63:32 - connect two servers together and they'll
63:35 - use balanced route robin and in that
63:37 - case you don't need a switch support or
63:39 - a switch that supports it because there
63:40 - is no switch involved right they're just
63:42 - directly connecting the two computers
63:44 - together and so like if you have a file
63:46 - server that you want to connect to your
63:47 - other server a lot of times this is a
63:49 - way that you can increase throughput
63:51 - without requiring any special switch
63:53 - support so if you're connecting directly
63:55 - computers you don't need to have switch
63:57 - support if you're connecting to a switch
63:59 - you do all right that's mode 0. mode 1
64:02 - is an active backup and this one's
64:03 - pretty easy to understand basically
64:05 - however many ports you have on your
64:06 - system only one is going to be active
64:09 - and if that one fails then another one
64:11 - is going to turn active and that's just
64:13 - how it works they always have one this
64:15 - is fault tolerance but this doesn't
64:16 - speed anything up it just means if one
64:18 - fails another one's going to come online
64:20 - all right this doesn't require switch
64:22 - support because
64:23 - you know it basically just only uses one
64:26 - port unless the next one fails and then
64:27 - you switch to that port and the switch
64:29 - is like okay so now we're going to use
64:30 - this port great uh balance xor
64:33 - does require special switch support and
64:36 - this is kind of cool how balance xor
64:38 - works basically you have your computer
64:41 - here your linux computer and it does a
64:43 - hash based on your mac address and the
64:47 - client's mac address and so here's
64:49 - another client over here and basically
64:51 - it says okay based on this hash i'm
64:53 - always going to use port 1 to connect to
64:56 - this client and then over here the hash
64:58 - is different so i'm always going to
64:59 - connect to this computer so it's
65:01 - basically a way to just spread out
65:04 - which computers use which port but this
65:06 - computer is always going to use this
65:08 - port and this computer is always going
65:10 - to use this port now this isn't used
65:13 - very often because if you have switch
65:15 - support which is required chances are
65:17 - you're going to use
65:18 - 802.3ad which is the industry standard
65:21 - link aggregation protocol right this
65:24 - means that your switch knows what to do
65:25 - and your client knows what to do and
65:27 - it's just a really smart way of
65:29 - increasing through throughput and
65:31 - availability fault tolerance so if your
65:33 - switch supports link aggregation you
65:36 - should use 802.3ad or mode4 which is the
65:39 - industry standard okay so even though
65:42 - balance xor is cool it's not very often
65:44 - used because if you can use it you might
65:45 - as well be using the one that's even
65:47 - better broadcast i kind of skipped over
65:49 - that broadcast is only in very specific
65:51 - cases that you would use it it just
65:53 - takes all of your ports on the server
65:55 - and spews all of the data out all of the
65:57 - ports at once it's not used very often
66:00 - and it definitely requires your switch
66:01 - to know what on earth is happening now
66:03 - the two i do want to focus on a little
66:05 - bit are these bottom two let's say you
66:07 - have a dumb switch it's not a switch
66:09 - that supports link aggregation it's just
66:11 - one you bought from amazon for 40 bucks
66:13 - it's gigabit but it doesn't have any
66:15 - smarts built in
66:16 - linux is smart enough to be able to
66:18 - utilize the dumb switch and increase
66:21 - bandwidth and throughput and reliability
66:23 - and there's two different ways it does
66:24 - it balance tlb which is balance transmit
66:27 - load balance and the balance of all load
66:31 - balancing and what this does is let's
66:32 - say we have four ports on our switch
66:35 - okay with tlb it's going to transmit
66:39 - from whichever port is currently the
66:41 - least busy so all the transmit is going
66:44 - to be balanced out now incoming is still
66:46 - going to always go to one active portent
66:48 - so that's not as good as alb which is
66:51 - the same concept except it does it for
66:54 - incoming and outgoing so basically the
66:56 - least busy port gets the traffic and
66:58 - this is really brilliant and how it does
67:00 - is it constantly changes the mac address
67:04 - on these ports or on these ethernet
67:06 - cards so the switch is like oh you moved
67:08 - again oh you moved again oh you moved
67:10 - again and from the switches standpoint
67:12 - it doesn't care how many times you
67:13 - switch the mac address so it generally
67:15 - works just fine now some people have
67:17 - issued with this i've used this in
67:19 - production for years and never had a
67:21 - problem so balance alb if you have a
67:24 - dumb switch i highly recommend you use
67:26 - mode six okay if your switch supports
67:29 - link aggregation i highly recommend mode
67:31 - four because that's the industry
67:33 - standard and if you're just connecting
67:34 - two servers together with multiple
67:36 - cables my shirt mode zero works really
67:38 - great to be honest the most difficult
67:40 - part of linux network bonding is
67:42 - figuring out which mode to work but
67:45 - really it's not that tough of a decision
67:46 - if your switch supports it use 802.3ad
67:49 - there's really no reason not to if your
67:51 - switch is a dumb switch and doesn't
67:53 - support it i highly recommend mode 6 or
67:55 - balance alb if you want to take
67:58 - advantage of bonded network interfaces
68:00 - but you don't have the expensive
68:02 - hardware that will support it
68:04 - once you know the type of bond that you
68:06 - want to set up for your two ethernet or
68:08 - two or more ethernet connections on the
68:10 - computer configuring them is pretty
68:12 - straightforward although it's
68:13 - drastically different depending on
68:15 - whether you're on ubuntu or centos so
68:17 - i'm gonna show you how to do it on both
68:19 - and then i'll show you also how to test
68:21 - it to make sure that the bonding modules
68:23 - are working so here i am on ubuntu i've
68:25 - actually already configured it so i've
68:27 - gone into etc
68:29 - netplan and i have my file in here so
68:32 - let's look at this file and what i've
68:34 - done is i've set up the proper yaml
68:37 - format with indentation and everything
68:38 - to set up bonding so i'll go over it
68:40 - really quickly first of all we need to
68:42 - use network d as our renderer we can't
68:45 - use network manager in order to
68:47 - configure bonds because it just doesn't
68:48 - support bonding
68:50 - we do have to define the ethernet cards
68:53 - themselves so ethernet eth0 i set dhcp4
68:56 - to false because i don't want it to
68:58 - actually assign an address to eth0 after
69:01 - all that is done we don't need to set up
69:03 - anything more for the ethernet ports
69:04 - themselves then we need to set up a
69:06 - bonded interface so a new section here
69:09 - bonds the name of it is bond 0 dhcp 4 is
69:13 - false because i'm going to assign a
69:14 - static ip address and the interfaces is
69:18 - a section that we tell it what
69:19 - interfaces are going to be a part of
69:21 - this bond in our case we only have one
69:23 - which is silly i mean we're only bonding
69:25 - one interface but you can do that one or
69:28 - more it's just silly that we only have
69:30 - one to bond that's just all this
69:31 - computer has i've set up the addresses
69:34 - the gateway
69:35 - the name server is set up just like it
69:37 - would be if we were setting it up for
69:38 - eth0 really the only new difference down
69:40 - here is the parameters and the
69:42 - parameters what i've done is mode active
69:45 - backup that's just one of our modes it
69:47 - happens to be
69:48 - mode one but we actually say active
69:50 - backup we specify by name the mode here
69:52 - and then we save this file and do
69:55 - netplan
69:56 - apply now how you can tell if it's
69:58 - working we can do ipadd
70:00 - to see that you know sure enough it's up
70:02 - here's our bond zero interface here's
70:03 - our ethernet zero interface which is up
70:05 - but doesn't have an ip address and
70:07 - another way you can test is to look at
70:09 - so we're just going to cap the file it's
70:11 - in the virtual file system proc under
70:14 - net
70:15 - bonding
70:16 - bond zero so if we look at this file
70:19 - it's going to tell us the information
70:20 - about it and say bonding mode is fault
70:22 - tolerance active backup
70:24 - primary slave none but the current
70:26 - active slave is eat zero it's our only
70:27 - one that we have it's up and it looks
70:30 - like everything is working good here's
70:31 - our slave interface eth0 down here and
70:33 - that's all working well as well so we
70:36 - have it all set up and it's working now
70:38 - with centos the setup is a little bit
70:40 - different because centos is set up
70:43 - differently in centos in order to
70:45 - configure our ethernet ports we go into
70:47 - etc sysconfig
70:50 - network scripts and in here we have our
70:53 - ifconfig files so i'm going to first
70:55 - look at the changes we have to make to
70:56 - ifconfig eat zero so
70:58 - here we basically we make it pretty
71:00 - simple ethernet type product boot
71:02 - protocol is none uh the name the device
71:04 - is zero on boot we want it to come up
71:06 - but notice i haven't given any ip
71:08 - addressing information and here are the
71:10 - two things the master
71:12 - is bond zero and yes this is going to be
71:14 - a slave to this bond all right so those
71:16 - are the changes we make here if we look
71:19 - at if config bonds zero this is where we
71:22 - set up bond zero we name it bond zero
71:24 - bonding master is yes i did give this
71:27 - one an ip address and a prefix which
71:29 - means the subnet mask
71:31 - on boot we want it to come up a boot
71:32 - protocol is none and then here the
71:34 - bonding options we tell it what we want
71:36 - it to do i actually set this one up to
71:38 - mode 6 mode 6 is balance all load
71:42 - balancing so it does its own version of
71:44 - load balancing for incoming and outgoing
71:46 - traffic again i only have the one
71:48 - interface on this computer but that's
71:50 - okay
71:51 - let's do the same thing now checking to
71:53 - make sure it's working is similar we can
71:55 - do ipadd we can see sure enough here's
71:58 - the bond set up right here and our
72:00 - ethernet is right here
72:02 - and really for configuring the bonds
72:04 - themselves that's all there is to it
72:05 - ubuntu and centos are configured
72:07 - differently but underneath they're both
72:09 - doing the same thing they're using the
72:11 - bonding kernel module and they're
72:12 - allowing you to do some awesome things
72:14 - with multiple ethernet ports on your
72:16 - computer
72:18 - gpt and mbr are two different ways of
72:22 - taking a hard drive and chopping it up
72:24 - into pieces so that those pieces can be
72:27 - recognized and mounted as different
72:28 - drives and stuff on your on your system
72:30 - so they're they do the same thing but
72:32 - gpt is much newer and much more
72:36 - feature-rich than the old-school mbr now
72:39 - there's also a really cool thing called
72:40 - protective mbr i want to talk about but
72:42 - basically we're going to talk about the
72:43 - differences between gpt and mbr here i
72:46 - have two big squares and i'm going to
72:48 - say that these actually they're
72:49 - rectangles
72:50 - i'm going to say that they represent the
72:52 - drives themselves and they're going to
72:53 - be partitioned with two different
72:56 - systems so we'll start over here with
72:57 - the old one mbr which stands for master
73:01 - boot record okay now how this would work
73:04 - is let's say this drive is device
73:08 - sda okay so this is the device on the
73:11 - linux system it recognizes this drive
73:14 - now the mbr is a little tiny bit of
73:17 - reserved space
73:19 - at the very beginning of the disc and
73:21 - this is basically like a table of
73:22 - contents and it describes
73:25 - how
73:26 - this is chopped up okay so this is
73:29 - chopped up into let's say four pieces
73:31 - there's four primary partitions you can
73:33 - also cut each one of the primary
73:35 - partitions into four so we could have
73:37 - you know mult we could have this one be
73:38 - like
73:41 - have four partitions there if we wanted
73:43 - but basically what this means is once
73:45 - the mbr defines in this little
73:48 - first part of the drive right here what
73:50 - is what we come up with other devices on
73:53 - the system we have
73:55 - dev sda1
73:58 - devsda2 and it goes on down the line and
74:01 - so each of these chunks is referenced on
74:04 - the system as their partition name now
74:07 - this is the raw device dev sda doesn't
74:10 - go anywhere it's still there but the
74:12 - individual partitions get their own
74:14 - device and that's how we reference them
74:16 - on the system so mbr has this you know
74:19 - this little tiny table of contents at
74:21 - the beginning and it says where things
74:23 - are chopped up now gpt or
74:26 - gui guid partition table which i think
74:28 - is interesting because there's an
74:30 - acronym wrapped inside of an acronym
74:32 - this stands for globally unique
74:34 - identifier partition table and basically
74:36 - it does conceptually the same thing
74:39 - right it will chop up this drive and
74:41 - you'll end up with dev sda for the raw
74:44 - device and so on down the line the
74:46 - differences are though gpt does have a
74:50 - spot at the beginning with the table of
74:51 - contents but then it also scatters them
74:54 - copies of them
74:56 - around the drive so that if something
74:58 - were to happen with one of the copies of
75:01 - the gpt it can still figure out what's
75:05 - on the disk it also does some crc
75:07 - correction on the files itself or on the
75:10 - the file system itself so that it knows
75:12 - if there's some corruption and it can
75:13 - fix it it's just very very robust along
75:16 - with the ability to use much bigger
75:18 - drives mbr is limited to two terabytes
75:21 - gpt is limited to i think petabytes i
75:23 - mean there's no practical limit at this
75:25 - point of how much drive space it can
75:27 - talk about rather than being
75:29 - limited by four partitions you can have
75:31 - tons of partitions on here so you know
75:33 - we could chop it up into as many as we
75:35 - wanted and it just goes down the line
75:37 - sda1 sda2 sda3 and one other really
75:41 - interesting thing and i wanted to talk
75:43 - about is the protective mbr so gpt is
75:47 - used on newer systems it's specifically
75:50 - part of uefi that replaces bios but
75:52 - biosystems can still see gpt drives and
75:55 - part of the reason they can do that is
75:56 - at the very beginning
75:58 - there's this section that looks exactly
76:01 - like an mbr basically it's an mbr record
76:04 - here that says okay there is one big
76:06 - partition on this drive the entire drive
76:08 - is a partition
76:10 - there's no room available on this
76:12 - partition and it takes up the entire
76:14 - drive now why would that exist it's
76:16 - basically so systems don't say oh well
76:18 - there's no mbr in this drive so this
76:21 - must be a blank drive with nothing on it
76:24 - well we don't want that to happen so
76:25 - basically what it means is it allows the
76:28 - mbr system or a bio system that is used
76:31 - to seeing mbr it will allow it to
76:33 - realize that this is not an empty drive
76:35 - it's just something it can't read and
76:37 - then there's some really cool stuff
76:39 - where part of this initial mbr can be
76:42 - hints to the operating system itself as
76:45 - to what's happening underneath and so
76:47 - some older bio systems are able to boot
76:50 - from a gpt drive
76:52 - even though it shouldn't be able to
76:54 - because the linux system or you know the
76:56 - operating system itself says okay i see
76:59 - mbr is saying that um you know it's
77:01 - really a gpt drive but i know enough
77:03 - about gpt myself that i'm going to be
77:05 - able to find the software and you know
77:08 - the the drive files and partitions on
77:10 - here myself and so you can actually use
77:13 - it on there but it's because of that
77:14 - protective mbr that all that is possible
77:17 - so when it comes down to it mbr is the
77:19 - old way of doing things gpt is the new
77:22 - kid on the block honestly there's no
77:24 - reason not to use gpt it does everything
77:27 - mbr does it does it more efficiently
77:29 - more reliably
77:30 - it's just the better way to go so i
77:32 - recommend that you use gpt and while
77:35 - there are significant differences a lot
77:37 - of those backwards compatibility issues
77:39 - make it so that you don't even have to
77:40 - worry about them
77:42 - the linux file system is actually really
77:45 - cool because all of the network mounts
77:48 - and different hard drives and usb drives
77:49 - are all on one
77:51 - giant file system it's not there's no a
77:54 - drive b drive c drive d drive there's
77:56 - nothing like that it's just all one big
77:58 - file system hierarchy and we're gonna
78:00 - look at the different things because
78:02 - whether it's a real or virtual file
78:03 - system it's on the same file system
78:05 - whether it's relative or absolute this
78:07 - is just how you traverse
78:09 - the actual file system we're gonna look
78:10 - on the command line about that network
78:12 - mounts they're just you know on a remote
78:14 - system but they just show up as a folder
78:17 - on your local computer it's just it's
78:20 - really cool so first of all let's let's
78:22 - start at the very beginning it's a very
78:24 - good place to start so we have a hard
78:27 - drive right so we're going to say it's
78:29 - dev sda1 and that has the root partition
78:33 - on it you know just forward slash so
78:34 - this is like where everything starts the
78:36 - root partition is the basis of our linux
78:39 - file system it's it's on a hard drive of
78:42 - some sort in our case it's this one now
78:44 - inside there there's tons of files and
78:47 - folders some of the files are directly
78:49 - on that dev sda drive right on the root
78:52 - file system or folders within that root
78:54 - file system they're actually stored on
78:56 - that hard drive
78:57 - some of the folders and the files in
78:59 - there are a virtual file system if you
79:02 - look inside the
79:03 - root directory there's a proc folder an
79:06 - assist folder these are dynamically
79:08 - created file systems that are just a way
79:11 - to interact with the kernel itself so if
79:14 - you want to make a change to the running
79:15 - kernel you can make a change to one of
79:17 - the files in these folders and it's
79:19 - going to affect the running kernel but
79:20 - it's not actually files it's a virtual
79:24 - file system it's just a way that they
79:25 - represent that interface with the kernel
79:27 - is this virtual file system then we also
79:30 - have like a remote nfs server it could
79:32 - be nfs or samba or you know whatever
79:35 - your network protocol of choice is but
79:37 - it's mounted on the folder
79:40 - inside of your root system so this could
79:42 - be like the home folder on your system
79:44 - might not be on the actual hard drive it
79:47 - might actually be on a remote system but
79:49 - it's mounted inside your file system and
79:52 - from you know from a layman's position
79:54 - just looking at the system you don't
79:56 - know if it's a remote system or a local
79:58 - system or a virtual system because they
80:00 - all look the same same thing when you
80:02 - insert a usb drive it doesn't come
80:03 - through as like you know like the e
80:05 - drive or the f drive like on a windows
80:07 - system it's just mounted somewhere on a
80:10 - folder inside that same
80:13 - one solid
80:14 - monolithic file system even if you put
80:17 - in another hard drive so this is we're
80:19 - saying this is dev sda1 like the
80:20 - partition one on the sda drive even if
80:23 - you were to put in a second hard drive
80:25 - in the system it's still going to mount
80:28 - inside a folder or a subfolder of this
80:31 - root
80:32 - drive right it's gonna be like in mount
80:34 - data or wherever you happen to mount it
80:36 - it's just going to appear as a folder
80:38 - inside this root file system so
80:41 - everything is inside that root file
80:43 - system it's really a neat way to handle
80:46 - all of the various things that can be
80:48 - stored in linux and the virtual file
80:50 - system is very unique in that it's not
80:52 - really a file system it's more like an
80:54 - interface designed as a file system so
80:56 - you can interact with the kernel itself
80:58 - alright so let's go to
81:00 - our file system here and i just want to
81:02 - show you kind of how it looks and i want
81:04 - to talk about this whole absolute versus
81:05 - relative thing all right so i'm just
81:07 - going to
81:08 - show you the file system here we have ls
81:10 - and we have a folder called pictures we
81:11 - can do ls picture gotta spell it right
81:15 - ls
81:16 - pictures and i have a folder cbt gold
81:19 - which is this background and then a
81:20 - trips folder uh what if we were to do ls
81:24 - trips
81:25 - okay there's a folder called grocery
81:27 - store mexico orlando now there's a cool
81:29 - program called tree i'm going to use so
81:31 - let's say tree
81:33 - pictures it's going to show us a tree
81:35 - representation of all the files and
81:37 - folders inside here so we can look we
81:39 - have the pictures folder there's a one
81:41 - file in there called cbt gold then
81:42 - there's a folder called trips inside
81:44 - that folder are three different folders
81:46 - grocery store mexico orlando inside each
81:48 - of those there are files that are stored
81:51 - in there this is the hierarchy of that
81:53 - now honestly
81:54 - this mexico folder this could be like a
81:57 - remote nfs share we don't know because
81:59 - it's all on the local file system that
82:02 - is you know mounted everywhere on the
82:03 - system it's just one file system so we
82:05 - don't know where these are we just
82:07 - interact with them as if they're all one
82:09 - local file system so that's just a
82:10 - really cool thing about it but this
82:12 - whole absolute versus relative let's go
82:14 - over to
82:15 - the pictures folder
82:17 - and trips
82:19 - i'm going to clear the screen and if we
82:20 - were to type ls minus a we're going to
82:22 - see all of the things in here now we
82:24 - already saw some of these orlando mexico
82:26 - grocery store but these dot and dot dot
82:30 - now these are special folder entries
82:32 - that mean the dot means the current
82:34 - folder so if i were to say cd to dot
82:37 - i'm in the same folder dot dot means the
82:40 - directory above me so if we are in trips
82:44 - dot dot is going to be pictures so if we
82:47 - were to say cd dot dot
82:50 - all of a sudden you'll see now we're in
82:51 - the pictures folder that's pretty cool
82:54 - right now we can use that as a folder
82:56 - name anywhere so let's go into
82:58 - trips orlando okay and inside here let's
83:01 - do an ls minus la we can see here are
83:04 - all the the pictures that we have and
83:06 - then these two folders dot dot and dot
83:08 - in every single folder you're gonna find
83:10 - a dot and a dot dot because it's just a
83:12 - pointer that means
83:13 - this directory
83:15 - the directory above me okay so we can
83:17 - put that in a string too let's say i
83:19 - want to cd to dot dot
83:22 - dot dot
83:24 - and see where this takes us
83:25 - two pictures now why did it do that well
83:27 - because dot dot if we're in orlando dot
83:30 - dot means trips and then we're in trips
83:33 - the second dot dot means pictures so
83:35 - that's interesting we could do something
83:37 - really complicated and i'll end with
83:38 - this we could say cd
83:41 - trips
83:43 - orlando
83:44 - dot dot
83:47 - grocery store
83:49 - oh okay what happened there and we'll
83:51 - end with this one like i said so we
83:52 - started in pictures and we went to the
83:54 - trips folder
83:56 - orlando
83:57 - back to the trips folder and then into
83:59 - the grocery store folder and sure enough
84:01 - that's where we ended up pictures trips
84:03 - grocery stores so you can use dot dot
84:05 - anywhere in your thing to talk about the
84:08 - relative path of where you're where
84:11 - you're going okay now the absolute path
84:13 - of this is going to
84:14 - be cd home
84:18 - bob
84:19 - pictures
84:20 - trips
84:21 - grocery store
84:23 - and then sure enough we're in the same
84:24 - folder this is the absolute path
84:25 - starting at the root level but we can
84:28 - use relatives paths using things like
84:30 - dot dots one other thing i said i was
84:32 - going to end there and i guess i lied to
84:33 - you this tilde image or this tilde thing
84:36 - is a shortcut for your home directory so
84:38 - if we were to say cd to the tilde which
84:41 - is usually to the left of your one key
84:43 - boom now we are in the tilde which if we
84:46 - type pwd we'll see is home
84:49 - bob all right so those are the relative
84:51 - path tools that you can use to construct
84:53 - where you want to go but that's really
84:54 - how it works and the tree program is
84:56 - just kind of a cool way to look at
84:57 - things you can see everything else
84:59 - spelled out there the big takeaway is
85:01 - that the linux file system is just one
85:03 - big monolithic file system and whether
85:06 - you're mounting network shares or you're
85:07 - mounting usb drives or second hard
85:09 - drives or even a virtual file system to
85:12 - interact with the kernel it's all under
85:14 - the same bunch of file system in this
85:17 - big hierarchy
85:19 - partitions are really just
85:20 - organizational units that are on a hard
85:22 - drive you kind of chop a hard drive up
85:24 - into
85:25 - different partitions and those
85:26 - partitions are used for different things
85:28 - like swap space or you know a particular
85:31 - folder on your system
85:33 - you can use partitions for a lot of
85:34 - things and depending on the system that
85:36 - you're using whether it's going to be an
85:37 - mbr master boot record or gpt gui id
85:41 - partition table you can have a multitude
85:44 - of partitions or just a few and
85:47 - depending on which scheme you use it
85:48 - depends how big your hard drive can be
85:50 - now we're going to look at a handful of
85:51 - tools like parted and g parted and this
85:54 - stands for partition editor and
85:56 - graphical partition editor
85:59 - and the old school f disk which is just
86:01 - a command line tool that didn't used to
86:03 - handle the gpt partition table but now
86:06 - it does so there's this one size fits
86:08 - all tool called fdisk and then i do want
86:11 - to show you a couple tools that will let
86:12 - you see what block devices are available
86:15 - to partition on your system so let's
86:16 - actually go right to the command line so
86:19 - that we can check out what's on our
86:20 - system and i chose to use centos today
86:22 - for no other reason than i thought let's
86:24 - use centos so i want to show you first
86:27 - of all how we can identify the block
86:28 - devices on our system we can type lsblk
86:32 - and it's going to show us this really
86:33 - nice little cool tree thing right so we
86:35 - have fd0 floppy disk which actually is a
86:37 - lie there's not a floppy disk on this
86:39 - system it's a virtual machine but then
86:41 - sda is the main hard drive on the system
86:44 - and it's partitioned into two partitions
86:47 - the sda1 which is the boot partition and
86:50 - then sda2 which is used in lvm which
86:53 - we'll talk about in a different nugget
86:55 - then there are a bunch of other hard
86:57 - drives installed on the system that
86:58 - don't have anything on them at all there
87:00 - are four 10 gigabyte drives sdb sdcsd
87:04 - and sde and we can also see these things
87:07 - if we look at proc partitions this is
87:10 - again the virtual file system that shows
87:12 - us an interaction with the kernel and we
87:13 - can see sure enough here they are sdb c
87:16 - d and e and this is how big they are the
87:18 - number of blocks so they're 10 gigabytes
87:20 - and of course if we just looked in the
87:22 - dev folder and gripped for sd we would
87:25 - see all these devices too right sd b c d
87:28 - and e so what i want to do is just
87:29 - partition one of them we're going to
87:30 - pick sdb and there's a couple ways we
87:33 - can do this we could use g parted now
87:35 - notice i'm root we have to be rude if
87:37 - we're going to do the system level stuff
87:38 - like partition a hard drive but we could
87:40 - say g parted and it'll start up and scan
87:42 - for all the drives available and there's
87:44 - a little drop down here sdb very cool we
87:47 - would have to start by creating a
87:49 - partition table and then we could create
87:51 - a partition with gui tools it's really
87:53 - really easy to use g parted but a lot of
87:55 - times the system doesn't have a gui so i
87:57 - don't want to do it that way now we
87:58 - could also use parted or partition
88:01 - editor this is the cli version of the
88:03 - program that we just used we can type
88:05 - help and it'll show us it does the exact
88:08 - same things it's just used you know use
88:10 - text to tell it what to do all right so
88:12 - i'm not going to use this one either but
88:13 - i want you to know that they exist and
88:15 - if you're more comfortable with them
88:16 - they're a little bit newer and they have
88:18 - a few more features and that sort of a
88:20 - thing but what i want to show you is the
88:22 - old school f disk and i want to show you
88:23 - this because if you're on a server it
88:26 - may not have partition editor you know
88:28 - part ed or especially g parted the
88:30 - graphical one so i want to show you what
88:32 - almost every linux system is going to
88:34 - have and we're going to use that one to
88:36 - actually do our work so we're going to
88:37 - say fdisk
88:39 - dev sd b we have to tell it what device
88:42 - we want to use so it's a good thing we
88:43 - know how to find the available devices
88:45 - on our system
88:46 - type this and type m for help now we
88:50 - just have these single letter commands
88:52 - but that's okay the first thing we're
88:53 - going to need to do is to create a
88:55 - partition table and it can be one of two
88:57 - types we can create a gpt partition
89:00 - table by pressing g
89:01 - or we can create the old
89:03 - mbr or ms-dos partition table using o oh
89:07 - i'm just going to pick since it's not
89:09 - over two terabytes in size either one is
89:11 - going to work so let's just use gpt for
89:14 - the heck of it so i'm going to say g
89:15 - press enter it says okay it built a new
89:18 - gpt disk label this is its id and now we
89:21 - have a partition table but no partitions
89:23 - to create a partition we can actually
89:25 - type p to see what's there there's gonna
89:27 - be nothing there so to create one let's
89:29 - press m again so we get the whole help
89:31 - screen we can say n for add a new
89:33 - partition so new and now it says
89:36 - partition number one through 128
89:38 - right this is not mbr mbr would only
89:41 - support one through four this is gpt so
89:44 - one through 128 i'm just going to pick
89:46 - the default
89:47 - first sector the default is going to be
89:49 - the first one available last sector the
89:51 - default is going to be the last one
89:52 - available right this is our range and it
89:54 - chose the last one so i want to fill up
89:55 - the entire partition or the entire drive
89:58 - with this one partition so if we type p
90:00 - now we're going to see sure enough we
90:01 - have a partition there it's 10 gigabytes
90:03 - linux file system type that's okay
90:05 - and now to quit let's press m again for
90:07 - help to quit we could just press q and
90:10 - it would quit without saving changes but
90:11 - we actually want to make these changes
90:13 - so we're going to make the change to the
90:14 - disk so we're going to use w to exit
90:16 - which means right so w
90:19 - enter and now our partition table has
90:21 - been done we can say lsblk and look at
90:24 - that now it shows up that we have a
90:25 - partition created on our system it
90:27 - happens to be a gpt partition table and
90:29 - it's a single partition that takes up
90:32 - the entire drive i didn't actually go
90:34 - through the process of using parted or
90:36 - g-parted they're very straightforward
90:38 - and they walk you through it and the
90:39 - help screen is right there and easy to
90:40 - use so if you want to use those by all
90:42 - means go ahead but i wanted to show you
90:44 - the more complicated f-disk because it's
90:46 - going to be on every single system that
90:48 - you run across
90:49 - there's a wide variety of file systems
90:52 - that you can put on an empty partition
90:53 - in linux but the idea of all of them is
90:55 - the same you take a big empty partition
90:58 - like a big field and you divide it up so
91:02 - that you can store data efficiently like
91:04 - if this parking lot were
91:06 - an example of a file system each car
91:08 - would be a piece of data that is stored
91:10 - logically in its place and and some file
91:13 - systems have you know bigger spaces for
91:15 - parking buses some have littler spaces
91:18 - for parking compact cars but
91:19 - conceptually they all do the same thing
91:22 - now like i said there's a bunch of
91:23 - different options available in linux ext
91:26 - is the most common family of file
91:30 - systems that you can use on linux it's
91:31 - very mature it's been around forever the
91:33 - later versions support journals so that
91:35 - if a computer gets powered down before
91:37 - the reads and writes are synced up
91:39 - usually you can salvage the data on
91:41 - there so it's fairly robust as well xfs
91:45 - is a file system that's been around for
91:47 - a long time this used to be what you had
91:48 - to use for really really big drives but
91:51 - now everything supports big drive so
91:53 - that's not really the issue anymore it
91:55 - is still used by centos and red hat
91:57 - though so xfs is still widely used
92:00 - interestingly it has its own set of
92:02 - tools like for
92:04 - file checking fixing things manipulating
92:07 - the the xfs file system itself rather
92:09 - than using standard linux tools it has
92:11 - its own set of xfs tools there's a
92:14 - couple others
92:15 - btrfs it's often called butterfs
92:18 - this was the new kit on the block right
92:20 - this has awesome features like
92:22 - snapshotting and it's just awesome
92:24 - unfortunately it's kind of been
92:25 - abandoned which is weird but nonetheless
92:28 - it's kind of what happened so btrfs is
92:30 - still functional but it's not widely
92:33 - used anymore and then of course i'm just
92:34 - going to mention them dos or the windows
92:37 - world has their own file systems like
92:38 - ntfs vfat fat32 things that you're
92:41 - familiar with if you're in the windows
92:43 - world and linux can usually read and
92:45 - even write to most of these file systems
92:48 - but when we're talking about linux file
92:49 - systems we're generally talking about
92:51 - linux specific ones and ext
92:54 - is awesome i'll be honest i like ext
92:56 - there's generally three there's e xt 2
92:59 - ext3 and ext4 now this isn't necessarily
93:03 - like one is better than the next they
93:05 - each have their own features but ext4 is
93:07 - the newest and has the most features
93:09 - i'll be honest i almost always pick ext4
93:12 - as my default file system not because
93:15 - it's necessarily better than any other
93:17 - option but because it's so widely used
93:19 - that means there are a ton of tools and
93:21 - utilities and tutorials online to get
93:24 - data back if you have some corruption so
93:27 - ext4 is my file system of choice mainly
93:30 - because it's used in so many places when
93:32 - it comes to creating a file system
93:34 - basically you need a partitioned hard
93:36 - drive so that you can you know have a
93:38 - partition or that empty field in order
93:40 - to draw the lines for your parking lot
93:41 - or put that file system on now i'm going
93:43 - to say lsblk
93:45 - and we're going to see these are the
93:46 - different block devices on our system i
93:49 - have two partitions created i have sdb1
93:52 - and sdc1 these are just 10 gigabyte
93:54 - partitions on 10 gigabyte drives so it
93:56 - takes up the whole drive and we're going
93:58 - to format each of them all right so i'm
94:00 - going to say oh here's another really
94:01 - cool thing about linux the file
94:03 - formatting or the hard drive formatting
94:05 - programs all start with mk for make fs
94:09 - file system and then just hit tab a
94:11 - couple times and you're gonna see all
94:12 - the various tools for creating the
94:14 - different types of file systems so let's
94:17 - say we're going to make a butterfs file
94:19 - system so we would say
94:22 - mkfs.btrfs and then what partition we
94:25 - want to create that file system on in
94:27 - our case dev
94:29 - sdb1 all right so it's created it it
94:31 - says we have 10 gigabytes idu's one
94:35 - that's the path okay so it looks like it
94:36 - did that without any problems let's
94:38 - create another uh file system so uh mkfs
94:42 - hit tab a couple times so i can see our
94:44 - options now like i said i usually use
94:46 - ext4 so i'm going to say ext4
94:49 - dev sdc one which was the other
94:52 - partition that i had created on this
94:53 - system and it went through and it
94:55 - created that file system and now a
94:56 - really cool thing if we use the lsblk
95:00 - but we add the dash f it's going to show
95:02 - us the file systems that are on the
95:04 - particular block devices as well so if
95:06 - we do that we're going to see up here we
95:08 - have sda1 which remember i said red hat
95:11 - and sent to us use xfs well sure enough
95:13 - there it is xfs is used sdb1 is that
95:16 - butterfs file system that we created and
95:18 - then down here is an ext4 file system
95:21 - that we created on our system so that's
95:24 - all there is to creating the various
95:26 - file systems and really you can pick
95:28 - whichever one you want but you do have
95:29 - to have a partition in existence before
95:31 - you can create a file system on it and
95:33 - while yes there are a whole bunch of
95:34 - file systems that you can use on linux
95:36 - and it supports a bunch i really
95:38 - recommend that ext family of file
95:41 - systems if you have a choice and you're
95:43 - just trying to decide what one to use
95:45 - largely because it's used so often
95:47 - there's so much support if something
95:49 - goes wrong you can find a lot of help
95:50 - online
95:51 - if we want to be able to access the data
95:53 - that's on the drives or the partitions
95:55 - of the drives that we put into our
95:57 - system we have to mount them into our
96:00 - local file system now we can do that
96:02 - manually using tools like mount or
96:03 - u-mount or we can use the et cetera fs
96:06 - tab file to do it automatically on boot
96:09 - but conceptually what's going on is that
96:11 - we have a new hard drive or a
96:13 - partitioned hard drive and we want to
96:15 - incorporate that into our file system
96:18 - now it's really important to note that
96:19 - when you mount a partition or a hard
96:21 - drive it goes into a folder and that
96:24 - folder becomes what is in that drive now
96:27 - we couldn't mount it on this folder
96:29 - because this folder already has
96:32 - things inside of it it has to be mounted
96:34 - on an empty folder because it doesn't
96:35 - make sense to have all the things in
96:38 - this hard drive in this folder and then
96:40 - have these other folders alongside of it
96:42 - so it has to be in an empty folder that
96:44 - we mount a partition or a drive so we
96:47 - could actually take this hard drive and
96:49 - mount it into this folder if it's an
96:51 - empty folder and that's what we're going
96:52 - to do on our system is find an empty
96:55 - folder and then this all the files
96:57 - inside this drive will become part of
97:00 - our bigger linux file system starting at
97:02 - this mount point
97:04 - now i'm here on an ubuntu system and i
97:06 - have the regular route mounted hard
97:09 - drive and then i also have an additional
97:11 - 10 gig drive and if we do lsblk we can
97:14 - see that we have well a bunch of things
97:16 - here loop loopback devices but we have
97:18 - down here sdb1 okay this is a 10
97:20 - gigabyte partition and and it's all set
97:23 - up and ready to mount but it's not
97:24 - currently mounted on our system so in
97:27 - order to mount that i actually want to
97:29 - mount it in a folder if we look inside
97:31 - mnt there's a folder called 10 gig and
97:34 - inside that folder
97:36 - is nothing it's an empty folder so i
97:38 - want to mount it on there now if we do
97:41 - blk id we can see a little bit more
97:44 - information about the device itself so
97:47 - here is dev sdb1 now here is the
97:50 - universally unique identifier for this
97:52 - partition uh keep note that this is
97:55 - something that's specified about the
97:56 - partition we'll look at that in a second
97:58 - but we know that it's type
97:59 - ext4 okay that's good to know and we
98:02 - know that this is where the actual
98:04 - partition lives so we can say mount now
98:07 - i'm going to say dash t for type ext4
98:10 - usually mount can automatically figure
98:13 - out what kind of file system it is but
98:15 - if we know there's no reason not to do
98:17 - that so i'm going to say mount dev
98:20 - sdb1
98:22 - and where do i want it to mount on mnt
98:25 - 10 gig
98:27 - press enter
98:28 - and now if we go into
98:30 - mnt
98:32 - 10 gig
98:33 - we're gonna see sure enough now there's
98:34 - a lost and found thing this is the root
98:36 - level of that hard drive but now it
98:38 - actually lives in our file system right
98:40 - here we can type mount alone on the on
98:43 - the line it will show us where it's
98:44 - mounted right so right here it's mounted
98:46 - on mnt 10 gig so let me type cd and then
98:50 - we can unmount it by typing umount
98:53 - mnt
98:54 - 10 gig it's not unmount it's umount all
98:57 - right so there now that that's how we
98:59 - manually mounted and unmounted if we
99:00 - wanted to have it mount automatically on
99:03 - boot we would edit the file etc fs
99:06 - tab all right and i'm actually going to
99:08 - stretch this out so we can see
99:10 - everything on here we can see there's
99:12 - already an entry in here for the root
99:14 - file system sda or s yeah
99:18 - sda1 but notice it doesn't specify it by
99:22 - its device it specifies it by its
99:24 - universally unique identifier which we
99:26 - could get by using that blk id command
99:29 - it'll get us that uuid for the
99:31 - particular partition now we could use
99:33 - the uuid for a dev sdb1
99:37 - and we could put that in here to mount
99:39 - it but i'm actually going to use let me
99:41 - make another entry here i'm actually
99:43 - going to
99:44 - say that the file system is on
99:47 - dev sd b1 we can specify it by device or
99:51 - by uuid or we could even use the drive
99:53 - label if we want but in this case i'm
99:55 - just going to use the the device itself
99:58 - and then tab over the next field here is
100:01 - the mount point so i want this mounted
100:03 - on mnt
100:04 - 10 gig
100:06 - tab over the next thing is type it's an
100:09 - ext4
100:11 - options i'm just going to say defaults
100:14 - and then the last two fields are dump
100:16 - and pass now dump is an old school
100:19 - backup program it used to dump the files
100:21 - to a backup this is really deprecated
100:23 - it's not really used anymore at all so
100:25 - dump you're going to want to put zero
100:27 - for dump the last line though pass this
100:30 - means do you want it to run a file
100:33 - system check zero means never run a file
100:35 - system check
100:37 - one means run the file system check
100:39 - first so you put a one on the root
100:42 - partition
100:43 - any other partition that you wanna have
100:45 - checked when the system boots up you're
100:47 - gonna put a two
100:48 - so i'm going to put dump of 0 you always
100:50 - put 0 for dump and then pass is 2. it's
100:53 - the second most important because the
100:55 - root is the first one you want to have
100:56 - scanned and then everything else is
100:57 - going to be 2. so you can have like five
100:59 - different partitions mounted they could
101:00 - all have pass of 2. now there's more to
101:03 - it to get it to scan automatically on
101:05 - boot but when you're setting up the
101:06 - fstab file this is where you do it so
101:08 - save this and now we could just type
101:11 - mount minus a and it's going to mount
101:13 - everything that is specified in fstab
101:17 - and we can look by saying
101:19 - mount and it'll show us that sure enough
101:20 - it remounted that because we defined it
101:22 - in fstab and if we reboot the computer
101:25 - it's going to automatically boot it or
101:27 - it's going to automatically mount it as
101:28 - well it's really easy to mount
101:30 - partitions using the manual tools it's
101:32 - also pretty easy to use the fstab file
101:35 - to specify it and you can either specify
101:37 - it by device name or the uuid that we
101:40 - can find out using the blk id program
101:45 - to scan a linux file system generally
101:47 - you use the tool fsck or just fisk as
101:51 - it's often referred to now the real key
101:53 - though is to have it scan automatically
101:56 - periodically on boots so you don't have
101:58 - to manually do it because here's the
102:00 - deal in order to run fisk the file
102:03 - system itself has to be unmounted that's
102:05 - not really a problem for secondary or
102:07 - tertiary drive mounts like the home
102:09 - directory or something like that but the
102:11 - root directory it's pretty difficult to
102:13 - unmount the root directory and scan it
102:15 - unless you're in the boot up process or
102:17 - you've booted from a cd or something so
102:19 - i want to talk specifically about how to
102:21 - set up the system to scan the the file
102:24 - system on boot including the root file
102:27 - system so that you can you know have it
102:29 - automatically maintain itself now when
102:31 - it comes to scanning automatically
102:33 - there's a few different flowchart things
102:36 - that go on the very first thing the
102:37 - kernel looks for is inside your fs tab
102:40 - file if the pass setting is set up if
102:44 - it's a zero you know if you have your
102:46 - your dump and pass and if the pass is
102:48 - set to zero then it won't scan it just
102:50 - absolutely will refuse to scan it
102:52 - doesn't even look any further it just
102:53 - stops right there and continues booting
102:55 - up the system if however you have that
102:57 - partition set up with either a one or a
103:00 - two a one for the root partition a two
103:02 - for any other kind of partition if you
103:04 - have it set up then it looks at the
103:07 - drive itself and it says okay has the
103:10 - maximum number of allowed mounts been
103:13 - reached and if that threshold has been
103:16 - reached it will scan the drive before it
103:18 - boots up if not if it hasn't met this
103:22 - maximum yet then it's not going to scan
103:24 - it's going to increment it's going to
103:25 - say okay i'm going to mount one more
103:27 - time and add it to the number of times
103:28 - i've been mounted but i'm not going to
103:30 - scan it even if the pass is set up to
103:33 - scan it's not going to scan it if it
103:35 - hasn't met the max now the max by
103:38 - default is negative one which means it's
103:40 - never going to scan because that's just
103:43 - the way of saying like don't ever
103:45 - automatically mount so by default you're
103:47 - never going to get an automatic scanning
103:48 - which is a little bit frustrating
103:50 - because you do want to have your system
103:52 - automatically scanned so on ubuntu here
103:55 - i have
103:56 - dev
103:57 - sdb1 mounted on mnt 10 gig okay so this
104:01 - is another partition this is not my root
104:03 - partition but it's mounted on mnt 10 gig
104:06 - all right if i look inside of the fs tab
104:10 - file
104:11 - we're going to see that on this
104:13 - partition that i have automatically
104:14 - mount on boot it's set up with a pass of
104:17 - 2 which means that it is going to check
104:20 - to see if it should scan automatically
104:22 - okay it's not the root partition so i
104:24 - don't have it set up with a pass of one
104:26 - but since it's set up with two it's
104:28 - going to check and say okay if it's time
104:30 - i'm gonna scan this
104:32 - so let's get out of here and how we can
104:34 - see what the maximum number of allowable
104:36 - mounts before it will scan is is to use
104:39 - the tune 2fs
104:42 - we're going to do dash l for a listing
104:44 - of
104:45 - dev sdb1
104:47 - and it's going to show us this now what
104:49 - you want to look for in here is this
104:51 - maximum amount count remember i said by
104:53 - default it doesn't ever scan that's
104:55 - because this is set to negative one and
104:57 - you're never going to reach that because
104:59 - that's just the way of saying disable it
105:01 - if we want to have it automatically scan
105:03 - every so often we need to change this so
105:05 - we would say
105:06 - tune 2fs
105:09 - c for count and i'm going to say
105:12 - every 10 months i want it to scan in dev
105:16 - sd b1 okay so now the maximum amount
105:19 - count is 10. we can look at that by
105:22 - doing the same command over and we can
105:23 - see now the maximum amount count is 10.
105:26 - okay so what does that mean well every
105:28 - time the system boots it mounts the
105:30 - partition well we could speed that up we
105:33 - could say u-mount dev sd b1
105:36 - mount dev sdb one we do that and now if
105:40 - we look it's going to increment it by
105:42 - one because we unmounted it and
105:44 - remounted it so if we do that a bunch of
105:46 - times
105:49 - and now we look back and see okay our
105:51 - mount count is now 16 and our maximum
105:54 - count that is allowed is 10. well why
105:57 - didn't it automatically scan well it
105:59 - only does that on boot so if we were to
106:01 - reboot the system it would go through
106:03 - the flowchart and it would say okay you
106:06 - have your pass set to two so that means
106:08 - i need to check the drive and say okay
106:10 - drive is your mount count higher than
106:13 - the maximum amount count allowed before
106:16 - a scan and it will be so if we do a
106:18 - reboot
106:21 - and once it's booted back up we look and
106:24 - run that tune 2fs again so sudo
106:27 - tune2fs-l
106:30 - dev sdb1
106:32 - now we're going to see that the mount
106:33 - count is down to 1 which means that it
106:36 - scanned it it ran fisk on boot before it
106:38 - was mounted and it reset the mount count
106:41 - to zero and then of course it mounted it
106:42 - so now it's one so now it's not going to
106:45 - rescan that on boot until the mount
106:48 - count gets above this maximum mount
106:51 - count and then it will do it
106:52 - automatically and figuring out what
106:54 - number to set here can be kind of tricky
106:56 - because here's the deal if you're on a
106:58 - laptop you might reboot fairly often so
107:01 - you're going to want to have that number
107:02 - kind of high so it doesn't scan every
107:04 - single time but if it's a big file
107:06 - server maybe you rarely ever reboot it
107:09 - maybe once a year well in that case you
107:12 - might want the mount count to be very
107:13 - low so that every time it gets rebooted
107:16 - it does scan for consistency's sake and
107:19 - then one more thing if it's a huge
107:22 - partition with just millions and
107:23 - millions of files it's going to take
107:25 - hours or days to scan so maybe you don't
107:28 - want to scan it every time it mounts it
107:30 - really depends on your situation so plan
107:32 - out how often you want it to scan and
107:34 - the type of situation that you're in to
107:36 - make the best choice for your particular
107:38 - partition and honestly the best choice
107:41 - for you might actually be just to run
107:43 - fisk manually just unmount the partition
107:46 - or boot from a cd or usb drive if you
107:48 - need to scan the root partition maybe
107:50 - you never want to automate the process
107:52 - you only want to do it manually for some
107:54 - cases that's fine too regardless it's
107:56 - important to know how the system works
107:59 - so that if you think you're
108:00 - automatically scanning you really are
108:03 - lvm or logical volume manager is
108:06 - basically like a software version of a
108:10 - storage area network it allows you to
108:13 - take a whole bunch of physical devices
108:16 - and lump them into one big group that
108:19 - allows you to kind of carve out slices
108:21 - of storage for the use in your local
108:23 - system it consists of a bunch of parts
108:25 - physical volumes volume groups and
108:27 - logical volumes they use the word
108:29 - volumes a lot in there
108:31 - but nonetheless it's a way of taking raw
108:33 - storage and combining it into a thing
108:36 - that you can just slice up and expand
108:38 - and contract and add more things to it
108:41 - without disrupting the existing services
108:43 - here's how it actually works or looks in
108:46 - practice so we have we start with
108:47 - physical volumes i'm just calling them
108:49 - pv and we're going to say that we have
108:52 - four 10 gigabyte drives now in the
108:54 - standard practice these could be actual
108:57 - hard drives they could be raid devices
108:59 - or they could be partitions on a hard
109:02 - drive it doesn't really matter what they
109:03 - are they're just chunks of storage and
109:06 - you create physical volumes out of them
109:08 - and then you combine those physical
109:10 - volumes into volume groups and so then
109:15 - all of these are combined into a volume
109:17 - group and if you add 10 times 4 you get
109:20 - 40 gigs so then you have this volume
109:22 - group which is like just a big bucket of
109:24 - storage and that bucket of storage has
109:27 - no protection now i know that's not like
109:29 - a feature right but i really want you to
109:31 - know that if you just have 10 gigabyte
109:33 - drives all in a bucket so you have 40
109:36 - gigabytes of storage and you're just
109:38 - gonna take and carve out chunks of that
109:40 - that doesn't offer you any protection so
109:42 - if one of these drives fails
109:45 - all of a sudden you could have your end
109:47 - result be completely corrupt and useless
109:49 - so physical volumes being raw devices
109:52 - and not having any redundancy is a
109:54 - little bit scary so anyway just wanted
109:56 - to throw that in there once you have
109:57 - this volume group you carve out a slice
110:01 - of it and it can be a small slice like
110:04 - here i just said this is about seven
110:05 - gigs i just kind of like spatially
110:07 - guessed how much of 40 gigs that would
110:08 - be um but you can carve out a big chunk
110:11 - so you could have like a 30 gig slice or
110:14 - you could have like a 32 gig slice that
110:16 - would use like two plus a little of
110:18 - another drive basically you don't know
110:20 - underneath what's going on the volume
110:22 - group is just a big chunk of storage
110:25 - that you carve out a slice of and then
110:27 - this slice is called a logical volume
110:30 - that logical volume is what you format
110:33 - with a file system and mount on your
110:36 - local hard drive or on your local file
110:37 - system and what you install linux on so
110:40 - it's a long step process but it allows
110:42 - for a lot of flexibility and so i want
110:44 - to show you what it looks like in
110:46 - practice even though it's not this
110:48 - robust system with multiple physical
110:50 - volumes if you have centos installed
110:53 - they actually use lvm even if you only
110:55 - have one drive so i'm going to show you
110:58 - here if we look at the etc fs tab
111:02 - file what we have here is our device is
111:05 - called dev mapper centos dash root okay
111:09 - now this is like devmapper what is that
111:11 - well this is where logical volume
111:13 - manager creates those logical volumes
111:16 - for us to use and you'll see here this
111:18 - devmapper sent to us root is mounted on
111:21 - the root of the hard drive or root of
111:23 - the file system it has xfs as a file
111:26 - system and it's installed same thing
111:27 - down here they have another carved out
111:29 - slice called centos swap and that's
111:32 - mounted as swap space on the system so
111:35 - if we look inside dev mapper
111:38 - we're going to see we have sent to us
111:40 - root and sent to us swap now i want to
111:42 - show you really quickly a handful of
111:44 - commands so you can see what's going on
111:46 - if we look at pv
111:48 - display this is physical volume display
111:51 - it's going to show us what's going on
111:53 - behind the scenes right like what makes
111:55 - up the bucket of data that we're going
111:56 - to use we only have one physical volume
111:59 - i know it seems weird right why am i
112:01 - making a bucket out of one device well
112:03 - you can expand it if you want so they're
112:05 - giving you the room to expand later if
112:08 - you want to do it after it's already
112:09 - installed so we have one physical volume
112:12 - and it's a partition it's dev sda2
112:15 - all right it's in a volume group named
112:19 - centos
112:20 - and that gives us it looks like about 19
112:24 - gigabytes of storage okay so this
112:27 - physical volume is inside a volume group
112:29 - called centos so our our bucket with all
112:32 - the data is called sent to us and it
112:33 - looks like we carved out root
112:35 - and swap
112:37 - from that bucket so let's look at that
112:38 - really quick we're just going to look at
112:40 - lv
112:41 - display logical volume display and we
112:44 - should see two and sure enough we have
112:45 - two logical volumes i'm going to scroll
112:47 - up a little bit here our first one
112:50 - is named swap it's in the centos volume
112:53 - group because that's the only volume
112:55 - group we have it happens to be two
112:57 - gigabytes in size and it lives in dev
112:59 - centos
113:00 - swap this is an interesting thing you
113:02 - can you can use dev mapper and the name
113:04 - of it or you could use
113:06 - dev
113:07 - the name of the volume group
113:10 - the name of the logical volume as like
113:13 - in folders here so that's another way
113:15 - that you can reference it and find the
113:16 - actual logical volumes and then the same
113:18 - thing down here dev sent to us root
113:21 - the logical volume name is root it's
113:23 - carved out of the centos volume group
113:25 - and this one looks like it's about 17
113:27 - gigabytes so if we look inside
113:30 - dev sent to us we're going to see sure
113:32 - enough there we have root and swap as
113:35 - our two different logical volumes that
113:37 - we could one is formatted right this is
113:39 - formatted with xfs and this is just swap
113:41 - space i know we didn't go through the
113:43 - process of actually creating all of the
113:45 - different parts but hopefully you
113:46 - understand exactly what lvm is doing
113:49 - taking physical volumes whether
113:51 - partitions or hard drives or raid
113:52 - devices combining them into a volume
113:55 - group and then carving out logical
113:57 - volumes that you can use as regular
114:00 - devices on your system and it just
114:02 - allows for flexibility kind of like a
114:04 - software-based san in your own computer
114:08 - building an lvm is actually one of the
114:10 - most straightforward things that you can
114:12 - do when it comes to block storage
114:14 - devices on linux it's surprisingly
114:16 - consistent all the way through the
114:18 - process for you know the names of the
114:20 - tools and it really is kind of fun and
114:22 - once it's built you can expand it by you
114:24 - know adding more drives to the system or
114:27 - you know stretching your existing
114:28 - volumes but let's go ahead and actually
114:30 - create from start to finish an lvm
114:32 - system on our linux device now here i am
114:35 - on ubuntu and if we do lsblk we're gonna
114:38 - see that well we have a bunch of stuff
114:39 - but down here this is the drive that our
114:41 - system is installed on so we're not
114:43 - gonna touch this one we're going to use
114:44 - these four
114:46 - devices so sdbcd and e which are 10
114:49 - gigabyte devices notice i don't have
114:51 - partitions created on these now you can
114:53 - create partitions some people prefer to
114:55 - use partitions for their physical
114:58 - volumes in an lvm some people prefer to
115:01 - use the raw devices either one works
115:03 - fine they work the same
115:04 - the advantage of setting up a partition
115:06 - is that if somebody else comes to your
115:08 - system they're gonna see that there's
115:10 - partitions on the system and they're
115:12 - gonna know that something is already
115:14 - done there whereas if you leave them raw
115:16 - devices they might think oh look empty
115:18 - drives now it's kind of far-fetched and
115:20 - you're not just going to like start
115:21 - formatting drives in somebody's system
115:23 - but that's the reason some people like
115:24 - to use partitions i'm just going to use
115:26 - the raw devices and to turn these raw
115:28 - devices into physical volumes we use pv
115:32 - create and we just make a list of the
115:35 - devices we want to use so dev sdb devs
115:38 - dc dev sdd and dev sde so it created
115:41 - them now we can do pv display if we want
115:44 - and it's going to show all the devices
115:46 - that we have now each of them is 10
115:47 - gigabytes and the name of it is just
115:50 - the device itself dev sdc so the next
115:52 - step is to create a volume group now to
115:56 - do that we just do vg create which is
115:59 - very very nice
116:00 - the first flag or the first command
116:02 - argument here is the name of the volume
116:05 - group so i'm going to call this
116:07 - bucket because it's just a big bucket of
116:09 - our hard drives right of our data that's
116:11 - available so i'm going to call the
116:12 - volume group bucket and then we just
116:14 - make a list of the physical volumes that
116:17 - we want to add to it so those same
116:19 - volumes we just did before
116:21 - and then press enter our volume group
116:22 - bucket was created we can look at that
116:24 - by doing vg display there's four
116:27 - metadata areas meaning we have four
116:29 - devices our current active pv are four
116:32 - we have 40 gigabytes of storage just
116:34 - about all together because each one was
116:36 - 10
116:37 - and now we have this thing called bucket
116:39 - that we can carve a slice out of if we
116:42 - want and use that slice and put a file
116:45 - system on it so to do that we're going
116:46 - to use i'm sure you guessed it lv create
116:49 - i love the consistency of these tools
116:51 - it's really nice here we do dash capital
116:53 - l and how big of a slice we want in this
116:56 - case let's do something that's going to
116:58 - span all four disks so i'm going to say
117:00 - 32 capital g for 32 gigabytes and then
117:04 - dash n the name that i want to call it
117:07 - i'm going to call this big underscore
117:10 - slice and then we have to tell it where
117:13 - we want to get the data from well in our
117:15 - case it's in bucket the name of our
117:17 - volume group right there is bucket so
117:19 - what we're doing is creating a 32
117:22 - gigabyte slice called big slice out of
117:25 - the volume group bucket
117:27 - press enter logical volume big slice is
117:29 - created so we can do lv display
117:33 - and sure enough lv size is 32 gigabytes
117:35 - so we know if that worked the name is
117:37 - big slice it's in bucket the lv path is
117:40 - dev
117:41 - bucket big slice which is exactly what
117:43 - we would expect because we've created
117:45 - this volume group called bucket and now
117:47 - this logical volume lives inside there
117:49 - so the last step is that we would
117:51 - actually use this as an actual block
117:54 - device or as a hard drive in and of
117:56 - itself and then we could just do
117:57 - something like mkfs
117:59 - ext4 dev bucket big slice
118:04 - and there we go so now we've done that
118:05 - we could mount it somewhere and every
118:07 - time the system starts it's going to be
118:09 - available in dev bucket big slice and
118:11 - then if we put it in fstab it's going to
118:13 - be mounted on boot and then there are
118:15 - other tools that we can go and like lv
118:17 - extend if we wanted to make it bigger so
118:19 - we could do something like lv extend
118:22 - dash l i'm going to say plus 5 gigs dev
118:26 - bucket big slice and now it says the
118:29 - size has gone from 32 gigabytes to 37
118:31 - gigabytes it was resized and we did that
118:34 - without adding anything to the system we
118:36 - just used the tools to change the size
118:39 - of our logical volume the thing to
118:42 - remember again about lvm is that it
118:44 - provides flexibility in your system it
118:46 - doesn't provide any redundancy so if you
118:48 - have one physical volume fail it's going
118:51 - to crash the entire volume group and
118:53 - logical volumes are going to get messed
118:55 - up so you want those pvs to be like a
118:57 - raid device if you're worried about
118:58 - something going wrong underneath and
119:00 - losing data but setting up lvm as you
119:02 - can tell is very simple and honestly
119:05 - even kind of fun raid is a redundant
119:08 - array of independent disks or drives and
119:11 - basically what it means is that it you
119:13 - take a bunch of drives and put them
119:15 - together and you end up with a larger
119:18 - pool of storage now the cool thing about
119:19 - raid is that it doesn't just pull things
119:22 - together like lvm and give you a bunch
119:24 - of data it allows you to do some pretty
119:26 - neat things with performance or
119:28 - redundancy so i want to talk about the
119:29 - different raid levels that we can offer
119:32 - using raid specifically linux raid linux
119:35 - has a software version of raid which is
119:37 - very powerful very robust and
119:39 - surprisingly efficient so basically i
119:42 - want to make sure we cover all the
119:43 - different raid types and to do that i
119:45 - want to show you this big scary dragon
119:47 - now here's the idea i'm going to i'm
119:49 - going to talk about
119:50 - raid but instead of a redundant array of
119:53 - independent drives we're going to say
119:54 - they're a redundant array of independent
119:57 - knights of the round table okay and in
119:59 - true 80s fashion our knights are going
120:01 - to be just squares like from atari's
120:03 - adventure anyway here's the deal with
120:05 - raid 0 our drives are set up in a stripe
120:09 - which means that they work together
120:11 - reads and writes happen across two
120:13 - drives very very quickly and so with
120:16 - raid 0 or a striped array it's very fast
120:20 - right you can get dual writes and dual
120:22 - reads at the same time the problem is
120:25 - let's say that the knights are attacking
120:27 - the dragon and the dragon is attacking
120:29 - the knights if we lose one of the
120:31 - knights well then the dragon can get
120:33 - right through to the king because if you
120:36 - lose a single drive in a striped array
120:40 - or in a raid 0 all of a sudden your data
120:42 - is gone because half of your data is
120:44 - written on that other drive so while
120:47 - it's very fast they better kill the
120:49 - dragon quick because if one of them
120:50 - fails all of their date is gone and the
120:53 - king gets destroyed now raid 1 is kind
120:56 - of the opposite it still has multiple
120:58 - drives but they're set up in a mirror
121:00 - which means every time you write
121:02 - something to the first drive you write
121:04 - it to the second drive so you have a
121:06 - complete copy of both now because
121:08 - they're in a line like this they can
121:10 - only attack the dragon one at a time
121:12 - right they can't both attack the dragon
121:14 - like over here in the striped setup but
121:16 - the advantage here is if one of them
121:18 - dies there's still another full night
121:21 - there protecting the king same thing
121:23 - with your data right if one of these
121:24 - dies you still have a full set of your
121:27 - data because you've been writing it to
121:29 - two drives the entire time so a mirror
121:32 - doesn't give you any speed increase
121:34 - because you're not spreading the writes
121:36 - across here you're actually writing all
121:38 - of your data two times once to each
121:40 - drive so you don't get any advantage
121:42 - over a single drive when it comes to
121:43 - speed but you do get that advantage of
121:46 - either drive can die and you still have
121:49 - full protection for your data now raid 5
121:52 - this is a little bit different raid 5
121:54 - uses a parity disk and how that actually
121:57 - works is like some digital magic that is
122:00 - beyond the scope of this nugget and to
122:02 - be quite honest it still stumps me a
122:04 - little bit but conceptually how it works
122:06 - is you have multiple drives three
122:08 - minimum and any of these drives can die
122:12 - any one of them it doesn't matter which
122:14 - one and all of your data is still in
122:16 - place so you get the advantage of being
122:19 - able to lose any drive in your array the
122:22 - disadvantage is you lose one drive's
122:25 - worth of storage now what do i mean by
122:28 - that let's say these are all five
122:29 - gigabyte drives okay if these are all
122:32 - five gigabyte drives together that would
122:34 - be 15 gigabytes but you lose one drive's
122:38 - worth of storage for that parody magic
122:41 - and so if you have three five gigabyte
122:43 - drives you're only going to have 10
122:45 - gigabytes of usable space but the
122:48 - advantage is it's writing to multiple
122:50 - drives as it's going along and if one of
122:53 - the drives dies you still have all of
122:55 - your data represented in the remaining
122:58 - drives now if you lose two of course
123:00 - then your date is corrupt and and you're
123:01 - done but you can lose any drive and it's
123:03 - not just like this is the drive you can
123:05 - lose no you can lose any one of these
123:07 - and all of your data is still there it
123:10 - really is magical and so that means that
123:12 - you can lose a knight and the dragon is
123:14 - still going to be stopped by whatever
123:16 - two of the knights are still protecting
123:18 - the king hopefully that makes sense with
123:20 - the different raid levels and just
123:21 - briefly i want to talk about there are
123:23 - some hybrid levels as well so raid 0
123:26 - could be raid 0 1
123:28 - where you have like four drives and what
123:31 - happens here is you have a stripe of
123:33 - mirrors your drives are mirrored and
123:35 - then striped across the mirror or raid
123:37 - 1-0 which is a mirror of stripes or vice
123:40 - versa but basically four drives and
123:42 - you're mirroring two two of them and
123:44 - then striping those two mirrors and vice
123:47 - versa you're gonna stripe them and then
123:49 - mirror those two stripes with raid five
123:51 - there's actually a raid six which is
123:54 - cool but it requires another drive and
123:56 - then you can lose up to two drives and
123:59 - still have your data there's two of
124:01 - those parity drives in place now the
124:03 - downside is you lose two drives worth of
124:06 - storage on your full array but it's
124:08 - awesome because you can lose more than
124:09 - one drive now even if you don't follow
124:11 - along with my awesome dragons and
124:13 - knights kind of scenario hopefully the
124:15 - raid levels make sense now my trick my
124:18 - little mental trick to remember what it
124:20 - is i look at the number after raid and i
124:23 - say how many disks can i lose because
124:25 - for years i would confuse raid 0 and
124:27 - raid 1. but here's the deal with raid 0
124:29 - you can lose zero drives right because
124:32 - if you lose one you lose your data with
124:34 - raid 1 you can lose one drive and you
124:36 - still have another drive raid five i
124:38 - guess you could lose one of five i don't
124:41 - know it kind of falls apart but rate
124:42 - zero and raid one are the ones that i
124:43 - would always struggle with so i think of
124:45 - that number as how many drives i could
124:47 - lose and still have my data
124:50 - you can go to the store and buy a raid
124:52 - card like a hardware raid device and
124:54 - then you can use that on your system and
124:56 - you'll be able to have hardware raid but
124:58 - linux has a really awesome and powerful
125:01 - software raid
125:02 - program that will use kernel level tools
125:04 - to allow you to create your own raid
125:06 - devices without needing any specialty
125:09 - hardware at all now there's a couple
125:10 - things we need to discuss like
125:12 - partitions versus using raw devices i
125:14 - want to make sure we cover all the
125:15 - configuration stuff but conceptually
125:18 - it's really easy rather than having a
125:20 - hardware based card we just use our
125:22 - regular sata controllers and then our
125:24 - hard drives can all work together in a
125:27 - raid array that we choose now when i
125:29 - talk about partitions versus raw devices
125:31 - let's say we have 200 gigabyte hard
125:33 - drives but they're from different
125:34 - manufacturers now they both say that
125:37 - they're 100 gigabytes however if you
125:39 - look close they might have slightly
125:41 - different number of sectors and slightly
125:43 - different size so this one says it's 100
125:45 - gigabytes but it might be actually 1028
125:48 - megabytes and this one says 100
125:49 - gigabytes but it might actually be 1022
125:51 - megabytes now they round for marketing
125:54 - purposes and that's perfectly fine and
125:56 - usually on a system it doesn't matter
125:58 - but if you have like this drive fail in
126:01 - a raid array and you need to replace it
126:03 - with another drive and you try to use
126:05 - this drive and all of a sudden oh you
126:07 - created a raw disk device raid array
126:10 - unit and it has
126:11 - 1028 megabytes of space and you try to
126:14 - replace it with another hundred gigabit
126:15 - drive but this one only has a thousand
126:17 - and twenty two megabytes you're not
126:19 - going to be able to work it because this
126:22 - isn't big enough so generally what
126:24 - people do is you take and make a
126:26 - partition
126:27 - inside of your drive that is slightly
126:30 - smaller than the hard drive itself so it
126:33 - might be
126:34 - 99.9 gigabytes and then the same thing
126:37 - when you have a new drive you're going
126:39 - to have enough room to create a 99.9
126:42 - gigabyte partition and so even though
126:45 - this drive itself is slightly different
126:47 - the underlying partition is going to be
126:49 - the exact same size so you're going to
126:51 - be able to use it to replace a failed
126:53 - drive in an array so that's why we
126:55 - generally use partitions even though
126:57 - using a raw device would work until you
127:00 - need to replace it with a smaller drive
127:02 - that is your replacement now here on our
127:04 - ubuntu system if we do lsb lk we're
127:06 - going to see we have four 10 gigabyte
127:09 - drives that are installed in here we're
127:10 - going to make a right array with those
127:11 - this sda1
127:13 - this is our root partition this is where
127:14 - our system is installed but these drives
127:17 - down here are the ones that we're going
127:18 - to use to create our raid array now i've
127:20 - already partitioned the first three
127:22 - you'll notice it's a 10 gigabyte drive
127:25 - and the partitions are 9.9 gigabytes
127:27 - awesome we're going to do the sde the
127:29 - last one together and so fdisk dev sd e
127:34 - and the first thing well we can press m
127:36 - to see all of our different options but
127:37 - i'm going to go kind of quickly i'm
127:38 - going to say o to create a new partition
127:40 - type and it's going to be a dos one it
127:42 - doesn't have to be dos but i just
127:43 - decided dos and then i'm going to say n
127:45 - for a new partition and i want the
127:47 - partition to be primary so default
127:50 - number one default the start point on
127:52 - the drive default and here's where
127:54 - rather if i choose default it's going to
127:55 - be 10 gigabytes in size and that would
127:57 - be fine as long as our replacement was
127:59 - the exact same kind but i want to do it
128:01 - slightly smaller than the drive itself
128:03 - so here i'm going to say plus
128:05 - 9.9
128:07 - g and press enter and now we have it 9.9
128:10 - gigabytes in size so any 10 gigabyte
128:12 - drive we'll be able to replace it with
128:14 - because we'll just create a 9.9 gigabyte
128:15 - partition inside now the one last thing
128:18 - if we do t for type and press enter it's
128:21 - going to say okay what partition type do
128:24 - you want here it says it created a new
128:25 - partition with type of linux but if we
128:27 - type capital l we're going to see all of
128:29 - the available codes here now this is not
128:32 - a format this is just like a flag to
128:34 - give the kernel a hint as to what sort
128:37 - of partition this is supposed to be so
128:39 - the one that we want to put on here is
128:41 - actually f d
128:43 - for linux auto raid so i'm going to type
128:45 - f d
128:47 - and now it says change type of partition
128:49 - to linux auto raid or linux right auto
128:51 - detect i'm going to press w to write
128:53 - this change to the disk and now if we do
128:55 - lsblk we're going to see we have all of
128:58 - them here now that partition type is
129:00 - just to give the kernel a hint if you
129:01 - put these drives in a new system it's
129:03 - going to say oh look at those partitions
129:05 - those are part of a linux array or of a
129:08 - raid array so we're going to treat it as
129:10 - such so it's just a hint but it works
129:12 - even if you don't change that partition
129:13 - type all right so now it's pretty easy
129:15 - to create the actual raid device we're
129:18 - going to create a raid 5 device with
129:20 - four 10 gigabyte devices well about 10
129:22 - gigabytes and so we should end up with
129:24 - about a 30 gigabyte usable space with
129:27 - our raid 5 array now the tool we use is
129:30 - mdadm and we're going to say dash dash
129:33 - create because we want to create a brand
129:35 - new one i'm going to say verbose just so
129:37 - we can see it do things as we type it in
129:40 - and now what device do i want to create
129:42 - well the devices are dev
129:44 - md and then the number of the raid
129:46 - device you're creating so we're going to
129:48 - start with md0 because that's our first
129:50 - device and we don't have any raid
129:52 - devices on here yet i'm going to do dash
129:54 - dash
129:55 - level equals
129:57 - 5 i want it to be a raid 5 device and
130:00 - then dash dash
130:01 - raid
130:02 - devices
130:04 - equals 4 because we have 4 devices and
130:07 - now we need to list those devices out
130:09 - and we're going to list the actual
130:10 - partition so
130:11 - dev
130:12 - sdb1
130:14 - dev sdc1
130:16 - dev sdd1 and dev sd e1 we'll press enter
130:22 - boom it created it that quickly now we
130:23 - can see the details of it if we were to
130:26 - look at
130:27 - md stat this is the virtual file system
130:29 - proc and this is going to show us the md
130:32 - stat which is the current rate arrays in
130:34 - our system so here we have
130:36 - it's currently a raid 5 array it shows
130:38 - our devices here lots of information it
130:40 - says recovery that's because it's
130:42 - building the array but we can use it
130:43 - while it's currently using the array
130:45 - which is really awesome okay so we look
130:48 - into
130:49 - dev
130:50 - grip for md we're going to see there we
130:52 - have md0 so we have a device all created
130:55 - and we can now use this as a hard drive
130:57 - in our system before we do that though i
130:59 - want to save this configuration of this
131:01 - raid5 array into our system so that on
131:04 - boot it knows exactly what sort of array
131:07 - to build to do that we just do md adm
131:10 - detail
131:11 - scan and if we do that it's going to
131:13 - show us the configuration so that's the
131:15 - configuration for our current array what
131:17 - we want to do is save that so i'm going
131:18 - to redirect it into etc
131:21 - mdadm
131:23 - md
131:23 - mdadm.conf so we're going to save that
131:26 - result into this file
131:28 - and now every time we boot the system
131:29 - md0 is going to be created and then we
131:31 - just treat it like any other hard drive
131:34 - on our system so
131:35 - nkfs
131:39 - dev md0 and boom it created it and now
131:42 - it's part of our system and it's going
131:44 - to be about 30 gigs in size let's see
131:46 - lsblk and we look down here md0 shows up
131:50 - as 29.6 gigabytes about 30 gigabytes of
131:54 - raid 5 storage on our system if you're
131:57 - thinking that was a little bit too easy
131:58 - well you're right linux raid is awesome
132:01 - it's super simple to set up it allows
132:03 - you to use the regular drives in your
132:05 - system and set them up as a raid device
132:08 - so as long as you can save that file
132:10 - into mdadm.com
132:12 - that detail scan that we did and you can
132:14 - check for the progress or the status of
132:17 - your current rate array in mdstat you
132:19 - are really set that's all it takes to
132:21 - use raid on a system using nothing but
132:23 - software provided with the linux kernel
132:25 - installing tarballs sounds like some
132:27 - sort of prank you might pull on somebody
132:28 - in high school but really this is the
132:30 - way that we would install software on
132:32 - linux for years before package
132:34 - management systems came out now you can
132:36 - still download tarball files of source
132:38 - code for programs and install them
132:40 - although it's not terribly common
132:42 - anymore now we used to refer to this as
132:44 - the three step we would extract compile
132:46 - and install and this is the process to
132:48 - convert source code into an executable
132:50 - program now i'll show you how to do that
132:52 - really quick i've downloaded already a
132:54 - very simple program as a tarball file
132:57 - it's called sun weight it's just a
132:58 - simple program that waits until the sun
133:00 - goes down and then executes so if you
133:02 - have a script that you want to run at
133:03 - sunset that's kind of a cool tool to use
133:05 - to do it but the first step is to
133:07 - extract it so we're going to say tar
133:08 - minus the xvf
133:10 - sun wait we'll go into the folder that's
133:13 - created if we type ls we'll see there's
133:15 - a couple files in here this is the
133:16 - source code and also a make file now
133:20 - sometimes there's more complicated
133:21 - things like dependencies sometimes
133:23 - there's going to be a config file so
133:24 - we'll run
133:25 - config and go through that process and
133:27 - it'll tell you if you need other
133:28 - dependencies since we don't have a
133:30 - config file i'm just going to type make
133:32 - because make will compile it into an
133:35 - executable program now you'll notice we
133:36 - got some warnings but we didn't get any
133:39 - errors a lot of times if it's a big
133:40 - program it'll say oh i need this
133:42 - dependency or oh you forgot this library
133:45 - and you'll have to download and install
133:46 - those dependencies before you can
133:48 - compile it but this one is very very
133:50 - simple if we type ls again we're going
133:51 - to see now we have a result here we have
133:54 - the sun weight program now we can
133:56 - execute it right here by saying dot
133:58 - forward slash sun weight and we'll see
134:00 - sure enough there it runs and we could
134:01 - use this to wait until sunset to execute
134:03 - a program if we want to install it
134:05 - though we have to either copy it to our
134:08 - user local bin folder or sometimes
134:10 - they'll include in the make file an
134:12 - installer so we could say something like
134:15 - make install this one doesn't actually
134:17 - have that ability to install it it's a
134:19 - very simple program so if we wanted to
134:21 - install it if you get an error like this
134:23 - you just simply say okay i'm gonna move
134:26 - sun weight to user local bin and now if
134:29 - we type sunway it's going to execute
134:31 - because it's in our path now i told you
134:33 - that three-step process is really really
134:35 - simple and it is you just basically type
134:37 - make and it compiles and then you have a
134:39 - binary that you can install either using
134:40 - a script or just putting it in your user
134:42 - local bin file there is a big
134:44 - disadvantage though if you compile
134:45 - things from source and that is there are
134:48 - no update mechanisms for getting a newer
134:50 - version if you use a package manager
134:52 - it'll update old software but if you
134:55 - just compile it yourself and install it
134:56 - manually there's no way to update it and
134:59 - that can be a real problem especially
135:00 - when security concerns come up so while
135:02 - it's important to understand how to use
135:04 - tarballs to compile and install programs
135:07 - it's not really the best way to go about
135:09 - it if you have any other options
135:12 - deb files are the way that programs are
135:14 - packaged up in the debian and ubuntu
135:16 - world now there's a couple different
135:18 - ways that we can manage the subsystem
135:20 - and there's a little bit of confusion as
135:22 - far as what tool to use now behind the
135:23 - scenes they all use d package which is
135:26 - like the the lowest level of interaction
135:28 - with dev files and i'll show you why
135:30 - this is not what you use on a regular
135:31 - basis in order to actually install
135:34 - packages on debian or ubuntu there are
135:36 - three different options though for
135:38 - installing packages using the proper
135:40 - system apt apt-get and aptitude now i
135:43 - want to talk about them because they do
135:45 - the same thing but it's just a matter of
135:48 - being replaced by something better so
135:50 - apt just apt all on its own is the
135:53 - newest program to interact with the app
135:56 - system it's new it's simple this is the
135:59 - one to use so just use apps i'm going to
136:01 - try to use apt if i can
136:03 - aptitude you may find online
136:05 - instructions people telling you how to
136:06 - install packages with aptitude this is
136:09 - older but it still works i don't
136:10 - recommend you use it though it's a
136:12 - little bit strange when it comes to
136:13 - dependencies but it's been outmoded and
136:15 - now apt is the way to go now here's the
136:18 - other thing apt get has been around for
136:20 - a very long time it's the oldest of the
136:22 - three it still works but i don't
136:24 - recommend you use it because again apt
136:27 - is by far the best way that you can go
136:29 - about installing packages here's the
136:31 - real problem though i've been installing
136:33 - packages on debian and ubuntu for so
136:35 - long that sometimes if you're watching
136:37 - me in a nugget i might use apt-get by
136:40 - mistake just because it's a habit it
136:42 - still works there's nothing wrong with
136:44 - doing it but the proper way to go about
136:46 - installing packages is to use apt that's
136:48 - what i'm going to try to do and that's
136:49 - what i'm going to show you now now on
136:51 - our ubuntu system if we type ls we're
136:53 - going to see i have a deb file so it's
136:55 - kate kate is a text editor that works in
136:58 - the kde environment and this is the
137:00 - installer the dev file now remember i
137:02 - said that d package is the program that
137:04 - is used behind the scenes that's how you
137:06 - interact with dev files here's the
137:08 - problem so i'm going to say sudo d
137:10 - package minus i for install kate.deb
137:14 - it's going to try to do it but here's
137:16 - the problem it doesn't resolve any
137:18 - dependencies so if i want to use d
137:20 - package to install it i'm going to have
137:23 - to find every one of these deb files on
137:25 - the internet download them install them
137:27 - one by one find out if they have
137:29 - dependencies and it can be a real mess
137:32 - so thankfully the apt system takes care
137:34 - of all the dependencies for us so i have
137:36 - to erase this so i'm going to say pseudo
137:39 - d package minus r kate and it's going to
137:42 - undo the mess that i made and now we're
137:44 - back to square one rather than
137:46 - downloading the deb file we can use the
137:48 - app package management system and just
137:50 - say sudo
137:51 - apt
137:52 - install
137:53 - kate and it's going to look for the
137:55 - latest version and get all of the
137:57 - dependencies and you can see there are a
138:00 - ton it would have taken me a week to
138:01 - come up with all these dependencies so
138:03 - if i say yes it's going to install them
138:05 - all
138:08 - and it's finally finished that took like
138:10 - over three minutes i sped it up so i
138:12 - didn't have to sit here with me the
138:13 - whole time but now all we have to do is
138:15 - run kate because it's installed with all
138:16 - of its dependencies on the system and
138:18 - here it is our little text editor kate
138:20 - now another nice thing about using a
138:22 - package management system is we can keep
138:24 - things updated so we could say sudo apt
138:27 - update which is going to download the
138:29 - latest repository information to find
138:31 - out all the updates that are out there
138:32 - for us to install and then once we have
138:34 - the freshest versions of what's out
138:36 - there we can use that same program apt
138:39 - and say sudo apt upgrade and looks like
138:42 - we have a couple things we could upgrade
138:43 - hit enter and it's going to keep our
138:45 - system up to date that easy not worrying
138:47 - about dependencies it does all that on
138:49 - its own so while all three of these will
138:51 - technically work for installing and
138:53 - updating packages you really want to use
138:55 - just the simplest one which is apt it's
138:57 - the newest and it's the easiest to
138:59 - remember
139:01 - rpm is the red hat package manager and
139:04 - it does just that it manages packages on
139:07 - a red hat based meaning red hat or sent
139:09 - to us or anything else that uses the rpm
139:11 - system that's how it manages their
139:13 - dependencies and their installation and
139:14 - their programs and updates etc now
139:16 - there's a few tools we need to know how
139:18 - to use in order to really utilize rpm
139:20 - yum is kind of the de facto standard but
139:22 - there's a new kit on the block called
139:24 - dnf i want to talk about that and then
139:26 - of course rpm itself is not only a
139:28 - package management system but it's also
139:30 - the tool the low-level tool that we use
139:32 - to actually handle packages now the cool
139:35 - thing about rpm is there's no two steps
139:37 - required when it comes to installing now
139:40 - what do i mean by the two-step process
139:42 - well here we have our multiple programs
139:44 - i just mentioned now yum is yellow dog
139:47 - updater modified which may seem silly
139:50 - but just for a brief second yellowdog
139:52 - was a linux distribution that ran on
139:55 - powerpc or old apple hardware and its
139:58 - claim to fame was actually that it
140:00 - started this yum program for managing
140:02 - packages now the operating system itself
140:05 - didn't do well after the power pc
140:07 - platform kind of faded out but yum is
140:09 - still around today and in fact that's
140:11 - the program that we use on almost every
140:13 - rpm distribution it handles dependencies
140:15 - um it is it updates the repo information
140:18 - as it's installing and upgrading so
140:20 - unlike app you don't have to say like
140:21 - yum update and then yum upgrade when you
140:24 - upgrade yum updates before it does
140:26 - anything else now dnf which and i'm not
140:29 - kidding here it stands for dandified yum
140:32 - but dnf is the new program it's in
140:35 - fedora right now it's not in centos but
140:37 - it's going to replace yum it's just a
140:39 - rewrite it has some features that are
140:41 - that it worked better but similarly
140:44 - structured and how it works and then of
140:46 - course rpm is what happens behind the
140:48 - scene there's a program called rpm and
140:50 - this is the low level tool but it
140:52 - doesn't handle dependencies so we
140:54 - generally don't use the rpm tool on its
140:57 - own let me show you what i mean i'm on
140:59 - centos here and we're going to use yum
141:01 - to install packages but first i want to
141:03 - show you rpm now if we look i have
141:05 - downloaded this program called kate this
141:06 - is just a text editor that works in the
141:09 - kde environment but if we were to
141:10 - install it with rpm we would have a
141:12 - problem if we say rpm dash i for install
141:15 - the name of the package it's going to
141:17 - say i can't do that because you have 110
141:19 - billion different dependencies that
141:21 - aren't installed so what you'd have to
141:23 - do is find every dependency every rpm
141:26 - install them one by one
141:28 - these probably have dependencies of
141:30 - their own that we'd have to track down
141:31 - but thankfully that's where the package
141:33 - management system yum comes into play so
141:35 - we could simply just say
141:37 - yum
141:38 - install kate and it's going to go to our
141:40 - repositories it's going to update the
141:43 - cached information like show us the
141:45 - latest information from those
141:46 - repositories and then it's going to
141:49 - search for kate it's going to find all
141:50 - of the dependencies right here say it's
141:53 - looking for all the dependencies and the
141:54 - dependencies of the dependencies and now
141:57 - it says would you like to install it
141:58 - along with the 77 dependent packages
142:01 - okay i'm going to say yes actually i'm
142:02 - going to say no if we install it then it
142:05 - would just download install all of those
142:06 - packages and life would be good and we
142:08 - would have kate installed but what i'm
142:11 - going to do is now show you that's how
142:12 - we would install a package but if we
142:14 - want to update the system all we need to
142:15 - do is type yum
142:17 - upgrade and it's going to query all of
142:19 - our repositories it's going to download
142:22 - all the package information dependency
142:24 - information that we need and now it's
142:26 - just telling us if we want to get our
142:27 - system updated we're going to have to
142:29 - download 116 packages install one new
142:32 - package and it's going to take 308
142:34 - megabytes of space do we want to do that
142:36 - i'm just going to say yes and it's going
142:38 - to go through the whole process of
142:39 - downloading all those rpms it's going to
142:42 - use the rpm tool in the background
142:44 - install each one of them one by one
142:46 - until they're all updated and all
142:48 - installed to the latest version so yum
142:51 - is very simple to use and knowing that
142:53 - it comes from you know a distribution
142:56 - that's no longer even a valid
142:57 - distribution i don't know that's just
142:59 - cool for me that you know yum is still
143:01 - around even though yellow dog hasn't
143:03 - been a distro for many years now i don't
143:05 - have a fedora system to show you dnf
143:07 - first hand but it's a very similar
143:09 - program to yum it's going to work very
143:11 - very similarly so if you find yourself
143:13 - on fedora just use it very similarly to
143:15 - how you'd use yum and you'd be fine one
143:17 - of the big things i want to point out
143:18 - though is that there's no two-step
143:19 - process like there is with the apt
143:22 - environment meaning you don't have to
143:24 - update your repositories before you
143:26 - install it you just run yum and it's
143:28 - going to update and upgrade all the
143:30 - information before it does any
143:32 - installing or upgrading
143:35 - one of the nicest things about the app
143:37 - package management system is that you
143:38 - can add repositories which are just
143:41 - different groups of software packages so
143:43 - if something's not in the standard
143:45 - ubuntu or debian system and somebody
143:47 - else has written something you can add a
143:49 - whole repository of new software and
143:52 - then the app system can use it just like
143:54 - any other package on your system it's
143:56 - pretty cool now we're going to look how
143:57 - to add something and there are a few
143:59 - gotchas that we need to look at but
144:01 - thankfully it's a fairly simple system
144:03 - when it comes to configuring new
144:05 - repositories so i'm here in the etc apt
144:08 - folder on an ubuntu system if we do an
144:10 - ls we're going to see there are two
144:11 - things i want to show you there's
144:12 - sources.list this is a folder and
144:15 - there's actually nothing inside there
144:17 - right now but we could create a new
144:19 - file.list in here and it would be read
144:22 - just like this
144:24 - systemdefaultsources.list so it doesn't
144:25 - matter where things go i'll just add
144:27 - something to the existing sources.list
144:29 - so we're going to look and you'll see
144:30 - there's already a bunch of repositories
144:32 - added each one of these lines is a
144:34 - repository containing software that the
144:36 - apt system can install now some of them
144:39 - are commented so we would just uncomment
144:41 - the existing ones like here this is a
144:42 - partner archive we could uncomment this
144:44 - and then this would be an active
144:45 - repository but if we want to add a third
144:48 - party repository we can like i said
144:50 - either add it at the end of this file or
144:52 - create a new file in that sources.list.d
144:54 - folder and call it like new program dot
144:57 - list but i'm just gonna add it in here
144:58 - and i'm going to add the opera browser
145:01 - repository in here let's say we wanted
145:03 - to add the opera browser it looks like
145:05 - this
145:06 - it's okay if every field here doesn't
145:08 - make perfect sense to you this is just
145:10 - the format it says what kind of a
145:11 - package it is where it's stored what
145:14 - folder in there and then what version of
145:16 - the software we want to actually add the
145:18 - stable and then it's non-free as far as
145:20 - like what what type of repository it is
145:22 - so this is the line right this is where
145:24 - the opera browser is stored on the opera
145:26 - website so if we save this we would be
145:28 - able to do apt update no dash
145:33 - apt space update and if you look it is
145:36 - updating them all but i do want to show
145:37 - you back at the top here it gave us a
145:40 - little warning slash error oh and it
145:42 - repeated the error down here so i'm
145:43 - going to show you here it says this
145:44 - repository is not signed so what that
145:47 - means is we don't have their key because
145:49 - we don't want there to be a man
145:50 - man-in-the-middle attack where somebody
145:52 - you know takes over opera.com and then
145:55 - starts sending us bogus packages so they
145:57 - do signing key signing in order to make
145:58 - sure that we get the right software so
146:00 - if we want to use the repository we have
146:02 - to add their gpg key to our system now
146:06 - it's not difficult to do we just do kind
146:08 - of a two step here we have to download
146:09 - the key itself so wget
146:12 - so we're going to download the file and
146:13 - then pipe that into
146:15 - apt key add all right so we'll do that
146:18 - it's going to download the key and it's
146:20 - going to add it to our system and it
146:21 - just says ok we can see if it's there by
146:24 - typing apt key list and it's going to
146:26 - list all of the keys in our system and
146:29 - if we look we should be able to find
146:31 - sure enough here's the opera one so
146:33 - there's the upper key that we installed
146:34 - and now if we do apt update
146:36 - notice there's no errors at all it
146:38 - updated and now we could just install it
146:39 - using our app system app install
146:42 - opera stable and it would install our
146:46 - needed packages you know it would
146:47 - resolve dependencies even if they're in
146:49 - other distributions and it would install
146:51 - it for us just fine i'm going to say no
146:53 - because i want to show you another way
146:54 - you can add a repository and this is
146:55 - kind of a cool thing that ubuntu added
146:57 - it's called a ppa or a personal package
147:00 - archive there's a particular text editor
147:03 - that i really like it's called adam atom
147:05 - and they have a ppa which is a
147:07 - repository and to add it you just say
147:10 - add apt repository ppa colon and then
147:14 - where it lives or what user it is web
147:19 - team and the name of the repository is
147:22 - atom
147:23 - press enter it's going to do a couple
147:25 - things it's going to add it to our
147:27 - sources.list but it's also going to
147:29 - download that key for us so all we have
147:31 - to do is say press enter and it's going
147:33 - to install the key it even does an apt
147:36 - update for us and then we would just do
147:38 - apt install adam and sure enough it
147:40 - would be able to do it from that package
147:42 - or from that repository that we just
147:44 - added it can be a bit overwhelming once
147:46 - you have to start adding gpg keys for
147:48 - the repositories that you put into your
147:49 - sources.list but ppas make it really
147:52 - really really simple they do everything
147:54 - for you i really like ppas i think it's
147:55 - been a wonderful addition to the way we
147:58 - handle apt packages
148:01 - repositories in an rpm system using yum
148:03 - are very similar to that of an app
148:05 - system adding them is maybe even easier
148:08 - and editing the config is about the same
148:10 - just with different files let me show
148:12 - you what i mean now the main
148:13 - configuration file in centos is going to
148:15 - be the yum.com file so let's look at
148:17 - that it's in etc and it's
148:20 - yum.com here's where we can do a couple
148:22 - things one we set the main configuration
148:25 - things like where the cache is stored
148:27 - and things like this one thing i want to
148:28 - point out in here is this gpg check now
148:31 - you can actually turn off yum's ability
148:34 - to verify using signed key pairs and
148:38 - this will just allow it to install any
148:40 - repo or install from any repo that you
148:42 - install in your system it's not a good
148:44 - idea to turn this off though because
148:45 - again this is a safety check to make
148:47 - sure you're not getting a man in the
148:48 - middle attack but the main section is at
148:50 - top you can put new repos in the bottom
148:53 - or like it says right here you can put
148:55 - them in etc
148:56 - yum.repose.d as individual files with
148:59 - the format file dot repo that's usually
149:02 - what's done but we could add them here
149:03 - let's look inside the
149:05 - yum.repos.d folder so let's get out of
149:07 - here go into etc
149:09 - yum.repost.d
149:12 - and here's where all of the repos that
149:14 - are currently installed on our system
149:16 - live so let's look at one really quick
149:19 - look at the base file here and we're
149:20 - gonna see how it is set up so there's
149:23 - the base configuration up here the name
149:25 - of it the release where the actual files
149:28 - are stored gpg check you can turn this
149:30 - on and off for individual repos as well
149:32 - so if you set up a repo and you don't
149:34 - have signed key pair you could turn it
149:36 - off for just one repo and then this
149:37 - tells us where the actual key file if
149:40 - it's turned on lives so we can put our
149:43 - put it in there manually so that yum
149:44 - knows where to look to find that key now
149:47 - normally these aren't added manually but
149:49 - you could type all of these in these are
149:51 - all individual repos that are defined in
149:53 - here in this bracketed section usually
149:55 - what you do though it's really elegant
149:57 - is let's get out of here you just
149:59 - install the package so one of the really
150:00 - popular packages is called apple which
150:02 - stands for extra packages for enterprise
150:05 - linux and to do that we just do yum
150:07 - install apple release
150:10 - i'm gonna say yes to install it and now
150:12 - if we look in here we're gonna see here
150:14 - we go the apple.repo has been added so
150:17 - now if we were to install packages apple
150:19 - would also be one of the places that we
150:21 - could pull packages from we can just cap
150:23 - this to look at it
150:25 - and we can see it's enabled the gpg
150:27 - check is on it tells us to use this key
150:30 - file for checking the signatures and
150:32 - that's all there is to installing a
150:34 - repository in yum and since yum
150:36 - automatically updates we don't have to
150:38 - like update the cache when we install a
150:40 - package it's going to automatically fill
150:41 - in the blanks for us yum is an
150:43 - incredibly awesome and powerful package
150:45 - manager and we can tell just by how easy
150:47 - it is to add a repo and edit that config
150:49 - either using the yum.com file or the
150:52 - individual files inside etc yum.repo.d
150:57 - apt and yum are certainly the most
150:59 - common package managers out there but
151:01 - there are a few less common package
151:03 - managers that you should still be aware
151:05 - of now arch linux uses a program called
151:08 - pacman for managing their packages and
151:11 - open souza uses zipper now i'm not
151:13 - saying that the mascot for zipper is a
151:15 - purple horse but i'm just saying maybe
151:17 - it should be nevertheless it's not too
151:20 - difficult to use them even if you're not
151:21 - familiar here i have two terminal
151:23 - windows to two different linux
151:25 - distributions the first one is arch
151:27 - linux which uses the pacman package
151:29 - manager so if we just do pacman minus h
151:32 - we're gonna see here are a list of the
151:34 - commands now it's not immediately clear
151:36 - how you go about installing a package
151:38 - unfortunately it's not just install it's
151:40 - actually capital s for sync we kind of
151:43 - want to sync the system into a state
151:46 - that we wanted so to install a package
151:47 - it isn't difficult once you know what to
151:49 - do just pac-man minus capital s and
151:52 - let's install vim my favorite text
151:53 - editor you have to actually spell pacman
151:56 - correctly pac-man
151:58 - minus capital s vim it'll say do you
152:00 - want to install it and say yes it's
152:02 - installed it and now if we type vim you
152:04 - can see sure enough there's vim my
152:06 - favorite text editor now over here in
152:08 - open souza it's a little bit different
152:10 - here we use a program called zipper
152:12 - zypper we're gonna do zipper minus h and
152:16 - it'll show us all of the help commands
152:18 - that are available this one it is pretty
152:20 - easy you just do install or you can
152:22 - shorten it to just in so we could say
152:24 - zipper
152:26 - in
152:27 - vim we'll install vim again press enter
152:29 - it's going to retrieve the repositories
152:31 - online just like yum or apt would do and
152:33 - then it's going to install the vim
152:36 - package for us and we'll be able to use
152:37 - it on open souza
152:41 - it'll ask us so we want to continue i'm
152:42 - going to say yes
152:44 - and it installs all of the packages and
152:47 - the dependencies so now same thing here
152:48 - we get startup vim and sure enough
152:50 - there's vim this time on open souza
152:53 - pac-man and zipper are really two of the
152:55 - more popular alternative package
152:57 - managers but there are some others if
152:59 - you're on slack where you're gonna have
153:00 - to install things by hand using tar.gz
153:03 - files but these two along with apt and
153:05 - yum will get you through most systems
153:09 - managing local users on your server is
153:11 - really easy and there's a bunch of tools
153:13 - that make it even easier now there's the
153:15 - standard command line tools that allow
153:17 - you to add modify and delete accounts
153:19 - and there's this super cool script that
153:21 - i really like which makes adding a user
153:24 - very very easy there are a whole bunch
153:27 - of different facts about a user that is
153:29 - stored in the system though full name
153:31 - username password all of these things
153:33 - plus some others that aren't even listed
153:35 - are on there and it's important to know
153:37 - that the tools will manipulate all of
153:39 - these but you don't have to specify
153:41 - every single thing every time especially
153:43 - things like office number those aren't
153:45 - even really used anymore but there are
153:48 - possibilities that you can add specific
153:50 - information in the local group now i
153:52 - just want to go right to the command
153:53 - line so we can actually start adding
153:55 - users and at first we're going to use
153:57 - the tools that you know kind of come
153:59 - with it like the low level tools user
154:02 - add user dell and user mod so first of
154:04 - all i want to say
154:05 - user add because we don't have any extra
154:07 - users on our thing i'm going to do dash
154:09 - h and that'll give us the help screen
154:11 - now you can see there are tons of
154:13 - options for adding users but the format
154:16 - is pretty much the same user add
154:18 - whatever options you want to add and
154:20 - then the login or the username for the
154:22 - new user now we're going to use just a
154:24 - couple and i want to show you the
154:25 - problem with using user ad as opposed to
154:28 - that fancy script add user
154:30 - we have to determine like a home
154:32 - directory and a user shell and all sorts
154:35 - of things like that so let's say we
154:36 - wanted to make a user we're just going
154:38 - to say now notice i'm root we have to be
154:39 - root to make a system user but we would
154:41 - say user add and i want to do minus d
154:46 - home susie minus s for shell i'm going
154:49 - to use the bin
154:50 - bash shell and her username is going to
154:53 - be susie
154:55 - press enter it's all done now there is
154:56 - no password for susie we'd have to
154:58 - actually do that with the password
154:59 - command uh we'll actually say
155:01 - p-a-s-s-w-d
155:03 - suzy all right so now she has a new
155:05 - password and we can here let's start a
155:07 - new window
155:08 - ssh suzy at
155:10 - localhost susie
155:12 - and we're logged in as susie oh but see
155:16 - it says unable to change to directory
155:17 - home susie there's no such file or
155:19 - directory well dog on it we said that
155:21 - that's our home directory but by default
155:23 - it doesn't make that directory we
155:25 - actually have to make that directory or
155:27 - there's another command dash m which
155:29 - will create it as we're adding the user
155:31 - so it's possible again to use this tool
155:34 - and set all of those different flags up
155:36 - as we create the user if we go through
155:38 - all of these things but it's much easier
155:40 - to use the add user script and i'll show
155:42 - you what i mean
155:43 - add user frank and now it says okay i'm
155:46 - creating the frank user added a new
155:48 - group for frank created frank's home
155:50 - directory copying all the files from
155:52 - etsy scale and now it's asking me put to
155:54 - give frank a password so i'm going to do
155:56 - that now the full name of frank his room
155:59 - number which again we don't use room
156:01 - number work phone all those things
156:03 - anymore really but full name is nice to
156:05 - have in there and is this information
156:06 - correct i'm going to say yes
156:08 - and so now we have a really nicely set
156:11 - up user so if we were to open a new tab
156:13 - again and do ssh frank at localhost log
156:17 - in with frank i have to type frank's
156:19 - password correctly and now you'll see
156:21 - sure enough if we do pwd we're gonna see
156:23 - we're in frank's home directory he has a
156:25 - perfectly usable account because that
156:26 - add user script goes through and
156:28 - remembers all the various things that we
156:30 - need to do so let's get out of here now
156:33 - there is another tool we can use user
156:36 - dell so we can say user dell let's do
156:39 - minus h so we can see the options
156:40 - there's really only one option that's
156:42 - ever really important that is minus r
156:44 - which removes the user's files so we
156:46 - could say user dell
156:48 - [Music]
156:49 - r for remove frank and it removed all
156:52 - those files that said there wasn't any
156:54 - mail form so i couldn't remove that but
156:55 - now frank's home directory is gone now
156:58 - we could modify suzy's account if we use
157:01 - user mod so let's see user mod minus h
157:05 - and we're gonna see same thing we have a
157:06 - whole bunch of tools and this is just to
157:08 - modify an existing user so we could do
157:11 - something like change her shell like
157:13 - right now it's been bashed but we could
157:15 - change her shell so we could say user
157:17 - mod
157:18 - minus s let's say bin
157:21 - false susie
157:22 - what this is going to do it's going to
157:24 - change her shell so if she tries to log
157:26 - in it's going to fail so let's open up a
157:28 - new tab and try to log in as her ssh
157:32 - susie at localhost it logged in and then
157:35 - immediately logged out see it says it
157:37 - still doesn't have a user account we are
157:39 - a user directory we didn't make her a
157:40 - home directory but then it says
157:42 - connection to localhost closed that's
157:44 - because as soon as it logged in her
157:46 - shell is been false which immediately
157:48 - exits and then we're back to being
157:50 - logged out we're logged in as bob here
157:52 - so the ability to modify a user account
157:55 - is really important but if you're going
157:57 - to add a user i highly recommend you use
157:59 - that script you can certainly use the
158:02 - manual tools with all the flags to add
158:05 - that account but add user just makes it
158:06 - so easy by remembering all the steps and
158:09 - i'll be honest i often have a difficult
158:10 - time remembering is it add user or user
158:13 - ad add user user ad for my own sake i
158:16 - like to think okay alphabetically add
158:18 - user is first and that's the first tool
158:20 - i want to use for adding a user so
158:22 - that's just the trick i use regardless
158:24 - of what tools you use to add users it's
158:26 - important to understand that modifying
158:28 - them on the command line is fairly
158:30 - simple and not that difficult to learn
158:33 - local groups on a linux system are
158:35 - fairly straightforward to handle but
158:37 - it's important to understand the
158:38 - difference between primary groups and
158:39 - secondary or supplementary groups on
158:42 - each individual user now every user on
158:45 - the system is going to have their own
158:47 - personal primary group now usually
158:50 - that's going to be the same as their
158:52 - username so bob is going to have a
158:53 - username of bob and he's also going to
158:55 - have a primary group of bob and that's
158:57 - usually how it goes it could be a it
158:59 - could be a different group that says
159:01 - primary group but almost always that's
159:03 - how the primary group is going to be on
159:05 - a linux system and then there are all of
159:07 - the supplementary groups which happen to
159:09 - be like things that he belongs to like
159:11 - maybe he's in the admin group maybe he's
159:13 - in the sales group marketing third floor
159:16 - public all of these groups are in
159:18 - addition to his primary group and it
159:20 - will give him access to certain folders
159:22 - on the system that he might not have
159:24 - access to if he didn't have these
159:26 - different group memberships now in order
159:28 - to actually create groups the tools are
159:30 - very straightforward just like adding
159:32 - users with much fewer options so let's
159:35 - actually look at that and i want to show
159:36 - you how to manipulate users in groups on
159:39 - a system now here we are on an ubuntu
159:41 - system and we can simply say
159:43 - group add
159:45 - public it's going to add the group
159:46 - public to our system we could say
159:49 - group ad
159:50 - sales and it's going to do that now we
159:52 - could look at the different options
159:53 - group add minus h you see there aren't
159:56 - too many options we could specify a
159:58 - group id number if we wanted and we
160:00 - could do some things with group mod to
160:03 - change some of those features like the
160:05 - group id and then of course we could
160:06 - delete them with group dell and the same
160:09 - sort of thing you know we just delete
160:11 - them as we would use user dell on a
160:13 - system to get rid of a user so this is
160:16 - pretty straightforward but the part
160:17 - about primary and secondary can be
160:19 - confusing so right now if we type groups
160:22 - bob we're going to see that bob is in
160:24 - all of these groups the first one listed
160:26 - is his primary group so bob's primary
160:29 - group is bob and then these are all of
160:31 - his supplementary or secondary groups
160:34 - now i want to show you user mod minus h
160:37 - because it shows us how we can
160:39 - manipulate groups right here so
160:42 - lowercase g is how we force a user to a
160:45 - new primary group so we could change
160:47 - bob's primary group using the lowercase
160:50 - g flag on user mod in order to change
160:53 - his secondary or supplementary groups we
160:56 - use a capital g but here's where the
160:58 - gotcha comes into play if we do like
161:01 - minus capital g public it's going to
161:04 - delete all of his other supplementary
161:06 - groups and only make him part of the
161:07 - public group and that's not what you
161:09 - almost ever want so there's this nice
161:12 - dash a which means append the user to
161:16 - another supplementary group without
161:18 - getting rid of the additional groups
161:20 - that he already belongs to so let's
161:21 - actually do that in practice so we're
161:22 - going to say user mod minus a for append
161:26 - minus capital g
161:27 - public bob okay and now if we do groups
161:31 - bob we're going to say that bob still
161:32 - belongs to all those secondary groups
161:35 - and also to the public group which is
161:37 - exactly what we wanted to have happen
161:39 - because if we wouldn't have used that a
161:41 - this is what would have happened if we
161:42 - would have done user mod minus g let's
161:46 - do sales for bob this seems like it's
161:49 - going to do the right thing no errors
161:51 - but then if we do
161:52 - groups bob we're going to see uh he
161:54 - still has his primary group of bob and
161:56 - then just sales and so we'd have to
161:58 - manually go back through and add him to
162:01 - each individual group which is really a
162:03 - pain in the butt so you don't want to do
162:05 - that you want to always remember to use
162:06 - the dash a now in function the
162:08 - difference between a primary group and a
162:10 - secondary group the primary group is
162:12 - what is used if bob were to create a
162:15 - file so let's open up a new tab here we
162:18 - are bob
162:19 - say this is in our home folder if bob
162:21 - were to
162:22 - touch a file and we do ls minus l we're
162:24 - going to see the file that we just
162:26 - created is owned by bob and the group
162:29 - membership is bob's primary group of bob
162:31 - so that's really the difference between
162:33 - primary and secondary is when you have a
162:35 - primary group that's what the group
162:37 - membership of a new file you create is
162:39 - going to belong to now creating groups
162:41 - is really easy with the group ad group
162:43 - mod group dell tools so i didn't even go
162:45 - into that very much in depth the real
162:47 - important takeaway is the idea of
162:49 - primary versus secondary or
162:51 - supplementary and how to take individual
162:53 - users and put them into groups without
162:56 - deleting all of their other
162:57 - supplementary groups that they already
162:59 - belong to i hope this has been
163:01 - informative for you and i'd like to
163:02 - thank you for viewing figuring out what
163:04 - users are on your system and what
163:06 - accounts they're using and what they're
163:07 - doing is really an important part of
163:09 - forensics but also it's an important
163:11 - part of a sanity check like why is my
163:13 - computer running slow or what user am i
163:16 - logged in as and there is a handful of
163:18 - simple command line tools that we're
163:19 - going to go over that will just help you
163:21 - figure out the users on your system now
163:24 - the first scenario this happens a lot if
163:25 - you log into embedded systems like
163:28 - routers and stuff where you don't get a
163:29 - prompt that tells you who you are you
163:31 - just get like a hashtag here well what
163:33 - you can do is say who am i which seems a
163:35 - little bit silly but it will just give
163:37 - you the user that you're currently
163:38 - logged in as if you're starting to use
163:40 - sudo and su and you're sshing from one
163:43 - computer to another sometimes just
163:44 - figuring out what user you're logged in
163:46 - as is really important so that's it
163:49 - seems silly but it's something that i
163:50 - use in nuggets even you'll see me use
163:52 - that quite a bit another one if we just
163:54 - do who it'll show us who is logged into
163:57 - our current system it actually gives us
163:59 - quite a bit of information we have bob
164:01 - frank it looks like susie is logged in
164:03 - twice and it tells us when that person
164:05 - logged in and where they're logged in
164:07 - from so bob is our current user and i'm
164:10 - logged in on the display zero meaning
164:13 - i'm using an x windows session here and
164:15 - then frank and susie are both logged
164:17 - into localhost probably ssh and then
164:19 - suzy is logged in from a remote computer
164:21 - probably over ssh as well so who tells
164:24 - you that w which is like what although
164:27 - you don't have to type the rest of it
164:28 - it's just a w gives you the same
164:30 - information with a little bit more so
164:32 - these are the users where they're coming
164:33 - from when they logged in how long
164:36 - they've been idle and then what again
164:38 - that's where that what came from what
164:40 - they're actually doing so here i'm using
164:42 - a gdmx session uh looks like frank is
164:44 - sleeping on the job frank judging you
164:47 - buddy
164:48 - and then susie's just logged into a bash
164:51 - terminal so these are tools that give
164:53 - you information another one is pinky
164:56 - which seems like a silly tool but it
164:57 - replaces the older tool finger that has
165:00 - kind of been abandoned about 10 years
165:02 - ago but this gives you even more
165:04 - information but not the what's going on
165:06 - this gives you the login name full name
165:09 - when they logged in how long they've
165:10 - been idle where they're coming from and
165:12 - a combination of these really usually
165:14 - any one of them will give you the
165:15 - information that you want but these are
165:17 - all here to give you information on
165:19 - who's logged into the system now if you
165:21 - want further information about it you
165:22 - could also do id susie and it will give
165:25 - you information about susie's id
165:27 - including her user id her primary group
165:30 - id what groups she belongs to looks like
165:32 - she only belongs to the susie group so
165:34 - let's do an id on bob and yeah bob
165:37 - belongs to a whole bunch of other groups
165:38 - so it'll give you all of that and then
165:40 - lastly lastly there's the command last
165:44 - hahaha if you type last it gives you a
165:46 - history of the people that have been
165:48 - logged into the system recently so it
165:50 - looks like we go back all the way to
165:52 - march 7th here today's march 13th and i
165:55 - logged in a bunch of times just so we
165:56 - would get some results here and we can
165:58 - see who logged in where they logged in
166:00 - from and when they logged out or if
166:03 - they're still logged in so you can see i
166:05 - logged in at 1001 logged out at 1001 up
166:07 - here logged in at 1003 still logged in
166:10 - from the local host computer and that is
166:14 - susie so there's a lot of tools that you
166:16 - can use to figure out who's logged into
166:17 - your system how long they've been there
166:19 - where they're coming from what they're
166:20 - doing and these really might seem like
166:22 - throwaway commands like why would i need
166:24 - to figure out who's logged into the
166:25 - system but knowing the simple little
166:27 - tools like who and w and last can really
166:30 - be convenient when you're tracking down
166:32 - what's going on on your server who's
166:34 - logged in who was logged in did somebody
166:36 - log in bob said he logged in did he
166:38 - really log in well check out last and
166:40 - it'll tell you the point is there's a
166:42 - bunch of tools that are available
166:43 - that'll give you information on users on
166:45 - your system whether they're logged in
166:47 - not logged in or have been logged in in
166:49 - the past
166:51 - passwords and group memberships are
166:53 - things in linux that are stored in text
166:54 - files just like everything else but the
166:56 - problem is we don't want people to have
166:59 - access to our passwords and so there's
167:01 - kind of this elegant system of shadow
167:04 - files that has been invented this is
167:05 - fairly recent in the world of technology
167:08 - it used to be everything was stored in a
167:10 - single file called etc password but
167:12 - things have been changed now so that
167:14 - everybody doesn't have access to seeing
167:16 - the encrypted passwords so how it works
167:19 - now is this let's say this is our user
167:21 - bob now bob when he logs into a system
167:24 - has to be able to see what his home
167:26 - directory is so he needs to have access
167:28 - to a lot of information about his
167:31 - account however we don't want bob to
167:33 - have access to everybody's encrypted
167:35 - passwords so that's kept over in another
167:37 - file called a shadow file so what we
167:40 - have in the password file is we have
167:42 - bob's username and then literally just
167:44 - an x that takes the place of where the
167:46 - password used to be stored and if this x
167:48 - is here then the system knows okay i
167:50 - need to go over and look in the shadow
167:52 - file for the actual encrypted password
167:55 - of bob and then it does system
167:57 - authentication with root access as
167:59 - opposed to
168:01 - bob's access which is to read the
168:02 - password file but he doesn't have access
168:05 - to everybody's encrypted password the
168:07 - reason we don't want that is if he were
168:09 - to do like a brute force attack if he
168:12 - had access to everybody's encrypted
168:14 - password he could just keep hammering
168:16 - away at it until he finally figured out
168:18 - what the password was we don't want that
168:20 - so we don't want every user to have
168:22 - access we just want root or the system
168:25 - to be able to authenticate and check out
168:27 - you know the encrypted password file so
168:29 - anyway there's a neat and elegant system
168:31 - of how this works now notice obviously
168:33 - the etc password file is readable by all
168:36 - the etc shadow file is only accessible
168:39 - by the root user but when it comes to
168:41 - editing those there are special tools to
168:43 - make sure that we do it properly now
168:45 - first let's actually look at the files
168:47 - so if we do an ls minus all of etc pass
168:50 - sswd we're going to see that sure enough
168:52 - it's owned by root and everybody on the
168:55 - system can read it right only root can
168:57 - write to it but everybody can read it
168:59 - but if we look at the etc shadow file
169:02 - we're gonna see that only root can write
169:04 - to it and only people in the shadow
169:07 - group can read to it everybody else in
169:08 - the system can't even read it so our
169:10 - encrypted passwords are protected now
169:12 - there's also if we do ls minus l etc
169:15 - group we'll see the same scenario where
169:17 - this is the group definitions for users
169:20 - on the system and the same settings
169:22 - permission wise as etc password has and
169:25 - if we do ls minus l
169:27 - etc
169:28 - g shadow we're gonna see it's the exact
169:30 - same thing as the shadow file now groups
169:32 - don't normally have passwords associated
169:35 - with them but they can so the shadow
169:37 - system does the same with the group file
169:39 - as it does with the password file now if
169:41 - we wanted to edit one of these files we
169:43 - could do something like sudo vi et
169:46 - cetera pass
169:48 - wd and it's going to let us edit this
169:50 - file using our text editor but this is
169:52 - not the ideal way to go about it because
169:55 - we want to do it the shadowy way right
169:57 - we want to be able to edit it and then
169:59 - be sure that the shadow file matches so
170:02 - let's get out of here let's not make any
170:03 - changes to properly edit these files
170:05 - what you do is say sudo
170:08 - vipw this is part of the shadow package
170:11 - and it's going to ask us what editor we
170:13 - want to use if you want to use nano this
170:15 - is the easiest one like it says right
170:16 - here easiest you can use this i prefer
170:18 - to use vim so i'm just going to choose
170:20 - selection number two but number one is
170:22 - perfectly fine and it opens up and looks
170:24 - exactly the same and we make changes
170:26 - here and we could like go down here
170:29 - you'll notice all the things about bob
170:30 - are listed in this line right here's his
170:32 - username his password is just a
170:34 - placeholder here as an x because the
170:36 - actual encrypted password is in the
170:38 - shadow file but his user id is group id
170:40 - his full name his home directory his
170:43 - shell we could make any changes we
170:44 - wanted here and then we would just go
170:47 - and save the changes
170:49 - and this is what it would tell us it
170:50 - would say okay you've modified the etc
170:52 - password file you may want to modify the
170:54 - shadow file too and to do that you do
170:56 - vipw dash s for shadow so the same thing
170:59 - we would say
171:00 - sudo vi pw
171:02 - dash s
171:04 - and now this is the actual shadow file
171:06 - that we're editing and we can go through
171:08 - and if we wanted to make changes here
171:10 - this is bob's encrypted password now
171:12 - this is obviously not bob's plain text
171:15 - password his plain text password is just
171:16 - the word bob we know that but this is
171:19 - what it's like encrypted but since this
171:21 - is only accessible to root there's
171:23 - nobody who's going to be able to do a
171:24 - brute force attack to try to decrypt
171:26 - this
171:27 - because they don't have access to the
171:28 - passwords encrypted themselves so we'll
171:31 - get out of here and now the exact same
171:32 - thing with the group password or the
171:35 - group file in the group shadow file is
171:37 - done too we can say sudo vigr
171:40 - and this is going to edit the group file
171:42 - and sudo vi gr
171:45 - s and that's going to edit the g shadow
171:47 - file all right so that's the proper way
171:49 - to go about editing those files manually
171:51 - if you man if you edit these files it's
171:53 - going to do the same thing as if we did
171:55 - like user mod and changed somebody's
171:57 - home directory it just does it by
171:59 - editing the underlying configuration
172:01 - files so yes group and password files
172:03 - are still just text files but there is
172:05 - this elegant shadow system that allows
172:08 - us to make sure that the right people
172:10 - have access to the encrypted passwords
172:11 - and not everyone on the system can see
172:13 - everyone else's encrypted passwords
172:16 - quotas are the way that we make sure
172:18 - users or groups don't overuse the hard
172:22 - drive we don't want a particular user a
172:23 - particular group to use up too much of a
172:25 - hard drive and stop other people from
172:27 - saving files now there's soft quota
172:29 - limits and hard quota limits the
172:31 - difference is with a soft limit you're
172:33 - warned every day hey you've gone over
172:35 - your limit hey you've gone over your
172:36 - limit whereas if you reach the hard
172:38 - limit you're no longer able to save
172:41 - files at all now there's a couple things
172:42 - that we have to do to get our system
172:44 - ready for using quotas and keeping track
172:47 - of things but the first thing is we have
172:48 - to make sure that our partition is
172:50 - mounted correctly so on our system here
172:53 - i have a disk mounted or a 10 gigabyte
172:56 - drive mounted on
172:58 - mnt
172:59 - disk okay now if we look into our etc fs
173:02 - tab file i'm going to show you how you
173:05 - mount it so that quotas are enabled so
173:07 - here's our drive it's dev sdb1 and it's
173:09 - mounted on mnt disk it's ext4 i've used
173:13 - default mounting options and then i've
173:15 - added a comma and usr quota now we could
173:19 - also put grp quota we could put another
173:21 - comma and grp quota i'm just going to do
173:23 - user quotas group quotas work the same
173:25 - way so we'll learn one and we'll know
173:27 - how to use both but we have to make sure
173:29 - that it's mounted this way so if you're
173:31 - making this change you want going to
173:32 - want to reboot your system to make sure
173:33 - that it actually takes effect
173:36 - and then if we type mount we're going to
173:38 - see that sure enough mount disk or mnt
173:40 - disk is mounted with quotas enabled
173:43 - specifically user quota management okay
173:47 - so we know that the drive is able to
173:49 - support it but out of the box quotas are
173:52 - not turned on so what we need to do is
173:55 - first of all scan the existing drive for
173:58 - files owned by a particular user so we
174:00 - need to actually do sudo
174:02 - quota check
174:04 - dash a for all partitions that support
174:06 - quotas dash u for user owned files press
174:10 - enter it's going to go through it's
174:12 - going to check our drive and now if we
174:13 - look in mnt
174:15 - disk
174:16 - we're going to see sure enough now
174:18 - there's a quota file that has been
174:20 - created and it shows just you know all
174:22 - the files on the drive who owns them
174:23 - which is none right now but we're going
174:25 - to change that in a minute now the other
174:26 - thing is so that prepares the drive but
174:28 - we actually have to turn quotas on so
174:30 - we're going to say sudo quota on
174:33 - a for all supported partitions
174:35 - so now quota quota ing
174:38 - is actually turned on but if we want to
174:40 - set a particular quota for a user we're
174:42 - going to have to use ed quota so sudo
174:46 - ed quota and i want to do this for the
174:48 - user bob on our system so we're going to
174:50 - do it for
174:51 - bob and then we get this list now it's
174:53 - going to show us all the file systems
174:54 - that support quotas in our case that's
174:56 - just this one dev sdb1 now i have to
174:59 - explain really quickly there's two kinds
175:01 - of quotas we can do we can set up quotas
175:03 - for inodes or we can set up quotas for
175:06 - block usage now an inode means a file so
175:10 - we could say how many files a person can
175:13 - store on a particular partition but this
175:15 - isn't all that useful right i mean what
175:17 - if they have two files but those two
175:19 - files are like 27 gigabytes each so
175:22 - rather than set limits on inodes i tend
175:24 - to like to set them based on blocks now
175:27 - by default these are one kilobyte blocks
175:30 - so this zero means how many are
175:32 - currently in use and there's nothing on
175:33 - the drive owned by bob so that's set to
175:35 - zero right now
175:37 - but i'm going to make some changes here
175:38 - i'm going to say i want the soft limit
175:42 - to be 500 kilobytes and i want the hard
175:45 - limit to be 1000 kilobytes okay or like
175:48 - one megabyte this is not practical
175:50 - number you'd probably do something
175:51 - bigger in real life but we're going to
175:53 - save this say yes and now as bob if we
175:56 - go over to mount disk ls we're going to
175:59 - see that's in there now there's no usage
176:01 - currently but let's say i were to create
176:04 - a file now to do that i'm going to use
176:05 - dd it's okay if you don't use the dd
176:07 - command basically we're going to say an
176:09 - input file of dev zero output file of
176:14 - file one block size equals one kilobyte
176:18 - so that we can know exactly how many
176:19 - kilobytes we're using up and count
176:22 - equals let's say 400 so this should make
176:24 - a 400 kilobyte file if i press enter and
176:27 - do ls minus l we're going to see sure
176:29 - enough we have a 400 kilobyte file on
176:31 - here and this is fine this isn't meeting
176:33 - our quota at all we haven't done
176:35 - anything bad we're not even up to our
176:36 - soft quota but if we do this again i'm
176:38 - just going to push the up arrow and
176:40 - change this to file 2 and press enter
176:43 - okay it's done the same thing we do ls
176:45 - minus l now there's 800 kilobytes stored
176:48 - on this particular disk what this means
176:50 - is it hasn't stopped us from creating it
176:52 - but every day we're going to get an
176:54 - email from the system that says
176:55 - hey you've gone over your soft limit you
176:58 - really need to delete some files and
177:00 - we'll maybe do that maybe we won't do
177:01 - that but here's what happens if we try
177:03 - to create another 400 kilobyte file
177:06 - which will take us over the limit right
177:08 - because 400 plus 400 plus 400 would be
177:11 - 1200 but we only have a thousand
177:13 - kilobyte limit so what's gonna happen if
177:15 - we press enter it says that there's an
177:18 - error writing file three the disk quota
177:20 - is exceeded so let's do ls minus l and
177:22 - see what happened so it looks like it
177:23 - went along and it was creating fine
177:25 - creating fine it got to 200 kilobytes
177:27 - and all of a sudden it couldn't write
177:28 - anymore and that makes sense because 800
177:31 - or 400 plus 400 is 800 plus 200 it is a
177:34 - thousand so we hit our hard limit and
177:36 - that's exactly how quotas work on the
177:38 - system once quotas are turned on it's
177:40 - really a hands-off kind of thing they
177:42 - take care of themselves the emails go
177:44 - out automatically every day if the user
177:46 - goes over their soft quota and at the
177:48 - hard quota it stops them no matter what
177:50 - so quotas are easy to set up once you
177:53 - remember to use quota on to turn it on
177:55 - make sure that it's mounted with the
177:56 - proper options and run that initial
177:59 - quota check so that it knows what files
178:01 - are on there so it knows when it is or
178:04 - isn't getting close to the actual quota
178:06 - that you set
178:07 - user profiles are where initial settings
178:10 - are set for a particular user like if if
178:12 - they're going to set up like aliases or
178:14 - they need their path variables those are
178:16 - the sort of things that profiles will do
178:18 - and there are system-wide profiles and
178:20 - also individual profiles and it can be a
178:23 - little bit overwhelming because not
178:25 - every linux system is the same now there
178:27 - are some commonalities usually there's
178:29 - an etc environment file and that file
178:31 - will
178:32 - often but not always set up the path
178:35 - variables so that the users who log in
178:37 - get a particular
178:38 - path set up now there's almost always an
178:41 - etc profile in the system-wide file in a
178:44 - profile is something that is run on a
178:48 - login shell so like the very first time
178:50 - you log into a system like if you're
178:51 - logging into a gui
178:53 - that first time you log in you will
178:54 - execute the profile these are settings
178:56 - that only need to be executed one time
178:58 - like it doesn't matter if you're going
179:00 - to open a new terminal you only need to
179:02 - set these settings one time and then
179:05 - there's also going to be one of these
179:08 - not both of these it's usually either
179:09 - one or the other either the etc bash rc
179:12 - or etc bash dot bash rc uh this one is
179:16 - pretty common in ubuntu this one is
179:17 - pretty common in centos
179:19 - but nonetheless these are they serve the
179:21 - same function so you're going to have
179:22 - one or the other and these are profile
179:25 - settings that need to be set every time
179:27 - you open a shell so let's say you're
179:28 - already logged in to
179:30 - x windows like in a gui session you're
179:32 - in there and you click on an icon to
179:34 - open up a new terminal window well
179:36 - that's not considered a login shell this
179:38 - is just considered a sub shell of your
179:41 - main system login so you will not
179:43 - execute a profile you will only execute
179:46 - your bashrc now this is again systemwide
179:50 - so that happens to everybody when you
179:51 - log in you get the systemid profiles
179:53 - applied and then every individual has
179:56 - the possibility to have these individual
179:59 - files in their home folders now they all
180:00 - start with a dot so they're all hidden
180:03 - you have to do ls minus a if you want to
180:04 - see them
180:05 - but these are the same things up here
180:08 - it's just if you have any changes or
180:09 - additions you want to make to the
180:10 - system-wide settings you put them in
180:12 - your own personal folder and you put it
180:15 - in like bash rc and that'll run every
180:17 - time you open a sub shell everything in
180:19 - here will be set up and then the dot
180:21 - profile or bash underscore profile
180:23 - depending on which system you have
180:25 - you're going to have one or the other
180:26 - one of these but this is executed
180:28 - the very first time you log in just like
180:30 - the system-wide profile your personal
180:32 - profile only gets executed that initial
180:35 - time when you log into the system any
180:37 - sub shells will only apply the bashrc
180:40 - files but that's the way it works i'll
180:41 - show you really quick how it's set up on
180:44 - a system
180:45 - but the hierarchy is really the
180:46 - important thing to understand now this
180:49 - is bob's home folder i did an ls minus
180:51 - la so you can see all of the things in
180:53 - here he has a dot bash rc file and he
180:56 - also has a dot profile that means that
180:59 - these are going to be applied after the
181:01 - system-wide settings because the
181:03 - system-wide settings are given to
181:04 - everybody and then any personalizations
181:06 - like if you have an alias that you want
181:07 - to set on your own you would put it in
181:09 - your own personal bash rc file now
181:11 - inside etc there are those common files
181:15 - like ls minus l grep4
181:18 - profile we're going to see we have etc
181:21 - profile and also etc profile.d this is a
181:25 - folder if we go in there we're going to
181:27 - see there's a bunch of sh scripts all of
181:29 - these are included in the dot profile in
181:32 - fact i'll show you what i mean vi dot
181:34 - dot
181:35 - let's look at that system-wide profile
181:37 - file
181:38 - and if we look all the way down in the
181:40 - bottom here it's going to call in all of
181:43 - those files inside profile.d so when i
181:46 - say that the profile is executed by
181:48 - everybody not only etc profile but also
181:51 - etc profile.d everything in here is
181:55 - going to be executed as well to every
181:57 - user on the system now there's a couple
181:59 - important things to remember don't worry
182:01 - so much about what exactly is the name
182:04 - of the file when you look in the etc
182:05 - folder you're either going to find an
182:07 - etc bash rc file or an etc dot bash rc
182:11 - file don't worry too much about which
182:13 - system has which whichever one is there
182:15 - is the one that you need to use now as
182:17 - far as the hierarchy goes it's important
182:20 - to remember that the system-wide stuff
182:22 - is executed for everybody so everything
182:24 - in etc is executed for all users and
182:27 - then if you have changes or additions
182:29 - you put them in your personal dot
182:31 - profile or dot bash rc user profiles are
182:34 - pretty easy to track down and once you
182:36 - understand how the system-wide and
182:37 - individual settings work it's a snap to
182:40 - figure out which comes first
182:42 - if you're working on the command line a
182:44 - text editor is going to be an invaluable
182:46 - tool because pretty much everything in
182:47 - linux is text based now you should use
182:50 - nano nano is the editor you should use
182:53 - it's a wonderfully simplistic
182:55 - straightforward intuitive text editor
182:58 - that works just fine and then there's vi
183:01 - vi is clunky it's hard to use it doesn't
183:04 - make a whole lot of sense and it's the
183:07 - editor that i use almost exclusively now
183:10 - i know that doesn't make any sense
183:12 - but here's the deal vi has been around
183:14 - for a very very long time like since the
183:17 - beginning so even though it's difficult
183:19 - to use i've managed to learn to use it
183:21 - and it's just what my fingers do with
183:23 - muscle memory so i encourage you use
183:26 - nano unless you've been using vi long
183:29 - enough that it's the only option that
183:31 - seems to make sense now there is one
183:34 - scenario that you may want to learn at
183:36 - least the basics of vi
183:38 - sometimes you're going to come across a
183:39 - system that doesn't have nano installed
183:42 - most systems do but if you end up on a
183:44 - system that only has vi
183:47 - these couple commands are going to kind
183:49 - of save your bacon so here's the deal
183:52 - this is what makes vi so confusing there
183:54 - are two modes there's command mode which
183:57 - is what it starts in an insert mode
183:59 - which is what you use when you actually
184:01 - type text now the way that i can kind of
184:04 - describe this is if you're sitting down
184:07 - and typing you're going to be in insert
184:09 - mode because insert mode is where you
184:11 - insert text and delete text and use your
184:13 - arrow keys to you know go around and
184:15 - change text but then if you need to do
184:18 - some command
184:20 - like save or quit or anything like that
184:23 - you're going to go into command mode and
184:25 - the way i think about it is let's say
184:27 - you are on a standard word processor if
184:29 - you're typing
184:31 - you're in insert mode if all of a sudden
184:33 - you need to reach for the mouse and
184:35 - click on something
184:37 - you're going to be in command mode so
184:38 - while it's not a perfect analogy if you
184:40 - want to do something like save you're
184:42 - going to want to go into command mode so
184:44 - that you can save and quit now since
184:46 - there's no mouse it's all still text
184:49 - things that you're doing but think
184:51 - mentally okay i'm in the mode where i'd
184:53 - be using my mouse to save things instead
184:56 - of just typing out text now to go back
184:58 - and forth that can be confusing too so
185:01 - you start out when you open vi you're in
185:03 - command mode if you want to start typing
185:05 - something you press either i for insert
185:08 - or a for append meaning like do you want
185:10 - to insert right where the cursor is or
185:13 - to the right of where the cursor is but
185:14 - either one is going to work fine so
185:16 - either i or a and then if you want to
185:18 - get back
185:20 - into command mode you press escape so
185:23 - those are your magic keys to go back and
185:25 - forth right i or a i usually use i to go
185:28 - into your typing text mode or insert
185:30 - mode escape to go back so that back and
185:33 - forth that's how it works
185:35 - now the actual commands to save or quit
185:39 - or save and quit are right here and they
185:42 - may not make sense but if you're in
185:43 - command mode you're going to press colon
185:47 - and then type w
185:49 - and then q and press enter that's going
185:52 - to save your document and quit a lot of
185:54 - times people get stuck in vi and have no
185:57 - idea how to get out it can be so
185:59 - frustrating
186:00 - so this will get you out also if you
186:02 - want to quit without saving like you've
186:04 - accidentally made changes and you didn't
186:05 - mean to you press escape again to get
186:08 - into command mode and then you press
186:10 - colon q
186:12 - exclamation point and press enter and
186:14 - that will that will exit without saving
186:17 - and then if you just want to save
186:18 - halfway through a document you can just
186:20 - do colon w enter and it's going to save
186:22 - but you'll stay in then you'll press i
186:24 - to go back into insert mode and continue
186:26 - making edits i'll show you really
186:28 - quickly well i'll show you what nano is
186:30 - and then i'll show you vi just so you
186:32 - can see it in practice like i said
186:34 - almost every distribution is going to
186:36 - have both nano and vi so i'll show you
186:38 - nano first if we do an ls we'll see i
186:39 - have this text file dot
186:41 - so if we just type
186:43 - nanotextfile.txt it's going to open the
186:45 - editor with this and you can just use
186:47 - arrow keys and you can start editing
186:49 - right away this is like you would expect
186:51 - any text editor to work okay so press
186:53 - enter it's going to insert blank lines
186:55 - and then if you want to save you can
186:57 - look right down here we have control x
187:00 - to exit and you can do other things too
187:02 - there's all sorts of commands but i'm
187:03 - going to show you the basics here
187:05 - control x to exit and then it says would
187:08 - you like to save your changes and you
187:10 - can say see the options here y for yes
187:13 - and for no control c for cancel i'm
187:15 - going to say yes and then it says what
187:18 - file name would you like to write well
187:19 - it'll default to the current text file
187:21 - but if you wanted to save it as like
187:23 - copy 2 you could i'm just going to hit
187:24 - enter
187:25 - and boom we're done the text file has
187:27 - been edited it's very simple very easy
187:29 - to use and again i recommend you use it
187:31 - now vi i'm going to look at the same
187:33 - text file with vi so vi
187:35 - text file
187:37 - and here we have we're in what mode are
187:39 - we in we're in command mode now we can
187:41 - still use the arrow keys to get around
187:43 - but we can't edit any text or insert any
187:46 - text if we want to add text we press i
187:49 - and then look down here it says insert
187:51 - so this is a little cheat it tells you
187:52 - that you're in insert mode if we're
187:54 - going to go back into command mode press
187:56 - escape i'm going to go into insert mode
187:57 - press i escape to get out insert mode
188:00 - and once you're in insert mode you can
188:03 - type text and then if you want to save
188:05 - it again you have to press escape
188:07 - and then
188:08 - colon
188:10 - w
188:11 - q
188:12 - enter and then boom we've saved the file
188:14 - we can look and see the text file has
188:17 - been changed all this changes were saved
188:19 - and that's how you use vi it's confusing
188:22 - but that's how it works so again use
188:24 - nano it just makes sense it's easy
188:26 - that's what i recommend you use but if
188:28 - you have to use vi at least now you know
188:30 - the couple shortcuts that are going to
188:31 - get you through so that you can actually
188:33 - use it to edit text now remember i said
188:36 - i use vi all the time and it's true but
188:39 - the funny thing is that it's followed me
188:41 - into things like word processors so
188:42 - sometimes in my microsoft word documents
188:45 - even on the very bottom you'll see colon
188:47 - wq because my head i just automatically
188:50 - do that when i'm done editing text
188:52 - anyway use nano but vi is fun and it's a
188:55 - good skill to have i hope this has been
188:57 - informative for you and i'd like to
188:58 - thank you for viewing viewing text files
189:00 - is an extremely common thing for a
189:03 - system administrator to do on a linux
189:04 - system so we're going to look at a bunch
189:06 - of tools that allow us to examine text
189:09 - files in a way that allows us to view
189:11 - but also to search and i'm just going to
189:13 - go right to the command line so that we
189:14 - can see these things work in real time
189:17 - now i've created in my folder here a
189:19 - file called two cities now this is just
189:22 - the public domain tale of two cities
189:24 - this is the first chapter i'll just type
189:26 - cat so we can look at it
189:28 - two cities see it's just a tale of two
189:29 - cities the first chapter all right so
189:32 - let's clear the screen now the first
189:33 - thing i'm going to show you is the head
189:35 - command and what it does it'll show you
189:37 - the first lines of a text file so the
189:40 - head or the beginning of it so we can
189:42 - just say head two cities and it's going
189:45 - to show us the first 10 lines of the
189:47 - story so the best of times the worst
189:49 - times that's part that we're familiar
189:51 - with now we can change that how many
189:52 - lines it shows us if we were to do
189:54 - head
189:55 - dash n 20 it's going to show us 20 lines
189:59 - the first 20 lines of the file so see
190:02 - it's a little bit longer now and it's
190:04 - shown us all 20 lines now head isn't
190:06 - usually as commonly used as its
190:09 - companion which is tail so let me clear
190:12 - the screen oop and it spell clear right
190:15 - clear the screen now if we were to do
190:17 - tail
190:18 - two cities this shows us you've probably
190:20 - already guessed it the last ten lines
190:23 - and we could do the same thing with the
190:24 - dash n and a number we could decide how
190:26 - many lines of the file we want to see
190:28 - now this is really useful if you're
190:30 - looking at log files and that's almost
190:32 - exclusively where i use the tail command
190:34 - if i'm looking at a log file i just want
190:36 - to see the last things that were written
190:38 - to a log file so i'll do a tail of the
190:41 - log file in question and i'll see what
190:43 - was added to the very end so i don't
190:45 - have to look like 27 megabytes of text
190:47 - for all of the logs just the last little
190:50 - bit of it and so that's a very useful
190:52 - command and again you can use n20 if you
190:54 - want to see 20 or whatever number you
190:56 - want to see 10 is the default now the
190:58 - other ones i want to show you are less
191:00 - and more we'll start with more this is
191:01 - the older command so let me clear the
191:03 - screen if we were to type more
191:05 - two cities this is going to show us the
191:07 - entire file and if we want to scroll
191:10 - through it we press the space bar and
191:12 - it'll go to the next page space bar go
191:14 - to the next page the enter key will go
191:16 - line by line
191:17 - but this is that's it so we're all the
191:19 - way to the end of the into the first
191:20 - chapter but that's how more works you
191:23 - just kind of go through it like that you
191:24 - can also search but it only searches
191:27 - down and it's not one that i use very
191:29 - often anymore because it's been outmoded
191:32 - by the much more powerful
191:34 - although it has a more diminutive name
191:37 - less so actually let me clear the screen
191:39 - so if we were to say less
191:41 - two cities
191:43 - now we have what looks like a similar
191:45 - kind of interface but we can use our
191:47 - arrow keys to scroll up and down
191:50 - page up and page down work so we don't
191:52 - have to worry about like hitting the
191:54 - spacebar to go down a page we can
191:56 - spacebar will go down a page but then we
191:57 - can scroll back up with the up key now
192:00 - the other really nice thing about less
192:02 - and more does this to an extent but less
192:04 - is even more powerful if you type
192:06 - forward slash in a term so let's search
192:09 - for france press enter it's going to
192:11 - take us to the first entry of the word
192:14 - that we searched for it's going to
192:15 - highlight it and it's highlighted all of
192:18 - them so if we were to press forward
192:19 - slash and enter again it's going to
192:20 - repeat the same search and here we are
192:23 - francis found again france is down here
192:25 - again forward slash it'll take us to
192:27 - that one put it right to the top of the
192:28 - screen so we can search through an
192:30 - entire text file as well so it's very
192:33 - very powerful to use the command that
192:35 - seems like it would be less powerful
192:36 - because it's named less but really it's
192:39 - a lot better okay so to get out of here
192:41 - and this actually confused me for a long
192:43 - time if you just press q just the letter
192:45 - q it'll exit the less command and get
192:48 - you out of it so less more head tail
192:50 - they're very commonly used i usually use
192:53 - less and tail more commonly than the
192:55 - other two but that's just because i want
192:57 - to see the end of a log file and i want
192:59 - to be able to go up and down when i'm
193:01 - scrolling through a text file and search
193:03 - really powerfully it's not a really
193:05 - tough nugget because these are pretty
193:07 - straightforward tools they're all useful
193:09 - and you'll probably find yourself using
193:11 - them fairly frequently on the command
193:13 - line
193:14 - sometimes when i'm at the grocery store
193:16 - i wish i could search for where things
193:18 - are like i think pizza sauce should be
193:19 - right next to spaghetti sauce but it
193:21 - almost never is well thankfully when it
193:23 - comes to searching for text in a linux
193:26 - system there is an awesome tool that
193:27 - allows you to do just that narrow down
193:30 - what you're looking for with tool called
193:32 - grep now greb does use regular
193:35 - expressions or regex and if you're
193:37 - interested in the you know very
193:38 - fine-tuned filters you can get with
193:40 - regex i cover that really great in the
193:42 - linux foundations course but today i
193:44 - want to talk about searching for strings
193:46 - of text using grep because it can be a
193:49 - real powerful way to get the information
193:51 - you want really quickly now i said that
193:53 - grep uses regular expressions so if you
193:56 - want to make sure that it's absolutely
193:58 - searching just for strings of text you
194:00 - can use the dash capital f flag and that
194:02 - means just fixed strings
194:05 - usually you don't have to do that
194:06 - because if you just search for a string
194:09 - it's going to generally find it in the
194:11 - file but occasionally your string might
194:14 - be regular expression characters and you
194:16 - can cause yourself some headaches so if
194:18 - you want to be safe use dash capital f i
194:21 - usually don't because it's usually not
194:23 - an issue but i just want you to be aware
194:25 - that if you do grep minus capital f it's
194:27 - going to just search for strings now
194:30 - there's two different ways that we can
194:31 - use grep we can say graph
194:34 - the string
194:36 - from a file and it's going to search the
194:38 - file for the string that we specified
194:41 - and that works really well but there's
194:43 - also another way you can do it you can
194:45 - do this cat file or anything that has a
194:48 - text output like ls or anything that's
194:50 - going to output text and then you can
194:53 - use the pipe symbol and kind of push it
194:56 - through grep and search for a string
194:58 - i'll show you why this is a really
195:00 - powerful way to use grep because it
195:02 - seems a little backwards like why
195:04 - wouldn't we just say you know grep this
195:06 - string from this file i'm on an ubuntu
195:08 - system here and i'm just going to search
195:10 - a log file okay so i'm going to say grep
195:13 - now we can say dash capital f or we can
195:16 - leave that off i'm just searching for
195:17 - strings i just again want you to know
195:19 - that capital f is going to force it to
195:21 - just use strings but i want to grep for
195:24 - dhcp from the var log syslog file press
195:30 - enter and it's going to find all of the
195:32 - lines in that text file that have dhcp
195:34 - in it actually even highlights the dhcp
195:37 - which is really convenient now there's
195:38 - another place we could get some system
195:40 - log information and that is using the
195:42 - dmesg command
195:44 - but here's the problem that's a command
195:47 - that has output but it's not a file we
195:49 - can't grep the d message command so
195:52 - that's where the pipe symbol comes into
195:54 - play and it works really really well we
195:56 - could just say d message and instead of
195:58 - just having it print to the screen we
196:00 - can use the pipe symbol which is usually
196:02 - above the enter key in a us keyboard
196:04 - grep i'm going to use minus f this time
196:07 - we don't have to necessarily
196:09 - dhcp
196:10 - and then it's going to take all of that
196:12 - output from d message and grep for dhcp
196:15 - and sure enough there's two lines that
196:17 - have dhcp now another really useful way
196:20 - that we can use the pipe symbol let's
196:22 - clear the screen
196:23 - because i want to show you that first
196:24 - one that we did right we we actually
196:26 - grew up for dhcp from that file and we
196:29 - got these results let's say we had just
196:31 - pages and pages of results and we wanted
196:33 - just to look for things that mentioned
196:36 - init init what we could do is kind of
196:39 - like chain grips along we could say
196:42 - grep dhcp from var syslog and then pipe
196:46 - those results into
196:48 - grep init and press enter and now we're
196:51 - just going to get the lines that were in
196:54 - this result that also contain the word
196:57 - init and so here now we've filtered all
196:59 - the way down to these two lines of text
197:02 - from the log files so even if you're not
197:04 - getting super fancy with regular
197:06 - expressions you can do some really
197:08 - powerful searching of strings using the
197:10 - grep tool for things like log files or
197:13 - any kind of text that you want to search
197:14 - for and remember you can chain those
197:16 - grep commands together so that you get a
197:19 - really fine filter looking for exactly
197:21 - what you're looking for
197:23 - every application in the linux system
197:26 - has three sort of like pipes it has
197:29 - standard input standard output and
197:31 - standard error and basically it's just a
197:33 - way to get information in and out it's
197:35 - an io type situation for every
197:38 - individual app now i have just an
197:40 - application here
197:41 - drawn out and i want to show you the
197:43 - difference between the three so standard
197:45 - input is pretty easy to understand right
197:47 - this is like if you're putting something
197:49 - into a program we use the pipe symbol if
197:51 - we're going to pipe something into it or
197:53 - we can use less than if we want to just
197:54 - assign a file to the standard input now
197:57 - a lot of programs don't accept things on
198:00 - standard input but some of them do so if
198:02 - you've ever seen me pipe a command into
198:04 - another command what i'm doing is piping
198:06 - the results of one command into another
198:09 - command so it can work on it i'll show
198:11 - you how that works on the command line
198:12 - but then there's two other pipes and one
198:15 - of them is the standard output this is
198:16 - what happens if you type ls and it shows
198:18 - you know the contents on the screen
198:20 - that's the output that it shows you is
198:22 - the standard output now there's also
198:24 - standard error if an error occurs it
198:27 - also prints the things out on the screen
198:29 - but they're different pipes now we don't
198:31 - realize the difference because they both
198:33 - end up on the command line that's like
198:35 - the default place for standard output
198:37 - and standard error to go but you can
198:40 - treat them differently so if you want to
198:42 - redirect the output of a file of an
198:44 - application into a file use the greater
198:46 - than symbol if you want to redirect the
198:49 - standard error or like you know an error
198:51 - message you have to use two greater than
198:53 - because it's a different pipe and you
198:55 - have to redirect it separately so let me
198:57 - show you what i mean first of all let's
198:58 - talk about standard input now i have in
199:00 - here a file called file.txt i'll show
199:03 - you what's inside of it okay so this is
199:05 - what we have okay just a text file with
199:07 - some text in it now if we wanted to use
199:10 - grep to search for text we could just
199:12 - say
199:13 - grep text from
199:15 - file.text and it would show us the text
199:17 - that's in there but we could also
199:19 - redirect to the standard input rather
199:22 - than telling grep what to use so we
199:23 - could say
199:25 - cat
199:26 - file.txt
199:27 - and then pipe the results into standard
199:31 - input of grep and then have grep look
199:34 - for text we should get the exact same
199:36 - results now what we've done though
199:37 - rather than telling grep you know what
199:39 - file to choose from we just piped the
199:42 - results of cat into standard input and
199:44 - then grep use that as its input for
199:47 - grepping for the word text now that is
199:49 - using the pipe symbol we can also say
199:51 - grep for
199:53 - text and i want you to use file.txt as
199:57 - your standard input
199:59 - now this looks very similar to this up
200:01 - here but it's drastically different
200:03 - because what we've done is we've used
200:05 - redirection so this is redirecting
200:08 - standard input this actually functions
200:10 - exactly the same as this one because
200:13 - here we're using the pipe symbol to
200:15 - redirect standard input here we're using
200:17 - the less than symbol to redirect
200:18 - standard input so that's how you can do
200:20 - standard input it's not something you do
200:22 - as often apart from with this scenario i
200:25 - do this a lot you know piping one thing
200:27 - into another so that you can get the
200:29 - results from there now the other thing
200:31 - is standard output and standard error so
200:33 - i have a really quick way to show you so
200:35 - we say ls and we get these are the
200:37 - contents of ls we could redirect that by
200:40 - using greater than into a file called
200:43 - results.txt and we should get no output
200:46 - because rather than redirecting the
200:48 - output to our terminal window here it's
200:50 - actually redirected the standard output
200:52 - into results.txt so if we look there's a
200:54 - file now called results.txt and if we
200:57 - look at results.txt it has the contents
201:00 - of that ls command right it just dumped
201:02 - the contents into there here's a problem
201:04 - though what if we did this let me clear
201:06 - this screen what if we did ls lsf
201:10 - and we tried to redirect the standard
201:12 - output into
201:14 - results.txt
201:16 - why did we get the error message here
201:18 - and let's look at results well there's
201:20 - nothing in results now because there was
201:22 - no standard output this is an error
201:23 - there is no file called ff for us to use
201:26 - ls on if we wanted to redirect an error
201:29 - we would have to do
201:30 - lsf
201:32 - to greater than
201:34 - error.txt if we do that ah nothing
201:36 - appeared however if we look at in the
201:38 - file here now we have a file called
201:40 - error.txt
201:41 - and if we look in that sure enough that
201:43 - was the error message we redirected it
201:45 - using a standard error redirector using
201:48 - standard input standard output and
201:50 - standard error redirection is something
201:52 - you're going to find yourself doing a
201:53 - lot because you want to see the results
201:56 - of things when you're not there to see
201:57 - it happen on the command line that's
201:59 - basically what log files are right
202:01 - they've taken errors and redirected them
202:03 - into a log file for you
202:06 - once you understand how input and output
202:08 - works with an application on the command
202:10 - line there are some really cool tricks
202:12 - and tips that we can learn to make life
202:14 - a little bit easier now there's a
202:15 - handful of things we want to look at but
202:17 - i've drawn a diagram so we can actually
202:19 - get a real good taste for what each
202:21 - thing is now devnl you may have heard of
202:24 - people call it the black hole or the bit
202:26 - bucket and basically devnull is a
202:29 - location on your file system that you
202:31 - can copy anything to and it will
202:34 - disappear forever now that seems like a
202:36 - weird concept i know but if you have
202:39 - like
202:40 - extraneous logs that you don't really
202:42 - want to ever see you just want to like
202:44 - throw them immediately in the trash dev
202:46 - null is where you want it to go for
202:48 - example you would not want to copy
202:50 - important information and redirect it to
202:52 - dev null because it will just disappear
202:54 - forever so devnet is just a place that
202:57 - everything disappears when you copy it
202:59 - there now t is an interesting command it
203:01 - doesn't seem like it does very much but
203:03 - it accomplishes a task that's remarkably
203:06 - difficult to do without using the tool
203:08 - itself so here's how it works we take
203:10 - some sort of text like output from a
203:13 - file or something like that and we put
203:15 - it into teas standard input and then all
203:18 - it does is dump that same information
203:20 - out of its standard output but it also
203:24 - writes it to a file so it does like a t
203:27 - in the road or a fork in the road it
203:29 - lets you see what it is right on the
203:30 - standard output right in your command
203:32 - window but then it also copies it to a
203:34 - file so that's what t does and it's
203:37 - really nice if you want to see what's
203:38 - happening but you also want to have a
203:39 - record of it and keep it into a file
203:41 - and then arguably the most complicated
203:44 - one but also the niftiest one maybe is
203:47 - called x-args now how x-args work is
203:50 - let's say you have a different program
203:51 - like ls or something and you do the
203:54 - command and so you see stuff come out in
203:56 - standard output and then we're going to
203:58 - pipe it in or redirect it into x args
204:01 - standard input then what x args does is
204:04 - it takes it and says okay what program
204:07 - do you want me to use this information
204:09 - that you just piped into me on and you
204:11 - tell it like application number two and
204:13 - then it executes application two and it
204:16 - uses that information as the arguments
204:18 - for the second command now the reason
204:20 - this is really powerful is not all
204:22 - applications can accept things from
204:25 - another program on their standard input
204:27 - so x args basically takes and forces a
204:30 - program to accept something from
204:32 - standard input by accepting that
204:34 - standard input itself and then putting
204:36 - it as an argument onto the application
204:38 - now let's look at all of these really
204:40 - quick because the cool part is you know
204:42 - when you actually do it now first of all
204:43 - devnl so we're going to say
204:46 - echo
204:47 - hello and it'll put it to the screen if
204:49 - we do echo
204:50 - hello and then we redirect it to
204:53 - dev no
204:54 - boom it's completely gone right that's
204:56 - how devnet works it's just a place that
204:58 - never fills up it's kind of like a
205:00 - teenage girl at a pizza party sleepover
205:02 - right it just never gets full you can
205:03 - put as much as you want in there it's
205:05 - just gonna disappear now we've
205:06 - redirected standard output we could also
205:09 - redirect standard error
205:11 - and then we should see hello because
205:13 - there was no error there right if we did
205:15 - something like this let's say
205:18 - ls
205:19 - documents
205:20 - and ff we should get both standard
205:23 - output and standard error sure enough
205:25 - here's our standard error there is no ff
205:27 - but here is the contents of documents so
205:29 - we got both now if you wanted to do
205:31 - something cool and redirect both
205:33 - standard output and standard error into
205:36 - one place you can do this you can say ls
205:39 - documents ff just like we did and i'm
205:41 - going to redirect standard output into
205:44 - dev null and here's the magic part and
205:47 - then i'm going to redirect standard
205:49 - error into
205:51 - and
205:52 - one oh my goodness what is this well the
205:54 - ampersand one is a way that we can tell
205:56 - it that what we want is standard error
205:59 - to get redirected into standard output
206:03 - so the one is standard output so what
206:04 - this does is all of our standard output
206:06 - is getting redirected to dev null so all
206:09 - of our standard error is going to go
206:11 - into standard output which is of course
206:13 - going to dev null so this should give us
206:15 - absolutely no results and sure enough
206:18 - both standard output and standard error
206:19 - have gone into devnet all right so
206:21 - that's just a really cool thing that you
206:23 - can do with redirection and then devnet
206:25 - is just a place that never fills up all
206:27 - right let's clear the screen i want to
206:28 - show you so here i have a couple files
206:31 - or one file let's look and see what's in
206:33 - there
206:34 - all right just a bunch of different
206:36 - words in the text file so what we can do
206:38 - is say
206:39 - cat file.txt i'm going to pipe my
206:42 - standard output into t's standard input
206:46 - and then i'm gonna call it copy.txt and
206:49 - now we should see the contents of
206:50 - file.txt sure enough it printed to the
206:52 - screen but then the t command also
206:55 - created that copy.txt that also contains
206:58 - this so if we look sure enough there's a
207:00 - copy of our stuff and then last i'm
207:02 - going to show you x args and it's hard
207:05 - to come up with a real good example but
207:06 - i think i have one all right what we
207:08 - want to do is i want to create a folder
207:11 - named everything in this file so i want
207:13 - to have a folder named red named yellow
207:15 - named blue and name tuna fish well turns
207:16 - out to be kind of difficult to do that
207:18 - but we can do it really simply if we say
207:21 - catfile.txt
207:23 - pipe that into x-args
207:26 - and then x args is going to mkdir and
207:30 - then it will put the standard output of
207:32 - this command and kind of like plunk it
207:34 - right there so if we press enter
207:37 - and we do ls look at that we have a
207:39 - folder with each one of those names
207:41 - which is really convenient right it was
207:43 - able to do like what would have taken us
207:45 - quite a bit of typing to do it just did
207:47 - it by piping it and then it kind of
207:48 - pastes the results right at the end of
207:50 - whatever command you tell it now we
207:52 - could also do something cool if i want
207:53 - to clean up my mess instead of mkdir i'm
207:56 - going to say rm dir
207:58 - and then they're gone
207:59 - standard input standard output standard
208:01 - error they're really cool things and
208:03 - there are some additional tips and
208:04 - tricks that make using them even more
208:06 - usable and more beneficial on the
208:09 - command line
208:10 - dealing with text on the command line is
208:12 - something that's kind of fun to do to be
208:14 - quite honest and there are some tools
208:16 - that are pretty nifty to play with so
208:18 - let's look at a couple of them right now
208:20 - we'll just go right to the command line
208:21 - now i've already set us up with a few
208:23 - files i have file one and file two so
208:25 - let's look at them just so we know
208:26 - what's in them that's what's in file one
208:29 - and that's what's in file two just a
208:31 - list of words so i wanna show you a few
208:33 - things now you'll notice that these are
208:35 - not in alphabetical order okay so we
208:38 - could use the sort command so i could
208:40 - say sort file1 dot txt and it's going to
208:43 - return the contents but notice now
208:45 - they're in alphabetical order chicken
208:47 - fish monkey turtle so what we could do
208:49 - is if we wanted to save a file call it
208:51 - sorted then we could redirect the output
208:53 - to
208:54 - sorted.txt
208:56 - and then if we look at sorted.txt now
208:58 - it's going to be a file with them in
209:00 - alphabetical order so sort does just
209:02 - that and if you look at the commands for
209:04 - sort like to the man page for sort you
209:06 - can see that it does some other things
209:07 - you know you can actually sort with
209:09 - options like you know do i ignore case
209:11 - what about numbers what about you know
209:13 - what if it's a bunch of dates so sort's
209:15 - very powerful but that's basically what
209:16 - it does it takes a text file and then it
209:18 - outputs that text file sorted however
209:20 - you tell it to do so let's clear this
209:22 - screen all right the next one i want to
209:23 - show you is word count it's pretty
209:25 - simple it's just wc and it stands for
209:26 - word count so we could do word count of
209:29 - file1.txt and it'll give us three fields
209:32 - it says 4 4 and 27 in our case what this
209:35 - means is it means there are four words
209:37 - there are four lines and there are 27
209:40 - characters now if we just want to know
209:42 - one of those things we could just say wc
209:44 - minus m for character count
209:47 - and it's just going to show us that
209:49 - there are 27 characters in file1.txt now
209:52 - the last two i want to show you are
209:53 - really the most interesting so there's
209:55 - cut and paste which i know sounds like a
209:57 - gui thing but let's actually look at our
209:59 - file again just so we know exactly what
210:00 - we're dealing with so file1.txt
210:03 - this is what we have these lines if we
210:05 - were to use the cut command we could say
210:06 - cut i'm going to do cut by characters
210:09 - and i want it to cut out character oh
210:11 - let's just say 1 from
210:14 - dot file1.txt
210:16 - if we do that we should see just the
210:18 - first oh i did file two my goodness i'm
210:21 - like those aren't the first letters at
210:22 - all
210:23 - so let's look at file one that dxd that
210:26 - makes more sense so the c in chicken the
210:28 - effing fish teen turtle m in monkey okay
210:30 - so we have those uh we could do more
210:33 - than just one character and we could do
210:34 - more than just the first character let's
210:36 - say we wanted to do cut minus c
210:39 - the third fourth and fifth character in
210:42 - the file file one dot txt so now we
210:45 - should see
210:47 - [Music]
210:48 - and what it did is it took the third
210:50 - fourth and fifth character
210:52 - but you see fish only has four
210:54 - characters so there is no fifth
210:55 - character so it just did sh for the fish
210:57 - line all right but see that's that's
210:59 - what cut does it'll actually take it
211:00 - right out of the middle of the file
211:02 - which is surprisingly difficult to do if
211:04 - you don't actually use the cut command
211:06 - and paste does kind of the exact
211:08 - opposite so let me clear the screen
211:10 - because it's kind of full and i want to
211:11 - show again file one and file two now
211:15 - let's say we wanted to put this file
211:18 - file two
211:19 - after file one right we wanted to say
211:22 - chicken lips fish whiskers turtle
211:24 - feathers and monkey flippers well that's
211:27 - kind of difficult to do if we cat them
211:29 - together it's just going to put one at
211:30 - the end of the other so that's where
211:32 - paste comes into play we can say paste
211:34 - file1.txt
211:36 - file2.txt and it's going to output
211:38 - sure enough i put a tab between them and
211:40 - then we have chicken lips fish whiskers
211:42 - if we wanted to do this and redirect it
211:44 - into a file
211:46 - and then we look at join.txt look at
211:48 - that our file now has those two pasted
211:50 - together now i know that most of what we
211:52 - did using these commands was really just
211:54 - playing around but really playing around
211:56 - is one of the best ways to learn to use
211:58 - a tool and you're going to find that
212:00 - every once in a while one of these tools
212:02 - like cut or paste especially are going
212:04 - to be extremely useful because it's kind
212:06 - of hard to put things next to each other
212:08 - in a text file or cut out the middle
212:10 - bits of a text file without using simple
212:13 - tools like this
212:15 - awk and said are text manipulation tools
212:18 - that for some reason most people are
212:21 - afraid of and i honestly don't know why
212:24 - yes they can be very complicated you can
212:25 - do a lot of powerful things but you
212:27 - don't have to you can do some very
212:29 - simple yet still powerful things with
212:31 - awk and said now what do they stand for
212:34 - said just stands for stream editor and
212:37 - awk i actually had to google this
212:39 - because i had no idea i mean i've been
212:40 - using awk for decades but i didn't
212:42 - really know what it stood for it turns
212:44 - out it's the initials of the people who
212:46 - first wrote it and i'm not going to try
212:48 - to pronounce them all but that's what
212:50 - the a the w and the k mean basically awk
212:54 - is a data extraction tool it allows you
212:57 - to pull out certain bits of data from
212:59 - text and set of course is just a stream
213:01 - editor which allows you to edit things
213:03 - without interacting with it directly so
213:05 - let's actually go to the command line so
213:06 - we can see it work now i've already
213:08 - prepared a couple files so if we do ls
213:10 - we're gonna see we have file one file
213:11 - two and joined so let's just look at
213:13 - them this is file one this is file two
213:17 - and this is basically the two of them
213:18 - joined together i actually use the paste
213:20 - command to do that so i have these three
213:22 - files and i'm going to use said and awk
213:25 - to do things with these files okay so
213:27 - first of all said is a stream editor
213:30 - which means you can put files in and
213:32 - you'll it'll output the edited version
213:34 - and how it works i'm just going to cat
213:36 - one of these files so cat file1.txt
213:40 - and i'm going to pipe that into
213:42 - said for stream editor and here's where
213:44 - i'm going to set up the rules i'm going
213:45 - to substitute so i'm going to say s and
213:48 - then forward slash what i want to search
213:50 - for is the word monkey and a forward
213:53 - slash what i want to replace it with i'm
213:55 - going to say dolphin and then a forward
213:58 - slash ng for global that just means that
214:00 - if it occurs more than one time i want
214:02 - every occurrence of monkey to be
214:04 - substituted with dolphin and then i'm
214:06 - just going to press enter
214:08 - and what we get is chicken fish turtle
214:10 - dolphin because it took
214:12 - this initial file and it substituted
214:15 - monkey for dolphin and really that's
214:17 - what said does it's a stream editor it
214:20 - allows you to edit things as it flies
214:22 - through there so you can make changes to
214:24 - text as it's being manipulated so you
214:27 - can put this inside of a script and do
214:29 - things without interacting on a like a a
214:32 - gui like you'd want to open it up with
214:34 - vi and edit it out and change monkey to
214:36 - dolphin or anything like that so that's
214:38 - what stream editor or said does now i'm
214:40 - going to clear the screen
214:42 - and we're just going to look at joint
214:44 - i'm going to say cat join just so we can
214:46 - see it now awk takes a text file and it
214:49 - will allow you to pull out bits and do
214:52 - things with them so i'm just going to
214:53 - type this out and then we'll see what
214:54 - i'm talking about so i'm going to say
214:56 - awk
214:57 - and i'm going to put single quotes open
214:59 - curly braces print
215:01 - dollar sign 1 close curly braces close
215:04 - single things and i'm going to use
215:06 - joined.txt as the file so what this is
215:09 - saying now this is maybe why people are
215:11 - scared there's a bit of an odd syntax
215:13 - here but we say awk and then this is
215:15 - what we want awk to do with the file i
215:18 - want it to print out the first field now
215:22 - it will auto detect that these fields
215:24 - are separated by a tab they could just
215:26 - be spaces and it'll auto detect it but
215:28 - basically this is on line one this is
215:30 - field one field two line two it's field
215:32 - one field two so this should print out
215:34 - the first field of every line so let's
215:37 - press enter and sure enough chicken fish
215:39 - turtlemonkey it printed them all out now
215:42 - we can do more than just one thing at a
215:44 - time so let's go back over here what if
215:46 - we wanted to do dollar sign two
215:49 - dollar sign one now we should get a
215:51 - printout of whiskers fish and and
215:54 - flippers monkey and let's see what what
215:57 - turns out here now it is gonna be a
215:58 - little hard to read and i'll show you
215:59 - why see it did do that right here we had
216:02 - chicken lips and it gave us lips chicken
216:04 - whisker fish feathers turtle flippers
216:06 - monkey now the problem is it took those
216:08 - fields and just mushed them right
216:09 - together so we could add another thing
216:11 - in there we could kind of build this out
216:13 - longer and we could say i also want
216:16 - a space in there so hopefully that makes
216:18 - sense it's going to print field 2 and
216:20 - then it's going to print this space and
216:21 - then it's going to print field 1. so
216:23 - let's see if that's what we get
216:25 - sure enough lips chicken whisker fish
216:27 - feather turtle flippers monkey and it
216:28 - doesn't have to be used just one time
216:31 - right we could do this we could say i
216:32 - want dollar sign two dollar sign two
216:35 - which means field two field two and now
216:37 - we should get
216:38 - a duplicate of each one lip slips
216:40 - whiskers whiskers so awk just takes bits
216:43 - of data and allows you to manipulate
216:45 - them and do what you want with them
216:47 - honestly the only thing i could think is
216:49 - that the syntax for all can said
216:51 - intimidate people but once you get used
216:53 - to doing it and especially with stream
216:55 - editor the syntax is very similar to the
216:58 - vi editor when it comes to replacing and
217:00 - substituting things in a text file so
217:02 - hopefully you get used to them and
217:04 - you're not afraid of them because
217:05 - they're super powerful and awesome tools
217:07 - to use especially in scripts because
217:09 - there's no interaction required you can
217:12 - put them right inside of a script and
217:13 - they work without you entering more data
217:16 - hard links and soft links or symbolic
217:19 - links as a lot of people call them are
217:21 - very similar in what you get on the file
217:23 - system as far as usability goes but they
217:25 - work drastically differently so let me
217:28 - explain the difference between them so
217:29 - when we have a hard drive we basically
217:31 - have every file that takes up a certain
217:34 - number of sectors on the hard drive
217:36 - itself so this one let's say takes up
217:37 - three blocks this one takes up
217:39 - four blocks this one takes up seven
217:42 - blocks and these are the actual
217:45 - files on the hard drive but the file
217:47 - system actually only knows where those
217:49 - files live because of the file
217:52 - allocation table so this is kind of like
217:54 - a table of contents right it says okay
217:56 - file one is actually right here and it
218:01 - extends three blocks uh this one i'll
218:03 - say okay file two
218:05 - this actually lives right here on the
218:07 - hard drive and it extends four blocks
218:10 - and then the same thing here file three
218:12 - and you know it extends all the blocks
218:15 - here and so on and so forth for all of
218:17 - the other files on the system now there
218:19 - is a difference though let's say this is
218:21 - a symbolic link okay a symbolic link
218:24 - doesn't point to the hard drive at all
218:26 - it actually just points to a file in the
218:30 - file allocation table so this is a
218:32 - standard
218:33 - you know table of contents link right
218:35 - this is pointing to this spot and
218:38 - these blocks on the hard drive but the
218:41 - symbolic link just points to
218:43 - filename.txt
218:45 - on this system itself now there's the
218:48 - other kind of link and that's a hard
218:49 - link so you probably notice there's
218:51 - another purple file here so let's say
218:53 - this is file two and it's pointing to
218:55 - you know these four blocks
218:58 - this could be like file 12 and it points
219:02 - to the exact same
219:05 - spots on the hard drive so it points to
219:07 - the exact same file location and the
219:09 - same number of blocks it's basically the
219:12 - exact same file but it has two different
219:15 - reference points in the file allocation
219:17 - table that can be really confusing but
219:20 - what's cool about it is let's say you
219:22 - accidentally delete this file well
219:24 - that's okay it's still on the hard drive
219:26 - and you can still reference it from this
219:28 - file here so let me show you what that
219:29 - looks like in practice in our system
219:31 - here we have let's do an ls minus l we
219:34 - have my file.doc now if we wanted to do
219:37 - a symbolic link we would do
219:38 - ln minus s for soft or symbolic the
219:42 - source is my file and the destination is
219:45 - going to be my
219:46 - linked file.doc
219:49 - do ls minus l and we're gonna see it
219:51 - actually shows us exactly what's
219:52 - happening my linked file dot doc is just
219:55 - pointing to the name
219:57 - myfile.doc in fact it's just pointing to
219:59 - this name itself so if we were to say
220:02 - move my file dot doc to my
220:05 - new file dot doc and then we do an ls
220:08 - minus l this link is broken because it
220:10 - still points to the name my file dot doc
220:13 - and that doesn't exist anymore so this
220:15 - is now a broken link on our system so
220:18 - symbolic links are kind of dumb they
220:20 - don't take up much space but they're
220:22 - kind of dumb in that they don't follow a
220:23 - file if you move it or rename it all
220:26 - right so that is a soft link now a hard
220:28 - link works differently a hard link if we
220:30 - were just to say ln without any flags
220:33 - my new file dot dock to
220:36 - my file dot doc and then we do ls minus
220:39 - l well one we've fixed the symbolic link
220:42 - right because now this file points to a
220:44 - file that exists now so all of a sudden
220:46 - now it's pointing to this file
220:48 - myfile.doc and you'll notice it's the
220:51 - same size as the other one and if we
220:53 - were to move the original so we're going
220:56 - to say
220:57 - move my
220:59 - new file to
221:00 - my cool file dot doc
221:04 - it doesn't break the hard link that we
221:07 - made both of them are still there
221:08 - they're still fine they're their own
221:10 - independent file name in the file
221:12 - allocation table they just happen to
221:13 - point to the same spot in the hard drive
221:15 - and we can see that if we do ls minus l
221:17 - i for inodes it's going to show us the
221:20 - spot on the hard drive that it's
221:22 - actually pointing to and sure enough
221:23 - these have a matching
221:25 - inode whereas this symbolic link has a
221:27 - completely different inode because it's
221:28 - you know just a file that only points to
221:30 - a file name but these two have the exact
221:33 - same spot on the physical hard drive now
221:35 - another cool thing this number here
221:37 - which you've probably never even thought
221:38 - about before but this says how many
221:41 - linked files
221:42 - are on this inode now this says there
221:44 - are three now of course we see two right
221:46 - here but that means somewhere on my file
221:48 - system there's another hard link to this
221:52 - inode now i did actually make it before
221:54 - we started so we could use the find
221:56 - command to find that i'm going to say
221:57 - find
221:58 - i'm going to look in my home directory
222:01 - in the same file flag and i want to find
222:04 - the same file as
222:05 - my file dot doc or i could say my cool
222:07 - file dot doc because these are the same
222:10 - files so it doesn't matter which one i
222:11 - have find look for a match for and press
222:14 - enter and it's going to find all three
222:16 - of them sure enough i have a hidden file
222:18 - right here that i that i did earlier
222:20 - before the nugget started and this is
222:21 - just one more hard linked file to this
222:24 - same
222:25 - inode we could look really quick ls
222:26 - minus li
222:28 - l i a so we can see the hidden files and
222:31 - sure enough hidden file there's that
222:32 - same inode reference that the other ones
222:34 - are referencing now honestly soft links
222:36 - are generally used more because they're
222:38 - easy to see you can do an ls and see
222:40 - where they're pointing to so they're a
222:41 - lot more convenient but hard links do
222:44 - have their place because each file acts
222:47 - as an independent file you can delete
222:48 - one and it doesn't ruin the reference
222:50 - that the other one has so hard links
222:52 - point to inodes soft links just point to
222:54 - file name references of other files on
222:56 - the existing file system
222:59 - when you're trying to figure out the
223:00 - location of files on your system there's
223:02 - basically two ways you can do it there's
223:04 - the find command and the locate command
223:06 - and both do pretty much the same thing
223:09 - but find is quite a bit more powerful
223:11 - yet has some limitations over locate i'm
223:14 - going to just show you how they work
223:15 - because trying to explain the pros and
223:17 - cons just seems a little bit silly when
223:19 - we can just actually see how it works in
223:21 - action now if we look in our documents
223:23 - folder i have a few files here i have
223:25 - new paper and it looks like it has camel
223:27 - caps here capital n capital p old file
223:30 - and research paper dot doc so let's
223:32 - actually use the locate command first
223:34 - because it's simple so we say locate and
223:37 - then what we want to look for and it can
223:38 - just be a substring so if we say old
223:40 - file and press enter it's going to give
223:42 - us the full path of old file.txt notice
223:45 - i didn't have to search for the entire
223:47 - file name i just searched for old
223:48 - file.txt
223:50 - or old file and it found old file.txt
223:52 - now we can do the same for let's see
223:54 - locate research underscore and it should
223:57 - find research paper and sure enough
223:59 - research paper now there was one more
224:01 - file in there if we type locate
224:03 - new
224:04 - paper no it doesn't find it oh did i
224:07 - spell it wrong well let's look over here
224:09 - new paper no i did not spell it wrong
224:11 - and that's where the limitation of
224:13 - locate is locate uses a database that is
224:17 - cached on your system which means it's
224:19 - super duper fast for searching for the
224:22 - names of files however the cache is only
224:25 - created once a day now we can force an
224:28 - update we could say sudo
224:30 - update db press enter and it's going to
224:33 - update the database of all the file
224:35 - names on the system and now if we just
224:37 - do up arrow and locate new paper now
224:40 - it's going to find it because we updated
224:42 - the cache of all the files on the system
224:45 - so it's very very fast but it has that
224:47 - limitation that it uses cached data now
224:50 - the find command is more powerful but it
224:53 - has the limitation that because it
224:55 - searches in real time it's a lot slower
224:57 - so how does it work pretty much the same
224:59 - way we're going to say find
225:01 - and you tell it where you want it to
225:02 - search so we can say search the root
225:05 - directory
225:06 - and now rather than just a file name
225:08 - find does a lot more things so we're
225:09 - going to say i want you to search for a
225:11 - file
225:12 - named
225:13 - let's say star
225:15 - new paper star and this should find all
225:18 - of the files that have new paper in them
225:21 - okay so i'm going to press enter
225:24 - and oh my goodness what is all this
225:25 - permission denied well find actually
225:27 - goes through the entire file system
225:30 - because i said search in the root
225:31 - directory and i actually don't have
225:33 - permission to look at all of these
225:35 - things so it's going to search through
225:37 - every single folder on the whole system
225:40 - and let's see did it actually find the
225:42 - file it should have but we have to look
225:46 - through all the error messages and if we
225:48 - scroll up sure enough it did find it all
225:49 - right it did find it just like the
225:50 - locate command but there were a lot of
225:52 - permission denied errors now we could do
225:54 - something like redirect the error right
225:56 - we could say two greater than dev null
225:58 - which will just pipe the errors into our
226:00 - dev null bit bucket and sure enough
226:02 - there it found it was pretty quick but
226:04 - it wasn't as quick as using locate now
226:06 - there are some other really cool things
226:08 - that find can do we can say find in our
226:11 - current home directory and what that'll
226:13 - do is it will allow us to search in just
226:15 - this home directory so it doesn't search
226:17 - the entire file system so that can be
226:19 - pretty convenient so if we say find dot
226:21 - and we're gonna look for the name new
226:24 - p
226:24 - oh i didn't do the stars new p
226:28 - it should find it for us sure enough it
226:29 - did find documents new paper and then it
226:31 - does this other thing we can actually
226:33 - say dash delete
226:36 - and it will delete it and how can we see
226:38 - if it's deleted
226:39 - if we look in the documents folder whoa
226:41 - it deleted that file so find does more
226:43 - than just locate files however it has
226:46 - some finicky things like this it's going
226:48 - to be using regular expressions to
226:50 - search for the files and while it's more
226:52 - powerful it's slower and it can be
226:54 - annoying when we do things like get
226:56 - errors from permission denied things
226:58 - like that so while conceptually find and
227:01 - locate do the same thing they do them in
227:03 - different ways the important thing to
227:04 - remember about locate is that it's
227:06 - always going to use old data unless you
227:08 - run that update db command now find is
227:11 - much more powerful but it works in real
227:13 - time so it's slower and there that means
227:15 - that there are pros and cons to using
227:17 - both tools
227:19 - while it's certainly possible to set up
227:21 - network shares for copying files from
227:23 - one server to another generally if
227:25 - you're going to copy files over the
227:26 - network from linux server to linux
227:28 - server you're going to use either ssh or
227:31 - really scp which stands for secure copy
227:33 - but it uses the ssh protocol in order to
227:36 - do that copying or rsync which actually
227:39 - will sync a whole bunch of files across
227:41 - the network so we're going to look at
227:43 - doing both but it's important to realize
227:45 - that ssh is the same program in the same
227:48 - protocol that we use to connect from one
227:49 - computer to another to reach its
227:51 - terminal so let me show you what i mean
227:53 - now i have two computers set up in our
227:55 - lab i have this ubuntu computer
227:57 - and i have this centos computer they're
227:59 - both on the same network so i'm going to
228:02 - ssh from one to another i'm going to say
228:04 - ssh to centos it's going to ask me for
228:08 - bob's password on centos
228:10 - and then all of a sudden now i'm logged
228:11 - in to that remote computer sent to us in
228:14 - fact if we go into the desktop folder
228:17 - and we do an ls we're gonna see over on
228:19 - sent to us we have things called like
228:20 - cool picture cool pic 2 and these things
228:23 - are on the remote desktop all right i'm
228:25 - going to exit and that's going to bring
228:26 - me back to ubuntu now if we look on the
228:28 - desktop folder we're going to see
228:30 - there's nothing in there because on our
228:31 - local ubuntu computer we don't have
228:33 - those things let's say we wanted to copy
228:36 - something over well let's go into our
228:38 - desktop folder
228:39 - again there's nothing here nothing up
228:40 - our sleeve we could use scp which is
228:44 - secure copy and this uses ssh right so
228:46 - we would say scp from
228:49 - centos now we could also specify a
228:51 - different user now it's the same user
228:53 - for us but i'm still going to specify
228:54 - i'm going to say bob at
228:56 - centos
228:57 - colon then the remote path which is
229:00 - going to be home
229:01 - bob
229:02 - desktop and let's pick one of these
229:04 - files i'm going to say cool picture cool
229:08 - picture.jpg and i want it to copy it to
229:10 - dot which means our current directory
229:12 - i'm gonna press enter it's gonna say
229:14 - okay what is bob's password bob and now
229:17 - if we do an ls we're gonna see look we
229:18 - have cool picture that was copied over
229:20 - the network using scp which uses the ssh
229:23 - protocol and it was copied over and now
229:25 - we have a copy of it here locally we can
229:28 - do the same thing we could say scp a
229:30 - local thing and rather than the
229:31 - destination be our local computer we
229:33 - could do it backwards right we could say
229:35 - scp
229:36 - coolpicture.jpg to bob at centos
229:40 - home bob i'm going to copy it just to
229:42 - his home folder and so now it's sent one
229:44 - over to bob's home folder now we could
229:47 - copy everything all at once if we wanted
229:49 - by using the rsync command now rsync is
229:52 - pretty cool in that it will even recurse
229:54 - directories if we wanted to so we could
229:56 - actually do this we could say rsync i'm
229:59 - going to say minus a so it does all the
230:01 - things including recursively going into
230:04 - directories i'm going to say v so it
230:06 - does it verbosely so we can see what
230:07 - it's doing so rsync dash av and the
230:10 - remote thing is set up just like with
230:12 - scp so bob at
230:15 - centos or we don't have to say bob add
230:17 - if it's the same username we could just
230:18 - say
230:19 - centos colon and then the path so i want
230:23 - home
230:24 - bob
230:25 - desktop i want that entire folder copied
230:28 - to here so what we should end up with is
230:31 - a new folder inside our ubuntu desktop
230:34 - folder called desktop because it's going
230:36 - to copy this folder to our current thing
230:38 - and it's going to have recursively
230:40 - everything in the remote desktop folder
230:42 - let's see if that works press enter it's
230:44 - going to say what is bob's password bob
230:46 - and so now it says receiving all of
230:48 - these files and look sure enough there's
230:50 - a folder called desktop if we were to
230:52 - look inside there now i look all those
230:54 - files that were on that remote computer
230:56 - are now on our local computer as well we
230:58 - used rsync and it will transverse all of
231:01 - the directories recursively and it will
231:03 - copy it over for us now this might seem
231:05 - like a throwaway nugget something that
231:07 - is just nice to know but you're not
231:08 - going to use i'll be honest i use scp
231:10 - and rsync almost every single day
231:13 - copying files back and forth using scp
231:16 - is so easy and so fast you don't have to
231:18 - set up servers it's just a way to get
231:20 - one file to another server without
231:23 - having to worry about installing
231:24 - anything because it uses ssh which is
231:27 - already installed on all of your servers
231:29 - so whether you just want to copy a file
231:31 - or two with scp or you want to do
231:33 - recursive directories with rsync it's
231:35 - really easy to copy files over the
231:37 - network in linux
231:39 - pretty much every distribution out there
231:41 - uses system d to manage the services
231:44 - like the various programs that are
231:46 - installed like web servers and stuff on
231:48 - their system and system ctl is the
231:50 - command line tool that we use to
231:52 - manipulate and manage those services now
231:54 - there's a couple concepts we need to
231:56 - understand we need to know enable and
231:57 - disable versus start and stop enable and
232:01 - disable is basically talking about when
232:03 - the computer boots up will it
232:05 - automatically start the service and so
232:07 - you can have something that you can
232:09 - start and stop but that doesn't mean
232:11 - it's automatically going to start or
232:12 - stop when the system boots up that's
232:14 - where the enable and disable comes into
232:15 - play now it's really really easy to tell
232:17 - what a service is doing by default and
232:20 - we can change it without much more
232:21 - difficulty at all so i'm at a computer
232:24 - right now and i've installed apache 2 on
232:27 - this centos machine so httpd is the
232:29 - package name and i've installed it
232:31 - however if we go over here we can see
232:33 - localhost it's unable to connect it's
232:35 - not running so the first thing we would
232:37 - do is say systemctl
232:40 - status httpd and it's actually giving us
232:43 - more information than it first appears
232:45 - see it's telling us that it's actually
232:47 - inactive which makes sense because we
232:49 - can't get it to load but more
232:51 - importantly it's saying that the service
232:53 - itself is disabled and the vendor preset
232:56 - meaning like when you first install it
232:58 - it's set to disabled so we can change
233:01 - that because if it's disabled it means
233:03 - it's not going to start when the
233:04 - computer boots so even if we rebooted
233:05 - this computer it still wouldn't load
233:08 - because it wouldn't start by default so
233:10 - we can say system ctl
233:12 - enable httpd
233:15 - and press enter and now if we do that
233:16 - status we're going to see that it's
233:18 - changed okay it says it's enabled even
233:20 - though the vendor preset is still
233:22 - disabled this means that you know when
233:24 - we installed it it was disabled but
233:25 - we've changed it now so it's enabled but
233:27 - you'll notice
233:28 - it's still inactive or dead now if we
233:31 - did restart the computer it would
233:33 - automatically start up but we can start
233:35 - and stop it independently from whether
233:37 - it's enabled or disabled as not we can
233:39 - just say system cto start httpd and it's
233:42 - going to start our service we can look
233:44 - at status httpd and we can see sure
233:47 - enough now that it's active right it's
233:49 - running and it's still enabled so when
233:52 - we reboot it's going to start running
233:54 - automatically now even if we left this
233:56 - disabled we could still have started it
233:59 - using the start command however when the
234:01 - computer rebooted it wouldn't start
234:03 - automatically so if you want it to
234:04 - always start up you have to make sure
234:06 - that it's enabled even if it comes
234:08 - disabled by default just a quick look
234:11 - boom it's running and sure enough it's
234:12 - right there running for us and it will
234:14 - run when the computer reboots because
234:16 - we've changed it to enabled i really
234:18 - like systemd because systemctl is kind
234:20 - of the one-stop shop it's like the swiss
234:22 - army knife for managing services on a
234:24 - computer that's controlled with the
234:25 - systemd startup init service
234:29 - sys5 or sysv or system five it's called
234:32 - a lot of different things but this is an
234:34 - older way that linux systems would put
234:36 - themselves in various modes or run
234:39 - levels that determine the type of system
234:41 - whether it's a gui system whether it's
234:43 - just a standalone network system and we
234:46 - can switch those various modes we can
234:48 - set defaults to those modes but it's
234:49 - important to understand what the modes
234:51 - actually are and there's a whole list of
234:53 - them unfortunately the modes are
234:56 - different in debian
234:57 - and centos or debbie and ubuntu centos
235:00 - souza they actually use the various
235:02 - levels differently so i just want to
235:04 - briefly go over the difference so that
235:05 - if you're on one system you kind of
235:06 - understand what's going on so centos
235:08 - actually separates them the most so
235:10 - let's go here first we have run level
235:12 - zero and run level zero is basically if
235:14 - you go into this mode it halts the
235:17 - system this is like a way to power the
235:19 - system down run level one is single user
235:22 - mode there's no networking or anything
235:23 - and there's no asking for the root
235:24 - password this is the way that you would
235:26 - recover a root password
235:28 - on a sys5 computer mode 2 is multi-user
235:32 - with no network 3 is multi-user with
235:35 - network 4 is not used at all with centos
235:39 - and 5 is the multi-user gui system like
235:42 - if you have x windows installed and then
235:44 - lastly run level six is reboot if you
235:46 - switch into run level six it will then
235:49 - reboot your computer and it will go into
235:51 - whichever default is set now w ubuntu
235:54 - are similar
235:56 - halt is the same reboot is the same
235:58 - single user mode is the same the
236:00 - difference is here
236:01 - two run level two is the full multi-user
236:05 - system just like run level three is here
236:08 - and then if there's a gui installed on
236:10 - the system the gui will start up there's
236:12 - no difference in debian ubuntu between
236:15 - having a gui system and having a not gui
236:17 - system when it comes to run levels
236:19 - that's only if the gui is installed so
236:21 - run level 2 is pretty much what we use
236:23 - all the time when we're in debian and
236:25 - ubuntu run levels 3 through 5 don't do
236:27 - anything at all they're just not used so
236:30 - that's the big big difference between
236:32 - the two we still have reboot we still
236:34 - have halt we still have single user mode
236:36 - but it's how they handle the other
236:37 - things that are a little bit different
236:38 - now switching between them and setting
236:40 - the defaults are exactly the same now
236:42 - here's the gotcha it took me a long time
236:44 - to find a system that still uses sys5.
236:47 - this is outmoded and not used in any
236:49 - modern distributions but if you go if
236:52 - you find one that is still in use like
236:53 - this is centos version six it will still
236:56 - use it so what we can do we can say run
236:58 - level
236:59 - and it will show us what run level we're
237:01 - in we're in run level five
237:03 - and the previous run level we were in
237:05 - was just a new boot okay now if we want
237:07 - to switch between run levels we can say
237:10 - tell init and then the run level we want
237:12 - to switch to so i'm going to say 3. this
237:14 - should drop us out of a gui
237:16 - and into a text only environment you can
237:19 - see here there's no gui there's just
237:20 - this text box right here so i'm going to
237:23 - log in so we can go back if i want to go
237:25 - back into the gui system i can say tell
237:28 - init 5 and it'll get us right back into
237:30 - the gui system and here we are in the
237:32 - gui system if i start up
237:35 - a terminal and we say run level we're
237:37 - gonna see we're currently in run level
237:39 - five our previous run level was three
237:42 - now if we switch into run level six it's
237:44 - going to reboot if we switch into run
237:46 - level zero it's going to just halt the
237:48 - computer and power it down if you want
237:50 - to change the default and the default is
237:52 - just what run level it automatically
237:53 - boots into we need to edit a file so i'm
237:56 - going to become root and we need to edit
237:58 - etc init
238:00 - tab
238:01 - and this file has a couple things we can
238:02 - edit but really the main thing is all
238:04 - the way down at the bottom which is the
238:06 - default run level now it gives us a
238:07 - little bit of a cheat sheet here and
238:09 - this is actually really really good
238:11 - advice
238:12 - the halt mode run level 0 do not set
238:14 - your init default to this because it'll
238:16 - boot up and immediately halt and that's
238:17 - not what we want same thing with setting
238:19 - it to run level 6. it will boot up and
238:22 - switch immediately into run level 6
238:24 - which is reboot so it's going to be in a
238:25 - constant reboot loop so you never want
238:27 - to set the default to that ours is
238:29 - currently in
238:31 - run level five for the default and it's
238:34 - right here now we could change that to
238:36 - three
238:37 - save this file and now when we reboot
238:39 - the computer it's just going to
238:41 - automatically go into the text only mode
238:44 - i'll just show you really quick what
238:45 - happens if we
238:46 - tell in it into run level six
238:49 - it's going to reboot that's what it does
238:50 - so if you run across an older system
238:52 - that uses run levels specifically system
238:55 - five run levels you need to know what
238:57 - the various modes do and remember it's
238:59 - going to be different whether it's
239:00 - ubuntu ubuntu and debian or centos and
239:02 - red hat and then you need to know how to
239:04 - switch the modes using telenit and how
239:06 - to set those defaults and most
239:08 - importantly what not to set the defaults
239:10 - to namely run level 0 or run level 6.
239:15 - i often find myself on a system thinking
239:17 - what if i need to switch between modes
239:19 - like i have a gui machine that i want to
239:20 - get rid of that gui interface so it's
239:22 - just a server with the text mode or vice
239:24 - versa well switching modes and setting
239:27 - the defaults is done one way with the
239:29 - sys5 system but if you have a newer
239:31 - system d
239:33 - initialization system it can be very
239:35 - very confusing especially if you have
239:37 - that sys5 background thankfully there
239:39 - are pretty simple comparisons when it
239:42 - comes to how it used to be and how it
239:43 - currently is now if you're not familiar
239:46 - with init 5 or with sys5 in it that's
239:48 - all right we're just going to talk about
239:50 - what the various modes are basically we
239:52 - start with run level zero which has a
239:55 - correlation
239:56 - in the system d world as a boot target
239:59 - called power off now boot targets are
240:02 - basically just modes right these are
240:04 - modes that computers are are set to so
240:07 - that they can function in a specific way
240:09 - and while it doesn't seem like a mode
240:11 - it's a really easy way to shut your
240:13 - computer down by switching into the
240:15 - power off mode now there's also one this
240:18 - is single user mode in the world of
240:20 - systemd it's called rescue mode this is
240:22 - like insist five if you want to like
240:24 - reset your root password you need to
240:26 - switch into single user mode well same
240:28 - thing with a boot target it's just
240:29 - called rescue mode then there's mode
240:31 - three which in a centos system is going
240:34 - to be like a
240:35 - non-graphical user interface with
240:37 - networking support that translates to
240:39 - just multi-user target in system d uh
240:42 - the gui mode five translates to
240:45 - graphical target and of course six is
240:47 - like the the compatriot to run level
240:50 - zero and this is how you can reboot your
240:52 - system by switching into run level six
240:54 - or boot target reboot now switching
240:57 - between them is actually easier than it
240:59 - is with the old sys5 you can actually
241:01 - just use a command line tool instead of
241:04 - editing that init tab file that you have
241:06 - to do with sys5 now i'm on centos
241:08 - version 7 here because centos version 7
241:11 - uses system d whereas centos version 6
241:13 - uses sys5 now the first thing you need
241:15 - to do is be root so i'm going to quickly
241:17 - become root once we're root we can type
241:20 - system ctl which is the way we do most
241:22 - things with systemd but systemctl
241:25 - getdefault
241:26 - and this is going to tell us what the
241:28 - default mode is and that makes sense
241:29 - because our default mode here is
241:31 - graphical target and you can see we have
241:33 - a gui interface now we could change that
241:36 - we could say systemctl
241:38 - set default to multi-user.target
241:44 - and see now it's changed that so if we
241:46 - say get default it's going to tell us
241:47 - okay now it's multi-user but notice it
241:49 - didn't change we're still in the gui
241:51 - environment well that's because it just
241:53 - changed the default if we were to reboot
241:55 - this computer it would reboot into a
241:57 - text only mode now if you want to switch
241:59 - between modes or between targets with a
242:02 - computer that's already started you
242:04 - simply type system
242:06 - ctl
242:07 - isolate and then the name of the target
242:10 - in our case let's say isolate
242:12 - multi-user and it should drop us
242:15 - directly into sure enough the text only
242:17 - mode now if you're already used to the
242:20 - world of run levels you just have to
242:22 - kind of think what the different targets
242:24 - that correspond to it are but if you're
242:25 - not familiar with run levels like this
242:27 - is something that happened before your
242:29 - time in linux that's okay because
242:30 - honestly boot targets make a heck of a
242:33 - lot more sense than the run levels did
242:36 - because they actually have their
242:37 - description right in their names and
242:39 - while it's important to understand both
242:42 - sys5 and system d you should know that
242:44 - all systems going forward are going to
242:46 - be system d so you're gonna have to know
242:49 - about the various modes how to switch
242:50 - between them using isolate and then how
242:53 - to set and get the default so you know
242:55 - what happens to a system when it boots
242:57 - up so you don't have your rack servers
242:59 - booting up to a gui environment because
243:01 - that just doesn't make any sense
243:04 - services are the various programs that
243:07 - are installed on a server that are going
243:08 - to run and serve out like web pages or
243:10 - whatever you might have installed
243:12 - they're called services and if you have
243:14 - sys5 on your computer the way that you
243:16 - manage and start and set defaults for
243:18 - those individual services are by using
243:21 - specific programs in the
243:22 - etc init.d
243:24 - folder now there are tools that we can
243:26 - use to manage those specifically service
243:28 - and check config and i want to show you
243:30 - how they work because the services are
243:32 - determined
243:34 - to start and stop based on the run level
243:37 - of a particular what the computer is set
243:38 - to so if like it's run level three a
243:41 - certain system might start and if it's
243:43 - run level five
243:45 - another service might not start let me
243:47 - show you what i'm talking about here on
243:49 - our system though this is centos 6 which
243:50 - has sys5 if we look in etc.d
243:55 - these are all the various services or
243:57 - programs that are installed on the
243:59 - computer we can see things you know like
244:01 - post fixes the email server sshd is our
244:04 - ssh server and we can start and stop
244:07 - these by using the service command so i
244:10 - can say service
244:11 - sshd
244:13 - start
244:14 - and it's going to start the service i
244:16 - can say service sshd
244:19 - stop and it will stop the service i can
244:20 - actually do status to see what it's
244:22 - currently doing so right now it's
244:24 - currently stopped it says but what i
244:27 - want to do is change how it starts or
244:29 - stops on system boot and what we can do
244:32 - is say chk config
244:34 - dash dash list sshd and it's going to
244:37 - show us what sshd is going to do on
244:40 - every run level so run level zero it's
244:43 - off one it's off two it's off three it's
244:44 - off four it's off five it's off and six
244:46 - it's off so this means it is not going
244:48 - to start up on system boot regardless of
244:51 - what run level the system is starting at
244:53 - now we can set it so that it will start
244:55 - for all of the run levels one through
244:58 - five it's never going to start
244:59 - automatically for zero or for six
245:02 - because those are
245:03 - those are halt and reboot and that would
245:04 - just be silly but if we wanted to start
245:06 - on all of them we can just say chk
245:09 - config
245:11 - sshd on and it's going to set them to on
245:14 - for all of the run levels so we can do
245:16 - that list command again and we're going
245:17 - to see now it's on four two three four
245:20 - and five actually it doesn't do it for
245:21 - single user mode so if we just say on
245:24 - it's going to set it for run level two
245:26 - three four and five it's going to be
245:27 - turned on but we can do it individually
245:29 - too so first of all let's turn it back
245:31 - off so now they're all set to off if we
245:34 - look see they're all off again we can do
245:36 - a single one so it gets a chk config
245:39 - dash dash level
245:41 - 3 on
245:43 - and now if we look it's just going to be
245:44 - on for level oop
245:47 - gotta get the format right sshd on
245:51 - and now if we look there now let's turn
245:53 - it on for run level three but the other
245:55 - ones are still off so chk config is the
245:58 - way that we change how it boots up
246:00 - whereas the service command up here is
246:02 - how we change it immediately if we want
246:04 - it to start or stop we can use the
246:05 - service command but if we want it to
246:07 - start on boot we need to use the chk
246:09 - config command because that's going to
246:12 - change the behavior at the various run
246:14 - levels thankfully when you install
246:15 - packages they create their own entries
246:17 - in the etc.d folder we don't need to
246:20 - make scripts or anything in there and
246:22 - the programs install things in there so
246:24 - that the service and the chk config
246:26 - commands know exactly what to do in
246:28 - order to start and stop or configure
246:30 - what happens on boot with a given system
246:33 - that's running sys5
246:35 - modern linux systems use system d to
246:38 - manage their services things like their
246:40 - web server their ssh server and the same
246:43 - tool is used to start them stop them
246:45 - enable them on boot and that's that
246:47 - swiss army knife that catch all tool for
246:49 - systemd
246:51 - system ctl so i want to show you how to
246:53 - go about starting and stopping
246:55 - individual services but also how to
246:57 - affect what happens on boot when a
246:59 - system boots up what happens with
247:01 - particular services but first there is
247:04 - one thing that can be frustrating about
247:05 - system d and that is that the service
247:08 - files can be scattered all over the hard
247:10 - drive so for example inside etc systemd
247:14 - system we're going to find a couple
247:16 - service files like anything that ends in
247:18 - dot service is going to be a system d
247:20 - service file but you'll notice like
247:22 - there's no ssh here well that's
247:24 - frustrating well let's actually search
247:26 - for that say locate
247:28 - sshd.service you'll find that this is
247:31 - actually located in user lib systemd
247:34 - system that's where sshd.service live so
247:37 - there's several places that you can find
247:39 - the service files whereas with sys5 it
247:42 - was always in the etc.d folder here
247:44 - there are several folders that are going
247:47 - to house system files that are service
247:50 - files for your system so that can be
247:52 - frustrating but nonetheless we
247:54 - regardless of where they're stored we
247:55 - can still use systemctl to query them so
247:58 - we can say for example systemctl sshd
248:02 - let's do a status
248:05 - and this is another gotchu if you're
248:06 - going from sys5 right into system d the
248:10 - frustrating thing is normally we would
248:11 - say like service sshd status well now
248:14 - it's backwards now we have to say
248:17 - system ctl
248:19 - status sshd gur it's frustrating but you
248:22 - get used to it unless you go back and
248:24 - forth from systems then it can be a
248:26 - little bit frustrating but nonetheless
248:28 - on system d we have to say status or
248:30 - start or stop and then the service name
248:32 - whereas it's backwards with sys5 anyway
248:35 - we have a lot of information here so we
248:37 - can see that it's active which means
248:39 - it's running so it's currently started
248:41 - there's more information here though we
248:43 - look up here it says it's loaded it's
248:45 - enabled
248:46 - and enabled in systemd world means that
248:48 - it's going to start on system boot and
248:51 - there's even some more information here
248:53 - it says vendor preset is enabled now
248:56 - what that means is when we install the
248:58 - sshd daemon it's going to automatically
249:02 - be enabled now that doesn't mean it's
249:04 - going to start unless we restart the
249:06 - system but it means that it's going to
249:08 - be set to start on the system boot
249:10 - that's what the vendor preset is now we
249:12 - can change this easily we can say
249:15 - system
249:16 - ctl disable sshd and now if we go back
249:20 - and say status sshd we're going to see
249:23 - now it's disabled and the vendor preset
249:26 - is still enabled but we've changed it
249:28 - now so that it's not going to start on
249:30 - boot however this is another important
249:32 - thing to note it's still running because
249:34 - we've changed what happens on boot but
249:36 - we haven't changed what's currently
249:38 - happening on the system so if we reboot
249:41 - it's not going to be running but if we
249:43 - want it to not run we actually have to
249:45 - tell it that so we have to say systemctl
249:48 - stop sshd
249:50 - and now if we were to say status now we
249:52 - would see it's no longer running it's
249:54 - inactive and it's not going to start on
249:57 - system boot but let's change that
249:59 - because we definitely wanted to start on
250:01 - system boot so systemctl will start it
250:04 - up
250:05 - sshd and systemctl
250:09 - enable sshd and now if we do system ctl
250:13 - again this is a catch all tool
250:15 - status sshd we're going to see it's back
250:18 - to how it should be it's running and
250:20 - it's enabled which means it's going to
250:22 - start on boot
250:24 - so regardless of what service we want to
250:26 - start stop or enable or disable that
250:29 - system ctl tool is what we use for just
250:31 - about everything in the world of system
250:33 - d really the only gotcha with going from
250:36 - sysv to system d when it comes to
250:39 - services you have to remember to use the
250:41 - system ctl tool and then you have to
250:43 - remember that the actual command goes
250:46 - before the name of the service and
250:48 - that's backwards from sys5 so we have to
250:50 - say like systemctl start sshd whereas
250:54 - with sys5 it was backwards but it's easy
250:56 - to get used to and i love having a
250:58 - one-stop tool to do all of the things
251:02 - that when we're planning servers on our
251:04 - network it's important to know that
251:05 - servers serve things they serve things
251:07 - like ntp which is a network time
251:09 - protocol ssh a secure shell so you can
251:12 - get into the computer remotely dns is
251:14 - domain name service which translates
251:16 - things like cbtnuggets.com into an ip
251:18 - address dhcp hands out ip addresses on a
251:21 - local network so you don't have to
251:22 - manually assign them a docker is a
251:24 - containerization system that allows you
251:26 - to run services in siloed environments
251:29 - and then of course configuration
251:30 - management tools allow you to centralize
251:33 - the individual configuration of servers
251:35 - so there's basically several kinds of
251:37 - services that we're going to install in
251:39 - our networks we have centralized things
251:41 - which are going to run on like one
251:42 - server for your entire network and then
251:44 - individual which are going to run on all
251:47 - or most of your servers so here we have
251:50 - things like i mentioned before dhcp dns
251:53 - configuration management server these
251:55 - are going to run on one server on your
251:58 - network you don't need more than one
251:59 - dhcp server more than one dns server
252:02 - apart from redundancy or high
252:03 - availability but generally speaking you
252:05 - only need this in one place individual
252:08 - computers all have to have an ssh server
252:11 - installed because you want to get into
252:13 - every server on your network right this
252:16 - is just something that's going to be
252:17 - installed everywhere your configuration
252:19 - management client is going to be
252:21 - installed on every computer it's a
252:24 - service that needs to be there so that
252:25 - it can take advantage of the
252:27 - configuration management system like
252:29 - chef or puppet or ansible so that it can
252:32 - you know work together to keep those
252:34 - servers in line docker is a
252:35 - containerization program that runs on an
252:37 - individual server and if you're gonna
252:39 - have a lot of different servers out
252:41 - there you may have docker installed on
252:43 - multiple computers so that it can host
252:46 - services for you now ntp is kind of the
252:48 - in the junction point of my venn diagram
252:51 - here and that's because ntp or network
252:53 - time protocol is the service that keeps
252:55 - your computer in the proper time like
252:58 - you know if you have some clock skew
252:59 - where it's a little bit too fast or a
253:00 - little bit too slow ntp will keep your
253:04 - server running in the proper time now
253:06 - there is a centralized ntp server very
253:09 - often on your network and all of the
253:11 - other computers or servers on your
253:14 - network will then query your centralized
253:17 - ntp server but here's the deal this same
253:20 - ntp server software is actually the
253:22 - client software as well so ntp does two
253:25 - things one it queries an above computer
253:28 - for the time you know in the case of the
253:30 - centralized one it's in the cloud and it
253:32 - also can serve out that time information
253:35 - to its peers or to people on your local
253:37 - network so usually we have a centralized
253:40 - ntp server but we don't even have to
253:42 - right all of these ntp server machines
253:45 - could query right out to the cloud and
253:48 - bypass a centralized ntp server it's
253:51 - just nice to have a centralized place so
253:52 - you have one time frame that your entire
253:55 - network is based on but it's the same
253:57 - server program so that's why i kind of
253:59 - put it in both camps here as individual
254:01 - and centralized now when you're setting
254:03 - up your servers on your network it's
254:06 - important to think through how it should
254:08 - work and it's actually gone through this
254:11 - change as computer hardware and
254:13 - technology has progressed there used to
254:15 - be a time where you would have a bare
254:17 - metal server for every service on your
254:20 - network if you had a dns server it would
254:22 - literally be a physical server sitting
254:25 - in your server closet and it would sit
254:27 - right next to your dhcp
254:29 - server whose sole purpose was to serve
254:31 - out dhcp same with ntp or you know a web
254:34 - server
254:35 - but then we said you know what now
254:37 - computers are getting to be so fast that
254:39 - we could put multiple services on a
254:42 - single computer because the problem here
254:44 - is it was very expensive right if you
254:47 - had to buy a physical server for every
254:48 - service you wanted to do it got
254:50 - expensive fast so what if we bought a
254:52 - decent sized server and then we
254:54 - installed dns software we installed dhcp
254:57 - software ntp software web software
255:00 - whatever we wanted to do it would all
255:01 - run alongside each other and be really
255:03 - happy
255:04 - the problem comes what if you need to
255:06 - run an update on one of these like we
255:08 - need to take dns offline so we can
255:10 - update it and maybe restart the server
255:12 - when we restart the server all of our
255:15 - services go down because we've put them
255:18 - all in one basket right all of our eggs
255:20 - are in one basket it's also a single
255:22 - point of failure basically it's messy
255:25 - and then the dawn virtualization
255:27 - happened and this is where
255:29 - server closets got really awesome really
255:31 - fast that's because we had large
255:34 - computers you know basically the same
255:36 - large computer it's not that computer
255:38 - hardware got all that much faster but
255:40 - virtualization technology allowed us to
255:43 - instead of just installing a dns service
255:45 - software we could install a virtual
255:48 - server inside here by taking a slice of
255:50 - the resources from the bigger server and
255:53 - install a completely new server
255:56 - virtualized in there that would run dns
255:57 - and we could do that alongside another
255:59 - virtual server and if we had to take
256:01 - this offline or or restart it it
256:03 - wouldn't affect the others because they
256:04 - were their own standalone virtualized
256:07 - servers it was really really awesome it
256:09 - still is a very powerful way to go about
256:11 - protecting your different services from
256:14 - each other on the network the problem is
256:16 - and this is something that i've fallen
256:17 - prey to is sprawl potential it's really
256:20 - easy to spin up another server oh i want
256:22 - to do this i'll spin up another server
256:23 - oh what if we did this sir spin up
256:25 - another server that's where docker comes
256:28 - into play and i won't go too much into
256:29 - docker other than to tell you what
256:31 - docker does is it takes a server and it
256:34 - has a single operating system running
256:36 - linux and then each service has its own
256:39 - like isolated pocket it doesn't have its
256:42 - own
256:42 - operating system it's not like a virtual
256:45 - machine all it does is have its own
256:47 - little slice of the running system where
256:50 - it has its own file system and it can
256:53 - run its own little service here and it
256:55 - doesn't affect anything else because
256:57 - it's walled off so containerization is
257:00 - an even better way to take better
257:02 - advantage of server hardware even than
257:04 - virtualization when it comes to virtual
257:06 - servers so yes there's a lot to think
257:08 - about when you're installing servers on
257:10 - your network on where to put them but
257:12 - the nice thing is whether it's a local
257:13 - service that has to be installed on
257:15 - every computer or a centralized service
257:17 - that you just install like in one place
257:19 - for your whole network planning has
257:21 - gotten a lot easier because you don't
257:23 - have to worry so much about putting all
257:24 - of your eggs in one basket we've been
257:26 - able to isolate individual services
257:29 - without the need to buy brand new
257:30 - hardware so planning is kind of fun and
257:32 - more flexible than it's ever been before
257:35 - conceptually we pretty much understand
257:37 - how a web server works you send a
257:39 - request and the web server sends back
257:40 - the web page but when you add ssl or tls
257:44 - it really does add a layer of complexity
257:46 - but that complexity is for a good reason
257:48 - because it can secure the traffic so
257:50 - nobody knows what is going through your
257:53 - internet connection like bank account
257:55 - information and stuff like that so it's
257:57 - very important that we have ssl
257:59 - encrypted secured traffic now the
258:01 - process is going to be a little bit
258:03 - different than just a standard web page
258:05 - and part of the thing that you want to
258:07 - make sure you have if it's like for a
258:08 - bank or something is a certificate
258:10 - authority now let me demonstrate exactly
258:12 - what goes on
258:14 - when you try to get a web page from a
258:16 - web server let's say this is our web
258:18 - server now if you're not talking about
258:20 - ssl basically the guy in the computer
258:22 - here says hey i would like to see your
258:24 - web page and then the computer says okay
258:26 - here is my web page and that's pretty
258:28 - much the entire process there's no
258:30 - encryption at all but when you go to
258:32 - like your bank's website you're going to
258:35 - set up an ssl session so that all of
258:37 - your information that goes back and
258:39 - forth is encrypted so basically here is
258:41 - how the process works the client sends a
258:44 - message to the server
258:45 - and it says hey i would like to start an
258:48 - ssl encrypted session with you and then
258:50 - the web server responds okay
258:53 - here is my certificate this says who i
258:56 - am and that i'm valid and look here's a
258:59 - picture of my kid playing softball maybe
259:01 - not that bar but it sends a certificate
259:03 - describing who it is to prove that it's
259:05 - who the server says it is that it's not
259:07 - like some man-in-the-middle attack now
259:09 - the only way the end user knows that
259:12 - it's real is because he contacts a
259:15 - certificate authority which is a
259:17 - centralized trusted place that signs
259:20 - certificates basically it's this
259:22 - person's job to contact this web server
259:26 - and make it prove who it is and then
259:28 - once it proves who it is it gets its
259:30 - certificate signed by the certificate
259:32 - authority so then let's say this guy's
259:35 - name is bob bob says okay i see that at
259:38 - the bottom of your certificate it was
259:40 - signed by somebody who i trust so i'm
259:42 - going to trust that you're really who
259:43 - you say you are so then after that
259:46 - identification has been verified bob
259:49 - then sends his encryption key to the web
259:52 - server so the key is sent from the end
259:54 - user to the server and then the server
259:58 - uses that key that bob sent and that is
260:01 - what is used to encrypt the actual data
260:04 - that is going to go to bob's computer so
260:07 - the actual encryption
260:09 - uses bob's key that he sends to the
260:12 - server after the server proves who it is
260:15 - and then they use this tunnel back and
260:17 - forth and that's how they communicate
260:18 - using bob's key now if you set up a
260:21 - server in your own network you've
260:23 - probably heard of something called a
260:24 - self-signed certificate now that is
260:27 - exactly what it sounds like when that
260:28 - initial request comes from bob and he
260:30 - says hey server i would like to set up
260:32 - an ssl connection the server does
260:35 - respond with a copy of its certificate
260:37 - it says here i am this is all my
260:39 - information uh this is the stuff that
260:41 - you know describes who i am i'm
260:43 - promising that i am the person i say i
260:45 - am but there's no signature on the
260:47 - bottom from the certificate authority
260:49 - it's something that bo that the server
260:51 - signed himself so bob has to like just
260:54 - trust that this server is who he says it
260:56 - is now if it's on your own local network
260:58 - that's usually fine and it's okay to
261:00 - accept a self-signed certificate but if
261:02 - it's over the internet you don't want to
261:04 - accept a self-signed certificate because
261:06 - there's no way to be sure that it's
261:08 - actually the server it says it is and if
261:11 - you trust a self-signed certificate and
261:12 - it ends up being like a
261:14 - man-in-the-middle attack you could be
261:16 - sending all of your banking data to a
261:18 - server that isn't who it says it is and
261:20 - that's very dangerous so a self-signed
261:22 - certificate encrypts the exact same way
261:25 - the problem is you're not a hundred
261:27 - percent positive who it is that
261:29 - initially set up that certificate so
261:31 - there's a lot of trust involved whereas
261:33 - if you use a certificate authority trust
261:36 - is taken out of the picture because you
261:37 - trust the certificate authority it's
261:39 - built into your web browser so the
261:42 - actual ssl encryption is the same
261:44 - whether it's a certificate authority or
261:46 - a self-signed certificate but you don't
261:48 - know if it's the server it says it is
261:50 - unless you have that certificate
261:52 - authority that signs the server
261:54 - certificate that's why it's very
261:56 - important especially on the internet to
261:58 - make sure that you don't get an error
262:00 - about not having a certificate signed by
262:02 - an authority but the process is the same
262:05 - either way
262:06 - it turns out that local network server
262:08 - roles have changed fairly dramatically
262:11 - over just the past few years now don't
262:13 - get me wrong things have come a long way
262:15 - from when we used to have a sneaker net
262:17 - so if we had a file we'd have to put it
262:19 - on a floppy disk and then you know carry
262:21 - to the cubicle next to us and pass it on
262:23 - like that but we don't even use local
262:26 - servers as much as we used to now what
262:29 - am i talking about well i'm talking
262:30 - about the introduction of cloud
262:33 - computing now let's look at file
262:34 - services for example we used to have and
262:37 - then we actually we do still have local
262:39 - file services that you know if we want
262:41 - to save files in a local centralized
262:43 - place we do things whether we're on
262:44 - windows or linux or mac if we want to
262:47 - serve to windows computers we can use
262:48 - the samba program which allows us
262:50 - through file sharing that is hosted on
262:53 - linux but is accessible from a windows
262:56 - machine it's a free way very stable very
262:58 - scalable that we can actually share
263:00 - files with windows computers same thing
263:02 - with nfs which is network file storage
263:04 - and this is applicable for linux mac
263:07 - windows and then if you have old school
263:09 - apples that only use like the apple talk
263:12 - sort of networking stuff well there's
263:14 - neta talk which uses the native apple
263:16 - file sharing but this isn't even used
263:18 - anymore so much because now macintosh
263:21 - computers can very easily do windows
263:23 - shares using samba or nfs but netetalk
263:26 - is still around if you like that native
263:27 - apple file sharing stuff the point is
263:30 - linux computers can do local file
263:32 - sharing very very well the thing to
263:35 - think about if you're implementing a
263:36 - network though is should i and that's
263:38 - where cloud services come into play
263:40 - because while sure you can serve things
263:42 - locally on a file you might want to
263:43 - consider something like dropbox or
263:45 - onedrive or google drive that works on
263:48 - almost every platform and allows you to
263:50 - not only sync things between computers
263:53 - but also have an online
263:56 - backup which is really really vital and
263:58 - it saves a ton of money if you don't
264:02 - have to buy the servers to actually
264:04 - store all of your files if it's stored
264:06 - on a cloud service that you usually pay
264:09 - a service fee for you're going to save
264:11 - that money on maintenance and hardware
264:13 - purchases and etc etc so think about
264:15 - cloud services every time you're
264:18 - thinking about local services there are
264:20 - some cases you'll want local services
264:22 - but some cases it just doesn't make any
264:24 - sense and there are complementary cloud
264:26 - services to almost every one of our
264:28 - local services that we can offer i want
264:30 - to mention the ways that you can serve
264:32 - them locally because it does make sense
264:34 - sometimes for example a print server is
264:36 - going to be cups common unix printing
264:38 - system this works across the board if
264:40 - you're sharing a printer with mac or
264:42 - linux it's going to be using cups and
264:44 - even windows can print two cups servers
264:47 - it's like a centralized place but
264:48 - honestly most printers now pretty much
264:51 - have a robust ability to share and queue
264:54 - jobs on their own so we don't always
264:56 - have to use a centralized cup server uh
264:59 - we can all print to the same printer and
265:00 - it's just handled well netatalk also has
265:02 - printing if you have an old school apple
265:04 - computer you want to use that for but
265:06 - again that's not even used very much
265:07 - anymore how could your local printer be
265:10 - used with cloud services well it doesn't
265:11 - make sense until you think about
265:13 - no configuration printing right with
265:16 - google print or air print these are ways
265:18 - that you can actually send your print
265:20 - job over the internet to a printer that
265:22 - may or may not be connected directly so
265:25 - it's something that isn't going to
265:26 - replace common everyday office printing
265:28 - but it's something to think about if you
265:30 - want to be able to configure or
265:31 - especially print from mobile devices
265:33 - having cloud solutions is very powerful
265:36 - now mail is a special case because a lot
265:38 - of times we want mail to be as secure as
265:41 - possible and that means we don't
265:43 - necessarily want to give the ability to
265:45 - another company to host our mail but
265:48 - remember with great power comes great
265:50 - responsibility
265:51 - keeping your locally hosted email files
265:54 - whether it's using postfix or xm or
265:56 - sendmail can be a full-time job because
265:59 - we want those to be really secure not
266:01 - only so people can't read our emails but
266:03 - so our servers aren't compromised and
266:06 - used to send out spam to the entire
266:07 - world so even though having that fine
266:10 - control over security of your own mail
266:12 - is important think about how nice it is
266:15 - if a huge company like google or
266:17 - microsoft or yahoo would have to worry
266:20 - about the security aspect so you can
266:22 - actually just focus on communicating
266:24 - with it so there's a lot to be said
266:26 - about using a third-party company for
266:28 - email even though you do lose some of
266:29 - that local control and then lastly i
266:31 - want to talk about a proxy now when we
266:33 - talk about proxies in linux we're
266:34 - talking about squid or squid guard which
266:36 - is an add-on to squid and generally
266:38 - proxies have historically taken the load
266:41 - off of your internet connection so a
266:43 - bunch of computers can actually request
266:46 - things one time from the cloud and then
266:48 - the proxy server kind of takes that and
266:50 - distributes it internally but our
266:52 - internet connections are very powerful
266:54 - now so we don't often do that now when
266:56 - we're thinking about proxy a lot of
266:58 - people mistakenly call a web filter a
267:01 - proxy and what a web filter does is it
267:04 - stops you from going to like
267:05 - pornographic websites and that's what
267:07 - squid guard does there's a lot of
267:08 - commercial products that keep a list of
267:11 - sites that shouldn't be visited by
267:13 - people and there are other solutions too
267:15 - like open dns is a way that you can set
267:17 - your dns server your upstream dns server
267:20 - so that it doesn't resolve sites that
267:22 - you don't want to see like pornographic
267:24 - websites they won't even resolve
267:25 - properly so your users can't get there
267:27 - now when it comes to actually caching or
267:29 - proxying large things there are some big
267:32 - companies like akamai that will cache
267:35 - entire video libraries of like netflix
267:37 - and stuff because that's a way that they
267:39 - can save bandwidth between isps but in
267:42 - general we don't use proxies as much as
267:44 - we used to although there are still a
267:46 - lot of use cases for things like squid
267:48 - guard or open dns for blocking unwanted
267:51 - websites that are going to waste time or
267:53 - expose us to things that you know we may
267:55 - not want to be exposed to in the company
267:56 - or in a school so while it's really
267:58 - important to know that there are local
268:00 - services that you can provide on your
268:02 - network using linux i encourage you to
268:05 - think through before you install a
268:07 - server on your network to do a
268:09 - particular task see if it really makes
268:11 - sense to host that locally or if going
268:13 - for a third party service might make
268:15 - more sense
268:17 - authentication services and database
268:19 - services are both things that we often
268:21 - do on local computers i want to talk
268:23 - about their purpose and their importance
268:25 - but it also might seem a little weird
268:26 - that i group them together and that's
268:28 - because we usually think about
268:29 - authentication and databases as local
268:32 - services that run on robust servers and
268:34 - that's for a reason it's because they're
268:35 - very very important to what we do on a
268:38 - regular basis and i just want to talk
268:40 - about while we oftentimes still run them
268:42 - on local computers there's still an
268:44 - argument to be made for putting those in
268:46 - the cloud as well now generally if
268:48 - you're talking about linux you're
268:49 - thinking about a sql service if you're
268:51 - thinking traditionally right this could
268:53 - be my sql or
268:55 - maria database which is basically my
268:57 - sequel only newer
268:59 - postgres there's a whole bunch of other
269:01 - sql servers that would normally run on a
269:03 - really robust server on our network now
269:05 - there are tons of other
269:08 - database services some of them are you
269:10 - know are non-sql and and some of them
269:13 - are good for certain types of data and
269:14 - bad for other types of data but there
269:16 - are tons and tons of database services
269:19 - and generally when we have a database
269:21 - server it's going to be on its own
269:24 - computer and that's just because
269:26 - database servers tend to be kind of
269:27 - robust so you're going to have something
269:29 - like mysql maria postgres they're going
269:32 - to be on their own server and
269:34 - authentication services are similar as
269:36 - well because we need to have a central
269:39 - place to authenticate all of our users
269:40 - now when you log into like gmail you're
269:43 - going to put in your username and
269:44 - password and that's all stored in a
269:46 - central place on google servers
269:48 - if you're on your local network there
269:50 - are tons of ways that you can store user
269:53 - information on your own local network in
269:56 - fact for years i would use nis on a
269:58 - linux server and i would use all of our
270:00 - computers in the network would
270:02 - authenticate to this one centralized
270:04 - server and it was so important that all
270:06 - user information was stored on there
270:08 - that i had a redundancy so that
270:11 - in case one of the servers went bad i
270:13 - would still have a backup that was live
270:15 - high availability so there's lots of
270:17 - ways we can do it but the vital
270:18 - importance of having our own server or
270:22 - even multiple servers is important but
270:25 - here's the deal you'll notice i have all
270:27 - of these things around the outside you
270:28 - can use open ldap to host your user
270:31 - accounts on your network and it's going
270:33 - to work with a bunch of different
270:34 - programs but honestly i would say 95 of
270:37 - the time user data is going to be stored
270:40 - on an active directory on a windows
270:42 - computer even if you're a linux person
270:44 - in a linux shop it seems like ad has
270:48 - taken the cake as the king when it comes
270:51 - to user authentication now the one
270:54 - alternative to that is if you're going
270:55 - to use an online like saml or i don't
270:58 - want to get too much into programming
271:00 - but there are ways that you can leverage
271:02 - online authentication for your local
271:04 - stuff like single sign-on and things
271:06 - like that so that may take the place of
271:08 - active directory on your network but if
271:11 - you're if you're talking about user
271:13 - authentication active directory is
271:15 - almost certainly going to be where a
271:17 - medium to large or even small office is
271:20 - going to host all of their user accounts
271:22 - so it's important to know that you can
271:25 - host authentication services on a linux
271:27 - machine but you may
271:29 - not end up doing that because active
271:31 - directory is probably going to be
271:32 - somewhere and it's a great place to
271:34 - centralize your users and your computers
271:37 - so the whole point of this nugget is
271:39 - really twofold one authentication can be
271:42 - done on linux and i did it for over a
271:44 - decade where everything was hosted on a
271:46 - local linux machine and i used nis for
271:49 - authentication i could have used
271:50 - openldap but generally you're not going
271:52 - to do that on a big network because you
271:54 - have more than linux machines that need
271:56 - to authenticate now the other thing
271:58 - though is database servers i want you to
272:01 - know that they're almost always going to
272:02 - be on their own server because they use
272:05 - a lot of resources a lot of memory a lot
272:08 - of cpu a lot of disk io so if you're
272:11 - setting up server roles on your network
272:13 - think about a database server as having
272:15 - its own need unless you host it out on
272:18 - the cloud in which case you're just
272:20 - paying for somebody else's resources
272:22 - which can often be even more effective
272:26 - centralized logging and monitoring is
272:29 - great for a big network because it's
272:30 - easy to lose track of a big number of
272:32 - servers but honestly it's great even if
272:35 - you have a tiny little network now i'm
272:37 - going to look at
272:38 - combining syslogs but i also want to
272:40 - peek at
272:41 - snmp because both are vital for
272:45 - combining information from multiple
272:47 - sources
272:48 - centralizing them if you will so that
272:49 - it's easier to see and easier to use for
272:53 - making predictions and adjustments in
272:55 - how your infrastructure works so first
272:57 - of all i want to talk about central
272:59 - logging okay now there are a ton of
273:01 - devices out there a lot of them can be
273:03 - you know servers you know and lots of
273:05 - servers on the rack and you don't want
273:06 - each one to have its own set of logs you
273:08 - want to combine them but there's other
273:10 - things now that can create logs but may
273:13 - not have the storage area to keep those
273:16 - logs on themselves like security cameras
273:19 - routers motion detectors smart bulbs
273:22 - printers all of these things can create
273:25 - log files and if you can redirect them
273:28 - to a centralized
273:30 - server that's going to allow you to comb
273:33 - through data in a very efficient way and
273:34 - in fact sometimes this is the only way
273:37 - you can get data from certain devices
273:39 - that have absolutely no storage on them
273:42 - but can generate logs and information
273:44 - now when you combine them all together
273:46 - it is pretty neat how it works the
273:47 - centralized log server is going to just
273:50 - have one big log file however each
273:53 - individual device is going to put its
273:56 - own name in the log file so you can sort
273:59 - by whatever computer is adding it so
274:01 - even though you have one log file that
274:03 - is going to contain everything it's easy
274:05 - to separate out the individual devices
274:08 - to see what they're doing using tools
274:10 - like grep or there are some really fancy
274:12 - devops tools that will allow you to sort
274:14 - data from combined log files
274:17 - when you combine log files like that you
274:19 - end up being able to see some trends or
274:22 - see some relationships that might not
274:24 - otherwise be easily accessible for
274:26 - example if none of these devices are
274:29 - able to access a dns server well maybe
274:31 - you have some problem with the network
274:33 - in that portion of your company and so
274:36 - you can help troubleshoot based on what
274:37 - logs are being submitted now snmp
274:41 - is slightly different and it stands for
274:44 - simple network management protocol but
274:47 - it's a little bit of a misnomer because
274:49 - traditionally this was used to not only
274:52 - read data but also remotely control
274:55 - devices using this network management
274:58 - again it was a two-way street protocol
275:00 - now there are still some instances where
275:02 - you can use this to manage devices but
275:05 - mainly it's used for pulling data and
275:08 - what i mean by that is let's say you
275:10 - have some data that you'd like to
275:12 - concatenate together for an informative
275:15 - data pie that's just delicious you're
275:17 - trying to make graphs or something you
275:19 - can use snmp
275:21 - to pull data from a device one of the
275:23 - most common things that i use it for is
275:26 - i have a router that i connect to the
275:28 - internet with and i would like to see
275:29 - some interface statistics for what's
275:32 - going on how much data is going through
275:34 - it and things like that snmp can pull
275:37 - that data it's not really like
275:39 - individual servers pushing data to a
275:41 - centralized logging it's kind of going
275:42 - the other way it's kind of using snmp to
275:46 - pull data from individual devices and
275:48 - what that looks like in practice here is
275:51 - this is actually the home page that
275:52 - every time i load up a web browser this
275:54 - is what loads up and i have a couple
275:55 - convenient links for me you know to go
275:57 - to see the weather in my area that sort
275:59 - of thing but i have these graphs that
276:01 - show the bandwidth usage both in my
276:04 - house in the town and we own a farm as
276:07 - well that has fiber internet connection
276:09 - and this shows the connection between
276:12 - them now you'll notice there's a lot of
276:14 - matching between the two and that's
276:16 - because i will often back all of my
276:18 - townhouse data to our farm because it's
276:21 - an off-site storage location so that
276:23 - makes a lot of sense but this is just a
276:25 - way that i can see what's happening on
276:26 - my network and i pull this from my
276:28 - routers using snmp now it's important to
276:31 - realize that while they accomplish sort
276:33 - of the same thing centralized logging
276:35 - allows all of your servers to push data
276:38 - to a centralized server so you can comb
276:40 - through all that data in one place
276:42 - whereas snmp is generally used as a
276:45 - protocol that you can pull data out of a
276:49 - server and do something with it like
276:51 - make cool graphs or whatever it is you
276:53 - want to do
276:54 - vpns might be something that you use
276:56 - every day but don't really understand
276:57 - what's going on so vpns or virtual
277:00 - private networks are really just a way
277:02 - to connect to a private network that
277:04 - isn't accessible from the internet
277:06 - itself now talk about the concepts then
277:08 - i want to talk about what options are
277:09 - available if you're using linux because
277:12 - vpn isn't just a one-size-fits-all thing
277:14 - there are several different protocols
277:16 - and stuff that you can use to connect
277:17 - but first of all conceptually what is
277:20 - going on well we have two networks let's
277:23 - say these networks are separated by
277:26 - being in different countries okay now
277:28 - you want to have this computer be able
277:30 - to interact with this computer or this
277:32 - server or something on the remote
277:34 - network but you don't want to open those
277:36 - ports up to the internet right because
277:38 - that's unsafe so what you do is your
277:41 - router or your linux server or something
277:43 - will establish what's called a tunnel
277:46 - and this tunnel is just a layer of
277:48 - encryption
277:50 - that goes from one side to the other and
277:52 - then inside that encrypted tunnel it
277:55 - just sets up a route like it would any
277:57 - other route on your network so your
277:59 - router just sees inside the tunnel and
278:01 - it sees a route using standard network
278:04 - addressing like let's say the vpn
278:07 - internal route is 10.10.0.5
278:12 - or something and it just sees this as
278:14 - another route so that this computer can
278:16 - route information across the tunnel to
278:19 - this router and then get into here so it
278:21 - works the same as traditional routing
278:23 - the only difference is the router or
278:26 - like i said the linux server or whatever
278:28 - it is sets up this tunnel that blocks
278:32 - anybody on the internet from actually
278:34 - seeing what's going on in the route so
278:36 - that tunnel is set up and then the route
278:38 - goes inside the tunnel so nobody sees
278:41 - the traffic now this setup that i have
278:43 - here is called a site to site vpn and
278:46 - what it means is since there is a
278:48 - standard route set up here anything on
278:51 - this network is going to be go is going
278:53 - to be able to go over here to this
278:54 - network and anything on this network is
278:57 - going to route over to this network as
278:59 - if they were in the same building it's
279:01 - just a standard route inside that
279:03 - encrypted tunnel now the other type of
279:05 - vpn is going to be just an end user
279:08 - connecting to an office and if if you're
279:10 - a remote worker or you're like a road
279:12 - warrior you're going to use this a lot
279:14 - your computer is going to establish the
279:16 - same type of tunnel to block all of the
279:19 - internal
279:20 - network traffic from the internet itself
279:23 - once it sets up that tunnel then just
279:25 - your computer is going to be connected
279:28 - to this internal network okay so you're
279:32 - actually going to as if you plugged into
279:34 - an ethernet port in the wall next to all
279:37 - of your other employees or your other
279:39 - fellow workers who happen to be in the
279:41 - headquarters so what this does is it
279:43 - puts your computer inside this local
279:46 - network by establishing a tunnel and
279:49 - then setting up routing protocols that
279:51 - will put you inside there so it's a
279:53 - little bit different than a site to site
279:55 - because these computers are probably not
279:58 - going to like serve data from your
280:00 - computer it's going to work a little bit
280:02 - differently but conceptually the same
280:04 - thing is happening your remote computer
280:06 - is now able to connect to computers
280:09 - inside the remote network and it's all
280:12 - protected from the internet by using a
280:14 - vpn now i talked about different
280:16 - protocols to do that and there are a
280:18 - bunch there's openvpn which is an open
280:21 - source program that allows you to
280:22 - establish these types of connections uh
280:25 - there's ssh which can establish a tunnel
280:27 - for you to do stuff there's l2
280:30 - tp there's ipsec there's all these
280:34 - different protocols and programs that
280:36 - will allow these tunnels to be created
280:38 - and a vast majority of these will
280:40 - actually run on a linux server inside
280:44 - the network so if your router itself
280:46 - doesn't support vpn that's okay you can
280:48 - port forward into a linux server and the
280:51 - linux server will handle all of the vpn
280:54 - routing now there are lots of nuances
280:56 - when it comes to vpn like can you only
280:58 - connect through the remote business can
281:00 - you connect to the internet and also to
281:02 - those things is all of your traffic
281:04 - routed through the vpn even if it's a
281:06 - slow link so there's a lot to think
281:08 - about when setting up vpns but once you
281:10 - understand what's going on it's a lot
281:12 - easier to plan how you're going to
281:13 - implement it so that it so that it can
281:16 - best serve your users or your multiple
281:19 - branch offices so they can communicate
281:20 - to each other i hope this has been
281:22 - informative for you and i'd like to
281:24 - thank you for viewing
281:25 - containers aren't really new technology
281:27 - they've been around for quite a while
281:29 - there have been options like lxc and
281:31 - you've probably heard of docker and also
281:34 - kubernetes comes into the mix which is
281:36 - actually like an orchestration tool that
281:38 - takes care of docker but while
281:39 - containers aren't new they are kind of
281:42 - the new kid on the block when it comes
281:43 - to devops and containerizing
281:45 - applications is something that's really
281:47 - really popular now conceptually they're
281:49 - a little bit like a virtual machine but
281:51 - they're they're different enough that
281:53 - it's important to understand the
281:54 - difference so let's say we have a
281:56 - traditional virtual machine which i'm
281:58 - going to say is the left-hand side of
281:59 - this slide so how it works is you have
282:01 - the the big computer you know and then
282:03 - that computer or that host has its own
282:06 - operating system and then on top of that
282:09 - we carve out a section of the host's cpu
282:13 - and memory
282:14 - and cards and hard drive space we carve
282:17 - that out and then on top of that we
282:18 - install another operating system inside
282:21 - this virtualized environment and then we
282:23 - can put applications on that now
282:25 - containers work in a different way they
282:28 - run right inside the host operating
282:30 - system so you just have an app
282:33 - running in another app running and
282:34 - another app running and this seems like
282:36 - the traditional server model right where
282:38 - you just install linux and then you
282:40 - install applications like apache on top
282:42 - of it the difference is with a
282:44 - containerized application they are
282:46 - running directly on the host computer
282:49 - but they have
282:50 - not really their own operating system
282:53 - all they have is like their own file
282:56 - system
282:57 - and they're jailed off or they're
282:59 - completely separate from the file system
283:02 - of the host operating system itself so
283:04 - they run in their own little world
283:08 - but they're still running directly on
283:10 - the operating system it's just like
283:12 - they're sectioned off in a little
283:14 - container
283:16 - but they're still running on the host
283:17 - operating system and that's really what
283:18 - makes them efficient you'll notice over
283:20 - here um yeah it's drawing it's not like
283:22 - the actual technology but it takes up a
283:24 - lot more hardware and and storage and
283:27 - slices of the host system itself if
283:29 - you're going to install an entire
283:32 - operating system on top of virtualized
283:35 - hardware it just you're not you can't
283:37 - put as many things on one host operating
283:39 - system plus you also have then this
283:42 - operating system to maintain along with
283:45 - this operating system these don't have
283:48 - their own operating system so you don't
283:49 - need to maintain anything except the
283:51 - application
283:53 - itself and it works really cool that
283:55 - jail system is neat so i want to show
283:56 - you how that works let's go actually
283:58 - over to a virtualized environment so
284:01 - here i am in i'm running ubuntu and i
284:03 - have docker installed so we're not going
284:06 - to get into how docker works there's a
284:08 - whole course on how docker works that i
284:10 - taught which is one of my favorite
284:11 - courses but first of all we're just
284:12 - going to start a docker container and
284:14 - we're going to put ourselves inside of
284:16 - it so this is just a little bit of free
284:18 - info we're going to say
284:19 - docker run dash it for interactive tty
284:24 - let's say we're going to run the ubuntu
284:25 - image and i want to run bin
284:28 - bash which is the shell command that i
284:30 - want to run so now boom it it was that
284:32 - fast right it created the container that
284:35 - quickly and i didn't like pause the
284:36 - video and wait for it it actually went
284:38 - that quickly and now we're inside this
284:41 - container which acts like its own
284:42 - operating system because remember it's
284:44 - jailed off but it's still running on the
284:46 - system and we can demonstrate that see
284:47 - i'm not i'm no longer on cbt docker now
284:49 - i'm on this internal container and we
284:52 - have our own file system but let's run a
284:53 - command in here we're going to run
284:55 - something that'll show up with cpu usage
284:57 - so i'm just going to say
284:58 - dd input file equals dev 0 i'll put file
285:02 - equals
285:04 - dev no and this is just something that's
285:06 - going to keep running keep running keep
285:07 - running and not really do anything
285:09 - except use up resources on the computer
285:11 - and i want to do that so we can come
285:13 - over to cbt docker here run the top
285:15 - command and even though this is now in
285:18 - its own container completely separate
285:20 - from cbt docker the operating system you
285:22 - can see look dd shows up as another
285:26 - command running inside this computer
285:28 - because even though it's separated in a
285:30 - container it's still using the same
285:33 - operating system the same kernel the
285:34 - same hardware that everything else along
285:37 - this system is it's just separated so it
285:39 - doesn't interfere and dependencies won't
285:41 - interfere with other apps it won't
285:42 - interfere with dependencies on the host
285:44 - system it's just super efficient so
285:46 - whether you're looking at lxc containers
285:49 - or docker containers which is what we
285:51 - looked at it's important to understand
285:52 - that containers are a lot like a virtual
285:55 - machine except they don't use all of
285:57 - that hardware and they don't completely
285:59 - section themselves off and most
286:00 - importantly they don't have their own
286:02 - operating system that's where containers
286:04 - make things much more efficient and much
286:06 - easier to deal with with much less
286:08 - overhead meaning you don't have to
286:09 - maintain the operating systems of
286:11 - individual apps
286:13 - it's really easy to confuse the concepts
286:15 - of clustering and load balancing because
286:18 - they kind of are the same it's kind of
286:20 - like the question is a hot dog a
286:22 - sandwich i mean they're both meat
286:23 - between bread but are they the same
286:25 - thing
286:26 - not exactly not quite but they both
286:28 - function similarly and that's what
286:30 - clustering and load balancing is like
286:32 - the difference is though clustering is
286:34 - an actual computer term for computers
286:37 - working together to do one task that can
286:39 - be split up whereas load balancing is
286:41 - more of an it concept that can be
286:43 - accomplished in the multiple ways so
286:45 - when we have a cluster basically we have
286:47 - a bunch of computers like we have here
286:49 - that are working together and then
286:50 - there's like a cluster manager it can be
286:52 - a computer it can be a software on you
286:54 - know one of the cluster computers but it
286:56 - actually keeps track of which computer
287:00 - in the cluster is doing what part of the
287:02 - task and these are designed to work
287:04 - together they know about each other
287:05 - these computers are a team and they
287:08 - really do well if susie here
287:11 - sends them a task that is designed to be
287:13 - broken up into multiple pieces so people
287:14 - can work on it at the same time so some
287:17 - jobs lend themselves to clustering
287:19 - solutions whereas some of them don't but
287:22 - basically they know about each other the
287:24 - cluster works together as a team to
287:26 - break down a bigger task into a bunch of
287:28 - smaller ones they can work on at the
287:29 - same time a load balancer like i said is
287:32 - more of a concept it load balances
287:34 - meaning it it has a big job and it
287:37 - splits that job up and lets different
287:39 - computers do the job but usually these
287:43 - computers don't know or care about each
287:46 - other at all they don't know each other
287:47 - exist the load balancer itself whether
287:50 - it's software or a hardware device
287:52 - it knows the entire big load that susie
287:55 - is sending to it and it splits it up and
287:58 - says okay she has 12 jobs so you do
288:01 - three jobs and you do three jobs and you
288:03 - do three jobs they don't know each other
288:05 - or doing jobs as far as the computers
288:07 - know there's only three jobs to do it's
288:09 - the load balancers job to keep track of
288:11 - everything so it's a little bit
288:12 - different they don't really work
288:13 - together they each work separately
288:16 - and accomplish a bigger task that the
288:18 - load balancer itself knows about now i
288:20 - said it's a concept it can work multiple
288:22 - ways right a very common way it's done
288:24 - is the load balancer will be in front of
288:26 - some web servers and there's a whole
288:28 - bunch of people that want to hit that
288:30 - web server and so the load balancer says
288:33 - okay you go to this one and now you go
288:36 - to this one and the next request will go
288:38 - to this one and it splits up the load so
288:40 - that one computer isn't doing all of the
288:42 - work now we can do that very simply on a
288:45 - linux machine if the linux machine is
288:47 - set up for round robin dns now this is
288:50 - not a great way to load balance just
288:52 - conceptually this is what it's going to
288:54 - do so here is my dns configuration on my
288:57 - network i have the domain name web it's
289:01 - actually set up for three different ip
289:03 - addresses okay so you'll see it's
289:05 - actually web web web but they have three
289:07 - different ip addresses and what my dns
289:09 - server is going to do is then round
289:10 - robin and it will split up the load
289:14 - between these three let me show you how
289:16 - that works here we are on the command
289:17 - line so i'm going to say ping web
289:20 - and we'll see we get the response from
289:22 - the web server notice the ip address
289:24 - here is
289:26 - 216-58192.238. if we do the exact same
289:29 - thing now
289:30 - boom if we get responses but notice it's
289:33 - sent it to a different computer together
289:35 - so we got these from another computer
289:38 - and if we do it again we'll get still
289:40 - that third one
289:41 - if we do it a fourth time it's going to
289:42 - wrap around and give us the first one
289:44 - again so this is technically a load
289:47 - balancer we're using dns round robin
289:49 - load balancing and it's conceptually
289:52 - splitting up the load of the pings so
289:54 - that each computer that is responding
289:56 - only gets a third of the requests so i
289:59 - guess it's fair to say that all
290:01 - clustering is load balancing but not all
290:04 - load balancing is technically clustering
290:06 - because clustering is a specific way
290:07 - that computers work together to
290:10 - accomplish a task now is a hot dog a
290:12 - sandwich i gotta leave that one up to
290:13 - you i have no idea but i hope this has
290:15 - been informative for you and i'd like to
290:17 - thank you for viewing cron jobs are
290:19 - pretty much the linux equivalent to like
290:21 - the task scheduler in windows now
290:23 - there's some really cool things that we
290:25 - need to understand and that's how to set
290:27 - up the scheduling which is kind of
290:28 - complicated but also very powerful and
290:31 - i'll be honest it's kind of fun the
290:33 - other thing i want to point out though
290:34 - is that there are pre-made folders that
290:36 - you can just drop scripts in and they
290:38 - will execute at a regular interval i'll
290:40 - show you those but first let's talk
290:41 - about how we set up the schedules
290:43 - because it can be intimidating but like
290:45 - i said it's not that bad and it's
290:47 - actually kind of fun so the scheduling
290:50 - fields which we'll look at in practice
290:52 - are separated into five different fields
290:54 - so we have minute hour day of the month
290:56 - month of the year and day of the week
290:59 - and how it works is for example this
291:02 - first line that i have has all asterisks
291:04 - and this means everything so every
291:06 - minute of every hour of every day of the
291:08 - month of every month of the year of
291:10 - every day of the week it's going to
291:11 - happen so this means every minute for
291:13 - all of eternity whatever task we
291:15 - schedule with this string is going to
291:18 - execute so every minute it's going to do
291:20 - whatever you tell it to do
291:22 - now there are some shortcuts we can use
291:24 - for example down here i have asterisk
291:26 - divided by five this means every five
291:29 - minutes now we could actually spell it
291:31 - out we could say zero comma five comma
291:33 - ten comma fifteen all the way to fifty
291:36 - five but i don't really like to do that
291:38 - because it's a big mess and you know one
291:40 - field would be this entire big string of
291:43 - numbers so rather than do that we can
291:45 - just say asterisk divided by five and
291:48 - this is going to be every five minutes
291:51 - during the third hour of the day so this
291:54 - means at am 305 a.m 3 10 a.m 3 15 a.m
291:58 - but once it gets to 4 a.m it's gonna
292:00 - stop doing it okay so this is during the
292:02 - third hour every five minutes every day
292:05 - of the month every month year every day
292:06 - of the week so this means every day it's
292:08 - going to do this but only between 3 a.m
292:10 - and 3 59 a.m and every five minutes okay
292:14 - now this one is very very very specific
292:16 - this says two minutes after the fourth
292:19 - hour so two and four means at 402 am
292:23 - on the 13th
292:25 - of july but only when that 13th of july
292:29 - lands on a tuesday the day of the week
292:31 - goes from zero to six so two is a
292:34 - tuesday right sunday is zero monday is
292:36 - one tuesday is two so this means every
292:39 - july 13th at 402 am if it happens to
292:43 - also be tuesday so this is only going to
292:46 - execute every few years when july 13th
292:49 - happens to land on a tuesday and then
292:50 - down here this one zero minutes after
292:53 - the hour so this means that six a.m
292:55 - precisely on
292:57 - every day of the month every month of
292:59 - the year
293:00 - days one through five so this means
293:02 - monday through friday at six a.m it's
293:05 - going to execute whatever task okay so
293:08 - this is basically the way of saying six
293:09 - a.m every weekday because we've
293:11 - specified one through five on the days
293:14 - of the week over here pretty cool right
293:16 - let's actually see how it works in
293:17 - practice now i'm on a centaurus system
293:19 - here and i'm root because we're talking
293:21 - about the system-wide cron jobs if we go
293:24 - into etcon.d
293:28 - we're going to see we have a few files
293:29 - in here now any file in here is going to
293:31 - be read by the cron daemon so let's
293:34 - actually look at one let's look at
293:36 - systat all right because this is already
293:38 - in there so we're going to look at
293:40 - systat and here we can see a couple
293:42 - things are scheduled here are the five
293:45 - fields that we just talked about so
293:46 - here's the first field so every 10
293:48 - minutes of every hour every day every
293:52 - month year every day of the week so this
293:54 - is going to be every 10 minutes it's
293:55 - going to execute
293:57 - as root so this field talks about what
294:00 - user it's going to run as and then the
294:02 - rest of it is what it's going to
294:04 - actually do so we have the five
294:06 - scheduling fields who it runs as and
294:09 - then the last part however long it is is
294:11 - what it's going to execute so down here
294:13 - these are commented out but let's
294:14 - pretend it's not this would be every
294:16 - hour at zero past right because this is
294:18 - like at one o'clock two o'clock three
294:21 - o'clock four o'clock it's going to run
294:22 - as root this command down here at 23
294:27 - which is 11 so 11 53 p.m
294:30 - every day see all these are asterisks so
294:32 - every day as root it's going to execute
294:35 - this so you can either add to any of
294:37 - these or really the best thing to do is
294:39 - create your own right just create a file
294:41 - and then put that scheduling the
294:43 - username and what you want it to execute
294:45 - and it will do that now the one other
294:47 - thing i wanted to mention really quick
294:48 - if you go back into
294:50 - the etc folder and let's do an ls and
294:52 - just
294:53 - look for
294:54 - cron we're going to see there are a
294:56 - bunch of folders in here there are cron
294:59 - daily cron hourly cron monthly cron
295:02 - weekly and if we go in there let's go
295:03 - into cron dot
295:05 - daily
295:07 - we're going to see these are just
295:09 - executable scripts these are not timed
295:12 - things right let's look at one real
295:13 - quick so vi log rotate notice there's no
295:16 - like startup star star star star star
295:18 - there's no scheduling in here this is
295:20 - just an executable script that we want
295:22 - to have
295:23 - execute every
295:25 - day
295:26 - so this is going to do the scheduling of
295:28 - everything in here once a day same with
295:30 - monthly same with hourly the kran deny
295:33 - is a way that we can tell a specific
295:35 - user that they're not allowed to use the
295:36 - kron daemon for personal use uh cron.d
295:39 - we looked at actually cron tab is a
295:41 - single file let's look at that one
295:42 - really quick that'll be our last thing
295:44 - etc
295:45 - cron
295:46 - tab and this is the same sort of thing
295:48 - we can put things in here if we want it
295:50 - even tells us like very specifically all
295:52 - the things the five fields the username
295:54 - we want it to run as and then the
295:56 - command to be executed this is the same
295:58 - thing as creating a file in the
296:00 - eccentric cron.d folder you can just add
296:02 - things here and they'll automatically
296:03 - execute now the pre-made folders are
296:05 - very convenient for dropping scripts in
296:07 - that you want to have execute every so
296:09 - often but really the coolest part about
296:11 - cron is just how flexible that
296:13 - scheduling system is and you can figure
296:15 - out how to do that by you know
296:17 - manipulating all of those different
296:19 - fields like we looked at in this slide
296:21 - here so i encourage you to just try to
296:22 - figure out how you would specify a
296:24 - particular time and you know just play
296:26 - with it it's a lot of fun to do
296:29 - when it comes to scheduling events you
296:31 - have a couple options as a personal end
296:33 - user on a linux account you can use
296:35 - crontab personal crontab which you
296:38 - invoke by typing crontab minus e or we
296:40 - can use the at daemon which is a one
296:42 - time thing it's not like for recurring
296:45 - events it's for events that happen just
296:47 - at a specific time so let's go right to
296:49 - the command line because it's not
296:51 - difficult to use either one and
296:52 - scheduling tasks is something that's
296:55 - really really nice to be able to do so
296:57 - here we are on a centos machine i'm
297:00 - logged in just as a user notice i'm not
297:02 - root and the first thing i want to do is
297:04 - look at my personal cron tab now this is
297:07 - a little bit different than a system
297:08 - wide crontab so first we type cron tab
297:11 - minus e and it's going to bring us into
297:14 - an editor okay and now this is my
297:16 - personal crown tab again it's not system
297:18 - wide and it's slightly different because
297:20 - i still have five fields if you're not
297:23 - familiar with the five fields look at
297:24 - the system-wide crontab nugget because
297:26 - it'll explain how this works but we have
297:29 - every 10 minutes of every hour of every
297:32 - day of every month of the year every day
297:34 - of the week so here we have every 10
297:36 - minutes it's going to do something now
297:37 - notice there's no field here that
297:40 - specifies the user in the system wide we
297:43 - have to specify what user it runs as but
297:45 - since this is my personal cron tab it
297:48 - obviously runs as me so we just have the
297:51 - five fields and then we have the command
297:54 - that we want to have it execute at the
297:56 - time scheduled here so what this what
297:58 - happens here is we have echo and this
298:00 - text string and append it to a file
298:02 - called homebob timetracker.log every 10
298:05 - minutes so every 10 minutes it should
298:06 - add a line to our field so let's see if
298:09 - this is actually running because it's
298:11 - been here a while
298:13 - let's quit here
298:14 - if we do ls we can see oh there is a
298:16 - file time tracker.log and if we look at
298:19 - it well sure enough it looks like about
298:20 - a half hour has gone by since i created
298:22 - that crontab entry and it's been adding
298:25 - to this file if we do ls minus l we can
298:28 - see the last time that was touched was
298:30 - at 18 10. so if we waited around until
298:33 - 1820 it would do the same thing again it
298:35 - would add another line to it so that's
298:38 - how you do a recurring event using a
298:40 - personal crontab now if you just have
298:42 - something you want to have execute one
298:44 - time let's clear the screen we can use
298:46 - the at daemon and first i'm going to do
298:49 - something really quickly so we'll say at
298:51 - and then can specify the time and this
298:54 - is what's nice it's very flexible we
298:56 - could say tomorrow we could say next
298:59 - week and it will interpret all of those
299:02 - different commands it uses a lot of
299:04 - fuzzy logic to figure out what you want
299:06 - i'm going to say at now plus one minute
299:10 - and then we're gonna get this at prompt
299:12 - which now allows us to execute something
299:15 - so i wanted to do echo
299:17 - this was a one off and i want to append
299:21 - that to home
299:23 - bob time tracker dot log press enter and
299:27 - now we could do another thing we could
299:29 - have like a whole list of things we
299:30 - wanted to do at now plus one minute but
299:33 - i'm just going to do control d
299:35 - and that will put it in queue so it says
299:37 - job4 is in queue and it's going to
299:39 - execute at 18 13. okay now if we type
299:42 - atq
299:44 - oh it already happened dog on it
299:47 - first of all let's look cat time tracker
299:50 - look at that it did it right it put it
299:51 - to the end of the file but i need to do
299:53 - another one so at now plus one minute
299:57 - again and i'm gonna say echo hello
300:01 - into
300:02 - home bob time tracker dot log ctrl d
300:07 - atq ah there we go okay did it in time
300:10 - so what this shows us is the queue of
300:12 - things that at is going to run so job
300:14 - number five is scheduled for thursday
300:16 - june 20th at 1814 and the user bob is
300:20 - who's doing it so if we keep pressing at
300:23 - q
300:23 - once the time rolls around it's going to
300:26 - execute that and then go away because
300:27 - it's a one-off right we could do
300:29 - multiple things we could say at tomorrow
300:32 - then i want to say echo
300:34 - test tomorrow i spelled it wrong but
300:37 - that's okay on home bob time tracker.log
300:41 - control d on a blank line now if we do
300:44 - at q we're going to see well look job 5
300:46 - executed but job 6 is going to wait
300:48 - until tomorrow and it does it the same
300:51 - time tomorrow so 24 hours from now and
300:54 - tomorrow at 18 14 it's going to do that
300:56 - command test tomorrow okay now let's say
300:59 - we don't want to do that we want to
301:00 - change our mind well then we can say at
301:02 - rm job six and now at q is gonna say
301:06 - there's no jobs because we've deleted
301:08 - job number six that was going to execute
301:10 - tomorrow but if we look at time tracker
301:12 - look at that sure enough hello was put
301:14 - there along with that this is the one
301:15 - off and if we wait around until the next
301:17 - 10 minutes pass our cron job is going to
301:19 - add another 10 minutes has passed on to
301:21 - the end of this file and that's how we
301:23 - can schedule things with crontab for a
301:25 - repeating task like these or just a
301:28 - one-off task like this by using the at
301:30 - daemon it's great to be able to do
301:32 - system-wide things using cron
301:35 - but i personally like the fact that you
301:37 - can do it as a personal end user using
301:40 - cron tab minus e and it's going to do it
301:43 - just as your user so you don't have to
301:45 - become root or worry about escalating
301:47 - privileges it's going to just execute it
301:49 - as you even if you're logged out same
301:51 - with the at daemon even if we're not
301:53 - logged in it's still going to execute it
301:55 - at the given time
301:57 - working with multiple processes on linux
302:00 - is really really easy because you can
302:01 - put them in the foreground or the
302:02 - background and interact with them
302:04 - however you want now there are some
302:05 - tools that may not seem intuitive at
302:08 - first but once you get the hang of using
302:10 - them they're really really easy and
302:11 - there's also some keystrokes that we're
302:13 - going to have to learn and a couple
302:15 - tricks that'll allow us to do things
302:16 - that we normally couldn't do so let's go
302:18 - right to the command line because this
302:20 - is the kind of stuff you have to
302:21 - experience in order to really understand
302:23 - so first of all i am on the command line
302:26 - and i'm going to show you how to put a
302:27 - process in the background now i'm just
302:29 - going to use a simple process called
302:31 - sleep the sleep command if you're not
302:32 - familiar with it it just pauses right so
302:34 - if we say sleep one it's going to sleep
302:36 - for one second and then it's going to be
302:37 - done so i'm going to say sleep for a
302:40 - whole bunch of seconds which will like i
302:41 - don't know that's probably a couple
302:42 - hours or something and then i'm going to
302:44 - put the ampersand after it now what's
302:47 - going to happen is notice it's done a
302:49 - number one and then this is the actual
302:52 - process number so our job number is one
302:54 - now we can do that with another one
302:56 - sleep two two two two two
302:58 - put that in the background and now we're
303:00 - gonna see we have job number two in the
303:01 - background with this process id and
303:03 - they're just running in the background
303:04 - if we type jobs we can see sure enough
303:07 - there they are there's sleep one one one
303:08 - there's sleep two two two job one and
303:10 - job two now if we want to start going
303:13 - and using one again like let's say we
303:14 - wanna bring one in the foreground we
303:16 - just type f g and then the job number so
303:19 - fg two and it's going to bring us it
303:22 - tells us what the command is that's
303:23 - running and here we are we're just at
303:25 - the command line here if we wanted to
303:26 - stop this we'd have to do control c it
303:28 - stopped that process and now if we do
303:30 - jobs see there's only the one job
303:32 - running it's actually really cool now
303:34 - what if we did a job like we did
303:36 - sleep
303:37 - 3333 and pressed enter and i'm like oh
303:41 - man i really wish that was in the
303:42 - background i didn't mean for it to just
303:44 - like hold my command prompt here well
303:46 - what we can do is do control z and it
303:50 - stops it and puts it in the background
303:52 - so see it says stopped if we type jobs
303:54 - we can see this first one that we did is
303:56 - still running but this one is stopped so
303:58 - if we want to make it run in the
304:00 - background we have to say
304:02 - b g for run in the background job number
304:05 - two
304:06 - and now if we do jobs we're gonna see
304:08 - now they're both running in the
304:10 - background so bg and then the job number
304:12 - will start that background task running
304:14 - fg will bring it out of the background
304:16 - and bring it right to our interactive
304:18 - terminal okay so that's kind of neat
304:20 - it's a way we can create them we can put
304:22 - them in the background if we've started
304:24 - them and we don't and we want to put
304:25 - them in the background just ctrl z will
304:27 - suspend it briefly and then we can tell
304:30 - it to go in the background by doing bg
304:32 - and then the job
304:34 - number so let's do foreground one i'm
304:37 - going to do control c
304:38 - foreground two control c and now jobs we
304:41 - have no more jobs running now there is a
304:44 - problem because if we have a job running
304:46 - in the background like i have a command
304:48 - here called my hello all right and all
304:50 - it does is every two seconds it prints
304:53 - hello on the screen
304:55 - all right so i'm gonna ctrl c what if i
304:57 - wanted to put my hello in the background
305:00 - and it's going to run in the background
305:02 - i was still going to put it out on the
305:03 - screen every hello but it's running in
305:04 - the background if we do exit it's still
305:07 - running in the background but the
305:08 - problem comes where if we log out
305:12 - and then we log back in
305:14 - we open a terminal window
305:16 - and we do a ps aux grip for my hello
305:21 - we're gonna see it's no longer running
305:23 - this is just actually the grep process
305:24 - that it actually found here but notice
305:26 - it's not running in the background
305:28 - anymore and if we wanted it to stay
305:30 - running just putting it in the
305:32 - background wouldn't work we'd have to
305:33 - use a program called no hup because
305:36 - here's the problem when we log out of
305:38 - the system up here it actually sends a
305:40 - hang up interrupt to all the running
305:42 - processes and the hang up or hup
305:46 - tells it to stop running well we can run
305:48 - a program by saying no hup which means
305:51 - don't hang up when the user logs out
305:53 - what program we want to run so my hello
305:56 - and then ampersand in the background
305:59 - it's going to put it in the background
306:00 - just like before we can see it jobs
306:02 - there it is running but it says it's
306:04 - ignoring the input and appending the
306:06 - output to nohup dot out all right so i'm
306:08 - going to exit i'm going to log out and
306:11 - then i'm going to log back in
306:15 - open up a terminal window
306:17 - i want to notice two things one if we do
306:18 - a ps minus aux grip for my hello it's
306:22 - still going to be running see here it is
306:24 - it's still running because we ran it
306:26 - with no hup but here's another cool
306:28 - thing if we do an ls see this nohup dot
306:30 - out let's look at that
306:32 - all of the output was put into that file
306:36 - so all of the hellos were put into that
306:38 - file so we know what's going on plus
306:40 - when we logged out it didn't stop
306:41 - running so not only is it really easy to
306:43 - handle processes when you're on the
306:45 - linux command line it's also possible to
306:47 - do a couple cool things like no hub if
306:49 - you want to make sure it doesn't quit
306:51 - when you log out and also control z of a
306:54 - running process which will put it in the
306:55 - background suspended and then you can
306:57 - run bg to make sure that it continues
306:59 - executing in the background
307:02 - finding specific information about local
307:04 - devices on your system can be a little
307:06 - bit challenging but thankfully there's a
307:08 - bunch of tools that will help us along
307:09 - the way d message is one that we can use
307:12 - that will kind of see how things are
307:13 - going in real time if you plug something
307:15 - in d message is going to show you the
307:17 - results of plugging that in but then
307:19 - there's a whole suite of ls tools if you
307:21 - will they start with ls it's ls usb
307:25 - lspci lsdev msblk ls cpu all of these
307:30 - tools are going to be able to be used to
307:33 - find out information about hardware on
307:35 - our system and there's a nice trick to
307:37 - remember these so that you don't have to
307:38 - actually remember pci dev blk cpu all of
307:41 - these different things so let's check
307:42 - that out and see if we can find the
307:44 - various hardware that is in our system
307:47 - you have to be root to use most of these
307:49 - some of these you can use as an end user
307:50 - but since we're going to be looking at
307:52 - all of them i became root just so that
307:54 - we get a better view of what's going on
307:56 - now first of all d message you just type
307:58 - d message on the command line and it's
308:00 - going to show you things as they happen
308:02 - and this is the location that we'll see
308:05 - things happen if we make changes to the
308:07 - system like if we plug in a usb drive or
308:10 - plug in a sata drive or something like
308:11 - that a new mouse it's going to show up
308:13 - here and it's going to give us
308:14 - information about the particular device
308:16 - but if something's already plugged in or
308:18 - you just want to see like what's built
308:20 - into the system that's where the ls
308:22 - tools come into play so let's clear the
308:24 - screen
308:25 - and what i like to do is just do ls and
308:27 - then hit tab a couple times and that's
308:30 - the trick because really tab completion
308:32 - is vital here there are so many of these
308:34 - commands now we know ls just means list
308:37 - like the file directory but they've used
308:39 - this same tool or the same keystrokes to
308:42 - prefix a bunch of commands like ls blk
308:46 - for example which will show us the block
308:48 - devices it will list the block devices
308:52 - on our system if we do that it's going
308:54 - to show us all of the block devices that
308:56 - we have like the floppy drive all of
308:58 - these are virtual loopback devices that
309:00 - were created down here these are our
309:02 - actual drives on our system sda we can
309:04 - see right here it's mounted on forward
309:06 - slash sda1 is then we have a bunch of
309:09 - other drives down here that aren't being
309:11 - used right now but they're all 10
309:12 - gigabytes in size we use those and we
309:14 - set up raid before but this shows us all
309:16 - of the block devices so if we do ls and
309:19 - hit tab a couple times again let's look
309:21 - at the next one we have ls block we have
309:23 - ls cpu
309:25 - now i actually really like this one
309:26 - because it will give you all of the
309:28 - information about the cpu in the system
309:31 - so we can here we can see here that it's
309:33 - a 64-bit processor little endian it's an
309:37 - intel
309:38 - it actually shows us the actual
309:40 - processor itself the model number it
309:42 - shows us the clock speed all sorts of
309:44 - stuff that we have vtx enabled so we can
309:47 - do virtualization and it shows us all of
309:50 - the awesome things that our cpu has
309:52 - including all the flags that it supports
309:55 - when we're compiling things anyway
309:56 - that's ls cpu if we hit ls and tab a
309:59 - couple times again i'm going to do this
310:00 - every time because it's the quickest way
310:02 - to see what's there we have lsdev i want
310:04 - to do this you have to be root to do
310:06 - this and what this shows us this might
310:08 - not be as useful as it was years and
310:10 - years ago and we would have to
310:11 - troubleshoot hardware more frequently
310:13 - but what this is going to show us is the
310:16 - the device like what device it is like
310:17 - our floppy disk our keyboard a pci port
310:20 - here and it's going to show us what
310:22 - direct memory access number it uses what
310:24 - dma what irq number it's using uh the io
310:28 - ports meaning like in memory what io
310:30 - parts of memory or what parts of memory
310:32 - is it using for i o and it will show us
310:34 - all these things now if we're trying to
310:35 - find conflicts on our system this might
310:37 - be useful but i'll be honest i've never
310:39 - once had to use this in practice it's
310:41 - important to know that it's there though
310:43 - lsdev will show you all the devices on
310:45 - the system now if you do ls tab tab
310:48 - one that i actually do use fairly often
310:50 - is
310:51 - lspci where is that up here lspci so oh
310:55 - pci will show us all the pci devices so
310:57 - here we have a vga compatible controller
311:00 - this is the acpi controller the ide
311:02 - controller
311:04 - so these are the pci devices that are
311:06 - plugged into our system uh we can do ls
311:10 - usb now i don't have anything plugged
311:12 - into our usb ports but if we did lsusb
311:15 - would show us what's there same thing ls
311:18 - pcmcia if you're a laptop user you might
311:20 - have things that show up if you type
311:22 - that and one last one we'll look at is
311:24 - ls mem and this will just give us the
311:26 - range of the memory and how it's being
311:28 - used and where it is in our system but
311:30 - really the big big pull away from this
311:32 - is ls tab tab and it'll show you all of
311:35 - the different ways that you can look at
311:37 - the devices on your system so whether
311:39 - you're trying to get an inventory of the
311:40 - things that are currently on your system
311:42 - or you want to see changes as they
311:43 - happen in real time there's some really
311:45 - simple built-in tools on our local linux
311:48 - machine for detecting and looking at
311:50 - specifics on devices
311:52 - you ever try to solve a problem only to
311:54 - make it worse yeah me too for example
311:57 - we had a wall with a nail in the wall
312:00 - and that nail would get loose after
312:02 - hanging stuff on the nail for a long
312:03 - time because it was just in the thin
312:05 - layer of drywall this nail just went
312:07 - into the drywall and then the more we
312:08 - hung stuff on it the more it got loose
312:10 - so i thought i would make things better
312:12 - by getting rid of the nail drilling a
312:14 - hole in the drywall and then getting one
312:16 - of those really nice hollow wall anchors
312:19 - that you could then put a nail or a
312:20 - screw into and it would be really nice
312:22 - and sturdy the problem is i drilled the
312:24 - hole way too big the hollow wall anchor
312:26 - didn't work at all and then i just had
312:27 - this gigantic hole in the wall that my
312:29 - wife was really upset about that's kind
312:32 - of what happened in the world of linux
312:34 - virtual file systems and let me tell you
312:36 - what i'm talking about here because the
312:38 - idea of virtual file systems has been
312:39 - around since the unix days basically
312:41 - it's a file system that's created when
312:43 - the system boots up and one of the
312:45 - really popular ones is called proc and
312:47 - what this was used for is process
312:49 - information like of running apps and
312:51 - running programs on the system they
312:53 - would store all of their runtime
312:55 - information in this virtual folder in
312:56 - memory called proc and then people said
312:59 - hey that's a really neat place to store
313:00 - things like process id number 181 for
313:03 - that application and 2 5 5 6 for that
313:06 - application what if we also put things
313:08 - about like the cpu in there or the
313:10 - network card in there and then people
313:12 - started adding things to the proc folder
313:14 - it started to get a little bit confusing
313:17 - and so we thought hey wouldn't it be a
313:19 - great idea if we separated all of that
313:22 - kernel information so that process
313:24 - information was stored in the proc
313:25 - folder and kernel information was stored
313:28 - in assist folder they're both virtual
313:31 - file systems that work the same way but
313:33 - some organizations seem to make a lot of
313:35 - sense right now the same thing with dev
313:37 - dev is a folder that we thought why
313:38 - don't we start putting things like
313:40 - information on different devices like
313:42 - hard drives or
313:44 - mouses mice mouse mice mouses anyway
313:48 - when we put those things into the dev
313:50 - folder oh here's the issue the proc
313:53 - folder had been around for a long time
313:54 - and it already had a mix of things in it
313:57 - so we said okay we'll keep all of those
313:59 - things and then we'll just put new
314:01 - things in the sys folder the problem is
314:03 - there's not that many new things so
314:04 - while the sys folder is very well
314:07 - maintained and very neat and organized
314:09 - it doesn't contain a lot of the things
314:11 - that we use on a daily basis because
314:12 - they were already in the proc file
314:14 - system and now they're there for
314:15 - backwards compatibility
314:17 - now that doesn't mean proc and sys are
314:19 - any less useful if we go into the proc
314:22 - folder and do an ls we're going to see
314:24 - here are all of those numbers these are
314:25 - the process ids that i talked about
314:27 - right and if we do like an ls of all the
314:30 - process id 47 inside here it's going to
314:32 - be all of the various things that this
314:35 - particular application is doing like
314:36 - it's it's memory io what's mounted uh
314:39 - the status all of the things about this
314:41 - running thing are in here so if you want
314:43 - to find out information about whatever
314:45 - process id number 47 is you can look at
314:48 - these various things but notice over
314:50 - here on the right hand side there's also
314:52 - a bunch of things that aren't process
314:54 - ids and that's where like mdstad mem
314:56 - info
314:58 - cpu info let's look at that so if we
315:00 - look at cpu info this is going to just
315:02 - be a complete breakdown of the cpu in
315:05 - the system right now that's running this
315:07 - is our current cpu which is really
315:09 - useful information but it might make
315:11 - more sense if it was over here in the
315:13 - sys folder because the sys folder is
315:16 - very well laid out right there's not a
315:17 - whole bunch of crud here this is laid
315:19 - out in very nice sections we could go
315:21 - into oh let's say the kernel folder and
315:24 - inside the kernel folder it's separated
315:26 - into various things about the kernel
315:28 - like the current configuration
315:30 - all of these things are nice and
315:31 - organized but it's not all inclusive
315:34 - meaning it doesn't contain a lot of the
315:36 - information if we scroll up that's still
315:38 - stored in the proc folder so here's how
315:41 - it ends up working a lot of the
315:42 - interactive stuff is going to be in the
315:44 - proc folder because it's always been
315:46 - there but a lot of the information about
315:48 - the running kernel is very organized
315:50 - well in the sys folder and that's where
315:52 - a lot of times programs will look if
315:54 - they want information about the current
315:56 - running kernel like do i work on this
315:57 - program well i don't know let's see you
315:59 - know information about hypervisor and
316:01 - kernel modules and all of those things
316:04 - it'll look in the cis folder so
316:05 - generally you'll find yourself in the
316:07 - proc folder more often all right now one
316:10 - other place that it's worth looking in
316:11 - is the dev folder and this just shows
316:14 - about system devices right these are
316:16 - hardware devices that are plugged into
316:18 - the system either like soldered in like
316:20 - the real-time clock or hardware-like
316:22 - hard drives that we put in here and this
316:24 - is going to be information binary
316:25 - information generally available to the
316:27 - system talking about the various bits of
316:30 - hardware that are plugged in now this is
316:32 - fairly well organized too and a lot of
316:34 - times programs will look here to find
316:36 - out information like hey is there
316:38 - hardware that is going to be compatible
316:39 - with my software well this is where it
316:41 - would look for hardware information so
316:44 - while it sounds like it's a big mess
316:45 - honestly it's not that bad there's three
316:47 - main places to look the proc folder
316:50 - which is what we see here the sys folder
316:52 - which we see here and then the dev
316:55 - folder which we see here all of them
316:57 - contain different information sys and
316:59 - proc have a little bit of crossover
317:01 - there's going to be some kernel
317:03 - information insist that's already living
317:05 - in the proc file system but if you're
317:07 - going to be interacting it's mostly
317:09 - going to be in the proc file system and
317:11 - applications are going to be hitting the
317:12 - sys file system pretty hard now i know
317:15 - that's a lot of information about linux
317:17 - virtual file systems the key takeaways
317:20 - are that we need to know information
317:21 - about the running kernel are going to be
317:23 - in generally one of three places in the
317:25 - virtual file system that happens when
317:27 - the computer boots up the proc file
317:29 - system the sys file system and the dev
317:31 - file system if you can look in all three
317:33 - of those places you're going to find
317:35 - what you're looking for but they might
317:37 - be spread out in places that don't make
317:38 - a whole lot of sense just because we
317:40 - keep things there for backwards
317:42 - compatibility i hope this has been
317:44 - informative for you and i'd like to
317:45 - thank you for viewing on a linux system
317:47 - the printing is going to be handled by
317:49 - cups which is common unix printing
317:52 - system which interestingly is actually
317:54 - owned by apple of all people but
317:55 - nonetheless this is what every modern
317:58 - linux distribution is going to use to
317:59 - handle the printing now the nice thing
318:01 - is there are some backwards
318:02 - compatibility command line tools so we
318:05 - can print things from the command line
318:07 - and if you don't have a gui to actually
318:09 - install the printer like if you don't
318:11 - have gnome or kde or anything like that
318:13 - installed you can use a really nice web
318:15 - interface that will allow you to
318:17 - interact with the cup system and install
318:19 - modify and do all the things you need to
318:21 - do to a printer but we're going to look
318:23 - at the web interface really quickly just
318:25 - to show you where it is and i want to
318:26 - show you how to use the command line
318:27 - tools so you can print from a command
318:30 - line system even if it's a headless
318:31 - system on a rack now i'm logged in here
318:34 - on my local ubuntu computer on my local
318:36 - network and you'll see up here i went to
318:38 - localhost
318:40 - port 631
318:42 - now that's important because cups
318:44 - listens for incoming connections on port
318:46 - 631 and if you go there it'll allow you
318:48 - to log in so you can do things like
318:50 - administration for example we are here
318:53 - and i have one printer installed we can
318:54 - click on it'll give us information about
318:57 - this particular printer called office
318:59 - underscore laser we can see it's a
319:01 - socket-based connection on this ip
319:03 - address on port 9100 and basically it's
319:06 - installed on the computer i actually
319:08 - installed it using the web interface
319:10 - instead of going into the gui on this
319:12 - computer and installing it with the
319:14 - ubuntu tools i used the web-based
319:16 - interface to make sure that it would be
319:18 - able to install correctly and it did
319:20 - once we're here we can actually do
319:22 - things you know from firefox like print
319:24 - the page but if we're on the command
319:26 - line things are a little bit different
319:28 - there are a couple tools that start with
319:29 - l p and if we hit lp and then hit tab a
319:32 - couple times for tab autocomplete we're
319:34 - going to see some of those here now
319:36 - they're not all things we're going to
319:37 - look at right now but mainly lpr
319:41 - is going to send commands to the printer
319:44 - lpq is going to show us the queue of
319:46 - things waiting to be printed so if we
319:48 - type lpq we're going to see office laser
319:50 - is our default printer it says it's
319:52 - ready but there are no entries meaning
319:53 - there's nothing that's currently being
319:55 - printed now we can use lpr to print
319:58 - things in a couple different ways we
320:00 - could actually just say echo this
320:03 - is a test
320:05 - and we can pipe that into the lpr
320:08 - command and if we look over here on my
320:10 - printer it's going to print this page
320:12 - right out
320:17 - and we can see sure enough it says this
320:19 - is a test so it'll do text just like
320:22 - that now we don't have to do line by
320:24 - line we can also do something like in my
320:26 - folder here i have a full file called my
320:28 - document so if we look at my document
320:31 - you can see it's just a string of text
320:33 - things and we can say
320:35 - lpr and then the name of the text file
320:38 - my document we'll print that and as it
320:40 - prints out on the page if we look at lpq
320:43 - we're going to see we have a job right
320:45 - here job number 10 is that we could use
320:47 - lprm if we're quick enough and get rid
320:49 - of job10 oh it's already completed but
320:51 - that is how we would delete a job that
320:53 - we had already sent so if there's a
320:54 - whole bunch of things queued up and
320:56 - something's wrong we can use lprm in
320:59 - order to fix it and if we come back over
321:01 - here we're gonna see sure enough it
321:02 - printed out that entire file for us
321:04 - right there on the page so it's really
321:06 - easy to print using the command line
321:08 - once it's set up with cups and
321:11 - thankfully cups is really easy to set up
321:13 - too because it's all web-based and that
321:16 - web interface honestly is very powerful
321:18 - we can use it to queue up jobs to stop
321:20 - jobs do test pages we can use cups for
321:23 - gui environment printing but the most
321:26 - important thing to realize is that we
321:28 - have access to the cup system by using
321:30 - the command line tools that are
321:32 - installed on our system
321:35 - udev is the user space device manager
321:38 - that has replaced dev fs and older linux
321:41 - systems now what's really cool is it
321:44 - uses sysfs which is a virtual file
321:46 - system that has information about the
321:48 - hardware and then it follows rules in
321:51 - order to keep devices with consistent
321:54 - names now what i mean by that is if
321:56 - you've ever had a linux system with
321:58 - multiple anything but we'll say hard
322:00 - drives the order that you used to put
322:02 - them in the system depended on the name
322:05 - they would get so the first one the
322:06 - system recognized would be sda then sdb
322:10 - and then sdc but on the next boot if
322:13 - they came up in like a different order
322:15 - while all of a sudden this one might be
322:17 - sda and this one would be sdb and this
322:20 - one might still be sdc and those are
322:23 - real pain in the butt so what udev does
322:25 - is it creates devices based on specifics
322:29 - with the hardware so it'll take its like
322:31 - uuid and it will create a solid
322:35 - consistent device that that's always
322:36 - going to be so if you put them in a
322:38 - different order or the buses come alive
322:40 - in a different order on boot they're
322:42 - still going to be the same devices which
322:44 - makes things a lot simpler when it comes
322:46 - to mounting drives and things like that
322:48 - now it also allows us to do some other
322:50 - things like create rules so first of all
322:53 - i want to show you some of the things
322:54 - you can do if you're root you have more
322:56 - access to do this so we're going to say
322:58 - u dev adm this is the administrator
323:01 - command that allows us to do some things
323:03 - with the udev system so the first thing
323:05 - i want to do is say udev info
323:08 - let's actually look at
323:11 - dev
323:12 - sr0 which is actually our dvd drive
323:16 - and it gives us all sorts of information
323:18 - specific to this drive so we'll see a
323:20 - couple things like let's scroll up we
323:22 - see this is n means the name so this is
323:25 - the name that it has assigned it this is
323:28 - the place in the pci device where it
323:29 - exists this is all the specific
323:31 - information about it and if we look
323:35 - lsdev
323:37 - grep sr0 we're going to see sure enough
323:40 - it's right in the dev folder sr0 it's
323:42 - dynamically created when it detects it
323:45 - and puts it in now sr0 is not terribly
323:48 - useful at least for me to recognize a
323:51 - hard drive or a dvd drive when it's in
323:53 - the system now i can see it mounted
323:55 - right here but that doesn't help me sr0
323:57 - doesn't mean dvd to me so we could do
323:59 - something like make a rule that creates
324:01 - a shortcut to it every time it
324:04 - recognizes it in the system so we're
324:06 - going to go into the etc udev rules.d
324:10 - folder and in here let's see what there
324:12 - is there's one called snap core rules
324:14 - but i'm going to create a new one i'm
324:16 - going to say vi
324:17 - we'll say number 10 so it loads it first
324:20 - sean.rules
324:22 - sean rules nice anyway it has to end in
324:24 - dot rules and then we're going to create
324:26 - our own rule now the format here is
324:28 - something that you just kind of have to
324:30 - get the hang of but the kernel is equal
324:33 - to
324:33 - sr0 meaning this is what the kernel
324:36 - knows the device as
324:38 - it's in the
324:39 - sub system
324:41 - is equal to
324:43 - block which it actually showed us when
324:45 - we did that command and then what i want
324:47 - to do is create a sim link and i want to
324:50 - call that sim link my underscore dvd
324:54 - okay so what we've done is created this
324:56 - rule anytime it has a device called sr0
324:58 - in the block subsystem meaning like a
325:00 - block device like a hard drive or a
325:02 - cd-rom i wanted to create a sim link
325:04 - called my dvd in the dev folder so i can
325:06 - reference it there instead of
325:08 - remembering sr0 so let's save this
325:12 - now we could reboot the computer or we
325:14 - could just do udev adm
325:17 - trigger
325:18 - okay and now if we go into the dev
325:20 - folder
325:21 - and we do an ls
325:23 - we should see in here
325:25 - look at that my dvd it's created that
325:28 - sim link to well in fact let's do ls
325:31 - minus l grab dvd
325:33 - my dvd is a link to sr0 it looks like
325:36 - there already was a dvd shortcut to sr0
325:40 - but we created a new one by making our
325:43 - own udev rule called my dvd and that's
325:45 - pointing to sr0 and we can use this when
325:48 - we're referencing the device in anything
325:50 - that we want like mounting and that sort
325:51 - of a thing and the cool part is this
325:53 - isn't just a sim link sitting on our
325:55 - system this is something that's going to
325:56 - be created every time the dvd is
325:59 - recognized
326:00 - and set up by the system so on boot even
326:03 - though the dev file system is a virtual
326:05 - file system it's always going to have
326:07 - that sim link my dvd pointing to sr0 now
326:10 - we just graze the surface of the things
326:12 - we can do with udev rules we can
326:15 - actually make things happen when certain
326:16 - usb drives are plugged in that sort of a
326:19 - thing but one of the key things i want
326:20 - you to take away is that it's really
326:22 - smart and it uses sysfs in order to know
326:26 - information about the drivers and
326:28 - everything else how it interacts with
326:30 - the kernel it uses the information in
326:32 - sysfs to create the entries in the dev
326:36 - folder i hope this has been informative
326:37 - for you and i'd like to thank you for
326:39 - viewing
326:45 - you