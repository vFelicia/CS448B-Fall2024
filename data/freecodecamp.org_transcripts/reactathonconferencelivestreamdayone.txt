00:02 - [Music]
00:12 - i know that you're starving for
00:14 - something you can't touch but you'll be
00:17 - honest with me right now
00:21 - there's something in the undercurrent i
00:24 - can feel it coming up don't you want to
00:27 - feel it
00:29 - [Music]
00:39 - [Music]
00:46 - [Music]
00:55 - [Music]
01:25 - don't you wanna feel it
01:27 - don't you wanna don't you wanna
01:46 - tell me that you wanna stay baby just
01:49 - don't walk away i need you now
01:53 - faded out
01:55 - all the time we spent alone fighting
01:58 - through the fires don't don't let me
02:00 - down
02:02 - i need you now cause i'm feeling worn
02:05 - out it's getting to me
02:08 - lost some heart trying to get on my feet
02:13 - caught in the madness i feel you somehow
02:17 - don't let me go
02:19 - i need you right now i wanna be next to
02:22 - you
02:23 - you wanna be next to me
02:26 - holding our paper hearts fading out
02:29 - broken dreams i wanna be
02:33 - next to me
02:38 - broken dreams
02:41 - [Music]
02:54 - uh
02:58 - [Music]
03:26 - tell me that you wanna stay baby just
03:30 - don't walk away
03:33 - [Applause]
03:35 - [Music]
03:35 - [Applause]
03:40 - don't let me down
03:42 - i need you now cause i'm feeling
03:46 - [Music]
03:58 - don't let me go i need you right now
04:02 - i wanna be next to you you wanna be next
04:05 - to
04:06 - [Music]
04:13 - you me be next to me
04:17 - [Music]
04:40 - you wanna be next to me
04:45 - [Music]
05:07 - [Music]
05:22 - held your hand
05:23 - [Music]
05:40 - [Music]
05:45 - [Music]
05:55 - i don't have a clue
05:57 - [Music]
06:19 - because i'm
06:24 - missing you
06:41 - because i miss blue
06:46 - i was chasing all the wrong sides
06:51 - trying to hold on to something that i
06:53 - couldn't find
06:59 - [Music]
07:14 - now
07:17 - [Music]
07:28 - don't
07:29 - [Music]
07:39 - because i'm missing
07:52 - because i'm missing you
07:57 - because i'm missing you
08:18 - is
08:22 - [Music]
08:27 - okay
08:30 - [Music]
08:42 - [Music]
08:50 - i was running
08:52 - to the
08:53 - [Music]
09:07 - on a saturday night i was doing
09:11 - just out on my own
09:17 - [Music]
09:31 - [Music]
09:38 - for me
09:42 - [Music]
09:54 - [Applause]
10:05 - hello everyone have you ever made a
10:07 - forum like this or maybe made an api
10:10 - request and then had an error like this
10:13 - turn up in your application later on
10:15 - down the track
10:16 - yeah i have and i've seen it plenty of
10:18 - time and it's a pain in the ass
10:20 - and you'll eventually end up like this
10:22 - guy just like annoying of these errors
10:23 - like ah just
10:25 - stop
10:26 - well
10:27 - there is a better way and
10:29 - by the end of this talk i'll promise my
10:31 - promise to you is that you'll know a
10:33 - little bit more about functional
10:34 - programming and in the library fpts
10:37 - and then where to go from here and where
10:38 - to learn more about it if you're
10:40 - interested
10:41 - so first let's look at an example
10:44 - this is a simple function which just
10:46 - goes to an api and downloads some data
10:49 - and returns it
10:50 - as a result
10:52 - um and i want you to look for a few uh
10:55 - errors or air places where this function
10:57 - can fail
10:58 - i'll wait
11:02 - i mean it's a simple function right all
11:04 - it does is it just saves some data and
11:06 - returns it well i see two areas for
11:09 - problems to arise firstly this
11:12 - i just blindly assign the result to a
11:14 - type assuming it's of a certain type uh
11:17 - i've seen this fail countless times
11:20 - um even when the api we can trust the
11:22 - api or whether it's our api stuff goes
11:25 - wrong somewhere so this this is bound to
11:27 - cause errors and then also secondly i
11:29 - have a bit of a problem with uh this
11:31 - return type promise
11:33 - this is more of a
11:35 - technical one but
11:37 - this function returns an error right and
11:39 - this promise doesn't really tell us
11:40 - whether or not this function returns an
11:42 - error so as a consumer of this function
11:45 - you either have to you know look into it
11:48 - and check
11:50 - and then go that way or just program
11:52 - defensively
11:53 - and so that means you have to assume
11:55 - that every promise can fail and by
11:58 - extension you like why do you stop at
11:59 - promises you have to assume that every
12:01 - function can fail and so are you just
12:02 - going to wrap
12:03 - try catches around every single uh
12:06 - every single function that happens
12:08 - um what if you look in this function you
12:10 - see it doesn't fail
12:12 - so you don't handle it and then down the
12:14 - track it gets changed um
12:17 - by by yourself or someone else or even
12:19 - it's a dependency you have no idea that
12:21 - this function change and it can now
12:22 - throw an error and then boom your
12:24 - application blows up to me this seems
12:26 - like a sub a sub optimal solution and i
12:29 - think we can do better
12:32 - so
12:33 - let's look a bit into
12:35 - uh before we look into the solution
12:36 - let's look a bit into functional
12:38 - programming and fpts and their pros and
12:40 - cons
12:41 - so
12:42 - the way i like to explain functional
12:44 - programming to someone who already has
12:46 - typescript knowledge
12:47 - is
12:48 - it kind of does the same
12:50 - for typescript as what typescript does
12:52 - to javascript so
12:54 - if you go from javascript to typescript
12:57 - you kind of get data contracts
12:59 - so
13:00 - this means that touchscreen says hey you
13:03 - know i'm going to handle making sure
13:05 - that all the data flows around your
13:07 - application correctly and that you know
13:09 - all these all these return types and
13:11 - parameter types and everything you set
13:13 - up they all match together perfectly i'm
13:15 - going to handle that for you and so you
13:17 - can lean on the
13:18 - the the compiler to to help you ensure
13:21 - that your data flows around correctly
13:23 - and then if something breaks it will
13:25 - tell you if you're a factor or something
13:28 - i see
13:29 - functional programming working the same
13:30 - way
13:31 - except with behavior
13:33 - so now no longer are you just encoding
13:35 - your how the data flows around your
13:37 - application but you're also encoding how
13:40 - the errors and the success states and
13:43 - how your app how your functions and
13:44 - applications actually behave you're
13:47 - encoding that into the type system and
13:50 - you can start to lean on the compiler to
13:52 - help you ensure that your
13:54 - your function
13:56 - your application kind of fits together
13:58 - these these behaviors fit together so if
14:00 - a function can throw an error you're
14:03 - forced to handle it you have to handle
14:04 - it and also lets you know if something
14:07 - changes or things like this in the
14:08 - future so it can be very very useful
14:10 - uh and set up with the right kind of
14:12 - framework it's not super cumbersome as
14:15 - we'll see
14:17 - and
14:18 - another thing i like to say about
14:19 - functional programming is let's let's
14:22 - you know
14:23 - often you'll be writing
14:25 - non-functional code so object oriented
14:27 - or something like this
14:28 - and you kind of will be adopting best
14:31 - practices uh having guidelines
14:34 - and you try to get your code to a good
14:36 - state and sometimes it can feel like
14:38 - you're pushing
14:40 - a ball up a hill
14:41 - so then when you actually get to
14:44 - the top of the hill
14:46 - it can feel like your your your code can
14:48 - kind of fall out of this happy state
14:49 - super easy
14:50 - if someone just doesn't follow the
14:52 - code guidelines or the you know some
14:55 - code review is missed like this ball can
14:57 - very easily roll off the top and you're
14:59 - back in a bad state where your code
15:01 - isn't correct or test testable or
15:04 - isolatable
15:05 - etc
15:06 - functional programming is often seen as
15:08 - a pit of success
15:10 - um because of how
15:14 - it
15:15 - forces you to architect your
15:16 - applications
15:18 - since it forces you to write your
15:19 - applications in a certain way and then
15:21 - it has the compiler to help you out
15:23 - it's
15:24 - seen as a lot easier to
15:27 - uh
15:28 - get your
15:30 - um your code into this pit of success
15:33 - where it's kind of harder to push to put
15:35 - to get out of it
15:37 - if you if you step outside the compiler
15:39 - says hey look that's not going to work
15:41 - buddy
15:42 - um
15:43 - and
15:44 - and it pushes you back into there
15:46 - there's you know there's no there's less
15:48 - room for error that's why it's called a
15:49 - pit of success
15:50 - and i believe there's actually three
15:52 - pits of success with um
15:55 - functional code
15:56 - uh
15:57 - isolation correctness and testability
16:00 - this talk will focus mostly on
16:02 - correctness
16:04 - but if you're looking for an explanation
16:05 - about other um
16:08 - other
16:10 - or even looking for an explanation about
16:12 - how
16:13 - uh function functional programming leads
16:15 - to the other pits of success check out
16:17 - this talk from mark seaman uh honestly
16:19 - it's really really good it's now long
16:21 - and his other talks are also amazing
16:23 - honestly let's go just go check it out
16:24 - it's great
16:26 - so on to fpts this is a library for
16:31 - typescript which implements functional
16:33 - programming
16:34 - it's written by a guy called giulio
16:35 - kenti uh it's been around for a while
16:38 - it's got 4.7 k stars so it's pretty
16:40 - um pretty stable and it has a an
16:42 - ecosystem of libraries which we will see
16:45 - later on
16:46 - some pros and cons in my eyes
16:49 - i think that
16:51 - functional code is more correct
16:55 - because of the
16:57 - the types and the and the behaviors and
16:59 - how it's encoded there's less code based
17:01 - just by design
17:03 - refactoring becomes easier because you
17:04 - can lean on the compiler to ensure your
17:06 - behavior and errors are handled
17:08 - correctly validation becomes easier as
17:10 - you'll see in this talk
17:12 - code becomes more isolated and thus
17:15 - becomes more testable
17:16 - on the downsides unfortunately
17:19 - typescript wasn't made for fp so the
17:20 - experience won't be quite as elegant as
17:23 - it is in
17:24 - languages like haskell or fsharp which
17:26 - are designed for
17:27 - functional programming but don't let
17:29 - this sway you i think it's still uh
17:32 - there are still benefits to be had but
17:34 - maybe if you're you know if you're sold
17:36 - in this function think you'll you'll
17:38 - switch to one of those languages in the
17:39 - future but it's i think it's nice to be
17:41 - able to to try it out in typescript
17:43 - anyway without having to change
17:45 - everything
17:46 - um
17:47 - and also in the same way that typescript
17:49 - isn't really recommended for super small
17:51 - projects this also isn't really
17:53 - recommended for super small projects um
17:55 - it's recommended for big projects
17:58 - because it helps you maintain projects
18:00 - over time
18:03 - and lastly uh my another downside is
18:05 - your qa team might not have any work to
18:07 - do so
18:08 - your manager might come to you and say
18:10 - hey man like give me some bugs so the qa
18:11 - team can like check them and you're like
18:13 - sorry dude got nothing
18:15 - imagine that not running any bugs
18:17 - well functional programming won't stop
18:19 - you writing all your bugs but they'll
18:21 - definitely help you stop writing some
18:24 - so
18:24 - let's look and look a little bit into
18:26 - how functional application is
18:28 - architected
18:30 - usually we have this kind of pure area
18:32 - where everything is nice and perfect and
18:34 - we have this impure layer which is the
18:36 - interface the outside world
18:38 - where your validation your side effects
18:40 - and so on happen and you have this
18:42 - little guard that stands there
18:44 - and let's look at what's a simple
18:46 - example of how we can kind of fix our
18:48 - problems from before
18:50 - so
18:50 - you probably already have this type for
18:52 - your
18:53 - api response
18:55 - and how we would do this with fpts and
18:58 - its system library iots if we would
19:01 - rewrite that type using iots iots is
19:04 - like a
19:05 - type system
19:07 - excuse me
19:10 - ots is a type system
19:12 - and we can just straight modify that
19:14 - across
19:15 - iots is really powerful it has lots of
19:18 - custom types you can define your own
19:19 - types honestly it's great
19:22 - and then
19:23 - we can also pull that touchscript type
19:25 - out at the bottom you see type i use it
19:27 - so we're pulling that pulling out an
19:28 - actual state the same type out of it uh
19:31 - in the end
19:33 - but what this allows us to do is that if
19:35 - we look at our function from before
19:37 - rewritten
19:38 - we have this user.decode function uh
19:42 - which now what it will do is it will go
19:44 - and check that whole api response and
19:47 - check every single key in value to make
19:48 - sure that
19:49 - that is as we expect
19:52 - um and you can use this all over the
19:54 - place in form validation api requests uh
19:58 - also on your back end is mostly where
20:00 - it's used um and it's great and you can
20:02 - now be certain when you
20:05 - uh
20:06 - use this in your application that it's
20:08 - going to be passed around perfectly then
20:10 - it will be perfect
20:12 - but if you write this
20:14 - you might hover over you might look at
20:15 - the user the user and see i wonder what
20:17 - type it is and it's
20:19 - turns out to be this either type you
20:20 - think uh what fred what is that
20:23 - well
20:24 - an either type is simply a type which
20:27 - can represent a failure or a success and
20:29 - the left is the failure the right is the
20:31 - success so in this case if there's an
20:33 - error right is would be user type
20:36 - um
20:37 - and how we kind of handle this in this
20:38 - example
20:40 - is we're just going to collapse that
20:41 - down to one value when we return it
20:43 - so
20:44 - we're going to fold
20:46 - how we do that we call this fold thing
20:48 - fold method we get from uh fpts we
20:50 - import from fpts and we fold the user
20:54 - down and we have we say what do we do
20:56 - when it's an error what do we do when
20:57 - it's a success whatever return
20:59 - so
21:00 - what this looks like written out is when
21:02 - it's a left an error we return a user
21:06 - not found error when it's the user we
21:08 - just return a user pretty simple and
21:10 - then
21:11 - this will return as a promise um to
21:14 - to the consumer
21:17 - now the second area i talked about
21:19 - before
21:20 - or um
21:21 - wanted to look at was the promise
21:23 - and i said that this doesn't really
21:25 - encode
21:26 - um doesn't really show that it's
21:28 - functioning an error
21:29 - well what would that look like with
21:31 - under functional programming
21:33 - well we had this eta type
21:35 - we could just say this function returns
21:37 - an ether
21:39 - so now we say this function either
21:40 - returns
21:41 - uh either a success that's either an
21:44 - error or a success which is an eye user
21:47 - so
21:48 - uh now we've kind of encoded into that
21:50 - function contract that this this
21:53 - function can error and so the consumers
21:57 - one they can see that it errors and two
21:59 - they're forced to handle it because of
22:00 - how functional programming um happens
22:03 - um but they
22:04 - and so what we what they do oh and what
22:07 - the function body looks like here is we
22:09 - can actually just return that
22:10 - that's either we get from the b code
22:14 - to the to the consumer to the parent
22:17 - and then you know if the thing is
22:20 - they're they're informed that there's
22:21 - this error but they don't have to handle
22:24 - it they can also keep passing it up um
22:26 - and they could just return like the
22:29 - result of this um
22:31 - function to their parent as well and so
22:32 - on and there's there's various uh
22:35 - ways that f various patterns that exist
22:38 - to help you do this in a pretty elegant
22:40 - way
22:42 - [Music]
22:43 - briefly want to show that there's a
22:44 - bunch of other types that exist in
22:46 - functional programming
22:48 - which have
22:49 - relationships to javascript and
22:51 - typescript um
22:56 - and
22:57 - there's even some types which kind of
22:58 - represent behaviors which don't even
23:00 - exist in javascript or typescript and so
23:02 - you can
23:03 - define your applications more
23:04 - expressively with with functional
23:07 - programming
23:09 - um
23:10 - but yeah that's that's been most of my
23:11 - talk if you're interested and you want
23:13 - to learn more i have a longer talk half
23:16 - an hour long where i really go uh
23:19 - somewhat in depth about how to build an
23:21 - actual functional application and what
23:23 - these kind of patterns look like and how
23:25 - they help you
23:26 - so go check it out um
23:29 - and then also there's this five-minute
23:31 - talk from robin mccorney when he talks a
23:33 - little bit similar to what i've done
23:36 - about form validation with fpts
23:40 - there's also these two libraries
23:43 - which
23:45 - might help you integrate
23:47 - fpts into your react
23:48 - application um
23:50 - and yeah
23:52 - i wanted to take a moment to thank my
23:54 - company imogex a sponsor of this
23:56 - conference for letting me put on this
23:58 - talk
23:59 - and
24:01 - personally i enjoy working imagex a lot
24:04 - they're
24:05 - a
24:06 - a great team and there's some good
24:08 - people on the team and
24:10 - everyone really knows their stuff
24:12 - and if you're interested in our service
24:15 - come check out our booth um and you'll
24:19 - get some account credit
24:21 - otherwise that's been my talk i'm pretty
24:23 - foggidy
24:24 - uh and i wish you all the best of you
24:26 - for the rest of your conference
24:28 - take care
24:32 - hi everybody
24:33 - i'm matt billman co-founder and ceo of
24:36 - netlify it's great to be back at the
24:39 - react-a-thon this time in this online
24:42 - virtual edition to talk about the jam
24:45 - stack architecture and netlify our
24:47 - end-to-end platform for managing modern
24:50 - web properties
24:52 - when we think about web properties 10
24:54 - years ago if i had gone to most
24:56 - designers and told them that today
25:00 - uh their mean design tool will no longer
25:03 - be a desktop application like photoshop
25:05 - and illustrator it'll just be a url they
25:08 - open in the browser they probably
25:10 - wouldn't have believed me but with tools
25:12 - like figma that's really becoming the
25:13 - case office suites coding environment
25:17 - the modern browser is an amazing
25:19 - powerful platform that we can build deep
25:22 - and engaging user experiences with
25:25 - but traditionally to build these we've
25:27 - had to manage provision
25:29 - operate tons of infrastructure database
25:32 - servers application servers web servers
25:35 - load balancers cdn distribution setting
25:38 - up caching rules to cash purchase
25:41 - invalidations all of this
25:43 - it's traditionally been a really complex
25:46 - system to operate web properties at
25:48 - scale
25:50 - this is one of the things that we've
25:52 - really worked to try to change with
25:54 - netlify and with jamstack as an
25:56 - architectural approach
25:58 - the idea behind both notifying the
26:01 - damstack is this idea of like how much
26:03 - can we pre-build up front instead of
26:06 - running this whole stack with all these
26:08 - complex servers all this infrastructure
26:11 - can we run a build step and then take
26:13 - the output as a pre-built web
26:15 - application a website and distribute it
26:18 - to a cdn with nodes all over the world
26:22 - and at nutify we really saw that if if
26:24 - we could do that we could also tie it
26:26 - into this git centric workflow that most
26:29 - of us as developers have already adopted
26:32 - working through branches pull requests
26:34 - commits and so on and just expecting
26:36 - that their deploys will flow to the edge
26:38 - from each of those we also quickly
26:40 - started seeing that content updates
26:43 - could be pulled in during build time
26:45 - from headless cmss like contentful or
26:47 - sanity or cosmic and deployed directly
26:50 - to the edge as well and build an
26:51 - orchestration system for tying all of
26:53 - that together the same even with data
26:56 - updates a lot of those can be accessed
26:58 - at build time pre-processed and deployed
27:01 - globally
27:03 - now
27:04 - this approach
27:05 - with the jam stack it's not just about
27:07 - like building static sites from
27:09 - different data sources and so on it's
27:11 - really about a mental model where we
27:12 - start reversing the traditional flow of
27:16 - a web request response cycle so
27:18 - with the traditional way we built web
27:21 - applications every request from the
27:23 - browser would go through this whole
27:24 - stack of a request and response cycle
27:27 - involving sometimes a cdn then passing
27:29 - through to a web server an application
27:31 - server that would then talk to all of
27:33 - our apis and services to our main
27:36 - database into our search cluster
27:38 - generate html and then send that html
27:42 - back to the browser
27:44 - now
27:45 - with the new sort of modern serverless
27:47 - world of course we can keep the exact
27:50 - same architecture we can run serverless
27:52 - functions that just connect to our apis
27:54 - and services to our database to our
27:55 - search cluster and send to respond back
27:58 - to back to the client and that's one way
28:01 - of of using serverless but it comes with
28:04 - all of the sort of traditional
28:05 - trade-offs of this architecture and the
28:07 - time it takes to go through this request
28:09 - response cycle
28:11 - with the jam stack approach we try to
28:13 - really shorten the distance to the user
28:16 - and sort of reverse the flow of the
28:18 - request response cycle so instead of
28:21 - having the browser talk to an
28:22 - application server they'll talk to an
28:24 - api on every request we try to just have
28:27 - our pre-compute step our build service
28:30 - that just talks to apis talk to
28:32 - databases talk to our search cluster
28:34 - pre-built as much as possible up front
28:37 - and then send it out in advance to each
28:39 - node and and this means that the actual
28:42 - request to from from the user's browser
28:45 - just hit an edge note get a pre-built
28:47 - html site and and we'll get a response
28:50 - to the user in milliseconds incredibly
28:53 - fast great user experience now of course
28:56 - we might still have a whole runtime we
28:58 - might be building an application like
29:00 - app.netlife.com
29:02 - that we can't completely pre-build up
29:04 - front
29:04 - um but there's no reason that we
29:06 - shouldn't just shorten the distance to
29:08 - the apis and services as well why go
29:11 - through that whole stack of cdns of load
29:14 - balancers of web servers application
29:16 - servers to talk to our apis and services
29:19 - if we can just do it straight from the
29:20 - browser all through the net its network
29:24 - this allows some of these services like
29:26 - algolia or fauna db or the like to in
29:29 - themselves be globally distributed and
29:31 - to the in themselves build really
29:32 - advanced hard to imitate caching
29:35 - infrastructures that will give the user
29:37 - incredibly fast response times
29:40 - now
29:41 - for this build step where we pre-built
29:43 - everything up front we've seen this
29:45 - whole movement of different frameworks
29:47 - and site generators emerge tools like
29:50 - 11c or scully for angular or next for
29:53 - vue
29:54 - hugo as a really fast scope-based
29:56 - generator and
29:58 - chapter grid sum next year is less like
30:01 - if if you go to jamstack.org you can
30:03 - find a massive list on them if we take
30:05 - next year's as an example it's become
30:07 - like a really important uh site
30:10 - generator tool
30:11 - and application framework for the for
30:14 - the react community
30:16 - it it allows you to group pages just
30:20 - based on on the convention
30:22 - and based on the name of your file it'll
30:25 - generate like a pre-built page that we
30:28 - can distribute directly to the edge at
30:30 - build time um you can
30:33 - fetch data at at build time through the
30:36 - git static props method and and
30:39 - we'll know that like we if you use
30:41 - netlife netlife's build system will run
30:43 - this it'll pre-build all the different
30:45 - urls and distribute them with an atomic
30:48 - deploy directly to the edge in handling
30:52 - all the all the assets
30:54 - now
30:55 - traditionally when we had web servers we
30:57 - didn't just use them to serve responses
30:59 - we also had a set of of like sort of
31:02 - typically declarative compute rules
31:04 - around like routing rules redirect rules
31:07 - rewrite rules and so on and on netlify
31:11 - we will we allow you to do all of these
31:13 - things directly at the edge as well
31:16 - through our netlife counterfeit format
31:19 - or our underscore redirects format again
31:22 - we really tie into this git centric
31:25 - workflow so it's this core idea that you
31:27 - can just add a file to your repository
31:29 - either in idlify tamil file or redirect
31:32 - file this is just a really simple
31:34 - example of a redirects file that just
31:36 - defines simple like 301 redirects from
31:39 - one destination to another this is an
31:42 - example of a terminal redirect that's a
31:44 - bit more complex that will say like
31:46 - if the language of the end user is set
31:49 - to english and the country is the united
31:52 - states
31:53 - then do this redirect and otherwise
31:56 - don't do it so we can build like complex
31:58 - localized version of our app and have
32:00 - the edge nodes directly handle this
32:02 - logic
32:04 - apart from distributing these pre-built
32:06 - html pages and running routing rules of
32:10 - course sometimes you also have to
32:11 - actually build custom api endpoint that
32:14 - that your front end can talk to
32:16 - sometimes you'll have services like
32:18 - stripe that you can talk to directly but
32:21 - often you might even even when you're
32:22 - talking to those need a secret and need
32:24 - something um that runs server side at
32:28 - netlify we've we've embraced this
32:29 - serverless paradigm in terms of
32:31 - serverless functions where you can just
32:33 - add a functions folder to your
32:35 - repository and every file there will be
32:38 - set up a with routing based on conveying
32:41 - conventions so in this example we just
32:44 - have a hello js they'll automatically
32:46 - respond under dot netlife function slash
32:50 - hello
32:52 - now if you're using
32:54 - next test you can also use these
32:56 - functions to actually go back to sort of
32:58 - the traditional server-side rendered
32:59 - approach just by saying get server-side
33:02 - props instead of get static props
33:05 - you do the same cycle talk to your data
33:07 - source
33:08 - but by marking this as as get server
33:11 - side props we'll actually like delegate
33:13 - this to a server side function that will
33:17 - generate the page you request on demand
33:21 - this comes of course with a lot of the
33:23 - same trade-offs that that we've had with
33:25 - traditional server-side architectures we
33:27 - can add layers of caching in front of it
33:30 - and so on um but when you can you should
33:32 - still try to see can we pre-build as
33:34 - much as possible upfront that'll always
33:37 - be the fastest the most secure
33:39 - and the most predictable
33:41 - sometimes you'll also need to run
33:44 - background processes
33:46 - in like let's let's take the
33:47 - subscription example you might
33:51 - have a have a function that's a quick
33:53 - api endpoint that adds a new
33:56 - subscriber to a plan but then
33:59 - once you do that you might do a bunch of
34:01 - steps you might send a new
34:03 - email you might add them to a marketing
34:06 - automation system and so on with netlify
34:09 - we have a concept called background
34:11 - functions and it's just as simple as
34:13 - serp as serverless functions you just
34:15 - append dash background to any function
34:18 - and now when you trigger it instead of
34:20 - immediately giving a response you'll
34:22 - just trigger a background process that
34:24 - can run up to 15 minutes great for
34:27 - scheduled tests or these kind of
34:28 - background operations that you do when
34:30 - something happens
34:32 - another really interesting aspect of
34:34 - this architecture is again like this
34:37 - edge layer where we just talked about
34:40 - routing right like
34:41 - language based versioning and so on
34:44 - we also just that netify introduced a
34:46 - new a new functionality that we talked
34:48 - about as edge handlers
34:50 - this is for when the declarative set of
34:53 - routing rules just don't cut it let's
34:55 - say you want to really build advanced
34:57 - personalization or authentication based
35:00 - on very detailed rules or you want to
35:03 - build api gateway-like functionality
35:05 - where you can route to authenticated
35:07 - services directly from the edge node
35:09 - with a netifies edge handlers you can
35:12 - simply add an edge handlers folder to to
35:15 - your git repository and start writing a
35:18 - handlers just let you just like you
35:20 - would write your
35:22 - serverless functions
35:25 - these can really intercept this request
35:28 - response cycle
35:29 - and you should typically use them for
35:31 - things that you can do within a few
35:33 - milliseconds again we don't want to go
35:35 - back to this old style architecture of
35:37 - everything being part of a very long
35:39 - request response cycle but for example
35:42 - let's say you just want to check an
35:44 - authorization header if someone access a
35:46 - secret part of your site and you want to
35:48 - do some custom logic in in in response
35:51 - to that this would be a little exchanger
35:53 - that you could write that that do this
35:55 - imagine you want to serve like a
35:57 - specific set of javascript a specific
36:00 - bundle of javascript
36:02 - to mobile browsers and another one to
36:04 - desktop browsers i don't recommend this
36:06 - but you would totally write an and an
36:09 - edge handler that would just look at the
36:10 - user agent and then decide which bundle
36:12 - version to serve in directly from the
36:15 - edge network
36:17 - so just to put these different pieces
36:19 - together like when you build with the
36:21 - jam stack and when you build on netlify
36:23 - the types of primitives we offer is
36:26 - first of all the pre-compute layer
36:27 - that's really our build service you can
36:29 - run a long process here that can stitch
36:32 - together hundreds of thousands of html
36:34 - pages and our service will push the ones
36:37 - that change directly to the edge and
36:39 - prepare them there
36:41 - these will deliver be delivered to the
36:43 - end user almost instantly and it's
36:45 - always sort of the fastest the most
36:47 - secure the most the the simplest to
36:50 - reason about that you can do
36:52 - then we have this layer of routing and
36:55 - transformations that split between like
36:58 - our declarative route engine in tunnel
37:00 - files so underscore redirects and then
37:02 - edge handlers where you can fully
37:04 - program the edge layer
37:07 - then there's the serverless functions
37:10 - that can run in a few seconds like
37:12 - typically great for api in point micro
37:14 - services or glue layer or even for
37:17 - server-side rendering like with get
37:19 - server-side props in next and then
37:22 - background functions for when you need
37:24 - compute that takes longer when you don't
37:26 - want to be trapped inside a request
37:28 - response cycle when you want to trigger
37:30 - a job and just run it in the background
37:32 - do actions
37:34 - and and trigger requests
37:36 - as you can see like at netlify we're
37:39 - really building out this whole platform
37:42 - around the jamstack architectural
37:43 - approach that makes it incredibly easy
37:46 - to write
37:47 - great user experiences with great
37:49 - performance without ever having to
37:52 - work with um
37:55 - operating servers maintaining
37:57 - infrastructure or thinking about complex
38:01 - deployment systems or pipelines
38:04 - you just work in kit you follow a few
38:06 - clear conventions and our platform will
38:09 - take care of all of the operations and
38:11 - infrastructure for you
38:13 - if you're interested specifically in in
38:15 - how we handle next year's is since this
38:18 - is so focused on react and next year's
38:20 - is of course really popular in the react
38:23 - world right now go to netlify.com slash
38:26 - with slash next years and reach read
38:28 - much more about it thank you so much
38:30 - have a great rest of the conference
38:36 - hi my name is max i'm a software
38:38 - engineer at flexport today i'll be
38:40 - talking about how we streamline mobile
38:41 - development using react native and expo
38:44 - there'll be four sections first some
38:46 - background
38:47 - then three deep dives into different
38:49 - areas where we're using these tools
38:51 - um to improve our development lifecycle
38:56 - so a little bit of context
38:58 - flexport is a freight forwarder we help
39:00 - facilitate the movement of large
39:02 - shipments of cargo across the world this
39:04 - is an example of an ocean container
39:06 - moving from an origin factory to a
39:08 - destination warehouse the section on the
39:10 - right with the green
39:11 - uh shows destination trucking and that's
39:13 - where our mobile app is being used this
39:15 - part of the shipment life cycle is
39:16 - really important for our customers
39:18 - because
39:18 - it's when their warehouses need to get
39:20 - ready to prepare to receive the cargo
39:23 - and then package it and send it out to
39:24 - customers of theirs
39:28 - so to help facilitate
39:29 - gathering data
39:31 - on this section of the lifecycle we
39:32 - built
39:33 - products called transmission
39:35 - transmission is a software suite that
39:37 - trucking carriers can use to manage
39:39 - their fleets internally as well as to
39:41 - provide updates to flexport and flexpose
39:43 - clients
39:44 - and so this mobile screen these mobile
39:47 - screenshots so what this is like for a
39:49 - driver or one of these trucking carriers
39:50 - they can enter a container number and
39:52 - then provide
39:53 - pickup and delivery events and then this
39:56 - data is useful both for flexport and
39:58 - also for the trucking carrier because
39:59 - the trucking carrier can see data like
40:01 - where their truckers are at a given time
40:03 - when they're due back
40:04 - things like that
40:07 - and so transmission is an important part
40:09 - of our ecosystem for managing
40:11 - destination trucking but i included this
40:14 - slide because i want to show that it's
40:15 - not the only thing that we're working on
40:16 - in this area so you can see that on the
40:18 - bottom
40:19 - containers are going from ocean ports
40:21 - sometimes to rail terminals and then
40:23 - filing to client warehouses
40:25 - we have a lot of different data sources
40:27 - including ocean carriers terminals api
40:30 - integrations we built apps for the
40:32 - warehouses
40:33 - and so we're doing a lot of different
40:34 - stuff to get this data and the mobile
40:36 - app is just one of the things we're
40:37 - doing
40:38 - and so
40:39 - this is one of the reasons we decided
40:41 - upon using react native is because we
40:42 - can increase the leverage of our team
40:44 - writing one code base in javascript that
40:46 - we're familiar with
40:47 - and deploying native mobile apps to both
40:50 - android and ios
40:51 - really really awesome
40:53 - expo
40:54 - allows us to make changes to these
40:56 - applications and deploy them to our
40:58 - clients phones
40:59 - without needing to
41:02 - make binaries and go through the app
41:04 - store approval process and things like
41:06 - that so it's much easier to add small
41:08 - features change copy fix bugs that sort
41:10 - of thing using exposed deployment
41:12 - lifecycle
41:14 - so we expected these benefits going in
41:16 - but the thing that we were surprised by
41:18 - is how much
41:20 - is possible to build on top of
41:23 - expo's um
41:25 - javascript bundle management system
41:28 - for our own internal tooling and so
41:30 - that's what these next three
41:32 - features we'll highlight so the first is
41:34 - the mobile sandbox
41:36 - so some context here is we have at
41:38 - flexport internally something called the
41:39 - web sandbox so here you can
41:42 - push a feature branch to get
41:45 - to github
41:46 - and then
41:48 - take your branch name put it into a
41:50 - sandbox tool
41:52 - and then launch a version of our web app
41:54 - running within obfuscated development
41:55 - database
41:57 - and uh
41:58 - but kind of fully functional
42:00 - and
42:01 - and then share share that with customers
42:04 - ems designers things like that
42:06 - um and get feedback on it before you
42:08 - merge into master so here you can see
42:09 - that this is a pull request from a few
42:11 - years ago it used to be called staging
42:13 - instead of sandbox but there's a url
42:15 - generated for your branch in particular
42:17 - that anyone can load
42:18 - internally on the vpn um to test things
42:21 - out so you wanted something similar like
42:23 - this for mobile
42:24 - but it turns out it's not a one-to-one
42:27 - mapping because with web
42:29 - there's a
42:30 - client code running in a browser right
42:32 - we have a wrapped front end and there's
42:33 - server code running on aws there's a
42:35 - rails back-end
42:36 - and so when we push the sandbox for web
42:38 - code we just push
42:40 - the front end and back-end code to a
42:42 - single server and then when the client
42:44 - code running in the browser fetches the
42:45 - javascript bundle to run the web app
42:47 - it's fetching the code from your branch
42:51 - but
42:52 - with mobile
42:53 - the react native front end code isn't
42:55 - coming from our backend it's coming from
42:57 - the mobile app stores in the form of
42:59 - downloaded app binaries as well as from
43:01 - expo's bundle servers where expo is
43:02 - sending javascript bundles to the phones
43:05 - to change behavior on the phones and
43:07 - that's where most of our business logic
43:08 - is leading
43:09 - and so
43:10 - if we want to create something like a
43:12 - sandbox
43:13 - we it's insufficient to just push the
43:15 - front end code to the same server as the
43:17 - back end code so we ended up doing is
43:19 - using exposed servers and creating
43:21 - different release versions of the app
43:24 - for each sandbox that makes it possible
43:26 - to replicate the sandbox experience on
43:29 - um
43:30 - on mobile
43:31 - and so the code is something like this
43:33 - it's like hey deploy the sandbox
43:35 - um
43:36 - set this mobile app to talk to this
43:38 - particular sandbox back-end
43:40 - publish the mobile app
43:42 - and then
43:43 - you can see that's just standard we're
43:45 - just running the standard expo cli
43:48 - commands but we're doing it in kind of a
43:49 - programmatic way
43:51 - and so the experience from a developer's
43:53 - perspective is you can just check this
43:54 - box i want a mobile
43:56 - sandbox
43:57 - and then you'll get a link to expo and
44:00 - you can paste the qr code into your pull
44:02 - request your designer or pm can review
44:04 - it there
44:05 - so really cool feature and it's just
44:07 - something we were very we were able to
44:09 - build on top of xbox javascript bundles
44:13 - automatic deployment so
44:15 - for web we have continuous deployment
44:17 - every time we commit to master we're
44:20 - taking off the deploy pipeline um
44:23 - we wanted something similar for mobile
44:25 - um
44:26 - we built one
44:28 - so we have two versions of the operating
44:29 - one is production and one is release
44:31 - candidate and so the release candidate
44:33 - one
44:34 - is these are this is unlike the sandbox
44:36 - in the sandbox we're just using separate
44:39 - um release
44:41 - channels within the same expo project
44:42 - but here we actually have two server
44:43 - expo projects two separate app binaries
44:46 - two separate listings in the stores we
44:48 - actually have four store listings total
44:50 - um android and ios and then prod and our
44:53 - prod and rc for each of those
44:55 - and so our continuous deployment
44:57 - pipeline every hour is cutting
44:59 - master building the javascript bundle
45:01 - pushing it to expo and then for
45:03 - production we're using a similar
45:05 - code path but you have to click the
45:07 - button to do it just because we don't
45:08 - want to be doing that
45:10 - every time there's a commit
45:14 - and so
45:15 - the architecture here is like we have
45:17 - you can have a phone
45:19 - running both the prod app and the rc app
45:21 - because there's separate listings in the
45:22 - app store
45:23 - and then get updates independently
45:26 - and they are both they're both talking
45:27 - to the rails backing so it's production
45:29 - light in that sense
45:32 - so the code for this is you know running
45:34 - in our in our deployment pipeline and
45:37 - it's it's similar so build the mobile
45:39 - app publish the expo you'll notice the
45:41 - release channel is default here
45:44 - and then we persist the app manifest
45:45 - i'll talk more about that in a second
45:47 - but first i want to talk about why the
45:48 - release channel is default
45:50 - that's because in our code base in
45:51 - master
45:53 - the
45:54 - javascript uh the configuration of the
45:56 - expo app is for the release candidate so
45:58 - this is what the source code looks like
46:00 - everything is released candidate
46:02 - and so
46:03 - the default release candidate release
46:05 - channel for expo is the thing that has
46:07 - our javascript code for
46:09 - so when we push to production the code
46:11 - is a little bit different we send some
46:13 - slack alerts which are useful and then
46:15 - we set production values in app.json
46:17 - that basically takes the master code you
46:19 - see here
46:20 - and then replaces release candidate with
46:22 - production so this way we have one
46:24 - version of our app.json checked into
46:26 - master no one is ever manually editing
46:29 - this or trying to keep it in sync
46:30 - between release candidate and production
46:32 - instead as part of our build pipeline we
46:34 - programmatically update the values into
46:36 - app.json and then we build the app
46:39 - push it to
46:40 - the default release channel for the slug
46:43 - transmission production in this case
46:45 - and then persist the out manifest and so
46:47 - this is it just feels very clean and
46:49 - there's only one way to push to
46:50 - production and that's using our built-in
46:51 - pipeline and it does these things in a
46:53 - programmatic way so there's no risk of
46:56 - manual messing up
46:59 - so the mobile app manifest has data
47:01 - about the version that was pushed to
47:02 - expo and we persist this in our database
47:06 - and i'll talk about why that's useful in
47:07 - a second
47:08 - so here's a quick screenshot of the um
47:11 - slack notification
47:14 - so what do we do with the persisted data
47:16 - we prompt users to upgrade so we can ask
47:18 - users hey
47:20 - um
47:22 - your app is out of date please upgrade
47:24 - and it's kind of an optional thing they
47:25 - can still use the app but there's a
47:27 - spanner up top
47:28 - or if we are like
47:30 - really you know we see a bug in a
47:32 - previous version or there's some new
47:33 - functionality that we really need all
47:34 - users to have
47:36 - we can block access to the app and say
47:38 - hey you have to upgrade this to keep
47:39 - using it
47:41 - and so here's some of the code in our
47:43 - configuration for this
47:45 - and then we prompt users to do upgrading
47:49 - and we can prompt not only to upgrade
47:51 - binaries but also to prompt update the
47:52 - javascript bundles if it's just like a
47:54 - lightweight refresh so in that case a
47:56 - user can tap this thing
47:58 - tap the red banner it'll just refresh
48:00 - the app they'll get the latest
48:01 - javascript bundle good to go
48:03 - um
48:04 - and
48:04 - so all of this stuff was just very easy
48:07 - to layer on top of expo's manifest
48:09 - system
48:10 - and so
48:12 - hopefully this is useful to others uh we
48:14 - really like using these tools check out
48:15 - this blog post if you have any questions
48:17 - i want to give a shout out to some of my
48:18 - teammates derek and yongfu for helping
48:20 - to work on these features
48:22 - thanks
48:25 - [Music]
48:45 - i was waking up
48:47 - [Music]
48:53 - the rest of my life
48:58 - [Music]
49:03 - to see
49:05 - [Music]
49:47 - [Music]
49:50 - nothing else matters on great days
49:54 - [Music]
50:05 - i've been waiting all day to let you
50:10 - i want to stay know forever
50:14 - [Music]
50:42 - is
50:48 - [Music]
50:59 - [Music]
51:10 - [Music]
51:13 - the space between us
51:17 - [Applause]
51:17 - [Music]
51:23 - is
51:25 - [Music]
51:46 - [Music]
52:20 - hi everyone
52:21 - my name is benjamin dunphy and i'm the
52:24 - organizer of
52:26 - react-a-thon and i just wanted to
52:28 - personally welcome you to react-a-thon
52:31 - online worldwide
52:33 - you know
52:34 - when i started react-a-thon back in
52:37 - 2017
52:39 - i could have
52:40 - never imagined
52:42 - the amazing community we would have
52:44 - built
52:46 - and i also could not have imagined
52:49 - what has happened here in 2020
52:53 - and so i want to thank you
52:56 - for
52:58 - your understanding
53:00 - for your patience
53:03 - and for your trust
53:06 - as we move this event
53:08 - online
53:09 - to a remote worldwide safe
53:13 - atmosphere
53:14 - as we wait the next
53:16 - in-person event where we can all
53:19 - come together
53:20 - until then
53:22 - please enjoy react-a-thon online
53:26 - worldwide 2020.
53:29 - have a great conference everyone
53:32 - [Music]
53:37 - [Music]
53:48 - [Music]
54:02 - [Music]
54:18 - [Music]
54:56 - [Music]
55:04 - hello everyone
55:07 - welcome welcome welcome
55:11 - we're here we're worldwide we are coming
55:14 - at you through the interwebs
55:16 - and we are so excited to be here with
55:18 - you today my name is anjana vakil i'm
55:21 - going to be one of your mcs for the next
55:23 - few days i'm a software developer and
55:26 - developer advocate at observable really
55:28 - excited to be here uh coming at you from
55:31 - san francisco today
55:34 - jonathan oh i'm sorry
55:37 - we've got a little bit of a
55:39 - tiny delay i think because i'm in
55:41 - tennessee uh so we have just that little
55:43 - bit of latency so you might see that
55:46 - amongst other things my name is jonathan
55:47 - catrell
55:48 - i am a director of engineering at pbs i
55:52 - am also the host of a podcast called
55:54 - developer t
55:55 - and i will also be an emcee over the
55:58 - next couple of days we're very excited
56:01 - for everything that's getting ready to
56:03 - happen
56:04 - you know this has been a difficult year
56:06 - for everybody probably everybody who's
56:08 - connected to uh to the to the conference
56:11 - today has their own story about 2020 and
56:16 - uh it's been a unique year it's it's
56:18 - come with its challenges challenges
56:20 - always make us better but we're not
56:22 - going to focus on the challenges for
56:24 - this
56:24 - for this conference instead we're going
56:26 - to focus on kind of geeking out together
56:29 - about react and uh the various kind of
56:32 - things around the react world
56:35 - and there are people around the world
56:37 - who are connected
56:38 - to this conference today and we're
56:40 - really excited about it
56:42 - yeah
56:43 - we are super excited to have you all
56:45 - here with us today we are also really
56:47 - grateful to the sponsors that make this
56:50 - event the next few days possible so we
56:53 - just want to give a huge shout out and
56:54 - thank you to our sponsors flexport
56:57 - course hero
56:58 - imagex verso
57:00 - off xero hasera vonage netlify and mux
57:05 - thank you so much
57:08 - and if you didn't get a chance to hang
57:10 - out with our sponsors already at their
57:11 - expo boost this morning you'll have
57:13 - other opportunities to do so
57:15 - this afternoon and over the next two
57:17 - days we encourage you to go and learn
57:18 - from them and uh it's it's not just
57:21 - because they're the sponsors and we want
57:23 - them to be happy with us as a conference
57:25 - is because they have some of the world's
57:27 - top engineers uh and and some of the
57:30 - hottest companies in the bay area but
57:31 - also with remote work uh around the
57:34 - world so make sure you go and check
57:36 - those out by the way we're on a platform
57:39 - called hop in
57:40 - uh this is a a new way of doing uh
57:44 - conferences for a lot of us but i
57:46 - encourage you to go and click around a
57:47 - little bit there's a lot to learn
57:49 - uh about hop in i guess there's not a
57:51 - lot to learn there's a lot to explore i
57:53 - guess is a better way to put it it's
57:55 - pretty easy to use
57:56 - but certainly don't sit back if you're
57:59 - just sitting back and watching the talks
58:01 - you're not going to get all that you can
58:02 - out of this conference
58:04 - there's a lot that we can and we'll talk
58:06 - about it a little bit more in the kind
58:08 - of interim between the talks as well and
58:11 - you know suggest that you go to certain
58:12 - parts of hop-in but definitely go and
58:14 - check out those uh sponsor expos
58:18 - yeah absolutely and again we are all
58:21 - really excited to have you all here with
58:23 - us uh virtually with us in hoppin the
58:27 - really great thing about hopin is that
58:28 - it allows us all attendees at the
58:31 - conference speakers mcs everybody around
58:33 - the uh react-a-thon world to be able to
58:36 - connect and get to know each other and
58:38 - there's even some cool features you can
58:40 - explore like to be randomly paired uh to
58:42 - meet somebody just like you would maybe
58:44 - bumping into them at a sponsor booth or
58:46 - uh in line for the bathroom between the
58:49 - talks at a
58:50 - irl conference so we're hoping that
58:52 - hopit allows us to all connect in the
58:54 - best way that we can uh given the
58:57 - virtual constraints of our environment
58:59 - here so really really thankful to all of
59:01 - you who are here with us today
59:04 - whether you're joining us live in hopin
59:06 - or whether you're tuning in through the
59:08 - live stream hello
59:10 - and we are super super grateful
59:12 - especially to everybody who was planning
59:13 - to attend react-a-thon in san francisco
59:15 - back in march i know i was and has been
59:18 - waiting the better part of a year uh for
59:20 - this uh really exciting new addition to
59:24 - happen so we could not be more thrilled
59:26 - to have everybody here together today
59:28 - in the constraints of our virtual world
59:31 - but we do need to keep in mind that we
59:32 - are still all in a community so jonathan
59:35 - is going to give us a special update
59:37 - about uh
59:38 - how we can be mindful of each other's
59:40 - experience
59:42 - yeah there's there's an excellent
59:45 - way that we can kind of come together
59:48 - and uh and hold each other accountable
59:50 - and that's a code of conduct you know
59:52 - it's a very explicit thing that we have
59:54 - in real life conferences and this is no
59:56 - different we want to respect each other
59:58 - whether we're behind a screen or not so
60:01 - there is a code of conduct the tldr is
60:04 - please be considerate respectful and
60:07 - take responsibility for your actions
60:09 - and please read the full code of conduct
60:11 - at
60:12 - reactathon.com conduct
60:16 - yeah and we want to make sure that this
60:18 - just like an in-person conference would
60:20 - be that this is a really safe welcoming
60:23 - learning focused environment uh for
60:25 - everyone so in that interest we want to
60:28 - make sure that if anyone if you ever
60:31 - feel unsafe harassed
60:34 - or someone is trolling or otherwise
60:36 - making your conference experience
60:38 - unpleasant or unsafe you can reach out
60:41 - to the organizer so that we can
60:44 - act on that so if you find someone is
60:48 - harassing you or making your experience
60:49 - unsafe in hop in there's actually a
60:52 - feature you can click on their profile
60:55 - and you would have an option to report
60:57 - user when you do that the conference
60:59 - organizers will receive a report which
61:01 - then they can investigate and take the
61:03 - necessary actions as per the code of
61:05 - conduct so once again please make sure
61:07 - to check out the code of conduct at
61:09 - reactathon.com
61:11 - conduct
61:13 - and here's the great thing we have three
61:15 - days of content
61:17 - three days of amazing content and
61:19 - networking learning education it's all
61:21 - planned for you
61:22 - and each of these uh days follow a
61:24 - similar format that anjana is going to
61:26 - talk about
61:28 - yeah so as you uh have already seen
61:30 - we're going to start out the day with
61:32 - some morning workshops and then a
61:34 - sponsor expo we're going to hear a
61:35 - little bit some from some sponsors and
61:37 - there'll be time for everybody to reach
61:39 - out to each other and do some networking
61:41 - on the hop-in platform also talk to the
61:43 - sponsors visit their booths all that
61:45 - good stuff and just get yourself really
61:47 - excited for the rest of the day which is
61:50 - going to consist of some stage talks on
61:52 - the morning and jonathan and i will be
61:54 - here with you on the stage uh for all
61:57 - three days uh to to guide us all through
61:59 - it
62:00 - and we will also have following those
62:02 - stage talks we will have 90-minute topic
62:05 - table sessions with experts and speakers
62:08 - and folks who you can connect with more
62:10 - directly around specific topics of
62:13 - interest
62:14 - then at the end of the day we're going
62:15 - to cap things off with another hour of
62:17 - some stage talks to really make sure
62:19 - that our brains are chock full of new
62:21 - ideas and exciting information uh when
62:24 - we leave at the end of the day
62:27 - so that is what our next few days are
62:28 - gonna look like but jonathan i think
62:31 - we've been yapping and we should just uh
62:32 - you know get this show on the road as
62:34 - they say what do you think yeah it's
62:36 - time to hand time to hand the stage over
62:39 - to our first
62:41 - guest for the day
62:42 - guillermo rauch uh guillermo is the
62:44 - founder and ceo of versailles uh he is
62:48 - uh the co-creator of now uh if you've
62:50 - ever used now if you haven't it was
62:52 - pretty awesome uh and next js and former
62:55 - cto and the co-founder of learn boost
62:57 - and cloud up acquired by wordpress in
62:59 - 2013
63:00 - he created the first mongodb orm for
63:03 - node.js
63:05 - uh and mongoose.js before that he was a
63:08 - core developer of the mootools
63:10 - javascript framework that's a throwback
63:12 - if there ever was one and he's been
63:14 - working on react since its early days
63:17 - all right and and here's the cool thing
63:19 - he's gonna share with you a post jam
63:21 - stack uh talk today uh the post jam
63:24 - stack world and the rise of hybrid
63:28 - frameworks yes so please join us in
63:31 - welcoming guillermo rauch for the
63:33 - opening keynote of react-a-thon
63:34 - worldwide
63:39 - hello everybody uh this is guillermo and
63:42 - i'm really excited to be here with you
63:43 - today hope you're all staying safe
63:45 - i'm here to talk about today about the
63:48 - post gemstock world
63:50 - and what that entails and the rise of
63:54 - uh hybrid frameworks like
63:56 - nexjs
64:03 - so
64:04 - i like to start by contextualizing kind
64:07 - of uh
64:08 - the state that we're in today and the
64:10 - problems that we're solving and perhaps
64:12 - starting with a little bit of a green
64:13 - message but
64:15 - later on turns really optimistic i
64:17 - promise which is that the web is in
64:19 - jeopardy
64:21 - and
64:22 - to illustrate that i look back to 2018
64:26 - uh really interesting tweet that i
64:28 - have since kind of memorized almost
64:31 - which talks about
64:33 - the this website usa today
64:35 - and this gentleman gentlemen marcel went
64:38 - ahead and did a before and after
64:40 - performance audit
64:42 - by just removing a lot of junk from that
64:45 - website
64:46 - a lot of unnecessary javascript requests
64:48 - a lot of unnecessary downloads a lot of
64:50 - unnecessary craft
64:52 - and yes he did remove the gdpr banner
64:55 - but that's not really entirely what's
64:58 - wrong with it
64:59 - so what he found is that before it would
65:02 - take an akitio nod 14 000 milliseconds
65:06 - so that's 14 seconds to get to the first
65:09 - paint of this
65:11 - usa today website
65:13 - and after removing everything pretty
65:15 - much other than the text
65:17 - and we'll get into why this concept of
65:20 - craft or additional js is important or
65:23 - not later in the presentation
65:25 - he found that he could bring everything
65:28 - down to
65:29 - three seconds
65:31 - so he went uh from a load time of uh 45
65:35 - seconds to three seconds so
65:38 - this is why i think the web is in
65:39 - jeopardy and by the way this was in 2018
65:42 - but
65:43 - the situation has really not gotten a
65:45 - lot better since
65:47 - because if you look at the progression
65:50 - of key metrics like first content full
65:52 - paint and on load
65:54 - and largest content in full paint which
65:55 - is a metric that hasn't merged most
65:57 - recently it's pretty much it's gotten
65:59 - better for sure but it's pretty much
66:02 - been a very slow
66:04 - improvement and when it comes down to
66:06 - metrics like first contentful paint and
66:08 - largest content for paint we don't see
66:10 - that
66:11 - big of a difference so we would hope
66:13 - and that's where that's what really this
66:14 - presentation is all about is
66:16 - i think we can make this a lot better
66:19 - but we need to understand the problem
66:21 - fully and we need to attack it in the
66:22 - best possible way with the best possible
66:24 - tools
66:25 - and with the best possible approaches
66:28 - and before i go too much further i think
66:30 - something that perhaps not a lot of
66:32 - presentations go into
66:34 - which is this concept of
66:37 - what do we mean exactly by the web right
66:39 - like
66:40 - we obviously all talk about it but
66:43 - there's three properties that i think
66:44 - about when i think about the web that i
66:47 - would love personally to see
66:49 - improve and a lot of
66:51 - organizations and businesses and
66:53 - individuals i think throughout the world
66:54 - would love to see improvement one of the
66:56 - key things is that this web is global
66:58 - so when we look at the data for
67:01 - how
67:02 - things have changed in terms of
67:03 - performance over the past few years
67:06 - and we look at you know this orange bar
67:09 - line at the top we'll see that
67:12 - india
67:13 - is possibly you know twice as bad as for
67:15 - example south korea in this case
67:18 - um
67:19 - and interestingly enough india is where
67:21 - a lot of the growth is a lot of where
67:23 - the best tech companies and unicorns
67:26 - have been created it's where a lot of
67:27 - the
67:28 - people are coming online so this matters
67:30 - a lot
67:31 - and interestingly enough that web that
67:33 - i'm talking about is also increasingly
67:35 - mobile
67:36 - right so i like to talk about this more
67:38 - recent uh data point which i found uh
67:42 - from
67:43 - josh camille
67:45 - where he talks about you know the most
67:48 - common device in the world today and
67:50 - guess what
67:51 - that device is not the iphone 12 pro max
67:55 - super m1 duper it's
67:58 - actually more like this phone that you
68:00 - see on the screen here which is a
68:02 - xiaomi redmi 8 and it's the most common
68:05 - budget smartphone in india which is
68:08 - one of these key areas that we're taking
68:10 - a look at
68:11 - and
68:12 - one of the things he finds
68:14 - is
68:15 - that the web side by side so on the
68:18 - right hand side you have an iphone and
68:20 - on the left you have this xiaomi redmi
68:23 - average indian smartphone
68:26 - so you can see that there's quite a bit
68:28 - more spinning
68:29 - on this website on the left and that's
68:32 - a very very optimized website with a lot
68:36 - of resources behind it that in this case
68:39 - happens to put up
68:41 - almost entirely on the client side right
68:42 - so it's not something that has compre
68:44 - rendered from a server which will get
68:46 - into the benefits of it later
68:49 - and actually that's still pretty good
68:51 - because all things considered because
68:53 - he goes on to say things get problematic
68:55 - when we visit news sites
68:58 - and i think because of all the tracking
68:59 - snippets and such it's a pretty good
69:01 - guess
69:02 - these sites take forever so here's the
69:04 - new york times and before we go on uh
69:06 - for a lot of those of you
69:08 - that have already in your personal
69:10 - experience identified this problem with
69:12 - the web because we all notice that when
69:13 - we just use the web every day uh yes
69:16 - this is gonna be a little painful to
69:18 - watch so let's take a look so he's
69:20 - tapping
69:21 - on on a story here
69:24 - and you can see on the right hand side
69:26 - that actually still took pretty long for
69:28 - my liking personally but notice that on
69:30 - the left and speaking and is still going
69:34 - uh so this is kind of the reality of
69:36 - today right like you can you can buy one
69:37 - of these phones on amazon and run this
69:39 - test yourself and what we're taking a
69:42 - look at here is a what
69:44 - in our minds
69:46 - uh in in an oversimplified model we
69:48 - could say well this is a super simple
69:49 - website right it's just like
69:51 - it's literally an online newspaper how
69:53 - how could it be like this right
69:56 - so he goes on to make a lot of
69:58 - interesting observations one of them is
70:00 - that ad heavy wordpress sites and like
70:03 - modern web apps seem to be really really
70:05 - bad for him so it's actually an
70:07 - interesting concept there like the idea
70:08 - of ads and third-party scripts
70:11 - then he mentions every major
70:13 - react tab and we're going to get into
70:15 - why this idea of that major react app
70:17 - happens to be really relevant here since
70:19 - it's either server rendered
70:22 - or other forms of pre-generation so
70:25 - he notices that that boot up time is
70:27 - actually not bad he does mention the
70:29 - time to interactive is slow
70:31 - and we certainly need to fix that
70:33 - so another great observation there and
70:35 - he says that next js for example
70:38 - has
70:39 - done a lot here because nexjs in
70:41 - particular
70:42 - offers both server rendering and
70:44 - pre-rendering so
70:46 - gatsby's more focused on the latter but
70:48 - he says that that's a property that is
70:51 - making that web feel faster especially
70:53 - when you first load the page
70:55 - and the the third property i think about
70:57 - when i think about what is the web to me
70:59 - is that and it goes into this concept of
71:01 - he makes the observation that major
71:03 - websites built with react are not as bad
71:06 - is that the web is not all
71:09 - evenly distributed
71:10 - nor
71:11 - build a like
71:13 - so another interesting tweet that came
71:15 - from one of the team members of the
71:16 - google chrome turned me to this idea of
71:19 - what does the traffic distribution of
71:21 - the web look like
71:23 - and this is why i use the dragon emoji
71:24 - is that i try to find an animal that
71:27 - both had a very long tail
71:30 - and b
71:31 - had a lot of potential that we can
71:32 - unleash so
71:34 - one of the key insights from this
71:35 - telemetry that came from google chrome
71:38 - is that the head of the web which is
71:40 - just 10 websites
71:42 - represents 33 of global page views
71:45 - and those are actually discrete page
71:46 - rendering so we're not thinking traffic
71:48 - here because we've probably heard the
71:50 - data like netflix has tons of the
71:51 - internet's bandwidth or whatever this is
71:54 - in particular pages so where are you
71:56 - opening a web browser to go to
71:59 - and then the tours of the web which is a
72:01 - lot of other websites
72:04 - in particular
72:05 - 10 000 so the body of this
72:07 - dragon the torso is 10 000 that's also
72:10 - 33
72:12 - and then what's kind of interesting is
72:15 - that the long tail of the web is up to 3
72:18 - million websites depending on the device
72:20 - and that represents 33 so just
72:24 - torso and head which is not that many
72:26 - websites represent 50
72:30 - so if you consider like the top thousand
72:33 - actually that's like
72:34 - the head and a little bit more that's 50
72:37 - and if you consider head and torso
72:38 - entirely that's you know nearly 66 or so
72:43 - so
72:43 - what's interesting too is that if you
72:45 - correlate it with if you go and look how
72:47 - these things are built you start
72:49 - noticing a pattern or a trend that i
72:51 - think is really interesting in the
72:52 - context of thinking about jam stack
72:54 - which is
72:55 - the static web is more of the realm of
72:59 - that like long tail
73:01 - where
73:02 - there's more individual creators or
73:04 - perhaps you know you fire and forget you
73:06 - build it or perhaps you use some sort of
73:09 - um
73:10 - static generation tool and you just not
73:12 - updated as frequently and for example
73:14 - like
73:15 - long build times don't matter as much
73:18 - but then as you start traversing into
73:19 - the more
73:21 - you know heavy traffic web we know it's
73:23 - actually the opposite it's super dynamic
73:26 - lots and lots of pages you could never
73:28 - possibly build them all in in a build
73:32 - process through ci cd
73:34 - and also we notice that it's hyper
73:36 - personalized so
73:39 - each user is getting a different page so
73:41 - there's not much that's a static there
73:44 - and that correlates a lot with what
73:47 - we're seeing in terms of that you know
73:49 - where people are spending time and what
73:52 - technology is best suited for that
73:54 - so
73:55 - in conclusion the larger the site
73:58 - the more likely that performance matters
73:59 - a lot right because like if you're the
74:01 - new york times you're everywhere
74:04 - and you have a big business at stake
74:07 - and then
74:08 - and unfortunately what we're seeing from
74:10 - all this from the data and the anik data
74:14 - so the things that users are reporting
74:15 - or recording
74:17 - performance is not really that great
74:18 - that great
74:19 - so this made me think i'll spend a lot
74:21 - of time thinking about like okay what is
74:23 - the difference between
74:24 - this monster diamond and called fagozon
74:28 - uh it's pretty cool i hope i'm an
74:30 - inventor of that so what's the
74:31 - difference between that fagozon
74:34 - uh so this top 10 websites that
74:37 - seemingly have figured it all out
74:38 - they're both dynamic and super
74:40 - performant
74:41 - and they keep evolving fearlessly and
74:44 - their page loads are fast so what's the
74:46 - difference between them
74:47 - and the rest of the web and
74:50 - some of the conclusions that we found is
74:51 - that if you look at like for example
74:54 - how they consider front-end development
74:57 - they have lots of teams supporting
74:59 - fairly advanced front infrastructure
75:02 - and they have a unified approach a
75:04 - unified framework a lot of automation
75:08 - um it when it comes down to go into
75:11 - production that's also very much
75:13 - automated so the front end developer
75:15 - doesn't have to figure out
75:17 - the production environment and they can
75:19 - usually
75:20 - reproduce that production environment
75:22 - really well throughout the development
75:24 - process and they're assisted by a lot of
75:25 - data
75:27 - and finally
75:29 - there's this idea of reusing so reusing
75:33 - components reusing design systems and
75:35 - learning from the past so there's a lot
75:37 - of
75:38 - um sort of intelligence and historical
75:40 - data has been built up because frankly
75:42 - those top ten have had a lot of you know
75:46 - uh a lot a bit of a head start no pun
75:49 - intended because they've been around for
75:51 - so long
75:53 - so to fix it we i think we can take a
75:55 - page and we can learn from this so
75:58 - what we're trying to do uh in our
76:00 - company is give you the framework that
76:02 - unified front-end infrastructure
76:04 - solution that unified tooling that
76:06 - continues to get improved without you
76:08 - having to deal with webpack
76:10 - configurations and other implementation
76:12 - details
76:13 - in a platform that you can fearlessly
76:16 - evolve the evolution of your front end
76:19 - in through
76:20 - preview deployments
76:22 - constant benchmarking
76:24 - testing your site and results in a real
76:27 - production environment a global cdn and
76:30 - so on
76:31 - and one of the things that we notice as
76:33 - well is that nexus demonstrated that it
76:36 - has
76:37 - quite a bit of a fit
76:39 - specifically in this
76:41 - top
76:42 - segment of the web this most common side
76:44 - so once we're frankly you want to spend
76:46 - the most time optimizing because like i
76:48 - said number one
76:50 - they have a reason to constantly invest
76:53 - in better performance and their
76:55 - performance is not there yet
76:58 - so our approach consists in
77:01 - wrapping react which gives you this
77:03 - incredible unit of collaboration in the
77:05 - component
77:06 - so you build a component
77:08 - and you can reuse it and your entire
77:11 - team benefits from every improvement
77:13 - that you make to that component i like
77:14 - to call it the lego brick of the web
77:16 - then you can constantly preview your
77:18 - front and so every time you push to get
77:21 - when you import your project into
77:22 - versailles you get a url you can see it
77:24 - here
77:25 - at the shop get new checkout url
77:29 - and you can share that with the rest of
77:30 - your team and then when you ship
77:32 - everything around performance has
77:34 - already been figured out automatically
77:37 - for the entire team
77:39 - but most importantly what we've noticed
77:41 - what we've been noticing is that even
77:43 - though our motto is developed previous
77:45 - ship
77:45 - it really is in this iteration phase and
77:48 - collaboration phase where a lot of the
77:49 - value in making the web better really
77:52 - resides
77:54 - and when it comes down to iteration and
77:56 - when it comes down to understanding
77:58 - performance deeply i think one of the
77:59 - most important things is to have
78:01 - a very very good lens of the reality of
78:06 - the state of your front ends and your
78:07 - websites
78:08 - so the common expectation that i've seen
78:11 - sometimes in the ecosystem is
78:13 - okay so
78:15 - this is the sort of the image
78:17 - of the web and
78:20 - i know that if i have a cdn that
78:23 - will ensure that everything is fast and
78:26 - especially if it's been pre-rendered or
78:27 - statically generated it's all good it's
78:29 - fast
78:31 - and then i think the only thing i need
78:33 - to do is figure out the size of my js
78:35 - bundle which that is like the other big
78:38 - thing there's only there's these two
78:39 - things is that i have a fast cdn i use
78:42 - jam stack static generation whatever and
78:44 - as long as i don't have a lot of js in
78:46 - the client side i'm good
78:49 - reality however is
78:50 - really quite different from that
78:52 - oversimplified model that a lot of us
78:54 - used to have in the past
78:57 - so a cdn nowadays is kind of table
78:59 - stakes most websites nowadays have it
79:02 - and we go to great lengths to automate
79:05 - it and make it available and free for
79:06 - you
79:08 - but then performance becomes quite an
79:11 - interesting subject quite an interesting
79:12 - rabbit hole i'd like to start with this
79:14 - example of box shadow because
79:17 - when facebook rewrote their
79:20 - facebook.com in the latest and greatest
79:22 - technologies in 2020 using
79:25 - react and for the first time they were
79:27 - using the entirety of react very similar
79:29 - to how nexjs works where the entire page
79:33 - is driven by react whereas in their past
79:35 - it used to be a combination of php and
79:37 - legacy technology and all that
79:40 - so a gentleman went ahead and started
79:42 - doing what every web developer does
79:44 - right we inspect the open web so they
79:46 - went ahead and like took a look at like
79:48 - how this new facebook thing was being
79:50 - built
79:51 - and this gentleman ahmad noticed
79:55 - that
79:56 - the background at the very top
79:59 - was not box shadow with css it was
80:01 - actually a background image
80:04 - yes so the new facebook
80:06 - this experts of the web the creators of
80:09 - react in 2020 were using an image which
80:13 - for
80:14 - all of you that have been using the web
80:16 - for many many years like myself you
80:17 - remember that this is how we used to do
80:19 - this like 10 to 15 years ago because we
80:21 - didn't have the box shadow properly so
80:25 - they're they're sort of going back and
80:26 - why was that so
80:28 - one of the
80:30 - performance engineers at facebook uh
80:32 - graciously
80:33 - uh noted that it's for performance a box
80:36 - shadow in the floating header like that
80:38 - was killing scroll performance in
80:39 - browsers
80:41 - and mateos goes ahead and asked so i
80:44 - don't know if this is a question but how
80:45 - do you guys test that
80:47 - and this again we're like expectation
80:48 - reality or a little bit um uh not what
80:51 - we expect which is
80:53 - honestly you just scroll the page and
80:55 - you would notice so like i said teams
80:57 - like facebook spend a lot of time
80:59 - worrying about performance and obviously
81:01 - they get great results from that and
81:03 - sometimes it's very sophisticated and
81:05 - sometimes it's very
81:07 - much
81:08 - that good old
81:10 - you know feeling test
81:12 - so and here's why i'd like to use this
81:16 - image of the iceberg which is
81:19 - this mass of complexity that we tend to
81:22 - ignore in our oversimplified models has
81:25 - so many things that contribute to
81:27 - performance like the latest web font
81:30 - that you copied and pasted from
81:31 - somewhere in the web
81:33 - with lots of css files and js files and
81:35 - so on your gdpr pop-up that comes from
81:38 - some third-party script and your
81:40 - marketing team as an analytics script
81:42 - and then your product teams as analytics
81:45 - script and
81:46 - as uh
81:48 - josh was mentioning earlier the
81:50 - ads and trackers play a big role in
81:53 - exception reporting scripts
81:55 - and session recording scripts for
81:57 - product teams and images
82:00 - and
82:02 - your js bundle
82:04 - and i think here's where
82:07 - you know the solution
82:09 - which that tweet from usa today was kind
82:11 - of alluding to
82:13 - is where also i think we have to be on
82:16 - the side of reality which is
82:18 - it's very easy to say well just throw
82:20 - all that away and then your website will
82:23 - be fast and i'm actually willing to bet
82:25 - that that would be the case for the most
82:26 - part if you throw all that away
82:29 - then i'm sure your website would be fast
82:31 - but then
82:32 - i think these things got there not
82:34 - because we're intending to make the web
82:36 - slow
82:37 - but because we didn't have the right
82:39 - workflow
82:40 - in many cases we didn't have the right
82:42 - tools so for example if you now use the
82:44 - nexjs image component that image which
82:47 - was a big part of the iceberg because
82:49 - for example you were giving a gigantic
82:50 - image that was unoptimized to a very
82:53 - small screen now that gets fixed
82:56 - so
82:56 - um it's not that you had to remove the
82:58 - image instead of how to make it optimal
83:01 - and
83:02 - and that's where my sort of
83:04 - perception here is you have to focus on
83:07 - real solutions deleting them deleting
83:10 - all that sounds good but it's not very
83:12 - realistic for most businesses
83:14 - and one of the solutions really ends up
83:16 - being
83:17 - the
83:18 - good all
83:19 - cloud computing and i like to use this
83:21 - stock photo that i found in google
83:22 - images because
83:24 - notice that like the cloud is
83:27 - streaming ones and zeros to a screen
83:29 - which is actually pretty different from
83:30 - how the actual cloud works but it's a
83:33 - good metaphor for okay
83:35 - instead of trying to
83:37 - run everything on my device perhaps i
83:39 - can start doing some things at different
83:41 - times i can start doing some things
83:43 - earlier in the life cycle i could do
83:45 - them
83:46 - on the edge i could do them on my server
83:49 - i could do it at build time sometimes
83:52 - and then it begins sort of a streaming
83:54 - one
83:55 - one unified
83:57 - painting of the web that i want to
83:59 - deliver
84:01 - so one of the strategies here that's
84:02 - quite obvious is okay so instead of
84:04 - doing competition the device shifted to
84:07 - the cloud so all those spinners that we
84:08 - saw
84:09 - when the app was booting up on a slower
84:11 - device would have happened on a more
84:13 - powerful device
84:16 - a more powerful
84:17 - literally machinery in the cloud
84:21 - so and this is where for example
84:23 - combining and starting to introduce
84:26 - server rendering or server less
84:28 - rendering like in our case where you
84:31 - define a page that is not static and is
84:34 - also not deferring all the computation
84:37 - to the client side but instead we
84:39 - leverage
84:40 - this asymmetry of computing right
84:42 - because the computing on on the cloud is
84:44 - more powerful than the one on the device
84:46 - and this is really what the new
84:48 - generation of hybrid frameworks are
84:50 - enabling so
84:51 - next knox and zveltkit are examples of
84:54 - frameworks that can say well
84:56 - yes this one page is a static but this
85:00 - other page can also do server rendering
85:02 - so you're not locked in
85:04 - to a local maxima to a peak of
85:07 - performance that could be done with
85:09 - static generation
85:11 - and you're only out outlet it's not just
85:14 - to put everything on the device is to
85:16 - also put it where it belongs
85:19 - and this also comes from the conclusion
85:21 - realization that your cdn is not enough
85:24 - right so
85:25 - that time to first buy that that
85:27 - connection to a to a city and edge and
85:30 - getting some html there is a very
85:32 - simplistic view of the problem and it's
85:34 - very limited and it's not how we're
85:36 - going to accomplish great performance
85:39 - one of the ways that we can do this
85:40 - because
85:41 - server rendering is also not a silver
85:43 - bullet or just saying well i'm just
85:45 - going to use a hybrid framework i'm done
85:47 - that's also not the right solution so
85:50 - when when i mentioned the post gems at
85:52 - world and the rise of hybrid frameworks
85:55 - i'm not saying well just use a framework
85:57 - that comes with all these batteries
85:58 - included
86:00 - you'll have to measure continuously as
86:02 - well but this is why next js is also
86:05 - focusing on
86:06 - not just giving you for example a better
86:08 - image component
86:10 - that optimizes that part of the iceberg
86:12 - and we have tons of other efforts
86:14 - ongoing for optimizing a lot of the
86:16 - other parts of that mass of ice
86:20 - but one of the things we wanted to do
86:21 - early on is
86:23 - put you on a workflow and give you a
86:25 - workflow
86:27 - where you constantly get feedback about
86:29 - how you're doing but from the
86:30 - perspective of the real world so we call
86:33 - this a real experience score and what we
86:35 - do essentially is
86:36 - we take
86:38 - a subset of the same inputs that
86:40 - lighthouse uses when you do a synthetic
86:42 - manual test
86:44 - but we collect them from your devices
86:46 - and then we give you a picture of like
86:48 - how well you're performing across mobile
86:50 - desktop how you're doing across
86:52 - different countries how you're doing
86:53 - across different dimensions so this is
86:56 - gonna
86:57 - help you
86:58 - for example not ship that box shadow
87:00 - because then perhaps it was slowing you
87:02 - down
87:04 - and like i said the nice thing is that
87:06 - it's integrated into
87:08 - the nexus
87:09 - data source so we know for example what
87:12 - pages and we can help you find out what
87:14 - pages are contributing to the different
87:17 - breakdowns of scores
87:19 - and what's really cool is that it's not
87:20 - just unique to next.js so
87:23 - we are working to enable this for all
87:26 - frameworks starting with gatsby and more
87:28 - are coming very soon where for example
87:30 - if you import your gatsu project into
87:32 - versailles you're gonna start getting a
87:33 - lot of these benefits of continuously
87:36 - thinking about performance from the
87:38 - perspective of your real users
87:40 - so all that said does it mean gemsec is
87:43 - bad doesn't mean that putting a lot of
87:46 - like that j that encourages putting
87:48 - javascript in the client is bad no i
87:51 - don't think so i think it really depends
87:53 - on what you're building and it really
87:54 - depends on what are your ambitions are
87:57 - ambitions are
87:58 - and furthermore it's not just that
88:01 - gemsec is not bad is that a lot of the
88:04 - ideas that were
88:06 - built in into that stack like the idea
88:09 - that the markup the m can be cached at
88:12 - the edge
88:13 - and that you should leverage a lot of
88:15 - pre-rendering that's a great tool as
88:17 - well
88:18 - and you can start there for example in
88:20 - his you can make some of your pages
88:22 - completely gems and completely static
88:24 - and then you can combine it with a
88:27 - performance-oriented workflow where
88:29 - you're analyzing your metrics
88:31 - and you're really starting to ascertain
88:32 - if it makes sense for you or not but you
88:34 - also always have that possibility of
88:37 - adding more
88:38 - so my advice in that regard is you can
88:42 - use subsets of these ideas whenever
88:44 - possible so when you define your pages
88:46 - you say well this one is a static and
88:49 - nexus automates all that so you don't
88:51 - have to say well for this build process
88:55 - i built statically and then i wrap it
88:56 - with a server and cache and purge so the
88:59 - beauty of it is too that
89:01 - you really have to
89:03 - just define your pages and you're off to
89:05 - the races
89:07 - and
89:08 - again it's all about not limiting what
89:10 - you can do or how good your performance
89:12 - can be
89:15 - if you want to learn more about nexjs
89:16 - and
89:17 - learn how this hybrid capabilities work
89:20 - you can go to nexus.org learn
89:23 - and later
89:24 - in in the conference lee robinson will
89:26 - be talking about specifically how this
89:29 - page generation and data fetching
89:32 - components of flexjs that enable
89:34 - pre-rendering server rendering and much
89:36 - more work
89:39 - and you can deploy all kinds of front
89:41 - ends whether fully static and jump stack
89:44 - or the new generation of hybrid
89:45 - technologies you can deploy to the
89:47 - versailles for free
89:49 - and by the way you also get the ability
89:51 - to measure continuously so
89:53 - it the the
89:55 - journey doesn't end at just deploying
89:58 - but it really
89:59 - ends with and continues with learning
90:02 - from your users and
90:04 - ensuring that they're happy no matter
90:06 - where they are in the world
90:09 - thank you so much and i hope you have a
90:11 - great rest of your conference
90:19 - awesome
90:21 - i always love you amazing uh
90:24 - it's it's so good to hear guillermo uh
90:26 - in these discussions
90:28 - uh performance is such an important
90:30 - thing so uh please go back and re-watch
90:32 - that talk um these are going to be
90:34 - available after the conference but now
90:37 - we're going to move into our next
90:39 - section
90:40 - our lightning talks these are four talks
90:42 - in less than 15 minutes i love lightning
90:45 - talks what do you think boom boom boom
90:48 - boom can't wait to hear some of these
90:50 - great lightning talks that we're about
90:52 - to dig into here
90:54 - and following the lightning talks we're
90:55 - going to break up into topic tables so
90:58 - we can get up and close and personal in
91:01 - live sessions with some of these
91:02 - speakers and sponsors and some of the
91:05 - instructors of the workshops as well and
91:07 - other folks that we just can't wait to
91:09 - connect with so more on that and how
91:12 - that's all going to go after the
91:13 - lightning talks but first first up first
91:17 - up yeah is uh lydia holly um
91:20 - lydia is is uh an independent software
91:23 - engineer and you can see her work at the
91:25 - avocado.com
91:27 - that's like
91:28 - avocado uh
91:31 - with er at the end i guess yes um she
91:33 - will be explaining and visualizing the
91:35 - life of a script for us and it gets
91:37 - really technical and really cool and the
91:40 - visuals are awesome so please stick
91:42 - around for this awesome lightning talk
91:44 - with lydia alley
91:47 - i'm lydia halley and today i'm going to
91:48 - give you a pretty like high level
91:50 - walkthrough of basically everything that
91:52 - happens going from our human friendly
91:54 - javascript file all the way down to
91:56 - something that computers can understand
91:58 - and they're like there are so many parts
91:59 - to this process but for now i'm only
92:01 - going to focus on two things namely the
92:03 - browser side of things and v8 side of
92:05 - things and v8 is the javascript engine
92:08 - used in chromium-based browsers and in
92:10 - node as well first let's go all the way
92:12 - back to the beginning so we're trying to
92:14 - load a website that uses a small calc.js
92:16 - script and as we're trying to load the
92:19 - website the html parser encounters a
92:21 - script tag and tries to fetch the
92:23 - calc.js file from either of the network
92:25 - or maybe cache or a service worker that
92:28 - prefetched a file either way a stream of
92:31 - bytes get returned that gets sent to the
92:33 - bytestream decoder relaxer and this is
92:35 - part of the parser that takes care of
92:37 - decoding the stream of bytes and
92:40 - generating tokens based on the data it
92:42 - received for example it sees that the
92:44 - bytes decode to f-u-n-c-t ion it
92:47 - generates a token say like hey i know
92:50 - this function is a keyword in javascript
92:53 - and it creates a token based on that and
92:55 - it'll just continue to do so for the
92:57 - rest of the stream as well and as it's
92:59 - generating these tokens is actually
93:01 - sending them all down to the parser and
93:03 - the parser then goes ahead and creates
93:05 - notes based on the tokens that match a
93:08 - certain syntax rule in javascript
93:10 - for example a variable declaration or a
93:13 - function statement and based on these
93:15 - notes a parser generates an abstract
93:18 - syntax tree that represents our program
93:21 - now this one is uh very much simplified
93:23 - because in real life it also contains
93:24 - some extra information about a program
93:26 - but for now this will suffice um and
93:29 - also while it's doing that it's checking
93:30 - for syntax errors because the tokens
93:33 - themselves may be valid but maybe they
93:35 - may not actually match a certain syntax
93:37 - rule finally it's time for the
93:38 - javascript engine to do its work because
93:40 - this est is actually sent down to v8's
93:43 - ignition interpreter and this
93:45 - interpreter is responsible for
93:47 - generating the bytecode that it based on
93:49 - the ast that it received
93:51 - and we can actually see the bytecode
93:53 - that gets generated with the print
93:55 - bytecode flag in node so for example
93:57 - this bytecode for our calc function
93:59 - if we invoke it with an object
94:01 - containing an xy and z key it would look
94:03 - something like this and this may seem
94:05 - like a lot of data but there's actually
94:07 - only two parts here that are really
94:09 - important so ignition uses registers in
94:12 - order to execute the bytecode and
94:14 - there's registers like r0 and r1 but
94:16 - there's also an accumulated register
94:18 - that the byte codes use for their input
94:20 - and output or both
94:22 - and then there's also registers like a0
94:24 - that are used for the values that got
94:26 - passed to the function and this makes
94:28 - more sense as we're walking through the
94:29 - bytecode don't worry
94:31 - so in this case we passed an object
94:32 - containing an x y and z key to the
94:34 - function so this is where the second
94:36 - part of the generated output is
94:38 - important because a0 points to a shape
94:41 - table that contains information on where
94:43 - to find those properties on the object
94:45 - that we pass to the function
94:47 - all right so now let's see what those
94:48 - bytecodes actually do so in the very
94:50 - first line we see lda named property by
94:53 - code so lda specifies that a value gets
94:56 - loaded into the accumulator and that the
94:59 - value is the named property from the
95:01 - object that we passed to the function
95:02 - stored in a0 and the property itself can
95:05 - be found on index 0. so we see that the
95:08 - value on index 0 maps to x so we load
95:11 - the value of the x property of the
95:14 - object that we passed the function so
95:16 - the numeric value 10 in this case
95:19 - then we multiply the current value in
95:21 - the accumulator by the small integer 50.
95:24 - and then star r0 specifies that the
95:27 - current value of the accumulator has to
95:29 - get stored in register r0
95:32 - then again we load a property and store
95:34 - this into the accumulator but this time
95:36 - it's from the second index which points
95:38 - to y and y has a value of 20. so the
95:41 - value of the accumulator is now 20 and
95:44 - star 2 specifies again that the current
95:46 - value of the accumulator has get stored
95:48 - in register r2 we again load a named
95:51 - property from a1 or sorry a0 into the
95:54 - accumulator
95:55 - the value in the third index this time
95:57 - which maps to z has a value of 30. so we
96:00 - multiply the current value of the
96:02 - accumulator with the value that's
96:04 - currently stored in register r2
96:06 - so one more step we have to add the
96:08 - values to it and register r0 to the
96:11 - current value of the accumulator so this
96:13 - means that we're adding 500 plus 600 is
96:16 - 1100 and finally we return the value of
96:19 - the accumulator which is 1100. now the
96:21 - bytecode that is generated by the
96:22 - bytecode generator also goes through
96:25 - some smaller optimizations after which
96:27 - the bytecode actually gets executed and
96:29 - it's possible to run this on our
96:30 - machines so finally we have something
96:33 - that our machines can work with now you
96:35 - may have noticed that i skipped some
96:37 - things in a bytecode um
96:39 - so let's see what's up with them this is
96:41 - actually part of v8 optimizations
96:44 - because when we pass an object to v8
96:47 - such as the x y and z object in this
96:49 - case it creates a shape for that
96:51 - specific object structure
96:54 - um and if you're reading like
96:55 - documentation or blog posts this is also
96:58 - referred to as a hidden class or a map
97:00 - but it's kind of confusing because we
97:02 - also have classes in javascript and we
97:03 - have maps in javascript but it's not a
97:05 - javascript class or a javascript map so
97:08 - shape is the way to go because we don't
97:10 - have those natively in javascript
97:13 - so a shape is basically just the
97:15 - structure of that object
97:18 - and this shape contains pointers to the
97:20 - offsets on which we can find the values
97:22 - of the properties on the object because
97:24 - even though we only specify the x y and
97:27 - z properties there are many many more
97:29 - built-in properties and objects
97:31 - that also all have their location
97:33 - somewhere stored in memory
97:35 - so when we're trying to access a
97:36 - property on the object for example x um
97:39 - it can now just get it quicker by
97:41 - checking okay does this object have the
97:42 - same shape yeah it does okay cool uh now
97:45 - i i want to get x so i know the offset
97:48 - shapes are really useful for an
97:49 - optimization technique that va uses
97:51 - namely inline caching
97:53 - with inline caching we basically store
97:56 - the results from previous operations so
97:57 - that the next time we call the exact
98:00 - same operation we already know the
98:02 - result now each time we do a property
98:04 - lookup it can just simply store the
98:06 - results for the offset that the last
98:08 - time it didn't look up so in the future
98:10 - when we're trying to perform the exact
98:12 - same action it can simply just get the
98:14 - result from the inline cache instead
98:17 - now these inline caches are not only
98:19 - beneficial for the interpreter but they
98:21 - also generate really valuable feedback
98:24 - for the turbofan optimizer so finally we
98:27 - can go back to the bytecode example
98:29 - because these values are actually
98:31 - references to a feedback vector slot
98:33 - where it stores information about the
98:35 - execution of the function
98:37 - and this includes information from like
98:40 - arrhythmic operations such as the fact
98:42 - that so far we've only added numbers
98:44 - which result in a numeric value one
98:46 - useful example of this is the fact that
98:49 - in javascript you can also concatenate
98:51 - strings with the plus operator which
98:53 - would have to be handled way differently
98:55 - internally but so far it knows okay i've
98:58 - only had numerical values that's fine
99:00 - now let's say that we're invoking the
99:02 - calc function hundreds of times this
99:04 - function is now considered hot um
99:07 - because although the bytecode is already
99:10 - really fast v8 actually uses turbofan
99:13 - the turbofan optimizer in order to
99:14 - generate machine code that's even faster
99:17 - so based on the bytecode and the
99:19 - generated feedback for specific code
99:22 - blocks it can generate optimized
99:24 - architecture specific machine code
99:27 - that can run directly on your machine so
99:29 - the next time that we invoke the
99:31 - function it can just skip over the by
99:33 - code and immediately execute the machine
99:35 - code instead however there is one
99:37 - problem in javascript namely that it's
99:39 - dynamically typed so we can invoke the
99:42 - calc function with the same object like
99:44 - hundreds and thousands of times but
99:46 - there is absolutely no guarantee that
99:48 - this will always be the case in the
99:49 - future for example we can also invoke
99:51 - the calc function with an an empty
99:53 - object
99:54 - or just with an x key or just an x and y
99:56 - key i don't know why you would do it but
99:58 - it's possible so for all those different
100:00 - types of objects va generates a new
100:02 - shape that contains the new different
100:04 - properties
100:05 - so previously we saw that the inline
100:07 - cache contained a field with a value of
100:09 - the shape of the object and then the
100:11 - corresponding offset however if we
100:13 - passed multiple objects so multiple
100:15 - shapes got generated we also have to
100:17 - update the inline cache in order for it
100:19 - to point to multiple shapes
100:21 - and they're offset so now when we're
100:22 - trying to load a property from a
100:24 - specific object it first has to walk
100:26 - through all the possible shapes in order
100:28 - for it to find the object that contains
100:29 - that specific property which could
100:31 - result in a linear search which is not
100:33 - very optimal but now previously we
100:35 - generated machine code for the calc
100:37 - function when it's only gotten invoked
100:39 - with one type of object namely the
100:41 - object with the x y and z keys
100:44 - however if we call the calc function
100:46 - again but with a different shape
100:48 - turbofans
100:49 - shape check fails in which case we can
100:51 - no longer use this optimized machine
100:53 - code and we actually have to de-optimize
100:56 - back to the generated bytecode and this
100:58 - is a pretty expensive operation that you
101:01 - mostly want to avoid so the inline cache
101:04 - of the calc function is also updated to
101:06 - say like hey it's actually got multiple
101:08 - shapes now
101:09 - um now the calc function again can get
101:11 - hot and optimized even after
101:13 - de-optimization although turbofan has to
101:15 - handle it a little bit differently when
101:17 - it's encountered multiple shapes and
101:19 - these inline caches actually also have
101:21 - multiple states because if an inline
101:23 - cache has only seen one type of object
101:25 - it's considered monomorphic which is
101:27 - pretty much the best case scenario
101:29 - because in that case we can just
101:31 - generate optimized machine code and
101:33 - assume that in the future this function
101:36 - will just get invoked with the same
101:39 - object shape now if a cache has two or
101:41 - four different shapes it's considered
101:43 - polymorphic and if we're continuously
101:45 - just invoking it with whatever random
101:48 - types uh it's considered megamorphic in
101:50 - which case it's like you know what never
101:51 - mind i won't try to optimize it so as
101:53 - you can see although it's pretty nice
101:55 - for us sometimes as developers that
101:56 - javascript is dynamically typed it's uh
101:59 - it's not so great for the compiler and
102:00 - it can really only work with
102:02 - speculations and just assume that in the
102:04 - future we will use the same type of data
102:08 - now even though i had to walk through
102:09 - this pretty quickly we went all the way
102:11 - down from loading the script in our
102:13 - browser all the way down to running
102:15 - optimized machine code on your machine
102:17 - and i just want to quickly mention that
102:18 - there are so many great resources out
102:21 - there um if you want to know more about
102:22 - the internals of v8 and it's open source
102:25 - so you can just check out the source
102:26 - code if you want anyways thank you so
102:28 - much for watching and have fun coding
102:33 - wow love that oh man i love that we are
102:36 - digging so deep into the internals of
102:38 - javascript
102:40 - so early in the day getting down to the
102:42 - bite code
102:43 - love it
102:44 - love it all right but we should probably
102:45 - keep these lightning talks rolling
102:48 - yeah
102:49 - yeah those visuals are fantastic
102:52 - um got so many great talks for you today
102:54 - this lydia halley's talk just now is so
102:56 - awesome
102:57 - and uh we are going to keep the fun
103:00 - rolling with our next talk from
103:03 - our next lightning talk speaker
103:05 - swizz teller who is a software engineer
103:08 - at tia i'm also a blogger at suzek.com
103:12 - and creator of the serverless handbook
103:14 - that you can find at
103:14 - serverlesshandbook.dev
103:17 - and so it's also created uh an open
103:19 - source library called use off and i
103:22 - believe we are going to be learning more
103:24 - today about adding off to jam stack apps
103:28 - and you can apparently add off to any
103:30 - jamstack app in five minutes jonathan
103:33 - does that sound possible
103:36 - it is uh
103:38 - just spoiler alert i've seen it and it
103:40 - works it's incredible um
103:43 - off is a hard problem this was going to
103:44 - talk about why it's a hard problem um
103:47 - and we're going to get into some some
103:48 - details in a short talk which is really
103:51 - cool we also hear that he's going to
103:53 - make an exciting announcement today um
103:56 - and i i really hope you all stick around
103:58 - for that as well so let's get straight
104:00 - into this talk with zach teller
104:03 - hello everyone i'm swizz and today i
104:05 - want to talk to you about a pesky little
104:07 - topic called authentication it's one of
104:10 - those things that you're going to need
104:11 - to add to your react app whether you're
104:13 - using create react app next js gatsby or
104:15 - any of the other frameworks that you
104:17 - like you are going to need to add
104:19 - authentication at some point it sounds
104:21 - pretty easy in theory right you need
104:24 - some way of saving who the user is you
104:26 - need to check with the server whether
104:28 - they are the person they say they are
104:30 - you need to potentially save their
104:32 - password maybe their username and you
104:34 - gotta do some little
104:36 - you know it's pretty easy talk to the
104:38 - server hey is this person logged in i
104:40 - have these credentials
104:42 - the server saves them and then things
104:44 - kind of just work out that's how that's
104:46 - how it usually works
104:48 - but good authentication is where things
104:50 - get really tricky because with good
104:52 - authentication you have to deal with
104:54 - things like security you have to deal
104:56 - with authorization whether this person
104:58 - even if you know that this person is
105:01 - this person do they have access to this
105:03 - page or do they have access to that page
105:05 - are they an admin or the user are there
105:07 - a meta admin whatever else you might
105:09 - want to think of authorization is really
105:11 - the hard part of a lot of authentication
105:14 - where authentication is who are you
105:17 - authorization is now that i know who you
105:19 - are do you have access to a particular
105:21 - topic or a particular resource that's
105:24 - that gets tricky and then when it comes
105:26 - to saving all of this stuff on the
105:28 - server it gets even trickier because
105:31 - well what if you're what if your
105:32 - database gets licked leaked can people
105:35 - read your passwords or can they not read
105:37 - your passwords how is your hashing
105:39 - structure are you still using hashing
105:41 - from many many years ago or are you
105:43 - using a modern salt and
105:46 - encryption and whatever honestly it's
105:48 - really hard to even keep up with what
105:50 - you should be doing how you should be
105:52 - doing it and then when it comes to
105:53 - saving the authentication state on the
105:56 - front end because the front end needs to
105:57 - be like hey i know you're already logged
105:59 - in and i know who you are so i need to
106:01 - tell the server to check with the server
106:03 - whether this is still true do you save
106:06 - that in cookies do you save it in local
106:07 - storage there's a lot of tricky little
106:10 - things that come with that one of the
106:12 - big ones is that once you split your app
106:15 - into multiple apps you're going to want
106:17 - to have an authentication service or
106:20 - some sort of authentication provider
106:23 - that can work with multiple services
106:25 - like if i log in on ios
106:27 - do i want to still be logged in in the
106:28 - browser if i switch browsers do i still
106:30 - want to be logged in usually as a user i
106:33 - do but you as an app developer get into
106:36 - a tricky situation where you have to
106:38 - have api based authentication you can
106:40 - just be passing cookies around because
106:42 - you need to have you probably want to
106:44 - use the same authentication for multiple
106:46 - different clients whether they're a
106:48 - server trying to do something in the
106:49 - name of your user whether it's the web
106:52 - app trying to do something in the name
106:53 - of the web app all of that gets really
106:55 - tricky so people start building
106:57 - authentication services and they start
107:00 - trying to think about how to do tokens
107:02 - when you really get start reading about
107:04 - it it kind of blows your mind i honestly
107:07 - you just should never roll your own
107:09 - authentication you should rely on a
107:12 - service that already provides
107:13 - authentication because there's a lot of
107:15 - little tricky things that you get you
107:17 - can get wrong and you don't want to end
107:19 - up like equifax which leaked something
107:21 - like many many 100 million users you
107:25 - don't want to be the person who everyone
107:27 - laughs at for oh wow they rolled their
107:30 - own authentication lost everybody's data
107:33 - and now you can just go to the dark
107:36 - parts of the internet and get
107:38 - everybody's social security numbers
107:39 - because equifax had a breach
107:41 - oops you don't want to roll your own
107:43 - authentication you want to use somebody
107:46 - who already exists who's out there and
107:48 - whose
107:49 - core business model it is to make it
107:51 - easy for you to add authentication and
107:53 - authorization and user management and
107:56 - all that fun stuff to your app so you
107:58 - have a lot of different options you have
107:59 - off zero as one of them you have netlify
108:02 - identity as a simple solution there's
108:04 - aws cognito which is kind of tricky to
108:06 - set up you have firebase authentication
108:08 - and there's probably a bunch of others
108:10 - you can build your own that follows the
108:12 - same protocols but unless you have a
108:15 - team of experts on authentication
108:17 - authorization encryption jwt tokens and
108:21 - really you have time to do this and it's
108:23 - your core business model you should
108:25 - probably just use somebody else once you
108:28 - start using somebody's
108:30 - authentication provider this stuff
108:33 - still is kind of tricky to use um
108:36 - especially on the jam stack or on the
108:38 - browser you need to you have this weird
108:40 - authentication flow where the user
108:42 - clicks a button gets redirected to
108:45 - somebody else's authentication page
108:47 - and you want that page to be somebody
108:50 - else's because that guarantees security
108:52 - and make sure that you as the
108:54 - application developer aren't sniffing
108:57 - people's passwords and usernames which
109:00 - you don't want to do
109:02 - well you might want to do it but you
109:03 - shouldn't want to do that so you
109:05 - redirect them to a different page they
109:07 - log in they authenticate and then that
109:09 - page redirects them back to your page
109:11 - and you have something called a callback
109:13 - page which then processes the the
109:16 - authentication looks at the looks at a
109:18 - bunch of data in the
109:20 - uh in the url sends it back to the api
109:23 - for for your authentication provider
109:26 - says hey is this data correct did you
109:28 - send me this or is somebody trying to
109:29 - hack this poor person and the
109:31 - authentication provider says yes that is
109:33 - okay and you have to then put it into
109:36 - your global state you have to make sure
109:38 - that every component that needs to check
109:40 - hey is this person currently logged in
109:43 - should they be seeing this authenticated
109:46 - content should they be seeing this
109:47 - authorized content and there's a lot of
109:49 - little tricky things that you still have
109:52 - to do
109:52 - even though you're using somebody's
109:54 - authentication provider and most of
109:56 - these have to do with global state
109:58 - management and making sure that you have
110:00 - the right access and the right info and
110:02 - you everywhere
110:03 - so what i started building about a year
110:05 - ago and has now just reached version one
110:08 - yay use auth v1 is significant because
110:12 - it now has support for multiple
110:13 - authentication providers yay
110:16 - also it's
110:17 - there's been a lot of changes behind the
110:19 - scenes so it's now easier to use and
110:21 - configure and it just works better i
110:23 - built this hook called use auth which
110:26 - makes it really easy for you to add
110:28 - authentication and authorization
110:30 - anywhere in your react app it works with
110:32 - nexjs it works with gatsby i've tried it
110:34 - with create react app rather than have
110:36 - you trust me at my word that this code
110:38 - snippet is the best thing since sliced
110:40 - bread when it comes to adding
110:41 - authentication to your react app i'm
110:43 - going to show you we're going to do
110:45 - three minutes and we'll have
110:46 - authentication added to a completely
110:49 - blank gatsby app i started it with the
110:52 - gatsby default starter i installed a
110:54 - couple of dependencies and now we're
110:55 - going to add authentication we're going
110:57 - to start by
110:59 - creating a config auth
111:01 - react component that renders on every
111:03 - page load
111:05 - this part has also gotten a little
111:07 - easier since i recorded this talk you
111:10 - can see it in the documentation page
111:11 - that's going to be linked at the end of
111:13 - the talk if you're not familiar with
111:14 - gatsby going into gatsby browser adding
111:17 - a react a react component there helps
111:19 - you add something to every page and
111:22 - ensure that it's always rendering we
111:24 - don't need to wrap it in anything
111:25 - because
111:27 - we're using x state behind the scenes so
111:29 - there's no context provider or anything
111:31 - like that that you need with use auth
111:34 - everything is completely independent
111:35 - we're going to take the dispatch
111:37 - function from use use off this is a
111:41 - helper that's returned from the use auth
111:43 - that's returned from the user hook so
111:45 - that you can send events to the x-state
111:47 - machinery behind the scenes we don't
111:49 - need to render anything because again
111:51 - this is not a wrapper and we're going to
111:53 - have an effect that runs or on every
111:56 - initial page load but does not run on
111:59 - subsequent re um re-renders we're going
112:02 - to dispatch a set config event we're
112:05 - going to give it an auth provider that
112:08 - comes from
112:10 - providers.net life identity we're going
112:13 - to send use off our navigate function
112:16 - this is so that it can work with any
112:18 - routing solution that you want to use
112:20 - you can always use use auth regardless
112:23 - of what you're set up as long as you
112:24 - give it the whatever function it needs
112:27 - to call to navigate because it needs to
112:29 - change between pages sometimes now to
112:31 - show that it's actually working
112:33 - we're going to go into index.js and
112:35 - we're going to create a login
112:38 - login component
112:41 - which doesn't need to get any props it's
112:45 - going to
112:47 - take is authenticated
112:50 - authenticated is a method that comes
112:53 - from use off and tells us whether the
112:55 - user is currently authenticated if the
112:58 - user is authenticated
113:00 - we're going to
113:02 - return a logout button
113:05 - button
113:06 - which on click calls logout which comes
113:10 - from use off
113:12 - log out and we're going to say that we
113:15 - are currently logging out
113:17 - else
113:18 - we're going to return a button
113:21 - that on click
113:22 - calls the login function
113:25 - login
113:27 - and we say
113:28 - login so now a button should show up
113:31 - here let's see if it does oh we need to
113:33 - actually render it duh
113:35 - so we're going to render the login
113:37 - button here
113:39 - we now get a button and when i click
113:41 - this the netlify identity
113:43 - should pop up and ask me
113:46 - whether i want to log into this page
113:49 - in theory that should work but it's not
113:52 - five minutes later i don't know what i
113:54 - did wrong because it now works without
113:57 - me changing anything
113:58 - computers right so i click login
114:01 - and it asks me for the netlify url that
114:04 - i'm using for your for netlify identity
114:07 - i'm gonna copy it so that i don't type
114:10 - or anything
114:11 - and set site sites url i can now log in
114:15 - as myself and i am logged in see the the
114:18 - button changes to logout i'm still me if
114:21 - i reload the page use auth looks at the
114:24 - local storage and make sure that it
114:27 - checks the when when my session is
114:29 - expiring and preemptively puts me in the
114:31 - logged in state before it talks to the
114:33 - auth provider and verifies that that is
114:35 - still true what i can also do here
114:37 - is instead of just saying hi people i
114:41 - can say hello to myself
114:43 - so we're going to
114:44 - return
114:46 - this layout stuff and i'm going to
114:49 - uh
114:50 - user
114:51 - equals use auth again everything
114:54 - everything connects to the data in the
114:56 - background without me having to really
114:57 - think about it i'm just calling use aust
114:59 - wherever i need something about being
115:03 - being authenticated or about the current
115:05 - user and if i'm authenticated i'm going
115:08 - to show user.email
115:10 - otherwise i'm going to say hello people
115:13 - i need to get is authenticated
115:17 - as well
115:19 - let's see so it now says hi swizzads
115:22 - blah blah blah i can log out
115:24 - puts me back in log in and it just works
115:27 - now let's say you want to change your
115:29 - authentication provider you're tired of
115:30 - netflix identity you want to use
115:32 - something a little bit more powerful
115:33 - with better administration features or
115:35 - whatever what does it take
115:38 - right now when you think about your
115:39 - current app what does it take to switch
115:41 - to a different authentication provider
115:43 - it's usually a lot of work right so what
115:45 - we're going to do now is switch this app
115:48 - to using auth0 instead still using use
115:51 - off and yes those are the only two
115:53 - authentication providers that are
115:54 - currently supported
115:56 - it's this takes time so let's see
116:00 - we're going to go back into gatsby
116:01 - browser and instead of netlify identity
116:04 - we're going to use alt0 as the provider
116:07 - we're going to give it the dispatch
116:08 - function and it's going to need a little
116:11 - bit more configuration because we need
116:13 - to set application keys and stuff like
116:15 - that we're gonna have to create a new
116:18 - all zero callback page as well this page
116:20 - makes sure that all xero when it
116:22 - redirects you back to your app has
116:24 - somewhere to go we're gonna call it
116:26 - all0callback.js
116:28 - put it in source.pages and yes i'm copy
116:31 - pasting from my old code because you
116:32 - don't want to watch me type all of this
116:34 - it's basically taking the handle
116:36 - authentication function from use off and
116:39 - calling it whenever that function
116:41 - changes or the page is loading now let's
116:43 - see
116:44 - if this magically starts working five
116:46 - minutes later giving you more power than
116:49 - netlify identity but also a little bit
116:51 - more responsibility click login
116:54 - go to the auth xero authentication page
116:57 - see this is fully secure it's on their
116:59 - domain so i can't steal anything i'm
117:02 - going to use my existing user it's going
117:05 - to redirect us back yes i'm authorizing
117:07 - the app to to be used comes back to the
117:10 - callback page
117:11 - and it should me should redirect me
117:14 - immediately
117:15 - but it is not so i'm going to switch to
117:17 - the old mode because use auth v1 is
117:21 - completely backwards
117:23 - compatible with the previous stuff so
117:26 - we're going to render this off provider
117:28 - which the auth provider is designed to
117:30 - magically set you up with aut00
117:33 - so now this is reloading and it's
117:35 - redirecting me back and yay it works so
117:38 - obviously v1 still might have some bugs
117:40 - by the time you watch this i will have
117:42 - fixed them i can log out it redirects me
117:44 - to the home page to make sure that
117:46 - everything is fresh
117:47 - log in
117:50 - yes see it works as promised we got that
117:54 - working in less than five minutes using
117:56 - both of the providers that are currently
117:59 - supported netlify identity and auth0
118:02 - it's all use auth is designed so that
118:04 - you can easily add different providers
118:06 - i've created a an interface that is sort
118:09 - that seems to be working for multiple
118:11 - providers so i would like you because
118:14 - this is open source you can add new
118:16 - providers maybe add your own add your
118:18 - favorite there's um i'm going to add
118:21 - documentation on how to do that very
118:23 - soon you can go to use auth.dev to learn
118:25 - more about how all of this works to
118:28 - learn more about how to provide how to
118:30 - add different providers to read the
118:32 - documentation and start using it in your
118:33 - own app i'll be hanging out in the chat
118:35 - room if you have any questions
118:39 - off in five minutes
118:42 - that's uh that is impressive on its own
118:45 - it's so incredible um with this is like
118:48 - the the problem that i hear about with
118:50 - uh with these uh static
118:53 - static site builders and that kind of
118:55 - thing
118:55 - uh so it's it's really cool and what's
118:58 - even cooler is that we have swiss here
119:00 - to talk with us uh and so i'm i'm
119:03 - excited about that
119:05 - welcome sweetie yeah
119:08 - hey everyone hi
119:10 - welcome we're so excited you could join
119:12 - us for this live chat after that awesome
119:15 - talk wonderful
119:17 - um
119:18 - we are we are really uh thankful to have
119:20 - you here with us and especially now you
119:23 - know we've heard so much about this um
119:25 - this auth library we're gonna talk more
119:27 - about it um in this chat right here but
119:30 - for me i'm curious you know there are so
119:32 - many things you've worked on so many
119:34 - things that you do as a developer and as
119:36 - an educator
119:37 - what uh made you want to talk about this
119:39 - topic here today with our audience
119:42 - yeah so it's a funny story actually i
119:44 - created the library itself it came out
119:47 - of trying to teach people how to build
119:49 - this stuff how to build full stack apps
119:51 - and
119:52 - by my second or third time i was like
119:54 - this is stupid it's just always the
119:56 - exact same thing this shouldn't be
119:58 - something that you learn it should be
119:59 - something that just works for you so i
120:01 - created that library and i figured
120:04 - it it's taken me a while but now that
120:06 - it's v1 i wanted to talk about it at
120:09 - react-a-thon and encourage people to
120:11 - contribute and somebody asked in the
120:13 - chat room about um
120:15 - adding more providers you can add those
120:18 - providers and i would really love it if
120:19 - you did
120:22 - so that's the official the official
120:24 - request here is is for other people to
120:26 - come along and
120:28 - and bring their own providers because
120:30 - now that it's in in uh 1.0 stage
120:33 - uh it's ready for that right
120:36 - yeah exactly the that was the big thing
120:38 - that we that everyone's been waiting for
120:40 - i've had a lot of people ask hey does it
120:41 - support anything other than odd0 can i
120:43 - use it with my own thing can i use it
120:45 - with traditional sessions and
120:48 - now you can i've only tested it with
120:50 - netlify identity and
120:52 - all zero but the idea is that there's a
120:55 - an api layer built into the library that
120:58 - lets you add more providers like almost
121:01 - like a plugin system kind of there's an
121:03 - abstraction layer and you if you follow
121:06 - that abstraction layer you should be
121:08 - able to magically make it work with
121:09 - everyone but like i said in the talk
121:11 - this takes time
121:14 - yes and so important to get right
121:17 - as we saw yes um absolutely so if folks
121:21 - are you know wondering like oh man i
121:23 - would really love to use this but it
121:24 - doesn't have a plug-in for my uh
121:27 - provider of choice provider that i'm
121:29 - tied to they can actually go in and add
121:32 - it themselves that's so exciting so
121:34 - other than extending this to work with
121:36 - more different auth services is there
121:38 - anything else that you're hoping that
121:39 - folks um you know come in and help out
121:41 - with or things that you're thinking of
121:43 - for v2 now that v1 is done
121:46 - yeah i mean honestly
121:47 - i just want people to use it try it out
121:49 - tell me how it is
121:51 - um
121:52 - examples are always great i love it when
121:54 - people like i originally built it with
121:57 - just gatsby in mind and then somebody
121:58 - came and added the create react app
122:00 - example somebody added an xjs example so
122:02 - i would love to see more of that because
122:05 - i can't do everything myself and
122:07 - examples in particular can be really
122:09 - tricky to build but if anyone wants to
122:11 - pitch in i would be super excited about
122:12 - that
122:14 - awesome enough i assume that oh go ahead
122:18 - good job
122:22 - here we are um so
122:24 - i i assume the best place for people to
122:27 - contribute would be
122:29 - uh in the official repo
122:32 - and where else can they find you and
122:35 - your work
122:36 - yeah so i'm super excited to push other
122:39 - people's work as well i we have the all
122:41 - contributors spec we follow it everyone
122:43 - if you add code if you have
122:44 - documentation you will be on the github
122:46 - readme
122:47 - as for my other stuff you can follow me
122:49 - on at
122:51 - swizzits on twitter if you put swizzits
122:53 - into the internets in google you will
122:55 - probably see the first three pages of
122:57 - results are about me
122:59 - i have serverlesshandbook.dev which is a
123:02 - free resource if you want to get into
123:03 - serverless and full stack stuff
123:05 - and i blog at swisses.com i'm taking a
123:08 - break right now but in general i post
123:11 - relatively
123:12 - often
123:14 - awesome very thank you so much for
123:16 - joining us
123:18 - yeah thank you for having me
123:21 - thanks again
123:23 - oh man that's cool jonathan
123:26 - we got we got so many cool speakers
123:29 - yeah official official call for um
123:32 - for people to go and create their own
123:34 - auth providers that's that is one of the
123:36 - hardest problems and that's that's so
123:38 - exciting that that is uh that that's
123:40 - getting better in the react
123:42 - uh ecosphere i suppose ecosphere is that
123:45 - a word
123:46 - it is now it is now today you're here to
123:49 - hear first folks the react ecosphere
123:52 - coming at you live
123:55 - and what i love about this is that um
123:57 - you know i love uh venues like this
123:58 - conferences you know in real life or
124:01 - online where we can hear about these
124:03 - exciting new libraries and tools that
124:06 - are coming out that can make uh
124:07 - developer life easier and folks can
124:09 - actually go in and get involved in
124:11 - things that they're excited about so
124:12 - really hoping that some folks get to
124:14 - connect with swiss after this on github
124:17 - um that folks are able to use this
124:19 - library successfully in their own work
124:21 - and don't have to worry about off and
124:24 - breaking it
124:25 - so that is a super exciting
124:28 - takeaway from this i think um but yeah
124:31 - shall we keep it moving and keep on with
124:33 - our our next amazing talk here
124:36 - yeah absolutely let's go
124:38 - let us go okay so our next talk is going
124:42 - to come at us from alex krolick who is a
124:45 - software engineer at box and a
124:47 - maintainer of the react testing library
124:50 - and that i believe is what we're going
124:52 - to be talking about today
124:54 - yeah you're going to learn how to use uh
124:57 - async code in your react apps you're
124:59 - going to learn how to use react testing
125:01 - library to test that
125:03 - uh this talk will show you how to test
125:04 - async code such as network calls timers
125:08 - and promises and react these are the
125:10 - things of nightmares for a lot of
125:11 - engineers especially when you go to try
125:14 - to test them so you're going to learn
125:16 - how to put those nightmares out of your
125:19 - mind and sleep better at night hopefully
125:22 - uh so let's get straight into this talk
125:24 - with alex kralik
125:27 - hello everybody and welcome to this talk
125:29 - about testing async components i'm alex
125:32 - scrollick i a good box and in my spare
125:35 - time i help out with react testing
125:37 - library
125:39 - before we get into timers promises and
125:42 - api calls i want to do a quick recap of
125:44 - component testing 101
125:47 - so what that looks like
125:48 - is you'll have a ui element and you'll
125:50 - go through three phases to arrange act
125:52 - assert
125:53 - steps
125:55 - so in testing library terms
125:57 - that's render the component then find
125:59 - elements and fire events on them and
126:01 - then use your expectations to do
126:03 - assertions about the final state
126:06 - so for this example we have a comment
126:07 - box and we're going to pass in on submit
126:09 - prop that's a just mock function um
126:13 - into its
126:14 - own submit handler then we're going to
126:17 - find this uh element the text box
126:20 - element we're going to enter a value
126:21 - into it then we're going to click submit
126:24 - and then finally we are going to move
126:27 - into the
126:28 - assertion phase and we're going to
126:30 - assure that our
126:32 - our click handler has been our submit
126:34 - handler has been called with the right
126:35 - data and that our text
126:37 - submitted has appeared in the document
126:40 - one thing you'll note
126:43 - so we're not using act here because
126:44 - react testing library wraps fire event
126:46 - with that automatically so any effects
126:48 - that are generated there
126:50 - and microtasks are cleaned up by react
126:52 - and rendered before we move on to the
126:54 - next of the test
126:56 - the difference between this component
126:58 - and components in a real app is that
127:00 - it's fully synchronous so there's no
127:01 - delays everything happens immediately
127:03 - whereas a real test is full of sources
127:05 - of asynchronicity
127:06 - from timers promises and networks
127:09 - you're going to see animations browser
127:12 - apis are going to be using promises and
127:14 - everything is basically sync all the
127:16 - time
127:18 - so i'm going to walk through each of
127:19 - those three elements timers promises and
127:22 - network and talk about how you can deal
127:24 - with
127:24 - them so first
127:27 - timers
127:29 - i'm going to extend that previous
127:30 - example a little bit and say that we've
127:32 - debounced the change handler for the
127:34 - input box that's inside of this comment
127:37 - modal form thing
127:39 - so
127:40 - what a debounce does is it makes sure
127:42 - that the function isn't called until the
127:45 - user stops interacting with the thing so
127:48 - we're now at a 200 millisecond delay to
127:51 - prevent that change handler from being
127:52 - called in every single key press that
127:54 - will affect our test because we can no
127:56 - longer immediately click that button
127:57 - after we stop typing
127:59 - because we're waiting for that delay to
128:00 - kick in
128:02 - so
128:03 - what do we do about it strategy one we
128:06 - just get rid of the timer completely so
128:07 - we can find anywhere on our code that
128:09 - has a timeout and replace that constant
128:10 - with a zero
128:12 - and the other thing that we can do is
128:14 - mock out any functions that are creating
128:15 - timers i.e the low dash
128:18 - debounce function
128:20 - and replace it with a mock function that
128:21 - we can then assert about
128:23 - so since blue dash debounce is fairly
128:26 - well tested and we we kind of trust it
128:28 - to work this is a pretty good candidate
128:30 - for it because we can say was that
128:32 - function debounced was that callback
128:34 - debounced yes because of this this mock
128:38 - but we don't care about the actual
128:39 - implementation of that code running so
128:41 - it doesn't affect our test anymore it's
128:43 - no longer asynchronous
128:46 - the other strategy that we can do is we
128:48 - can use fake timers meaning it's like
128:50 - driving a stick shift you're taking full
128:52 - control of the test and all the time
128:55 - inside of it so
128:56 - uh the way that just handles it and
128:58 - there's an equivalent sign-on is that
129:00 - there's an api called fake timers
129:02 - just use fake timer startsit
129:06 - and every time you want to advance time
129:08 - you have to call one of the apis it's
129:09 - either run all timers which runs every
129:11 - timer that has been created or advanced
129:14 - timers by a time and that will
129:17 - allow it to move forward just only by
129:19 - that specific amount
129:20 - so in our test after our change after
129:22 - we're triggering that text box is change
129:25 - event
129:26 - we would advance the time by our
129:28 - debounce
129:29 - amount 100 milliseconds and then after
129:32 - that we could finally click the putt the
129:33 - disadvantage of this
129:35 - is that if you have uh advanced timers
129:37 - by time a round timer is all over the
129:39 - place in your test it gets a little bit
129:41 - hard to manage because um
129:43 - now you have to know everywhere that a
129:46 - potential asynchronicity is happening
129:48 - and kind of manually work around it and
129:49 - it can you kind of end up with manual
129:51 - time and control all over the place if
129:53 - this is something you use wildly
129:55 - so
129:56 - the alternative
129:58 - and this is kind of the preferred
129:59 - testing library pattern and something
130:01 - that's very much enabled by testing
130:02 - library apis is to make the whole test
130:04 - async and then if you want to do uh any
130:07 - optimizations around individual d-bounds
130:11 - or anything like that you can but
130:13 - anything small is going to be glossed
130:14 - over
130:15 - single ticks or 20 20
130:18 - 100 milliseconds
130:20 - that'll that'll go off without hiccup in
130:21 - the test so the big difference is
130:24 - in how you write a test that's async
130:26 - versus synchronous are these
130:29 - so first
130:30 - you've got to rewrite your test to await
130:32 - syntax
130:34 - so
130:35 - by changing it to an async function you
130:37 - can then use a weight anywhere which
130:39 - kind of resembles a synchronous thing
130:41 - but it's actually using promises under
130:42 - the hood
130:44 - and then the big difference is that
130:45 - anywhere where you think that you may
130:48 - have something that's going to take a
130:50 - certain amount of time or certain amount
130:51 - of ticks
130:52 - you want to replace that manual weight
130:55 - like you know wait 200 milliseconds or
130:58 - advanced time or 20 milliseconds with an
131:00 - assertion about the the next step um and
131:04 - when it's ready to proceed
131:06 - so in this case what we can say is that
131:08 - that button is disabled well the input
131:10 - box is empty once we type the value in
131:12 - there it will become enabled
131:15 - so what we can say is we can add this
131:17 - little assertion inside of the wait for
131:19 - callback that expects that button to not
131:22 - be disabled and then after that becomes
131:24 - true we'll be able to move on to
131:25 - clicking it
131:26 - so that's just a retrial assertion that
131:28 - signals to us when we can continue the
131:31 - test
131:33 - if the assertion that we're talking
131:34 - about is that an element is appearing we
131:36 - have a shortcut which is that we can
131:38 - replace any get by queries
131:40 - with find by queries so we're replacing
131:42 - our get by text with a find by text
131:44 - which is an awaitable assertion that
131:46 - will retry until that element is in the
131:48 - dom
131:50 - this pattern is basically what you're
131:52 - going to use for promises as well as
131:55 - most timers
131:57 - it works pretty well in both scenarios
132:00 - so if you have promises the first thing
132:02 - you're going to do rewrite async tests
132:04 - but the big difference between a timer
132:05 - test and something that's dealing with
132:07 - promises the promises typically affect
132:09 - control flow
132:11 - so the code needs to be testing both the
132:14 - resolve path and the reject path
132:17 - so
132:18 - just mock functions can do that for you
132:20 - so if i have a mock function like the
132:22 - one we passed in on submit what we can
132:24 - do is we can say mock rejected value
132:26 - once that'll
132:28 - say that when that function is called to
132:30 - return a rejected promise with this data
132:32 - which is a 500 status code a server side
132:35 - error
132:36 - and then we can have our async find by
132:38 - text query that's looking for that
132:40 - server error to be
132:42 - shown to the user in the dom
132:46 - now moving on our final source of
132:49 - asynchronicity is the big one the actual
132:51 - network
132:52 - so
132:53 - in a test you really don't want to be
132:55 - hitting real servers because for one
132:57 - they're unreliable um you don't want
133:00 - your front-end test code to be totally
133:01 - reliant on the entire backend system and
133:04 - for a vital reasons you might not
133:05 - actually be able to access it and then
133:07 - of course as we've just shown there's a
133:09 - good chance that we're also wanting
133:10 - wanting to be able to test
133:13 - you know error error paths or bad data
133:15 - being passed in
133:17 - finally of course it could be pretty
133:18 - slow
133:20 - so
133:21 - the way we can deal with network api
133:23 - calls in a unit test
133:25 - um
133:26 - first approach
133:28 - take whatever interface that we're using
133:30 - to call the api and mock it usually they
133:32 - have a promise based interface so we
133:34 - just use the same patterns that we've
133:36 - been using
133:37 - um so if we're using window fetch we
133:40 - replace that with a mock function and
133:41 - then we treat it like a regular promise
133:43 - anywhere that we want to call
133:45 - that api we replace the value
133:49 - with some data that we've mocked out and
133:51 - then we respond to the mock results
133:53 - normally if we want to pass in bad data
133:55 - we change it to a rejected downside of
133:57 - this approach
133:58 - if we change our mind about using window
134:00 - fetch we change it to axios or something
134:02 - um
134:04 - now we kind of have to rewrite all of
134:06 - our tests to conform to that new test uh
134:09 - a new
134:10 - data format so for example fetch you
134:13 - always have to call res json do you want
134:15 - to mock out you know the json methods on
134:18 - all this stuff not necessarily um so it
134:20 - might be kind of over constraining your
134:22 - test a little bit if you're always using
134:24 - these interfaces but to get started if
134:26 - you just have a few calls that you need
134:28 - to mock out this is definitely what you
134:30 - can do it
134:32 - a bit more sophisticated approach is
134:34 - that we could actually mock out a fake
134:36 - server so there's a few libraries that i
134:38 - am aware of so mock service worker and
134:41 - mirage js they both seem to work fairly
134:43 - similarly the idea is that you have a
134:46 - service worker that can intercept
134:48 - calls to certain routes
134:50 - and then replace them with fake
134:52 - responses so in this example which i
134:54 - pulled from the testing library docs um
134:58 - we set up a server that is responding to
135:00 - this greeting route and it's sending
135:01 - back a bad
135:03 - bad status code to 500.
135:05 - so every time somebody calls slash
135:07 - greeting
135:08 - that's what they're going to get back
135:09 - and then in different tests you can
135:10 - change the response to something else um
135:12 - this works pretty well the only real
135:14 - downside here is that now we're kind of
135:16 - couple to the network interface rather
135:18 - than the specific library so potentially
135:20 - if we're thinking about refactoring big
135:22 - chunks of the app
135:24 - we may want to have some kind of
135:25 - abstraction between our actual network
135:27 - calls and what we're doing in the app so
135:29 - here's how you could do that
135:31 - so
135:32 - creating an api module is as simple as
135:35 - creating a file let's call it api js and
135:37 - then you put all of your code design
135:39 - network in there so in this case we've
135:41 - got something called get user that's an
135:42 - async function takes an id and then it
135:44 - does window fetch for a certain endpoint
135:47 - if we later replace that with a
135:49 - different library or we introduce
135:51 - something
135:53 - some response handling in there or even
135:54 - rewrite it to hit a graphql endpoint
135:56 - instead this will keep working because
135:58 - the app code is insulated from that at
136:01 - the same time the way that we use our
136:02 - tests uh we use this module in our test
136:05 - is we can generate create mock from
136:07 - module which will take all of these
136:08 - functions and replace them with mock
136:10 - functions
136:10 - and then we can say okay get user let's
136:13 - change the
136:14 - value to return say on authenticated
136:17 - status code uh 401
136:19 - or we could change it to return or
136:21 - actual user data um
136:23 - the downside with that again is that now
136:25 - we kind of have created this additional
136:26 - interface here so we do have to both
136:28 - unit test it and validate that it
136:30 - actually is correct um and then also if
136:33 - you're working with state management
136:34 - code that is very intelligent that makes
136:36 - api calls on your behalf it's not
136:38 - necessarily going to want to go through
136:40 - this intermediary module so
136:43 - um
136:44 - so for these like very intelligent new
136:46 - libraries that might not be the way to
136:48 - go
136:50 - so that said
136:52 - we've been talking about just we've been
136:54 - talking about unit tests i'm talking
136:57 - about the downfalls where
136:58 - interfaces can kind of not be quite
137:01 - right between what we thought we were
137:02 - testing and what actually happens when
137:03 - we build the app so sometimes testing in
137:05 - a real browser in an end-to-end testing
137:07 - scenario is the way to go
137:09 - cyprus is a pretty good library for that
137:13 - cool thing about cyprus is that all of
137:15 - its uh assertions all of its uh queries
137:17 - for elements are already async so more
137:20 - than the get queries they resemble the
137:22 - find by queries in react testing library
137:24 - um so the
137:26 - built-in.get.contains methods
137:28 - they're async
137:29 - so they'll retry until that album exists
137:31 - which is very good if you have
137:32 - asynchronous code anywhere um
137:35 - if you want to use the exact queries the
137:37 - testing library exposes the role query
137:39 - for example an accessible assertion or
137:42 - an accessible query
137:43 - or a label text or placeholder or
137:45 - anything like that we have a plugin
137:47 - called testing library cypress and you
137:49 - can then use
137:51 - all of those commands as well and they
137:52 - behave in the exact same way
137:55 - if you do decide that that intent test
137:58 - maybe has a few paths that you weren't
138:00 - able to test maybe you want to test
138:02 - errors or something
138:03 - you can do network mocking in cyprus 2.
138:06 - so they've iterated through this api a
138:08 - few times but where they've settled now
138:10 - is called cypress intercept in older
138:12 - versions it was called router route 2
138:14 - but they are acting very similarly to
138:17 - the service worker methodology that we
138:19 - were talking about before where you say
138:20 - an individual route
138:22 - and then when it's called certain
138:23 - arguments it returns certain values so
138:26 - very powerful very useful
138:28 - and ultimately
138:30 - you have kind of a whole suite of
138:32 - options available to you as far as
138:34 - testing all the steps all this code
138:36 - so that's pretty much everything i have
138:39 - i'm hoping that
138:40 - these techniques were useful to you if
138:42 - you want to read more they're up to date
138:44 - guys on the testinglibrary.com website
138:46 - as well as react.js.org and justjs.io if
138:49 - you want to get in touch with me my
138:51 - website is alexcrolic.com and on github
138:53 - i'm also alex frolick
138:55 - thank you so much
139:00 - a huge thank you to alex for joining us
139:03 - and talking about
139:04 - that asynchronous testing and cypress
139:07 - and all of those good things
139:09 - uh of course testing is always becoming
139:12 - more important
139:14 - as we build more and more complex
139:16 - applications with react
139:18 - they're they're about as complex as they
139:20 - can get uh and um
139:22 - hopefully you know the observability of
139:25 - applications is a big deal right now and
139:27 - that's kind of what we're gonna hear
139:29 - about in the next talk right
139:30 - on jenna
139:32 - yeah so our next speaker is going to be
139:35 - brian manuel who is a software engineer
139:38 - at flexport and is going to be showing
139:41 - us how to quantify
139:43 - the health of a react code base which i
139:45 - am really excited to learn about so
139:48 - without further ado let's welcome our
139:50 - next lightning talk speaker brian manuel
139:58 - all right let's jump right in
140:01 - so to kick off this presentation i want
140:03 - to begin by telling you a story that
140:06 - takes place in the year 1993.
140:09 - now the year 1993 is a pivotal year in
140:12 - computing history because it marks the
140:14 - beginning of what is known as the
140:16 - browser wars
140:17 - now just three years prior
140:20 - tim burns lee at cern had just invented
140:22 - arbinet
140:23 - uh thereby birthing would later be known
140:25 - as the internet
140:27 - and in this year the year 1993
140:30 - we have uh the creation of three major
140:33 - browsers the links browser the arena
140:36 - browser and the mosaic browser
140:38 - each find to become the first viable
140:40 - user interface to world wide web each
140:43 - bringing with them their own opinions on
140:44 - what a browser should be
140:46 - and how the markup language of the web
140:48 - should be
140:49 - and each
140:50 - rapidly innovating eager to bring about
140:52 - the new wave of the internet
140:55 - links browser was the first scene it
140:57 - brought with it the concept of html
141:00 - followed by the arena browser which
141:02 - brought the concept of the gui for the
141:04 - web and also introduced the concept of
141:06 - the image tag
141:07 - and last but not least the mosaic
141:08 - browser brought with a whole slew of new
141:11 - tags such as form tag
141:14 - nested lists etc
141:17 - and also not so desirable tags such as
141:19 - the blink tag and the marquee tags
141:23 - and so 1993 was a period of dizzying
141:26 - innovation in the browser sphere
141:29 - all these browsers had uh wonderful
141:31 - ideas on where the specs should go for
141:34 - html
141:35 - uh
141:36 - and sometimes these ideas were at
141:38 - conflict so in the year 1994 all the
141:41 - major engineers and academics behind the
141:43 - browsers decided to convene in geneva
141:46 - for what was known as the w3c or the
141:49 - world wide web consortium
141:51 - and here's a picture that very first
141:52 - meeting
141:54 - and 3c essentially hashed out what the
141:58 - spec for html and the web should be
142:00 - and because of what w3c and what they
142:03 - did
142:04 - uh
142:05 - we now have a standardized spec for html
142:08 - javascript and css and we can pretty
142:11 - much have a very consistent experience
142:13 - across all the major browsers
142:16 - and one thing that the introduction of
142:19 - the w3c would introduce extra overhead
142:21 - to the various browsers but it really
142:23 - hasn't uh browsers are still innovating
142:26 - at a rapid pace
142:28 - here we have a picture of the web gpu
142:30 - experiments that firefox is running on
142:31 - firefox nightly
142:33 - here's an image of html portal element
142:35 - which is experiments that chrome is
142:37 - running on chrome canary
142:40 - and what w3 c brought to the table is
142:43 - process invisibility into its innovation
142:46 - cycle and so
142:48 - you're able to track how web gpu is uh
142:51 - progressing uh via their website
142:54 - uh and how portal is progressing uh it's
142:57 - very cool
143:01 - and
143:01 - the reason why i bring up the story
143:03 - about
143:04 - uh the browser wars and the forming of
143:07 - the w3c
143:08 - is because
143:09 - it's a story about an ecosystem and
143:12 - ecosystems share a very fundamental
143:15 - concept called ecosystem life cycle
143:18 - every ecosystem starts from some sort of
143:20 - solid foundation
143:22 - it will then go through a period of
143:24 - rapid growth
143:26 - and then
143:27 - finally
143:29 - consensus and best practices will emerge
143:30 - in that ecosystem and
143:32 - if
143:34 - it it's so called for standards will
143:36 - emerge as well
143:38 - and it turns out that a react code base
143:41 - is also an ecosystem and a subject of
143:43 - this talk
143:45 - us react code base will grow over time
143:48 - and uh the team members that
143:51 - write in that reaction code base will
143:53 - grow over time and these team members
143:55 - will introduce
143:56 - new best practices new concepts new
143:59 - packages entire new ways of thinking
144:01 - into react code base
144:04 - at some point we'll want to start
144:06 - tracking
144:07 - these ideas and how they evolve we want
144:10 - to identify trends emerging best
144:12 - practices and where we need to improve
144:16 - just as the w3c did for the browser
144:18 - sphere back in 1994
144:21 - and once we understand these trends we
144:24 - can begin to remote them and reinforce
144:26 - them and if it's so called for answer to
144:29 - standards
144:30 - and guidelines
144:33 - and so the person's talk is to get you
144:36 - to a point where
144:37 - you can be the w3c for your own react
144:40 - code base
144:41 - and
144:42 - learn some strategies on how to manage
144:44 - and guide the growth of your code base
144:47 - and the process by which we'll be doing
144:48 - so is this three step process we'll
144:52 - first go over how you can ask
144:53 - quantifiable questions about the health
144:56 - of a react code base
144:58 - how you can answer those questions using
145:00 - stack analysis
145:02 - and finally how you can crystallize
145:04 - those best practices by turning your
145:06 - analysis queries into
145:08 - say lint rules or into code mods
145:14 - and what we won't be going over so this
145:16 - is react define after all and we will be
145:18 - focusing prominently on react and
145:20 - anything outside this cover react it
145:22 - won't be covered so bottle stats code
145:24 - styling ci cd
145:26 - all these things are important but you
145:28 - can get information on these elsewhere
145:32 - and a little bit about me before we
145:33 - begin
145:34 - my name is brian uh my alias is for me
145:36 - to rock sometimes just drock
145:38 - and
145:39 - i work on the front infra team at
145:41 - flexport and i've been working here for
145:43 - about the last two years
145:44 - um why she listens to this talk is
145:46 - flexport has one of the largest and
145:48 - oldest react code bases
145:50 - we adopted react five months after it
145:52 - came out and we're pretty much react
145:54 - monolith on the front end i also
145:56 - contribute to react and react like
145:58 - projects like doc gen
146:02 - alright let's begin
146:04 - so code base health
146:06 - before we begin before we can begin at
146:08 - quantifying anything
146:10 - it's important that we ask ourselves
146:12 - where a co-base is in its history and
146:15 - also where it's going
146:17 - what is the state of our code base today
146:19 - when we think about these questions it's
146:21 - important that we pose them in terms of
146:23 - code based health
146:25 - uh how stable how readable how
146:28 - maintainable is our code base
146:30 - and by asking these questions
146:34 - we can begin to understand and get a
146:35 - better feel for
146:37 - what's working what isn't working
146:39 - what needs improvement and how we can
146:42 - improve those things that need
146:43 - improvement
146:46 - and so in this slide since this is
146:48 - reactifon i have some examples of
146:50 - questions that you can formulate around
146:52 - the health and save your react code base
146:54 - so let's just go over them
146:56 - uh
146:57 - our teams creating too many redundant
146:59 - components
147:01 - is our design system library over
147:02 - generic or overly
147:04 - or or not generic enough
147:08 - our engineer is still using a legacy
147:09 - approach to certain systems say css
147:11 - styling and if so why
147:15 - are we
147:16 - uh achieving are we adhering to
147:18 - accessibility standards
147:20 - and
147:21 - should this particular category of
147:23 - component be generalized into a shared
147:25 - component
147:27 - so all these are questions subjective
147:28 - questions that you can ask about your
147:30 - react code base in the next slide we'll
147:32 - go over an exercise on turning one of
147:33 - these questions into
147:35 - an injective question with objective
147:37 - answers
147:38 - so let's focus on one of those questions
147:40 - is our design system library overly
147:42 - generic or not generic enough
147:45 - and to paint some context let's say
147:48 - your company has an internal
147:50 - design system team
147:52 - and that team wants to understand the
147:54 - adoption of their component to library
147:58 - uh i always urge to probe deeper uh go
148:01 - talk to that team figure out exactly
148:03 - what they want and figure out metrics
148:05 - based on your conversations with them so
148:07 - let's say you go talk to that team and
148:09 - you figure out that they're working on a
148:11 - slew of form ui components
148:13 - and they want to understand their
148:14 - adoption rate
148:16 - and what they need to do in order to
148:18 - drive adoption
148:21 - well now we have something to work with
148:23 - we can formulate a question off that
148:26 - what percentage of forms in our code
148:27 - base used to form ui components from our
148:30 - design system
148:32 - and of the forms that don't let's just
148:34 - list them that way the team can go talk
148:36 - to those form code owners and figure out
148:39 - what they need to do with drug adoption
148:43 - and
148:44 - that gives us some quantifiable data
148:46 - that we can track
148:50 - one the adoption rate of form ui
148:51 - components
148:53 - and two
148:54 - uh a list of forms that are not using
148:56 - form ui components
148:59 - and
149:00 - though these queries seem to be nebulous
149:03 - it turns out that we can answer them
149:05 - though very loosely with a stack
149:07 - analysis
149:09 - and the tools of choice i will be using
149:10 - are ast explorer
149:12 - and js code shift ast explorer is a tool
149:16 - that will help us mock and test out our
149:18 - stack analysis queries and js code shift
149:20 - is a library that we'll be using for
149:23 - actually writing these queries
149:25 - all right so this is ast explorer ast
149:28 - explorer is a tool we'll be using to
149:29 - explore running stack analysis queries
149:32 - with
149:32 - it consists of four panels the top left
149:35 - panel is some source code we'll be
149:37 - testing against
149:38 - uh here we have an example form called
149:40 - my form which imports some form ui
149:42 - components
149:44 - renders some stuff and then it returns
149:47 - the form
149:49 - on the right hand side we have a
149:51 - tree representation of our source code
149:53 - so if i were to for instance highlight
149:54 - this import decoration on the left-hand
149:57 - panel it highlights
149:58 - the stringful import decoration
150:01 - uh if i were to highlight this block
150:02 - statement it highlights block statement
150:04 - to the forum
150:05 - it's essentially a true representation
150:07 - of our source code
150:09 - and then on the bottom left hand corner
150:10 - we have our transformer so transformer
150:13 - for js code shift
150:14 - takes some source code and outputs
150:17 - resulting source code
150:18 - so
150:19 - here uh it's parsing our source code
150:22 - looking for any identifier and then
150:24 - reversing uh the text of that identifier
150:28 - and you can see that in the output on
150:29 - the bottom right panel
150:31 - all the identifiers are reversed for the
150:33 - sake of this presentation we're not
150:35 - interested in a transformation so
150:39 - we can delete this and it'll default
150:41 - it's just returning our source code as
150:42 - is
150:44 - going back to our formulated question
150:45 - statement what percentage of forms used
150:48 - to form ui components we can now break
150:50 - this question down into two distinct
150:52 - steps
150:53 - step one
150:54 - get a list of the form components in our
150:56 - code base and in step two from that list
150:58 - determine which forms contain any form
151:01 - ui components
151:02 - and the way we'll be doing so is by
151:04 - looking at the opponent's import
151:06 - statements
151:08 - so for step one it turns out for a
151:11 - theoretical codebase that we're working
151:12 - on
151:13 - doing this is pretty simple
151:15 - all forms have the convention of ending
151:17 - in form.jsx so we can simply walk
151:19 - through a project directory and match
151:21 - for any component file that matches that
151:22 - regex
151:24 - for step two in order to determine
151:26 - whether a form contains formula
151:27 - components we'll do what i described
151:29 - earlier check the forms import
151:31 - statements
151:32 - and the way we'll be doing so is via js
151:34 - code shift
151:36 - um so the first thing i'm going to do is
151:38 - i'm going to copy over this list of form
151:40 - ui component import paths
151:42 - into this file this is a list of all the
151:44 - known form ui components in the report
151:46 - paths
151:47 - and our strategy is going to be
151:49 - uh first
151:51 - find
151:52 - all the import declarations
151:55 - in this file
151:57 - and then uh check if any reference
152:00 - the above
152:02 - import paths
152:03 - and so it turns out with js code shift
152:06 - this is actually quite straightforward
152:08 - we simply call tree.find
152:11 - jscodeshift.import declaration
152:14 - and uh
152:15 - we care about this uh import path so we
152:19 - call.find again
152:21 - uh this import path is a literal so we
152:22 - call find.literal
152:28 - and if we
152:30 - run for each
152:33 - on each of these literals
152:36 - and console.log each of them
152:40 - or rather their value
152:47 - let's open up our console we can see
152:49 - that we are indeed hitting these uh
152:51 - import paths
152:55 - this is what a full implementation ends
152:57 - up looking like
152:58 - now for those of you who want to read
152:59 - this code and dig in
153:01 - don't you worry at the end of this
153:02 - presentation there is going to be a link
153:04 - to github just with the full
153:06 - implementation that you can read play
153:08 - around with and do a fashion please
153:10 - so i hope this section gave you a quick
153:12 - taste of what it's like to write a stack
153:14 - analysis query i hope it didn't go by
153:16 - too fast
153:19 - the final section crystallizing best
153:21 - practices
153:23 - i'm going to show you a scenario say
153:25 - your company is doubling down on
153:26 - internationalization and
153:29 - through analysis we found that we really
153:32 - like i18n
153:33 - we don't want to have any
153:35 - free-floating texted rules in our jsx
153:38 - everything must be passed through i18n
153:40 - for internationalization
153:42 - and our company wants us to enforce this
153:44 - as a standard
153:46 - so there are two ways we could go about
153:48 - this um
153:50 - the first way is we can introduce an
153:52 - eslint rule
153:53 - here we've introduced a new rule called
153:55 - no string literals and it'll create a
153:57 - violation whenever it finds a string
154:00 - literal uh free floating in your jsx
154:04 - this is extra work for your engineers
154:05 - because it means that they'll need to
154:07 - dig into the code and remove these
154:09 - violations and fix them themselves
154:14 - and the other approach is we can write a
154:16 - code mod now the query we wrote
154:19 - was in js code shift and the purpose of
154:20 - js code shift is for writing code mods
154:23 - uh and what codebond is is essentially a
154:25 - transformation of code you go from one
154:27 - type of code to another type of code and
154:29 - here we transformed all these free
154:31 - flowing text rules to be passed through
154:33 - i18n
154:35 - now using uh codemod isn't always
154:37 - possible uh there might for instance
154:39 - there might be too many edge cases or a
154:41 - lot of
154:42 - complexity uh but uh in general you
154:45 - should always hear writing code mod and
154:47 - if you can't
154:48 - definitely go for an eslint rule
154:51 - um
154:52 - so yeah those are two ideas on how you
154:53 - can
154:54 - crystallize best practices
154:56 - and that's it for my presentation
154:59 - reach out if you have any questions i'm
155:00 - going to be at the topic tables later
155:02 - today uh so you can talk to me there uh
155:05 - or reach out earlier it doesn't matter
155:07 - and as promised there are links to the
155:09 - code samples um that's all
155:13 - have a great reaction find everybody and
155:14 - thank you for listening to my talk
155:20 - awesome
155:21 - react uh quantifying react code base is
155:24 - difficult uh but
155:27 - luckily brian has made that seem much
155:29 - easier much easier for us
155:32 - now we are going to move into a very fun
155:35 - part of the day um as a special part of
155:38 - this conference which is our live topic
155:41 - tables this is where you
155:43 - can get up up close and personal with
155:45 - the speakers uh the workshop instructors
155:48 - sponsors and other experts on a specific
155:51 - subject
155:52 - just click on the sessions button
155:54 - if you don't know where that is it's in
155:55 - hop in on the left side of the screen
155:57 - the sessions buttons in the left menu to
156:00 - browse all of those topic tables you
156:02 - could talk about the jam stack with
156:04 - guillermo for example uh you could uh go
156:07 - talk about going from junior to senior
156:09 - engineer with swix
156:11 - or
156:11 - next js with joe
156:13 - uh you can talk about data
156:14 - visualizations with janet beck and many
156:16 - more talks will start up back in a
156:19 - little over an hour at 1 30 pacific time
156:23 - we'll be back here
156:25 - talks will start up back then so we'll
156:27 - see you back here shortly thanks for
156:29 - joining us
156:32 - [Applause]
156:33 - [Music]
157:02 - [Music]
157:10 - [Music]
157:40 - [Music]
158:08 - [Music]
158:51 - i've had my heart broken
158:54 - into
158:55 - [Music]
158:59 - but something's different next to you
159:04 - [Music]
159:06 - it's like my soul is
159:11 - [Music]
159:15 - i'm starting to feel tired
159:19 - [Music]
159:21 - cause i can
159:23 - [Music]
159:32 - [Music]
159:32 - [Applause]
159:36 - is
159:38 - [Music]
159:50 - i know
159:53 - [Music]
160:11 - feelings that i know
160:18 - [Music]
160:40 - i can't keep on this road alone
160:48 - and all this time i
160:50 - [Music]
160:54 - thought all this time
161:01 - [Music]
161:05 - [Applause]
161:11 - bottled up inside
161:18 - is
161:19 - [Music]
161:38 - is
161:53 - feelings
161:54 - [Music]
162:07 - to feel
162:16 - is
162:17 - [Music]
162:39 - wanna know is are you ready for the ride
162:45 - what have i been waiting for oh i can
162:49 - run but i can't hide the feelings that i
162:54 - know
162:57 - [Music]
163:14 - so
163:17 - [Music]
163:56 - so
163:59 - [Music]
165:33 - so
165:36 - [Music]
166:14 - so
166:16 - [Music]
167:00 - [Applause]
167:02 - [Music]
167:07 - [Applause]
167:12 - so
167:13 - [Music]
168:09 - so
168:12 - [Music]
168:16 - [Applause]
168:22 - so
168:23 - [Applause]
168:26 - [Music]
169:29 - next
169:32 - [Music]
169:45 - so
169:51 - [Music]
170:14 - [Music]
170:19 - without you baby
170:21 - [Music]
170:31 - is
170:33 - [Music]
170:39 - tell me
170:41 - [Music]
170:50 - [Music]
170:55 - i'm
170:59 - [Music]
171:08 - baby
171:10 - [Music]
171:30 - is
171:35 - [Music]
171:48 - is
171:49 - [Music]
172:05 - nobody
172:07 - [Music]
172:16 - is
172:19 - [Music]
172:29 - tell me
172:32 - [Music]
172:34 - [Applause]
172:40 - [Applause]
172:40 - [Music]
172:43 - is
172:46 - [Music]
172:53 - [Applause]
172:54 - [Music]
173:09 - give me
173:12 - [Music]
173:16 - [Applause]
173:19 - [Music]
173:32 - [Applause]
173:36 - me baby
173:39 - [Music]
174:02 - [Music]
174:22 - [Music]
174:30 - there's a song in my head
174:33 - [Music]
174:44 - so i love you so bad
174:48 - [Music]
175:00 - every single crowd
175:02 - and i know you love me
175:06 - [Music]
175:27 - is an open sky full of dreams
175:37 - [Music]
176:08 - till the sky
176:15 - [Music]
176:19 - falls down
176:21 - [Music]
176:25 - [Applause]
176:25 - [Music]
176:52 - since i met you i didn't know
176:56 - [Music]
177:12 - is
177:14 - [Music]
177:25 - [Music]
177:35 - [Music]
178:15 - so pick me
178:19 - [Music]
178:30 - i think you're perfect
178:32 - [Music]
178:56 - [Music]
179:04 - for me
179:07 - [Music]
179:52 - [Applause]
179:53 - [Music]
179:57 - [Applause]
180:04 - [Music]
180:12 - [Music]
180:29 - so
180:32 - [Music]
180:43 - so
180:45 - [Music]
181:01 - so
181:03 - [Music]
181:30 - [Music]
181:54 - so
181:57 - [Music]
182:18 - [Music]
182:36 - so
182:42 - [Music]
183:31 - [Applause]
183:37 - [Applause]
183:38 - [Music]
183:43 - [Applause]
183:44 - [Music]
184:15 - so
184:18 - [Music]
185:21 - so
185:22 - [Music]
185:29 - [Applause]
185:30 - [Music]
186:09 - so
186:13 - [Music]
186:30 - so
186:34 - [Music]
186:47 - so
186:53 - [Music]
187:17 - so
187:26 - [Music]
187:59 - [Music]
188:11 - so
188:12 - [Music]
189:33 - [Music]
190:34 - [Music]
190:48 - [Music]
190:58 - [Music]
192:37 - [Music]
192:40 - [Applause]
192:44 - [Music]
192:59 - [Applause]
192:59 - [Music]
193:04 - [Applause]
193:05 - [Music]
193:09 - [Applause]
193:11 - [Music]
193:18 - [Music]
193:32 - [Music]
193:43 - oh
193:45 - [Music]
193:57 - um
193:58 - [Music]
194:34 - it's
194:36 - [Music]
195:16 - i was watching you
195:22 - [Music]
195:31 - show me something
195:35 - [Music]
195:46 - singing
195:54 - through the windows
196:01 - [Music]
196:14 - like superheroes
196:16 - [Music]
196:23 - [Music]
196:42 - i couldn't see it
196:44 - until you showed me
196:51 - [Music]
197:10 - is
197:15 - through the windows
197:18 - [Music]
197:23 - [Music]
197:42 - every night on fire
197:46 - [Music]
198:19 - tonight is
198:22 - [Music]
198:36 - is
198:38 - [Music]
199:13 - is
199:16 - [Music]
199:24 - is
199:26 - [Music]
199:34 - oh
199:48 - is
199:53 - [Music]
200:09 - [Music]
200:11 - [Applause]
200:12 - [Music]
200:45 - [Music]
201:20 - [Music]
201:29 - [Music]
201:47 - [Music]
202:27 - [Music]
202:30 - i've had my heart broken into it
202:34 - [Music]
202:38 - but something's different next to you
202:43 - [Music]
202:45 - it's like my soul
202:50 - [Music]
202:50 - [Applause]
202:51 - [Music]
203:00 - cause i
203:02 - [Music]
203:11 - [Music]
203:15 - is
203:16 - [Music]
203:20 - [Applause]
203:25 - [Music]
203:28 - that i know
203:35 - the feelings
203:41 - [Music]
203:50 - feelings that i know
204:05 - the feelings that i know
204:12 - [Music]
204:19 - i can't keep on this road alone
204:26 - and all this time i thought
204:33 - [Music]
204:43 - [Music]
204:44 - [Applause]
204:51 - up inside
204:56 - is
204:58 - [Music]
205:09 - feelings that i've known
205:25 - is
205:40 - is
205:41 - [Music]
206:02 - is
206:06 - [Music]
206:13 - bottled up inside
206:16 - and all
206:20 - [Music]
206:22 - [Applause]
206:24 - [Music]
206:31 - the feelings that i know
206:36 - [Music]
209:12 - [Music]
209:37 - so
209:39 - [Music]
210:06 - so
210:08 - [Music]
210:39 - [Applause]
210:41 - [Music]
210:45 - [Applause]
210:49 - [Music]
211:13 - so
211:19 - [Music]
211:45 - so
211:46 - [Music]
211:56 - [Applause]
211:58 - [Music]
212:02 - [Applause]
212:05 - [Music]
212:14 - so
212:17 - [Music]
213:08 - next
213:11 - [Music]
213:29 - [Music]
213:37 - living in the light you're giving out
213:42 - [Music]
213:53 - [Music]
213:58 - without you
214:00 - [Music]
214:10 - [Music]
214:17 - tell me
214:20 - [Music]
214:28 - [Music]
214:34 - never gonna let you down
214:38 - [Music]
214:46 - baby
214:48 - [Music]
214:59 - [Music]
215:07 - home here in your eyes
215:14 - [Music]
215:19 - without your baby
215:21 - [Music]
215:26 - is
215:28 - [Music]
215:44 - nobody
215:46 - [Music]
215:55 - is
215:57 - [Music]
216:07 - tell me
216:11 - [Music]
216:13 - [Applause]
216:13 - [Music]
216:21 - is
216:24 - [Music]
216:32 - [Applause]
216:32 - [Music]
216:34 - tell me
216:36 - [Music]
216:48 - is
216:50 - [Music]
216:55 - [Applause]
216:57 - [Music]
217:16 - baby
217:18 - [Music]
217:41 - [Music]
217:54 - me
218:01 - when you're with me and i realize what
218:03 - it all means
218:06 - [Music]
218:23 - so i love you so bad
218:27 - [Music]
218:39 - every single crowd
218:41 - and i know you love me
218:45 - [Music]
218:52 - [Music]
219:06 - is sky full of dreams
219:12 - [Music]
219:27 - oh
219:29 - [Music]
219:47 - till the sky
219:54 - [Music]
220:03 - [Applause]
220:04 - [Music]
220:42 - i was doing just
220:45 - [Music]
220:57 - when the lights
221:02 - [Music]
221:11 - is gonna
221:14 - [Music]
221:54 - so pick me
221:55 - [Music]
222:07 - every day i'm with you i think
222:11 - [Music]
222:34 - [Music]
222:52 - is
222:57 - [Music]
223:31 - [Applause]
223:32 - [Music]
223:36 - [Applause]
223:43 - [Music]
223:51 - [Music]
224:20 - so
224:23 - [Music]
224:36 - so
224:38 - [Music]
224:52 - so
224:54 - [Music]
225:11 - you
225:13 - [Music]
225:31 - so
225:33 - [Music]
225:57 - [Music]
226:10 - [Applause]
226:10 - [Music]
226:16 - [Applause]
226:21 - [Music]
226:53 - [Music]
227:10 - [Applause]
227:11 - [Music]
227:16 - [Applause]
227:22 - [Applause]
227:28 - so
227:35 - [Music]
228:57 - so
228:59 - [Music]
229:48 - mr
229:49 - [Music]
230:12 - [Music]
230:25 - so
230:31 - [Music]
231:38 - [Music]
232:32 - so
232:35 - [Music]
233:12 - [Music]
234:13 - [Music]
234:27 - [Music]
234:37 - [Music]
235:21 - so
235:23 - [Music]
235:47 - so
235:51 - [Music]
236:03 - [Music]
236:16 - [Music]
236:18 - [Applause]
236:22 - [Music]
236:31 - so
236:34 - [Music]
236:48 - [Applause]
236:49 - [Music]
236:57 - [Music]
237:10 - [Music]
237:22 - um
237:24 - [Music]
238:13 - [Music]
238:55 - i was watching
238:57 - [Music]
239:10 - show me something new as each morning
239:16 - [Music]
239:48 - underneath
239:50 - [Music]
240:01 - [Music]
240:10 - is
240:13 - [Music]
240:33 - still
240:40 - [Music]
240:46 - singing
240:53 - [Music]
241:08 - is
241:09 - [Music]
241:31 - this is
241:35 - [Music]
241:54 - come with us
241:56 - don't
241:57 - hold back tonight is
242:01 - [Music]
242:14 - is
242:16 - [Music]
242:47 - is
242:50 - [Music]
243:07 - it's
243:10 - [Music]
243:38 - is
243:41 - [Music]
243:47 - [Music]
244:24 - [Music]
244:59 - [Music]
245:08 - [Music]
245:25 - [Music]
245:50 - so
245:55 - [Music]
246:09 - i've had my heart broken into it
246:13 - [Music]
246:16 - but something's different next to you
246:21 - [Music]
246:24 - it's like my soul is
246:28 - [Music]
246:49 - [Music]
246:53 - know is
246:55 - [Music]
247:13 - the feelings
247:15 - [Music]
247:28 - the feelings that i know
247:43 - the feelings
247:46 - [Music]
247:58 - i can't keep on this road alone
248:05 - and all this time i thought i knew
248:11 - [Music]
248:30 - up inside
248:35 - is
248:36 - [Music]
248:48 - that i've known
248:56 - [Music]
249:10 - feelings
249:12 - [Music]
249:32 - this
249:35 - [Music]
249:48 - that i know i can't keep bottled up
249:53 - inside
249:58 - is are you ready for the ride
250:02 - what have i been waiting for oh i can
250:06 - run but i can't
250:10 - the feelings that i know
250:15 - [Music]
251:24 - so
251:25 - [Music]
251:39 - so
251:45 - [Music]
252:07 - so
252:10 - [Music]
252:47 - so
252:50 - [Music]
253:30 - so
253:31 - [Music]
254:18 - [Applause]
254:20 - [Music]
255:24 - do
255:32 - [Music]
255:34 - [Applause]
255:36 - [Music]
255:36 - [Applause]
255:41 - [Music]
256:47 - next
256:49 - [Music]
257:02 - so
257:05 - [Music]
257:13 - [Music]
257:22 - space
257:25 - [Music]
257:56 - tell me
257:58 - [Music]
258:13 - never gonna let you down
258:16 - [Music]
258:25 - baby
258:27 - [Music]
258:56 - without you baby
259:00 - [Music]
259:05 - is
259:12 - [Music]
259:22 - nobody
259:23 - [Music]
259:32 - all this is
259:37 - [Music]
259:43 - [Applause]
259:43 - [Music]
259:50 - welcome back everybody
259:52 - i will give give folks a few seconds
259:55 - here to
259:56 - get back in and settled
259:58 - uh for our next talk this is we're going
260:01 - back to a a bit of a longer talk here
260:04 - with jana beck
260:06 - janet beck is a data visualization
260:08 - engineer at stitch fix in previous life
260:11 - she was a phd candidate in linguistics
260:14 - doing a lot of scientific computing
260:16 - in python now you may be wondering okay
260:20 - we're doing uh data visualization
260:22 - engineering with react
260:24 - uh this this could be a
260:27 - uh a difficult thing to do in the
260:29 - browser and that's exactly what janna's
260:31 - gonna be talking about how to actually
260:33 - do data science in the browser how to
260:35 - perform
260:36 - those kinds of tasks that are typically
260:38 - reserved for cloud computing
260:40 - so let's get straight into the talk with
260:42 - jana hello reactathon and welcome to
260:45 - escaping flatland a romance of data
260:47 - science in the browser
260:49 - now this title is a reference to a
260:50 - mathematical fable that we'll get to in
260:52 - a bit and we will torture the heck out
260:54 - of as a metaphor in this talk
260:56 - but
260:57 - first let me introduce myself my name is
260:59 - jana beck i'm a data visualization
261:01 - engineer at stitch fix which is a
261:03 - company based in san francisco
261:05 - california
261:06 - we are an online
261:08 - retailer we offer personal styling so
261:11 - for women men and children so you sign
261:14 - up you fill out a style profile you can
261:16 - also play a game we have called style
261:18 - shuffle to tell us about
261:19 - your style preferences and a sort of
261:21 - tinder for clothes kind of way
261:23 - um and
261:25 - and then we match you with a stylist who
261:27 - picks out things and sends them to you
261:29 - you don't pay upfront for all the things
261:30 - that are getting sent you just try them
261:32 - on and pay for what you decide to keep
261:34 - and ship the rest back
261:36 - and then in the last year we also
261:38 - launched a sort of personal store type
261:40 - of service where you just log in and
261:42 - we will show you a selection of all of
261:45 - the things that we think based on what
261:46 - we know about your style will be the
261:48 - most interesting to you and then you can
261:50 - just shop at your own convenience item
261:52 - by item
261:54 - now i work on
261:55 - the algo ui team
261:58 - which is a sub team of the data platform
262:00 - engineering team that supports about 120
262:02 - data scientists in our algorithms
262:04 - department or data science department at
262:06 - citrix
262:08 - and this is a pretty unusual role for
262:10 - front-end engineering
262:13 - but it's pretty fun so we basically
262:15 - operate as internal consultants we float
262:18 - around
262:19 - from project to project partnering with
262:22 - one or more of the data scientists on
262:24 - the team
262:25 - to surface their work in whatever way is
262:28 - necessary but usually through a web
262:30 - application of course
262:32 - to their business partners in the
262:33 - company so it's it's internal tools um
262:36 - or tools might be the wrong word
262:37 - sometimes it's things like prototyping a
262:40 - algorithmically driven experience like
262:42 - something that might even be client
262:43 - facing one day
262:45 - sometimes it is just putting together
262:46 - dashboards of business metrics or
262:48 - operational metrics uh that business
262:51 - partners throughout the company need to
262:53 - see
262:54 - so it varies a lot we create a lot of
262:56 - new applications all the time
262:58 - which is pretty interesting and a little
263:00 - different for the typical front-end
263:02 - engineering job
263:04 - so coming back here to the subtitle of
263:06 - this talk a romance of data science in
263:08 - the browser we're not going to talk
263:10 - about doing all types of data science in
263:12 - the browser though you can do a
263:13 - surprisingly large amount with something
263:16 - like tensorflow.js which is an
263:18 - implementation of the tensorflow
263:20 - framework in javascript
263:22 - what we're going to do in this talk
263:23 - instead is focus on one particular
263:25 - technique that's very useful for
263:27 - visualizing certain types of data sets
263:30 - that occur in data science data sets
263:32 - that we call high dimensional data sets
263:35 - so
263:35 - this technique is called dimensionality
263:37 - reduction
263:38 - now what is dimensionality reduction
263:41 - there are quite a few examples that are
263:43 - actually probably pretty familiar to you
263:44 - so one is maps
263:46 - maps are
263:49 - a way of reducing the three-dimensional
263:52 - globe to two dimensions so that you can
263:54 - print it out or display it on a screen
263:57 - and there's lots of different map
263:58 - projection algorithms and they're all
264:01 - very specific to
264:03 - the earth and and
264:05 - making the earth
264:06 - from two dimens three dimensions to two
264:09 - right so you have the much maligned
264:11 - mercator projection you have
264:13 - newly developed projections that are
264:15 - much better than the mercator projection
264:17 - like the equal earth projection and you
264:19 - have exotic projections like this one
264:22 - the watermen's butterfly projection and
264:24 - these are all of course extremely
264:26 - specific but there are more generic
264:28 - algorithms for doing dimensionality
264:30 - reduction on any data set and indeed on
264:33 - data sets that have hundreds or
264:35 - thousands of dimensions
264:37 - work we're going to look at in this talk
264:39 - is doing
264:40 - one particular dimensionality reduction
264:42 - algorithm that's pretty newly developed
264:44 - this is pretty cutting edge
264:47 - and doing this in the browser so this
264:48 - algorithm is called umap and that's an
264:50 - acronym for uniform manifold
264:52 - approximation and projection but we're
264:54 - not really going to get into what that
264:55 - means because that's not actually
264:57 - relevant here
265:01 - okay so let's dive into umap and see it
265:03 - in action and we'll start with something
265:05 - that should be pretty familiar to you as
265:07 - front-end engineers and that's color
265:09 - spaces
265:10 - so
265:11 - the rgb color space has three dimensions
265:14 - red green and blue
265:16 - and so as i'm sure you probably know you
265:18 - define
265:20 - millions of colors by encoding three
265:22 - different numbers from zero to 255
265:25 - for each of those channels those red
265:27 - green and blue channels so we can
265:29 - visualize this in the proper three
265:31 - dimensions for those
265:33 - three channels
265:35 - by uniformly sampling from
265:37 - the allowed values 0 to 255 for each and
265:40 - we get this uniform cube
265:44 - and then we can actually just apply umap
265:46 - to this telling it to map it onto two
265:49 - dimensions and it will get flattened out
265:52 - just like this and you can still sort of
265:54 - see some features of
265:56 - the original
265:58 - geometry here in in that you see these
266:00 - like corners it's pretty interesting and
266:03 - you'll get a different result
266:05 - if you do the same thing on the hsl
266:07 - color space visualized here in its three
266:09 - dimensions but it's not a cube it's a
266:11 - cylinder because the hue dimension in
266:14 - hsl is an angle from a circle the the
266:17 - hue circle
266:19 - so if we flatten this one out we get a
266:21 - very different result and again this is
266:23 - just applying umap from three dimensions
266:25 - to two and and again you kind of see
266:27 - some of those features of the original
266:30 - geometry you get these curves here with
266:32 - the hsl
266:33 - where you didn't see those with the
266:36 - rgb
266:43 - so now that we've looked at something
266:45 - pretty familiar color spaces let's look
266:47 - at something that's more
266:49 - data science-y and that's the mnist
266:51 - digits data set so this is a data set
266:53 - that has as we'll see a hundred
266:55 - dimensions so much more high dimensional
266:58 - than three
266:59 - and it's commonly used to test a variety
267:01 - of machine learning techniques
267:03 - so what this data set is is a set of
267:06 - images
267:07 - of hand drawn digits and each image
267:11 - is reduced to being 10 pixels by 10
267:14 - pixels so there's basically a grid
267:17 - of 100 squares and
267:20 - each square is one dimension
267:23 - and what all we're encoding here is
267:25 - whether that square that pixel and the
267:27 - 100 pixels
267:28 - how filled in it is with black versus
267:31 - white
267:32 - so here's an example of one of the
267:34 - hand-drawn digits a number eight and
267:36 - here's the
267:38 - grid of 100 squares and so if we look at
267:41 - a particular location like 2 2 here
267:44 - this one has a value of 0 because it's
267:47 - all white whereas 3 2 has a value of
267:50 - perhaps 0.825 because it is mostly black
267:58 - so if we apply an algorithm like umap a
268:00 - dimensional dimensionality reduction
268:02 - algorithm to a data set like the mnist
268:05 - digits data set that has 100 dimensions
268:07 - what we expect to see is clustering of
268:10 - the hand-drawn digits together by digit
268:13 - value because
268:14 - what the uh
268:16 - algorithm is doing is comparing each of
268:18 - those like dimensions so comparing pixel
268:21 - 0 0
268:22 - across all of the 5 000 examples that
268:25 - we're going to give it here uh the 5 000
268:28 - hand drawn digits and then it will
268:30 - categor it will put all the similar ones
268:34 - the ones that are similar across all
268:36 - those 100 dimensions
268:38 - it will show us that by clustering them
268:40 - on the two dimensions of our screen
268:43 - so
268:44 - if we look at the result that's exactly
268:46 - what you see here applying umap to 5000
268:49 - of the mnist digits
268:51 - and what's interesting and
268:53 - uh what actually makes umap a better
268:55 - dimensionality reduction than some that
268:57 - are similar is that you also get
269:00 - similar shapes
269:02 - appearing the the cluster for each digit
269:05 - and for each shape
269:07 - um
269:08 - the relationship between those clusters
269:10 - is also relevant which sometimes it
269:12 - isn't with other dimensionality
269:13 - reduction techniques so for example the
269:16 - fours and the nines are right next to
269:18 - each other which you can see because
269:21 - they're very similar shapes um
269:24 - just differ basically and the a9 is like
269:27 - curved on the top whereas the closed
269:29 - portion of a four
269:30 - is has sharp angles on the top um so
269:34 - those are very similar and they appear
269:36 - right next to each other
269:37 - similarly down um the red ones here are
269:40 - threes and the sort of citrine color is
269:43 - is eights and those are also very
269:45 - similar of course you just three is
269:47 - basically an eight with a couple bits
269:48 - erased from it right
269:50 - so that's one of the advantages of umap
269:53 - that you can see very clearly in this
269:55 - example
269:58 - so i told you before that escaping
269:59 - flatland was a reference to a
270:00 - mathematical fable and that fable was
270:03 - the book flatland a romance of many
270:05 - dimensions written by edwin abbott
270:08 - abbott and first published in 1884.
270:11 - now this mathematical fable a romance of
270:14 - many dimensions
270:15 - uh is the story of its pseudonymous
270:18 - author a square a square is
270:21 - a square as you might imagine who
270:23 - occupies flatland a two-dimensional
270:25 - world
270:26 - this land is also populated by other
270:28 - polygons and lines but
270:31 - all the beings that occupy this world
270:33 - are two-dimensional
270:35 - now the climax of the story spoiler
270:37 - alert
270:38 - is when one day flatland is visited by a
270:41 - being from
270:43 - spaceland which is a three-dimensional
270:45 - world and a square witnesses this
270:48 - visitation
270:49 - now how does a square know
270:52 - that
270:54 - this being is from another
270:56 - uh
270:58 - world with a greater number of
270:59 - dimensions well basically because the
271:01 - sphere is able to apparently teleport
271:05 - because he's able to move into the third
271:07 - dimension
271:08 - and then intersect flatland in a
271:11 - different location
271:12 - seemingly by magic
271:17 - so here's the part where we torture
271:19 - flatland as a metaphor and we're going
271:21 - to use it as a metaphor for the web
271:22 - browser itself
271:25 - now the web browser started out as
271:27 - something pretty simple and not very
271:28 - powerful it was a way to view
271:30 - hyperlinked text documents nothing more
271:33 - images came later video came later
271:35 - things like webgl came way later
271:39 - but today the web browser is pretty
271:41 - powerful as i mentioned before
271:42 - tensorflow has been implemented in
271:44 - javascript as tensorflow.js
271:46 - we'll be working with the javascript
271:48 - implementation of the umap algorithm
271:51 - that i introduced you to briefly
271:53 - um in a library called umapjs
271:56 - and
271:57 - these are computationally expensive
272:00 - things almost by definition
272:03 - and if you just implement them in the
272:05 - main thread the main execution context
272:07 - in the web browser you're going to cause
272:09 - jank you're going to freeze the ui it's
272:11 - not going to be a happy experience for
272:13 - the user
272:14 - but
272:15 - what
272:17 - the browser has today is the ability to
272:20 - accept visitors from space land from
272:24 - a larger more dimensional world a world
272:26 - that has concurrency basically is not
272:29 - limited to
272:30 - one single thread of javascript
272:33 - and that technology that we have today
272:35 - is the web worker
272:39 - so let's talk about web workers if
272:41 - you're not familiar with them
272:43 - so the the worker context is very
272:45 - similar to the main javascript execution
272:48 - context in every browser but there's a
272:50 - few differences so just like in a in a
272:53 - regular
272:55 - main thread context you can make xhr
272:58 - requests to get data asynchronous
273:01 - asynchronously
273:03 - but you do not have access to dom or
273:05 - even a dom and you don't have a window
273:08 - global instead you have a self global
273:11 - all data transfer between a worker and
273:14 - the main thread is done by message
273:16 - passing
273:17 - and this data is not is copied with one
273:22 - exception that we'll go to later um and
273:25 - instead of being shared across the
273:27 - worker and the main thread
273:29 - and it's serialized and then
273:30 - deserialized via the structured cloning
273:33 - algorithm so what are all the things
273:35 - that are serializable by structured
273:37 - cloning
273:38 - well it's basically a whole host of
273:40 - things that you'd expect all the
273:42 - primitive data types of javascript dates
273:44 - blobs array buffers
273:47 - but some things that it would be useful
273:49 - to pass back and forth that you cannot
273:52 - pass back and forth cannot serialize by
273:54 - a structured cloning
273:56 - are things like dom nodes error objects
273:59 - and functions
274:02 - the
274:03 - basic web worker code would look
274:06 - something like this it's just a big on
274:08 - message handler that receives data from
274:12 - the main thread
274:14 - and then you can do anything you want
274:16 - probably something computationally
274:17 - expensive
274:18 - and then there's a global post message
274:20 - handler that you just use to pass the
274:22 - result back whenever it's done
274:25 - on the app side you instantiate a web
274:27 - worker with the new keyword and then you
274:30 - call the
274:31 - uh uh the postmessage method on that
274:34 - instance that you've just created to
274:36 - pass your initial data to the worker or
274:39 - any message at all of course you could
274:40 - have a more complex system of message
274:43 - passing where you have types for all
274:44 - your messages and they do different
274:46 - things
274:48 - and then you have a you just define an
274:50 - onmessage handler to receive the results
274:53 - whenever the worker is done
274:58 - as far as tool chains the support for
275:00 - webworkers is quite good in my
275:02 - experience so the worker loader from
275:04 - webpack is what i've used for many years
275:07 - you can just tell it that any file
275:09 - ending in worker.js should use this
275:12 - worker loader and it bundles it up
275:14 - appropriately i've also heard great
275:16 - things about the worker eyes loader
275:17 - which you
275:19 - can be used on any you know file that's
275:22 - just a single function and you don't
275:24 - even have to write the sort of webworker
275:26 - message passing boilerplate it will just
275:29 - as it says workerize that function and
275:31 - make it into a web worker
275:34 - parcel i haven't used personally but i
275:36 - found a codepen example that used uh
275:39 - parcel to bundle up a
275:41 - uh webworker so i think that works uh
275:44 - the only thing that i haven't had great
275:46 - success with is roll up um if you're
275:49 - building a a library and you want to
275:51 - have a worker that people can use
275:53 - um
275:55 - roll up uh the plugin i tried a few
275:57 - years ago didn't work for me i do think
276:00 - there is a new plug-in out in the last
276:02 - year or so so that may
276:04 - work now but it didn't before in my
276:06 - experience
276:09 - so let's dive into some demos and these
276:11 - demos are going to be on a thousand of
276:13 - those mnist digits that we saw before
276:16 - running umap to
276:18 - cluster them by similarity by digit
276:21 - and the first demo is going to be the
276:24 - one where we run umap in a webworker and
276:27 - you will see a couple other things on
276:29 - the screen there'll be a frame rate
276:31 - meter in the upper left and
276:34 - a keyboard input that i'll be typing in
276:36 - in the upper right and so with the
276:38 - computation happening in the worker
276:40 - you'll see that my keyboard
276:42 - input is active the entire time while
276:44 - the computation is running or active in
276:47 - the sense that the ui will be updated my
276:50 - input is being accepted immediately as
276:52 - we hope and expect there's no lag no
276:54 - jank
276:56 - so let's give that a try and see how it
276:58 - goes so we'll just start it up here
277:07 - and there you can see 216 frames per
277:09 - second
277:10 - very responsive and that keyboard input
277:13 - was updating the entire time because
277:16 - that computation was happening off the
277:17 - main thread and not
277:19 - interfering with the main ui at all
277:22 - now in contrast same initial conditions
277:24 - a thousand imnis digits but we're going
277:26 - to run this umap in the main thread and
277:29 - try to do the same thing
277:30 - look at the frame rate and
277:33 - watch the
277:35 - lag and drank on the keyboard input
277:41 - so here i'm typing away as i'm sure you
277:42 - can hear
277:44 - but
277:45 - don't see anything from the keyboard
277:48 - until it finishes at two frames per
277:50 - second because it couldn't even update
277:53 - uh while it was computing
277:55 - sadly that's what happens in the main
277:57 - thread
278:00 - okay so for a third demo here this is
278:02 - basically just the same as the first
278:03 - we're going to do the umap in the worker
278:05 - for performance
278:06 - but bump up the number of digits to 2500
278:10 - and you'll see that we do start to see
278:12 - performance implications even with the
278:15 - worker implementation here
278:26 - so the final frame rate there was 86
278:28 - frames per second quite a bit
278:31 - slower than before
278:36 - and now for a fourth demo which i'll
278:38 - just leave my face off for this one
278:40 - because it takes a little bit longer
278:42 - um we'll just bump up the end to 5000
278:47 - and
278:48 - see how that goes
278:54 - so here you see that there was an
278:55 - initial period of time when the keyboard
278:58 - input wasn't updating on the screen but
279:00 - then it's kind of like all the others
279:03 - just again with a lower frame rate we're
279:06 - in the 40s now four frames per second
279:10 - okay so there's a little bit more that
279:12 - we can do in a web worker to optimize
279:14 - performance and we're going to talk
279:15 - about two more things basically
279:18 - transferable objects and then
279:20 - one type of transferable object or one
279:22 - specific
279:24 - instance of that which is an off-screen
279:27 - canvas
279:28 - so transferable objects are the
279:30 - exception to what i said before about
279:32 - data passing between the main thread and
279:34 - a web worker being exclusively a copying
279:36 - operation transferable objects are zero
279:39 - copy they are basically the
279:42 - conceptual equivalent to path by
279:44 - reference in other programming languages
279:48 - so here's an example of
279:50 - using transferable objects to pass the
279:53 - result of a umap computation back
279:55 - without having to copy it so it's a
279:57 - little bit faster so here i'm just
279:59 - taking the result the embedding which is
280:01 - what you call it when you reduce a high
280:03 - dimensional data set
280:06 - just taking that embedding and storing
280:07 - it in a float32 array and then in the
280:10 - post message there's a second argument
280:12 - which is an array
280:14 - and you put everything in this array
280:16 - that is a transferable object or is of
280:19 - an appropriate type that can be a
280:21 - transferable object and that just tells
280:24 - the the worker to not copy it and treat
280:27 - it differently and pass it to the main
280:29 - thread instead of copying it to the main
280:31 - thread
280:34 - so then the second
280:36 - transferable object or specific type of
280:38 - transferable object that's not an array
280:40 - buffer is an off-screen canvas and this
280:42 - is
280:43 - a weird thing and it's not transferable
280:45 - objects in general the array buffers
280:47 - those are supported in every browser but
280:49 - this is something special and new and
280:51 - only a couple browsers have it so far
280:53 - um it's basically like a canvas element
280:57 - that is
280:59 - a non-dom version of the canvas element
281:02 - um
281:02 - so here's an example of some some code
281:05 - of how you would actually use this you
281:07 - you know you want to
281:08 - you just you do render a canvas element
281:10 - in your dom like normal so here we've
281:12 - rendered one that has the id off screen
281:15 - and instantiate a render worker we'll
281:18 - call it because we're going to render
281:19 - onto this canvas and the word her
281:23 - then grab a reference to that canvas
281:25 - element that's been rendered and call
281:27 - this method transfer control to
281:28 - off-screen
281:30 - then you also have to post a message to
281:32 - the worker and include in the body of
281:34 - the message that you're passing
281:36 - this reference to the canvas and then
281:39 - also include that that reference to the
281:41 - canvas in that array of transferable
281:44 - objects that's the second argument to
281:46 - your post message
281:49 - then in the worker code remember a
281:51 - worker is basically just a big on
281:53 - message handler you pull that canvas out
281:56 - from the message and
281:58 - and then you just render onto it using
281:59 - the canvas api or the webgl api
282:02 - how you would normally render onto any
282:05 - kind of canvas and here you don't even
282:07 - have to pass it back like the worker
282:10 - rendering onto this canvas is
282:14 - just this it's kind of like a
282:15 - multi-dimensional wormhole back to the
282:17 - browser it just appears that rendering
282:19 - just appears in the browser where that
282:21 - canvas element was rendered so this is
282:24 - total magic in my opinion it's very cool
282:31 - okay so now we're approaching our final
282:33 - demo here where we're going to have the
282:35 - main thread and two workers one to do
282:37 - the umap computation and one just to do
282:39 - the rendering of each iteration of this
282:42 - algorithm as it converges on the result
282:45 - so the conditions here are the same as
282:47 - the fourth demo that we saw with 5000 of
282:50 - the mnist digits
282:57 - and now you can see with the comparison
282:59 - of the embedded one in the upper right
283:00 - corner that
283:02 - this one has gotten responsive a lot
283:04 - faster than that last one
283:11 - and the reason also that there's no
283:13 - framework meter on this one is because
283:15 - all the frame rate tools
283:18 - are not compatible yet with off-screen
283:20 - canvas so i couldn't actually put that
283:22 - in this final demo
283:27 - so to conclude in my opinion the
283:29 - combination of web workers especially
283:31 - with off-screen canvas
283:33 - gives you something that is basically an
283:35 - escape from the flatland of the browser
283:37 - because you can just do
283:39 - much more computationally intensive and
283:41 - exciting things
283:44 - and if you have any questions i'm happy
283:46 - to answer them on twitter where i'm i
283:48 - pancreas i'm jebec on github and also in
283:51 - various slacks or discords that's
283:54 - usually the name i'm under
283:56 - and you can also look at these slides
283:58 - again online if you want all the
284:01 - demos are live embedded in the slides so
284:03 - you can just play with them if you feel
284:04 - like it at janetbeck.com
284:07 - flatland
284:08 - and then if you also take a look at
284:10 - these slides you can go through these
284:12 - details of what i use to put together
284:14 - the demos and this whole slide deck in
284:16 - general if you're curious about that
284:19 - thank you so much for your time
284:24 - so we can do
284:26 - machine learning in the browser or maybe
284:27 - not machine learning but uh these these
284:30 - pretty interesting kind of intensive
284:32 - uh computationally intensive things in
284:35 - the browser
284:37 - off of the main thread that's really
284:38 - cool thank you jana for
284:40 - the fantastic talk and obviously the
284:43 - kind of stunning visual display that we
284:45 - saw there that was cool
284:47 - yeah how amazing i also love that jenna
284:50 - has this uh prior background in
284:52 - linguistics because that's also the
284:53 - background that i come from so love
284:55 - seeing folks uh go from uh studying
284:57 - things like dimensionality reduction in
284:59 - the language world and bringing that
285:01 - into uh computing and data vis and
285:03 - whatnot super cool thanks so much
285:05 - jennifer that awesome talk
285:07 - and now we've got another an amazing
285:10 - talk for you to to round out our day um
285:15 - our next speaker i feel like perhaps
285:17 - needs some introduction uh sean
285:19 - swix-wang uh who you may know as an
285:21 - infinite builder
285:23 - is uh formerly of netlify and now
285:25 - developer advocate at aws who works on
285:28 - developer experience and developer
285:30 - developer communities and is also
285:33 - just an amazing speaker writer teacher
285:35 - who i've had the pleasure of running
285:36 - into a various conferences myself and
285:39 - today uh swix is going to be talking to
285:41 - us about
285:43 - typesafe full stack react
285:46 - and we're going to
285:48 - be live coding an apt with react and
285:51 - typescript and graphql to demonstrate
285:54 - during his talk so wow
285:56 - get ready for some fun with uh full
285:59 - stack type safety in this next talk by
286:02 - swix
286:04 - hello reactathon i'm really excited to
286:06 - be joining you today i hope all of you
286:08 - are safe and at home and today we're
286:10 - going to talk a little bit about
286:12 - typesafe full stack react it's a broad
286:14 - introduction for those people who
286:16 - haven't considered it and a live demo
286:18 - for people who have and hopefully you
286:20 - might learn a new thing or two so let's
286:23 - get started so for those of you who
286:24 - don't know me
286:26 - hi i'm sean i am sitting here in
286:29 - singapore but i could be anywhere as far
286:30 - as you're concerned and i also go by
286:32 - swix on the internet that's my english
286:34 - and chinese initials i've had the
286:36 - privilege of giving some well-received
286:38 - reactive talks in the past in 2018 i
286:41 - kicked off my react conference speaking
286:43 - career with why react is not reactive at
286:46 - react rally 2018
286:48 - and then in 2019 i followed it up by
286:50 - giving my talk on hooks and cloning
286:53 - uh react clone from scratch in 29 lines
286:56 - of code live on stage and that was
286:58 - pretty much the scariest and best
287:00 - received talk that i've done
287:02 - in 2020 i also
287:05 - extended that to concurrent react so
287:08 - giving an explanation and live code demo
287:11 - of react fiber as well as the
287:13 - implications of that with time slicing
287:16 - and react suspense but more recently my
287:18 - interests have turned from react
287:20 - internals towards everything around
287:23 - react the tooling and the developer
287:25 - communities around react and that's what
287:27 - we're here to talk about today the
287:29 - stunning evolution and adoption of
287:31 - typescript within the react ecosystem
287:35 - and why is type safety so important to
287:37 - react well i can pretty much make that
287:39 - argument in two words and that's
287:41 - shifting left
287:42 - shifting left is this concept that's
287:46 - kind of new to web development or
287:47 - obscure in web development but it's not
287:49 - new to software engineering in general
287:52 - so if you look at ibm who did a survey
287:54 - of their hundreds of thousands of
287:56 - consultants and consulting projects
287:59 - they discovered that there's a
288:00 - correlation between how late in the
288:03 - process of the software development
288:04 - cycle where they catch a bug
288:07 - versus how much it takes to actually fix
288:09 - that
288:10 - and it's also non-linear so if you
288:13 - arrange the software process from design
288:16 - to implementation to testing to
288:18 - maintaining a production application
288:21 - from left to right the further right it
288:23 - shifts towards something that's already
288:25 - shipped then the more expensive it is to
288:26 - fix that bug so a bug in production is
288:29 - like 100 times more expensive than if it
288:31 - was caught at the design stage i like
288:33 - this quote that people have that you can
288:35 - save weeks and weeks of coding with just
288:37 - hours of planning and i think that
288:39 - that's a really true statement
288:41 - even more than that you can automate a
288:43 - lot of that planning and checking with
288:45 - type systems
288:47 - so the way i pitch this is it's not just
288:49 - type systems it's also about building
288:52 - automated developer tools so let's
288:54 - translate this shift left concept into
288:57 - terminology that we understand because
288:59 - we're not ibm
289:00 - so instead of relying on user bug
289:02 - reports and manual qa we can actually
289:05 - run tests inside of ci cd setup
289:07 - environments
289:08 - but instead of running that entire test
289:10 - suite we can actually just run tests on
289:12 - incremental commit hooks and diffs
289:15 - so it's even faster
289:17 - so what else can we do that increases
289:19 - the feedback loop even faster than that
289:21 - we can shift left again and we can run
289:23 - formatting on save that's what prettier
289:25 - is about and that actually
289:27 - unlocks another order of magnitude
289:29 - improvement in our software development
289:31 - cycle but what can we do that shifts
289:34 - even further left than that well while
289:36 - we read our code our ides can actually
289:40 - tell us if we've written code that's
289:42 - wrong so that's what the typescript
289:44 - language server and syntax highlighting
289:47 - and ides do for us they tell us when
289:50 - code looks wrong while we're writing
289:52 - that code we don't even have to save we
289:53 - don't have to commit we don't have to
289:54 - build or run it we can just look at it
289:57 - while we write and that is the highest
289:59 - possible
290:00 - version of shifting left in terms of our
290:02 - error detection everything that we're
290:04 - doing here
290:05 - is to try to reduce the length of time
290:08 - it takes to discover code errors and it
290:10 - should directly translate to dollars
290:12 - spent as well
290:14 - the shift left idea also trickles down
290:16 - in terms of other features that are also
290:18 - nice fearless refactoring is this
290:20 - concept i really like which says that
290:22 - the only way to avoid techdab is to not
290:24 - be afraid of refactoring your code base
290:26 - at any point and the only way to not be
290:28 - afraid of refactoring your code bases at
290:30 - any point is if your developer tools
290:32 - help you refactor so i can refactor any
290:35 - part of my code base and if anything was
290:37 - forgotten or if i broke any code i don't
290:40 - have to run the code again the ide would
290:42 - mostly just tell me what i need to fix
290:44 - typescript and type safety also helps
290:46 - you generate autocomplete because that's
290:48 - another implication of type checking
290:50 - it's kind of the inverse typescript also
290:51 - helps you inline documentation so you
290:53 - don't have to remember what exactly each
290:55 - name means you can just hover over
290:58 - variables and functions that it tells
291:00 - you what it does in terms of type
291:01 - signatures or type annotations but i do
291:04 - want you to know that types do not
291:05 - replace tests i actually wrote a post on
291:08 - css tricks on why types and tests serve
291:10 - overlapping but different purposes and i
291:12 - encourage you to check that out i'm
291:14 - personally quite tired of this
291:15 - discussion because i think it's a solve
291:17 - issue that you should have both my
291:19 - ultimate sales pitch to you on why type
291:21 - safety
291:22 - is that you can go from moving fast and
291:24 - breaking things to move fast without
291:27 - breaking things and that's ultimately
291:29 - what we all want right okay so let's
291:31 - talk about typesafe front ends i've
291:33 - helped to maintain the react and
291:34 - typescript cheat sheets for over two
291:36 - years and i've learned a lot about this
291:38 - so normally i just give a screenshot of
291:41 - what this basic component looks like but
291:43 - because this is pre-recorded video i can
291:45 - go one step better and actually show you
291:48 - inside of a typescript playground so
291:50 - here i have a basic function component
291:53 - and it's being used inside of an app
291:55 - this looks exactly like javascript
291:57 - because it is and that actually shows
291:59 - you one of the benefits of typescript
292:00 - which is that it is a superset of
292:03 - javascript any valid javascript is valid
292:05 - typescript under the right settings
292:08 - obviously you can make it a little bit
292:09 - more strict and that's a little bit of
292:11 - what we're going to do so here we're
292:13 - going to turn on the no implicit any
292:15 - check and that's going to start causing
292:18 - errors so it's going to start telling us
292:19 - that props implicitly has an any type so
292:21 - we need to give
292:23 - the type and specify the type of the
292:25 - component so let's go ahead and say that
292:28 - my type of component
292:30 - is going to have an id and the id is
292:33 - going to be a
292:35 - string
292:36 - so let's put that in there
292:38 - and this is going to type check properly
292:39 - properly so when i hover over props.id
292:42 - it's going to tell me that is a string
292:44 - okay so that's a simple reactant
292:46 - typescript app
292:48 - but what if we wanted to do a refactor
292:51 - that's exactly what we're trying to go
292:52 - for right so let's say i wanted to
292:55 - change my id
292:56 - into a number
292:58 - so if i change that number here it's
293:00 - going to light up accordingly so for
293:02 - example here i wanted to say
293:04 - i i'm running around a specific
293:07 - number
293:08 - function like two exponential
293:11 - i don't know what this is so it's going
293:12 - to document what i need to put in there
293:14 - so it must be in the range 0 to 20.
293:16 - excellent okay i can just say 15.
293:19 - i don't really care what it is but now
293:21 - i can just
293:22 - see that this code type checks because
293:24 - this the this returns the appropriate
293:26 - value but also i can see that here
293:30 - i have
293:31 - another place in my app that i need to
293:33 - fix as well so i need to change this
293:34 - instead of supplying a string into a
293:36 - number so that's a very simple
293:39 - demonstration of what the refactoring
293:41 - workflow looks like
293:43 - and what designing with types helps you
293:45 - consider when you're doing
293:47 - development with react and typescript
293:49 - typescript types are basically
293:51 - instructions to the typescript language
293:52 - server in compiler that says
293:54 - you know id is of a certain type so
293:57 - let's try something a little bit more
293:58 - complicated
293:59 - with our stateful component we're
294:01 - annotating both props and state
294:04 - and i'm doing it both in terms of the
294:05 - class component style as well as the
294:08 - function component styles using hooks
294:10 - you can see how hooks are a lot more
294:12 - concise to type with typescript that was
294:14 - not a motivation but it was definitely a
294:16 - nice to have and a plus in favor of
294:18 - adopting hooks the classes versus hooks
294:20 - discussion is also something i'm not
294:22 - very interested in discussing so
294:25 - leave
294:25 - your flame wars in the comments but in
294:28 - general what applies for props also
294:30 - applies for state if you try to refactor
294:32 - anything in a state then the rest of
294:34 - your app is going to update accordingly
294:36 - and that's a very useful thing to have
294:38 - in your reactor
294:40 - so that's a super brief introduction
294:42 - there's a lot more for example when
294:45 - you're making custom hooks here i have a
294:47 - custom used loading hook which covers a
294:50 - used state hook
294:51 - but then also has some custom behavior
294:53 - going on this hook just helps to wrap
294:56 - any promise so that it tracks the
294:58 - loading state
294:59 - and then unsets the loading state once
295:01 - the promise completes and it returns
295:03 - that loading state as a boolean and it
295:05 - gives you a function which you can call
295:07 - to use generically the trick here is
295:10 - that you cannot just return is loading
295:13 - and load in an array like you would in
295:15 - regular javascript because
295:17 - typescript would infer this weird
295:20 - type that is very hard to use and union
295:22 - type of both boolean and load
295:24 - instead you actually need to specify
295:26 - this special as const syntax of
295:29 - typescript and that actually tells
295:31 - typescript to infer as a tuple so
295:34 - in each place instead of assuming that
295:36 - i'll have a general type that matches
295:38 - each of the locations in the array
295:41 - and here is where we use it in a app as
295:44 - a sample where i can wrap any promise
295:46 - and get out that loading state which i
295:48 - can use to show a loading indicator
295:50 - there's a bunch of these little tricks
295:52 - that you need in typescript in order to
295:53 - do these things so it's not exactly
295:55 - clean there is a learning curve but
295:57 - hopefully it's worth it and you know
295:58 - what most of the ecosystem has decided
296:00 - that it's worth it so here i have a
296:02 - tracker of
296:04 - the react ecosystem libraries that are
296:06 - either written in typescript or have
296:08 - rewritten their code types here so they
296:09 - don't just offer typescript types or
296:12 - indefinitely typed or like a separate
296:13 - type to file their internals are written
296:15 - in typescript and so that's next.js
296:18 - react native react router expo redux
296:20 - yarn jest and so on gatsby i think now
296:23 - fully supports typescript as of
296:26 - november 2020.
296:28 - the other thing that's very gratifying
296:29 - is that it starts to bleed over from
296:31 - open source into closed source
296:33 - large-scale production systems one of
296:35 - the most compelling stories comes from
296:37 - rebunge at airbnb where she drove the
296:40 - adoption of typescript at airbnb and
296:42 - according to their own study because
296:44 - they keep very rigorous postmortems
296:47 - 38 of airbnb bugs were preventable with
296:50 - typescript it's also a very compelling
296:51 - story for those who think that you don't
296:53 - need typescript if you test enough
296:54 - because of course airbnb also tests very
296:57 - very rigorously
296:58 - if you were around tech twitter last
297:00 - year when this became a story and it was
297:02 - announced then you probably saw this
297:05 - version of this photo and it spread
297:07 - pretty virally around javascript twitter
297:09 - the reason was this talk wasn't publicly
297:11 - streamed and i just happened to be in a
297:12 - room so i'm happy to have my little
297:14 - contribution to reaction typescript lore
297:18 - if you want to get started learning then
297:19 - definitely check out my repo it's
297:20 - completely free it's called react and
297:22 - typescript cheatsheet there's a github
297:24 - version where you can just read in pure
297:25 - markdown but there's also a hosted
297:27 - version with search i definitely like
297:29 - using the search feature for anything i
297:31 - need to look up
297:33 - we definitely need contributors so
297:35 - please dig through the issues and ask
297:37 - questions or answer them as they come up
297:40 - okay so that's the front end i think
297:41 - that's more of a solved problem
297:43 - the harder problem is actually typesave
297:45 - backends which is something that we're
297:47 - not so clear about i think probably the
297:49 - winner in this space especially for the
297:51 - js ecosystem is graphql graphql itself
297:54 - has a schema definition language instead
297:56 - of a type language but it's pretty much
297:58 - the same thing this is part of the spec
298:01 - of graphql and you can see how they're
298:02 - used on the graphql.org site you can
298:05 - declare enums you can declare types
298:08 - types can have ids or strings or numbers
298:11 - or they can also embed other types and
298:14 - as for queries you can also have a type
298:16 - of query or you can have a type of
298:18 - mutation and that is all wrapped up in
298:21 - your overall schema
298:23 - that's essentially the raw spec and
298:24 - there's extensions that we can do to
298:26 - that spec but based on these type
298:28 - declarations we can start to generate
298:30 - tooling everyone who's used graphql
298:32 - probably knows this but there's a tool
298:34 - called graphical if you haven't come
298:35 - across it definitely check it out
298:37 - because this is probably one of the most
298:39 - effective inspirational influential
298:41 - tools that i've ever come across
298:44 - it's like a repo for your query so it
298:46 - actually runs against a real graphql
298:48 - endpoint you can do queries see those
298:50 - sample responses you can also check out
298:53 - inline documentation
298:55 - even if it's deprecated we can note that
298:57 - it's deprecated and we can tell people
298:59 - what else they should be using
299:01 - every single graphql request is
299:03 - validated before it runs so if you get a
299:05 - badly formed request it won't even go
299:08 - through there's a very standard error
299:09 - resolution process that happens when a
299:12 - bad request comes in so this is very
299:14 - similar to how typescript works for the
299:15 - front end but applies to the back end
299:18 - additionally if you use graphql right
299:20 - you can also get savings in data
299:22 - transfer that makes your app
299:24 - work faster and your bandwidth go down
299:27 - there's a lot of pros and cons to this
299:29 - design and it's hotly debated so i'm not
299:31 - going to cover it all but i just want to
299:33 - make sure that the point is made that
299:34 - because you have type save back-ends
299:36 - then very good tooling can be generated
299:38 - based on your type safe back-ends and
299:40 - because it's an industry standard we
299:42 - share the cost of developing things like
299:44 - graphical and that makes graphql a lot
299:47 - easier to work with
299:50 - so from back end to front end we then
299:52 - need to hook it up and that's the tricky
299:54 - part one of the cool projects that i
299:56 - like to see in this space is called
299:57 - graphql code generator it says what it
300:00 - does it takes graphql and it generates
300:02 - code in our case it generates typescript
300:05 - code and that's exactly what we need to
300:07 - take types from backend to frontend this
300:09 - isn't the only strategy in the space you
300:11 - can also go from typescript to graphql
300:14 - and that's what these two popular
300:16 - projects do type graphql and graphql
300:18 - nexus they both have different ways one
300:21 - uses decorators the other uses standard
300:23 - typescript functions but both are ways
300:25 - of describing what your types are in a
300:28 - way that can also be parsed to generate
300:30 - graphql there's also smaller solutions
300:32 - like type gql and deck api that are
300:35 - exploring different solutions in this
300:37 - problem space
300:38 - however i just want to step back a
300:40 - little bit
300:41 - and address the elephant in the room
300:43 - which is that we want to
300:45 - enable all of this in order to get
300:47 - better user experience by creating more
300:50 - reliable apps without tech debt
300:53 - but in order to get there we need to
300:54 - stitch together all of these tools and
300:57 - our developer experience goes down
300:59 - especially at the initial part when
301:00 - there's a learning curve and we have to
301:02 - figure out how to make all these tools
301:04 - talk together because they weren't
301:05 - designed with a single coherent mindset
301:08 - there's a lot of complexity in order to
301:10 - get all your ducks in a row to get a
301:12 - full stack type safe experience you need
301:15 - to pick your backend resources and then
301:17 - you need to write graphql resolvers for
301:18 - them you need to generate typescript
301:20 - types and then you also need to have
301:22 - client graphql or typescript libraries
301:24 - and then for everything else that you
301:25 - might need like offline syncing or
301:27 - real-time websockets you have to write
301:29 - custom custom code and probably your the
301:32 - open source ecosystem is not well
301:34 - developed enough for you to do all of
301:35 - this out of the box
301:37 - so the end result of reaching this type
301:40 - safe full stack react goal is that we
301:43 - either glue together our own framework
301:45 - and have to
301:46 - maintain a lot of glue code or we use an
301:49 - integrated framework designed for this
301:50 - workflow and that's something i'm
301:52 - interested in exploring at aws and
301:54 - working on
301:55 - so for each of these solutions we have
301:58 - aws absync that provides our backend
302:00 - resources like database but it also acts
302:03 - as a graphql gateway graphql transform
302:05 - which is an open source library that
302:07 - helps to write these graphql resolvers
302:09 - and typescript types and aws amplifier
302:11 - helps to do the code generation but it
302:13 - also provides the client libraries that
302:16 - you can use to access the resources that
302:18 - you've provided so let me show you what
302:20 - this looks like and the ultimate vision
302:23 - of
302:24 - how we can reduce all the boilerplate
302:26 - but actually still achieve this user
302:28 - experience of full stack type safe react
302:31 - so at aws we've actually extended
302:33 - graphql graphql is made to be extensible
302:36 - and one of those ways in which
302:37 - it does that is this cool idea called
302:39 - directives directives are anything with
302:41 - an at on top of them so for example if
302:44 - you write a type in standard schema
302:45 - definition language and you have this
302:47 - all these fields with standard graphql
302:50 - sdl we can actually just add an add
302:53 - model and that's some that only means
302:55 - whatever we make it to mean graphql has
302:57 - no opinion on that
302:59 - so we can just throw it onto here and if
303:01 - we have an integrator toolkit we can
303:03 - actually spin up the resources that are
303:04 - required
303:06 - to make this into a crud enabled model
303:08 - so we can say all right we have a type
303:11 - post inside of our graphql let's spin up
303:13 - the functionality to create posts read
303:14 - post update and delete posts and do that
303:17 - on the back end as well as the front end
303:19 - and that's a fair amount of value add
303:20 - typically the hard part of implementing
303:23 - graphql back-ends is that you have to
303:24 - write a lot of boilerplate for spinning
303:26 - out all these things these are all
303:27 - generated for you just by writing at
303:29 - model
303:30 - just six characters and it saves you a
303:32 - lot of code now i want to stress that
303:34 - this isn't the only solution that does
303:36 - this
303:37 - so hasura and fauna db both offer
303:39 - similar approaches where you can just
303:41 - specify the graphql schema and it spins
303:44 - up the required database resources they
303:46 - just have different underlying databases
303:49 - backing them so for sure this is not at
303:51 - all a unique insight but this is appsync
303:54 - and this is the aws solution if you want
303:56 - to use aws infrastructure
303:58 - so all right we have add model what
304:01 - other directives can we try we can also
304:02 - try adding off right because you know
304:04 - you want to have some authentication
304:06 - when you do crud the only trick is you
304:09 - do need some off service so of course if
304:11 - you have an integrated tool chain then
304:12 - you can add in something like amazon
304:14 - cognito which is aws's standard off
304:17 - service in front of appsync the main
304:19 - trick that you have to figure out when
304:20 - implementing such a solution is you have
304:22 - to figure out how to let users specify
304:24 - rules for who can access what so for
304:26 - example you need ways to specify if the
304:28 - whole model is private or if anyone can
304:30 - read but only the owner of the model can
304:33 - write and you need to be able to do this
304:35 - at the model level as well as the field
304:37 - level how about search imagine adding
304:40 - search capability with one more
304:41 - directive and then auto generating
304:43 - search posts functionality with the
304:46 - exact same workflow as everything else
304:48 - that you use
304:49 - so these are all really interesting and
304:51 - there are other directives you can check
304:52 - out with the graphql transform library
304:55 - we're not going to cover everything
304:56 - exactly but i just want to introduce you
304:59 - to this concept because you've done the
305:01 - sdl definition work whenever you use
305:03 - graphql but you might as well use that
305:05 - to spin up a back end and then you can
305:07 - flow the types to the front end with an
305:09 - auto generated toolchain
305:11 - so for the amount of work that you do
305:13 - just to do that it's actually very
305:15 - powerful to express your full stack type
305:18 - save react that actually brings us to
305:20 - the demo that i've set up and i have
305:23 - just enough time to do it so let's get
305:24 - started i have here a simple create
305:27 - react app it's been set up with
305:28 - typescript and chakra ui for some nice
305:31 - styling it's pretty much an extension of
305:33 - what i already showed you with reactant
305:35 - typescript here it's running and i
305:37 - already have all the client side logic
305:39 - in place and i can submit and it's going
305:41 - to load
305:42 - uh some values
305:44 - the only issue is that there's no
305:45 - persistence so if i refresh this app
305:47 - it's not going to remember anything so
305:49 - our task is to wire it up so it becomes
305:51 - full stack and type safe the first thing
305:53 - i'm going to do is i'm going to
305:54 - initialize my back back-end so i'm going
305:56 - to run amplify init and that actually
305:59 - asks me a few questions to get these
306:01 - process started i'm just going to enter
306:04 - the defaults for all of them but
306:05 - obviously you can customize it however
306:06 - you like and it's going to auto detect
306:09 - my create reactive settings so i don't
306:11 - have to modify any of these but i could
306:13 - if i wanted to all right the next
306:15 - process is to add our backend graphql
306:17 - api so i'm going to run amplify add api
306:20 - which is the standard workflow amplify
306:22 - add whatever category i'm trying to add
306:24 - i'm going to pick graphql and again i'm
306:26 - going to use choose the defaults for
306:28 - whatever they offer me
306:29 - by default they're going to offer me a
306:31 - to-do model i should probably replace
306:34 - that with something that i'm expecting
306:35 - so it's just going to slightly extend
306:37 - that into a simple blog post model and
306:40 - now i can run amplify push to provision
306:42 - those resources that i just established
306:45 - as part of the push process we also get
306:47 - to configure the code generation for
306:49 - front-end types so we get a full stack
306:52 - all the way from graphql all the way to
306:54 - our front end types so let's say yes to
306:56 - generate code and we're going to pick
306:58 - typescript because
306:59 - and we can just hit
307:01 - enter to select all the defaults for the
307:03 - rest so the push and code generation
307:06 - does a couple things and i'm going to
307:07 - talk you through them
307:09 - the first thing that you should check
307:11 - out is inside of your source folder you
307:13 - have an aws exports.js file and this
307:16 - contains all the configuration
307:18 - information that is automatically set up
307:20 - for you by the cli so all you really
307:23 - need to do is import it just importing
307:25 - it at the root of your app sets up your
307:27 - app to connect with the aws backend
307:29 - resources
307:30 - the other thing that's changed is that
307:32 - we have a new graphql folder where all
307:34 - the typescript types have been generated
307:36 - by default based on our models so for
307:39 - queries we have get blog and list logs
307:41 - and the mutation with create and update
307:43 - and delete
307:44 - so everything as you might expect
307:47 - so inside of our app we can actually
307:48 - import whatever queries have been auto
307:50 - generated by our cli and then we can use
307:52 - them inside of our reactant typescript
307:54 - code
307:55 - as you can see here i make use of
307:57 - api.graphql and i need to import that
307:59 - from the client library which i also
308:01 - need to install so yarn add aws amplify
308:08 - that gives us the api.graphql function
308:10 - as well as its typings and we can also
308:12 - use this to
308:14 - do a create operation so you can import
308:17 - create blog and set the variables to the
308:20 - new values that we've set in our react
308:22 - app we should also make sure to import
308:24 - the create blog function from mutations
308:28 - all right let's have a look at what
308:29 - happens when we run this app now i'm
308:31 - gonna let it take up the full screen
308:34 - and
308:37 - let's just autofill some content
308:39 - autofill some more
308:46 - and now when i refresh
308:48 - all the data should continue to be there
308:51 - something else that i really appreciate
308:52 - about this workflow is that it
308:54 - decomposes nicely to the underlying aws
308:57 - services for more control if i need them
308:59 - so i can type amplify console
309:01 - here and it's going to open up the raw
309:04 - services for example here we added the
309:06 - graphql api so i can actually view this
309:09 - in appsync and perform the exact same
309:11 - graphql queries that i was doing in my
309:14 - code
309:15 - uh inside of this little ui that we have
309:18 - over here so i can say list blogs
309:20 - and i can just say give me all of them
309:24 - body title image let's go
309:27 - and this is exactly the query that i was
309:28 - performing
309:29 - and you can actually play with this but
309:32 - also
309:33 - you can see inside of our data sources i
309:35 - can see that it's been provisioned by
309:37 - dynamodb i can use other data sources
309:39 - like
309:40 - aurora and inside of dynamodb i have
309:42 - access to all the other capabilities
309:44 - that regular dynodb has as well as the
309:46 - cost and scaling benefits so here i can
309:49 - access all the raw data and access
309:50 - without amplify and i have full ability
309:53 - to eject from whatever setup has been
309:56 - created so that's a really nice fallback
309:59 - option if i need it now i realize that
310:01 - was a really quick demo and it has no
310:03 - time to cover all the really cool stuff
310:05 - like real-time subscriptions or offline
310:08 - caching but you can check that out on
310:10 - your own
310:11 - mostly i just want to introduce you to
310:13 - the overall concept of an integrated
310:15 - toolkit right amplify provides the cli
310:18 - that you saw the client libraries that
310:20 - you saw and the things that we didn't
310:22 - see are ui components for you to get set
310:24 - up quickly so for example authentication
310:26 - you might want to have an authentication
310:28 - component in your favorite framework so
310:31 - using this unified workflow we can
310:32 - access all the other categories that are
310:34 - exposed to us via
310:36 - aws like analytics aiml predictions
310:40 - uh authentication data storage for with
310:42 - amazon s3 and uh amplified data store
310:46 - all of these are really really cool
310:47 - features and it just take 10 hours to go
310:50 - through all of them but i encourage you
310:52 - to check it out if you're interested in
310:53 - this idea of a full stack integrated
310:55 - serverless approach that is typesafe
310:58 - amplify only started about two years ago
311:00 - and it's getting a lot of traction it's
311:02 - one of the fastest scoring services
311:03 - within aws and new categories are
311:05 - getting added all the time
311:07 - so in fact this year we actually added
311:09 - live streaming video just in time for
311:12 - the madness of 2020. it's almost like we
311:14 - planned it but we did not anyway i want
311:16 - to bring it back to type safe full stack
311:18 - react and i want to acknowledge another
311:20 - react-a-thon speaker lauren tan who
311:23 - actually gave me this idea that she
311:25 - first wrote about the strongly typed
311:27 - graph and she says that the strongly
311:29 - type graph builds upon end-to-end type
311:30 - coverage and connects diverse domains
311:32 - into a single graph and that's a little
311:34 - bit of what we saw today just get to
311:36 - give you a sample it gives teams near
311:38 - real-time visibility of how changes in a
311:40 - larger graph affect your entire
311:42 - organization and that's the ultimate
311:43 - vision of how we can shift left our
311:45 - error discovery and resolution and
311:48 - improve our developer velocity and
311:50 - increase user experience without the
311:52 - cost of developer experience so thank
311:54 - you that was a really quick woven tour
311:57 - throughout all of reactant typescript
311:59 - and graphql all in aws and i hope you
312:01 - stuck through it with me i'll be around
312:03 - to answer any questions see ya and have
312:05 - a great day tomorrow
312:10 - wow
312:11 - we did it
312:12 - the first day of react-a-thon worldwide
312:15 - thank you so much swix for that last uh
312:18 - talk to finish out our wonderful first
312:20 - day here
312:21 - and thank you to all of our speakers um
312:24 - and our workshop leaders and our topic
312:27 - tables hosts and our sponsors and most
312:30 - of all thank you all for being here
312:34 - with us today
312:35 - uh whether through hop in or through the
312:38 - live stream um we're just so glad you
312:40 - all could join us today and we hope you
312:42 - had a ton of fun
312:43 - so that is a wrap for our talks for the
312:46 - day however there is still a lot more
312:48 - happening jonathan you want to tell us a
312:50 - little bit about what's going on
312:52 - yeah so for the next hour and a half you
312:54 - can check out the sponsor expo talk to
312:56 - the engineers there
312:58 - at the sponsor companies and they're
313:00 - there for the next hour and a half
313:01 - uh you can also continue to
313:05 - network with people in the networking
313:07 - session or the sessions section session
313:10 - of the app uh and anjana is going to
313:13 - give us a good reminder uh here as well
313:18 - yeah so the um
313:20 - the the
313:21 - sponsor boost the networking sessions
313:23 - the um the chat on the app all of these
313:26 - great places to connect with people um
313:28 - and as always we want to make sure that
313:31 - everyone is adhering to the code of
313:33 - conduct um again that is there to
313:35 - protect us all and to make this a really
313:37 - safe space for all of us
313:39 - and so as always please keep that in
313:41 - mind don't forget it's available at
313:43 - reactathon.com
313:44 - conduct and you can report any
313:47 - violations
313:48 - should the event arise
313:50 - by clicking on somebody's profile and
313:52 - then clicking report user to send a
313:55 - message to the conference organizers so
313:57 - let's all make sure that we are staying
314:00 - respectful and safe and protecting each
314:03 - other's experience as we continue to
314:05 - engage with each other
314:08 - and we're excited about tomorrow we're
314:10 - going to have more great content both
314:12 - tomorrow and wednesday but tomorrow
314:14 - morning uh starting at 7 a.m pacific
314:17 - time
314:19 - we will have our workshops kicking off
314:21 - at that time and sponsor expos start at
314:23 - 8 30
314:25 - and then of course sponsor talks start
314:27 - at 9 30 a.m pacific
314:30 - and then back on the main stage here you
314:32 - will see us
314:33 - myself and angela
314:35 - around 9 55
314:38 - pacific time
314:40 - absolutely so really excited to see
314:43 - everybody back here again tomorrow and
314:45 - in the meantime you can stick around for
314:47 - the next few minutes uh before you jump
314:49 - off to the sponsor booths and to chat
314:51 - with everybody that you got to connect
314:53 - with today you can also stick around to
314:55 - to catch some nostalgic shots from
314:58 - san francisco where we're hoping fingers
315:01 - crossed with a little luck and a lot of
315:03 - vaccines we might be able to see you all
315:05 - uh back in person next year but uh for
315:08 - now that's uh myself anjana vacheel and
315:12 - my wonderful co-mc jonathan signing off
315:15 - for this day one of react-a-thon we'll
315:18 - see y'all tomorrow
315:20 - bye
315:22 - [Music]
315:39 - [Music]
315:51 - [Music]
316:02 - so
316:08 - [Music]
316:25 - my
316:29 - [Music]
316:41 - foreign
316:46 - [Music]
316:55 - [Music]
317:24 - [Music]
317:26 - so
317:27 - [Music]
317:40 - [Music]
317:47 - [Music]
317:47 - [Applause]
317:51 - [Music]