00:00 - learn how to use mistal AI to build
00:01 - intelligent apps all the way from simple
00:03 - chat completions to Advanced use cases
00:06 - like Rag and function calling per borgan
00:09 - from scrimba created this course in
00:10 - collaboration with mistal AI you'll get
00:14 - hands-on experience with mistral's open-
00:16 - Source models including mistl 7B and
00:20 - mistl 8ex 7B and their commercial models
00:24 - by the end of this course you'll Master
00:26 - essential AI engineering paradigms
00:28 - enabling you to create sophisticated
00:30 - conversational user experiences and run
00:33 - AI models locally on your own
00:38 - computer hi there and welcome to this
00:40 - introduction to mistol AI my goal with
00:43 - this course is to teach you how to build
00:45 - magical stuff and more specifically how
00:48 - to do that using JavaScript and mistal
00:51 - AI if you don't know what mistal is it
00:53 - is a company that builds so-called
00:55 - foundational models that in 2023 twice
00:58 - managed to stun the AI Community by
01:00 - launching small open-source foundational
01:03 - models that were on par with the best
01:05 - close Source models out there so as an
01:08 - AI engineer mistel is definitely
01:10 - something that deserves your attention
01:12 - in this course we are going to start off
01:13 - by looking a little bit closer at mistel
01:15 - in general and their platform before we
01:17 - dive into the API Basics and how to use
01:20 - their JavaScript SDK as this course is
01:22 - based around JavaScript though their
01:24 - python SDK is similar so even if you
01:27 - prefer python over JavaScript you'll
01:29 - still get a ton of value value from this
01:30 - course we are also going to go through
01:32 - all of the models that mistl offers at
01:34 - the time of recording this course
01:36 - including their embedding model which
01:38 - lets you work with Vector databases
01:40 - which you'll also get an introduction to
01:42 - in order to give your AI apps domain
01:44 - knowledge which for example could be
01:46 - proprietary company data real-time
01:48 - information that the model hasn't been
01:50 - trained on or for example extra in-depth
01:53 - knowledge about a specific subject that
01:54 - is too narrow for the AI to have been
01:56 - trained on and we'll do this through a
01:58 - technique called retrieve augmented
02:00 - generation AKA rag you'll also learn how
02:03 - to build AI agents with function calling
02:06 - enabling your apps to take action based
02:08 - upon the user prompt a truly
02:10 - revolutionary Paradigm and finally
02:12 - you'll learn how to run your models
02:14 - locally on your computer and interact
02:16 - with them both via the terminal and a
02:18 - web page now who am I I've been a
02:21 - developer instructor and startup founder
02:23 - for almost 10 years now and I'm also the
02:26 - CEO of the learning platform you're on
02:28 - now which is scrimba I use create
02:30 - tutorials on JavaScript react and AI
02:32 - engineering and in total they have been
02:34 - watched by literally millions of people
02:37 - through the scrimba platform corsera and
02:39 - YouTube I love to connect with my
02:41 - students so please click on either of
02:43 - these links if you're interested in
02:44 - connecting on either X or LinkedIn now
02:47 - you'll also see lessons from two other
02:49 - teachers as well throughout this course
02:51 - namely from Gil Hernandez one of our
02:52 - brilliant instructors here at scrimba
02:54 - and we're also proud to have Sophia Yang
02:57 - the head of developer relations at
02:59 - mistol contributing to this course so as
03:02 - you probably understand now this course
03:04 - is a collaboration between mistol and
03:06 - scrimba so we're not pulling this
03:08 - curriculum out of thin air it has been
03:10 - created in partnership with the company
03:12 - itself if you ever find yourself lacking
03:14 - some JavaScript skills or AI engineering
03:17 - Concepts please check out our frontend
03:19 - developer career path or this AI
03:20 - engineering course as those will help
03:22 - you get up to speed so with that let's
03:25 - get
03:28 - started hello it's this is Sophia yam
03:30 - from Mr AI I like to welcome you to the
03:33 - course and give you a brief introduction
03:35 - of mrol Mr AI was founded last year by
03:39 - our three co-founders Arthur Tim and gam
03:42 - we first released our open W model Mr 7B
03:46 - in September last year we released a x7b
03:50 - mixture of experts model and that
03:53 - platform in December we currently have
03:56 - offices in Paris London and San
03:58 - Francisco Bay Area
04:01 - we offer six models for all use cases
04:04 - and business needs including two open
04:06 - source models mro 7B and mixol 8 x7b
04:11 - they're under open source AP par 2.0
04:13 - license they great to started
04:16 - experimenting with we also offer four
04:19 - optimized Enterprise grate models Mr
04:22 - small for low latency use cases Mr
04:25 - medium or language based tasks and Mr
04:27 - Large for your most sophisticated needs
04:30 - we also offer an embedding model which
04:32 - offers the State ofth art embeddings for
04:35 - text to get started you can use our chat
04:39 - assistant L to interact with our model
04:41 - right away just go to chat. m.ai and you
04:46 - can play with Lua there are several ways
04:48 - to use our models we offer API end
04:51 - points for all of our models through the
04:54 - platform you can subscribe and get an
04:56 - API key on the platform this is the
04:59 - easiest to use and deploy you can also
05:02 - use our model on cloud services which
05:05 - provide fastest deployment for
05:07 - Enterprise especially for those who
05:09 - already use cloud
05:11 - services you can also self- deploy our
05:14 - models on your own on Prem
05:16 - infrastructure this will give you more
05:18 - control and flexibility but it's the
05:21 - most complex among the three so it's a
05:24 - tradeoff between ease of deployment and
05:26 - level control so you can choose
05:28 - whichever you want for your own use
05:30 - cases and your business needs this
05:33 - course will focus on the platform and
05:35 - how to use Mr API for various tasks hope
05:39 - you enjoy the
05:43 - course okay in order to interact with
05:46 - the mistal API you need an API key which
05:49 - will'll get through their platform or La
05:51 - platform as they call it so click on
05:53 - this image right here and you'll be
05:54 - taken to the mistal homepage and there
05:56 - you can click on the build now option
05:59 - that'll take you to the authentication
06:00 - screen so choose however authentication
06:02 - method you want and then in the next
06:05 - step you're asked to create a worksspace
06:06 - name and check off whether you're a solo
06:09 - Creator or doing this as a team member
06:11 - in a company whatever you choose click
06:13 - create workspace and there we go this is
06:16 - the platform and in order to get access
06:18 - to the API you have to provide a card or
06:21 - subscribe as they say here however you
06:24 - only pay for what you use so this is not
06:26 - an ongoing fixed subscription so just
06:28 - add your card and once you done that
06:30 - this box will go away and you can click
06:32 - on API keys to create Keys you can
06:34 - authenticate with click on the create
06:36 - new key and give it a name and an
06:38 - expiration date and then create key now
06:41 - you'll only see this key once so be sure
06:44 - to save it as a scrimba environment
06:45 - variable you learn how to do that by
06:47 - clicking on this link right here and
06:50 - please don't take the time to try and
06:51 - copy this API key right here by the time
06:54 - you watch this scrim this key is no
06:56 - longer active as I've deleted it so go
06:58 - ahead and follow these steps and set the
07:00 - N variables in scrimba and then in the
07:02 - next scrim my colleague Gil will teach
07:04 - you the basics of how to interact with
07:06 - the mistal API through
07:10 - JavaScript hey in this tutorial we'll go
07:13 - over using the chat completion API which
07:16 - allows you to chat with a model that's
07:18 - fine-tuned to follow instructions so
07:20 - let's Dive Right In we're going to use
07:22 - mistral's JavaScript client which I've
07:24 - installed and set up in this interactive
07:26 - scrim I'm importing mistal AI at the top
07:29 - of the Javascript file and I've
07:31 - instantiated a mistal client using my
07:33 - API key which I've stored as an
07:35 - environment variable on scrimba so we're
07:38 - ready to go the chat completion endpoint
07:40 - is designed to handle back and forth
07:42 - conversations you feed it a prompt and a
07:44 - series of messages and it generates a
07:47 - completion or an appropriate
07:48 - continuation of that conversation so now
07:51 - let's make our first chat request using
07:53 - ml's chat method I'll declare a constant
07:55 - named chat response to store the
07:58 - response returned from the chat request
08:00 - which will await with await client. chat
08:04 - and pass the method an object containing
08:06 - the request body the chat completion API
08:08 - accepts various parameters the two
08:10 - required parameters are model and
08:13 - messages mistol has various pre-trained
08:16 - models you can use with the API for our
08:19 - purposes we'll use a model called mistal
08:21 - tiny then I'll set the messages
08:23 - parameter to an array and this is a key
08:26 - part of the chat request as it holds the
08:28 - prompts to generate completion for this
08:30 - should be an array of message objects
08:32 - each with role and content properties
08:35 - role defines the role of the message
08:38 - I'll set it to user indicating that the
08:40 - message is from the user's perspective
08:43 - then set content to the actual content
08:46 - of the user message this is usually a
08:49 - question like what is the best French
08:51 - cheese all right and this is all we need
08:53 - to generate a chat completion so let's
08:56 - log the response to the console and the
08:58 - way to access the message content
08:59 - directly is like this I'll run this code
09:02 - by clicking the Run button and good the
09:05 - API returns a humanlike response about
09:07 - the different types of French cheese all
09:10 - right so what I want you to do now is
09:12 - personalize the AI response by updating
09:14 - the content property to something that
09:17 - interests you you might not have
09:18 - realized this yet but this isn't your
09:20 - typical video player you are
09:22 - experiencing a fully interactive scrim
09:25 - that you can pause at any moment and
09:26 - jump right into the code and make
09:28 - changes to it so go ahead and ask the AI
09:30 - a question then click
09:36 - run okay hopefully that was fun and you
09:38 - got some great responses now let's
09:41 - experiment with other parameters to make
09:42 - our response more interesting we'll use
09:45 - the temperature parameter to set the
09:47 - creativity or randomness of the
09:48 - generated text and this should be a
09:50 - value between 0 and 1 Now the default
09:53 - temperature is
09:54 - 0.7 but as you get closer to one the
09:57 - output will be more random and creative
10:00 - while lower values make the response
10:02 - more focused and deterministic I'll set
10:05 - it right down the middle at 0.5 to
10:07 - strike a balance between creative and
10:09 - predictable responses and now I'll feed
10:12 - it a different question like I want a
10:14 - puppy what is the most kid-friendly
10:17 - dog I'll run this code and I get back a
10:20 - detailed conversational response about
10:22 - various dog breeds good all right I want
10:25 - you to go ahead and pause me now and try
10:27 - experimenting with different temperature
10:31 - values you can also provide custom
10:34 - system prompts to guide the behavior of
10:36 - the model this time I'll set roll to
10:38 - system then set content to the
10:41 - instructions or prompt for the model
10:43 - this is your chance to influence how the
10:44 - AI response so I'm instructing it that
10:47 - it's a friendly cheese kind of sore and
10:49 - that when asked about cheese to reply
10:52 - concisely and humorously now running
10:55 - this won't work because now we need to
10:56 - follow the system role with a user role
10:59 - in content I'll set the role property in
11:02 - this second message object to user then
11:05 - set this content property to ask what is
11:07 - the best French cheese I'll run this
11:09 - code and I get back a fun and witty
11:12 - response about French cheese fortunately
11:14 - it's always cheese season right all
11:16 - right so that's it for the basics of
11:18 - working with the chat completion
11:22 - API now that you've gotten to know the
11:24 - basics of how to set up a request to
11:26 - mistol let's have a look at some of the
11:28 - options and configurations you as a
11:30 - developer can adjust so that you tweak
11:32 - the response you get from mol to your
11:34 - needs and perhaps the most apparent one
11:37 - is adding support for streaming because
11:39 - that is often a key feature of AI apps
11:42 - for example here on hugging face the
11:44 - platform for open- Source AI models and
11:47 - data sets on the mistal organization
11:49 - there's a hosted version of one of their
11:51 - models along with a chat interface so
11:53 - that you can talk with it so here I'll
11:54 - ask it the question what's your favorite
11:56 - Taco ingredient and when I send that I
11:58 - immediately see the response getting
12:00 - built up token by token until it's done
12:03 - and this is a really Pleasant user
12:05 - experience so let's see how we can tweak
12:07 - this from just giving us the entire
12:09 - response to giving us one token at a
12:12 - time so the first thing we need to do is
12:14 - change this from chat to chat stream
12:17 - like that what then happens is that this
12:19 - chat response changes from being a
12:21 - regular object to being a so-called
12:23 - async iterable meaning that we have to
12:26 - await as every item in this iterable
12:28 - becomes available to us so chat response
12:31 - will kind of gradually be built out as
12:33 - we get token by token from the mystal
12:36 - API and the way to deal with this is to
12:38 - create an asynchronous for of loop so
12:41 - we'll do for A8 and then const chunk of
12:47 - chat response and every time the body of
12:50 - this for Loop is executed we get access
12:52 - to a new chunk and as for the chat
12:55 - response this is an object with many
12:57 - properties so we'll have to navigate all
12:59 - almost in the same way as we navigated
13:00 - into the chat response do choices though
13:03 - instead of message it's called Delta so
13:06 - if we now try to console log out this
13:09 - and comment this one out let's see what
13:12 - happens and yes we are getting a ton of
13:15 - stuff logged to the console super fast
13:18 - so this kind of buildup of the response
13:20 - would happen almost instantly and
13:22 - probably a lot faster than we could read
13:24 - it though it's a lot better user
13:26 - experience than having to wait until the
13:27 - entire thing is generated and and then
13:29 - get the response in one go okay let's
13:31 - have a look at another cool
13:32 - configuration you can make to the
13:34 - request and that is to tell mistl that
13:36 - you want the reply in the format of Json
13:39 - that is Javascript object notation here
13:41 - is an example of a Json string and if
13:44 - you don't know what is it is essentially
13:45 - a very common schema that developers use
13:47 - when sending and processing information
13:49 - so being able to get this kind of format
13:51 - from the AI is super helpful as you
13:53 - integrate it with your app and doing
13:56 - this only requires two small settings
13:58 - the first one being that you need to set
13:59 - the
14:00 - response format as an object of type
14:06 - Json object like that and then you also
14:08 - need to specify it in the prompt so here
14:11 - I'll write reply with Json like that
14:15 - here the data will be processed by code
14:17 - and not by a human first and foremost so
14:19 - let's skip this streaming here because
14:22 - it is mostly for the ux directed at
14:24 - humans and then go back to chat here and
14:26 - finally uncomment this one and then like
14:29 - that so let's run the code and yes there
14:32 - we get a Json object I'll copy it from
14:35 - the console paste it in here and there
14:37 - we can see it is an object with a key
14:39 - answer that talks a little bit about
14:41 - good cheese and then it also has a
14:42 - cheese key with a subsequent name key
14:45 - cheese key which is an object that has
14:47 - three keys name country and type so you
14:50 - can imagine it being a lot easier to
14:52 - extract the metadata from this reply as
14:54 - opposed to Simply getting a couple of
14:56 - sentences so I would recommend you to
14:58 - play around with this check out the
15:00 - documentation and see what other
15:01 - configurations and modifications you can
15:03 - make to this response and then once
15:05 - you're ready I'll see you in the next RM
15:07 - where we'll dive more into what we've
15:09 - configured on this specific line which
15:11 - is the models themselves that mistl
15:13 - provides as it's important to have a
15:15 - good overview in order to choose the
15:17 - right ones for the job so I'll see you
15:22 - there hey in this Grim we're going to
15:25 - look at the various models mistal offers
15:28 - now be aware though that these are the
15:29 - models it offers at the time of
15:31 - recording this scrim you should
15:33 - definitely click on this image right
15:35 - here so that you're taken to the landing
15:37 - page for their models as there you can
15:39 - click around and check out their latest
15:41 - optimized commercial models as well as
15:43 - their open models now speaking of open
15:46 - models mistol Rose to prominence in the
15:48 - AI community in 2023 when they launched
15:50 - their first model mistol 7B that is a
15:53 - model that has so-called open weights
15:55 - meaning that you can download it to your
15:58 - computer or upload it to a server and
16:00 - use it as a part of your application
16:02 - without paying mistel a dime one of the
16:05 - things that stunned the AI Community was
16:08 - how powerful it was despite only having
16:10 - 7 billion parameters as the leading open
16:13 - models back then had many more
16:15 - parameters than this even an order of
16:17 - magnitude more now a little later mistol
16:19 - launched the so-called mixol adex 7B
16:22 - which also is an open model and has a
16:25 - unique architecture that allows it to be
16:27 - much more powerful though only slightly
16:30 - more expensive to run inference on the
16:32 - core idea behind this one is that it
16:34 - uses a mix of eight different so-called
16:37 - experts so the total number of
16:39 - parameters here is actually 8 * 7 which
16:43 - is 46 though when you run inference it
16:45 - only Taps into one of these experts and
16:48 - it actually uses around 13 billion
16:50 - parameters when being run now at this
16:53 - point you might be a little bit confused
16:54 - and want to know more about this I don't
16:56 - want to go more into the technical
16:58 - details here because I don't think it's
17:00 - that important in order to use these
17:01 - Technologies though if you are
17:03 - interested feel free to click on this
17:05 - image right here and you'll be taken to
17:07 - a article which talks more in depth
17:09 - about the Mixel model moving on to the
17:11 - next models those are the mistal small
17:14 - mistal medium and mistal large and these
17:16 - are not so-called open weights meaning
17:18 - that you can simply download them from
17:20 - their website and get started locally
17:22 - you either have to use this VI cloud
17:24 - provider that supports these models or
17:26 - you can do self hosting as well though
17:28 - to to do that you have to talk with the
17:30 - mistal team now if we compare these
17:32 - models side by side with their
17:34 - performance on the MML U test as the
17:37 - height of each bar here you can see that
17:39 - the commercial models are more powerful
17:41 - than the open models though the small
17:43 - commercial model and the mix dra are
17:45 - quite within the same range now if you
17:47 - don't know what MML U is it is a common
17:50 - way to test llms it's short for massive
17:53 - multitask language understanding and it
17:55 - puts llms to the test through a range of
17:58 - different tasks giving them a score from
18:00 - 0 to 100% based upon how well they
18:03 - perform now looking at this image it
18:05 - seems that we always should go for the
18:07 - mistal large model but that's actually
18:10 - not the case because the flip side of
18:12 - using a better model is very often that
18:14 - it is more expensive so if we plot this
18:17 - models out on a two-dimensional space
18:19 - with the cost per million tokens on the
18:21 - x-axis and the ml U score on the Y AIS
18:25 - you can see that the picture is
18:26 - definitely different because mistal is
18:29 - by far the most expensive model over
18:31 - twice as expensive as the mistal medium
18:34 - so here if you are able to get the job
18:36 - done with medium you should definitely
18:38 - choose that one analogy you can think of
18:40 - here is when hiring people at a company
18:43 - in many cases you probably don't want to
18:45 - hire a person that is overeducated or
18:48 - over qualified for the job because most
18:50 - likely their hourly rate will be higher
18:53 - so how do you then decide which model to
18:55 - use if you want to dive more into this
18:57 - subject just click on this image here
18:59 - and you'll be taken to the guide in the
19:01 - docs which specifically talks about
19:03 - model selection there you can see some
19:05 - use case examples on what kinds of
19:07 - typical tasks a model is suitable for so
19:10 - for example the mistal small works well
19:12 - for things like classification and
19:14 - customer support whereas the mystal
19:16 - medium is the ideal model for
19:18 - intermediate tasks that require moderate
19:20 - reasoning that could be things like data
19:22 - extraction summarizing a document
19:25 - writing a job description and so forth
19:27 - and finally if you want to do more
19:29 - complex tasks Mr Large is your go-to
19:32 - model so later in this course we are
19:34 - going to create a little agent that can
19:36 - call functions on behalf of users in
19:38 - addition to doing so-called retrieval
19:40 - augmented generation AKA Rag and in
19:43 - those cases we are going to use the
19:44 - large model as those require significant
19:47 - reasoning capabilities and on that note
19:50 - what is exactly rag well you'll figure
19:53 - out in the next
19:57 - scrim here at scrim but we use an app
19:59 - called notion for notes taking and with
20:02 - a team of several teachers developers
20:05 - people in operations and so forth we
20:07 - have a lot of Internal Documentation and
20:10 - it quickly becomes chaotic so here we
20:12 - have a courses and teaching page which
20:15 - again contains a bunch of sub pages and
20:17 - they themselves also have sub Pages as
20:19 - well so it is actually quite hard at
20:21 - times to get to the answer you want to
20:23 - get to which is why I was really glad
20:25 - when lotion launched their ask AI
20:27 - feature which is essentially means that
20:29 - you can ask questions to notion so one
20:32 - day when I was working on our corsera
20:34 - exports I seemed to remember that we
20:36 - needed a widget for doing these exports
20:39 - and I asked it about exactly that it
20:42 - thought a little bit and then came with
20:43 - an answer yes you are correct for corera
20:46 - courses a type of item called plug-in is
20:49 - used to embed scrims and this is quite
20:51 - interesting because I asked for a widget
20:54 - but the AI understood that well actually
20:56 - I meant the plugins so it's shared with
20:59 - me through this footnote here the link
21:01 - to the document that talked about these
21:03 - corsera plugins and this kind of user
21:05 - experience is a GameChanger for web apps
21:08 - suddenly it is much easier to find the
21:11 - information you need and also you give
21:13 - the llm access to proprietary data as
21:17 - obviously the underlying model here does
21:20 - not have any knowledge about how we at
21:21 - scrimba internally embed our scrims in
21:23 - corsera courses now this whole
21:26 - experience was only possible through
21:28 - something called retrieval augmented
21:30 - generation which Probably sounds very
21:32 - complex but don't worry we'll go through
21:34 - it step by step and we won't refer to it
21:37 - through this long complex name here
21:39 - we'll use the popularized expression rag
21:42 - okay so rag contains of mainly two steps
21:44 - there's the retrieval step fetching the
21:46 - data you need to reply to the user's
21:48 - question and there's the generation
21:50 - taking whatever information you found
21:52 - and using that as context when
21:54 - generating the conversational reply back
21:57 - to the user so if if we zoom in on the
21:59 - retrieval first this is very often done
22:02 - in collaboration with a so-called Vector
22:04 - database that is a specific type of
22:06 - database that is optimized for storing
22:09 - information in a specific format that
22:11 - makes it easy for AI to reason about it
22:14 - so it stores so-called embeddings now at
22:17 - this point you're probably a little bit
22:19 - confused what's this thing about vectors
22:21 - and embeddings and all of that don't
22:23 - worry about it we'll get back to that
22:25 - later for now I just want to explain rag
22:27 - on a very high level so what you do is
22:30 - you take all of your data and shove it
22:32 - into a vector database in this specific
22:34 - embedded format and then you take the
22:36 - search query or the input from the user
22:38 - and turn that into an embedding as well
22:40 - as that gives you the opportunity to do
22:42 - a so-called semantic search and get
22:45 - these search results which intelligently
22:47 - for example understand that no pair
22:49 - wasn't looking for a widget he was
22:51 - actually looking for this and thus fetch
22:53 - the relevant data for the app that is
22:55 - the retrieval part once you've done that
22:57 - you take the user input that is the
22:59 - question I asked which was a very
23:01 - humanly written sentence about I seem to
23:03 - remember something about a corsera
23:05 - wouldit blah blah blah and then you
23:07 - combine that with the search results we
23:09 - got in the retrieval step and turn it
23:11 - into a singular prompt that the llm can
23:14 - use as input so mistal AI takes that
23:16 - prompt and the relevant context we
23:19 - retrieved and turns that into a very
23:22 - humanly readable response with in many
23:24 - cases a footnote or link to the
23:27 - underlying data as well thus providing
23:29 - the user a way of factchecking the claim
23:31 - that the AI comes with now there's one
23:34 - thing that all of this relies on which
23:36 - is our ability to turn data for example
23:39 - a sentence into numbers that the AI can
23:43 - understand now all of this relies in our
23:45 - ability to create something called
23:48 - embeddings and what is an embedding well
23:51 - it is what you get when you take a piece
23:52 - of data for example the string hello
23:55 - world and run it through an AI model
23:57 - that turns it into a long array of
24:00 - numbers also known as a vector and as we
24:03 - build out a rag solution in this course
24:05 - it is really important that you have an
24:07 - intuitive understanding of what this
24:09 - embedding concept is so before we
24:11 - continue on with our rag project I'll
24:14 - leave the mic to my colleague Gil
24:15 - Hernandez who will give you a primer on
24:17 - embeddings in the next
24:22 - scrim whether you realize it or not AI
24:25 - powered search shapes many parts of your
24:27 - daily lives every day you interact with
24:30 - platforms sifting through massive
24:31 - amounts of data from text and images to
24:34 - audio and video think about Amazon
24:36 - recommending products or search engines
24:38 - refining your queries social media
24:40 - platforms curate tailored content while
24:43 - services like YouTube Netflix and
24:45 - Spotify offer suggestions based on your
24:47 - preferences now Advanced AIS despite
24:50 - their capabilities don't truly
24:52 - understand the real world as we do they
24:54 - can't grasp the actual meaning or Nuance
24:56 - of a video title song or news article so
24:59 - how exactly do AIS and platforms like
25:01 - Spotify Netflix and YouTube truly get us
25:05 - how is it that they appear to understand
25:07 - predict and respond to us as effectively
25:09 - as if not better than people well the
25:11 - magic behind this capability involves a
25:13 - blend of algorithms AI models and huge
25:17 - amounts of data but a larger part of the
25:19 - answer involves embeddings you see when
25:22 - you present a question to an AI it first
25:24 - needs to translate it into a format it
25:26 - can understand so you can think of
25:28 - embeddings as the language that AI
25:31 - understands the term embedding is a
25:33 - mathematical concept that refers to
25:35 - placing one object into a different
25:37 - space think of it like taking a word or
25:40 - sentence which is in a Content space and
25:42 - transforming it into a different
25:44 - representation like a set of numbers in
25:46 - a vector space all while preserving its
25:48 - original meaning and the relationships
25:50 - between other words and phrases AI
25:53 - systems process lots of data from user
25:56 - inputs to information and databases at
25:58 - the heart of this processing are
26:00 - embeddings which are vectors
26:01 - representing that data transforming
26:03 - content like search queries photos songs
26:06 - or videos into vectors gives machines
26:09 - the power to effectively compare
26:11 - categorize and understand the content in
26:14 - a way that's almost human so how is all
26:17 - of this possible well it isn't exactly
26:19 - as easy as just turning data into
26:20 - vectors so before we go any deeper let's
26:23 - take a closer look at what vectors are
26:25 - think of a vector as a coordinate or
26:27 - point in space and to keep things simple
26:29 - we'll have a look at this 2D graph with
26:31 - an X and Y AIS let's say that a word
26:33 - like cat is translated into a vector
26:36 - like 4.5 12.2 which is this point this
26:40 - Vector encapsulates the meaning and
26:42 - nuances of the word cat in a way an AI
26:45 - model can understand and then we have
26:47 - the word feline represented by a nearby
26:49 - Vector of 4.7 12.6 so we'll place that
26:53 - point on the graph now words that have
26:55 - similar meanings are numerically similar
26:57 - and tend to be be closely positioned in
26:59 - the vector space so this closeness
27:01 - implies that cat and Feline have similar
27:03 - meanings now let's say we have the word
27:05 - or vectors for kitten which might also
27:08 - be close to cat and Feline but maybe
27:10 - slightly further apart due to its age
27:12 - related Nuance now a dog is different
27:16 - but still in the same general domain of
27:18 - domesticated animals so the word dog
27:20 - might be represented by a vector that's
27:23 - not too distant but clearly in a
27:24 - different region let's say 7.5 10.5
27:28 - and even a phrase like Man's Best Friend
27:30 - which is a colloquial term for a dog
27:32 - could be represented by a vector that's
27:34 - close to the vector for dog on the other
27:37 - hand a word like building is not related
27:39 - in meaning to any of these so its Vector
27:42 - would be much further apart let's say
27:44 - 15.3
27:46 - 3.9 here's another example that
27:48 - demonstrates how embeddings might
27:49 - capture semantic meaning and
27:51 - relationships between words let's say we
27:53 - have the word King represented by the
27:55 - vector 25 then man man is the vector 13
28:00 - and woman is represented by the vector
28:03 - 14 now let's do some quick Vector
28:05 - arithmetic we'll start with the vector
28:07 - for King then subtract the vector for
28:09 - man to remove the male context and add
28:11 - the vector for woman to introduce new
28:13 - context after performing this Vector
28:15 - math our resulting Vector is
28:18 - 26 so we'll plot that point on the graph
28:21 - and let's say there's another word in
28:22 - our space queen represented by the
28:24 - vector 2 6.2 right here well this Vector
28:28 - is extremely close to the resulting
28:30 - Vector so we might identify queen as the
28:33 - most similar word based on that Vector
28:36 - just as a trained AI model would now a
28:39 - two-dimensional graph is a massive
28:41 - simplification as real world embeddings
28:43 - often exist in much higher dimensional
28:46 - spaces sometimes spanning hundreds or
28:48 - even thousands of dimensions for example
28:50 - the actual Vector embedding for the word
28:52 - Queen might have values across multiple
28:54 - Dimensions each Dimension or number in
28:56 - this Vector might capture a different
28:58 - semantic or contextual aspect of the
29:00 - word Queen for instance royalty
29:02 - Cleopatra or even chess this is what
29:05 - allows the AIS to recognize and
29:07 - differentiate between these contexts
29:09 - when the word is used in different
29:10 - scenarios now imagine embedding hundreds
29:13 - of thousands of words and phrases into
29:15 - this high-dimensional space some words
29:17 - will naturally gravitate closer to one
29:19 - another due to their similarities
29:21 - forming clusters While others are
29:23 - further apart or sparsely distributed in
29:25 - the space these relationships between
29:28 - vectors are extremely useful think back
29:30 - to spotify's method of embedding tracks
29:32 - in a vector space tracks that are
29:34 - positioned closely together are likely
29:35 - to be played one after the other all
29:37 - right so what else can we do with
29:39 - embeddings and how are they used in the
29:40 - real world well you can imagine how
29:42 - embeddings have revolutionized our daily
29:44 - experiences for example search engines
29:47 - have evolved to understand the essence
29:49 - of your queries and content moving
29:51 - beyond mere keyword matching and
29:53 - recommendation systems with the aid of
29:55 - embedding suggest products movies or
29:57 - songs that truly resonate with our
29:59 - preferences and purchase history for
30:01 - example Netflix uses them to create a
30:03 - tailored and personalized platform to
30:05 - maximize engagement and retention also
30:07 - in the healthcare industry embeddings
30:09 - are used to analyze medical images and
30:11 - extract information doctors can use to
30:14 - diagnose diseases and in the finance
30:16 - World embeddings help with analyzing
30:18 - financial data and making predictions
30:20 - about stock prices or currency exchange
30:22 - rates so every time you interact with an
30:24 - AI chatbot every time an app recommends
30:27 - something behind the scenes embeddings
30:29 - are at work translating data into
30:31 - meaning all right so how are these
30:33 - embeddings actually created well let's
30:35 - dive into that
30:39 - next before we create our embeddings
30:42 - there's one important thing you need to
30:43 - learn and that is how to split text
30:46 - because as an AI engineer you'll find
30:48 - yourself having to split text again and
30:50 - again because let's say that you are
30:52 - working on an internal employee handbook
30:55 - app which lets employees ask questions
30:57 - about the compan policies well in which
30:59 - casee you probably have a large data
31:02 - source like the one you can see here in
31:04 - handbook. text which contains all of the
31:06 - data that you need to embed however
31:08 - creating one embed of this entire thing
31:11 - would just be meaningless there's far
31:13 - too many subjects and themes talked
31:15 - about in this handbook so it wouldn't
31:17 - really have any specific semantic
31:19 - meaning of value it would be far too
31:21 - broad so what we're going to do is take
31:23 - this document and split it into chunks
31:26 - and then we'll create an embedding of of
31:28 - every single chunk now creating such
31:30 - chunks is actually a little bit complex
31:32 - though luckily we have a tool to help us
31:34 - with that and that is Lang chain one of
31:36 - the leading libraries for AI Engineers
31:39 - so what we'll do is enhance this
31:41 - function so that it uses the Lang chain
31:43 - text splitter because as you can see
31:45 - this doesn't do much at the moment it's
31:47 - simply an async function that fetches
31:49 - the handbook and calls do text on the
31:52 - response thus giving us all of the text
31:55 - in this handbook let's run the code and
31:58 - just see that it works yes there we have
32:00 - it so now we can use Lang chain to split
32:02 - this into smaller chunks I'll import the
32:04 - Lang chain Library here as a dependency
32:07 - and then let's figure out which specific
32:09 - tool we need to import from Lang chain
32:11 - the simplest one is the character text
32:13 - splitter though the recommended one to
32:15 - use is the recursive character text
32:17 - splitter so that's the one we're going
32:18 - to use so here we'll do import recursive
32:22 - character text Splitter from Lang chain
32:26 - SL text splitter like that
32:28 - now we can create a new recursive
32:31 - character text splitter this is a
32:32 - Constructor function that takes an
32:34 - object as the argument and here you
32:36 - define two things the size of the chunk
32:38 - and how much overlap you want between
32:40 - the chunks we'll try for example 250
32:43 - characters for the size of the chunk
32:45 - that feels like a sentence or two and
32:47 - will allow for some overlap for example
32:49 - 40 characters we'll call our splitter
32:52 - simply splitter like that and then we
32:55 - can do splitter. create document
32:58 - and pass in the text this is an async
33:01 - function so we have to await it and
33:03 - store the result in a variable called
33:05 - for example output like that now if we
33:09 - log out the output let's run the code
33:13 - and there I got an error and that is
33:14 - because I have a typo I called the text
33:16 - splitter which is wrong it should be
33:18 - text splitter like that let's run the
33:22 - code again yes there we go as you can
33:25 - see in the console there are a bunch of
33:27 - data there and if we open the dev tools
33:29 - we'll be able to inspect it a little bit
33:31 - more in detail so let's do that here as
33:33 - you can see it is an array which
33:34 - contains 2 180 objects let's open up one
33:38 - of these objects and there we can see
33:39 - that we have the text itself under the
33:42 - page content property and also under the
33:44 - lines property we get the exact lines
33:46 - this content comes from in the handbook.
33:49 - text file that is very handy in case you
33:52 - want to create footnotes or reference to
33:54 - the original Source in your app now what
33:56 - you want to make sure of when you
33:57 - respect your data like this is that each
33:59 - of these trunks ideally only deal with
34:02 - one subject or theme that is how you
34:04 - create good embeddings if a given trunk
34:06 - is quote unquote polluted by different
34:08 - themes it'll be harder for the embedding
34:10 - model to create a meaningful Vector of
34:13 - it so here you can see that this trunk
34:15 - deals with delegation of authority and
34:17 - responsibility and the administration
34:20 - and the executive director so definitely
34:22 - a coherent subject though it's actually
34:24 - been split in the middle of two
34:26 - sentences so it could probably be better
34:28 - as well we have probably not struck the
34:30 - perfect balance here you could argue
34:32 - that it would have been better to split
34:34 - this into two and then use the entire
34:35 - sentences or maybe expand it in both
34:38 - ends and include both of the complete
34:40 - sentences in general the shorter your
34:42 - chunks are the more precise meaning the
34:45 - embedding will get though you might also
34:47 - miss some wider context and the longer
34:50 - the trunks are the more context they
34:52 - contain but it can also produce too
34:53 - broad of a scope of information and this
34:55 - would reduce the quality of the
34:57 - similarity search that the vector
34:59 - database does as the underlying meaning
35:01 - of the embedding could be ambiguous it
35:03 - could point in two different directions
35:05 - so to speak in general you want your
35:07 - chunks to be as small as possible but
35:09 - you don't want to lose context so it's
35:11 - definitely a balance to strike and
35:13 - something you'll probably only find
35:15 - through experimentation creating smaller
35:17 - and bigger chunks and actually seeing
35:19 - how it plays out in action in your app
35:21 - for now we'll stick with this and see
35:23 - how it works as we continue on building
35:25 - this rag feature let's carry on
35:31 - in the previous scrim I wrote all of the
35:33 - code for you but as you know this is a
35:35 - scrimo course meaning that your job is
35:38 - to get your hands on the keyboard and
35:40 - write the code out yourself so I left
35:42 - out a couple of pieces for you which you
35:44 - now are to implement through this
35:46 - challenge I want you to refactor this
35:48 - function so that it first of all takes
35:50 - the path to the data or document as an
35:53 - argument so that is to the handbook.
35:55 - text here that'll make it a little bit
35:56 - more generalized
35:58 - as it's really not a good practice to
36:00 - have the path for the fetal request
36:01 - hardcoded in here on line seven and then
36:04 - secondly I want you to return the
36:06 - splitted data as an array of strings and
36:08 - just that because that's how we want our
36:10 - data in the next step of building out
36:12 - this feature so go ahead and solve this
36:14 - challenge right
36:20 - now okay hopefully that went well first
36:24 - we'll specify that it takes a path here
36:26 - as the argument which we'll use in the
36:28 - fetch request and then of course we'll
36:30 - need to specify in the function
36:31 - invocation that we indeed want to get
36:34 - the data from the handbook. text that
36:36 - was part one part two returning the data
36:39 - as an array of strings if you remember
36:40 - from the previous Grim when we inspected
36:42 - this data it is actually an array of
36:44 - objects right now but this time around
36:46 - we only want the data that is within the
36:48 - page content property because we do not
36:51 - care about the location metadata at this
36:53 - point so here we'll take the output and
36:56 - we'll map through it
36:58 - and for each of these trunk objects
36:59 - we'll return trunk. page content like
37:04 - that and here we can store that in a
37:07 - variable called text R for text array
37:10 - and then simply return it now you can of
37:12 - course condense these into fewer lines
37:14 - of code but I like to be explicit and
37:16 - only do one thing at a time on each line
37:19 - so with that we are done and ready to
37:21 - carry
37:24 - on now it is finally time to use the
37:27 - myal API to create our very first
37:29 - embedding as you can see I have imported
37:31 - the mystal client and added my API key
37:34 - so we are ready to get going the first
37:36 - thing I need is an example text trunk to
37:38 - create an embedding of I happen to have
37:40 - copied one of them into my clipboard so
37:42 - I'll paste it in here and call it
37:44 - example trunk as you can see it says
37:46 - professional ethics and behavior are
37:48 - expected of all ambri employees further
37:51 - ambri expects each employee to display
37:53 - good judgment so this is a quite good
37:55 - text for embedding because it deals with
37:57 - one subject which is the expectation of
37:59 - characters for ambri employees now I'll
38:02 - comment this one out as we won't call
38:04 - this function right now instead we'll
38:06 - down here at line 22 call the client do
38:11 - embeddings function that is an async
38:13 - function so we have to await it and
38:16 - inside of the parameter the object we'll
38:18 - specify first what kind of model we want
38:20 - to use and here mistol provides an
38:22 - embedding model called mistol embed and
38:26 - then the second key in the sub
38:29 - is the input now we can't just paste the
38:31 - example trunk like this as this input
38:34 - isn't expecting a string it's actually
38:36 - expecting an array of strings so we have
38:38 - to do like this we'll store the response
38:41 - we get back from this in a const called
38:43 - for example
38:45 - embeddings response like that and then
38:48 - let's finally log it out I'll run the
38:50 - code and yet again I had a typo Mistral
38:54 - with r is what we want to write not Mall
38:56 - we'll try again and there we go we got
38:59 - something very interesting back let's
39:01 - paste it into the editor to inspect it a
39:04 - bit more like that here we can see it
39:07 - has an ID and under the data property we
39:10 - have an array that holds an embedding
39:12 - and that embedding is a long array of
39:16 - floating Point numbers all of which
39:18 - seemingly are very close to zero though
39:21 - slightly more or slightly less so this
39:23 - Vector right here is an embedding of
39:25 - this specific text as transformed by
39:28 - this model and as we use this model to
39:30 - transform other pieces of text the
39:33 - mathematical distance from the various
39:35 - vectors will be a reflect of how similar
39:38 - or how different the semantical meaning
39:40 - of the sentences in the various trunks
39:42 - are so pretty cool and with that I think
39:46 - you are ready to take the next step in
39:47 - building this rag feature so in the next
39:50 - scrim I'll give you a challenge let's
39:52 - move
39:55 - on okay now it's your turn to create
39:58 - your very first embeddings and as you
40:00 - might have noticed already I have
40:01 - removed the code I wrote in the previous
40:04 - Grim because yeah this is scrimba you
40:06 - are going to write the code on your own
40:08 - that's how you really learn so the only
40:10 - thing I've done is called this split
40:13 - documents function and stored the
40:14 - results in a variable I'm calling
40:16 - handbook chunks because you're going to
40:18 - use that when you create and invoke this
40:20 - create embeddings function it takes the
40:23 - chunks that is these as a parameter and
40:26 - turns them all into embeddings using the
40:28 - mistal API once you've done that you are
40:30 - to return the data in a specific format
40:33 - so what we're doing here is prepping it
40:35 - before we'll upload it to the vector
40:37 - database and the service we are using
40:39 - for our Vector database is called
40:41 - superbase which you'll learn more about
40:43 - very soon now the structure superbase
40:46 - wants us to create is the following it
40:49 - should be an array of objects and each
40:51 - of the objects should contain two
40:53 - properties one called content that is
40:55 - just the raw text string that you find
40:57 - in each of the Trunks and secondly the
40:59 - embedding property should simply be the
41:01 - embedded version of that string so aka
41:04 - the vector once you have the data in
41:06 - this format just return it and then
41:08 - later on we'll take care of uploading it
41:10 - to superbase so go ahead and give this
41:12 - one Your Best Shot good
41:17 - luck okay hopefully this went well I'll
41:21 - start by defining the
41:22 - function like that this will be one with
41:25 - asynchronous operations so we need to
41:26 - define it as yes an async function and
41:29 - inside of it we'll start with the mistal
41:31 - client and the embeddings method it
41:34 - takes two arguments the model which
41:36 - should be mistal embed and the input
41:40 - which should be the chunks that we have
41:42 - passed into the function now previously
41:45 - I added a string here so I had to wrap
41:46 - it in square brackets like this because
41:48 - the input is expecting an array of
41:50 - strings here though the trunks is
41:52 - already in the shape of an array as it
41:54 - is this handbook trunks array right here
41:56 - so we don't need to do that but we do
41:59 - need to await this one and store the
42:01 - result in a
42:02 - variable like that let's now console log
42:05 - out embeddings and see if we get
42:08 - anything when we run the code let's call
42:11 - the function pass in the handbook Trunks
42:15 - and see what we get out here on line 24
42:17 - all right so in our console you can see
42:19 - we have an object which contains a data
42:21 - array which again contains their own
42:23 - objects with a property called embedding
42:25 - so the data we want exists in ins side
42:27 - of embeddings do data then we can
42:29 - navigate into a random item in this
42:31 - array for example the 12th one and then
42:34 - fetch out it's embedding like that if we
42:37 - run the code again we should see yes one
42:40 - vector being logged out to the console
42:42 - really good now we need to combine all
42:44 - of these vectors with all of our text
42:46 - chunks in this structure we've defined
42:49 - down here so to do that I'll map through
42:51 - each of the chunks and then return a new
42:54 - object which contains the chunk as the
42:56 - cont
42:57 - and the vector should be under the
42:59 - embedding key and we'll find it by
43:01 - navigating into embeddings Data into one
43:04 - of the items and then dot embedding so
43:07 - there's a lot of embedding words here
43:08 - right now just bear with me and we'll
43:10 - try to make this work so actually I'll
43:12 - I'm a little bit lazy I'll just copy
43:14 - this one right in here and then we need
43:15 - to replace this with whatever index we
43:17 - are at at every step in the iteration
43:20 - luckily map gives us the index as the
43:22 - second parameter of the Callback
43:24 - function so we can simply replace this
43:26 - with I like this let's store this in a
43:29 - variable called data and then finally
43:31 - return data like that I'll remove this
43:34 - one now we can call create embeddings
43:36 - and expect to get back the data and then
43:38 - log it out but if we want to do that we
43:39 - also have to await it because here we
43:41 - have a synchronous code so console log
43:45 - like that let's run this and see what we
43:50 - get yes there we have a beautiful array
43:53 - with objects that contain two keys
43:56 - content that contains the raw text
43:58 - string and embedding that contains the
44:00 - vector itself so we have the data just
44:03 - how we want it now if you solve this in
44:05 - a slightly different way that's totally
44:07 - okay there are certainly ways to
44:09 - condense this code and make it quote
44:11 - unquote drier I'm not going to worry
44:12 - about that right now but feel free to
44:14 - write this however you want the
44:16 - important thing is that you got the
44:17 - intended result not exactly that my code
44:20 - and your code are mirror images of each
44:22 - other so with that we are ready to take
44:24 - the next very exciting step in our rag
44:26 - Journey and that is to start learning
44:28 - about Vector databases for that I'll
44:30 - hand the bow over to my colleague Gil
44:32 - who will teach you about Vector
44:33 - databases over the next couple of
44:38 - scrims in this course we're going to use
44:41 - super base to manage our Vector database
44:44 - superbase is a full-fledged open source
44:46 - backend platform that offers a
44:48 - postgressql or postgress database which
44:51 - is a free and open- Source database
44:53 - system recognized for its stability and
44:56 - advanced capability
44:57 - while postgress is not a dedicated
44:59 - Vector database superbase does support a
45:02 - powerful postest extension called PG
45:05 - Vector for storing embeddings and
45:07 - Performing Vector similarity searches if
45:10 - you've worked with subase or postgress
45:12 - this should be pretty straightforward if
45:14 - not don't worry you don't have to be a
45:16 - database expert to start using superbase
45:18 - it's quick and easy to set up and the
45:20 - platform has a simple to use dashboard
45:22 - that makes postest as easy to use as a
45:24 - spreadsheet so the first thing you want
45:26 - to do is head over to superb.com once
45:29 - there click to sign in which you can do
45:32 - using your GitHub credentials next on
45:34 - your dashboard's project page click new
45:37 - project you'll first create a new
45:39 - organization with superbase you can use
45:41 - a company name or your own name choose
45:44 - the type of organization in my case
45:46 - personal set the pricing plan to free
45:49 - then click create organization after
45:52 - that superbase will ask you to create a
45:54 - new project which comes with its own
45:56 - dedicated instance and full postgress
45:58 - database it will also set up an API so
46:01 - you can easily interact with your new
46:03 - database so give your new project a name
46:06 - like vector embeddings create a password
46:09 - for your postgress database then choose
46:11 - a region that's geographically closer to
46:13 - you or your user base for best
46:15 - performance then click create new
46:17 - project and after a short moment your
46:19 - new project should be all set up from
46:22 - here you'll need to enable the PG Vector
46:24 - extension in your new project click the
46:26 - the database icon in the sidebar to go
46:29 - to the database page then on the pages
46:31 - sidebar click extensions in the search
46:34 - field search for vector and enable the
46:38 - extension and that should set you up to
46:40 - use superbase to store index and query
46:43 - Vector embeddings all right next you'll
46:45 - need to integrate superbase with your
46:47 - application or in our case the scrims
46:49 - for this course to do that click on the
46:51 - project setting icon and navigate to the
46:54 - API section in the sidebar here you'll
46:57 - find your project URL and API Keys these
47:00 - are essential for integrating superbase
47:02 - with your app so first copy your project
47:05 - URL then save it as an environment
47:07 - variable on scrimba remember you can
47:09 - access your environment variables with
47:11 - the keyword shortcut command or control
47:14 - shift e and be sure to name this
47:16 - variable super basore URL exactly as
47:19 - shown here finally copy your project API
47:22 - key then save it as a scrimba
47:24 - environment variable named superbase API
47:27 - key just like
47:31 - this Vector databases or vector stores
47:34 - possess unique superpowers for managing
47:36 - Vector embeddings with the capacity to
47:39 - store and retrieve embeddings quickly
47:41 - and at scale all right so how do Vector
47:43 - databases actually work well embeddings
47:46 - essentially allow us to match content to
47:48 - a question unlike traditional databases
47:50 - that search for exact value matches in
47:53 - rows Vector databases are powered by
47:55 - complex algorithm Ms that store search
47:58 - and quickly identify vectors so instead
48:01 - of looking for exact matches they use a
48:03 - similarity metric that uses all the
48:06 - information vectors provide about the
48:08 - meaning of the words and phrases to find
48:10 - the vectors most similar to a given
48:12 - query so storing custom information as
48:15 - edings in a vector database gives you
48:17 - the benefit of enabling users to
48:19 - interact with and receive responses
48:21 - exclusively from your own content you
48:23 - have complete control over your data
48:25 - ensuring it remains relevant and up
48:27 - toate this can also help reduce the
48:29 - number of calls and token usage and even
48:32 - allow the summarization and storage of
48:35 - chat histories which helps AIS maintain
48:37 - a type of long-term memory an important
48:40 - tool against the problem of
48:41 - hallucinations with AI models so with
48:44 - all that said Vector databases are
48:45 - becoming a central part of how we build
48:48 - AI powered software and play a massive
48:51 - role in the advancements of large
48:53 - language models these days you have
48:55 - various Vector database options from
48:57 - tools like chroma to Pine Cone superbase
48:59 - and several others all right so next up
49:02 - I'll guide you through setting up your
49:03 - own Vector database see you
49:07 - soon now we need to configure superbase
49:10 - in our project so that we can start
49:12 - interacting with the database as you can
49:14 - see I've installed superbase as a
49:16 - dependency and imported the create
49:18 - client from the superbase JavaScript SDK
49:21 - on line six we invoke this function
49:23 - passing in the superbase URL as the
49:25 - first parameter and the API key as the
49:27 - second and then we have our superbase
49:30 - client however now we have two clients
49:32 - here the mistal one and the superbase
49:34 - one so I want to make it a bit more
49:35 - apparent that this one here is dealing
49:37 - with mistol so I'll rename it like that
49:40 - and then change the name here as well
49:43 - now I want you to head over to your
49:44 - dashboard in superbase and click into
49:46 - the vector embeddings project from there
49:48 - choose the SQL editor from the menu on
49:50 - the left hand side as this allows you to
49:53 - create tables in the database using a
49:55 - SQL query and and having tables is
49:57 - absolutely necessary in a SQL database
49:59 - as that is how you store the data I
50:01 - happen to have the query right here for
50:04 - you as you can see it's pretty
50:05 - straightforward create table we're
50:07 - calling it handbook docs and then we
50:09 - Define the three columns we want our
50:11 - table to have an ID which has the data
50:13 - type big serial that is the primary key
50:15 - so the identification field in this
50:17 - table we'll have the content which will
50:19 - specify as plain text and finally
50:21 - there's the embedding which is a vector
50:22 - of 1,24 Dimensions if you think this
50:26 - resembles our data structure down here
50:27 - you are completely right that is exactly
50:30 - why we formatted our data this way so go
50:32 - ahead and take the SQL and paste it into
50:34 - the editor hit run and then you should
50:36 - see under the results here success no
50:38 - rows returned that means that your table
50:40 - has been created to view it simply click
50:42 - on the table editor in the menu on the
50:44 - left hand side there you can see this is
50:46 - the very beginnings of a table that has
50:49 - an ID column a Content column and an
50:51 - embedding column now to get our data all
50:54 - the way from the handbook via the embed
50:56 - end point and finally into the structure
50:58 - we want and then upload it to super base
51:00 - we only have one line of code to write
51:02 - and that is simply super
51:04 - base do from here we'll specify our
51:07 - table handbook docs dot insert cuz we
51:12 - want to insert something and what do we
51:14 - want to insert well that is the data
51:17 - this is also an async operation so we
51:18 - got to wait it and when this line has
51:21 - executed and JavaScript moves on we'll
51:23 - log out upload complete let's now run
51:26 - this and there we go the upload should
51:28 - be complete let's head over to super
51:29 - base and boom there we go we have our
51:32 - content and their corresponding
51:34 - embeddings in the vector database
51:36 - meaning that we are ready to take the
51:38 - final step in this rag feature which is
51:40 - to perform the retrieval so that we can
51:42 - generate replies to the users for any
51:44 - question they might have about our
51:46 - employee handbook so great job reaching
51:49 - this far let's carry
51:53 - on with all of our text Trunks and
51:56 - embeddings safely stored at superbase we
51:58 - are finally ready to write the code for
52:01 - our rag feature so as you can see here
52:03 - I've changed around on the index JS a
52:05 - little bit as I moved the old uploading
52:08 - code over to data.js as we won't be
52:11 - using that now since we're now actually
52:13 - going to do the retrieval and generation
52:15 - steps so let's start by going through
52:17 - this code so that we're both on the same
52:19 - page the flow of this app contains four
52:22 - steps the first one is getting the user
52:24 - input here I've just hardcoded it as a
52:27 - variable where the user is asking for
52:29 - whether or not they get an extra day off
52:31 - since December 25th falls on a Sunday
52:33 - now of course in real app the user would
52:35 - probably ask this in some kind of form
52:37 - and you do some Dom manipulation to
52:39 - fetch this though that's outside of the
52:41 - scope for this course so we'll just keep
52:42 - it simple and use this input variable
52:45 - next we need to take this input and turn
52:47 - it into an embedding as we need to see
52:49 - if the embedding of this string matches
52:53 - some of the embeddings we've created of
52:55 - the various chunks in our handbook now
52:58 - creating this embedding should be piece
52:59 - of cake for you for now so I didn't
53:01 - bother going through that code with you
53:03 - as you've done that before so once we
53:05 - have this embedding stored in this
53:07 - variable we'll pass it into another
53:08 - function that we've called retrieve
53:10 - matches and this is where we are going
53:12 - to do the similarity search now I've not
53:15 - written the body of this function yet
53:17 - let's just continue on with the flow and
53:18 - then get back to that because once we've
53:20 - gotten the matches or aka the context
53:24 - we'll pass both the context and the
53:26 - input into a function called generate
53:28 - chat response where we'll use these two
53:30 - in combination to get mistol to
53:32 - formulate a reply to the user so that is
53:35 - essentially the four steps of our rag
53:37 - feature now let's look at this retrieve
53:39 - matches function here we need to tell
53:41 - superbase to do a similarity search and
53:44 - if you read some of these descriptions
53:45 - you might be a little bit scared because
53:46 - they're called things like ukian
53:48 - distance negative inner product or coign
53:51 - distance that certainly sounds
53:54 - complicated though luckily we don't have
53:56 - to to worry about any of that as
53:57 - superbase provides us with a SQL
53:59 - function that we simply can copy paste
54:01 - so that we don't have to dive into the
54:03 - underlying complexity I've pasted this
54:05 - function into the function. SQL file
54:07 - right here changing around a little bit
54:09 - on a few things like the name of the
54:11 - function which I want to be match
54:12 - handbook docs as this is the name of our
54:15 - table and also I've changed the vector
54:17 - to account for the number of Dimensions
54:18 - mistal gives our embeddings plus updated
54:21 - this query down here to account for our
54:23 - handbook docs name so what I want you to
54:25 - do now is copy this entire function head
54:28 - over to superbase and click into the SQL
54:30 - editor there click on the new query
54:33 - button and then paste in the function
54:36 - click on run and if you see success no
54:38 - rows returned it means that this
54:40 - function is now available in your
54:42 - database but now the question is how do
54:44 - we access this function in our
54:46 - JavaScript and that is where superbase
54:48 - is really user friendly CU they have an
54:50 - RPC method a so-called remote procedure
54:53 - call which you can invoke anywhere in
54:55 - your code just like they do on this
54:57 - snippet right here so what we'll do is
54:59 - simply copy this and paste it into our
55:01 - code now our function was not called
55:03 - match documents it was called match
55:06 - handbook docks and to begin with I don't
55:08 - want 10 matches which is what you define
55:10 - here I want just one now the match
55:13 - threshold sets a threshold for how
55:15 - similar embedding should be in order to
55:17 - be included as a match the higher you
55:19 - put this the more picky you are so the
55:21 - less mattress you'll see but also the
55:23 - more similar they will actually be and
55:25 - here the aquarium embedding is the
55:27 - embedding that we passed into this
55:28 - function in other words the embedding of
55:30 - this string right here finally we can
55:33 - return data and I happen to know that
55:35 - inside of the first item in the data
55:37 - array there is a property called content
55:40 - and that is what we want so now let's
55:43 - comment out this line and console log
55:47 - out the context and try to run this code
55:51 - and there we go we get back a very
55:53 - relevant piece of context which says
55:55 - Christmas Day full-time employees
55:57 - parenthesis employees work at least 35
55:59 - hours per week receive one paid day off
56:02 - for each full day of holiday time
56:04 - holiday benefits for part-time employees
56:06 - and then it stops so we were able to
56:08 - retrieve very relevant information
56:10 - though it's not formulated as a good
56:12 - reply to the user and also there's some
56:14 - lacking information here as well ideally
56:17 - we would have seen the sentence that was
56:18 - cut off Midway as that would have given
56:20 - us information about the part-time
56:22 - employee vacation policy for these kinds
56:24 - of situations so that leaves us with a
56:27 - couple of tasks to be done down here in
56:29 - these retrieve matches and the generate
56:31 - chat response functions and who do you
56:33 - think is going to fix up that yes you
56:35 - guessed it that's yourself so in the
56:38 - next Grim you are going to complete the
56:39 - retrieval and the generation process of
56:42 - this feature let's move on I'll see you
56:47 - there welcome to this two-part challenge
56:50 - where you are going to complete the
56:52 - retrieve matches function and write the
56:54 - entire body of the generate chat chat
56:56 - response function in the first one we
56:58 - are to fix the fact that we didn't get
57:00 - enough data back by simply getting one
57:02 - match so instead we are going to return
57:04 - five matches and that involves updating
57:06 - this object and changing how you return
57:09 - the data for the Second Challenge you
57:10 - are to take whatever context you get
57:12 - back from the retrieval step and combine
57:14 - it with the user's query or input and
57:17 - turn that into a prompt this prompt
57:19 - should be sent to mistral's API and
57:21 - decide for yourself what models and what
57:23 - settings you'd like to use and here
57:25 - you're going to do a little bit of
57:26 - prompt engineering as you'll need to
57:28 - combine the context and the query into a
57:31 - single prompt and I don't want to
57:33 - dictate this for you instead just think
57:35 - of how you would take two pieces of data
57:37 - a context and a question and turn it
57:39 - into one prompt that instructs the AI to
57:42 - answer the question based upon the
57:44 - provided context now I can disclose that
57:46 - it doesn't have to be complex the AI is
57:48 - pretty capable of figuring out what
57:50 - you're trying to do so just make it your
57:52 - best chart and see how it works finally
57:54 - once you've done this you probably want
57:55 - to log out the response here to inspect
57:57 - what kind of reply the AI generated for
57:59 - you okay with that best of luck you got
58:07 - this okay hopefully this went well let's
58:10 - do it so I'll start with this one and
58:13 - the first thing we need to do is of
58:14 - course update this number to be five
58:16 - instead of one and then I'll check out
58:19 - the data here by logging it out and then
58:22 - I'll actually run the code as we're
58:24 - logging out the context here and then
58:26 - I'll actually remove this and just
58:28 - return the data so that we get to
58:30 - inspect the underlying structure here as
58:32 - we are logging out the context here on
58:34 - line 15 let's run the code opening up
58:37 - the console and there we go so this is
58:39 - an array of objects where we are looking
58:41 - for the string inside of the content
58:44 - keys so if we want to combine all of the
58:46 - content Keys into a single string I'll
58:49 - do data. map and for each chunk I'll
58:52 - return the chunk. content if we return
58:55 - this let's see what we get running the
58:58 - code and there we get an array of
59:00 - strings to combine that to a single
59:02 - string we'll just do dot join and then
59:05 - specify that we want a space in between
59:07 - each of the strings logging this out yes
59:11 - that looks good moving on to this one
59:13 - here we'll start by using the mystal
59:14 - client and call the chat method passing
59:17 - in the model and let's try with the most
59:20 - capable one first mistal large latest
59:25 - and the messages only needs one object
59:28 - or I'll at least try with that and if it
59:30 - doesn't work I'll perhaps try to add a
59:31 - system message but let's go straight to
59:33 - the user as a first solution and the
59:35 - content here is where we'll need to do a
59:37 - little bit of prompt engineering I'll
59:39 - try the easy way first and simply do
59:42 - handbook
59:43 - context like that and then passing in
59:45 - the context like that and then we'll do
59:49 - question colon and pass in the query now
59:53 - we could of course have written this is
59:55 - an extract from the the handbook that
59:56 - contains relevant background info for
59:58 - the user question though as you've
60:00 - probably understood I like to start off
60:02 - simple and then only make it more
60:03 - complex if needed so this is actually
60:06 - all the prompt engineering I was looking
60:07 - for so as the next step we want to
60:09 - return whatever result we get from this
60:11 - and to do that we of course have to
60:13 - await this function and store the
60:15 - response in a variable and then I happen
60:17 - to know that the real generated reply to
60:20 - the user lives inside response do
60:22 - choices and the first item in that array
60:25 - do message. content as I happen to know
60:28 - that this is the location of the
60:29 - generated response from the AI so with
60:32 - that it is the moment we've all been
60:33 - waiting for let's log out the response
60:37 - like that and run the code and see how
60:39 - this works and yes based on the handbook
60:43 - context provided if Christmas Day falls
60:45 - on a Sunday you as a full-time employee
60:47 - would still receive one pay day off for
60:49 - the holiday brilliant that is exactly
60:52 - what we were looking for it was able to
60:54 - both figure out that December 25th was
60:57 - semantically related to Christmas day so
60:59 - that it was able to retrieve the
61:01 - relevant information and use that to
61:03 - generate a nice and humanly readable
61:05 - reply so phenomenally well done you now
61:08 - have rag as a tool in your tool belt as
61:11 - an AI engineer and this will definitely
61:13 - come in handy throughout your career if
61:16 - you continue down the path of AI so give
61:18 - yourself a pad on the back perhaps take
61:20 - a break at this point as you've learned
61:22 - a lot and perhaps has a need to digest
61:24 - it if not in the next next part of this
61:26 - course you are going to learn about an
61:28 - insanely exciting concept which is
61:30 - function calling which enables you to
61:31 - create AI agents that interact with the
61:34 - world on the user's behalf so truly
61:37 - something that opens the door to a whole
61:39 - world of revolutionary user
61:44 - experiences hey and welcome to the
61:46 - section about function calling this is a
61:48 - very exciting field that opens the door
61:50 - for you to AI agents and by that I mean
61:53 - smart assistants that can interact act
61:56 - with the world on behalf of your users
61:58 - just by interpreting what they say so
62:01 - this is a new paradigm in terms of the
62:03 - user experience we developers can
62:05 - provide now let's start off at a very
62:08 - high level looking at how the
62:10 - architecture of such a agent typically
62:12 - is so let's say that you are running an
62:14 - e-commerce website where you sell
62:16 - products to people and you have a chat
62:18 - where users come to ask questions for
62:20 - example things like is my package on its
62:22 - way what we'll do then is send this to
62:24 - our llm along with some Specific
62:26 - Instructions as to what kind of tools it
62:28 - has available to figure out the answer
62:30 - for the user and then if it is a good
62:32 - model it'll look at this query and
62:34 - realize for itself that hm I actually
62:36 - need to call the fetch order function to
62:38 - give the user a good reply and then
62:40 - it'll instruct our software to actually
62:43 - perform this function call this is often
62:45 - done via regular code like if and else
62:47 - conditionals so through the code you
62:49 - have written you'll ensure that when the
62:51 - AI wants to call this function you will
62:53 - actually perform this function call and
62:54 - get the order data she then again will
62:56 - return to the llm it will then read that
62:59 - data which probably comes in the form of
63:01 - an object and then turn that into a
63:03 - human readable response like yes your
63:05 - order is expected to arrive and blah
63:06 - blah blah which again then results in a
63:09 - happy user all without you having to use
63:11 - manpower to do this so you can imagine
63:14 - the power of this technology is it can
63:16 - drastically improve the customer service
63:18 - users can get when talking with these
63:20 - chat Bots we've all come across over the
63:22 - last few years and of course that is
63:24 - just the start imagine how powerful it
63:26 - is when this is rolled out to all
63:28 - Industries okay let's now have a look at
63:31 - the code this here is by and large a
63:33 - very standard function call to the chat
63:35 - endpoint at mistl so all of this should
63:37 - be familiar to you except for this line
63:39 - 13 here where we've added an array of
63:42 - tools and that comes from the import
63:44 - statement here on line two and if we
63:46 - head over to
63:52 - tools.jar and searches through that data
63:55 - and as you can see down in the tools
63:56 - array we have described this function
63:59 - through a specific schema this entire
64:01 - object's sole purpose is to describe for
64:04 - the AI what this function does so it
64:07 - says that yes first of all it is a
64:09 - function and its name is this and here
64:11 - is a description of it as well plus it
64:13 - takes one parameter of type object this
64:16 - one right here and this object has a
64:19 - property called transaction ID which is
64:21 - of type string and also it is the
64:23 - required property so I think I think you
64:25 - can guess what I'm getting to here this
64:27 - is all our aices it never sees the
64:30 - content of this function it just looks
64:32 - at the description and tries to decide
64:34 - whether or not it should be invoked and
64:36 - with what kind of arguments based upon
64:37 - the input from the user so if we yet
64:40 - again head back to index.js and try to
64:42 - run this code with the prompt is the
64:45 - transaction t01 paid and run this then
64:48 - you can see in the console we get back
64:50 - an object and I happen to have copy
64:52 - pasted one of these objects into the
64:53 - output JS just to make it a little bit
64:55 - easier to read and here as you probably
64:57 - remember from earlier the choices
65:00 - message content property is actually
65:02 - empty now this is where mistol always
65:04 - adds the reply from the llm though now
65:08 - the llm has nothing to say instead it
65:10 - has given us some instructions about
65:12 - what we should do here under tool calls
65:15 - there's a function key which has the
65:16 - name of get payment function and the
65:19 - argument of transaction ID t01 so this
65:22 - is how it tells us that hey developer
65:24 - now you got to invoke a function and the
65:26 - llm isn't done reasoning about this
65:28 - issue if it was it would have said stop
65:31 - here but instead it wants us to call a
65:32 - tool and then send back the result so as
65:35 - you can understand we developers have
65:37 - some work to do here and we're also
65:39 - going to make this agent even more
65:40 - capable by adding another function so
65:42 - I'll leave it at this so that the two of
65:44 - us can get back to work and start coding
65:46 - and we'll do that in the next
65:51 - scrim so we've been able to get the
65:53 - mistal model to tell us to call function
65:56 - when someone asks about the payment
65:58 - status of an order however if we take a
66:01 - look at the data you can see that
66:03 - there's also other things going on here
66:05 - there's both an amount and a date for
66:07 - each of the orders so there's definitely
66:09 - potential to make our agent more
66:11 - powerful I'm now going to paste a
66:13 - function in here called get payment date
66:16 - it also takes in the transaction ID and
66:18 - does more or less the same thing as get
66:20 - payment status though it instead Returns
66:23 - the date for when it was paid now you
66:25 - could have of course also have done this
66:26 - by simply making this one a bit more
66:28 - robust to fetch various pieces from the
66:30 - data based upon the argument passed in
66:32 - but the point here is not to build a
66:34 - production ready system but rather to
66:36 - give you some practice in building
66:37 - agents so what I want you to do now is
66:40 - expand upon this tools array by adding a
66:42 - new object that describes the second
66:44 - function because as you might remember
66:46 - the AI doesn't read this code it only
66:48 - knows about the function through how you
66:50 - describe it in the tools schema so that
66:53 - is your first Challenge and once you've
66:54 - done that I want you to verify that your
66:56 - solution works by changing the prompt
66:59 - that we give the agent here in a way
67:00 - that would get the llm to instruct us to
67:02 - call the newly added function so go
67:05 - ahead and solve these two challenges and
67:07 - I'll show you the solution when you
67:08 - return back to
67:14 - me okay let's do this I'll head back to
67:17 - the tools file again and then I will
67:19 - simply copy this object as I'm a little
67:21 - bit lazy and I've understood that the
67:23 - second object here will look very
67:25 - similar similar as the first one so I'll
67:27 - do like that and simply change from get
67:30 - payment status to get payment date and
67:34 - the description to get the payment date
67:38 - of a transaction and then the parameter
67:41 - can stay just the same as it is
67:43 - identical to the previous function and
67:45 - actually that was about it heading back
67:47 - to index JS I'll change this
67:50 - to when was the transaction t01 paid
67:55 - let's run this open up the console and
67:58 - yes indeed you can see that it is now
68:00 - instructing us to call get payment date
68:02 - and not get payment status so mission
68:04 - accomplished hopefully that forced you
68:06 - to get to know the schema a little bit
68:08 - more as we're going to move to the next
68:10 - step now where we'll start acting upon
68:12 - the instructions we get from the mistal
68:17 - model right now we are in this step of
68:19 - our flow the llm has just told us that
68:22 - we need to call a function and now we're
68:24 - about to write the code we need in order
68:25 - to do that so the first thing I want to
68:27 - do is that we keep our messages array up
68:30 - to date as it should include every
68:32 - single piece of dialogue going back and
68:33 - forth between the user the app and
68:35 - mistol so what I'll do is
68:38 - messages. push and I'll push some part
68:41 - of this response though not the entire
68:44 - thing let's have a look at how it was
68:46 - structured if we head into the choices
68:48 - and the first object in this array we
68:50 - can see that there is a message object
68:53 - and that is what we want so we'll do
68:55 - response on. choices the first one and
68:58 - then message like that as you can see it
69:01 - has a role just like our user message
69:03 - has a role though this is from the
69:05 - assistant the content is empty since it
69:07 - didn't have anything to say to us
69:09 - instead it had some instructions about
69:11 - what tools we should call so the next
69:13 - thing we want to do is write the N
69:15 - statement that checks if we indeed are
69:17 - about to call a tool and then write the
69:19 - code for the specific tool call now I
69:21 - don't want to use the fact that there's
69:22 - a tool calls here in our conditional
69:24 - instead the right way to do this is to
69:26 - look at the Finish reason and the fact
69:27 - that this has the string value of tool
69:29 - calls so we'll do
69:32 - if
69:34 - response choices the first item and then
69:38 - then finish reason if this is equal to
69:41 - Tool calls well then our next step is to
69:43 - fetch out the name of the function we
69:45 - are to call and its argument and at this
69:47 - point I think I've written more than
69:49 - enough code for you it is your turn to
69:51 - take over so here is a challenge for you
69:53 - I want you to get a hold of the name of
69:56 - the function that we should call and its
69:58 - arguments and we want the function name
70:01 - as a string but the arguments as an
70:03 - object so I've set up the two variables
70:06 - for you the function name and the
70:07 - function arcs both are just initialized
70:09 - as empty strings but whatever expression
70:11 - you replace this with should be of the
70:14 - data type object so now you'll have to
70:16 - dig through this one yourself and fetch
70:18 - out the relevant information and once
70:20 - you're done just return back to me and
70:22 - then I will show you the solution the
70:24 - final thing I'm going to do here is make
70:26 - sure that I close this if statement
70:28 - properly like that and indent this and
70:31 - have the correct indentation for this
70:32 - one as well and with that you are good
70:34 - to go best of
70:41 - luck okay hopefully this went well let's
70:44 - do this together so first I'll start
70:47 - with the function name and here I'll
70:50 - need to navigate all the way down to
70:53 - Tool calls function and then name and I
70:56 - happen to see that both the name and the
70:58 - argument is in the same object here this
71:02 - function object So to avoid too much
71:04 - repetition I'm going to do const
71:07 - function object like that and then I'll
71:10 - paste this in adding
71:12 - dot tool calls which is an array and we
71:15 - want the first item and do function like
71:17 - that now I can do function object. name
71:22 - and function object do r ents so if you
71:26 - got to this point good job though we're
71:28 - not quite done yet as this function
71:31 - object. argument is a string and we want
71:34 - it as an
71:35 - object and the way to do that is to do
71:38 - json.parse and that should turn whatever
71:41 - string we have into an object let's
71:43 - consol out the function name and the
71:47 - arguments and then run the code to
71:49 - verify that it works and I'll comment
71:51 - out the response down here running the
71:53 - code and yes the first first one is get
71:55 - payment date as a string and the second
71:58 - one is indeed an object so very well
72:00 - done solving this challenge let's carry
72:06 - on it is time for us to do this step
72:09 - which is to call the function so that we
72:11 - get the data we eventually can send back
72:12 - to mistal and as you know we have the
72:15 - function name and the function arcs but
72:17 - this file doesn't yet have access to the
72:19 - functions as they live in the tools file
72:22 - so I will import these functions get
72:25 - payment date and get payment status like
72:27 - that though now the question is how do
72:29 - we go from just having the data as a
72:31 - string value for example get payment
72:34 - date into actually calling the function
72:37 - well to help you with that I'm going to
72:38 - wrap these functions in an object called
72:42 - available functions I'll add get payment
72:44 - date and get payment status what this
72:46 - gives us the opportunity to do is to use
72:48 - the bracket notation to get a hold of a
72:51 - reference to any of these functions
72:53 - because if we passed in a string called
72:55 - get payment date this would be a
72:58 - reference to this function and if we
73:00 - throw in parenthesis we'll invoke the
73:02 - function so that is pretty cool and it
73:03 - is exactly what I want you to do right
73:06 - now in your challenge your job is simply
73:08 - to perform the function call so go ahead
73:10 - and write the code to do that and then
73:11 - I'll see you when you return back to
73:17 - me okay hopefully this went well the way
73:20 - to do it is to grab a hold of the
73:21 - available functions object and then use
73:23 - bracket notation to pass in our function
73:26 - name call it with parenthesis and
73:29 - finally add function arcs like that
73:31 - we'll store this in a variable called
73:33 - function response and then finally log
73:36 - it out let's run the code and there we
73:39 - go we have turned a prompt from the user
73:42 - into a real function call that returns
73:44 - data that our assistant asked for really
73:47 - good job reaching this far we are making
73:49 - a ton of progress so let's just keep up
73:51 - the pace and carry on
73:57 - so we've called the function obtained
73:58 - the data we need and now we need to send
74:00 - it back to our assistant so how do we do
74:02 - that well as I've said earlier it's
74:04 - important that we keep track of all the
74:07 - dialogue in this app whether it's from
74:09 - the user from the assistant or in this
74:11 - case from the tool itself and where do
74:14 - we keep track of this dialogue take a
74:17 - guess yes it is in this messages array
74:20 - which we are passing along to mistal
74:22 - every time we interact with our API so
74:24 - what we're going to do here first is
74:26 - messages. push pass in an object and as
74:30 - you've seen before we always have a role
74:32 - though this time around it's not the
74:34 - role of user and also not the role of
74:37 - assistant which is what we had when we
74:39 - got the instructions to call the
74:41 - function this time around the role
74:43 - belongs to the tool and the next piece
74:45 - of information we need to pass along is
74:47 - the name of the tool which we have here
74:49 - in function name and finally the content
74:53 - after we've told mol that we worked with
74:55 - the tool and gave them the name of the
74:57 - tool what do you think the content here
74:59 - should be take a
75:01 - guess yes hopefully you understood that
75:04 - it is the response we got back from the
75:05 - function because when mistol gets all of
75:08 - this data it should be able to decide
75:10 - what the next step should be and
75:11 - speaking of which how do we then send
75:13 - this off to mistl well we could start a
75:16 - new client. chat down here and add all
75:18 - of the metadata again though that's a
75:20 - very hard-coded and hacky solution
75:23 - instead we want to rerun this piece of
75:25 - code and then yet again check if we're
75:28 - instructed to call yet another function
75:30 - and then keep on going until the
75:31 - assistant tells us that yes we are now
75:34 - done with the back and forth and I have
75:35 - a good response for the user and hearing
75:38 - that what kind of programming Paradigm
75:40 - does that sound like a job for and yes
75:42 - you guessed it the loop so we are going
75:45 - to wrap this entire thing in a loop and
75:47 - keep it running until we have a
75:49 - satisfying result we'll do that in the
75:51 - next Grim so I'll see you there
75:56 - okay we are ready to perform the final
75:58 - steps of our flow we'll take the result
76:01 - from the function and send it to our
76:03 - assistant who will then construct a
76:04 - reply and send it back so that our user
76:07 - is happy again and as I talked about in
76:09 - the previous Grim we'll do this through
76:11 - the help of a loop so this is a
76:13 - challenge where you are to start by
76:15 - creating a for Loop that runs a maximum
76:17 - of five times and inside of the for Loop
76:20 - if the Finish reason is ever set to the
76:22 - string stop then I want you to simp
76:24 - simply return the response from the
76:26 - assistant so then you are to return the
76:28 - entire function and that'll also then
76:30 - break out of the loop as you can see the
76:33 - Finish reason lives down here in the
76:35 - object you get from the assistant now
76:38 - you might ask at this point well why are
76:40 - we simply hardcoding in a for Loop that
76:42 - runs five times wouldn't it be better
76:44 - with a while loop that could run as many
76:46 - times as you need until the task is
76:48 - complete or for example a recursive
76:50 - solution that would do the same thing
76:52 - and yes those could be better Solutions
76:54 - but they also open up for the
76:56 - possibility of infinite Loops so it
76:58 - would require some guard rails in my
77:00 - opinion to implement such a solution
77:02 - which is why we're simply going for a
77:04 - naive for Loop that runs five times and
77:06 - that should be more than enough for our
77:08 - use case though of course if you want to
77:10 - build on this after you've solved the
77:12 - challenge you are more than free to do
77:14 - that and actually I would encourage you
77:16 - to do that anyway give this challenge
77:18 - your best shot and then I'll see you
77:19 - when you're done
77:26 - okay let's do this we'll do four let I
77:30 - equals z and I should be less than five
77:35 - and it should increment moving this all
77:38 - the way down here and indenting
77:42 - everything inside of the loop like that
77:45 - and checking here if response do choices
77:51 - the first item and yes it lives within
77:55 - that object if the Finish reason is stop
78:00 - then we'll simply return the content
78:04 - within the message and finally let's
78:07 - bring this up here and do else if like
78:10 - that okay the moment of truth let's see
78:13 - if we've been able to successfully
78:14 - implement this entire flow I'll comment
78:17 - out this console log we're asking when
78:20 - this transaction was paid let's run the
78:22 - code and yes the transaction 2001 was
78:26 - paid on October 5th 2021 wow congrats
78:30 - you've just built your very first AI
78:33 - agent and while this of course is a
78:35 - dummy example You Now understand the
78:37 - basic building blocks which gives you a
78:39 - foundation for building Real World
78:41 - products so give yourself a pat on the
78:43 - back and then I'll see you in the next
78:47 - scrim hi there now you are going to
78:50 - learn how to run mistal models locally
78:52 - on your computer and the tool we are
78:54 - going to use for that is called olama it
78:57 - is an app that wraps large language
78:59 - models on your computer and lets you
79:01 - interact with them in various ways so
79:03 - click on this image right here and
79:05 - you'll get to the AMA page there you can
79:07 - search for models for example mistl
79:09 - click into it and see the size of it
79:11 - this one is 4.1 GB and also read about
79:14 - how it performs compared to other open-
79:16 - source models for now let's head back to
79:18 - the homepage and click on the download
79:20 - button then choose whatever platform you
79:22 - use and click yet again on the download
79:25 - button so that you can complete the
79:26 - download and install AMA on your
79:29 - computer once you've done that open up
79:31 - the terminal on your computer and type
79:33 - AMA run mistal that'll start the
79:36 - download process and as it'll take some
79:38 - time I'll fast forward and once it's
79:40 - done we get this little UI where we can
79:42 - type a message so let's ask the model
79:45 - something for example trying to use it
79:46 - as a motivational coach which I often
79:48 - use large language models for so I'll
79:50 - type feeling a bit demotivated today can
79:52 - you help me get started with my day and
79:54 - when I hit enter mistl starts typing out
79:57 - tip after tip not through being run on a
80:00 - thirdparty server but being run by my
80:03 - computer and let's just take a minute
80:05 - and acknowledge how cool this is because
80:07 - aside for the cost of the hardware and
80:09 - the electricity these tokens are
80:11 - completely free and there's also 100%
80:14 - privacy as the data stays on the device
80:17 - now what's perhaps even cooler is that
80:20 - you can use this as a model for any AI
80:22 - projects you build locally as well so
80:24 - let's try to do that in the current
80:26 - scrim click on the Cog wheel in the
80:28 - bottom right corner and then click
80:30 - download as zip then in your downloads
80:33 - folder you'll see this ZIP file so just
80:35 - go ahead and double click on it to unzip
80:37 - it and that'll give you a folder with a
80:39 - weird looking name that is the
80:40 - underlying ID for the scrim so take this
80:43 - folder rename it and place it wherever
80:45 - you keep your Dev project for me that is
80:47 - in the dev directory and I've named this
80:49 - project AMA hello world so I'll navigate
80:52 - into it and there you should do mpm
80:54 - install and then do npm start that'll
80:57 - spin up the project on Port 3000 meaning
81:00 - that you can head over to Local Host
81:02 - 3000 and there you will see the browser
81:04 - telling you to ask a question via the
81:07 - question parameter and what's going on
81:09 - here is that this little Express router
81:12 - checks if there is a question in the URL
81:14 - parameter called question and if there
81:16 - isn't a question there for example if
81:17 - you just visited the root page without
81:19 - any URL params it'll just render out
81:22 - this string though if it is a question
81:24 - there it'll execute the following lines
81:25 - of code and here we're using theama SDK
81:29 - and the patterns that are being used
81:30 - here is probably quite familiar to you
81:32 - right now because yes this resembles the
81:34 - mistal SDK quite a lot we call the chat
81:37 - method and pass in an object where we
81:40 - specify the model in this case it's
81:42 - mistal and a messages array that has a
81:44 - role and some content and the content
81:46 - here is whatever Express finds in the
81:48 - URL parameter called question so if we
81:51 - now type in a question in the browser
81:53 - for example why do stars shine and hit
81:55 - enter then we'll see that the browser
81:57 - will work for a little while and boom
81:59 - eventually it gives you reply which says
82:01 - that star shine due to nuclear fusion
82:03 - where hydrogen atoms are turned into
82:05 - helium and thus releasing immense
82:08 - amounts of energy and actually this
82:09 - continues until all of these atoms have
82:11 - turned into iron which by the way means
82:15 - that the iron you used to fry your eggs
82:17 - with was created billions of years ago
82:20 - in the center of a star wow that is
82:24 - mindblowing blowing to think about
82:25 - almost as mind-blowing as the fact that
82:27 - you have reached the end of this mystal
82:30 - course most people who start a course
82:32 - here on scrimba give up before they
82:34 - reach the end but you my friend do not
82:37 - you are not a quitter so give yourself a
82:39 - pat on the back and in the next scrim
82:41 - we'll do a quick recap of everything
82:43 - you've
82:46 - learned wow you really did something
82:49 - special today you completed this course
82:51 - please remember that most people who
82:53 - start online courses
82:55 - give up you are not like them so let's
82:57 - have a quick recap of what you've
82:59 - learned starting out we looked at the
83:01 - basics of mistl and their platform along
83:03 - with the chat completion API that we
83:05 - interacted with through their JavaScript
83:07 - SDK you have a solid grasp of the
83:09 - various mistal models right now and also
83:11 - know how to work with embeddings and
83:13 - Vector databases with superbase you've
83:15 - also dipped your toes into Lang chain
83:17 - and using it for chunking text because
83:19 - you had to do that when you were
83:21 - learning about rag or retrieval
83:22 - augmented generation finally you know
83:25 - how to create AI agents with function
83:27 - calling and how to do local inference
83:30 - through the help of AMA now it's time
83:32 - for you to celebrate your win do share
83:34 - that you've completed this course on
83:36 - social media or if you want a less
83:38 - public way of doing that you can check
83:39 - out scribus Discord Community as there
83:41 - we have a today I did Channel where we
83:44 - love seeing people completing courses
83:46 - and whatever you do please keep on
83:48 - building you have a unique set of skills
83:50 - here and this is just a start the world
83:52 - of AI is exploding giving Developers
83:54 - like yourself the possibility to create
83:56 - entirely new experiences and apps the
83:59 - world is your oyster so happy building
84:02 - and best of luck