With timestamps:

00:07 - Hi! My name is Alejandro Carrillo, and i'm a 
robotics engineer at an agricultural company.
00:12 - Specifically my team uses 
machine learning and robotics
00:16 - and computer vision, to identify the 
difference between the crops that we eat,
00:19 - and weeds that take nutrients away. We're able 
to remove those weeds without any chemicals.
00:24 - My name is Kate Park and I work at Tesla 
Autopilot. I build self-driving cars.
00:32 - Any place where there can be resources used 
more efficiently, is a place where technology
00:37 - can play a role. But of course, one of the best 
impactful ways of AI is through self-driving cars.
00:48 - Have you ever wondered how a computer can 
recognize a face, or drive a car? Or maybe you've
00:54 - wondered why it's so hard for a computer to tell 
the difference between a dog and a bagel?
01:02 - Well it all has to do with something called computer 
vision: the way machines interpret images.
01:09 - Let's take a look at a simple example of how 
computers learn to see. Here are two shapes:
01:16 - an X and an O. At some point you've learned 
the names for these shapes, but a computer
01:21 - looking at these images for the first time just 
sees a bunch of little squares, called pixels.
01:26 - Each pixel has a numerical value for a 
computer to see. It needs to make sense
01:31 - of these numbers to figure out what is in 
the picture. In traditional programming,
01:36 - you could tell the computer to check which 
pixels are filled to decide what shape it sees.
01:41 - If the center and corner pixels 
are full, then it's an X.
01:46 - If the center and corner pixels are empty, then 
it's an O. Traditional programming works great
01:53 - for this kind of thing, but what about asking the 
computer to recognize these images? What might the
01:59 - computer think these are? We gave the computer 
a strict definition of what an X looks like,
02:06 - but these images don't fill all the 
necessary pixels to fit the definition.
02:10 - So if the computer doesn't 
think these are X's at all,
02:14 - in fact the computer thinks these are O's 
because the corners and center pixels are blank,
02:20 - and that fits the definition 
of an O that we gave it.
02:24 - In this example, traditional programming only 
works some of the time, but with machine learning,
02:30 - we can teach the computer how to recognize shapes 
no matter their size, symmetry, or rotation.
02:36 - Teaching a computer requires thousands or even 
millions of examples of training data, and a whole
02:42 - lot of trial and error. So let's start training! 
Here are some simple shapes we can use to train
02:48 - the computer to see. At first the computer is 
completely clueless, and makes a totally random
02:54 - guess from a preset group of options, and it 
guesses wrong. But that's okay, because this
03:02 - is where the computer learns. After it makes a 
guess, the computer is shown the correct answer.
03:10 - It's like learning with flashcards: sometimes 
you have to get it wrong before you get it right.
03:16 - With every guess, the computer looks at 
each pixel and the surrounding pixels.
03:20 - It tries to recognize patterns 
and make rules to help it guess,
03:25 - like if it sees a row of orange 
pixels next to a row of white pixels,
03:28 - there's an edge. If the computer sees two edges 
oriented a certain way, say a 90 degree angle,
03:35 - then it's likely to guess that it's looking 
at a square. It won't get it right every time,
03:40 - but with more trial and error, it will slowly 
build a more confident guessing algorithm.
03:47 - Whether it's trying to guess shapes, 
animals, or any other category,
03:52 - machine learning finds patterns by learning 
from its mistakes. The training data is used
03:57 - to make a statistical model, which is just 
a fancy way of saying a guessing machine.
04:03 - When we give it training data, the guessing 
machine is tuned and optimized to recognize
04:08 - the pictures we gave it, with the hope that 
it will then be able to recognize new pictures
04:14 - with the same accuracy. It may seem easy to 
tell the difference between an X or an O,
04:20 - or to even categorize basic shapes, 
but most images aren't that simple.
04:25 - Let's take a look at how computer vision 
can learn to recognize complex images, or
04:30 - scenes like ones in the real world.
04:33 - Most complex images can be broken down into small 
simple patterns. For example, an eye is made up of
04:39 - two arcs and some circles inside. A wheel is made 
up of concentric circles and some radial lines.
04:49 - The way a computer recognizes the patterns 
in all these pixels, is by using a neural
04:54 - network made of many layers. The first layer of 
neurons takes pixel values as numerical inputs,
05:01 - to identify edges. The next few layers of neurons 
take those edges and try to detect simple shapes,
05:08 - until finally the computer puts 
it all together to understand.
05:13 - It can take hundreds of thousands, or even 
millions of labeled images, to train a computer
05:19 - vision system. But sometimes even that's not 
enough! Some face recognition systems have trouble
05:27 - even seeing people of color, because the system 
was primarily trained with photos of white people.
05:35 - Sometimes problems in computer vision are 
silly, like when a computer gets confused
05:39 - trying to tell the difference between 
these dogs. Oh wait, that's not a dog!
05:44 - But it does kind of look like 
a dog. At least this dog.
05:51 - But as society relies on computer vision for real 
problems, like detecting diseases and medical
05:56 - imagery, or helping a self-driving car identify 
pedestrians, it becomes increasingly important
06:01 - that we all understand how these systems work and 
what types of problems they're appropriate for.
06:07 - Computer vision can open up a 
miraculous world of possibilities,
06:11 - but a machine is ultimately only as 
good as the data used to train it.

Cleaned transcript:

Hi! My name is Alejandro Carrillo, and i'm a robotics engineer at an agricultural company. Specifically my team uses machine learning and robotics and computer vision, to identify the difference between the crops that we eat, and weeds that take nutrients away. We're able to remove those weeds without any chemicals. My name is Kate Park and I work at Tesla Autopilot. I build selfdriving cars. Any place where there can be resources used more efficiently, is a place where technology can play a role. But of course, one of the best impactful ways of AI is through selfdriving cars. Have you ever wondered how a computer can recognize a face, or drive a car? Or maybe you've wondered why it's so hard for a computer to tell the difference between a dog and a bagel? Well it all has to do with something called computer vision the way machines interpret images. Let's take a look at a simple example of how computers learn to see. Here are two shapes an X and an O. At some point you've learned the names for these shapes, but a computer looking at these images for the first time just sees a bunch of little squares, called pixels. Each pixel has a numerical value for a computer to see. It needs to make sense of these numbers to figure out what is in the picture. In traditional programming, you could tell the computer to check which pixels are filled to decide what shape it sees. If the center and corner pixels are full, then it's an X. If the center and corner pixels are empty, then it's an O. Traditional programming works great for this kind of thing, but what about asking the computer to recognize these images? What might the computer think these are? We gave the computer a strict definition of what an X looks like, but these images don't fill all the necessary pixels to fit the definition. So if the computer doesn't think these are X's at all, in fact the computer thinks these are O's because the corners and center pixels are blank, and that fits the definition of an O that we gave it. In this example, traditional programming only works some of the time, but with machine learning, we can teach the computer how to recognize shapes no matter their size, symmetry, or rotation. Teaching a computer requires thousands or even millions of examples of training data, and a whole lot of trial and error. So let's start training! Here are some simple shapes we can use to train the computer to see. At first the computer is completely clueless, and makes a totally random guess from a preset group of options, and it guesses wrong. But that's okay, because this is where the computer learns. After it makes a guess, the computer is shown the correct answer. It's like learning with flashcards sometimes you have to get it wrong before you get it right. With every guess, the computer looks at each pixel and the surrounding pixels. It tries to recognize patterns and make rules to help it guess, like if it sees a row of orange pixels next to a row of white pixels, there's an edge. If the computer sees two edges oriented a certain way, say a 90 degree angle, then it's likely to guess that it's looking at a square. It won't get it right every time, but with more trial and error, it will slowly build a more confident guessing algorithm. Whether it's trying to guess shapes, animals, or any other category, machine learning finds patterns by learning from its mistakes. The training data is used to make a statistical model, which is just a fancy way of saying a guessing machine. When we give it training data, the guessing machine is tuned and optimized to recognize the pictures we gave it, with the hope that it will then be able to recognize new pictures with the same accuracy. It may seem easy to tell the difference between an X or an O, or to even categorize basic shapes, but most images aren't that simple. Let's take a look at how computer vision can learn to recognize complex images, or scenes like ones in the real world. Most complex images can be broken down into small simple patterns. For example, an eye is made up of two arcs and some circles inside. A wheel is made up of concentric circles and some radial lines. The way a computer recognizes the patterns in all these pixels, is by using a neural network made of many layers. The first layer of neurons takes pixel values as numerical inputs, to identify edges. The next few layers of neurons take those edges and try to detect simple shapes, until finally the computer puts it all together to understand. It can take hundreds of thousands, or even millions of labeled images, to train a computer vision system. But sometimes even that's not enough! Some face recognition systems have trouble even seeing people of color, because the system was primarily trained with photos of white people. Sometimes problems in computer vision are silly, like when a computer gets confused trying to tell the difference between these dogs. Oh wait, that's not a dog! But it does kind of look like a dog. At least this dog. But as society relies on computer vision for real problems, like detecting diseases and medical imagery, or helping a selfdriving car identify pedestrians, it becomes increasingly important that we all understand how these systems work and what types of problems they're appropriate for. Computer vision can open up a miraculous world of possibilities, but a machine is ultimately only as good as the data used to train it.
