With timestamps:

00:00 - [Music]
00:07 - hi welcome to session four of AI 101 for
00:11 - teachers professional learning Series so
00:14 - far we have been focusing mostly on the
00:16 - benefits of AI which might be leaving
00:18 - some of you with some important
00:20 - questions like wait a minute I've heard
00:23 - that sometimes AI can make mistakes or
00:26 - even provide biased
00:28 - responses how do I ensure I'm using AI
00:31 - responsibly and
00:33 - thoughtfully what can I do to ensure I'm
00:37 - preparing my students to think
00:38 - critically about these new
00:40 - technologies these are all valid and
00:43 - important things to consider as you
00:45 - think about how you will approach AI in
00:47 - education let's dig into some of these
00:49 - [Music]
00:57 - topics hi I'm Danny I'm a former middle
01:00 - school and high school math computer
01:02 - science and engineering teacher I now
01:05 - work at code.org on our product team
01:07 - helping to develop the website that
01:09 - students and teachers use today we're
01:12 - here joined by Katrina to talk about AI
01:15 - we know that AI has been on many
01:17 - teachers minds and we're excited to dive
01:19 - into this topic today with Katrina could
01:21 - you introduce yourself hi I'm Katrina I
01:24 - am an elementary school special
01:26 - education teacher so could you tell us a
01:28 - little bit about how a relates to your
01:30 - work as an elementary school teacher AI
01:32 - is a really exciting tool but I am
01:36 - worried about how it relates to students
01:38 - and its use in the education setting
01:40 - what are some things you're excited
01:41 - about I think that AI can be really
01:44 - useful to help me when writing reports
01:47 - or when generating test questions or
01:50 - assignments for the students to work on
01:53 - um there's a lot of potential there so
01:55 - you said you had some concerns what are
01:57 - those concerns well I am worried about
01:59 - student priv privacy and how their data
02:01 - could be used by different AI tools and
02:04 - also about how AI could be used in the
02:06 - classroom and whether or not um the
02:09 - information that it provides would be
02:11 - accurate for students and also um how
02:15 - students might use it to help them with
02:17 - things like essay writing or homework
02:19 - are there ways you think you can
02:20 - leverage AI as a special education
02:22 - teacher um I do think that it could be
02:25 - really useful when helping to do things
02:27 - like write IEP goals um but with that I
02:30 - have concerns as well because IEPs are
02:34 - obviously very specific to each student
02:36 - and I wouldn't want to provide any
02:39 - personally identifying information to
02:41 - the AI tools I do think it can be really
02:44 - helpful with differentiation um I teach
02:48 - students who are at all different levels
02:49 - so for instance if I'm reviewing aition
02:53 - I can ask AI to help me write questions
02:57 - for my students who are at a lower level
02:59 - maybe add adding numbers between 1 and
03:00 - 10 but also my students who are more
03:03 - advanced in adding multi-digit numbers
03:05 - Danny I was wondering if you could give
03:07 - me advice so if I'm using AI to help me
03:12 - um come up with a reading passage at
03:14 - differentiated levels for my students
03:16 - about for instance the Revolutionary War
03:19 - how can I make sure that the information
03:21 - that it gives me for my students to read
03:24 - is actually accurate you really are
03:26 - going to have to be the expert we
03:28 - already think you know we know that
03:29 - teachers are the experts and you're
03:31 - going to have to rely on your knowledge
03:33 - to check what the AI tool is giving you
03:37 - to make sure that it is accurate so you
03:39 - can't just take what the I tool
03:41 - generates and hand it to students you're
03:43 - going to have to read it yourself and
03:44 - make sure that you believe what it's
03:46 - saying and maybe check other sources to
03:48 - make sure it matches what you find there
03:50 - as well Danny as somebody who works in
03:52 - educational technology and for a company
03:55 - that creates some of these AI tools what
03:58 - are your thoughts about the safety of
04:01 - using AI in a K12 classroom in terms of
04:04 - when we develop tools we work really
04:06 - hard to ensure their safety before they
04:09 - ever see a classroom so we're going to
04:11 - do a lot of rigorous testing to make
04:13 - sure that they're safe and they're
04:16 - producing factual information and
04:19 - they're reliable um that they're going
04:21 - to give the same result repeatedly and
04:25 - then we work hard to then pilot in a
04:28 - classroom make making sure that we do it
04:31 - with a small set so we can see what is
04:33 - happening and be really Hands-On we also
04:36 - always make sure that when we're
04:37 - developing tools that teachers have
04:40 - access to deciding what they want in
04:42 - their classroom and how it's used and
04:43 - then being able to monitor what is
04:45 - happening what are your thoughts on the
04:48 - future of AI where would you like to see
04:49 - it go if you could talk to you know
04:52 - creators of AI Technologies what would
04:54 - you want for your classroom well as a
04:57 - special education teacher I have a few
04:59 - students who are non-speaking and they
05:01 - use AAC devices to help them communicate
05:04 - um and I'm curious about how those AAC
05:08 - devices could be integrated with AI to
05:11 - give those non-speaking students or
05:14 - really any non-speaking individual a way
05:16 - to communicate their
05:18 - [Music]
05:23 - thoughts the potential for AI to help
05:25 - Society is enormous it's something that
05:27 - is influencing a lot of very important
05:29 - decisions about real humans and their
05:32 - lives it could be used in education to
05:34 - be more of an equalizer between people
05:36 - it could be used in healthcare to
05:37 - develop new drugs it could be used in
05:39 - science to develop new technologies and
05:42 - like any technology its application will
05:44 - depend on how it is utilized and at the
05:47 - same time we need to think about the
05:49 - risks that are associated with doing
05:50 - that the consequences are
05:52 - huge hi everyone I hope you're all as
05:55 - excited as we are to dive back into the
05:57 - fascinating world of AI my name is is
05:59 - Michelle and I'm a former High School
06:01 - science and computer science teacher I
06:03 - now work as a member of the professional
06:04 - learning team at code.org today we're
06:07 - going to discuss how you can ensure a
06:09 - responsible approach to AI in education
06:12 - Educators and administrators have valid
06:14 - concerns when considering whether or not
06:17 - AI Technologies are right for their
06:18 - classrooms some top concerns include the
06:21 - following data
06:23 - privacy how can my students and I use AI
06:26 - Tools in a way that protects our data
06:28 - and how do I know when a tool tool is
06:30 - safe enough to use with my students
06:32 - misinformation and AI fiction how can my
06:36 - students and I use AI effectively when
06:38 - it can be wrong algorithmic bias how can
06:42 - my students and I recognize AI bias and
06:44 - how can I teach my students to think
06:46 - critically about that bias throughout
06:49 - this video we will address each of these
06:50 - concerns and equip you with clear
06:52 - effective strategies you can use to
06:54 - mitigate risks for your students and for
06:58 - yourself
07:05 - it is really important that
07:07 - technologists kind of have this Mantra
07:09 - of ensuring that their Innovation is
07:12 - ethical and is beneficial to everyone in
07:16 - society machine learning requires a lot
07:18 - of true information to be provided to it
07:21 - in order to ultimately uh deliver a
07:24 - utility this information might be very
07:26 - sensitive to us it might be health
07:28 - related it might be Financial it might
07:30 - be very very
07:32 - personal we need to put checks and
07:35 - controls in place like with any
07:38 - technology that it's utilized to benefit
07:42 - us and that it is done with accordance
07:44 - to the law there's lot of gain from
07:47 - involving yourself in really
07:49 - understanding the details of how this
07:52 - technology
07:54 - Works given that it's so impactful given
07:57 - that it is something that will influence
07:59 - inuence your life and the life of
08:01 - everyone that you love AI systems
08:03 - process vast amounts of personal data
08:05 - consider a chess playing AI as an
08:07 - example rather than programming a set of
08:09 - steps that the computer should follow
08:11 - such as always start with the move
08:13 - Knight to F3 the computer analyzes
08:15 - millions of chess games to create its
08:17 - own patterns or algorithm that allow it
08:20 - to make the best moves in novel
08:22 - situations a large data set of millions
08:25 - of games is necessary for the computer
08:27 - to develop its own style of play now
08:29 - instead of Chess let's consider another
08:31 - example a video recommender algorithm
08:34 - how does an app recommend videos it
08:37 - constantly analyzes each person's
08:39 - interactions with the app monitoring how
08:41 - long you watch a video whether you
08:43 - comment on it or like it and More in
08:45 - order to learn your preferences the
08:47 - algorithm must process your data plus
08:50 - the data of everyone else using the app
08:52 - people tend to have different personal
08:54 - thresholds for what data they are and
08:56 - aren't comfortable sharing with AI
08:58 - systems individuals should have the
09:00 - autonomy to decide whether their data is
09:02 - collected for use in AI systems and
09:05 - companies should provide users with
09:06 - clear information about their data
09:08 - collection
09:09 - practices companies recognize the
09:11 - financial value of user data and often
09:14 - view it as an asset that can be
09:16 - monetized furthermore data protection
09:18 - regulations generally lag behind
09:21 - industry advancements for these reasons
09:23 - staying informed about how individual AI
09:26 - tools are using your data and advocating
09:28 - for privacy protect for your students
09:30 - are crucially important the introduction
09:33 - of AI tools and educational institutions
09:35 - presents nuanced challenges especially
09:37 - concerning data privacy often students
09:40 - find themselves with limited agency in
09:42 - choosing whether or not to use AI or
09:44 - edtech tools as decisions typically fall
09:47 - under institutional mandates emerging
09:49 - data intensive AI platforms may not
09:52 - always meet regulatory standards such as
09:54 - the US's family educational rights and
09:56 - Privacy Act furpa and children's online
09:59 - privacy protection act Capa or other
10:01 - International privacy protections making
10:04 - their integration into educational
10:05 - settings challenging especially for
10:08 - tools targeting users younger than 18
10:10 - parental consent becomes imperative
10:12 - unless these platforms were explicitly
10:14 - designed for educational use while it's
10:17 - Paramount for teachers to instill a
10:18 - thorough understanding of data privacy
10:21 - it's equally important to ensure that
10:22 - students don't feel overwhelmed or
10:24 - powerless though the broader control of
10:26 - personal data might seem elusive
10:29 - students should be equipped with the
10:30 - knowledge to make informed decisions
10:32 - about the data they can control
10:34 - promoting both awareness and
10:36 - [Music]
10:41 - empowerment the learns to take a text
10:44 - description and generate completely new
10:46 - images nobody has ever seen
10:49 - before or to alter existing
10:53 - images the same approach can also be
10:55 - used for
10:58 - videos
11:00 - now this raises multiple questions is
11:03 - the AI really learning creativity and
11:06 - Imagination on the one hand if you look
11:08 - at art and video created by AI it can be
11:11 - beautiful original and amazing on the
11:15 - other hand the AI only learns this by
11:18 - doing math at the pixel level while
11:21 - studying creations made by people is
11:24 - that really creativity another question
11:27 - is the issue of copyright I learns by
11:29 - studying the creations of others and the
11:33 - original creators may want to say in
11:35 - this of course when humans learn to
11:37 - create they also study creations made by
11:40 - others so the legal questions here are
11:43 - not simple we're still in the very early
11:47 - days of teaching AI how to create new
11:49 - types of media today AI can generate
11:52 - photos and videos soon you would also
11:55 - learn to create music my heart on with
11:59 - and 3D worlds this will have an
12:01 - incredible impact on all aspects of
12:04 - society especially in entertainment not
12:07 - just movies and music but also games
12:10 - think about all the information you've
12:12 - posted online over the years like family
12:13 - photos blog posts classroom websites and
12:16 - product reviews generative AI tools
12:19 - those that create new text code and
12:21 - images are typically trained on human
12:23 - Works possibly including some of the
12:24 - content you've contributed to the
12:26 - internet many AI tools also use the
12:28 - content users create within their
12:30 - platforms to enhance their own
12:32 - capabilities for example at present chat
12:35 - gbt and Bard use your conversations as
12:38 - training data by default we mentioned
12:40 - before that people have different
12:42 - personal boundaries around data privacy
12:44 - that holds true when it comes to
12:46 - generative AI
12:47 - too however many communities whose
12:50 - livelihoods depend on generating content
12:52 - like artists programmers and authors
12:55 - have objected to the use of their work
12:57 - to train AI tools since our students are
13:00 - artists programmers and authors too it's
13:02 - important to develop their skills as
13:04 - informed users of these AI tools so they
13:07 - can craft their own stance on data
13:10 - [Music]
13:14 - ownership AI tools Built For Education
13:17 - often have specific guardrails in place
13:19 - to promote safe student interactions and
13:22 - responsible stewardship of student data
13:24 - for example an AI chat bot Built For
13:26 - Education might limit the number of
13:28 - messages per day that a student can sent
13:31 - make a student's chat history visible to
13:33 - Educators or parents or proactively
13:35 - monitor a student's messages for
13:37 - inappropriate content an AI used in
13:39 - education should comply with furpa Capa
13:42 - and other Regional regulations when
13:45 - evaluating an AI tool to see if it is
13:47 - appropriate for use in your school
13:48 - environment first check to see if it was
13:50 - developed for use in education which can
13:52 - be a shorthand for understanding its
13:54 - safety
13:55 - standards look for first party help
13:58 - articles or guides available about the
13:59 - tool that explains safety and privacy
14:02 - features scan its privacy policy for
14:04 - passages that mention School use furpa
14:07 - and Capa you can also search Common
14:09 - Sense media's privacy program for a
14:12 - thorough privacy review of many online
14:14 - tools including chat GPT if you want to
14:17 - stress test an AI tool yourself get in
14:19 - the mindset of a mischievous teenager
14:21 - and see if you can break it how is this
14:24 - mitigated we can't ensure that all
14:26 - technologies that your students use have
14:28 - been optimize to protect their privacy
14:30 - here are some concrete strategies for
14:32 - keeping data private seek local
14:35 - guidance regulations around AI tools are
14:38 - constantly changing ask administrators
14:41 - or District leaders for guidance on AI
14:43 - tools such as guidelines or a white list
14:46 - search for any state and local laws that
14:48 - may affect the use of AI Tools in
14:50 - education scan the privacy policy don't
14:53 - be intimidated by all the legal language
14:56 - take a glance through with some help
14:58 - from control r f search for school use
15:00 - furpa CA and look for the age
15:03 - restrictions or required parental
15:05 - permissions check to see what types of
15:07 - data are collected and whether the data
15:09 - is sold to third parties if the policy
15:12 - doesn't address School use furpa or COA
15:15 - or if student data is sold you may want
15:17 - to consult your school's it department
15:19 - for more help adjust privacy settings
15:23 - most tools will offer some privacy
15:24 - setting such as disabling tracking or
15:26 - data storage before using a tool explore
15:29 - these options and use them to enhance
15:31 - privacy share these options with your
15:34 - students Empower your students it's
15:37 - crucial that students have a genuine
15:39 - Choice when using AI tools inform them
15:41 - about what the tools do and the Privacy
15:43 - implications show them a summary of the
15:46 - privacy policy and let them decide how
15:48 - they want to use the tool don't share
15:50 - personally identifying information a
15:53 - simple rule of thumb for sharing
15:55 - information is the anonymous Forum test
15:58 - if students wouldn't feel comfortable
15:59 - sharing something on an anonymous online
16:02 - platform such as Reddit or ciora they
16:04 - shouldn't share it with AI chat Bots
16:06 - like chat
16:07 - TBT don't forget that files may also
16:10 - contain personally identifying
16:11 - information and should be reviewed
16:13 - before uploading by keeping these points
16:15 - in mind we can help students navigate
16:17 - the world of AI while ensuring their
16:19 - privacy is respected let's take a quick
16:21 - look at how you might evaluate a tool
16:23 - like K Migo First let's check the Con
16:26 - Academy privacy policy right off the B
16:28 - there's a section about school use that
16:30 - mentions furpa and Capa compliance which
16:33 - helps us understand that the tool is
16:35 - intended for use in an educational
16:36 - environment it has sections that
16:38 - explicitly mention the use of the
16:40 - service for those under 18 and under 13
16:44 - second we'll look for first party help
16:46 - articles that explain the tool in a bit
16:48 - more detail we can see in this article
16:50 - that students are informed about the
16:52 - moderation of the tool that interaction
16:54 - is limited and that there are other
16:56 - safeguards in place it's also clear from
16:58 - a glance at the help articles that
17:00 - parents can turn off access to kigo and
17:02 - that some of the articles are directed
17:04 - at
17:05 - Learners let's conduct the same research
17:07 - for chat GPT first we'll scan the
17:09 - privacy policy for open AI you can see
17:12 - that the policy doesn't mention furpa
17:14 - Capa or School use so we can tell that
17:16 - the tool wasn't intended for use in an
17:18 - educational environment if we search for
17:21 - age restrictions the policy tells us
17:23 - that chat PT isn't designed for users
17:25 - under 13 and that users under 18 must
17:28 - have parental consent scanning the help
17:30 - articles for chat GPT there are clearly
17:33 - data control settings that we can turn
17:35 - on or off and ways to report harmful
17:38 - content however there aren't any
17:39 - articles directed at Learners or that
17:41 - mention parental or teacher controls now
17:44 - it's time for you to practice pause the
17:46 - video and examine the privacy policy of
17:48 - a site you use regularly with your
17:50 - [Music]
17:55 - students a large language model can
17:58 - produce unbelievable results that seem
18:00 - like magic but because it's not actually
18:03 - magic it can often get things wrong and
18:07 - when you get things wrong people ask
18:09 - does a large language model have actual
18:13 - intelligence discussions about AI often
18:16 - spark philosophical debates about the
18:18 - meaning of
18:19 - intelligence some argue that a neuron
18:22 - Network producing words using
18:25 - probabilities doesn't have real
18:27 - intelligence but what isn't under debate
18:30 - is that large language models produce
18:32 - amazing results with applications in
18:35 - many fields this technology is already
18:38 - being used to create apps and websites
18:42 - help produce movies and video games and
18:45 - even discover new drugs the rapid
18:48 - acceleration of AI will have enormous
18:50 - impacts on society and it's important
18:53 - for everybody to understand this
18:55 - technology misinformation is a problem
18:58 - and pmic to the internet not something
19:00 - created by AI just as you might have
19:02 - taught students to be skeptical of
19:04 - content on Wikipedia you'll need to help
19:06 - students understand that the information
19:08 - produced by AI isn't always correct
19:10 - healthy skepticism is a great mindset
19:12 - for your students to practice as they
19:14 - begin to encounter more and more
19:15 - information on the internet at home in
19:18 - school and in the workforce sometimes AI
19:20 - systems can confidently produce text
19:22 - that sounds very real but is actually
19:24 - not true while the type of information
19:27 - is often called the h ation we'll use
19:29 - the more inclusive term AI fiction in
19:31 - this video AI fictions happen because
19:34 - large language models were designed to
19:35 - mimic human language not be 100% factual
19:39 - they're language models not knowledge
19:41 - models while language does contain a lot
19:44 - of knowledge it can also contain
19:46 - incorrect information AI systems also
19:49 - don't have a true understanding of what
19:51 - they're saying like humans do so they
19:53 - often can't tell when they're making a
19:55 - mistake which means that these AI system
19:58 - systems communicate as though they're
20:00 - certain about their responses even if
20:02 - they're wrong why is this important well
20:05 - some people might use these madeup
20:06 - stories to spread false information on
20:09 - purpose others might come across these
20:11 - AI fictions by accident and think
20:13 - they're true this can be a problem
20:16 - especially now because with AI fake news
20:19 - stories and images can be created much
20:21 - faster and in larger amounts than before
20:24 - in the online world there's always been
20:26 - misinformation but with AI this
20:28 - information is now easier and faster to
20:31 - create AI fictions have already found
20:33 - their way into legal briefs and
20:34 - scientific papers and since AI mixes
20:37 - both right and wrong information it's
20:39 - important to double check anything you
20:41 - read or hear especially if it sounds a
20:43 - bit off or
20:45 - unbelievable students while eager to use
20:48 - AI tools might not be equipped to
20:50 - differentiate between factual
20:51 - information and AI generated fictions
20:54 - the introduction of AI in schools
20:56 - necessitates a recommitment to to
20:58 - bolstering digital literacy skills
21:00 - ensuring students critically evaluate
21:02 - the authenticity and relevance of the
21:04 - information they consume here are some
21:06 - concrete strategies for combating
21:08 - misinformation exercise healthy
21:11 - skepticism be cautious when asking large
21:14 - language models for factual information
21:16 - especially if that information is
21:18 - obscure reprompt is necessary if
21:21 - something sounds off when prompting a
21:22 - large language model prompt it again to
21:24 - re-evaluate for example by asking are
21:27 - you sure about blank
21:29 - emphasize digital
21:31 - literacy practice digital literacy
21:33 - skills with your students like
21:35 - corroborating information checking for
21:37 - bias in the author's Viewpoint and
21:39 - evaluating The credibility of online
21:41 - sources get creative with assignments
21:44 - give students assignments that ask them
21:46 - to debunk large language models outputs
21:49 - or Define the types of prompts that most
21:50 - often lead to AI
21:52 - fictions use a variety of tools use
21:55 - search engines and large language models
21:57 - to complement each other's strengths and
22:00 - weaknesses search engines can help with
22:02 - factchecking and finding citable sources
22:04 - while AI tools can help summarize and
22:07 - brainstorm so what we're going to do now
22:09 - is we're going to try out a common
22:10 - prompt type that can lead to
22:12 - misinformation this one is asking for
22:14 - quotes from a book to back up a claim in
22:17 - general asking large language models to
22:19 - site sources can be problematic so
22:22 - Katrina what type of books do you like
22:24 - to read I like to read all types of
22:27 - books but my favorite book is Pride and
22:29 - Prejudice awesome so what we're going to
22:31 - do is we're going to prompt our large
22:33 - language model we're going to ask it to
22:36 - list five reasons why Elizabeth Darcy
22:40 - liked Mr Wickham we're going to ask the
22:42 - model to use quotes from the book to
22:44 - back up your reasons we'll see what
22:56 - happens
23:09 - so what it's telling us is seems like
23:12 - you're referring to Pride and Prejudice
23:13 - by Jane Austin that's correct right that
23:16 - is correct U then it says however there
23:18 - isn't any clear evidence in the book
23:20 - that Elizabeth Darcy formerly Elizabeth
23:22 - Bennett like Mr Wickham is that
23:26 - true well in the end of the book she
23:30 - does not like Mr Wickham but there is a
23:32 - substantial portion of the book where
23:34 - she is um quite interested in him oh so
23:40 - it's not accurate here so let's try repr
23:43 - prompting and see if we can get chat gbt
23:46 - to correct itself okay so ask it but
23:49 - doesn't she initially grow to like Mr
23:51 - Wickham before she was aware about how
23:53 - he treated Mr Darcy she believes at
23:56 - first that Darcy treated him him
24:13 - poorly
24:15 - so it corrects itself so it says that it
24:18 - apologizes for the confusion that we're
24:20 - correct um Elizabeth Bennett initially
24:23 - had a favorable impression of Mr Wickham
24:26 - before learning the truth of his
24:27 - character and his actions and then it
24:29 - gives some quotes and you know it lists
24:32 - reasons here Charming manner friendly
24:34 - nature it gives the chapters this looks
24:37 - great to me what do you think as The
24:39 - Pride and Prejudice expert well here for
24:42 - quote number one that is a quote from
24:44 - the book about Mr Wickam and Elizabeth
24:47 - but it says it's from chapter 3 and
24:49 - actually it's from chapter 18 oh so it
24:52 - just has the chapter number wrong yeah
24:53 - but it is a correct quote and then quote
24:56 - number two is actually a quote that Mr
24:59 - Darcy says about Mr Wickham when he
25:02 - explains to Elizabeth um Mr Wickham's
25:05 - faults now so that doesn't really
25:07 - support our point at all here does it no
25:10 - that would not support Elizabeth's
25:13 - interest in Mr Wickham and then if we
25:15 - look at number four we see this is
25:17 - actually a quote from after Elizabeth
25:20 - learns of Mr Wickham's deceit and um the
25:23 - shame she feels for herself so this is
25:25 - not a quote that supports
25:28 - Elizabeth's liking of Mr
25:31 - Wickham that's some great examples of
25:33 - how chat GPT was able to produce an
25:36 - output that looked legitimate but
25:38 - actually had a lot of fictions now it's
25:41 - your turn to try pause the video open
25:43 - chat GPT or another large language model
25:45 - of your choice prop the large language
25:47 - model on a subject you know well fact
25:49 - check the output and see if you can find
25:51 - your own examples of AI
25:53 - [Music]
25:56 - fiction
26:00 - I think ethics becomes more important as
26:02 - something becomes more impactful and as
26:04 - AI becomes more impactful the more that
26:06 - we have to think about the ethics of
26:11 - AI artificial intelligence is ultimately
26:13 - built by human
26:15 - beings human beings can have very
26:18 - diverse motives for why they make
26:20 - something unfortunately there's a huge
26:23 - difference between those that are
26:25 - involved in creating these systems and
26:27 - those that are impacted by these
26:29 - systems so what we really want to think
26:31 - about long term is where is the society
26:33 - we want to get to and how is technology
26:36 - going to help enable
26:38 - that if we think about that in the long
26:40 - term we have a better chance of getting
26:42 - there than if we just try to develop the
26:44 - technology and then see what
26:48 - happens AI systems can sometimes produce
26:51 - unfair or discriminatory results this
26:54 - often arises from biases in the data
26:56 - that they're trained on or the way their
26:58 - algorithms are designed this phenomenon
27:01 - is known as algorithmic bias in
27:03 - artificial intelligence it represents
27:05 - the consistent and repeatable errors
27:08 - made by a computer system leading to
27:10 - unjust outcomes like favoring one group
27:12 - over another however the term bias isn't
27:15 - limited to distinctions like race gender
27:18 - or age broadly speaking bias is a more
27:21 - general term that reflects situations
27:22 - where an AI system consistently airs in
27:25 - a particular direction causing skewed
27:28 - conclusions these biases can emerge due
27:30 - to various factors such as design
27:32 - processes pre-existing prejudices
27:35 - embedded in the training data or even
27:37 - the interpretation of the results by
27:39 - those utilizing the AI for instance if a
27:42 - facial recognition system is trained
27:44 - predominantly on images of people from
27:46 - One ethnic group it may perform poorly
27:48 - on people from other ethnic groups
27:51 - moreover when algorithms trained on bias
27:53 - data are employed in real world
27:55 - applications they can perpetually uate
27:57 - inequities and create adverse outcomes
28:01 - understanding this concept is crucial as
28:02 - AI continues to play an increasingly
28:05 - integral role in various aspects of Our
28:07 - Lives from job applications to credit
28:09 - approvals from healthc care Diagnostics
28:11 - to personalized education these systems
28:14 - if left unchecked can inadvertently
28:16 - deepen existing disparities and hinder
28:19 - the objective of a just Society let's
28:21 - take a look at some prominent examples
28:23 - of algorithmic bias as a result of a
28:26 - facial recognition positive a black
28:28 - woman was wrongfully accused of a
28:30 - carjacking in Detroit facial recognition
28:33 - systems have performed poorly on the
28:35 - faces of people of color and even
28:37 - seemingly small error rates can still
28:39 - have a negative impact on a substantial
28:41 - number of individuals chat GPT has been
28:44 - found to exhibit a left-leaning bias
28:47 - likely in part because of the
28:48 - demographics of the people who trained
28:49 - the system to construct helpful
28:52 - prompts programs used to detect AI are
28:54 - more likely to flag writing from
28:56 - non-native English speakers as AI
28:59 - generated Common Sense Media recently
29:01 - found that in YouTube videos watched by
29:04 - kids eight and younger 62% feature no
29:06 - black indigenous or people of color
29:08 - characters at all while in another 10%
29:11 - of videos black indigenous or people of
29:13 - color characters were portrayed in
29:15 - Shallow ways while it's impossible to
29:17 - understand the extent to which the AI
29:19 - recommendation system was responsible
29:21 - for this outcome we do know it's
29:23 - responsible for 70% of all watch time on
29:26 - YouTube pause the video here and search
29:28 - for your own example of algorithmic bias
29:30 - in AI supported Technologies the problem
29:33 - is that with real world data there's
29:36 - often information in there that you
29:38 - didn't intend to be in there but is
29:40 - captured because of the bias in the data
29:42 - collection
29:43 - process so if you're building an AI to
29:46 - determine who gets a home loan or who
29:48 - should be charged with a crime it could
29:51 - definitely Bubble Up the racial biases
29:53 - that humans and our current Society
29:56 - already does
30:01 - a lot of what it means to build less
30:02 - harmful AI is really uh systems that are
30:06 - including the perspectives of those that
30:08 - are most vulnerable or most marginalized
30:10 - most likely to be hurt by the deployment
30:12 - of that
30:13 - system in many ways I've worried that
30:15 - the people who are particularly
30:17 - vulnerable to eii are the people who are
30:19 - already underprivileged in many
30:23 - [Music]
30:25 - respects most people in the world world
30:27 - just have ai applied to them rather than
30:30 - playing an active role in guiding what
30:32 - AI gets applied
30:34 - to everybody you know has a computer in
30:37 - their
30:38 - pocket that's young people old people
30:41 - rich people poor people to me that's
30:44 - actually quite exciting from a
30:47 - democratization of Technology
30:50 - perspective means that AI powerful as it
30:53 - is could theoretically be in everybody's
30:56 - Pockets benefiting
30:58 - everybody We should strive to make sure
31:00 - that things that provide value for
31:02 - society can be reached to
31:07 - anybody how do we give a greater voice
31:10 - to the people who are being impacted by
31:12 - AI to in turn be able to turn around and
31:15 - impact how AI is used for
31:19 - them every time when you looking at a
31:21 - new problem you have an opportunity to
31:24 - change the world sometimes we succeed
31:26 - sometimes we don't but we always
31:29 - try it's really critically important
31:32 - that we have as many diverse
31:33 - perspectives as possible influencing the
31:36 - development of AI we need the
31:38 - participation of more women more people
31:40 - of color to provide a different
31:42 - perspective and a different lens on
31:44 - which problems matter and how we should
31:46 - approach these
31:48 - problems now that we've taken a look at
31:51 - where algorithmic bias can emerge in
31:53 - real world context let's examine some
31:56 - guiding principles for teach teaching
31:57 - about bias in your
31:58 - classroom AI technology is nearly
32:01 - everywhere remember the old phrase
32:03 - there's an app for that today it's more
32:05 - like there's an AI for that artificial
32:08 - intelligence is an umbrella term
32:10 - encompassing machine learning and deep
32:12 - learning these techniques are applied in
32:14 - almost every sector you can think of do
32:18 - stay true to your passion and subject
32:20 - area find examples of both potentially
32:22 - harmful Ai and helpful AI in that space
32:26 - don't assume AI can do everything even
32:29 - if it's widespread the errors and biases
32:31 - are widespread too assume someone in the
32:34 - room is a data point depending on the
32:36 - age level various case studies of AI
32:38 - bias may come up these can include
32:40 - racial discrimination legal inequity
32:43 - housing insecurity gender discrimination
32:45 - social media manipulation misinformation
32:48 - education ACCESS food insecurity and so
32:51 - on teach us if you are speaking directly
32:53 - to someone affected by the issue as it
32:56 - may even be the case
32:57 - do speak with compassion and a Solutions
33:00 - oriented approach don't make jokes Tolen
33:03 - the mood don't treat the data like it's
33:05 - objective or detached don't treat
33:08 - outliers as useless data points don't
33:10 - use shock value data sources can be
33:13 - biased the problems we try to solve and
33:15 - the data we use to solve them can be
33:18 - narrow-minded for example trying to
33:20 - extrapolate instructional
33:21 - recommendations from one school's data
33:23 - likely won't translate using health
33:25 - costs as a proxim for how sick someone
33:28 - is discounts all the people who don't go
33:30 - to the doctor even though they are sick
33:32 - because they can't afford it data is not
33:34 - always ethically sourced and the right
33:36 - questions aren't always asked sometimes
33:39 - the problem itself is one that we
33:41 - shouldn't be trying to solve like how to
33:43 - predict someone's gender race criminal
33:46 - potential or sexuality from a photo do
33:51 - consider where the data comes from and
33:53 - how it was collected do look for whether
33:55 - it was ethically sourced do look for the
33:57 - year it was collected and the context of
34:00 - the time don't assume you always need
34:03 - more data you might need different data
34:06 - don't assume all problems are worth
34:08 - solving in the first place show
34:10 - Solutions no one wants to feel like
34:12 - their future is doomed you don't I don't
34:14 - your students don't we Thrive off hope
34:17 - for each case of algorithmic bias there
34:19 - are some solutions that have already
34:20 - worked and an opportunity to brainstorm
34:22 - possible solutions for the future do
34:25 - provide links to organ organizations
34:27 - working to solve issues of bias and
34:29 - algorithmic harm do be honest that
34:31 - mistakes will happen and that it takes
34:33 - bravery and accountability to tackle
34:36 - them don't assume that all solutions are
34:39 - technical fixes or magic aha algorithms
34:42 - Solutions are often cultural or policy
34:44 - driven don't imply all the problems have
34:46 - already been fixed and won't be
34:48 - represented in another similar context
34:51 - let's dive deeper return to the example
34:53 - of algorithmic bias that you explored
34:55 - earlier how how might those principles
34:57 - impact how you would approach leading a
34:59 - discussion about this issue with your
35:01 - students this session on ensuring a
35:03 - responsible approach to AI has been
35:05 - Illuminating we examine critical issues
35:08 - like privacy concerns misinformation and
35:10 - algorithmic bias underscoring the
35:13 - pressing challenges that come with the
35:15 - rapid advancements in AI
35:17 - technology however it's essential to
35:19 - remember that technology at its core is
35:22 - a tool the responsibility is on us its
35:25 - users and developers to guide ai's
35:27 - Direction by fostering open dialogues
35:29 - like the one we had today and working
35:31 - collaboratively we can ensure that AI
35:33 - serves Humanity ethically effectively
35:36 - and responsibly the conversation does
35:38 - not end here we challenge you to go back
35:40 - to your school and continue these
35:41 - conversations with your colleagues
35:43 - perhaps you might even establish data
35:45 - privacy policies with your school level
35:47 - teams or share successes and challenges
35:50 - related to discussing algorithmic bias
35:52 - with your students the future is bright
35:55 - and with our Collective Comm commitment
35:57 - we can harness ai's potential while
35:59 - safeguarding our shared values and
36:03 - principles AI certainly does have its
36:05 - benefits and also its pitfalls we hope
36:08 - that the information presented in this
36:10 - session will help you to navigate this
36:12 - new world with confidence the next step
36:15 - in our journey is to consider how you
36:17 - might bring AI into your classroom join
36:20 - us in session five where we focus on
36:23 - teaching about AI evaluating and
36:26 - utilizing ing AI Educational Tools and
36:29 - leveraging AI for student assessment
36:31 - this session will be a blend of theory
36:34 - practical examples and resources all
36:37 - intended to help you navigate the Ever
36:39 - Changing landscape of AI and education
36:42 - visit the ai101 for teers website at
36:45 - code.org
36:46 - ai101 to sign up for Early Access and to
36:50 - explore additional resources from
36:51 - code.org ETS IST and Con Academy thanks
36:55 - for joining us

Cleaned transcript:

hi welcome to session four of AI 101 for teachers professional learning Series so far we have been focusing mostly on the benefits of AI which might be leaving some of you with some important questions like wait a minute I've heard that sometimes AI can make mistakes or even provide biased responses how do I ensure I'm using AI responsibly and thoughtfully what can I do to ensure I'm preparing my students to think critically about these new technologies these are all valid and important things to consider as you think about how you will approach AI in education let's dig into some of these topics hi I'm Danny I'm a former middle school and high school math computer science and engineering teacher I now work at code.org on our product team helping to develop the website that students and teachers use today we're here joined by Katrina to talk about AI we know that AI has been on many teachers minds and we're excited to dive into this topic today with Katrina could you introduce yourself hi I'm Katrina I am an elementary school special education teacher so could you tell us a little bit about how a relates to your work as an elementary school teacher AI is a really exciting tool but I am worried about how it relates to students and its use in the education setting what are some things you're excited about I think that AI can be really useful to help me when writing reports or when generating test questions or assignments for the students to work on um there's a lot of potential there so you said you had some concerns what are those concerns well I am worried about student priv privacy and how their data could be used by different AI tools and also about how AI could be used in the classroom and whether or not um the information that it provides would be accurate for students and also um how students might use it to help them with things like essay writing or homework are there ways you think you can leverage AI as a special education teacher um I do think that it could be really useful when helping to do things like write IEP goals um but with that I have concerns as well because IEPs are obviously very specific to each student and I wouldn't want to provide any personally identifying information to the AI tools I do think it can be really helpful with differentiation um I teach students who are at all different levels so for instance if I'm reviewing aition I can ask AI to help me write questions for my students who are at a lower level maybe add adding numbers between 1 and 10 but also my students who are more advanced in adding multidigit numbers Danny I was wondering if you could give me advice so if I'm using AI to help me um come up with a reading passage at differentiated levels for my students about for instance the Revolutionary War how can I make sure that the information that it gives me for my students to read is actually accurate you really are going to have to be the expert we already think you know we know that teachers are the experts and you're going to have to rely on your knowledge to check what the AI tool is giving you to make sure that it is accurate so you can't just take what the I tool generates and hand it to students you're going to have to read it yourself and make sure that you believe what it's saying and maybe check other sources to make sure it matches what you find there as well Danny as somebody who works in educational technology and for a company that creates some of these AI tools what are your thoughts about the safety of using AI in a K12 classroom in terms of when we develop tools we work really hard to ensure their safety before they ever see a classroom so we're going to do a lot of rigorous testing to make sure that they're safe and they're producing factual information and they're reliable um that they're going to give the same result repeatedly and then we work hard to then pilot in a classroom make making sure that we do it with a small set so we can see what is happening and be really HandsOn we also always make sure that when we're developing tools that teachers have access to deciding what they want in their classroom and how it's used and then being able to monitor what is happening what are your thoughts on the future of AI where would you like to see it go if you could talk to you know creators of AI Technologies what would you want for your classroom well as a special education teacher I have a few students who are nonspeaking and they use AAC devices to help them communicate um and I'm curious about how those AAC devices could be integrated with AI to give those nonspeaking students or really any nonspeaking individual a way to communicate their thoughts the potential for AI to help Society is enormous it's something that is influencing a lot of very important decisions about real humans and their lives it could be used in education to be more of an equalizer between people it could be used in healthcare to develop new drugs it could be used in science to develop new technologies and like any technology its application will depend on how it is utilized and at the same time we need to think about the risks that are associated with doing that the consequences are huge hi everyone I hope you're all as excited as we are to dive back into the fascinating world of AI my name is is Michelle and I'm a former High School science and computer science teacher I now work as a member of the professional learning team at code.org today we're going to discuss how you can ensure a responsible approach to AI in education Educators and administrators have valid concerns when considering whether or not AI Technologies are right for their classrooms some top concerns include the following data privacy how can my students and I use AI Tools in a way that protects our data and how do I know when a tool tool is safe enough to use with my students misinformation and AI fiction how can my students and I use AI effectively when it can be wrong algorithmic bias how can my students and I recognize AI bias and how can I teach my students to think critically about that bias throughout this video we will address each of these concerns and equip you with clear effective strategies you can use to mitigate risks for your students and for yourself it is really important that technologists kind of have this Mantra of ensuring that their Innovation is ethical and is beneficial to everyone in society machine learning requires a lot of true information to be provided to it in order to ultimately uh deliver a utility this information might be very sensitive to us it might be health related it might be Financial it might be very very personal we need to put checks and controls in place like with any technology that it's utilized to benefit us and that it is done with accordance to the law there's lot of gain from involving yourself in really understanding the details of how this technology Works given that it's so impactful given that it is something that will influence inuence your life and the life of everyone that you love AI systems process vast amounts of personal data consider a chess playing AI as an example rather than programming a set of steps that the computer should follow such as always start with the move Knight to F3 the computer analyzes millions of chess games to create its own patterns or algorithm that allow it to make the best moves in novel situations a large data set of millions of games is necessary for the computer to develop its own style of play now instead of Chess let's consider another example a video recommender algorithm how does an app recommend videos it constantly analyzes each person's interactions with the app monitoring how long you watch a video whether you comment on it or like it and More in order to learn your preferences the algorithm must process your data plus the data of everyone else using the app people tend to have different personal thresholds for what data they are and aren't comfortable sharing with AI systems individuals should have the autonomy to decide whether their data is collected for use in AI systems and companies should provide users with clear information about their data collection practices companies recognize the financial value of user data and often view it as an asset that can be monetized furthermore data protection regulations generally lag behind industry advancements for these reasons staying informed about how individual AI tools are using your data and advocating for privacy protect for your students are crucially important the introduction of AI tools and educational institutions presents nuanced challenges especially concerning data privacy often students find themselves with limited agency in choosing whether or not to use AI or edtech tools as decisions typically fall under institutional mandates emerging data intensive AI platforms may not always meet regulatory standards such as the US's family educational rights and Privacy Act furpa and children's online privacy protection act Capa or other International privacy protections making their integration into educational settings challenging especially for tools targeting users younger than 18 parental consent becomes imperative unless these platforms were explicitly designed for educational use while it's Paramount for teachers to instill a thorough understanding of data privacy it's equally important to ensure that students don't feel overwhelmed or powerless though the broader control of personal data might seem elusive students should be equipped with the knowledge to make informed decisions about the data they can control promoting both awareness and empowerment the learns to take a text description and generate completely new images nobody has ever seen before or to alter existing images the same approach can also be used for videos now this raises multiple questions is the AI really learning creativity and Imagination on the one hand if you look at art and video created by AI it can be beautiful original and amazing on the other hand the AI only learns this by doing math at the pixel level while studying creations made by people is that really creativity another question is the issue of copyright I learns by studying the creations of others and the original creators may want to say in this of course when humans learn to create they also study creations made by others so the legal questions here are not simple we're still in the very early days of teaching AI how to create new types of media today AI can generate photos and videos soon you would also learn to create music my heart on with and 3D worlds this will have an incredible impact on all aspects of society especially in entertainment not just movies and music but also games think about all the information you've posted online over the years like family photos blog posts classroom websites and product reviews generative AI tools those that create new text code and images are typically trained on human Works possibly including some of the content you've contributed to the internet many AI tools also use the content users create within their platforms to enhance their own capabilities for example at present chat gbt and Bard use your conversations as training data by default we mentioned before that people have different personal boundaries around data privacy that holds true when it comes to generative AI too however many communities whose livelihoods depend on generating content like artists programmers and authors have objected to the use of their work to train AI tools since our students are artists programmers and authors too it's important to develop their skills as informed users of these AI tools so they can craft their own stance on data ownership AI tools Built For Education often have specific guardrails in place to promote safe student interactions and responsible stewardship of student data for example an AI chat bot Built For Education might limit the number of messages per day that a student can sent make a student's chat history visible to Educators or parents or proactively monitor a student's messages for inappropriate content an AI used in education should comply with furpa Capa and other Regional regulations when evaluating an AI tool to see if it is appropriate for use in your school environment first check to see if it was developed for use in education which can be a shorthand for understanding its safety standards look for first party help articles or guides available about the tool that explains safety and privacy features scan its privacy policy for passages that mention School use furpa and Capa you can also search Common Sense media's privacy program for a thorough privacy review of many online tools including chat GPT if you want to stress test an AI tool yourself get in the mindset of a mischievous teenager and see if you can break it how is this mitigated we can't ensure that all technologies that your students use have been optimize to protect their privacy here are some concrete strategies for keeping data private seek local guidance regulations around AI tools are constantly changing ask administrators or District leaders for guidance on AI tools such as guidelines or a white list search for any state and local laws that may affect the use of AI Tools in education scan the privacy policy don't be intimidated by all the legal language take a glance through with some help from control r f search for school use furpa CA and look for the age restrictions or required parental permissions check to see what types of data are collected and whether the data is sold to third parties if the policy doesn't address School use furpa or COA or if student data is sold you may want to consult your school's it department for more help adjust privacy settings most tools will offer some privacy setting such as disabling tracking or data storage before using a tool explore these options and use them to enhance privacy share these options with your students Empower your students it's crucial that students have a genuine Choice when using AI tools inform them about what the tools do and the Privacy implications show them a summary of the privacy policy and let them decide how they want to use the tool don't share personally identifying information a simple rule of thumb for sharing information is the anonymous Forum test if students wouldn't feel comfortable sharing something on an anonymous online platform such as Reddit or ciora they shouldn't share it with AI chat Bots like chat TBT don't forget that files may also contain personally identifying information and should be reviewed before uploading by keeping these points in mind we can help students navigate the world of AI while ensuring their privacy is respected let's take a quick look at how you might evaluate a tool like K Migo First let's check the Con Academy privacy policy right off the B there's a section about school use that mentions furpa and Capa compliance which helps us understand that the tool is intended for use in an educational environment it has sections that explicitly mention the use of the service for those under 18 and under 13 second we'll look for first party help articles that explain the tool in a bit more detail we can see in this article that students are informed about the moderation of the tool that interaction is limited and that there are other safeguards in place it's also clear from a glance at the help articles that parents can turn off access to kigo and that some of the articles are directed at Learners let's conduct the same research for chat GPT first we'll scan the privacy policy for open AI you can see that the policy doesn't mention furpa Capa or School use so we can tell that the tool wasn't intended for use in an educational environment if we search for age restrictions the policy tells us that chat PT isn't designed for users under 13 and that users under 18 must have parental consent scanning the help articles for chat GPT there are clearly data control settings that we can turn on or off and ways to report harmful content however there aren't any articles directed at Learners or that mention parental or teacher controls now it's time for you to practice pause the video and examine the privacy policy of a site you use regularly with your students a large language model can produce unbelievable results that seem like magic but because it's not actually magic it can often get things wrong and when you get things wrong people ask does a large language model have actual intelligence discussions about AI often spark philosophical debates about the meaning of intelligence some argue that a neuron Network producing words using probabilities doesn't have real intelligence but what isn't under debate is that large language models produce amazing results with applications in many fields this technology is already being used to create apps and websites help produce movies and video games and even discover new drugs the rapid acceleration of AI will have enormous impacts on society and it's important for everybody to understand this technology misinformation is a problem and pmic to the internet not something created by AI just as you might have taught students to be skeptical of content on Wikipedia you'll need to help students understand that the information produced by AI isn't always correct healthy skepticism is a great mindset for your students to practice as they begin to encounter more and more information on the internet at home in school and in the workforce sometimes AI systems can confidently produce text that sounds very real but is actually not true while the type of information is often called the h ation we'll use the more inclusive term AI fiction in this video AI fictions happen because large language models were designed to mimic human language not be 100% factual they're language models not knowledge models while language does contain a lot of knowledge it can also contain incorrect information AI systems also don't have a true understanding of what they're saying like humans do so they often can't tell when they're making a mistake which means that these AI system systems communicate as though they're certain about their responses even if they're wrong why is this important well some people might use these madeup stories to spread false information on purpose others might come across these AI fictions by accident and think they're true this can be a problem especially now because with AI fake news stories and images can be created much faster and in larger amounts than before in the online world there's always been misinformation but with AI this information is now easier and faster to create AI fictions have already found their way into legal briefs and scientific papers and since AI mixes both right and wrong information it's important to double check anything you read or hear especially if it sounds a bit off or unbelievable students while eager to use AI tools might not be equipped to differentiate between factual information and AI generated fictions the introduction of AI in schools necessitates a recommitment to to bolstering digital literacy skills ensuring students critically evaluate the authenticity and relevance of the information they consume here are some concrete strategies for combating misinformation exercise healthy skepticism be cautious when asking large language models for factual information especially if that information is obscure reprompt is necessary if something sounds off when prompting a large language model prompt it again to reevaluate for example by asking are you sure about blank emphasize digital literacy practice digital literacy skills with your students like corroborating information checking for bias in the author's Viewpoint and evaluating The credibility of online sources get creative with assignments give students assignments that ask them to debunk large language models outputs or Define the types of prompts that most often lead to AI fictions use a variety of tools use search engines and large language models to complement each other's strengths and weaknesses search engines can help with factchecking and finding citable sources while AI tools can help summarize and brainstorm so what we're going to do now is we're going to try out a common prompt type that can lead to misinformation this one is asking for quotes from a book to back up a claim in general asking large language models to site sources can be problematic so Katrina what type of books do you like to read I like to read all types of books but my favorite book is Pride and Prejudice awesome so what we're going to do is we're going to prompt our large language model we're going to ask it to list five reasons why Elizabeth Darcy liked Mr Wickham we're going to ask the model to use quotes from the book to back up your reasons we'll see what happens so what it's telling us is seems like you're referring to Pride and Prejudice by Jane Austin that's correct right that is correct U then it says however there isn't any clear evidence in the book that Elizabeth Darcy formerly Elizabeth Bennett like Mr Wickham is that true well in the end of the book she does not like Mr Wickham but there is a substantial portion of the book where she is um quite interested in him oh so it's not accurate here so let's try repr prompting and see if we can get chat gbt to correct itself okay so ask it but doesn't she initially grow to like Mr Wickham before she was aware about how he treated Mr Darcy she believes at first that Darcy treated him him poorly so it corrects itself so it says that it apologizes for the confusion that we're correct um Elizabeth Bennett initially had a favorable impression of Mr Wickham before learning the truth of his character and his actions and then it gives some quotes and you know it lists reasons here Charming manner friendly nature it gives the chapters this looks great to me what do you think as The Pride and Prejudice expert well here for quote number one that is a quote from the book about Mr Wickam and Elizabeth but it says it's from chapter 3 and actually it's from chapter 18 oh so it just has the chapter number wrong yeah but it is a correct quote and then quote number two is actually a quote that Mr Darcy says about Mr Wickham when he explains to Elizabeth um Mr Wickham's faults now so that doesn't really support our point at all here does it no that would not support Elizabeth's interest in Mr Wickham and then if we look at number four we see this is actually a quote from after Elizabeth learns of Mr Wickham's deceit and um the shame she feels for herself so this is not a quote that supports Elizabeth's liking of Mr Wickham that's some great examples of how chat GPT was able to produce an output that looked legitimate but actually had a lot of fictions now it's your turn to try pause the video open chat GPT or another large language model of your choice prop the large language model on a subject you know well fact check the output and see if you can find your own examples of AI fiction I think ethics becomes more important as something becomes more impactful and as AI becomes more impactful the more that we have to think about the ethics of AI artificial intelligence is ultimately built by human beings human beings can have very diverse motives for why they make something unfortunately there's a huge difference between those that are involved in creating these systems and those that are impacted by these systems so what we really want to think about long term is where is the society we want to get to and how is technology going to help enable that if we think about that in the long term we have a better chance of getting there than if we just try to develop the technology and then see what happens AI systems can sometimes produce unfair or discriminatory results this often arises from biases in the data that they're trained on or the way their algorithms are designed this phenomenon is known as algorithmic bias in artificial intelligence it represents the consistent and repeatable errors made by a computer system leading to unjust outcomes like favoring one group over another however the term bias isn't limited to distinctions like race gender or age broadly speaking bias is a more general term that reflects situations where an AI system consistently airs in a particular direction causing skewed conclusions these biases can emerge due to various factors such as design processes preexisting prejudices embedded in the training data or even the interpretation of the results by those utilizing the AI for instance if a facial recognition system is trained predominantly on images of people from One ethnic group it may perform poorly on people from other ethnic groups moreover when algorithms trained on bias data are employed in real world applications they can perpetually uate inequities and create adverse outcomes understanding this concept is crucial as AI continues to play an increasingly integral role in various aspects of Our Lives from job applications to credit approvals from healthc care Diagnostics to personalized education these systems if left unchecked can inadvertently deepen existing disparities and hinder the objective of a just Society let's take a look at some prominent examples of algorithmic bias as a result of a facial recognition positive a black woman was wrongfully accused of a carjacking in Detroit facial recognition systems have performed poorly on the faces of people of color and even seemingly small error rates can still have a negative impact on a substantial number of individuals chat GPT has been found to exhibit a leftleaning bias likely in part because of the demographics of the people who trained the system to construct helpful prompts programs used to detect AI are more likely to flag writing from nonnative English speakers as AI generated Common Sense Media recently found that in YouTube videos watched by kids eight and younger 62% feature no black indigenous or people of color characters at all while in another 10% of videos black indigenous or people of color characters were portrayed in Shallow ways while it's impossible to understand the extent to which the AI recommendation system was responsible for this outcome we do know it's responsible for 70% of all watch time on YouTube pause the video here and search for your own example of algorithmic bias in AI supported Technologies the problem is that with real world data there's often information in there that you didn't intend to be in there but is captured because of the bias in the data collection process so if you're building an AI to determine who gets a home loan or who should be charged with a crime it could definitely Bubble Up the racial biases that humans and our current Society already does a lot of what it means to build less harmful AI is really uh systems that are including the perspectives of those that are most vulnerable or most marginalized most likely to be hurt by the deployment of that system in many ways I've worried that the people who are particularly vulnerable to eii are the people who are already underprivileged in many respects most people in the world world just have ai applied to them rather than playing an active role in guiding what AI gets applied to everybody you know has a computer in their pocket that's young people old people rich people poor people to me that's actually quite exciting from a democratization of Technology perspective means that AI powerful as it is could theoretically be in everybody's Pockets benefiting everybody We should strive to make sure that things that provide value for society can be reached to anybody how do we give a greater voice to the people who are being impacted by AI to in turn be able to turn around and impact how AI is used for them every time when you looking at a new problem you have an opportunity to change the world sometimes we succeed sometimes we don't but we always try it's really critically important that we have as many diverse perspectives as possible influencing the development of AI we need the participation of more women more people of color to provide a different perspective and a different lens on which problems matter and how we should approach these problems now that we've taken a look at where algorithmic bias can emerge in real world context let's examine some guiding principles for teach teaching about bias in your classroom AI technology is nearly everywhere remember the old phrase there's an app for that today it's more like there's an AI for that artificial intelligence is an umbrella term encompassing machine learning and deep learning these techniques are applied in almost every sector you can think of do stay true to your passion and subject area find examples of both potentially harmful Ai and helpful AI in that space don't assume AI can do everything even if it's widespread the errors and biases are widespread too assume someone in the room is a data point depending on the age level various case studies of AI bias may come up these can include racial discrimination legal inequity housing insecurity gender discrimination social media manipulation misinformation education ACCESS food insecurity and so on teach us if you are speaking directly to someone affected by the issue as it may even be the case do speak with compassion and a Solutions oriented approach don't make jokes Tolen the mood don't treat the data like it's objective or detached don't treat outliers as useless data points don't use shock value data sources can be biased the problems we try to solve and the data we use to solve them can be narrowminded for example trying to extrapolate instructional recommendations from one school's data likely won't translate using health costs as a proxim for how sick someone is discounts all the people who don't go to the doctor even though they are sick because they can't afford it data is not always ethically sourced and the right questions aren't always asked sometimes the problem itself is one that we shouldn't be trying to solve like how to predict someone's gender race criminal potential or sexuality from a photo do consider where the data comes from and how it was collected do look for whether it was ethically sourced do look for the year it was collected and the context of the time don't assume you always need more data you might need different data don't assume all problems are worth solving in the first place show Solutions no one wants to feel like their future is doomed you don't I don't your students don't we Thrive off hope for each case of algorithmic bias there are some solutions that have already worked and an opportunity to brainstorm possible solutions for the future do provide links to organ organizations working to solve issues of bias and algorithmic harm do be honest that mistakes will happen and that it takes bravery and accountability to tackle them don't assume that all solutions are technical fixes or magic aha algorithms Solutions are often cultural or policy driven don't imply all the problems have already been fixed and won't be represented in another similar context let's dive deeper return to the example of algorithmic bias that you explored earlier how how might those principles impact how you would approach leading a discussion about this issue with your students this session on ensuring a responsible approach to AI has been Illuminating we examine critical issues like privacy concerns misinformation and algorithmic bias underscoring the pressing challenges that come with the rapid advancements in AI technology however it's essential to remember that technology at its core is a tool the responsibility is on us its users and developers to guide ai's Direction by fostering open dialogues like the one we had today and working collaboratively we can ensure that AI serves Humanity ethically effectively and responsibly the conversation does not end here we challenge you to go back to your school and continue these conversations with your colleagues perhaps you might even establish data privacy policies with your school level teams or share successes and challenges related to discussing algorithmic bias with your students the future is bright and with our Collective Comm commitment we can harness ai's potential while safeguarding our shared values and principles AI certainly does have its benefits and also its pitfalls we hope that the information presented in this session will help you to navigate this new world with confidence the next step in our journey is to consider how you might bring AI into your classroom join us in session five where we focus on teaching about AI evaluating and utilizing ing AI Educational Tools and leveraging AI for student assessment this session will be a blend of theory practical examples and resources all intended to help you navigate the Ever Changing landscape of AI and education visit the ai101 for teers website at code.org ai101 to sign up for Early Access and to explore additional resources from code.org ETS IST and Con Academy thanks for joining us
