00:00 - in this video i will talk about running
00:02 - kubernetes on cloud
00:04 - and the benefits of a managed kubernetes
00:06 - service
00:07 - among others i go through the topics of
00:10 - spinning up a cluster
00:12 - load balancing data persistence in
00:15 - kubernetes cluster
00:16 - and the problem of moving or migrating
00:18 - from one cloud platform to another
00:21 - there are so many tools and trends
00:22 - nowadays like infrastructure as a
00:24 - service kubernetes on cloud
00:27 - managed kubernetes service etc that have
00:29 - developed
00:30 - over the past few years and are trending
00:33 - now so it's good to get a
00:35 - good big picture overview of all this
00:37 - and that's what i will cover in this
00:39 - video
00:40 - one of the known infrastructure as a
00:42 - service platforms is
00:43 - lynode which is sponsoring this video so
00:46 - huge thanks to lenod for that because
00:49 - sponsorships like this
00:51 - allow me to create more free content for
00:53 - you on my youtube channel
00:55 - so let's build a case where you and your
00:58 - team are developing a micro service
01:00 - application
01:00 - with database that will be deployed in
01:03 - kubernetes cluster
01:05 - you want your application to be
01:06 - available from a browser
01:08 - it's your domain name with secure https
01:11 - connection
01:12 - plus you have some requirements like
01:14 - security for your whole cluster setup
01:16 - of course and the data persistence for
01:19 - your database
01:20 - and because you want to do it properly
01:22 - you want to have development
01:24 - and production coordinates environments
01:26 - that are the same
01:27 - so you can properly test new features
01:29 - before releasing them
01:31 - so this is your wish setup and you want
01:33 - to get this
01:34 - as efficiently as possible without
01:36 - wasting a lot of time
01:38 - and without having to spend your whole
01:40 - time learning and figuring out
01:42 - every piece of technology so bear that
01:45 - setup in mind while we go
01:46 - through the following concepts okay and
01:49 - by the way this whole setup that i will
01:51 - explain
01:52 - in this video with concepts i will make
01:54 - a practical demo of it so
01:56 - you know theoretically how all this
01:58 - works but can also
01:59 - implement it in practice so basically
02:02 - you have a complete knowledge
02:04 - package for this specific scenario from
02:06 - just
02:07 - two videos so let's dive right in
02:10 - first of all where will your kubernetes
02:13 - cluster for application be deployed
02:16 - consider you want to set up kubernetes
02:18 - cluster on a cloud platform like lenode
02:20 - how does this actually work now there
02:23 - are two
02:23 - options to do that the option number one
02:26 - is you can spin up
02:27 - let's say six lynode server instances
02:29 - and create your own kubernetes cluster
02:32 - from scratch
02:33 - meaning you install master processes on
02:35 - three nodes
02:36 - and make them master nodes then install
02:39 - the worker processes like cube ctl
02:41 - cube proxy and container runtime like
02:43 - docker on the other three and make them
02:46 - into
02:47 - worker nodes and once you have set them
02:49 - up
02:50 - you have a cluster and now you can
02:51 - deploy your applications on it
02:53 - so the whole cluster master and worker
02:56 - nodes
02:56 - are your responsibility to manage secure
02:59 - do backups etc so you have to manage the
03:02 - cluster now yourself it is doable but
03:04 - it's a pretty big overhead
03:06 - to install all these binaries and
03:09 - processes
03:10 - and to put the cluster together if you
03:12 - just want to create a
03:13 - simple cluster to deploy your
03:15 - applications
03:17 - the option of creating cluster from
03:20 - scratch
03:20 - on cloud instances is not very practical
03:23 - because as i mentioned you want to get
03:25 - things
03:25 - done fast and easy and don't want to
03:28 - spend too much time
03:29 - on setting things up and figuring it all
03:31 - out so as an alternative
03:34 - cloud providers like lenode also
03:37 - offer what is called a managed
03:39 - kubernetes service
03:40 - that does a lot of heavy lifting for you
03:43 - on lynode it's called a linode
03:45 - kubernetes
03:46 - engine so how does this work or what
03:48 - does it actually
03:49 - represent so you don't have to create
03:52 - cluster from scratch
03:54 - most of it is done for you automatically
03:56 - by lenovo platform
03:58 - so when you create a kubernetes cluster
04:00 - on lke
04:02 - linux engine you just choose how many
04:04 - worker nodes you want
04:06 - so you just care about worker nodes
04:09 - you will get for example three worker
04:11 - nodes with all the processes including
04:13 - docker container
04:14 - runtime pre-installed so you don't have
04:17 - to install
04:18 - any of this and you will get them up and
04:21 - running
04:21 - in no time so what about the masternodes
04:24 - who creates them
04:25 - who manages them where are they the
04:28 - thing is leadnote creates the master
04:30 - nodes
04:30 - or also called the control plane in the
04:32 - background when you create the cluster
04:34 - but you don't even see that because it's
04:36 - completely managed by lynode
04:38 - it's not your responsibility anymore so
04:40 - you don't have to manage
04:42 - and secure and do all the configuration
04:45 - on it
04:46 - that's one advantage but this also means
04:48 - that you only pay for the worker notes
04:50 - now
04:51 - you don't pay for this extra couple of
04:53 - notes that run as your masternodes
04:55 - that eliminates not only extra costs but
04:58 - also a lot of effort and
04:59 - overhead because you can literally just
05:02 - get started in minutes
05:03 - with a running kubernetes cluster so it
05:05 - saves a lot of time
05:07 - so let's go through this in more detail
05:09 - how does this all work and what can you
05:11 - do with
05:12 - linode kubernetes engine the process is
05:15 - pretty simple
05:16 - let's say you create a cluster with
05:18 - three worker nodes to deploy your
05:19 - application
05:21 - on linux ui choose your work notes
05:24 - with their resources leadnote has server
05:27 - instances of different capacities so
05:29 - depending on your needs
05:31 - whether it's a test development or
05:33 - production environment you will choose
05:34 - which nodes you need
05:36 - with how much capacity then you select a
05:39 - region
05:39 - or data center where the worker nodes
05:41 - will run so for example if you're
05:43 - let's say in uk maybe you create cluster
05:46 - in your nearest region in the uk and
05:49 - with a couple of clicks your kubernetes
05:51 - cluster will be up and running
05:54 - then you connect to the cluster using
05:56 - cubectl from your laptop
05:58 - and deploy your applications services
06:00 - and do all these things that you need to
06:02 - do
06:02 - in the cluster super straightforward so
06:06 - let's say you need to deploy a mongodb
06:08 - database
06:09 - for your node.js application and you
06:11 - want
06:12 - several replicas of that now database
06:16 - applications need data persistence right
06:19 - to save that application data and if you
06:21 - have three replicas of a database you
06:23 - need
06:23 - persistence or storage for all three
06:26 - replicas
06:27 - if you want to learn generally how data
06:29 - persistence works in kubernetes
06:32 - i have a separate video about that so
06:33 - you can check that out now if you have
06:35 - watched it
06:36 - already you know there are different
06:37 - types of storages like there are cloud
06:39 - storage providers
06:41 - there is nfs local storage on the nodes
06:44 - themselves etc and the storage you have
06:47 - to configure yourself kubernetes doesn't
06:49 - do that for you
06:49 - so you would have to create that storage
06:51 - the physical actual storage and
06:53 - make it available for the cluster
06:55 - resource like database
06:57 - then you would have to create persistent
06:59 - volume components
07:00 - with the storage backend and now you can
07:03 - attach these volumes to your database
07:05 - parts
07:07 - well lean out has its own storage linode
07:10 - block storage that you can use to
07:11 - dynamically create the volumes
07:13 - so you don't have to set up and
07:15 - configure anything you don't have to
07:17 - create the physical storage and then
07:19 - create volumes out of it and connect
07:21 - them
07:21 - etc you just use lynode's storage class
07:25 - and lynode will create the persistent
07:27 - volumes with the
07:29 - respective physical storage in the
07:31 - background automatically
07:33 - and when you deploy your database
07:35 - application
07:36 - the storage will get attached to your
07:38 - database pods
07:40 - and you will see all this in a demo part
07:42 - in detail
07:43 - so you have a very little effort here as
07:46 - well of course it's good to know how it
07:48 - works but you don't have to do
07:50 - much here okay so now you have your
07:52 - node.js application
07:54 - let's say running as well as mongodb
07:56 - database
07:57 - application with replicas and its
08:00 - storage
08:01 - configured so now we need services and
08:03 - access from the browser
08:05 - through ingress which is part of
08:07 - kubernetes
08:09 - that basically manages routing of
08:11 - incoming
08:12 - requests like from a browser to
08:15 - internal services in kubernetes so in
08:18 - our example
08:19 - you would need to install and run
08:22 - ingress controller
08:23 - in your kubernetes cluster so that you
08:25 - can configure
08:26 - ingress rules that will then route the
08:29 - incoming traffic
08:31 - to your node.js application to
08:34 - understand the concept behind this
08:35 - in a cloud environment like manage
08:38 - community service
08:39 - or in a lead note kubernetes engine how
08:42 - does this setup work
08:43 - how will ingress get that incoming
08:46 - request
08:47 - and it happens through lynode's node
08:49 - balancer
08:50 - so in cloud platforms you have cloud
08:52 - providers
08:53 - own load balancer implementations
08:56 - that gets in front of the nginx ingress
08:59 - controller
09:00 - so that becomes the entry point in your
09:02 - cluster
09:03 - so let's see how that works leenod's
09:05 - node balancer is
09:06 - as the name says a load balancer for
09:09 - your worker nodes
09:11 - where nodes are the lead node server
09:13 - instances
09:14 - so say you have two linux instances one
09:17 - runs a
09:18 - database application and other runs a
09:21 - web server
09:22 - and you expose the web server using a
09:24 - public ip address
09:25 - so browser can send requests directly to
09:28 - the web server
09:29 - the problem is you can't scale this
09:31 - application
09:32 - if you suddenly start getting a lot of
09:34 - traffic your web server will become a
09:36 - bottleneck
09:37 - also if you make changes to the web
09:39 - server like reboot it
09:41 - reconfigure it etc your application
09:43 - becomes unavailable
09:45 - instead let's say you add a node
09:47 - balancing fraud that takes the incoming
09:49 - request
09:50 - and directs it to the web server so node
09:53 - balancer will get the public ip address
09:55 - and web server will be hidden away and
09:57 - accessible only at
09:59 - private ip from the load balancer itself
10:03 - now you can add multiple web servers
10:05 - under that load balancer that load
10:07 - balancer can
10:08 - forward the request to so you can scale
10:10 - your application
10:12 - up and down without users even noticing
10:14 - anything
10:16 - now you have an entry point to your
10:18 - application that you set up
10:20 - once and just leave it and it works it's
10:23 - just there to accept the requests
10:25 - and then redirect it to one of the web
10:26 - servers you can also configure
10:28 - session stickiness with lean notes load
10:31 - balancer
10:32 - which means if user authenticated
10:35 - on one server that keeps sessions in the
10:38 - memory
10:39 - meaning only that web server instance
10:42 - has the session information
10:44 - and knows the client you can configure
10:46 - the node balancer to forward the next
10:48 - request from that client to the same web
10:51 - server
10:52 - instead of randomly picking or passing
10:55 - the request
10:56 - to any server so the same client will
10:58 - always land on the same backhand
11:00 - and trust me if your application keeps
11:02 - sessions in memory
11:04 - this will be the first thing you're
11:06 - gonna be asking how to solve
11:08 - so this feature is very helpful now
11:10 - obviously you need your connections to
11:12 - be secured so you can also configure the
11:15 - node balancer with
11:16 - ssl certificate pretty easily so you can
11:19 - accept https requests only node you can
11:23 - do that using
11:24 - a plugin called cert manager which
11:26 - basically helps with managing
11:28 - ssl tls certificates remember we don't
11:31 - want to spend time doing everything
11:33 - ourselves
11:34 - we want to delegate most of this stuff
11:36 - to technologies
11:37 - so in this case you can get the
11:39 - certificate and store it as a kubernetes
11:41 - secret and
11:42 - use it to secure the connection to your
11:44 - cluster now as i said i will make a demo
11:46 - video right after this where i will show
11:48 - you
11:49 - all of these in practice click the
11:52 - notification bell
11:53 - after subscribing and you will get
11:55 - notified when the new video is out
11:57 - and as i said the concept you'll learn
11:59 - on lynode
12:00 - you can apply on other platforms as well
12:02 - so far i've used
12:04 - three or four different cloud platforms
12:06 - and the usage concepts are pretty
12:09 - similar it's just that
12:10 - some platforms are better in doing
12:12 - certain things
12:13 - now that you have a successful setup
12:16 - your application is scaled and available
12:18 - through browser
12:19 - users can now use it and let's say when
12:22 - you created your cluster on lke you
12:24 - selected region
12:25 - let's say dallas usa so that's where
12:28 - your cluster
12:29 - or work nodes are running suddenly you
12:31 - notice
12:32 - most of your users are accessing your
12:35 - application from
12:36 - europe and india let's say this means
12:39 - that connection speed is not good for
12:41 - users because the servers are locating
12:43 - geographically too far away from them
12:46 - so you want to host your application in
12:48 - closer proximity to your users
12:51 - that's where the availability zones of a
12:53 - cloud provider come
12:54 - into play leadnote has data centers
12:58 - in 11 physical locations also called
13:01 - availability zones where you can run
13:03 - your nodes so if you want to roll out
13:06 - your application
13:07 - for german and indian users for example
13:09 - you can simply select the data center
13:11 - locations
13:12 - near them now let's say everything is
13:15 - set up on
13:16 - lke your application is running you have
13:19 - it in multiple data centers
13:21 - all looks good your team or company
13:23 - decides
13:24 - you know what we would like to move our
13:27 - data
13:27 - in all the sensitive information from
13:30 - the cloud platform to our private cloud
13:33 - and also there is
13:35 - this new feature of our application that
13:38 - will be most efficiently done
13:40 - using a specific service in cloud
13:43 - platform
13:43 - b whatever that is so basically you want
13:46 - to migrate
13:47 - part of your application setup to
13:49 - private cloud and
13:50 - part or just one feature to another
13:52 - cloud
13:53 - usually what happens is when you set up
13:56 - your kubernetes cluster on a cloud
13:58 - platform
13:58 - you end up using its services like
14:01 - native
14:02 - load balancers and storage or some apis
14:05 - that are specific to that cloud provider
14:08 - so your application or parts of your
14:10 - application gets
14:11 - closely tied up to that specific cloud
14:14 - provider
14:14 - and you can't migrate easily you may
14:17 - need a lot of reprogramming and
14:19 - reconfiguration
14:20 - to move parts of your code or the whole
14:23 - application
14:25 - away from the platform and migrate it
14:28 - to some other place that's called vendor
14:32 - lock in an obvious reason for that is of
14:34 - course cloud platforms want to keep the
14:36 - companies
14:37 - um tied to them by providing these
14:40 - useful
14:41 - super services but which are cloud
14:43 - specific
14:44 - so you can't move your application
14:47 - easily afterwards
14:48 - in case you need it leenode however
14:52 - doesn't have that vendor lock-in which
14:54 - is a great thing
14:56 - if you come to the point where you
14:58 - actually need that migration
15:00 - or partial migration so you would be
15:02 - able to easily do the above
15:04 - and move your workloads to other
15:06 - platforms
15:07 - and they do that by being open cloud and
15:10 - having their api
15:11 - completely open and free so they don't
15:14 - lock you
15:15 - in with their native api another point
15:18 - is
15:18 - let's say your setup grows in size
15:21 - you deploy more and more services your
15:24 - infrastructure configuration gets
15:26 - more complex and your devops team grows
15:28 - as well
15:29 - in this case you would want to automate
15:31 - as much as possible
15:33 - so you may automate creating configuring
15:36 - tearing down doing all sorts of things
15:39 - with your
15:40 - infrastructure where your cluster is
15:41 - running and also
15:43 - automate deploying your applications and
15:45 - services and you can do that
15:47 - using automation tools so for leenode
15:50 - specifically
15:51 - you can use those tools to automate your
15:54 - infrastructure and also deployment of
15:57 - services
15:58 - in that infrastructure so for example
16:01 - tools like terraform or insible which
16:04 - are
16:04 - automation tools have modules or
16:07 - providers or whatever they are called in
16:09 - their respective tool
16:10 - that can connect to lenode platform
16:13 - to get access to its resources and then
16:16 - let you automate your devops work
16:19 - to again save time and work more
16:21 - efficiently
16:22 - and finally a couple of things that must
16:24 - be mentioned about
16:25 - lenode kubernetes engine that may seem
16:28 - minor
16:28 - at the beginning but can also be very
16:31 - important
16:32 - first one is creating a cluster
16:34 - initially
16:35 - on many cloud platforms usually takes
16:38 - long
16:38 - because the master nodes need to be
16:40 - provisioned the configuration you
16:41 - selected must be applied
16:43 - some other resources must be created etc
16:45 - so on some platforms it could be up to
16:48 - 20 30 minutes even to just initialize
16:51 - the cluster
16:52 - on lke when you create a cluster it
16:55 - takes
16:56 - under five minutes which is way less
16:58 - compared to other
16:59 - platforms and it's pretty fascinating
17:02 - when considering how much actually needs
17:04 - to be
17:05 - done in the background now you may think
17:07 - that you only need to create cluster
17:09 - once and that's it so not a big deal
17:11 - if i have to wait half an hour at the
17:13 - beginning however when you're just
17:15 - starting off
17:16 - you want to practice you want to test or
17:18 - maybe create test or trial cluster
17:21 - you may need to do it a couple of times
17:23 - especially at the beginning
17:25 - for example i create demos and try out
17:27 - some new things
17:28 - on lke so i need to create and tear down
17:31 - the cluster
17:32 - pretty often so in this case it can save
17:36 - a lot of time
17:37 - and finally another detail that i notice
17:39 - is that
17:40 - you can ssh into your worker notes
17:43 - which can be very useful when
17:45 - troubleshooting for example
17:47 - and surprisingly this is not a common
17:49 - thing
17:50 - with managed kubernetes service because
17:52 - the other
17:53 - two cloud platforms that i've used they
17:56 - didn't support that feature
17:58 - or more correctly they didn't allow that
18:00 - feature so you can actually
18:02 - ssh into your notes into your worker
18:05 - notes
18:05 - in case you needed to troubleshoot
18:07 - something from that but know that you
18:09 - have to be careful when using the ssh
18:12 - into
18:12 - linux nodes because you can easily break
18:15 - something
18:16 - on the server so unless you know exactly
18:19 - what you're doing avoid changing some
18:22 - stuff there
18:23 - so that's it for the introduction of
18:26 - managed kubernetes service with an
18:28 - example of
18:29 - linux kubernetes engine thank you for
18:31 - watching
18:32 - and see you in the next video