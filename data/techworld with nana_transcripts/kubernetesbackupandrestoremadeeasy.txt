00:00 - in this video we're going to talk about
00:02 - a challenging task of data management in
00:04 - kubernetes
00:05 - and a tool that makes data management
00:08 - very easy for the kubernetes
00:09 - administrators
00:11 - which is castings k10 so what does
00:14 - data management in kubernetes actually
00:16 - mean and why is it a challenging
00:19 - task imagine we have the following real
00:22 - world
00:23 - application setup in our kubernetes
00:25 - production cluster
00:27 - let's say we have an eks cluster where
00:30 - our microservices application
00:32 - is running our microservices use
00:35 - elasticsearch database
00:37 - which is also running in the cluster
00:40 - and in addition to that our application
00:43 - is using amazon's
00:44 - rds data service which is a managed
00:47 - database
00:48 - outside the cluster this means our
00:51 - application has
00:52 - data services both inside and outside
00:55 - the cluster
00:57 - and this data will be physically stored
00:59 - on some storage backend
01:01 - rds data will be stored on aws of course
01:05 - and data for elasticsearch will be used
01:07 - in the cluster
01:09 - through kubernetes persistent volume
01:11 - components
01:12 - but they also need to be physically
01:14 - stored somewhere
01:15 - and this could be a cloud storage on aws
01:18 - google cloud etc or on an
01:21 - on-premise server now let's look at the
01:24 - use cases we would have to
01:26 - think about in terms of data management
01:29 - of this
01:30 - specific application setup imagine the
01:33 - following scenarios in your kubernetes
01:35 - cluster
01:36 - the underlying infrastructure where the
01:38 - cluster is running
01:39 - fails and will lose all the pods
01:42 - services and the whole cluster
01:43 - configuration
01:44 - we would need to recreate the cluster
01:47 - with the same cluster state
01:49 - and the same application data so we need
01:52 - to restore our cluster to the previous
01:54 - state
01:55 - or let's say our elasticsearch database
01:58 - gets corrupted or
01:59 - hacked into and will lose all the data
02:01 - there again
02:02 - we need to restore our database to the
02:05 - latest working state
02:06 - or another very common use case say our
02:09 - cluster is running on aws
02:12 - but we want to make our production
02:13 - cluster more reliable and flexible
02:16 - by not depending on just one cloud
02:19 - provider
02:19 - and by replicating it on a google cloud
02:22 - environment
02:23 - with the same application setup and
02:25 - application
02:26 - data in all these cases the challenge
02:30 - is how do we capture an application
02:33 - backup
02:34 - that includes all the data that the
02:36 - application
02:38 - needs whether it's the databases in the
02:40 - kubernetes cluster
02:42 - or a managed data service outside the
02:45 - cluster
02:46 - so that if our cluster failed or
02:48 - something happened to our application
02:50 - and we lost all the data we would be
02:53 - able to restore
02:55 - or replicate the application state with
02:58 - all its components
02:59 - like pods services config maps secrets
03:02 - etc
03:03 - and all its data and that is
03:06 - a challenging task so essentially
03:09 - you need a way to capture and backup all
03:12 - these parts
03:13 - of the cluster to then easily
03:16 - take that backup and replicate or
03:18 - restore the cluster state
03:20 - with it now let's look at what
03:22 - alternatives we have available
03:24 - for that if we do vm backups of
03:28 - our cluster nodes or ecd backups we will
03:32 - save the state of the cluster but what
03:34 - about the application data
03:36 - they are not stored on the worker nodes
03:38 - right they are stored outside the
03:40 - cluster
03:41 - on a cloud platform or on on-premise
03:44 - servers
03:45 - on the other side for the cloud storage
03:47 - backends
03:48 - the cloud providers themselves have
03:51 - their own backup and replication
03:53 - mechanisms
03:54 - but it's only partially managed by the
03:56 - platform
03:57 - so you still have to configure the data
03:59 - backups and
04:00 - take care of your data yourself plus
04:04 - it's just the data in the volume this
04:06 - doesn't include the cluster state
04:09 - many teams write custom scripts to piece
04:12 - together
04:13 - backup solutions on different levels
04:15 - like components
04:17 - and state inside the cluster and data
04:20 - outside the cluster
04:21 - but these scripts can get very complex
04:24 - very soon because
04:25 - the data and state is spread on many
04:28 - levels
04:28 - and many platforms and the script code
04:31 - usually
04:32 - ends up being too tied to the underlying
04:34 - platform or infrastructure
04:37 - where data is stored the same goes for
04:40 - the restore logic many teams use
04:42 - custom scripts to write restore logic or
04:45 - cluster recreation logic
04:47 - from all the different backup sources
04:51 - so overall your team may end up with
04:53 - lots of complex
04:54 - self-managed scripts which are usually
04:58 - hard to maintain and these are exactly
05:00 - the challenges that castings
05:03 - k10 tool addresses so how does k10
05:06 - solve these problems k-10 abstracts away
05:10 - the underlying infrastructure to give
05:13 - you a consistent data management support
05:16 - no matter where the data is actually
05:18 - stored so
05:19 - teams can choose whichever
05:20 - infrastructure or platform they want
05:23 - for their application without
05:25 - sacrificing operational simplicity
05:28 - because k-10 has a pretty extensive
05:31 - ecosystem
05:32 - and integrates with various relational
05:34 - or nosql databases
05:36 - many different kubernetes distributions
05:38 - and all clouds
05:40 - so instead of backup scripts for each
05:43 - platform
05:43 - or level you just have one easy
05:46 - ui interface of k10 to create
05:50 - complete application backups in the
05:52 - cluster
05:53 - so everything that is part of the
05:55 - application like kubernetes components
05:57 - themselves
05:58 - and the application data in volumes as
06:01 - well as
06:02 - data in managed data services outside
06:05 - the cluster
06:06 - will be captured in the application
06:08 - snapshot
06:09 - by k-10 so you can easily take that
06:12 - snapshot and reproduce or restore your
06:15 - cluster
06:16 - on any infrastructure you want and k-10
06:19 - works with
06:20 - policies so instead of manually backing
06:22 - up and restoring your applications
06:24 - which means more effort and higher risk
06:27 - of making mistakes
06:28 - you can configure backup and restore
06:30 - tasks to run
06:32 - automatically with the settings you
06:33 - define in the policy
06:35 - now what if you have multiple clusters
06:38 - across
06:39 - multiple zones or regions or even across
06:42 - cloud platforms how do you consistently
06:45 - manage
06:46 - tens or hundreds of cluster backups for
06:49 - that
06:50 - k10 actually has a multi-cluster mode
06:53 - in cayton's multi-cluster dashboard you
06:56 - have a single overview of
06:57 - all your clusters as well as a way to
07:00 - create and configure
07:02 - global backup and restore policies that
07:05 - you can then apply
07:06 - to multiple clusters now if you have
07:09 - hundreds or thousands of applications
07:11 - across
07:12 - many clusters of course you don't want
07:15 - to create policies on the ui
07:18 - and for that k-10 actually provides us
07:20 - with
07:21 - kubernetes native way of scripting
07:23 - policies with
07:24 - yemo so you can also automate your
07:27 - policy creation and configuration
07:30 - as part of your policy as code workflow
07:34 - now let's see how k10 actually works
07:37 - first we install k10 in a kubernetes
07:40 - cluster
07:41 - we can install it easily using a helm
07:43 - chart in its own
07:44 - namespace once deployed k-10 will
07:48 - automatically discover all the
07:50 - applications
07:51 - running inside the cluster and in our
07:54 - case let's say we have a mysql
07:56 - application
07:57 - running in its own mysql namespace with
08:00 - persistent data storage configured
08:03 - and you can see those automatically
08:04 - discovered applications on k10's
08:07 - dashboard
08:08 - which also gets deployed in kubernetes
08:10 - along with
08:11 - other components the applications
08:14 - card also shows warning that the
08:16 - discovered applications
08:18 - are unmanaged which means we don't have
08:21 - any backup policies
08:23 - configured for our applications yet
08:26 - so basically the application data isn't
08:28 - protected
08:29 - that's what the warning is about and for
08:31 - each application
08:32 - we have a details view which shows all
08:36 - application related components grouped
08:38 - together
08:39 - including all the labels data components
08:42 - workload as well as configuration and
08:44 - networking components
08:49 - so as a next step we can create
08:51 - automated backup policy
08:53 - for our mysql application to protect
08:56 - mysql application
08:57 - and its data and if i click on new
09:00 - policy
09:01 - i can create a policy for my application
09:04 - with all
09:04 - needed configuration options creating a
09:08 - policy on
09:09 - ui is as easy as simply choosing a
09:12 - snapshot action
09:13 - and selecting which application you want
09:15 - to backup and how often
09:17 - now you have an option to decide exactly
09:20 - what you want
09:21 - to back up we can choose to protect
09:24 - everything that's associated with that
09:26 - application
09:27 - or be more granular and protect only
09:30 - some components
09:31 - of the application using filter
09:34 - resources
09:35 - or we can go even broader and snapshot
09:37 - multiple applications at once
09:40 - using the labels now this will configure
09:43 - local snapshots but ideally we want to
09:46 - store
09:47 - our snapshots on an external storage
09:49 - location
09:50 - so we have our backups protected and
09:53 - living outside the cluster
09:55 - for that we can enable backups via
09:58 - snapshot exports and select the export
10:02 - location
10:02 - which is going to be the backup target
10:05 - this backup target can be configured in
10:08 - location profile section in the settings
10:12 - and this backup target can be any s3
10:15 - compatible storage like
10:17 - amazon s3 google cloud storage azure
10:20 - storage
10:21 - min io etc so you can store your
10:23 - application backups in your preferred
10:26 - location
10:26 - so in our case we can configure a min io
10:30 - storage profile by adding the
10:32 - credentials and
10:33 - endpoint bucket name and save profile
10:38 - now we can use this location profile as
10:41 - a remote storage location
10:43 - for our snapshots by selecting it
10:46 - here and before creating the policy
10:50 - if we click on this yaml button here you
10:53 - will see the policy component in a
10:55 - familiar
10:56 - yaml format and this is actually the
10:58 - kubernetes native
11:00 - api behind this policy so everything you
11:03 - see in the ui
11:05 - is enabled by this api so you can script
11:08 - your policies
11:09 - and this will be very useful if you have
11:12 - hundreds or thousands of applications in
11:14 - your cluster
11:15 - that you want to backup and you need a
11:17 - way to scale your policies and
11:19 - configuration options
11:22 - so we create the policy and this policy
11:24 - will run
11:25 - every hour since we configured an hourly
11:28 - backup
11:30 - but we can also run the policy manually
11:32 - at any time
11:33 - so if we click on run policy
11:36 - this will trigger a backup job that you
11:39 - can see
11:40 - on the dashboard and when completed we
11:43 - will see that all application
11:44 - components have been captured in that
11:47 - snapshot
11:54 - now that we have a backup of the
11:55 - application with a local snapshot
11:58 - as well as its remote copy we have the
12:01 - whole application protected
12:03 - so if something happens and we lose the
12:05 - data or
12:06 - application gets misconfigured etc we
12:09 - can restore the application from the
12:11 - latest
12:12 - snapshot simply by clicking restore
12:15 - and selecting the snapshot we can
12:18 - restore the application or even
12:20 - clone it in a different namespace in the
12:23 - same cluster
12:24 - in our case let's clone the mysql
12:26 - application in a new namespace
12:29 - called mysql clone
12:33 - and when i click on restore
12:36 - this will trigger restore job and if we
12:39 - go back to the cluster
12:41 - we can see what's happening in the
12:42 - background new namespace was created
12:45 - and we brought back all the application
12:47 - components and application data
12:50 - so they are now all available in that
12:52 - new
12:53 - namespace
12:57 - and finally when you're restoring the
13:00 - application
13:01 - maybe you don't want to clone and run
13:03 - the application exactly the same way
13:05 - with the same configuration for example
13:08 - if you're cloning your application to
13:10 - another platform maybe you want to
13:12 - change the storage type
13:14 - to use the storage of that platform or
13:17 - change the number of replicas of your
13:19 - applications or change the
13:21 - availability zone the application will
13:24 - run in
13:25 - and so on you can actually do such
13:27 - adjustments to the application
13:29 - when restoring it using what's called
13:32 - transformations in k10
13:34 - just by selecting transformations as an
13:36 - option and then basically configuring
13:39 - what you need to be adjusted
13:44 - so as you see k10 can make the data
13:47 - management for
13:48 - applications running in kubernetes way
13:51 - easier
13:52 - and you can actually get started with
13:54 - k10 for free
13:55 - as it has a free forever option for
13:58 - managing
13:58 - up to 10 notes and even more in the
14:01 - description of this video
14:03 - you will find a link to k-10's page
14:06 - where you can go through a hands-on lab
14:08 - to quickly try out the tool yourself
14:10 - without any cluster setup as well as the
14:12 - link to the free
14:14 - k10 version so make sure to check out
14:17 - those links
14:17 - and with that thank you for watching and
14:20 - see you in the next video