00:00 - Welcome to this
DevSecOps Crash course.
00:04 - After an extremely successful
launch of our
00:07 - complete DevSecOps bootcamp,
00:09 - which so many of you
were interested
00:11 - in and so many companies
are already using
00:14 - to upskill their engineers.
00:16 - After seeing this immense
interest in this topic,
00:19 - I wanted to create a DevSecOps
crash course for those who want
00:24 - to get an idea of what that is,
00:26 - to get a basic understanding
of DevSecOps concepts,
00:30 - DevSecOps tools,
00:31 - and get their very first hands
on experience with actual
00:35 - practical implementation
of DevSecOps.
00:38 - So in this crash course,
00:39 - we're going to go through
the fundamentals
00:41 - of what DevSecOps is,
00:43 - as well as see some hands
on examples with a demo project.
00:47 - So you get an understanding
of it.
00:49 - And then if it spikes
your interest,
00:51 - you can decide if you want
to actually enroll and do
00:54 - a full DevSecOps bootcamp
to learn this extremely
00:59 - demanded skill set
and basically just get
01:02 - way ahead in your career.
So let's get started.
01:09 - Security is important
01:10 - at all levels of software
01:12 - development lifecycle.
In the application itself,
01:16 - the application's
runtime environment
01:18 - and underlying infrastructure,
01:19 - which could be on premise
or cloud platform.
01:22 - And it's important to the level
that when companies fail
01:26 - to properly secure things
and they get hacked
01:29 - or some data gets leaked,
et cetera.
01:31 - Where their user data or company
data gets compromised,
01:34 - or their systems get attacked
and aren't accessible anymore,
01:38 - the price they pay
for that is way more
01:42 - expensive than actually
implementing the security.
01:46 - And it's expensive,
01:47 - both financially but also
reputation wise. And of course,
01:51 - that means all companies
should implement security.
01:55 - However, it is pretty difficult
and there are two
01:58 - biggest challenges companies
have in terms
02:00 - of security and what may be
the reason why they fail
02:05 - to actually implement
the security.
02:08 - First of all,
02:08 - often feature development
and providing business value
02:12 - is more incentivized
because that's what brings
02:15 - in customers.
02:16 - That's what provides the direct
value for users.
02:20 - And very simply,
02:21 - that's what brings in money
for the business.
02:24 - So security is like
a necessary evil.
02:27 - You don't get so much
reward and pat on the back
02:30 - for implementing great security.
02:33 - But if a security
incident happens,
02:35 - you get real punishment.
02:37 - So security stays
an afterthought
02:39 - in application development
or even
02:41 - infrastructure configuration
process.
02:44 - The second issue is,
02:45 - even if you and your
team are dedicated
02:48 - to implementing great security,
02:51 - you still have a challenge
because the application
02:54 - systems themselves are becoming
more and more complex.
02:58 - Think about the modern
tech stack.
03:00 - In our application systems,
03:01 - we have a large
containerized microservices
03:04 - application that is running
in Kubernetes
03:07 - cluster on cloud platform,
03:10 - using tons of different
services with data
03:14 - persistence in ten different
types of databases.
03:17 - You may have like a
primary database,
03:20 - a SQL database, NoSQL database,
a caching or memory database,
03:24 - and so on,
03:25 - and tens of external
services that your
03:27 - application may be talking to.
Additionally,
03:30 - we have a streamlined CI CD
pipeline that deploys
03:33 - to the cluster.
03:35 - Imagine how many entry
points and how large
03:38 - of an attack surface such
a complex system has that may
03:42 - allow different
types of attacks.
03:44 - These levels could be within
the application itself.
03:47 - So your own code or third party
applications and libraries
03:52 - that allow for SQL injection,
for example,
03:54 - or cross-site scripting
or forging requests
03:57 - from clients or even worse,
from servers,
04:00 - then you may have security
issues within your
04:03 - application container
image like the image
04:06 - operating system layer,
the image configuration,
04:09 - all these different third
party operating system
04:12 - packages that you may need
in that container
04:15 - environment that may have
security vulnerabilities.
04:19 - Now that container will
have to run somewhere
04:21 - like Kubernetes cluster.
04:23 - So here we have
the security challenges.
04:25 - Like is the access to the
cluster security.
04:28 - Is server publicly accessible
or only from within
04:32 - the internal network?
04:33 - Have you opened any unneeded
ports on worker
04:36 - nodes that allow access into the
cluster nodes directly?
04:40 - Now that's just outside
the cluster.
04:42 - What about inside the cluster?
Once an attacker is inside,
04:46 - do they have wide open
network where
04:49 - thousands of pods can all
talk to each other freely?
04:52 - Can the control plane
processes be easily
04:54 - accessed from within
the cluster?
04:56 - Is the pod two pod
communication encrypted,
04:59 - and so on.
05:00 - Now Kubernetes is not just
floating around on the air,
05:04 - right? It's running
on actual infrastructure.
05:07 - Let's say it's a cloud
infrastructure on AWS.
05:11 - So now the security continues
over to the servers.
05:14 - Then the underlying
infrastructure.
05:16 - Are people able to ssh into the
worker nodes directly.
05:20 - If they can do that,
05:21 - they could potentially access
the Kubernetes processes
05:24 - on that server directly,
05:26 - or the container processes
or even cloud
05:28 - processes running
on those servers.
05:30 - Or what if access is generally
are badly managed,
05:34 - like permissions are not
strict enough,
05:36 - and credentials are spread
around the company
05:39 - on different platforms
and developers machines,
05:42 - so attacker may easily access
them on other internal systems.
05:47 - Continuing with the CI CD
pipeline itself,
05:50 - what about CD accessing your
cluster to make
05:53 - deployment updates?
05:54 - What permissions does your CD
tool have?
05:57 - Is it able to delete
components in all
05:59 - Kubernetes namespaces?
06:01 - So basically if an attacker
hacked into one
06:04 - system like ci CD platform,
06:06 - will they attacker then get
access to credential?
06:08 - Stored in your CD platform
to your private repositories.
06:13 - Kubernetes cluster.
06:15 - Account basically all
the platforms
06:16 - that it connects to. And if yes.
06:19 - What permissions do
those credentials have?
06:22 - Are they restricted or can
they do a lot more damage.
06:26 - And we can go on and on with
these security
06:28 - questions around different
tools and platforms and so on.
06:31 - We'd like secret
management tools,
06:33 - credential rotation
certificates and so on.
06:36 - But I think you got the point.
06:38 - Security is complex
because the systems
06:41 - have become complex.
06:46 - Security is.
06:46 - Afterthought means
that those potential
06:49 - security issues get analyzed
after the main work is done.
06:54 - And there are two problems
with this approach.
06:57 - First of all,
06:57 - this creates long iterations
and slows down
07:00 - the release process compared
to if we checked and found
07:04 - security issues earlier during
the development process itself.
07:08 - And second,
07:09 - when you're checking all
security at once of 50 new
07:12 - features and bug fixes and 50
configuration changes,
07:16 - you may more easily oversee
stuff because you have
07:20 - way more things to test,
07:22 - and more issues may slip
into production as a result.
07:26 - Also, naturally,
07:27 - you have high chance of human
error when this kind of checks
07:31 - are done manually and less
frequently compared
07:34 - to the automated approach.
07:39 - Now you remember my
07:40 - simplified definition of DevOps.
Basically,
07:43 - what it really comes down
to eventually is anything,
07:47 - any tool or concept use
to remove any bottlenecks
07:50 - on the way of releasing
and delivering changes
07:53 - to the end user fast
and with minimal bugs.
07:58 - And this applies whether
it's application
08:00 - or infrastructure changes.
So naturally,
08:03 - if security is a bottleneck
in that release process,
08:06 - that should become part
of DevOps issue that we have
08:09 - to eliminate this showstopper.
08:12 - So DevOps naturally
should include security.
08:14 - But as I often say,
08:16 - reality in theory or how
it's supposed to be are two
08:20 - different scenarios.
So in practice,
08:23 - it's so happened that DevOps
left out the security,
08:27 - it focused on development
and even bug fixes
08:30 - and efficiency and speed
in those areas.
08:33 - But security teams and external
pen tests stayed in later steps,
08:38 - not streamline, not automated,
and still done mostly manually.
08:42 - So as a reminder to kind
of highlight
08:45 - the importance or bring back
the importance
08:47 - of security in DevOps,
the DevSecOps concept emerged.
08:52 - And as you know,
08:53 - DevOps affects entire software
development lifecycle too.
08:57 - So DevSecOps is naturally
taking that overarching
09:00 - security and integrating
it in all
09:03 - DevOps steps from start
to finish,
09:06 - along with application tests,
build steps and so on.
09:09 - So the responsibility of fixing
security issues and secure
09:13 - implementation still lies
with individual teams
09:17 - and different engineering
roles who have the expertise
09:20 - in those specific areas.
09:22 - But DevSecOps creates
an overstretching process
09:26 - and automated steps
that measure what's
09:29 - called the security posture
across your systems,
09:33 - basically giving us a visibility
of how secure our systems are.
09:39 - So how does DevSecOps do this?
09:42 - Automation is the key
here as well,
09:44 - just like it is in DevOps.
So with DevSecOps,
09:47 - we automate checking
and validating all these
09:50 - layers of security
in different parts
09:53 - of the software
development lifecycle.
09:55 - And there are tools
and technologies to run
09:58 - those automated tests.
10:00 - So what are those automated
checks and where
10:02 - in the release pipeline
are they?
10:04 - Edit first we want to check
security of our code.
10:08 - Do we allow for SQL
injection because we're
10:11 - sanitizing user input?
10:13 - Are we using weak
or outdated encryption
10:17 - algorithms to encrypt
user passwords.
10:20 - So all these checks that we're
doing in our code
10:23 - to validate for any such
security
10:25 - vulnerabilities is called
static application
10:28 - security testing, or Sast,
10:31 - where various SAS tools
will validate the static
10:34 - code for any of these issues.
10:36 - So it basically scans
the code base for known
10:39 - patterns of allowing
SQL injection,
10:42 - cross-site scripting, and so on,
10:44 - and common coding mistakes
that could lead
10:47 - to such security issues.
10:50 - And in the DevSecOps
bootcamp itself,
10:51 - we cover the individual security
issue types in detail.
10:56 - So you actually understand
what a SQL injection looks like,
11:00 - what it is,
11:00 - exactly what a cross-site
scripting is,
11:03 - what client or server
side request forgery is,
11:05 - and so on.
11:06 - And we even learn how to fix
some of those issues in code.
11:10 - So instead of just having
an abstract idea,
11:12 - just in theory,
11:13 - you actually see hands on how
it looks like and how it can
11:17 - be fixed in the code itself.
11:19 - Now we also want to check our
code for any hard coded secrets.
11:23 - And this happens way too
often that developers
11:26 - forget to remove API keys
that they use for testing,
11:30 - or hardcoded passwords
for database connection, maybe.
11:34 - And they basically end
up in git repository
11:37 - in the commit history,
11:38 - and secret scanning tools can
be used to go through
11:41 - the code and identify any hard
coded secrets
11:45 - like access tokens, API keys,
or various platforms,
11:50 - any credentials, certificates,
and so on. Again,
11:54 - in the bootcamp,
11:54 - we go into detail
and learn various use
11:57 - cases of when this happen,
12:00 - as well as how to use
these tools as pre-commit
12:04 - hooks so they don't even
end up in the code repository.
12:07 - Commit history because they get
validated before the developer
12:12 - can commit the changes. Now,
apart from our own code,
12:16 - we also want to check whether
the code from other
12:19 - people that we use in our
application has any such issues,
12:23 - like libraries,
12:25 - frameworks that we're
using as dependencies.
12:28 - They are code as well, right?
That other engineers wrote.
12:31 - So those engineers may
also write insecure code
12:34 - just like our engineers.
12:36 - And this is called software
composition. And.
12:38 - Allergies or SCA.
12:40 - So we use SCA tools to scan
all our application
12:43 - dependencies for any
publicly known,
12:47 - already discovered
vulnerabilities.
12:49 - And we identify whether
we're using any outdated
12:52 - versions of third party software
with security issues.
12:57 - And again,
12:57 - here we have a whole
section in the bootcamp.
12:59 - Or explain how these
publicly known
13:02 - vulnerabilities are documented
and where are they accessible,
13:06 - how the SCA tools actually
go through these
13:08 - dependencies and identify any
issues, how to analyze them.
13:12 - Once you found that you
have such
13:14 - vulnerabilities and more
importantly,
13:16 - how to actually
fix those issues.
13:18 - Now these are all static checks.
So we're checking the code base.
13:23 - But there are some security
issues that can
13:25 - only be caught
when the application
13:27 - is actually running.
13:29 - And this is called dynamic
application
13:31 - security testing or Dest,
13:33 - which is a testing method
that basically evaluates
13:36 - a running application
to identify
13:39 - different vulnerabilities.
Again,
13:41 - this could be SQL injection
or manipulating URLs
13:44 - with different parameters
to get data
13:47 - that you are not
authorized to see.
13:49 - So the Does tools basically
send various requests
13:52 - to the application
and they observe how
13:55 - the application responds,
13:56 - what data it returns
to those requests.
14:00 - And this way they can identify
any potential security
14:03 - weaknesses in the application.
14:05 - We also want to validate
the image
14:07 - artifacts that we're producing.
Again,
14:09 - there are tools that scan
the image layers to find
14:12 - any security issues on the
container runtime level.
14:17 - For example, are we using
a root user?
14:19 - Are we using a deprecated
vulnerable
14:21 - operating system package?
14:23 - Are we using a bloated
image with lots of tools
14:25 - that we don't actually need.
14:26 - So we are increasing the attack
surface and risk unnecessarily.
14:30 - So there are all these tools
out there that help us automate
14:33 - these type of security checks.
And again,
14:36 - in DevSecOps bootcamp,
14:37 - we basically go into details
and very importantly,
14:40 - the practical application
of introducing
14:43 - and implementing those tools.
14:44 - One of those concepts
important in the practical
14:47 - usage of the tools
is managing what's
14:49 - called the false positives,
14:51 - as well as how to visualize
the scan reports
14:54 - and analyze them
in vulnerability
14:57 - management tool.
14:58 - We basically combine all
the reports from different
15:01 - tools and see what issues
you have in your application,
15:04 - with what severity levels,
15:06 - where exactly in the application
are those issues,
15:09 - and some recommended options
of how to fix those.
15:12 - Understanding what's called
the quiz and CVEs
15:16 - that are a big part
of analyzing and fixing
15:19 - the discovered issues.
15:20 - And also what's very
important to me
15:22 - is to reference the real world
projects and understanding
15:26 - wherever relevant,
15:28 - whether there is a
difference between
15:30 - how the things should work,
the theoretical part,
15:33 - and how these tools are actually
used in real life scenarios.
15:37 - Things like how to balance
the additional checks
15:40 - that increase
the pipeline duration,
15:42 - and when to run separate
nightly builds for full scans,
15:46 - for example.
15:46 - So I go into detail in this kind
of examples in the boot camp.
15:51 - So these automated security
checks are done in multiple
15:54 - phases of release and can
start as early as pre commit,
15:59 - even before the developer
has committed the code.
16:01 - And the CI CD pipeline
was triggered.
16:03 - So it gives us fast feedback
on any security issues we may
16:07 - be introducing in our systems,
16:09 - through changes in code or
in infrastructure configuration.
16:13 - This is called shifting security
to the left,
16:16 - because another important fact
is that the later
16:20 - in the release stage we discover
security issues,
16:24 - the more expensive it is
to fix it.
16:26 - So instead of reactively
fixing issues
16:28 - in production and patching them,
16:31 - we are proactively reducing
the possibility
16:34 - that they end up
in the production
16:36 - in the first place. Now,
16:38 - talking about reactively
checking for security
16:41 - issues in your systems,
16:42 - I want to give a shout
out to chef,
16:44 - the sponsor of this video,
16:46 - which is one of the important
tools for security
16:48 - and compliance automation
as part of DevSecOps.
16:52 - If you've been in DevOps
long enough,
16:54 - you probably already know
that chef
16:56 - is a well-established
and widely used
16:59 - technology in the industry.
17:01 - Chef compliance provides
packaged CIS benchmark profiles,
17:06 - and these profiles can be easily
customized to support your
17:10 - organization's specific security
and compliance requirements.
17:14 - You can schedule those
compliance scans for single
17:17 - or multiple environments,
17:19 - and you can run them
regularly or on demand
17:22 - to basically automatically
detect and notify
17:25 - about any configuration, drift,
or errors in your environments.
17:29 - For example,
17:29 - running a profile that checks
that 44 controls are set
17:34 - properly and two
of the controls fail
17:36 - because of a misconfigured.
API server dot Yaml.
17:40 - To remediate
this misconfiguration,
17:42 - chef can automatically reset
the controls to the proper
17:47 - configuration based
on the profile.
17:49 - Chef uses the concept
of cookbooks,
17:52 - which provide flexible recipes
with template and attributes
17:56 - files to specify the correct
values for the cube
18:00 - API server Yaml.
18:02 - Using a simple chef
knife command,
18:04 - we can confirm the managed
Kubernetes control plane
18:07 - has the correct cookbook
and recipe in the run list.
18:12 - When the chef compliant skin
is run again,
18:15 - the Kubernetes system meets all
of the necessary requirements.
18:20 - And by the way,
18:21 - the whole Kubernetes security
compliance checks and CIS
18:24 - benchmarks themselves
are super interesting
18:27 - topics which you also
learn with practical use
18:30 - cases in our DevSecOps bootcamp.
So as you see,
18:35 - DevSecOps is a huge exciting
topic where on top
18:38 - of the DevOps, which is already
a huge thing,
18:41 - you explicitly integrate
security implementation in your
18:45 - engineering processes. So large
processes automated.
18:49 - That means lots of tools
and concepts involved.
18:52 - So 1 or 2 hours is really just
a drop in this large
18:56 - DevSecOps ocean to learn
all about it.
19:00 - So I try to take out
this part from the entire
19:02 - DevSecOps bootcamp to teach
about the fundamentals,
19:06 - and I have carefully
created the demo to give
19:09 - you the basics to get started
and see the benefits
19:12 - of DevSecOps,
19:13 - and get the understanding
of how the entire
19:15 - DevSecOps can be implemented
in an organization.
19:19 - So now enough with the theory.
Let's get to the practical part.
19:27 - We're going to be working
19:28 - with one project
19:29 - for the entire demo,
19:31 - and that is an open source
project from OS Foundation,
19:35 - which is a Python based project.
19:37 - And this application
is intentionally vulnerable
19:41 - so that it can serve as a demo
for various security scans.
19:45 - So we can actually see
the security
19:47 - vulnerabilities discovered
by those scanning results.
19:50 - So that's the project
that we're going to use.
19:53 - Since it is Python specific,
19:54 - we're going to see how
to select and then use
19:57 - various scanning tools based
on the language or tech stack
20:01 - that an application is using.
20:03 - And in order to work
with this project,
20:05 - I actually forked the project
and made my own copy.
20:08 - So we can start from a clean
state without any
20:12 - skins whatsoever.
20:13 - So I removed all
the pipeline code,
20:15 - I made a couple of adjustments
and we can build the demo
20:20 - step by step from the start.
20:22 - And I'm going to link
both of these repositories
20:25 - in the video description.
So you can easily follow along.
20:29 - So in this demo we're going
to build a pipeline
20:31 - a release pipeline
that is going to have
20:34 - security checks
for this application.
20:37 - So we're going to build
a DevSecOps pipeline.
20:39 - And we're going to do
that with GitHub actions.
20:41 - Since we are on GitHub.
20:43 - If you don't know
GitHub actions,
20:45 - I actually already have a crash
course on GitHub actions.
20:48 - So you can watch this video
first to learn the basics
20:52 - and get some
foundational knowledge.
20:54 - Of course,
20:54 - I'm going to explain some
details as well in this video,
20:57 - but that should give
you a starting point.
20:59 - And as I said,
21:00 - I do not have any pipeline code
in this project,
21:03 - so we're going to build
it from scratch.
21:08 - So here you see we have
21:09 - a tab called actions.
21:10 - So if I go here and you actually
learn this in the crash course,
21:15 - you have some templates
that you can start with.
21:18 - So instead of writing the GitHub
actions file from scratch,
21:21 - you can just go with one
of the templates.
21:24 - And templates are based
on the tech stack
21:26 - of your application.
21:28 - And as you see
it actually detected
21:29 - what we are using
in this application.
21:31 - And it is suggesting us
to use either Python
21:35 - template or Docker image
template and so on.
21:39 - And we're actually going
to build this pipeline
21:40 - from scratch. However,
21:41 - I still want to show you how
the template will look like.
21:44 - So for example,
21:44 - if we choose a continuous
integration template
21:47 - with Pylint since we're
going to be building
21:49 - continuous integration pipeline.
21:51 - So CI pipeline actually
and if I click on configure
21:56 - this will do two things.
21:58 - First one is in my
project it will
22:00 - automatically create
a dot GitHub folder.
22:03 - So this was not there before.
22:05 - And inside that it will
create workflows folder.
22:07 - And then pylint dot Yaml file.
22:11 - So this path will be
automatically created.
22:13 - This is the location where
GitHub actions detects
22:16 - a pipeline code automatically.
22:18 - So we can automatically
trigger it and run it.
22:21 - And the second thing
is that it generates
22:24 - a boilerplate code
for the continuous
22:27 - integration pipeline. And this
is what it looks like.
22:29 - Again, if you go through my
GitHub actions tutorial you will
22:33 - understand the syntax as well.
22:35 - So basically we could take
over this template code.
22:38 - But I want to show how
to build it from scratch.
22:41 - So first of all I'm going
to rename this to main dot Yaml.
22:45 - So we're going to build multiple
steps in that pipeline.
22:49 - And second of all I'm
just going to mark all
22:51 - of these and just remove.
22:53 - So we're going to start
from scratch.
22:55 - And as you learn in the GitHub
actions course
22:58 - the application
release pipeline,
23:00 - whether it's a CI or CI,
23:01 - CD pipeline is one of the
GitHub workflows.
23:05 - That's why we have these
workflows folder.
23:07 - We can name our pipeline
workflow in our
23:10 - main dot Yaml file. So I'm going
to call it CI.
23:15 - And then we want to configure
when this pipeline
23:17 - will get triggered.
23:19 - And we wanted to get
triggered on push.
23:24 - And you can actually specify
which branches you want
23:28 - to trigger this pipeline for.
So for example,
23:30 - if I had multiple
other branches,
23:32 - except for the main,
23:34 - I can say I only want these
pipeline to trigger. For.
23:41 - A list of specific branches,
whatever that is. However,
23:44 - because this is a continuous
integration pipeline,
23:47 - it makes sense to always run it,
23:49 - no matter whether it's a main
branch or feature branch.
23:53 - So that means we can.
23:57 - Basically say whenever there
is a push in the repository,
24:00 - no matter which branch that is,
24:02 - we always want to run
this pipeline.
24:05 - And now we can start writing
or adding our jobs.
24:09 - And this is going to be
a list of security scan
24:12 - jobs that we're going to run
against our application.
24:15 - And the first one we're
going to be adding is going
24:18 - to be assessed job.
24:19 - So we're going to run static
application security
24:22 - tests on our Python application.
So let's call it Sast skin.
24:29 - And we're going to use
a tool called bandit,
24:32 - which is a popular tool
specifically for Python
24:35 - applications to run static
application security tests. Now,
24:41 - as you know already,
24:42 - I always repeat that the tools
are not
24:44 - as necessary as knowing
the concepts.
24:46 - So you could theoretically
use whatever tool you want.
24:50 - However, of course,
24:50 - when you compare the tools
and evaluate them,
24:53 - you have to consider
a couple of criteria.
24:55 - So first of all, the adoption,
right?
24:58 - If it's largely used
by a community,
25:00 - there are a lot of people
who are contributing
25:02 - to this project. If it's an open
source project,
25:05 - for example,
25:06 - then that is definitely
a plus for the project,
25:09 - because you don't want to be
one of the few engineers
25:11 - who is using a tool that nobody
else is using or knows about.
25:15 - Another one is, of course,
25:16 - how easy it is to integrate
to use the tool.
25:19 - Is there already official
Docker image for the tool?
25:22 - So basically this simple
criteria should be enough
25:25 - to decide what tool to use,
because beyond that,
25:28 - like the specific features
and so on do not matter
25:32 - as much because most of the
tools are pretty similar.
25:34 - They can be configured
in a very similar way.
25:36 - So for most common use
cases they should work
25:40 - pretty much the same.
25:41 - So bandit is a very popular
tool for Python specifically.
25:45 - And it's also pretty
easy to use and that's
25:47 - why I chose that one.
25:48 - But again you can choose
whatever you want.
25:50 - You can also choose multiple
tools for the same job.
25:53 - So you can actually
have 2 or 3 different
25:55 - tools that do sass scanning.
25:57 - And basically you can compare
the results and see
26:00 - maybe one of the tools
finds vulnerabilities
26:02 - that others were not
able to detect.
26:04 - That is a common
practice as well.
26:06 - So let's go ahead and write
our script to use bandit. Again,
26:09 - you learn in the course
that within a job you have
26:12 - multiple steps or actions
that you want
26:15 - to execute during the job.
26:17 - So let's configure all
those steps.
26:20 - So first of all let's
add a description or name.
26:24 - We are running bandit skin.
26:29 - We also want
26:30 - to specify that we want to run
26:32 - it on an ubuntu machine.
26:36 - Because then the installation
26:37 - of the tool Cetera will
26:39 - depend
26:40 - on which operating
26:41 - system we are executing
26:42 - the job or the steps on.
26:44 - So we want an Ubuntu Runtime
environment for our job,
26:48 - and now we can write
those steps.
26:53 - We're going to start by checking
26:54 - out the code, obviously.
So again,
26:58 - as you learn in the course,
26:59 - the jobs get executed on fresh
new environments,
27:04 - on GitHub hosted machines,
27:07 - and you can choose
what operating system
27:08 - that machine should have.
27:10 - And that means it's a fresh
new machine.
27:12 - It doesn't know anything
about your application.
27:14 - It doesn't have any tools
that you need
27:16 - pre-installed on them.
27:18 - So you have to explicitly
install things on it.
27:21 - Plus check out your application
code so you have that available.
27:23 - And obviously we want to scan
our application code.
27:25 - So we want to have the code
on that machine
27:28 - where the job is going
to execute.
27:30 - So check out the code and we're
going to use an action here.
27:37 - Called check out. Version two,
27:41 - and this will take care
of checking out
27:43 - our repository code.
The second step will be.
27:50 - To set up Python on this job
environment. As I said,
27:54 - no tools are pre-installed,
27:55 - so we have to explicitly install
anything that we need
27:59 - for the job.
28:00 - And we need Python because
bandit is a Python package.
28:04 - So we're going to install
it using Python's
28:06 - package manager called pip.
28:08 - So we have to install
Python first.
28:11 - Or basically prepare the Python
installation and setup.
28:16 - And again,
28:16 - for this kind of common
regular use cases
28:19 - they are actions.
28:20 - So we're going to use
one of those actions.
28:23 - That is called setup Python.
28:27 - With this version
for the action,
28:30 - and we can specify a version
of the Python
28:33 - that we want to set up use,
which is logical,
28:37 - because whenever we are
installing a tool,
28:39 - obviously we want to have
an option to specify
28:42 - which version of the tool
we want, right.
28:45 - So we're going to define
Python version 3.8.
28:50 - That's the version
we want to use.
28:51 - And by the way we can find
those actions here
28:53 - as well to see what attributes
and parameters you can use.
28:58 - So if I search for setup
Python there we go.
29:01 - This is the action.
29:02 - And you can see all
the attributes
29:05 - that you can set here.
29:07 - So Python installation
is done here.
29:09 - Now we want to actually
install bend it so we can
29:13 - execute the bended skin right.
29:15 - So as I said it's a
Python package.
29:17 - So we're going to install
it with Python's
29:20 - package manager.
29:21 - So it's going to be
install bend it.
29:25 - And for this we're going
to actually run a command
29:27 - directly on our ubuntu machine
where the job is executed
29:31 - using pip install
bandit command.
29:36 - Super easy
and straightforward right.
29:39 - And finally we want to run
the bandit
29:41 - command or bandit skin.
29:48 - With a command called bandit.
Minus R dot.
29:55 - So this basically scans
everything
29:58 - in the current folder.
30:00 - So this is a location where
we are pointing bendit to.
30:04 - We're saying everything
in this current folder.
30:06 - All the files that it contains
should be scanned recursively.
30:09 - So whatever folders
we have here,
30:12 - subfolders that contain
Python files,
30:14 - all of that should be scanned.
30:16 - Very simple and straightforward
as you see.
30:19 - And the folders or the code
that we have available has been
30:22 - checked out with the first step.
30:24 - So that means the application
code will be on the machine.
30:28 - And after installing bandit
we can just run
30:31 - bandit scan against that entire
application code.
30:35 - So it will check and scan
every single file
30:38 - in the application code
and give us the results.
30:41 - And this is how you set
up and run a security scan.
30:45 - And now we want to commit
those changes.
30:47 - And as I said because we have
this Yaml file in GitHub
30:51 - or GitHub slash
workflows folder,
30:55 - GitHub will automatically
detect this location.
30:58 - And it will know there is a
workflow to automatically
31:00 - execute on code push.
31:02 - So this will trigger our zest
scan job.
31:06 - So let's do that.
31:07 - Commit the change I'm going
to work directly in the main
31:10 - branch for simplicity
for our demo.
31:13 - So let's go ahead and do that.
31:14 - And if I switch to actions
as you see
31:17 - the workflow is already running.
It's in progress.
31:21 - So let's wait for its execution.
31:26 - So run bandit scan
job was executed.
31:30 - And if I go inside,
31:32 - we're going to see
the execution results.
31:36 - And as you see, the job failed.
31:39 - And that is good
because it means
31:41 - the bandit scan actually
found security
31:43 - vulnerabilities in our
Python application.
31:46 - And it failed the job marking
our application
31:50 - is not releasable,
31:51 - which is the purpose
of security scans. Right.
31:55 - So let's go ahead and check
out the results.
31:58 - And right here in the run
bandit scan logs you see
32:02 - the test results listed
with some detailed information.
32:07 - If I scroll all the way down,
32:09 - you see all those are possible
security issues
32:13 - that it detected.
32:14 - And right here we have a summary
that says how many
32:17 - lines of code it scanned and how
many issues it detected.
32:21 - And one helpful thing that the
tool also gives us
32:25 - is it doesn't only tell us, hey,
32:28 - there is a security issue
or possible security issue here,
32:32 - but it also marks it with
the severity level
32:35 - because not all issues
are equally
32:37 - important or equally risky.
32:40 - And that's why we need
to differentiate between them.
32:43 - So we have the severity
level that basically
32:45 - says these are some issues,
32:46 - but they are low severity
so they won't
32:49 - cause as much damage.
32:51 - And they are high
severity issues.
32:53 - So this could be a more risky,
32:55 - highly exploitable
security issue.
32:58 - And this is an important
metadata about the findings
33:01 - because as you see,
33:02 - we have way more low severity
issues than high
33:05 - severity issues.
33:07 - And in practice this creates
a lot of noise and distraction
33:11 - from the actual severe issues.
33:14 - So usually in DevSecOps
we want to configure
33:17 - the scanning tools
to only focus on high
33:20 - severity or medium
severity issues,
33:23 - especially when we are first
introducing these
33:26 - scans to the team,
33:27 - because we imagine we're going
to the developers and saying,
33:30 - now we're going to start
scanning the application,
33:32 - and if there are any
security issues,
33:33 - you have to fix them.
33:35 - And the tool finds hundreds
of security issues,
33:38 - most of them low severity level,
33:40 - so developers don't have
much value from the scan,
33:43 - and they don't know
how to handle these
33:45 - hundreds of security issues.
Right.
33:47 - So this may create a lot
of unneeded effort
33:50 - and just destruction
without bringing
33:52 - much value to the team.
33:54 - You won't be too popular
with developers if you do that.
33:58 - Instead. If you show hey,
33:59 - we ran this and it detected
two severe issues that's
34:03 - manageable for the developer
team and proves
34:05 - the usefulness of the skin
to the developers
34:08 - that aren't fully bought
in the DevSecOps concept yet,
34:12 - and the tools can be tweaked
to teach them or to configure
34:16 - them to only focus on what's
important and mature those
34:20 - tools to the level that we 100%
can rely on their findings.
34:25 - Another metadata
that we are getting
34:28 - here along with the severity
level is confidence.
34:31 - So confidence is basically
the tools level of confidence
34:35 - about the discovery itself.
34:37 - So it found a high issue
with low confidence
34:40 - means it may be an issue.
34:42 - But the tool itself
is not 100% sure
34:44 - that it detected
the issue properly.
34:47 - So it could be a false positive.
34:48 - So for example here we have
an issue
34:51 - that is medium severity.
But the confidence is low,
34:53 - which means the tool
is not actually confident
34:55 - that the issue is and actually
issue with medium severity.
35:00 - So that could be a false
positive. And as I said,
35:02 - we can configure the tool
to ignore everything that is low
35:07 - severity or low confidence
and just concentrate
35:10 - on the important findings.
35:12 - And all security scanning tools
have that configuration option.
35:16 - As I said,
35:17 - most of them work
in a similar way.
35:19 - So let's configure bandit
to ignore and not display any
35:22 - low severity issues as well
as issues with low confidence.
35:26 - And for all these tools,
of course,
35:28 - you have the official
documentation pages where
35:30 - you can see the command
options and how to tweak
35:35 - and configure those
tools to your specific
35:39 - needs for your application.
And right here, as you see,
35:43 - it has an option to configure
what level of severity
35:47 - we want to focus on and
what confidence
35:50 - level want to focus on,
35:51 - and let the tool ignore
anything else.
35:54 - So we're going to use
these options to tweak
35:57 - our bandit configuration.
36:00 - So going back to the repository
this is our workflows folder.
36:05 - And let's.
36:08 - Edit or bend it command
with this configuration.
36:11 - So basically we're going
to tell bend it to only
36:15 - focus on medium and high
level issues and only medium
36:20 - and high confidence findings.
36:22 - So we're going to add
those two options.
36:24 - So we're going to copy them.
36:27 - Add them here.
36:31 - Take this one and that's it.
36:35 - Basically that's
the configuration.
36:36 - Let's commit the changes again.
36:43 - Let the pipeline run.
36:49 - The bandits again failed again.
However,
36:51 - now let's see how many issues
it actually printed out
36:54 - so the summary stays the same.
36:55 - So we get the information
about how many issues we have.
36:59 - However, the logs themselves,
37:02 - you see we only have medium
and high severity issues
37:07 - with high or medium confidence.
Right. So our list of.
37:12 - Findings have. Decreased,
37:15 - which means this is more
manageable
37:17 - for the developers now.
37:18 - So they can actually go
through this and analyze
37:21 - those issues one by one,
37:24 - because they're just a handful
of them.
37:26 - And again, if you're just
starting out.
37:29 - So this is the very first
introduction of DevSecOps
37:31 - tools to your project team.
37:33 - You can even start with only
high security issues.
37:36 - And once you have those fixed,
then move on to medium findings.
37:40 - As the next step,
37:41 - we're going to configure
our bandit scan to produce
37:44 - a reports file and to
provide all
37:47 - the findings of the scans
in the reports file,
37:50 - instead of just displaying them
in the job logs.
37:53 - Again, we can find
that configuration here we have
37:56 - two options for that. First
of all is the output file.
38:00 - So that's going to be the name
of the report file.
38:02 - We can name it whatever we want.
38:03 - And the second one is the format
of that report.
38:07 - So you can produce reports
in multiple formats.
38:10 - This could be CSV, HTML, Json,
XML, whatever.
38:14 - And note that all of these
formats are meant
38:17 - for machine consumption
and not human consumption,
38:20 - which means there are actually
tools where you can
38:23 - upload these scanning reports,
38:25 - where you can visualize in a
nice UI and analyze your
38:28 - findings there in one place.
38:30 - And I'm going to explain
that in detail
38:32 - later in the demo. But for now,
let's produce those reports.
38:37 - So we have the findings
in the reports file.
38:39 - So we're going to export
it in Json format.
38:42 - So let's go ahead and do that.
38:44 - It's going to be
EF or format Json.
38:47 - And we're going to produce
an output. Or output file.
38:51 - And let's call this benefit
report. Dot Json.
38:56 - And as I said,
38:57 - the purpose of generating
a report file
38:59 - is so that we can take
that report's file
39:02 - that has the findings inside
and we can fit it or upload
39:06 - it to a vulnerability
management tool
39:09 - such as Defect Dojo,
39:10 - that will then consume
that file and display all
39:13 - the contents of it in a nice
UI and a nice list with all
39:17 - the information
about the finding,
39:20 - the description,
the fix recommendations,
39:22 - and so on.
39:22 - Whatever the tool
basically provides,
39:24 - which makes the analyzing
and fixing of those
39:27 - issues way easier.
And as I said,
39:29 - if you run the pipeline
multiple times a day,
39:32 - if you have multiple tools,
39:33 - you have to have a central
place where you can view
39:36 - and manage all those findings,
39:38 - or the team of developers can
view all
39:41 - those findings in one place,
39:43 - as well as compare
the findings between
39:46 - the pipeline runs
in a vulnerability
39:48 - management tool
because you can't
39:50 - manage them through the logs.
So this is a very central,
39:54 - very important part
how to upload reports
39:56 - and how to consume them,
39:58 - how to analyze those
issues in Defect Dojo,
40:01 - which is one of the most
popular vulnerability
40:04 - management tools for DevSecOps.
40:06 - And you learn all of these
in the DevSecOps bootcamp.
40:10 - So right now we are generating
the report. However,
40:13 - to make it possible to download
that report,
40:15 - we have to create an artifact
or the job artifact that will be
40:21 - uploaded for the pipeline at
the end
40:24 - of the pipeline execution.
And for that,
40:26 - we want to have another step
to upload
40:30 - that artifact and make
it available for download
40:33 - for us.
40:33 - So let's call
this upload artifact.
40:38 - And there is an action for that,
of course,
40:40 - because it's a very common use
case or common step.
40:44 - It's called upload. Artifact.
Again,
40:49 - you can check what the latest
version is.
40:53 - And we can provide the name
40:56 - of the artifact.
40:58 - So how it should be called
when it's exported.
41:01 - Let's call it banded findings.
41:03 - And of course we need to tell
it which artifact to export.
41:07 - Now, as I said,
41:08 - the jobs in GitHub actions run
on isolated,
41:11 - fresh new machines that spin
up for that specific job.
41:15 - All the steps get executed there
on that machine,
41:17 - and when the job is done,
the machine gets thrown away.
41:21 - Everything that we
generated there,
41:23 - including the reports file,
everything is gone. Right?
41:25 - So that means
we upload artifact.
41:28 - We're taking the file
that we generated
41:31 - on that machine.
41:32 - It's going to be thrown
away after the job is done.
41:35 - And we're going to say you take
that file and upload
41:38 - it as an artifact so we can have
it available
41:42 - after the pipeline has run.
41:44 - So even when the machine
is gone,
41:46 - we still have
that file available.
41:48 - So the path points to the actual
file or folder on that machine.
41:53 - And this is just what we want
to call it.
41:55 - And they will make this file
available after
41:58 - the pipeline run. However,
41:59 - there is one more thing we need
to do for this to work,
42:02 - which is the way GitHub
actions works,
42:05 - is that whenever any
step in the job fails,
42:09 - the next steps will be skipped,
right? So for example,
42:13 - if the Python installation
didn't go through
42:15 - because of whatever reason
or the bandit installation,
42:18 - so this command failed, the next
steps will be skipped.
42:21 - Which makes sense,
42:22 - because usually this is an order
of executing
42:25 - the tasks where the next step
kind of relies
42:27 - on the previous one.
42:29 - And that means when the bandit
command fails,
42:33 - which it will fail
because we have
42:35 - security issues in the job,
this will not get executed.
42:39 - However, we want the findings
or the reports file to be
42:43 - uploaded with those findings.
42:45 - So even if it fails
and that means we have
42:48 - to explicitly tell GitHub
to execute this step always,
42:53 - which means whether the previous
step fails or succeeds,
42:57 - it doesn't matter. Always
execute this last step.
43:03 - So let's commit this. And now,
when the pipeline runs,
43:09 - we should have the bandit
report dot Json
43:11 - file available there. So let's
go back to actions.
43:16 - There you go. So the job failed.
And if I scroll down here.
43:24 - You see the artifact section?
43:25 - And now we have this bandit
findings artifact.
43:28 - I can show that it was not
available for the other jobs.
43:33 - So here we don't
have the artifacts.
43:37 - And this is the Json file.
43:40 - So in the zip file there
is bandit report dot json file.
43:45 - And here we have all
the information
43:46 - about those findings.
43:47 - Additionally to was displayed
in the logs.
43:50 - So that's how it looks like.
43:51 - As I said this is
for machine consumption
43:53 - or for those vulnerability
management tools where
43:55 - you can upload the reports file
and you can
43:58 - display those results in a UI.
44:03 - Awesome. So we have scanning
for our application
44:06 - code using bandit, which does
sass scanning.
44:10 - But we also learned that not
only the application
44:13 - code or the dependency code,
44:15 - but also the application
runtime environment,
44:19 - may have security
vulnerabilities
44:21 - that will allow the hackers
to hack into our systems.
44:24 - And since in the modern
application development,
44:27 - Docker and containers
have become a standard,
44:30 - the artifacts that we
are producing
44:32 - in our release pipelines
is Docker images
44:35 - and Docker image.
44:36 - As you have probably already
learned from my Docker videos,
44:39 - you know that it's built
with layers,
44:41 - so every single image
layer may actually have
44:44 - a security vulnerability.
An image layers,
44:47 - just as a reminder,
44:48 - are basically whenever
we're using a base image.
44:51 - Could be a Linux Alpine
base image,
44:54 - which is a lightweight
operating system layer.
44:56 - And then on top of that,
44:57 - we install a bunch of other
stuff like Python
45:00 - for our Python application
image or various operating
45:05 - system packages and tools.
45:07 - All of that basically add
as layers on top of each other.
45:11 - And just like in
application code,
45:14 - we have libraries
and dependencies
45:16 - with vulnerabilities.
45:17 - We may have operating system
packages and software
45:21 - with vulnerabilities.
45:23 - So we may actually be using
outdated images like base
45:27 - images or operating system
tools with security issues.
45:31 - And the same way we want
to scan the image
45:34 - to understand how secure
is the Docker image
45:37 - that we are building
for our application.
45:40 - And we have various tools
for scanning Docker images.
45:44 - And in this demo,
45:46 - I actually chose a Docker
native tool that actually
45:50 - part of Docker itself that is
called Docker Scout,
45:54 - that goes through the image
layers and scans
45:57 - for security issues.
45:58 - And it does that actually
on multiple levels.
46:00 - So let's add a job for Docker
Scout and see
46:03 - how vulnerable or how
secure our Docker images.
46:08 - And of course,
46:09 - to be able to scan a Docker
image we need to first
46:11 - build a Docker image.
46:13 - So we're going to extend
our current CI pipeline
46:16 - to build the Docker image.
46:18 - And then we're going to scan
that newly built Docker image.
46:21 - So let's go ahead and do that.
46:23 - So right here we're
going to add a new job.
46:27 - And this job will contain
the steps for building the image
46:30 - and then scanning that image.
46:32 - Now this could be
two separate jobs.
46:33 - So for example we can push
that image
46:36 - to a Docker repository.
46:37 - And in a separate job
we can pull that image
46:39 - from the repository and scan it.
However, to make this simpler,
46:43 - we're going to have one job
where the image is built
46:45 - on that job execution machine.
So we have the image available.
46:49 - We don't have to pull
it from anywhere.
46:51 - And then on the same machine
we're going to run
46:54 - scans against that image.
46:56 - So I'm going to call
this job image scan.
47:01 - And I can
47:02 - actually just copy this.
Configuration from here.
47:08 - Let's call these build.
Image and run image scan.
47:13 - We're going to run
on ubuntu latest.
47:16 - And here we're going
to define our steps.
47:18 - The first one is again going
to be checkout
47:20 - because we need our application
code with the Docker
47:23 - file to build the Docker image.
So we have the checkout step.
47:29 - Now for this job we actually
don't need Python.
47:33 - Instead we need Docker installed
on the machine where
47:37 - the job is executing
because we're going
47:39 - to execute docker build
command to build the image
47:41 - and later Docker scout command.
47:43 - So the same way we set up Python
in this machine for this job
47:48 - here we're going
to set up Docker.
47:52 - So let's create a step.
Let's call it set up Docker.
47:57 - And let's actually search
our marketplace for the action
48:02 - to install Docker. So.
48:05 - I'm going to look for set up
Docker and let's
48:08 - see what comes out. And we have
this one here.
48:12 - This is the location
of the action.
48:15 - So basically just
going to copy that.
48:21 - And paste it here.
And as I said,
48:23 - for any actions or any
steps that are very common,
48:26 - like installing
Python or Docker,
48:28 - they are prepackaged or ready
actions that you can just
48:32 - reference from the marketplace,
48:34 - which just makes the creation
of the pipeline easier.
48:36 - But of course, alternatively,
48:37 - you can just run a command
for installing Docker as well.
48:41 - I prefer to use this action
for the setups,
48:44 - just easier cleaner code,
48:47 - especially if something changes
in the installation of the tool.
48:50 - You don't have to worry
about that.
48:52 - And then of course you have
these parameters that allows
48:55 - you to specify additional stuff.
48:57 - So for example I want
to define Docker
48:59 - version for our installation.
49:02 - And I'm going to do that with
the width attribute.
49:06 - And. This is the Docker version.
49:10 - And I'm going to set it to one
of the latest Docker versions.
49:15 - Let's do 2010 seven.
49:19 - And that makes Docker
available on our
49:22 - job environment,
49:23 - which means we can now
execute Docker commands.
49:25 - And the first command will be
to build the image.
49:31 - And for that we're going
49:32 - to simply run
49:33 - docker build command.
And you know the drill.
49:36 - We need to specify the Docker
file as a blueprint
49:40 - for building the image.
49:42 - We can also specify
the name of the image
49:45 - so we can reference it later
when we want to scan the image.
49:48 - So we can call this my
app or Pi goat or whatever.
49:52 - And we can tag it with
the latest tag.
49:54 - And then we have to specify
the build context,
49:57 - which is the location
that Docker will
49:59 - take as a build context.
50:01 - And this is going to be
the current directory
50:04 - where the application code is.
50:06 - And that's our Docker build
command. Awesome.
50:09 - The next step will be
to scan that build image
50:12 - for any security issues.
50:14 - And as I said we're going to use
Docker Scout
50:17 - from Docker itself,
50:18 - which actually does a very
thorough scanning
50:21 - of the images on multiple
layers to find
50:24 - any security issues.
50:26 - And we can actually use two
different
50:27 - commands of Docker scout.
50:29 - One of them is called
quick view.
50:31 - Quick view command will
basically show you that your
50:34 - base image is outdated,
50:36 - and it will give
you a recommendation
50:38 - of how to update it to make
your image more secure.
50:42 - And then there is a more
extensive or more thorough
50:46 - scanning that you can do
with the
50:48 - Docker Scout CVS command.
50:51 - It basically gives
you a complete view
50:52 - of all the vulnerabilities
that your image contains.
50:56 - And just like the other
tools that we've used,
50:58 - you can tweak it and configure
it to add
51:01 - additional flags
to basically limit
51:03 - that you are only
interested in certain
51:05 - severity level and so on.
51:07 - So let's go ahead and add a step
for Docker Scout commands.
51:13 - So we're going to add
a step here.
51:16 - Let's call this Docker scout.
Skin.
51:21 - And we're going to run a command
here that basically
51:24 - is a multi-line command.
51:26 - And this syntax basically
allows us to write multiple
51:29 - commands one after another
instead of just single command.
51:33 - And here we're going to first
install the Docker
51:36 - scout command line tool.
51:38 - And then we're going to execute
Docker scout commands.
51:41 - And I'm going to copy the URL
which points
51:44 - to the installation.
51:46 - So this will basically
download the installer
51:49 - for Docker scout cli.
51:51 - So install scout dot s h
file will be created locally.
51:57 - Then we can execute
that installer file
51:59 - that shell script to actually
install Docker scout.
52:02 - And here we can then execute
Docker scout commands.
52:05 - As I said we can use both
commands for a quick view
52:09 - as well as to scan the complete
image for any vulnerabilities.
52:14 - So this is actually the main
command that scans the image.
52:17 - And that's what we
are executing.
52:18 - Now let's actually try to run
this and see what happens.
52:24 - So I'm going to commit
the changes and let's actually
52:27 - see the execution result. Again.
52:29 - You see that by default these
two jobs will actually be
52:32 - executed on two
different machines.
52:35 - That saves time because these
jobs can
52:37 - be executed in parallel
instead of waiting
52:39 - for the previous
jobs to execute.
52:42 - So your pipeline
is overall faster.
52:45 - So the job is running.
Let's wait for that.
52:49 - The image is being built.
52:55 - And we can also
52:56 - check the docker file.
52:59 - So this is a pretty simple
Docker file actually.
53:01 - We just have a couple
of commands.
53:03 - So each one of those commands
basically creates a new layer.
53:06 - And we may be configuring
the Docker environment
53:10 - or installing tools
that are vulnerable
53:12 - because they're outdated.
53:13 - And those things will be scanned
with the scanning tool.
53:18 - And the Docker scout scan
failed. And you see,
53:21 - the reason for that is because
we need to log
53:24 - in to Docker to execute
Docker scout.
53:27 - So we need to authenticate
with the Docker ID
53:30 - and email address.
53:32 - So that's what we need to set
to authenticate with Docker.
53:37 - So we can execute Docker
scout commands.
53:40 - And that leads to another
interesting concept in GitHub
53:44 - actions which is project secrets
or projects environment
53:48 - variables that you can
use to basically store
53:53 - secret or sensitive data.
As you know,
53:55 - in release pipelines, CI
pipeline or CI CD pipeline,
53:59 - you have to integrate
with multiple tools, right?
54:01 - So you are maybe pushing to a
Docker registry,
54:03 - maybe you are deploying
to an environment
54:06 - and you have to connect to these
platforms with credentials.
54:10 - Right? So you need a proper
way of storing
54:13 - those credentials.
54:14 - And obviously you don't want
to hardcode them in the code.
54:18 - Right. So in the settings
of the project you have
54:21 - security section.
54:22 - And in that security section
you have secrets and variables.
54:25 - So if I open that and
open actions.
54:29 - So these are where you can
create secrets and variables
54:34 - for GitHub actions workflows.
54:37 - And we're going to create
a new repository secret.
54:39 - So basically whatever secrets
and variables we create here
54:42 - will be available
as environment variables
54:45 - in the GitHub workflows.
54:47 - So you may have multiple
workflows for GitHub actions.
54:51 - And you can use these
secret values or variables
54:55 - in all your workflows.
54:56 - So here I'm going to create
variables secret
54:59 - variables for my Docker
user and Docker password.
55:03 - So basically these are the ones
that I use
55:05 - to log into Docker Hub.
55:07 - So if you don't have an account
you can just sign
55:09 - up here and you get your
Docker ID and Docker password.
55:14 - And I'm going to call
this repo user.
55:18 - You can call this whatever
you want.
55:20 - And this is my Docker ID.
55:24 - And now I'm going to create
repo password.
55:28 - And with the value
of my Docker password.
55:33 - So those two values are here,
55:35 - which means I can now reference
them in the pipeline
55:38 - or in my workflow. So going back
let's edit.
55:42 - So before we execute
the Docker scout commands
55:46 - we need to first
log in to Docker.
55:49 - And you probably already
know docker login command
55:52 - from various of my previous
tutorials where I have
55:56 - showed this.
55:57 - So a safer login
is not to provide
55:59 - password directly with password,
56:02 - but rather read it from
the command line.
56:05 - So we're going to do echo and.
56:08 - Our password variable
and the syntax
56:11 - for referencing environment
variables or project variables,
56:15 - repository secrets or repository
variables in GitHub.
56:18 - Actions is very simply
dollar sign and double
56:22 - curly braces like this.
56:25 - And inside that you have
secrets object
56:29 - that contains all the secrets
that you have defined here.
56:35 - Like this.
56:36 - So this is referencing
the value of the password.
56:39 - And then we are piping that to
Docker login command.
56:44 - So we have the username
which again we're going
56:47 - to reference like this.
56:50 - Repo user.
56:53 - And we're going to read
this password using. Password.
56:59 - Stdin standard input.
57:03 - So this is going to read
whatever we echoed
57:06 - here and that's it.
57:07 - We don't have to provide
the repository for Docker
57:09 - login because by default
it is Docker or docker.io.
57:13 - So this login command will
automatically go
57:16 - to Docker itself. And that's it.
57:19 - We are authenticating
with Docker.
57:21 - And after that we can execute
Docker scout commands.
57:24 - So now we're going to commit
those changes.
57:27 - And we're going to see
the results of Docker
57:31 - image scan our pipeline ran.
57:33 - So now let's actually check
the logs to see the findings.
57:38 - First of all you see
that the job is green.
57:42 - Let's see what it means.
57:43 - So we have the build Docker
image a new image
57:46 - was built and then we have
Docker Scout results.
57:49 - This is the login part.
57:51 - And this is basically
an output of Docker Scout
57:55 - quick view command
which basically gives
57:58 - you an overview of what image
you're using.
58:01 - What is the base image.
58:04 - That we have defined
in our Docker file
58:06 - that we are building on top of.
58:08 - And then it also tells us
whether our base
58:11 - image is outdated,
the size of the image.
58:14 - As you know from security
best practices of Docker,
58:16 - we don't want to use bloated,
58:18 - unnecessarily large images
because it just increases
58:21 - the attack
surface unnecessarily,
58:24 - especially if we don't use
or if we don't need most
58:27 - of the tools in that image
for our application and so on.
58:31 - So this is like a
quick overview.
58:33 - And this is a more detailed
overview of analyzing the image.
58:39 - And this is the Docker
scaled CVS command.
58:42 - And here you see a whole
list of the things it found
58:47 - which are a lot of issues.
So basically.
58:51 - For different tools that we're
installing or using
58:54 - in our Docker image.
For example, this one here,
58:57 - the curl package.
59:01 - Or this package
59:02 - with this specific version
59:04 - have all these vulnerabilities.
59:05 - And this is actually similar
to the dependency scan,
59:10 - because just like you
have libraries
59:12 - in your code that have
dependencies on other
59:15 - libraries and so on.
59:16 - So you have these
transient dependencies.
59:18 - Here we have a couple of tools
that we're installing. However,
59:21 - since we're using
this as a base image,
59:23 - which depends on another
base image
59:25 - that has some tools installed,
59:27 - Docker Scout basically goes
through all these image layers,
59:31 - including whatever base
image this one is built on,
59:35 - and it looks at the tools
that not only
59:39 - the tools that we're installing
on top of this image,
59:41 - but also whatever tools
this image itself comes with.
59:45 - And that's why we have
so many issues here.
59:49 - We have a pretty large list
of vulnerabilities
59:51 - that we found,
59:52 - because it basically went
through multiple layers all
59:55 - the way to the initial image,
59:56 - and we can actually check
that ourselves as well.
59:59 - So if we look for Python
image in Docker Hub.
60:01 - So this is the official
60:06 - Python image.
60:07 - And in text we basically look
for this text specifically.
60:14 - This one right here. As you see,
60:16 - Docker Hub itself shows
you this vulnerability scan
60:20 - results for the base image,
60:23 - and this one is also supported
by Docker Scout.
60:27 - And here you see the exact
breakdown of which packages
60:32 - in this specific image
are included
60:35 - and what vulnerabilities
those packages actually have.
60:38 - And as you see we have
curl Python open SSL.
60:41 - All of these are basically
part of this.
60:43 - And the thing is if we don't
need curl for example,
60:46 - or git in that image,
60:48 - then there's no need to use
this larger image as a base.
60:52 - Instead, we can use a slimmer,
60:54 - lightweight image with a less
libraries and less libraries
60:58 - automatically means less risk
for finding vulnerabilities,
61:01 - right? And this is
the Docker file
61:04 - that is used to create
this image that installs
61:07 - all those tools and so on.
61:10 - And again you have
this differentiation
61:12 - with critical high
level medium and low
61:14 - severity vulnerabilities.
61:16 - So you can kind of prioritize
and see
61:18 - if you have critical issues
which libraries are affected
61:23 - by those critical
issues and so on.
61:25 - So that's one thing using just
smaller images.
61:29 - But also this is one
of the older versions.
61:33 - The newer version
is already at 3.13.
61:36 - So of course upgrading
to a new version often
61:39 - would mean that some
of those issues
61:40 - and vulnerabilities
were actually fixed.
61:43 - But you can also
introduce new ones.
61:46 - So we're not going to go
into the remediation part.
61:48 - But this kind of scan basically
gives you a really
61:51 - good overview of whether
you are using
61:54 - an outdated image or whether
your image is too large.
61:57 - So you have lots of libraries
and packages inside which also
62:00 - have vulnerabilities.
62:01 - So you end up with a huge
list of security issues
62:04 - in your Docker image scan.
And also as we saw,
62:07 - we have this severity level
for each security finding.
62:11 - And we have 23 critical
issues and 267 low level
62:17 - issues or low severity issues,
62:20 - which means again this creates
a lot of noise.
62:23 - Look how large the list is.
That means,
62:27 - especially at the beginning
when it's the first time
62:30 - running an image scan for your
application your engineers
62:33 - probably don't want to deal
with, in this case,
62:36 - hundreds and hundreds
of vulnerabilities and just
62:39 - fix them so you can focus
on the critical and high ones.
62:43 - And then basically step by step,
62:45 - move on to the less critical
ones. So in this case,
62:48 - again, it makes sense
to configure Docker scout
62:51 - command to only print out.
62:55 - Those two severity level issues
and basically
62:58 - ignore the other ones.
And as you see here,
63:00 - you can even use
the Docker Scout
63:01 - recommendations command to give
you suggestions of how to fix
63:06 - those issues
that were discovered.
63:09 - And one more interesting
thing that I want to draw
63:11 - your attention to is that for
the issues
63:15 - that are discovered.
So for example,
63:17 - this one right here,
apart from the CV link,
63:22 - you also have the fixed
version attribute.
63:25 - So it tells you which version
you are using which is less
63:29 - than or smaller
than this version.
63:31 - And it tells you that there
is a version
63:34 - that has this vulnerability
fixed already,
63:36 - so you can upgrade to that one
to basically get
63:39 - rid of this security issue.
63:41 - And you also see that for some
issues the fix
63:43 - has not been done yet.
63:45 - So there is no safer
version for that for now.
63:48 - But again,
63:48 - many of these apply to the low
severity issues,
63:51 - which means we can now go
back to our workflow
63:55 - and configure Docker Scout
to basically just
63:59 - ignore all of those.
64:00 - So we don't have
this overwhelming
64:02 - list of issues,
64:03 - but we can kind of filter out
and just focus on the real
64:08 - issues and have them in the
logs. However,
64:10 - before we add these
configuration
64:13 - options directly here,
64:15 - I want to show you an
alternative option
64:18 - of running Docker Scout
commands with a ready GitHub
64:21 - action from the marketplace.
64:23 - And this is another good example
to show using the ready
64:26 - actions from the marketplace.
And of course,
64:28 - the main advantage of using
actions from here
64:32 - is always that it's high level,
it's more abstract,
64:35 - and it's just easier
to configure than directly
64:38 - working with the tool.
Less flexible sometimes,
64:41 - but if you just want to run
the tool with a couple
64:44 - of parameters and configuration,
64:46 - it's basically the easiest
way to get started.
64:49 - And if I look for Docker scout.
64:52 - You'll actually see that there
is one from Docker itself.
64:55 - So this is an official action,
64:57 - which is always good to use
the official ones.
65:01 - Now obviously the installation
of Docker Scout
65:03 - itself was pretty simple,
65:05 - as well as running the Docker
scout commands,
65:07 - so there is no requirement
or need to use action
65:10 - instead for simplicity
because it's pretty
65:13 - simple already.
But generally speaking,
65:16 - these ready actions make
it easier to use any tool
65:19 - with a high level configuration
so you don't have to worry
65:22 - about installing the tool.
You know,
65:23 - making sure that these curl
link is up to date and so on.
65:27 - So I just want to switch
to this one for demonstration.
65:31 - But to make sure you guys
still see this code
65:33 - snippet in the repository
when you follow along the demo,
65:36 - I'm actually just going
to comment this out.
65:41 - And I'm just going
65:42 - to create a new step.
65:43 - And this is going to use
the action. There you go.
65:50 - So this is Docker scout
action with this version.
65:54 - And then we have a couple
of configuration options.
65:56 - Obviously we need to configure
the login
65:59 - data just like we did here.
66:00 - So for that we have Docker Hub
user and Docker Hub password.
66:05 - So we're going to do
with and then we're
66:07 - going to set all those
parameters that we need.
66:10 - So Docker Hub user is going
to be.
66:14 - Referenced like this.
66:16 - Then we have Docker
Hub password,
66:20 - and I'm just copying this stuff
so that I don't
66:22 - make any spelling mistake.
66:27 - There you go. So we have
the login data.
66:31 - And finally we have the command
because we actually have
66:35 - to execute some kind of command.
And this is a list of commands.
66:39 - So we can basically execute
multiple Docker scout commands.
66:43 - We just need two of them.
So I'm just going to.
66:47 - List them here like this
separated by comma.
66:50 - And that's it.
66:51 - So this is basically exactly
the same as this part here.
66:56 - Looks a little bit
cleaner nicer.
66:58 - That's the only difference
in terms of what they do.
67:01 - However when I execute this we
will actually see one
67:03 - more difference of using
this action instead
67:07 - of running the Docker
scout commands like this,
67:10 - which is an improvement.
67:11 - So let's commit the changes
and let's
67:14 - wait for the job execution.
Okay. So our pipeline executed.
67:20 - So this is the one with Docker
scout action.
67:24 - And this is without. And let's
compare those two.
67:27 - So this is the workflow
with Docker scout action.
67:31 - And this is without.
67:33 - So if I scroll down here
we basically have our
67:35 - artifacts and some information
like annotations.
67:39 - And when we execute
it the build image
67:43 - and scan image with the official
Docker scout action.
67:47 - If I scroll down we see these.
67:51 - Visualization of results
in the user
67:55 - interface view itself.
67:57 - So instead of having to go
and check the logs,
67:59 - we can basically see
the entire thing.
68:02 - Here we see the breakdown
of what libraries got scanned,
68:07 - how many critical, high,
68:08 - etcetera issues
each library had,
68:11 - as well as the base
image and total summary
68:14 - of the entire image scan,
68:16 - which is actually pretty nice
because this makes it way
68:20 - easier to analyze and kind
of dig in into your image
68:24 - and what libraries you're using
and what you may need to update
68:27 - to fix those issues and so on.
So for example,
68:29 - you see all these libraries
actually do not
68:31 - have any critical issues,
so you can just ignore them,
68:35 - etcetera. So it gives
you this nice overview.
68:38 - So that could be another
advantage of using
68:41 - the Scout action.
68:43 - And finally
with that configuration
68:45 - let's now tweak our Docker Scout
action to only report
68:50 - critical and high level issues.
And also in addition to that,
68:54 - we want to create this report
file that we have
68:57 - generated for other tools.
So let's do those two changes.
69:01 - I'm going to edit
this again and again.
69:04 - If we check out the official
documentation to see
69:06 - what configuration
options we have.
69:08 - But this time for the Scout
action itself.
69:11 - And again if I bring
up the Scout action.
69:16 - We're going to see all
69:17 - the configuration options here.
However, if you want,
69:19 - for example a more detailed
overview with examples
69:23 - and so on, we can also search
it online.
69:26 - So this GitHub repository
for example that has Scout
69:29 - action gives you a more detailed
description of the inputs
69:35 - for different commands.
So this one for example.
69:38 - And as I said we only
want to focus on certain
69:41 - level of severities.
69:43 - And this is option
to configure that.
69:44 - So we have only severities.
69:46 - And we can basically just
choose or provide a comma
69:49 - separated list of what severity
levels we want to focus on.
69:55 - So I'm going to copy this.
And edit here as a parameter.
70:01 - And I'm going to choose
critical and high.
70:05 - So that takes care of ignoring
all the low
70:07 - and medium level issues.
70:09 - And we also want to configure
the report file.
70:12 - And we have this sorry file
which is a specific format.
70:16 - And again if I check this here
it basically
70:19 - expects a file name.
70:21 - So we can set this parameter
as well.
70:23 - And we can call this Scout
report. Dot.
70:28 - Serif and. Of course,
70:32 - we have to upload
that artifact as well
70:34 - so that it's available after
the workflow runs. And.
70:41 - Let's call these
70:42 - Docker Scout findings.
70:45 - And of course the name
of the report.
70:48 - And that's our configuration.
70:50 - Now with this we're going
to commit the changes
70:52 - and run the workflow again.
70:57 - And now up
70:57 - to this configuration,
70:59 - we see in the scan results
that only critical and high
71:05 - level vulnerabilities
were displayed
71:08 - by the tool and the list
of libraries that were scanned.
71:12 - We see that only those
that have either
71:14 - critical or high vulnerabilities
are displayed here.
71:17 - So we don't have this huge
list anymore,
71:20 - but we have rather manageable
list right now.
71:23 - So we can even limit that only
to critical issues.
71:26 - So we would basically be
working on fixing and updating
71:30 - these libraries here. And again,
71:32 - we still see the overview on all
levels of security issues,
71:37 - including low and medium.
However,
71:39 - the specific issues are only
limited to those two,
71:44 - so it's not
overwhelming anymore.
71:46 - And additionally,
71:47 - we also have these Docker Scout
findings which were exported
71:51 - as an artifact.
71:53 - And again we can download
it and import
71:55 - it in a vulnerability
management tool
71:58 - along with other reports.
72:00 - One more optimization we can
do with Docker Scout
72:02 - is to basically fail
the job when security
72:07 - vulnerabilities are found.
And again,
72:09 - if we go back
to the documentation,
72:10 - we see there is this exit
code parameter
72:14 - that is by default set to false.
72:16 - And we can set this exit
code to non zero value
72:19 - which will be unsuccessful
or error
72:22 - result which will fail the job.
72:25 - So again let's adjust
our configuration.
72:30 - And instead of default false,
I'm going to set it to true.
72:36 - And let's commit the change.
72:42 - And wait for the result.
72:45 - And if we check
our pipeline run,
72:47 - you see that our image
scan job is also red
72:50 - because we have security
issue findings in the result.
72:55 - So we optimized that as well.
Awesome.
72:58 - So our pipeline is doing
all the static code checks,
73:02 - is scanning the image artifact
that we are building
73:05 - for any vulnerabilities.
73:07 - And we're producing these
two different scan reports.
73:10 - And when you are implementing
DevSecOps in your
73:12 - organization you have to use
vulnerability management tools,
73:16 - because otherwise
it will be really
73:18 - inconvenient and hard to analyze
and fix the security issues,
73:22 - or to basically just see
the security posture
73:26 - of your application
and of your systems
73:28 - based on the security
scans that you are doing.
73:31 - So it kind of unnecessarily
making your work harder.
73:35 - And as I said,
73:36 - there are different
vulnerability management tools.
73:38 - One of the popular ones,
which is an open source project,
73:41 - is Defect Dojo,
73:42 - which is the tool I teach
in the DevSecOps bootcamp.
73:45 - And of course, every time we run
this workflow,
73:48 - it will produce new reports.
73:50 - That means you don't want to be
manually downloading these
73:54 - reports from each
workflow execution,
73:57 - and then importing that manually
in the dojo.
74:00 - Either you want to automate
that process
74:02 - because it just happens to often
and it's a repetitive task.
74:06 - So in the DevOps bootcamp,
of course,
74:08 - we want to learn things as they
are done in production
74:12 - in a proper way.
74:13 - So actually show how to write
a Python automation
74:16 - script that takes the reports
from each pipeline
74:20 - execution and automatically
connects to the Defect Dojo API,
74:24 - and automatically uploads
and imports those
74:26 - reports in the defect dojo.
And again,
74:29 - you can group that per
application version.
74:31 - So we have a history of scan
results and see whether your
74:34 - issues are increasing over time
or as you are fixing the issues,
74:38 - or they decreasing and getting
less over time.
74:41 - The second important
point is now that we've
74:43 - discovered the issues, those
issues need to be fixed,
74:47 - right. So first of all,
who fixes those security issues?
74:51 - Is it a DevSecOps engineer?
Is it a DevOps engineer?
74:54 - Security engineer?
The application team itself.
74:57 - So who is responsible for fixing
the issues in the code,
75:01 - fixing the issues
in the libraries,
75:03 - or upgrading the library
version so we don't
75:05 - use vulnerable, unsafe
or insecure libraries?
75:10 - Who fixes the Docker
image issues and so on.
75:13 - And this is important
to understand.
75:14 - To know how DevSecOps
is implemented,
75:17 - how the responsibilities
are divided among the team
75:19 - members in a practical, actual,
real time project.
75:23 - So in the DevSecOps bootcamp,
75:25 - we go into the topic
of dividing the roles
75:28 - and responsibilities
with DevSecOps principles,
75:31 - and also how
to pragmatically approach
75:34 - this in an organization
to implement DevSecOps
75:37 - and involve all of these
other roles
75:40 - in the implementation
process as well,
75:42 - and to kind of motivate
them to join in and not
75:45 - can resist against it.
75:47 - What's also super important
is we see different
75:50 - issue types like SQL injection,
vulnerable code,
75:53 - vulnerable third
party libraries,
75:55 - and how to fix those including
the transient dependencies.
75:59 - Same with the Docker
image scanning.
76:00 - How to fix security issues
found in your Docker image.
76:04 - And here it's important
to understand
76:06 - the CVEs in dependency scanning
and image scanning.
76:09 - So we go into detail in all
of those areas and learn how
76:13 - to analyze and find such issues.
76:15 - And then of course
fix those issues.
76:18 - And we actually use
completely different
76:20 - project and completely different
application in the bootcamp.
76:23 - So these Python application
on GitHub actions
76:26 - is just to demonstrate the basic
principles in DevSecOps.
76:29 - So we are actually not
repeating anything
76:32 - from this crash course
in the DevSecOps bootcamp.
76:35 - So this should already give
you a pretty good basis
76:39 - and understanding of DevSecOps.
76:41 - So you can actually
go ahead and start
76:43 - implementing this already.
However,
76:45 - you may want to know what the
next steps would be
76:48 - that DevSecOps also
encompasses and also
76:52 - more advanced scenarios.
76:54 - Diving deeper and really
getting to the production
76:56 - grade DevSecOps processes.
So of course,
76:59 - the obvious one is that
the continuous
77:01 - deployment part comes after
that we're deploying
77:04 - to servers on an
infrastructure will
77:07 - open up another world
of security concepts
77:11 - like cloud security,
infrastructure security,
77:14 - server administration,
77:16 - secure deployment to the servers
and so on. And as you know,
77:20 - in today's world,
77:22 - no DevOps topic is complete
without Kubernetes, which again,
77:26 - is its own separate world
of various different
77:30 - concepts that are security
relevant and security related.
77:35 - So starting from security,
handling, data encryption,
77:39 - network security within
the Kubernetes cluster,
77:42 - access control management, and.
77:44 - And DevOps and ops is anyways
about automation.
77:47 - So policy is code, cloud
infrastructure is code,
77:51 - compliance is code and so on.
77:53 - So there is a ton
of concepts and tools
77:57 - and topics involved
in DevSecOps that takes
77:59 - this whole thing to a completely
new next level.
78:03 - And that's exactly why
we have a complete
78:06 - bootcamp to teach
you all of this,
78:07 - because it's a huge subject.
78:09 - It's a very interesting
but very complex skill set.
78:14 - So you need a proper guide
with easy explanations,
78:17 - with real life production use
cases and examples to become
78:22 - really good at this subject.
So all these advanced topics,
78:25 - plus the monitoring and logging
on cloud level,
78:28 - on application level,
on Kubernetes,
78:30 - cluster level
for security specifically.
78:33 - So all of that is in
the bootcamp.
78:35 - That means if you need
this for your career,
78:38 - for your position,
78:40 - or if you work at a company
and your company or your
78:43 - projects actually need this,
78:44 - then DevSecOps bootcamp
that we created gives
78:47 - you complete picture
and complete skill set
78:51 - of everything you need to learn
and know about DevSecOps.
78:55 - We worked on this for almost
two years
78:58 - and there is way more content,
79:00 - and the topics and projects
are way more
79:03 - comprehensive than anything
that you can find out there.
79:06 - So as I said,
79:07 - if this is a topic
of interest for you,
79:09 - then I definitely recommend
our DevSecOps would come
79:12 - as a next step to completely
uplevel your
79:15 - career for just a fraction
of the price of what an engineer
79:19 - with this skill set will earn.
79:21 - So definitely check out
the information about
79:24 - the bootcamp in
the video description.
79:26 - But if you just needed
to get the conceptual
79:29 - understanding of DevSecOps,
understand what it is,
79:31 - and get your first practical
experience with DevSecOps,
79:34 - then I hope I was able
to give you exactly that.
79:37 - And this will help you in
your job,
79:39 - in your project.
79:40 - I'll be very happy
about that as well.
79:42 - And if it did,
79:43 - please let me know in the
comments what you liked
79:45 - about this, what value you get
out of this,
79:48 - and as well as share
it with other engineers
79:51 - who you think will also
benefit from this knowledge.
79:54 - And with that,
79:55 - thank you for watching
Till the End and see
79:58 - you in the next video.