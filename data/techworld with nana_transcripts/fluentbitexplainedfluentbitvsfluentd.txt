00:00 - in this video we're going to talk about
00:02 - fluent bit which is a locks and metrics
00:05 - processor tool as you know all
00:08 - applications
00:09 - need logging and the main use case for
00:11 - logging is
00:12 - data analysis something breaks in the
00:14 - application you check the logs to see
00:17 - what caused the error
00:18 - or you're trying to reproduce a bug and
00:21 - by looking at the application logs
00:23 - you can understand what happened or
00:25 - simply to have an
00:26 - overview of what your application is
00:28 - doing
00:29 - logs can come from different places logs
00:32 - are produced by
00:33 - applications but also server processes
00:36 - and so on
00:36 - so you have different sources of logs
00:39 - and fluent bid
00:40 - is actually a general purpose log
00:43 - processor
00:44 - meaning it can read and process logs
00:46 - from all these different sources
00:49 - but note that in addition to collecting
00:51 - logs
00:52 - fluent bit also has metrics collection
00:55 - capabilities
00:56 - for embedded linux systems for example
00:59 - it can gather metrics on cpu
01:01 - memory storage etc and because
01:04 - its general purpose fluent bit can be
01:07 - deployed on any environment
01:09 - like bare metal servers virtual machines
01:12 - embedded devices
01:13 - and containers however fluent bit is
01:16 - used the most for processing logs in
01:20 - kubernetes clusters now the challenge of
01:23 - logging
01:23 - in complex environments like kubernetes
01:26 - is that you have
01:26 - many different applications which
01:29 - produce logs in different formats
01:31 - each application is running in
01:33 - containers
01:34 - which run in pods which then run on
01:37 - kubernetes nodes
01:39 - so in addition to the log message and
01:41 - the application name itself
01:43 - we have all this additional information
01:44 - about where the log
01:46 - is coming from so if you have five
01:49 - replicas of the same application
01:51 - you want to know which pod replica on
01:53 - which node
01:54 - produced this log this means the
01:57 - challenge is to collect these data from
01:59 - different sources
02:00 - and then process it like parse all the
02:03 - values
02:04 - and identify where they are coming from
02:07 - as well as
02:08 - what the actual log contents are and
02:10 - parse them in key value pairs
02:13 - so that they can eventually be stored in
02:15 - elastic or kafka
02:17 - so that finally we can see the logs and
02:19 - do data analysis on them so as you see
02:22 - the log processor has a very important
02:25 - but also
02:26 - challenging job now processing the data
02:28 - of course needs
02:30 - resources the log processor needs enough
02:32 - memory
02:33 - storage and cpu resources to collect the
02:36 - logs
02:37 - then parse the logs and filter them and
02:39 - this should all be done
02:40 - as a background task right it shouldn't
02:43 - interfere with your main application's
02:45 - performance
02:46 - because then we have compromised the
02:48 - speed and performance of our application
02:51 - for a proper logging mechanism and of
02:54 - course the requirement for resources
02:56 - increases when you have applications
02:58 - with high throughput
02:59 - meaning producing high amounts of locks
03:02 - so
03:03 - as you see the log processor not only
03:05 - needs to collect and process
03:07 - logs but it needs to do it in a
03:09 - performant
03:10 - and resource efficient way so we need a
03:13 - lightweight
03:14 - and high performance log processor and
03:17 - one of the most popular ones today
03:19 - happens to be fluent bit so how does
03:22 - fluent beat
03:23 - work fluent bit uses input plugins to
03:27 - read the logs from the data sources
03:29 - for example if you need to read log
03:31 - files you need a plugin to read
03:33 - from log files if you're going to
03:36 - receive messages over tcp
03:38 - you need an input plugin that listens
03:40 - for messages over tcp
03:42 - and as mentioned at the beginning fluent
03:45 - bit supports
03:46 - many different input sources fluent bit
03:48 - also has
03:49 - input plugins for metrics data
03:51 - collection for example
03:53 - it supports statsd and collect the input
03:56 - plugins
03:56 - but also supports collecting metrics on
03:59 - the host systems
04:00 - cpu memory and disk once
04:03 - logs are collected and read fluent beat
04:06 - will process them
04:07 - and of course depending on the log
04:09 - format we would need to parse them
04:11 - differently
04:12 - for that fluent beat has different
04:14 - filters
04:15 - and parsers filters can be used to
04:18 - change the log
04:19 - record or even add some additional
04:22 - metadata to it
04:23 - like pod id or namespace where the log
04:25 - is coming from and so on
04:27 - you can also use filters to drop or
04:29 - ignore some records
04:31 - to make the filtering even more flexible
04:33 - in fluent bits
04:34 - you can use custom lua scripts
04:37 - as filters to modify and process the
04:40 - records in addition to all of these
04:43 - one unique advanced feature that fluent
04:46 - bit has
04:46 - is sql stream processing this allows
04:50 - users to write sql queries
04:52 - on the logs or metrics to do
04:55 - aggregations
04:56 - calculations even time series
04:58 - predictions
04:59 - this is super useful if you need to
05:01 - calculate an average
05:02 - max or min before sending the data
05:05 - to the storage or count the number of
05:08 - times a message
05:09 - appears or aggregate data to reduce data
05:12 - costs
05:13 - the best part about the sql stream
05:15 - processing is that
05:16 - no database is required and no indices
05:19 - are required
05:19 - everything runs on the same lightweight
05:22 - high performance process
05:24 - so you still keep that high performance
05:26 - and resource efficiency of fluent bit
05:29 - after the logs are processed fluent beat
05:32 - will send them to a storage
05:34 - like elasticsearch or splunk where you
05:37 - can then see the logs in a nice
05:39 - visualized format again fluent bits
05:42 - supports
05:42 - many different storage backends and to
05:45 - send the logs to the storage backhands
05:47 - fluidbit uses output plugins so
05:51 - basically the input plugin knows how to
05:53 - transform the data of a specific format
05:56 - to what fluent bit can read and process
05:59 - so for example
06:00 - tcp input plugin knows how to parse
06:03 - tcp data into fluent bit data an
06:06 - output plugin knows how to transform the
06:09 - fluent bit data into what the
06:10 - output target understands so
06:13 - elasticsearch output plugin knows how to
06:15 - translate the fluent bit data
06:17 - into the format which elasticsearch can
06:20 - read and save
06:22 - and in fluent bit you can send logs from
06:24 - multiple
06:25 - input sources to multiple output
06:28 - destinations
06:29 - you can do this log routing pretty
06:31 - easily using tags
06:32 - you can add text to logs and then group
06:35 - them
06:36 - so that you can say parse all the logs
06:38 - with a tag that starts with
06:40 - apache with this parser or
06:43 - send all the logs that match nginx to
06:46 - elasticsearch
06:47 - now how does fluent beat actually run in
06:50 - a kubernetes cluster
06:52 - fluent bit gets deployed as a daemon set
06:55 - which means it will run on every
06:57 - kubernetes node
06:59 - so when a new node gets added to the
07:01 - cluster a fluent bit
07:03 - pod will start there immediately so on
07:06 - each node
07:07 - fluent bit will gather logs from all the
07:09 - containers on that node
07:11 - in addition it will gather metadata for
07:13 - those logs like
07:15 - pod ip container ip name space
07:18 - and so on from the kubernetes api a cool
07:21 - feature of fluent bit is that we can
07:23 - suggest
07:24 - which parsers to be used on pods using
07:28 - annotations in kubernetes configuration
07:30 - files
07:32 - some other advantages of fluent bit are
07:34 - that it has a pluggable
07:36 - architecture as a log collector it
07:38 - doesn't try to replace the data sources
07:41 - like systemd or journal d instead the
07:44 - goal is to
07:45 - integrate with different data sources
07:47 - and to do that
07:48 - fluent bit needs to be able to talk to
07:51 - tcp
07:52 - read logs from a file system talk to
07:54 - systemd
07:55 - api etc it also has built-in security
07:59 - because when you are sending logs from
08:00 - the cluster out to the storage back-ends
08:03 - you are talking to third-party services
08:05 - outside your cluster
08:07 - so of course you don't want your logs to
08:08 - be sent in plain text
08:10 - you want to use https or tls for that
08:13 - connection
08:14 - and it has a simple architecture which
08:16 - makes it easy to scale
08:18 - fluent bit on hundreds of servers
08:21 - because as i mentioned
08:22 - fluent beat will run on each node in the
08:25 - cluster
08:26 - now fluent bit works in a very similar
08:29 - way as fluentd
08:30 - which is another log processor from the
08:32 - same company
08:33 - i have a separate video on fluentd as
08:35 - well so if you know fluentd
08:37 - you may be asking what is the difference
08:40 - between these two
08:40 - if they work the same way which one
08:42 - should i use in which case
08:44 - first of all fluent beat is much more
08:47 - lightweight than fluency
08:48 - which means it's highly optimized for
08:51 - performance
08:52 - and low resource consumption compared to
08:54 - fluentd
08:56 - and as i mentioned at the beginning if
08:58 - you have a complex application
08:59 - setup which generates a lot of logs you
09:02 - want your log collector to work
09:04 - efficiently so fluent bit is designed to
09:07 - run at high scale
09:09 - with low resource usage and it's
09:11 - actually the preferred solution for
09:13 - containerized environments
09:15 - however fluent beats follows the similar
09:18 - philosophy
09:19 - as fluentd as a log processor
09:22 - but also as a matrix processor fluent
09:24 - bit is actually
09:25 - a cncf subproject under the umbrella of
09:28 - fluency
09:29 - and also they're both vendor neutral so
09:32 - they can run
09:33 - on any environment regardless the
09:34 - platform and also
09:36 - interesting to know that there are even
09:38 - use cases where you can use
09:40 - both fluent beat and fluenty together to
09:43 - create a very efficient and high
09:45 - performance
09:46 - log processing architecture for your
09:48 - environment
09:49 - now let me know in the comments what
09:51 - other technologies you want me to cover
09:53 - on my channel with that thank you for
09:55 - watching
09:56 - and see you in the next video