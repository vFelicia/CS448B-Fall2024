00:00 - in this video you will learn everything
00:02 - you need to know to get started with
00:04 - using Docker compose we'll go over what
00:07 - it is exactly what problems Docker
00:10 - compose was designed to solve its common
00:12 - use cases and of course we will do some
00:14 - Hands-On demos to learn actually using
00:17 - Docker compose in practice I am super
00:20 - excited to teach you all this so let's
00:22 - jump into
00:24 - it now in order to understand Docker
00:27 - compos you need to First understand
00:29 - docker and have some basic experience
00:31 - with it if you don't I recommend you
00:34 - pause and watch my Docker crash course
00:36 - first and then continue with this one
00:39 - because Docker compost is essentially a
00:41 - tool that is supposed to manage and work
00:44 - with Docker containers so you need to
00:46 - understand that part first so that you
00:48 - understand the context for learning
00:50 - Docker compost so in the docker video I
00:53 - break down what the containers are what
00:55 - images are what problems Docker solves
00:57 - and what use case it it has dockerizing
00:59 - your application with Docker file and
01:00 - all the concepts you need to understand
01:02 - Docker itself so based on that knowledge
01:05 - we can Now understand why Docker compos
01:06 - was created along with Docker and when
01:09 - we want to use
01:12 - it now applications are composed of many
01:16 - different parts you can have apis
01:18 - databases any Services your application
01:21 - depends on and even within the
01:23 - application you may have a microservice
01:25 - application which is basically an
01:28 - application broken down into multip
01:30 - micro applications or microservices and
01:33 - when you're creating containerized
01:35 - applications all of these different
01:37 - application components must be deployed
01:40 - and run together because they have
01:42 - dependencies on each other so basically
01:44 - you have a set of containers which are
01:47 - running different services and
01:49 - applications within them that need to
01:51 - run together that need to talk to each
01:53 - other and so on so Docker compose is
01:56 - basically a tool that allows you to
01:59 - Define and run multiple services and
02:02 - applications that belong together in one
02:05 - environment so simply put if you want to
02:07 - deploy multiple Docker containers where
02:10 - each container may have its different
02:11 - configuration options you can use Docker
02:14 - compose to do this to manage these
02:16 - containers way more easily now this is
02:19 - just a general definition to give you
02:22 - some idea of what Docker compose is but
02:25 - of course we want to understand this
02:27 - with specific examples and specific
02:30 - demonstration so that you really
02:32 - understand these Concepts and the actual
02:34 - use cases of using doer compose and not
02:38 - just a general abstract explanation of
02:41 - what it is and because of that we're
02:43 - going to jump right into that demo where
02:45 - I'm going to explain the concepts the
02:47 - use cases using those demonstrations so
02:50 - let's get
02:51 - started as a first step we're going to
02:54 - start two Services as Docker containers
02:57 - using just the docker command so we're
02:59 - not going to use Docker compos as a
03:01 - first step so we can see and compare the
03:03 - before after States first we're going to
03:05 - create a Docker Network where these two
03:07 - containers will run and talk to each
03:09 - other using just the container name and
03:11 - then we're going to start two containers
03:13 - one is going to be a mongodb container
03:16 - and another one is going to be
03:17 - Express container which is basically a
03:20 - UI for the mongodb database very simple
03:23 - use case and we're going to run both
03:25 - containers using Docker run commands so
03:27 - that's our first very simple
03:29 - demonstration let's go ahead and do that
03:31 - so I'm going to switch to a terminal
03:34 - because we're going to execute those
03:35 - docket run commands on the terminal and
03:38 - you probably see this is a fancy fun
03:40 - looking terminal that I have been using
03:43 - since recently and this is an
03:45 - application or a terminal app called
03:47 - warp which is actually a sponsor of this
03:50 - video I actually played around with warp
03:53 - and love using it it's free it's easy to
03:55 - install on your computer so I will be
03:57 - using warp throughout the entire day
03:59 - demo because it also helps highlight
04:01 - some of the commands and stuff better so
04:03 - it's going to be easier for you guys to
04:04 - follow what I'm showing you however if
04:06 - you want to install warp yourself on
04:08 - your computer you can go ahead and check
04:10 - out the link to get started in the video
04:12 - description where I'm going to provide
04:14 - all the relevant links for this crash
04:16 - course including the warp installation
04:19 - so to run our Docker containers of
04:21 - course we need to have Docker installed
04:23 - and running so I'm going to start up
04:25 - Docker and then we can start the
04:27 - containers so the docker service is up
04:30 - and running let's go ahead and create
04:33 - the docker Network first so I'm going to
04:35 - do Docker Network and since we're going
04:38 - to run mongodb and Express
04:41 - containers we can call this network
04:43 -  Network and let's create and now
04:47 - if I do Docker Network LS so basically
04:51 - list all the networks available these
04:53 - are the default ones basically that you
04:55 - get out of the box when you install
04:56 - Docker and this is the Network
04:58 - that we just created awesome so the
05:00 - network is there now let's run our two
05:03 - containers and if you know Docker if you
05:06 - followed my Docker crash course
05:08 - basically you know all this stuff Docker
05:10 - run and we're going to execute this in
05:12 - the
05:14 - background and we have the and
05:19 - Express image documentation so we can
05:21 - actually reference
05:23 - this so first I'm going to define the
05:25 - port uh mongodb's default Port is $27
05:30 - 07 so we're going to map that to the
05:34 - same port so we we're going to bind that
05:36 - to the same port on the host then we're
05:39 - going to define those two environment
05:41 - variables to basically set the admin or
05:44 - the root user and password so we're
05:46 - going to copy those and we're going to
05:49 - call this
05:56 - admin and this is some password we're
06:00 - going to set this to super secret so all
06:03 - these should be actually be a refresher
06:05 - from Docker we also want to specify that
06:08 - it should run in this network
06:11 - network so we're going to
06:13 - do
06:16 - Network run in this
06:20 - one we're also going to name our
06:22 - container instead of having Docker just
06:25 - create a random container name so we're
06:28 - going to call this
06:30 - DB and finally we need to specify the
06:34 - image right and this is the name of the
06:39 - image and that's basically our Docker
06:41 - command so I'm going to
06:44 - execute and this will fetch or pull the
06:47 - latest image from dockerhub
06:50 - repository and run it in a detached
06:57 - mode perfect so we should have have our
07:00 - mongodb container running and now let's
07:03 - start Express container and I can
07:05 - actually bring up my previous command
07:08 - and we're going to adjust it for the
07:11 -  Express right here we see that
07:14 -  Express is running on port 8080 so
07:17 - that's what we're going to set here
07:19 - there you go we also have different
07:22 - environment variables so basically
07:25 - Express is just a UI for mongodb and
07:30 - in order for us to use it it needs to
07:33 - connect and authenticate with mongodb so
07:36 - we need to provide it the credentials as
07:38 - well that we set for mongodb database
07:41 - and we're passing those also as
07:43 - environment variables but in this case
07:46 - the environment variables are named
07:47 - differently so that's what we're using
07:49 - referring to the official documentation
07:50 - which you always should do to get the
07:52 - most up toate data and you also see the
07:55 - default values for those environment
07:57 - variables the port is correct because
07:59 - that's what we binded it to on our host
08:02 - and mongod to be server which is going
08:04 - to be the mongod to be container name in
08:06 - our case it's different because we
08:07 - called our container mongod beam so
08:09 - we're going to set this environment
08:11 - variable as well so right here I'm going
08:14 - to add this and we're going to set these
08:16 - to mongodb let's not forget the
08:19 - backwards slash here so the ports are
08:22 - correct the environment variables are
08:24 - correct we are going to run it also in
08:26 - the Network we're going to name
08:28 - this Express so that's going to be
08:31 - the name of the container and let's see
08:33 - what the actual name of the image is
08:36 - just going to copy that so that I don't
08:38 - make spelling mistake and that's it
08:40 - let's execute this as
08:45 - well and seems like it started without
08:48 - any problems let's see perfect it's
08:51 - running and now to test that it was
08:54 - actually able to connect without any
08:57 - issues to the mongodb database container
09:00 - we're going to access it in our browser
09:04 - so we opened it on Port 881 on our host
09:09 - and it is asking for basic
09:10 - authentication in the browser and we can
09:13 - actually get those in the locks let's do
09:16 - that do
09:19 - logs of Express and here we have
09:23 - the credentials so admin pass should
09:28 - work
09:31 - and there you go so that's a test and a
09:34 - proof that it was able to connect to our
09:37 - database since we didn't have any
09:39 - connection errors here and we're able to
09:41 - access the application here so this was
09:44 - basically just to demonstrate how you
09:45 - would start containers that belong to
09:48 - each other so Express container
09:50 - actually depends on mongodb because we
09:53 - don't need it without the database in
09:54 - the background so kind of start
09:56 - containers that belong together that
09:58 - should run together
09:59 - using just plain Docker and also
10:02 - starting them in the same network so
10:04 - they can talk to each other in that
10:06 - isolated virtual Network now obviously
10:10 - these are just two containers but if we
10:12 - have microservice application with 10
10:14 - different services that has a messaging
10:15 - service maybe two databases that it
10:18 - belongs to maybe those databases have
10:19 - their own UI services that we want to
10:22 - run in addition so now these are lots of
10:26 - containers that we need to start and
10:28 - manage using just plain Docker commands
10:31 - and now imagine if you need to stop
10:32 - those containers because you don't want
10:34 - to have them running all the time or you
10:36 - want to make changes and restart them
10:38 - again this is going to be a lot of
10:40 - manual tedious work and you don't want
10:42 - to execute these commands all the time
10:45 - on the command line terminal especially
10:47 - when you have tens of containers so you
10:49 - want an easier way to manage to stop
10:52 - start configure containers that you want
10:55 - to start together and that's exactly
10:57 - where Docker compose comes into the
10:59 - picture so Docker compos basically makes
11:01 - running multiple Docker containers with
11:03 - all this configuration that we just
11:05 - defined on those containers so you have
11:07 - the environment variables you have ports
11:09 - maybe you have multiple ports on the
11:11 - same container same application that you
11:12 - want to open maybe you want to configure
11:15 - additional volumes for example for data
11:17 - persistence so that's the main use case
11:19 - of Docker compose so with Docker compose
11:22 - basically you have a file a yaml file
11:25 - where you define all this configuration
11:28 - a list of contain ERS or services that
11:30 - you want to start together and all their
11:32 - configuration in one central place in a
11:34 - file that you can modify configure and
11:37 - use to start and stop those containers
11:40 - so let's see how the file looks like and
11:42 - how these Docker run commands actually
11:45 - map to the docker compost so how can we
11:47 - migrate or map all of these and write a
11:50 - Docker compost file that starts those
11:53 - two containers with exactly the same
11:55 - configuration that we defined
11:57 - here
11:59 - so this is a Docker run command of the
12:01 - mongod beam that we executed previously
12:03 - so basically with Docker compos file
12:06 - what we can do is we take the whole
12:08 - command with this configuration and map
12:11 - it into a file so we have that command
12:13 - defined in a structured way so if you
12:15 - have let's say 10 20 Docker containers
12:18 - that you want to run for your
12:19 - application and they all need to talk to
12:22 - each other and interact with each other
12:24 - you can basically write all the Run
12:26 - commands for each container in a
12:28 - structured way in Docker compose and
12:30 - Define the entire configuration there
12:32 - and this is how the structure in Docker
12:35 - compose will actually look like so the
12:37 - first two lines are required attributes
12:39 - of Docker compose file with the first
12:41 - line we basically Define the version of
12:43 - Docker compose which is the latest
12:45 - version that should be compatible with
12:47 - the docker compose that you have
12:49 - installed locally so the latest Docker
12:51 - compose tool installed on your computer
12:54 - will be able to read the latest Docker
12:56 - compose file version and then we have
12:58 - the services and Docker compose is super
13:01 - simple Services is basically an
13:03 - attribute where you can list all the
13:05 - services or all the containers that you
13:07 - want to run as part of this doer compos
13:09 - file so in this case the first service
13:11 - we want to Define is mongodb and that
13:13 - Maps actually to The Container name or
13:15 - rather this is going to be part of the
13:17 - container name when the services are
13:20 - created as Docker containers and for
13:22 - each service like Mong TB we have all
13:25 - the configuration for that specific
13:27 - container so the first one is obviously
13:29 - image because we are building the
13:31 - container from the image so we need to
13:33 - know which image that container is going
13:34 - to be built from and of course you can
13:36 - specify version Tech here next to the
13:38 - name the next one is the list of ports
13:42 - because you can open multiple ports on a
13:44 - container if there are multiple
13:45 - processes running inside the container
13:47 - but mostly you would just have one so
13:49 - this is where we Define the port
13:51 - mappings so mapping a container port to
13:54 - the host so just like in Docker command
13:56 - the first Port refers to the host the
13:58 - second one refers to the port inside
14:00 - container then we have the environment
14:03 - variables listed under an environment
14:06 - attribute like this and this is actually
14:09 - how the structure of Docker compose
14:11 - looks like for one specific command now
14:14 - let's actually add the second container
14:16 - command for Express and how that
14:18 - Maps into our Docker compost file so
14:21 - again we have the service which we can
14:23 - call Express and by the way the
14:25 - service names are completely up to you
14:26 - you can call them whatever you want just
14:28 - like the container names you can call
14:30 - the containers whatever you want and
14:32 - under that Express we have the
14:35 - same exact configuration options we have
14:37 - the image which refers to Express
14:39 - image again you can have a TCH here if
14:41 - you want to have a specific one then we
14:43 - have the port and all the environment
14:45 - variables that we defined with Docker
14:48 - run command under the environment
14:49 - attribute and this is how Docker compos
14:52 - will look like with multiple Services
14:54 - defined inside so basically Docker
14:57 - compos is just a structured way to
14:59 - contain very normal common Docker
15:02 - commands and of course it's going to be
15:03 - easier for you to edit this file if you
15:06 - want to change some variables or if you
15:08 - want to change the ports or if you want
15:10 - to add more services with those services
15:13 - and as part of everything as code Trend
15:16 - dock compose is basically a code that
15:19 - defines how your services should run
15:21 - within a file that you can check in to a
15:24 - code repository and multiple people can
15:27 - work on it together
15:29 - compared to a command that you just
15:31 - execute manually on your computer with
15:33 - individual Docker run commands the final
15:35 - thing here which you may already noticed
15:38 - is the network configuration is not
15:40 - defined in the docker compost so we
15:42 - didn't map that part from the docker run
15:45 - commands so this Monga Network that we
15:47 - created we don't have to explicitly
15:49 - create or Define it in Docker compost
15:51 - because Docker compose will actually
15:54 - take care of creating a shared network
15:56 - for all the containers from from the
15:58 - services list that it's going to run
16:01 - when we execute this file so we don't
16:03 - have to create the network specifically
16:04 - and then specify that all the containers
16:07 - run in that Network Docker compose will
16:09 - automatically take care of it and we're
16:11 - actually going to see that in action
16:13 - right away so now let's actually go and
16:15 - create a Docker compos file in a code
16:18 - editor so in this projects directory so
16:21 - basically where I'm in the terminal I
16:23 - created this mongos services. yl file
16:26 - which is my Docker compos file with
16:29 - those two Services defined here so
16:31 - exactly the same code that you just saw
16:33 - we have our credentials all our
16:35 - environment variables defined and since
16:37 - this is a yl format please make sure
16:40 - that your indentations are correct
16:42 - because yl is a very simple language but
16:44 - it's very strict on indentation so the
16:47 - services need to be on the same level
16:49 - and then inside that service you need to
16:51 - have correct indentation for the
16:53 - configuration attributes so now compared
16:56 - to the docker commands it's going to be
16:57 - easier for me to go here to this file
17:00 - first of all see what services I'm
17:02 - running with what configuration edit
17:04 - those make any changes add any new
17:06 - services that I want to run and now
17:08 - let's actually execute this Docker
17:10 - compos file and see how it works back to
17:13 - my warp terminal I'm actually going to
17:16 - stop all the
17:18 - containers because we want
17:21 - to start them using Docker
17:25 - compost so that's the first one
17:29 - let's stop
17:32 - them we can actually remove
17:34 - them and we can also
17:46 - remove the dock
17:52 - Network and there you go so we have a
17:55 - clean State no containers running and
17:58 - now how do we execute a Docker compost
18:00 - file with Docker compost good news is if
18:03 - you have Docker installed on your
18:05 - computer that means you automatically
18:08 - also have Docker compose installed so
18:10 - you don't have to do that separately
18:12 - that means we should have Docker compose
18:14 - command already available as part of
18:17 - Docker and Docker compos takes one
18:20 - attribute which is the file name
18:25 - Services there you go and
18:29 - the command which is up which basically
18:31 - means go through the docker compost file
18:34 - provided here and Run start all the
18:37 - services configured right here so let's
18:40 - execute this and we're going to see the
18:43 - result awesome so now there are a couple
18:45 - of interesting things that I want to
18:47 - point out and highlight in the output
18:50 - that we got and also explain some of the
18:52 - interesting Concepts behind so let's go
18:54 - through them one by one I'm going to
18:56 - scroll all the way up to the beginning
18:58 - of the output which is right here when
19:00 - we executed Docker compose command the
19:02 - first one is I mentioned that Docker
19:05 - compose takes care of creating a
19:07 - dedicated Network for all the containers
19:10 - and here we see in the output that it
19:12 - actually created Network called projects
19:15 - uncore default so this is the name of
19:18 - the network and it's going to run those
19:20 - two containers in that Network so if I
19:23 - open another terminal and if I do Docker
19:25 - Network LS we're going to see projects
19:29 - default network was created another
19:31 - interesting thing to point out is the
19:34 - container names for those two containers
19:36 - so in the docker compose we actually
19:38 - called those services mongodb and
19:40 - Express however as you see Docker
19:43 - compose actually added a prefix projects
19:46 - and a suffix at the end to each service
19:49 - so this is basically the folder that
19:53 - contains the docker compos file where
19:55 - the docker compos file is located as you
19:57 - see right here so Docker compose always
20:00 - takes the name of the folder where the
20:03 - docker compose file is executed and it
20:06 - uses it as a prefix of the container and
20:09 - then you have one as a suffix so we have
20:12 - one instance of each container and
20:15 - that's how the containers are called and
20:16 - we can also check our
20:19 - containers and here you see the names
20:24 - projects mongodb
20:26 - 1 another interesting thing to point out
20:29 - is that you see that the logs of those
20:31 - two containers are actually mixed so we
20:34 - have the mongod be logs Express
20:36 - then mongod be
20:38 - again and so on because we're starting
20:41 - both containers at the same
20:43 - time so if you had 20 Services defined
20:46 - here they will all start at the same
20:47 - time and you will see the logs basically
20:49 - just mixed together on Startup however
20:52 - when you have multiple Services where
20:55 - some Services actually depend on the
20:57 - others in our case Express depends
21:00 - on mongodb because it cannot establish a
21:02 - connection the initial connection with
21:05 - the service until mongodb is fully up
21:08 - and running so we may have such
21:11 - dependencies or we may have an
21:12 - application our custom web application
21:15 - that also needs to connect to the
21:17 - database when we actually start the
21:19 - application to fetch some initial data
21:21 - and so on however if the database is not
21:23 - up and running when the application
21:26 - starts the application will fail with an
21:28 - error because it won't be able to
21:30 - connect to the database because it's not
21:31 - ready for the connection yet and you may
21:34 - have lots of such dependencies when
21:36 - you're running multiple Services as part
21:39 - of one application and this is something
21:41 - that you can Define in Docker compose
21:43 - with a depends on attribute so you can
21:45 - explicitly say this service actually
21:48 - needs to wait for another service or
21:51 - container to be fully up and running
21:53 - until this container is created with a
21:55 - very simple dependson attribute so
21:58 - basically we can say the express
22:01 - service depends on and we can have
22:03 - multiple dependencies so for example we
22:05 - can say an application depends on two
22:07 - different databases to start plus an
22:09 - authentication Service so all of those
22:11 - should be up and running until we start
22:13 - the application because otherwise it's
22:14 - not going to be able to connect to those
22:17 - on the initial startup so dependon takes
22:19 - a list of the services and it basically
22:23 - says wait until all the dependent
22:26 - services are fully up and run running
22:28 - before you start this service so we can
22:30 - fix it very easily using this attribute
22:34 - and now since we have both Services up
22:36 - and running again I'm going to refresh
22:39 - here and we should see Express
22:41 - accessible from the browser and we can
22:43 - actually do something here so we can
22:45 - change something in the database so for
22:47 - example I can create a mydb
22:52 - database and inside that I can create my
22:55 - collection collection I'm very bad with
22:57 - with names and not very creative so
23:00 - that's all we got we have my DB and my
23:02 - collection and this actually creates
23:04 - those in the actual mongodb database
23:08 - cool and if I go back to the terminal we
23:09 - should actually see all these change
23:11 - logs from Express and in mongodb
23:15 - basically
23:17 - logs new entries in the database that it
23:21 - created cool now what do we do if we
23:24 - want to stop those containers or maybe
23:27 - we want to change some
23:29 - configuration in do compose and restart
23:33 - those containers right now since we have
23:35 - the dock compos process running in the
23:37 - terminal we're going to need to do
23:39 - contrl c to basically break out of the
23:42 - process and this is going to stop both
23:44 - of the containers however just like with
23:46 - Docker run commands we have the detached
23:48 - mode we can actually run Docker compose
23:52 - in the detached mode like this so we'll
23:56 - start the containers in the background
23:58 - however now if we want to stop the
23:59 - containers we could stop them using
24:01 - Docker stop
24:04 - commands and providing the ID of the
24:07 - container however again if we have 20
24:10 - containers running this is not going to
24:12 - be a efficient way to do it and with do
24:15 - compose it's also very simple
24:20 - actually instead of up we do down and
24:23 - what this will do if we have 20 Services
24:25 - defined here that are running as
24:27 - containers
24:28 - it's going to go through all of those
24:30 - and it will actually not only stop those
24:33 - containers but also remove them so now
24:35 - if I do Docker PS a so this shows
24:41 - running and stopped containers so all
24:43 - the containers in any state you see that
24:45 - we have no containers because they have
24:47 - been removed completely and you also see
24:50 - the network itself was removed so
24:52 - basically with Docker composed down you
24:55 - have a very easy way to clean up the
24:57 - entire state so you don't have any
24:59 - leftovers of containers and networks
25:01 - that you created previously everything
25:03 - will be completely removed however when
25:06 - you're running containers and when you
25:08 - make changes like we did in the database
25:10 - for testing you may want to retain those
25:13 - changes the state or the data in those
25:16 - containers so you don't want to
25:17 - completely remove the containers you
25:19 - just want to stop them and then restart
25:21 - them and as you've learned in the docker
25:23 - crash course containers are ephemeral
25:26 - they have no persistence so all the data
25:28 - is gone when you remove the container
25:31 - because by default it doesn't have any
25:32 - persistence unless you configure that
25:35 - persistence with volumes however if you
25:38 - just stop the containers and restart
25:40 - them you will still have the state and
25:42 - data because the container itself was
25:43 - not removed it actually stayed locally
25:46 - so to demonstrate that let's do up
25:50 - again and with Docker compos you can
25:53 - execute stop command which simply stops
25:55 - the containers and if I do docker PSA
25:58 - you see that the containers are still
26:01 - available locally they're just not
26:02 - running they're in an exited
26:06 - status and we can start them again using
26:10 - Docker compose start
26:13 - command and if we refresh our mydb
26:17 - database and collection are gone we can
26:20 - create them
26:24 - again like
26:26 - this
26:31 - we can restart using Docker compose and
26:34 - the data should still be there so that's
26:36 - basically the difference between up and
26:38 - down commands compared to start and stop
26:41 - and obviously both have their different
26:43 - use cases and one more thing since we
26:46 - are executing Docker compose
26:48 - commands very
26:50 - often like this one for example we can
26:53 - actually go ahead and bookmark this like
26:56 - this
26:59 - so if we have too many commands in the
27:02 - history for example and if we are
27:04 - scrolling around which basically creates
27:06 - this visual marker and you can just
27:09 - click inside and it jumps directly to
27:11 - that command we can then copy that
27:14 - command and execute here perfect so now
27:18 - before we move on to the next part of
27:21 - this demo where we connect our own
27:24 - custom application to the mongodb
27:26 - database and run it also as part of
27:29 - Docker compos service let's go to the
27:33 - database and in our new collection let's
27:36 - actually create a new document that our
27:39 - application is going to need it's going
27:41 - to be a very simple document let's add
27:44 - two more attributes here so we're going
27:46 - to have let's call this my ID again as
27:49 - you see I'm very uncreative with names
27:52 - so this is going to be an ID that we can
27:55 - reference in addition to this generated
27:58 - ID and then we're going to have the
27:59 - actual data which is going to be a
28:01 - string and we're just going to write
28:03 - here some Dynamic data loaded from DB so
28:08 - when we load this from our application
28:10 - we know that it's coming from the
28:12 - database so I'm going to save this
28:14 - document in the collection you see it
28:16 - was created here here are the values the
28:18 - generated ID my ID literally my ID and
28:22 - this data um text okay and we're going
28:26 - to make this a little bit more
28:28 - interesting so we're going to use a
28:30 - custom JavaScript application which is a
28:32 - super simple application with just one
28:34 - file that simply connects to the mongodb
28:37 - database and displays the data in the
28:39 - browser so we can see some of the
28:42 - concepts in action and we're going to
28:44 - containerize our JavaScript application
28:47 - and run it as part of the docker compos
28:50 - services and of course I'm going to
28:52 - provide the link to the git repository
28:54 - where this JavaScript application is
28:56 - hosted in the the video description so
28:58 - you can just clone it locally to follow
29:01 - along and by the way you will also find
29:03 - the docker compost file in that
29:05 - repository so all the code that we write
29:07 - in this demo will be
29:10 - there so I have cloned my own
29:12 - application locally in the
29:15 - projects I've called it Docker compos
29:17 - crash course so let's switch inside and
29:22 - to show you how simple the application
29:24 - is I have opened it in the visual studio
29:26 - code so I don't have the docker compos
29:28 - here yet this is the entire application
29:31 - we basically have the server JS which is
29:33 - a node.js backend and index.html which
29:37 - has the style the JavaScript code which
29:40 - is basically just one function and the
29:43 - HTML code in one file so the simplest
29:47 - app ever created so first of all you
29:49 - don't need to understand any part of
29:52 - this code we're just going to
29:53 - concentrate on the configuration and the
29:56 - dockerization part part of this app so
29:58 - even if it's simple app you don't need
30:00 - to understand the code but just to run
30:02 - through the logic on a high level this
30:05 - backand basically connects to the
30:07 - database logic we have this index.html
30:10 - file which shows two lines of data we
30:13 - have some static data which is hardcoded
30:16 - in the file itself and then we have data
30:20 - that is supposed to come from a database
30:23 - so this is empty so we're going to set
30:25 - it dynamically from the data that we get
30:28 - from the database which is going to be
30:31 - this data right here and the way we do
30:34 - that
30:35 - is in this JavaScript section when we
30:38 - load this index HTML page it basically
30:42 - the front end basically sends a request
30:45 - to our server JS backand and it says
30:48 - fetch the data and in server JS we
30:52 - accept that request right here we
30:56 - connect to the database base using this
30:58 - logic right here and now that we are
31:01 - using my DB and my collection as the
31:04 - database and collection name that's why
31:06 - we created them in the database and it
31:09 - connects to this collection and it
31:11 - basically grabs the element that has
31:15 - this key value pair inside my ID one so
31:18 - it's going to get this data here from
31:21 - the collection and it's going to send
31:23 - that the whole object back to the front
31:26 - end as a response and then we're going
31:28 - to grab the data attribute from that
31:32 - response that's the data this is the
31:34 - value of the data and we're going to set
31:36 - it as the value for this second line so
31:39 - that's how the whole thing is going to
31:40 - work and in order to connect to the
31:43 - database because remember we actually
31:45 - set username and password on mongodb so
31:47 - our application needs to have that same
31:49 - username and password just like the
31:52 -  Express container had to have
31:55 - those credentials so we are providing
31:57 - those also as environment variables so
32:00 - just like Express had to receive
32:03 - those values as environment variables
32:05 - our application is also going to receive
32:07 - those as environment variables with
32:10 - these names so Mong to be username M Tob
32:13 - password and we use those to connect to
32:15 - the database that's the entire logic so
32:17 - now our goal is to take this application
32:20 - to build a Docker container out of it
32:23 - using the docker file blueprint which is
32:25 - right here also very simple simple
32:27 - because it's a nodejs application we use
32:29 - node as a base image uh we basically
32:32 - take the code that we have here in the
32:34 - app folder we copy it into the image we
32:38 - run npm install to download the
32:40 - dependencies inside the
32:43 - image and then we just start the
32:46 - application using node command which
32:48 - comes from here and server.js file which
32:52 - is this file right
32:54 - here so it starts the application on
32:57 - Port 3000 and logs this as a first log
33:01 - of the
33:02 - application so we want to use Docker
33:05 - file and again you learn Docker file in
33:08 - the docker crash course how to use it so
33:10 - all this should be familiar to you so we
33:12 - want to build our custom JavaScript
33:15 - application as a container and run it as
33:18 - part of Docker compose along with
33:21 - mongodb and Express Services
33:24 - that's the goal how do we do that first
33:26 - of all we need to copy that Docker
33:28 - compos that we created into this
33:31 - application code and remember another
33:33 - interesting point to highlight here
33:35 - Docker compose is part of the
33:37 - application code so developers work on
33:39 - Docker compose just like they work on
33:41 - Docker file and other parts of the
33:42 - application code which is the best
33:44 - practice to have all this logic together
33:46 - in one repository instead of scripts and
33:49 - commands spread on laptops and computers
33:52 - of different developers everything is in
33:54 - a central place so we created the
33:57 - this Docker compose file in the projects
34:01 - folder and we want to copy this into
34:03 - this folder so let's do a simple
34:11 - copy there you go
34:15 - and here we have our Services yl.
34:19 - compost file and as I said we want to
34:22 - add our application as a third service
34:26 - which is going to run as a container
34:28 - service but we don't have the image yet
34:30 - so we need to build the image as well in
34:32 - do compost what you can actually do you
34:35 - can Define both in one configuration so
34:38 - we can build and then start the
34:40 - container with Docker compose so right
34:43 - here I'm going to add the service for
34:45 - our nodejs application and let's call
34:48 - this my app because great with names and
34:53 - instead of image because we want to
34:55 - build that image first we're going to
34:57 - Simply provide build attribute and the
35:01 - build context which is current directory
35:03 - and this basically points to where the
35:06 - docker file is located as well as the
35:09 - entire build context for that image and
35:12 - the rest of the configuration is going
35:14 - to be the same as for other services so
35:17 - we have the ports in our case we're
35:19 - starting this application on Port 3000
35:22 - so that's what we're going to Define
35:25 - right here so Port 3000 inside the
35:27 - container we're going to bind it on
35:29 - 3,000 on our host and as we saw we have
35:32 - the environment variables defined here
35:35 - as well so we need to set
35:39 - those so that our application will be
35:42 - able to connect to the database using
35:45 - those credentials and that's basically
35:48 - the entire configuration this will build
35:51 - our node.js application image using
35:55 - Docker file as a blueprint for the image
35:58 - and it will start it as a container on
36:01 - this port and pass in those environment
36:03 - variables that our application will read
36:06 - here and use it to connect to the
36:08 - database now we don't have to configure
36:11 - depend on here because the application
36:13 - doesn't actually connect to the database
36:15 - when it starts up so this is the startup
36:18 - logic so here we don't have any
36:20 - connection it only connects to the
36:22 - database when we load the application in
36:25 - the front end in the browser this
36:27 - function gets executed or this script
36:29 - gets
36:30 - executed and because of that we don't
36:32 - need to do depends on here and now let's
36:37 - go back to the terminal let's first of
36:39 - all see whether we have containers
36:43 - running let's get
36:45 - our Command to stop those containers so
36:49 - we're not going to remove them because
36:50 - we need the database collection and the
36:53 - data inside for our application and now
36:56 - I'm going to go into the docker compose
36:59 - crash course folder where we have the
37:01 - new Docker compose and I'm going to
37:05 - execute Docker compose up and let's
37:10 - execute and as you see it is actually
37:12 - building the new Docker image from the
37:15 - Noe base image and that was actually
37:18 - pretty fast and now we should have all
37:20 - three containers running let's check
37:24 - that and we have really bad names for
37:27 - our containers because the name of the
37:29 - folder is very descriptive large name
37:33 - which was used as a prefix for
37:35 - containers but that's fine and this were
37:38 - created from scratch so
37:43 - our previous
37:46 - containers with this prefix are not
37:49 - actually running instead it created the
37:51 - new ones and that brings me to another
37:54 - concept which is you can actually over
37:56 - IDE the value that is used as a prefix
37:59 - so maybe you want to reuse the same
38:02 - containers but you have moved the docker
38:04 - compost file to another location so
38:06 - let's
38:10 - actually remove those containers that we
38:13 - just
38:14 - started like
38:18 - this so now we only have those two and
38:22 - the way we can
38:24 - override is use using a flag on Docker
38:28 - compose so we can add an additional flag
38:32 - here minus P or also
38:37 - project name so essentially the name of
38:39 - the folder is assumed to be the project
38:42 - name so we can overwrite that project
38:44 - name value using this flag and we can
38:47 - call this projects which was the
38:50 - previous one like this and let's start
38:53 - the
38:54 - container let's do drps as you see our
38:59 - old instances of mongodb and
39:03 - Express were restarted instead of new
39:05 - ones being created plus the network
39:08 - called projects default that was already
39:10 - there and that means if I refresh this
39:16 - we still have our MB and my collection
39:19 - and the data inside for our application
39:22 - which means if I visit the application
39:24 - on Local Host 3000 which should see our
39:28 - awesome
39:30 - application and Let me refresh this once
39:33 - again so we can see the network traffic
39:35 - here we refresh so this was the fetch
39:38 - data
39:40 - request which we execute right here that
39:44 - basically returns this
39:48 - object that we created here from in the
39:51 - database back to the front end so if we
39:55 - go to preview or our response we see
39:58 - this object with my ID one this is the
40:02 - ID from the database and the
40:05 - data some Dynamic data loaded from DB
40:09 - and we're using that to set this line
40:13 - right here so if I actually went there
40:15 - and changed
40:18 - this like this and let save I'm going to
40:22 - refresh
40:23 - again you see that now we get this
40:26 - updated data from the database so the
40:29 - entire connection Works our application
40:31 - is connected to the database and
40:34 - displays that information right here now
40:37 - I mentioned that dock compose is part of
40:40 - the application code which means it gets
40:43 - committed and stored in a git
40:46 - repository so that everyone can work on
40:48 - it it's available for the entire team if
40:51 - a new engineer joins the team and they
40:53 - download the code they have docu compos
40:55 - so they know know exactly what services
40:57 - are running as part of that application
40:59 - and they can easily start that locally
41:01 - however that also means that it's really
41:04 - bad that we are hardcoding our secret
41:08 - credentials in the docker compost file
41:10 - because the best practice for security
41:13 - is that you shouldn't hardcode any
41:15 - sensitive data in the application code
41:18 - so it doesn't end up in the git
41:20 - repository and even if you remove it
41:22 - later if you accidentally checked it in
41:25 - and removed it it's still going to in
41:26 - the commit history so you shouldn't have
41:28 - any hardcoded values here so how do we
41:31 - solve this because we need those
41:32 - credentials to be passed on to Services
41:35 - well for that we can actually use
41:36 - variables or placeholders in Docker
41:39 - compost instead of the actual values and
41:42 - we can set the values of those variables
41:45 - as environment variables on the
41:46 - operating system so let's see how it
41:48 - works first of all we're going to remove
41:50 - all those hard-coded values and instead
41:52 - we're going to define the variables in
41:55 - Docker compos which has a syntax of
41:58 - dollar sign and then curly braces and
42:00 - inside that we can name the variable
42:02 - whatever we want I'm going to call this
42:04 -  admin user because it's the admin
42:07 - user in mongod to be and by the way this
42:09 - could be lowercase you can call this
42:12 - really what you want but I'm using a
42:14 - standard environment variable name
42:16 - convention here with all upper cases so
42:19 - we have the admin user let's call this
42:21 - admin pass for password and we're going
42:25 - to reuse use those
42:31 - everywhere which is another advantage of
42:33 - using variables because if you change
42:35 - those values like if you change the
42:37 - password value for example you just have
42:39 - to change it or set it once and it
42:41 - automatically gets updated everywhere so
42:43 - now this do compost does not have any
42:45 - hardcoded sensitive data and it's safe
42:48 - to check it in the G repository however
42:51 - we still need to set those actual values
42:55 - so to test that let's go back to the
42:57 - terminal first of all I'm going to stop
43:03 - those stop the containers so we can test
43:06 - that everything works and on the first
43:08 - Docker compos command execution we get a
43:10 - warning that says the variables are not
43:13 - set the containers were stopped however
43:15 - we need to set those as variables in our
43:19 - terminal session
43:21 - so we set them here export admin
43:25 - user
43:27 - let's set the other
43:32 - one like this and the same way as we did
43:37 - with up command we actually need to
43:39 - specify which containers we're stopping
43:41 - so by default it's going to look for
43:43 - containers that start with this name the
43:46 - name of the folder so we need to
43:47 - overwrite that projects tag
43:50 - again and there you go and I'm actually
43:53 - going to bookmark this one as well
44:01 - like
44:04 - this and if we
44:06 - refresh we should see that the pages are
44:09 - not working because the containers are
44:11 - stopped and then let's start them
44:15 - again and if we start them again with
44:17 - those environment variables
44:21 - set everything should
44:23 - work same as before
44:26 - let's wait there you go now I want to
44:29 - mention here that Docker compos actually
44:30 - has a concept of Secrets which is
44:34 - another functionality to manage the
44:35 - secrets especially when you're running
44:37 - do compos in a production environment
44:39 - which is exactly for this use case where
44:42 - you need to pass in credentials or any
44:43 - sensitive data to the services defined
44:47 - in Docker compose so you can use Docker
44:49 - compose Secrets as an alternative to
44:51 - this method basically awesome we have
44:53 - just learned the fundamentals of docker
44:55 - compose and more importantly you
44:57 - understand its core use case and by the
45:00 - way I want to highlight the importance
45:02 - of learning tools like Docker and Docker
45:04 - compos or generally cloud and devops
45:07 - Technologies because nowadays it is
45:09 - becoming more and more needed for
45:11 - software developers to learn those tools
45:13 - to become more valuable in their roles
45:16 - especially in the current tense job
45:18 - market where we have layoffs and
45:20 - companies hiring less as more and more
45:22 - companies are adopting devops it is a
45:25 - great way to Stand Out Among developers
45:28 - who only focus on programming and are
45:31 - not interested to learn new Concepts and
45:33 - tools that are being adopted in the
45:35 - industry so I think it's definitely more
45:37 - important than ever to educate yourself
45:40 - keep learning and with devops or Cloud
45:42 - engineering skills you will definitely
45:43 - be ahead of 90% of developers in fact
45:47 - most of our devop boot camp students are
45:50 - actually software developers or software
45:51 - Engineers since many companies do not
45:54 - have a separate devops engineer role but
45:57 - often their responsibility lies on
45:59 - senior developers to set up the devops
46:01 - processes like release pipelines for
46:03 - example so even if you are a junior
46:06 - software engineer learning devops and
46:08 - Cloud skills and technologies will
46:10 - absolutely accelerate your career to a
46:13 - senior engineer so if you want to get a
46:15 - complete education on devops to take
46:18 - over devops tasks at your work then
46:21 - definitely check out our devops boot
46:23 - camp you will learn various Technologies
46:25 - from zero to an advanced level to be
46:28 - able to build real world Davos processes
46:32 - at your job and if you need some
46:33 - guidance before you can also contact us
46:36 - there with your questions so check out
46:38 - the information below and let's move on
46:40 - to the next
46:42 - part so now we are building and running
46:44 - our JavaScript application as a
46:46 - container along with mongodb service and
46:50 - the mongodb UI but usually that's a
46:52 - testing environment as you learn in the
46:54 - docker crash course eventually you want
46:56 - the JavaScript application your custom
46:58 - application container to be stored
47:01 - centrally in a Docker registry or rather
47:04 - the image to be stored in Docker
47:06 - registry so we can start and deploy it
47:07 - as a container on the end environment on
47:10 - a actual deployment server where end
47:12 - users will access it so we need to build
47:14 - the image and push that to the
47:16 - repository like a dockerhub repository
47:19 - or whatever other Docker repository want
47:22 - and now the interesting question is
47:24 - after we push the image to private
47:25 - Docker repository how do we reference
47:28 - our Custom Image from our private Docker
47:31 - repository in Docker compose and also
47:34 - note that when we run this on an actual
47:37 - deployment server we're going to copy
47:40 - the docker compose on that server where
47:42 - we have Docker and Docker compose
47:43 - installed and when we run this Docker
47:45 - compost file or execute this it will go
47:47 - through all the services and it will
47:49 - pull all the images defined here and run
47:51 - them as containers with all this
47:52 - configuration so we pull the official
47:54 - images from docker H public repository
47:57 - and any custom images from the private
48:00 - repositories so let's actually see how
48:02 - it works it's actually very very easy
48:04 - and again building image pushing it to
48:07 - the repository the whole thing you
48:08 - should already know it from the docker
48:09 - course so this should be a refresher for
48:12 - you so let's actually see that in action
48:15 - right here so first of all I'm going to
48:17 - log into my dockerhub
48:19 - account and I'm actually going to create
48:21 - a new private repository in dockerhub
48:24 - like this
48:26 - let's call this my app because it's
48:28 - generic I may use it for some other
48:31 - demonstration later
48:33 - so there you go and now we're going to
48:38 - build our image using the docker file
48:42 - and we're going to push that image to
48:44 - this specific private
48:46 - repository so let's execute those
48:48 - commands I'm going to build using Docker
48:51 - build command I'm going to tag this and
48:53 - this is again a refresher from Docker
48:56 - course we need to take the image with
48:59 - the name of the repository so that
49:01 - Docker knows on push command which
49:03 - repository to push that image to so
49:06 - that's going to be the entire name so
49:08 - the image name itself includes the
49:11 - repository name and we're just going to
49:13 - tag it with a simple
49:15 - 1.0 and we need to provide the build
49:18 - context which is the current directory
49:20 - where Docker file is located and that's
49:22 - basically it let's
49:24 - execute again
49:26 - super first let's list all the images so
49:30 - we can see what we have built locally
49:32 - and there you go this is our image with
49:35 - an image tag and this is exactly the
49:38 - image we want to push now to the private
49:41 - reposer and you know when we want to
49:43 - push or pull from a private repository
49:45 - we need to be logged in to that
49:47 - repository so we need to do Docker login
49:50 - and the username is actually your
49:53 - dockerhub username name and dockerhub
49:59 - user password and this is actually
50:02 - different for other Docker repositories
50:05 - so if you have a ECR or some other
50:08 - Docker repository the process may be
50:10 - different with dockerhub it's very
50:12 - simple that's why I use it for the demos
50:14 - mostly so we are now logged in to
50:17 - dockerhub and what I can do now is
50:22 - basically push that image that we just
50:24 - created
50:26 - using simple Docker push and the image
50:29 - full name with the
50:32 - tag and there you
50:35 - go and if I refresh we should see one
50:40 - tag here 1.0 for our my app image
50:44 - repository perfect and one thing I
50:46 - wanted to show you here is that whenever
50:49 - you are building and pushing an image
50:51 - you basically have the same commands all
50:53 - the time for the specific action you
50:56 - build the image you log in if you're not
50:58 - logged in already you push the image and
51:00 - so on and I have actually used a feature
51:03 - called workflows in workp for these kind
51:05 - of use cases which can be really helpful
51:08 - if you want to if you have a set of
51:09 - commands that you always need for the
51:12 - same type of workflow you can basically
51:14 - Define that as one unit so you can group
51:17 - those commands in one unit called the
51:20 - workflow and you can save it here and
51:23 - whenever you need that you can just
51:25 - execute all those commands with one
51:26 - click which I personally found super
51:29 - cool so in warp drive you have some
51:32 - options here you create a new
51:34 - workflow and I'm going to call this
51:37 - Docker push and here you can list the
51:40 - different commands basically so let's do
51:43 - Docker login and we have
51:46 - username which was this one right here
51:49 - and obviously we don't want to provide a
51:51 - password hardcoded here so we're going
51:53 - to pass that as very
51:56 - variable or
52:00 - argument and we're going to read that
52:03 - from the standard input again this is a
52:05 - refresher from Docker this is how should
52:08 - use Docker login so you don't type in
52:09 - the password directly and with worp you
52:13 - can actually use
52:15 - arguments like this so whenever you run
52:18 - this command or list of commands before
52:21 - it runs it will actually tell you how
52:22 - you should fill out this argument so
52:24 - we're going to use an AR arent here and
52:26 - then after Docker login we're going to
52:27 - do Docker build like we
52:31 - did with an image
52:34 - tag we can also make this an argument
52:38 - let's make this an argument number two
52:41 - and then push
52:45 - that like this you can also set default
52:48 - values let's actually do 1.0
52:51 - here and this way you don't have to type
52:54 - out all the commands for the same
52:56 - workflow so let me check all these
52:59 - commands so we need a build context at
53:01 - the end and the rest looks pretty good
53:05 - and let's save the workflow and the way
53:06 - it works is now I have the workflow
53:09 - right
53:10 - here and whenever I need that workflow
53:13 - to execute I just click on it and it
53:17 - fills out the terminal basically with
53:19 - all these commands and it highlights the
53:22 - the arguments that I need to set so I'm
53:24 - actually going
53:25 - to put my password here as an argument
53:30 - and then let's say we want 1.1 as a
53:33 - second argument and we can execute all
53:36 - the commands like this and this will
53:38 - actually have pushed another tag with
53:41 - 1.1 so this is a cool feature that you
53:43 - can use on warp to make your life a
53:45 - little bit more convenient and that
53:48 - means now we have our image with two
53:50 - different Texs in a private
53:54 - Repository and now if we go back to the
53:57 - dock compost we don't need to build it
53:59 - locally we can again this is convenient
54:02 - for testing because when you're testing
54:05 - on a local environment as a software
54:06 - developer as an engineer you may want to
54:08 - just do very quick local changes in a
54:11 - Docker file or in application test it
54:13 - quickly and you don't want to be
54:15 - building and pushing and pulling image
54:18 - all the time so this is a very good
54:21 - functionality for local testing however
54:23 - on an end environment obviously we need
54:25 - to Define an image that comes from a
54:28 - repository maybe we have scanned that
54:30 - image already and made sure that it's
54:32 - secure and properly configured and so on
54:35 - and now we want to actually use it and
54:38 - how do we reference our Custom Image
54:40 - from a private repository in Docker
54:42 - compose very
54:44 - simple basically do it just like any
54:47 - other image in dockerhub or any other
54:49 - repository like this with a specific
54:52 - image tag that is available let's do 1.0
54:55 - and how will Docker compos be able to
54:57 - pull that image from a private
54:59 - repository or basically authenticate
55:01 - with the private repository to pull the
55:03 - image it actually uses the same Docker
55:05 - login that we use to do Docker push so
55:09 - Docker login basically creates after
55:11 - successful login authentication with the
55:14 - docker Hub it actually creates a Docker
55:17 - Json file locally that creates the
55:20 - authentication credentials or tokens in
55:23 - that file and Docker compos in the
55:25 - background is using Docker to run those
55:28 - containers so it's going to be the exact
55:29 - same process pulling or pushing the
55:31 - images from Docker compose so that means
55:35 - if you have done Docker login already to
55:37 - that repository then you should be able
55:39 - to pull any images defined in Docker
55:42 - compose from that repository that means
55:45 - that's the configuration this should
55:47 - work now in order to test that let's
55:50 - actually
55:52 - stop our containers
56:02 - so they're all stopped and I'm actually
56:04 - going to remove the application
56:07 - container because we want to simulate
56:09 - that the container is recreated from the
56:12 - new image that we
56:14 - pull and now if we
56:22 - do up again in DET mode
56:26 - and as you see my app image was pulled
56:31 - and the container my app was started
56:34 - from that if we check the running
56:37 - containers we see that this is the image
56:40 - that was used to create this container
56:45 - awesome and again we can check that our
56:48 - application still works and there you go
56:51 - that's how we can reference our Custom
56:55 - Image from a Docker repository in the
56:58 - docker compose and in case when you're
57:01 - executing those commands so let's say
57:03 - we're doing Docker build and you forget
57:06 - one of the arguments or use a wrong flag
57:10 - and so
57:11 - on first of all you get an error but you
57:14 - can also do a troubleshooting feature
57:17 - within the terminal to actually give you
57:21 - a pretty good tips and notes on what the
57:24 - error actually is because sometimes we
57:27 - make spelling mistakes sometimes we
57:28 - forget an argument or whatever so it
57:31 - could be helpful for a tool to actually
57:33 - tell you what the actual problem is so
57:35 - you can fix it and warp has this AI
57:38 - assistant which is pretty cool so for
57:41 - this specific error if I open this warp
57:44 - AI which you can see on every command
57:47 - block so you have this bookmark and you
57:49 - have this warp AI so if I click on this
57:53 - it actually autog generates the question
57:54 - question because it knows that this is
57:57 - an error and you can ask it how to fix
58:00 - it so you can modify your question or
58:03 - example and if I hit enter here it gives
58:06 - me an answer that the docker build
58:08 - command requires an argument which
58:10 - should be the path to the docker file
58:12 - and gives me an example with the correct
58:14 - one so change the directory that has
58:16 - Docker file and then execute this
58:19 - command which has dot at the end so I
58:21 - found this feature also pretty cool
58:23 - which means if any of the commands give
58:25 - you an error while you're following this
58:28 - demo you can actually use this to find
58:31 - out what the error is about and and
58:33 - ideally how to fix it so this is going
58:35 - to help you troubleshoot your issues and
58:38 - finally I want to actually add a few
58:40 - very interesting and important Concepts
58:43 - regarding docu compose and kind of what
58:46 - the next steps are so this final small
58:49 - section may be really really interesting
58:51 - for you so basically as you see the main
58:53 - use case of Docker composed was to have
58:55 - a central place to manage containers
58:58 - that were supposed to run together like
59:00 - your application and all the services
59:02 - that it depends on and we configure all
59:04 - the environment variables or any other
59:06 - configuration for those services in that
59:09 - one file and also start them in one
59:11 - isolated Docker Network and it makes it
59:14 - super easy for us to clean up all the
59:16 - resources so Engineers took Docker and
59:19 - they containerized their applications to
59:21 - a whole new scale that was not a
59:24 - standard before and Docker was
59:26 - especially perfect to use as a host for
59:29 - microservice applications where you have
59:32 - even more applications and more
59:34 - containers now running in one
59:36 - environment and again if you don't know
59:38 - about microservices I have a separate
59:39 - video about them but essentially it's
59:42 - when you have all the services needed to
59:44 - run one application but split into
59:47 - separate micro applications or services
59:49 - and they can be scaled independently and
59:52 - run independently as independent
59:53 - containers so Docker was a perfect host
59:56 - for that so we ended up with lots of
59:59 - applications lots of microservices
60:01 - applications with hundreds or thousands
60:03 - or tens of thousands of containers that
60:06 - is pretty much a standard nowadays such
60:09 - a scale actually led to Docker compost
60:12 - actually not being able to handle such
60:16 - large scale of containers and more
60:18 - importantly Engineers will have to still
60:20 - manually manage running and operating
60:22 - those containers with do compose like if
60:25 - containers die or crash or have
60:27 - connectivity issues ETC you have to
60:30 - manually detect and then debug and
60:32 - restart the services now Docker compose
60:34 - actually made some improvements on that
60:35 - there tags like restart and so on but
60:38 - it's still a lot of operational effort
60:41 - to run the containers with this kind of
60:44 - scale where you have thousands of them
60:46 - using Docker compose and that's where
60:49 - kubernetes kind of came into the picture
60:51 - to solve exactly these two main issues
60:54 - initially scaling to thousands or tens
60:57 - of thousands of containers with
60:59 - kubernetes you can basically merge
61:00 - hundreds of servers into one huge server
61:03 - to deploy all the containers that belong
61:05 - to the same application in that
61:07 - environment they will all run as if they
61:09 - were running on the same server so it
61:10 - naturally makes it easier to scale your
61:12 - applications and to run thousands of
61:15 - instances and the second one was the
61:17 - automatic operations or making the
61:19 - operations of applications easier or
61:21 - also called kubernetes Auto healing
61:23 - feature which basically manages starting
61:26 - and restarting containers if they crash
61:29 - and has mechanisms to manage operations
61:31 - of a large number of containers in an
61:33 - automated way when manual effort isn't
61:36 - it's just impossible or not feasible
61:38 - anymore and that led to C is becoming so
61:41 - popular so Docker compose is kind of
61:44 - like a intermediary step if you have
61:46 - smaller set of containers but with
61:49 - today's standards when you want to work
61:51 - with very complex applications with a
61:53 - large scale then Docker compose has its
61:56 - limits so that's where kubernetes
61:58 - basically comes into the picture so if
62:00 - you're learning this containerized
62:02 - containerization and container
62:04 - orchestration Concepts then I would
62:06 - actually recommend to use this road map
62:08 - of learning the docker using the docker
62:11 - crash course then learning the docker
62:13 - compose with this course like you did
62:16 - and then you can move on to the
62:17 - kubernetes and if you want to learn
62:19 - kubernetes I also very conveniently have
62:21 - a kubernetes crash course to get you
62:23 - started in kubernetes very easily so if
62:26 - you want to get started with that you
62:28 - can check out any of the many videos
62:30 - that I have on my YouTube channel but I
62:32 - would recommend to start with the
62:34 - kubernetes crash course so I hope you
62:36 - learned a lot of new Concepts you
62:38 - obviously learned Docker compose as a
62:40 - new tool new technology thank you for
62:43 - watching till the end let me know in the
62:45 - comments how this video actually helped
62:47 - you in your work or maybe in your job
62:49 - application I'm always happy to hear and
62:52 - read that feedback from our viewers to
62:54 - know that my videos are helpful in
62:56 - actual job environment you can also
62:59 - share any other tips and learnings about
63:02 - dock compose that you have from your
63:03 - practical experience so that other
63:06 - viewers can read and benefit from it as
63:08 - well and with that thank you for
63:10 - watching and see you in the next video