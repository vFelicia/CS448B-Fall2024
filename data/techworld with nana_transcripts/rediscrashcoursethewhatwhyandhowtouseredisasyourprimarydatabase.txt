00:00 - in this video we're going to talk about
00:02 - redis and how redis can be used as a
00:04 - primary database for complex
00:06 - applications that need to store data in
00:09 - multiple formats first we will see what
00:12 - redis is and its usages as well as
00:15 - why it is suitable for modern complex
00:18 - microservice applications we will talk
00:20 - about how redi supports storing multiple
00:23 - data formats for different purposes
00:26 - through its modules next we will see how
00:29 - redis as an in-memory database can
00:31 - persist data and recover from data loss
00:34 - we'll also talk about how redis
00:36 - optimizes memory storage cost using
00:40 - redis on flash
00:42 - then we will see very interesting use
00:43 - cases of scaling readies and replicating
00:46 - it across multiple geographic regions
00:50 - and finally since one of the most
00:52 - popular platforms for running
00:54 - microservices is kubernetes and since
00:57 - running stateful applications in
00:59 - kubernetes is a bit challenging we will
01:02 - see how you can easily run redis on
01:04 - kubernetes i'm proud to say that i have
01:07 - partnered up with redis to make this
01:09 - video so big thanks to redis for
01:11 - sponsoring and making this video
01:13 - possible
01:15 - now first of all redis which actually
01:17 - stands for remote dictionary server is
01:21 - an in-memory database
01:24 - so many people have used it as a cache
01:26 - on top of other databases to improve the
01:29 - application performance however what
01:31 - many people don't know is that redis is
01:34 - a fully fledged primary database that
01:36 - can be used to store and persist
01:39 - multiple data formats for complex
01:41 - applications let's see the use cases and
01:44 - examples for that let's look at a common
01:46 - setup for a microservices application
01:49 - let's say we have a complex social media
01:52 - application with millions of users and
01:55 - let's say our microservices application
01:58 - uses a relational database like mysql to
02:01 - store the data
02:02 - in addition because we are collecting
02:05 - tons of data daily we have an
02:07 - elasticsearch database for fast
02:10 - filtering and searching the data
02:12 - now the users are all connected to each
02:15 - other so we need a graph database to
02:17 - represent these connections
02:19 - plus our application has a lot of media
02:21 - content that users share with each other
02:24 - daily
02:25 - and for that we have a document database
02:28 - and finally for a better performance for
02:30 - the application we have a cache service
02:33 - that caches the data from other
02:35 - databases and makes it accessible faster
02:39 - now it's obvious that this is a pretty
02:42 - complex setup but let's see what are the
02:44 - challenges of this setup
02:47 - first of all all these data services
02:49 - need to be deployed run and maintained
02:52 - right this means your team needs to have
02:54 - some kind of knowledge on how to
02:57 - operate all these data services
02:59 - plus of course for high availability and
03:02 - better performance you would want to
03:04 - scale your services and each of these
03:06 - data services scales differently has
03:09 - different infrastructure requirements
03:11 - and that could be an additional
03:13 - challenge so overall using multiple data
03:15 - services for your application increases
03:19 - the effort of maintaining your whole
03:21 - application setup of course as an easier
03:24 - alternative to running and managing the
03:26 - services yourself you can use the
03:28 - managed data services from cloud
03:31 - providers but this could be very
03:33 - expensive because on cloud platforms you
03:36 - pay for each managed data service
03:38 - separately
03:40 - now on the development side your
03:41 - application code also gets pretty
03:44 - complex because you need to talk to
03:46 - multiple data services and for each
03:49 - service you would need a separate
03:51 - connector and separate logic and this of
03:54 - course makes testing your applications
03:57 - also quite challenging
03:59 - and finally the more number of services
04:01 - that talk to each other the higher the
04:03 - latency because even though each service
04:06 - may be fast on its own
04:09 - each connection step between the
04:11 - services or each network hub will add
04:14 - some latency to your application
04:16 - in comparison with a multi-modal
04:19 - database like redis you resolve most of
04:22 - these challenges first of all you run
04:24 - and maintain just one data service so
04:27 - your application also needs to talk to a
04:29 - single data store and that requires only
04:31 - one programmatic interface for that data
04:34 - service and latency will be reduced by
04:37 - going to a single data endpoint and
04:39 - eliminating
04:40 - several internal network hubs so having
04:44 - one database like redis that allows you
04:47 - to store different types of data or
04:49 - basically allows you to have multiple
04:52 - types of databases in one as well as act
04:55 - as a cache solves such challenges
04:58 - so let's see how redis actually works
05:01 - first of all how does ready support
05:04 - multiple data formats in a single
05:06 - database
05:07 - the way it works is that you have ready
05:09 - score which is a key value store that
05:12 - already supports storing multiple types
05:14 - of data and then you can extend that
05:16 - core with what's called modules for
05:19 - different data types which your
05:21 - application needs for different purposes
05:23 - so for example ready search for search
05:26 - functionality like elasticsearch or
05:29 - redis graph for graph data storage and
05:31 - so on and a great thing about this is
05:34 - that it's modular so these different
05:36 - types of database functionalities are
05:39 - not tightly integrated into one database
05:42 - as in many other multi-modal databases
05:45 - but rather you can pick and choose
05:47 - exactly which data service functionality
05:50 - you need for your application
05:52 - and then basically add that module and
05:54 - of course when using redis as a primary
05:56 - database you don't need an additional
05:58 - cache because you have that
06:00 - automatically out of the box with redis
06:02 - that means again less complexity in your
06:05 - application
06:06 - because you don't need to implement
06:09 - the logic for managing populating and
06:12 - invalidating cache and finally as an
06:14 - in-memory database redis is of course
06:17 - super fast and performant which of
06:19 - course makes the application itself
06:21 - faster but in addition it also makes
06:25 - running the application tests way faster
06:28 - as well because radius doesn't need a
06:30 - schema like other databases so it
06:32 - doesn't need time to initialize the
06:34 - database and build the schema and so on
06:37 - before running the tests so you can
06:40 - start with an empty redis database every
06:42 - time and generate data for tests as you
06:45 - need and fast tests can really increase
06:47 - your development productivity
06:52 - okay great so we understood how redis
06:54 - works and all its benefits but at this
06:57 - point you may be wondering how can an
07:00 - in-memory database persist data because
07:03 - if the redis process or the server on
07:05 - which redis is running fails all the
07:08 - data in memory is gone right and if i
07:10 - lose the data how can i recover it so
07:13 - basically how can i be confident that my
07:15 - data is safe well the simplest way to
07:18 - have data backups is by replicating
07:21 - redis so if the redis master instance
07:24 - goes down the replicas will still be
07:26 - running and have all the data so if you
07:28 - have a replicated redis the replicas
07:30 - will have the data but of course if all
07:33 - the radius instances go down you will
07:35 - lose the data because there will be no
07:38 - replica remaining so we need real
07:40 - persistence
07:42 - well redis has multiple mechanisms for
07:44 - persisting the data and keeping the data
07:46 - safe first one the snapshots which you
07:50 - can configure based on time number of
07:52 - requests etc so snapshots of your data
07:55 - will be stored on a disk which you can
07:58 - use to recover your data if the whole
08:01 - radius database is gone but note that
08:03 - you will lose the last minutes of data
08:05 - because you usually do snapshotting
08:07 - every five minutes or an hour depending
08:10 - on your needs so as an alternative redis
08:13 - uses something called aof which stands
08:16 - for append only file in this case every
08:20 - change is saved to the disk for
08:22 - persistence continuously and when
08:24 - restarting redis or after an outage
08:27 - redis will replay the append only file
08:30 - locks to rebuild the state so aof is
08:34 - more durable but can be slower than
08:36 - snapshotting
08:38 - and of course you can also use a
08:40 - combination of both aof and snapshots
08:43 - where the append only file is persisting
08:45 - data from memory to disk continuously
08:48 - plus you have regular snapshots in
08:50 - between to save the data state in case
08:52 - you need to recover it this means that
08:54 - even if the redis database itself
08:57 - or the servers the underlying
08:59 - infrastructure where redis is running
09:02 - all fail you still have all your data
09:04 - safe and you can easily recreate and
09:07 - restart a new redis database with all
09:10 - the data
09:11 - now a very interesting question is
09:14 - where is that persistent storage so
09:16 - where is that disk which holds your
09:19 - snapshots and the append only file locks
09:22 - located are they on the same servers
09:24 - where redis is running well this
09:27 - question actually leads us to the trend
09:29 - or a best practice of data persistence
09:31 - in cloud environments which is that it's
09:34 - always better to separate the servers
09:36 - that run your application and data
09:39 - services
09:40 - from the persistent storage that stores
09:43 - your data so with a specific example if
09:46 - your applications and services run in
09:49 - the cloud on let's say aws ec2 instance
09:53 - you should use ebs or elastic block
09:57 - storage to persist your data instead of
09:59 - storing them on the ec2 instances hard
10:02 - drive for example because if that ec2
10:05 - instance died you won't have access to
10:07 - any of its storage whether it's ram or
10:10 - disk storage or whatever so if you want
10:13 - persistence and durability for your data
10:16 - you must put your data outside the
10:18 - instances on an external network storage
10:21 - as a result by separating these two if
10:25 - the server instance fails or if all the
10:27 - instances fail you still have the disk
10:30 - and all the data on it unaffected you
10:32 - just spin up other instances and take
10:34 - the data from the ebs and that's it and
10:37 - this makes your infrastructure way
10:39 - easier to manage because each server is
10:42 - equal you don't have any special servers
10:44 - with any special data or files on it so
10:47 - you don't care if you lose your whole
10:49 - infrastructure because you can just
10:51 - recreate a new one and pull the data
10:53 - from a separate storage and you're good
10:55 - to go again
10:56 - so going back to redis example
10:59 - ready service will be running on the
11:01 - servers and using server ram to store
11:04 - the data
11:05 - while the append only file logs and
11:08 - snapshots will be persisted on a disk
11:11 - outside those servers making your data
11:13 - more durable
11:17 - great now we know you can persist data
11:20 - with redis for durability and recovery
11:24 - while using ram or memory storage for
11:27 - great performance and speed
11:29 - so the question you may have here is
11:32 - isn't storing data in memory expensive
11:35 - so you would need more servers compared
11:37 - to a database that stores data on disk
11:40 - simply because memory is limited in size
11:43 - so there's a trade-off between the cost
11:45 - and performance well redis actually has
11:48 - a way to optimize this using a service
11:51 - called redis on flash which is part of
11:55 - redis enterprise so how does this work
11:58 - it's a pretty simple concept actually
12:00 - redison flash extends the rem to the
12:03 - flash drive or ssd where frequently used
12:06 - values are stored in rem and the
12:09 - infrequently used ones are stored on ssd
12:12 - so for redis it's just more ram on the
12:15 - server and this means
12:17 - that redis can use more of the
12:19 - underlying infrastructure or the
12:21 - underlying server resources by using
12:23 - both ram and ssd drive to store the data
12:27 - increasing the storage capacity on each
12:29 - server and this way saving you
12:32 - infrastructure costs
12:37 - all right so we've talked about data
12:39 - storage for redis database and how it
12:41 - all works including the best practices
12:44 - now another very interesting topic is
12:47 - how do we scale a redis database
12:50 - let's say my one oneredice instance runs
12:52 - out of memory so data becomes too large
12:55 - to hold in memory or radius becomes a
12:58 - bottleneck and can't handle any more
13:00 - requests in such case how do i increase
13:03 - the capacity
13:05 - and memory size for my redis database
13:09 - we have several options for that first
13:11 - of all ready supports clustering which
13:14 - means you can have a primary or master
13:17 - redis instance
13:18 - which can be used to read and write data
13:22 - and you can have multiple replicas of
13:25 - that primary instance for reading the
13:27 - data this way you can scale red is to
13:30 - handle more requests and in addition
13:32 - increase the high availability of your
13:35 - database because if master fails one of
13:38 - the replicas can take over and your
13:41 - radius database basically can continue
13:44 - functioning without any issues
13:46 - now these replicas will all hold copies
13:50 - of the data of the primary instance so
13:52 - the more replicas you have the more
13:55 - memory space you need and one server may
13:58 - not have sufficient memory for all your
14:01 - replicas plus if you have all the
14:03 - replicas on one server and that server
14:06 - fails
14:07 - your whole radius database is gone and
14:09 - you will have a downtime instead you
14:11 - want to distribute these replicas among
14:13 - multiple nodes or servers so for example
14:17 - your master instance will be on one node
14:19 - and two replicas on other two nodes
14:23 - well that seems good enough
14:25 - but what if your data set grows too
14:27 - large to fit in a memory on a single
14:30 - server plus we have scaled the reads in
14:34 - the database so all the requests that
14:36 - basically just query the data but our
14:39 - master instance is still alone and still
14:42 - has to handle all the rights so what is
14:45 - the solution here for that we use the
14:48 - concept of sharding which is a general
14:50 - concept in databases and which redis
14:54 - also supports
14:55 - so sharding basically means that you
14:58 - take your complete data set and divide
15:01 - it into smaller chunks or subsets of
15:04 - data where each shard is responsible for
15:07 - its own subset of data
15:09 - so that means instead of having one
15:11 - master instance that handles all the
15:14 - writes to the complete data set
15:16 - you can split it into let's say four
15:18 - shards
15:19 - each of them responsible for reads and
15:22 - writes to a subset of the data and each
15:26 - shard also needs less memory capacity
15:29 - because they just have a fourth of the
15:31 - data
15:32 - this means you can distribute and run
15:34 - charts on smaller nodes and basically
15:37 - scale your cluster horizontally and of
15:39 - course as your data set grows and as you
15:43 - need even more resources you can reshart
15:46 - your radius database which basically
15:48 - means you just
15:49 - split your data in even smaller chunks
15:52 - and create more shards
15:54 - so having multiple nodes which run
15:57 - multiple replicas of redis which are all
16:00 - sharded gives you a very performant
16:02 - highly available redis database that can
16:05 - handle much more requests without
16:07 - creating any bottlenecks now i have to
16:10 - note here that this setup is great but
16:12 - of course you would need to manage it
16:15 - yourself do the scaling add notes do the
16:18 - sharding and then resharting etc so for
16:20 - some teams that are more focused on the
16:23 - application development and more
16:25 - business logic rather than running and
16:27 - maintaining data services this could be
16:30 - a lot of unwanted effort so as an easier
16:33 - alternative in redis enterprise you get
16:35 - this kind of setup automatically because
16:38 - the scaling sharding and so on is all
16:40 - managed for you
16:42 - now let's consider another interesting
16:44 - scenario for applications that need even
16:47 - higher availability and performance
16:50 - across multiple geographic locations so
16:53 - let's say we have this replicated
16:55 - sharded redis database cluster in one
16:58 - region in the data center of london
17:01 - europe but we have the two following use
17:04 - cases
17:05 - first our users are geographically
17:08 - distributed so they are accessing the
17:11 - application from all over the world so
17:13 - we want to distribute our application
17:15 - and data services globally
17:18 - close to the users to give our users
17:21 - better performance and second if the
17:24 - complete data center in london europe
17:27 - for example
17:28 - goes down we want an immediate switch
17:31 - over to another data center so that the
17:34 - ready service stays available in other
17:37 - words we want replicas of the whole
17:39 - redis cluster in data centers in
17:42 - multiple geographic locations or regions
17:46 - this means a single data should be
17:48 - replicated to many clusters spread
17:51 - across multiple regions
17:53 - with each cluster being fully able to
17:56 - accept reads and writes
17:58 - so in that case you would have multiple
18:01 - redis clusters
18:02 - that will act as local redis instances
18:06 - in each region and the data will be
18:09 - synced across these geographically
18:11 - distributed clusters
18:13 - this is a feature available in redis
18:15 - enterprise and is called active active
18:18 - deployment because you have multiple
18:20 - active databases in different locations
18:22 - so with this setup we'll have lower
18:25 - latency for the users
18:27 - and even if the redis database in one
18:30 - region completely goes down the other
18:32 - regions will be unaffected and if the
18:35 - connection or syncing between the
18:37 - regions breaks for a short time because
18:40 - of some network problem for example
18:42 - the reddish clusters in these regions
18:45 - can update the data independently and
18:48 - once connection is re-established they
18:50 - can sync up those changes again now of
18:53 - course when you hear that the first
18:55 - question that may pop up in your mind is
18:58 - how does redis resolve the changes in
19:01 - multiple regions to the same data set so
19:04 - if the same data changed in multiple
19:06 - regions how does radies make sure that
19:08 - data changes of any region isn't lost
19:12 - and data is correctly synced and how
19:14 - does it ensure data consistency
19:16 - specifically for that redis enterprise
19:19 - uses a concept called crdts which stands
19:23 - for
19:24 - conflict-free
19:26 - replicated data types and this concept
19:28 - is used to resolve any conflicts
19:31 - automatically at the database level and
19:34 - without any data loss so basically redis
19:37 - itself has a mechanism for merging the
19:40 - changes which were made to the same data
19:42 - set from multiple sources in a way that
19:46 - none of the data changes are lost and
19:48 - any conflicts are properly resolved and
19:52 - since as you learned ready supports
19:54 - multiple data types for each data type
19:57 - they use its own data conflict
19:59 - resolution rules which are the most
20:01 - optimal for that specific data type
20:04 - so simply put instead of just overriding
20:06 - the changes of one source
20:09 - and just discarding all the others all
20:12 - the parallel changes are kept and
20:14 - intelligently resolved
20:17 - and again this is automatically done for
20:19 - you with this active active
20:21 - geo-replication feature so you don't
20:23 - need to worry about that and the last
20:25 - topic i want to address with redis is
20:28 - running redis in kubernetes as i said
20:31 - redis is a great fit for complex
20:33 - microservices that need to support
20:36 - multiple data types and that need an
20:39 - easy scaling of a database without
20:41 - worrying about data consistency
20:44 - and we also know that the new standard
20:46 - for running microservices is the
20:48 - kubernetes platform so running redis in
20:51 - kubernetes is a very interesting and
20:53 - common use case so how does that work
20:56 - with open source redis you can deploy
20:58 - replicated redis as a help chart or
21:01 - kubernetes manifest files and basically
21:03 - using the replication and scaling rules
21:06 - that we already talked about
21:08 - set up and run a highly available redis
21:11 - database
21:12 - the only difference would be that the
21:14 - hosts where redis will run will be
21:17 - kubernetes pods instead of for example
21:19 - ec2 instances or any other
21:22 - physical or virtual servers but the same
21:25 - sharding replicating and scaling
21:28 - concepts apply here as well when you
21:30 - want to run redis cluster in kubernetes
21:33 - and you would basically have to manage
21:35 - that setup yourself
21:37 - however as i mentioned many teams don't
21:40 - want to have the effort of maintaining
21:43 - these third-party services because they
21:45 - rather invest their time and resources
21:48 - in application development or other
21:50 - tasks so having an easier alternative is
21:53 - important here as well so redis
21:56 - enterprise has a managed redis cluster
21:59 - which you can deploy as a kubernetes
22:00 - operator if you don't know operators
22:03 - operator in kubernetes is basically a
22:05 - concept where you can bundle all the
22:08 - resources
22:10 - needed to operate a certain application
22:12 - or service so that you don't have to
22:15 - manage it yourself or you don't have to
22:17 - operate it yourself
22:19 - so instead of a human operating a
22:21 - database you basically have all this
22:23 - logic in an automated form to operate a
22:26 - database for you and many databases have
22:29 - operators for kubernetes and each such
22:32 - operator has of course its own logic
22:34 - based on who wrote them and how they
22:37 - wrote them
22:38 - the redis enterprise on kubernetes
22:40 - operator specifically
22:42 - automates deployment and configuration
22:45 - of the whole radius database in your
22:47 - kubernetes cluster it also takes care of
22:50 - scaling doing the backups and recovering
22:52 - the redis cluster if needed etc so it
22:55 - takes over the complete operation of
22:58 - radius cluster inside the kubernetes
23:00 - cluster well i hope you learned a lot in
23:02 - this video and that i was able to answer
23:05 - many of your questions if you want to
23:07 - try redis enterprise cloud be sure to
23:10 - check out my special link in the video
23:12 - description for a 200 credit and if you
23:15 - want to learn more similar technologies
23:17 - and concepts then make sure to subscribe
23:19 - to my channel because i make videos
23:22 - regularly about different devops and
23:24 - cloud technologies also comment below if
23:27 - you have any questions regarding reddis
23:30 - or any new topic suggestions and with
23:32 - that thank you for watching and see you
23:35 - in the next video