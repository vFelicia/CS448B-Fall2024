in this lesson we will try to analyze time complexity of recursive implementation of fibonacci sequence in an earlier lesson we had shown how and why recursive implementation of fibonacci sequence a simple recursive implementation of fibonacci sequence is lot costlier than iterative implementation where we simply write the loop let's try to deduce it mathematically as we know fibonacci sequence is a sequence in which the first two elements are zero and one and all other elements are sum of previous two elements and a recursive program to find an element in the sequence goes something like this if n is less than or equal to one which accounts for the first two elements in the sequence we simply return n else we make two recursive calls to calculate fib of n 1 and fib of n 2 sum them up and return the value let's say time taken to calculate fib of n is T(n) now when we try to analyze time complexity of programs we make an assumption that each simple operation takes one unit of time so if we call this method fib of n for n greater than one then first we perform a compassion here with one which is one unit of cost let's say one unit of cost is there for comparison and because it is greater than one so it goes to the else conditioned control of the program and here we make two recursive calls where we pass arguments n 1 and n 2. Sowe make two subtractions so there is one unit of cost for this subtraction and one unit of cost for this subtraction and then one unit of cost for this addition so for n greater than one there are four simple operations, two subtractions one addition and one comparision now time taken to calculate fib of n can be calculated as time taken to calculate fib of n minus one which is T (n 1) plus time taken to calculate fib of n 2 which is T( n 2) plus 4 units of time for these simple operations if n is less than or equal to one which is the case for T(0) and T(1) we only have one simple question which is comparision so here the time taken is one unit let's try to reduce T in terms of these known values which are T(0) and T(1) but before I do that i will try an approximation and i will come back to why I am doing this let's say the time taken to calculate fib of n minus one which is T n minus one is almost equal to the time taken to calculate fib of n minus two which is T n minus two now in reality the time taken to calculate fib of n minus 1 is greater than the time taken to calculate fib of n minus 2 so what they're trying to do here is we are trying to calculate a lower bound for T(n) the time taken to calculate fib of n so now T(n) would be 2 times T of n 2 plus four let's say we write this 4 as a constant C so C is equal to 4 is a constant that adds up into this expression now let's try to reduce this expression T(n2) can be written as 2 times T of n4 plus C so this expression eventually reduces to four T (n 4) plus three C and again and T(n4) can be reduced to T(n6) so this will be eight T(n6) plus seven C and we can go on like sixteen T(n8) plus fifteen c and so on now if i want to reduce it by some generic value then we can say that this is equal to 2 to the power k time T of n minus two k plus two to the power k minus one into C and you can veriffy that this expression is true for all the values of k like this k is equal to 2 this is k is equal to 3 the this is k is equal to 4 and this is our T(n) now if i want to read this in terms of T(0) which is known to us then that case n minus two k would be equal to 0 that will imply k = n by 2 and our expression T(n) will be reduced as 2 to the power n by 2 T(0) plus 2 to the power n by 2 minus one C and this is nothing but one pluc C into 2 to the power n by 2 minus C so in simple terms we can say here that T of n is proportional to 2 to the power n by two and this is a lower bound for us the lower bound for the time taken and i will clear this calculation and write here now let's try another approximation this time. Let's say the time taken to calculate fib of n minus 2 which is T(n2) is almost equal to T of n minus one now this reduces our expression or this simplifies our expression as T(n) is equal to 2 times T of n1 plus constant C and C is equal to 4 now in reality T of n 2 will be lesser than T of n 1 so this expression is kind of giving an upper bound this time and we can go on reducing this particular expression similar to what we had done before so this would be four T n minus 2 plus three C which is again equal to eight T n minus 3 plus seven C and if I have to reduce it in some generic form then this is equal to 2 to the power k T of n minus k plus 2 to the power k minus 1 into C now if i want to read this expression k in terms of the T(0) then n minus k will be equal to 0 which will imply k is equal to n and that could mean than T(n) is equal to 2 to the power n T of 0 plus 2 to the power n minus one into C and t(0) is nothing but 1 so finally it will be 1 plus C into 2 to the power n minus C so in simplest of terms in this particular case we can say that T(n) is proportional to 2 to the power n and this is our upper bound because we have approximated T of n minus two to be T of n minus 1 while in reality lesser than t(n1) we have used approximations because it was a lot easier using these approximations to reduce this expression and show you that the time taken by this program grows exponentially with the input so even if we take lower bound of to 2 to the power n by 2 then for a simple input like n is equal to 100 this program will take years to give you the result the order of growth of T(n) would be somewhere in between the lower bound and upper bound but in complexity analysis we often see the closest of the bound to make a sense of the run time of the worst case thank them of the program in the worst case now i will clear this calculation and write here big O notation which is one of the most famous notations to describe time complexity of a program actually represents the upward bound of the growth of the function or rather the upper bound of the growth of the time so we can say in this case that this particular algorithm is having the time complexity which is big O of 2 to the power n so fib recurssion which is a recursive implementation of fibonacci sequence has a complexity big O of 2 to the power n if we would have written an iterative implementation using loops then the complexity would have been big O of n or in other words this algorithm is order of n if an algorithm is order of n in terms of time complexity such an algorithm is called linear time algorithm and if an algorithm has time complexity of the order of something like a to the power b then such an algorithm is called exponential time algorithm now a linear time algorithm or an algorithm of order n is lot lot better than exponential time algorithm. infact exponential time algorithm is an algorithm with the worst kind of time complexity for example in this particular case using the iterative method for an input as high as a million we will get the result in no time while the recursive implemetation which has an exponential run time and for an input as small as 100 we will not get the result in a reasonable time we will dig deeper into complexity analysis of programs and all these notations like big O notation in couple of more lessons so thanks for watching