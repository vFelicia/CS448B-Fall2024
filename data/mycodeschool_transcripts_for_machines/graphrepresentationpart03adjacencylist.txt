so in our previous lesson we talked about adjacency matrix as a way to store and represent graph and as we discussed and analyzed this data structure we saw that it's very efficient in terms of time cost of operations with this data structure it costs Big O of 1 that is constant time to find if two nodes are connected or not and it costs Big O of V where V is number of vertices to find all nodes adjacent to a given node but we also saw that adjacency matrix is not very efficient when it comes to space consumption we consume space in order of square of number of vertices in adjacency matrix representation as you know we store edges in a twodimensional array or matrix of size V cross V where V is number of vertices in my example graph here we have 8 vertices that's why I have an 8 cross 8 matrix here we are consuming 8 square that is 64 units of space here now what's basically happening is that for each vertex for each node we have a row in this matrix where we are storing information about all its connections this is the row for the zeroth node that is a this is the row for the one at node that is B this is for C and we can go on like this so each node has got a row and a row is basically a one dimensional array of size equal to number of vertices that is V and what exactly are we storing in a row let's just look at this first row in which we are storing connections of node a this twodimensional matrix or array that we have here is basically an array of onedimensional arrays so each row has to be one dimensional array so how are we storing the connections of node a in these eight cells in is one dimensional array of size 8/0 in the zeroeth position means that there is no edge starting a and ending at zero at node which again is a an edge starting and ending at itself is called a selfloop and there is no self loop on a of one in one at position here means that there is an edge from a to 1 at node that is B the way via storing information here is that index or position in this onedimensional array is being used to represent endpoint of an edge for this complete row for this complete onedimensional array start is always the same it's always the zeroth node that is a in general in the adjacency matrix row index represents the start point and column index represents the end point now here when we are looking only at the first row start is always a and the indices 0 1 2 and so on are representing the endpoints and the value at a particular index or position tells us whether we have an edge ending at that node or not 1 here means that the edge exists 0 would have meant that that edge does not exist now when we are storing information like this if you can see we are not just storing that b c and d are connected to a we are also storing the knot of it we are also storing the information that a e f g and h are not connected to a if we are storing what all nodes are connected through that we can also deduce what all nodes are not connected these zeros in my opinion are redundant information causing extra consumption of memory most realworld graphs are sparse that is number of connections is really small compared to total number of possible connections so more often there would be too many zeros and very few once think about it let's say we are trying to store connections in a social network like Facebook in an adjacency matrix which would be the most impractical thing to do in my opinion but anyway for the sake of argument let's say we are trying to do it just to store connections of one user I would have a row or one dimensional matrix of size 10 to the power 9 on an average in a social network you would not have more than thousand friends if I have thousand friends then in the row used to store my connections I would only have thousand ones and rest that is 10 to the power 9 minus thousand would be citizen and I'm not trying to force you to agree but just like me if you also think that these zeros are storing redundant information and our extra consumption of memory then even if we are storing these ones and zeros in just one byte as boolean values these many zeros here is almost one gigabyte of memory once are just of one kilobyte so given this problem let's try to do something different here let's just try to keep the information that these nodes are connected and get rid of the information that these nodes are not connected because it can be inferred it can be deduced and there are a couple of ways in which we can do this here to store connections of a instead of using an array such that index represents endpoint of an edge and value at that particular index represents whether we have an edge ending there or not we can simply keep a list of all the nodes to which we are connected this is the list or set of nodes to which a is connected we can represent this list either using the indices or using the actual names for the notes let's just use indices because names can be long and may consume more memory you can always look at the vertex list and find out the name in constant time now in a machine we can store this set of nodes which basically is a set of integers in something as simple as an array and this array as you can see is a different arrangement from our previous array in our earlier arrangement index was representing index of one node in the graph and value was representing whether there was a connection to that node or not here index does not represent anything and the values are the actual indices of the nodes to which we are connected now instead of using an array here to store this set of integers we can also use a linked list and widest array or linked list I would argue that we can also use a true here in fact a binary search tree is a good way to store a set of values there are ways to keep a binary search tree balanced and if you always keep a binary search tree balanced you can perform search insertion and deletion all three operations in order of log of number of nodes we will discuss cost of operations for any of these possible ways in some time right now all I want to say is that there are a bunch of ways in which we can store connections of a node for our example graph that we started with instead of an adjacency matrix we can try to do something like this we are still storing the same information we are still saying that 0 each node is connected to one at to it and 3 at node one eighth note is connected to 0 at fourth and fifth node to Earth node is connected to 0 eighth and sixth node and so on but we are consuming a lot less memory here programmatically this adjacency matrix here is just a twodimensional array of size 8 cross 8 so we are consuming 64 units of space in total but this structure in right does not have all the rules of same size how do you think we can create such a structure programmatically well it depends in c or c++ if you understand pointers then we can create an array of pointers of size 8 and each pointer can point to a 1 dimensional array of different size 0 8 pointer can point to an array of size 3 because 0 8th node has 3 connections and we need an array of size 3 one at pointer can point to an array of size 3 because one it's node also has 3 connections to its node however has only 2 connections so 2 its pointer should point to an array of size 2 and we can go on like this the 7th node has four connections so 7th pointer should should point to an array of size 4 if you do not understand any of this point to think that I am doing right now you can refer to my code schools lesson titled pointers and arrays the link to which you can find in the description of this video but think about it the basic idea is that each row can be a onedimensional array of different size and you can implement this with whatever tools you have in your favorite programming language now let's quickly see what are the pros and cons of this structure in the write in comparison to the matrix in the left we are definitely consuming less memory with the structure in right with adjacency matrix our space consumption is proportional to square of number of vertices while with this second structure space consumption is proportional to number of edges and we know that most real world graphs are sparse that is the number of edges is really small in comparison to square of number of vertices square of number of vertices is basically total number of possible edges and for us to reach this number every node should be connected to every other node in most graphs a node is connected to few other nodes and not all other nodes in the second structure we are avoiding this typical problem of too much space consumption in an adjacency matrix by only keeping the ones and getting rid of the redundant zeros here for an undirected graph like this one we would consume exactly 2 into number of edges units of memory and for a directed graph we would consume exactly ethat is number of edges units of memory but all in all space consumption will be proportional to number of edges or in other words space complexity would be big o of e so the second structure is definitely better in terms of space consumption but let's now also try to compare these two structures for time cost of operations what do you think would be the time cost of finding if two nodes are connected or not we know that it's constant time or Big O of 1 for an adjacency matrix because if we know the start and end point we know the cell in which to look for 0 or 1 but in the second structure we cannot do this we will have to scan through a row so if I ask you something like can you tell me if there is a connection from node 0 to 7 then you will have to scan this 0 at row you will have to perform a linear search on this 0 at row to find 7 right now all the rows in this structure are sorted you can argue that I can keep all the rules sorted and then I can perform a binary search which would be a lot less costlier that's fine but if you just perform a linear search then in worst case we can have exactly V that is number of vertices cells in a row so if we perform a linear search in worst case we will take time proportional to number of vertices and of course the time cost would be bigoh of log V if we would perform a binary search logarithmic run times are really good but to get this here we always need to keep our rows sorted keeping an array always sorted is costly in other ways and I'll come back to it later for now let's just say that this would cost us big o of V now what do you think would be the time cost of finding all nodes adjacent to a given node that is finding all neighbors of a node well even in case of a jason c matrix we now have to scan a complete row so it would be Big O of V for the matrix as well as this second structure here because here also in worst case we can have V cells in a row equivalent to having all one's in a row in an adjacency matrix when we try to see the time cost of an operation and we mostly analyze the worst case so for this operation we are Big O of V for both so this is the picture that we are getting looks like we are saving some space with the second structure but we are not saving much on time well I would still argue that it's not true when we analyze time city we mostly analyze it for the worst case but what if we already know that we are not going to hit the worst case if we can go back to our previous assumption that we are dealing with a sparse graph that we are dealing with a graph in which a node would be connected to few other nodes and not all other nodes then the second structure will definitely save us time things would look better once again if we would analyze them in context of a social network I'll set some assumptions let's say we have a billion users in our social network and the maximum number of friends that anybody has is 10,000 and let's also assume computational power of our machine let's say our machine or system can scan or read 10 to the power 6 cells in a second and this is a reasonable assumption because machines often execute a couple of millions instructions per second now what would be the actual cost of finding all nodes adjacent to a given node in a Jason Z matrix well we will have to scan a complete row in the matrix that would be 10 to the power 9 cells because in a matrix we would always have cells equal to number of vertices and if we would divide this by a million we would get the time in seconds to scan a row of 10 to the power 9 cells we would take thousand seconds which is also sixteen point six six minutes this is unreasonably high but with the second structure maximum number of cells in a row would be 10,000 because the number of cells would exactly be equal to number of connections and this is the maximum number of friends or connections a person in the network has so here we would take 10 to the power 4 upon 10th the power 6 that is 10 to the power minus 2 seconds which is equal to 10 milliseconds 10 milliseconds is not unreasonable now let's try to deduce the cost for the second operation finding if two nodes are connected or not in case of adjacency matrix we would know exactly what cell to read we would know the memory location of that specific cell and reading that one cell would cost us 1 upon 10 to the power 6 seconds which is 1 microsecond in the second structure we would not know the exact cell we will have to scan a row so once again maximum time taken would be 10 milliseconds just like finding adjacent nodes so now given this analysis if you would have to design a social network what structure would you choose nobrainer isn't it machine cannot make a user wait for 16 minutes would you ever use such a system milliseconds is fine but minutes it's just too much so now we know that for most realworld crafts this second structure is better because it saves us space as well as time and remember I'm saying most and not all because for this logic to be true for my reasoning to be valid graph has to be sparse number of edges has to be significantly lesser than square of number of vertices so now having analyzed space consumption and time cost of at least two most frequently performed operations looks like this second structure would be better for most graphs well and there can be a bunch of operations in a graph and we should account for all kind of operations so before making up my mind I would analyze cost of few more operations what if after storing this example graph in computer's memory in any of these structures we decide to add a new edge let's say we got a new connection in the graph from A to G then how do you think we can store this new information this new edge in both these structures the idea here is to assess that once the structures are created in computer's memory how would we do if the graph changes how would we do if a node or edge is inserted or deleted if a new edge is inserted in case of an adjacency matrix we just need to go to a specific cell and flip the zero at that cell to 1 in this case we would go to silhouette row and sixth column and overwrite it with value 1 and if it was a deletion then we would go to a specific cell and make the 1 0 now how about this second structure how would you do it here we need to add a 6 in the first row and if you have followed this series on data structures then you know that it's not possible to dynamically increase size of an existing array this would not be so straightforward we will have to create a new array of size 4 for the zeroth row then we will have to copy content off the old array write the new value and then wipe off the old one from the memory it's tricky implementing dynamic or changing lists using arrays this creation of new array and copying of old data is costly and this is the precise reason why we often use another data structure to store dynamic or changing lists and this another data structure is linked list so why not use a linked list why can't eat Ruby a linked list something like this logically we still have a list here but concrete implementation wise we are no more using an array that we need to change dynamically we are using a linked list it's a lot easier to do insertions and deletions in a linked list now programmatically to create this kind of structure in computer's memory we need to create a linked list for each node to store its neighbors so what we can do is we can create an array of pointers just like what we have done when we were using arrays the only difference would be that this time each of these pointers would point to head of a linked list that would be unknown I have defined node of a linked list here node of a linked list would have two fields one to store data and another to store address of the next node a zero would be a pointer to head our first node of linked list for a a one would be a pointer to head of linked list for B and we will go on like a 2 for C a 3 for D and so on actually I have drawn the linked lists here in the left but I have not drawn the array of pointers let's say this is my array of pointers now a 0 here this one is a pointer to node and it points to the head of linked list containing the neighbors of a let's assume that head of linked list for a has address 400 so in a 0 we would have 400 it's really important to understand what is what here in this structure this one a 0 is a pointer to node and all appointed is store an address or reference this one is a node and it has two fields one to store data and another a pointer to node to store the address off next node let's assume that the address of next node in this first linked list is 450 then we should have 450 here and if the next one is at let's say 500 then we should have 500 in address part of the second node the address and last one would be zero or null now this kind of structure in which we store information about neighbors of a node in a linked list is what we typically call an adjacency list what I have here is an adjacency list for an undirected unweighted graph to store a weighted graph in an adjacency list I would have one more field in node to store weight I have written some random weights next to the edges in this graph and to store this extra information I have added one extra field in node both in logical structure and the code all right now finally with this particular structure that we are calling adjacency list we should be fine with space consumption space consumed will be proportional to number of edges and not to square of number of vertices most graphs are sparse and number of edges in most cases is significantly lesser than square of number of vertices ideally for space complexity I should say Big O of number of edges plus number of vertices because storing vertices will also consume some memory but if we can assume that number of vertices will be significantly lesser in comparison to number of edges then we can simply say Big O of number of edges but it's always good if we do the counting right now for time cost of operations the argument that we were earlier making using a sparse graph like social network is still true adjacency list would overall be better than adjacency matrix finally let's come back to the question how flexible are we with this structure if we need to add a new connection or delete an existing connection and is there any way we can improve upon it well I leave this for you to think but I'll give you a hint what if instead of using a linked list to store information about all the neighbors we use a binary search tree do you think we would do better for some of these operations I think we would do better because the time cost for searching inserting and deleting a neighbor would reduce with this thought I'll sign off this is it for this lesson thanks for watching