in this lesson we will try to analyze time complexity of recursion to calculate x to the power n in the previous lesson we had seen two different recursive approaches to calculate x to the power n. We will try to deduce time complexity for both of them mathematically now the first approach that we had seen was this we had defined a recurrence relation where we had expressed x to the power n as x *(x^n1) and n is equal to zero was our base condition so in the program it goes like, if n is 0 then simply return 1 else make a recursive call to calculate x to the power n minus 1 multiply it with x and return the output now once again when we try to analyze time complexity we say that each simple operation costs us one unit of time so any of the arithmetic operations like addition subtraction or a comparison all of these cost us one unit of time now in this particular program as you can see there is a comparison let's say takes one unit of time so if n is greater than zero then we first compared it with 0 then we make a recursive call and we make a subtraction to pass the arguments so this is one unit of cost and this multiplication is say one unit of cost and let's say all other costs are negligible then if we were not making a recursive call then the cost would have been only three units or the cost would have been some constant but because we are making a recursive call the time taken varies now it should also be evident to you that the time taken does not vary because of x it varies only because of n because it is n that is deciding that how many times the recursion would be called or what would be the depth of the recursion tree so for example if we want to calculate x to the power 4 then we go on making recursive calls like this so we have five calls in calculation of x to the power 4 similarly in calculation of x to the power 2 there would be three calls so the time taken by this program is only a function of n so let's say time taken is T(n) for an input n so T(n) would be equal to the time taken to calculate x to the power n1 which will be T(n1) plus some constant time let's say it's equal to c for the simple operations like comparison and multiplication and subtraction and this is true for all n greater than 0 and for our base case which is T(0) there is just one comparison with zero and returns so let's say this one unit of time now let's try to solve this recurrence relation and try to express it in terms of the base condition which is T(0) now this is pretty straight forward T(n1) can be written as T(n2) + c so this will be T(n2) + 2c and we can go on like T(n3) + 3c or if we want to write it some generic form then T(nk) + k*c now we want to express this in terms of T(0) so in that case nk will be equal to zero that will imply k will be equal to n so eventually T(n) will be equal to T(0) + n*c, where c is a constant and T(0) is nothing but one so this will be n*c + 1, overall so clearly the time taken is proportional to n and this is also big O(n) or order of n in terms of time complexity now let us try to analyze the second approach to calculate x to the power n so this time we had expressed x to the power n as x to the power n by 2 into x to the power n by 2 if n is even x into x to the power n minus one if n is odd and one for the base case which is n equals to zero and the program goes something like this if n is 0 return 1 if n is even calculate x to the power n by 2 and return its square else make a recursive call to calculate x to the power n minus one and return the product of it with x so again like the previous case the time taken is a function of n and it does not depend upon the x in this case as well let's say the time taken is T(n) now if n is even then we make a recursive call to calculate x to the power n by 2, so wecan say that T(n) is equal to T(n/2) plus some constant time for the simple operations like comparison division or modulo so let's say this constant is c1 this time and this is true if n is even if n is odd then we make a recursive call to calculate x to the power n minus one, so T(n) would be T(n1) plus some constant time for the simple operation let's say this constant is c2 and for the base case we have T(0) there is just one comparison so let's say this takes one unit of time now if n is odd then n minus one must be even so for the second case when n is odd we can also write this as T(n1) by 2 plus c1 so for the odd scenario T(n) can be equal to T(n1/2) plus c1 plus c2 now if n is an integer and we take only the integral part then we can also write this as T(n/2), T(n1/2) is T(n/2) if n is always odd and we can write c1 plus c2 as some other constant c and this is similar to even case except that the constant has changed and because c is greater than c1 so this solving this particularly recurrence relation will give us an overall analysis of the upper bound of the time taken which is fine because we often analyze the closest upper bound of the time taken in complexity analysis now let us try to reduce this expression T(n/2) can be written as T(n/4) plus c so this will be T(n/4) plus 2c and we can go on reducing like this we can write this as T(n/8) plus 3c and if i have to make it in some generic form then this can be written as T(n) by 2 to the power k plus k into c now if n is a positive integer and if we go on dividing it by 2 so if we go from T(n/2) to T(n/4) and T(n/8) and so on we can never reach T(0) so let us define one more base case here let's define T(1) and this will be equal to one is odd this will be equal to T(0) plus one and T(0) is nothing but one so this will be one plus C2 by this particular recurrence relation here now let us try to express T(n) in terms of T(1) in that case n by 2 to the power k will be equal to one that will imply 2 to the power k is n or k is log n to the base 2 so T(n) can be written as T(1) plus c logn where c is a constant and T(1) is also a constant which is equal to one plus c2 so the overall expression is 1 plus c2 plus c logn where c and c2 are both constants so we can see here that time taken T(n) is proportional to logn so this is a big O of logn algorithm or order of logn algorithm in terms of time complexity now there was a similar problem that we have solved which was to calculate modular exponentiation and in that problem also we solve the same recurrence relation T(n) is equal to T(n/2) plus c so the complexity for that algorithm is O(logn) as well an order of logn is the best time complexity to have thanks for watching