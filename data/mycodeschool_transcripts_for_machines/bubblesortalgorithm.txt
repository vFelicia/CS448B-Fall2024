In our previous lesson, in this series on sorting algorithms, we had discussed Selection Sort algorithm. Now in this lesson, we are going to discuss another sorting algorithm, named Bubble Sort. So, once again, let's say we have a list of integers, given to us in the form of an array something like this. Let's name this array A, we have six elements in the array. So, we have indices from 0 to 5. Now, we want to sort this array, so, we want to rearrange the elements in the array in increasing order. What we are going to do in this algorithm is we are going to scan the array from left to right multiple times. We will call each scan 1 pass on the array. It's like we will first look at the 0th element and then look at the 1th element and then the element at index 2 and so on. Of course we will not scan the array for no reason. What we will do is when we are scanning the array and we are at a particular position, we will compare the element at that particular position with the adjacent element at the next position. So, if we are at 0th position, then we will compare the element at 0th position with the element at 1th position, and if the element at the current position is greater than the element at the next position, we will swap the two elements. In this case, 2 is not greater than 7, so, we will not swap the two elements. We will just move on to the next position which will be position 1. Once again we will compare the element with its next element and if it is greater, we will swap the two elements. In this case 7 is greater than 4, so, we will swap the position of these two elements. So, 7 will move to index 2 and 4 will move to index 1. And now we will move to index 2, the number at index 2 at this stage will be 7. Once again we will look at the next element, it's 1. 7 is again greater than 1, so we will swap and now, we will move to index 3. Once again, at this stage the number at index three is 7, we will compare it with 5 and we need to swap again. So, 7 will go to index 4 and 5 will move to index 3 and now we will go to index 4. As, you can see, this whole process is pushing number 7, which is the largest in the array towards higher indices at each step. When we are position 4, once again 7 is greater than three, so we will swap. There is no next element for index 5 and at this stage we are done with one pass on the array and what has happened after this one pass is that 7 which is the largest in the array is at its appropriate position. It deserves to be at index 5 in the sorted array and that's where it is. So, 7 has kind of bubbled up to the right most position in the array, with this whole logic of swapping the adjacent elements. This was our initial array and after first pass we have gone to a state like this. If I quickly have to write pseudo code for a pass, it will be running a loop something like this. We will run a loop from 0 to n1. Let's say n is the number of elements in an array and if A[i], the element at position i, is greater than element at position i+1, we will swap the two elements. There is one minor bug here, if i=n1, it will be the last index, so there will be no element after that. So, we will not be able to access A[i+1], so we will run this loop only till n2. We don't want to access an index that will be out of the bound of the array, out of the range of the array. For i=n1, A[i+1] would have been out of range. Okay, so this is the state of the array after one pass. What if we perform another pass and once again keep comparing the adjacent elements and performing swaps. If we will do so, now the second largest element in this example will land up at index 4. The second largest in the array is number 5. So, after 2nd pass our array will be in a state like this. With every pass on the array, the array will be divided into two parts, one part will be the sorted part and another part will be unsorted part. After 2 passes, the part of the array from index 4 till 5 is sorted and the part of the array from index 0 till 3 is unsorted. With each pass, the largest element in the unsorted half will bubble up to the highest index in the unsorted half. So, in 3rd pass, number 4 should bubble up to position 3, at index 3. And while scanning, once we reach to the part where we are sorted, there will be no swapping. We can actually avoid going to the sorted part. It will only improve our algorithm. After pass 3, our array will be looking like this. In fact we are already sorted. In general, if we will conduct n1 such passes, for an array of size n. We can say something like for k, 1 to n1, or we could say for k, 0 to n2, after n1 passes, we are guaranteed to be sorted. So, this is our pseudo code for bubble sort algorithm. Given an array and the number of elements in the array, this function Bubble Sort will sort the elements in the array in increasing order. Let's now try to analyze the time complexity of this algorithm. The running time of this algorithm will be the running time of these statements inside the nested loop. Let us assume that these statements will take constant time c in the worst case. These statements will execute in constant time. Now, the first loop will run exactly n1 times, and the second loop will also run exactly n1 times, so the total time taken as a function of n will be (n1)* (n1)* c, which will evaluate to c* (n^2) 2cn +1. Whenever we have a polynomial expression for time, then we say that the time complexity is bigOh of the highest order term in the polynomial. The highest order term here is n^2, we just remove the constants. And, we say that this running time will fall into the class bigOh of highest order term, in this case it will be n^2.If you do not know about bigOh notation, or how to calculate running time of algorithms, we have a whole series on time complexity analysis, you can find a link to it in the description of this video. BigOh of n^2 is not the best running time for a sorting algorithm. In fact this running time is bad. Bubble sort is a slow sorting algorithm, it's as good as Selection Sort but both Bubble sort and Selection sort are slow sorting algorithms. We can do couple of things in this algorithm to improve the time complexity, at least for some scenarios. The first thing that we can do is, we need not run this second loop till n2, all the time. As we had discussed earlier, at any stage during the sorting, the array will have some part as sorted and some part as unsorted. There is no point passing through the sorted part because there will be no swapping in that part. For first pass we can run this inner loop till n2, for the second pass we can run this inner loop till n3 and we will be good. For the third pass, we can only run till n4 and so on. So, in general we can run the loop till nk1, so when k is 1, we can run till n2, when k is 2, we will run till n3 and so on. This is some improvement, but in this case also, if you will calculate the time expression, it will be some polynomial of the form an^2 + bn + c, so complexity will still be bigOh of n^2. We can do something else to improve this algorithm further. If you remember the example that we had picked up, it was sorted after 3 passes only and 4th and 5th pass was only redundant. If the list is already sorted, there would be no swaps. So, if we go through a pass without swapping anything, then definitely at that stage the list is already sorted. So, I will do something like this in this algorithm, I will take a variable and name it flag and set it to 0, before making a pass and once this condition A[i]>A[i+1] is true for any i, then we will have to swap and we will set this flag as 1. And now, when we will come out of this loop after a pass, if flag is 0, then there has been not even one swap, so we do not need to conduct any more passes, so we can break out of this loop, the outer loop and this way we will be able to avoid making redundant passes once the array is sorted. Now, with this modification, if we input an already sorted array, to the function bubble sort then this particular loop will execute only once to figure out that it's already sorted. So, the time taken if we were considering this as taking some constant time c, in the worst case, the time taken will be c*(n1) only. So, this will be the best case for our algorithm. Our algorithm will be O(n) in the best case. In the average case, somewhere midway, after making let's say n/2 passes, we will exit the inner loop. If we will deduce the time complexity expression, it will still come something like an^2 + bn +c kind of expression, so in average case also, this will be BigOh(n^2). And in the worst case, the inner loop will also run n1 times, and we will be BigOh(n^2). Bubble Sort is in place and stable sorting algorithm and we just deduced it's time complexity which is BigOh(n^2) in the worst case. This is it for this lesson. Thanks for watching!