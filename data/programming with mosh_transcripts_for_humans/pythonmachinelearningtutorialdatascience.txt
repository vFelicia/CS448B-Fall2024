With timestamps:

00:00 - [Music]
00:01 - if you're looking for a machine learning
00:02 - tutorial with python and jupyter
00:04 - notebook
00:05 - this tutorial is for you you're going to
00:07 - learn how to solve a real world problem
00:09 - using machine learning and python we're
00:11 - going to start off with a brief
00:12 - introduction to machine learning
00:14 - then we're going to talk about the tools
00:15 - you need and after that we're going to
00:17 - jump straight into the problem we're
00:18 - going to solve
00:19 - you'll learn how to build a model that
00:21 - can learn and predict the kind of music
00:23 - people like
00:24 - so by the end of this one hour tutorial
00:26 - you will have a good understanding of
00:28 - machine learning basics
00:29 - and you'll be able to learn more
00:30 - intermediate to advanced level concepts
00:33 - you don't need any prior knowledge in
00:34 - machine learning but you need to know
00:35 - python fairly well
00:37 - if you don't i've got a couple of
00:38 - tutorials for you here on my channel the
00:40 - links are below this video
00:42 - i'm ashamed only and i'm super excited
00:43 - to be your instructor on this channel i
00:45 - have tons of programming tutorials that
00:47 - you might find helpful
00:48 - so be sure to subscribe as i upload new
00:51 - tutorials every week
00:52 - now let's jump in and get started
01:03 - in this section you're going to learn
01:04 - about machine learning which is a subset
01:06 - of ai or
01:07 - artificial intelligence it's one of the
01:09 - trending topics in the world these days
01:11 - and it's going to have a lot of
01:13 - applications in the future
01:14 - here's an example imagine i ask you to
01:16 - write a program
01:17 - to scan an image and tell if it's a cat
01:20 - or a doc
01:21 - if you want to build this program using
01:22 - traditional programming techniques
01:24 - your program is going to get overly
01:26 - complex you will have to come up with
01:28 - lots of rules to look for specific
01:30 - curves
01:31 - edges and colors in an image to tell if
01:33 - it's a cat or a dog
01:35 - but if i give you a black and white
01:36 - photo your rules may not work
01:38 - they may break then you'll have to
01:39 - rewrite them or i might give you a
01:41 - picture of a cat or a dog
01:42 - from a different angle that you did not
01:44 - predict before
01:45 - so solving this problem using
01:47 - traditional programming techniques is
01:48 - going to get
01:49 - overly complex or sometimes impossible
01:52 - now to make the matter worse what if in
01:54 - the future i ask you to extend this
01:56 - program
01:56 - such that it supports three kinds of
01:58 - animals cats
02:00 - dogs and horses once again you'll have
02:02 - to rewrite all those rules
02:04 - that's not gonna work so machine
02:06 - learning is a technique to solve these
02:08 - kind of problems
02:09 - and this is how it works we build a
02:11 - model or an engine
02:12 - and give it lots and lots of data for
02:15 - example we give you
02:16 - thousands or tens of thousands of
02:18 - pictures of cats and dogs
02:20 - our model will then find and learn
02:22 - patterns in the input data
02:24 - so we can give it a new picture of a cat
02:26 - that it hasn't seen before
02:27 - and ask it is it a cat or a dog or a
02:29 - horse and it will tell us with a certain
02:31 - level of accuracy
02:32 - the more input data we give it the more
02:34 - accurate our model
02:36 - is going to be so that was a very basic
02:38 - example
02:39 - but machine learning has other
02:40 - applications in self-driving cars
02:43 - robotics language processing vision
02:45 - processing
02:46 - forecasting things like stock market
02:48 - trends and the weather
02:50 - games and so on so that's the basic idea
02:52 - about machine learning
02:54 - next we'll look at machine learning in
02:55 - action
03:02 - a machine learning project involves a
03:03 - number of steps the first step is to
03:06 - import our data which often comes in the
03:08 - form of a csv file
03:09 - you might have a database with lots of
03:11 - data we can simply export that data
03:13 - and store it in a csv file for the
03:15 - purpose of our machine learning project
03:18 - so we import our data next we need to
03:20 - clean it and this involves tasks
03:22 - such as removing duplicated data if you
03:24 - have duplicates in the data
03:25 - we don't want to feed this to our model
03:27 - because otherwise our model will learn
03:29 - bad patterns in the data and it will
03:30 - produce the wrong result
03:32 - so we should make sure that our input
03:34 - data is in a good and clean shape
03:36 - if there are data that is irrelevant we
03:37 - should remove them if they are
03:39 - duplicated or
03:40 - incomplete we can remove or modify them
03:43 - if our data is text-based
03:44 - like the name of countries or genres of
03:47 - music
03:47 - or cats and dogs we need to convert them
03:50 - to numerical values
03:52 - so this step really depends on the kind
03:53 - of data we're working with
03:55 - every project is different now that we
03:57 - have a clean data set we need to split
03:59 - it into
04:00 - two segments one for training our model
04:02 - and the other for testing it
04:04 - to make sure that our model produces the
04:06 - right result
04:08 - for example if you have a thousand
04:09 - pictures of cats and dogs
04:11 - we can reserve eighty percent for
04:12 - training and the other 20
04:14 - for testing the next step is to create a
04:17 - model
04:18 - and this involves selecting an algorithm
04:20 - to analyze the data
04:22 - there are so many different machine
04:23 - learning algorithms out there such as
04:25 - decision trees
04:26 - neural networks and so on each algorithm
04:28 - has pros and cons
04:30 - in terms of accuracy and performance so
04:32 - the algorithm you choose
04:33 - depends on the kind of problem you're
04:35 - trying to solve and your input data
04:37 - now the good news is that we don't have
04:39 - to explicitly program an
04:41 - algorithm there are libraries out there
04:43 - that provide these algorithms
04:44 - one of the most popular ones which we
04:46 - are going to look at in this tutorial
04:48 - is scikit-learn so we build a model
04:50 - using an algorithm
04:52 - next we need to train our model so we
04:54 - fitted our training data
04:56 - our model will then look for the
04:58 - patterns in the data so next we can ask
05:00 - it to make predictions
05:02 - back to our example of cats and dogs we
05:04 - can ask our model
05:05 - is this a cat or a dog and our model
05:07 - will make a prediction
05:09 - now the prediction is not always
05:11 - accurate in fact when you start out
05:13 - it's very likely that your predictions
05:14 - are inaccurate so we need to evaluate
05:17 - the predictions and measure
05:18 - their accuracy then we need to get back
05:20 - to our model
05:21 - and either select a different algorithm
05:24 - that is going to produce
05:25 - a more accurate result for the kind of
05:27 - problem we're trying to solve
05:28 - or fine-tune the parameters of our model
05:32 - so each algorithm has parameters that we
05:34 - can modify to optimize the accuracy
05:37 - so these are the high level steps that
05:38 - you follow in a machine learning project
05:41 - next we'll look at the libraries and
05:42 - tools for machine learning
05:50 - in this lecture we're going to look at
05:51 - the popular python libraries that we use
05:53 - in machine learning projects
05:55 - the first one is numpy which provides a
05:57 - multi-dimensional array
05:58 - very very popular library the second one
06:01 - is pandas which is a data analysis
06:03 - library that provides a concept called
06:05 - data frame
06:06 - a data frame is a two-dimensional data
06:08 - structure similar to an excel
06:10 - spreadsheet
06:11 - so we have rows and columns we can
06:13 - select data in a row or a column
06:15 - or a range of rows and columns again
06:18 - very very popular in machine learning
06:20 - and data science projects the third
06:22 - library
06:23 - is matplotlib which is a two-dimensional
06:25 - plotting library
06:26 - for creating graphs and plots the next
06:29 - library is scikit-learn which is one of
06:31 - the most popular machine learning
06:32 - libraries
06:33 - that provides all these common
06:35 - algorithms like decision trees
06:37 - neural networks and so on now when
06:40 - working with machine learning projects
06:41 - we use an environment called jupiter for
06:43 - writing our code
06:45 - technically we can still use vs code or
06:46 - any other code editors
06:48 - but these editors are not ideal for
06:49 - machine learning projects
06:51 - because we frequently need to inspect
06:52 - the data and that is really hard
06:54 - in environments like vs code and
06:56 - terminal if you're working with a table
06:58 - of 10 or 20 columns
07:00 - visualizing this data in a terminal
07:01 - window is really really difficult and
07:03 - messy
07:04 - so that's why we use jupiter it makes it
07:06 - really easy to inspect our data
07:08 - now to install jupyter we're going to
07:10 - use a platform called anaconda
07:13 - so head over to anaconda.com
07:16 - download on this page you can download
07:18 - anaconda distribution for your operating
07:20 - system
07:21 - so we have distributions for windows mac
07:24 - and linux so let's go ahead and
07:28 - install anaconda for python 3.7
07:32 - download
07:36 - all right so here's anaconda downloaded
07:38 - on my machine let's double click this
07:41 - all right first it's going to run a
07:42 - program to determine if the software can
07:44 - be installed
07:45 - so let's continue and once again
07:48 - continue
07:49 - continue pretty easy continue one more
07:51 - time
07:52 - i agree with the license agreement okay
07:55 - you can use the default installation
07:57 - location so don't worry about that
07:59 - just click install give it a few seconds
08:02 - now the beautiful thing about anaconda
08:04 - is that it will install jupyter
08:06 - as well as all those popular data
08:08 - science libraries like numpy
08:10 - pandas and so on so we don't have to
08:11 - manually install this using pip
08:16 - all right now as part of the next step
08:17 - anaconda is suggesting to install
08:19 - microsoft vs code we already have this
08:21 - on our machine so
08:22 - we don't have to install it we can go
08:24 - with continue and
08:26 - close the installation now finally we
08:28 - can move this to trash because we don't
08:30 - need this installer in the future
08:33 - all right now open up a terminal window
08:35 - and type
08:36 - jupyter with a y space
08:40 - notebook this will start the notebook
08:43 - server on your machine
08:44 - so enter there you go this will start
08:48 - the notebook server on your machine you
08:49 - can see these default messages here
08:51 - don't worry about them now it
08:53 - automatically opens a browser window
08:55 - pointing to localhost port 888
09:00 - this is what we call jupiter dashboard
09:02 - on this dashboard we have a few tabs the
09:04 - first tab
09:05 - is the files tab and by default this
09:07 - points to your home directory
09:09 - so every user on your machine has a home
09:11 - directory this is my home directory on
09:13 - mac
09:13 - you can see here we have a desktop
09:15 - folder as well as documents
09:17 - downloads and so on on your machine
09:18 - you're going to see different folders
09:20 - so someone on your machine you need to
09:21 - create a jupyter notebook
09:23 - i'm going to go to desktop here's my
09:26 - desktop i don't have anything here
09:28 - and then click new i want to create a
09:31 - notebook
09:32 - for python 3. in this notebook we can
09:34 - write python code
09:35 - and execute it line by line we can
09:37 - easily visualize our data as you will
09:39 - see over the next few videos
09:41 - so let's go ahead with this
09:45 - all right here's our first notebook you
09:47 - can see by default it's called
09:48 - untitled let's change that to hello
09:52 - world
09:52 - so this is going to be the hello world
09:54 - of our machine learning project
09:56 - let's rename this now if you look at
09:59 - your desktop you can see this file
10:01 - helloworld.i
10:02 - pi nb this is a jupiter notebook
10:06 - it's kind of similar to our pi files
10:08 - where we write our python code
10:09 - but it includes additional data that
10:11 - jupiter uses to execute our code
10:15 - so back to our notebook let's do a
10:18 - print hello world and then
10:22 - click this run button here and
10:25 - here's the result printed in jupyter so
10:28 - we don't have to navigate back and forth
10:29 - between the terminal window
10:31 - we can see all the result right here
10:34 - next i'm going to show you how to load a
10:36 - data set from a csv file in jupyter
10:44 - all right in this lecture we're going to
10:46 - download a data set from a very popular
10:48 - website called
10:49 - kaggle.com gaggle is basically a place
10:52 - to do data science projects
10:54 - so the first thing you need to do is to
10:55 - create an account you can sign up with
10:57 - facebook google or using a custom email
10:59 - and password
11:00 - once you sign up then come back here on
11:02 - kaggle.com
11:04 - here in the search bar search for
11:07 - video game sales this is the name of a
11:10 - very popular data set that we're going
11:12 - to use in this lecture
11:13 - so here in this list you can see the
11:15 - first item
11:16 - with this kind of reddish icon so let's
11:19 - go with that
11:21 - as you can see this data set includes
11:22 - the sales data for more than 16
11:25 - 000 video games on this page you can see
11:27 - the description
11:28 - of various columns in this data set we
11:30 - have rank
11:32 - name platform year and so on so here's
11:35 - our data source it's a csv file called
11:38 - vgsales.csv
11:39 - as you can see there are over 16 000
11:42 - rows
11:43 - and 11 columns in this data set right
11:46 - below that you can see the first few
11:47 - records
11:48 - of this data set so here's our first
11:50 - record the ranking for this game is one
11:53 - it's the wii sports game for we as the
11:55 - platform and it was released in year
11:56 - 2006
11:58 - now what i want you to do is to go ahead
12:01 - and
12:01 - download this data set and as i told you
12:04 - before you need to sign in before you
12:05 - can download this
12:07 - so this will give you a zip file as you
12:09 - can see here
12:10 - here's our csv file now i want you to
12:13 - put this
12:14 - right next to your jupyter notebook on
12:16 - my machine that is on my desktop
12:18 - so i'm going to drag and drop this onto
12:20 - the desktop folder
12:22 - now if you look at the desktop you can
12:24 - see here is my
12:25 - jupyter hello world notebook and right
12:28 - next to that we have
12:30 - vgsales.csv with that
12:33 - we go back to our jupyter notebook let's
12:35 - remove the first line
12:36 - and instead import
12:40 - pandas as pd
12:43 - with this we're importing pandas module
12:45 - and renaming it to pd
12:46 - so we don't have to type pandas dot
12:49 - several times in this code
12:51 - now let's type pd dot read
12:54 - underline csv and pass the name of our
12:58 - csv file
12:59 - that is vg sales.csv now because this
13:03 - csv file is in the current folder
13:04 - right next to our jupyter notebook we
13:06 - can easily load it otherwise we'll have
13:08 - to supply the full path to this file
13:11 - so this returns a data frame object
13:14 - which is like an excel spreadsheet let
13:17 - me show you so
13:18 - we store it here and then we can simply
13:21 - type
13:21 - df to inspect it so one more time let's
13:24 - run this program
13:26 - here's our data frame with these rows
13:28 - and columns so we have rank
13:30 - name platform and so on now this data
13:33 - frame object has lots of attributes and
13:35 - methods
13:35 - that we're not going to cover in this
13:37 - tutorial that's really beyond the scope
13:38 - of what we're going to do
13:39 - so i'll leave it up to you to read
13:41 - panda's documentation or follow other
13:43 - tutorials to learn about pandas data
13:45 - frames
13:46 - but in this lecture i'm going to show
13:47 - you some of the most useful methods
13:49 - and attributes the first one is shape so
13:52 - shape let's run this one more time so
13:55 - here's the shape of this data set
13:56 - we have over 16 000 records and
14:00 - 11 columns technically this is a two
14:03 - dimensional array
14:04 - of sixteen thousand and eleven okay
14:07 - now you can see here we have another
14:10 - segment for writing code so we don't
14:11 - have to write all the code in the first
14:13 - segment
14:14 - so here in the second segment we can
14:15 - call one of the methods of the data
14:17 - frame
14:17 - that is df dot describe
14:22 - now when we run this program we can see
14:25 - the output for each segment
14:27 - right next to it so here's our first
14:29 - segment here we have
14:30 - these three lines and this is the output
14:33 - of the last line below that we have our
14:36 - second segment
14:37 - here we're calling the describe method
14:38 - and right below that we have
14:40 - the output of this segment so this is
14:43 - the beauty of jupiter
14:44 - we can easily visualize our data doing
14:46 - this with vs code and terminal windows
14:48 - is really tedious and clunky
14:50 - so what is this describe method
14:52 - returning basically it's returning some
14:54 - basic information about each column
14:56 - in this data set so as you saw earlier
14:58 - we have columns like rank
15:00 - year and so on these are the columns
15:02 - with numerical values
15:04 - now for each column we have the count
15:07 - which is the number of records in that
15:08 - column
15:09 - you can see our rank column has 16
15:12 - 598 records whereas the year column has
15:16 - 16 327 records
15:19 - so this shows that some of our records
15:21 - don't have the value for the year column
15:24 - we have no values so in a real data
15:26 - science or
15:27 - machine learning project we'll have to
15:28 - use some techniques to clean up our data
15:30 - set
15:31 - one option is to remove the records that
15:33 - don't have a value for the year column
15:35 - or we can assign them a default value
15:38 - that really depends on the project
15:40 - now another attribute for each column is
15:42 - mean so this is the average
15:44 - of all the values now in the case of the
15:46 - rank column this value doesn't really
15:48 - matter
15:48 - but look at the year so the average year
15:51 - for all these video games in our data
15:53 - set
15:53 - is 2006 and this might be important in
15:56 - the problem we're trying to solve
15:57 - we also have standard deviation which is
16:00 - a measure
16:01 - to quantify the amount of variation in
16:03 - our set of values
16:05 - below that we have min as an example the
16:08 - minimum value for the year column
16:10 - is 1980. so quite often when we work
16:13 - with a new data set
16:14 - we call the describe method to get some
16:16 - basic statistics about our data
16:18 - let me show you another useful attribute
16:21 - so in the next segment let's type
16:24 - df.values let's run this
16:28 - as you can see this returns a
16:29 - two-dimensional array this square
16:31 - bracket indicates
16:32 - the outer array and the second one
16:36 - represents the inner array so the first
16:38 - element
16:39 - in our outer array is an array itself
16:42 - these are the values in this array which
16:45 - basically represent the first row
16:47 - in our data set so the video game with
16:49 - ranking 1
16:50 - which is called wii sports so this was a
16:53 - basic
16:53 - overview of pando's data frames in the
16:56 - next lecture i'm going to show you some
16:57 - of the useful shortcuts of jupyter
17:06 - in this lecture i'm going to show you
17:07 - some of the most useful shortcuts in
17:09 - jupyter
17:10 - now the first thing i want you to pay
17:11 - attention to is this green bar
17:13 - on the left this indicates that this
17:16 - cell is currently in the edit mode so
17:18 - we can write code here now if we press
17:21 - the escape key green turns to blue and
17:25 - that means this cell is currently in the
17:27 - command mode
17:28 - so basically the activated cell can be
17:30 - either in the edit mode or
17:32 - the command mode depending on the mode
17:34 - we have different shortcuts
17:36 - so here we're currently in the command
17:38 - mode if we press
17:40 - h we can see the list of all the
17:42 - keyboard
17:43 - shortcuts right above this list you can
17:46 - see
17:48 - mac os modifier keys these are the extra
17:51 - keys that we have on a mac keyboard
17:53 - if you're a windows user you're not
17:54 - going to see this so as an example here
17:57 - is the shape of the command key this is
18:00 - control this is
18:01 - option and so on with this guideline you
18:04 - can easily understand the shortcut
18:06 - associated with each command
18:07 - let me show you so here we have all the
18:10 - commands
18:11 - when a cell is in the command mode for
18:13 - example we have this command
18:15 - open the command palette this is exactly
18:18 - like the command palette that we have in
18:20 - vs code
18:21 - here's a shortcut to execute this
18:23 - command that is
18:24 - command shift and f okay so here we have
18:29 - lots of shortcuts of course you're not
18:31 - going to use all of them all the time
18:32 - but it's good to have a quick look here
18:34 - to see what is available for you
18:36 - with this shortcuts you can write code
18:37 - much faster so let me show you some of
18:39 - the most useful ones
18:41 - i'm going to close this now with our
18:44 - first cell
18:45 - in the command mode i'm going to press b
18:49 - and this inserts a new cell below this
18:52 - cell
18:53 - we can also go back to our first cell
18:55 - press escape
18:57 - now the cell is in the command mode we
18:59 - can insert an empty cell
19:00 - above this cell by pressing a
19:03 - so either a or b a for above and b
19:06 - for below okay now if you don't want
19:09 - this cell you can press
19:10 - d twice to delete it like this
19:14 - now in the cell i'm going to print a
19:15 - hello world message so
19:18 - print hello world now
19:22 - to run the code in this cell we can
19:24 - click on the run button here
19:27 - so here's our print function and right
19:30 - below that you can see
19:31 - the output of this function but note
19:34 - that when you run a cell
19:35 - this will only execute the code in that
19:38 - cell
19:38 - in other words the code in other cells
19:41 - will not be executed let me show you
19:43 - what i mean
19:44 - so in the cell below this cell i'm going
19:46 - to delete the call
19:47 - to describe method instead i'm going to
19:50 - print
19:51 - ocean now i'm going to put the cursor
19:55 - back in this cell where we print the
19:57 - hello world message
19:59 - and run this cell so you can see hello
20:02 - world
20:02 - is displayed here but the cell below is
20:05 - still displaying
20:06 - the described table so we don't see the
20:09 - changes here
20:10 - now to solve this problem we can go to
20:13 - the cell menu on the top
20:14 - and run all cells together
20:18 - this can work for small projects but
20:20 - sometimes you're working with a large
20:21 - data set
20:22 - so if you want to run all these cells
20:24 - together it's going to take a lot of
20:25 - time
20:26 - that is the reason jupiter saves the
20:28 - output of itself so we don't have to
20:30 - rerun that code
20:31 - if it hasn't changed so this notebook
20:34 - file that we have here
20:35 - includes our source code organized in
20:38 - cells
20:38 - as well as the output for each cell that
20:40 - is why it's different
20:42 - from a regular pi file where we only
20:44 - have the source code
20:46 - here we also have autocompletion and
20:48 - intellisense
20:49 - so in the cell let's call
20:52 - df dataframe dot
20:56 - now if you press tab we can see all the
20:58 - attributes and methods
21:00 - in this object so let's call
21:03 - describe now with the cursor on the name
21:05 - of the method we can press
21:07 - shift and tab to see this tooltip that
21:10 - describes
21:11 - what this method does and what parameter
21:13 - it takes so here in front of signature
21:15 - you can see
21:16 - the describe method these are the
21:18 - parameters
21:19 - and their default value and right below
21:21 - that you can see
21:22 - the description of what this method does
21:25 - in this case it generates
21:26 - descriptive statistics that summarize
21:28 - the central tendency and so on
21:31 - similar to vs code we can also convert a
21:33 - line to comment
21:34 - by pressing command and slash on mac or
21:37 - control slash on windows
21:40 - like this now this line is a comment we
21:42 - can press the same shortcut
21:44 - one more time to remove the comment
21:47 - so these were some of the most useful
21:48 - shortcuts in jupyter
21:50 - now over the next few lectures we're
21:51 - going to work on a real machine learning
21:53 - project
21:54 - but before we get there let's delete all
21:56 - the cells here so we start with
21:58 - only a single empty cell so here in this
22:01 - cell
22:01 - first i'm going to press the escape
22:03 - button now the cell is blue
22:05 - so we are in the command mode and we can
22:07 - delete the cell by pressing d
22:09 - twice there you go now the next cell
22:12 - is activated and it's in the command
22:14 - mode so let's delete this as well
22:17 - we have two more cells to delete there
22:19 - you go and the last one
22:21 - like this so now we have an empty
22:24 - notebook with a single cell
22:27 - hey guys i just wanted to let you know
22:29 - that i have an online coding school at
22:31 - cordwindmarch.com where you can find
22:32 - plenty of courses on web and mobile
22:34 - development
22:35 - in fact i have a comprehensive python
22:37 - course that teaches you everything about
22:38 - python from the basics to more advanced
22:41 - concepts
22:41 - so after you watch this tutorial if you
22:43 - want to learn more you may want to look
22:45 - at my python course it comes with a 30
22:46 - day money back guarantee
22:48 - and a certificate of completion you can
22:49 - add to your resume in case you're
22:51 - interested
22:52 - the link is below this video
22:58 - over the next few lectures we're going
22:59 - to work on a real machine learning
23:01 - project
23:02 - imagine we have an online music store
23:04 - when our users sign up we ask their age
23:06 - and gender and based on their profile we
23:09 - recommend
23:10 - various music albums they're likely to
23:12 - buy so in this project we want to use
23:14 - machine learning to
23:15 - increase sales so we want to build a
23:17 - model
23:18 - we feed this model with some sample data
23:21 - based on the existing users
23:23 - our model will learn the patterns in our
23:25 - data so we can ask it to make
23:26 - predictions
23:28 - when a user signs up we tell our model
23:30 - hey we have a new user with this profile
23:32 - what is the kind of music that this user
23:34 - is interested in
23:35 - our model will say jazz or hip hop or
23:38 - whatever
23:38 - and based on that we can make
23:39 - suggestions to the user so this is the
23:42 - problem we're going to solve
23:44 - now back to the list of steps in a
23:45 - machine learning project
23:47 - first we need to import our data then we
23:49 - should prepare or clean it
23:51 - next we select a machine learning
23:52 - algorithm to build a model
23:54 - we train our model and ask it to make
23:56 - predictions
23:57 - and finally we evaluate our algorithm to
24:00 - see its accuracy
24:01 - if it's not accurate we either fine tune
24:03 - our model
24:04 - or select a different algorithm so let's
24:07 - focus on the first step
24:09 - download the csv file below this video
24:11 - this is a very basic csv that i've
24:13 - created for this project
24:14 - it's just some random made up data it's
24:16 - not real
24:18 - so we have a table with three columns
24:20 - age gender
24:22 - and genre gender can either be one which
24:25 - represents a male
24:26 - or zero which represents a female here
24:29 - i'm making a few assumptions
24:30 - i'm assuming that men between 20 and 25
24:33 - like hip-hop
24:35 - men between 26 and 30 like jazz
24:38 - and after the age of 30 they like
24:40 - classical music
24:42 - for women i'm assuming that if they're
24:44 - between 20 and 25 they like dance music
24:47 - if they're between 26 and 30 they like
24:49 - acoustic music
24:51 - and just like men after the age of 30
24:53 - they like classical music
24:54 - once again this is a made-up pattern
24:56 - it's not the representation of the
24:58 - reality
24:59 - so let's go ahead and download this csv
25:01 - click on this
25:03 - dot dot icon here and download this file
25:07 - in my downloads folder here we have this
25:10 - music.csv
25:11 - i'm going to drag and drop this onto
25:13 - desktop because that's where
25:15 - i've stored this hello world notebook so
25:18 - i want you to put the csv file
25:19 - right next to your jupyter notebook
25:22 - now back to our notebook we need to read
25:24 - the csv file
25:26 - so just like before first we need to
25:28 - import the pandas module
25:30 - so import pandas as pd
25:34 - and then we'll call pd that read analyze
25:37 - csv
25:38 - and the name of our file is music.csv
25:42 - as you saw earlier this returns a data
25:44 - frame which is a two-dimensional array
25:46 - similar to an excel spreadsheet so let's
25:48 - call that
25:49 - music underline data
25:53 - now let's inspect this music underline
25:56 - data to make sure we loaded everything
25:58 - properly
25:59 - so run so here's our data frame
26:02 - beautiful next minute to prepare or
26:04 - clean the data
26:05 - and that's the topic for the next
26:08 - lecture
26:13 - the second step in a machine learning
26:15 - project is cleaning or preparing the
26:17 - data
26:17 - and that involves tasks such as removing
26:19 - duplicates
26:20 - null values and so on now in this
26:22 - particular data set we don't have to do
26:24 - any kind of cleaning because we don't
26:25 - have any duplicates
26:26 - and as you can see all rows have values
26:30 - for all columns so we don't have null
26:32 - values but there is one thing we need to
26:34 - do
26:35 - we should split this data set into two
26:38 - separate data sets
26:39 - one with the first two columns which we
26:41 - refer to as the input set
26:43 - and the other with the last column which
26:45 - we refer to as the output set
26:47 - so when we train a model we give it two
26:49 - separate data sets
26:51 - the input set and the output set the
26:53 - output set
26:54 - which is in this case the genre column
26:57 - contains
26:58 - the predictions so we're telling our
27:00 - model that if we have
27:01 - a user who's 20 years old and is a male
27:04 - they like
27:04 - hip hop once we train our model then we
27:07 - give it a new input set
27:09 - for example we say hey we have a new
27:11 - user who is 21 years old
27:13 - and is a male what is the genre of the
27:15 - music that this user probably likes
27:17 - as you can see in our input set we don't
27:20 - have a sample for a 21 year old male
27:22 - so we're going to ask our model to
27:24 - predict that
27:25 - that is the reason we need to split this
27:27 - data set into two separate sets
27:30 - input and output so back to our code
27:34 - this data frame object has a method
27:36 - called drop
27:39 - now if you put the cursor under method
27:42 - name and press
27:43 - shift and tab you can see this tooltip
27:46 - so this is the signature of this drop
27:48 - method these are the parameters that we
27:50 - can pass here
27:52 - the parameter we're going to use in this
27:53 - lecture is columns which is set to none
27:55 - by default
27:56 - with this parameter we can specify the
27:58 - columns we want to drop
28:00 - so in this case we set columns
28:04 - to an array with one string genre
28:08 - now this method doesn't actually modify
28:10 - the original data set
28:12 - in fact it will create a new data set
28:14 - but without
28:15 - this column so by convention we use a
28:19 - capital x
28:20 - to represent that data set so capital x
28:23 - equals this expression now
28:26 - let's inspect x so as you can
28:30 - see our input set or x includes these
28:32 - two columns
28:33 - age and gender it doesn't have the
28:35 - output or predictions
28:37 - next we need to create our output set so
28:41 - once again we start with our data frame
28:43 - music data
28:45 - using square brackets we can get all the
28:47 - values in a given column
28:49 - in this case genre once again this
28:52 - returns
28:53 - a new data set by convention we use a
28:55 - lowercase y
28:56 - to represent that so that is our output
28:59 - data set
29:00 - let's inspect that as well
29:03 - so in this data set we only have the
29:06 - predictions or
29:07 - the answers so we have prepared our data
29:10 - next we need to create a model using an
29:12 - algorithm
29:19 - the next step is to build a model using
29:21 - a machine learning algorithm
29:22 - there are so many algorithms out there
29:24 - and each algorithm has its pros and cons
29:27 - in terms of the performance and accuracy
29:29 - in this lecture we're going to use a
29:30 - very simple algorithm called
29:32 - decision tree now the good news is that
29:34 - we don't have to explicitly
29:36 - program these algorithms they're already
29:38 - implemented for us in a library called
29:40 - scikit-learn so here on the top
29:45 - from sklearn.3
29:49 - let's import the decision
29:52 - tree classifier so sklearn
29:56 - is the package that comes with
29:58 - scikit-learn library this is the most
30:00 - popular machine learning library in
30:01 - python
30:02 - in this package we have a module called
30:05 - tree and in this module we have a class
30:07 - called
30:07 - decision tree classifier this class
30:10 - implements
30:11 - the decision tree algorithm okay so
30:14 - now we need to create a new instance of
30:16 - this class
30:18 - so at the end let's create an object
30:21 - called
30:21 - model and set it to a new instance of
30:24 - decision
30:26 - tree classifier
30:29 - like this so now we have a model next we
30:32 - need to train it so it learns
30:33 - patterns in the data and that is pretty
30:35 - easy we call
30:37 - model that fit this method takes two
30:40 - data sets
30:41 - the input set and the output set so
30:44 - they are capital x and y
30:48 - now finally we need to ask our model to
30:50 - make a prediction
30:52 - so we can ask it what is the kind of
30:53 - music that a 21 year old male likes
30:56 - now before we do that let's temporarily
30:59 - inspect
31:00 - our initial data set that is music data
31:04 - so look what we got here
31:07 - as i told you earlier i've assumed that
31:09 - men between 20
31:10 - and 25 like hip-hop music but here we
31:13 - only have
31:14 - three samples for men aged 20
31:17 - 23 and 25 we don't have a sample for a
31:20 - 21 year old male
31:22 - so if you ask our model to predict the
31:23 - kind of music that a 21 year old male
31:25 - likes we expect it to say
31:27 - hip hop similarly i've assumed that
31:30 - women between 20 and 25
31:32 - like dance music but we don't have a
31:34 - sample for a 22 year old female
31:36 - so once again if you ask our model to
31:38 - predict the kind of music
31:40 - that a 22 year old woman likes we expect
31:42 - it to say
31:43 - dance so with these assumptions
31:46 - let's go ahead and ask our model to make
31:48 - predictions
31:50 - so let's remove
31:53 - the last line and instead we're going to
31:56 - call
31:56 - model dot predict this method
32:00 - takes a two dimensional array so here's
32:03 - the outer array
32:04 - in this array each element is an array
32:07 - so i'm going to pass
32:08 - another array here and in this array i'm
32:10 - going to pass
32:11 - a new input set a 21 year old male
32:14 - so 21 comma one that is like a new
32:17 - record
32:18 - in this table okay so this is one input
32:22 - set
32:22 - let's pass another input set for a
32:24 - 22-year female
32:26 - so here's another array here we add 22
32:29 - comma zero so we're asking our model to
32:32 - make two predictions at the same time
32:34 - we get the result and store it in a
32:38 - variable called predictions
32:39 - and finally let's inspect that in our
32:43 - notebook
32:44 - run look what we got
32:48 - our model is saying that a 21 year old
32:50 - male
32:51 - likes hip hop and a 22 year old female
32:53 - likes
32:54 - dance music so our model could
32:56 - successfully make predictions here
32:58 - beautiful but wait a second building a
33:00 - model that makes predictions accurately
33:02 - is not always that easy
33:03 - as i told you earlier after we build a
33:05 - model we need to measure its accuracy
33:08 - and if it's not accurate enough we
33:10 - should either fine tune it or build a
33:11 - model using a different algorithm
33:13 - so in the next lecture i'm going to show
33:15 - you how to measure the accuracy of a
33:22 - model
33:24 - in this lecture i'm going to show you
33:25 - how to measure the accuracy of your
33:27 - models
33:28 - now in order to do so first we need to
33:30 - split our data set
33:31 - into two sets one for training and the
33:34 - other for testing
33:35 - because right now we're passing the
33:37 - entire data set
33:38 - for training the model and we're using
33:40 - two samples
33:42 - for making predictions that is not
33:44 - enough to calculate the accuracy of a
33:46 - model
33:46 - a general rule of thumb is to allocate
33:49 - 70 to 80 percent of our data
33:51 - for training and the other twenty to
33:53 - thirty percent for testing
33:54 - then instead of passing only two samples
33:57 - for making predictions
33:58 - we can pass the data set we have for
34:00 - testing we'll get the predictions
34:02 - and then we can compare these
34:03 - predictions with the actual values
34:06 - in the test set based on that we can
34:08 - calculate the accuracy
34:09 - that's really easy all we have to do is
34:11 - to import a couple of functions
34:13 - and call them in this code let me show
34:15 - you so first on the top
34:18 - from sklearn the model
34:21 - underline selection module we import
34:24 - a function called train test split
34:28 - with this function we can easily split
34:30 - our data set into two sets
34:32 - for training and testing now
34:35 - right here after we define x and y sets
34:39 - we call this function
34:40 - so train test split
34:44 - we give it three arguments x y
34:47 - and a keyboard argument that specifies
34:50 - the size of our test data set
34:52 - so test underline size we set it to 0.2
34:57 - so we are allocating 20 of our data for
34:59 - testing
35:00 - now this function returns a tuple so we
35:03 - can unpack it into four variables
35:05 - right here x underline train
35:09 - x underline test y underline train
35:13 - and y underline test
35:16 - so the first two variables are the input
35:19 - sets for training
35:20 - and testing and the other are the output
35:24 - sets
35:24 - for training and testing now when
35:27 - training our model
35:29 - instead of passing the entire data set
35:31 - we want to pass only
35:32 - the training data set so x
35:36 - underline train and y
35:39 - underline train also when making
35:42 - predictions
35:42 - instead of passing these two samples we
35:44 - pass x
35:46 - underline test so that is the data set
35:49 - that contains
35:50 - input values for testing now we get
35:53 - the predictions to calculate the
35:55 - accuracy we simply have to compare these
35:57 - predictions
35:58 - with the actual values we have in our
36:01 - output set
36:02 - for testing that is very easy first on
36:05 - the top we need to import
36:06 - a function so from sklearn.metrics
36:10 - metrics
36:11 - import accuracy underlying score
36:16 - now at the very end we call this
36:17 - function so accuracy
36:20 - score and
36:23 - give it two arguments y underline test
36:26 - which contains
36:27 - the expected values and predictions
36:31 - which contains the actual values now
36:34 - this function returns
36:35 - an accuracy score between zero to one so
36:38 - we can store it here
36:41 - and simply display it on the console
36:44 - so let's go ahead and run this program
36:48 - so the accuracy score is one or 100
36:50 - percent
36:51 - but if we run this one more time we're
36:53 - going to see a different result
36:55 - because every time we split our data set
36:57 - into training and test sets
36:58 - we'll have different data sets because
37:00 - this function randomly picks data
37:02 - for training and testing let me show you
37:05 - so put the cursor
37:06 - in the cell now you can see this cell is
37:08 - activated note that if you click this
37:10 - button here
37:11 - it will run this cell and also inserts a
37:14 - new cell
37:15 - below this cell let me show you so if i
37:17 - go to the second cell
37:19 - press escape button now we are in the
37:21 - command mode
37:22 - press d twice okay now it's deleted
37:26 - if we click the run button you can see
37:29 - this code was executed and now we have a
37:31 - new cell
37:32 - so if you want to run our first cell
37:34 - multiple times every time we have to
37:36 - click this
37:36 - and then run it and then click again and
37:38 - run it it's a little bit tedious
37:40 - so i'll show you a shortcut activate the
37:42 - first cell
37:44 - and press ctrl and enter
37:47 - this runs the current cell without
37:49 - adding a new cell
37:50 - below it so back here let's run it
37:53 - multiple times
37:54 - okay now look the accuracy dropped to
37:57 - 0.75
37:58 - it's still good so the accuracy score
38:00 - here is somewhere between
38:02 - 75 to 100 but let me show you something
38:06 - if i change the test size from 0.2
38:10 - to 0.8 so essentially we're using only
38:13 - 20
38:13 - of our data for training this model and
38:16 - we're using the other 80
38:17 - for testing now let's see what happens
38:20 - when we run this cell multiple times
38:22 - so control and enter look the accuracy
38:25 - immediately dropped to 0.4
38:27 - one more time now 46 percent
38:30 - 40 26 it's really really bad
38:35 - the reason this is happening is because
38:37 - we are using very little data
38:39 - for training this model this is one of
38:41 - the key concepts in machine learning
38:43 - the more data we give to our model and
38:45 - the cleaner the data is
38:46 - we get the better result so if we have
38:49 - duplicates
38:50 - irrelevant data or incomplete values our
38:52 - model will learn
38:53 - bad patterns in our data that is why
38:55 - it's really important to clean our data
38:57 - before training our model now let's
39:00 - change this back to 0.2
39:03 - run this one more time okay now the
39:05 - accuracy is one
39:06 - 75 percent now we drop to 50
39:10 - again the reason this is happening is
39:11 - because we don't have enough data
39:14 - some machine learning problems require
39:16 - thousands or even millions of samples
39:18 - to train a model the more complex the
39:20 - problem is the more data we need
39:22 - for example here we're only dealing with
39:24 - a table of three columns
39:26 - but if you want to build a model to tell
39:28 - if a picture is a cat or a dog or a
39:30 - horse or a lion
39:31 - we'll need millions of pictures the more
39:33 - animals we want to support the more
39:34 - pictures we need
39:36 - in the next lecture we're going to talk
39:37 - about model persistence
39:45 - so this is a very basic implementation
39:47 - of building and training a model to make
39:49 - predictions
39:51 - now to simplify things i have removed
39:53 - all the code that we wrote in the last
39:54 - lecture for
39:55 - calculating the accuracy because in this
39:57 - lecture we're going to focus
39:58 - on a different topic so basically we
40:01 - import our data set
40:03 - create a model train it and then
40:06 - ask it to make predictions now this
40:08 - piece of code that you see
40:10 - here is not what we want to run every
40:12 - time we have a new user or every time we
40:14 - want to make recommendations
40:16 - to an existing user because training a
40:18 - model can sometimes be really time
40:19 - consuming
40:20 - in this example we're dealing with a
40:22 - very small data set that has
40:23 - only 20 records but in real applications
40:26 - we might have a data set
40:27 - with thousands or millions of samples
40:30 - training a model for that might take
40:31 - seconds
40:32 - minutes or even hours so that is why
40:35 - model persistence is important
40:37 - once in a while we build and train our
40:39 - model and then we'll save it to a file
40:42 - now next time we want to make
40:43 - predictions we simply load the model
40:45 - from the file and
40:46 - ask it to make predictions that model is
40:49 - already trained we don't need to retrain
40:51 - it
40:51 - it's like an intelligent person so let
40:54 - me show you how to do this it's very
40:55 - very easy
40:57 - on the top from sklearn.externals
41:02 - module we import
41:05 - lib this job live object has methods for
41:08 - saving
41:09 - and loading models so after
41:12 - we train our model we simply call
41:15 - joblib dot dump
41:18 - and give it two arguments our model and
41:21 - the name of the file
41:22 - in which we want to store this model
41:24 - let's call that
41:25 - music dash recommender
41:28 - dot job lib that's all we have to do
41:33 - now temporarily i'm going to comment out
41:34 - this line we don't want to make any
41:36 - predictions we just want to store our
41:38 - trained model in a file
41:40 - so let's run this cell with control and
41:42 - slash
41:44 - okay look in the output we have an array
41:48 - that contains the name of our model file
41:50 - so this is the return value of the dump
41:52 - method
41:53 - now back to our desktop right next to my
41:55 - notebook you can see our job live file
41:57 - this is where our model is stored it's
41:59 - simply a binary file
42:01 - now back to our jupyter notebook as i
42:04 - told you before in a real application we
42:05 - don't want to train a model
42:07 - every time so let's comment out
42:10 - these few lines so i've selected these
42:12 - few lines on mac we can press
42:14 - command and slash on windows control
42:17 - slash
42:18 - okay these lines are commented out now
42:20 - this time instead of dumping our model
42:23 - we're going to load it so we call the
42:24 - load method we don't have the model we
42:27 - simply pass
42:28 - the name of our model file this returns
42:31 - our trained
42:32 - model now with these two lines we can
42:35 - simply
42:35 - make predictions so earlier we assumed
42:38 - that men between 20 and 25
42:40 - like hip-hop music let's print
42:43 - predictions and see if our model is
42:45 - behaving correctly or not
42:47 - so control and enter there you go
42:50 - so this is how we persist and load
42:56 - models
42:59 - earlier in this section i told you that
43:01 - decision trees are the easiest to
43:03 - understand and that's why we started
43:04 - machine learning
43:05 - with decision trees in this lecture
43:07 - we're going to export our model in a
43:09 - visual format
43:10 - so you will see how this model makes
43:12 - predictions
43:13 - that is really really cool let me show
43:15 - you so
43:17 - once again i've simplified this code so
43:19 - we simply import
43:21 - our data set create input and output
43:24 - sets
43:25 - create a model and train it
43:28 - that's all we are doing now i want you
43:30 - to follow along with me
43:32 - type everything exactly as i show you in
43:34 - this lecture don't worry about
43:35 - what everything means we're going to
43:36 - come back to it shortly so
43:39 - on the top from sklearn
43:42 - import tree this object
43:45 - has a method for exporting our decision
43:48 - tree in a graphical format
43:50 - so after we train our model let's call
43:53 - tree dot export underline
43:56 - graph vis now here are a few arguments
43:59 - we need to pass
44:00 - the first argument is our model the
44:03 - second is the name of the output file
44:05 - so here we're going to use keyword
44:07 - arguments because this method takes so
44:09 - many parameters and we want to
44:10 - selectively pass
44:11 - keyword arguments without worrying about
44:13 - their order
44:14 - so the parameter we're going to set is
44:17 - out
44:18 - underline file let's set this to
44:21 - music dash recommender dot
44:25 - d o t this is the dot format which is a
44:28 - graph
44:28 - description language you'll see that
44:30 - shortly
44:31 - the other parameter we want to set is
44:34 - feature
44:35 - underline names we set this to an array
44:38 - of two strings age and
44:41 - gender these are the features or the
44:43 - columns
44:44 - of our data set so they are the
44:46 - properties or features of our data
44:48 - okay the other parameter is class names
44:52 - so class underline names we should set
44:55 - this to the list of classes
44:57 - or labels we have in our output data set
45:00 - like hip hop jazz classical and so on
45:04 - so this y data set includes all the
45:06 - genres or all the classes of our data
45:09 - but they're repeated a few times in this
45:11 - data set so
45:13 - here we call y dot unique this returns
45:16 - the unique list of classes now we should
45:19 - sort this alphabetically
45:20 - so we call the sorted function and
45:24 - pass the result a y dot unique
45:28 - the next parameter is label we set this
45:32 - to a string
45:33 - all once again don't worry about the
45:35 - details of these parameters we're going
45:37 - to come back to this shortly
45:39 - so set label to all then
45:42 - round it to true and finally
45:45 - filled to true so this is the end result
45:50 - now let's run this cell using control
45:52 - and enter
45:53 - okay here we have a new file
45:57 - music recommender dot dot that's a
45:59 - little bit funny
46:00 - so we want to open this file with vs
46:03 - code so drag and drop this
46:05 - into a vs code window
46:10 - okay here's a dot format it's a textual
46:12 - language for describing graphs
46:15 - now to visualize this graph we need to
46:17 - install an extension in vs code
46:19 - so on the left side click the extensions
46:22 - panel
46:22 - and search for dot dot
46:26 - look at the second extension here
46:28 - graphviz or dot
46:30 - language by staphon vs
46:33 - go ahead and install this extension and
46:35 - then reload vs code
46:37 - once you do that you can visualize this
46:39 - dot file
46:40 - so let me close this tab all right
46:44 - look at this dot dot here on the right
46:46 - side click this
46:47 - you should have a new menu open preview
46:49 - to the site
46:50 - so click that all right here's the
46:53 - visualization
46:54 - of our decision tree let's close the dot
46:57 - file
46:58 - there you go this is exactly how our
47:00 - model makes predictions
47:02 - so we have this binary tree which means
47:04 - every node can have
47:06 - a maximum of two children on top of each
47:09 - node we have
47:10 - a condition if this condition is true we
47:12 - go to the child node on the left side
47:14 - otherwise we go to the child node on the
47:16 - right side so let's see what's happening
47:18 - here
47:19 - the first condition is age less than or
47:22 - equal to 30.5
47:24 - if this condition is false that means
47:26 - that user is 30 years or older
47:28 - so the genre of the music that they're
47:30 - interested in is classical
47:32 - so here we're classifying people based
47:35 - on their profile
47:36 - that is the reason we have the word
47:38 - class here so a user who is 30 years or
47:41 - older
47:41 - belongs to the class of classical or
47:44 - people who like
47:45 - classical music now what if this
47:47 - condition is true
47:49 - that means that user is younger than 30.
47:52 - so now we check the gender if it's less
47:55 - than
47:55 - 0.5 which basically means if it equals
47:58 - to 0
47:59 - then we're dealing with a female so we
48:01 - go to the child node here
48:03 - now once again we have another condition
48:05 - so we're dealing with a female who is
48:07 - younger than 30.
48:08 - once again we need to check their age so
48:11 - is the age
48:12 - less than 25.5 if that's the case then
48:16 - that user likes dance music otherwise
48:18 - they like acoustic music
48:21 - so this is the decision tree that our
48:22 - model uses to make
48:24 - predictions now if you're wondering why
48:26 - we have these floating point numbers
48:28 - like 25.5 these are basically the rules
48:31 - that our model generates
48:32 - based on the patterns that it finds in
48:34 - our data set
48:36 - as we give our model more data these
48:38 - rules will change so they're not always
48:40 - the same
48:41 - also the more columns or more features
48:43 - we have our decision tree is going to
48:45 - get more complex
48:46 - currently we have only two features age
48:48 - and gender
48:50 - now back to our code let me quickly
48:51 - explain the meaning of all these
48:53 - parameters
48:54 - we set fill to true so each box or each
48:56 - node is filled with a color
48:58 - we set rounded to true so they have
49:01 - rounded corners
49:03 - we set label to all so every node has
49:05 - labels that we can read
49:08 - we set class names to the unique list of
49:10 - genres
49:11 - and that's for displaying the class for
49:12 - each node right here
49:14 - and we set feature names to age and
49:16 - gender
49:17 - so we can see the rules in our notes
49:22 - hey thank you for watching my tutorial i
49:24 - hope you learned a lot and you're
49:25 - excited to learn more
49:27 - if you enjoyed this tutorial please like
49:29 - and share it with others and be sure to
49:30 - subscribe to my channel
49:31 - as i upload new videos every week once
49:34 - again thank you and i wish you all the
49:36 - [Music]
49:41 - best

Cleaned transcript:

if you're looking for a machine learning tutorial with python and jupyter notebook this tutorial is for you you're going to learn how to solve a real world problem using machine learning and python we're going to start off with a brief introduction to machine learning then we're going to talk about the tools you need and after that we're going to jump straight into the problem we're going to solve you'll learn how to build a model that can learn and predict the kind of music people like so by the end of this one hour tutorial you will have a good understanding of machine learning basics and you'll be able to learn more intermediate to advanced level concepts you don't need any prior knowledge in machine learning but you need to know python fairly well if you don't i've got a couple of tutorials for you here on my channel the links are below this video i'm ashamed only and i'm super excited to be your instructor on this channel i have tons of programming tutorials that you might find helpful so be sure to subscribe as i upload new tutorials every week now let's jump in and get started in this section you're going to learn about machine learning which is a subset of ai or artificial intelligence it's one of the trending topics in the world these days and it's going to have a lot of applications in the future here's an example imagine i ask you to write a program to scan an image and tell if it's a cat or a doc if you want to build this program using traditional programming techniques your program is going to get overly complex you will have to come up with lots of rules to look for specific curves edges and colors in an image to tell if it's a cat or a dog but if i give you a black and white photo your rules may not work they may break then you'll have to rewrite them or i might give you a picture of a cat or a dog from a different angle that you did not predict before so solving this problem using traditional programming techniques is going to get overly complex or sometimes impossible now to make the matter worse what if in the future i ask you to extend this program such that it supports three kinds of animals cats dogs and horses once again you'll have to rewrite all those rules that's not gonna work so machine learning is a technique to solve these kind of problems and this is how it works we build a model or an engine and give it lots and lots of data for example we give you thousands or tens of thousands of pictures of cats and dogs our model will then find and learn patterns in the input data so we can give it a new picture of a cat that it hasn't seen before and ask it is it a cat or a dog or a horse and it will tell us with a certain level of accuracy the more input data we give it the more accurate our model is going to be so that was a very basic example but machine learning has other applications in selfdriving cars robotics language processing vision processing forecasting things like stock market trends and the weather games and so on so that's the basic idea about machine learning next we'll look at machine learning in action a machine learning project involves a number of steps the first step is to import our data which often comes in the form of a csv file you might have a database with lots of data we can simply export that data and store it in a csv file for the purpose of our machine learning project so we import our data next we need to clean it and this involves tasks such as removing duplicated data if you have duplicates in the data we don't want to feed this to our model because otherwise our model will learn bad patterns in the data and it will produce the wrong result so we should make sure that our input data is in a good and clean shape if there are data that is irrelevant we should remove them if they are duplicated or incomplete we can remove or modify them if our data is textbased like the name of countries or genres of music or cats and dogs we need to convert them to numerical values so this step really depends on the kind of data we're working with every project is different now that we have a clean data set we need to split it into two segments one for training our model and the other for testing it to make sure that our model produces the right result for example if you have a thousand pictures of cats and dogs we can reserve eighty percent for training and the other 20 for testing the next step is to create a model and this involves selecting an algorithm to analyze the data there are so many different machine learning algorithms out there such as decision trees neural networks and so on each algorithm has pros and cons in terms of accuracy and performance so the algorithm you choose depends on the kind of problem you're trying to solve and your input data now the good news is that we don't have to explicitly program an algorithm there are libraries out there that provide these algorithms one of the most popular ones which we are going to look at in this tutorial is scikitlearn so we build a model using an algorithm next we need to train our model so we fitted our training data our model will then look for the patterns in the data so next we can ask it to make predictions back to our example of cats and dogs we can ask our model is this a cat or a dog and our model will make a prediction now the prediction is not always accurate in fact when you start out it's very likely that your predictions are inaccurate so we need to evaluate the predictions and measure their accuracy then we need to get back to our model and either select a different algorithm that is going to produce a more accurate result for the kind of problem we're trying to solve or finetune the parameters of our model so each algorithm has parameters that we can modify to optimize the accuracy so these are the high level steps that you follow in a machine learning project next we'll look at the libraries and tools for machine learning in this lecture we're going to look at the popular python libraries that we use in machine learning projects the first one is numpy which provides a multidimensional array very very popular library the second one is pandas which is a data analysis library that provides a concept called data frame a data frame is a twodimensional data structure similar to an excel spreadsheet so we have rows and columns we can select data in a row or a column or a range of rows and columns again very very popular in machine learning and data science projects the third library is matplotlib which is a twodimensional plotting library for creating graphs and plots the next library is scikitlearn which is one of the most popular machine learning libraries that provides all these common algorithms like decision trees neural networks and so on now when working with machine learning projects we use an environment called jupiter for writing our code technically we can still use vs code or any other code editors but these editors are not ideal for machine learning projects because we frequently need to inspect the data and that is really hard in environments like vs code and terminal if you're working with a table of 10 or 20 columns visualizing this data in a terminal window is really really difficult and messy so that's why we use jupiter it makes it really easy to inspect our data now to install jupyter we're going to use a platform called anaconda so head over to anaconda.com download on this page you can download anaconda distribution for your operating system so we have distributions for windows mac and linux so let's go ahead and install anaconda for python 3.7 download all right so here's anaconda downloaded on my machine let's double click this all right first it's going to run a program to determine if the software can be installed so let's continue and once again continue continue pretty easy continue one more time i agree with the license agreement okay you can use the default installation location so don't worry about that just click install give it a few seconds now the beautiful thing about anaconda is that it will install jupyter as well as all those popular data science libraries like numpy pandas and so on so we don't have to manually install this using pip all right now as part of the next step anaconda is suggesting to install microsoft vs code we already have this on our machine so we don't have to install it we can go with continue and close the installation now finally we can move this to trash because we don't need this installer in the future all right now open up a terminal window and type jupyter with a y space notebook this will start the notebook server on your machine so enter there you go this will start the notebook server on your machine you can see these default messages here don't worry about them now it automatically opens a browser window pointing to localhost port 888 this is what we call jupiter dashboard on this dashboard we have a few tabs the first tab is the files tab and by default this points to your home directory so every user on your machine has a home directory this is my home directory on mac you can see here we have a desktop folder as well as documents downloads and so on on your machine you're going to see different folders so someone on your machine you need to create a jupyter notebook i'm going to go to desktop here's my desktop i don't have anything here and then click new i want to create a notebook for python 3. in this notebook we can write python code and execute it line by line we can easily visualize our data as you will see over the next few videos so let's go ahead with this all right here's our first notebook you can see by default it's called untitled let's change that to hello world so this is going to be the hello world of our machine learning project let's rename this now if you look at your desktop you can see this file helloworld.i pi nb this is a jupiter notebook it's kind of similar to our pi files where we write our python code but it includes additional data that jupiter uses to execute our code so back to our notebook let's do a print hello world and then click this run button here and here's the result printed in jupyter so we don't have to navigate back and forth between the terminal window we can see all the result right here next i'm going to show you how to load a data set from a csv file in jupyter all right in this lecture we're going to download a data set from a very popular website called kaggle.com gaggle is basically a place to do data science projects so the first thing you need to do is to create an account you can sign up with facebook google or using a custom email and password once you sign up then come back here on kaggle.com here in the search bar search for video game sales this is the name of a very popular data set that we're going to use in this lecture so here in this list you can see the first item with this kind of reddish icon so let's go with that as you can see this data set includes the sales data for more than 16 000 video games on this page you can see the description of various columns in this data set we have rank name platform year and so on so here's our data source it's a csv file called vgsales.csv as you can see there are over 16 000 rows and 11 columns in this data set right below that you can see the first few records of this data set so here's our first record the ranking for this game is one it's the wii sports game for we as the platform and it was released in year 2006 now what i want you to do is to go ahead and download this data set and as i told you before you need to sign in before you can download this so this will give you a zip file as you can see here here's our csv file now i want you to put this right next to your jupyter notebook on my machine that is on my desktop so i'm going to drag and drop this onto the desktop folder now if you look at the desktop you can see here is my jupyter hello world notebook and right next to that we have vgsales.csv with that we go back to our jupyter notebook let's remove the first line and instead import pandas as pd with this we're importing pandas module and renaming it to pd so we don't have to type pandas dot several times in this code now let's type pd dot read underline csv and pass the name of our csv file that is vg sales.csv now because this csv file is in the current folder right next to our jupyter notebook we can easily load it otherwise we'll have to supply the full path to this file so this returns a data frame object which is like an excel spreadsheet let me show you so we store it here and then we can simply type df to inspect it so one more time let's run this program here's our data frame with these rows and columns so we have rank name platform and so on now this data frame object has lots of attributes and methods that we're not going to cover in this tutorial that's really beyond the scope of what we're going to do so i'll leave it up to you to read panda's documentation or follow other tutorials to learn about pandas data frames but in this lecture i'm going to show you some of the most useful methods and attributes the first one is shape so shape let's run this one more time so here's the shape of this data set we have over 16 000 records and 11 columns technically this is a two dimensional array of sixteen thousand and eleven okay now you can see here we have another segment for writing code so we don't have to write all the code in the first segment so here in the second segment we can call one of the methods of the data frame that is df dot describe now when we run this program we can see the output for each segment right next to it so here's our first segment here we have these three lines and this is the output of the last line below that we have our second segment here we're calling the describe method and right below that we have the output of this segment so this is the beauty of jupiter we can easily visualize our data doing this with vs code and terminal windows is really tedious and clunky so what is this describe method returning basically it's returning some basic information about each column in this data set so as you saw earlier we have columns like rank year and so on these are the columns with numerical values now for each column we have the count which is the number of records in that column you can see our rank column has 16 598 records whereas the year column has 16 327 records so this shows that some of our records don't have the value for the year column we have no values so in a real data science or machine learning project we'll have to use some techniques to clean up our data set one option is to remove the records that don't have a value for the year column or we can assign them a default value that really depends on the project now another attribute for each column is mean so this is the average of all the values now in the case of the rank column this value doesn't really matter but look at the year so the average year for all these video games in our data set is 2006 and this might be important in the problem we're trying to solve we also have standard deviation which is a measure to quantify the amount of variation in our set of values below that we have min as an example the minimum value for the year column is 1980. so quite often when we work with a new data set we call the describe method to get some basic statistics about our data let me show you another useful attribute so in the next segment let's type df.values let's run this as you can see this returns a twodimensional array this square bracket indicates the outer array and the second one represents the inner array so the first element in our outer array is an array itself these are the values in this array which basically represent the first row in our data set so the video game with ranking 1 which is called wii sports so this was a basic overview of pando's data frames in the next lecture i'm going to show you some of the useful shortcuts of jupyter in this lecture i'm going to show you some of the most useful shortcuts in jupyter now the first thing i want you to pay attention to is this green bar on the left this indicates that this cell is currently in the edit mode so we can write code here now if we press the escape key green turns to blue and that means this cell is currently in the command mode so basically the activated cell can be either in the edit mode or the command mode depending on the mode we have different shortcuts so here we're currently in the command mode if we press h we can see the list of all the keyboard shortcuts right above this list you can see mac os modifier keys these are the extra keys that we have on a mac keyboard if you're a windows user you're not going to see this so as an example here is the shape of the command key this is control this is option and so on with this guideline you can easily understand the shortcut associated with each command let me show you so here we have all the commands when a cell is in the command mode for example we have this command open the command palette this is exactly like the command palette that we have in vs code here's a shortcut to execute this command that is command shift and f okay so here we have lots of shortcuts of course you're not going to use all of them all the time but it's good to have a quick look here to see what is available for you with this shortcuts you can write code much faster so let me show you some of the most useful ones i'm going to close this now with our first cell in the command mode i'm going to press b and this inserts a new cell below this cell we can also go back to our first cell press escape now the cell is in the command mode we can insert an empty cell above this cell by pressing a so either a or b a for above and b for below okay now if you don't want this cell you can press d twice to delete it like this now in the cell i'm going to print a hello world message so print hello world now to run the code in this cell we can click on the run button here so here's our print function and right below that you can see the output of this function but note that when you run a cell this will only execute the code in that cell in other words the code in other cells will not be executed let me show you what i mean so in the cell below this cell i'm going to delete the call to describe method instead i'm going to print ocean now i'm going to put the cursor back in this cell where we print the hello world message and run this cell so you can see hello world is displayed here but the cell below is still displaying the described table so we don't see the changes here now to solve this problem we can go to the cell menu on the top and run all cells together this can work for small projects but sometimes you're working with a large data set so if you want to run all these cells together it's going to take a lot of time that is the reason jupiter saves the output of itself so we don't have to rerun that code if it hasn't changed so this notebook file that we have here includes our source code organized in cells as well as the output for each cell that is why it's different from a regular pi file where we only have the source code here we also have autocompletion and intellisense so in the cell let's call df dataframe dot now if you press tab we can see all the attributes and methods in this object so let's call describe now with the cursor on the name of the method we can press shift and tab to see this tooltip that describes what this method does and what parameter it takes so here in front of signature you can see the describe method these are the parameters and their default value and right below that you can see the description of what this method does in this case it generates descriptive statistics that summarize the central tendency and so on similar to vs code we can also convert a line to comment by pressing command and slash on mac or control slash on windows like this now this line is a comment we can press the same shortcut one more time to remove the comment so these were some of the most useful shortcuts in jupyter now over the next few lectures we're going to work on a real machine learning project but before we get there let's delete all the cells here so we start with only a single empty cell so here in this cell first i'm going to press the escape button now the cell is blue so we are in the command mode and we can delete the cell by pressing d twice there you go now the next cell is activated and it's in the command mode so let's delete this as well we have two more cells to delete there you go and the last one like this so now we have an empty notebook with a single cell hey guys i just wanted to let you know that i have an online coding school at cordwindmarch.com where you can find plenty of courses on web and mobile development in fact i have a comprehensive python course that teaches you everything about python from the basics to more advanced concepts so after you watch this tutorial if you want to learn more you may want to look at my python course it comes with a 30 day money back guarantee and a certificate of completion you can add to your resume in case you're interested the link is below this video over the next few lectures we're going to work on a real machine learning project imagine we have an online music store when our users sign up we ask their age and gender and based on their profile we recommend various music albums they're likely to buy so in this project we want to use machine learning to increase sales so we want to build a model we feed this model with some sample data based on the existing users our model will learn the patterns in our data so we can ask it to make predictions when a user signs up we tell our model hey we have a new user with this profile what is the kind of music that this user is interested in our model will say jazz or hip hop or whatever and based on that we can make suggestions to the user so this is the problem we're going to solve now back to the list of steps in a machine learning project first we need to import our data then we should prepare or clean it next we select a machine learning algorithm to build a model we train our model and ask it to make predictions and finally we evaluate our algorithm to see its accuracy if it's not accurate we either fine tune our model or select a different algorithm so let's focus on the first step download the csv file below this video this is a very basic csv that i've created for this project it's just some random made up data it's not real so we have a table with three columns age gender and genre gender can either be one which represents a male or zero which represents a female here i'm making a few assumptions i'm assuming that men between 20 and 25 like hiphop men between 26 and 30 like jazz and after the age of 30 they like classical music for women i'm assuming that if they're between 20 and 25 they like dance music if they're between 26 and 30 they like acoustic music and just like men after the age of 30 they like classical music once again this is a madeup pattern it's not the representation of the reality so let's go ahead and download this csv click on this dot dot icon here and download this file in my downloads folder here we have this music.csv i'm going to drag and drop this onto desktop because that's where i've stored this hello world notebook so i want you to put the csv file right next to your jupyter notebook now back to our notebook we need to read the csv file so just like before first we need to import the pandas module so import pandas as pd and then we'll call pd that read analyze csv and the name of our file is music.csv as you saw earlier this returns a data frame which is a twodimensional array similar to an excel spreadsheet so let's call that music underline data now let's inspect this music underline data to make sure we loaded everything properly so run so here's our data frame beautiful next minute to prepare or clean the data and that's the topic for the next lecture the second step in a machine learning project is cleaning or preparing the data and that involves tasks such as removing duplicates null values and so on now in this particular data set we don't have to do any kind of cleaning because we don't have any duplicates and as you can see all rows have values for all columns so we don't have null values but there is one thing we need to do we should split this data set into two separate data sets one with the first two columns which we refer to as the input set and the other with the last column which we refer to as the output set so when we train a model we give it two separate data sets the input set and the output set the output set which is in this case the genre column contains the predictions so we're telling our model that if we have a user who's 20 years old and is a male they like hip hop once we train our model then we give it a new input set for example we say hey we have a new user who is 21 years old and is a male what is the genre of the music that this user probably likes as you can see in our input set we don't have a sample for a 21 year old male so we're going to ask our model to predict that that is the reason we need to split this data set into two separate sets input and output so back to our code this data frame object has a method called drop now if you put the cursor under method name and press shift and tab you can see this tooltip so this is the signature of this drop method these are the parameters that we can pass here the parameter we're going to use in this lecture is columns which is set to none by default with this parameter we can specify the columns we want to drop so in this case we set columns to an array with one string genre now this method doesn't actually modify the original data set in fact it will create a new data set but without this column so by convention we use a capital x to represent that data set so capital x equals this expression now let's inspect x so as you can see our input set or x includes these two columns age and gender it doesn't have the output or predictions next we need to create our output set so once again we start with our data frame music data using square brackets we can get all the values in a given column in this case genre once again this returns a new data set by convention we use a lowercase y to represent that so that is our output data set let's inspect that as well so in this data set we only have the predictions or the answers so we have prepared our data next we need to create a model using an algorithm the next step is to build a model using a machine learning algorithm there are so many algorithms out there and each algorithm has its pros and cons in terms of the performance and accuracy in this lecture we're going to use a very simple algorithm called decision tree now the good news is that we don't have to explicitly program these algorithms they're already implemented for us in a library called scikitlearn so here on the top from sklearn.3 let's import the decision tree classifier so sklearn is the package that comes with scikitlearn library this is the most popular machine learning library in python in this package we have a module called tree and in this module we have a class called decision tree classifier this class implements the decision tree algorithm okay so now we need to create a new instance of this class so at the end let's create an object called model and set it to a new instance of decision tree classifier like this so now we have a model next we need to train it so it learns patterns in the data and that is pretty easy we call model that fit this method takes two data sets the input set and the output set so they are capital x and y now finally we need to ask our model to make a prediction so we can ask it what is the kind of music that a 21 year old male likes now before we do that let's temporarily inspect our initial data set that is music data so look what we got here as i told you earlier i've assumed that men between 20 and 25 like hiphop music but here we only have three samples for men aged 20 23 and 25 we don't have a sample for a 21 year old male so if you ask our model to predict the kind of music that a 21 year old male likes we expect it to say hip hop similarly i've assumed that women between 20 and 25 like dance music but we don't have a sample for a 22 year old female so once again if you ask our model to predict the kind of music that a 22 year old woman likes we expect it to say dance so with these assumptions let's go ahead and ask our model to make predictions so let's remove the last line and instead we're going to call model dot predict this method takes a two dimensional array so here's the outer array in this array each element is an array so i'm going to pass another array here and in this array i'm going to pass a new input set a 21 year old male so 21 comma one that is like a new record in this table okay so this is one input set let's pass another input set for a 22year female so here's another array here we add 22 comma zero so we're asking our model to make two predictions at the same time we get the result and store it in a variable called predictions and finally let's inspect that in our notebook run look what we got our model is saying that a 21 year old male likes hip hop and a 22 year old female likes dance music so our model could successfully make predictions here beautiful but wait a second building a model that makes predictions accurately is not always that easy as i told you earlier after we build a model we need to measure its accuracy and if it's not accurate enough we should either fine tune it or build a model using a different algorithm so in the next lecture i'm going to show you how to measure the accuracy of a model in this lecture i'm going to show you how to measure the accuracy of your models now in order to do so first we need to split our data set into two sets one for training and the other for testing because right now we're passing the entire data set for training the model and we're using two samples for making predictions that is not enough to calculate the accuracy of a model a general rule of thumb is to allocate 70 to 80 percent of our data for training and the other twenty to thirty percent for testing then instead of passing only two samples for making predictions we can pass the data set we have for testing we'll get the predictions and then we can compare these predictions with the actual values in the test set based on that we can calculate the accuracy that's really easy all we have to do is to import a couple of functions and call them in this code let me show you so first on the top from sklearn the model underline selection module we import a function called train test split with this function we can easily split our data set into two sets for training and testing now right here after we define x and y sets we call this function so train test split we give it three arguments x y and a keyboard argument that specifies the size of our test data set so test underline size we set it to 0.2 so we are allocating 20 of our data for testing now this function returns a tuple so we can unpack it into four variables right here x underline train x underline test y underline train and y underline test so the first two variables are the input sets for training and testing and the other are the output sets for training and testing now when training our model instead of passing the entire data set we want to pass only the training data set so x underline train and y underline train also when making predictions instead of passing these two samples we pass x underline test so that is the data set that contains input values for testing now we get the predictions to calculate the accuracy we simply have to compare these predictions with the actual values we have in our output set for testing that is very easy first on the top we need to import a function so from sklearn.metrics metrics import accuracy underlying score now at the very end we call this function so accuracy score and give it two arguments y underline test which contains the expected values and predictions which contains the actual values now this function returns an accuracy score between zero to one so we can store it here and simply display it on the console so let's go ahead and run this program so the accuracy score is one or 100 percent but if we run this one more time we're going to see a different result because every time we split our data set into training and test sets we'll have different data sets because this function randomly picks data for training and testing let me show you so put the cursor in the cell now you can see this cell is activated note that if you click this button here it will run this cell and also inserts a new cell below this cell let me show you so if i go to the second cell press escape button now we are in the command mode press d twice okay now it's deleted if we click the run button you can see this code was executed and now we have a new cell so if you want to run our first cell multiple times every time we have to click this and then run it and then click again and run it it's a little bit tedious so i'll show you a shortcut activate the first cell and press ctrl and enter this runs the current cell without adding a new cell below it so back here let's run it multiple times okay now look the accuracy dropped to 0.75 it's still good so the accuracy score here is somewhere between 75 to 100 but let me show you something if i change the test size from 0.2 to 0.8 so essentially we're using only 20 of our data for training this model and we're using the other 80 for testing now let's see what happens when we run this cell multiple times so control and enter look the accuracy immediately dropped to 0.4 one more time now 46 percent 40 26 it's really really bad the reason this is happening is because we are using very little data for training this model this is one of the key concepts in machine learning the more data we give to our model and the cleaner the data is we get the better result so if we have duplicates irrelevant data or incomplete values our model will learn bad patterns in our data that is why it's really important to clean our data before training our model now let's change this back to 0.2 run this one more time okay now the accuracy is one 75 percent now we drop to 50 again the reason this is happening is because we don't have enough data some machine learning problems require thousands or even millions of samples to train a model the more complex the problem is the more data we need for example here we're only dealing with a table of three columns but if you want to build a model to tell if a picture is a cat or a dog or a horse or a lion we'll need millions of pictures the more animals we want to support the more pictures we need in the next lecture we're going to talk about model persistence so this is a very basic implementation of building and training a model to make predictions now to simplify things i have removed all the code that we wrote in the last lecture for calculating the accuracy because in this lecture we're going to focus on a different topic so basically we import our data set create a model train it and then ask it to make predictions now this piece of code that you see here is not what we want to run every time we have a new user or every time we want to make recommendations to an existing user because training a model can sometimes be really time consuming in this example we're dealing with a very small data set that has only 20 records but in real applications we might have a data set with thousands or millions of samples training a model for that might take seconds minutes or even hours so that is why model persistence is important once in a while we build and train our model and then we'll save it to a file now next time we want to make predictions we simply load the model from the file and ask it to make predictions that model is already trained we don't need to retrain it it's like an intelligent person so let me show you how to do this it's very very easy on the top from sklearn.externals module we import lib this job live object has methods for saving and loading models so after we train our model we simply call joblib dot dump and give it two arguments our model and the name of the file in which we want to store this model let's call that music dash recommender dot job lib that's all we have to do now temporarily i'm going to comment out this line we don't want to make any predictions we just want to store our trained model in a file so let's run this cell with control and slash okay look in the output we have an array that contains the name of our model file so this is the return value of the dump method now back to our desktop right next to my notebook you can see our job live file this is where our model is stored it's simply a binary file now back to our jupyter notebook as i told you before in a real application we don't want to train a model every time so let's comment out these few lines so i've selected these few lines on mac we can press command and slash on windows control slash okay these lines are commented out now this time instead of dumping our model we're going to load it so we call the load method we don't have the model we simply pass the name of our model file this returns our trained model now with these two lines we can simply make predictions so earlier we assumed that men between 20 and 25 like hiphop music let's print predictions and see if our model is behaving correctly or not so control and enter there you go so this is how we persist and load models earlier in this section i told you that decision trees are the easiest to understand and that's why we started machine learning with decision trees in this lecture we're going to export our model in a visual format so you will see how this model makes predictions that is really really cool let me show you so once again i've simplified this code so we simply import our data set create input and output sets create a model and train it that's all we are doing now i want you to follow along with me type everything exactly as i show you in this lecture don't worry about what everything means we're going to come back to it shortly so on the top from sklearn import tree this object has a method for exporting our decision tree in a graphical format so after we train our model let's call tree dot export underline graph vis now here are a few arguments we need to pass the first argument is our model the second is the name of the output file so here we're going to use keyword arguments because this method takes so many parameters and we want to selectively pass keyword arguments without worrying about their order so the parameter we're going to set is out underline file let's set this to music dash recommender dot d o t this is the dot format which is a graph description language you'll see that shortly the other parameter we want to set is feature underline names we set this to an array of two strings age and gender these are the features or the columns of our data set so they are the properties or features of our data okay the other parameter is class names so class underline names we should set this to the list of classes or labels we have in our output data set like hip hop jazz classical and so on so this y data set includes all the genres or all the classes of our data but they're repeated a few times in this data set so here we call y dot unique this returns the unique list of classes now we should sort this alphabetically so we call the sorted function and pass the result a y dot unique the next parameter is label we set this to a string all once again don't worry about the details of these parameters we're going to come back to this shortly so set label to all then round it to true and finally filled to true so this is the end result now let's run this cell using control and enter okay here we have a new file music recommender dot dot that's a little bit funny so we want to open this file with vs code so drag and drop this into a vs code window okay here's a dot format it's a textual language for describing graphs now to visualize this graph we need to install an extension in vs code so on the left side click the extensions panel and search for dot dot look at the second extension here graphviz or dot language by staphon vs go ahead and install this extension and then reload vs code once you do that you can visualize this dot file so let me close this tab all right look at this dot dot here on the right side click this you should have a new menu open preview to the site so click that all right here's the visualization of our decision tree let's close the dot file there you go this is exactly how our model makes predictions so we have this binary tree which means every node can have a maximum of two children on top of each node we have a condition if this condition is true we go to the child node on the left side otherwise we go to the child node on the right side so let's see what's happening here the first condition is age less than or equal to 30.5 if this condition is false that means that user is 30 years or older so the genre of the music that they're interested in is classical so here we're classifying people based on their profile that is the reason we have the word class here so a user who is 30 years or older belongs to the class of classical or people who like classical music now what if this condition is true that means that user is younger than 30. so now we check the gender if it's less than 0.5 which basically means if it equals to 0 then we're dealing with a female so we go to the child node here now once again we have another condition so we're dealing with a female who is younger than 30. once again we need to check their age so is the age less than 25.5 if that's the case then that user likes dance music otherwise they like acoustic music so this is the decision tree that our model uses to make predictions now if you're wondering why we have these floating point numbers like 25.5 these are basically the rules that our model generates based on the patterns that it finds in our data set as we give our model more data these rules will change so they're not always the same also the more columns or more features we have our decision tree is going to get more complex currently we have only two features age and gender now back to our code let me quickly explain the meaning of all these parameters we set fill to true so each box or each node is filled with a color we set rounded to true so they have rounded corners we set label to all so every node has labels that we can read we set class names to the unique list of genres and that's for displaying the class for each node right here and we set feature names to age and gender so we can see the rules in our notes hey thank you for watching my tutorial i hope you learned a lot and you're excited to learn more if you enjoyed this tutorial please like and share it with others and be sure to subscribe to my channel as i upload new videos every week once again thank you and i wish you all the best
