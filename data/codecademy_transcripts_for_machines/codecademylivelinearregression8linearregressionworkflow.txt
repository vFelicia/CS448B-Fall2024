stream series on linear regression um we're gonna be kind of reviewing a lot of the stuff that we covered in the last seven weeks in one day and we're just gonna kind of play with a data set and really go through a full process from start to finish of how do we get some data how do we clean it up a little bit how do we fit some models how do we compare them and maybe we'll come up with we'll see if we can come up with the best possible model that we can for predicting rental prices uh by the end of this session yeah i think this session in particular is kind of more openended than our last ones basically our plan is to play around with this data set and so definitely if you're watching this in the chat as we are doing this live um and you want us to like take a look at any of these features or want us to experiment with this in a particular way we are super open to uh kind of uh making this as interactive as possible so um yeah exactly yeah we want this to be kind of a fun way to kind of wrap everything up but also make it explorational explorative i don't know um okay cool so um one thing i do want to point out before we get started is that um if you're following along with the linear regression course on our on our site and i'll i'll go to codecademy really quickly right now and pull that up so um if you go to this linear regression in python course and take a look at the syllabus um the data set that we're using in a cleaned form exists in this um last project in the in the course this craigslist analysis so if you'd like to play around with this and you want to just get the data already loaded for you and see an example solution this is a little bit subseted and it's a little bit cleaned up but you can do that here if you have a codecademy subscription and even after this this stream if you want to play with it yourself but you don't want to set up your local environment this is a great place to come and um and play with it cool so i'm just going to show you i'm not going to go through the full process but i'm just going to show you where i downloaded the data from and the reason i'm showing you this is really just because if you're working on your own computer you're doing your own analysis you're just getting started um you might come to a place like kaggle or the uci machine learning repository that we've shown before and you might download your own data set and so i think it's it's useful to kind of see the process from the beginning um so this is the data set we're going to be working with i found it on kaggle just by clicking going to kaggle.com clicking data sets and then searching around within data sets um i like to use data sets that have a high usability rating so 10.0 is like the highest i think that you can get um so if you're just starting out it just means it's really easy to download this data and get started with it it's not super super messy although this is a pretty big data set and has um some columns that you might not care about but it's super easy to use it's got um it's got like descriptions of everything um it's got like an overview it's got easy download all of that so we can take a a brief look at it even on kaggle we see there's 22 columns 10 of them are printed out here so you can get a sense for what kind of information might be contained in here and then we can also get a little bit of of context and information about how this data set came to exist on kaggle um so it gives us this the sentence craigslist is the world's largest collection of privately sold housing options yet it's very difficult to collect all of them in the same place so this person built this data set as a means by which to perform experimental analysis on united states um as a whole and instead of isolated urban housing markets the data is scraped so web scraped every few months so somebody else has done all the web scraping for us which is nice um it contains almost all relevant information that craigslist provides on retail sales so um this is just data that has been web scraped from craigslist about housing listings yeah the license is kind of interesting in if you're like making a project for your portfolio or something that you're making for your own personal projects you might want to look at the license and just kind of like dive into um what you're allowed to do with the data set um obviously if it's on table like this um you'll probably be able to like download it and play around with it yourself but again you might want to look at the license when you think about hey how should we be like publishing something related to this this data set yeah exactly um okay so i think we can get started so all i did was i pressed this download button um you have to create a kaggle account oh you can't see my mouse but you can see that it's highlighted in the top right of this right hand corner of this page there's this download button and you have to create a kaggle account once you press download it will download onto your computer and then all i've done is i've moved this housing.csv file that i that was downloaded when i press that button into the folder where my jupyter notebook is or it could be the folder where you've got um like your script that you're writing as well and then i've just opened up this code dot ipynb um this jupiter notebook and this allows me to start playing with the data yeah and again if you aren't super familiar with how to work with jupyter notebooks we've got a lot of articles that kind of help you set that up it's slightly complicated to just like open the jupyter notebook to begin with i'm assuming you did it through terminal or did you do it through um like the jupiter app i did it through terminal um it's actually like once you have it downloaded um it's relatively simple to do via the terminal um i think you just you just type jupiter notebook into the terminal um but yeah it definitely takes a little setup on your computer first before you get that running um and i think we we provided some information on how to download everything on the first stream i believe cool um cool so um i'm just gonna load a bunch of libraries i don't know which ones we'll end up using and then i'm gonna go ahead and load this data um you'll notice normally i just do like this right read in the csv um but let's just print what that looks like um oh actually seems like it's fine i pulled this from somewhere else um you might notice though things that happen when you when you first load a data set um you might see like the header for example is getting pulled in as a row instead of um instead of like column names and so that's what i was intending to do in that first line of code but it looks like it's being read in okay so that's fine um and i've used the pandas library to read it in and so i think a good goal for today is to try to come up with a linear model that allows us to predict price and in the process we can start thinking about what the relationship between price and some of these other variables is so type of apartment square feet beds baths um but also all this other stuff got like parking options laundry options comes furnished um so we got lots of lots of information and then we're going to see if we can figure out the relationship between all of those things in price and see if we can predict price accurately and maybe we would be doing this if we are renting an apartment ourselves or maybe if we are the owners of an apartment and we're trying to figure out like what is the the best or the appropriate market value for this apartment okay so um let's take a look at a couple of things if we're trying to build a linear model for price um are there any columns that you think we should get rid of alex so there's all this kind of like metadata information like the url the id even i don't know if we necessarily need that um i mean it looks like all of these are from reno tahoe so like region url it seems like it's already represented in the region column um so i would probably get rid of region url um that's all i would get rid of from what i'm seeing here there might be more things to the right if we keep looking but uh so let's actually we'll prac we'll print out the info so that we can see first of all how many rows and columns there are and see all the names um looks like so we've got around 385 000 rows so a fair number of rows and then 22 columns we saw that before um i agree it that it makes sense to get rid of some at least id and url um it looks like id for example is being read in as an integer so we're thinking of this as like a numerical value but like an id that is a higher number like this is a higher number than this i believe if i'm looking this correctly but no i have to go back further this this bottom one actually is a larger number than the one above it but um that doesn't really mean anything meaningful about this apartment with respect to this one doesn't mean like it has more of something it just means that it has a different id yeah this might even be a good example of something that are like not correlated at all and so would not make for a good uh good linear regression where if we mapped like price to id the id is just kind of like a randomly generated number presumably or um or at least that's what i'm assuming and so you wouldn't really see any relationship there yeah and then for url um i mean i don't want to do it because i don't want to like create a problem well we can do it on a smaller scale but um what would happen alex if we if we just like put url in it looks like it's being saved as a string right um if we added url to our linear model what do you think would happen i mean so i think that that would try to break it that would consider that like categorical variable right of like hey there are 700 categories and none of them share you know uh category one is this url category two is this url so it's just seven under categories and they're all different because none of them share the same url presumably yeah so let's actually do this really fast because i think this is kind of a funny exercise let's um let's start by just making a um a smaller subset of this housing data where we'll just take um i always forget the syntax here is it like if you just want the first couple of rows and then you do like i think it's like zero to zero colon five won't give you the first five i think yeah i think let's see cool um okay so let's do like let's do 50 rows and then let's fit a model i'm gonna actually like grab my i'm gonna grab some code from somewhere random um again because i never memorized these uh these things so i think uh breaking down uh breaking down this line of code real quick so we are using the sm module which if we look at our import statement is statsmodel.api and then within that we are using if you scroll back down to your line of code within that we are using the uh ols what does ols stand for do you know ordinary least squares okay so this is remember at the beginning we kind of talked about um ways of fitting linear regression model and the way that we've been using is called ordinary least squares because we're minimizing the squared distance between each point and the line essentially okay and then we're saying we're building it from a formula and that formula is what uh based on predicting price based on url yeah and i'm gonna use housing underscore sub and then i'm just gonna print model one dot params and so like how many parameters do you expect to see i expect to see what 50 parameters because it's uh yes again this is the example where they're using a url as a category and there's presumably 50 different urls and so yeah yeah i think there might be fifth well there's going to be 50 unique urls and then um minus one reference group right so 49 plus a intercept so yeah you're exactly right there's gonna be 50 of these and we end up with so here's the intercept and then you see we have a slope for url true dot this whole thing url and then we have a different one for url true dot this whole thing um and then this it keeps going right so pretty good example if you just like take your data set without thinking about it you're going to um run into something like this where suddenly we have yeah 49 parameters based on these these random urls that's definitely not what we're what we're interested in doing yeah and this is actually one of the things that um so we can talk a little bit about this if we have time a little later today but i think um a lot of times people end up using other packages i think the most common one is scikitlearn to fit models and when you fit a model in scikitlearn you can get the you can get these like uh parameters but they don't come with labels automatically and it's like it's a library that's really built around like building the model and making predictions not necessarily like inspecting the model output and so i think that that one of the reasons i like stats models is that when if i were to print out like just the standard model summary here like it's gonna give me i'm gonna have to like see that something crazy happened here um and then that hopefully gives me a clue that i need to like be more purposeful about my model um and it's not always the diagnosis that that has to happen isn't always like it's not always really detailed and small sometimes it's like a big mistake like this where you just threw something into a model and it didn't make sense um but you weren't thinking about it necessarily before so yeah we have a question on the facebook page of how do we deal with those categorical variables um do you so one we we touched on this in much greater detail in an earlier session so take a look at our youtube page and if you look at this series you'll find you'll find videos about dealing with category categorical variables but do you have like a quick answer of like how would you deal with something like this well so you can definitely include categorical variables in your model um but you need to be a little bit careful about it because depending on how many possible values there are of a particular variable you could end up with a whole lot of parameters in your model which means you have to estimate a lot of things and you've now created something that's super complicated um that may or may not really be improving the model so in our last session we talked a little bit about like what's the tradeoff between like accuracy of a model and or predictive ability of a model and like complexity complexity and i think depending on the problem there's maybe a different balance there's no right or wrong answer but i definitely think like there's a limit to how much complexity you potentially want in your model so we'll we'll actually we'll talk about that a little more today too yeah so i'm curious what and this is maybe a tangent but in looking at the url and then i was also curious about the column um description like we scroll over to see the description on some of these just to get a sense of like what those look like um what would you think of doing something like creating a new column that's like you know is the word um stunning in either the url or the description right could we do some like natural language processing of taking these taking this information that's in you know paragraph form or natural language form and trying to create new categories um like that or like you know definitely imagine you know washer washer dryer is already a column in here but let's say that column didn't exist could we look in the description and try to like create our own variable of like oh the description mentions a washer dryer totally yeah so that's a really good point um a lot of times in your data preprocessing stage you might like right now i think for time's sake we'll probably just get rid of this description column although we could we could probably relatively quickly write some code to pull something out from here um but but yeah for for sure there are definitely places where you can take data that exists in a format that you're not going to use like you're not going to throw description into your linear model and turn it into usable information like i like your example of if the word stunning is in here like maybe or i'm trying to think of another yeah i was looking i was thinking that when i was looking at the urls if you scroll down to uh or maybe you got rid of it at this point but um if you if you look at those urls um which were showing up in the when you were showing all of them when you were showing all of the uh parameters but the urls are like you know craigslist.org stunning dash bedroom like three dash bedroom uh yeah so i was thinking oh like there's information in those urls that even though we don't want to use the urls themselves as categorical things we could like maybe parse those urls to get um some information out of them yeah or maybe like ocean view or something like that yeah they'll want oh yeah interesting comment in the youtube chat from alex of uh you could just get the length of the description as a comp uh as a column um yeah what if i do len description is that going to give me the number of characters yeah i think so assuming it's just a string let's uh let's actually we can try that um let's before we do that though let's go back and let's actually like pull out some of these things so um i i feel like we can safely say the id column is probably not giving us any information towards uh price i'm gonna get rid of url as well because i figure anything that's in the description is probably in the url also i'll get rid of region url like you said because that information is also contained in this region variable um image url uh number 17 there probably isn't super helpful okay yeah um and then can leave we can leave lat and lawn i assume those are latitude and longitude which might be interesting so let's go ahead and start with that um so actually let's think should i use i think there's like a dot drop that allows us to easily get rid of columns or we can use subsetting but let's uh let's try our let's see if i can find this drop columns um i'm gonna just show you guys my googling as well because i feel like this is a useful skill indeed um okay so this is the the labels parameter gives the index or column labels to drop and it looks like i can just input like a list of labels that i want to drop so i'm going to go ahead and grab those so we've got id url region url i wonder if it doesn't in place or if we'll have to do housing you are probably right let's check and then was there anything else image url maybe okay was it img uh full image girl okay let's see this might just give us uh maybe it takes index of uh 0 1 2 instead of the column names i'm gonna try labels equals this and then we might need to give it an axis okay from the index or the column so let's give it axis equals one because we want to drop the column okay and then this just gave us this exact same data set but with those columns dropped and so now if we want to resave it we either need to add in place equals true or housing equals so i'll do it this way and then let's just see so if i take len of housing dot description is that gonna just give me a bunch of numbers that give me so uh interesting i bet that's like the sum total of the description i'm guessing you want to call them right right um you might need to do like an apply of like um or housing of description of the column uh let's see right so let's just get the column right housing.description of um i don't know that that is what uh that is that is what yeah so um let's try apply function to a column in pandas um i know that's the dot apply but i just want to pull up the pull this up so we can see it so um this allows us to apply the same function to every value in a column um so axis along which the function is apply zero would apply it to each column or sorry one apply each function apply the function to each row so if we want to apply to each row we would set that equal to one so let's try this as well um let's do like housing dot and then i see on youtube someone's uh pointing us to dot shape as well which uh which might be a uh a good way to do that i'll look into that as you uh as you work on the fly okay um well let's see this is gonna apply it to every column um so i wonder if i can just i wonder if i can just pull out like housing dot um description dot apply and then do like and give it wayne that's the function one do i do i would just give it len and then like then we have to figure out the axis stuff but one takes no keyword arguments um interesting let's see if i do like len of hello i am sophie it does give me the number of characters let's see so if we if we get just the column uh so if you do um if you do data frame or so if you do housing dot description dot s dot len dot s dot one dot string sorry dot s t dot str.len len and get rid of yeah and then parentheses after plan as well what does the str do oh wow i believe it was saying treat it as a string we can try to get rid of it you can try to get rid of str um and see what happens i think we had oh we had applied interesting okay so if we apply len to the entire into the entire series then there is no there's no way to calculate the length of a series object so we need to turn the series into a string or something a set of strings yeah super interesting was that was that your own googling or is that uh yeah so i google panda get length of string in column and it was the first result nice okay well i wish you guys could also see alex's screen but this is fun okay so this gives us the the length of the description let's um let's add this into our into our initial data set so we'll say like housing dot um description length equals it's gonna give me a warning but it's gonna work um let's go ahead and take a look at housing.head again yeah probably good to like verify that this is doing what we expect where um description and description link is probably all the way at the very end you didn't see it actually oh did you reset housing equals let's try this again but i think oh there it goes there it is um okay so now we've got a description length the number of characters um and then i'm gonna now drop description i don't think we're gonna use anything else but again like alex said we could we could do something else here we could figure out um we could pull out some word that we think is gonna be um associated with particularly um high like high prices like exceptional or special maybe like places that have us some sort of one free month special or more likely yeah we could even look for like free month in there because i think that that's that's not a data that's represented uh in any of our other columns like oh this comes with a free month well that like changes the you know real price of the apartment exactly so we could definitely pull some things out of here and and create some more columns around description but i'll leave that for now um and then i'll just grab this drop again so you can drop description okay and then let's take a look at it again okay i feel like we're getting closer um do you have any other questions before we try to fit a model like anything else you think should one thing i would want to do is because we kind of like made this description length thing on the fly i would kind of want to verify that that is indeed an integer rather than a string because like who knows who knows what data type uh you know these random functions that we were just googling it was throwing out so i probably want to look at the info again just to make sure that we know for that uh description length cool it's a it's a float that looks good um the other thing i mean one thing that i might look at before we get started is um first of all for some of these categorical variables like parking options and region i'm i'm curious how many different values there are because if there's like a thousand different values we're still gonna end up with like a lot of parameters in this model right um so one thing i might do is just like we can even do um is it describe give us a little bit more or allow us to um like this so in the region there's 404 different categories right so we probably don't want to throw that into the model willynilly because we're going to end up with 403 slopes um on region if we put that in it also looks like oh well actually that's an and for a reason there's 12 different types of apartments that's a little more reasonable um how would you go about um states yeah um yeah that's interesting we could look into that maybe you know puerto rico or something is in there um how would you go about kind of verifying that all of these that there's like no errors in the data of like oh maybe laundry options maybe one of the five is like capitalized differently than the others or like you i mean i would go through if if we were spending more time on this and i want to make sure we got some time for modeling but if i was spending more time on this i would definitely go in much more detail looking at each of these like so for example um let's look at type for a moment because this has kind of a lot of categories to just throw it into the model but not so many that we just want to like definitely throw it out um but so one thing i might do is first of all take a look at housing dot type dot value counts and so this gives me all of the values in this column so we've got apartment house townhouse condo duplex manufactured goes on so it looks like these are all at least their own thing right um we definitely have a couple categories like assisted living and land that don't seem very highly represented in the data and in fact like even even in law and flat and loft and cottage cabin are like oh there are a lot fewer of those um than all of the other ones so like one thing i might do is this is a lot of extra parameters for like not that much variation in the data i might collapse this into one category that's like other interesting um to just kind of cut this down a little bit the other thing i might do is take a look at a box plot of all these things and price so i might do like sns.box plot x equals type y equals price data equals housing and then show the plot okay so it's like there's one massive outlier this is actually okay let's let's investigate this further so like if i it might not even be one outlier it might be like a bunch and you're going to change somewhere so one thing i might also look at here is um guess i'll use i always forget if we're at his plot or his plot um seabourn keeps changing it's uh or disc plot like um and then do uh housing.price okay so we've got this like very very skewed um distribution here where we go from zero all the way up to like a million or more than it's the one with nine yeah so yeah 2.5 with nine zeros um so i think we wanna probably restrict this a little bit let's for the moment i'm gonna just kind of arbitrarily cut this down um what do you think is a good like cutoff point so we're gonna be removing that rose where price is over a million yeah or like so how would you go about deciding this in like the real world of like when can you just throw out data like this so um i guess there's again no clear answer um i'm sorry to say but i think in practice you kind of play around with this for a little while so let's like for example let's just start without making any permanent changes let's actually we can do this in here let's subset this right like within the plot and say we only want um values where price is less than 1 million um and then let's like replot this and it still just looks like super skewed like we still really can't see this variation um one thing we could do at this point is we could try we could even try like taking a log and see if like the log transform helps us get some things like oh and then here we're we're gonna have an issue with taking the log of anything um that's zero so that gives us a clue that there's actually some apartments where the price is zero so um now i'm gonna say like and housing.price greater than zero and i think i need to put these in parentheses and now okay so now we've got like a little bit more usable of a distribution um so this might be a clue that we want a log transform for our price variable um because i threw this log in here but we could also could we go in the other direction try like super like over cutting things and just say like hey what does it look like if we cut everything that's less than um you know two thousand or everything that's greater than two thousand um dollars and see yeah let's do like three thousand i feel like because these might be rental prices and this is yeah so that looks pretty good this is another thing that we could do instead of instead of just taking log we could just cut this down and say okay like realistically we really only care about this um when we're looking at apartments that are three thousand price range within our lowly price range um yeah and then i see somebody wrote in the chat can we see performance before and after including the outlier and definitely so um this comes back to a question that somebody asked on discord a couple weeks ago and i thought it was a great question which is like how do you compare models and i think totally if you have a data set where it's not super costly to run or time consuming to run the model you can definitely like run the same model with a bunch of different iterations getting rid of um getting rid of an outline liar or getting um or like taking a log transform not taking a log transform you can try all those things and refit the model it gets a little more difficult if you have like a huge data set then you might need to like take a subset of data to do that exploration um but yeah no no need to ignore your comment because it looked like it definitely looked like an one outlier in that plot that we saw um i think it was just like a weird artifact of the skew um but it definitely looked like an outlier um in that first plot so i would say based on looking at this um i feel like 3000 seems like a pretty good cutoff point i mean we could like look at this tail to ten thousand or five to like ten thousand and see if it looks like yeah i mean it kind of looks like to me this the cutoff is maybe like three or four thousand so my very um precise uh method for this i'm gonna cut it to 4 000 or smaller okay so let's let's actually do that we'll do housing dot housing equals housing housing price uh actually totally override it uh i like housing affordable um okay and that kind of that kind of distinction is like if we saved over housing then it would be a little bit trickier to say oh let's like plug in the let's plug in the model before we we cut out the super expensive um houses it'd be a little bit trickier to do that or we'd have to like reload the data set and uh yeah for sure okay let's do that um okay so now let's just take a look at this again all right so we've got region price and then i'm reminding myself as well we looked at this before we saw region is a little bit overwhelming of a variable right here um maybe like again i assume that the region is giving us like specific cities basically um maybe there's a way that we can do some like combining of categories again where we just say like north west yeah southwest right maybe we could oh market in the south and new york is in the northeast yeah um so there's there's lots more i guess it's gonna feel a little unsatisfying because there's a lot more cleaning of this data set and producing like not just cleaning but creating of new features so like feature engineering um that we could do before fitting a model that would probably improve this model because to be fair like the relationship between price and square feet is probably different by region right like the prices in jacksonville are going to be different than the prices in new york city and the relationships between like price and other variables might also be different in different regions so i feel like region is probably important in some sense but like yes i mean so ultimately we could do the same thing of like depending on you know depending on the realworld application of this if we're renting an apartment in denver we don't really care what rent is like in new york and so we could take this data set and just like we cut out all the super expensive apartments we could cut out all the apartments that are not in denver um that's also true yes um but what if we have apartments that we want to rent out in like every major city in the u.s yeah that's a good thing what do we do i don't know um okay so let's let's see what should we include in our first model should we include i mean i think the most obvious things are like square footage bedrooms yeah okay let's um let's let's get a a model going let me grab and grab the same code from up above and i'm gonna go ahead and start adding we're gonna do this with housing affordable and let's start grabbing something so we want should we include we'll include type for now um square feet and remind me of like those are certainly should be treated like a category right yes yes no but it looks like right now they're treated as like zero one um so remember that here let's actually print out the info again so all of these are being stored it looks like as integers so it's just zero one um and remember that when we when we fit this model with say like uh type what's actually happening under the hood is we're getting a new um like a new design matrix here that has 11 new columns that are ones and zeros um i can actually like print that out let's see i think it's like patsy dot you know what i'm gonna do i'm gonna go back to i think it was here i may have done this so let me try one more place yeah okay so this is a different different data set but let's just for a moment do you like rent or it was price as a function of type and this is um housing affordable and return it as a data frame and so yeah so this is the new x matrix that we get and so it'll have like this one for an intercept column of one for the intercept and then it'll have like type t assisted living and this will be ones and zeros type t condo and this will be ones and zeros and so it basically just creates a bunch of dummy variables with ones and zeros for all of the um for all of the possible values of that categorical variable so back up here this column cataloud is basically the same is being treated in the same way as this type column it's just we're not seeing it when we use this os from formula we're we're just putting in the string but in order to fit the model it's separating that column into like 11 new columns got it but if we if we had three so that that's working because it's binary if it's either cat's lab or not but if this were if there was a third category for that we wouldn't want it to be numerical zero one two we would want it to be you know string zero one two which would then be treated as a category or or the you know the string the actual names of those categories whatever they might be yeah exactly um that's a good point so again if we were being more thorough here we'd probably want to verify that the only values are zeros and ones um i'm pretty sure i've taken a look at this before and and verified that um but definitely would want to it also seems like these all of the columns where it is like a binary thing like cast can be allowed or not it seems like those are ones and zeros and anything where the type like type where there's more than two options it seems to be recorded as strings but that's an assumption that i'm making that's not like something that we have checked right now um okay let's go back so we were here so we had up to smoking aloud in the model let's do wheelchair access i'm just adding everything i don't know there might be a shortcut to add everything and then take some things out you know an r there is but um and then let's do what do you think we'll add description we'll add latin law let's add description length to start and then we'll we'll come back and add some more things um and then the data is housing underscore affordable and we're going to fit this model and then let's print out the summary it's going to be big but it might take a minute okay so and i'm actually gonna do zoom out so that we can see all of this this is one thing i don't like about the summary output i would love if they would output it for me as a data frame um directly but instead we get this like crazy thing that is subject to whatever weird formatting um jupiter notebooks decides to use um okay so we can actually see all a lot of the things we've already talked about we can see that the r squared is 0.129 and adjusted r squared is also 0.129 so i would interpret this as like this model is not super good at identify or at predicting price because we're really only um really only explaining about like 13 of the variation in price for all of these apartments um but we could use these numbers to compare this to a new model so let's see what happens and you'll notice like we do have at least the type variable like we said we've got like 11 different um values here right let's add in let's add in lat and lawn and just see if that improves it at all because right now we have nothing cutting down the region at all so maybe maybe that would be useful oh yeah live long is actually a great way to get the region uh but that's not going to be like linear right yeah it's hard to because it's not it's not like oh higher latitude is going to be more expensive yeah maybe we need like well okay let's add it in okay well it didn't prove it i feel like i mean for such a small number like this is only 0.129 so we're already up to like 15 percent so that's not terrible um i bet that that if we ran like a um anova comparing these two models i bet the bigger model would like that added complexity would probably be worth it um other ideas or questions uh question from the youtube chat how do we calculate feature importance oh um that is a very loaded question um so one thing that we can do is if there's something called like uh what are they called standardized coefficients um another another thing that we can do that's slightly different but related is we if we standardize all of the um all the quantitative variables then they're all on the same scale then they're then the um coefficients at least are all on the same scale so they are comparable so we could actually if everything was standardized we could compare coefficients at least for the quantitative variables um another thing that people do and i guess this is really a plug for the feature engineering um content that's coming out hopefully in a couple of months um that nitia is working on because there there are a lot of other mechanisms that we can use to try to like pick out features based off of their relative importance in terms of this model um or there's also ways that we can iteratively try to build this model for example like we can use like forward and or backward selection to kind of tell the computer okay like start with a model that has everything in it and start deleting things and testing them out and then if something helps to delete it then keep it missing and then like continue the process from there or the reverse we could start with nothing and try like adding predictors one at a time and then see which one and do it which one improves the model the most and then only keep that one and then iteratively do that again um we can also use like uh like ridge or lasso regression to try to shrink some of the coefficients to zero if they're or close to zero if they're not super relevant um i see a question i wonder what why stats models doesn't include in summary metrics such as mean absolute error means squared error root mean squared error is r squared better that's a interesting question um so r squared is related to all of those things um because it is also based off of the um it included in that r squared calculation you're calculating like the error as part of it and seeing basically saying like how much of that error are you or how much of the variation are you accounting for by adding that line in um but i don't know i don't know why they chose not to include additional metrics um it's always interesting um okay we are like running quickly out of time and i know we haven't gotten super far but at least we've had a chance to test out some models and hopefully we've gotten you've all gotten a taste of what this might look like on your own um i think the fun of today is kind of we didn't have a clear direction of where we were gonna go with this today um but it was i think i hope useful to kind of see how one might get started on an analysis like this and my hope is that if you're interested in learning more about linear regression and if you're interested in practicing these skills a little bit more that you might take this and run with it and like try running your own model see if you can improve this even more another thing i would probably do is start subsetting the data to one region and see if that allows me to get at least a better a little bit better um yeah but i think this kind of work in general just will make you more comfortable using all these tools make you more comfortable with like kind of solving arbitrary tasks like we were doing like how do i find the length of the string in this column just like the more and more work that you do working with data frames working with um these libraries that are making these models i think that that will just help grow your skill in like being able to or being more confident in doing these with when you need to do it in a real world situation yeah and another thing that i will say is once you have learned more methods for creating models then you can even like you could extend this even further this doesn't have to be just a linear regression problem this can be like a how well can i predict price problem and you can try even more methods and use some of the methods that we discussed here to still compare compare models and also some of these metrics that alex in the chat just mentioned so like mean absolute error is um is a useful one to compare different types of models because you know like you don't want to you don't necessarily have a way of calculating like aic for um for like every model that you might every type of model that you might create but mean absolute error you definitely could cool well that's it that's it for linear regression um i hope that you guys found this helpful and definitely let us know if you have any more questions we'll try our best to answer them and feel free to write those questions as comments in the youtube video or also on discord if you have been on discord yeah uh we don't have any other live streams currently planned but hopefully we will do another kind of series like this um in the near future but yeah might uh might take a little a couple weeks break um so we'll see what happens but uh yeah keep an eye on the youtube channel for more stuff like this and yeah thanks for thanks for doing this sophie so he led the you know eight straight weeks of this um great work sophie it's all fun thanks for joining me on all of these alex this is a wild ride all right cool all right