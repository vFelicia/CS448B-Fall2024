i know it says we're live but i don't believe it i don't believe it until i see it okay we're good to go all right hi everyone uh i hope that everyone is having a good tuesday and i'm excited to get into uh our week six topics um i think we had a little snafu with the timing on the youtube page so it's possible uh that people will be filtering in slowly uh today but if you're here and you're live ask us any questions you have on the youtube chat and we will make sure to address them uh cool so i think we can get started pretty quickly this this time around um i have something that i want to address from last week uh a small correction so i'm gonna start with that and then we're gonna get into the material for this week so with that i will share my screen yeah i saw you posted a comment on the last video so this is also in the last video but uh something that we were going over that um uh i was either said incorrectly or you just want to go oops sorry i shared the wrong screen yes exactly all right sure all right um yeah so this was a really quick edit from last week and this was related to a really good question that alex asked so um it comes back to our discussion of how the binomial distribution is pretty similar to the normal distribution except for um except that it's discrete uh which means that like you can only have the numbers one two you can only have integer values um along your xaxis and i kind of walk through the exam or i talk through how the central limit theorem sort of applies and um at one point alex asked if we could see how the the width of the distribution changes for different sample sizes and we didn't get to it but uh off as i was thinking about it later i realized that actually what we were looking at last time and i think we still have it was we were looking at a histogram of um in this case the number a number of purchases or earlier we were looking at a histogram of coin flip results where each number on the xaxis represented a number of coin flips that resulted in heads um but this example of a normal or this example of a binomial distribution if you think about whether you flip 500 coins versus 10 coins um the 10.1 is going to be less the distribution for 10 coin flips the distribution of the number of heads for 10 coin flips is going to be um thinner than this distribution just because the number there are less numbers between 0 and 10 than there are between 0 and 100 so what i everything i was saying only applies if you divide each of these numbers by the sample size so just demoing it down here and the intuition like makes a lot of sense and i feel like people probably intuited this at the time but if you flip 10 coins and you record the proportion of heads instead of the number of heads and plot that distribution you could get anywhere from zero to a hundred percent heads in infinitely many coin flips whereas if you put if you flip a hundred coins um you're more likely or 500 coins i think in this example you're more likely to get closer to 50 heads you could still potentially get zero percent heads but it's a lot like it's like so much more minuscule it's not even gonna happen in our in this simulation um and so so so this example the blue histogram is uh 10 um what's the terminology 10 attempt 10 coin flips 10 like attempts or something like that yeah so this is we repeated this process a bunch of times each time we flipped 10 coins and we recorded the proportion of heads in each of those 10 flips and we did that and then the orange is 100 500 or something like that i think the orange i i made it 500 but yeah you can see and the histograms look a little funny because of how the xaxis shows up but um but you get the idea that it's basically you can be more confident about the proportion of heads that will come up the more times you flip the coin okay cool and yeah and and again the the correction from last week is we weren't talking last week we didn't specify that's the proportion if you scroll back up to that other graph we were talking about like the overall number and so of course when you're flipping a hundred coins the number of heads can range from zero to a hundred versus ten coins it can only be zero to ten so like by definition that range is going to be smaller but you know that's not what we're actually interested we're interested in the percentage or proportion exactly cool makes sense so with that um i'm going to move to today's topic which i think is a really fun one and we're going gonna use the same data in the same framework as we did last time just to keep things simple um but we're going to talk about the issue of multiple hypothesis tests and we're going to talk a little bit more so last week we we introduced the idea of a pvalue as being like an outcome of a hypothesis test um and we'll we'll review a little bit what that definition of a pvalue was but then there's another question about what to do with that pvalue value and in order to answer that question we're going to need to think a little bit more deeply about about what it means to make a decision based off of a probability so that's the that's the topic for today and this is really important because you may have heard of the reproducibility crisis in statistics um which is the idea that a lot of published research can't be reproduced like people aren't getting the same findings when they try to do the same study over again um and that issue is related to what a lot of people call p hacking um which is going to be a topic of today so with that uh let's jump in so a quick reminder from last week i'll actually pull up um pull up our code from last week and so as a quick recap we were looking at this situation where we had some data about uh people making purchases on a website and we had a sample of 500 people and we expected the purchase rate to be 10 and we wanted to know if the purchase rate was significantly less than that because we thought there was some sort of bug or we had changed something where we thought the purchase rate might go down we want to check that assumption so we ran this test where we collected our sample we have 500 visitors to a web website who saw this thing and we saw that i think it was like uh like eight percent made a purchase i forget like 41 out of 500 whatever that was yeah so 41 out of 500 so less than our expectation made a purchase um right if it was 10 it would be 50 and we saw only 41 made a purchase and then we talked about how um the outcome of this hypothesis test is we could kind of say well if the purchase rate was what we expected then we would expect 50 purchases but if we repeat this process randomly a bunch of times and give everyone a 10 chance of making a purchase we still see a range in the number of purchases that happen among 500 people in simulated samples and so based off of that we estimated this p value which was the probability that a randomly sampled group of people a group of 500 people made 41 or fewer purchases given that the true probability of a purchase was 10 um and that was that's our p value it came out i think to like 0.1 um we did it using simulation we also did it with a builtin function and both times it came out to around 0.1 and so that's that's a probability um and it can be interpreted right if we if we got a really low probability so like let's say we observed only 30 purchases in our sample then the probability would just be like the area of this tiny little block to the left of 30 divided by the total area of the whole thing so it'd be a really small number and right and intuitively right if we say the probability of making 30 or fewer purchases given that the true probability of a purchase is 10 if that probability is really small then it's unlikely that um it's unlikely that the purchase rate really was 10 in that case so we're making some estimate of how likely is it that the null hypothesis is true given what we observed right and i think uh you might go into this in this lesson sophie but i think a lot of times or the thing that i know about pvalue is that like 0.05 po value 0.1 pvalue right like we're saying that okay at this level we can reject the null hypothesis because um you know the probability of purchase is ten percent or you know in the other case it'll be like two percent if we saw um if we saw 30 purchases instead of um instead of 41. so why why those values why 0.5 and 0.1 as like the values where you say like this is when we can reject the null hypothesis yeah so we're actually gonna just jump right into that right now so um so what alex is alluding to is that um i think we all if we're all okay with the idea of a probability or hopefully we feel comfortable with the idea of the probability but sometimes you need to use that probability to actually make a decision so in this case it's maybe maybe the example that i came up with isn't super conducive to this but let's say that um let's say that what we were doing was we tried out some new version of our website that's cheaper for us to build and um and so we expected the purchase rate might go down we wanted to know if it really did go down or not and if the purchase rate didn't go down significantly with our new cheaper version of the website then we're going to implement the cheaper version of the website because it will save us money but if the purchase rate went down significantly then we don't want to implement it and so we have to make that decision implement don't implement based off of this number and if we're going to do that we don't really want to like i think in general we often want to have some cut off for ourselves like this is a probabilistic number the pvalue is a probability um but we're not necessarily comfortable with the idea that like there's just a 10 chance that the purchase rate really did drop at a 90 chance that it didn't or whatever we want to um or whatever we want to ascribe to this we want to actually use that probability to decide like is it worth making this decision or not and so a way that people do that is they choose a threshold and they say okay any pvalues below this threshold i'm gonna deem them significant what that means it or i'm gonna decide to reject the null hypothesis which is the um the wording that alex used and the idea here is that the null hypothesis in our example was that the probability of a purchase is 10 if we get data that challenges that null hypothesis that makes it unlikely that that null hypothesis is true then we're gonna reject it and say okay it's unlikely that the null hypothesis is true therefore i'm gonna say that it's more likely or therefore i'm gonna accept or i don't know people use different language uh usually we don't say like accept the alternative but you say i reject the null hypothesis in favor of the alternative which is to say that we haven't proved that we haven't calculated a probability of the alternative hypothesis we've only calculated a probability of the null hypothesis and then said that it's unlikely um and so a common choice for that threshold at which we say will reject the null hypothesis is .05 um but lots of people use .01 or um or a different threshold or 0.1 um so there's some choice in that and we need to decide it ahead of time um in this case yep i hear i see someone wrote fail to reject so in this case if we got a pvalue of about 0.1 and if we set a significance threshold of 0.05 we would fail to reject the null hypothesis because 0.1 is not smaller than .05 um and so the probability that the null hypothesis is untrue given our data data is not small enough for us to reject the null and so uh interesting thing with the language here is that yes is that then saying that we think that the probability of purchase is indeed 10 or that we just don't think that it's less than 10 percent um no it's saying that we so if we oh you mean if we don't if we fail to reject the null if we if we fail to reject the null is that us saying that we think that it is that it remains uh 10 probability of purchase um no i mean depending on if you want to be technical about how you should interpret it but if you fail to reject the null you're basically just saying that there is not enough evidence that the purchase rate is not 10 so um you can't say basically you can't say whether the null hypothesis is true or not right just that you can't that you can't accept this alternative hypothesis or you just say you can't reject the null i know it's like it goes in circles because uh and the language is complicated and i feel like it's been ingrained in me to be really careful about what language i use really precise um but yeah the whole framework of a hypothesis test is really about setting up the null hypothesis testing the null hypothesis and then saying whether you have enough evidence to reject the null hypothesis or not reject and that's like that's as far as you can go if you reject you're saying it's unlikely that the null hypothesis is true if you fail to reject then you're saying there's not enough evidence for me to say the null hypothesis is not true okay and that's a lot of words that i just said um and i know it's confusing so uh bear with me i think as you're learning this stuff you have to like do it a bunch of times try practice problems decide reject or fail to reject interpret and practice interpreting so that you feel comfortable with that idea yeah lots of double negatives like fail to reject is like a double negative of like oh we're failing to turn this thing down right it's uh i can see how it gets uh it gets confusing yeah okay so with that i'm gonna jump right in so um first thing i wanna do is i want to think through um in the same way that when we talked about the central limit theorem we kind of had this like allpowerful mode and in that allpowerful mode we got to know what the truth was and then um and then we kind of went into researcher mode where we didn't know where the what the truth was and we were trying to analyze something as a researcher we're gonna do the same thing for right now so remember that um that last time we looked at this data this was like a simulated data set 500 visitors to a website um and basically the important thing here is whether or not the each visitor made a purchase and in this data set we have um 41 purchases but we can recalculate that so i think we discuss such disrespect the importance of our uh items that we came up with uh i mean no disrespect at all i love this date i love this data set so much i just watch it here even though it's totally fake i watched love actually for the first time over the weekend so now i could uh be this purchaser of the cue card i wish i had watched it this weekend i totally forgot about that um did you enjoy it it was great very pleasant yeah it was just nice yeah it is nice okay so we'll just confirm there's 40 oops i didn't yeah okay so confirming that there's 41 purchases but now we're let's go back to what we were doing in the previous week so remember that last week we started doing this these kind of simulations where we said okay but what if the true probability of a purchase was 0.1 i'm going to copy over this code so we don't have to rewrite it but for those that haven't seen that if you're just visiting for the first time um what we're doing here right is we're saying okay but what if in this data set we saw 41 purchases but what if the truth is that the probability of a purchase is 0.1 and we simulate 500 new visitors so this data set has 500 visitors what if we simulate 500 new visitors and see how many purchases we get and remember that we expect 0.1 times 500 or 50 purchases but we're going to get some variation around 50 so this time we got 55 um and every time we run this we're going to get a different number and it's going to be totally random okay so next thing i want to do is think about what would happen if we repeated this a bunch of times and instead of every time collecting the number of purchases what if every time we run this we run a binomial test and calculate a p p value okay so um let's let's try writing this out here i'll make a new so alex do you want to like walk me through yeah say that sentence again i think i i think i got lost so every time we run one of these um tests or run one of these simulations we're going to run a um ptest on it or we're gonna get a pvalue for it yeah so we're gonna run a binomial test okay yeah so right this is this is gonna get like a little bit meta so um if if anyone is confused in the chat um please please please let me know um okay so each time i run this loop i'm going to simulate 500 visitors each with a 0.1 probability or 10 probability of making a purchase i'm going to calculate the number of purchases but then what i'm going to do is i'm going to grab this code and i'm actually going to just grab the the binom test code so right because because last week what we did is we ran that a thousand times um and then made a distribution of like oh this time we saw 50 purchases this time we saw 45 and we made that distribution um now we're not making that distribution anymore we're just running the uh binomial test on it yeah actually you know what i feel like i skipped a step let me let me go back before we do this for loop let me quickly just demonstrate what i'm going to do inside the for loop but demonstrate it outside the for loop so right we have this process where here every time we're calculating the number of purchases in our simulated sample but what if instead of that we import this binome test function and then we run the binomial test the exact same test that we simulated last week and we'll do with alternative is less and instead of putting 41 in here let's put in the number of purchases in our simulated test our simulated data set so the originally the 41 came from our real data of 41 people um bought the item but let's see what happens if we do it with a random a random number yeah and actually each time i'm going to print the number of purchases and then i'm going to print the p value so you can see both of them so here we go all right this time we got 55 purchases and we got a pvalue of 0.795 alex do you want to talk through like how would you conceptualize this pvalue or how would you explain that pvalue right so i'm visualizing the um the distribution right and so um we expect the um number of purchases to be 50. we saw 55 and so we're saying if um if the actual number of or if the actual rate of purchase was 10 which would give us our 50 and we saw 55 percent there's a and we saw 55 purchases rather than 50. there's a uh 79.5 chance that um that the uh the the true value is uh ten percent right or not sort of so we again it's like the double negative of like we can't rej it's not that it's 10 it's that it's um like can you write out the um null hypothesis for me yeah so the null hypothesis here i'll do it and mark down so the null hypothesis is that the purchase rate is 10 and then the alternative hypothesis is that because we did alternative equals less the alternative hypothesis is that the purchase rate is less than 10 right and so um like what i want to say is there's a 79.5 chance that the null hypothesis is true but it's not exactly that right so i would say there's a 79.5 chance that um or sorry let me back up there's a 79.5 chance of observing 55 or fewer purchases given that the purchase rate is 10 so because we had alternative equals less this is going to be it's going to be a probability of observing 55 or fewer purchases if the true purchase rate were 10 um so let's do another one let's run it let's see if we can get something that's like less than 50. okay so here's 39. actually this this p value is pretty close to 0.0.05 this is pretty close to our threshold even though right in our simulation the probability of a purchase was 0.1 no it was yeah 0.1 but we got a randomly really small number so this is saying that there's a 5.5 chance of seeing 39 purchases given that the true purchase rate is 10 yeah 39 or fewer purchases because yeah because the alternative was less than yeah right yeah something that's interesting so we uh in the last one that you ran i think the value the total number was like 62 and so the p value was like 0.98 um which means that there's like a 98 chance of seeing 63 or fewer purchases given that the total purchase rate is 10 which is like it's a little bit confusing because normally you know you're used to seeing like very small p values so i always come back to it has to do with the fact that we have that alternative equals less um contingency if we had um if we had changed the alternative or to uh both i think is how it's coded here or i think it's also the default then you get the um doublesided pvalue it would have been really small for that value but um i think the i like to conceptualize it and i think i have some pictures somewhere i can like pull them up but i like to conceptualize it with this this image it this image so i think about that pvalue as a proportion of the area of this blue histogram and so for when we had 41 the pvalue was the proportion of the histogram that was left of 41. so that was about 0.1 when we got 69 it was all the way over here and it was the proportion of the histogram that's less than 69 and so we got 0.98 and could we could we see can we go back to our code and hard code in that 69 and see that it's 98 percent rather than purchases and then maybe flip from let's first see what it looks like with alternative equals less and then um here uh actually let me just create a new yeah right i'm sorry if this is a tangent no no no this is great this is a really helpful discussion because you feel like this is the kind of thing that helps um conceptualize the next steps i'm glad we're taking the time to do it okay so 99 chance of seeing 69 or fewer purchases given a 10 purchase rate which again if you're picturing that histogram that's like basically all of the area under the histogram but now if we switch to not less but the default which is like twosided right so this is now saying there's a point seven percent that we're either above 69 purchases or below some very small value right yeah so i'm gonna just actually we're going to go to codecademy.com outlooker and let's pull up there's um thanks for hanging with me guys um i think it's in this lesson oh yeah right so i find this picture kind of helpful so um right the twosided pvalue which is the um which is the default is looking just at the probability of observing something as extreme or more extreme than um than what was observed in the data so in the case where we had a value of 69 we're like drawing we're drawing a line at 69 shading everything to the right of 69 red and then we're drawing we're saying okay 50 69 minus 50 is 19 so 69 is 19 units away from 50. so let's go 19 units away from 50 in the other direction to 31 and let's also add in everything to the left of 31 right so um right so it's like distance away from the expected mean right versus what we did what we're doing before is we're just coloring everything with the alternative being less we're coloring everything to the left and then um if we get a high number then you're going to get a really large p value yeah and so going back to our code now if we i assume we can put in a parameter for the third value where we've done less and then twosided can we put in greater than and see they'll like point the like one percent of uh seeing something greater than 69 um given the 10 yeah so it's going to be even it's gonna be half as big as this right so if we do alternative i think it's just greater let's try it yeah yeah right and so again that's picturing that histogram finding uh your value and saying okay what's the area greater than that that area and it's um you know 0.5 of the total histogram yeah exactly cool um all right i'm glad we went on that tangent i feel like hopefully that clarified some things for people um and now we'll go and try to do this a bunch of times so in this case right if we and let's just like take it back to the um to the original goal of this right in this case if we had observed 69 purchases and let's say we used our alternative hypothesis was that the purchase rate was greater than 10 and then we observed 69 purchases we'd be pretty certain or we could be pretty certain that the null hypothesis is not true or in other words i should say we could be there's a very low probability that the null hypothesis is true in that case because 69 is so much different from our expectation and so if we were using a threshold of 0.05 to decide whether something whether we should reject the null hypothesis then in this case we would and the key that we're going to talk about now is that sometimes when we reject the null hypothesis we're going to be wrong right like we randomly simulated 69 visitors we did that earlier right completely randomly where the true purchase rate was 0.1 um and so sometimes by random chance extreme things happen right like sometimes by random chance you um flip 100 coins and 80 of them come up heads or whatever it is so sometimes we'll reject the null and we shouldn't have rejected the null so that's where we're going but let's let's go through this so um here we've got all of this now i'm putting it inside a for loop so i'm just saying i want to repeat this a bunch of times each time i'm going to simulate my visitors with a 10 probability of a purchase then i'm going to calculate the number of purchases and then i'm going to put that into my um binomial test and i'm going to get rid of this alternative equals less but for some reason my computer doesn't like to i think it has something to do with zoom um okay and then what i want to do actually before this is i want to collect those p values from for further inspection so i'm going to say p vowels equals empty list and then each time i'm going to say p vowels call this a thing simpler like p val u and then we'll say p vowels equals p val stop append um p value thank you do you do the overwrite or can you just do p values dot append um what do you mean do you need to set p values equal to the new thing or can you just do p files oh right you're right yes okay so um so we've appended the new p value onto our list so that we're saving them every time um so i'm gonna run this and then what i'm gonna do is um i'm gonna plot a histogram of the p values so here's where i feel like when i first saw this like i had a professor once that did this in class and before before plotting this they asked the whole class what they thought this histogram would look like and like the one person that had seen it before got it right and all of the rest of us voted for something that was wrong so um so now i'm going to pose this question to you alex that's a hard question the people in the chat also answered this question oh yeah people in the chat also please try to answer this question so i'm going to repeat as i'm going to give you a minute to think and while you're thinking i'm going to repeat what we're doing so basically we've repeated this a thousand times each time we're going to simulate 500 visitors where each visitor has a 10 chance of making a purchase we've set the purchase rate to 10 but by random chance there's going to be different numbers each time for each simulated sample of 500 we're going to calculate the number of purchases then we're going to run a binomial test to see whether the number of purchases is significantly different from 50 which is our expectation if the purchase rate is 10 and so and given also a sample size of 500 right and this is our null hypothesis and then we're going to collect the p values from we're going to collect the p values in a list and then we're going to plot a histogram of them we want to know like so remember when we were doing this example before we were printing out the p values each time and we said like you know when it's 39 we're gonna get a pvalue of 0.05 um or whatever so each time we're just collecting the pvalues um yeah dr monkey uk says no pressure alex nobody else nobody else has been brave enough to venture a guest so the bad thing is that i like reviewed your content uh and so i've i've already oh this is i actually i don't think i put this in the content because i feel like i don't remember i didn't want to this is a bonus by watching this okay so i think the so i i don't think this is the actual answer because you've like prefaced this with so much like anticipation and uh trickery maybe you're just smarter than my entire class i mean so i would just guess that it looks like you know the normal curve where it's um we see a lot of so we're not going to see a lot of um things that are um oh god i don't even know now sorry i'm trying to think through it because we ran this a couple of times and we saw like we occasionally saw things that are tiny like this like .004 um and i guess we would also occasionally see something that's huge like 0.99 but more often than not we're gonna see something that's like right in the middle so i would guess that it's like the normal curve with the center going from zero to one with the center at 0.5 okay and i see some message and messages in the chat um kristin in the croissants at croissant says total shot in the dark a normal distribution shape so agrees with you um dr monkey uk says i thought that too you guys are all following the same trap that i fall i fell into so that makes me feel better about myself um i'm gonna plot it now the way it is over i don't know if you want to drumroll this now i actually need sound i need sound effects on this thing i know whoa what is it it's basically what we call a uniform distribution which is to say that in fact if the null hypothesis is true you're equally likely to get any pvalue between zero and one nice kristen and the croissant actually got it there right before we yeah just we we know that there's a delay on chat so we got it before i showed the picture yeah exactly um yeah so actually your intuition when you were first talking it through alex was right right on right like we saw some we saw just as many large and small numbers as we did in the middle so um so basically this is this is a super important like thing to understand for the context of um when you when you make mistakes in hypothesis testing which is that so again i'm just repeating what we did but um with like a new lens so we simulated a sample where the true probability of a purchase was 0.1 then we ran a binomial test where the null hypothesis was that the purchase rate was 0.1 so we when we ran this this hypothesis test in this line every single time we ran this hypothesis test then the null hypothesis was actually true because we simulated the sample like the way that we got this number was that we simulated a sample where the null hypothesis was true where the where the purchase rate really was 0.1 so because we simulated our sample knowing like saying the purchase rate is 0.1 then when we run this test with the null hypothesis that the purchase rate is 0.1 we're running this test where the null hypothesis is true does that that makes sense but why does that why does that make this uh you know essentially a straight line across so okay so let's let's again now like think through some potential errors that we can make so um so if the null hypothesis is true then um there's there's two things that could happen so if the null hypothesis is true then we don't want the pvalue to be significant right we if the null hypothesis is true we should not reject the null um and maybe instead of not significant pvalue above threshold right and then pvalue below threshold um make this a little bit easier right so if the null hypothesis is true we want our pvalue to be above the threshold that if the pvalue is above the threshold then we are correct um if the pvalue is below the threshold like if we simulate a sample where the null hypothesis is true we run our binomial test and we get a pvalue less than 0.05 then we've made what's called a type 1 error which means that we rejected the null hypothesis even though it's true and it it turns out right when we said so think back to our um our picture and our interpretation of that pvalue remember that in this example right the interpretation of the pvalue was the probability of observing 41 or fewer purchases given that the null hypothesis is true which is to say that our pvalue is exactly the probability of observing one of these values by random chance even when the null hypothesis is true so right like if we um right we got a couple of those examples of like when we when we randomly got 30 true and the pvalue was like 0.02 or something like that um then that was just that was a time when we would have rejected the null hypothesis even though we know that we were randomly picked those values with a 10 purchase rate yeah exactly and whoop right the p values that we collected here are just the probability of observing something more extreme than this given that the null hypothesis is true there is a it's a probabilistic process so every time we run this right every time we we simulate a new set of visitors we're simulating it so that we there is a a probability of getting something that is extreme that we don't expect and then every time we're just looking at the probability of observing something that extreme or more extreme wouldn't we more often get things that aren't as extreme right aren't we going to more often get exactly 50 people purchasing because the true probability is 10 so more often than not we're going to get 50 people purchasing less we're less often going to see 10 people purchasing um and so wouldn't that make it because we more often see 50 people purchasing wouldn't we more often um like see a different value here like what what's the so if we go back up to the the code um and we enter in let's the not in the loop let's just do one example uh if you scroll back and scroll up like if we hard code in rather than 69 there if we hard code in 50 right right what's the what's the um upsides 40 not not 50. oops sorry what's the pvalue going to be alex right so i think this is going to be like 0.5 or wait it's one oh because it's uh because it's twosided in this case um gotcha okay so wouldn't we see a lot more ones because we're most often going to get 50 there as that number that is a really well phrased question and i'm gonna be honest that my brain is like i when i really like putting you on the spot no no i this is really good and i feel like um i i this is one of those things where i go in and out of being able to explain it clearly and sometimes i have it in my head and sometimes my brain is tired and i'm like that's a good point alex uh let me see if i can explain that to you um let me let me like talk it through and maybe we can figure it out together and then if not i want to leave a little time to do one other thing totally um also in the chat if you have like a good way of conceptualizing this definitely share it with us and i guess one thing that we could do is can we run the the loop of a thousand over again and see another example of this graph because i'm curious because right now we do see one more often than not one right the the highest bar in the histogram is one um and i don't know if that's a coincidence or not no it's just a coincidence actually what i'd like to do to help answer our question is just i mean we know what this is going to look like but the so the part if we were to collect the purchases when we do this right if we like purchase [Laughter] and we do this and then below this we'll also do pld.hist um yeah purchase files here this should be a i guess a binomial distribution right right let's read it's funny that you're right it does like look like that every time but i promise you and if we crank it up to like 10 000 which might take more time to run i'm curious what happens right so okay so more frequently we're getting around 50 purchases um and now yeah let's see 10 000. it's running you can see a little good jupiter notebook trick is that you can see the okay there we go interesting why is this i'm actually confused why it looks like this every time like it it keeps seeming to like have the shape where it goes like up to two percent like point two and then up to point to one point oh so i hope i'm not like misleading you guys again like i did last time at the start of the next session though no no no but it should be that i i know this is like making me sad that my brain is not upset well it is confusing um um but basically this time it looks a little different but it still has that same shape i'm like i'm not sure about that but yeah we are getting this distribution which we expect um let's uh let's get to the the rest of the exercise and next week we can come back with further thoughts about this because i'm also curious about what's happening here okay yeah i have i definitely um i definitely can't explain this well when uh when i've like go through yeah sorry um no no it's i'm so glad that you do um okay so the last thing i wanted to kind of demonstrate is that um so remember so we went over these different kinds of errors where if the probability if the pvalue is below our threshold when the null hypothesis is true then we've made a type 1 error and so the question is like if the null hypothesis is true how often are we going to make a type 1 error and so let's pick a threshold let's pick 0.05 i guess okay and let's let's run this with a threshold of 0.05 um so i'm gonna copy and paste this below so that we can make a couple of edits to it and this time i'm gonna start a counter um and i'm gonna i'm gonna count the number of times that we make an error so i'm going to count the type 1 errors so i'm going to start my counter at zero and every single time i run this i'm going to um i'm going to say if actually we don't need to keep the pvalues this time so now i'm going to say if the pvalue is less than our threshold so less than 0.05 arbitrarily chosen threshold then i'm going to say add 1 to type 1 error so i'm going to say type 1 errors plus equals 1. which just means so and so this is a case where it's like we from our randomized sample we got a really let's say tiny value this time like 30 purchases when uh when we know that the the actual purchase rate is 10 and that's going to happen a certain number of times where we get this like really tiny value randomly yeah or i guess really large value randomly too since this is twosided right yeah so i'm going to do print type 1 errors over i'm going to do the this is going to be the type 1 error rate so we we ran this experiment 10 000 times and then i'm going to print how many of those 10 000 times resulted in a type 1 error okay let's try that it's gonna run it's a little slow quick question from chat briefly uh there's no uh you haven't seated the random numbers have you no i haven't seeded them um one thing that gets a little bit funky with um with the binomial distribution is also if our probability is too close to zero we start getting like um like some weird skew so we can try again but basically the point that i was trying to make and now i'm going to like go back and try to talk through your um your confusion alex but as you'll see here this number is pretty close to 0.05 right and because this should be uniformly distributed um basically exactly five percent of the time if you use a a threshold of 0.05 then exactly 5 of the time you're going to get a pvalue that is less than 0.05 because right like any pvalue between 0 1 and 1 is equally likely and so if we say what's the what's the probability of getting a pvalue less than 0.05 it's really just like that proportion of this area right and if that was a perfect rectangle then that would be five percent of the rectangle right um which is to say that basically whatever significance threshold you set becomes the type 1 error rate for your test and so um so if you say i'm going to set a significance threshold of 0.05 i'm going to reject the null hypothesis when um a pvalue is less than .05 then you're saying that i'm okay with the idea that five percent of the time the null hypothesis is going to be true and i'll still reject the null and so putting that in context of like back to the very start of like we've made this change to the website we want to see if purchases have uh decreased because of this change um or i guess are different because of this change because it's twosided right right then then this is saying like what it what is this can you put it in terms of like the actual experiment so right so and i think actually this like somehow helps with the confusion from before so remember that our experiment was essentially we're gonna look at a sample of 500 visitors and see whether the purchase rate in those visitors was less than our expectation so our expectation was that it would be 10 and we're gonna see if it's less than that or we're going to test this hypothesis that it's equal to 10 or less than that is our alternative and so now we're coming at it from another perspective we're saying let's say like the true purchase rate like if we could show this website to this version of the website to every visitor who could ever visit our website if we could show it to all of those people the true purchase rate the two probability of a purchase for each visitor would be 10 let's say let's suppose that that's true but we by random chance like we got 500 we got a sample of 500 uh visitors where among those 500 visitors the purchase rate just happened to be low by random chance we're saying this like five we're we're okay with the idea that five percent of the time if the true purchase rate was ten percent we're good five percent of the time we're still going to get a p value less than .05 right so if we did that this experiment of getting 500 different people 10 000 times like we're doing here then five percent of those times we're going to reject the null hypothesis even though it was true okay yes um okay one thing i want to see with respect to this picture is really quickly is if we change this to like 0.5 and 0.5 and 0.5 whether this shape is still persisting so now it looks more like i would expect um although it's still really jagged right i guess that's that jagged with 10 000 uh uh runs yeah i don't know this honestly might be yeah i'm surprised about it too i feel like there's something going on with how random seeds are being interesting or like how the random function is is working yeah um that's interesting but yeah that is really interesting it should be if the null hypothesis is true then this should be a a uniform distribution i'm going to um after this because we're running out of time but once i'm not on the spot i'm going to write out a clear explanation of this and why this is the case and then i will add it to the video but um but i want to leave you with kind of like the the main takeaway from all of this which is that when we run an experiment and we use a significance threshold so we say we're going to reject the null hypothesis if the pvalue is below some threshold the pvalue is is probabilistic remember that pvalue is the probability of observing something or more extreme given that the null hypothesis is true but that doesn't even if you get a pvalue of 0.001 that doesn't mean that what you observed is not possible it just means that it's unlikely but you can still observe that and so you have even if the null hypothesis is true so you have to have some threshold for error and what this means is because many people are using 0.05 as a significance threshold it means that five percent of all the tests that have been run with a significance threshold of 0.05 are wrong um if we're using that threshold right and so what ends up happening and we didn't get into this as much as i hoped but like if you let's say you run a hundred experiments at your company so i know my boyfriend for example his company is caught constantly running experiments let's say you run and they're probably running like thousands a day i would wouldn't be surprised so let's say but let's say you ran a hundred different tests what that means is that even if the null hypothesis was true for all of those 100 tests five of them would result in a significant pvalue at a 0.05 significance level and if all you do is report and act upon the ones that are significant then you're acting upon being a mistake and then that experiment might not be reproducible it was a fluke that you got something that your sample was so different from expectation but and how do you how do you counteract that though because you're no matter what you're always going to have whether it's five percent or one percent or point five percent right there's always going to be uh it's always probabilistic so like what's the what's the upshot of that how do you protect it yeah there's lots of different ways that people do this um sometimes people just use a smaller threshold so 0.01 instead so you have a lower chance of making a mistake um there's also like ways that you can basically uh what's the word um like adjust all of your pvalues based on the number of uh based on the number of tests that you've run so like a bonferroni adjustment is like one that's common um so there's different there are different uh approaches but the truth of the matter is you never are gonna fully you're never gonna fully escape the probability of some probability of making a mistake and the only antidote to that is being is one setting all of this like setting your threshold and setting and figuring out how you're going to adjust p values or what p what threshold you're going to use ahead of time figuring out how many tests you're going to run ahead of time and then if you're publishing a paper and you ran or your pub you're making a decision based on some results and you're like presenting it to your company you should show data for every single test that you run you ran not just the ones where you got a significant result right um so yeah the the antidote is clear communication of what you did and how you decided to do it um cool yeah cool all right um good work sophie uh sorry for putting on the spot i feel bad oh no no don't feel bad this is like what that's what this is all about i feel bad i feel like we've been doing these streams on tuesdays aft after the work day and so sometimes i you know i come in a little bit frazzled but i want to make sure that everybody's getting as much as possible out of these and i hope that they're super helpful and i will be sure and we're kind of pretending that this is like a this is a real class and so in a real class it's like we would come back next week and talk about this which is why we talked about last week this week so um so yeah i will i will make sure to post a more full explanation um so that everybody can benefit from that cool all right well thank you everyone we will uh yeah see you next week all right good one