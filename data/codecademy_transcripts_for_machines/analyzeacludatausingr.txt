oh hey everyone testing testing do you hear us okay something maybe comes up from the chat if your your aim I can hear us awesome thanks everyone for joining us yes yes welcome welcome we're streaming live from Kolkata me headquarters right here in New York City the Big Apple Big Apple my name is Nathan I adore the tigress and my name is Ian freed and we're the two curriculum developers behind the learn are launched today we hope you enjoyed our pirate puns as much as we did yes there's no feedback here they were a little corny we are a little corny a little punny bear with our but yeah we're super excited about today and this course release learn are the first our course I ever on code Academy and we're so excited about it yes when you know we spent the last few months going into our using kind of our backgrounds and data analysis and data signs and trying to think of some really intuitive and fun ways to teach what we think is a really really incredible tool for data analysis so a little bit of a highlevel overview of what is our exactly our is a statistical programming language that has a huge community of data enthusiasts and if you sign up for the course you'll see that there's three different modules that came out today but there's more coming soon the ones that came out today the first one is actually about our syntax and it walks you through some of the basic coding concepts like variables conditionals functions and how to import packages because if are as powerful for one thing it's for all the packages that it has for statistics and analysis and if you have never coded before it's totally alright our this intro course is great for people who want to jump into programming and learn things from the basics but at the same time if you're someone who's maybe been doing a little bit of JavaScript or a little bit of Python and you're see this language are and you're interested in it this is also a really great to jump in you know move over to what maybe we are starting to think is the best is out there but once you do not bias but and yeah if any of you um you know have been using are or have heard about it feel free to pop in the chat let us know we want to keep this you know chat here today a conversation we'll be talking about some really important things some really interesting things some cool things and we want to share that with you yeah we want to know why you're excited to learn kind of what your preconception of the language bar was before you signed up for the course and yeah so once you get past that you know introduction and syntax you can in the second module learn a little bit about data frames data frames are a really great data structure for organizing data that we can import maybe from a CSV or Excel spreadsheet or Google sheets and it basically the date frame will allow you and are to manipulate that data with different tools in order to organize it and arrange it in a way that's best for your own analysis so if you're someone who for work or for school is on Excel in Google sheets crunching numbers we hope that by the end of that second module you'll say goodbye Excel goodbye a Google Schneider circle hello and with that we'll be diving into a really useful package called deep liar that is a really great addon to our that enables you to work with data frames yeah and so I'm we're seeing some people have never heard of our or the heard of it but never use it that's totally okay we're here today to give you that introduction and we hope that you can get some practice with it as you follow along and we see Kenji baby has heard of our but hasn't used it that's perfect your perfect audience for this course yes and Elizabeth thanks for joining in and this is being recorded so you'll be able to access this on our YouTube channel and any time moving forward so we know we recommend you follow along today by watching the stream by also following along with us in the project but you know and let's say maybe you're a little bit newer and maybe you you got lost at some point which if you do and in time or some loss feel free to write in the chat but you know in a week from now let's say maybe you've gone through a few more of the modules and you're feeling more comfortable you can always come back and revisit the video will be there for you to watch so should we get into the data I kind of explain in the background of the topic of this project yeah let's let's let's seven okay cool so this project uses data that was published on an ACO you report which Kenya will pop right into the channel you can go ahead and read more about it but the ACO you report kind of is the result of a lot of data cleaning that the statistics team there did shout out to brook Watson she kind of inspired us taking on this data set thank you brother yeah Thank You Brooke um she has a great talk that kind of walks everyone through the process of the data cleaning and the legislation around family separations and the result of being able to organize data and recognize inconsistencies in it so that they could track down where the children who were separated on the family work and natal you want to give a little feedback for for our viewers on the situation and I kind of give like yeah context yeah let's start with context so there's a timeline kind of that explains the policy around family separation most of y'all maybe heard about it in the summer but a quick plug and just in general like a good approach to learning a language is to start with the data set that really interests you that's great advice from our inhouse data scientist Katherine she kind of told me you know start with something that makes you passionate and then go from there and I'll speak a little bit to my personal connection to a family separation and just immigration policy in general and then I'll explain the context of the whole thing but just in general anyone should be concerned about this is this general citizen but I grew up in the border of Texas so this kind of hit home and it and was really intrigued by understanding the data more so it helped me learn ours I was teaching it and I guess just from my perspective of both of our perspectives you know we we love programming we love coding we love data analysis and data science there are really useful tools and in our world and but we also think that there's a huge responsibility and task that comes with with this knowledge and you know there are so many projects that you can do out there so many things you can do with data analysis data science but to us it's really meaningful to take these skill sets that you can gain you know practicing here in Kolkata me you're practicing on your own or in school and using them to to make an impact and this is an area that we're you know we thought that the ACU was making a huge impact Brook was doing that and it's something that we're really passionate about too and so I think it's really meaningful for us I'd be able to share that with you guys here today and just be a reminder that you know data analysis the data that you're working with there's always stories kind of behind the the numbers as real people and real people and the work that you do analyzing the data can have a huge impact on people's lives so let's start with the boys because actually learned a lot about it I don't think that headlines really got into the weight of it but so in February 2018 the ACLU filed a class action lawsuit against immigration and customs enforcement branch of the government because at that point even though it was not a policy they had been separating children from their family some as far as two thousand miles away with little to no contact between the parent and the child the main case for this lawsuit actually only spoke to the child six times in a period of four months and they were separated 2,000 miles so this classaction lawsuit came about and in March when this was happening John Kelly proposed that this particular example could serve to help deter immigration on this other border so at that point conversation started around can get an actual policy aka making it legal to separate children from families and so inmate 2018 what became known as the zero tolerance policy actually went into place and family started being separated at the border and then that happened that was legal to do for like a month they were lots of protests maybe saw headlines about it but throughout that month over two thousand children were separated and at the end into the in June 2018 that's when the policy was stopped but at that point there was so much consolidation of the data that needed to happen so that the ice was equipped with how do you reunify his children that were separated with their families and the ACO you started analyzing data pouring in then June 2018 and kind of it was a month long effort months and months of consolidating the inconsistency so they could hold ice accountable for all the children that were in reunify debt and so the result of that is this really clean data set in this really awesome report written off by the ACLU and we use that and we take it one step further in the project to gain more insight into what was happening this summer so yeah that's that's kind of the background on all of it if you have any questions about that yeah I can we can talk more about it but if not let's just get to the code definitely and just before we jump in to just like one thing that you know they did at the ACLU was clean all this data that immigrations and Customs Enforcement was providing to them and you know when you're working as a data analyst or a data scientist you want to kind of get right away to you're like looking into the data getting insights maybe making visualizations or you know making some sort of model but often one of the most important tasks is just like organizing and cleaning the data because you can't you can't jump into that analysis until until the data is in a proper format and one of the things that they did here was you know sips through many different Excel spreadsheet was no standard documenting like the immigration number per child yeah so it may be like certain columns they have the same information but different names and different column or different sheets or even like inconsistencies and data like maybe you know for example and their documents they found that there were certain children who their date where they were is reunified with their family was a date before they were processed into the country so that information doesn't make sense so you it's important that when you're getting kind of raw data you're sifting through it and making sure that it makes sense and so that's something they did and then enabled us to go ahead and analyze yeah and that's not like an endemic problem to this dataset that happens all the time someone once said they're like 80% of a data scientist job is data cleaning so I think we you should extrapolate kind of the learning that's happening with this particular data set but realize that it applies to like a lot of scenarios not just this particular topic yeah and before we jump into the code I want to just take a look at what some of you guys are saying here so yeah using realworld interesting data is definitely the way to go I would say when trying to get more comfortable with doing data analysis like Natalia said find those data sets they're really stuck to you speak to you that means something to you and then also having that background knowledge on the data is super important as well it's really hard to jump into the data let's say like finance data if you don't have like some of that knowledge about finance and so even if it's just like you take a day or two to kind of dig into it it's really important to get that background I think your analysis will be a lot better for that so great point Arian and then someone else was asking is there a google of datasets and so there is we love it yeah what's the domain so I'm not sure the exact domain name but Google itself has a dataset search tool we'll try and find out that exact domain for you and you can try and post it in there but are you just Google even like Google dataset search it's a really great tool for finding datasets accessible for you to analyze yeah a lot of the times they come well documented so they'll tell you about the data collection process and the different fields and columns for it mmhmm and agree with Tim yeah katal is also a great place for finding datasets that are definitely well documented and especially also if you're if you're a newer you can kind of make me see what other people are doing with similar that kind of data again all of these links are posted up so if you want to learn more about the ACO a report or Burke Watson's talk you can find them yeah so this would be a great time if you guys are following along to make sure that you're in the the project with us and so you can either follow along in the the project that should be in the URL or if you're also going through the modules and you're at the ACLU data project you can follow along right in there so we have some background information here which kind of spoke at a spoke about we'll go ahead and get started with the first task you know always necessary always important so when you're gonna go ahead and do an analysis it's good to have access to different packages and what are packages packages are essentially collections of code that users have put together one of the other great things about our is that it's open source so anyone's able to go in and publish these packages where they can take all the work that they've done to simplify certain you know processes or tests that they think are really common and put them into a package that enables you to go ahead and just load that package and perform the task really nicely and simply and so we're gonna well I call it Diplo whatever insider deep fire and we're gonna use both of them so let's just go ahead and import them with the library function mmhmm I will say R has lots of kind of fun package names that three hours I think it is so they're into the puns too okay so to go ahead and load a library or a package we use the library function and you give as an argument to the library function of the name of the package you'd like to load so I'm gonna load the reader I'm also gonna load the packages and also if you're unfamiliar kind of with our notebooks which I would say problems yeah you know a lot of people may be and we were as well so basically what we're doing and let me move this over to the side just for a second make this bigger so it should be a little bit bigger for you guys now our notebooks are a really cool way to code because they enable you to not only write code that you'll be able to run but you can also do some nice annotation with markdown markdown just a nice way to yeah just add some some annotation explanation to your code but what's really cool is once you run the notebook file it goes ahead and renders into a HTML page which we don't have any code that's gonna do anything exciting yet and I'm gonna try and expand this side as well but in a little bit you'll see what this rendered notebook looks like and you can see it right here on the right hand side we just have any code yet but it takes your code and it makes it look nice and presentable and then it will also show the output yeah and what I really like specifically about our notebooks is that I kind of isolates the subtasks of a bigger program so if you see we've grouped code blocks and we've given a comment to each one with the hashtag symbol that kind of explains what our code block will do as we go through the project but if later you need to go back and change part of the logic you can just go straight to that part and not have to sift through the whole file mmhmm definitely I would definitely agree that kind of displaying and up into the different segments makes it really easy and then you can also see what the output looks like after each segment so if you're doing a data analysis where you're you know changing columns of a data frame or you're reordering things you can see at each step how that data is changing and confirm that your code is working as expected so the second step after we have imported our libraries we're ready to use it is to actually import the CSV file with the data so that we can use it inside a data frame which is a data structure for act angular data in our so let's go see what's that file called in our so yeah if you just click on the little top left there is that a file navigator I mean you can see the different files there so it's called a cou separations dot CSV and the way that you make a variable in our so that we could save it into a dataframe variable is you use this fun arrow syntax which is a little different than how most languages do it most languages use an equal sign but our uses this arrow syntax and then after that comes the value that you wanna identify that you want to assign the identifier so we made a variable name a cou and inside of that variable we want to go ahead and read the CSV which is a reader function and we want to pass in a string or character type that has the file name that we just saw which was a cou and in order to see if that actually loaded in as the right data frame we want to just get kind of the we want to print it so that we can actually see it right now when we hit that and the way that you do that there's many ways to do it you can print the whole thing you can print part of it but the way that most that is most common is to just print the top six rows of it so you can see what's in there and the way that you do that is with this function called head so you want the head of this data frame we just made called ACL you save it and here we have it and now you can see that on this right hand side this is what the surrendering notebook is looking like and so it gives us a little bit of feedback for some of the different code blocks so when we loaded the CSV file existed some information on the columns that are being brought in and then here when we look at the head of the data frame we are seeing the different columns so you see Baltimore big town Bethlehem let's just look at the column names really quickly together address maybe that's refer address and which is the number of children that were separated in that particular location the program City the program state the lawn which is the longitude and the latitude so it's kind of what we're working with here in this dataset so another way that's really good to kind of inspect data once you load it which is always a nice thing just because you might have some big CSV and you don't know the information that's in there and you wanna get an idea is to use the summary function and let's go ahead and use the summary function we'll pass in our data frame ACLU as an argument and it just provides a of summary statistics about the data frame so it will give for each different column if it's a numeric column so we're working with numbers it'll say you know how what's the smallest value what's the largest value what's the median value and maybe give a mean or a max and you know if you're not too familiar with different statistics like you know don't worry about it um we already have we have the courses for the mean median and mode coming out soon within the next two months so keep an eye out for those I did see someone and the chat was asking about more advanced our concepts and that's coming to you soon yes it's coming to you soon and are we also have some statistics and Python courses currently going so if you want to kind of jump and see things from a different perspective that's also a great way to go yeah so this gives just like nice kind of summary information so you have an idea of the data that you're working with so for example if we look at longitude I'm going to zoom in a little bit here so we can see we can see the the lowest longitude is negative 122 and then the let's see the max is negative 71 with latitude we're seeing a minimum of 25 and a max of 47 and so I I feel like all the time whenever I see lots of longitude I'm like which which which one goes which way so the lines of latitude they run horizontal around the world so those will kind of give you an understanding of how far north or south you may be so we're ranging between a minimum latitude of 25 and a maximum of 47 and so once again what it like one of these numbers mean all right sometimes it's like easy to get lost so that latitude is the latitude of these different detention centers where you know children who are being separated with their families where we're being taken so so I think it's always good to kind of just jump back and get like okay what what does it number mean in the contact of my project rather than it's just every ages from 25 to 47 yeah another interesting statistics just right up off the top with the summary function is that the median sorry the mean for children separated at any given location was 41 all the different locations we see in there that's what an average is up to but then yeah we see there's one location with a max of 350 50 no children separated there so I will see you later which one that is when we analyze it a little more for a second and and Connor I see that you are running into some trouble in your first five lines of code that happened to us like before we got anything installed in our computer we ran into a bunch of trouble let us know what's happening but also it's okay to be a different stage size I think like if you know a little bit of programming from another language it might be a little bit you might pick up are a little bit more quickly but that doesn't it's not a reflection of your ability to do it or like if that looks very differently for everyone so we definitely encourage everyone on the threat to help each other out let us know how we can help yeah we've all been there you know if your clothes not running and I would bet that sometime during the next 40 minutes our clothes yeah so yeah so alright we now saw kind of in the data let's start inspecting in step four says after you've inspected it you realized that the address column contains the same information that is contained in the program city and program state columns let's go check that out so let's say address column has Baltimore Maryland and then program city has Baltimore in programs to you Maryland that seems pretty repetitive hmm select all the columns from the ACLU but that one and save your new data to the ACLU variable so wait to clean what this is saying is like that's kind of repetitive remove that one let's go ahead and do that we're gonna reassign the value of the ACLU so that it changes with the updated data frame that does not include that one and the way that you do that is you use this pipe symbol the way that I describe this one to any student whenever I'm talking about art is that anything that comes after this pipe refers to the data frame that came before it and was gonna come after this is we're gonna stay select what's currently in the a cou data frame and give all of it back except for that's what the minus sign says the column adder which is address so we're saying select and program City program State longitude and latitude but please don't give us the address let's just make sure that works by printing it with our handy function head and so like another way to think about what that pipe symbol is doing is it's taking the ACLU data frame that's on its left and it's kind of pushing it or piping it into the first argument of that function select so and it's just another way that of kind of framing or writing code and are and you know as you dig deeper I and further into our this kind of formatting becomes super helpful and really like organizing your code and makes it clear for you know like what you are doing to a data frame yeah should we be writing about the pipe so kind of they can see yeah we can we can do both ways but another way to think about it without the pipe so that you can understand the cup a little better you could just do the same thing but instead of putting the pipe you would just put the first argument that's the data frame so like I was gonna look at this that line of code before I would say okay let's select from ACLU every column except address but now when we write it with the pipe you can say like from this data frame ACLU select everything but the column address yeah there's many way to do it we could have done the inverse which is listed out every single one but address and there's going to take a quick second so I see yeah Connor I'm glad you're not seeing the internal error anymore if they're still potentially in our in the our notebook the the rendered page might not you know appear properly so what I would do is try and look back at every code block that you know we've written compare it to yours and see that things are kind of similarly and then hopefully that should address the issue that's a ten yeah yes I was like filing yeah I think that don't happen though they might have to click on expand on the aircool so let's go ahead and do step 5 mmhmm so we were taking a look at the columns before but but one thing I always like to do especially I have a really big data set is just print out all the column names so I know I know the dinner that I'm working with because it's not always the case that you can easily click through and your notebook and see see all the columns and so the way we can do that is by using the call names function and we just pass to the call names function as an argument our data frame ACLU I want to go ahead and just put that all inside a print statement you don't have to put inside the print statement it would still render in the notebook but the output looks a bit nicer if you wrap it in the print statement so we'll go ahead and run this and we'll scroll down and we'll now see that were printing out the column names that we were seeing earlier now maybe maybe we can have reach out to you guys you guys think that these are helpful column names are they are they descriptive enough for you and they took my bows like what do you what do you think yeah I know I've got some thoughts and opinions on them so doesn't this Holly oh we're very opinionated people so Leah maybe maybe we can see if you guys have any thoughts and maybe if you have would like to see some changes for those column names maybe you can even without seeing what we've written I think of maybe some column names that we could change these two if you have an idea feel free to put it in the chat well we'll wait a little bit for you for someone to me put something in there just like a quick reminder these are the column hmm so we have one two three four five column names currently one is and it's not gonna Talia that's that's you know that says something about the column name it's not very descriptive mmhmm and we have program city program state and then lon which actually almost looks like Ian also yeah and yes yeah alright so we let's just brainstorm together like given what we know about the data set you know we didn't all this research creating the ACO your report we can kind of speculate what these mean and then let's come up with names together and let's so we're gonna reassign our data form to be more descriptive so we'll do that same kind of pattern we've been doing we just say the name of the variable and then reassign it with this arrow but after we're gonna do something to the a cou data frame with right and that something is gonna be we're gonna rename the column so based on that action we're gonna use the function called rename that's one really sweet thing about our that I found you know I know other languages and are just has the best most descriptive and concise function names that tell me exactly what it's doing yeah rename will take in X amount of arguments depending on what you want to do with that but the way that it takes them is it takes the name of the new column and the name of the old column and then it reassigns that so if let's say we wanted to name the rename the first column and which is not very descriptive to something like number of children because that's way more descriptive the way that we would pass that argument and it's like this number underscores okay and we would follow that pattern with the other ones every one to rename them in my opinion program city is too verbose the column name what what that column is is just a city so I'm gonna rename it to City oh and look I just pattern matched myself so I supposed to actually be the name of a new column and then after it the name of the old column this is one that I still make mistakes on all the time yeah always do it in the wrong way I have my own opinions about attacked I think I should be like you should have old column name first and then anyone cuz that makes more sense intuitively but our has its reasons and if you know this is a like a general programming thing that I really recommend if you're ever unsure about a function what it does or a package and the different functions that are in it going online just maybe searching are the package name so this case may be like Rd plier and renamed and right here in documentation you can go to the the website see the documentation for this package and for that function and potentially see examples or explanations what the arguments are or should be and that's always a really helpful tool for for troubleshooting or for answering questions true let's print it out to see what happened and we have a great question from Alex does our have strings yes our does have strings that you indicate with quotes but often when we are referring to like a column name of a data frame you don't need to use the quotes to indicate a string let's say if we're using that column name as an argument to a function so yeah great question and well we're gonna work with strings a little bit later on yeah and we do so here we have it we use the rename function after piping it the a cou data frame and it renamed end number of children program city to city program state to state and latitude and longitude to their full flush that works so now we can start coding and analyzing and actually know what these columns represent mmhmm and now that we have this information here you know when I was originally looking at this I was thinking okay we have this data that we got from the ACLU but what what else might I want to try and do with it right what else could we could we find out and I think this is an important question to ask when you're doing a data analysis because you might get your data from one source but you know that might you might want to dig a little further and find something else out that the original data didn't have and I was interested in trying to see how far some of these detention centers where children were being taken were from the border yeah to give a sense of you know really how far away some of these children under age 5 in many cases we're being taken I think it's a great question that you're asking with that specifically because a lot of the kind of headlines that went around with this topic didn't mention kind of the magnitude of the separation it wasn't just like they were kept in separate rooms a lot of the times they were kept in completely different states miles and miles from where the parents were kept so yeah and and you know when I was thinking bout this I said okay how how can I try and come up with some sort of metric to determine how far away these centers were and so since we were given the latitude locations at the center's I came up with the idea that maybe we should try and find the latitude for for part of the border between US and Mexico and kind of use that as a baseline to measure distance and so you know the usmexico border is thousands of miles long you know it stretches from the western most parts of the country to the eastern most and it varies it in latitude but you know I went ahead and we we found this the lower latitude of 25.8 3m as kind of a low point and in order to use this in an app our analysis we're gonna go ahead and create a variable just going to be called border latitude yeah and that old servers our frame of reference and we're gonna assign it the value twenty five point eight three and yeah once again just just to kind of backtrack for a second with the arrow like assignment operator you know you're still feeling like maybe a little uncomfortable from it if you're coming from another language I like to just think of it as you're taking the value on the right and the arrow is saying put that to the left into this variable I'm so now board allotted to it is now storing this twenty five point eight three identifier value and so now that we have this border latitude we can go ahead and try and create a new column to add to our data frame that's going to contain the distance or the latitude change really from that individual detention center to the border latitude that we have defined here so once again I'm going to I want to store this new data frame with this new column of you know back into ACLU our different we've been working with and we're going to take the data from that we're working with ACLU we're going to use the pipe symbol once again and we're going to use a new function keep using the dollar sign a new function that's also part of D plier that is used for adding columns to a data frame and that function is called mutate and that's also aptly named because that is what we're doing to the data frame we're mutating it by inserting a new column in it mmhm and the way the mutate works is we provide as an argument to mutate what we want the new column that we're creating to be called and we give an expression that defines how our calculating this new column so let's go ahead and we're going to name this new column lat change order just to indicate that we're saying this is the change in latitude from the Detention Center to the border and it will be equal to we want to find the difference between this border latitude and the latitude of the question Center so we have this column latitude so we're gonna say it's equal to latitude border latitude before we present let's just go through so we're saying alright take that data frame a cou and mutate it by computing a new whole new column called lat change border and the values inside that column will be based on what's in the latitude row for the data frame and in the word order latitude value that we have to be 25.8 III based on the average of work for tourism and I made another little mistake I have this equal sign here when I really want to sit sign because we're finding the the difference so let's just do an example really quickly if we're looking at this detention center that in Baltimore Maryland will zoom in for a second and I'll go over and we see that has a latitude of thirty nine point two nine we're gonna say take that dirty nine point two nine subtract 25 from it so we're getting fourteen approximately you know a little less than fourteen changed latitude so once we do this we want to go ahead and take the head once again of the data frame just so we can see what this scroll down and now we are over to the righthand side oh okay I'm gonna move my head out of the way and we can see we have this new column I keep backing up further a lot change border that is showing that calculation that we just made showing that changing latitude from the border to the detention center and that kind of makes sense if we look at the latitude for Maryland and we take that 25 it's about 13 in difference so it computed it exactly so let's go on to step 9 step 9 cents that's this whole section is actually about filtering and arranging gross so now that we have a column representing a Detention Center distance from the border you want to see which detention centers are far away from where the family separation occurred filter the rows of ACLU to find all of the detention centers where the latitude change border is greater than 15 save this new data frame to a new variable called further away and then let's see what's in that a different all right so I like this stuff because it has a lot to it we're basically now getting to the analysis part so we're gonna can you variable let's do that first further away we're gonna sign it and arranged version of what cou based on a condition um so let's pipe the ezo you and filter and like Natalia was saying before I think one of the really great things about deep liar which is a lot of the functions that we're using here today is they do they're doing exactly kind of what they say so here we want to filter out rows that don't meet this condition of the lot change water it's greater than 15 so the condition we're about to write is just gonna go inside the parentheses and that condition students basically give us anything where the value inside this column that change border is greater then after that what's printed I think I think it's just a formatting that's good further away great and now let's go take a look at this new data frame nice and so if we take if we go over to the right we can see that all of the latitudes or this lat change border column all those values are greater than 15 so we filtered out all the rows that you know don't meet that condition and are now just looking at these locations that are much further away from from the border now now we've done this filtering but there's kind of a next logical step that can be done once we've done the filtering and that is to order the rows of this data frame to see okay now that we have this group like which detention centers of this selection are furthest away I'm compared to which are closer and we can order or arrange these different rows using the arrange function and this is where we're going to go ahead and really use the power of the the pipe symbol that we've been using here and I'm gonna go ahead and I'm going to expand the code editor for a second yeah and so the way them I'm gonna use the pipe symbol now is instead of just making a new variable and saying okay let's take further away and pipe it into this function of rain if you want to use but we're gonna just take the pipe and stick it on to the end right here after our filter and then I'm gonna put a reins right here and to arrange we basically give as an argument the column that we want to order the rows by so if I go ahead and say lat change order this would then go ahead and arranged in ascending order our data frame smallest values and then from smallest to highest but we're interested in getting descending order so if you want to see the furthest ones away and then getting closer and closer so all we have to do is just put in DSC this is descending function and give it that change border as an argument so we're just going to wrap the column that we want to order by list DSC and so what what is happening right when we added this second pint so basically what this is doing is saying let's take all of the the code beforehand that we've done we've taken the ACLU data frame we filtered it on the latitude change border where the rows are greater than 15 or where that values greater than 15 and then take that new data frame that we have and then using the pipe let's arrange it or order the rows by descending lab to change order and then the result of all of that combined gonna get saved into further away so we'll give that a run and if we scroll down now and we more latitude degrees mmhmm yeah so that was a great great like point out by Natalia we we see Seattle first then we get to Oregon Oregon sprite south of Seattle then we're heading New York Michigan and so we're only taking the head right now is we're only seeing be the first six rows but now we have the furthest away centers and then the closer ones I'm so let's take a quick break for a second we'll go over to the chat yeah I also miss type like reader but it doesn't have any and neither does the player mmhmm yeah I'm gonna roll back to the top of our code compare and yeah we can do some quick comparing and contrasting one thing that might also be leading to certain issues is all the code that we're typing is written in between these tick marks so we have three tick marks and then we close a code block with three tick marks and this is essentially saying everything that was in that block of code is our code that we want to run so if you're typing outside of those three tick marks that is not gonna be run as our code it'll just show up potentially as markdown yeah so think of it as like anything inside this world I can code and it'll run are anything outside this code it's a different language and it's the markdown language and we we thought it was useful to split up code blocks for you kind of when you get to this page you see a bunch of political blocks that's the legend logic chunks but theoretically you could take all of the code that's our and put it inside one block and then it would do the same thing but we'd like to split up logic or clean code and document it code and reproducible code which is really important that's a data scientist and one of those advantages of the notebook is that you can add more kind of almost like paragraph style or formal writing in between the code blocks to really explain what what kind of work is being done so if you're you know writing reports it's a really useful tool for annotation yeah but if you have any more questions about that maybe that clarified some of the stuff with typing outside of the blocks if not we can move on to the number of children's analysis so step 11 says that as a concerned citizen of the world you want to identify the detention centers that held the largest number of children so let's order the rows of the a cou data frame by the number of children in descending order and save the new data frame to a new variable called order by children so okay let's take that step by step but we kind of just did something like it hint to this descending function and this arranged function we're gonna do something very similar to that actually I'll just show you like a normal workflow that I do which is copy paste and then just replace I'm gonna copy paste that line so I don't have to retype it I'm also gonna make the variable first cuz that's kind of limit my brain logic skips to variable creation first secret about coding copy and pasting the vegetables yeah from your own code from your own come from stack overflow the internet or resources we're not saying that you can go ahead and you know exceed people's code that's not what we're saying what we're saying when you write something you know it's really helpful to go ahead take the code that you've written yeah utilize it again and something we are saying though is that the art community is pretty collaborative so a lot of the times you'll see people give talks at these different conferences and then they'll put up they'll link to their codes but you can also reproduce it yourself it is a very collaborative community very true you know we recommend as you guys kind of dig into the our world to engage with that community it's something that's been like enjoyable for I think both of us yeah and for for people that we know who have been working with our for for longer it's a huge part of why they love our so much and I think this is a truly unique thing that that really sets our apart is that there is this active you know community that is out there if you go on Twitter hash check our stats yes super engaging community and if you ever have questions it's a great place to go mmhmm there's also lots of meetups this so okay so I'm gonna pipe it and then I have it in my clipboard that I copy and paste at this line and we're trying to arrange the ACO au data set in order of number two so I'm gonna paste that in and what's going to change in this particular operation is that instead of the Latin change border I'm gonna sort it by and that should do it that should give us a new data frame that has everything sorted by the highest virtually so it's pretty it to make sure we actually get to verify that worked ordered by and what this should tell us or show us is the detention centers that have the most number of children that are yeah actually when I first saw this report and I downloaded the data I was shocked that the Bronx was number one I was not shocked at all that Browns what was number two just because that is the border of Texas is actually where I'm from but the Brahms I was surprised about because I didn't know that it was happening so close to us like I thought it was happening down in the order just up of the borough yeah and that's I think a common thing with when doing lots of analyses that kind of you're working with like real world human data you know lots of issues can seem foreign to to people it might be something that they can't relate to but I think a really powerful tool of data science data analysis is like showing how something that you know might seem far and it can really be close to home or connected to to you and and that was one of the things that I really like connected with me step 12 which now that we've understood a little more about where was happening the most well let's see let's zoom in on particular state and then let's analyze that state because kind of right now we're still doing the whole country you see we have New York we have Texas Arizona Florida let's just go in it and before we kind of jump into the cove you want to reach out to you guys and see if there's any states you want to analyze or maybe yeah what you're looking in or maybe you're you know you're logging in from outside the US maybe there's a state you've visited or maybe there you haven't been to the US but the state you're interested in visiting more than you have family and our friends in so if you want to want us to check out a certain state just type it in to the chat give it a look we'll go ahead and set up kind of the code that we'll use to do this analysis in the mean time so I'm gonna create a variable called chosen state that is gonna hold the state that we are gonna take a look at I'm not gonna put anything in this variable right now I'm just gonna leave it as an empty string and we'll fill that with the state that I'm hopefully someone will provide to us and what we want to do is we want to go ahead and filter the rows of our ACLU data frame to only show the rows for the state we've chosen so I'm going to say ACLU and then okay first let's create the variable that we're gonna store this in so we want to call that chosen state separations so say chosen state California separations yeah I think just for many reasons will be interesting to analyze that state but it is a border state so I'm curious to see so as you can see in the state column we have this abbreviation of two letters for every state so the abbreviation for California is CA so we'll put that into our chosen state variable and then we'll say chosen state separations let's give it a value of taking our ACLU data frame and we're going to use the pipe and I'm going to just expand our code editor for a second and we'll type this into filter and we're going to say we that we want we want to give a condition that we're going to filter on so we're gonna say we want our the state to be equal to let me use the double equal sign here in studios measure equality since that single equal sign usually means what we're giving we're signing a value so we use that double equal sign is equal to our chosen state now why are we just saying chosen state instead of just typing in California directly we could just write CA but you know what's what's the purpose so the idea here is that by using this variable we can update that state really easily and and we're gonna use that chosen state again next a little bit later on and we won't have to update you know all the different parts of our code we can just update that one single chosen state and that's it you know I'm Josh accordingly so let's go ahead and run our code but before I run it let's go and take the head of our new data frame so that we can see what it looks like so we're gonna take the head of chosen state okay so I'm just gonna yeah I'll be my code do a little refresh yeah always copy your coat before you your fresh just to be safe I'm gonna strength this back and we'll see okay all our coat is still here I'm gonna click Save nice that worked and down don't want to look up in dictionary there we go so we see in concord california there was two children in el cajon there was 11 fuller 10 19 laverna too and then in los angeles there's only one mmm oh yeah we're now we're not seeing any detention centers that were in states outside of California so just seeing this one one state and if you're following along at home feel free to change that state from California to the state that you want to check out and you can see if there are any detentions are children to be held in detention centers there so now that we've chosen the state of California we want to find a way to organize this filter data frame and one way that we can do that is by now using the arrange function again and seeing how we can place these detention centers in order by the number of children that are being held there ordered by children but now it's gonna be happening on the chosen state separations variable so once again I'm going to use that pipe symbol and we'll place it at the end of filter which is saying let's take everything before the pipe that filter data frame and let's pipe it into our next function which is to be arraigned will give to arrange the column we want to arrange by which will be number children we wanted to do that in descending order and send the order not ascending will ESC and just wrap that around our number children and I will click head so down here sorts it this way and we see that the most detentions that happened in California was in Fullerton and it was nineteen you I'm just really curious what happens if we change this to Texas just because I am from there um so I'm gonna change it and kind of drive home the point that it's really nice to say things to variables we saved that and we run that in Texas there was a lot more separation that happened so we actually see that in Brownsville there was 348 in Harlingen which is 30 minutes from ran school there 174 in San Antonio there was 163 there's just a lot more separations happening there and yeah so and just you know maybe 30 40 minutes of coding here today we were able to dig into this data set and get an idea of how far away our children being taken or where children being taken from their families we have an understanding of the areas where these detection centers were how far they were from the border how many children were there and you know just looking at the CSV it would have been you know rather difficult to ascertain this information but we you know just from this limited amount of time have a better understanding and can maybe speak better to you know what was happening and then take action based on you know this analysis and the ACLU you know did some data visualization as well you can relate it to this data if we go over to you know the article that they worked on they came up with this great visualization showing where these descent centers are located and assigning every is too huge Detention Center seat visibly tell which ones had over 350 children which ones had around 100 and which ones had around 10 we will say though like a big point when I Drive home and in general with anything we teach is that you know code allows you to analyze data and most of the time depending on what kind of research you're doing that data is very impactful and so we've been talking I'm strapped me about these number of children but there it is a human behind that is it and there's statistics that represent these humans so never losing that component when you're coding is really important yeah definitely just always you know as someone working with data analysis data scientist there is a sense of responsibility that we hope that as you dive into this if you're if you're newer to programming or if you're more experienced and you know just checking this out that you just take with you as you go forward because yeah you have access to a powerful tool and we hope that you use it to do some good with powerful data comes great responsibility yes we recommend that if you're interested in any of the things that we did with this data set or in analyzing your own data's that you're interested in that you go find something you're passionate about download it and do some of these things to it whether it be arranging it by descending order or filtering it or really diving into the nittygritty of it we think it can be a great way to learn and our is made up of this community of a bunch of professions not just statisticians it's a lot of the humanities researches a lot of Natural Sciences it's just it's a very intersectional community so welcome you know if you're so just getting started feel free to check out our courses on code Academy we have three modules that we're really excited about on there so give them a look dig into the data sets that we provided in there we some fun ones I'm in addition to you know the ACU project you can you know ones about dolls yes that's one that I really like there is another data set about popular music groups and so hopefully some of that will interest you all census data yes u.s. census data so there's lots of exciting things there and then definitely like Natalia said after that we really encourage you to go on your own find some data that you are interested in and do an analysis and I'm feel free to leave as many comments with data sets you would want to see mmhmm yes definitely you know tag us on twitter at code kata me also reach out to our community hashtag our stats get involved we also would love your feedback about the live stream so we have a link that's just been placed into the chat so you can leave your feedback there we would be really really appreciated everything we do here is to is for learners like you to try and yeah hear what you guys are thinking and give you the best experience possible thanks for tuning in thank you so much for tuning in enjoy your coding and see you next time definitely see you next time take care everyone