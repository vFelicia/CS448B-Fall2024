okay but we don't know for sure but yeah let's go ahead and get started okay let us know in the youtube chat if you can hear us and see us um we'll be getting started in just a moment i feel like cool we look good together all right well welcome to our first session of codecademy live going through the recent launch recently launched linear regression course um we're gonna have eight sessions over the next nine weeks so we're gonna skip the week week of fourth of july um that we're going to have every tuesday at 11 a.m we're going to go through some content together um it'll be alex and i for today might have some different uh c devs so curriculum developers that codecad me jumping on these calls um but we're really really excited and then on thursdays for at least the next three weeks we're gonna run kind of an open office half hour also at 11 a.m so if anybody has questions or things that they weren't able to ask in this in this session um for anyone that was watching it later and things came up or anyone really if it's a small group who has questions about any of our data science content we'll welcome questions we really just want um to get to know everyone who is joining us and and we want to spend some time with you and learn what you're interested in and what you want to get out of this almost like a regular classroom so um it's good to see some people saying hello in the chat wow we've got someone from vietnam um that's awesome we moved the uh the time of this event from some of our previous live streams hoping that maybe we could get uh more people from around the world uh in a reasonable time zone for for joining us so i hope that that was helpful yeah so to join that uh that office hour on thursday um this is our first time kind of really trying this so we hope that the tech works and it's all set up properly but there's a link in the youtube description to kind of an event page where you can register basically it's just you're going to be joining a zoom webinar um i also just posted it in the chat um so if you're interested in that um hopefully it all goes smoothly um this first week and we can we'll see uh see some of you in kind of like a private zoom call where you can ask us some questions yeah super awesome i guess since this is our first stream um i'll quickly introduce myself and alex can introduce himself as well um so i'm sophie i'm a curriculum developer at codecademy i've been here now almost a whole year which is crazy and i work on data science content primarily um and i was pretty involved in building the linear regression course um working with content contributors and writing some of the content myself so super excited to go through it yeah and i'm alex i'm also a curriculum developer um i used to be on the data science team with sophie but i've gone over and started doing more of the computer science content so that those are courses that are kind of like similar to traditional college courses um so yeah if you check out the computer science past we're building out a ton of new stuff in that path awesome cool wow i see some people from india trinidad and tobago atlanta belgium super awesome um so we are keeping an eye on the youtube chat throughout this i think we're streaming on a couple other platforms but um come over to youtube if you want to chat with us live feel free to ask questions as we go along um i'm going to kind of lead and alex is going to keep an eye on the chat um and so he can let me know stop me if anyone has questions cool cool i'm going to go ahead and share my screen also while i'm sharing my screen see someone asked if there are any free courses on code academy alex you want to take that really quick yeah lots of free courses on code academy if you go to the catalog kind of like the full catalog you should see um so there's a bunch of paths which are all pro only but if you scroll down towards the bottom you should see courses and uh some of those are marked as pro only but a lot of them are totally free so um yeah lots of free courses in our in our catalog yes and i believe is i believe this course is also free yeah i think so what is what is this one actually called sophie or if you want to show off radio regression in python yeah so so so if you're your fourth power yeah your fourth tab there looks like it's the um oh yeah on this page well yeah let's see um if you go to the catalog and look for a linear regression in python um let's see linear regression in python yep that is a free course so anyone may join it and and take this content on your own as well cool so we're going to get started uh so before i code anything um i just want to remind everyone and this is in the youtube description as well but we have a um a github page that has all of this uh all of this code that i'm gonna be writing um and it has all of the code for the next three weeks after after this so you can get a head start and take a look it's meant to complement this content um we're gonna be using jupiter notebooks which requires a little bit of prep work and a download but if you didn't have time to do it before today you can definitely do that before the next session um so a little bit of motivation so linear regression at its core is a modeling technique um it's considered part of machine learning um and it's really like the the base model that a lot of more complex models are built upon so it's really if you're interested in machine learning you're interested in data science you're interested in statistics or you even just want to be able to like read other uh analyses read read papers or um you know find out about medical research or whatever it's a really good thing to understand because it's really the basis for a lot of a lot of things that people work on so uh for today we're gonna stick with some madeup data um and if you download the the code file the jupyter notebook code file in the first session uh link from the github page you will see that data as well so um in my jupyter notebook i have downloaded a bunch of packages here with aliases if you don't understand for right now we're just kind of going to zoom through this but essentially there are a bunch of different libraries in python that you can download to use functionality within them and then we're going to load them as these shorthand so that we can access them a little bit more simply cool so for today we're going to imagine that we went out on the street and we stopped i think there's maybe like nine numbers in here it's like seven eight nine um we stopped nine people on the street and we asked them for some information we asked them their height and we asked them their weight and then we collected that information um and we we wrote it down in these these two python lists so here i've got a list of heights and here i've got a list of weights and and they kind of match up as for individual people at each in this index so for example the first person was uh 175 centimeters tall and weighed uh 64 kilograms i believe those are the great correct measurements i i'm so yeah i'm so used to like pounds and inches which i know are nonsensical measurements so i gotta get used to centimeters and kilograms but yes so we clicked that information and i just threw it into a data frame here so you can see what that looks like for each person you have a height um for cratique if you're seeing saying that uh there's an error and you're not able to see anything um it might be on github it's sometimes it uh make has an error loading the jupiter notebook in github so uh in order to see it you need to download it and then run the code yourself but hopefully everyone can see my screen um okay so let's take a look at a visualization of this like what's the relationship between height and weight here so i'm going to go ahead and graph this use the actually use s and s scatter um and i'm going to graph the height on the xaxis and the weight on the yaxis and then we will show that okay so we see that there's this sort of relationship and this probably isn't super surprising to any of us that at least among the nine people that we collected data for um generally people who are taller tend to weigh more so right like the person that is around 180 centimeters tall is about 70 kilograms uh in weight and the person who's 160 centimeters tall is about i don't know 58 uh kilograms in weight and this is not true for every single height and weight so here we see a person who is around 173 centimeters tall who weighs more than someone who's taller at 175 centimeters tall so it's not always true that every person who is taller weighs more but in general we see this kind of trend that there's a relationship between these two things in the data that we collected so how do we try to use this to create a model um a predictive model or even a model to kind of analyze this relationship understand what is the relationship between height and weight here how can we numerically summarize that relationship and you might notice right that you could kind of if you were going to try to draw what this relationship looks like you could kind of draw draw a line through these plots and the question is how do we draw that line so we're going to take a step away from the data for a second and we're going to go back and do a little refresher on some geometry and then we'll come back and we'll see if we can get a line onto this plot so um so there's a good question in the chat right now of if i'm just starting um python three or three i guess the the direct question in the chat is i'm taking the python three course on code academy what will i have to do next to understand linear regression so somebody that's coming in watching this is our first session right we're trying to make this as approachable as possible if you don't need any kind of like stats background or linear regression background in order to follow this but some of the code that you're writing might look a little bit intimidating that's like oh i'm using sns.scatterplot i don't know what sns is i don't you know i don't know how to graph something up quickly i don't even necessarily even know how to like run jupiter notebook like what do you think the prerequirements for one watching this series is and then two for like trying to code along maybe after uh after the series totally so i think hopefully the prerequirements if you have a little bit of experience with python um you understand what a list is uh you understand how to use a loop uh write a function we're not really going to get go further than that in terms of python skills um i don't even yeah we'll we'll use a little bit of like looping and indexing in the later uh in some of the later sessions um but i do think so we're using in in these sessions a lot of python libraries that are specifically targeted for data science and statistics and those packages are primarily numpy pandas seaborn and matplotlib uh for plotting so those are i think hopefully if you understand some basic python you can learn those packages pretty quickly um and you can kind of get a sense for what i'm doing and follow along um in terms of like python 3 and jupiter notebooks it it takes a little bit of setup we have some articles on codecademy about setting up jupiter notebook and some instructions even in i think the youtube link and the event link on what you should download the easiest way is just download anaconda which is like a package manager and it will it also simultaneously will download jupiter notebooks um to get this code you need a little bit of github knowledge um but really you can just download these files as a zip file if you don't know how to clone the repository um so yeah it takes a little bit of setup a little bit of github a little bit of jupiter notebooks a little bit of python and then some knowledge about this these packages which hopefully i can help mediate as we go yeah i think the all these like kind of setup questions are definitely things that we can cover in the office hours of kind of like showing sophie's whole setup uh how to download all of these packages how to install them that kind of stuff um but yeah i really would encourage you even if you're not following every line of code i think the important thing here are like the concepts of um linear regression where you don't need to exactly know how this scatter plot function is working um you should be focusing on okay we're comparing height versus weight and there's some relationship between the two and we're trying to figure out how to draw a line between uh between all these points all right uh oh sorry i also see a note about for who is the police coming uh yeah i now live in new york city again i live across the street from a hospital um and it's not super super loud all the time but if you hear sirens you you will hear sirens and i apologize um nothing to be done so okay so let's go back to kind of thinking about what it means to draw a line through these points so what i'm going to do is i'm actually going to write out some new lists um actually i'm gonna i'm gonna make them numpy arrays so that we can uh work with them a little bit more easily so let's create a a numpy array of some some numbers i don't know alex come up with some numbers uh i'm a big fan of the tv show lost so i'm just going to give you the lost numbers of uh 4 8 15 16 23 42. okay so i don't know if that that's gonna work with our scale but this makes me feel anxious um okay so we've got a set of numbers and then let's come up with another set of numbers that are related to these numbers in some way so um we could for example take all of the numbers in a and add 5 right now actually i'm just going to print out b so that you can see it for a second so this is one of those things where understanding these packages a little bit can be helpful so the reason i turned this list into a numpy array is that um python math works a little bit differently with numpy arrays which are also panda series also true for panda series which are like these columns of numbers and a data frame in that when i when i say a plus 5 it's going to add 5 to all of these numbers so you'll see i've got 9 13 20 21 28 47 9 is just four plus five eight is just eight plus or sorry thirteen is just eight plus five um twenty is fifteen plus five and so on yeah so it's nice to be able to just be able to use that plus operator to say do it on every element of my array where normally i think just in like basic python arrays if you tried to do an array plus five it would say i have no idea what you mean by you would add five to this array i think it would actually add the five to the end of it yeah i think like if i do this oh you're right you're right yeah so can only concatenate lists not into the list so that was thinking that it was like trying to add on this thing to the end of the array but it didn't know how to add on a number cool okay so if this is my relationship and then i try to plot this relationship the same way i did before but instead i'm gonna just plot a and b right you'll notice that now all these points form a line right if i did some some other uh some other relate if i made some other relationship like if i squared all of these numbers for example right and then i wrote i plotted this you'll notice now all of a sudden they don't really follow the line they follow kind of like a curve um and so when we say fit a line what we really mean is can we figure out a relationship between these two sets of numbers that most closely represents the true relationship between the numbers because of course these points don't fall perfectly in a line but can we find a set of points or can we find a line a relationship between height and weight that really closely matches what we see in this form so if you why why can't we do that for this example where we we have this nonlinear relationship when we're when we're squaring all of the values in a right we can still draw a line that tries to meet those points like at what point is it too far away from a linear relationship to use linear regression well it's a good question so actually as we get past so today we're going to talk about simple linear regression which is really just the process of trying to fit a line to a set of data where you've got uh two quantitative variables um well simple linear regression could even be with a categorical predictor but for today we're going to stick to two quantitative variables and try to fit a line showing some relationship between them um once we get into more complex methods within still within linear regression we're going to find that there are actually ways to model more complicated relationships so actually like we can use linear regression still to follow this curve um there's a method for doing that um we also could try to represent this curve with a line and then acknowledge you know this doesn't fit our data as well but it's a simpler model and so we're okay with it um so there's really no there's really no specific rule or like threshold at after which you wouldn't use linear regression and actually like using some other methods within still within the world of linear regression you can model some complex relationships beyond just the line um but yes cool i see um i see a question about mean squared error and try to minimize it yeah so we're gonna we're gonna get to that in just a second how do we define what the best line is cool all right so what i'm gonna do is i'm actually gonna so i'll demonstrate this really quickly something kind of cool is that if we use the plot function from matplotlib dot pi plot it'll actually plot a line it'll just like connect the points with a line which looks a little awkward for this curve but if we come back to this like a plus five situation down here um right because all the points were in a line if we connect them we're just going to get a line right off the bat so we're going to use that trick to try to add some lines to this plot cool so um i guess actually before we do that let's come back to so what kinds of relationships here create this linear linear relationship so we saw one example where we get this line we saw another example where we get a curved relationship what kind what formats of relationships create a line and if you've taken an algebra class you've probably seen this particular format which is m y equals mx plus b um i guess i shouldn't have used a and b i'll use x and y here so that we can we can use that same shorthand that should be uh y equals x plus five right okay so um okay this should all still work great though just renamed everything so i'm going to define two more numbers i'm going to call them m and d and i'm going to say m is equal to 2 and d is equal to 5 and then i'm going to write this out as m times x so really all i'm doing here um and i'll i'll print y again is i'm saying okay my x's are these numbers then for each value so take four as an example i'm gonna do i'm gonna take two times four because i set m equal to two two times four plus 5 because i set b equal to 5. so 2 times 4 is 8 plus 5 is 13 and that's how we got this number and then we're just going to do that for each one so like 8 times 2 plus 5 is equal to 21 and then if we plot this it'll still be a line okay just so that we can see the changes a little bit more easily i'm gonna just set the limits for this plot so i'm going to set it from 0 to 45 42 if those are our x's are between 0 and 42. give ourselves a little extra room and then um i'll set the y limits to say let me go yeah and the reason why we're doing this is because it's a little bit hard to see that like these points are actually changing because the the axes just change on us automatically if we're if we keep redrawing this graph over and over again so what we're doing here is we're setting the bounds of the of the axes that we're drawing so now if we if we redraw that um uh that's what that line looks like but now if we change our original equation up there our y is mx plus b if we change it to like uh so if we change it to like times uh times three rather than yeah make n3 all right well times 1.5 because i didn't make this big enough yet hold on let's do it at 2 again let's up this to like 200 okay so now we've got more space so now if i change this to 3 and i rerun it now we've got the line changed slightly we can see that it got a little steeper yeah which would have been happening even if we didn't set the even if we didn't do this dot excellent.ylm um these two lines of code but basically the graph would look exactly the same except the axes would be different um and so by setting our axes we can actually see the line looks different rather than the axes looking different yeah exactly um and so it turns out that this format if you write a relationship between some set of numbers x and some set of numbers y in this way where y is equal is always equal to a number times the x value plus a number or minus a number because you could have a negative here you could have a negative number in either spot um if if you stick to that kind of a relationship then you'll always get a line a straight line and before when we were just adding five we were still conforming to this because we were kind of just multiplying x by one right okay so let's let's just like see what this does a little bit let's investigate these numbers so um so the first number the number that multiplies each of these numbers our x's um this is called the slope of the line and it has some effect on how steep the line is so if we make this bigger so if we make this a 5 and rerun this we'll see that that line got even steeper it's going off the page now if we make it a one it's going to be a lot shallower right a lot less and then if we make it negative so let's say i make it like negative three it's gonna actually i guess i should have done sorry guys still getting cut off but you can see it's going um it went from sloping up to sloping down and then the more negative we make this they probably should have done a smaller number as an example but if we made it even more um it's going to start sloping down even more steeply so that's our slope that gives us one one piece of the line and then the other piece of it the other thing that we might want to control is how high or low like where the line is or uh vertically like if it's higher or lower so that's what this is going to control this b is going to control what's called the y um intercept and so that is technically the value um up on this like yaxis where this line would hit at x equals zero so it's basically the value of y when x is zero or what we would get if we plug in zero into this point so in this case right if we plug in zero to this formula right now i'll just write it out so we can see it right now we basically have two times x plus five if we plug in zero for x we really have two times zero plus five so y is equal to five and you can see if we kind of extend this line out it's hitting this yaxis around the number five and so that that controls where that line falls if we go ahead and increase b let's say we make b equal to 100 all that's going to do is raise that line up so that if we draw this back to where uh the zero line is it's hitting at 100 um and then if we make it say like negative 50 it'll bring it down so that it hits the line right and so your original question here sophie was like what kind of operations make a linear relationship right yeah and and so the answer is kind of a dish uh like addition and multiplication and um based off of that also subtraction and division where b could be a negative number which makes it subtraction m could be a fraction which would make it division um so those are the operations that will make this linear relationship whereas we saw something like um using an exponent if we if we squared all of these numbers that made something that wasn't a linear relationship exactly so let's now take this back to our original problem and let's see if we can add a line to this to this plot um so one thing i'm gonna do really quickly so we saw right that we can control where the line hits um at height equals zero so we if we extend this out all the way to zero we can control where the hot where the line would hit this yaxis and then we can control how steep the line is so let's go ahead and let's extend the axes of this are we gonna eyeball the uh the line of best fit and try to uh this this would be a great thing to get from from chat of like come up with your y equals mx plus b that you think fits uh uh gets this data the best this one's going to be a little tricky because we have to like go back a ways and then we've got to go from let's go all the way from zero well we'll go from type all right sorry guys um okay so why is the weight so it is and then excellent we wanted to go from zero to okay there we go so here's here's our points now we've got to imagine so we're gonna write out an equation for a line we're gonna see if we can figure out if we were to draw this all the way back to here where would this hit at height equals zero and then if you want to throw your guesses in the chat go ahead and then um and then the second piece is going to be the slope that one's a little bit harder so one way we can think about slope is rise over run so rise is how far up we have to go for some distance forward okay so in this case it's like the ratio of if we if we're drawing this line how far up do we have to go to how far over do we have to go to stay on that line so if the ratio is equal to one it means that we could draw this line by going up one over one up one over one up one over one and the resulting points would create the line if the slope is two it means we have to go up two and over one up two and over one to get that line i think there's a picture of this in the linear regression course which i think is helpful right so this line has a slope of 2 because in order to create the line we have to go up 4 and over 2 or up 2 and over 1. no matter what it's going to be the same ratio but we have to go up twice as far as we have to go over in order to draw this line so the slope is in this example 4 over 2 um or 2. and right a negative slope would be you have to go down right or over two and down four um okay so did we get any guesses in chat for the yintercept not not yet so yeah in chat try to guess what the yintercept is and then also kind of what sophie was just talking about what do you think this slope of best fit might be um and yeah i see steve is saying oh maybe you can remove the x lam and y limb in order to have it automatically kind of size the uh size of the graph that's totally what we'll we'll do in the long run but we're just trying to be able to we're trying to basically eyeball the um the what's the xintercept or the yintercept um so we wanted to expand the graph to just kind of see where that uh that intercept might be but yeah i imagine soon we will go back to uh just having it automatically generate the um the dimensions of the axes yeah good questions are a good comment of all the points won't hit one common line in this case we can assume the two points lowest and biggest on the plot scale would give an idea of where the y concept would be right so kind of an implied question there is like how do we even go about this right because this isn't going to we know this isn't going to be a perfect line so like how can we even begin to guess what oh what an intercept would be um thoughts on that sophie yeah totally i think i think everybody that approaches this problem probably approaches it a little bit differently um so right so do you want to just try to like take the smallest and the largest and draw a line through that do you want to draw the line sort of in the middle of all of the points um and the most commonly used form of linear regression is ordinary squares regression which i'll define in a second but that's one definition of what makes the best line um you can actually run linear regressions with different definitions of what makes the best line and it changes the calculation slightly um but yeah okay see someone guess around negative 10 on the yintercept so um i'm gonna i'm going to type that in because that's the first one i see i think the slope is a little tricky don't see any um the ideas on slope yet i'll come up with an idea while we're waiting too in case no one has one but um but go for it if anyone there's no shame in in giving it a try yeah let's see so i think if i were to guess this slope it looks like it's going from about so the rise is like you know 75 to the the the point on the furthest right is like at 75 maybe in the point on the first left is that like 55 so that's the change of 20. and then the run is uh like 85 to uh what is that 60 so uh what is that 35 no 25 so 20 over 25 would be my guess if i i remember those numbers correctly so let's see i guess we could see what that line looks like i guess we try that sure all right okay what looks does the slope so 20 over 25 i just want to print out what that is so 20 20 over 25 is about point b um so let's try what do you guys think we definitely want to move this line down a little bit and it also looks like the line is a little bit too steep so um maybe let's try to kind of mod modulate the steepness first okay so we want it to be less steep so we want a smaller slope so what do you think point six we'll see what it looks like maybe okay closer i think maybe even a little less 0.4 oh that's too small maybe or 0.5 i think that looks about right for these points um so we want the intercept i think to be a little lower um so maybe let's try like negative 20. okay and i think one of the points of this is that this is like hard to do right or where it's like we're kind of struggling to eyeball this and so that's that's eventually going to be the point of linear regression is that we're going to be able to find a line that is that we compute in a way that's you know a little bit more scientific than us just kind of like randomly guessing um i i we had a comment that said the slope looks good but the wire is up to his way off that was my instincts too but i actually think that it was that the slope was a little bit more off and the y intercept just need to be suited down a little bit yeah so i think i've gotten to a place where i think this is pretty good we can change the excellent now maybe to like oops um you can change these limits now to more like 150 to 200 um 40 to 80 maybe that we can zoom back in um more like 50 to 80 and it looks like this line pretty well describes that relationship between the sets of the set of points um and so now the next question is how do we operationalize this which means like how do we define this so that's repeatable and then how do we actually calculate what these numbers should be this slope and this intercept right and i think a question is like is this actually good right because it's we could like kind of tweak forever where i could say oh i want this to be raised a little bit or the slope to be changed a little bit so like how do we know is this the best that we can possibly do how do we even define what is the best that we possibly can do um just kind of the question of how good is this yeah totally 100 agree okay so um i actually i think alex maybe you wrote this uh at one point this little applet but i'm going to go to the code cabinet i think yeah this one this one was not me but this one's good i like this one yeah um so it turns out that what we often do um or what we we do if we're running ordinary least squares regression is we set up this equation we say okay for each point right each height and each weight um so we can think of the y here as as weight and the x here is height for example um we want to define this relationship between the points we want to say somebody's weight is equal to some number times their height plus some number plus some error right so we're saying basically we'll make predictions along the line but we know that each individual weight is going to be not directly on that line so going back to this picture right none of these weights are exactly on the line and we can measure how far away they are from the line by drawing kind of the vertical line between them and so ordinarily squares regression says okay let's try to minimize these distances between the point and the line now actually finding the minimum of the absolute distances between the point and line is a more complicated math problem so because of like math being hard we actually do instead of the absolute differences so just taking like okay this one is um two units away or five units away or whatever and this one is one unit away and adding those up we actually just square these different these distances and add them up the squaring automatically makes them all positive right because if you square a number um a square a negative number is positive so by squaring it it means that a point below the line is just as that's far below the line is just as bad as having a point that's far above the line doesn't matter just matters how far it is away and um and so let's try to minimize those square distances for all of the points so we take square distance for this point square distance for this point square distance for this point add them all up and let's find the line that minimizes all of those distances this may be a silly question but why do we care about the um the vertical and distance and not like perpendicular to the line or horizontal to the line so actually there's like linear regression models that you can fit that minimize the horizontal distance so it actually depends on the research problem what you're trying to do um if you're trying to make predictions of the y variable so in this case like if your goal is to make weight predictions using height information and for example doctors might do this when you're when you're young they want to like estimate i don't know predict what height you're going to be or what weight you're going to be or say are you overweight or underweight compared to normal and so they want to know what this line looks like for on average so that you know um if your goal is to predict weight then minimizing these square distances is really like minimizing um minimizing how off you'll be in your prediction but you know if if you minimize the horizontal distance you're minimizing um how off you are with respect to like how much a difference in height um i don't know i honestly because because it's like if if we if we just change the axis if we just put height on the yaxis and weight on the xaxis it's the same data right but now the the line is going to be slightly different and the thing that we're minimizing is going to be the difference in you know in that other variable um is there is there one where you do perpendicular distance where you like just see how far away it is from the line oh you mean like like the crows distance or whatever like yeah exactly uh yeah i'm sure there is i have never seen it done yeah but that doesn't mean anything um so yeah cool cool cool so all right so i like this uh this little applet so in this applet you can randomize a set of points you can say okay let's like make 10 points on this graph and then let's move m and b around and see if we can minimize those distant those total squared errors um and so we can see this little bar on the side that kind of grows as the line gets further away and shrinks as it gets closer and we notice that there's some kind of like minimum here right like as i move the line as i move b up the squared error is getting smaller and smaller and then at some point it hits the smallest point and then starts getting bigger again so it's like we want to find this minimum here and if you have some time i very much recommend playing with this a little bit to get yourself kind of used to this idea of what you're what you're calculating when you are fitting these models cool so um there are a lot of different ways to actually calculate m and b for this problem for a simple linear regression problem where you have two variables you can use some calculus and you can actually just like get a formula basically for what those numbers are going to be um you need a little bit of matrix algebra for that and i think in session four maybe three or four um we'll actually walk through a little bit of that math because i think it's helpful in order to understand some of the assumptions that you're making and some of the errors that you can get it's also helpful if you want to use a different software besides python or a different package to fit a model um but i'm going to actually just go ahead and use a um a function within the stats models package and just quickly demonstrate to you all how we could fit this so i i've set this on live streams before i come from um a staff background and i learned how to program an r all of this in r first so i really like stats models interface more than scikit learn which is another package that you can use to fit these models there are actually many in python i think a lot of data scientists prefer scikitlearn because it has some other functionality that's really useful that stats models does not have um but for right now i'm going to just use stats models because it gives us a lot of useful information and this is the and this is the code so i've already downloaded statsmodels.api as sm so this is my shorthand for the statsmodels.api library and then i'm saying i want to do ordinary least squares regression which like we said is just minimizing those squared distances and i'm using the from formula function which allows me to kind of input a formula that i want to use to fit the model and so in this case i saved this data set as something called data it has two attributes right two columns white sorry weight and height um and i'm going to go ahead and fit the model to predict weight using height so this tilde tells me that weight is my outcome variable that's the first one height is what i'm using to predict it um so that's like my x variable here the data set i've called it data which is redundant um but anyway it's called data so this is telling python where to find these variables and then i'm just gonna go ahead and fit the model instead of doing that in two steps um and then i'm gonna go ahead and print a model summary so that we can all inspect it together so here's what this looks like um you'll notice so we do get this warning um the warning says any like it says something about uh kurtosis test is only valid for n greater than or equal to 20 continuing anyway n equals nine so basically it's giving me some sort of error around my sample size is not big enough i only have nine data points it only wants to run this test if there's uh 20 or more data points fine we're doing this as as an example we also see we see some other warnings in here um and we'll talk a little bit more about what these warnings mean basically those warnings are happening for a couple of reasons one because um all of these points are so far away on the xaxis from zero so we saw how much um that that intercept could change uh based on exactly what these points look like because it's so far away and then partly because we have such a small sample size and those are things that we can fix but really the important part here is we see these two numbers the intercept and so these are under the coefficient section so we see that the intercept which is the yintercept or that b value is about negative 21.6 or 0.7 and then we see that the slope and it it tells us that it's the coefficient on height the reason it does that is that we can add more variables this later um but tells us that that slope is 0.5 um cool so i see a question about using libraries or hard coding simple linear regression um so i'm going to show you within the course of this these sessions i'll show you how to implement this in stats models i'll also show you how to implement it in psychic learn um and i'll also show you how to calculate it by hand using a formula um so we're going to do all three in the course of this this session i think the important thing is not so much understanding um how to do it in a particular package but understanding what you're doing so that you could do it in any python package or package or um you know some or stata or something else entirely sophie so if we go back to our to when we were eyeballing it and just drawing the line ourselves and change our coefficients to that negative 21 and the zero point uh or yeah 0.5 whatever so we were pretty close yeah maybe sophie knew the answer is all along i bet she did but that's okay yeah this basically this line is the model that uh whatever library we were using would generate yes exactly so we're getting a lot of information this information is super useful if you're trying to do something more complicated really all we cared about and i can just print them out is the parameters of the model which were the intercept and the slope and we can see that those look pretty good they fit our model pretty well cool um so cool we have about five minutes left one last thing that i was hoping to kind of get through in this session is the assumptions of linear regression i'm gonna compress it because we don't have a ton of time um but one thing i think it's one reason i think it's important to in any discussion of simple linear regression or linear regression or any model whatsoever to think about the assumptions is that a lot of times a particular method like ordinary least squares regression might not be appropriate for the kind of data you have or the kind of question you're asking um and so it's important to know when it's appropriate and when it's not um and so that's where the assumptions of linear regression come in um also if you're interested in applying for like data analysts and data scientist positions this is the kind of thing that someone might ask you in an interview what are like i know i i've heard that we ask this in our data science interviews um what are the assumptions of linear regression so worth worth knowing what they are um so the first two are pretty simple first one is that there is a linear relationship between your variables if there's not like i said you can use more complicated methods to model it but if you're modeling using a line then you have to believe that there is a linear relationship that you're trying to model the second one is that each of the observations are independent um which really just means that one row in this data set can't affect another row so let's say that these were actually the heights and weights of all the people all the people in a single family um then you know a mother's height and weight might be more similar to a son's height and weight or they might have some like familial thing where they're really short and or really tall and really skinny or whatever it is that isn't really true of the general population so if you're trying to use this model to describe a relationship in the larger population you shouldn't use um you shouldn't use that model um so we we assume that they're independent and then um and then there's two more assumptions related to uh related to the actual data so one is that the outcome variable is normally distributed and a lot of times we check that by looking to see if the residuals are normally distributed um and so the residuals are those error terms they're basically like how far away is each point from the line um so we can actually calculate those so really quickly um i just want to demonstrate for example we can get the predicted heights for each person by applying this model so in this case if we take or sorry the predicted weights if we take the predicted heights of each person we multiply by sorry we multiply by the slope and then we add this number and adding a negative number is just like subtracting then we will get the predictions for the weights of each person in our data set and we also have the true weights of each person in our data set right so the first we would predict the first person is 66 uh kilograms but they're actually 64. the second person is 59 kilograms they're actually 58. um and we can see that here right in this line the prediction is where they would fall on the line and then the true value is below it so we saw the first one the prediction is a little high right and i think i don't know if these are these points are in order actually but um but we can see right the prediction here is a little high so we can take all of these predicted weights and true weights and then we can subtract them um to get the residuals those just those um differences and we can plot a histogram of them to check for normality um normality just means that they roughly follow the histogram kind of follows this bell curve like shape um actually i will i'll jump over to the example code to show you at this point so basically this is saying that um some of those residuals are or some of those points are under the predicted values some are over the predicted value um a lot of them are you know closer to the predicted value than not um and follow that bell curve exactly and it's a little hard to see here because we only had nine points but if we estimate the the line that should follow this histogram we see it's like roughly a normal distribution um and like alex said most of them are around zero some are a little bit below the line some are a little above the line and then the last is an assumption of linear regression how do you how do you what do you do sorry sorry i think my internet broke up there for a second um if this is an assumption for linear regression like how do you know this without doing all of this um well so you can plot you can start by plotting a histogram of the outcome variable if the outcome variable is bimodal or something or super skewed then um you probably want to apply some transformations um you could also fit the model and and look at this directly um but yeah it's something that you can you can deal with there are some methods for managing it if it's not met um but it's actually a way that you can improve your model if you fit a model and then you check this assumption and you see something super skewed that means like you have some avenues some indication that you might want to fit a different model um you might want to do something a little differently um and then the last one it's called um it has a fancy name uh homoscedasticity uh which really just means that the variance of uh of the points is the same for all values of the uh predictor variable um i feel like i didn't get so basically what you're looking for is not this um so in this example we see that the points are really tightly wound around like the um there's not a lot of variance in the points like down here for small values of height this is totally made of data and not realistic at all we even have a person with negative weight which is not possible but just a picture right like so these points are really tightly bound together and then these points are a lot more uh have a lot more variation and this kind of a picture would violate the homoscedasticity assumption it would say like what you want is for the points to be kind of like have equal variance around the line for all of the predictor and you can check that by making a plot um of the residuals against the fitted values the fitted values being those predicted values and then taking a look at um at what that that plot looks like and if you see any weird patterns in it that's an indication that that the homoscedasticity assumption might be violated so these are also i'm guessing you cover all of this in this first lesson in the first lesson in the course exactly yeah so this is um right we're about five minutes over so i'm gonna end it there um we can definitely answer more questions about the assumptions in office hours um and then also highly recommend just taking this first lesson um in the course on codecademy it's um the introduction to linear regression lesson it's the first the first lesson in the linear regression in python course um and starts to introduce some of the topics for next week for office hours again i'm putting the link in the chat there's also a link in the um youtube description we're doing that uh on thursday at the exact same time right now we've only booked it out for a half hour depending on how many people show up there um but yeah again it's kind of a zoom call or it's a zoo zoom webinar technically um so you can join the call and then we can like bring you on to ask um to ask questions to us um we also got questions about setup i saw sophie in the in the github page um you talk a little bit about um let me find that uh you talk a little bit about installing anaconda um so if you want to go through this code definitely make sure to follow those instructions and um maybe we can put together something uh to help out um with all that uh installation stuff there's also i think um i think another curriculum developer just recently updated a bunch of our content on setting up jupiter notebooks so i can try to find those articles but also if you go back to the first session of the master statistics live stream which we have on our youtube page um in the first like 10 15 minutes or so we go through the full process of like opening a jupiter notebook on your computer from anaconda and like running code for the first time so if you want to check that out um that also exists cool all right well i hope some people show up on thursday otherwise will be pretty lonely yeah but uh but yeah that'll be fun thank you for um yeah everyone in chat for asking questions a lot of new faces i haven't seen here before a lot of good questions um so yeah we'll um and then we'll be back next week with another um another session awesome cool all right thanks sophie