hi they're making sure we're alive awesome thank you everyone for joining us today we're here to do another livestream here at code Academy HQ where we'll be doing a natural language parsing analysis on a novel of your choosing we'll give everyone a little bit of time to log in and get settled at your computers my name is Ian freed I'm a curriculum developer here at code kata me working on some of their data science content that we have here and also delving into natural language processing which is why we're here today so if you are coming from a background where you've done some naturally entrusting before that's amazing hopefully you'll get to learn something new in NLP today if you're not coming from that background it's totally alright I hope that today you will get to learn a little bit about what natural language processing is and some of the things that we can do with natural language processing and along the way we'll also get to use a really useful tool known as regular expressions and we'll utilize that in order to do our analysis and thank you Mario for the happy birthday wishes I appreciate it and I will have some colleagues in the chats also answer some questions that anyone has along the way feel free to to be active in the chat I want this to be a conversation I don't want to just be talking here for an hour but have it be a conversation a twoway street where we can work together to hopefully perform a really great analysis together so natural language processing is a area of data science where we can look at text data and do really cool analyses on it and so today what our plan is going to be is to look at a whole novel and we have a few different novels that we can consider working with and maybe at the end you'll have the chance to choose any novel of your own choosing and do an analysis on the word choices that the author has made and trying to find some meaning that we can quickly discern from the novel without having to read the whole thing so using our programming skills and specifically Python in order to find out some of the insights that might be hidden in a piece of text and just to give you kind of an idea of some of the really cool things that we can do with naturally into processing and specifically parsing natural language I just want to highlight some really cool examples that are out there that people have done um one was an analysis on the Harry Potter novels and someone went and did this kind of parsing analysis on the Harry Potter novels and looked at how the author and the characters in Harry Potter used different words so what nouns or what what nouns are common so names potentially or what additives are used to describe those nouns in the novel or how action occurs to different characters in the novel so you can see here in this analysis they were looking for certain combinations of verbs and nouns or nouns and adverbs or potentially adjectives as well and seeing what patterns arose and how these different kinds of parts of speech are put together and this person who did this analysis was able to find a bit of a gender bias in how different characters have action happened to them or action is described by characters so that was a really cool thing that maybe just by reading the novels you wouldn't get to understand but this person was able to discover using parsing with natural language processing another really cool analysis that was done by someone was posted here on Twitter and they were looking at declassified CIA documents and they were able to use this kind of analysis to find a code word that hadn't been with analyzed before I discovered that this code word has some importance and so they found this code word to be really relevant just because it came up so often in the documents and these were hundreds and hundreds of declassified CIA documents that you couldn't really read through by hand but by using this kind of analysis they were able to find this this code word and so yeah today I'm meant to mention this we'd love for you to follow along with us by clicking on the link on the bottom of in the YouTube description which will take you to code Academy where you'll have a workspace set up where you can complete this kind of analysis with us so hopefully you can follow along stepbystep and get the same results as weekend so for today's analysis we are going to work with one piece of text and I have two texts that I've been thinking about using one is the wonderful what sort of oz which many of us are familiar with has characters that are you know from our childhoods and we've all probably seen the movie at one point so we can do a fun analysis with that or I have another novel anthem by ein Rand that I've also gotten the text for so I'm trying to decide between what which texts to use today so if someone wants to maybe shout something out in the chat about what you prefer we can choose one of those two texts and move forward with our analysis I like both books you know Wizard of Oz it's a classic that I think we all have fun memories of but anthem is also another interesting novel that I think bring out some interesting insights by doing this kind of parsing analysis on the text anthem is kind of about a dystopian future and a character who's coming to this sense of individuality in his society yeah I'm glad I some of the other Rafal think that this is awesome natural language processing is a really really powerful tool and it's really crazy what can be done with utilizing this tool I'm kind of insights that we can find especially going through these sometimes lengthy pieces of text and finding insights that would maybe take longer if we were to fully read them or things that you might not even pick up in a casual reading okay so what we'll do is we'll probably go ahead with The Wonderful Wizard of Oz I think it's just a classic and I think hopefully can be relatable to a lot of people and knowing the characters so we're gonna go ahead and get started and what I'm gonna do is here on code kata me I'm just gonna minimize my left hand side so that we can get a better view of the code editor and I'm gonna expand my output terminal a little bit and let's go ahead and start our analysis so we can see I have two files open one's just a Python script I'll be writing my code today I've imported a few different libraries and functions for those libraries that will be useful in our analysis and I'll explain those as we go through and then I also have a text file that contains the wonderful wizard of odds and this file has the whole novel in here and I was able to get this novel from Project Gutenberg which is a really great resource if you like to read or you're really interested in digging international language processing and Project Gutenberg is this project that contains lots of open source of public domain pieces of literature that you are able to use you know that are open and can be reproduced so this website as you can see right here has a huge variety of these public domain novels and you can feel free to go find any novel from here and do an analysis on it later which you will have an opportunity to but I've got the text for The Wonderful Wizard of Oz from here and I just pasted that text file into this text file that I created over here in the code editor so now that we have this text file let's go ahead and open it in Python so I'm going to create a variable named text and to open the text file I'm just going to use the open function and I'm going to pass it as an argument the name of the text file which is the Wizard of Oz text dot txt and I could just try and then add a dot read here at the end to read that file in and if I try and run this right now I'm going to run into an issue and say ok no such file directory found because I repeated off so that was not the error I was expecting but another error nonetheless but so I'm going to delete that extra of The Wizard of Oz here we go miss the Z and I'll run this one more time and The Wizard of Oz no text file names are important guys you will see that if you don't get the exact filename right it's not going to load so this time I want to check it word for word The Wizard of Oz dot txt matching my text file there at the top no I will run this again and we're going to see you okay well so I'm not printing out anything so we won't see any response but if I go and try and print text right now we're still gonna not have our full text arrow we do great so we can see we have on the right hand side our full text that we opened if you're working with certain text files sometimes there's an encoding that might be included on that file so another argument you can add is encoding to our open function and just add utf8 utf16 m8 encoded but it doesn't appear to be so so you can include that just to be careful when you're loading in that text file and one more thing I'm going to do in addition reading the file in is to make every single word in the text lowercase and the reason for doing this is when we're trying to see how frequent maybe certain words occur in the text we want maybe words that are capitalized at the beginning of the sentence to be considered the same as a word that maybe appears in the middle of a sentence so just because it has a capital letter we don't want there to be a difference so I'm going to add lower to the end of this importing of the text and now if I rerun my file will see that now every single word is now in lowercase depending on your analysis you might care that certain words are uppercase or lowercase so you can choose to you know make that decision if you feel the need to do so so I see oh we have a question here I want to carry out analysis on Fight Club not sure where to stand with the copyright so when going into natural image processing it's good to keep in mind you know the copyright of the text that you are working with or who has ownership of the piece whether it's an article from a newspaper or it's even let's say you're grabbing a bunch of tweets and doing your analysis a bunch of tweets so it depends what you plan to do with your analysis if you're distributing it out to the public and or if you're doing it personally so you do want to be careful in that realm you should look at the copyright that is given on the piece of text that you're working with the beauty of Project Gutenberg tax is that they are in this public domain I'm allowing us to to kind of use it without a lot of worry so I would say to just you know proceed with caution if you're going to be sharing any any of your work just so you're not violating any sort of copyright law great question okay so we've gone ahead and imported our text but to perform our analysis we need to break down our text from this giant novel that we have into a smaller pieces that we are able to analyze and so one smaller piece that we can break down our checks into is from the whole novel to individual sentences and when we break Tom check to individual sentences we can then perform a sentence by sentence analysis and and this makes things a little easier to digest in this process of breaking down checks into smaller components as a process notice tokenization so let's go ahead and perform some tokenization on our text the first step being substance organization so to do this we are going to use the natural language toolkit which is a really great tool and package and Python so natural language tool kit or NLT kay it has a lot of great NLP functionality that we can use and one of these is the punked sentence tokenizer and this is a tool that will go ahead and look through our entire text and split it up into individual sentences so I'm going to create a sentence tokenizer right here and I'm gonna set equal to punked sentence tokenizer and if you look at the top of the file we have seen that imported at the top and I'm going to give as an argument to that Punk census tokenizer my entire text and what this is doing is it's almost training this sentence organizer on the piece of text that we are giving to it and it's using some machine learning in the background to do this training and now that I have this sentence tokenizer I can go ahead and split up my text into individual sentences so I'm going to make a new variable called sentence tokenized and set it equal to my sentence tokenizer sentence tokenizer and I'm going to call the sentence tokenizer is tokenize method and once again give as an argument our text data so what this is saying is we're going to use that Pung sentence tokenizer that we created and tokenize that entire novel The Wonderful Wizard of Oz I'm going to go ahead and now print sentence tokenized so we can see what we are working with and rerun our code and so it's a little hard to see here but what I'm going to do is I'm just going to look at one index of this variable that we created and so sentence organized is now a Python list and so Python lists contain indexes which have their own individual pieces of information so if I let's say look at the tenth index of sentence tokenize and I print that now we can see at the bottom and I'm actually going to comment out my printing of the whole text to make this easier we can see that we're now just getting one sentence from the novel and if I change the index from ten to fifteen and I run the file again we're gonna see that we're now printing out in the console another sentence of the novel so we've taken that entire piece of text data and then split it up into individual sentences and if we wanted to see how many sentences are in the novel we can just go ahead and take the length of this list that we now have and we'll print in the lane and we'll see we have two thousand two hundred twenty sentences so this is now the the data that we're working with and it's easier for us to handle rather than having one giant piece of text okay now that we've broken down our text into individual sentences if we want to look at the choices that our author is making in terms of maybe the parts of speech within a sentence we need to break down our sentences into individual words and so this is the process known as we're tokenization so let's go ahead and do word tokenization on each sentence from our text so to access each sentence we're gonna do a loop through such and silk'n eyes so I'll say for sentence in sentence tokenized and right here we're going to use another function from an LC k which is where tokenized which you can also see imported at the top of our code and I'm going to say word tokenize and give we're tokenized as an argument each sentence and since we're going through each sentence I want to create a new list that's gonna store all these sentences that are now going to be split up into individual words so I'm going to create a new list called word tokenized before my for loop and I was going to set it equal to an empty list and then when I'm going and we're tokenizing each sentence I'm now going to append that result to my empty list we're tokenized so let's just review this what we're doing this loop one more time we are going ahead and saying let's look at each sentence in our novel and for each sentence let's break it down into individual words and we're gonna store those words in a list and so let's go ahead and print out a 1 1 piece of that word tokenized list and i'm going to save and run my code and will now see if we look at the output terminal we have the original sentence even the grass was not green for the sun had burned the tops of the long blades and then we see beneath that we have a list where each index in the list is an individual word from that sentence so we now split up that sentence level into an individual word level so we want to just take a second to pause make sure everyone's able to follow along and has hopefully got ahead and said to tokenized and we're tokenize on the novel checkin for any questions let's see glad you guys find NLP exciting I do too it's a really cool area of data science of a natural language study and I hope you got to learn something here today okay so if no other questions we'll go ahead and continue and just as a check I'm gonna go ahead and print the length of our word tokenized lists as well and you'll see that the length of this list is also two thousand twenty two thousand two hundred twenty which is good we still have two thousand two hundred twenty sentences in our novel this time though instead of each index just being the regular sentence as a string we have a list where each index in that list is an individual word in in the sentence and I said we have a question is a stream going to be staged in at all for later reference yes you'll be able to find the stream on YouTube to rewatch at any time so if for some reason you're not able to follow along don't worry you'll be able to go back rewatch and hopefully completely analysis yourself now that we've gone ahead and split up our text into individual sentences and individual words we need to think about how we're gonna go ahead and look at the different parts of speech of her sentence since you know that's a really helpful technique for going ahead and looking at the choices that an author has made and so let's do a little quick recap of what are parts of speech I might have been a while since you had been in English class but and this can vary between different languages but there's different parts of speech and in English there are eight or nine depending on us main parts of speech and these parts of speech explaining how different words function within the structure of a sentence so one part of speech are nouns nouns are usually the subject of a sentence the name of some of a person potentially a place or a thing or an idea that we are discussing and then we have pronouns which are words that go set in place of a noun we have determiners which determine a noun so kind of this taking a break here you know for example this is my cat and that sentence cat is the noun because we are talking about the cat in terms of pronouns Tyra is a student she is studying computer science she is standing in place of the noun tarot and then determiners are introducing nouns so I have two alligators it's saying that we have two of the noun in the sentence where we have some bunnies another common or another part of speech or verbs verbs describes what we do you remember that Nickelodeon I think it was like verbs it's what you do kind of jingle so always good to review these I'm sure many of you are familiar with them but it's you know easy to forget sometimes adjectives will modify or describe a noun so you're describing let's say your pirate your power it is colorful or your part is big colorful and big are words that are describing that noun then we have adverbs which are modifying how modifying a verb so are you running quickly are you eating quickly quickly is modifying that verb and then just a few more prepositions which are placed before noun so I went to work I went to the store is that preposition conjunctions we'll combine things together and or but so I like Tigers and I like lions and then interjections like ouch Wow exclamations things that are inserted into sentences and often are evocative so by looking through each of our sentences in our novel what we can do is we can assign the part of speech to the words in those sentences and then go ahead and try and find patterns in how authors or writers are using these different parts of speech so how are they choosing their nouns or how are they using to describe the nouns with adjectives or how are they choosing to describe the action or the verb that maybe happens to their subjects which are nouns and this can bring some interesting insights so we could go ahead and manually look at every single sentence of ours and assign the part of speech but that would take a long time but thankfully with an ltk and natural language processing we can go ahead and automate that process and part of speech tag sentences automatically and that's what we're gonna do here today and we're going to use an NL CK function POS tag in order to do this part of speech tagging so what we want to do is we want to do this for every single sentence in our text so we're gonna do another for loop so I'll say for sentence in word tokenized and maybe let me stop for looking at questions before I jump into this any questions someone asked what is the advantage of the tokenizer function over using the dot split function so tokenize will go ahead and kind of use a little bit of a more advanced analysis than then dot split so dot split you can provide as an argument what you want to split on so maybe you want to split on spaces but the the sentence organizer from and the word tokenize are from NLT k just have a little more behind the hood to make sure that we're splitting as best as possible that's a great question and as I'll I was we're saying we can capture potentially punk punctuation or or whitespace better with I don't see J's tools okay so now we're going to loop through each sentence and our word tokenize text and we're going to go ahead and part of speech tag that sentence using the POS tag function and as an argument we'll pass each sentence and once again we want to store all of these part of speech tag sentences that we are creating so we're gonna create a list right before hand and I was gonna call it POS tag text and we'll initialize that as an empty list and also it's just because my code is probably running off the screen I'm gonna move it up a little bit and I'm going to append this part of speech tag sentence to my POS tagged text list just like so and once again I'm just going to print one value from the part of speech tag sentence that I have created so we can take a look at it so I'm going to say a POS tagged text and I'm gonna say at let's say index 10 so I'm going to run and oh no I'm getting an error so let's go and investigate and it's saying that NLT kay is trying to do this part of speech tagging but we are missing essentially a resource which is a data set that ltk uses in or it's a part of speech tag the sentence um and so if you are kind of doing this analysis on your own computer at another time there are different packages or a different data sets is part about lck that aren't always downloaded so you might need to download some of this extra data so we'll go ahead and download this data by running the command that's listed here in the ER says NLT kay download average perceptron tagger and this is going to give basically a data set of part of speech 10th words for adult ek to use as a reference so I'm gonna go ahead and above where I use POS tag I'm going to run that one line and I'll take a download average perception tracker I'll click Save to run my code and there we go we can see this confirmation saying that we've downloaded the resource and then we can see here we have this part of speech tag sentence and what I'm gonna do just to make it easier to see what's going on I'm just gonna comment out some of my previous print statements just that we can focus on the part of speech tag sentence and I'm also gonna comment out our download we all need to do the download one time once you download the data there's no need to download it again so well comment and let's run our code again and here we can see this sentence where the split up into a list and it's a list of tuples which are defined by the pair of parentheses and the first index in the parenthesis is a word and the sentence is the part of speech tag so we can see we have was which is tagged vbd and you're thinking okay you were talking about nouns verbs adjectives pronouns what what is vbd what does this mean it's a great question if you're thinking that and basically there are these abbreviations for the different parts of speech and they get even more specific than the 8 or 9 main parts of speech in English and we'll look at a list of what some of these abbreviations are here and we can also I can post this into the chat as well for you guys to see on your computer but basically this is a list that shows what the abbreviations are for different parts of speech and the part of speech name so we saw vbd before back in our code so that was for was so if we look up vbd we can see vbg is a past tense verb so this gets more specific than just a general verb it's going into the tense of the verb or the different forms potentially for adverbs or for adjectives so for adjectives we have regular adjectives which was indicated by JJ but we also have comparative adjectives or superlative adjectives so it gets pretty specific which can be really useful for finding specific sequences of parts of speech in our text and this is just a great reference to have when you're doing this kind of analysis if you're ever confused about what part of speech is being tagged you can come here and get an explanation and if you're still unsure about what the the part of speech means may be something you're not from with their you know definitely some things on here that I'm not familiar with I'm no expert linguist you know don't be don't be afraid to go google it dig into the word a little bit and get a better understanding of what that part of speech is it's all part of the the process of learning of digging into NLP which is such a huge area of research so so don't don't ever feel like intimidated or I think you don't know it's okay you can always you know fill in your knowledge by doing a little bit of research so we can see here that this sentence has now been tagged with the different parts of speech so let's just zoom in a little bit and we can see we have an adjective small so small JJ it's describing a noun a small hole hole is the noun and we also have determiner DT for the word dumb and let's see some other things that we can point out crush crush is a verb so this is a really powerful tool that we have available to us and so we've gone ahead and now part of speech tagged our whole piece our whole text what is the next step how do we go ahead and tell our program hey I have these different parts of speech I want to look for now certain patterns a part of speech that might give me some sort of insight into what my text is about or how my characters you're acting or how my author is describing things and this is where we get to use the power of regular expressions regular expressions are a hugely useful tool in computer science and are used to essentially describe patterns of characters that need to be found in a piece of text so if you've ever you know control after in your computer to look for word in the background there could be some regular expressions running to to find that search term on your on your page they're often used for validation of information so if you're ever typing in something on a form there could be some sort of regular expression running in the background that's validating what you're entering is this a valid phone number is this a valid email address by looking for essentially the @ symbol so it's a really really useful tool and if you're not familiar with regular expressions that's okay we're just going to touch on a few concepts for them here today and if you want to learn more there you can feel free to come on code Academy we have a great course on regular expressions that you can check out and against them further but what we're gonna do here today is we're going to use regular expressions to not match the specific characters but to match specific sequences of parts of speech and this is a really really useful thing that we can do to find these patterns in our text and the way that we can do that is through through parsing our text through a means known as chunking and chunking basically says looking at these part of speech tag sentences that we have I want to find a certain sequence of words and I want to pull out that sequence and we do this by defining what's called a piece of chunk grammar so I'm going to find that right here I'm gonna say chunk grammar and what my chunk grammar is is essentially a explanation of this pattern of parts of speech that we want to that we want to find and so the first part of the song grammar is the name of the chunk that you're looking for and this is something that you can decide yourself so I'm gonna start off by just naming it chunk and you put a colon and then what you do is you put a pair of braces and inside the braces you put the pattern of parts of speech that we want to match so to do this you put in the parts of speech with brackets so I will do an open and close and I know you inside inside these brackets you put the name of the part of speech that you're looking to find so I wanted to just find nouns inside my braces I then have the this NN and that means I want to just chunk mounts and and this would just find nouns for us in our text once we use the chunk grammar but we don't want to just look for nouns the the idea here is to look for a pattern a different parts of speech that will give us insight and one part of speech that we can chunk together is what's known as a noun phrase and this is essentially any phrase that contains a noun and other parts of speech that relate to that now and I'm going to write out here the chunk grammar for a popular form of noun phrase that we're gonna search through search for in our text and then we'll go ahead piece by piece and try to understand what is going on in this piece of chalk grammar okay I'm gonna zoom in here so we can see and before I dive into this I want to just look at some questions that people have someone's having this is what saying on my computer attribute our list object has no attribute opened so I would see that open dispelled with double P so maybe I look at your spelling there to see exactly what what are you're running into and yeah okay and yes I know it's hard sometimes to find room to learn and and your busy day whether you're in school you're in work or there's other things going on in life my advice to you in that case is just try and set aside maybe 10 minutes every day 30 minutes every day depending on what's available to you just some time to code jump on your computer log in to code kata me or just you know open up a code editor and get a little practice in that day consistent practice I think is the is the most useful thing when I'm trying to learn something new so you're not able to devote a huge chunk of time every day if you are able to do it a little bit of time and keep it as consistent as possible I think you'll you'll find a lot of success in learning whatever it is you're trying to learn okay and someone else does any question about the the download of the average perception tracker you should just be able to type in that exact piece of code and run it and it should download that data set for you and then you can come to it out after that okay looking now at our chunk grammar I've put in three different parts of speech here with a few different symbols from regular expressions so let's tackle it from left to right so once again we have the name of our chunk which I'm naming chunk and I'm actually gonna update this now to NP since I said we're gonna be looking for noun phrases noun phrases being these phrases that contain a noun and a few other parts of speech and the powder we're looking for is going to start with a determiner et and once again these are words like the and I'm putting a question mark next to the determiner and this means I'm looking for either 0 or 1 determiners I'm making it optional so this noun phrase might have a determiner and might not I don't care I'm willing to take either either form moving over to the right we then have this JJ JJ if you recall stands for adjective some saying after that determiner that we may or may not have I want to find an adjective right afterwards and I have a star after that adjective if you're familiar with regular expressions you'll know that the star is the clean star and this basically means that we want to match this preceding adjective 0 or more times so I can have one adjective in my noun phrase I can have 0 adjectives I can have 7 adjectives so if I have a whole string of adjectives describing my noun that's great I'll take them all if there's none it's ok then at the end of my noun phrase the one thing I need to have the one thing I want to have is a noun just one noun but it's required I need this noun to be in my noun phrase otherwise I don't have it I don't have a noun phrase so so this is the regular expression pattern that we're looking for an optional determiner followed by an adjective or no adjectives or five adjectives any number and then ending with a noun and this is the chunk grammar that I can use to go ahead and look through my sentences and pull out the noun phrases that I'm looking for so now that we've gone ahead and defined this chunk grammar we can go ahead and and get it ready for use on our sentences so what we're gonna do is we need to create a chunk parser to go ahead and do this for us and this is basically something that will go ahead and download that or sorry not download that we'll go ahead and look through a sentences and pull out the noun phrases so I'm going to say chunk parser is equal to and we're going to use another on lck tool if we you scroll up to the top called regex parser and what I want to do is I want to create a reg X parser object and give it an argument my chunk grammar so this is saying that our what we're going to use to look through each of our sentences I wanted to chunk out these noun phrases using the chunk grammar that we have defined right of both and then what I'm going to do is use this chunk parser to parse a piece of text so we will say chunk parser dot parse and we're using the chunk parsers parse method and what we will do is we will pass this chunk parser a sub chance from our mobile so I'm going to go ahead and use this same sentence that we use up here just so we can take a look at it and I'm gonna save this also a variable I'm gonna say chunked sentence it will chunk so strong sentence will be able to chunk parser dot parse this one sentence from our text I'm gonna go ahead and print this sentence chunk sentence and I'm also gonna comment out I'll leave I'll leave our previous sentence so we can take a look at it and I'm gonna click Save and let's see I'm getting a ern so let's see to do invalid syntax so I'm gonna go review what I did just see if I can find the error so I've defined my chunk grammar here and then I go ahead and I create my chunk parser object my records parser object with the grammar oh okay so I did not have a eco stumble right here so I'm saying that my chunk sentence is equal to chunk parser dot parse posx text at the next time so we'll go ahead and rerun our code and I'll scroll to the top so we have our original sentence here that is split up into the different parts of speech and then we scroll down we see our sentence now written in this new format and so the sentence reads there was and then we see this break NP no Garret at all and NP no seller so NP is indicating every place in our sentence where we are finding a noun phrase so it's gone ahead and looked at this sentence and said okay where are my patterns of determiner option determiner followed by adjective followed by noun and it pulls those out into individual chunks which are listed with his NP so you can see multiple end piece here so we have any building we have path and we have case it's another noun and the family is another noun phrase so we're finding all those noun phrases from within our sentence so now that we've done this on one sentence we can go ahead and do this on every single sentence from our novel and to do this once again we're just going to run a loop through our part of speech tag text so I'll say for sentence once again in POS tagged text and POS SEC text and I'm just going to call chunk parsers parse method once again on each sentence and I'll once again need to create a list to store all of our sentences that have been chunked for these noun phrases so I'm going to call it a MUX variable NP Chun sentences and it'll start off as an empty list and then as I go ahead and parse each sentence to pull out these chunks I'm going to append them to NP chunked sentences and then just to confirm that everything's been done I'm going to print one of these chunk sentences so I'm gonna say let's look at NP Chun sentences at index we'll do 222 I feel like that's gonna be a good sentence and I'm going to comment out my previous sentences or my previous print statements just so that we can focus on this one sentence so I'm going to go ahead and run this code oh and we're gonna see since I haven't run my quoted in a little bit sometimes it might reset your your workspace a little bit so I'm gonna do this download once again so I want to uncomment my download let's see running into this error again so I'm going to try and rerun my code hmm okay I'm going to try troubleshooting this to see what's happening I'm gonna refresh I'm gonna copy my code and refresh refreshing often helps solve issues when they arise so let's go ahead and rerun I know TK average perceptrons I'm gonna go ahead and we're gonna copy my code I just reset my project maybe that won't solve my problem I'm just gonna go ahead and we paste my code in and let's give this a shot troubleshooting code running into errors is a common thing that we run into while coding it's a part of the process so don't ever get too upset and you know don't ever get to worrying if you're if you're running into errors it's a totally natural part of the process so it seems like I'm not having any issues now with downloading that data but I do have a issue chunk parse is not defined so I'm missing the R in my chunk parser so I'm gonna go ahead add that are in and rerun my code Gregg expressor object is not callable okay let's see on line 39 so chunk parser so what I need to do is I need to use trunk parser stop parse method here's my error again so you can't just use that chunk parser you need to call its dot parse method so I'll say chunk parser dot parse and I'm gonna comment out my download so we don't see the popup happening and I'll save my code give it a run and there we go working through our errors as they arise thank you and the chat for helping me out with some of the spelling and we can now see that for the sentence which is a long one that we have these different noun phrases indicated by NP so once in noun phrase a while she would pass noun phrase a house and the people came out to look at her and bow low as she went by for noun phrase everyone knew she had been non phrase the means of destroying a noun phrase the wicked witch and setting them free from bondage noun phrase so we can see that our noun phrases are picking up these sequences of determiner adjective noun and sometimes it's picking up these items of importance so if you're familiar with the Wizard of Oz the Wicked Witch is a character who comes up often she gets crushed by the house at the beginning when Dorothy comes to Oz so we're seeing we're picking up these phrases that might have some importance Patrick I'm sorry for some spoiler spoiler warning it's for the warning for anyone who maybe hasn't read so you'll see there's any other questions in the chat is there a list of chichi where I can find the explanation of all the functions use so there is documentation that exists online regarding a lot of these functions which are mostly coming from NLT kay also we have a course on parsing with like your expressions here in code kata me where you explain a lot of the functions that were using here today ahead of a form is such an analysis but you can also always come back here to reference this video and see how we did it this work so now that we've gone ahead and chunked these noun phrases we want to go ahead and perform some sort of analysis on the chunks and one way that we can easily do this is with a frequency analysis and this analysis we'll go and look at each sentence that we've chunked from our text and count how how often these chunks appear and then we can see in a novel what are the most common noun phrase chunks so we'll go ahead and do that here today to get an idea of maybe what are the important topics in The Wizard of Oz and to do this I'm going to use a function that I have built myself that will go ahead and easily count these chunks for you and if you go to the top of the workspace you'll see that we are importing these functions for you they are included in another file that is given to you and if you click on the top left our file navigator you can see that there is a file called chunk counters and I'll open up that file and we can see the function written in here and so I'm not gonna go into indepth detail here today on the chat of how this function works since it gets a little a little entailed but basically what it's doing is it's looking through each of our chunk sentences and it's finding all of those n P chunks that we had and it's using a really useful tool in or package in Python the collections package to go ahead and count how often these chunks appear and so you can look at this function and yourself here in the workspace if it seems like something that people want to dig into further maybe at the end I can jump back in and you know explain more deeply but we're just going to use it here today in order to go ahead and get that frequency account for us and so what we're gonna use is this NP chunk counter function so I'm gonna go back to the bottom of my script and I'm going to create a new variable called most common and P chunks and I'm going to set it equal to and we're going to call this function and Peach on counter right so NP chunk counter and I'm going to give this phone my list of cheong sentences so what this will do is it will take as input this list of chunk sentences and go count all of the noun phrase chunks in them and return to me the 30 most common chunks ranked from most common to the least common out of the top 30 and I can go ahead and then print that most common chunks and I'll run this and we'll see most common chunks is not defined most common NP chunks so that's the name that I named my variable and I'll say most common and P chunks and we'll see here now that we have this list of different chunks that appear in the novel with their count so the most common NP chunk is the noun I so lots of characters are referring to themselves as I and the novel not too much inside there but then we get this list of Dorothy with 222 counts the Scarecrow with 213 counts the lion with 148 the tin so we're maybe missing part of this name here but alluding to the tin the Tin Man or the tin one men as he is referred to in this original of The Wonderful Wizard of Oz novel and we also see toto at 73 so we're getting an idea from this analysis of who are the important characters in our novel without reading the text ourselves clearly a lot of us coming into this have an understanding of you know who is important in The Wonderful Wizard of Oz we know the characters well but but but this is kind of giving us really quickly an insight into who are who are the main characters we also see the Wicked Witch come up the Emerald City the Emerald City seems to be a place of importance so now we're not only are getting an understanding of who is important to this text but a location of importance as well and and the nice thing about using the whole noun phrase rather than maybe just looking at the frequency of individual words as we pick up these these names essentially that are made up of multiple parts of speech so if we were just picking up which and the count of which in the novel it gives us less insight then the occurrence of the Wicked Witch which as we know is you know a character who is very prevalent so it's interesting to see what comes up in this list also a heart we know that on on this journey you know to do Wizard of Oz we have a character who may be looking for a heart they're looking for something so we get these ideas that maybe are important and our novel another thing that we can do that can give insight is not just looking at noun phrases but is looking at verb phrases and verb phrases give some insight into action that is occurring and our piece of text that we're analyzing and also sometimes shows how an author talks about the characters or how the author describes action occurring two characters I'm noticing gifts sometimes insight into like for example with the Harry Potter novels maybe a bias that the author is writing with or give us insight into maybe how they offer whether the author thinks about certain characters and so to go ahead and do this we can do what's called verb phrase chunking and this is essentially changing our chunk grammar to instead of finding noun phrases to finding these verb phrases and verb phrases similar to noun phrases will contain a verb that is describing an action that's occurring and then they will often just also include a noun phrase as a part of that verb phrase so let's go ahead and go back and add some new trunk grammar that will chunk verb phrases so I'm going to create a new variable called VP Chong grammar and I'm going to create this new piece of junk ramp trunk grammar I'm gonna say VP as the name of the chunk and then I'm gonna give within the curly braces this pattern of parts of speech tags that we are going to search for within our our texts and so I'll write out this pattern and then we'll walk through how how that pattern or where the powder is searching for so it's gonna start out with a verb VB and I'm going to add a little bit more regular expression syntax here so if you're you know don't get overwhelmed or don't get scared by it we'll talk it through and I'll explain what what it's doing so maybe dot star so we're gonna find that verb and then after the verb we're gonna copy this noun phrase over and then we're gonna end with a okay so let's dig into this verb phrase on grammar piece by piece so we're starting out with VP the name of the chunk that we're looking for so VP in this case will stand for verb phrase and then we are going to look for a verb and so verb is indicated by BB but I've also included this dot star here so if you are familiar with regular expressions the dot is the wild character wild card character and this could represent any any character that we'd like so as you saw before when we were looking at those different parts of speech tags for verbs we can have a past tense verb vbd or we can have a past part of all verb VPN or gerund vbg and so we want to try and catch all these fun kinds of verbs in our verb phrase and to give this flexibility we can use the power of regular expressions to catch all these different types of verbs which is why we're using this dot wildcard to say okay I want to find a look for VB for verbs and my Sciences but I might want there to be a potentially a D after the VB to represent a past tense verb or I might want there to be an N to represent I believe it is a verb past participle so we're using that dot as the wildcard and then I'm using the clean star to say okay I can I can match that dot I can find that extra letter in in what I'm looking to match or I don't need it I could just find a simple verb VB and so that's all that we're doing there then we're using the same piece of chunk grammar to find a noun phrase so we were looking for that optional determiner we're looking for any number of adjectives and we're looking for finally unknown but then at the end we're also saying okay we might also be looking for a adverb RB and once again we're using this wildcard to say okay if we go back we look at our B or B here our B is an adverb but we want to also try and catch the two other forms of adverb comparative and superlative and to do that we're going to use the wildcard dot and then we're going to say use this question mark to say you we can match that additional character we can get that comparative or the superlative adverb or we can just match the regular adverb RV and then we're adding one more optional quantifier right at the end to say okay we don't even need any adverbs as we've won all we care about is having a verb and then having a noun which is either this performing the action or the action is happening to them if you're not familiar with are your expressions once again don't get don't get scared by them it's one of those languages that at first sight can be a little overwhelming can be a little bit scary but as you work with them you get more control with them and you can see how powerful they can be and how useful they can be and so so if you are unfamiliar my recommendation is get some practice either using your course on our platform or going out there and just practicing on your own and in time you'll come to understand how to work with them how to use them too and they're really useful on any project you might be working on but definitely useful also here in syntax parsing and it can get a little complicated sometimes since we're within the carrots where we're kind of matching individual characters but then I'm also saying okay use this quantifier to match just one adverb which is like a whole whole word so it is a little more complex thanks for hanging in there and and hopefully maybe if it's not clicking for you immediately or right now on maybe a second pass or a second learn things can be a little bit clearer but now we've gone ahead and defined this verb phrase chunk grammar we can go ahead and once again chunk our text and this time instead of looking for noun phrases looking for for phrases so what we're gonna do is we're gonna just copy a lot of the similar code that we did before and this time we're gonna recreate a new chunk parser but we'll name it VB chunk parser and this time we'll create another reg X parser object but with our very own grammar instead of our regular Tron grammar and we're very similarly going to create a list called VP Chun senses that will hold all of our verb phrase Chun sentences and we're gonna then loop through each of the part of speech tag sentences and you know what I don't even need to do this loop again let's reuse the loop that I used before so there's no need to duplicate code so I'm gonna move actually that list above my for loop and I'm going to add within that same for loop that I wrote before I'm going to use my VB Chun parser that we initialized right up here at the top and say VB chunk parser and use its dot parse method dot parse and give dot parse as an argument the sentence that we are chunking and we want to go ahead and then append that sentence to our vp chunk sentence make sure all my parentheses line up make sure that all my underscores our other scores and our pluses and then I want to go ahead and then similarly let's count up our verb phrase chunk sciences and so this time instead of using the n piece on counter function that we have created for you we're gonna use the VP chunk counter function so same EP chunk counter and we're gonna give this function as an argument our VP chunk sentences and we'll assign this to a variable most common VP chunks so let's go ahead and just review everything that we just did here because we just did a lot of like steps over again so we went ahead and we defined a new chunk grammar our very own grammar which is going to find for us a pattern of a verb followed by a noun phrase followed by an optional adverb also we're doing that here on this line and then we're gonna go and create a verb phrase chunk parser another buy gekks parser object with our very own grammar did here then we're going and initializing an empty list that will hold our verb phrase chunk sentences and then we go ahead and go through each part of speech tag sentence in our text and we use that chunk parser to parse the sentence to pull out those verb phrase chunks and we save we saved those chunk sentences to our vp chunks sentences and then we're using the VP ton counter which is that function that we created for you that we're importing from our chunk counter file here and we're using it to find the top 30 most common verb phrase chunks and just so we can see the split in between I'm going to add one print statement right here this is going to say VP chunks and I'll add another print statement right above my NP chunks that says add P chunks just so we have some way to more clearly see in the console what is happening and I'm gonna go ahead and I just need to add one more print statement at the bottom to print the most common VP chunks I will run that code give it a second and VB chug grammar is not defined so I misspelled VP chunk grammar somewhere in my code mixing up my keys in my B's so I'm gonna change that to a P and we'll rerun our code here great and now if we look we'll see we have oh well I'm printing my VP chunk too early so I'm gonna move that down so I'll reset from there and then move it to right above my VP chunks and this will now separate for us my NP chunks and IVP chunks and while while we wait for to load George is asking what languages do you know so personally I learned to code originally in Java never really went too far in it and then really got my experience learning to code deeply in Python and which is what we're using here today using some common packages in Python for performing natural language processing and I'm here in in the US here in New York and code kata me HQ anyone else in the chat wants to share where they're from we're happy to see where everyone is maybe you're coming from around the world in the u.s. wherever you're from we're happy to have you here okay so we now have not only our MP chunks which we looked at before but if we scroll down we'll see we have our VB chunks and so here the the most common VP chunk of this form with a count of 33 times in our novel is said the Scarecrow said Dorothy asked Dorothy so we see once again characters who are relatively important in our novel maybe we have some insight into who's asking questions so Dorothy is asking lots of questions maybe she is confused about where she is or or what is happening to her if you are familiar with with the novel this might rain true for you or you know might make sense that Dorothy's asking lots of questions so reading a little bit of more insight now into not just who is important in the text but some descriptors about how this character is acting or what they're experiencing we can also see more Carter said the lion said the girl asked the Scarecrow said the Cowardly Lion so so we're just seeing more and more more discourse that's happening with the characters and we see another thing the Scarecrow let's see the Scarecrow answered the Scarecrow so that's one that's popped out to me answered the Scarecrow and so that's one of the most common verb phrase chunks that we're seeing in in the novel so you know it's not it's not a huge amount we see I see a times but if you are familiar with the novel the Scarecrow is sometimes looking for more knowledge he's kind of seeking to to have a brain and overseeing that the Scarecrow is answering questions so maybe this is giving us some sort of insight into how the author really thinks of the Scarecrow maybe maybe he does have more knowledge and where then we think so by looking at these verb phrases we can see maybe not just the action that's happening to characters in the novel but also maybe how the author thinks about the characters so this is the analysis that we're able to do one of the fun things I think to do with syntax parsing is to get creative I gave you the chunk grammar here for very common forms of chunking that people perform noun phrase chunking and verb phrase chunking but you're not limited to these patterns you can choose to put in a pattern okay excuse me any pattern of parts of speech tags that you like that you enjoy and everyone watching these are my amazing colleagues here at code Academy jumping into the picture it's my birthday today and they so graciously surprised me with these cupcakes which I'm super thankful for thank you all so much for for this I really appreciate it we are we are a team yes we're a team here at code Academy I don't work on my own so so all these people are here behind the scenes helping out thank you all so much yes okay I will take a cupcake I will bite into it in just a second you guys can see thank you everyone for all the happy birthday wishes and the chat I appreciate it before I dig into this lovely cupcake one thing I wanted to say was you can't get creative so you can change this chunk grammar that you have thank you guys change the Strunk grammar that you have listed to do any pattern of parts of speech that you'd like and you can go ahead and use any text that you'd like whether it's a novel that you've read maybe you keep your own journals and you want to analyze your own writing or get your text message data and I don't like your text messages you might be able to find some interesting things and to go ahead and do that if you go to the file navigator on the top left you can click that and you'll see there is a file called my text dot txt if you clicked that oh man just single click that you'll see that there is a empty text file here and you can put in any text that you like into this text file and then go back to your Python script here and change the name of that file that we're opening from The Wizard of Oz into my text dot txt and that will allow you to go ahead and run this analysis and any piece of tax that you'd like I'm so I really recommend you go ahead and do it you'll see that in the file navigator there are some other novels we've included in there for you so you can run those analyses but I say go get creative I think it's one of the best parts of coding as you get to kind of work off of what other people have and add on your own insights so building off the knowledge of others so go and put in whatever text you'd like find some interesting patterns of parts of speech that you want to search for and look at the frequencies of the of the chunks that appear and see what foot in stage you can find maybe you'll see that you you know talk about a certain topic more than you thought or maybe you see that you use certain kinds of adjectives or some kinds of verbs more often and maybe that gives some sort of insight into who you are or who your friends are if you're looking at something that your friend wrote so get creative if you do any of this please share it with us on Twitter you can feel free to add us at cook Adam e or hashtag code Academy we want to see your results we want to see what you find there's a lot out there to be analyzed there's a lot of mysteries to uncover lots of insights that can be found so go out there share with us your knowledge what you find and thanks so much for joining us here today I'm gonna dig into my cupcakes I don't know if I should do this one or this beautiful like unicorn one there's so many options so thank you all for joining we also have a a feedback form that we would love for you to fill out just so you can give us you know what you liked about the live stream what you would like to see in the future it's posted for you in the chat thanks to our wonderful Alex and yeah so that's it if there's any questions I you know feel free to reach out to us on Twitter or in the comments here and I really recommend you go check out all of our natural language processing content me and my colleague Mario we just put out two courses this week on this topic we discuss here today and also the bag of words language model there's also a great introduction to natural language processing of course that we have that Muriel also worked on that really gives you a highlevel overview of this whole field and what you can do with it it's amazing give it a watch and enjoy thank you so much for joining me here today thanks for the birthday wishes and enjoy the rest your day Cheers I'm gonna take one bite and then I'm gonna then I'll cut off mmm yummy very good