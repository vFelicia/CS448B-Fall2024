With timestamps:

00:00 - what is up guys welcome to the python ai
00:03 - tutorial
00:03 - 2021 for beginners all right so i'm
00:06 - aaron if you haven't seen me before i'm
00:07 - on the channel a little bit i'm not cozy
00:09 - um i look different than cozy but uh
00:11 - this is gonna be a crazy tutorial we're
00:13 - looking around on youtube a few months
00:14 - back and we didn't see that much ai
00:16 - stuff so i started dropping these cool
00:17 - tutorials um i was doing some face
00:19 - detection and everything and we kind of
00:20 - lumped all these projects together into
00:22 - one so that you guys can learn how to
00:24 - actually start your ai journey and take
00:26 - the first steps towards being a actual
00:28 - data scientist so this is very beginner
00:29 - friendly
00:30 - it's not too advanced if you've never
00:31 - coded in um anything related to
00:33 - artificial intelligence before that's
00:34 - totally okay this is built for you uh i
00:36 - explain
00:37 - everything in detail me and then there's
00:38 - some other instructors too i think nas
00:40 - and kazi and sunny also teach a little
00:42 - bit in here
00:42 - but i'm throughout the whole thing so i
00:44 - hope you like me because if you don't
00:45 - then
00:48 - um all right so we're gonna be building
00:50 - four amazing projects okay
00:52 - four of them the first one is gonna be
00:53 - the face detector app so this is very
00:55 - useful for things like instagram or
00:57 - snapchat where
00:58 - people you know that you have your phone
00:59 - and you're like hey you have like the
01:00 - the face filters so this is
01:02 - actually what they're using to be able
01:03 - to like detect your face
01:05 - and like superimpose something over so
01:07 - that's really cool the second project is
01:09 - actually going to be a self-driving car
01:10 - app um so it's gonna be like car
01:12 - detection and pedestrian detection in
01:15 - real time and this is the kind of stuff
01:16 - that tesla uses and
01:18 - companies like lyft and uber are
01:20 - actually starting to implement over time
01:22 - because
01:22 - computer vision is the way that they
01:24 - want to go forward with self-driving
01:25 - cars okay so elon musk has even said
01:27 - that um it's all it's all computer
01:28 - vision no
01:29 - no weird sensors and stuff it's just
01:30 - complete ai okay so we're gonna be doing
01:32 - that as well the last one is smile
01:34 - detection that's pretty cool
01:35 - because it can actually like distinguish
01:37 - uh two different expressions on your
01:38 - face and
01:39 - we're going to be detecting that in real
01:40 - time and the fourth project is we're
01:42 - actually going to be doing a intro to
01:44 - tensorflow which is
01:45 - a pretty much the most popular machine
01:47 - learning platform library framework
01:48 - whatever you want to call it out there
01:50 - that's available for python and a few
01:51 - other languages
01:52 - but we're going to be doing an intro to
01:53 - that pretty much building a our own
01:55 - neural network from scratch
01:56 - and actually having a cool image
01:58 - classification out
01:59 - that can actually like classify
02:01 - different types of images so if you're
02:02 - excited for this please let us know in
02:03 - the comments below
02:04 - yeah guys and that's really it so i
02:06 - hand-picked these four projects for you
02:08 - because i feel like they're
02:09 - just really like a good bite-sized
02:10 - project for beginner to go from
02:12 - complete beginner to maybe like beginner
02:14 - intermediate um in ai
02:15 - and really get you started okay other
02:17 - than that you guys i hope you enjoyed
02:18 - the video but if you're interested
02:20 - in actually excelling your skills on
02:22 - python and actually making a real income
02:24 - from it a real living then
02:25 - um please click on the link below to
02:27 - check out our course profitwood python
02:29 - which does just that it pretty much
02:31 - assumes you're a beginner and takes you
02:32 - through the complete roadmap from
02:34 - beginner to actually making an income
02:35 - from beginning to end using python and
02:38 - to actually become a full-fledged python
02:40 - developer all right you guys i know
02:41 - we've been sleeping on python for a long
02:42 - time we've been doing all the javascript
02:44 - stuff you know
02:44 - this might have been plugged in by the
02:46 - way but we've we've been doing
02:48 - javascript react merge stack all that
02:50 - stuff but don't sleep on python because
02:52 - python is huge okay from the back end
02:54 - pretty much everything uses python
02:55 - python's everywhere so you really need
02:57 - to know python as well
02:58 - make sure you know your python so other
02:59 - than that i hope you guys are excited
03:01 - let's get started
03:13 - [Music]
03:17 - bernap what's up you guys guys for the
03:19 - python tutorial and by the way guys i
03:21 - want to kind of
03:21 - show you what we're going to be working
03:23 - on today look at the screen yo aaron
03:25 - what are we looking at right now uh this
03:29 - is uh robert downey jr's
03:31 - glorious face with his uh going to be
03:33 - learning
03:34 - real time face detection with
03:37 - python if you are excited please
03:40 - drop it in the comments below and let us
03:42 - know that you are excited about this
03:45 - this took us forever to put together i
03:47 - apologize we were late today to the
03:49 - stream
03:49 - we're 45 minutes behind but get a lot of
03:53 - things set up for you guys and make sure
03:55 - that you guys get a great experience
03:58 - now that we're here guys take a look at
04:00 - this here is aaron's face
04:02 - and it is actually what's up right now
04:05 - right so look at that he can move around
04:09 - right it detects his face uh with a
04:12 - pretty high level of confidence
04:14 - and this is all real time you guys this
04:16 - is with python and today the biggest
04:18 - thing we want to do for you is show you
04:20 - how you can do this yourself with a few
04:22 - lines of code
04:23 - and we want to make it as simple as
04:25 - possible because
04:27 - um there's so many different places to
04:30 - show you how to do this but
04:31 - they don't make it simple right aaron
04:36 - yeah a lot of the other tutorials like
04:38 - they
04:39 - added a bunch of unnecessary code to get
04:41 - up and working like this is actually a
04:42 - pretty small app
04:43 - to be honest there's not that much code
04:45 - but there's a lot going on behind the
04:47 - scenes and
04:48 - we're gonna build it first because
04:49 - that's the fun part we're gonna get it
04:50 - all going you guys can have it on your
04:51 - own computer running you can detect your
04:53 - own face and whatever other embarrassing
04:55 - videos you have of yourself
04:56 - um but then i'm also going to explain it
04:59 - at the end of actually what's going on
05:02 - instead of just like a bunch of
05:03 - like code in your face i'm going to
05:04 - explain in layman's terms so it's going
05:06 - to be interesting a different approach
05:08 - than what you've probably seen before
05:09 - but
05:09 - it's going to be good you guys excited
05:12 - awesome okay beautiful we are
05:16 - pumped so i think at this point um
05:19 - what should we take a look at now aaron
05:21 - should we go ahead and look at like how
05:23 - the algorithm works
05:25 - yeah so oh first of all here's the
05:27 - robert downey jr
05:28 - photo i i caught from the internet just
05:30 - to prove that it's uh
05:32 - what didn't already have the green
05:33 - square yeah but yeah i have this little
05:35 - presentation here
05:40 - [Music]
05:43 - okay so let's just start this up first
05:45 - just to give you a little debriefing
05:46 - before you jump into the code you guys
05:48 - yeah so first thing here
05:51 - uh in a super simplified way but just to
05:53 - give everybody context because i know a
05:55 - lot of you guys are beginners
05:56 - um we are all beginners ones me quasi
05:58 - all of us yeah and i just want to give
06:00 - you a
06:00 - a short step-by-step thing of how like
06:02 - face detection actually works with
06:04 - python
06:04 - all right so first step um the first
06:08 - thing you want to do
06:09 - is of course this is going to be a
06:10 - machine learning thing that's the
06:13 - really the only way or the most popular
06:15 - way to do this kind of thing is you have
06:16 - to train it on what a face actually is
06:19 - and then from there then you're able to
06:20 - classify faces down the road
06:22 - so step one get a crapload of faces
06:24 - clear
06:25 - good yeah and from there um
06:29 - we actually um don't need it to be
06:32 - colored so step two we're just gonna
06:34 - just real quick go back to step one i
06:36 - wanna highlight what you're saying
06:37 - because you're saying something really
06:38 - awesome there and i wanna make sure
06:40 - everybody truly really understands this
06:42 - you guys so
06:43 - this is awesome how aaron is putting
06:45 - this together for you take a look at
06:46 - that like the
06:47 - first thing we do is like we give our
06:50 - algebra like
06:51 - we want to give it tons of faces so it
06:53 - knows how to detect a face
06:55 - so we're just giving a ton of faces you
06:57 - can see george w bush in the middle
06:59 - and then you can see like their
07:00 - thousands of faces around it
07:02 - so that's our first thing that we're
07:04 - doing get all of the faces right
07:06 - um so what are we doing then on step two
07:09 - so after you have all the faces uh we
07:11 - actually don't need to be color
07:13 - uh the reason being for this is because
07:15 - what defines a face
07:17 - isn't so much the color it's more so the
07:20 - composition
07:20 - of like this set of pixels like okay
07:23 - there's two eyes and nose
07:24 - and then there's like some reddish or
07:26 - like dark color or lighter colored lips
07:28 - depending on maybe some teeth or
07:29 - something like that
07:30 - um so we get rid of the colors because
07:31 - it it it um
07:33 - hurts the the performance of the
07:35 - algorithm i believe
07:36 - but the way opencv does it which we're
07:38 - going to be using it opencv if you if
07:40 - you don't know what opencv is
07:42 - opencv is an open source computer vision
07:45 - library um that some people put together
07:48 - i don't know who put it together but
07:49 - it's called opencv we're going to be
07:50 - using that
07:51 - and they have a lot of cool computer
07:52 - vision functions that we can use to
07:54 - build our app
07:55 - so the first step we're going to do is
07:56 - we're going to turn everything black and
07:57 - white all of those
08:00 - faces that we had at the beginning here
08:02 - the very first step
08:04 - and we turned them black and white
08:05 - because the computer
08:07 - the only way that algorithm knows how to
08:09 - look at a face is
08:10 - in black and white so you want to give
08:11 - it that it's not going to be looking at
08:13 - it in color
08:14 - so we turn it into what we call
08:15 - grayscale
08:18 - grayscale that's the word yeah and then
08:20 - from here once we have all of our gray
08:22 - uh our black and white images our face
08:24 - images we can
08:26 - pump those into the algorithm and it
08:28 - will eventually learn how to
08:30 - detect faces so as you can see here it's
08:32 - detecting all these different faces here
08:33 - whether you have glasses open mouth
08:35 - frowning
08:36 - smiling eyes closed hair i mean the hair
08:39 - is all similar here but you get the idea
08:40 - if you train it on enough
08:41 - data it can it can recognize babies
08:44 - females
08:45 - um males uh even monkeys so
08:49 - uh that's that's pretty much the
08:50 - oversimplified
08:52 - three-step thing you just get a bunch of
08:53 - faces you change them to black and white
08:55 - and then you train it and then you run
08:57 - your class your face classification
09:00 - um code and it will find all the faces
09:02 - in your image
09:04 - awesome so that's a pretty simple
09:05 - three-step formula right so step one
09:07 - just go to step one real quick step one
09:10 - get a crapload of faces step two
09:12 - turn them black and white step three
09:14 - train the algorithm that's it guys it's
09:16 - just
09:17 - simple three steps okay hopefully you
09:19 - guys understand that so
09:20 - again get lots of faces two turn in
09:24 - black and white and then
09:25 - three just train the freaking algorithm
09:28 - and now you're good to go now it's gonna
09:29 - start detecting everything so like to
09:30 - actually
09:31 - use it you guys is stupid simple it's
09:33 - like ten lines of code
09:35 - and then boom your webcam is working and
09:36 - everything is working so like step one
09:38 - get away from the fear of like what it
09:41 - means to actually use these types of
09:43 - algorithms
09:44 - first use them play with them and then
09:46 - go deeper into the complexity and
09:48 - everything so you can start to
09:49 - understand
09:50 - and make your own models
09:53 - wow we have 664 people live that is
09:55 - awesome what's
09:56 - up that is awesome welcome you guys
09:59 - anybody just coming in we're making a
10:00 - face detector if you came in a little
10:02 - bit late
10:02 - but yeah so um with that said
10:06 - this simple three-step process let's
10:08 - just jump straight into the code you
10:09 - guys okay let me give one more quick
10:10 - demo in case there's anybody
10:12 - um you know aaron and what i was
10:14 - actually even thinking of maybe you
10:15 - could have code on the left hand side so
10:17 - you could actually like make your code
10:19 - like on the left hand side on the right
10:20 - hand side you could have the webcam open
10:22 - the entire time
10:24 - ah you see what i'm saying yeah the
10:27 - thing is the way this is implemented
10:28 - oh yeah yeah it's kind of you have to
10:30 - keep running it you have to keep running
10:31 - it yeah that's okay that's okay no
10:32 - worries
10:33 - let's keep going so we'll just keep it
10:35 - this way is the
10:36 - code is big enough for you guys to see
10:37 - right i think that's that's big
10:39 - and by the way you guys if you are
10:41 - enjoying this video erin open up your
10:43 - face detection again just so we can see
10:44 - it
10:47 - unless you comment so guys if you guys
10:49 - are enjoying this
10:50 - and if you think this is cool i think
10:52 - this is so freaking cool that we're
10:54 - doing this with python right now
10:56 - make sure to hit that like button
10:59 - it's free it doesn't cost you anything
11:01 - it helps us get the video out
11:03 - to so many places so please go down
11:05 - below
11:06 - and like smash that like button
11:07 - subscribe to the channel if you want to
11:09 - learn from aaron myself
11:11 - and all of us that we just give you so
11:12 - much value so please please please
11:14 - hit that like button and let's keep it
11:16 - rolling
11:20 - by the way puge says i read this comment
11:22 - there and he says aaron taught me how to
11:23 - code in python today i finally completed
11:25 - my titanic data set
11:27 - thank you titanic dataset
11:31 - titanic probably something you like he
11:33 - probably learned from you and then went
11:35 - and like
11:35 - applied it on something else
11:39 - right on i don't know what that means
11:41 - but it sounds like something i wouldn't
11:42 - understand so keep that
11:43 - that is awesome all right you guys
11:46 - there's
11:47 - 826 people live 826 what's up you guys
11:51 - let me okay let me just keep this
11:52 - running it seems like people
11:54 - keep flooding in where is the here we go
11:56 - you guys
11:56 - [Music]
12:04 - okay we're this is what we're building
12:06 - you guys let's just jump into the code i
12:07 - think we're almost at a thousand so
12:09 - let's just get started all right so let
12:11 - me comment out all the code that is
12:13 - pre-existing here
12:14 - um so we can start from scratch for all
12:17 - you guys
12:18 - and actually just
12:22 - all of it okay so the very first thing
12:25 - that we're gonna have to do
12:27 - is obviously install opencv so if you're
12:29 - following along with me
12:31 - then please install opencv and you can
12:33 - do that
12:34 - with the command wait i gotta quit out
12:37 - of this one second
12:39 - it should be uh pip if you're on linux
12:42 - or unix
12:42 - system do me a favor a few things aaron
12:45 - do me a favor
12:46 - take your terminal put in the middle one
12:48 - and then also hit command plus multiple
12:50 - times hit command plus
12:52 - just to zoom in
12:55 - and make your screen smaller and then
12:57 - it's easier to see for everybody
12:59 - terrible habit is that that's big enough
13:01 - right that's really good that's really
13:03 - good it's easier to see for everybody
13:05 - all right you guys so the first thing
13:07 - you wanna gonna
13:08 - um gonna want to run is pip install
13:12 - python dash open cv
13:15 - okay i've already installed it uh oh
13:17 - also maybe add headless here
13:19 - if you're getting errors this is
13:21 - optional but like if you're getting
13:22 - weird errors try running this as well
13:24 - and it might work but this dash headless
13:26 - is optional
13:27 - but point is install opencv that's the
13:29 - very first step
13:30 - um honestly there's no way i can help
13:32 - you install it i forget there's an
13:34 - endless amount of errors you could get
13:35 - but you're going to have probably google
13:37 - it and look on opencv so like if you are
13:39 - getting issues let me just do that let's
13:41 - see opencv
13:42 - installing issues or something i'll just
13:44 - give like a brief thing
13:46 - um find the stack overflow here opencv
13:49 - installation problems
13:50 - you probably come into here and there's
13:52 - no answers on this one
13:54 - but uh i mean point is yeah i just
13:56 - installed opencv
13:58 - and hopefully that that command should
13:59 - work for you the one that we were just
14:01 - looking at here
14:02 - and um once that's installed then you're
14:04 - pretty much ready to go
14:06 - all right so from here you can come into
14:08 - our code and the first thing we're going
14:10 - to want to do
14:10 - is simply well first
14:13 - you're going to want to make a face
14:14 - detector.pi file of course
14:16 - so start with making your first uh
14:19 - python file phase detector there
14:21 - and just to make sure that it's running
14:22 - let's just do this
14:25 - this is a little big shot just a real
14:27 - quick shout out to pratik
14:29 - uh he says today i had an interview and
14:31 - i showed yesterday's project of amazon
14:33 - price detector and i got selected
14:36 - holy crap that is amazing guys
14:39 - go team jacob yo we literally built the
14:43 - price detector
14:44 - exactly we built the price detector
14:46 - yesterday you guys with jacob so that is
14:48 - huge
14:51 - that is awesome all right let's keep it
14:53 - going
14:54 - yeah that is so sick all right you guys
14:58 - so once uh you have your python file
15:01 - created face detector.pi then let's just
15:04 - make sure it's working correctly okay so
15:06 - the first thing you're going to want to
15:07 - do
15:07 - is just run pi well make sure you're in
15:10 - the right directory so you want to make
15:11 - sure that the
15:12 - face detector.pi file is in my um
15:15 - in in the in the same directory and then
15:17 - from there then you can just run python
15:20 - and run face detector.pi just like that
15:24 - okay
15:25 - nice and then hit enter and as you can
15:27 - see it says code completed here which is
15:29 - the print statement so everything is
15:30 - hooked up and working correctly that's
15:31 - the
15:32 - very first step and i like personally
15:34 - when i'm coding i like to keep this at
15:35 - the end of my program because then i
15:37 - know
15:37 - that if this shows up everything in my
15:39 - code ran and no errors popped up so i
15:41 - leave this at the end so that's just
15:42 - kind of an errand convention that you
15:43 - can
15:44 - adopt if you like but um now that we
15:47 - have opencv installed the first thing
15:48 - you
15:49 - you're going to want to do is actually
15:50 - import that library so that library is
15:52 - called cv2
15:54 - this is i think the 2 just means version
15:56 - 2. it's been cb2 for a long time but
15:58 - just it's called cb2 you have no choice
16:00 - just type it in and from here go again
16:03 - and then let's see if we get any errors
16:06 - run the same command and as you can see
16:08 - it says code completed which means it
16:10 - ran this in imported library without any
16:12 - issues because it reached this line
16:14 - so from here now we can actually start
16:16 - coding with open
16:17 - cv so coming back down here
16:21 - um one thing you're gonna have to do is
16:24 - here
16:24 - actually let me let me go here so opencv
16:27 - like i mentioned earlier is a open
16:28 - source computer vision library
16:30 - provided by some people um
16:33 - and they provide a lot of pre-existing
16:36 - code of course it's a library so they
16:38 - have code that we can use that we're
16:39 - going to be using that we just imported
16:41 - but they also have some data files for
16:42 - us so what this is here
16:44 - is actually pre-trained data so
16:48 - if you look here there's uh what okay so
16:51 - har cascade is an algorithm we'll get
16:52 - into that a little bit but just ignore
16:54 - this big scary word
16:55 - heart cascade and then it might say this
16:57 - is the one we're gonna be using the
16:59 - front
16:59 - frontal face default because this uh
17:01 - they provided us with
17:03 - a bunch of data and they actually
17:05 - trained um
17:06 - this on a bunch of face images like the
17:08 - ones i showed you in the presentation
17:09 - before
17:10 - like this but they're basically like
17:13 - that yeah so that data is actually
17:15 - trained on tons and tons of faces like
17:18 - frontal faces right just like this one
17:20 - hundreds yeah like all of these
17:21 - like all ages all that kind of stuff but
17:23 - frontals you know so there's no like
17:25 - blockages there's no side faces
17:27 - yep um none of that just just front
17:28 - faces
17:30 - yeah um so from there they they provide
17:32 - all that so what you're gonna have to do
17:33 - is actually download this so if you can
17:35 - just go to this url
17:37 - okay github slash opencv slash opencv
17:40 - slash tree blah blah blah
17:41 - and just go to the default front this
17:44 - one frontal face.default.exe
17:46 - and download it it'll be right here and
17:49 - it's just a big xml file and all this is
17:51 - this is basically a machine learning um
17:55 - machine and when you pump an image
17:57 - through all of these all of these
17:59 - numbers
18:00 - it'll tell us and find if there's a face
18:02 - in the image or not and as you can see
18:03 - this goes on forever
18:05 - so this is actually what was already
18:06 - trained on like thousands of images
18:08 - so um you want to download this because
18:10 - openc provides it for you training it
18:12 - yourself is
18:13 - a gargantuan task of its own so we're
18:16 - not doing that in this video we're just
18:17 - using what they're providing for us
18:19 - maybe we can do that in a future video
18:20 - but point is download this from this url
18:23 - and then we can continue on from there
18:26 - so any comments quasi awesome no i love
18:29 - it uh basically
18:30 - guys to summarize it all we did so far
18:33 - is literally just downloaded that file
18:35 - that's
18:36 - it um so it's really simple just
18:39 - hard cascade frontal faces i think
18:41 - default or whatever and then download it
18:43 - put it in the same directory that you're
18:45 - in
18:46 - and that's all we've really done so far
18:49 - and i have mine right here see right
18:51 - parallel to here
18:52 - along with my uh robert downey junior
18:56 - photos and stuff
18:58 - oops not not this one so once you have
19:01 - this installed then we can go
19:03 - and import it into our app so the first
19:06 - thing
19:07 - is uh well first first of all i like i
19:09 - called my
19:10 - variable trained face data because
19:12 - that's what the heck it is
19:14 - and um this is the name of the file we
19:15 - just downloaded an xml file i'd actually
19:17 - don't
19:18 - i think i forgot what xml stands for but
19:20 - it just looks like it looks like this
19:21 - with all these tags
19:23 - from here you're gonna want to call the
19:25 - opencv
19:26 - library and call this function to make a
19:30 - classifier so all the classifier is it's
19:32 - a fancy word
19:33 - for um detectors so uh detector so we're
19:37 - making a face detector app
19:39 - a classifier can classify something as a
19:41 - face that's all really is and then
19:42 - cascade is again the algorithm the hard
19:44 - cascade i was talking about
19:45 - uh we'll get into that later just ignore
19:47 - the scary word
19:48 - but what we're going to do is we're just
19:50 - going to pass in that training data and
19:51 - create a classifier for this
19:53 - and since this is the front-facing
19:56 - training data then this classifier
19:58 - now will be able to detect front uh
20:01 - front
20:01 - frontward-facing faces and that's what
20:04 - we have here
20:05 - okay so as you can see i put a comment
20:07 - here to load some pre-trained data on
20:09 - face
20:09 - frontals from opencv
20:12 - from there we can continue to
20:16 - um choose an image or a video stream
20:19 - or our webcam and then we can actually
20:22 - pass that
20:22 - um into this classifier and be able to
20:26 - find
20:26 - the location of faces and then we can
20:28 - put the rectangle around it and you have
20:29 - to like draw the rectangle on the image
20:31 - or the video and
20:31 - we'll get to all of that but moving on
20:34 - the first thing we're going to do let's
20:36 - just do the robert downey jr
20:38 - uh photo i'm just going to copy and
20:39 - paste it just so i have to type it out
20:41 - but i'll go slowly so you guys can type
20:42 - it out yourself so
20:45 - uh the thing we're going to want to do
20:46 - is choose an image
20:48 - to detect the faces in so mine is the
20:52 - robert downey jr photo so the way you do
20:54 - this
20:54 - is you want to call the image read
20:56 - function from opencv
20:58 - so very sim very simple the image you're
21:00 - going to read it in
21:01 - and it's going to be um the
21:04 - the photo that i just had of robert
21:06 - downey so that should be
21:08 - this one okay so it's on my desktop here
21:12 - and once you have it over there somebody
21:14 - just donated to us bro
21:16 - that is awesome uh really really yeah
21:19 - hashtag yo garage i can buy lunch today
21:22 - yeah finally thank you appreciate that
21:25 - uh so that's awesome thank you so much
21:27 - for that it's like please make a uber or
21:29 - ola clone app using react native so we
21:32 - might not be using react native but
21:34 - we're going to be making a bunch of
21:35 - clones with
21:36 - react so uber is not on our list yet we
21:39 - might think about putting it on our list
21:41 - we are definitely going to be doing tick
21:42 - tock
21:43 - and i think spotify and stuff like that
21:45 - and then uber we might do it at some
21:47 - point as well
21:49 - i'm not sure what ola is yeah i'm not
21:51 - sure
21:52 - i'll look that up later but anyways
21:56 - this is how you import an image into
21:58 - opencv okay so this is actually
22:00 - i mean an image is just an array like a
22:02 - big matrix of a bunch of numbers you
22:04 - know pixels are just numbers
22:05 - so really what this is you're just
22:07 - reading the image into a big
22:09 - like double um two-dimensional array so
22:12 - a big image a bunch of numbers and bits
22:14 - from there um now we can actually um
22:18 - change it to grayscale so again if i let
22:21 - me see if i can actually
22:22 - show this yeah so let's let's just go
22:24 - one step before
22:26 - xml file link so maybe you want to just
22:28 - go to that github
22:30 - real quick and maybe just show the url
22:33 - and then they can pause it on there so
22:35 - just go there and show the url
22:37 - so you guys can pause it here and type
22:38 - that in
22:40 - um and then go to it okay
22:43 - maybe we should put in the description
22:44 - or something that might help yeah we'll
22:46 - put in the description too
22:47 - at some point for sure after okay here
22:50 - and make sure you're downloading the
22:53 - frontal face default this one okay
22:55 - there's also cat faces and stuff i mean
22:57 - you could actually use all these other
22:58 - ones like lower body upper body
23:00 - the just the profile of the face you can
23:02 - detect smile all this stuff cool
23:04 - yeah just eyes um yeah what's cool about
23:06 - this
23:07 - is you can detect anything pretty much
23:08 - you could you could detect coca-cola
23:10 - cans and stuff but
23:11 - we're just doing faces like the same
23:12 - algorithm works for anything like it's
23:14 - very generic and robust
23:19 - i don't know what that is oh probably
23:20 - like a car license probably a license
23:23 - plate
23:23 - right yeah like for russian cars yep but
23:26 - anyways yep so here again
23:28 - url download this one okay
23:32 - and once you have that then we can
23:34 - continue on so let me just show
23:37 - uh this this image first so i imported
23:40 - the robert downey jr
23:42 - image and um so image read we read it in
23:45 - and then to show this image there's
23:47 - another opencv
23:49 - function called image show i am show and
23:52 - um
23:52 - this string here is just going to be the
23:53 - name of the window that pops up and then
23:55 - this is the image you want to display
23:57 - so let's just save this and run this to
23:58 - show you that the robert downey jr stuff
24:00 - is going to pop up
24:02 - and what is wrong
24:05 - oh i forgot you you also need this thing
24:11 - uh let me just make sure it works first
24:12 - before i because the weight key
24:13 - basically waits
24:14 - for it yep so the weight key you it
24:17 - because otherwise it just closes
24:18 - instantly
24:19 - go ahead yeah so what this does is it
24:23 - actually pauses the execution of your
24:25 - code
24:26 - so it will show the image and then it
24:28 - will continue on to the end of the
24:29 - program and it'll
24:30 - it'll terminate the program because they
24:31 - got they got to the last line here and
24:33 - it's like okay i'm done
24:34 - so it'll open this for a split second
24:36 - you won't even see it then it'll close
24:37 - it immediately
24:38 - so what this means is this will wait
24:40 - until a key is pressed
24:42 - so you can press any key to continue in
24:43 - the execution so it gets here and it
24:45 - waits
24:46 - and it keeps this open so that you can
24:49 - um
24:49 - view the image that does that that's
24:51 - just the way opencv is implemented
24:54 - um i mean if you like it or hate it it's
24:56 - just how it is
24:57 - but once you have that then you can run
25:00 - the program
25:01 - and of course robert downey jr pops up
25:03 - here in color just like i said okay
25:05 - and of course you can hit any any button
25:07 - on the keyboard i just hit spacebar and
25:08 - it just closes it and then it's of
25:10 - course it says code completed and i'm
25:11 - back to the terminal
25:12 - so i'll show you step by step as we're
25:15 - going
25:16 - uh what it looks like so we'll just keep
25:18 - these two together
25:20 - okay at the very bottom and okay so we
25:23 - have a robert downey jr image
25:24 - in here next we are going to like we
25:26 - said in the presentation
25:28 - we got to make it black and white
25:29 - because the algorithm that we're going
25:31 - to be using the
25:32 - the har cascade algorithm the way it's
25:34 - implemented only takes grayscale images
25:36 - because
25:37 - we can still identify faces in grayscale
25:39 - we don't need the color
25:40 - i mean you can do color but that's a
25:42 - much more complicated like if you want
25:43 - to classify like
25:44 - skin color or race or even like actually
25:46 - identify people that's even more
25:48 - advanced that's what facebook does you
25:49 - know how you can like tag your friends
25:50 - it automatically knows their face
25:52 - um that's way more you need way more
25:54 - training of like one person to do that
25:56 - so we're not going to be doing that here
25:58 - but i just want to mention that
26:01 - so aaron one real quick uh side note
26:04 - uh what can they do if they want to
26:06 - learn not only these types of skills but
26:09 - also learn how to make an income with
26:11 - these skills where can they go
26:13 - uh yeah so if you like coding in python
26:16 - and you want to learn how to actually
26:20 - make a living from it so if you want to
26:21 - start coding and landing clients or
26:23 - land a job and just like get your skills
26:25 - and your confidence up and have projects
26:26 - on our portfolio and all those things
26:28 - and really just do this for a living
26:30 - then we have a course
26:32 - called profit python formerly a
26:33 - profitable programmer so if you hear
26:35 - either name or
26:36 - either name they're the same and the
26:37 - link is in the description if you want
26:39 - to join that
26:39 - yep um we can actually and i'm showing
26:42 - it on the screen
26:43 - actually so i don't know if you you can
26:45 - probably not see my screen but yeah i'm
26:46 - showing it on the screen so guys
26:49 - the program is called profit with python
26:51 - so in this program we show you all of
26:52 - these things that you're going to be
26:53 - learning today
26:55 - you know whether it's like detecting
26:56 - faces or building e-commerce stores
27:00 - or any kind of project that you can take
27:03 - from upwork web scraping as
27:04 - advanced as you can think it and then we
27:07 - show you how to actually land those
27:09 - clients
27:09 - our biggest one of the biggest things we
27:11 - focus on is like how can you actually
27:13 - earn a killing with python that's huge
27:15 - for us
27:16 - we have dedicated python success coaches
27:19 - and really one of the most important
27:21 - things in this program
27:22 - is the fact that you get weekly live
27:24 - python training calls now
27:26 - aaron like what do you think is a
27:28 - benefit um of those like
27:30 - live calls uh you know for for the
27:33 - python like live training calls
27:36 - um live training calls i mean
27:39 - humans learn live that's how you've been
27:41 - learning all throughout history so
27:42 - having somebody there to give you
27:43 - real-time
27:44 - feedback and answer your questions right
27:45 - then and there is like evolutionarily
27:48 - the
27:48 - that's even a word the best way to learn
27:50 - um so it's pretty much like
27:52 - you're in a college course you know but
27:53 - i mean but a cool one because you have a
27:55 - cool teacher and
27:56 - you can show up and do whatever you want
27:57 - but there's live calls where you build
27:59 - apps together
28:00 - and you can ask all your questions yeah
28:03 - directly to a python expert
28:04 - you guys are literally building traffic
28:06 - projects every week so like jacob
28:08 - is building an e-commerce store like you
28:10 - guys think we're building live projects
28:12 - on our youtube wait till you get inside
28:13 - of the program because there
28:15 - the conversation turns over to you and
28:17 - you are the one building all these
28:19 - projects
28:20 - and then we're giving you personal video
28:22 - feedback
28:23 - on each of your projects that you build
28:25 - and we get tons and tons of submissions
28:28 - from people like even right now
28:30 - you know if i show you guys here like we
28:32 - have tons of projects that people are
28:34 - sending in that they're building with
28:36 - python that they're building like people
28:38 - are building covet trackers and all
28:40 - kinds of stuff so here's an example of a
28:42 - project
28:43 - uh boom here's something that was built
28:46 - and
28:46 - i can switch it up into any different
28:48 - country and you can see that it pulls
28:50 - the queries
28:51 - it shows all this data and people are
28:53 - using these skills to freelance
28:54 - so if you guys want to learn these
28:56 - skills you want to you want to be able
28:58 - to make an income with python
28:59 - then definitely go and check out in the
29:02 - description below the program is called
29:04 - profit with python
29:06 - and we would love to see you inside of
29:07 - there yeah
29:09 - so because coding is fun you know
29:10 - building projects like this this is all
29:12 - fun but i mean if it's fun then it's
29:13 - just a hobby if you can make a living
29:15 - from it
29:16 - uh i mean i say why not because then you
29:18 - can have your fun and make a living from
29:19 - it and do it more
29:20 - so that's why we provide um these
29:22 - courses we love helping people like do
29:24 - what they love
29:25 - be that being coding and just live the
29:27 - lifestyle they want instead of you know
29:29 - slaving away at a job they hate whether
29:30 - it be like retail or fast food or
29:32 - whatever it is
29:33 - yeah so that's worth mentioning that um
29:35 - optional for you but definitely there we
29:37 - would highly recommend it
29:38 - and just check it out
29:40 - [Music]
29:47 - let me just keep going for the for the
29:50 - viewers
29:50 - yep where was i i was
29:54 - i imported the image so like i said we
29:56 - need to make it grayscale
29:57 - because the algorithm requires to be
30:00 - grayscale because it's just easier to
30:02 - only deal with one number on each pixel
30:04 - the the color
30:06 - there's it's like on a range from like
30:07 - black to white instead of like our
30:09 - there's no rgb in each pixel it's just
30:10 - one
30:11 - one number instead of three numbers
30:13 - across red green blue channels
30:15 - so we got to change it to grayscale so
30:17 - of course opencv allows us
30:19 - to do that too and let me just go grab
30:21 - that code down here
30:23 - and i will just paste it and you guys
30:25 - can type it out yourself as well
30:29 - so as i as i said here in the comment
30:31 - you must convert it to grayscale
30:32 - and so i just called the variable
30:35 - grayscaled image
30:36 - because it's the same image but
30:38 - grayscale
30:39 - and the function that you want to call
30:41 - is convert color
30:43 - so opencv dot convert color and then you
30:46 - give it the image you want is the first
30:47 - argument
30:48 - and then the second one is what kind of
30:50 - conversion you want to do because this
30:51 - function
30:51 - actually you can do a lot of different
30:53 - things why don't we pull the
30:54 - documentation i'll just show you a
30:56 - little bit really quick
30:57 - convert color so open cv documentation
31:02 - and let's just go here not this one
31:06 - uh this one should look ugly
31:10 - yeah it is i got out of there quick we
31:13 - just lost 600 people in 10 milliseconds
31:17 - um where is it
31:21 - probably i guess there's a bunch
31:25 - uh gray basics thresholding options
31:28 - is this the right documentation open cv
31:31 - two-point
31:33 - okay once here we go okay cb2.com color
31:36 - awesome yeah so here uh convert color
31:40 - you have a bunch
31:40 - so the first one is the source image
31:42 - which is the robert downey jr image that
31:44 - we had first
31:45 - and then there's a bunch of different
31:46 - things you can do so for us we're going
31:47 - to be using
31:48 - uh grayscale but you can also change
31:50 - like you can change the gray you could
31:52 - change color to
31:53 - just the red channel or just a blue
31:54 - channel or you could like dim the whole
31:56 - thing
31:57 - pretty much you can convert the image to
31:59 - whatever you want
32:00 - there's a bunch of stuff in here to
32:01 - definitely check out documentation but
32:03 - just wanted to show you guys that
32:04 - because this is actually where you would
32:06 - find
32:06 - how to do that instead of just like oh
32:08 - aaron told me to type it no the
32:09 - documentation has all the information
32:11 - you need so
32:11 - you can go check it out you can play
32:12 - with it but for now we're just going to
32:14 - do
32:14 - the very simple one cv2.color bgr to
32:18 - gray
32:19 - one caveat to or one little quirk to
32:21 - opencv
32:22 - is i'm sure everybody knows what rgb is
32:25 - red green blue that's how
32:26 - each pixel can like mix those three
32:28 - channels colors together and make any
32:30 - color on for each pixel uh but an open
32:33 - cv
32:34 - the channels are actually backwards so
32:35 - instead of rgb it's bgr
32:37 - and that was very frustrating when i was
32:39 - first learning it but just be
32:40 - aware of that and that's why it is bgr
32:43 - to gray because it's taking this image
32:45 - and then turning it to gray
32:46 - so let's just show you uh what that
32:48 - looks like so instead of displaying the
32:49 - color image i'm going to display the
32:51 - grayscale image
32:52 - let's go back to our terminal and type
32:56 - in python face detector dot pi again
32:58 - enter and voila we have a grayscale
33:01 - robert downey jr beautiful
33:04 - looks just as sexy that is nice
33:08 - that is nice all right you guys and then
33:11 - of course any button to quit out
33:12 - and we are back to our terminal and now
33:15 - we can continue so once so that's pretty
33:17 - simple straightforward i'm sure you guys
33:18 - all understand at that point
33:20 - again go check out these different
33:21 - settings there's a bunch you can do
33:23 - and of course you could even convert it
33:25 - from gr from gray back to
33:27 - rgb and it would be considered an rgb
33:30 - but the thing is when you lose the color
33:32 - and it's gray then it actually is just
33:34 - gray so you won't actually get the color
33:35 - back but it'll technically be a color
33:36 - image but it's not actually going to
33:38 - look like it but
33:39 - i'm getting off topic there um from here
33:44 - uh the thing we're going to want to do
33:45 - next is going back to our
33:48 - our little presentation here is we want
33:51 - to train the algorithm right
33:53 - but that already happened opencv was
33:55 - already able to do that so all we want
33:56 - to do now
33:57 - is to plug that gray image into our
34:00 - algorithm that we're given by opencv the
34:02 - xml file we downloaded
34:04 - and from there it'll be able to open up
34:06 - all these or detect all of these faces
34:08 - so like this is actually one image and
34:09 - it detected all eight
34:11 - and um that's what we're going to be
34:12 - doing next so let's just quit out of
34:14 - here
34:15 - go back and let's just detect faces
34:19 - so
34:22 - yes yes some of you guys are probably
34:24 - like oh maybe this this is kind of fake
34:25 - it's just one liner that is technically
34:27 - faces that is true but
34:28 - like i said at the end of this video i'm
34:29 - actually going to go through the whole
34:30 - algorithm and explain it
34:32 - in layman's terms so that you can
34:33 - actually understand um how this is
34:35 - working and why it's working and all of
34:37 - that because then you have a full
34:38 - understanding
34:39 - um and there's no point of coding
34:40 - yourself if it already exists so this is
34:42 - actually a better approach because you
34:43 - can understand it you can get the result
34:45 - and that's all you need once you have
34:46 - those two things then you can innovate
34:47 - further
34:48 - and go on and optimize or create your
34:51 - own algorithms for your own problems
34:53 - so yes this is just one land to defeat
34:55 - um the face
34:57 - to detect the faces uh but i mean
35:00 - shorter code is better right quasi
35:02 - shorter code is better
35:05 - because like look here
35:09 - what was that but shorter shorter code
35:13 - is always better
35:14 - less errors i hate having a lot of code
35:17 - i even try to get my functions never to
35:19 - be more than like four lines of code
35:21 - um or i'll refactor it yeah nice having
35:25 - nice encapsulated code that's the word
35:27 - for it like if your function is just
35:29 - it does one thing and one tiny thing
35:30 - then you want to encapsulate it in one
35:32 - thing and keep
35:32 - keep your code very modular so you can
35:34 - plug and play
35:36 - uh functions all over the place so
35:39 - then says you guys are amazing you guys
35:41 - are putting so much effort to make us
35:42 - understand things like python
35:44 - and you were doing this at midnight as
35:46 - well so amazing you guys
35:47 - love you all thank you so much johnson
35:49 - we are not doing this at midnight it's
35:52 - my time for me yeah really early for
35:55 - aaron
35:56 - but uh thank you we appreciate the
35:58 - support guys and thank you for the
35:59 - positivity that really keeps us going
36:02 - yeah guys you wouldn't be doing we
36:03 - wouldn't be doing this if it wasn't for
36:05 - you guys like there's no
36:06 - there's no reason if nobody's watching
36:08 - them what's the point so yeah
36:10 - thanks for thanks for sticking around
36:12 - and putting up with us
36:14 - um all right so here uh what this is
36:17 - what what's happening here is before
36:20 - we we created our classifier the trained
36:22 - face data that opencv
36:24 - supplied for us within this xml document
36:26 - that we downloaded
36:28 - and from there we're going to call a
36:30 - function called detect
36:32 - multi-scale okay so this probably sounds
36:34 - a little bit
36:35 - maybe scary maybe not to others but all
36:37 - this means is
36:39 - whatever this classifier is which is a
36:41 - face
36:42 - face classifier since that's what we
36:43 - trained it on the train face data
36:45 - then we want to detect all of the faces
36:48 - with a multi-scale thing so all that
36:51 - means is no matter the scale of the face
36:52 - if it gets smaller or bigger
36:54 - then if it's small or big then it'll
36:56 - detect it anyways it's just looking for
36:58 - the overall composition like the
36:59 - relations of the eyes to the nose to the
37:01 - mouth
37:01 - whether it's smaller up close or if
37:03 - there's multiple of them
37:05 - then it just wants to detect all of them
37:06 - so that's what detect multi-scale is too
37:08 - why don't i actually pull this up on the
37:10 - um documentation
37:12 - quick question aaron prakar says can we
37:15 - use
37:15 - phone camera for detecting the face in
37:17 - real time
37:20 - um phone camera i mean you would have to
37:24 - somehow connect your phone camera to
37:26 - your laptop so that you could run opencv
37:28 - on there uh i think opencv has mobile
37:30 - support
37:31 - or to some extent i actually i've never
37:33 - done opencv on mobile but they might
37:35 - take a look at it and do it
37:37 - yeah but uh you would have to somehow
37:39 - hook up your phone camera i mean i'm
37:41 - sure it's possible somehow i haven't
37:42 - personally done it
37:43 - but you'd have to hook up your phone
37:44 - camera to your laptop and then pipe that
37:46 - into opencv
37:48 - somehow like maybe you make it your
37:49 - default camera i actually think
37:51 - yeah i'll take i'll take a look at that
37:53 - you don't have to worry about that i'll
37:54 - take a look
37:55 - look at it and see if something like
37:56 - that exists but uh if you guys do
37:58 - understand
37:59 - how to use it this way then you'll be
38:01 - able to even use it later for phone
38:03 - camera and things like that
38:05 - yeah we're focused on teaching a
38:08 - thorough understanding of the basics
38:09 - the basic building blocks like all
38:11 - encompassing everything so that
38:13 - when you learn this then you're equipped
38:14 - to actually go to your own innovation
38:16 - your
38:17 - implement your own creativity and do
38:18 - those kinds of things because that's
38:19 - where the real learning happens
38:21 - and then you can be original like i'm
38:22 - just gonna be like hey here's this
38:23 - project it's like oh here's the skill
38:25 - now you can go do what you want with it
38:27 - awesome all right let's keep going
38:30 - so let's just open up this detect
38:32 - multi-scale
38:41 - here we go cascade classifier
38:44 - and here we go so detect multi-scale
38:47 - uh this one it basically detects objects
38:49 - of different sizes in the input image
38:51 - so objects is just faces in our case
38:53 - because that's what we trained it with
38:54 - we could have trained it with dogs we
38:56 - could have trained it with cars with
38:57 - houses but in our case it's faces
39:00 - and from there the detected objects are
39:03 - returned as a list of rectangles
39:05 - so pretty much it just returns the
39:06 - coordinates of those green rectangles
39:08 - and once we have those coordinates we're
39:09 - able to actually draw those rectangles
39:10 - on our image so that's what we're going
39:12 - to be doing
39:13 - next okay so from here
39:16 - detect multi-scale we feed in the
39:18 - grayscale image which is a robert downey
39:19 - jr image
39:20 - and like like we said this returns the
39:24 - this returns the the coordinates of the
39:27 - rectangles so that's why i call that
39:28 - face coordinates
39:29 - because it'll give us the coordinates of
39:31 - the rectangles surrounding the face and
39:33 - then from here once we have these
39:34 - coordinates
39:35 - it's it's very simple to just draw
39:37 - rectangles onto the image or the
39:39 - the current frame of the video if we're
39:40 - doing a video and it just runs on every
39:42 - frame
39:43 - [Music]
39:52 - so from here why don't we actually
39:55 - print out first of all we don't need to
39:58 - display robert downey jr anymore
40:00 - but why don't we actually print out the
40:02 - coordinates okay
40:04 - so face coordinates
40:07 - did i spell that correctly
40:10 - yeah and let's just run the code okay so
40:14 - the
40:15 - the coordinates of robert downey jr's
40:16 - face should be displayed in the terminal
40:19 - and can you make your can you do me a
40:20 - favor can you make your terminal
40:22 - like wider that way your line of code
40:25 - can show on one line instead of
40:27 - wrapping perfect perfect perfect
40:30 - yeah my dirty coding habits right i've
40:32 - gotten
40:34 - bad habits beaten into me but all right
40:36 - you guys
40:37 - so this is the location of robert
40:41 - downey's face
40:42 - in the image is it possible aaron is it
40:46 - is it possible to also later show the
40:49 - face coordinates but with your face
40:51 - with the webcam open and so then as you
40:53 - move it like
40:54 - actually prints out the console logs in
40:57 - the terminal
40:59 - yes actually yeah okay so let's do it
41:02 - like that
41:03 - let's do that yeah let's do that once we
41:04 - get to the webcam but right now we're
41:06 - going to focus on getting one single
41:07 - image up and running
41:08 - got it so i'll explain this so what this
41:10 - is like i said it returns the
41:12 - coordinates of a
41:14 - um of the face so all this is is the
41:16 - upper left
41:17 - coordinate of the face and this is the
41:19 - bottom right coordinate
41:20 - so just a bounding rectangle that's all
41:23 - it is can you just show it visually like
41:24 - can you open up the dot
41:26 - robert donnie jr uh robert donnie jr's
41:29 - photo and then like
41:30 - show what you mean yeah so like i was
41:34 - saying
41:34 - um of course this is going to be gray
41:36 - scaled in within our app right now but
41:38 - just for demonstration purposes the face
41:40 - is about right here
41:42 - okay so this 307 115
41:45 - would probably be right around here the
41:47 - upper left hand
41:48 - of the um face and then this
41:52 - 336 uh 336 would be
41:55 - right around here the bottom right
41:57 - corner bottom right so you have a
41:59 - bounding rectangle and then from here
42:00 - it's very easy to just actually draw
42:02 - the green um the green box surrounding
42:04 - the face and that's how it happens
42:06 - okay we're doing all that manually we're
42:08 - actually drawing we're finding the
42:09 - location of the face and then we're
42:10 - drawing the rectangle
42:11 - around the face and then we're
42:12 - displaying that new image with
42:15 - so that's exactly what's happening with
42:17 - it and the rectangle that we're drawing
42:18 - we're drawing it from a module an open
42:20 - cv
42:21 - lets you draw as well yes got it
42:24 - wait how do i get rid of
42:28 - yo tony how's it going uh awesome this
42:31 - is tony that was actually yeah you you
42:33 - know him right here
42:35 - yeah yeah tony orbis what's up man yeah
42:38 - this is awesome
42:40 - um dang it i think my terminal bugged
42:42 - out
42:43 - let me just terminate and open a new one
42:47 - cool terminal and that's desktop
42:52 - and clear
42:55 - and again python is going to be face
42:58 - detector
43:00 - you're not in that file i think you have
43:02 - to go in that file why don't you open up
43:03 - your terminal
43:04 - in uh visual studio code
43:07 - um i could do that is it command j
43:13 - yep all right and go to my bash you can
43:16 - you can be in your
43:18 - so that's my desktop and from here
43:22 - we can run python um
43:25 - i think it was face detector
43:29 - or dot pi
43:33 - and there we go awesome i actually
43:35 - haven't run it from here let's see if it
43:36 - actually displays the image
43:38 - i haven't actually hmm
43:43 - swipe up no no it's it's running it's
43:45 - running so use your four fingers to
43:47 - swipe up on your mouse pad
43:49 - um and then it'll like yeah and then
43:51 - it'll show
43:52 - oh it doesn't have yeah it's i thought
43:54 - it would visually show up
43:56 - it's because i'm printing the
43:57 - coordinates and then the weight key but
43:58 - it's not
43:59 - um displaying something it's just
44:02 - bugging out so
44:02 - got it just let's just terminate this is
44:05 - how you terminate it
44:06 - yeah just open up a new yeah perfect you
44:09 - can just open up a new terminal if you
44:11 - want
44:13 - yeah oh stick to this one because then i
44:16 - can
44:18 - um because i like having the full code
44:20 - open the whole thing
44:21 - at one time okay got it so
44:24 - okay back to desktop python
44:28 - face detector not pi
44:32 - okay there we go so from here then we
44:35 - can
44:36 - continue yeah the weight the weight key
44:38 - bugged out because there was nothing
44:39 - popping up there there was nothing to
44:41 - close so nothing to
44:42 - actually capture a key and then continue
44:45 - but that's
44:46 - not that important oh hello kazi
44:50 - hi guys and
44:55 - yeah so those are the coordinates now
44:58 - from there now like i said
44:59 - we want to superimpose a rectangle over
45:01 - the image
45:02 - so that we can display it back and of
45:04 - course we want to do it with the color
45:06 - image again so once we have the
45:06 - coordinate we can go back to the color
45:08 - image
45:08 - and draw the rectangle on the color
45:10 - image once we get the coordinate from
45:11 - the grayscale
45:12 - image in the algorithm so let's just
45:15 - comment this out
45:18 - and the next thing is we're just going
45:21 - to draw rectangles
45:23 - and of course if there's multiple faces
45:24 - then it'll draw rectangles around all of
45:26 - them so we have a loop
45:28 - um but actually let's just let's just
45:30 - delete that for now let's just start
45:31 - with one rectangle
45:33 - so to draw a rectangle uh this is the
45:37 - function so opencv again
45:38 - allows us to just call something called
45:40 - rectangle and what it takes is
45:42 - an image that you want to draw a
45:44 - rectangle on so of course we'll use our
45:45 - color image originally
45:48 - then it the next one it takes a tuple of
45:51 - the upper left hand
45:53 - um the upper left hand
45:56 - coordinate got it this is the lower
45:59 - right hand coordinate
46:00 - so this x y and x this doesn't work
46:02 - because i had the loop so let's actually
46:03 - just delete this for now
46:05 - and like i said the face coordinates is
46:07 - what we want so the upper left hand
46:09 - would be
46:10 - whatever this gives us yeah so phase
46:12 - coordinates gave us
46:14 - like that that uh 305 thing right like
46:16 - 305 116
46:18 - whatever we had in the command line
46:19 - earlier for the robert downey junior's
46:21 - face yeah so actually why don't we
46:24 - yeah just yeah run it type that out
46:26 - perfect
46:27 - like actually just like manually put in
46:28 - the numbers just to show you guys that
46:30 - it actually
46:31 - works okay so i'm just gonna show
46:33 - visually what we're doing here you might
46:35 - not be able to see my screen for a
46:36 - second
46:36 - okay so just hold on and i'm gonna just
46:39 - explain this also visually um all right
46:42 - guys
46:42 - so basically you know if you guys are
46:44 - with us so far
46:46 - what aaron is about to do right now is
46:47 - we're going to have robert donny jr's
46:49 - face
46:49 - like this okay and um i don't know if
46:52 - he's smiling or whatever
46:54 - and then around this we're going to draw
46:56 - a rectangle
46:58 - now what we need is the top left
47:01 - so aaron the 307 and then the 116
47:05 - do both of those coordinates refer to
47:07 - like
47:08 - x and y pixels x and y pixels okay so
47:11 - one is like okay
47:13 - the top so basically just two points
47:15 - right one is the top left point and one
47:17 - is the bottom right point
47:18 - yep that's it okay so this is going to
47:21 - be and
47:22 - what are the first two numbers aaron is
47:23 - it 305 comma one what are they can you
47:25 - tell me 307
47:26 - and 115. okay
47:29 - so guys that's that point over there
47:32 - okay then we have the second point here
47:34 - and what are
47:35 - what is the coordinates for the second
47:36 - point three three six
47:38 - three three six okay so it's three three
47:41 - six three three six
47:45 - all right so here are the two tuples
47:48 - this is tuple one
47:49 - this says tuple two right over here and
47:51 - that's how we're gonna draw the
47:53 - rectangle
47:53 - around somebody's face we need those two
47:55 - points once we get those two points
47:57 - cv2 allows us to actually make a
48:00 - rectangle around the face okay so that's
48:02 - what aaron the
48:03 - line of code that aaron has if we go
48:05 - look at his screen
48:07 - right now right here yep
48:10 - so that's those coordinates that he's
48:12 - referring to
48:14 - um these right here yep and that's what
48:16 - we're gonna do i just hard coded them in
48:18 - just to show you guys for now
48:20 - exactly and then i imagine the zero two
48:22 - five five or whatever that's the color
48:23 - like it's gonna make a green color or
48:25 - something
48:26 - i choose green so this of course opencv
48:28 - is backwards so this is
48:30 - bgr instead of rgb so if this was 255
48:32 - this would be blue
48:34 - if this was 255 this would be red if i
48:36 - zeroed this one out
48:37 - but i like green so i just chose green
48:39 - but you could you could even make it
48:40 - white you can make it black that's why
48:42 - the heck you want now what's the last
48:43 - two at the end the
48:45 - thickness of the rectangle okay perfect
48:47 - how thin that's all it is so
48:49 - of course if it's 10 it's going to be
48:50 - really thick but two is a nice
48:52 - it's a nice thin line awesome so this is
48:55 - guys this is a cartoon
48:56 - way of looking more cartoony way of
48:58 - looking at it how is it drawn here
49:00 - you saw aaron's lot what the one line of
49:02 - code that he has
49:03 - right over there so now let's go ahead
49:06 - and actually run it
49:08 - got it so here we have the
49:11 - the rectangle being drawn on image okay
49:14 - and then down here we have an image show
49:16 - and here we still have the grayscale
49:18 - image so all we got to do is just change
49:19 - this back to image because now image
49:21 - has the green rectangle drawn on it
49:23 - around his face let's give it a save
49:26 - let's go to the terminal and let's run
49:29 - it
49:31 - and something is wrong
49:35 - um might have these backwards
49:39 - um yeah that's pop
49:43 - i'm trying to think
49:47 - uh dude let's just get right angle
49:49 - documentation
49:52 - what it does is it adds them so if we
49:55 - actually look at the code that we had
49:57 - earlier and the one
49:58 - we commented out or whatever it's like
50:01 - uh x plus w and then y plus h
50:04 - so you want to take the x
50:08 - coordinate exactly so you want to take
50:10 - the x coordinate and add the width to it
50:12 - and then you want to take the
50:14 - y-coordinate add the height to it and
50:16 - that will give you what you're looking
50:17 - for so just add the width and add the
50:19 - height
50:19 - whatever yeah you're right i forgot that
50:21 - detail it's so this is actually the
50:23 - upper left-hand point let's go back to
50:25 - there let's let's
50:26 - um confirm that so the whoever developed
50:28 - opencv decided to implement it this way
50:30 - probably because it was smarter in the
50:31 - long term instead of having the top left
50:33 - point
50:34 - and bottom right point they actually
50:35 - have the top left point and then the
50:37 - width and height
50:38 - of the rectangle so that you can just
50:39 - add this to these points to get the
50:41 - bottom right point
50:42 - so i guess equally effective it's the
50:45 - same data just in a different way so
50:47 - actually
50:48 - what this would be would be 307 plus 336
50:52 - and that would make sense why it's 336
50:54 - because it's a square
50:56 - it's the same number because the width
50:57 - and height of a square is the same
50:59 - so now now let's try it now it should
51:02 - run correctly
51:05 - back to the terminal oops
51:10 - yeah and ah much better
51:14 - nice okay so that bug was fixed
51:18 - and there we go so this is a solution is
51:20 - it still
51:21 - true that the top left point is um
51:25 - is 307 and 115 is that still true
51:28 - and the bottom bottom right point is 336
51:31 - comma 336
51:33 - no the bottom right point this is the
51:34 - width and height of the square because
51:36 - it's a square so width and height is the
51:37 - same so
51:38 - so what's the bottom right point then
51:40 - that would have to be
51:41 - this point um to get the
51:44 - i mean it's just some some coordinate
51:46 - math so 307 is the x
51:49 - is the x uh location of the top left
51:52 - point
51:52 - so this is 307 this way uh okay and then
51:55 - the bottom right
51:56 - bottom right is just one one five yeah
51:59 - and then this is
52:00 - this is one one five no no no you have
52:03 - to come on quasi
52:04 - you got to add the you got to add the
52:06 - 336 to
52:08 - um the width and the height to this
52:10 - point
52:11 - and once you add 336 it'll come out here
52:13 - and go down so
52:14 - that's how you get the rectangle got it
52:17 - get the offset
52:20 - so from there uh we have robert downey
52:22 - jr's face
52:23 - okay the problem with this though is of
52:25 - course we hard-coded it
52:27 - in so we do not want to do that okay uh
52:29 - what we do want to do is actually
52:32 - just get the
52:35 - points dynamically
52:38 - and then print those out so like we just
52:41 - did
52:43 - it's going to be like this
52:47 - nice the thing is we are going to want
52:50 - to
52:52 - make sure we are getting the
52:56 - coordinates from the face coordinates
52:57 - correctly so
52:59 - x y width and height like we said in the
53:02 - terminal okay so this is x
53:03 - y width and height here
53:06 - and we can do that using a four tuple
53:09 - and just set this equal to phase
53:11 - coordinates
53:12 - okay and this will automatically
53:15 - assign each of those four numbers one
53:18 - two three four
53:19 - to these four variables one two three
53:21 - four another two
53:22 - nice and a two pole then we can just
53:25 - pull those x y
53:26 - and the x y um wh out just like this and
53:30 - this should work unless i got my math
53:32 - wrong again which could be
53:33 - very awesome we just broke a thousand
53:35 - likes i heard
53:36 - on the video that is amazing thank you
53:38 - guys thank you one more value to unpack
53:42 - [Music]
53:45 - what is the last coordinate
53:52 - wait what was it complaining about face
53:56 - and line equals face coordinates value
53:59 - error need more than
54:01 - uh you never differ oh yeah you actually
54:03 - did define
54:04 - um buggy maybe wait hold on
54:08 - isn't it face coordinates of zero or
54:10 - something because it's an
54:11 - array with that it's a list within a
54:13 - list so you might have to like
54:14 - the double brackets there right yeah i
54:16 - don't know what that is but
54:18 - yeah that'll probably work so let's give
54:19 - this a shot
54:23 - there we go yeah oh that i guess that
54:27 - makes sense because
54:28 - it's a list of
54:32 - here that would make sense because if
54:33 - there's multiple faces then you want a
54:35 - list of lists yeah yeah
54:38 - okay that's why that's like that makes
54:39 - sense yeah um but there you go there you
54:41 - go guys so now we have it dynamically
54:43 - getting the
54:44 - the face with the coordinates here that
54:45 - is so cool that is so cool can you turn
54:48 - it red real quick
54:49 - just like in just real quick like that's
54:51 - awesome
54:53 - so there we go sunny was telling me you
54:56 - have like scary amount of knowledge on
54:58 - color
55:00 - oh yeah i worked at a i worked at a
55:04 - i had a data science gig for eight
55:05 - months doing opencv stuff like
55:08 - exclusively like four years back
55:16 - oops oh i killed the terminal
55:29 - guys this is the right person uh keep
55:31 - opening it up and once you open it up do
55:33 - let me know but guys this is the right
55:34 - person to learn opencv stuff from like
55:36 - he just was doing
55:38 - this for almost a whole year yeah edge
55:41 - detection
55:42 - motion detection background like you can
55:44 - you can do a lot of cool stuff but right
55:46 - now we're just doing face detection so
55:47 - desktop
55:49 - and again let's go python face detector
55:52 - yo aaron maybe like upcoming few weeks
55:55 - just like go crazy edge detection like
55:57 - bring all of that back so yeah you guys
55:58 - look at that we just turned it red super
56:00 - fast super easy green
56:02 - yeah it's awesome change the color i
56:04 - mean
56:05 - minor detail but yeah let's change it
56:08 - back to green because i like green
56:09 - better
56:10 - and although of course this is the
56:11 - thickness so let's let's just do a quick
56:13 - yeah change it to real thick like five
56:16 - or ten that would be awesome
56:19 - kaboom nice that looks that actually
56:21 - looks great i like that level of
56:23 - thickness
56:24 - like it all right let's keep it there
56:25 - yeah so we'll keep that there
56:27 - that is so cool like we're detecting a
56:29 - face in real time and
56:31 - drawing the circle dynamically around it
56:33 - and this code already works on
56:35 - any image you give it that is
56:37 - mind-blowing you could even you could
56:39 - even have a circle instead of a
56:40 - rectangle but it's only gonna
56:42 - but right now it's only gonna make draw
56:44 - it on the first person it sees you guys
56:46 - so if there are two people it'll only
56:47 - draw it on one person's face
56:49 - but once we write a loop it's so cool
56:51 - we're looping through humans
56:52 - like that blows like you literally are
56:55 - looping through human beings
56:57 - that is insane
57:01 - it kind of blows my mind i almost want
57:02 - to take a picture i almost want to take
57:04 - a picture of us right now and send it
57:05 - can i do that can i just take a picture
57:07 - of both of us
57:08 - split side by side and then you open
57:10 - that image up and run it on it or is
57:12 - that just
57:13 - go for it no it should work okay cool
57:16 - yeah this this algorithm isn't 100
57:19 - accurate
57:19 - they um the algorithm the hard cascade
57:22 - algorithm
57:23 - is more concerned with speed than
57:24 - accuracy so it might not 100 work but
57:26 - like 90 percent it'll work
57:27 - so let's okay just make sure you have
57:29 - good lighting and then it should work
57:30 - fine
57:31 - yeah i got good lighting let's uh detect
57:33 - it right now so i
57:34 - pulled it from our live stream and i'm
57:37 - sending it over to you
57:39 - in slack so what you can do in the
57:41 - meantime is uh just
57:43 - go ahead and pop it in to your like it's
57:46 - so cool to me so
57:47 - just go in slack and then pop it into
57:50 - your image
57:51 - see what i'm saying
57:55 - okay cool but like guys this is so
57:58 - mind-blowing to me the fact that you can
58:00 - actually like
58:01 - detect images so like what i'm talking
58:03 - about looping through human faces here
58:05 - right
58:05 - if i can just draw it out for you guys
58:07 - so let's go over here and i'm gonna draw
58:09 - it out
58:09 - but let's say that we had i'm gonna
58:11 - clean this up
58:13 - but let's say the image i gave aaron has
58:15 - two people in it so if you have actually
58:17 - two human beings here
58:19 - like this right what we're about to do
58:22 - right now which is
58:22 - mind-blowing is for right now our code
58:25 - all it's going to do is draw
58:26 - a circle around like one person's face
58:29 - it's going to decide who whether it's
58:30 - aaron or me
58:31 - and that's it but then once we write a
58:33 - for loop it's actually going to make a
58:35 - square
58:36 - around aaron so that's person one and
58:38 - then it's gonna loop through
58:39 - find me right this is causie
58:43 - it's gonna find me and then it's gonna
58:45 - make a circle around my face like a for
58:47 - loop that loops through
58:48 - human beings that is just cool like
58:51 - that's the power
58:52 - of you know being able to actually do
58:54 - like face detection
58:56 - and uh ai with python or really any
58:58 - language like it's so
59:00 - freaking cool to me you know if you guys
59:02 - think it's cool go ahead and smash that
59:04 - like button but
59:05 - to me it's kind of mind-blowing
59:09 - and then whenever you're ready aaron
59:10 - just let me know got it
59:13 - yeah so i got the picture of me and qazi
59:15 - here on my desktop and
59:17 - instead of reading the robert downey jr
59:18 - photo i just want to read in
59:20 - this photo so i just named it qazi aaron
59:22 - okay and i'm gonna comment is it in the
59:24 - same directory
59:25 - okay yeah yeah yeah yeah yeah yeah yeah
59:25 - yeah yeah yeah yeah yeah yeah yeah yeah
59:25 - yeah yeah yeah yeah yeah yeah yeah yeah
59:25 - yeah yeah just on my desktop it's kind
59:26 - of cool cool that's fine but
59:28 - that's why i just uh keep it there just
59:30 - to get it up and running can you show
59:32 - the image first can you show the image
59:33 - first by itself
59:35 - so they don't think i sent it to you
59:36 - with green squares around it
59:38 - there we go so this is the image okay um
59:41 - i wonder
59:42 - no i think yeah it'll detect my face
59:44 - there yeah maybe
59:46 - we'll see so that is the um
59:49 - image now we're using that instead yeah
59:52 - and
59:52 - from there we want to um detect the
59:55 - all the faces so right now we only gonna
59:57 - detect one so let's run it and see who
59:59 - it detects first aaron or kazi
60:01 - yeah just give it a shot or if it breaks
60:04 - we'll see
60:04 - [Music]
60:12 - we'll find out and hey whoa
60:15 - that is so cool and for that reason it
60:19 - probably goes
60:19 - i think it gets me first because it it
60:21 - scans from the bottom yeah can you can
60:23 - you do me a favor and change that in
60:25 - like dude this is an array of us two
60:28 - like in one
60:29 -  array like i'm sorry guys excuse
60:31 - the language but like
60:32 - in one list it's two human beings can
60:35 - you index that array
60:36 - can you index it list with one so then
60:39 - it puts me maybe
60:40 - let's take a look yeah so because you're
60:42 - second in the list so if you did yes
60:43 - then it would
60:45 - oh dude this is about to blow my
60:46 - freaking mind right now
60:48 - i'm so pumped oh my god dude that is
60:52 - cool like that is so cool let's see if
60:55 - there's a three let's see if i got your
60:57 - shirt
60:58 - let's see oh if it got oh my god maybe
61:00 - it did yeah maybe maybe
61:01 - maybe it detects my face this is so cool
61:04 - this is so cool i can't get over it
61:05 - i cannot get over it i don't care if
61:07 - people think it's cool or not i think
61:08 - it's so freaking
61:10 - oh my god
61:16 - that's what i was talking about you guys
61:18 - when it says multi-scale
61:20 - it's what it's doing is it's taking the
61:22 - train data and it's
61:24 - checking for all sizes so it's starting
61:25 - big or starting small
61:27 - and then it's iterating so it's called a
61:30 - sliding window so it'll like slide the
61:31 - window all the way across
61:32 - tiny did nothing nothing nothing nothing
61:35 - bing found a match
61:36 - they go a little bit bigger nothing good
61:39 - that is sick
61:40 - it's an array with it's array of three
61:42 - items of three human beings
61:44 - in a little list three human beings in a
61:46 - list how does it make you feel
61:48 - um yo that is so cool like i'm blowing
61:51 - like logan is like damn
61:53 - paulo is like insane i know right and
61:56 - all we did is copy and paste like six
61:58 - lines of code it's amazing
62:00 - it's so crazy it's six lines of code
62:02 - that's right
62:03 - uh people are like oh we got somebody's
62:07 - like that's actually epic
62:08 - um dude can you can you now can we loop
62:12 - through it and draw the squares around
62:13 - all of us
62:15 - i don't know about that man i don't know
62:16 - if my skills are up to par for that but
62:18 - i mean i mean you know we had the loop
62:20 - you wrote the loop earlier
62:22 - yeah okay all right all right
62:25 - we got you guys so now we're just gonna
62:27 - have this be a loop so we have a list
62:29 - and a list of three of three faces that
62:31 - we detected in that image
62:32 - and now we just want to loop over them
62:34 - instead of just doing it one by one
62:36 - of course we could probably do this this
62:38 - is a sloppy way to do it
62:39 - but why don't we do it just for um
62:43 - sake so this is actually like running a
62:45 - loop three times but just manually
62:47 - yeah it's just listing it out okay got
62:49 - it and
62:51 - run it and kaboom oh
62:54 - man that is nice so this is just
62:57 - manually doing it
62:58 - yeah and let's make this nice and big
63:00 - purl nice nice thumbnail you know
63:03 - wow oh that should have been the
63:04 - thumbnail of the video
63:06 - nah i mean robert jenny jr is too sexy
63:08 - man justin timberlake
63:09 - that's true that's true that's true
63:11 - you're right or ugly bro
63:13 - yeah six lines of code man like that is
63:16 - so
63:16 - cool to me yeah even logan is going he's
63:18 - like bro just literally input
63:20 - in the six lines of code what the hell
63:23 - it'd be cool if you can change the color
63:24 - you know
63:24 - like you even like like label them and
63:26 - stuff but anyways let's go back and make
63:28 - this actually loop the proper way
63:30 - so uh the way we're gonna do that is oh
63:33 - yeah
63:34 - change uh also yeah once you write the
63:36 - loop let's also
63:37 - like change the colors between 0 and 255
63:40 - it just picks randomly so then it'll be
63:42 - different colors
63:43 - oh that's fun all right yeah okay dude
63:46 - on the on the webcam when we're doing a
63:47 - live webcam it's going to be like
63:48 - rainbow it's going to be like going
63:50 - crazy
63:50 - it's going to be pretty cool yeah yeah
63:52 - yeah yeah
63:53 - but all right so let me just go in here
63:55 - so i'm going to type it out
63:57 - here's the loop all right and we're just
64:00 - going to
64:00 - replace this top line this one we're
64:03 - going to replace it with this okay
64:05 - so instead of manually getting it here
64:08 - and getting the first
64:09 - the first face in this list of faces and
64:12 - then assigning it we're just actually
64:13 - going to loop through all of them
64:15 - so because this is a list we can loop
64:17 - over it using the word in
64:18 - so for this tuple in this list which
64:21 - means it's going to iterate over
64:22 - everything
64:23 - then um it's going to have the same
64:24 - functionality okay so
64:26 - do this make sure you tab correctly so
64:30 - for this tuple x y uh with height
64:33 - in phase coordinates then this is
64:35 - unchanged okay because we have the
64:36 - variables exactly the same so this is
64:38 - actually going to work
64:39 - uh minus the randomization of the colors
64:42 - but let's just give this a run and see
64:43 - what happens
64:44 - and it might even pick up extra stuff if
64:46 - it if it failed there might be like a
64:48 - fourth phase somewhere
64:50 - no there is none but
64:53 - there we go you guys so this is
64:54 - functioning so far that loop worked
64:57 - yeah it did we're looping through three
64:59 - human beings right now
65:01 - or two human beings beings in one
65:04 - cartoon
65:05 - man this is so crazy to me wow
65:09 - why do you look so dirty we have the
65:10 - same glasses this is awesome yo okay i
65:12 - got you with the
65:13 - i got you with the different colors so
65:15 - aaron go all the way to the top of the
65:17 - file
65:18 - and um and just do
65:21 - um do hold on
65:25 - import so do from random import rand
65:28 - range
65:28 - although at the top
65:32 - like that yep um i am
65:35 - so you misspelled import yep and then um
65:38 - where you have that 255
65:42 - you can you see where you have zero
65:43 - comma 255.
65:46 - so just do ran range uh no no no
65:50 - no don't do that don't do that don't do
65:51 - that
65:53 - don't do that just the 255 just wrap the
65:56 - 255
65:57 - in the function rand range
66:01 - got it and right you can do 250
66:05 - yeah 256 because it's going to go up to
66:08 - but not including
66:11 - okay so now it should be randomly like
66:14 - making the colors so now if you hit save
66:16 - and run it everybody should have like a
66:17 - different
66:18 - uh color hopefully it would be really
66:21 - unlucky if all three of them were
66:22 - randomly generated well this is just the
66:24 - green this is just the green channel so
66:26 - it's going to be different
66:27 - scales of green but not different colors
66:29 - oh
66:30 - so then you can actually just do rand
66:32 - range for all of them like for all of
66:34 - the coordinates you could do
66:35 - so go back you could do for like for
66:38 - zero you could do that and
66:40 - all three of them you could do the same
66:41 - thing there we go
66:44 - and yeah now let's run it and now it
66:46 - should be
66:47 - random colors
66:51 - that is so cool and green
66:54 - damn okay awesome
66:57 - that would be useful for identification
66:59 - like if you ever actually trained if you
67:01 - got enough of your images enough of my
67:02 - images
67:03 - and enough of this little shirt we could
67:05 - uh we could actually like train it and
67:07 - be like okay
67:08 - it's red aaron's blue i just can't get
67:09 - over that we're in a list
67:11 - we are in a list right now in a python
67:13 - like that
67:14 - okay dude i can't get over that all
67:16 - right let's keep going
67:18 - we know uh one thing i do want to try
67:20 - though is i feel like those colors a
67:22 - little bit dark
67:23 - but if we keep the the range in the
67:25 - upper half of the 256 then they won't be
67:27 - so dull all the time so let's actually
67:29 - go
67:29 - um 128 to 256.
67:33 - okay oh i try this and then i think the
67:35 - colors the colors will always be
67:37 - brighter
67:38 - color science
67:42 - oh i mean it kind of looks
67:45 - it's fine but that's fine
67:49 - you can remove the one yeah just so it's
67:51 - less confusing for them but yeah ran
67:53 - range is awesome right guys it's pretty
67:54 - cool
67:55 - quasi logan goes kazia 20 20. i'm in a
67:58 - list
68:03 - for you getting excited coronavirus got
68:06 - us all screwed up you know like we're
68:07 - getting excited about a list
68:08 - like awesome
68:12 - all right thank you guys we just broke a
68:14 - thousand likes thank you guys so much
68:16 - really appreciate you guys uh we
68:18 - our team just notified us frankie just
68:20 - notifies like thousand likes on this
68:22 - video frankie's pumped
68:25 - awesome you guys thanks for all the
68:27 - support we appreciate it uh i don't know
68:28 - how long we've been going for like
68:29 - almost an hour already right
68:31 - yeah way longer than one hour for six
68:33 - lines this is so
68:34 - fun this is so fun i think everybody's
68:36 - pumped i think everybody's totally
68:38 - like what do you guys think but in my i
68:40 - honestly think that everybody's freaking
68:42 - pumped out of their minds
68:44 - because i think this is the coolest
68:46 - freaking tutorial that's out there on
68:48 - face detection everything else is like
68:50 - so boring every time i try to learn it i
68:52 - go to fall asleep
68:54 - wait wait till wait till i explain
68:56 - actually how it works like
68:57 - mathematically
68:58 - like it's not complicated but like
69:00 - that'll blow your mind because right
69:01 - here we're just calling a piece of code
69:02 - anybody can copy and paste this but if
69:04 - you actually understand how it works
69:06 - that's the mind-blowing part so stay
69:07 - tuned to the end for that okay guys
69:09 - uh we're almost done so we're gonna move
69:11 - on to
69:12 - um video now because actually our
69:16 - our image is done so we are have already
69:18 - gotten the image and we're displaying it
69:20 - here
69:20 - and then we did i would display it here
69:22 - so we display the image here
69:24 - play the image with the faces
69:29 - and then we have the wait key of course
69:31 - which is just waiting until we press a
69:33 - key to close and once it closes then
69:34 - code says code completed and we are done
69:38 - so okay we are detecting faces on a
69:41 - single image but what if we want to
69:42 - detect faces
69:43 - in a video
69:52 - but what if we want to detect faces in a
69:54 - video well all a video is is a bunch of
69:57 - images one after another so
69:59 - um we can actually just run this code on
70:01 - every single frame of an image
70:03 - of a video i mean whether it be a video
70:06 - file or
70:06 - our webcam stream we're going to be
70:08 - using the webcam stream
70:11 - and that will basically
70:14 - give us real-time face detection so it's
70:16 - pretty much the same exact code with
70:17 - just a loop added
70:19 - on the outside so let's do that now okay
70:21 - i'm just going to mod i'm just going to
70:22 - continue modifying this code
70:24 - so let's go down here and
70:28 - the first thing we're gonna have to do
70:29 - is actually instead of capturing an
70:31 - image we're gonna
70:33 - want to capture the webcam so let's
70:35 - start from
70:36 - here let's comment out the image
70:40 - and instead let's paste in
70:44 - this okay so instead of
70:47 - calling image read on an image file to
70:48 - wait um to get an image like this
70:50 - we instead are going to call cd2 video
70:53 - capture
70:54 - so all video capture means is you're
70:55 - going to capture a video if you put a
70:57 - zero in here
70:58 - it's gonna get your default webcam so
71:00 - for the person asking about your iphone
71:02 - if you can make your iphone the default
71:03 - cam i think using xero would actually
71:05 - work you just have to like specify it on
71:07 - your computer assistantly i went
71:08 - unfortunately i went and checked and
71:10 - opencv does not work
71:12 - with ios but
71:15 - i honestly think that if you figure out
71:17 - how to make this
71:18 - work you can easily make something with
71:21 - javascript
71:22 - and then host it online and then people
71:25 - can go and use it but the most important
71:26 - thing is to get experience
71:28 - using it learn how this technology works
71:31 - and then it you can go and implement it
71:33 - in any language you want
71:35 - on any system
71:38 - absolutely so i mean i i think it might
71:41 - be possible like look into it maybe
71:43 - uh it won't work natively on the iphone
71:45 - but you could use your iphone camera
71:46 - hook it up your computer and then use
71:48 - your iphone and
71:49 - look around and have that being in this
71:50 - app but the point i was saying was
71:53 - if you have zero it automatically goes
71:54 - to your default webcam
71:56 - um but if you put a file name in here
71:57 - then you could have like you know
71:59 - video.np4 or something if that was on my
72:01 - desktop it doesn't exist
72:03 - um well actually i do have a video here
72:06 - or is it it was a funny
72:07 - detective face that's actually cool lol
72:10 - memes so let's just do this
72:12 - oh nice i didn't know you could give it
72:14 - a video that is so nice
72:16 - yeah you can oh it's actually not going
72:17 - to work because we haven't coded it all
72:18 - out so let's actually do this later
72:20 - but first step is calling video capture
72:22 - which allows you to get the webcam
72:24 - or a video file with the same function
72:26 - which is nice so thank you opencv for
72:28 - being smart and efficient
72:29 - so ahmed asks where's the training part
72:32 - the training part is on line
72:33 - six that's where we trained it the
72:36 - that's where we train the data
72:37 - but keep going yeah we actually didn't
72:40 - train
72:41 - opencv because training takes a lot of
72:42 - time like we would be sitting here for
72:44 - anywhere from
72:46 - probably like half an hour to multiple
72:48 - days depending on what kind of data
72:49 - you're training
72:50 - um so that's why we didn't do that here
72:52 - we just we stole the training
72:53 - the train data that opencv already
72:56 - trained for us like years ago and then
72:57 - they just
72:58 - supplied supplied this machine learning
73:00 - network for us to use and
73:02 - we just downloaded that which is right
73:04 - here so this is actually
73:05 - the train data so all these numbers the
73:07 - negative four the negative two and all
73:09 - these crazy numbers
73:10 - if you pump an image through all these
73:12 - crazy numbers it just filters through
73:13 - and it finds the faces magically
73:15 - you know the same way your eye can find
73:16 - a face when you look at a picture
73:18 - this is doing something remotely similar
73:20 - that your brain is doing but in a
73:22 - different
73:22 - like in a computer computerized way so
73:25 - that's what that's what this is so yes
73:26 - the training is happening
73:28 - um in here in essence
73:31 - hope that's clear
73:37 - quasi i cannot hear anybody
73:42 - no you're good you're good to go keep
73:44 - going
73:45 - got it so
73:48 - um let's just get this going and then
73:51 - actually display the
73:53 - webcam okay um i believe
73:58 - we need weight key as well yeah pretty
74:00 - sure we need weight key
74:03 - and webcam release
74:11 - let's see if this works
74:15 - and this is awesome we still have 685
74:17 - people live this just tells us we got to
74:19 - be doing a lot more of this aaron
74:20 - because
74:22 - it seems like everybody loves this stuff
74:24 - because most of the times by now we drop
74:26 - to like 100 live
74:28 - people watching this is awesome yeah
74:30 - people are loving it right
74:35 - oh says yeah well it's not gonna work
74:37 - because we need the loop so this is a
74:38 - little bit confusing
74:40 - um what i so if i was if i were to do
74:42 - this and display
74:43 - what this gave us it would only give us
74:44 - the first frame so we're gonna have to
74:46 - kind of do a big chunk of
74:48 - um logic together guys we're gonna have
74:50 - to cut up the whole loop
74:51 - and get it going as one um so just bear
74:54 - with me
74:55 - and and we'll get that going so
74:58 - uh once you get the the webcam here uh
75:01 - what you're gonna want to do is
75:04 - um get a a while loop okay so this loop
75:09 - is going to go right here and what this
75:12 - does
75:12 - is we just want it to loop over all the
75:15 - frames in the video
75:16 - forever until the video ends or until we
75:18 - kill the webcam so for the webcam we
75:20 - just want to run forever because it's
75:21 - just gonna
75:22 - is a real time until we tell it to stop
75:24 - so that's why we want a while loop
75:25 - running forever
75:26 - and then from here now we can actually
75:28 - go and fetch the current frame
75:30 - and display the current frame so um
75:33 - let's go down and get this so this is
75:37 - the next
75:39 - um call so this is actually how you
75:40 - would get the image out from the
75:42 - video you could technically run this
75:44 - outside the loop but then like i said it
75:45 - would only get the first frame and it's
75:47 - essentially just an image again
75:48 - which is kind of the same as what we did
75:50 - before so i'm just jumping into the loop
75:52 - so uh there is this
75:57 - webcam that we made okay from the video
75:58 - capture we called it webcam
76:00 - and webcam allows you to read from it so
76:03 - you just call the read function here and
76:05 - what this returns is two things
76:07 - uh tuples so the first thing it returns
76:09 - is if the
76:10 - reading the frame was successful or not
76:11 - this is just a boolean it'll be true or
76:13 - false
76:14 - and then this is the actual image so the
76:16 - frame
76:17 - that is being read currently from the
76:20 - from the the webcam uh this we actually
76:24 - don't need but we need
76:25 - we need to be there just to like for
76:26 - placeholder but we're never gonna use
76:27 - this this should always be true
76:29 - okay but this is all we want we just
76:31 - want the frame so once we have the frame
76:33 - now we can actually
76:36 - take the frame and instead of frame
76:39 - um use the frame instead of image so
76:41 - before we're using image with robert
76:43 - downey jr and everything and being
76:44 - causey
76:45 - and all that but now we just want to
76:46 - actually change the image to frame
76:48 - because this is the
76:49 - the image we're using it's the current
76:51 - frame so
76:53 - why don't we actually do that and
76:58 - let's comment this out
77:03 - and um just show
77:06 - the webcam in grayscale okay so we're
77:09 - not going to do any detecting yet
77:11 - let's take this
77:15 - paste that in here
77:19 - and show
77:22 - this okay
77:28 - remembered
77:31 - yeah so um the one thing about weight
77:34 - key is
77:35 - actually let me demonstrate it first and
77:37 - i think that'll be better so let me just
77:38 - run this and see what pops up
77:41 - i don't think anything's gonna there we
77:43 - go so as
77:44 - you can see this is just a single frame
77:46 - it's not moving because uh the wait key
77:48 - is
77:48 - is waiting on something and i got a
77:50 - little bit screwed up so actually what
77:51 - we need to do
77:52 - if i had an image though you can see it
77:54 - skips to the next frame
77:55 - so i can move around and then when i hit
77:57 - my space bar then it automatically goes
77:59 - to that frame because it's waiting for
78:00 - the key
78:01 - so one way to get um out of this i gotta
78:03 - force quit this because there's no way
78:04 - out of it
78:06 - forks quit force quit python
78:09 - there we go we are um going to put a
78:12 - delay in here
78:13 - so um wait key here if there's nothing
78:15 - in here it'll wait infinitely until you
78:17 - hit a key
78:17 - for it to quit or to go to the next
78:19 - frame like we did but if you put a
78:20 - number in here it'll wait
78:22 - this amount of milliseconds before it
78:23 - automatically hits a key for yourself so
78:25 - we can wait one millisecond then it'll
78:26 - auto hit a key
78:27 - which means each frame will be um
78:30 - happening every millisecond
78:31 - so let's try this all right and this
78:34 - should actually be live webcam footage
78:36 - um in grayscale from our webcam so as
78:40 - you can see it's just grayscale
78:41 - there's no face detection yet or
78:43 - anything i'm just doing this and then
78:44 - the wait key every millisecond is
78:46 - um it keeps just keeps pressing a key
78:48 - every millisecond already
78:50 - wait it so hold on one second so that's
78:53 - so sick that already has you in great
78:55 - scale in real time
78:56 - like from python i did not know you
78:58 - could do that that is so cool
79:00 - um and what are you saying about this
79:02 - one millisecond thing i'm not
79:03 - understanding it like what is it
79:04 - what is it doing it's a little no no no
79:06 - no just show your show your screen
79:09 - show your camera so like okay so what's
79:13 - happening like without it would it close
79:15 - would the window close no so wait key
79:18 - what weight key does in opencv the ways
79:20 - it's coded the way it's implemented is
79:23 - um it's going to wait for a key press to
79:25 - execute code so
79:26 - the code will just wait at wait key
79:28 - that's why it's called weight key it's
79:29 - waiting for a key to be pressed
79:30 - i'm just i'm just trying to understand
79:31 - in english like what happens if it's not
79:33 - there or you don't do it the right way
79:35 - like does the code
79:36 - break like does the video stop playing
79:38 - does the next
79:39 - frame not load like just in pure english
79:42 - like what is it that it actually does
79:46 - weight key um
79:52 - it's stuck if it's not there then it
79:54 - just won't work
79:56 - okay what's great is it's like
79:59 - like you need you need weight key to
80:00 - actually display something like you
80:02 - cannot just
80:02 - in opencv the way the way it's designed
80:05 - is you cannot display something if you
80:06 - don't call way key
80:07 - okay that's it that's all that's the
80:08 - most important thing i care about like
80:10 - if i just want to use this like all
80:12 - that's
80:13 - for me that's really important so okay
80:14 - so if i don't have weight it won't
80:15 - display
80:18 - it's not actually what it is but that's
80:20 - the behavior that okay
80:21 - beautiful beautiful got it okay so yeah
80:24 - because if it's not here then it'll just
80:25 - it won't work so let's quit this
80:28 - um again you gotta force quit we'll fix
80:31 - that in a bit you guys will be able to
80:32 - like hit the q button and it'll it'll
80:34 - it'll quit instead of having the force
80:35 - quit
80:37 - uh but here if i run this
80:40 - then i don't think it's gonna work it'll
80:43 - like pop up for a second or something
80:44 - and then disappear yes
80:46 - it just freezes up and there's nothing
80:48 - over here
80:50 - yeah so it gets there and then it gets
80:52 - stuck in an infinite loop so that's not
80:53 - a good idea
80:54 - nothing pops up you need weight key
80:56 - because you want it to wait here and
80:58 - you want to show a frame and then wait
80:59 - at that frame that's what you want
81:01 - got it okay uh so let's close see
81:05 - python not responding because if we're
81:06 - stuck in this infinite loop with no way
81:08 - to get out so
81:09 - it just just bugged out
81:13 - all right continuing on now so let's put
81:15 - this back you can think of it as display
81:17 - but what i was saying was if it's if
81:19 - there's nothing in here it'll wait
81:20 - forever
81:21 - and wait for you to actually press a
81:24 - button for it to continue to the next
81:25 - iteration of the loop
81:26 - so if you go back to the code this is a
81:27 - while loop right and it's going to run
81:29 - over and over and over again
81:31 - and each time it runs it's getting the
81:32 - current frame and then displaying it in
81:34 - grayscale to the screen
81:35 - okay it's getting it's turning at the
81:37 - grayscale and then displaying it with
81:38 - image show right here
81:39 - the current frame then it waits here
81:40 - forever until a key is pressed
81:43 - so that's why the behavior is weird it's
81:44 - frozen it's the current frame
81:46 - and then when i hit a key then it goes
81:48 - to the next iteration of the loop
81:50 - the next one next one and if i spam it
81:53 - then you can see that i'm kind of like
81:56 - moving but then if i stop then it breaks
81:59 - so
82:00 - what weight key does is it waits for a
82:02 - key infinitely but if you put a number
82:03 - in here then it'll only wait for that
82:04 - many milliseconds before it
82:06 - automatically
82:07 - just continues on and goes here so
82:08 - that's why we're saying then i don't
82:09 - have to press any buttons it'll wait for
82:11 - one millisecond then automatically go to
82:12 - the next iteration
82:13 - aka the next frame and so we're getting
82:15 - one frame every millisecond
82:18 - i mean i mean the the camera rate will
82:20 - be lower but that that's uh that's what
82:22 - it does
82:23 - so we'll quit out of this again one last
82:25 - time
82:26 - force quit this and
82:31 - run this to get the correct behavior
82:35 - and there we go so we're in real time
82:36 - every millisecond the loop is
82:38 - automatically restarting with the weight
82:39 - key because we put a one here you could
82:41 - even put like
82:42 - a thousand in here and then every 10
82:43 - seconds it would go
82:45 - automatically so but we'll leave it at
82:46 - one because we want to be real time
82:50 - now moving on from here we have the
82:51 - grayscale but now we want to plug in the
82:54 - face detection into this
82:55 - so just the same as before um we are
82:57 - going to want to take the
82:59 - detect uh detect faces and of course we
83:02 - want to apply it to the grayscaled
83:04 - frame so instead of
83:08 - just displaying the grayscale image we
83:10 - want to find the coordinates of that and
83:12 - then display it
83:13 - display um display over it so
83:17 - the grayscale image this is all the same
83:19 - code the face coordinates are
83:21 - going to be using the trained face data
83:23 - and then of course
83:24 - the detect multiscale and then we're
83:26 - giving it the grayscale image from right
83:27 - here
83:27 - just the same as the image then we need
83:30 - to draw the rectangle so this is the
83:31 - same thing again
83:32 - let's just steal this loop that we wrote
83:35 - earlier
83:38 - and pop it in right there
83:42 - and this should work as well so
83:45 - let's just double check image actually
83:48 - this won't work because image was the
83:50 - image before this actually needs to be
83:51 - frame
83:52 - instead okay and
83:56 - um i think that is it it's just the
83:59 - frame has to change so what we're doing
84:00 - is we're
84:01 - detecting oh i see it's pulling the
84:02 - frame just to be clear because i got
84:04 - confused at this i'm sure people are
84:06 - going to get sometimes confused
84:07 - it's pulling the frame from line 18 when
84:10 - webcam.read
84:11 - unpacks okay cool the the current frame
84:14 - of this loop every millisecond
84:16 - the current frame is called frame so you
84:19 - want to
84:20 - we want to detect the face in this frame
84:22 - grayscale
84:23 - and then we want to draw the rectangle
84:25 - on the frame
84:26 - not on the robert downey image that we
84:28 - had before but on the current
84:29 - frame of the webcam because we have
84:31 - webcam now
84:32 - so that's how that works now let's
84:36 - um just run this and see how it goes
84:39 - i think i think it's everything
84:43 - so of course you're going to need to
84:45 - force quit this again
84:49 - and go to terminal
84:56 - and why is it not working ah because i
84:59 - am displaying the grayscale image not
85:01 - the um colored
85:03 - colored one one second i must got a bug
85:05 - somewhere
85:10 - so yeah so the image show it's showing
85:12 - the grayscaled image what we want to
85:14 - show is actually frame
85:15 - okay because that's where that's the
85:18 - colored frame
85:19 - going back to color and then we color we
85:20 - put the rectangle on top of it so we
85:22 - want to display that instead of
85:23 - grayscale so now it should work
85:25 - but knowing my luck probably won't
85:28 - there we go and there's the rand range
85:31 - oh nice and the colors changing every
85:34 - second look at that that is so nice
85:37 - so you can so you can see that you can
85:39 - see the one million
85:40 - the one millisecond refresh rate that's
85:42 - actually pretty cool the color you can
85:43 - see like in real time yeah actually you
85:45 - can see
85:45 - every time so cool every time the loop
85:48 - uh
85:49 - iterates it's getting my face it's not
85:50 - perfect though because this is actually
85:52 - a pretty lean algorithm
85:54 - there's there's more powerful algorithms
85:55 - but of course there's always a trade-off
85:57 - of um speed and accuracy whenever you're
86:00 - doing algorithms
86:01 - for everything in like computer science
86:03 - and data science there's always multiple
86:04 - algorithms you can use to solve a
86:06 - problem
86:06 - this one we're using har cascade um
86:08 - specifically because this is the most
86:10 - commonly used one like this
86:11 - like on your little camera's digital
86:12 - cameras your iphone is probably using
86:14 - this
86:14 - that's so cool that we're you like we're
86:17 - looping through
86:18 - on your face and like drawing like
86:20 - looping through and making new colors
86:22 - like that is just the coolest thing
86:26 - and we're gonna have to force quit this
86:30 - wow okay
86:34 - and let's continue on so we can actually
86:36 - get rid of this stuff
86:39 - and keep code completed
86:43 - [Music]
86:48 - so
86:51 - uh oh i forgot one more thing so i i
86:54 - kept having the force quit which is
86:56 - pretty
86:56 - pretty dang annoying to be honest um so
86:59 - i threw in this thing
87:00 - uh earlier today of giving us the
87:03 - ability to oh we gotta clean up after
87:04 - two but
87:06 - of being able to actually quit using a
87:09 - key a specific key so did i copy the
87:12 - right one
87:14 - yeah this one
87:20 - so if i pop this in here um all this
87:22 - means is
87:23 - um oh first of all i screwed this up so
87:26 - actually when you're
87:27 - getting the wake key you can actually
87:28 - capture which key was pressed on the
87:29 - keyboard so it's waiting for a key
87:31 - and then you can actually get it so if
87:34 - if
87:34 - if if i don't press a key then this is
87:36 - probably like zero or null or something
87:38 - or none in in python um but if you press
87:42 - a key
87:42 - then it'll go into this so what i
87:46 - decided was i
87:47 - um if you press the q key then q for
87:50 - quit
87:50 - then it'll quit out so i looked up the
87:53 - ascii characters for
87:55 - q very simple you can just type in ascii
87:57 - if you didn't know
87:58 - every every keyboard character has its
88:01 - own ascii
88:02 - code ascii is just a sci i don't know
88:05 - what it actually stands for
88:06 - but every every letter has its own
88:08 - number so if you go to q you can see q
88:11 - is 113.
88:12 - lowercase q is 113. uppercase q is 81.
88:14 - so 113 and 81
88:16 - that's where i got these numbers from
88:17 - 113 and 81. so uppercase or lowercase q
88:20 - will actually break out of this infinite
88:23 - loop
88:23 - and that allows us to exit the
88:27 - real-time face detection without needing
88:28 - to force quit the way i was doing it all
88:30 - this time
88:31 - okay so let's give this a shot and see
88:34 - what happens
88:36 - run it and it's going good
88:39 - and let me hit the q key q
88:45 - are you connected q
88:49 - unless i had a bug let me um
88:54 - let me go double check
89:08 - what is wrong oh yeah i forgot the
89:11 - webcam release
89:12 - i always forgot these things uh good
89:14 - things like especially when you're doing
89:15 - um memory allocation or any any kind of
89:18 - like streams
89:19 - of data you should always clean up your
89:20 - code afterwards so
89:22 - in this case you're going to have to
89:23 - release so i think this might be the
89:25 - case
89:27 - um let me see the
89:32 - yeah let's try let's try it again
89:35 - there we go now let's hit q
89:44 - i think it's lagging i think it was
89:46 - actually working
89:48 - but it's just taking a long time to
89:50 - actually there we go
89:52 - okay so what's working i think i think
89:54 - the color maybe the random color was
89:56 - um doing some stuff uh
89:59 - i don't know it's just being laggy but
90:01 - pretty much it has the the working
90:02 - functionality i'm actually curious let
90:04 - me just try to
90:05 - change this and see if this is actually
90:06 - what is holding it up
90:12 - and let's run this again
90:15 - go here so it's just green back to what
90:17 - i had before and then hit q
90:23 - nope my computer is just slow i think
90:25 - it's just bogged down from the live
90:26 - streaming and everything at once i think
90:28 - that's why it's slow
90:32 - really slow anyways it'll close after a
90:34 - few seconds
90:35 - not important but let's change this back
90:37 - to the multi-colors because that was
90:39 - cool
90:40 - and um that there guys is pretty much
90:43 - the completed
90:46 - uh real-time face detector app okay uh
90:49 - we have the ability to
90:51 - detect faces in images to detect faces
90:54 - in webcam and even video so actually
90:56 - let's
90:57 - uh i have a video here um called
91:02 - lol memes that you guys have probably
91:06 - seen before and let's pop this in so
91:07 - instead of reading from the webcam
91:09 - we're going to be reading a a video file
91:12 - on my
91:12 - desktop so if you give it if you give it
91:15 - an argument
91:16 - of zero it reads it from your webcam but
91:18 - if you give it all
91:21 - and if you give it a name it actually
91:24 - looks for that file path
91:26 - it's just capturing video from somewhere
91:27 - you've got to tell it where to cap your
91:29 - video from awesome that's all it's doing
91:31 - so now let's try to run this and we can
91:34 - see
91:35 - it work whoa
91:38 - what is going on
91:43 - whoa that is crazy it's getting that guy
91:46 - a little bit
91:47 - now you can see it's not perfect i mean
91:50 - it's really difficult like this is a
91:51 - crazy video and it's already pulling it
91:53 - like that's insane
91:56 - wow i pulled this this video and you can
91:59 - see it's getting his face at the end
92:00 - there people are like wow it's amazing
92:02 - very nice
92:04 - awesome and then of course if you hit q
92:06 - it will quit
92:07 - and that one happened a lot faster can
92:09 - you oh i see
92:10 - okay interesting um i'm trying to think
92:13 - okay cool
92:14 - is there any other videos you have on
92:15 - your computer that it can
92:17 - pull from
92:20 - yeah i have this funny baby that i got
92:23 - okay
92:24 - let's see so yeah right there
92:27 - i was testing these earlier nice and
92:30 - there's no audio but here's another oh
92:33 - my god that is so
92:35 - cute that is so
92:39 - cute i love that i love that
92:42 - the dad is basically like tormenting the
92:44 - baby by making them say stuff
92:47 - but yeah logan says super impressive
92:51 - aaron
92:52 - logan's super impressive aaron thank you
92:54 - for the content
92:56 - absolutely we haven't even gotten to the
92:58 - interesting part yet this is the fun
92:59 - part but the interesting part is about
93:00 - to happen
93:02 - so this is working here again i'm going
93:04 - to try capital q this time
93:06 - and it should quit
93:14 - wow our loop is still working and going
93:16 - through the random colors
93:17 - i love that yeah i think i think we're
93:19 - giving the baby epilepsy that's what's
93:20 - happening here he's going crazy
93:23 - you know what you can even do is like
93:25 - like right next to it draw random
93:27 - captions like
93:28 - draw like random you know so like how
93:31 - have that
93:32 - people have that like speech thinking
93:33 - bubble next to them uh
93:36 - yeah something like that so we could
93:37 - even exactly so you can detect faces and
93:40 - automatically put like speech bubbles in
93:42 - real time next to it that like writes
93:44 - out text
93:45 - or or morty i think we could superimpose
93:48 - our i don't know i don't know about that
93:51 - rick
93:53 - yeah we're thinking doing that we're
93:55 - gonna superimpose rick and morty's faces
93:57 - over our faces but
93:58 - uh it was too hard to do that with the
94:00 - stream at the same time we couldn't
94:02 - technically figure it out the stream oh
94:04 - oh geez i mean i mean we could we could
94:07 - probably do that you guys
94:09 - you you would really you would really
94:10 - have to just let us know if that's
94:12 - something you're going to like
94:13 - i mean i mean you you can go ahead i
94:15 - mean oh
94:16 - geez just go ahead and smash that like
94:18 - button that that'll be so awesome
94:21 - yeah morty
94:25 - i didn't actually had a i didn't
94:26 - actually know you had a head on your
94:27 - shoulders morty but
94:28 - i'm proud of you today people are loving
94:32 - it they're like this is amazing they're
94:33 - like i wish i could code like this
94:35 - i still hate you morgan you piece of
94:37 -  logan is laughing
94:41 - yeah i love rick and morty man i love
94:43 - brick and morty
94:44 - yeah awesome anyways um
94:47 - that is that and that completes the app
94:50 - but now i mean this is a lot of hand
94:52 - wavy woo-woo stuff we just called this
94:54 - detect multi-scale and downloaded this
94:56 - file and it just kind of magically
94:58 - started detecting faces like cool like a
95:00 - five-year-old could have done this
95:01 - which is true but which is also awesome
95:04 - because i mean you got this up and
95:05 - running with like minimal work
95:06 - but i do want to give you guys
95:08 - understanding of how the algorithm is
95:09 - actually doing it
95:18 - but i do want to give you guys
95:19 - understanding of how the algorithm is
95:21 - actually doing it like how the heck
95:22 - is a computer looking at an image and
95:25 - how does it know what a face looks like
95:26 - and actually
95:27 - understand it so um that's
95:31 - where i want to actually go to here okay
95:35 - so let's just look at this for now i put
95:36 - together a little presentation
95:38 - um to actually transition people over
95:43 - into thinking like a data scientist
95:44 - because
95:45 - um most data scientists are coders but
95:47 - not all coders are data scientists like
95:49 - you can be a coder you can be a
95:50 - front-end developer
95:51 - which is amazing web developer and stuff
95:53 - but like if if you don't actually
95:54 - understand like some of the underlying
95:56 - algorithms and stuff you
95:57 - you can't actually pursue anything in
95:58 - data science if that's what you want to
95:59 - do and that's what python is known for
96:01 - so
96:01 - that's why i want to touch on it so um
96:04 - instead of being a coder and just like
96:05 - copy pasting what i just i taught you
96:07 - now
96:07 - you need to actually understand what's
96:10 - happening behind the scenes
96:11 - so that in all the little tricks that
96:12 - are happening so that you can actually
96:14 - innovate on that
96:15 - and continue forward and actually come
96:16 - up with like new and faster and better
96:18 - face detection down the road so but you
96:20 - got to understand the basics
96:21 - before so let's continue on okay
96:25 - um face detection so what the hell is
96:27 - har
96:28 - cascade that's the big question because
96:30 - if we go back to the code
96:32 - then um all this stuff was like hard
96:34 - cascade hard cascade what like what the
96:35 - heck
96:36 - is hard cascade why does it say har
96:37 - cascade and we just downloaded this
96:39 - thing
96:40 - um well this is just an algorithm okay
96:41 - so har is the name of a dude who
96:44 - invented the algorithm and cascade is
96:45 - just the word cascade so cascade is like
96:47 - a chain of events pretty much
96:48 - and you're just going down like you're
96:50 - going down a funnel so what it's doing
96:52 - is it's like it's going down a funnel
96:53 - until it finds a face at the bottom of
96:54 - the funnel and then it's like here's one
96:56 - face and it keeps doing it over and over
96:57 - again for every phase you're cascading
96:58 - down
96:59 - um that's the one paragraph explanation
97:02 - but let's actually go to one second and
97:04 - real quick uh if you want to cue me to
97:07 - show your face
97:07 - just you know just be like his you know
97:10 - camera one or something like that
97:11 - and i'll switch over to your face or you
97:12 - can just tell me so right now i'm i'm i
97:15 - have the camera on
97:16 - both of us so now when you're drawing
97:18 - like moving your hands physically it'll
97:20 - show
97:20 - and now i'll hit two and it'll go back
97:22 - to the screen got it
97:23 - yeah we'll just show me really quick
97:25 - while i'm explaining it so
97:27 - um like i was saying the hard cascade is
97:29 - just like a chain of
97:31 - machine learning things that that the
97:33 - image is being passed through
97:34 - and then it's going to funnel it down to
97:36 - until it finds the exact square where
97:38 - there
97:38 - where there's a face it kind of looks at
97:39 - like every square of every size on the
97:41 - image
97:42 - and it passes each of those squares
97:43 - through this machine learning thing
97:45 - and then it cascades down eventually
97:46 - it's like okay if you pass all of the
97:47 - cascades and you get to the bottom
97:49 - it's like okay this is close enough to a
97:50 - face to actually be considered a face
97:53 - and that's why it's called cascade
97:54 - horror is just a name you can kind of
97:56 - ignore that but
97:57 - hopefully this makes it seem a little
97:58 - less scary you can't understand but now
98:01 - it's time to reveal the magic trick
98:03 - of face detection okay it's pretty
98:04 - mind-blowing like honestly i wouldn't
98:06 - have been able to figure this out on my
98:07 - own like these geniuses did it but
98:09 - i learned it in my in my schooling at
98:12 - georgia tech when i took computer vision
98:13 - and i'm just gonna share it with you
98:15 - okay
98:16 - so yep time to reveal the magic trick uh
98:18 - don't be this guy
98:21 - um i have this gif here so it's actually
98:25 - it's actually pretty simple how it works
98:31 - and i want you to understand instead of
98:33 - being like this guy like how the hell
98:34 - does faces section work
98:35 - i want you to just know like how it
98:37 - works because it actually
98:38 - is this simple you can see it from the
98:40 - third one like once you understand
98:41 - it's that simple i love that that is
98:43 - awesome let's continue on
98:45 - yeah so as you know the algorithm is
98:47 - called har cascade so let's start with
98:49 - haar so what heart cascade does you can
98:52 - also by the way you can full screen this
98:54 - you can just hit command
98:55 - enter and it'll full screen it so
98:57 - everybody can see it in a better way
99:00 - and and you can actually use a pointer
99:02 - so at the bottom left click
99:03 - pointer and then when you actually move
99:05 - your mouse around like
99:07 - people you can yeah so it's easier to
99:09 - know what what you're talking about
99:12 - okay see i'm just i'm just a coder i
99:14 - don't know all this fancy google google
99:15 - side stuff
99:16 - but anyways so these are har features so
99:18 - this is the first
99:20 - part of the hard cascade algorithm it's
99:22 - a very very simple thing
99:24 - um what you can think of hard features
99:25 - as as rudimentary
99:27 - building blocks so this is a one heart
99:30 - feature this is another hard feature
99:31 - this is in the hard feature this is one
99:33 - and this is one
99:34 - all this really is is a little block so
99:37 - what we're going to be doing
99:38 - is we're going to be placing this over a
99:40 - portion
99:41 - of an image that has a face in it or it
99:43 - doesn't have a face in it
99:44 - and all it's doing is it's kind of
99:47 - showing the relationship from the white
99:49 - portion to the black portion
99:50 - and then what this allows us to do is it
99:52 - kind of allows us to
99:53 - approximate the relationship of these
99:56 - pixels within this box
99:57 - so if we overlay this over um somebody's
100:01 - face
100:02 - then we could be like okay um down here
100:04 - in relation to the pixels up here
100:06 - there's some kind of relationship
100:08 - and then um or or this way you could be
100:10 - like okay the pixels on the left have
100:11 - some kind of relationship to the pixels
100:12 - on the right
100:13 - or like this um you can do the three
100:16 - thing like okay there's there's a
100:17 - relationship
100:17 - a three-way here or um a diagonal and
100:19 - this is like the the most elementary
100:21 - ones that you don't have to go any
100:22 - bigger because you can just
100:23 - kind of chain them together but these
100:25 - starting blocks is what you start with
100:27 - and if you chain these together over and
100:29 - over again and you layer enough you can
100:30 - actually
100:31 - some combination of these five things
100:33 - will actually give you a template for a
100:35 - face it'll look like a face and then
100:37 - that's how they actually
100:38 - find faces by layering this over and
100:40 - over again and cascading all the way
100:41 - down these different layers
100:43 - um and then actually finding one that
100:44 - matches the face and though the way it
100:46 - does that is you give it faces
100:47 - so it finds out the combination of these
100:49 - things to know what a face is and then
100:51 - you can just filter through it again
100:52 - so that's kind of the um the idea of of
100:56 - heart features so far so these are hard
100:57 - features and uh let's continue on to the
101:00 - next slide i think i'll make more sense
101:01 - when i show this one
101:02 - so this is how a hard feature is applied
101:04 - to an image
101:05 - so like these let's say these are blank
101:07 - images or background images i have no
101:08 - faces in them
101:09 - um one heart feature is here and um
101:12 - here's another one different a different
101:14 - type
101:14 - where it has three um three columns
101:16 - another one is here
101:18 - and as you can see this is uh how you
101:20 - would overlay it on an image so this is
101:22 - the raw image but then if you have the
101:23 - heart
101:24 - the heart feature here what we're
101:25 - looking for here is oh the relationship
101:27 - of this
101:28 - black box to this white box and um
101:32 - what's cool is if you look on this face
101:33 - here you can kind of tell that this
101:35 - rectangle here of his eyes
101:37 - is a little bit darker than his cheeks
101:39 - and his nose and you see how that
101:40 - corresponds to the black and the white
101:42 - here
101:42 - so we can actually say that this heart
101:44 - feature is closer to a face
101:46 - than something else like placing this
101:48 - like all the way on the bottom left
101:49 - where it's kind of like not
101:51 - because there's kind of like a black bar
101:52 - here in the white part here so white
101:54 - so the white one means that that is more
101:56 - like a face and then the black
101:58 - the area that's black is like that's
101:59 - less like a face the
102:01 - the black is like you can think of it as
102:03 - like it being darker and the white is it
102:05 - being lighter so you're saying that
102:06 - there's some kind of like going from
102:07 - light to dark
102:08 - in this direction or dark to light to
102:10 - dark in this direction
102:11 - so oh wow so like the electric so like
102:15 - bar going to a light bar you see right
102:17 - here is exactly what this okay so
102:18 - one second so i'm so basically the face
102:21 - detection it's
102:22 - literally it doesn't look for facial
102:24 - features it's just looking for like
102:25 - how dark and light it usually is around
102:28 - faces
102:29 - and that's why you only need greyscale
102:31 - crap that is well this is this is only
102:33 - one algorithm there's like
102:34 - there's a bunch of different ones but
102:36 - this is the most well known and most
102:38 - widely used like literally just looking
102:40 - at
102:40 - so for this one specifically it's just
102:42 - looking at like yo
102:43 - here are 100 different faces you'll
102:45 - frank you bring your face in real quick
102:47 - so like it's like it'll like have like a
102:50 - certain thing for like dark
102:51 - and light for his face versus a dark and
102:54 - light
102:57 - yeah so then it's just looking for white
102:59 - and black like okay
103:00 - okay cool like if you if we went back
103:02 - like this would even be a better match
103:04 - because you have
103:04 - forehead then eyes then cheeks you see
103:07 - what i mean if we had that here you
103:08 - could also have a white bar up here
103:10 - you can kind of see it's like white then
103:11 - dark than white so we're basically
103:13 - saying there's some kind of
103:15 - three layered relationship of this block
103:17 - of pixels
103:18 - and this is only one layer of hard
103:20 - cascades basically we're going to layer
103:22 - a thousand of these little matches
103:24 - together and eventually those added up
103:25 - will add
103:26 - add up to a face wow you can see the
103:28 - second one here you can kind of see like
103:30 - okay the eyes are darker and the bridge
103:31 - of the nose is lighter
103:32 - see the eyes are dark and the bridge of
103:34 - the nose is darker so this heart feature
103:36 - plus
103:37 - this heart feature is even closer to
103:38 - what the heck of faces yeah this is what
103:40 - this is what logan is saying he's like
103:42 - ah he goes this is why we use
103:44 - grayscale right aaron and he goes
103:46 - because color is irrelevant
103:48 - we're actually just looking for
103:49 - brightness yes exactly well you can you
103:52 - can start using color when you want to
103:54 - get like really like if you want to like
103:55 - profile like race or skin color or if
103:58 - somebody has freckles or not you could
104:00 - even start doing that if but it would of
104:02 - course you would need more data
104:03 - and longer time to train but this is the
104:04 - most generic case but i want to teach
104:07 - you guys from the ground up so that you
104:08 - understand
104:09 - how this works because this is the
104:10 - prerequisite to everything else okay
104:12 - yeah um so this is how a hard feature is
104:15 - applied to an image
104:16 - and of course you would just take this
104:17 - box and you just drag it all the way
104:18 - around the image you would even resize
104:20 - it
104:20 - like um because again you could have
104:22 - like this similar thing
104:24 - might be like it might match on the
104:25 - mouth a little bit but let's move on
104:27 - okay
104:28 - so these are hard features these are the
104:29 - five rudimentary heart
104:31 - har features and this is how hard
104:33 - features are applied to an image
104:35 - and if it's like this then there's no
104:36 - match you know there's like it's just a
104:37 - white but
104:38 - like flat background or if it was like a
104:40 - landscape or like
104:41 - your wall or something then there's
104:43 - gonna probably be nothing there
104:45 - um but let's go on there's a little bit
104:46 - more nuances but that's the general idea
104:48 - so far
104:49 - so now actually how did opencv
104:52 - train that face detector that we
104:54 - downloaded that xml file because that's
104:56 - where the magic is we just called we
104:57 - just downloaded it and just like called
104:59 - a few lines of code which is kind of
105:00 - like okay cool
105:01 - but how do they actually do it because
105:03 - from here if you understand it
105:04 - then you can actually start thinking
105:06 - correctly and do some real data science
105:08 - stuff like you're not a data scientist
105:09 - unless you actually understand the
105:10 - algorithms
105:11 - so step one like we mentioned the very
105:14 - beginning of the call
105:14 - you want to start out with your training
105:16 - data so in machine learning the
105:18 - the way it works is you have positive
105:20 - images and negative images
105:21 - and all these are are just labels so
105:23 - this would be labeled as face label as
105:25 - face labeled as face
105:26 - this would be labeled as not face not
105:28 - face not face that's all it is you just
105:30 - need
105:30 - faces labeled as faces so just to
105:32 - contrast just to
105:33 - just to contrast that guys so here is a
105:36 - face
105:37 - right but here is like this would be a
105:40 - negative
105:41 - image right a phone would be a non-face
105:44 - so like it's not a face so again
105:46 - non-face is happy
105:48 - cup of coffee this is a non-face when it
105:50 - sees it
105:51 - this is a face when it sees it right and
105:53 - this was through supervised learning so
105:55 - it fed the data to the hurricane cascade
105:58 - right and it told it yo
105:59 - these are all faces and these are all
106:02 - non-faces
106:02 - yeah so this is yeah yeah so this is
106:05 - called supervised learning we're
106:07 - probably not going to go too much into
106:08 - unsupervised supervised but like at a
106:10 - high level
106:11 - it's like a human being's telling it
106:13 - what is a face and what
106:14 - isn't and then feeding it like lots and
106:17 - lots of data
106:19 - yeah uh another way maybe another way to
106:21 - explain if somebody didn't catch that is
106:23 - there's two fields of machine learning
106:24 - there's supervised machine learning and
106:26 - unsupervised machine learning which is
106:28 - what causes just said
106:29 - supervised means you know these are all
106:31 - faces and you know these are all
106:33 - non-faces it's supervised you're
106:34 - supervising the actual data and you can
106:36 - tell it like these are faces
106:38 - okay that's what it faces these are not
106:39 - phases okay that's not what
106:41 - a face not is um but if you're doing
106:44 - unsupervised you're literally just given
106:46 - a bunch of stuff and you have no labels
106:49 - and then you can just at the end be like
106:50 - oh was it right or wrong so you have
106:52 - even less data
106:54 - but that also is a lot better because
106:56 - when you're
106:57 - gathering photos from the real world or
106:58 - data from the real world
107:00 - usually it's not labeled you'd have to
107:02 - go in there and manually label it by
107:03 - human
107:04 - because how else would you know these
107:05 - are faces so there's kind of two fields
107:07 - of thought
107:08 - supervised is better to learn first but
107:09 - unsupervised gets very very
107:11 - messy and just kind of like the cutting
107:13 - edge right now yeah
107:14 - yeah that's where like you really get
107:16 - into ai and all that like
107:17 - deep deep neural nets and all that stuff
107:19 - deep deep girl nets
107:21 - awesome this is just yeah machine
107:22 - learning so uh star one start out with
107:25 - training your data so you have a bunch
107:26 - of labeled images
107:27 - and from here you'll go to um
107:31 - the next thing so after you have all of
107:34 - your images so you have face images
107:36 - and then also non-face images
107:40 - you want to find um the winning har
107:43 - features so like i said
107:44 - this heart feature matches nicely with
107:46 - the eyes and the cheek and then even if
107:47 - we had like
107:48 - the other heart feature with the with
107:49 - the lighter bar on the forehead that
107:50 - would even be a better match
107:52 - but for this one is we're just using
107:53 - this this is a fairly good match
107:55 - and this one is also a good match okay
107:56 - so basically what we want to do is we
107:58 - just want to chain together all the hard
107:59 - features that kind of match
108:00 - and add them together sum them up until
108:03 - we get a face template
108:04 - these are like little lego blocks to
108:05 - like doing it and this is why it works
108:07 - for nothing because they're rudimentary
108:08 - building blocks
108:09 - this can work for a coca-cola can you
108:11 - can distinguish a coca-cola can from a
108:12 - pepsi can
108:13 - eventually because it looks different
108:15 - and like the the brightness and
108:17 - the brightness relationships within
108:18 - these boxes and sizes of boxes
108:20 - is all different that's why there's you
108:22 - just start with like plain old boxes and
108:24 - you add them up
108:25 - i have insane that you can tell the
108:27 - difference of
108:28 - everything based on brightness like this
108:31 - is where algorithms are
108:32 - so freaking cool because i mean it's
108:34 - what your brain is doing right like what
108:35 - is your brain doing it's doing the exact
108:37 - same thing
108:37 - it recognizes a face versus not a face
108:40 - and we're just teaching the computer how
108:42 - to do the same thing
108:43 - dang damn so it blows your like
108:45 - self-driving cars this is
108:47 - this is absolutely like essential like
108:49 - tesla you know tesla stock is going up
108:50 - like crazy elon musk just passed warren
108:52 - buffett
108:53 - and his net worth as of like three days
108:54 - ago like go elon are you serious
108:56 - protect yeah he's 70 billion warren
108:58 - buffett is 69 billion whoa
109:01 - but he's now elon musk is now number
109:02 - seven in the world
109:04 - he's exploding bro but um but yeah the
109:07 - tesla self-driving cars they use this
109:09 - heavily
109:10 - um it like with other things but there's
109:12 - a lot of computer vision
109:13 - so like you could like um you could
109:15 - detect pedestrians
109:16 - whoa i am showing that on my screen
109:19 - using the same heart function
109:21 - that is insane i just um i have an ad
109:23 - blocker on so i have to turn that off
109:25 - real quick but um i'm just showing them
109:28 - on the screen that elon musk actually
109:31 - passed
109:31 - oh my god is this website annoying holy
109:34 - crap
109:35 - jesus christ okay i'm out of here
109:38 - they can they can keep their we don't
109:41 - need to look at that
109:42 - business insider yeah elon musk just
109:45 - passed them officially that is insane
109:47 - yeah elon musk is my guy man like
109:50 - daniel works at blue origin right that's
109:52 - like the competitor of elon musk's
109:53 - spacex
109:55 - well we have a guy here a programmer who
109:56 - works at a competitor jeff
109:58 - yeah he worked for jeff bezos company
110:00 - and he works on an actual rocket ship at
110:02 - clever he's gonna actually be here next
110:04 - week
110:04 - and he's gonna be teaching everybody
110:06 - algorithms and maybe even some
110:07 - stuff with python yeah he makes me look
110:09 - like a baby
110:11 - yeah awesome so keep going but yes so
110:13 - after we have all of the images
110:15 - the face images and the non-face images
110:17 - we want to find the winning heart
110:19 - feature so which har features
110:21 - um align with a face and then on the
110:24 - reverse for non
110:24 - feet um for non um non-hard features we
110:28 - want to see which
110:29 - heart features don't match so like
110:30 - you're doing the reverse you want to
110:31 - make you want to find heart features
110:33 - that like
110:33 - do the anti-match and then eventually if
110:35 - you do enough reps
110:36 - then you can kind of understand the
110:38 - heart feature that determines the face
110:39 - versus not a face
110:41 - so this is how it works so we have
110:44 - if we go back to this you have a bunch
110:48 - of faces and a bunch of non-faces so the
110:50 - way the algorithm actually works is i'm
110:51 - actually going to come out of here
110:53 - for now and can i zoom in no this is big
110:56 - enough though
110:57 - so we have to test every heart feature
111:00 - okay that's pretty much it
111:01 - there's only five but of course we can
111:03 - scale the size so what we want to do
111:05 - is you literally want to start here and
111:07 - check
111:08 - check check check check check and then
111:10 - go down
111:11 - check check check check check of course
111:13 - and do this across the entire thing
111:16 - and then again do it with a smaller one
111:18 - check check check check check blah blah
111:20 - blah
111:20 - and then go to the second heart feature
111:22 - and the third the fourth and fifth
111:24 - and you keep doing this on every single
111:26 - image until
111:27 - you can find which ones actually match
111:29 - your face so
111:31 - after um yeah every like i said every
111:34 - type of heart feature every size of our
111:36 - feature
111:36 - and every location cause you there's a
111:38 - lot of background noise my bad
111:42 - there's a um and every location of every
111:45 - image
111:45 - okay and each heart feature after it
111:48 - goes through the whole thing it'll give
111:49 - you a number
111:50 - and um this number tells you whether
111:53 - it is a face or not a face like what
111:55 - this heart feature will say so after
111:56 - this heart feature
111:58 - goes through this entire image okay or
112:00 - let's make a little bit bigger
112:02 - like there so this is this is the good
112:03 - matching one so after this goes through
112:05 - the entire image
112:07 - um each of these spots it's going to get
112:10 - a number so
112:11 - um the way it does this number is it
112:13 - takes all the pixels in the black
112:15 - and adds them up to one number then
112:17 - takes all the pixels in the white
112:19 - this box adds them up into one number
112:21 - again grayscale is useful because we
112:22 - only have to deal with one number
112:23 - instead of rgb
112:25 - and from there um you have a white
112:27 - number and a black number then you just
112:29 - minus them to get the difference like
112:30 - how far away are these numbers from each
112:31 - other like if this was
112:33 - if this was 0 and this was 100 then the
112:35 - difference would be 100 or this was 20
112:37 - this was 70
112:38 - the difference would be 50 they're 50
112:40 - apart from each other so this would be a
112:41 - 50
112:42 - and we could say okay this match is 50.
112:44 - so this
112:45 - this horror feature in this location on
112:46 - this image has the number 50
112:48 - and then we give it a threshold of
112:50 - saying okay if if it's
112:52 - 50 or higher say it matches good for a
112:55 - face
112:56 - if it's 50 or lower then say it's not
112:58 - good for a face
112:59 - and so that's what we do so you say okay
113:01 - this hard feature goes all the way
113:02 - through
113:03 - and here and then at the end it gets a
113:05 - it gets a final number for itself
113:07 - and you and then you can say at the end
113:08 - of this you're like okay this hard
113:09 - feature in this location
113:10 - was really good let's keep this okay
113:13 - this is level one this was the best
113:14 - performing par feature
113:16 - um let's keep this because it was the
113:17 - highest like maybe it was like like
113:19 - closer to 100 or something
113:21 - and then um after you do that that was
113:24 - just one heart feature on one image
113:25 - you'd have to do this on every single
113:26 - image
113:27 - to um find it because it would also find
113:30 - the same kind of
113:31 - pattern on other people's faces because
113:32 - you know their eyes are going to be dark
113:33 - and their cheeks are going to be light
113:34 - too
113:35 - because that's what a face is and then
113:37 - after that you could be like okay this
113:39 - this is the winner
113:40 - that's cascade one that's level one so
113:44 - whichever heart feature matches the
113:45 - training images closest is our first
113:47 - winner
113:47 - so if you go back here um it matched
113:49 - this one like her eyes are darker than
113:51 - her cheeks and you can say okay that's a
113:53 - match that's the first winner
113:54 - then we would go to the second one and
113:56 - go here and
113:58 - and then see that this is another good
114:00 - match because the light nose plus the
114:01 - dark eyes
114:02 - and um we would do that too but of
114:04 - course you would have to iterate through
114:05 - the whole thing
114:06 - and then of course all the different
114:08 - sizes too you'd even go like tiny
114:10 - on every single image and all the
114:11 - background images too but that's how
114:13 - that works and eventually at the end
114:14 - because
114:14 - if you take this black segment add it to
114:18 - this black segment and then subtract it
114:19 - from this white segment you get a number
114:21 - at the end again and then if it's above
114:22 - 50
114:23 - or closer to 100 that's the idea then
114:25 - you can say okay this is a pretty good
114:26 - match
114:27 - versus here where it would be like not a
114:29 - very good match
114:30 - and you just do this over and over again
114:32 - and you want to get like a thousand
114:33 - hearts
114:34 - harf on features that match right now
114:35 - we're only looking at two but you want
114:37 - to do this over and over again that's
114:38 - why computer's so powerful
114:39 - and that's how you actually train the
114:41 - cascade object detector or in our case
114:44 - the face detector but you can detect any
114:45 - object
114:46 - depending on this on the on the training
114:49 - data so
114:51 - that's how that works you have to test
114:52 - every cart um har feature
114:54 - and then after that after you've gotten
114:56 - a thousand winner har features
114:58 - you can take that and then put it all
115:00 - together into a big
115:02 - um machine learning algorithm for face
115:04 - detection so that's what this diagram
115:05 - here is
115:06 - so step three this is the cascade which
115:08 - is just the chain of heart features a
115:09 - chain of heart features this was the
115:11 - first best match this was second best
115:13 - third best fourth best all the up to a
115:14 - thousand a thousandth
115:16 - best and you would go through an order
115:19 - and if a picture passes all a thousand
115:21 - then you can definitively say hey
115:22 - this is a face if it only passes 900 it
115:25 - doesn't get to a thousand you'd be like
115:26 - ah it's not good enough to be a face
115:28 - so that's the kind of the the mark there
115:29 - that's how that would work so you take
115:31 - all the images
115:32 - that are faces all the images that are
115:34 - not faces
115:35 - um then you train it with uh these hard
115:38 - features you find the one thousand
115:40 - one or it can be any number is you can
115:42 - kind of decide like when it's close
115:43 - enough
115:44 - but you choose let's just say a thousand
115:45 - winner heart features in order
115:47 - and then we can chain them together into
115:48 - our face detector which is called a
115:49 - cascade classifier because you cascade
115:51 - from stage one
115:52 - to stage two to stage three all the way
115:54 - down to stage 1000
115:55 - and then that is stored as an xml file
115:58 - which is exactly the data that is stored
116:00 - in here
116:01 - so in here it probably has a thousand of
116:03 - these little things so this here
116:04 - is one heart feature could be one heart
116:07 - feature like from this tag to this tag
116:09 - is one single heart feature that's the
116:11 - idea okay and then all these numbers are
116:14 - actually the heart feature we're looking
116:15 - at has the the brightness and the color
116:17 - and the location and the size of it
116:19 - and um you would go through and then of
116:21 - course there's like a thousand so you
116:23 - just fish the
116:24 - the image through here and then it looks
116:26 - for every single
116:28 - um thing in the image until it finds
116:30 - faces so that's why it's called a
116:31 - cascade classifier you or a hard cascade
116:33 - because using hard figures
116:35 - and then you're cascading down all the
116:36 - matches hard figures until you find a
116:38 - face
116:39 - okay so that's the explanation of how it
116:41 - actually works
116:43 - one final thing i want to um do is uh
116:46 - the way it actually will actually
116:48 - continue on in the slides
116:49 - can you full screen it please yeah
116:53 - so the nice thing about that is opencv
116:55 - does the hard work for
116:56 - us okay um opencv provides all the
116:59 - pre-trained classifier
117:00 - um data that has the chain of heart
117:03 - features that best match the frontal
117:04 - face
117:05 - which is exactly what we downloaded
117:06 - remember when we were at the github i
117:08 - said download har cascade frontal face
117:10 - default
117:11 - they have all of that data for us they
117:13 - trained it already and they have that
117:14 - data
117:15 - um and then from there then after uh
117:18 - it's classified we can just pass a
117:19 - sliding window so a sliding window is
117:21 - just a window over the
117:23 - image or the current frame or whatever
117:25 - into the and pump it into this
117:26 - classifier and run it through all 1000
117:29 - hard cascades and if it makes it
117:30 - past all 1000 it's a face if it only
117:33 - gets to 999
117:34 - it's not a face that's the threshold and
117:37 - so yeah if it gets all the way to the
117:38 - end it's
117:38 - a face but if it doesn't then it's not
117:40 - so that's why it's called a cascade
117:41 - because you're like funneling down
117:43 - into what a face actually is
117:46 - uh one last thing let me just explain
117:48 - how that actually works so
117:49 - what you what we would be doing is you
117:51 - would have a have like a sliding window
117:54 - so you would have
117:55 - or let me make this full screen or
117:57 - actually i can actually just add a
118:00 - square can't i shape
118:06 - nice so let's just say we have a square
118:09 - here a question by evil
118:10 - namekian he said is it possible to use
118:13 - face detection
118:14 - into a flask application absolutely
118:18 - yeah i've never done it personally but i
118:22 - mean
118:23 - yeah you can you can tie you can tie
118:24 - this into web development
118:26 - you can take this and then you can
118:28 - somehow call the opencv code in your
118:29 - flask application
118:31 - um i mean you would like you could use
118:34 - flask like house something or
118:35 - house a web page but you would need some
118:37 - way to get the
118:38 - um opencv code running on your flask but
118:41 - it's definitely possible
118:43 - django might be better but flash might
118:44 - be cleaner but look into it but it's
118:46 - definitely possible
118:47 - just got it beautiful check it out
118:49 - that's homework for you but uh the way
118:51 - this works is you would take this little
118:52 - square
118:53 - pass it through all a thousand hearts
118:55 - it's like oh no this is not a face
118:56 - not a face not a face not a face not a
118:58 - face not a face and this is so tiny this
119:00 - would be not a face the entire time
119:02 - and eventually then you would check a
119:03 - little bit bigger not a face not if it's
119:05 - not if it's not a face
119:06 - but eventually when you got this big
119:08 - you'd be like okay not a face not a face
119:10 - match is 900 um blah blah blah
119:14 - matches nine um 950 not quite a thousand
119:17 - yet matches 950 but 950 boom
119:19 - and then boom it matches a thousand and
119:21 - then that's when you get the face so
119:22 - that's how it would work and then it
119:23 - says ding ding ding that's a face
119:25 - and if there's multiple faces then it'll
119:26 - find all of them in the current frame
119:28 - and that's kind of the full algorithm of
119:30 - how the face detection actually
119:32 - works in practice and actually like
119:34 - threw it through with the method numbers
119:37 - okay so now i want to show you the
119:39 - romano
119:40 - one interesting thing romano says you
119:41 - can adjust the sensitivity of face
119:43 - detection
119:44 - and he basically says that that phase
119:47 - classifier detect multi-scale thing you
119:49 - have
119:50 - the last argument is actually for
119:52 - sensitivity
119:53 - so you can actually yeah change the
119:55 - scent sensitivity you're looking for
119:58 - yeah you can go here detect multi-scale
120:00 - so you will have all of these parameters
120:02 - you can do um min neighbors scale factor
120:05 - so you can say like okay
120:06 - how many faces can be close to each
120:08 - other like do the faces have to be
120:10 - far away you know how we're getting
120:11 - random little squares here and there you
120:12 - can say oh if there's a little square
120:13 - next to a big square
120:15 - um prioritize that big score and just
120:17 - omit those little squares to kind of
120:18 - clean it up so you can kind of
120:20 - fine-tune it um that's the nature of
120:21 - algorithms you want to fine-tune things
120:24 - until they're working nicely
120:26 - but you just want to get it really close
120:27 - to working effectively and of course
120:29 - there's always a trade-off of speed and
120:30 - accuracy that's always the case that's
120:32 - just how the universe works
120:33 - um there's always going to be that
120:34 - trade-off so but yes you're correct go
120:37 - check it out you can play with all of
120:39 - these
120:39 - um things like scale factor is one by
120:41 - one by 1.1 by default midnight versus
120:43 - three and it explains what all these
120:45 - things do
120:46 - and there's even other things like set
120:47 - image that i didn't go over there's a
120:49 - bunch i mean
120:50 - it would take forever to go over
120:51 - everything but definitely look at the
120:53 - documentation for opencv
120:55 - but good catch that that that is correct
120:58 - uh
120:58 - now let's go to this
121:04 - um video so this is actually hard code
121:07 - visualization happening
121:09 - live so everything i just explained and
121:11 - everything we just coded this is what's
121:12 - happening after the har code is trained
121:15 - um this is actually how the algorithm
121:17 - goes forward okay
121:18 - so let's start here we have a lady here
121:21 - and as you can see like i said though
121:22 - the window
121:23 - will go across right and as you can see
121:26 - whenever
121:27 - the red the current red red square will
121:30 - run
121:30 - a bunch it through a bunch of har
121:32 - features so
121:33 - you can see it's spamming a bunch and
121:35 - it's saying okay all those a thousand
121:37 - heart features within this red square
121:38 - did this red square pass through all
121:40 - those hard features yes or no
121:41 - and it's saying no no no because it's
121:43 - not the face obviously the face is down
121:45 - here
121:45 - so it's saying okay is this box's face
121:47 - no is this face no is this a face no is
121:49 - this a face no by running through all
121:51 - these crazy hard features
121:52 - for each of these red boxes that's why
121:54 - it's going so freaking fast
121:55 - and it'll keep doing this um at for
121:58 - every
121:59 - for every face at every size until it
122:01 - finds the face so let's just speed this
122:03 - up
122:05 - and um we're getting close
122:08 - so as you can see the stage let's see it
122:10 - says 100 match here
122:12 - features 16 of 135 it's matching there's
122:14 - 135 instead of a thousand
122:16 - in this case and you can see that this
122:18 - is what makes up a face you can see the
122:20 - match is pretty close
122:22 - oh there's 22 stages so see how it's
122:24 - seeing seeing these red squares are a
122:26 - match
122:27 - and then at the end it probably averages
122:28 - all those red scares and
122:30 - the red squares to find the actual face
122:32 - and that's where those tweaking things
122:33 - that's where those tweaking those
122:35 - tweaking numbers come into play because
122:37 - you can be like okay if all these
122:38 - squares are so close together you can
122:40 - kind of approximate and just
122:41 - make it one square instead of six faces
122:43 - that's the same phase just be like math
122:45 - this is just one face with a bunch of
122:46 - square matches damn
122:49 - so this is cool it happening in real
122:51 - time and of course if it's multiple
122:52 - faces then it'll catch all of us
122:54 - people want to go people want to see the
122:56 - video they're like can you share the
122:57 - link of the video maybe you can just uh
122:58 - uh
123:00 - show us our description yeah just um
123:02 - just
123:03 - no but hit just hit escape for now so
123:05 - you can show the url
123:06 - and hold on give me one second just show
123:08 - the url and so you guys can pause
123:10 - search this up anchor divi car
123:13 - visualization yeah there you go and you
123:15 - guys can also just type in the url at
123:18 - the top there you go
123:24 - and that's that's really it you guys so
123:26 - that's the entire algorithm you guys
123:28 - coded it up you guys followed along with
123:29 - how it actually works mathematically why
123:31 - it works
123:32 - and how effective it works and the
123:34 - efficiency and all that
123:36 - and the trade-offs and then also the
123:38 - extensions of it like you could do
123:39 - um actually start like recognizing
123:41 - people like we could distinguish like
123:43 - jeff bezos from elon musk
123:44 - or you could distinguish from coke cans
123:48 - and stuff like that if you
123:49 - if you do it enough depends how much you
123:51 - want to train the data
123:52 - um i mean train the algorithm how much
123:54 - data you want to do it but as you can
123:55 - see this is getting pretty
123:57 - see how it got bigger the red square is
123:58 - getting bigger because it's a sliding
124:00 - window algorithm
124:01 - which is how most of like self-driving
124:02 - cars same stuff it's very very similar
124:04 - kind of idea
124:06 - and that's really it you guys so it's
124:09 - getting close to the end here and boom
124:11 - there at the end it got all the boxes
124:13 - and it approximated that that is the
124:15 - face
124:16 - um in the huge i love that that
124:19 - all of that is happening in literally
124:22 - milliseconds like that to me is insane
124:25 - can you open up the webcam again like i
124:27 - want to just see it happening in real
124:29 - time
124:29 - that is crazy yeah i did omit one
124:33 - optimization
124:34 - so um i didn't get into the nitty gritty
124:36 - math i'm just explaining the general
124:38 - idea because the math is really simple
124:39 - once you like if you know one plus one
124:41 - you'll understand the math i just didn't
124:42 - bother because it would
124:43 - it gets really in-depth if you want to
124:45 - read it you can read the paper
124:46 - i'll link that in the description too
124:48 - but let's go back to the to the code and
124:50 - then you can actually
124:51 - see it happening with the um
124:56 - camp for this one so you might have to
124:58 - go at the top and change the mp
125:00 - uh for ah yeah yeah you're right you're
125:04 - right
125:07 - zero save that
125:10 - and run this and get that going
125:16 - and quasi text me a picture um text me a
125:19 - picture
125:20 - there we go to my phone to my phone
125:21 - because i'm going to pull up my phone
125:22 - i'm going to hold it up
125:25 - uh send you is it the webcam oh i see
125:28 - okay i'll send it to your slack right
125:30 - now
125:32 - got it okay cool so it's working in real
125:35 - time
125:36 - every single frame it's doing the
125:37 - sliding window thing all the way across
125:39 - the entire thing
125:40 - and it's doing it's doing the entire har
125:42 - cascade of all the har features that it
125:44 - was trained to
125:45 - within each of these squares until it
125:47 - finds this square at this size and finds
125:49 - my face and it's doing that
125:50 - in real time just because the computer
125:52 - is so dang fast
125:55 - so all right about okay
125:58 - i'm having trouble actually i got
126:00 - different ones so we can actually
126:03 - so real time we can oh wow my face and
126:06 - all of my faces
126:08 - it's kind of not getting cozy but see
126:11 - there we go
126:12 - it got me i want to close yeah dude it
126:15 - is
126:16 - looping through in real time that is
126:18 - insane it is literally
126:19 - looping through in real time every frame
126:22 - every size square
126:23 - across the entire image with all the
126:25 - thousands of heart functions
126:26 - and it's just like number crunching you
126:28 - know fast enough that's all it is
126:30 - wow it's really it's really cool and you
126:33 - get an appreciation once you understand
126:35 - how it works aaron this is how we gotta
126:37 - demo it next time we gotta just have
126:38 - like you holding like three phones
126:40 - one with your foot and then just like
126:43 - showing the three phones in your face at
126:44 - the same time that's like mind-blowing
126:46 - one issue is going sideways doesn't work
126:49 - so it's not super robust
126:51 - but you can do that there's also side
126:52 - profile like there's different
126:54 - like this looks different than a frontal
126:55 - but you could like get your
126:57 - you could combine a frontal um machine
127:00 - learning algorithm
127:01 - with a with a side you can be like oh if
127:04 - it matches either of them
127:06 - then detect it you know then you can be
127:07 - like okay this or even a back hit you
127:10 - could even be like okay if it matches
127:11 - any
127:12 - like any anything and of course like
127:14 - different hairstyles mine might be
127:15 - different than a girl
127:16 - or a bald guy um but i mean eventually
127:20 - you could
127:20 - you could really detect anything and
127:22 - damn that's really it you guys
127:24 - face detection with open cv and python
127:27 - with the entire theory and math behind
127:29 - it so you guys understand it through and
127:30 - through
127:31 - uh hope hope you guys had your curiosity
127:35 - spiked and maybe you're inspired to go
127:37 - learn how to do self-driving cars and
127:38 - work at tesla
127:39 - because that's what i want to do that is
127:43 - so exciting
127:43 - that was awesome dude thank you so much
127:46 - for that demonstration
127:47 - guys if you enjoyed this so far you know
127:50 - first of all drop it in the comments and
127:52 - like
127:53 - let us know if you enjoyed this and also
127:56 - go ahead and smash that like button
127:58 - because if you enjoyed this
127:59 - chances are somebody else will get value
128:01 - out of it somebody else will also enjoy
128:03 - it
128:04 - all you gotta do is smash that like
128:05 - button to get this video out
128:07 - as many people as possible and if you
128:10 - haven't already subscribed to the
128:11 - channel
128:12 - yup awesome i think that's it guys thank
128:14 - you hopefully this gave you value
128:16 - uh and taught you guys something new
128:18 - this was a mind-blowing experience for
128:20 - me hopefully it was also a mind-blowing
128:22 - experience for you
128:23 - with that said guys we love your face
128:25 - this is qazi and
128:28 - this is aaron what's up you see me
128:31 - yep and that's it with that said we'll
128:33 - see you guys in the next
128:35 - video
128:39 - peace out guys bye
128:52 - okay let's check out what we are going
128:53 - to do what's up guys
128:55 - so this is the app we're going to be
128:57 - building i just let this demo running so
128:58 - what we got here is
129:00 - uh some urban city driving some guy on a
129:02 - motorcycle there's some cars and
129:03 - pedestrians these guys are about to get
129:05 - hit
129:05 - and yeah as you can see the pedestrians
129:07 - are outlined in yellow and the car is in
129:09 - red and blue
129:10 - so yep this organ building you guys are
129:12 - python super excited as you can see here
129:14 - the cars in the background
129:16 - some girls crossing the street here it's
129:17 - it's doing a decent job it's not perfect
129:19 - but
129:20 - you know it's good enough so this is
129:21 - some guys this is some
129:23 - tesla right here i'm not kidding
129:24 - i'm gonna take a take a look at this
129:25 - right
129:26 - it's able to detect pedestrians it is
129:28 - able to detect cars
129:29 - which is just crazy right i mean it's
129:32 - like imagine basically you know you got
129:34 - your new tesla right and you have to
129:35 - figure out you know
129:36 - what cars in front of you right you need
129:37 - to figure out when to stop you need to
129:39 - figure out when to go
129:40 - this is a system that something that
129:42 - tesla would build
129:43 - for their cars like who is up
129:46 - to build a system like that guys huh
129:48 - tesla autopilot man elon we're coming
129:50 - for you
129:51 - guys elon exactly we're building our own
129:54 - startup company
129:55 - to compete with you elon there we go
129:56 - that's how we're doing it
129:58 - i mean that's that's the hope that's the
130:01 - hope
130:01 - exactly exactly so guys yeah it's like i
130:04 - said who's excited
130:05 - who's excited to build this drop that in
130:07 - the comments below this is an
130:09 - epic system again we are building an ai
130:12 - for detecting what detecting pedestrians
130:15 - and
130:15 - cars with bikes and car tracking
130:18 - tracking exactly
130:19 - pedestrian car tracking and this is what
130:21 - this is beginner friendly right this is
130:22 - beginner friendly
130:23 - yeah beginner friendly the app is not
130:24 - hard at all if you're a beginner you
130:26 - should be able to follow along pretty
130:27 - easily
130:28 - we're gonna be using python and opencv
130:30 - so opencv
130:31 - is an open source computer vision uh
130:34 - library
130:34 - so that's it just python opencv and that
130:37 - should get this entire app finished yep
130:39 - guys now before we get going guys so
130:40 - here's what you do i want you to make
130:42 - sure
130:42 - that we defeat the youtube algorithm
130:44 - system help us
130:45 - defeat the ai of youtube by smashing the
130:48 - like button
130:49 - subscribing to this youtube channel and
130:52 - of course
130:52 - of course sharing the video is that
130:54 - right yep
130:56 - yep that's it so if you want to see more
130:58 - stuff like this in your in your feed
130:59 - then help the youtube algorithm like
131:01 - this video and then youtube will show
131:02 - you more coding stuff and that's what
131:03 - you want right so
131:04 - yeah definitely do that yeah guys i mean
131:07 - look look how cool this is such an
131:08 - awesome
131:09 - tutorial look at this guys it's just
131:10 - like it's making boxes around the actual
131:13 - cars
131:14 - and right and it's able to detect them
131:16 - like in real time we're talking like
131:18 - split seconds we're talking milliseconds
131:22 - this is i mean maybe not milliseconds
131:24 - like it's pretty good it's not quite
131:26 - milliseconds i mean i mean i mean life
131:27 - is happening really fast right so it
131:29 - needs to detect really fast right
131:31 - yeah it's good like even like pretty
131:32 - like you can like see that pedestrian
131:33 - the distance
131:34 - for a split second at least yeah but
131:36 - yeah i'll just let this demo keep
131:37 - running it's pretty dope
131:39 - um i'll probably probably move forward
131:43 - uh oh by the way guys if you're
131:44 - interested if you guys like coding and
131:46 - um i mean to assume you guys are because
131:48 - you're watching this video then here
131:49 - clever programmer we
131:51 - um what we do is we teach people how to
131:52 - become developers like we teach them how
131:54 - to make a living from coding pretty much
131:55 - so we have we offer courses we have a
131:58 - python course called profitwood python
131:59 - that gives you a whole 15-week roadmap
132:01 - of becoming a big
132:02 - beginner to expert and landing your
132:04 - first job or client with python so um
132:06 - check that out
132:06 - if not uh feel free to watch the free
132:08 - content youtube this is this video is
132:10 - free and we also have a free training if
132:11 - you wanna check it out too in the
132:12 - description they're both down there
132:13 - yeah other than that yeah that's that's
132:16 - really good we have a master
132:17 - master class training in the description
132:18 - below if you want to check that out and
132:19 - one thing i really want to mention we
132:21 - we recently had a really an amazing
132:23 - store from our students
132:24 - how about you tell this aaron huh oh
132:26 - yeah yeah this morning so
132:28 - or this morning or yesterday morning i
132:29 - think yesterday uh we had a student
132:31 - land a 90 000 a year ago um ninety five
132:34 - ninety ninety thousand dollar a year job
132:37 - uh so the story is she she lost her job
132:40 - through the covid she enrolled in our
132:41 - course she got a forty five thousand
132:43 - dollar
132:43 - at your job um through by being in the
132:46 - course lost that job and then a couple
132:47 - days later just happened just just
132:49 - yesterday she got a call
132:50 - randomly um for a job offer for 90k so
132:53 - twice as much
132:54 - really awesome there but just shows that
132:55 - yeah we do get our students results but
132:57 - check it out um but other than that
132:59 - let's get into the code not because
133:00 - that's what we've got here
133:01 - do it guys who's excited who's excited
133:03 - to build an ai system like this
133:05 - drop that in the comment below and we're
133:07 - gonna be doing this together guys we're
133:08 - gonna be learning this together
133:10 - so make sure to smash that like button
133:11 - subscribe and let's get into it aaron
133:14 - heck yeah man okay so um
133:17 - yep i think it's been going on long
133:19 - enough let me just cut this and
133:21 - clear my terminal
133:30 - and let's go to a presentation so i just
133:33 - want to give you guys a quick quick
133:34 - presentation a little bit of context
133:35 - before we actually start coding
133:37 - if you want to skip this and just skip
133:38 - right to the code feel free to jump to
133:40 - the time stamp the link will be in
133:41 - description
133:42 - uh this will take like five or ten
133:43 - minutes it's fine i'm just explaining um
133:45 - how the algorithm works and stuff so
133:46 - let's get started so card tracking with
133:48 - python
133:49 - okay uh with a couple of cute little
133:52 - emojis there
133:53 - so first of all we're only using
133:55 - computer vision so you guys might have
133:56 - seen
133:57 - some self-driving cars that have like
133:58 - this weird radar thing on the roof of
134:00 - the car and like spins and stuff
134:01 - it's like like the google one like the
134:03 - google one yeah like the google one and
134:05 - i mean that's
134:06 - like using lasers and radar and stuff
134:08 - and it kind of sucks
134:09 - uh but we're not doing that we're only
134:11 - using computer vision because that's how
134:12 - human works you just use your eyeballs
134:14 - you don't have like a laser sensor
134:15 - okay so only computer vision yeah um and
134:18 - the reason we're doing that
134:19 - the reason we're doing that is because
134:20 - says so okay elon musk he's uh
134:22 - he's a my dad i coined him as my daddy
134:25 - daddy elon
134:27 - but i'll show you sure sure okay sure
134:29 - computer science only
134:31 - and damn
134:36 - tesla stock is up tesla stock is up so
134:38 - this this
134:40 - don't smoke though but not encourage
134:41 - smoking okay
134:44 - yeah none of us smoke anything exactly
134:46 - exactly
134:48 - uh anyways so yeah this is the little
134:50 - article that i found there's actually a
134:51 - video of elon saying it he's kind of
134:53 - cursed about it he's like anyone using
134:54 - uh lidar is doomed and pretty much the
134:57 - reason for that is it's bulky
134:58 - it's expensive it's not effective and
135:00 - humans can do it with just her eyes so a
135:02 - car can too
135:02 - okay so we're gonna be using computer
135:04 - vision just like this and not like this
135:06 - all right
135:07 - beautiful beautiful that's really it so
135:09 - let's explain how this works okay
135:11 - yeah let's do it man i'm i'm very
135:12 - curious oh what the slide didn't load
135:15 - oh there you go anderson now okay let's
135:17 - keep going all right so
135:18 - let me get rid of this zoom thing is in
135:20 - the way all right so step one so how
135:22 - does this actually work
135:24 - good question this is gone one second
135:27 - guys
135:28 - there we go what happened there that's
135:31 - all right guys that's okay
135:32 - we got we got we got you know there we
135:35 - go
135:39 - but anyways so step one is to get a
135:42 - a bunch of car images so what's supposed
135:44 - to be here is actually this image but in
135:46 - color
135:47 - okay so just pretend that that's there
135:48 - so step one get a bunch of car images
135:50 - that look like this
135:51 - step two you want to make them all black
135:53 - and white so that's what it'll look like
135:55 - and the reason we do that i believe nazi
135:57 - asked earlier is because
135:59 - when it's black and white it just makes
136:00 - the algorithm faster because there's
136:02 - less data you don't have to worry about
136:03 - color data it's just
136:04 - relationships and you can still tell
136:05 - that it's a car even though it's black
136:06 - and white
136:07 - am i right that's that no that is true
136:09 - they can still take a lot of things but
136:11 - yeah i mean
136:12 - yeah and if you have rgb color right so
136:14 - you have to have colors i'm guessing
136:15 - it's going to take a lot longer to
136:17 - process because it's just so much more
136:18 - data in there
136:19 - and so we kind of kind of scrap that and
136:21 - be like nope no we don't do that and
136:22 - actually enough
136:23 - actually if you look deeper i think
136:25 - tesla does the same thing
136:26 - so tesla when they actually go ahead and
136:28 - process their videos they process
136:30 - there you know the video that comes to
136:32 - cameras they turn that
136:34 - into black and white guys and we are
136:37 - doing the exact same thing
136:38 - like how epic is that you know
136:43 - yeah i think so i mean yeah it's the
136:44 - first step you've got to turn black and
136:46 - white because it makes things faster and
136:47 - tesla's all about being fast
136:49 - but and then step three once we have the
136:52 - um all the images in black and white
136:53 - like you get a bunch of car images make
136:54 - them black and white just like tesla
136:56 - then you're able to detect and track
136:58 - cars all right and basically the same
137:00 - thing pedestrians but i'm just using
137:02 - cars as the example here
137:03 - yeah so that's kind of the brief
137:05 - explanation of how it works like overall
137:07 - i'm going to go into a little bit more
137:08 - detail here for some context and then
137:10 - we'll get into the code shortly
137:12 - so so how does the computer train the
137:14 - algorithm like how does it go from this
137:16 - to knowing what a car is in each of
137:18 - these images how come it didn't put the
137:19 - red
137:19 - like square like over here where it was
137:21 - incorrect it's actually correcting all
137:23 - of these
137:23 - yeah how does it do that so very good
137:26 - yeah i mean the computer algorithm
137:28 - behind it we're just gonna explain it um
137:30 - in simple terms for people to understand
137:31 - so very simple we use these
137:33 - so these little box shape things are
137:35 - called a heart features
137:37 - and pretty much what they are are like
137:38 - little building blocks like little lego
137:40 - blocks that you can
137:41 - you can use to define um something and
137:44 - that doesn't make any sense but on the
137:45 - next slide i'll show you how it works so
137:48 - pretty much we just do this let me zoom
137:50 - here so i can show you guys
137:52 - so as you can see this is a picture of a
137:53 - car here okay a rear end view
137:56 - and as you can see this little window is
137:59 - is like a dark patch right and this
138:02 - little thing down here
138:03 - is a little bit lighter like this area
138:04 - is lighter and then again the shadow is
138:06 - a little bit darker
138:07 - so what we can actually do is we can
138:08 - take one of these hard features like we
138:09 - have right here this one
138:11 - like this one but inverted and we can
138:14 - actually
138:14 - say that this kind of matches right over
138:18 - here
138:18 - because it's kind of darker up here and
138:19 - lighter down here so we can say that
138:21 - this
138:22 - hard feature matches this location on a
138:24 - car better than it would match here
138:26 - where it's just flat or flat green up
138:28 - here
138:29 - okay so right and the way it does that
138:31 - is it just takes all of the pixels it
138:33 - just takes all the pixels in that black
138:34 - square and adds them up
138:35 - and then all the pixels in this white
138:37 - square and adds them up to one number
138:38 - which is just like a
138:40 - um the way to really boil down like to a
138:42 - single number how dark or how light that
138:44 - entire box as a whole
138:46 - is and then you can compare those two
138:47 - numbers to be like if those two numbers
138:49 - are far enough away from each other
138:50 - you can be like okay this this rectangle
138:52 - is a lot darker than this rectangle
138:54 - or this rectangle is a lot lighter than
138:56 - this rectangle and that's what
138:58 - exactly what's happening here because
138:59 - this rectangle is and so so it almost
139:01 - creates like a shape it also creates
139:02 - like a shape basically because if it
139:04 - basically if it knows right
139:05 - darker up top white at the bottom and
139:07 - then i can continue on doing with that
139:09 - it creates like a shape and and it
139:10 - remembers that shape basically right
139:13 - it'll just find that this match is
139:15 - pretty good when you're training the
139:16 - data and you're like okay
139:18 - this heart feature um of this size kind
139:20 - of matches the car
139:21 - pretty good right okay and then we can
139:23 - also say likewise like i said there's a
139:25 - shadow down here
139:26 - um and this one's a little bit bigger
139:27 - and there's a white strip you can kind
139:29 - of say that this
139:30 - heart feature would match down here
139:32 - because if you cover the shadow it's
139:33 - kind of darker on the shadow and lighter
139:34 - on the bumper
139:35 - so you can actually see that this is
139:36 - also a good match for a car
139:38 - and then these two in added together you
139:41 - can actually see that
139:42 - this dark window and the bumper and then
139:44 - this dark shadow and the bumper
139:46 - are kind of like these two hard features
139:47 - together kind of define a car even
139:49 - better than any of them
139:50 - by themselves yeah so you guys want to
139:52 - take a look at the shuttle at the
139:53 - shuttle below and if you look if you
139:55 - look at all the other cars guys
139:57 - they have a shadow below as well right
139:59 - so that's kind of how it kind of starts
140:00 - to recognize that
140:01 - so that that honestly is so interesting
140:03 - like guys who's like
140:05 - who's who's excited to learn something
140:07 - like this because honestly applying
140:08 - this into your real world into your life
140:11 - is so extremely important
140:13 - mainly because like like you know with
140:15 - tesla with gm with all these companies
140:17 - if they are going towards this they are
140:19 - going towards either
140:20 - autopilot so just imagine right so let's
140:23 - just imagine
140:24 - the amount of jobs that this will create
140:28 - right like it's just jobs with python
140:30 - with machine learning that's going to
140:32 - create in the future
140:33 - in the coming future and already is is
140:35 - insane
140:36 - bro yeah yeah the uber uber's going out
140:38 - of business man like ilama said that
140:40 - there's going to be robo taxi soon
140:42 - so i might have already said this but if
140:43 - you're if you're an uber driver you're
140:45 - going to lose your job so you should
140:46 - probably become a programmer instead
140:47 - because then you can program the cars
140:48 - instead of driving
140:49 - exactly like exactly profit with python
140:52 - descriptions maybe 10 years max and then
140:53 - your job is done
140:55 - so well okay we don't know about that
140:58 - but
140:58 - let's not be let's not be so harsh but
141:00 - let's continue on bro i got faith in
141:02 - elon man like what are you doing
141:04 - my daddy don't do that bro end this
141:07 - stream right now
141:09 - but anyways so that's how it works the
141:10 - idea is these two hard features match
141:12 - nicely for a car um and you can chain
141:15 - like thousands of these together
141:17 - and all added up all of those hard
141:19 - features added up will kind of match to
141:20 - what a car
141:21 - is so these are just two examples and um
141:24 - same thing works for
141:25 - detecting pedestrians so i'll show that
141:26 - next okay
141:28 - okay let's go to the next slide real
141:30 - quick
141:32 - so yeah the same exact idea with
141:33 - pedestrians you get a bunch of images
141:36 - okay of pedestrians you make them all
141:37 - black and white you want to run all of
141:39 - these hard features over all these
141:40 - images to find which ones match in which
141:42 - locations
141:43 - and then eventually you'll train it
141:45 - enough for it to be able to detect
141:46 - actual pedestrians so for example like
141:48 - if you look at this pedestrian here
141:50 - then maybe this hard feature will be
141:51 - really good like if you took this hard
141:52 - feature and stretched it taller
141:54 - and put it over you can kind of say that
141:56 - like maybe here is like a darker
141:58 - person or here is a darker person darker
142:00 - person darker person
142:02 - um and then you have the white the
142:03 - lighter areas on the sides okay
142:05 - so you can kind of use that that's kind
142:06 - of a good match also you can see her
142:09 - her pants are very dark here they're
142:10 - basically like dark blue or black or
142:11 - something
142:12 - you could say that this heart feature if
142:13 - it was a little bit stretched taller too
142:15 - and skinnier
142:15 - then you can say okay this our feature
142:17 - matches good and same here because
142:19 - usually people are wearing pants and
142:20 - shirts of different colors so you could
142:21 - say that that also matches a human
142:24 - yeah a pedestrian so and so and so again
142:26 - it basically it
142:27 - almost like creates a shape again you
142:28 - know it creates it uses all those black
142:30 - and white boxes it counts them in and it
142:32 - creates a shape and knows okay so
142:33 - if this this kind of shape matches right
142:36 - this kind of shape is created it matches
142:38 - a human
142:38 - if this kind of a shape is created it
142:40 - matches a car or a match as a pedestrian
142:43 - right so that is the interior what about
142:45 - this or a coat can
142:46 - yeah you know or or an apple i don't
142:48 - know whatever you want anything
142:50 - anything you know yeah but this is
142:54 - distinguishing apples from pears like
142:55 - that's a little bit trickier and then
142:57 - you probably need to keep the color in
142:58 - there at that point but i mean this is
142:59 - just a generalized
143:01 - explanation of course you there's always
143:02 - a trade-off of accuracy and speed
143:04 - so yeah um it takes a lot more work to
143:06 - distinguish an apple from a pair than it
143:08 - does
143:08 - from a human to a car because they're
143:10 - just very different things sure that
143:12 - show that sweet man all right let's
143:13 - continue on yep that's it so let's just
143:16 - jump into the code let's code it up hey
143:18 - let's go guys we're probably like 12 15
143:21 - minutes in
143:22 - but um again timestamps in the
143:24 - description if you re-watch stuff or
143:25 - skip anything
143:26 - yeah but let's get into the code okay
143:30 - guys
143:37 - are we still alive nice maybe we are
143:39 - alive we're all good
143:40 - we're all good we're all good we're all
143:41 - good let's continue on guys who's pumped
143:43 - to build
143:43 - who's pumped to build an ai system like
143:45 - this who's pumped to build an is system
143:47 - for a car
143:48 - and pedestrian tracking i'll jump put in
143:50 - the comments below and we're gonna we're
143:52 - going to get started
143:53 - right now got it
143:57 - all right guys so i got the code up here
143:58 - and running this is what was running the
144:00 - the demo code it's actually not that
144:02 - long
144:02 - as you can see it's just a few lines all
144:04 - this here
144:05 - was doing all of that it was taking in
144:07 - the image um not the image
144:09 - it was taking in the um the video
144:12 - of the the guy the dash cam and the
144:14 - pedestrians and then it was finding
144:15 - everything detecting everything and
144:16 - displaying it to the screen that's all
144:18 - happening right here
144:19 - right okay okay so let's just jump into
144:21 - it we're going to start with just an
144:22 - image and then we'll go to video a
144:24 - second
144:25 - but yeah feel free to follow along so if
144:27 - you guys don't have vs code you're going
144:28 - to want to download vs code
144:30 - you're probably going to want to pause
144:31 - this video and download it because i'm
144:32 - going to be going a little bit faster
144:33 - but download vs code get it all set up
144:36 - and
144:37 - that's it next what you're going to want
144:38 - to do is you're going to want to
144:40 - create a python file um you can call it
144:42 - whatever you want but i call the car and
144:44 - pedestrian tracking dot pi
144:45 - okay this is the one i had before i'm
144:47 - just going to be copying pasting code
144:49 - um over to show you guys how it works i
144:50 - don't want to have to type it out it's
144:52 - the same thing pretty much
144:53 - but you want to start here okay next
144:56 - thing you want to do
144:57 - is install opencv so you can do that
145:00 - through the command
145:01 - pip install opencv dash python okay
145:05 - and if that doesn't work then try
145:07 - running pip install
145:08 - the same thing but just add headless at
145:10 - the end okay there might be an issue
145:12 - there
145:12 - um one of those should work if you're
145:15 - running on a mac or a linux computer if
145:17 - using linux you're probably already a
145:18 - badass programmer so you don't even need
145:19 - to
145:20 - you need to know this stuff but again
145:22 - you can just do a google search like how
145:23 - to how to install opencv on your
145:25 - computer if if these don't work you're
145:26 - going to kind of have to figure it out
145:27 - yourself because
145:28 - i can't help with every error but like i
145:32 - said
145:32 - we're about to cost 100 likes so let's
145:34 - keep liking the video guys about to cost
145:36 - 100 likes
145:37 - like the video let's and let's continue
145:40 - on
145:41 - yeah uh where was i
145:45 - uh yeah oh yeah install opencv so once
145:48 - you have that installed
145:49 - you should be good okay um the way you
145:50 - can the way you can test that is you can
145:52 - just put python
145:54 - okay and you have your little python of
145:55 - arm here in your terminal
145:57 - and um oh if you know what this is this
145:58 - is terminal so you wanna go
146:00 - you can do command space on mac and then
146:03 - this little spotlight thing pops up and
146:04 - type in terminal
146:05 - and just hit enter and then it'll pop
146:06 - this up and this kind of tells you
146:09 - um gives you access to your computer so
146:10 - if you type in python then you can do
146:12 - stuff like
146:13 - hello okay yeah
146:16 - and then it'll print hello whatever says
146:18 - there or you know nice nice nice nice
146:21 - daddy oh my god
146:25 - elon is not your dad bro come on man
146:29 - you look very different
146:34 - no no no don't even think about it don't
146:36 - even think about it no no aaron
146:37 - you think about it back on track so to
146:39 - make sure you have opencv installed you
146:40 - can just import
146:41 - cv2 which is short for computer vision
146:44 - 2.
146:44 - and if you hit enter then you this will
146:46 - happen nothing will happen it'll be fine
146:48 - if you get an error it means it
146:49 - installed incorrectly
146:50 - so just make sure that when you run this
146:52 - it just goes to the next line there's
146:54 - nothing happens that means it's
146:55 - installed correctly then you're good
146:56 - to get out of python you can
146:59 - just do control d and it'll go back here
147:01 - and i'm just going to type clear
147:03 - so that we're back to the terminal uh
147:05 - but once you have open cv installed and
147:07 - you have your python
147:08 - file created and you have it open in vs
147:10 - code we are ready to start coding
147:12 - okay okay so now guys guys looks like
147:14 - edwin edwin
147:16 - uh just gave us a one euro super chat
147:18 - edwin
147:19 - thanks so much appreciate it and let's
147:21 - continue on
147:22 - yeah i think my lunch now right now i
147:25 - know right i know
147:27 - anyway so let's just start with a simple
147:30 - um
147:31 - code completed so this is a little thing
147:33 - i like to do i put this print statement
147:34 - at the end of my program so that i know
147:36 - if it prints that the whole program
147:37 - completed without any errors so let's
147:40 - just run this first so this is the first
147:41 - thing that i'm going to run
147:42 - go to the terminal make sure you are in
147:45 - your desktop
147:46 - so pwd stands for present working
147:49 - directory
147:49 - and as you can see i'm on my desktop if
147:51 - you're not then
147:52 - um like if you're not if i'm not my
147:55 - desktop let's say just i'm at my user's
147:57 - user file then you want to put in cd
147:59 - which is change directory
148:00 - and then just type desktop just like
148:02 - that with a capital d okay
148:04 - and then once i do that then i am in
148:07 - desktop okay then once you're in desktop
148:09 - that's where i have my files housed
148:11 - or if it's on if you're if you have all
148:12 - your files housed in a folder then you
148:14 - got to go there instead of desktop but
148:15 - for me i just have it on desktop right
148:16 - here
148:17 - that's that's that's that that's a messy
148:18 - messy file structure bro but anyway
148:22 - are you teaching them how to code like i
148:24 - don't know how to keep my computer
148:25 - organized this is free free content you
148:26 - know
148:27 - all right all right all right okay this
148:28 - is aaron's stream rogue off the stream
148:30 - knives
148:32 - i need you to help me anyway
148:36 - so let's run this code so the way we do
148:38 - that
148:39 - is we just write python because this is
148:41 - a python program
148:42 - and then we wants to run
148:46 - um car i think i gotta put dashes
148:50 - car there we go so car and pedestrian
148:54 - tracking dot pi
148:55 - okay these little slashes and it's a
148:57 - space because it's kind of silly when it
148:58 - when there's actual spaces like i had
149:00 - underscores in the other file but
149:01 - ignore that yeah and then and the way by
149:03 - the way and the way aaron was able to
149:05 - get that is he simply started with so
149:07 - he typed in car and then he pressed tab
149:09 - right away right
149:10 - so he pressed tab and that's basically
149:12 - right away it autofilled because
149:13 - you know we got autofocus yeah it tried
149:15 - to auto find any
149:17 - any files that has car at the beginning
149:18 - and then it gives you all the options
149:20 - exactly you can just type it all the way
149:22 - out maybe just use underscores because
149:23 - then it gets sort of this nasty
149:24 - complicated thing with this stuff if you
149:26 - just use underscores and all your file
149:27 - names and you can just type out this
149:29 - exact thing
149:29 - and then you won't have all this weird
149:30 - stuff it'll just look like
149:33 - it'll look like like that yeah yeah
149:36 - okay it looks nicer nice but uh
149:39 - this video will just use this okay
149:41 - that's fine so when i run this
149:43 - because it says code completed then we
149:44 - should see code completed pop up here
149:47 - and voila it does so
149:50 - that then okay surprisingly because
149:52 - there's just a print statement
149:53 - but like i said when you're running
149:55 - opencv you want to run
149:57 - import cv2 make sure you save and if we
150:00 - run this now
150:01 - then and this prints out we know that
150:02 - this is working correctly if this
150:03 - doesn't print out
150:05 - and that means there's an error here
150:06 - importing and then we'll see it but i
150:08 - mean i think it's going to work
150:09 - so you can press the up arrow key to
150:10 - repeat your last command
150:12 - and just hit enter again and as you can
150:14 - see no errors so
150:16 - guys and that's it our program has been
150:18 - completed thank you very much no
150:19 - no i'm kidding
150:24 - get out of here
150:27 - all right so let's start with just
150:30 - detecting
150:31 - cars and images all right so i have a
150:32 - little mini program up here let me just
150:34 - comment this out
150:35 - it's a comment out in python um you can
150:38 - just use triple quotations like that and
150:39 - everything
150:40 - everything between will be commented out
150:42 - and
150:44 - these and
150:49 - there we go save this and here we go so
150:53 - it's even shorter for just an image but
150:55 - we're going to go through all of them
150:55 - one by one and explain how it works okay
150:58 - so let's start with this all right
151:02 - so first thing we're gonna do is we're
151:04 - gonna want to um
151:06 - decide on an image of course if we're
151:07 - gonna be detecting cars we need an image
151:09 - that has a car in it to detect
151:11 - okay so i just have a image on my
151:13 - desktop called car image.jpg
151:15 - right here car image.jpg this is the
151:18 - same one that was in the slides i was
151:19 - using i just cropped it out yeah
151:20 - the same exact image and we literally
151:22 - and we literally and we literally got
151:23 - guys we really just got these images
151:25 - from the internet so don't think it's
151:26 - anything special it's just an
151:27 - image from the internet and we're going
151:28 - to yeah yeah yeah yeah kind of videos
151:29 - i'm actually using in this
151:30 - in this tutorial the links to the
151:32 - youtube videos i stole them from
151:34 - are in the description so credit to
151:36 - those people the guy on the motorcycle
151:37 - he has like 2 million subscribers for
151:38 - riding his motorcycle around cities and
151:40 - like
151:40 - revving his engine at hot chicks like
151:42 - it's pretty cool but
151:44 - all right all right okay i use a video
151:45 - from him and that's where i get it from
151:47 - so this isn't spoofed
151:48 - i'll go check it out there you can also
151:49 - use a youtube downloader to get the
151:51 - videos yourself
151:52 - if you wanna use the same videos then by
151:53 - all means do it so this is the car
151:55 - image.jpg okay right here
151:59 - and um that's it so the image file we
152:01 - have is just car image.jpg
152:03 - very simple okay and let's just run this
152:05 - this is called unit testing every time
152:07 - you write a new line of code or like a
152:08 - different
152:09 - different group of code i'm a little bit
152:12 - ocd and psychotic and do it every single
152:14 - line i run it to make sure code
152:15 - completed prints because if it doesn't
152:17 - that means the line i just added screwed
152:19 - something up
152:20 - right okay okay called unit testing
152:22 - because you want to test every single
152:23 - unit of change in your code
152:25 - right um even you can be redundant even
152:27 - if it's like as simple as
152:28 - oh i deleted something like you maybe
152:30 - you thought you deleted the d but you
152:31 - actually deleted this
152:32 - that's going to screw you it's going to
152:34 - it's going to break the code true
152:36 - um but yeah pretty self-explanatory
152:38 - that's the
152:39 - importing the image there second thing
152:41 - is we are going to want some way to be
152:43 - able to
152:44 - detect and track cars okay and
152:46 - pedestrians but let's just start with
152:48 - just cars
152:49 - okay so let's start here so these are
152:52 - um our image we put in some comments
152:54 - because comments are good
152:55 - it's good coding practice and our
152:58 - pre-trained
153:00 - car classifier okay so this is a little
153:03 - bit
153:04 - wordy but all it is is like i said when
153:07 - you
153:07 - when you train the algorithm with the
153:09 - hard features and you have a big
153:10 - list of heart features that defines a
153:12 - car when they're all added up like the
153:13 - dark boxes and the light boxes all of
153:15 - those added up define what a car is like
153:16 - it kind of captures the
153:18 - pattern of what a card looks like on in
153:20 - an image or in a frame of a video
153:22 - then you encapsulate all of those
153:24 - numbers and heart features
153:25 - in a file an xml file so
153:29 - um i think
153:33 - yeah so what this looks like i can
153:35 - actually open it right here
153:36 - okay i'll take a look if i just open
153:37 - this up then this is what it looks like
153:39 - so cartesian
153:40 - xml so all this is this is the result of
153:43 - training the algorithm this is what the
153:45 - algorithm at the end spit out after you
153:46 - put in thousands of images
153:48 - oh by the way i totally forgot the car
153:51 - images the data set that
153:52 - that i stole sorry guys
153:56 - we borrowed the hey i got who you bought
153:57 - right now i'm gonna i'm gonna die on the
153:59 - stream
154:00 - you got some water you gotta get it okay
154:02 - what's up
154:04 - get some water you know yeah i got some
154:06 - right here actually so okay i'm gonna
154:08 - drink while i'm talking
154:09 - all right cool cool
154:14 - should be awesome conquering hiccups
154:17 - okay
154:17 - anyways all right so we're not actually
154:19 - going to train the algorithm ourselves
154:21 - on this
154:21 - on this video that takes way too long
154:23 - because like it takes like like a long
154:25 - time for a human to learn and build a
154:26 - habit it takes a long time for a baby to
154:28 - understand what a car and a pedestrian
154:30 - is the same way it takes a long time for
154:31 - a computer to learn what a car is
154:33 - because you have to give it
154:34 - thousands of images and run all the
154:36 - thousands of heart features at every
154:37 - location of every size of every
154:39 - orientation until you eventually decide
154:41 - on the hard features that match nicely
154:42 - for a car
154:43 - and then once you have all those then
154:45 - you're good to go but the
154:46 - end result is pretty much this okay so
154:50 - this is just like some encoding i
154:51 - actually don't know how this works
154:52 - exactly
154:53 - it's just the xml xml encoding is what
154:56 - they use but the idea is you can
154:58 - generate one of these files
154:59 - um and it has all the numbers like these
155:01 - numbers are like different coordinates
155:03 - and different colors and different
155:04 - thresholds of like okay is this a hard
155:05 - feature is this good enough it needs to
155:07 - be
155:07 - above this number below this number and
155:09 - it just goes through the entire list of
155:10 - thousands and thousands
155:12 - and thousands
155:24 - oh
155:27 - yeah guys cause he called me i don't
155:29 - know if you guys can hear one second
155:38 - guys
155:47 - oh we got another donation dope
155:54 - it yeah i'm not in the chat guys i think
155:56 - we've overlooked that but somebody
155:58 - somebody uh donated uh are we still live
156:01 - nos
156:01 - yeah we're live of course all right yeah
156:03 - let's keep going let's keep going
156:04 - there's no no
156:05 - i was just i was just talking with maybe
156:07 - we were like you know
156:08 - yeah yeah yeah all right guys we're back
156:10 - on track somebody else donated i think
156:12 - we missed in the chat because we're
156:13 - focused on the code so we overlooked
156:14 - that but don's
156:15 - keep an eye so whoever that was i don't
156:18 - know their name
156:19 - but appreciate that very appreciate that
156:22 - appreciate the gesture
156:23 - and where was that yeah so the so this
156:26 - is the long list of hard features it's
156:27 - gonna go through all of these and if the
156:29 - image
156:30 - passes all of these you can say okay
156:32 - yeah this is a car
156:33 - awesome or like a little patch of an
156:35 - image if the little patch passes through
156:37 - all these and it's
156:38 - it's a yes all the way through and it it
156:40 - counts as a car if not it's not a car
156:42 - and then that's how we know where they
156:44 - are so
156:45 - you're gonna need to specify this file
156:48 - because this is what's gonna tell us
156:48 - what a car is and what a car
156:50 - isn't and the link to this file is
156:52 - actually in the description so you can
156:53 - just go download this this is just a url
156:55 - just go file save as and you can
156:56 - download this
156:57 - um it's actually just called car.xml but
156:59 - i added a detector
157:01 - for for the video so download that okay
157:04 - that's explanation of that a lot of
157:05 - explanation for one line of code but i
157:07 - don't just want to be like hey just
157:08 - download the
157:09 - work like nah i'm gonna explain i'm
157:10 - gonna explain how it works so they have
157:11 - an overall
157:13 - understanding that's the proper way to
157:14 - do stuff okay we're actually programmers
157:17 - i mean we're lazy half the time but it's
157:18 - fine
157:20 - um all right so moving on
157:24 - um now the next thing we're going to
157:25 - want to do is we're actually going to
157:27 - want to
157:28 - create an image within the opencv format
157:31 - so this here
157:32 - of course this is actually just a string
157:33 - okay car image is just a string
157:35 - in python but we want to give it to
157:37 - opencd remember cv2
157:39 - and actually read the image so that
157:41 - opencv can actually use it correctly
157:43 - okay so all we're going to do is we're
157:44 - going to call opencv.imageread
157:48 - and pop in the image file the name of
157:49 - the image file which is just car
157:51 - image.jpg again
157:52 - car image.jpg right here so we're
157:54 - reading this in our program
157:57 - and from there we have it in here image
157:59 - so that image is actually now in this
158:01 - variable here in our program okay
158:02 - so why don't we just show uh i believe
158:05 - so the image image image read file
158:07 - imagery file basically like takes in the
158:09 - image and all the and it processes it as
158:10 - like data
158:11 - is that what it does right yep so it
158:13 - just reads it just reads in all the
158:14 - pixel data from that image file and then
158:16 - reads it into
158:18 - some double um multi-dimensional array
158:20 - so you know like a big array a double
158:22 - array of an array of arrays so that
158:24 - every pixel has its own data and then
158:26 - it's just
158:26 - all encoded into this one variable here
158:28 - image right right right right gotcha
158:30 - gotcha and now what we're gonna do is
158:31 - we're actually just going to
158:33 - this is not a face detector this is a
158:35 - car detector
158:36 - okay we're going to display this image
158:39 - so there is a
158:41 - um we're also going to need this just
158:44 - once
158:45 - so so these two lines of code that we're
158:46 - currently working on we got the image in
158:48 - our program
158:49 - next we're going to need to show the
158:51 - image so opencv
158:52 - has a function or method called image
158:55 - show
158:56 - and the first thing is the name of the
158:58 - window so the name of the window like
158:59 - here is car and pedestrian tracking.pi
159:01 - that's what'll pop up there and then the
159:03 - actual image won't show
159:04 - okay okay that shows up and then in
159:07 - opencv
159:08 - this basically just means display so
159:10 - opencv.wait key
159:12 - you need to you need to run this line of
159:14 - code so that it actually displays
159:16 - otherwise it'll display for a split
159:17 - second basically one frame
159:19 - so like literally a split second then
159:21 - it'll disappear
159:22 - but this says wait until you hit a key
159:24 - before it disappears so it kind of like
159:26 - this displays for a millisecond but this
159:28 - makes it pause and so you need okay okay
159:30 - okay okay it's kind of just like display
159:32 - by the way by the way i just want to say
159:33 - thanks to lars lars donate looks like
159:35 - a euro as well so appreciate that man
159:37 - and we got sony pete guys we got so many
159:39 - people in the comments between abdullah
159:40 - between kristen between tracks between
159:42 - kent
159:42 - usa usma vicky right joshua so many of
159:46 - you guys amazing and
159:48 - so excited in the comments i'm excited
159:50 - that we have such such
159:52 - a great community man literally so yeah
159:54 - i just wanted to mention that because
159:55 - you know so many amazing people that's
159:57 - yeah well let's go ahead and continue on
160:00 - awesome you guys so let's just run this
160:03 - code now all right so again we imported
160:05 - opencv we got the image file we have our
160:07 - car classifier
160:08 - we import the image okay okay
160:11 - um and i just want to show you the image
160:13 - now real quick okay to prove that the
160:14 - image is actually showing up and is
160:15 - within our python program
160:17 - so this will actually pop up a little
160:18 - window with the image and that's it it's
160:21 - not detecting anything yet it's just
160:22 - going to show the actual image
160:24 - so boom right there as you can see it
160:26 - says clever programmer car detector and
160:27 - that's the image
160:29 - right okay okay and remember this this
160:31 - title
160:32 - is from here okay so that's that
160:36 - all right now let's just quit out of
160:38 - this so it's waiting for a key press if
160:39 - i hit space bar or any key it'll just
160:41 - quit out
160:42 - and now we can continue on all right
160:44 - okay so
160:46 - so now we're going to be coding in here
160:47 - because of course at the end we want to
160:48 - make sure we're displaying the image at
160:50 - the end
160:51 - um but now we have our image in our file
160:53 - okay so now that we have the image and
160:55 - we have a classifier
160:56 - how do we actually find where the car is
160:58 - in that image because
161:00 - i mean there's a car here there's a car
161:01 - here there's a car all down here
161:03 - i mean granted these are half cars so it
161:05 - might not detect these i don't think it
161:06 - will
161:07 - but these full cars it definitely will
161:09 - okay
161:11 - well kazi's calling again
161:14 - hey what's up quasi
161:18 - live stream is dead oh
161:21 - stream is dead now
161:27 - uh no you're not mute
161:31 - no it's running is it is the stream up
161:33 - guys in the comments can you guys it's
161:35 - running
161:35 - it should be running guys right it's
161:37 - running you guys hear us
161:40 - it's working yeah it's all good guys
161:41 - always good got it
161:44 - it's all good it's working now all right
161:47 - we don't want another uh dead dead
161:48 - livestream you know you guys it's
161:50 - terrible because it keeps getting cut
161:51 - off but yeah
161:52 - i think we're good right i think we're
161:53 - good yeah we're good we're good we're
161:54 - good we're good we're good we're good
161:56 - anyways so this is the image that's
161:58 - going to be read in
161:59 - and from here we want to be able to
162:02 - classify
162:03 - that this right here is a car so it's
162:05 - like if we pass this little rectangle of
162:07 - the image
162:08 - through that whole xml file and if it
162:10 - gets all the way to the end it's like
162:11 - okay cool this
162:12 - square counts as a car and this square
162:15 - does not count as a car
162:16 - okay okay that's what we're gonna be
162:18 - doing so the next step to do
162:20 - is to actually create our classifier so
162:22 - that's pretty simple that's just this
162:23 - line right here
162:24 - let me show you guys i'll copy and paste
162:26 - this and
162:27 - we want to create our car classifier so
162:30 - all it is
162:31 - is we run this function opencv.cascade
162:35 - classifier because again we're running a
162:37 - har
162:37 - cascade algorithm that's why it's called
162:39 - cascade because there's a cascade a long
162:41 - list
162:41 - a long chain of heart features that
162:43 - we're going to run it through and
162:45 - classifier is just classifying something
162:47 - as a car or classifying it as
162:48 - a pedestrian or classifying it as a face
162:51 - or an apple or whatever but in this case
162:52 - a car and
162:55 - the classifier file is what we just
162:57 - specified the xml file
162:59 - file so we just pop that into here and
163:01 - so opencv we're just going to create a
163:03 - classifier
163:04 - from that file and then we're just going
163:05 - to call it car tracker because
163:07 - once you have a car tracker now we can
163:08 - apply this car tracker to this image
163:10 - and we can actually find where in this
163:13 - image
163:13 - if there is a car or not so here there's
163:15 - a bunch but it might only it
163:16 - might only detect a few but that's the
163:18 - idea okay so in an image we have a car
163:20 - tracker now we just want to apply this
163:21 - car tracker to the image
163:23 - and then spit out the rectangles okay
163:25 - right so
163:26 - let's move on um i mean again
163:29 - this doesn't show anything we just have
163:30 - the car tracker created if i displayed
163:32 - it it's just gonna be the image again so
163:33 - i'm gonna move on
163:35 - like i said in our presentation we do
163:36 - want to convert it to black and white
163:38 - though
163:38 - first so let's just do that next and the
163:41 - reason for this is because it speeds up
163:42 - the algorithm makes it essentially three
163:44 - times as fast because instead of three
163:45 - colors rgb
163:47 - we can just focus on black and white
163:49 - that's it so you're simply converting
163:50 - basically from
163:51 - from color to to to to black and white
163:55 - yep okay question if you guys wanna
163:58 - why why don't why don't you do why don't
163:59 - you do that before you classify is my
164:01 - question
164:01 - like why don't you do that before the
164:03 - classifier i mean you're just creating
164:05 - it
164:05 - yeah we can shuffle this up it doesn't
164:06 - really matter it doesn't matter okay
164:08 - yeah doesn't matter i mean this might
164:09 - make more sense because you have the
164:10 - image then then you change it to black
164:12 - and white
164:13 - and then create the classifier gotcha
164:16 - i mean we could even do this you know we
164:17 - could like keep away or different so
164:19 - like we've got an image here
164:21 - yeah and then we read in the image and
164:22 - then we change it to black and white
164:24 - and then we get a classifier and then we
164:26 - create the classifier and then but the
164:28 - point is what we want is we want to have
164:30 - this uh classifier and this a black and
164:34 - white image ready so once we have both
164:35 - of these
164:36 - we can do this in any order then we can
164:38 - pair these together and actually get the
164:39 - images
164:40 - okay nice so i mean i guess i'm gonna
164:42 - put it back here because i like keeping
164:44 - all of the
164:45 - static stuff together because these can
164:46 - change like you can change the file very
164:48 - easily here or the file very easily here
164:50 - just by changing this and all this code
164:51 - remains unchanged
164:53 - right all right so here we go we got
164:56 - somebody asking how can i how can i
164:57 - donate oh my gosh some of you guys are
164:58 - asking how can i donate dang i really
165:00 - appreciate that guys
165:01 - that is so awesome my paypal is
165:05 - my my venmo my only fans like i got
165:07 - everything
165:08 - just faith all of that you know yeah my
165:12 - snapchat
165:14 - no um i actually don't know how you can
165:16 - do that do you know nas
165:17 - i don't know i think kaz has got it
165:19 - kaiju's got it he's got taken care of
165:20 - all is good
165:21 - yeah cool yeah or we can hook you up
165:23 - with something maybe there's something
165:24 - uh a itch
165:25 - like a fighter course something i don't
165:26 - know yeah it's something up
165:28 - who knows anyways back to the code you
165:31 - guys so once you have the image right in
165:32 - you want to change it to black and white
165:34 - like we said because it speeds up the
165:35 - algorithm and you can still
165:36 - you can still tell what a car is and
165:37 - what a car isn't in black and white
165:39 - images so it's totally fine
165:40 - um you want all the improvements you can
165:42 - have there's always a trade-off of speed
165:44 - and accuracy pretty much in everything
165:45 - in life
165:46 - um so algorithms are no different so you
165:48 - kind of want to change
165:49 - like again like an apple and a pair if
165:51 - you go black and white it's going to be
165:52 - much harder to distinguish the
165:53 - difference
165:54 - um but a car and a human very easy to
165:57 - distinguish
165:58 - okay right yeah that's true the way we
166:00 - do that is opencv
166:02 - you just there's a function called
166:04 - convert color
166:05 - so all you're gonna do is this allows
166:07 - you to to convert
166:08 - color to black and white it allows you
166:10 - to convert black and white to color
166:12 - and there's all different kind of color
166:13 - encodings i'm not going to get into
166:15 - crazy details but the point is
166:16 - this allows you to convert the color
166:18 - stuff of an image to whatever you want i
166:20 - could even make it all red like have
166:21 - only the red channel it'll look really
166:23 - red
166:23 - and stuff like that all right so i'm not
166:26 - going to demonstrate that here
166:27 - um but well let me see actually
166:32 - now i don't i don't want to go down that
166:34 - rabbit hole um the but
166:35 - yeah the point is you can you can
166:37 - convert any the color of any image so
166:39 - we're going to feed in the regular color
166:40 - image here
166:41 - and then all we're going to do is we're
166:42 - going to say we want to go from color
166:45 - from bgr to gray so bgr is just rgb
166:49 - backwards
166:50 - in openc um rgb
166:54 - rgb is like you know the color of a
166:56 - pixel everybody should know that if you
166:57 - don't well now you do
166:59 - um then they just use it backwards so
167:02 - it's bgr a little bit confusing i don't
167:03 - know why that's so weird that's that's
167:05 - so weird like how about
167:06 - it's like the stan was like but wait if
167:08 - you didn't know if you didn't guys
167:09 - didn't know rgb
167:09 - it's red green and blue those are the
167:12 - three main colors that all the other
167:13 - colors are made up of
167:14 - if you didn't know that so yeah that's
167:16 - that's something interesting for you
167:18 - yeah yeah each pixel has a r uh a red a
167:21 - green and a blue light
167:22 - and then it just like makes the
167:23 - brightness of those three different
167:25 - levels and the combination of those
167:26 - three levels can make any color pretty
167:28 - much
167:28 - if they're all max white if they're all
167:30 - off it's black
167:32 - okay for rgb but for gray it's just one
167:35 - number there's no there's no three
167:36 - channels it's just oh
167:38 - is it zero to like a hundred or
167:39 - something yeah yeah okay from your 100
167:41 - like what's the brightness that's all it
167:43 - is so we're just converting
167:45 - rgb to gray and once we have that i just
167:48 - call it black and white
167:49 - because why not now we can actually
167:52 - display this black and white image so
167:54 - let's take this
167:54 - and in our image show down here which
167:56 - was showing the color image before
167:58 - let's just change this to the black and
167:59 - white image and of course we need this
168:01 - to display for longer than millisecond
168:03 - and this should actually give us the
168:04 - black and white image okay so let's just
168:06 - run the same thing again again your up
168:07 - arrow key will
168:09 - allow you to go to the last command you
168:10 - ran in your terminal hit
168:12 - enter and voila we have a black ops
168:16 - okay interesting guys give give some
168:18 - give us aaron
168:19 - some round of applause in the comments
168:21 - below
168:23 - i ran six lines of code you know i've
168:25 - been coding for eight years
168:26 - and we converted an image to a black and
168:28 - white image that's what we just did
168:30 - this is all i learned in eight years
168:31 - guys exactly
168:35 - eight years in college eight years in
168:36 - college you know grad school
168:39 - pursuing masters and everything
168:42 - um anyways so that's the black and white
168:45 - image so now that we have the black and
168:46 - white image we can actually apply
168:48 - the card classifier to that image and
168:51 - then we can get the
168:53 - um the the car um
168:56 - in the image out okay yeah so the next
168:58 - thing we're
168:59 - going to want to do is actually detect
169:01 - where the cars are in the image
169:03 - so let's run that next okay okay
169:09 - so i'm going to got it are you trying to
169:10 - figure out what line or line to write
169:12 - this on
169:13 - no no i just kind of want to like submit
169:14 - like these are files shut up
169:17 - it's just like wait don't run down this
169:19 - line or this line
169:23 - guys well guys drop in the comments
169:25 - below what what line should
169:26 - should should aaron write write the
169:28 - piece of code
169:32 - actually cool good question who would
169:34 - win the fight a good question
169:36 - i mean drop that in the comments drop it
169:38 - down in the comment below i'm very i'm
169:40 - very curious
169:45 - we'll see we'll see we'll see one day
169:47 - one day
169:49 - anyways uh yeah so the way you you
169:52 - detect
169:53 - things in opencv is once you have a
169:55 - classifier object
169:56 - okay a car tracker you can apply this to
169:59 - an image so all we're going to do
170:01 - is we're going to say car tracker and we
170:03 - want to detect multi-scale so what that
170:05 - means is
170:06 - detect cars of any size of any scale
170:09 - okay so we're going to
170:10 - detect cars it doesn't matter if the car
170:12 - is big
170:13 - or small it's going to detect it matter
170:16 - what or even if
170:17 - it was even bigger it'll detect that too
170:19 - okay got it got it got it got it
170:23 - editor is this guy this is using vs code
170:26 - guys okay
170:27 - visco so like just download this code is
170:29 - the the most
170:30 - the most important one you'll ever use
170:31 - as a developer so yeah
170:33 - it looks like what
170:43 - yep oh by the way um if you guys want to
170:46 - have the the
170:48 - the documentation for opencv um i'll
170:50 - link that link in description too so you
170:51 - can check all these files because
170:53 - there's a lot of cool little things you
170:54 - can tweak i'm not gonna go
170:55 - over all them extensively i'm just
170:57 - getting the app done uh but detect
170:58 - multiscale there's cool things you can
171:00 - add on to the end to kind of like tweak
171:01 - the algorithm to make it
171:03 - perform better or worse yeah that's
171:05 - linked in the description i'll just show
171:06 - it right here though
171:07 - detect multi-scale so this is the
171:09 - documentation again link in description
171:10 - just
171:11 - click there it'll zoom in guys yeah cool
171:14 - cool link in bio link in description
171:16 - instagram i'm used to that you know
171:19 - i know i know you dirty
171:21 - millennial okay listen
171:23 - let's just let's just let's focus on the
171:25 - work here okay
171:27 - [Laughter]
171:30 - like i don't like those no boring videos
171:31 - boring live streams
171:33 - anyways so um yeah detect multi-scale so
171:36 - of course you take the image in first
171:38 - which is what we were doing here we're
171:39 - just passing in the
171:40 - black and white image but then there's
171:42 - other stuff you can add on there's all
171:43 - this cool stuff reject level scale
171:45 - factor minimum neighbors you can read
171:46 - all the details here if you're
171:47 - interested but you don't need it for the
171:48 - app to work i'm not using it
171:50 - so that's really it so detect
171:52 - multi-scale
171:53 - you just plug in the black and white
171:55 - image with the car tracker that we got
171:56 - again
171:57 - from this xml file which was trained
171:59 - with the images
172:00 - and the heart features so that's the
172:01 - whole entire holistic view
172:03 - and once we apply this tracker to this
172:06 - black and white image
172:07 - it'll pick out all the places in that
172:09 - image where there's a square that
172:11 - contains a car and it'll give us the
172:12 - coordinates of all of those cars
172:14 - okay okay so why don't we just print
172:16 - this out
172:17 - and see what the hell is in cars okay
172:20 - okay guys this is this is getting
172:22 - interesting guys this is getting really
172:23 - interesting all right let's see
172:24 - let's see let's run it and boom
172:28 - so again the black and white image is
172:29 - popping up because i still have these
172:31 - two lines of code down here running okay
172:32 - but okay
172:33 - that i printed out cars so all cars is
172:37 - just the numbers yes relative to that
172:40 - really
172:41 - yeah i mean uh i guess it's only taking
172:44 - two cars in this we'll see exactly where
172:45 - they are
172:46 - in a bit um i already know ahead of time
172:47 - because i ran this before but it detects
172:49 - this big car in front
172:50 - and this little car on the right reason
172:52 - being is because these are all half cars
172:53 - so it's not quite smart enough to get
172:55 - the half car
172:56 - well actually actually actually that's a
172:57 - good question guys guys which cars do
172:58 - you think it will actually detect let us
173:00 - know in the comments below like
173:01 - okay man yeah i know you give it away
173:04 - but like
173:04 - this is come on gotta not give it away
173:08 - so easily you know
173:10 - but easy mode i mean like it's
173:12 - impossible to predict bro like not even
173:14 - us you just run the program and see what
173:15 - happens like come on yeah
173:17 - but uh yeah but anyways so yeah it's
173:19 - gonna detect this one and this one
173:21 - okay so there's only two spoilers
173:24 - but these are the two these are the two
173:25 - cars so these are just the coordinates
173:27 - of where
173:28 - the car is it just kind of like defines
173:29 - the square that's all it's doing
173:31 - okay okay so there's two cars one car
173:34 - here one car here if there's ten cars
173:36 - like in the video stream there's going
173:37 - to be like 10 of these in here instead
173:39 - of just two
173:40 - right all right so that's really it
173:43 - let's go back
173:52 - and now all we need to do is once we
173:54 - have these coordinates we just print out
173:55 - we just want to draw a rectangle around
173:57 - that car so we can actually see it
173:59 - because we know where it is we just
174:00 - can't see it because there's no
174:02 - rectangle drawn on the image yet wait
174:03 - so those so those numbers were actually
174:05 - rectangles is what you're saying
174:07 - yeah they kind of define the coordinates
174:09 - oh this is guys
174:11 - yes this one yeah interesting okay okay
174:14 - okay
174:15 - okay okay okay the top left point the
174:17 - top left point of the
174:19 - of the rectangle and this is the width
174:21 - the height see it's the same because
174:22 - it's the square
174:23 - this is the height it's the square yeah
174:25 - yeah that's all interesting
174:26 - okay okay okay gotcha gotcha gotcha
174:28 - gotcha yeah applause for that this is
174:30 - really cool stuff
174:33 - you guys don't hear aaron you don't hear
174:35 - the sound of the chat
174:36 - you know i'm in the chat i'm gonna chat
174:38 - aaron you don't have you you don't have
174:39 - the center fox but we have some amazing
174:40 - sound effects going on in the background
174:41 - just so you know
174:42 - it's amazing sound effects yep yep yep
174:45 - yep you'll you'll see it later don't
174:46 - worry
174:47 - that we'll see you later oh in the
174:48 - stream okay i thought i thought it was
174:50 - like you know
174:51 - it was like dying outside in my
174:53 - background but there's nothing happening
174:54 - bro
174:55 - yeah awesome all right anyway
174:58 - yeah so this is just like because
174:59 - they're squares by default um we're
175:01 - detecting things within a square so this
175:02 - is the width and height of the square
175:04 - because it's the same number within
175:05 - height
175:05 - square and then this is the left the top
175:07 - left point in the image of where it is
175:09 - so from here we can be like okay this is
175:10 - the top left
175:11 - point and i just draw a square of these
175:13 - dimensions at that point
175:15 - going down to the right and that's
175:17 - actually where the um
175:18 - the car is in the image so there's two
175:20 - in this one
175:21 - okay so we have top left point and width
175:24 - and height
175:25 - okay if you guys watched the face
175:26 - detection video a couple weeks ago very
175:28 - similar we're just detecting different
175:29 - things and applying it differently but
175:31 - um same idea okay got it
175:34 - um so guys who's ready who's ready to
175:37 - see some squares
175:38 - and detection squares huh who's ready
175:40 - you guys ready you guys ready drop in
175:42 - the comment below
175:43 - and aaron let's see it let's see it bro
175:46 - got it all right you guys so
175:50 - um okay it's gonna be what's up e
175:54 - uh bgr so this is actually wrong let me
175:56 - okay let me explain this i just copied
175:58 - and pasted
175:59 - um actually let's get rid of this for
176:01 - now i don't want to okay ignore this
176:03 - loop for now
176:03 - actually let me just get it straight up
176:05 - delete it because i want to explain it
176:06 - line by line
176:07 - all right all right all right oops let's
176:10 - go
176:10 - logan hey so here we go here
176:13 - is the um
176:17 - the line to draw a rectangle so opencv
176:19 - allows you to draw a rectangle on any
176:20 - image
176:21 - very straightforward and simple so it's
176:23 - just called dot rectangle so
176:24 - opencv opencd.rectangle and then it's
176:26 - like okay what rectangle of what size
176:28 - what color what thickness and where do
176:31 - you want to draw that rectangle so this
176:32 - is all these specifications here and of
176:34 - course we have that data within cars
176:36 - so if we have the data in there then we
176:37 - can just print it out here okay
176:39 - but where you get the x and the y those
176:41 - are the question where is the x and y
176:43 - coming from
176:44 - uh from here so we're going to get that
176:45 - data out of here so remember okay okay
176:47 - remember we have these here so this is
176:48 - going to be x it's going to be y y it's
176:51 - going to be width and this is going to
176:52 - be height
176:54 - and then from there we can just x y and
176:57 - then x plus width and
176:58 - y plus height and then this is the color
177:01 - this is the color of the
177:02 - rectangle and this is the thickness of
177:04 - the rectangle oh that makes so much
177:06 - sense now guys
177:07 - actually that's not that's not that's
177:08 - not so bad at all guys you get this like
177:10 - drop down below do you get that like
177:12 - it's actually not bad you're simply
177:13 - drawing a rectangle with x y coordinates
177:15 - and you're saying here's the height and
177:16 - here's the width
177:17 - like that is pretty pretty interesting
177:19 - and it's actually not that bad
177:21 - to understand as well you can do it like
177:23 - we can do it
177:24 - you can do it too trust me if they watch
177:26 - their face detection stuff this is very
177:28 - similar they'll probably breathe
177:29 - through this right now just watching us
177:30 - bigger which is awesome exactly
177:32 - that was that was that one was with kazi
177:34 - you know so a little bit hard to make
177:35 - fun of him to make
177:36 - you know yeah he's more of a challenge
177:40 - anyways um so let's just actually prove
177:42 - that this is
177:43 - is working so we're gonna want to unpack
177:46 - um
177:48 - uh this so in cars it was actually an
177:50 - array right so there's an array here
177:53 - and then within the array there's two
177:55 - arrays within the array so let's just
177:56 - grab out these two arrays
177:57 - okay okay so this is going to be array
178:00 - at index zero
178:01 - and this is gonna be arrayed index one
178:02 - okay because there's two elements in
178:04 - this
178:04 - and there's a list of numbers in there
178:06 - okay so all we're gonna
178:07 - do is say um
178:12 - i guess cars at zero so this would be
178:15 - car one okay okay and then why why car
178:19 - zero
178:19 - cars let's just ignore the um let's just
178:22 - ignore the the second car for now okay
178:24 - okay so car one equals cars zero so if
178:27 - we print out
178:28 - if we print out car one
178:32 - car one just like that let's go
178:35 - here run it again as you can see we have
178:38 - just the first car so 375
178:39 - 375 that's what we're looking for and
178:42 - from there
178:43 - we just want to get the
178:47 - um x y within height so what we're going
178:50 - to say is we're going to unpack this
178:51 - i'm going to unpack this this this list
178:55 - here
178:55 - and say this is x this is y this is
178:58 - width
178:59 - and this is height okay okay seems to
179:02 - you guys
179:02 - you're still with us guys guys give us a
179:04 - thumbs up if you're still with us this
179:05 - is kind of like
179:06 - it's all coming together it is honestly
179:08 - not that difficult
179:09 - give us a thumbs up if you're still with
179:11 - us and aaron let's go let's go ahead and
179:13 - start seeing you know the result of all
179:14 - this
179:15 - hell yeah so um all we're doing here is
179:18 - we're unpacking this
179:18 - okay so car one again is this these four
179:22 - numbers and we just want to pack these
179:23 - four numbers into these four variables
179:24 - x y and height okay and then from here
179:27 - now this code should work so x and y
179:29 - is the top left point okay okay we have
179:32 - the we have the image you want to put it
179:33 - on the color image
179:34 - not the black and white image we want to
179:36 - color on the color image
179:37 - um and then put the top left point xy
179:40 - and then the bottom left the bottom
179:42 - right point which is going to be x plus
179:44 - width and y plus height
179:45 - okay that's how the graph works um and
179:48 - then from there this is just going to be
179:50 - uh should be red color so bgr remember
179:53 - instead of rgb so b
179:55 - so blue is zero g green is zero
179:58 - but red is maximum 255 is the highest
180:01 - value you can have so we're creating a
180:02 - rectangle basically that's it yeah a red
180:04 - rectangle of thickness two
180:06 - two pixels thick on this image at this
180:09 - top left point and this bottom right
180:10 - point
180:11 - that's all it is because that's all the
180:12 - rectangle is it's two points thanks and
180:14 - then you just the rectangle between
180:15 - those two points
180:16 - okay so let's run this and see what the
180:18 - heck happens
180:19 - guys ready actually nothing's gonna
180:21 - happen
180:35 - um so we drew it on the color image not
180:37 - on the black and white image but we're
180:38 - still displaying the black and white
180:40 - image so let's just display the color
180:41 - image which has the rectangle drawn on
180:43 - it now
180:44 - okay so now it should work so again
180:52 - [Music]
180:59 - let's go
181:12 - i got the perfect gift for it look at
181:14 - that oh look at that oh look at that
181:15 - you don't see it aaron but trust me we
181:16 - see it it's hilarious i'm looking at my
181:18 - code yo but i'm appreciating
181:20 - funny or something i'm making very much
181:21 - fun of aaron guys
181:23 - give aaron a thumbs up in the comments
181:24 - guys this is so epic look at this we
181:26 - already we did we just detected
181:28 - we actually just detected a one car
181:31 - like how crazy is that with how many
181:33 - lines of code directly
181:35 - directly in front of you oh i don't know
181:36 - one two three four
181:38 - five six seven eight nine ten eleven
181:41 - twelve
181:41 - thirteen lines of code fourteen lines of
181:43 - code guys thirteen bro
181:45 - learn to count you count okay you learn
181:48 - how to count okay i'll i can't find it
181:51 - minus one all right guys yeah that's
181:54 - just
181:54 - epic stuff so okay we got one rectangle
181:56 - now my question is how do we get the
181:58 - second rectangle
181:59 - if you guys know how to do that drop
182:00 - down the comments below and a lot of you
182:01 - guys are are a lot of you guys are like
182:04 - whoa let's go we got abdullah in the
182:05 - house we got harsha like yeah we got
182:08 - logan whoa
182:10 - we got oh man you guys are pumped for
182:12 - this look at that you guys are pumped
182:14 - i love it like this when this stream is
182:16 - done definitely go check out the face
182:17 - detection too because it's
182:18 - similar but it's a different application
182:20 - and it's pretty damn cool
182:22 - yeah yeah yeah sweet but this one for
182:24 - car and pedestrians
182:25 - all right so let's see let's see how do
182:27 - we go ahead and actually like
182:29 - get into the second car yeah okay cool
182:31 - well first of all why don't we just
182:33 - change this because this is a very easy
182:34 - change
182:35 - we're currently looking at the first car
182:37 - why don't we just get the second car
182:38 - instead by changing
182:40 - so here instead of grabbing this first
182:41 - car we just grab the second car and
182:43 - let's just draw the rectangle around
182:44 - that
182:45 - we simply do that by just changing this
182:47 - to grab the second car instead of the
182:48 - first car
182:49 - so second car right and let's change
182:51 - this to two just to be
182:54 - clean about and that there should just
182:55 - change all of this to the second car
182:57 - instead and we'll
182:58 - display it to the screen so let's just
183:01 - run it let's see it
183:02 - ready
183:10 - you say
183:16 - bro i'm not kidding abdullah abdullah is
183:18 - like in the comments like
183:20 - damn aaron and nas seem like siblings
183:21 - fighting
183:23 - yeah pretty much i mean like we spend
183:24 - pretty much every day together working
183:26 - on stuff all the time coding
183:27 - like we practically live together it's
183:28 - kind of annoying yeah i know
183:30 - i'm i'm i'm an artist that's it yeah
183:32 - yeah i hate everybody
183:34 - too much too much but anyways let's
183:36 - continue on we're here to learn right
183:38 - let's go
183:38 - yeah yeah yeah um so there that's the
183:42 - second car and like i said
183:43 - in this in this uh image this trained
183:46 - classifier is only good enough to train
183:47 - to like identify
183:48 - full-on cars from the back like this um
183:51 - these half cars you can't actually get
183:52 - them
183:53 - but actually if you trained um something
183:56 - to detect half cars like the right half
183:58 - of a car
183:58 - or the left half of a car you could
184:00 - actually find a way to detect all of
184:01 - these as well but you'd have to train it
184:03 - even further yeah
184:04 - and so on or like the bottom half of a
184:06 - car you know something's being but right
184:07 - now like this pattern is what we're is
184:09 - what we're
184:10 - checking is the the full a full back of
184:12 - the car
184:13 - right okay so now the point is all we
184:16 - want to do is instead of manually going
184:18 - through the array like this we just want
184:19 - to loop through all of them
184:21 - and draw every rectangle on the image
184:23 - for every car that we find
184:25 - okay so that's that's what i had before
184:27 - i'm just gonna have a
184:29 - a loop and this is gonna make it super
184:31 - super simple
184:32 - so let's just start from scratch i'm
184:34 - leaving this here for reference but just
184:36 - ignore just pretend we deleted all this
184:37 - okay
184:38 - so what we're going to want to do is
184:40 - just like in cars so in cars which is an
184:42 - array of
184:43 - an array of arrays we want to
184:46 - or is it an array of arrays we want to
184:48 - iterate through every sub-array so we
184:49 - would iterate through this first one and
184:51 - the second one and the third and fourth
184:52 - and fifth if there's any of those
184:53 - so basically we're saying um in cars you
184:56 - wanna
184:57 - take out the xy and the width and the
184:59 - height of
185:00 - every one of every list in there so
185:02 - actually i think if i just if i copy and
185:04 - paste this it'll be a little bit clearer
185:06 - yeah yeah so i think
185:09 - and that's another thing and the thing
185:10 - sorry let's cut you off so really so one
185:12 - important thing guys to mention
185:13 - one one important thing guys to mention
185:14 - is the way that this is works the way
185:16 - the whole
185:17 - y w h right this right here is
185:20 - interpolation like interpolation or
185:22 - there's a special name for it where
185:23 - basically
185:24 - it will take the object that's in cars
185:26 - right it will loop for that and it will
185:28 - basically grab
185:29 - the x y the width and the height out of
185:32 - those numbers
185:33 - right so it will abstract those numbers
185:35 - from those different places
185:37 - and so that is actually in python right
185:38 - i think i'm not sure what it's called
185:40 - interpolation but
185:41 - what it is but you're getting super
185:44 - confusing but
185:44 - no no no but but it's important because
185:46 - they're like okay where's this x y w h
185:48 - coming from
185:49 - right but because here's the thing it's
185:51 - looping through one single object so
185:53 - that maybe i can do like a screen brush
185:54 - on show screen brush if i can do it so
185:57 - yeah
185:57 - right there right so this is the first
185:59 - object right so this first object is
186:00 - going to be
186:01 - on here right in here and it's going to
186:04 - map to the x
186:05 - to here the y to here the w to here and
186:08 - the h
186:09 - to here and you don't see it but i'm
186:11 - drawing basically on your screen so
186:13 - yeah yeah so yeah that's that's the
186:15 - really cool part about python and
186:16 - javascript actually does this too
186:17 - but i just want to explain that and so
186:19 - that you guys know but anyways yeah
186:20 - let's keep going
186:22 - awesome yeah yeah i have the stream up
186:24 - on my phone looks like it's still live
186:26 - yeah we're good we're going we're in the
186:28 - bottom right that's we got 300 people
186:30 - in the house yo wait wait wait 300 which
186:32 - way are you that way can i punch you
186:37 - wait i think i can wait wait wait there
186:40 - we go go there you go hold on hold on
186:42 - hold on
186:43 - hold on ready punch hold on no no no no
186:45 - no no no
186:46 - no beat him up
186:50 - man i wish i wish i wish
186:53 - i wish we could like yeah yeah i wish
186:55 - there's like a real you know
186:56 - maybe you can punch you yeah that'd be
186:58 - good and then you're gonna get in the
187:00 - cage bro
187:01 - let's go i'm ready i'm ready i'm ready
187:04 - man i'm ready
187:05 - have you seen the fight club have you
187:07 - seen warrior with tom hardy
187:08 - steve is like please punch him if he was
187:10 - like please punch him
187:14 - wait punch who punch who's the question
187:17 -  each other bro they want to see us
187:19 - in a ring it's like logan paul in the
187:20 - ksi guys
187:22 - who wants to see a live caller who wants
187:24 - to see a live call like that
187:27 - or conor mcgregor in uh mayweather we
187:29 - can do it like that yeah
187:30 - but yeah let's let's keep going we're
187:32 - here we're here let's keep going bro
187:34 - yeah anyways so this is like the longest
187:36 - explanation of a loop ever yeah
187:40 - we're having fun you guys i mean we're
187:41 - having fun
187:43 - um so yeah we're going to loop over all
187:45 - these and then within each of these
187:47 - we're just going to unpack the x y w
187:48 - and h okay so that's all that's
187:50 - happening there and once we have x y w
187:52 - and h
187:53 - we just want to draw all of those
187:54 - rectangles
187:57 - on the screen we can get rid of this
187:58 - hard-coded so we're going to iterate
188:01 - through every
188:01 - um pair of coordinates in that list
188:03 - we're going to get all of them and then
188:05 - it's just the same exact line of code
188:06 - here we're just going to draw every
188:07 - rectangle
188:08 - on the screen but actually what i want
188:11 - to do
188:12 - is um a screw it that's fine
188:16 - what nothing nothing there's a little
188:18 - little flavor styling thing i was going
188:20 - to do but i'll do it later
188:21 - so right here this should work so if we
188:23 - run this this will actually loop through
188:25 - both cars
188:25 - and draw both rectangles both both
188:28 - squares
188:28 - so why don't we just save this and give
188:30 - this a run
188:32 - um so we just
188:36 - give this a run up arrow and hit enter
188:39 - and tada boom
188:43 - oh upper left hand point then we
188:45 - know the width and the height
188:46 - and then we with the width and the
188:48 - height and this point we can calculate
188:50 - this point so it's just
188:51 - boom boom red pixel width boom
188:54 - boom red two pixel width and bam that's
188:57 - it
188:58 - and that's it guys video that's it and
189:00 - then for videos
189:01 - you just want to do this for every
189:02 - single frame of the video over and over
189:05 - guys guys if we just did this for we
189:07 - just did this for a picture
189:08 - guys who's pumped to see this for a
189:10 - video
189:12 - drop that in the comment below aaron are
189:14 - you ready are you ready to show this in
189:15 - the video because i'll be epic
189:17 - oh girl i get up all night coding and i
189:18 - just i'm kind of like bored you know
189:20 - but uh hey let's go
189:23 - stuff is awesome like i'm gonna send
189:25 - this video to eli musk and be like adopt
189:27 - me
189:27 - please you know like uh you know like
189:29 - big bang theory yeah howard howard
189:31 - everyone's yeah yeah that's basically
189:33 - but you know pay me money pay me money i
189:35 - just i just did this for you you're
189:36 - welcome
189:36 - you know you're welcome yeah
189:40 - yeah or maybe he'll hire me who knows i
189:41 - mean maybe one day i'm not sure i'm not
189:43 - sure about it i don't know i don't know
189:44 - why you hired but aaron but anyways yeah
189:48 - i'll be a mma fighter like joe rogan and
189:51 - then i'll have elon musk smoke beat on
189:52 - my podcast
189:53 - oh man abdullah abdullah abdullah was
189:55 - like i put all my bets on nas thank you
189:57 - abdullah
189:58 - oh really all all his it's unknowns
190:03 - i think knowledge would be too scared to
190:05 - hit me i think that's what happened
190:06 - to too scared not sure about that i'm
190:09 - not sure about that
190:13 - whatever whatever okay okay all right
190:15 - let's continue on let's see
190:16 - let's go now that we have it done for
190:18 - one image now it's as simple as getting
190:21 - it into a loop okay
190:30 - all right so um i have that here uh it's
190:33 - pretty simple to add it
190:34 - the only difference is you have to read
190:36 - a video in
190:37 - instead of a um
190:40 - a video in instead of an image so let's
190:42 - go up here and actually change that
190:44 - so instead of image it's going to be
190:47 - a video um video okay
190:52 - so i have a video on my on my desktop
190:55 - called tesla dash cam accident so this
190:58 - is actually real dash cam footage from a
191:00 - real tesla
191:00 - that was running autopilot and avoided
191:02 - an accident okay so let's just
191:05 - um here tesla dash cam accident okay
191:08 - okay
191:12 - okay and this is just this is just a
191:13 - video basically you got from somewhere
191:15 - but like from youtube i think right in
191:16 - the description yeah
191:17 - it's in the description yeah yeah it got
191:18 - you know like self-driving tesla so as
191:21 - you can see
191:22 - this tesla almost it like auto drove and
191:24 - like got out of the lane
191:25 - and safely did that so we're gonna be
191:26 - detecting all these cars in this video
191:28 - okay it's almost over
191:30 - so that's it that's the car i have i
191:32 - trimmed it to that just that little clip
191:34 - but that's the first clip of the video
191:35 - in the description if you go check it
191:36 - out okay
191:37 - so that's first thing so instead of an
191:39 - image we just wanted a video
191:41 - okay and um from there so all the video
191:44 - is
191:45 - is just a bunch of images so we can just
191:47 - grab out each frame of this video
191:49 - and just apply the same thing as we did
191:51 - to this image to every frame
191:52 - and then display the rectangles on every
191:54 - frame and just loop forever into them
191:56 - okay so let's do that okay so i'm really
191:58 - interested to see how this one this
191:59 - actually works out okay cool cool
192:01 - yeah um i'm gonna
192:05 - hey what's up caesar caesar in the house
192:06 - hey what's up
192:12 - copy paste it you know oh yeah that's
192:14 - the best best way especially the code
192:15 - guys i would just copy and paste don't
192:16 - ever don't ever create your own code
192:19 - i'm kidding by the way i'm kidding
192:23 - so um yeah i'm just taking a peek here
192:25 - so yeah we need a while loop and
192:27 - everything so
192:27 - well i'll type out this one because it's
192:29 - because it's short this is the first
192:30 - line of code i'm actually coding on the
192:31 - stream i copy and pasted everything up
192:33 - to this point
192:34 - okay okay but pretty much what we're
192:37 - going to want to do is we're going to
192:38 - want to have a while loop okay
192:40 - not caps supposed to be and we just want
192:42 - it to run forever
192:43 - okay because the video might be if
192:45 - you're driving a car you don't know how
192:46 - long the video is going to be like a
192:47 - real self-driving car so you just want
192:49 - it to run forever
192:50 - and then at some point when the car is
192:52 - turned off or like it reaches its
192:53 - destination you could be like okay turn
192:55 - this to false and then it'll stop
192:56 - reading
192:56 - it'll stop reading um stuff from the
192:59 - camera so we're just this is just going
193:00 - to run forever so that's the first step
193:02 - now within here we want to run this
193:05 - same logic on every frame so again we
193:08 - had an image here but instead of an
193:09 - image we want to get a frame from the
193:10 - video
193:11 - so we're actually not going to read an
193:13 - image we're going to be reading a frame
193:14 - from a video
193:16 - and that's what this thing here is so
193:17 - let's just copy and paste
193:19 - this okay okay
193:23 - let's see it's indented properly
193:26 - so the way we do that is okay run
193:30 - forever until car stops or something
193:33 - or crashes okay
193:36 - yeah um yeah there we go
193:40 - i've still until what the car crashes oh
193:44 - i don't get sued by tesla
193:47 - um but yeah so there's in in
193:51 - um an open cv uh once we have the video
193:54 - here
193:54 - okay we have one it's called video
193:56 - capture so see opencv two dot
193:58 - video capture and the name of the the
193:59 - file then you can just
194:02 - uh run this and we can just run read so
194:04 - all this will do is it'll read
194:05 - one frame from the video okay and that's
194:08 - a function part of it's a function part
194:10 - of cv
194:13 - okay interesting okay so once you've got
194:15 - another video capture object
194:17 - here called video then you can call dot
194:19 - read
194:20 - on that video capture object which is
194:22 - just the video so you're just going to
194:23 - read
194:24 - you're going to read a single frame from
194:25 - this video okay and then once it reads a
194:27 - single frame it keeps track of it so
194:29 - when it when you call this the second
194:30 - time it gets the second frame
194:32 - when you call this the third time it
194:33 - gets the third frame again
194:35 - through all the and that's how this is
194:36 - implemented and
194:38 - uh what it returns is it actually
194:39 - returns two values so the first value is
194:41 - if the read was successful or not
194:43 - it might be might be actually keep this
194:45 - in parentheses
194:47 - yeah if the read was successful or not
194:49 - and then the second
194:50 - the second value is if the frame is the
194:53 - actual frame so like this frame is
194:54 - actually the image which is just going
194:56 - to be the same as this
194:58 - so this frame here is actually what we
195:00 - want instead of instead of using image
195:02 - and reading an image in
195:03 - we're reading a frame from this video
195:05 - got it got it got it so we got the frame
195:06 - here and then this here is if the frame
195:08 - was read successfully so we definitely
195:10 - want to have good code
195:11 - and make sure that there wasn't errors
195:13 - before we try to display it yeah okay
195:15 - and the way and the way i see it is like
195:16 - this biscuit this video that read
195:17 - basically
195:18 - returns an array which we simply
195:20 - basically map the first
195:22 - portion so no when you call it a tuple
195:25 - a tuple it's called no it's a tuple
195:27 - right it's a tuple
195:29 - yeah a tuple a tuple returns a tuple
195:32 - until we map the first
195:33 - the first okay fine fine fine fine fine
195:35 - fine
195:37 - because five it's tuple because we map
195:39 - the first part of the tuple to the two
195:41 - here and then the second part of the
195:42 - tuple is going to map to here
195:43 - now we don't actually see this you know
195:45 - but in the background that's actually
195:46 - what happened so i just want to make
195:47 - sure that
195:48 - you guys understand this but yeah
195:49 - anyways let's keep going it's the same
195:51 - thing as here we're unlocking a four
195:53 - pole here
195:54 - i mean it's just a four a four variable
195:57 - two four
195:58 - a fourth ball i can't even say that
196:03 - of course we're unpacking these four
196:04 - variables out of this array same thing
196:06 - we're packing these two values out of
196:07 - this array okay okay okay and this ray
196:09 - is a frame which is
196:11 - itself an array it's an image and then
196:13 - this is
196:14 - a boolean yes or no yo kaz is in the
196:16 - house yo
196:17 - what's up all right keep going what's up
196:19 - quasi
196:20 - all right so next what you want to do is
196:22 - of course
196:23 - i'll just type this one out what you
196:25 - want to do is you only want to
196:27 - handle this frame if it was successful
196:29 - so you want to make sure
196:30 - you're checking so here we'll call this
196:32 - safe coding
196:36 - use protection you guys
196:38 - [Laughter]
196:40 - save coding uh
196:44 - was successful i mean i there's a little
196:47 - optional live stream it's like is this
196:48 - video made for kids i was like
196:50 - uh no i turned that i turned that option
196:54 - on hard
196:54 - so if there's any kids here you're not
196:56 - supposed to be here okay you're supposed
196:57 - to
196:58 - um this guy you can still look at it so
197:01 - you can still learn it's fine
197:02 - but but yeah so here if if read is
197:05 - successful
197:06 - yeah then you want to operate on this
197:07 - frame okay so i'm just going to copy
197:08 - paste the rest because
197:09 - okay so
197:13 - um so if the read was successful okay
197:17 - only then do you want to continue so
197:18 - then at that point we'll get the frame
197:20 - which is here and then we'll convert the
197:21 - grayscale
197:22 - okay because if you um if you if the
197:25 - frame didn't read
197:26 - correctly okay if this returns false
197:29 - because the frame is broken
197:30 - you can't actually call this on this
197:32 - next step is this needs to be a valid
197:34 - frame for it to be converted to
197:35 - grayscale so if this is an invalid frame
197:37 - because the read
197:38 - like screwed up then you just want to
197:40 - skip this and
197:41 - just break out the loop okay all right
197:43 - just
197:44 - when would it ever be a non invalid
197:47 - frame
197:49 - last on when the last frame of a video
197:51 - it'll automatically
197:52 - end video by itself automatically okay
197:55 - okay if you air out or if you manually
197:58 - say hey
197:59 - stop this video yeah but wait guys we're
198:01 - really late guys we're completely
198:02 - kidding about the kids thing
198:04 - if you're a kid it's okay to say a lot
198:05 - of you guys like oh my kid i'm a kid and
198:07 - i'm a kid i'm a kid
198:08 - i'm a kid you know i'm like guys it's
198:09 - okay we're completely joking about this
198:11 - stuff
198:12 - guys i mean it's it's already forgotten
198:15 - at this point
198:16 - yeah yeah yeah welcome kids welcome to
198:18 - woody wonka's chocolate factory oh god
198:20 - all right that's that's let's keep it
198:22 - let's continue
198:24 - um oh man hi mom
198:29 - so where are we at yes it's gonna break
198:31 - out so once we have the grayscale
198:32 - grayscaled frame here the same
198:34 - idea of an image and black and white we
198:36 - can actually change this to black
198:38 - i'll just keep it grayscale that's the
198:39 - proper term instead of black and white
198:42 - then we have a grayscaled frame from
198:44 - here okay
198:45 - okay and why don't we just um display
198:48 - that
198:49 - so okay let's see it actually um
198:52 - let's comment all of this out
198:55 - because it's gonna it's gonna break
198:57 - something okay okay okay
198:59 - and and let's just
199:04 - this is not going to do anything because
199:06 - it's not displaying anything so we do
199:07 - need
199:07 - the display code again okay remember the
199:10 - display code want to display the current
199:12 - frame
199:13 - in this case it'll be scaled frame
199:15 - instead of image
199:16 - okay instead of image it'll be
199:18 - grayscaled frame
199:20 - and it'll only get here if the frame was
199:21 - successful remember that you guys
199:22 - because else we break out of this while
199:24 - loop and then we don't even get to this
199:25 - code so it avoids
199:27 - the errors i'll ask you a question let
199:28 - me ask you a question we have logan
199:30 - actually asked a question
199:31 - would it be better to or to would it be
199:33 - better to only
199:34 - what would it be better to only use
199:36 - every other frame for speed
199:40 - yeah yeah you could do that of course
199:43 - you would have a little bit lowered
199:45 - um quality you could even lower the
199:47 - resolution of each frame to go even
199:48 - faster because just because the
199:50 - resolution of an image is halved
199:51 - like if this was kind of blurry you as a
199:53 - human could still tell this is a car
199:55 - if it was super blurry you could
199:56 - probably still tell it's kind of like a
199:58 - car you could kind of make it out you're
199:59 - like okay this is a highway
200:00 - and a car so there's many things you can
200:02 - do to speed it up you can down scale it
200:04 - um actually i'll touch on quick if you
200:06 - go to detect multi-scale
200:08 - that's the scale factor actually be like
200:10 - okay blur this image little bit to make
200:12 - it faster
200:12 - you can like increase factor oh
200:15 - interesting okay that's
200:16 - yeah that was good i think that was a
200:18 - good question
200:19 - yeah like if you have 4k footage it's
200:21 - gonna be kind of like really hard to run
200:23 - all the algorithms but if you scale it
200:24 - down to like scale 4k down to like 360
200:27 - pixels 360p
200:28 - or 480p it'll be a lot faster and it
200:30 - might still work
200:31 - so you can that's probably and that's
200:34 - probably what tesla does as well right
200:35 - because they probably scale down the
200:37 - image so that they can process it much
200:38 - faster
200:39 - right because you can't pass like 4k
200:41 - yeah
200:42 - yeah there's some trade-off between
200:44 - having accuracy with high resolution
200:46 - images and also speed because
200:47 - when you're driving a real car you need
200:49 - to have real like real-time feedback
200:51 - so they go as high as as high as the
200:54 - accuracy can be
200:56 - while keeping it real time because speed
200:58 - is speed and accuracy are both important
201:00 - it's like oh this car is going to hit me
201:01 - and then two hours later
201:02 - you don't turn you know you're still
201:03 - getting there yeah yeah you got it
201:07 - like too late yeah just like this
201:10 - playing like this guy crashing before
201:13 - remember like
201:14 - like tesla here it sees this and as soon
201:16 - as he comes
201:17 - over he's instantly it's quick it's
201:18 - quick it's really cool yeah it's like
201:20 - instantaneous
201:21 - so there's a trade-off of accuracy and
201:22 - speed there yeah yeah okay
201:24 - cool sweet all right moving on
201:28 - so uh from here we're gonna display the
201:30 - gray scaled frame and then of course you
201:32 - need to have
201:33 - um this because this will just display
201:36 - for a split second then disappear so we
201:38 - want it to stay on the frame
201:39 - the current frame and this actually
201:41 - tells us stay on the frame for one
201:42 - second or one millisecond or something
201:43 - like that okay okay
201:44 - and then and then it'll loop up and show
201:46 - the second frame it'll
201:47 - read the frame it will if it's
201:50 - successful it'll turn it gray
201:51 - and then it'll display it the gray the
201:53 - gray skilled frame and then it'll wait a
201:55 - second one millisecond and repeat
201:56 - and it'll do this for every single one
201:58 - so this is basically not you're not
201:59 - creating a video
202:01 - no no i'm creating a video okay you are
202:05 - so this is going to be a black and white
202:07 - version of that same video
202:08 - god okay okay okay okay i get it i get
202:11 - it okay okay okay
202:12 - okay uh-huh is right no i don't know
202:15 - what blue is
202:16 - is it red all
202:19 - i have to right every joke bro like it
202:20 - turns unfunny when you say it
202:24 - anyways hey hey look at that
202:28 - oh this is like it's like sped up why is
202:29 - it so sped up he cut
202:31 - because we changed the gray scale so it
202:32 - can compute it faster
202:35 - oh see okay okay okay okay interesting
202:38 - so it's going faster
202:39 - and this is the whole video the video is
202:41 - going and then when the video ends it
202:42 - automatically closes
202:44 - guys do you understand like in trouble
202:46 - cosplay do you understand how this even
202:47 - like displaying that specific video
202:49 - right
202:50 - because like i mean look like drop in
202:52 - the comments below if you understand
202:53 - like the way
202:54 - this is working right the way i
202:56 - understand it personally the way i
202:57 - understand it personally
202:58 - is literally right if we have the way i
203:00 - see it is like yes we have a video
203:02 - right we have a video right here what we
203:04 - literally do after that point
203:06 - is we literally we unpack the video and
203:09 - we go through
203:10 - frame by frame and then we output
203:13 - that frame again to create yet another
203:15 - basically video
203:17 - it's just at this time we added the
203:19 - video simply because we changed it to
203:21 - grayscale so every single frame
203:23 - as you guys know every video right is
203:24 - created it's created with frames
203:26 - right what we do is literally take that
203:29 - frame we convert it to grayscale and
203:30 - then we show it again
203:32 - and again you went from video to another
203:35 - video
203:35 - except this time it is grayscale so i
203:38 - just thought it was really interesting
203:39 - if you know what i'm talking about like
203:40 - drop in the comments below because
203:41 - that's just that's mind-blowing to me
203:43 - you know
203:44 - yeah what he said yeah what i said
203:47 - [Laughter]
203:50 - all right guys so we have the gray
203:51 - skilled images here in a loop and it's
203:53 - properly looping through every frame of
203:54 - the video
203:55 - now all we need to do is run the
203:57 - detection code again
203:59 - and then from there once we have the
204:01 - detection code we can draw the
204:02 - rectangles again on the colored image
204:04 - and then display the colored image
204:05 - the colored frame instead of the
204:07 - grayscale frame and interesting that
204:09 - pretty much does it and then at that
204:10 - point that we
204:10 - also want to introduce pedestrians and
204:12 - use different kinds of videos with both
204:13 - and mix them together
204:14 - but that's the last step so yeah yeah
204:17 - let's go with that next so the next
204:18 - thing
204:18 - is once we have our grayscaled frame we
204:21 - want to run the car classifier on it
204:23 - remember we have our
204:25 - um oh i don't even have it it's uh
204:29 - i deleted it didn't i what cart tracker
204:31 - so let's get this back
204:33 - okay so let's get our car classifier
204:36 - back
204:36 - and paste it up here once we have the
204:38 - classifier file then you want to feed
204:40 - that into cascade classifier and we have
204:42 - a car tracker now so this is the
204:44 - pre-trained data that we downloaded from
204:45 - this file
204:46 - okay now with this car tracker
204:49 - we can do the same thing we can just go
204:52 - down here and copy paste the code
204:53 - because
204:54 - laziness and detect cars
204:57 - especially i mean yo copy and paste as
205:00 - much as you can because
205:01 - what's the point of typing it out like
205:02 - you want to show bigger and bigger
205:04 - problems sure
205:05 - at the same time this is literally
205:07 - cutting the stream length in half and we
205:08 - could fill it up with jokes
205:10 - yeah yeah okay okay okay so now we want
205:13 - to
205:13 - detect all the cars in this current
205:15 - frame so again
205:16 - um we have our car tracker up here auto
205:19 - highlights for us
205:20 - and then again we want to detect all of
205:22 - our cars regardless of the scale
205:25 - of the of the um car match and then what
205:28 - we're feeding in
205:29 - is the grayscaled frame okay because
205:32 - this is the current frame in black and
205:34 - white
205:34 - and black and white is much faster okay
205:36 - okay okay and if any and if you just
205:38 - just so you know guys like
205:39 - when we say frame a frame is simply hold
205:41 - on motion a frame
205:43 - is simply just a still image it's just a
205:45 - image
205:46 - from the video right that's why it's
205:48 - able to detect the car so it's not
205:49 - actually moving
205:50 - it's just one image right that's the
205:52 - interesting part about it right we took
205:54 - that image out
205:55 - so yeah let's let's get on and that's
205:56 - how we were able to detect
205:58 - right multiple detect those cars in
206:00 - there
206:02 - hell yeah what he said yeah what i said
206:06 - what he said
206:07 - [Laughter]
206:10 - hey no no no not hitting me
206:13 - let's take it outside okay we'll take it
206:15 - outside next time
206:17 - after this corona things done i'm back
206:18 - in l.a kidding me man
206:20 - man guys man but this can be a live
206:23 - stream okay
206:25 - i'll cough on you bro
206:29 - that's not gonna do anything to me
206:32 - yeah you can cough at your own pace
206:34 - coffee your own plows you know
206:35 - don't don't cough here don't cough in
206:37 - that way this is the stupidest stream
206:39 - ever
206:39 - but whatever um
206:42 - we paid like two dollars right like
206:44 - people have donated to us i know
206:46 - we made two euros we can go get coffee
206:49 - you can get the dollar coffee from
206:50 - mcdonald's hey
206:51 - let's go let's go anyway so
206:54 - yeah we have the cars here and again
206:56 - remember this is an array of a bunch of
206:57 - different coordinates of the cars
206:59 - so why don't we actually print out um
207:02 - print that out so let's print out cars
207:04 - and each time for each frame you're
207:05 - gonna see a bunch of different stuff
207:07 - print out because every frame there's
207:08 - multiple cars
207:09 - so you're gonna see a bunch of stuff
207:10 - printed on the terminal forever because
207:12 - it's a it's a loop
207:14 - so let's actually run this
207:17 - okay and as you can see
207:21 - wow we have a lot of cars detected in
207:23 - each frame we just haven't drawn them on
207:25 - the video yet
207:26 - you can see them all getting spit out
207:27 - here you know top left point bottom
207:29 - right point the width
207:30 - and the height that's insane the width
207:33 - and the height is always the same
207:35 - that's insane by default and then you
207:37 - get and you can see some of them and you
207:39 - can see some of them don't even have a
207:40 - car
207:40 - yeah some of the yeah they don't have
207:42 - cars correctly but there is no car
207:45 - in that frame and it just skips it and
207:47 - then once it gets to the end
207:48 - um this when there's no frames left this
207:51 - actually becomes false because it can't
207:53 - read anymore so this actually does air
207:54 - out
207:55 - so it actually does get to this break
207:56 - statement on the last frame of the video
207:58 - and that's what you're seeing gotcha
207:59 - screen happens okay and then and then it
208:02 - gets to the code completed remember
208:03 - got it that's why it's good to have this
208:04 - because you can see
208:06 - got it there dope so now last step is
208:10 - just drawing the rectangles on the
208:12 - colored image just the same as with the
208:13 - image
208:14 - okay so pretty simple uh we don't need
208:16 - print cards anymore
208:19 - and of course on the copper paste master
208:23 - of course um
208:30 - yeah this one right i think so
208:36 - rectangles
208:41 - there we go so
208:44 - uh pretty much this should work now only
208:47 - only error is
208:48 - that this image is not an image it
208:50 - should be actually
208:52 - uh frame should not be image because
208:54 - we're not doing images anymore we're
208:55 - doing frames so we just pop frame in
208:57 - there
208:58 - so it'll iterate over every single car
209:00 - it finds in each frame
209:01 - and then it'll just draw a rectangle
209:02 - around that car on that current frame
209:04 - again with a red color and a two
209:07 - thickness
209:08 - got it got it
209:12 - so let's just run this and see what
209:13 - happens let's run this baby guys ready
209:14 - are you guys ready for this
209:15 - you guys ready all right let's see what
209:17 - happens actually
209:19 - on okay oh dang
209:22 - uh it is not working and oh no oh
209:25 - man oh no oh no bueno this is not good
209:28 - no good it's not good
209:29 - no good no reason is we are still
209:32 - displaying the grayscale image
209:34 - we actually display the frame because we
209:36 - drew the rectangle on the
209:37 - frame so okay okay little bug there
209:39 - actually did you guys see that did you
209:41 - guys get that did you guys get that
209:42 - i hope you did yeah because it was black
209:44 - and like when i ran it i'll run it again
209:46 - okay it was oh okay so now it's working
209:50 - oh hold on hold on you guys are you guys
209:53 - ready you guys ready you're ready for
209:54 - this
209:55 - you ready for this it's black and white
209:57 - no come on
209:59 - because when i ran it yep still black
210:00 - and white okay because it says
210:01 - grayscaled frame here but if we're
210:03 - explaining the colored frame which has
210:05 - the squares
210:06 - drawn on it then i can save this and
210:08 - display the frame so let's go
210:11 - um back here this is normal frames right
210:14 - now
210:15 - clear again okay now now we're
210:18 - displaying the colored image
210:19 - with the rectangles drawn on each frame
210:21 - over and over and over again okay
210:23 - within the while loop because you want
210:25 - to make sure
210:31 - [Music]
210:36 - all right you ready ready hey let's go
210:40 - oh but i mean hey it's not random you
210:43 - can tell that it's more correct than it
210:45 - is incorrect
210:46 - like it's not just random words all over
210:48 - the image it's fairly
210:49 - it's pretty damn accurate like we think
210:51 - about it this is like amazing accuracy
210:52 - that's not nearly good enough for like
210:54 - real world scenarios and cars but you're
210:56 - we're 80
210:57 - there bro that is insane this is some
210:59 - magic guys seriously like
211:00 - this is some magical stuff like how
211:04 - how pumped are you to see this or to
211:06 - even build something like this
211:07 - especially the fact that we just built
211:09 - this like guys we literally just built
211:11 - this in like what and how many and
211:12 - what i mean an hour an hour and a half
211:14 - and two or maybe holy
211:17 - i mean holy bro chill out guys i
211:20 - only okay i only have i only have one
211:22 - gift to show
211:22 - to show how i think we we feel like
211:25 - right now
211:26 - are you ready ready to see this i'm
211:27 - sorry aaron you don't see this but they
211:29 - will see this
211:30 - so only one only one way
211:33 - only this way oh yeah peace out peace
211:36 - out guys this is how we do it
211:38 - all right let me check this drop in the
211:40 - comments guys for some
211:42 - you'll see it it's there's gonna be a
211:44 - small delay but that's all right
211:49 - who is that there's some random random
211:57 - logan's like this is awesome valley this
212:00 - is
212:00 - epic we got logan wow
212:04 - i mean we haven't even gone to
212:05 - pedestrians yet how do we how do we
212:07 - detect pedestrians
212:08 - and cars in the city oh wait so we
212:09 - haven't got the pedestrians yet
212:11 - no not real we haven't even touched that
212:13 - yet we still got to download that
212:14 - classifier and get that running you have
212:16 - to scan
212:16 - across every frame from both of them so
212:18 - that we can detect pedestrians and cars
212:21 - okay and then you can also you could
212:23 - train them for anything like you could
212:24 - train
212:24 - to detect nas you know um in videos and
212:27 - stuff if you want to that's important
212:29 - detecting
212:29 - who would want to do that
212:33 - everybody okay guys but uh what i'm
212:36 - gonna do is i also want to show you some
212:37 - other videos so i actually have a bunch
212:39 - here
212:39 - okay let's see um i have a couple other
212:42 - videos that i pulled out from youtube
212:44 - this is all from the same video linked
212:45 - in the description there's like okay
212:46 - it's like within the first three or four
212:48 - all three of these clips are in that
212:49 - video i skipped some of them because it
212:51 - was like dark and rainy
212:52 - and it wasn't performing that well but i
212:54 - mean this is pretty good performance for
212:56 - stuff you downloaded off the internet of
212:57 - course if you trained your own hardcast
212:59 - classifier extensively and you let it
213:01 - run for like three weeks
213:02 - and you traded it then that have really
213:05 - really really good results
213:06 - but these are just ones i just
213:08 - downloaded off the internet like like i
213:09 - said like the car data set
213:11 - this was created by people like caltech
213:12 - the california institute of technology
213:14 - um but these cars all look old so this
213:16 - must have been done in the freaking 80s
213:17 - you know so like this is old data
213:19 - um that we're using but they did use
213:21 - this to train their hard cascade but we
213:23 - could go out and take our own thousands
213:25 - of images but i mean i'm not going to do
213:26 - that sorry guys okay yeah yeah
213:27 - that's too much work that's too much
213:29 - work why we define the wheel but it's
213:31 - already defined for you you know
213:33 - yeah yeah and you know it's like use use
213:35 - a library because it exists
213:36 - but hey we got robert robin donated a
213:40 - hundred i don't know what might that i
213:41 - don't know what money that is
213:42 - a hundred you're not euro something i
213:44 - don't know how much money that is it's
213:46 - like robin
213:46 - yeah anyways 100 something thank you
213:49 - robin appreciate it
213:54 - what was his name robin robin yeah
213:56 - appreciate that rob
213:58 - yep appreciate that now
214:01 - um let's continue on so the next step
214:04 - would be
214:06 - um oh yeah i was going to show the other
214:07 - videos so let's just change up this
214:09 - video
214:10 - so this one this one is actually one
214:11 - where um
214:14 - the tesla self-driving car actually can
214:16 - detected and avoided a tumbleweed so it
214:18 - was a huge thing on the road
214:20 - and it actually avoids it so let's run
214:21 - this footage
214:23 - so this happens here okay it's running
214:25 - in color and then boom
214:26 - tumbleweed where and it just dodged it
214:29 - bro you missed it i missed it oh man
214:33 - oh there it is there it is oh dang so
214:36 - that is insane yeah in an actual video
214:39 - the guy's talking and then somebody
214:41 - behind him actually hits it so i don't
214:42 - know but hopefully they're okay
214:43 - but it's just a tumbleweed it'll damage
214:45 - your car but unless they swerve they
214:47 - might cause an accident but if they just
214:48 - hit it it should be
214:50 - fine i hope and uh yep so that's that's
214:54 - another video from that clip
214:55 - and then here's another one i just
214:56 - pulled this off like randomly off the
214:58 - internet i just did tesla
214:59 - dash cam footage and i just found this
215:01 - video and then here this last one
215:03 - um is some highway footage also from
215:05 - that same clip so feel free to go watch
215:07 - that same clip
215:08 - that's damn guys how cool
215:12 - is that like how cool is that the fact
215:15 - that we just created a system
215:17 - that you know i mean i would say tesla
215:18 - like i mean i would say it's not perfect
215:20 - right
215:21 - but but the gist of it and that now you
215:23 - understand kind of how it works
215:25 - i want to point that out see how this is
215:27 - constantly saying it's a car because
215:28 - think about that there's the dark window
215:30 - the light bumper the dark shadow so it
215:33 - keeps
215:34 - mistaking this for a car because it has
215:35 - that same profile remember
215:37 - the heart feature of light and dark dark
215:40 - and light
215:41 - and then light and dark remember yeah
215:43 - from here
215:45 - so this matches these things this
215:48 - thing kind of looks like this because
215:50 - there's a dark window a light bumper and
215:51 - a dark shadow underneath the car
215:53 - see dark window light bumper and a
215:55 - shadow underneath the car
215:56 - so that's why it is it's miss miss
215:58 - classifying this
215:59 - so false that's why it's not a perfect
216:02 - system right it needs a lot more
216:03 - classification basically for this
216:05 - yeah i mean if you ran it super
216:06 - extensively you could you could detect
216:08 - every single car
216:09 - in the single image perfectly but it
216:10 - would take forever to run it wouldn't be
216:12 - running that fast that makes sense that
216:13 - makes sense uh-huh
216:14 - okay and so that's it so these
216:17 - these clips are in the description um
216:20 - you're gonna have to download the
216:21 - youtube video yourself
216:22 - and then trim it trim out the the clips
216:25 - but you can definitely do that and then
216:27 - just name it whatever you want
216:28 - it's an mp4 file so make sure you
216:29 - download the video got it got it got it
216:32 - that's really it so i had those three um
216:34 - examples
216:35 - okay and one thing i did forget the show
216:38 - is uh
216:39 - nah that's okay it's too late i already
216:41 - showed the image thing yeah
216:43 - uh with the with that video so what
216:45 - should we do now so what what's the next
216:47 - step aaron
216:49 - well why don't we
216:52 - detect this the thing i started off with
216:54 - the demo where there's cars and
216:55 - pedestrians
216:56 - okay both in the same video i don't know
216:59 - if you guys can hear that
217:01 - but okay
217:05 - but yeah this is the the original
217:07 - footage i showed so now we want to
217:08 - actually introduce pedestrians as well
217:10 - all right let's do it bro we got cars
217:12 - next thing is pedestrians then we got
217:14 - cats and dogs
217:15 - no okay we're just going to do
217:16 - pedestrians i think yeah pedestrians so
217:19 - yeah
217:19 - who's probably going to do cats and dogs
217:21 - next time but i mean i think
217:22 - self-driving cars is cooler
217:23 - yeah yeah maybe next time maybe next
217:25 - time but yeah if you're pumped to see
217:26 - that let's get into it
217:28 - actually drop in the comments below too
217:29 - drop in the comments below
217:31 - yeah so what we're going to want to do
217:33 - is
217:34 - we are going to want to actually
217:36 - download another
217:37 - um classifier okay okay so we have a
217:40 - card classifier and that's what's doing
217:41 - all the work for our car classifier
217:43 - but we're also going to want a
217:44 - classifier for pedestrians and have both
217:46 - of them running
217:47 - okay okay so how we do that is
217:50 - we're just simply going to download
217:51 - another pedestrian classifier so again
217:53 - the link is in the description
217:54 - this one is actually supplied to us from
217:57 - opencv by default there's a hard cascade
217:59 - file xml file again
218:00 - called power cascade full body right
218:03 - here on my desktop
218:04 - open this up so it's the same exact
218:06 - thing again it has the
218:08 - all these crazy numbers and it goes on
218:10 - for thousands and thousands of har
218:11 - features
218:12 - um and it filters through all of it but
218:14 - this series of heart features
218:16 - kind of matches up with what a
218:18 - pedestrian would look like whether
218:19 - they're standing or walking
218:21 - or running or whatever or even like on a
218:22 - scooter they would still they would
218:24 - still be able to detect it
218:26 - yeah yeah so a bunch you can see it goes
218:28 - on forever and it takes forever to train
218:29 - this and actually generate these correct
218:31 - numbers
218:31 - just capturing the relationship in the
218:33 - patterns evil
218:35 - aval aval aval is like wow this is
218:37 - amazing
218:39 - wow oh robin robin just donated another
218:43 - 200 i think it's called v v dollars i
218:46 - don't know what it's called
218:47 - but another 200 dang
218:50 - i don't know what the videls are but it
218:51 - sounds like thank you robin
218:54 - appreciate it oh wait well actually he
218:56 - actually asked a question he asked the
218:58 - question actually
218:58 - his question was and i can't i can't put
219:00 - up on the screen because i don't have a
219:01 - for example
219:02 - for some reason actually show up on ecam
219:05 - but his question was
219:06 - if a different ide is used while speed
219:09 - and accuracy get impacted and output
219:13 - a different ide yeah no
219:17 - no reason being is this ide is just a
219:19 - code editor it just makes the color it
219:21 - makes the colors nice it makes strings
219:23 - orange it makes comments in green
219:24 - it does all that nice stuff but when
219:26 - you're running code from the terminal
219:28 - it's literally just getting this raw
219:29 - text file this raw python file which is
219:31 - just a text file that has python code in
219:32 - it
219:33 - and then it runs that python code so
219:35 - like i could even open up this python
219:36 - code
219:37 - i could open it in text edit okay got it
219:40 - like this is the code for running in vs
219:41 - code so it doesn't matter what you're
219:43 - using to edit it
219:44 - it's just running this raw text code
219:46 - it's just translating this to
219:47 - ones and zeros the computer understands
219:49 - so actually what's running all that
219:51 - stuff is literally just this text file
219:52 - this text file is
219:53 - generating all of this this tracking so
219:56 - it's reading the file name
219:57 - getting all the stuff it's making the
219:59 - classifier i mean you know i can't see
220:01 - but like yeah so to answer so to answer
220:04 - your question quickly
220:05 - no will not biscuit would not matter it
220:06 - will not impact any processing or
220:08 - anything like that at all
220:09 - zero yeah yeah yeah zero sweet
220:14 - and um yeah so let's just move on to
220:16 - pedestrians okay
220:17 - [Music]
220:25 - yeah so let's just move on to
220:26 - pedestrians okay so i have a video here
220:29 - a dash cam
220:29 - of dashcam pedestrians which is this
220:32 - video
220:33 - of a lot of pedestrians here there's not
220:35 - so many cars because i want to show this
220:36 - first
220:37 - okay okay okay
220:40 - and what we're gonna have to do is we're
220:42 - gonna have to actually get the
220:44 - um pedestrian classifier as well so
220:48 - actually let's just grab this
220:52 - okay and paste this here okay
220:55 - so classifier file is car detector
220:58 - really
220:59 - this should be called car tracker so
221:00 - actually let's change that
221:02 - so it's only popping up here and here
221:04 - but let's change this to car tracker
221:06 - all right okay okay to car tracker
221:09 - so now it's a little bit clear that this
221:11 - is a car tracker
221:14 - and um well actually
221:18 - what we have two different trackers
221:20 - right one is a car tracker and then wait
221:22 - so yeah yeah i uh
221:25 - screwed it up a little bit so we should
221:26 - actually no no this is car tracker down
221:29 - here
221:29 - so this should be car tracker file oops
221:32 - and this should be car tracker file okay
221:34 - okay so ignore this stuff let me just
221:36 - delete it because it might be
221:37 - confusing so let me ignore that for now
221:39 - so what i did was i changed this name to
221:42 - car tracker file to be a little bit more
221:43 - descriptive with the name and then again
221:45 - we're just popping this car tracker file
221:47 - into here to get the class k classifier
221:49 - which create
221:50 - gives us our car tracker now let's
221:52 - repeat these two lines of code but for
221:53 - pedestrians
221:54 - okay so for us it's going to be
221:58 - pedestrian file tracker
222:01 - no pedestrian tracker file equals this
222:05 - okay so it's the same thing as this line
222:06 - but here for pedestrians
222:08 - okay we have a different xml file for
222:10 - cars a different xml file for
222:12 - for pedestrians and let me just comment
222:14 - this again
222:17 - and actually i think it'll be better to
222:18 - keep these together so our our
222:20 - pre-trained cats
222:22 - our pre-trained car and pedestrian
222:28 - classifiers with an s okay so we have
222:30 - both of them here
222:31 - and now we can have our pedestrian
222:34 - tracker
222:35 - so this would actually be this is where
222:39 - we actually well actually i don't even
222:40 - have to do it i can just copy and paste
222:41 - this here
222:42 - the cascade classifier okay
222:45 - so pedestrian track is going to be this
222:48 - i'll just type it out this time
222:49 - so cv2 and cascade
222:53 - classifier and it autocompletes for me
222:55 - and then from here
222:57 - then you want to get the pedestrian
222:58 - tracker file and paste that in here
223:00 - so that should make sense we did it once
223:02 - for car car file
223:04 - car tracker now we have pedestrian file
223:06 - and pedestrian tracker
223:08 - all right so we have both
223:12 - now that we have both all we want to do
223:13 - is detect both and every frame and draw
223:16 - rectangles around both in every frame
223:17 - very straightforward so the thing we're
223:20 - going to want to do
223:21 - is um of course for every every
223:24 - frame we want to run the loop we want to
223:26 - read the frame that doesn't change
223:28 - but um and then we create it we change
223:30 - it to grayscale okay that doesn't change
223:32 - either once we have the grayscale image
223:34 - then we want to detect cars and
223:37 - pedestrians
223:38 - okay see that we're only detecting cars
223:40 - right now but
223:41 - we want to detect cars and pedestrians
223:43 - so that would be
223:45 - something like this okay pedestrians
223:48 - equals pedestrian tracker
223:50 - okay pedestrian tracker dot
223:53 - again detect multi-scale because you
223:55 - want to detect pedestrians of all scales
223:57 - in all sizes
223:58 - and we're just going to in the grayscale
224:01 - frame
224:02 - so this is just exactly the same code as
224:03 - for cars we're just using a different
224:05 - classifier
224:06 - okay which means it's going to give us
224:07 - different coordinates different squares
224:09 - of different um of different
224:13 - um what you'll
224:18 - for like pedestrians and stuff like that
224:19 - oh yeah i get i get it yeah yeah
224:21 - so this is a bunch a list of cars and
224:23 - this is listed pedestrians
224:24 - that's all it is okay yeah okay
224:28 - um so if you so if you guys if you guys
224:30 - yeah so if you guys don't know it's
224:32 - basically yeah
224:32 - we got pedestrians so we're attacking
224:34 - different pedestrians we're using one
224:35 - classifier for pedestrians right
224:37 - and then we're using another cluster for
224:38 - a classifier for cars right
224:40 - and that's that again is detect that is
224:44 - detected through
224:45 - where through here well i don't think if
224:47 - you can draw but yeah you can
224:48 - see one for car tracker
224:50 - and another one for pedestrian tracker
224:53 - so that is really cool okay all right
224:54 - let's keep going let's keep going
224:56 - yeah and once we have these then we can
224:59 - just repeat the same exact process
225:00 - with the rectangles for drawing the
225:02 - pedestrians that we do for
225:04 - drawing the cars so it's literally the
225:06 - same exact thing
225:07 - i'm just going to draw the pedestrians
225:09 - in yellow instead of red okay
225:13 - and that's really it okay
225:16 - that's it that's it yeah oh man all
225:19 - right so all right okay
225:20 - pasted it the only difference is um for
225:23 - cars you want to iterate through all the
225:25 - cars again
225:26 - for those points then you want to draw
225:27 - on the current frame the current color
225:29 - frame
225:29 - top left point top bottom right of the
225:32 - top left point
225:33 - the bottom right point and make it red
225:36 - with thickness of two
225:37 - now for the pedestrians we want to again
225:40 - we can just reuse the same variables of
225:41 - x y w and h because at this point we're
225:43 - done with them so we can just overwrite
225:44 - them
225:45 - x y w h and pedestrians so again this is
225:48 - a list
225:49 - its own list of pedestrians then we want
225:51 - to draw a rectangle
225:52 - again on the colored frame top left
225:54 - point bottom right point
225:56 - this time we want to do yellow so this
225:58 - is the color for yellow so
226:00 - if um the green and the red are maxed
226:01 - out it becomes yellow i don't know
226:04 - and again guys it's not it's not so much
226:06 - about like
226:07 - you know red green like we simply just
226:09 - picked those colors because you know
226:10 - because why not you just pick the random
226:11 - colors
226:12 - right but you can pick any color you
226:13 - want right that's those zeros
226:16 - yeah this would be completely white so
226:18 - everything you can pretty much you can
226:19 - pretty much change it to anything you
226:21 - want
226:22 - yeah unimportant detail i mean to be
226:24 - honest
226:25 - in on tesla when they're doing
226:26 - self-driving cars they don't even bother
226:28 - drawing the rectangles around the car
226:30 - because from this point they just know
226:32 - where the car is and the car doesn't
226:33 - need to see it
226:35 - i mean the car already does see the
226:36 - other cars or the pedestrians with this
226:38 - data it doesn't actually need to draw a
226:40 - rectangle
226:41 - no the rectangles are just for humans so
226:43 - yeah on this okay look
226:44 - look look in life logan in the live
226:46 - stream man logan logan
226:47 - appreciate your freaking energy bro
226:49 - logan says like i love this live stream
226:51 - this is so much helpful
226:52 - much nicer way to expose myself to
226:54 - opencv with this
226:55 - then arena communication you know yeah
226:58 - oh yeah yeah
226:59 - apple apple is like aaron you're
227:01 - crushing it buddy keep it up
227:03 - bro you're crushing it bro what watch
227:05 - our video and our jokes
227:07 - yeah let's just let's just read this
227:09 - through the live stream you know
227:11 - that's all we do that's all we do let's
227:13 - read the commentation
227:14 - classifier colon colon detect
227:16 - multi-scale detects
227:18 - objects of different sizes of the input
227:20 - image the detected objects are returned
227:21 - as a list of rectangles i mean this is
227:23 - exactly what we're saying
227:24 - right it's just it sounds very nerdy you
227:27 - detect
227:27 - objects in our case cars and pedestrians
227:30 - of different sizes because it's
227:31 - multi-scale
227:32 - okay the input images are framed yeah
227:33 - yeah the detected objects are returned
227:35 - as a list of
227:36 - rectangle points and then we just draw
227:38 - them so
227:40 - that's it all right let's do let's see
227:42 - man i'm like so
227:43 - excited let's go guys we're gonna see a
227:45 - bunch of pedestrians because the video
227:47 - we're using
227:48 - okay there's there's a bunch of
227:51 - pedestrians but not
227:52 - very many cars like i think there's like
227:53 - one car here but all these pedestrians
227:55 - will all get
227:56 - um get identified okay so let's just go
228:00 - for it
228:01 - right
228:06 - wait did i delete something ready ready
228:07 - where'd you delete oh i deleted the
228:09 - whole loop
228:11 - oops i was
228:16 - no no i didn't i deleted a bunch of the
228:17 - code i just typed out and then i didn't
228:19 - even run it yet but
228:20 - i caught myself okay okay okay all right
228:22 - let's just do this nastiness
228:24 - all right
228:33 - let's run the python file so car and
228:36 - pedestrian tracking dot pod
228:38 - and boom oh see it's oh deep down
228:43 - taking the pedestrians guys holy
228:46 - moly hey
228:50 - guys this is a wow okay okay holy
228:52 - wait so wait okay this is
228:54 - just pedestrians right now you guys
228:55 - ready check this out how cool is that
228:58 - how cool is that guys drop that in the
228:59 - comment below
229:01 - that is sweet oh man
229:05 - that is amazing all right so
229:08 - wow is that it that is that
229:12 - that's pretty much it what i want to do
229:14 - is i want to add a little bit of flavor
229:15 - to something
229:16 - and then add a couple other um safe
229:18 - keeping things that we're going to go
229:19 - over
229:20 - all right and then add a little bit of
229:21 - style and then and then run it on some
229:23 - new videos and then that'll conclude it
229:25 - pretty much pretty consistent that's
229:28 - that's my face right there guys that
229:29 - that that is that this right here is
229:30 - probably your face right now i'm kidding
229:32 - i'm not kidding
229:32 - like like make that face right now and
229:34 - as you're watching the video make that
229:36 - face right now
229:37 - you know the face i'm talking about oh
229:39 - it's cloudy with a chance of meatballs
229:42 - is that is that okay yeah exactly um bro
229:45 - didn't you grow up when that came out
229:46 - you were like 12 when it came out hey
229:48 - this is still an awesome movie bro
229:50 - yeah who doesn't watch that come on come
229:52 - on man
229:53 - incredibles is better come on man what
229:56 - people are like this is
230:06 - guys what i want to do is um i don't
230:09 - know about you guys but in the thumbnail
230:10 - of this live stream
230:12 - i had like a little quirky styling thing
230:14 - where for the cars it was red and blue
230:16 - and then for pedestrians it was just
230:17 - yellow
230:18 - so i just want to chuck that in so all i
230:19 - did was i'm just drawing two rectangles
230:21 - here
230:22 - instead uh just you know for a little
230:24 - bit of flavor
230:25 - and just pop that in so i actually for
230:27 - each car
230:28 - i actually draw two rectangles one red
230:30 - rectangle and one blue rectangle so this
230:31 - is the reference
230:32 - what's the reason for that i'm just
230:33 - curious just because you want to be
230:35 - fancy
230:36 - yeah i just want to be fancy real quick
230:37 - okay fine i mean so all i did was i just
230:39 - drew a red background here
230:41 - with the red channel max everything else
230:42 - closed and the blue channel here
230:44 - 255 enclosed but i offset it by one and
230:46 - two pixels a little bit so you can see
230:48 - it
230:48 - changing you know this is like this is
230:50 - completely useless code it's just for a
230:51 - little bit of
230:52 - you know front-end development but when
230:55 - you run it
230:56 - you can see i mean there's not that many
230:57 - cars here but you can see whenever a car
230:59 - pops up there's a little bit of blue as
231:00 - well as oh man
231:03 - a little bit of flavor put that image in
231:05 - the center put the video in the center
231:07 - oh never mind just keep going never mind
231:09 - just keep going you're fine you're fine
231:12 - like that guys how cool is that
231:17 - how cool is that to go like
231:20 - okay that that that makes me excited bro
231:22 - honestly all right
231:24 -  all right i don't know let's calm
231:26 - down
231:27 - i love this ai stuff i used to i
231:30 - actually guys actually interesting
231:31 - enough i
231:31 - i used to do ai stuff as well for a
231:33 - company but we did we did a yeah so
231:35 - interestingly enough
231:36 - i'll just tell you a really quick story
231:37 - i i did ai for
231:40 - i did ai for um
231:43 - for actually detecting signatures
231:45 - detecting fake signatures
231:47 - so we use the similar we also used
231:49 - alpinstv as well and we detected if
231:51 - signatures were fake
231:52 - or they were real and we had i'm not
231:54 - kidding we had signatures from like
231:55 - thousands and thousands of like images
231:58 - and we will be able to detect like if
231:59 - the images was like real or not by the
232:01 - way i don't really know
232:02 - robin robin seriously holy moly thanks
232:05 - again
232:06 - donated 400 400 v v something
232:09 - v dollars i don't even know i don't know
232:12 - robin
232:13 - you're the best thank you appreciate it
232:15 - what was appreciating donations
232:16 - you know oh man yeah yeah
232:20 - right but anyways fire yeah that was a
232:22 - fight he's like robin's like
232:23 - yo let's go we just hit the goal
232:26 - [Laughter]
232:28 - all right we're almost done you guys
232:30 - just a couple more things and we can run
232:31 - on some extra videos and then we can
232:32 - just let it run
232:34 - and yeah that'll complete the app you
232:36 - guys
232:37 - yeah so uh last things i want to do are
232:40 - actually um when you're running the the
232:43 - video
232:43 - i want to be able to actually quit the
232:46 - the window
232:47 - um with the key so guys there's a robin
232:50 - donated right there i appreciate it bro
232:51 - right there you guys can see it yeah
232:53 - there we go
232:54 - hey all right let's continue on by the
232:57 - way i don't see you do i see you
232:59 - no i don't see you oh there we go
233:03 - there now i see you there you are now
233:05 - there you go
233:06 - am i good no you're good you're good
233:07 - keep going keep going okay
233:09 - got it yeah so here on the code i'm just
233:11 - gonna copy and paste in a little
233:13 - um housekeeping here so if the q
233:16 - key is pressed q for quit then i want to
233:19 - break out of this loop which means it'll
233:21 - abort the video stream
233:24 - like whenever you type that key so the
233:27 - key for a lowercase q and uppercase q
233:29 - are 81 and 113.
233:30 - you can learn look that up online every
233:32 - letter and every keyboard
233:34 - button has its own number and you can
233:35 - just find it with a google search you
233:37 - just be like lowercase q and uppercase q
233:38 - what are the numbers
233:40 - you just put that in and um once you
233:43 - have these numbers then if either of
233:44 - those are pressed
233:45 - if key equals um that or that then it
233:47 - will just break out and we'll just stop
233:49 - okay
233:49 - and the key is automatically whatever
233:51 - you press from wait key because
233:53 - it's waiting for a key you see what i
233:54 - mean and so if it's waiting for a key
233:57 - and you press q
233:58 - automatically it goes to the next one
233:59 - and then key becomes q and it'll it'll
234:02 - match
234:03 - and that's really it cool okay last
234:05 - thing is you want to release the video
234:07 - capture
234:08 - so wait what is the release why release
234:10 - what
234:11 - so um video here our video is the video
234:15 - capture object
234:16 - that we got from our video file all
234:18 - right and it's
234:19 - it's constantly reading a file okay
234:22 - and so video is constantly reading a
234:24 - file so when we're done doing it we just
234:26 - want to release
234:26 - reading of the file so it's just like
234:28 - it's like it's like okay stream of data
234:30 - coming in
234:31 - so it's like you stop basically stop
234:32 - bringing the file you're good
234:34 - that's what it's saying yeah okay it
234:36 - says we're done reading this file
234:37 - just release all resources from trying
234:39 - to read this file so we're done
234:41 - okay that's really it's just a clean up
234:42 - like a memory management thing yeah
234:46 - and that's really it you guys um guys i
234:49 - don't think that's
234:49 - pretty much it i haven't planned
234:54 - that change all right so let's see
234:57 - driving car
234:58 - all right i'm excited to see some videos
235:00 - bro let's do it
235:02 - yeah let's go here and
235:05 - let's run it again oh your name
235:08 - is ready it's not you guys hey guys
235:12 - oh there's an error here it says key is
235:14 - not defined because
235:15 - you guys know what the key is you guys
235:17 - know what the problem is drop in the
235:18 - comment below you guys huh
235:20 - i think i know i know it is do you know
235:22 - aaron
235:23 - yep of course i do not
235:27 - are you sure you do i'm not sure i'm not
235:28 - sure about that so
235:30 - yeah the problem is that this key
235:32 - variable doesn't actually exist and the
235:34 - problem for that
235:34 - the reason for that is we didn't
235:36 - actually set that equal to here so this
235:38 - does wait for a key to be pressed but it
235:40 - never captures that so we gotta capture
235:42 - it in key and now when key is pressed
235:44 - then it should work
235:45 - okay back here let's just clear this out
235:48 - so it's nice and clean
235:50 - run it again and there we go
235:53 - so it's going hey okay if i press the
235:57 - q key it should quit quit sweet okay
236:00 - cool cool cool all right
236:04 - damn guys this is crazy guys this is
236:07 - amazing holy
236:09 - like we just created a system that
236:11 - detects pedestrians and cars
236:14 - within you know an hour two hours
236:17 - with some training data that's it that
236:19 - we didn't create
236:20 - we just bought it we did we
236:23 - you borrowed download all this off the
236:24 - internet like you can download xml files
236:27 - for anything you can probably download
236:28 - xml file for a cat for a dog
236:31 - for a water bottle for a football
236:34 - or anything you can download somebody
236:36 - else probably somewhere on the planet
236:38 - has trained a hard cascade file for you
236:40 - somewhere and uploaded it somewhere you
236:42 - could probably download it and you could
236:43 - probably use it
236:44 - and do a very similar thing depending on
236:45 - how well they trained it
236:47 - and of course you can train your own too
236:49 - if you want to go that route i'm sure it
236:51 - that exists on google
236:52 - how to do that but that's a much longer
236:54 - process you have to find all your own
236:55 - data
236:56 - yeah cool cool your own images wait wait
236:58 - guys so let's let's give you some more
237:00 - videos what has we got
237:02 - yeah so we have a couple more all right
237:05 - um
237:09 - so that was just that was that was like
237:11 - a pedestrian heavy let's run it again
237:12 - this was a very pedestrian heavy video
237:14 - okay lots of pedestrians so what do you
237:17 - guys see
237:18 - what do you guys see you guys see just a
237:19 - lot of pedestrians walking right and
237:20 - it's able to detect those systems
237:21 - and if you think about it right what
237:23 - would a system do you can now
237:25 - since you cannot detect something you
237:27 - basically can now tell a system hey
237:28 - you know if you detected it stop to stop
237:30 - the car or hey
237:31 - you know stop anything you want so
237:33 - that's kind of why this stuff works
237:35 - really well you know what i mean
237:37 - yup
237:40 - so let's just do this okay so another
237:43 - another
237:43 - video file i have is dash cam cars and
237:45 - pedestrians because it has a little bit
237:47 - more mix of both
237:48 - this is actually the video file that i
237:50 - um showed you at the beginning
237:51 - okay so how long is this video
237:56 - all right okay that's a different video
237:58 - it's like four minutes long
237:59 - all right um so let's go and let's just
238:02 - let it run
238:03 - so this is the video i showed you at the
238:04 - beginning oh man that's cool
238:08 - damn guys give us some fire in the
238:10 - comments guys
238:13 - that is cool all right look at this
238:14 - guy's walking
238:16 - what is that you see how it's able to
238:18 - detect that like little pothole at the
238:19 - bottom i thought that was interesting
238:22 - yeah it's not perfect but yeah of course
238:24 - it's better than
238:26 - nothing better than random much better
238:29 - than random
238:32 - and there we go you guys if you can see
238:33 - it looks a little bit slower because
238:34 - it's doing double compute power
238:36 - yeah yeah you see so you can think about
238:38 - it for tesla like a real self-driving
238:40 - car think about it
238:41 - it has to detect pedestrians it has to
238:43 - detect cars
238:44 - it has to detect signs all different
238:46 - kinds of signs speed limits stop signs
238:48 - has to detect traffic lights
238:50 - have to detect different night time and
238:52 - daytime things have to detect
238:54 - rainy conditions and non-raining
238:56 - conditions it has to actually send those
238:58 - values to the car to break or turn
239:00 - accordingly there's so much going on
239:02 - so this is just scraping the surface
239:03 - this is pretty cool but this is just the
239:05 - very very surface of what actually of
239:06 - what's actually going on
239:07 - i mean in general honestly in general
239:09 - it's like it's it's crazy right because
239:11 - the amount of data that it has to
239:13 - process
239:13 - right in terms of pixels right in terms
239:16 - of in terms of how fast it has to do it
239:17 - as well
239:18 - it's insane but you can see what's real
239:20 - like i think guys what's really
239:22 - interesting and how long i'm actually
239:23 - not
239:23 - let's let's keep watching the video as
239:25 - you guys can see right the really
239:26 - interesting part is like the fact that
239:29 - the relationship part is like all we
239:31 - simply did is
239:32 - if we divide a problem right into
239:36 - different little into
239:37 - certain little parts right into into
239:39 - small little parts right which is how do
239:40 - we divide this up like
239:41 - drop in the comments below how do we
239:43 - divide up this huge problem which is
239:44 - we wanted to detect right we want to
239:47 - detect like um
239:48 - you know pedestrians and cars in the
239:50 - video
239:51 - how do we divide that well first is we
239:54 - found a lot of training data that's part
239:55 - one
239:56 - right two right we basically we first
240:00 - did training we trained uh we first did
240:02 - testing
240:03 - on the pictures individual individual
240:05 - pictures right
240:06 - individual pictures and then what
240:08 - happened is once we got the pictures
240:10 - right we were able to bring in a video
240:13 - we were able to take certain pictures
240:16 - right every single frame
240:17 - from that video and the next thing you
240:20 - know
240:20 - we're able to display it back to the
240:22 - user so but if i'm
240:24 - dividing this up into three or four
240:26 - different parts
240:27 - you're literally just able are able to
240:29 - solve this humongous
240:31 - issue not an issue but this this crazy
240:33 - epic
240:34 - you know thing in an hour or two
240:39 - do you guys see that yeah just drop that
240:41 - in the comment below if you agree with
240:43 - me like seriously because that is to me
240:44 - is insane
240:45 - you know a lot of people think that this
240:46 - is this is crazy stuff but you know
240:48 - honestly you just you know just some
240:50 - work and you're good
240:52 - am i right yeah man look at it go
240:56 - well there i think it's slow motion yeah
240:58 - yeah
240:59 - i mean it's detecting that sign wrong
241:01 - but it's getting the girl is getting
241:02 - some of the cars in the back
241:03 - yeah yeah right there right there
241:04 - screens a little bit yeah
241:07 - yeah and there's ways to optimize this
241:09 - you can be like okay if there's like two
241:10 - if there's two um rectangles in the
241:13 - general same area twice in a row you can
241:15 - kind of
241:16 - be like okay there's a higher chance
241:17 - this actually is a pedestrian it's not
241:18 - just a random
241:20 - thing a random detection so hold on i
241:22 - want to ask you a question so
241:23 - somebody asked a question actually
241:24 - george asked the question how can i get
241:27 - this source code uh if i can take a look
241:30 - at it please so i can take a look at it
241:32 - uh i'll post it in the in the
241:34 - description i'll like upload it to like
241:35 - a riplet or something
241:36 - or i t and then you can download the
241:38 - code if you didn't type it out yourself
241:40 - with us
241:42 - yeah granted it won't work in riplet
241:44 - like you're gonna have to download
241:45 - opencv
241:46 - the opencv package within riplet itself
241:48 - and run it there
241:49 - but you can just i'm just gonna post it
241:51 - there for like code reasons and you can
241:52 - just copy paste it to your own visual
241:54 - studio code
241:55 - yeah wait but can we just put host on
241:56 - github or no
241:58 - we could do that too yeah right
242:01 - that's it yeah either or github's
242:04 - probably the proper way to do it but
242:05 - yeah riplet fanboy so yeah we'll post it
242:08 - to github how is that
242:10 - that's the proper way to do it post the
242:11 - game you can download the code from
242:12 - there
242:13 - exactly exactly exactly so guys how sick
242:17 - was this
242:18 - how sick was that to create such an
242:20 - insane
242:21 - python tutorial such as saying python
242:23 - program
242:24 - aaron i think it's pretty dope i'm just
242:28 - like admiring the the work that other
242:30 - people admire your work
242:32 - okay don't get too cocky bro don't get
242:34 - too cocky on this you know it's just
242:35 - like you know i said i'm admiring the
242:36 - work that other people have done bro
242:37 - that's the option
242:39 - okay okay okay i thought i said admiring
242:40 - my work you know
242:42 - open your ears i mean what i wrote like
242:44 - 20 lines of code it's pretty badass but
242:46 - i mean
242:46 - you know yeah yeah i didn't do all the
242:49 - training the training that's the hardest
242:50 - part
242:51 - yeah yeah but that that to me is insane
242:53 - so yeah but awesome job guys
242:55 - guys give aaron a give aaron a round of
242:57 - applause in the comments
242:59 - right he worked on this all of us give
243:01 - all yourselves
243:02 - you know i was partially involved in the
243:03 - code i was just like you know okay
243:05 - good look at this wow holy crap he's
243:08 - getting these
243:09 - pedestrians super accurately it's like
243:12 - stop stop stop stop you know pedestrians
243:14 - in front
243:14 - yeah yeah yeah and then the bigger the
243:18 - bigger the rectangle the closer it is
243:19 - you know you can do stuff like that like
243:21 - if there's a big rectangle you can tell
243:22 - that the thing is close to you yeah yeah
243:24 - look at that that's insane that's cool
243:28 - that is so cool okay this one's not
243:30 - working at all
243:31 - this one's terrible it's like i think
243:34 - it's just too many people man
243:35 - probably yeah there's too much
243:37 - information confused with crowds and
243:39 - stuff
243:39 - yeah yeah if you had just people walking
243:41 - like on a white sand beach just a single
243:43 - person walking it would track it almost
243:44 - perfectly but just because there's so
243:46 - much noise and stuff
243:48 - it's not quite perfect yeah yeah
243:51 - but dude this this motorcycle driver is
243:53 - like freaking
243:55 - he's trying to run people over you know
243:56 - yeah people are like
243:59 - how are you going his name is royal
244:01 - jordanian so maybe
244:03 - yeah yeah i mean i never i found him
244:05 - this morning because
244:06 - i needed this video but he has like two
244:08 - million subs it's ridiculous
244:10 - oh wow for riding his motorcycle he just
244:13 - rides his motorcycle and he records it
244:14 - is that it
244:15 - i guess so i mean he probably talks
244:17 - about his motorcycle and stuff too i
244:18 - don't i didn't really look at his
244:19 - channel
244:20 - even evil evil is like evil i'm not i
244:23 - don't know how to say that evil was like
244:25 - aaron do a project with me
244:28 - whoa look at this truck i got that truck
244:30 - hard did you hear me
244:31 - did you hear me evan yo it's getting
244:34 - it's getting the the cars in the
244:35 - advertisement it's funny
244:37 - where all the up top yeah
244:40 - are those even cars oh they're not even
244:41 - cars i don't know their cars
244:43 - yeah i mean guys obviously it's not
244:45 - perfect right this is not perfect
244:47 - yeah but still it's insane it's more
244:51 - right than it is wrong
244:52 - yeah yeah yeah that's that's a
244:54 - monumental task
244:56 - yeah hey guys let me ask you a question
244:58 - like what
244:59 - else let me see a question what else
245:01 - would you like us to see like what else
245:02 - would you like us to do
245:04 - in terms of you know ai or face
245:06 - detection
245:07 - anything that you want us to do like let
245:08 - us know in the co drop it in the
245:10 - comments below
245:10 - right because we read your comments
245:12 - right so we have great ideas for you
245:14 - know what to come next
245:15 - before we have great ideas of what you
245:16 - guys want from us right
245:18 - we read those comments i am not kidding
245:20 - so if you got any suggestions
245:22 - right if you got any suggestions on what
245:24 - to do yeah just drop in the comments
245:25 - below
245:26 - we'll take a look at it and then aaron
245:28 - is just going to
245:29 - take a crack at it you know and then
245:30 - create something amazing right there
245:34 - am i amazing bro i mean you know just
245:36 - whip it up yes i'm amazing
245:38 - like one-fourth amazing one-fourth
245:40 - amazing
245:41 - yep and boom cool projects any cool
245:45 - ideas you guys have for projects going
245:46 - forward related to
245:47 - python and and any kind of artificial
245:50 - intelligence then drop it in the
245:51 - comments too then you can consider it
245:52 - maybe we'll make something
245:54 - maybe we'll use opencv again maybe we'll
245:55 - use something else or else
245:57 - something else something somebody said
245:59 - so we have idol said
246:00 - idol said i don't know ido said to
246:03 - detect numbers
246:04 - okay we could do that actually detecting
246:06 - numbers like you want to yeah
246:07 - you could detect you could yeah you
246:09 - could detect
246:11 - numbers on a page like if you had a
246:12 - piece of paper okay you had opencv
246:14 - you could you could technically um scan
246:17 - that and then find out
246:18 - like all of the places where there's
246:20 - words like that's actually how pdfs
246:21 - are able to like scan the numbers and
246:24 - letters in it and like auto populate all
246:26 - the numbers in
246:26 - the numbers and letters is through scan
246:29 - it doesn't use
246:29 - i don't think it uses hard cascades it
246:31 - uses something different
246:33 - but um yeah same principle you can
246:35 - detect different letters and shapes on a
246:37 - piece of paper
246:37 - same exact principle gotcha gotcha what
246:39 - about somebody said
246:41 - something you said sprush sparsh sparsh
246:44 - asked
246:45 - uh age detection i'm not sure if we can
246:47 - do that that that's a little bit harder
246:49 - yeah i mean in theory it's possible like
246:51 - if you had if you had like facial
246:53 - recognition you know how facebook can
246:55 - can recognize your face and be like oh
246:56 - this is quasi this is
246:58 - nas this is area tag your friend
247:00 - automatically if it can recognize an
247:02 - actual
247:02 - independent face it can easily recognize
247:04 - old versus young
247:06 - um so yeah you could but you would take
247:09 - more training and you would need you
247:10 - would need a lot of
247:11 - picture of old people and a lot of
247:13 - picture uh pictures of a lot of young
247:14 - people and to distinguish between those
247:17 - yeah that's true but i think it's like
247:19 - when you get to like you know when
247:20 - you're 20s
247:21 - or 30s it's really hard to get the exact
247:23 - age like if it can get an exact
247:25 - age it could be like it could be like
247:26 - old middle-aged child infant you could
247:28 - just split it into four groups you know
247:30 - infant
247:30 - yeah kid middle-aged adult and
247:33 - elder senior citizen you could have like
247:35 - those four that's close that's true
247:37 - so guys if you want us to do like an age
247:38 - detection system that would be actually
247:40 - interesting
247:41 - and then we could age attacked air and
247:42 - they'll probably say like 50 you know or
247:43 - something
247:44 - yeah the thing with that is i don't know
247:45 - if that exists on the internet we have
247:47 - to train our own
247:48 - hard cascades and there's other
247:49 - algorithms hardcast i'm sure there is
247:51 - the algorithm used for this
247:52 - um but maybe we had someone say hold on
247:56 - it's itzhak said face expression
247:58 - detection
248:00 - oh like smile sad like
248:03 - mad you know be like no i'm mad i'm like
248:06 - your smile you know
248:07 - yeah we could do a smile detection a
248:09 - smile that's interesting
248:10 - it's like smiling or not smiling because
248:13 - let's just keep it simple
248:15 - smiling versus not smiling faces
248:19 - it could say like smile on top yeah
248:21 - that's not a bad idea we can look into
248:23 - it
248:23 - some guys anything else would you want
248:25 - us to create a face expression
248:28 - system a smile detector a smile find a
248:30 - small detector system yeah
248:32 - because because that way if you guys
248:33 - don't smile you know we could i don't
248:34 - know we detect some points you know
248:38 - you like points for me i don't know i
248:39 - don't know how but we did we would
248:40 - detect points
248:42 - if you guys smile so yeah sweet i think
248:45 - that's pretty much it bro
248:46 - right we're good yeah that's it so again
248:49 - if you guys are interested in coding
248:50 - more and
248:51 - actually making a living from it if
248:52 - you're not currently doing that if
248:54 - you're
248:55 - uber driver or working at a retail or
248:57 - fast food place or something like that
248:58 - yup
248:59 - um we offer courses here at
249:01 - cleverprogrammer to help you learn how
249:02 - to do that so
249:03 - we teach you a bunch of different
249:04 - projects in python
249:06 - and how to actually monetize those
249:08 - skills so this is a 15-week program
249:11 - um hosted by uh qazi
249:14 - and um our other python expert jacob
249:17 - yep and then um also there's a little
249:19 - bit of me in there we're gonna add in um
249:21 - some stuff in there at some point with
249:22 - me
249:23 - and we all teach python and how to
249:25 - actually use python to make a living
249:27 - from it
249:28 - so if you're interested in that then
249:29 - definitely give it a click in the
249:30 - description there's a
249:31 - free three-part master class and also um
249:34 - the actual course is there so you can
249:35 - check out both
249:36 - um if not then yeah just keep watching
249:38 - us on youtube and thanks for watching
249:40 - you guys
249:40 - yeah sweet guys and i just want to say
249:42 - guys is it you just want one one small
249:44 - thing guys
249:44 - if you're interested like i said with
249:46 - the profit with python you get amazing
249:47 - success coaches you get you know you get
249:49 - to learn how to make a live a killing
249:51 - with python
249:51 - right so it's not just about teaching
249:53 - you skills right but it's also teaching
249:55 - you about how to actually make money
249:56 - from that
249:57 - because that's the most important thing
249:58 - that you know you're going to get from a
249:59 - course right
250:00 - we get weekly training calls literally
250:03 - every single week you get a coaching
250:04 - call
250:05 - from a developer who knows his stuff
250:08 - right
250:08 - you have an amazing community who loves
250:10 - each other and you have an amazing
250:11 - facebook community at the same time
250:13 - so yeah if you're interested in you know
250:15 - becoming a python developer or learning
250:16 - python and just
250:17 - making a killing with python where do
250:20 - they go aaron
250:22 - they can go to the link in the
250:24 - description and check it out there
250:26 - profit with python profit guys on course
250:30 - yep and then there's also a free
250:32 - three-part master class it gives you a
250:33 - little bit more information about making
250:35 - money as a python developer
250:36 - you can check that out it's just about
250:38 - like the opportunity there is and stuff
250:39 - and
250:40 - there's some activities in there you can
250:41 - check it out and then you can join the
250:43 - course after if you want or something
250:45 - like that
250:45 - but exactly yep that option is there for
250:47 - those who are interested
250:48 - for those who are not um yeah come back
250:51 - for the small detector next
250:52 - yeah the small detector all right guys
250:55 - awesome guys
250:56 - this was amazing this was so much fun
250:58 - guys oh hold on
250:59 - something evil said my heart my evil
251:01 - says my heart is python
251:04 - my heart is played my heart is python
251:06 - yes what about javascript bro
251:08 - what about javascript that was cool too
251:12 - you guys you guys you guys are not you
251:13 - know not cool
251:15 - anyways but sweet awesome guys in that
251:18 - case i think we're done here hope you
251:20 - guys
251:20 - have a great day if you guys have well i
251:22 - don't know if you hope you guys have a
251:23 - great day
251:24 - and other than that we will see you
251:27 - in the next video right aaron
251:31 - yep next yeah probably probably tomorrow
251:34 - right
251:34 - yeah probably tomorrow schedule for
251:36 - tomorrow yeah i think so
251:37 - awesome guys stay tuned stay tuned and
251:40 - have a great day guys
251:41 - let's go
251:56 - so we are going to be building a
251:58 - real-time ai
251:59 - smile detection app in python i am sunny
252:03 - and today i am here with
252:06 - aaron what's up guys remember me i'm the
252:09 - python guy apparently
252:11 - super pumped guys super super pumped for
252:13 - today aaron what we building today
252:17 - uh all right can they see my screen
252:18 - right now uh
252:20 - coming through now yeah let me pause
252:22 - this
252:23 - like mute this all right guys so this is
252:25 - what we're building
252:27 - i got my little app here and i got a
252:29 - multi detection app let me go ahead and
252:31 - share the screen one sec
252:33 - all right let's go
252:37 - yup they can see you all right
252:40 - here's my face and
252:43 - when i smile it should be able to notify
252:47 - uh detect that i'm smiling and then it
252:48 - displays i mean it's bugging out a
252:50 - little bit right now
252:51 - so go ahead and throw a smile hey look
252:53 - at that there we go guys
252:54 - and what we do how are we getting that
252:56 - to work right now
252:58 - uh this is the code bro that's how stuff
253:00 - works
253:03 - what are we using that's pretty much so
253:06 - that's
253:07 - we're using ai right and we're using
253:08 - what what in particular to get that
253:10 - working
253:12 - uh opencv so we're gonna be using the
253:14 - open computer vision library
253:15 - um as usual if you guys are watching the
253:17 - other couple streams in similar
253:19 - but uh this one has some cool some cool
253:21 - optimizations in uh
253:22 - in the code so it's pretty short so it's
253:24 - pretty powerful library i mean what
253:26 - 50 lines of code with comments and
253:28 - spaces so yeah
253:29 - pretty bite-sized but you can do some
253:31 - cool stuff with it awesome dude
253:33 - okay so let's go back to us guys there
253:37 - we go
253:37 - nice so let's go ahead and see where
253:39 - everyone's at nice we've already got 250
253:42 - people in here that's
253:43 - dope hope you guys okay okay
253:47 - this is the first time guys me and aaron
253:48 - are going live together so this will be
253:50 - exciting
253:52 - yeah first time very first time exactly
253:54 - and also guys i'm not actually a python
253:56 - developer so many of you guys know me
253:58 - for react so this will be cool for me as
254:00 - well so i've never done machine learning
254:01 - with python so i'm excited for today
254:04 - um yeah let's go sonny let's do it so
254:06 - aaron let's go ahead and like let's just
254:08 - jump straight in i think yeah
254:10 - all right yeah let's get straight to the
254:13 - to the project okay
254:14 - so uh here's the stream
254:25 - uh all right got a little presentation
254:26 - here for you guys let's just start off
254:27 - to get a little bit of context
254:29 - um so smile detection with python
254:33 - all right
254:36 - uh first of all you just want to you
254:38 - know pay uh pay respects to the joker
254:40 - himself
254:41 - the the infinite smiler i mean he's
254:43 - always smiling but really not
254:45 - the legend heath ledger residents rest
254:48 - in peace bro but
254:50 - uh yeah guys just make sure you're
254:52 - spying a lot because it's important it's
254:54 - good for your mental health and people
254:55 - will probably like you more
254:57 - or just think you're freaking crazy
255:00 - so how are we gonna do this uh sunny
255:03 - smiles a lot
255:04 - i've noticed so you can be blessed with
255:06 - his super white teeth
255:08 - it's a british thing now you guys just
255:10 - misspelled words that's all it is
255:12 - it's the spilled word all right so how
255:14 - are we gonna do this
255:15 - so you guys guessed it it's
255:19 - all um all things go to machine learning
255:21 - okay all thanks go to machine learning
255:23 - so we're gonna be doing that we're not
255:24 - gonna be training anything but we're
255:25 - gonna be doing some pretty crafty stuff
255:27 - uh in the app with some pre-trained
255:28 - models this time it gets a little bit
255:30 - fancy here and there but
255:31 - i'll explain how it's how it's happening
255:33 - so here's a quick code breakdown of our
255:36 - app i just kind of want to give like the
255:37 - overall
255:38 - idea of the code logic just so that
255:40 - people
255:41 - um have some context going before we
255:44 - start coding because i don't like when
255:45 - they just jump in they're like oh what
255:46 - are we doing
255:46 - but this kind of gives you a holistic
255:48 - view so uh
255:50 - so step one the very first thing we
255:52 - gotta do
255:53 - is uh find faces in our photo in our
255:56 - case it's gonna be a frame from the
255:57 - webcam
255:58 - that's what i'm gonna be using an app
256:00 - but here awesome
256:01 - the first thing you want to do is find
256:03 - yeah you want to find faces and that's
256:05 - using the har
256:06 - algorithm what is the heart algorithm
256:10 - yeah so i'm not actually going to be
256:11 - explaining the algorithm in this video
256:13 - but if you want to know how the
256:14 - algorithm actually works in depth you
256:16 - can watch the
256:17 - uh our face detection video for our car
256:20 - and pedestrian tracking
256:22 - video uh from a week or a couple weeks
256:24 - back
256:25 - and in those two videos i explained them
256:27 - in depth
256:28 - uh different explanations in both at the
256:30 - face detection it's at the end
256:32 - um and then the other video it's at the
256:33 - beginning but if you want to actually
256:34 - see how it works you can go watch those
256:36 - videos
256:36 - those are cool but this apps a little
256:38 - bit longer and more complicated so i'm
256:39 - just
256:39 - glossing over it okay awesome also i
256:42 - just want to say so so step one is find
256:44 - the faces so at this point we're
256:45 - literally just finding the face right
256:47 - so we're not actually finding that yeah
256:49 - no smiles yet so
256:51 - so you want to find just the face like
256:52 - that yep step one that step
256:54 - find the face very simple yep and then
256:57 - we also want to crop it out just so
256:58 - we're dealing with this
256:59 - okay okay uh step two
257:03 - we want to find smiles within those
257:04 - faces because i mean it's pretty rare
257:06 - you have a smile outside the face i mean
257:08 - maybe if you had like some dentures
257:09 - lying around or like a weird
257:11 - piece of art on the wall but i mean nine
257:13 - times out of ten a smile is always
257:15 - going to be within a face yeah okay
257:16 - again this is the heart algorithm so
257:18 - again if you want to see how it works
257:20 - it's uh it can it's just generic object
257:23 - detection but we can detect smiles on
257:26 - the faces okay so we just
257:27 - detect the smile there then then step
257:31 - three
257:32 - all we need to do is just put the rest
257:33 - of the image back
257:35 - get rid of that bounding box and give it
257:37 - a nice little label on the bottom
257:39 - because this makes more sense you know i
257:41 - mean you could have a box around the
257:42 - mouth i guess that's kind of cool but
257:43 - this is cooler because then you just
257:44 - kind of want to know if the face is
257:46 - smiling or not it just seems more
257:47 - more human so that was the design choice
257:49 - there for the app nice
257:50 - and that's really it guys so yeah i know
257:53 - it's
257:54 - you basically you found the face first
257:56 - and then what
257:57 - then we found the smile within that box
257:59 - right
258:01 - yep and then why did why do we do that
258:03 - instead of just doing the whole
258:04 - um you'll actually see uh
258:08 - once we get to there okay uh a lot of a
258:11 - lot of yeah a lot of ai stuff you kind
258:12 - of need to get
258:14 - clever with the optimizing and um
258:16 - layering different layers because if we
258:18 - did smile detection just every word the
258:20 - performance is actually really really
258:22 - terrible okay so i'll show you guys that
258:24 - i'll show you guys that uh once we're
258:26 - coding and then you'll see
258:28 - because it's actually pretty accurate
258:29 - like when i'm running the code
258:31 - yeah well here so i actually ran it here
258:33 - on the i mean here it's a little bit bad
258:35 - because it's blurry the lighting's bad
258:36 - but i just wanted to run it on this gif
258:37 - before
258:38 - to show you that it's kind of working
258:39 - like when he's smiling you can kind of
258:40 - see it picking it up
258:42 - a little bit here and there um but on
258:44 - the webcam
258:45 - is pretty accurate so yeah you'll see
258:47 - you'll see how ass though
258:49 - how ass the performance is if you run it
258:51 - on the whole thing but there's there's a
258:52 - little trick to make it like really
258:53 - really accurate
258:55 - so guys let's get to the code yeah
258:58 - so guys for this just all we ask is that
259:01 - before
259:02 - we get started just smash the thumbs up
259:04 - button
259:05 - what we got here what was that
259:08 - yeah i had the i have the other from the
259:10 - car and pedestrian tracking i just
259:11 - forgot to
259:12 - delete it anyways
259:16 - um yeah so let's get to the
259:19 - code okay uh real quick guys before we
259:21 - start though just got a donation dude
259:23 - from tushar near us
259:24 - he says character doing a shadow sign
259:27 - with his hand saying cool
259:28 - oh okay no he actually sent in something
259:31 - uh like we can't actually see it
259:32 - properly on the superchat guys but it's
259:34 - it's some guy waving cool so thank you
259:36 - for that cheers
259:39 - all right uh real quick sonny um
259:42 - you want to show them the stream about
259:43 - the the free training
259:45 - yeah real quick yes let's do it guys so
259:48 - we have a
259:49 - free python master class that i
259:51 - recommend everyone goes ahead and signs
259:53 - up to you
259:54 - uh i haven't actually got the link aaron
259:56 - uh i've got the i've got profit with
259:58 - one second let me go ahead and show this
260:00 - so guys
260:01 - let me go do you mind just slacking me
260:03 - the link for the
260:05 - where's it going yeah or i can do it you
260:08 - just share my screen and then i can go
260:10 - through it
260:10 - let's do it yeah yep
260:15 - there we go there we go can they see my
260:17 - screen i got you
260:19 - yeah what's up guys so uh
260:22 - so if you guys are interested in
260:23 - learning how to actually make a
260:26 - make a living from python then we have a
260:28 - free python training here that teaches
260:30 - you the three secrets
260:31 - of how to become a python freelancer so
260:33 - link is in description you can click
260:35 - down there to check it out
260:36 - or if you just want to jump straight to
260:37 - our python course and we also have a
260:39 - course which
260:40 - teaches you how to do that as well this
260:42 - is a paid course though so if you're
260:43 - interested in that
260:44 - there's also the link in description
260:45 - okay a lot of cool stuff in here free
260:46 - trainings
260:47 - uh private communities weekly live calls
260:50 - um with a couple instructors and yeah
260:52 - feel free to check it out
260:54 - but other than that let's just get to
260:56 - the code okay guys
260:57 - also guys just want to point out one
260:58 - thing with that said
261:00 - the something that i really want to
261:01 - point out that i think is always cool is
261:03 - that we actually offer weekly live
261:05 - training calls in that program so if you
261:07 - do want to go ahead and like and you get
261:08 - a bit bored of the sort of
261:09 - udemy courses that you see online then
261:11 - make sure you go and check it out but
261:13 - before any of that
261:14 - be sure to sign up to that free training
261:16 - guys because it's completely free so you
261:18 - have nothing to lose go ahead and check
261:19 - it out
261:19 - if you enjoy the video awesome
261:23 - all right let's do it dude all right man
261:26 - is the focus back on my screen the focus
261:28 - is back
261:28 - on your screen
261:38 - let's go guys okay so uh let's just jump
261:41 - right in all right so remember we're
261:43 - going to be
261:43 - finding faces first and then from there
261:45 - finding smiles and layering it over so
261:46 - this is the full app
261:48 - again opencv very powerful uh we can do
261:50 - some stuff in a pretty short app
261:52 - um so first thing is you're gonna need
261:54 - to download um
261:56 - a couple files these are in the in the
261:57 - description down below so just go to
261:59 - those web pages and download these two
262:01 - xml files to start out i'll explain this
262:02 - in a second
262:04 - and once you've done that uh you just
262:07 - need to make a python file so start with
262:09 - a small detector.pi
262:10 - yep um and actually i think i'll just
262:14 - i'll just code in here yeah let's do
262:16 - that it's always nice to see a bit of
262:17 - fresh code
262:20 - yeah oh yeah of course but i was gonna
262:21 - make a new file but
262:23 - and i'm not feeling it so we'll just
262:25 - pretend this is a new file okay
262:27 - so just make it make a new file in a new
262:29 - directory
262:30 - um we just got another donation as well
262:32 - we got vishal s
262:34 - dropped a 20 rupee super chat thank you
262:36 - very much dude
262:37 - and i dropped another one thank you guys
262:40 - good show
262:41 - thanks to sure thank you everyone
262:44 - appreciate that much appreciated man
262:48 - yeah all right so let's get started okay
262:51 - so first thing we're gonna need to do is
262:54 - install opencv if you don't already have
262:56 - that
262:56 - so i think that is through the command
262:58 - well let me quit out of this
263:01 - there we are hey
263:04 - get out of that um you're gonna need to
263:07 - install it from
263:08 - pip install open cv dash python okay
263:11 - i'm new to python so what is pip firstly
263:14 - like for for those that don't know
263:16 - uh uh python
263:20 - uh i forget what it stands for but it's
263:21 - it's a package oh package installer
263:23 - python or something
263:24 - okay so it's like it's a bit like npm
263:26 - then right
263:28 - yeah yeah so it just allows you to
263:29 - install um
263:31 - a bunch of libraries that are for python
263:33 - so there's pip there's anaconda
263:35 - um there's homebrew there's a there's a
263:37 - few you can use to download
263:38 - different things but we're just using
263:40 - pip it's the it's the simplest one in my
263:42 - opinion
263:43 - so yep just run pip and then this is a
263:44 - command install and then we're gonna be
263:46 - installing opencv dash python it might
263:48 - be python
263:49 - opencv just try both okay and the one
263:50 - that works works and if you're having
263:52 - issues with that
263:53 - then adding headless at the end um can
263:55 - sometimes fix stuff
263:57 - but yeah just do that or do google
263:58 - search if you really can't figure it out
263:59 - once you have opencv installed
264:01 - then um then we can start coding okay
264:04 - yep so um you can
264:07 - we can just import cb2 so that's the
264:09 - very first step it's just importing
264:11 - um opencvs this two is uh the second
264:14 - version there's the second version of
264:16 - cv2 i actually don't know why it's like
264:17 - that but
264:18 - cv2 is the library for opencv okay
264:21 - and let's just start with uh this just
264:25 - to make sure that our code is running
264:26 - correctly
264:27 - so opencv 2 yeah i mean import cv2
264:32 - and then it's big enough right yeah yeah
264:35 - very good yeah
264:36 - and that's how we run our python script
264:37 - we write python with the file name dot
264:39 - pi
264:40 - and that's it right yep just make sure
264:42 - you're in the same directory so in my
264:44 - case i'm actually
264:45 - um in a folder but and then make sure
264:47 - you're in a folder here if you guys
264:48 - don't know how to do that then um
264:52 - i mean yeah i don't want to make this
264:54 - too much of a command line
264:56 - thing but cd is change directory yep
264:59 - yeah so actually let me just go back
265:01 - here so see i'm on the desktop here you
265:03 - probably
265:05 - well actually you'll probably be here
265:07 - when you open your terminal it might
265:08 - look different but you'll probably want
265:10 - above the desktop you're going to want
265:11 - to put
265:11 - cd and then just type in desktop to go
265:14 - to your desktop
265:15 - i'm in the desktop and then from there
265:17 - you're going to want a cd
265:18 - to open cv well this is the name of my
265:21 - folder it's opencv default
265:23 - uh smile detection and then from there
265:25 - and now i'm in this folder
265:26 - and then i can run this command okay
265:28 - because the file is located
265:29 - okay yeah i don't know so
265:33 - it's modified dot pi yep and if we run
265:35 - this
265:37 - it should just print what's up because
265:38 - that's all we have in here okay so it's
265:40 - working correctly
265:41 - um that also means this is working
265:42 - correctly it'll pop an error for you if
265:44 - you don't actually have it installed
265:45 - correctly but this one it just
265:47 - doesn't say anything if it says nothing
265:48 - you mean you got it installed correctly
265:50 - if it says something you gotta
265:51 - install it correctly go ahead all right
265:53 - so let's just move on okay
265:55 - let's do it uh let me pull some of these
265:57 - code from down here
265:58 - so first thing i said is we're gonna
266:00 - actually start with just the face
266:02 - section so let me copy the comments as
266:04 - well just so like we have a nice
266:06 - um nice app with comments and everything
266:09 - nice so face class
266:13 - all right so here this is a pre-trained
266:15 - model for detecting faces like all the
266:17 - fancy machine learning stuff happens in
266:18 - here it's just a bunch of numbers that
266:20 - the image gets passed through and then
266:21 - it tells you face or not that's all it
266:23 - is
266:23 - you pop in an image to this and then it
266:25 - says yes or no and it gives you an
266:27 - answer
266:28 - again if you want to see how this is
266:30 - actually made the whole algorithm and
266:31 - step by step without everything that's
266:32 - happening inside the computer then you
266:34 - can go watch one of the other
266:35 - face detection or car and pedestrian
266:37 - tracking videos yeah
266:38 - i think it's worth saying well let's
266:40 - just start with just just like uh
266:42 - from my understanding all right like a
266:43 - classifier is something where we have
266:45 - like
266:45 - some kind of input right and then we
266:48 - have this model
266:49 - so in this case we have the har cascade
266:51 - frontal face so some kind of like model
266:53 - is is inside of that classifier and then
266:56 - so let me go ahead and i'm just dropping
266:58 - on the screen so we have some kind of
266:59 - model
266:59 - and then from that so we have some kind
267:01 - of input right
267:03 - then we have a model and then we have
267:07 - a sec and then we have some kind of
267:09 - output and what would that output say
267:10 - whether like
267:11 - a certain value which says if you're
267:13 - smiling or not right
267:15 - yeah literally just a one or a zero yeah
267:17 - okay it'll just say yeah
267:18 - one or yes or no but yeah but well
267:21 - technically
267:22 - it'll give you coordinates on your image
267:24 - of where the box is around the face
267:26 - in practice but i mean basically it just
267:28 - kind of says yes or no
267:30 - okay um kinda i mean it the
267:33 - implementation is different but the idea
267:34 - is it'll just say
267:35 - smile or not smile that's all it'll say
267:37 - right so we have some kind of input a
267:39 - classifier which is what we're using
267:40 - here which is a hard cascade and then
267:42 - some kind of output which is
267:44 - whether it's telling us if it's smiling
267:45 - or not or some kind of coordinate but
267:47 - that's
267:47 - that's how it roughly works guys so as
267:50 - aaron said you pretty much this is the
267:51 - line of code to go ahead and get that
267:52 - working nice
267:53 - yeah carry on yeah actually i guess i
267:55 - can explain
267:56 - a little tiny bit technically if you
267:58 - have a whole entire image or a frame
267:59 - from the video
268:01 - then it will look over every little box
268:03 - inside that and then it'll tell you if
268:05 - each
268:05 - boxes of different sizes if that's a
268:07 - face or not or if that's a smile or not
268:09 - no so that's what it's actually saying
268:10 - if it's a yes it sends you the
268:12 - coordinates within the whole image
268:14 - of the little box and then that's how we
268:16 - draw the little box because we have the
268:17 - coordinate and we can just draw a box at
268:18 - that coordinate
268:19 - so that's actually what's happening so
268:22 - it's the whole image and then you just
268:24 - go over the whole thing and then choose
268:26 - it like no no no no no no oh found a
268:27 - face that's a yes
268:28 - give me the coordinate and then no no no
268:30 - again so if there's multiple faces it'll
268:31 - find multiple faces as well
268:33 - awesome okay so it's not just one phase
268:35 - we can support mobile faces or nice
268:37 - surab yeah we just dropped a 100 rupee
268:40 - donation
268:40 - says thank you so much for sharing
268:42 - awesome thank you dude
268:44 - let's carry on thank you yeah here
268:46 - actually let's uh let's run the code
268:48 - really quick
268:49 - yep um i want to show it with two faces
268:51 - i didn't show with two
268:52 - oh nice yeah i should have shown it with
268:54 - you real quick i can just use my phone
269:00 - there we go well i mean hopefully it
269:02 - works it might bug out because one of
269:03 - them is an image
269:04 - yeah but we'll see oh
269:07 - nice that's dope dude
269:11 - this is smiling yeah and it's real time
269:13 - and it's quite performant like that's
269:15 - that's pretty like fast like it's as you
269:17 - move your phone around if you try and
269:18 - move it around fast
269:20 - yeah look at that that's just smooth
269:22 - nice
269:24 - okay and so there's some kind of loop
269:26 - i'm guessing this running or like some
269:27 - kind of thing that's gonna happen there
269:29 - yeah
269:30 - yeah we're just pulling out the let me
269:32 - clear this we're just pulling out the
269:34 - the webcam footage
269:35 - okay webcam it's the easiest way to get
269:37 - some real-time footage yeah i mean this
269:39 - could be a security camera could be a
269:41 - whatever um but in our case we're just
269:44 - gonna be using
269:45 - the webcam go ahead nice all right so
269:48 - let's do that next let's just pull up
269:49 - the webcam and show you how to get the
269:50 - webcam with opencv if you guys are
269:52 - watching the other streams you guys know
269:53 - how to do this you'd be very comfortable
269:54 - by now the third time we're doing it
269:56 - but let's just do this
270:00 - right there and this is the best way to
270:03 - do it because then there's no typos and
270:05 - i don't embarrass myself
270:06 - right sunny sure that happens a lot
270:10 - yeah but anyways so this is how you want
270:13 - to grab your webcam
270:14 - um we just call it webcam a variable
270:16 - you're gonna need to have a variable for
270:17 - that because this is how we access all
270:19 - the webcam stream
270:20 - footage uh but really it's just video
270:22 - capture so
270:23 - um you just call the opencv library dot
270:26 - video capture
270:27 - and if you put zero this is the webcam
270:29 - but you could actually also put like
270:30 - something like whatever
270:31 - dot mp4 okay you could also get video
270:33 - files and run it on there
270:35 - um like that joker like the joker one
270:37 - that i had yeah over here
270:39 - this is how i did that i just imported
270:40 - this file and then i ran it through and
270:43 - then i recorded it and put it back here
270:44 - but for us zero is webcam
270:48 - nice quick so with pop-up zero and
270:52 - let's just uh i think you'll see
270:55 - that m show okay no no no not m show
270:59 - uh what is it i always get confused
271:02 - between
271:03 - between uh footage and yeah it is m show
271:06 - okay i always get confused between um
271:12 - images so
271:15 - yeah show the current frame so let's
271:17 - just pop in a quick loop and just show
271:19 - the webcam
271:20 - live to the screen okay so and from here
271:23 - then it should be
271:25 - uh we should clean up i think it's
271:26 - destroy all windows yeah cv2
271:29 - and and uh oh okay you have to release
271:32 - the webcam as well
271:33 - yes yeah i just clean i mean you
271:35 - technically don't have to but i mean
271:36 - it's just like good practice
271:38 - so this here is what's actually going to
271:39 - show so while true
271:41 - um we're just going to be uh showing the
271:44 - frame oh i forgot another line of code
271:46 - we're actually going to need
271:47 - um one more this is actually a big chunk
271:51 - side let me go line by
271:52 - line let me just get this last one here
271:53 - yep get it
271:55 - here it is read the current frame
272:00 - all right nice let me go line by line
272:02 - because this this kind of was a big
272:03 - chunk
272:04 - so what's happening here is after we get
272:05 - the webcam the webcam variable
272:08 - um uh how we how we get a frame is we
272:12 - actually
272:13 - uh actually let me just show this real
272:14 - quick so let me comment out all this
272:18 - just so that we can go step by step is a
272:19 - better way doing this on the fly guys
272:22 - yeah so here here we go look at this
272:25 - single line here ignore everything after
272:26 - that
272:27 - okay okay um we can okay
272:30 - we'll do this why the way i like to do
272:34 - it
272:35 - code completed so if this prints yeah it
272:38 - means if it prints then there is no
272:39 - errors because it's at the end
272:40 - but so this is how we actually read the
272:43 - webcam
272:44 - so you call dot read on the webcam and
272:47 - what this returns is a tuple
272:49 - so this is actually a two a two tuple so
272:52 - this is the first one
272:53 - first element this is the second element
272:55 - okay and
272:57 - oops what this is this is just the
273:00 - boolean of if it was a
273:01 - successful frame read or not and the
273:02 - second one is
273:05 - uh the actual frame so this is like an
273:06 - image that we can actually
273:08 - um run things on so let's actually just
273:10 - show that okay now i can grab the
273:13 - cv2.image show but right there
273:17 - and this is the name of the window so i
273:19 - just put why so serious but you can put
273:20 - smile detector if you want
273:22 - yeah okay and let's go back to the
273:25 - terminal
273:26 - oops what did i do
273:33 - there we go small detector yep and
273:37 - there's oh i forgot one more so after
273:40 - this
273:40 - you're gonna need to run cb2 dot
273:44 - weight key okay and what does this do
273:46 - okay let's
273:48 - what this does is so what happens is
273:52 - we get the webcam okay and then we call
273:54 - webcam.read
273:55 - which is just reading from the webcam
273:57 - stream and it'll get the first frame the
273:59 - very first frame of the webcam video
274:01 - yeah and then if it succeeded now but
274:03 - ignore this for now it'll get the first
274:04 - frame
274:05 - then from here it'll say cv2 dot image
274:07 - show uh
274:08 - image show means it'll show that image
274:10 - to the screen we're going to show frame
274:13 - what the and then the window name will
274:14 - have small detector like up here at the
274:16 - top of the window will be small detector
274:17 - nice the thing is this shows only for a
274:20 - split second as long as it needs to and
274:21 - then it quits out
274:23 - right what this does is it says let's
274:25 - wait for a key before we continue to the
274:26 - end of the program so it'll stay open
274:28 - till we press a key
274:29 - okay this basically means display right
274:31 - okay so this is
274:32 - so this means that without this line of
274:34 - code it pretty much hides it super quick
274:36 - so now we're saying wait until wait
274:37 - until you press a key on the keyboard to
274:39 - hide it right
274:40 - yeah pretty much and this is here
274:42 - because once we're going frame by frame
274:44 - you don't want to be pressing a key
274:45 - every time the frame changes it's going
274:47 - to automatically change in real time
274:48 - okay so we really only need this for uh
274:51 - this
274:52 - case of doing just the the first frame
274:54 - of the image so let's run this
274:56 - and see what happens there we go
274:59 - so that's the first frame okay so like
275:02 - not it's not an actual video it's just
275:03 - one frame
275:04 - okay um but we're gonna wrap this in a
275:06 - loop and then we'll see it in real time
275:08 - okay oh i see okay so you just got a
275:10 - single frame okay i got you i'm with you
275:12 - yep
275:13 - yep yep because dot read will read a
275:15 - single frame okay and then it keeps
275:17 - track of where it is so every time
275:18 - it calls dot read it'll read the next
275:20 - frame next next frame so we just wrap
275:21 - this in a loop and that's how you can
275:23 - get the real-time webcam footage
275:24 - right so i'm just going to read a single
275:26 - frame right read single frame
275:28 - oops yeah nice okay i'm taking notes for
275:32 - them
275:32 - yeah there we go what's nice bro i'm
275:36 - running out of coffee this is uh
275:38 - this is a disaster
275:42 - so this makes sense yeah we're going to
275:43 - read a single frame and then we're going
275:45 - to wrap it in some kind of loop so we
275:46 - get that real-time functionality
275:49 - exactly which is what we're going to do
275:50 - down here uh so let's get back to
275:53 - here now but i'm just going to plug in
275:54 - things one by one so like i said
275:56 - uh just the webcam and then read a
275:58 - single frame display that frame
276:00 - and then display that frame like wait
276:02 - until a key is pressed before you hide
276:04 - before you hide the frame okay so now
276:06 - all we want to do is just
276:08 - pop this in a loop okay so we got the
276:10 - webcam here
276:12 - now um the loop is going to be here
276:15 - because once we have the webcam
276:16 - we want to keep calling dot read on each
276:18 - frame over and over again
276:19 - yeah okay so we would just want to run
276:21 - this forever and that's why it's a while
276:22 - true loopy it's going to run forever
276:24 - until we're done so let's pop all of
276:28 - this
276:29 - into there and
276:34 - uh from here oh like let me get the
276:36 - cleanup code
276:37 - okay so this here at the end let me let
276:38 - me show you guys this real quick
276:41 - this here is just some cleanup okay so
276:43 - it's not super important it's kind of
276:44 - boring code but i'm just going to say at
276:45 - the end of the whole app you want to
276:47 - make sure you have
276:48 - a webcam dot release it's just letting
276:49 - the operating system know that hey
276:51 - this app is done using the webcam uh
276:53 - free up all resources so that something
276:55 - else can use like zoom or skype can now
276:56 - use the webcam without any
276:58 - uh memory issues go ahead and then
277:02 - and then the last thing is uh cv2 to
277:05 - destroy all windows
277:06 - so this just kind of closes all windows
277:08 - to make sure nothing's still open okay
277:10 - because sometimes that happens yeah this
277:11 - is a cool little thing i forgot about
277:13 - what i found recently so
277:14 - very handy yeah
277:17 - um okay so after this then
277:21 - we get a webcam we have a while loop and
277:24 - same exact thing so this should work
277:25 - the only caveat is uh if this is empty
277:28 - it's gonna
277:29 - keep waiting for a key press so let's
277:31 - let's run this and then i'll show you
277:33 - how that works
277:35 - so here we go it's a frozen frame but as
277:38 - i press a key
277:39 - it keeps going to different iterations
277:40 - of loops so it keeps running
277:42 - it keeps yeah and each time i
277:46 - hit it it gets the current frame because
277:48 - it's calling dot read
277:49 - alright so calls.read on the frame yep
277:52 - dot free and if i spam it and then
277:56 - kind of like real time but that's
277:58 - annoying so what we actually want to do
278:00 - is
278:01 - yeah what we actually want to do is dot
278:02 - weight key actually just waits
278:04 - until the key is pressed uh forever but
278:06 - if we put something in here this is how
278:08 - many milliseconds it'll wait before it
278:09 - automatically
278:10 - goes by right so if we put one it'll
278:12 - automatically spam
278:14 - a key every one millisecond and that's
278:16 - kind of
278:17 - like the behavior if i put like a
278:18 - million then it would just wait a
278:19 - million
278:20 - that'd be too long would be like 10
278:21 - minutes yeah but if i just put one
278:23 - millisecond
278:24 - now when i run this this should be
278:26 - updating every millisecond by itself and
278:28 - i should be in real time so let's give
278:29 - it a shot nice well let me quit out let
278:32 - me quit out of the old one
278:35 - oh wait i gotta i gotta kill it one
278:36 - second
278:40 - how do you kill it in uh uh it should be
278:42 - as h it should be control c
278:44 - yeah so if you just spam control c
278:47 - sometimes it takes a little bit
278:50 - uh oh it's not working
278:54 - i'll just force quit yeah also guys just
278:56 - want to drop in
278:57 - before wire and sorting now we have one
278:59 - comment over there
279:00 - there's one says bernard you people are
279:04 - really amazing awesome i have no words
279:06 - to express my feelings it's only because
279:07 - of you people
279:08 - today i got a job at google
279:12 - at google he got a job at google did
279:15 - that's insane
279:17 - damn like seeing that holy crap i
279:20 - couldn't even get a job of google what
279:21 - is
279:22 - bro bro get this guy in the stream he
279:23 - should be teaching not me i know
279:25 - yeah not a same we love that guys and we
279:28 - also got another donation from
279:30 - tech programmer thank you very much dude
279:33 - we massively appreciate that and also
279:35 - yeah that's amazing
279:36 - guys drop us questions in the chat and
279:38 - we'll literally we'll be happy to answer
279:40 - it as the stream goes on
279:41 - we really love when you guys engage with
279:43 - us and let us know yeah
279:45 - yeah hey whoever landed the job at
279:47 - google send uh send me and send me a dm
279:49 - on instagram and then uh we want to hear
279:51 - a little about your story that's awesome
279:52 - i don't know that's exciting yeah what
279:54 - was his name sunny
279:55 - what did he say he said yeah let me go
279:57 - ahead and find it again so what is his
279:59 - name
279:59 - it's i don't have it on i don't get
280:01 - removed so i've just popped it open it
280:02 - says
280:04 - [Music]
280:07 - ajax got it all right we'll meet yeah
280:09 - we'll be expecting you to dm us okay
280:11 - yeah awesome yeah i'm the google guy
280:13 - yeah i'm the google guy
280:15 - that's insane dude we love that nice
280:19 - kind of jealous actually yeah you soured
280:21 - my mood
280:22 - [Laughter]
280:24 - that's amazing great that's that's
280:25 - exciting we have another awesome comment
280:27 - by she goes you guys are just amazing
280:29 - i've learned a lot from these live
280:31 - stream your work is very inspiring thank
280:33 - you so much
280:34 - that's awesome dude thank you for
280:35 - watching
280:38 - all right let's go all right let's go
280:40 - yeah yeah it did
280:41 - the control c didn't work so i don't
280:43 - know what's happening but i just killed
280:44 - it manually
280:45 - yeah um so where were we before i got
280:49 - distracted
280:50 - oh i was running the frames yeah so when
280:52 - i run this again
280:53 - it should actually refresh every
280:55 - millisecond by itself okay so that's how
280:57 - we
280:57 - we fetch this let's run this
281:00 - and go back here and there we go
281:03 - so i'm feeding the webcam footage i mean
281:06 - opencv is
281:07 - getting the webcam footage the webcam
281:09 - stream and it's just displaying it in
281:11 - this window
281:12 - and then i called it small detector
281:14 - right
281:15 - okay so so that that by putting one
281:18 - inside of the weight key
281:19 - that's pretty much saying every second
281:21 - every second like go to the next
281:23 - frame right yeah like it says only wait
281:26 - for one second it says wait for one
281:27 - second then
281:28 - press it press a key like like a fake
281:30 - key like a pretend key and then it
281:31 - presses a key every one second right
281:33 - okay so this waits one this way it's one
281:36 - millisecond
281:37 - yeah but nothing waits infinitely nice
281:39 - that's the difference awesome
281:40 - or ten we could do ten ten milliseconds
281:43 - is fast so this would still work
281:44 - but it doesn't really matter awesome all
281:47 - right
281:47 - yep nice and
281:51 - okay let's see if it'll kill okay so now
281:53 - control c is working
281:55 - nice i don't know what this red thing is
281:56 - means sunny sunny have you installed
281:58 - this weird shell thing
281:59 - zsh i've only used it like once but i
282:00 - ran away but he says it's colorful
282:02 - yeah usually i think that's when your
282:03 - branch is dirty i think so
282:05 - i mean that's usually i got it something
282:08 - like that yeah
282:09 - yeah yeah i changed the i probably
282:12 - changed the code in here and then it
282:14 - changed
282:14 - but no big deal just ignore this like
282:16 - the color of the arrow
282:19 - but yeah let's just move on okay so
282:22 - i can actually get rid of this stuff
282:26 - because we actually pulled everything
282:28 - out so now we're back to the
282:30 - code ran without errors nice
282:34 - okay uh here let me just pop in some
282:37 - comments
282:39 - we have 350 people watching right now so
282:42 - thank you
282:42 - so much for watching and yeah if you're
282:45 - enjoying what you're what you're seeing
282:46 - right now
282:46 - um with the face detection you think
282:48 - it's pretty cool all we ask is that you
282:50 - just smash the thumbs up button
282:51 - and that will help this video get out to
282:53 - more people nice
282:55 - yeah yeah like smash the track pad like
282:58 - slam your mouse
282:59 - just hit it as hard as you can
283:02 - keep that
283:06 - domestic violence and domestic violence
283:08 - in the software program
283:13 - that's a terrible joke but uh
283:16 - so yeah this is step one all right so we
283:18 - got we got the webcam footage in here
283:20 - all right you guys should be comfortable
283:21 - if you guys done this before pretty
283:22 - straightforward
283:24 - now uh once it one check we want to put
283:26 - in though is actually this
283:29 - so i mean it wasn't it wasn't breaking
283:31 - before but we do want to put in a check
283:33 - here
283:33 - uh right here so after we read the the
283:35 - frame
283:36 - okay the first frame with the dot read
283:38 - method the first variable or i mean the
283:40 - first element is actually
283:42 - a boolean of if the read was successful
283:44 - or not okay so
283:45 - all i want to do is put yeah because
283:47 - sometimes it might bug out
283:49 - um what the webcam is usually fine but
283:51 - for a video file if you're reading an
283:52 - mp4 or something like you put a
283:54 - video file in here like sometimes if one
283:56 - of the frames is corrupted or whatever
283:57 - then
283:58 - it'll not work so you just kind of put a
284:00 - safe check in here so
284:02 - if it wasn't a successful successful
284:04 - frame rate just break out of this while
284:06 - loop and just like abort the program and
284:07 - it'll go down to here and close
284:08 - everything so that it doesn't break it
284:10 - just kind of quits
284:11 - so yep that's that's all that is just a
284:14 - quick
284:15 - quick little aaron somebody asked a
284:17 - decent question
284:18 - they said how can i install the face xml
284:20 - file so the one that we used at the top
284:22 - where did you actually get that from
284:24 - again uh the opencv github document
284:28 - github repo so they they provide all of
284:30 - that the link is in the description so
284:32 - you can just go down and scroll to the
284:33 - bottom
284:34 - and just download this uh the face xml
284:36 - file
284:37 - there's also a smile one but we haven't
284:39 - gotten there yet we're going to be using
284:40 - both we need both to make this
284:42 - work um you'll see you guys will see
284:44 - later why that is
284:45 - yeah but yeah let's let's just continue
284:48 - let's do it
284:50 - uh huh so after we get the frame read
284:53 - and we have this little check here
284:54 - then uh let's actually start detecting
284:56 - faces okay so if you guys watched the
284:58 - face detection video you guys already
284:59 - know how to do this pretty
285:00 - straightforward
285:01 - it's a very similar but there's a little
285:03 - trick here that you guys are probably
285:04 - gonna lower your minds
285:05 - at some point uh hopefully
285:08 - but but maybe not uh okay so after we
285:12 - got the frame
285:14 - to actually run uh face detection on the
285:17 - current frame using this xml
285:19 - we need to use i mean we're using opencv
285:22 - of course it's a very simple
285:24 - code it's just like detects faces pretty
285:25 - much but we do need to
285:29 - yeah we do need to change the frame to
285:31 - black and white though this is just an
285:33 - optimization
285:34 - because in a black and white image you
285:36 - can still you can still tell what a face
285:38 - is
285:38 - you know if a human can can still tell
285:40 - then the computer can still tell and
285:41 - then there's less data to deal with
285:43 - but the actual like you know recognition
285:46 - ability of
285:47 - a face isn't hindered by it being black
285:50 - and white so we just
285:51 - converted to black and white to greatly
285:52 - optimize it it increases it
285:54 - by a lot actually because rgb has three
285:57 - channels
285:58 - black and white only has one channel
285:59 - that's super interesting i had no idea
286:01 - that that would be an optimization so
286:02 - we're making a grayscale
286:04 - so that it actually reduces like the
286:06 - sort of not the amount of processing
286:07 - they have to do on the the video
286:10 - yeah because you're kind of just like
286:11 - jumbling rgmb
286:13 - together into one number you know red
286:15 - green and blue because then you can just
286:16 - kind of be like oh
286:17 - then you can just play with brightness
286:18 - you can be like okay um
286:20 - somebody's eyes look a little bit darker
286:22 - than their right cheeks something like
286:23 - that
286:26 - or somebody's eyebrows are darker than
286:28 - the forehead you can just you just want
286:29 - to see the relationship of brightness
286:31 - between different areas on the thing
286:32 - and those all added together if you do
286:34 - it enough you'll eventually define a
286:36 - face like okay eyebrows darker than
286:38 - forehead
286:39 - eyebrows darker than nose lips a little
286:41 - bit darker than cheeks
286:43 - eyes a little bit darker than cheeks
286:44 - stuff like that like hairline a little
286:46 - bit darker
286:47 - than um if you have dark hair so like
286:49 - it's just those kinds of things over and
286:50 - over
286:51 - um you eventually can can um explain to
286:54 - a computer what a face looks like after
286:56 - thousands of those little relationships
286:58 - or a car or pedestrian or anything or a
287:00 - smile in this case also like teeth you
287:02 - know
287:03 - teeth are whiter than your lips so like
287:05 - it would understand what a smile is
287:07 - nice okay that's that's awesome i would
287:09 - never have thought i would be
287:10 - optimization so that's that's cool
287:11 - also just to jump in chin moy kalia says
287:14 - again because of you i'm able to make my
287:16 - college fees
287:17 - by freelancing just wanted to throw that
287:19 - in
287:21 - i love stuff like that thank you i feel
287:23 - like these people are making making more
287:24 - money than us like i'm kind of
287:26 - kind of upset i know guys that's
287:35 - a guy make money so we can go to school
287:37 - to learn from people that are not us
287:39 - is that is that actually a win for us
287:41 - honey is that actually a win for us
287:43 - let's think about this for a second
287:44 - i think we should cut the stream okay
287:48 - abort yeah nice cut off signals
287:53 - oh got it what i love though anyways is
287:56 - that is this like literally
287:58 - so few lines of code to get this all
287:59 - working
288:01 - yeah that's what i love about it too and
288:03 - then if you if you optimize everything
288:05 - under the hood which is how you should
288:06 - be doing stuff like if you like c
288:08 - or c plus plus under the hood um then
288:10 - it's still pretty fast but you can be
288:12 - very expressive with your stuff i think
288:13 - that's why they choose it for machine
288:15 - learning
288:15 - because there's a lot of weird yeah
288:17 - there's a lot of weird nasty stuff
288:20 - and you actually see the power of python
288:21 - here later on
288:23 - if this was written in javascript it'd
288:25 - probably be like two or three times as
288:26 - long you know
288:26 - like yeah maybe not yeah
288:29 - i could vouch for that yeah
288:33 - of course this is this is this is nice
288:34 - and clean compared to javascript
288:36 - all right let's carry on yeah i don't
288:38 - like javascript yeah yeah
288:41 - i know no javascript is amazing sonny i
288:43 - don't want to hurt your feelings i know
288:45 - it's going to make me hook out guys
288:49 - you just see a video yeah reconnecting
288:52 - it
289:02 - but yeah let's continue on so once it's
289:05 - gray once it's gray
289:06 - okay this is actually requirement like
289:07 - opencv you have to take it
289:09 - um and so oh i should explain all this
289:12 - so what this is is opencv
289:13 - has a function called convert color
289:16 - which allows you to convert the color of
289:17 - an image
289:18 - um to to black and white or back and
289:21 - forth or just the red channel or just a
289:22 - blue channel you can do all different
289:24 - kinds of things
289:24 - but in our case we just want to change
289:26 - something from a color image
289:28 - to um gray okay i mean well this is
289:32 - a bgr which is rgb backwards and then
289:35 - two gray so that's all this means
289:36 - there's like different encodings we can
289:38 - use
289:38 - so we're gonna be using this one to
289:40 - convert this from a color image
289:41 - to gray so let's actually run this now
289:44 - go ahead and
289:45 - actually we need to display the actual
289:47 - black and white frame
289:49 - i feel like i've done this a bajillion
289:50 - times because i actually have it might
289:51 - be boring some people who've seen the
289:52 - other streams but whatever
289:55 - and there we go oh black and white
289:58 - webcam yep so you can still tell that
290:00 - this is the face
290:01 - you can still tell but my mouth is
290:03 - smiling so we don't need color to be
290:05 - already and stuff it actually looks like
290:07 - it's smoother it actually looks a bit
290:09 - smoother when it is
290:10 - yeah because there's there's only a
290:12 - third of the data you know with color
290:14 - you have
290:14 - three channels or four channels actually
290:17 - there's a brightness channel
290:18 - as well yeah um but on this one it's
290:20 - just the brightness channel
290:21 - that's nice that's it so it's actually
290:23 - four times as fast
290:25 - because there's one channel versus four
290:26 - channels awesome
290:30 - and let me just quit out on the terminal
290:33 - control c and let's just clear this up
290:36 - because it's getting messy
290:38 - nice all right so there we go black and
290:41 - white frame
290:42 - now it's literally as simple as popping
290:44 - this grayscale frame into
290:46 - our classifier for faces yeah
290:49 - and it'll spit out the coordinates of
290:51 - where my face is and then we can just
290:52 - draw a rectangle on my face
290:54 - and bada bing bada boom that's a face
290:56 - detector um
290:57 - that's the first and then we gotta do
290:59 - smiles you have to like overlap them in
291:00 - some weird way and there's some cool
291:01 - little there's a little trick i'll show
291:02 - you guys later that
291:03 - is critical for this to work and then
291:05 - some tuning you have to
291:06 - uh tune some variables at the end too
291:08 - which actually make it work properly
291:10 - but i love a simple you make it like
291:12 - yeah you know we just gotta use this
291:13 - machine learning classifier and then you
291:15 - know
291:16 - we're gonna get some coordinates right
291:17 - and then we just gotta draw a box around
291:18 - the face yeah there's no big use
291:20 - you gotta do that infinite loop
291:26 - i mean i'm explaining every line so i
291:28 - feel like people can follow along if
291:29 - they know python if not then uh
291:32 - you know i'll fire myself yeah donald
291:34 - trump
291:35 - nice yeah
291:38 - so let's go down here and actually
291:42 - just detect faces okay let's do that
291:45 - stop
291:46 - here i might go a little bit faster
291:48 - because i'm just kind of this is like
291:49 - repeating the face detection stream
291:51 - yeah we haven't even gotten to the smile
291:52 - stuff yet but here here's the line for
291:54 - detecting the actual faces
291:56 - okay so yep so how this is gonna work is
292:00 - we have our classifier up here okay face
292:02 - detection
292:03 - face detector which we created from this
292:06 - xml file which has like all the data
292:08 - about like what
292:09 - a face actually looks like depending on
292:10 - the brightness relationships like we
292:12 - talked about
292:12 - okay um like and then from there so we
292:15 - have this this phase detector
292:17 - now with this face detector okay with
292:19 - this face detector
292:20 - we can call a function called detect
292:22 - multi-scale okay
292:23 - okay and then it just takes in an image
292:25 - and then
292:26 - um so what this will do it will
292:29 - tell us where all the faces are in this
292:32 - image okay it'll say oh there's a face
292:34 - here there's a face here there's a face
292:35 - here
292:36 - and that's what it'll do so is it
292:38 - returning an array
292:41 - yes an array of points okay an array of
292:44 - rectangles
292:45 - so the reason it's called detect
292:47 - multi-scale is because you just want to
292:49 - detect
292:50 - uh faces of any scale so if there's a
292:52 - small face you want to detect a small
292:54 - face if there's a big face you want to
292:55 - take the big
292:55 - big face and you want to take multiples
292:58 - of them so you
292:59 - detect all of them that's why it's
293:00 - called detect multiscale
293:02 - uh uh because we can really pop in we
293:04 - can i mean we can use any detector like
293:06 - we have a dog detector or a cat detector
293:07 - we could also detect multi-scale of cats
293:09 - or dogs
293:10 - okay so that's why it's called that nice
293:12 - okay
293:15 - so it takes in a frame a black and white
293:17 - frame and then
293:19 - it'll say okay at these at these places
293:21 - there are faces in this image
293:23 - and that's what this is so this is just
293:24 - an array of points yeah uh
293:26 - in my case there's it's gonna be array
293:28 - of length one because there's only one
293:29 - face but when i had the joker on the
293:30 - face
293:31 - um when i had joker on the screen too
293:34 - yeah and
293:34 - let me quick then there would actually
293:36 - be
293:37 - so when there was both of us yeah then
293:40 - there would be
293:41 - these faces would be a length two
293:42 - because there's two faces in the
293:44 - the in the video go ahead it makes sense
293:48 - yep so from there uh let's just print
293:51 - out
293:52 - actually uh faces okay
293:55 - so this is just gonna be a list let's
293:58 - just show this and it's going to spam
294:00 - the
294:00 - terminal here over and over again
294:02 - because we're in an infinite loop
294:03 - remember
294:05 - so as i'm here oh nice you can see the
294:08 - you can see the
294:09 - location of my face is being detected
294:11 - and then it's just being spit out here
294:13 - okay so like x y coordinates you know
294:15 - like
294:16 - blah blah blah yeah and then from this
294:19 - we can just
294:20 - draw a rectangle on the face that's it
294:23 - that's clean man i was expecting like
294:26 - some really intense stuff for that
294:27 - that's super clean how it comes back
294:29 - like
294:30 - yeah that's it so it's it's a it's a
294:33 - list
294:34 - of lists so if there's two faces so
294:36 - actually watch this
294:40 - now there's two faces hey look at that
294:44 - see how there's two faces on the screen
294:46 - yeah
294:47 - and then when i get rid of it we're back
294:48 - to one face the list is
294:50 - linked one not a list of of length two
294:54 - and there's two per them that's nice
294:56 - okay quiet and if there's three then you
294:59 - know three if there's a bajillion
295:01 - yeah or in the matrix you know mr
295:03 - anderson
295:05 - agents going i think it's what i'm
295:07 - saying guys like just
295:08 - from like that classifier you're able to
295:11 - do all of this so this is just the power
295:13 - of machine learning like
295:14 - and like yeah and as i said this is a
295:16 - face detector human face detector but
295:18 - you could easily go and pick up like a
295:20 - dog detector
295:21 - put that here and i guess it would do
295:23 - the same thing right
295:25 - you can detect anything so a hard
295:27 - cascade is a single algorithm that can
295:29 - detect any arbitrary object so basically
295:32 - we're
295:32 - you're like if the computer was a person
295:34 - we're literally downloading
295:35 - this is what a face looks like into its
295:37 - brain that's literally what this is
295:38 - doing
295:39 - you just have to teach this before we
295:41 - give it to it so
295:42 - this was a result of machine learning
295:44 - with a bunch of face images
295:45 - uh that somebody created and it takes
295:47 - probably like a few hours or a few days
295:49 - to
295:50 - create it but then once it's created
295:51 - then anybody can use it so that's kind
295:53 - of the power of it
295:54 - awesome got you yep
295:57 - and of course heart cascade is just one
295:58 - algorithm for for object detection
296:01 - whether whatever object happens to be in
296:02 - our case of face or smile
296:04 - yeah there's many algorithms but this is
296:05 - the simplest and oldest one it's
296:06 - actually based on viola jones
296:09 - um these names probably mean nothing but
296:10 - if you don't look it up look up viola
296:12 - jones algorithm
296:13 - yeah and then um our cascade so these
296:15 - are just names of people who came up
296:17 - with them back in like the 70s or 60s or
296:19 - whatever
296:20 - nice but awesome smart smart people yeah
296:23 - very smart people
296:24 - so okay so that's the face so uh from
296:27 - here
296:28 - we just want to draw those rectangles
296:30 - back on the
296:31 - image here and then when we show it then
296:33 - it'll actually have the rectangles drawn
296:35 - on this as well instead of just showing
296:37 - just the raw frame
296:38 - okay so that's really all we're doing
296:41 - uh then from there then we can get to
296:43 - the smile stuff so at this point
296:44 - we probably should at the beginning oh
296:45 - if you want to get to the smile part
296:46 - just skip ahead but it's too late this
296:48 - is a stream
296:49 - yeah for anybody watching the replay but
296:52 - i mean i guess
296:52 - it is what it is yeah 45 at 0.45
296:56 - 45 minutes or so like that's when we
296:58 - start the smart stuff so yeah we can add
297:00 - that in the comments afterwards
297:02 - uh yeah let's put the timestamps and
297:04 - then you know like the youtube has that
297:05 - nice that
297:06 - thing now or like where the play bar is
297:07 - like segmented that thing
297:09 - might blow exactly yeah that's insane
297:11 - bro you should do that that would be a
297:12 - cool clone to do you should be like
297:14 - youtube you know segmentation
297:15 - clone like you scrape out like the the
297:17 - stuff and you segment
297:18 - the video or something i don't know it
297:19 - would be cool yeah
297:23 - all right stay tuned tomorrow for that
297:24 - because sonny's the beast can code
297:25 - things in five minutes
297:27 - wait guys just as another reminder we
297:29 - actually have quite a few people on this
297:30 - live stream right now
297:31 - tomorrow if you're excited we are
297:33 - building a whatsapp clone
297:36 - so we are building a whatsapp film
297:37 - tomorrow it's going to use firebase it's
297:39 - going to have a real-time chat
297:40 - functionality so
297:41 - if you're excited about that smash the
297:43 - thumbs up and make sure you set a
297:44 - reminder
297:47 - have you coded imessages yet an imessage
297:49 - clone no
297:50 - that's a good idea yeah we'll do that as
297:52 - well yeah
297:54 - you should do that because either
297:54 - facebook messenger but you should do
297:56 - imessage too
297:57 - instead of whatsapp you know what i mean
297:58 - what's that is more internationally
298:00 - yeah yeah forget the android people
298:06 - all right okay so now what we want to do
298:08 - is we just want to run
298:10 - um we just want to draw some rectangles
298:12 - on the frame so i'm going to kind of go
298:13 - over this quickly if you're getting
298:14 - confused then
298:16 - again there the other videos go a little
298:18 - bit uh
298:19 - slower to explain this in detail but i'm
298:21 - just going to go a little bit faster
298:23 - okay
298:23 - because we're going a little longer
298:25 - longer than i thought it's already been
298:26 - an hour bro
298:27 - yeah but uh so are we going to do like i
298:30 - said faces is a list of points
298:33 - so we just want to iterate over all of
298:34 - the points so all of the faces that
298:36 - the the algorithm found let's just kind
298:39 - of list let's just iterate over all of
298:40 - them and pull out those points
298:42 - so like i said there's four points here
298:44 - for each face
298:45 - so um we're just going to iterate over
298:47 - all of them okay
298:48 - go ahead so uh the first point is x the
298:51 - x
298:52 - coordinate the second point is the y
298:53 - coordinate this is the top left point of
298:55 - the face
298:57 - yep and then this is the width
299:00 - and this is the height of how big that
299:03 - uh square a rectangle should be so for a
299:05 - face it's squares by default
299:07 - but for smiles it can be any shaped
299:09 - rectangle so it just gives us like the
299:10 - width and height of the rectangle so
299:12 - we're given a point and a
299:13 - height from that from there that's all
299:15 - we need to actually draw because we can
299:16 - say at this point
299:17 - go this far and then go down and you can
299:19 - just you can you can figure out the rest
299:20 - with math which is what we're going to
299:21 - do here
299:22 - go ahead okay nice
299:26 - so here uh cv2 allows you to draw stuff
299:29 - on frames
299:30 - so like like this we can draw rectangles
299:32 - we can also put text on the screen
299:34 - which is how i put the smiling little
299:35 - thing when it says smiling so you can
299:37 - also put text we'll do that later but
299:38 - for now we're just going to draw a
299:39 - rectangle
299:40 - okay so the way this works is you just
299:42 - give it the image you want to pop it on
299:44 - so in our case we want to we want to
299:45 - draw the rectangle back on the colored
299:47 - frame not the grayscale
299:48 - frame but the colored frame oh okay
299:52 - because we're only doing the
299:53 - calculations on the grayscale on the
299:55 - grayscale frame because the coordinates
299:57 - and everything is exactly the same
299:58 - but once we have the data of where the
300:00 - face is we can just use the color again
300:02 - okay so it's an optimization yep because
300:04 - you're doing the calculations on the
300:05 - black and white image but then we're
300:07 - actually still only seeing the color
300:08 - image which is what you want
300:10 - okay and for rectangle all you need is
300:15 - the top left point and bottom right
300:17 - point of the rectangle for it to draw
300:18 - because
300:19 - those two points it makes it easy to
300:21 - draw the rectangle
300:22 - so the top left point like we mentioned
300:24 - is x y that's what we have here
300:26 - then the bottom right point is just
300:28 - going to be x y but you add the width
300:30 - and the height to the correct
300:32 - coordinate so uh x you want to go
300:35 - an extra width because that's the width
300:37 - of the rectangle just go you just add
300:39 - w to it okay and then why you just want
300:41 - to add the height to it
300:42 - and those two together will be the
300:43 - bottom right point of the rectangle okay
300:45 - if you guys don't know this then just
300:47 - like look at your geometry yeah brush up
300:48 - a little bit
300:49 - x plus the width and then y plus the
300:51 - height and that will give us the square
300:53 - right like the rectangle sorry yep yep
300:55 - go ahead yep
300:56 - square root in our case it'll be a
300:57 - square but uh any rectangle you can draw
301:00 - any rectangle
301:00 - go ahead and what's the numbers on the
301:03 - right
301:04 - so what are these this so this is rgb
301:06 - the color of the rectangle
301:07 - okay um well technically bgr because
301:10 - it's backwards and opencv
301:11 - uh this is just a random color you can
301:12 - put whatever you want you can play
301:14 - these can go from zero to 255. okay uh
301:17 - you can use whatever color you want but
301:18 - i just chose this as a nice green color
301:20 - okay because like it kind of like it
301:22 - matched nicely with the joker
301:23 - the joker screenshot so this is just a
301:25 - random green color you can use use this
301:27 - if you want
301:28 - but you use whatever color you want then
301:30 - this is just the thickness of the
301:31 - rectangle
301:32 - okay nice or four pixels thick that's
301:35 - all so this is just like customization
301:36 - stuff
301:37 - this one line is going to draw the
301:39 - rectangle on that
301:40 - on that frame yep yep i'm just gonna
301:43 - draw
301:44 - on that frame well a single face on that
301:45 - single frame yeah so
301:47 - we're gonna draw all the faces on the
301:48 - frame then we're gonna display that
301:49 - frame
301:50 - nice and then on the second frame it'll
301:52 - detect all the faces in the second frame
301:54 - and then show all the faces in the
301:56 - second frame and then again
301:58 - third frame because we're in remember
302:00 - we're in another loop so this is a
302:01 - nested loop
302:02 - yeah and uh and there's going to be
302:03 - another nested loop within this one
302:05 - which is going to be crazy later on but
302:07 - yeah okay let's go ahead and run this to
302:10 - see if we can actually see the the
302:11 - rectangles that you just
302:12 - you just talked about yeah definitely so
302:15 - um displaying the colored frame here
302:17 - which is what we drew the rectangles on
302:19 - colored frame
302:20 - yeah and let's just run this
302:25 - as you can see here um this is the x
302:27 - point
302:28 - this is the y point yep this is the
302:30 - width and this is the height
302:32 - nice and faces are always squares by
302:34 - default because that's just the
302:36 - parameter they set so you can see the
302:37 - width and height is always the same
302:40 - within height is always the same but
302:41 - different sizes sometimes because detect
302:43 - multi-scale
302:44 - it can be smaller or bigger okay awesome
302:55 - let's run this and there we go magic oh
302:59 - snap dude that's insane in javascript
303:03 - that would be like
303:04 - 30 lines of code you know just yeah
303:08 - yeah i know yeah it'd be something you
303:10 - know yeah this is where like i really do
303:12 - come back to python a bit like whoa
303:15 - yeah man you know you can do web
303:17 - development with python too you know you
303:18 - don't actually need javascript you know
303:20 - you just use django
303:24 - i'll fight you and i'll fight you and
303:26 - nas both yeah you might have a green
303:28 - circle around your face but you took it
303:29 - to the hook
303:33 - yeah with no legs right there's an
303:36 - enjoying goat guys i think we should
303:38 - just tell the community
303:39 - like sunny's good is so much stuff so
303:41 - when he joined the team a few months
303:42 - back
303:43 - um i was like one day we're on a team
303:45 - meeting i was like yo sonny you're so
303:46 - good at everything there has to be
303:48 - something effed up about you
303:49 - but he lives in uk we're all in los
303:51 - angeles so kazi was like hmm
303:53 - you know we've never seen sonny's legs
303:55 - and we're like he must be in a
303:56 - wheelchair or something
303:57 - like there's something here everyone
304:00 - thinks
304:00 - i don't have legs
304:06 - so he's always insecure and showing his
304:07 - legs in the in the video chats like
304:09 - yeah but guys at least at least today
304:13 - i i'm not the only one wearing a black
304:15 - shirt so
304:16 - you know is that is that a thing are you
304:19 - always wearing a black shirt that's
304:20 - always a thing dude everyone's always
304:21 - like yes and he's all sunny doesn't have
304:23 - any other shirts besides black t-shirt
304:25 - he's like he's like steve jobs wears a
304:28 - whole um
304:29 - you know what's it called um turtleneck
304:32 - right yeah row neck and then they're
304:33 - like sonny wears a black t-shirt every
304:35 - single time
304:37 - zuckerberg wears a blue t-shirt right
304:39 - yeah like a gray t-shirt it saves you
304:41 - time in the morning guys
304:43 - so that's why
304:46 - technically this is dark gray it's not
304:48 - black so you're still by yourself sonny
304:50 - oh but uh anyways let's get back to
304:54 - this
304:54 - so that's the face detection app
304:56 - basically you just repeated the face
304:57 - detection video but
304:59 - whatever so now um
305:02 - that's pretty good so like wouldn't
305:04 - wouldn't a small sector be as simple as
305:05 - just changing this out for a smile and
305:07 - writing the same thing
305:08 - well yeah let's try it i mean you would
305:11 - think so
305:12 - you would think so but you guys about to
305:14 - see some really really weird crap
305:17 - and then really really cool trick to fix
305:19 - that weird crap
305:21 - which is interesting it's a smart thing
305:24 - to do
305:25 - so let's create our smile detector okay
305:29 - [Music]
305:37 - let's create our smile detector okay
305:41 - yep so they smoke all correctly yeah
305:44 - there we go smile detect so same exact
305:47 - thing
305:47 - uh we're gonna be using hard cascade and
305:50 - um
305:50 - to detect faces but we can also use use
305:53 - it to detect smiles
305:54 - so in this case there's another file and
305:56 - description it's just called heart
305:57 - cascade
305:58 - dot smile i think let me double check
306:00 - down here
306:01 - yeah our cascade underscores smile yep
306:04 - and we just use this pre-trained
306:05 - classifier instead so this took a bunch
306:07 - of images of people smiling with their
306:08 - teeth showing
306:10 - it doesn't it doesn't detect like
306:11 - regular smiles that good
306:13 - it's mostly like teeth smiles um from
306:16 - the training data but you can teach you
306:17 - to do both but in our case you kind of
306:19 - have to show your teeth for it to work
306:20 - like really well uh but that's there
306:24 - so why don't we just use this instead of
306:26 - the face like because it's detecting the
306:28 - face so well right like it was cracking
306:29 - my face perfectly and if there's
306:30 - multiple faces
306:31 - yeah shouldn't be able to detect smiles
306:33 - too supposedly
306:35 - supposedly so let's go down this code
306:38 - and make the changes okay so we have to
306:40 - we we get the webcam uh we want to
306:42 - iterate over every frame
306:44 - we want to read every frame in each
306:47 - iteration
306:47 - and then a little check and then frame
306:49 - grayscale
306:50 - so we get the current frame you change
306:52 - the grayscale now instead of detecting
306:54 - faces
306:55 - let's actually detect oops
306:59 - smiles okay nice okay
307:03 - like smiles and instead of on face
307:05 - detector let's call smile detector
307:07 - and we want to call it on this on the
307:09 - same frame so grayscale frame
307:11 - yeah and then again let's just copy this
307:14 - exact code
307:15 - but instead of and we can use the same
307:19 - variables because
307:20 - this and this loop will never overlap
307:22 - like this loop will completely finish
307:24 - before this loop starts so we can
307:26 - we can use the same variables which is
307:27 - fine okay keep it nice and clean look
307:29 - yep there's no if it was nested we
307:32 - cannot because then they would get
307:34 - um they'd fight over the variables but
307:37 - loop completes before this even starts
307:39 - so it's okay to use the same variables
307:40 - here
307:41 - right um but instead of faces let's draw
307:43 - smiles
307:45 - okay so now this is going to be so this
307:48 - is what it's doing is the same exact
307:49 - thing it's going to find all the smiles
307:51 - in the image
307:52 - and then return a list of points the
307:54 - exact same thing upper left hand point
307:57 - um upper left-hand point here and then
307:58 - the width and height of the smile in
308:00 - this case it's going to be like a
308:01 - horizontal rectangle instead of a square
308:03 - okay so it's returning the same thing
308:06 - right the same coordinates
308:08 - uh the same form
308:11 - yeah it's going to look just like this
308:13 - but instead of giving us the coordinates
308:14 - of faces is going to give us the
308:15 - coordinates of smiles it's like just a
308:18 - different rectangle on the image it's
308:19 - smaller
308:20 - around the mouth and it's like
308:21 - horizontal looking right uh let's change
308:23 - the color though i had a pre
308:26 - uh this color okay that's the color i
308:28 - chose it's like a nice red color
308:30 - yeah and because right now it's the same
308:32 - color as the face but i want to change
308:33 - it to this red color
308:35 - go ahead uh like i said bgr so
308:38 - r is at the end that's why it's so high
308:40 - so it looks more red because the r
308:41 - channel is the highest
308:42 - right okay red so let's
308:46 - run this and let's um let's actually not
308:49 - draw the sm
308:50 - the faces let's just get rid of the
308:52 - faces so i'm not even going to draw the
308:53 - faces
308:54 - okay so we're just going to we should
308:55 - just see
308:58 - yeah so not even faces it should just
308:59 - have things of smiles on my face
309:02 - right okay i mean they just have
309:03 - rectangles around the smile on my face
309:05 - yeah so let's run this
309:08 - and whoa voila as you can see
309:11 - it's working perfectly holy crap okay so
309:16 - this is well this one okay this is what
309:17 - you meant by
309:18 - it's just a lot it doesn't work for
309:21 - yeah
309:22 - yeah it doesn't it does not work
309:25 - but it does uh and i'll explain that in
309:27 - a second and how that actually works but
309:29 - as you can see right now the default
309:31 - it's like this isn't even working
309:32 - properly like what the hell like how
309:34 - like okay is that it's actually getting
309:36 - my smile look at my smile
309:38 - i was actually getting the smile yeah
309:40 - it's actually getting it so it's smart
309:42 - enough to find it
309:43 - but there's a lot of false positives
309:45 - like it's things this stuff over here
309:46 - like this little window sill is there
309:48 - because it probably thinks this white is
309:49 - like teeth
309:50 - and this is my lip or something yeah but
309:52 - i mean there's also getting things here
309:53 - on the freaking
309:54 - freaking curtain which makes no sense
309:55 - you know like like what
309:58 - i mean this may be a little bit too like
309:59 - it looks like the upper teeth and the
310:01 - lower teeth and the little gray line is
310:02 - like maybe the gap between the teeth
310:03 - a little bit we kind of understand maybe
310:06 - we just built a ghost detector or some
310:08 -  you know
310:09 - like yeah that's what they said in the
310:12 - face detection video or the pedestrian
310:13 - tracking but
310:14 - yeah point is this is working like ass
310:17 - okay
310:17 - yeah uh so how do we fix this it's like
310:19 - this isn't even working
310:21 - um first let me explain why this is
310:23 - happening
310:24 - so there's a there's probably a couple
310:26 - reasons why i saw what this is happening
310:27 - and i'm gonna explain both
310:29 - okay uh first thing is so let's just
310:32 - quit out of this first so why is this
310:35 - performing so
310:36 - yeah i realize it's wearing screen it's
310:38 - fine
310:40 - it's fine first reason
310:43 - is to be honest uh faces are one of the
310:46 - very first things that people detected
310:48 - from the beginning
310:49 - um that's like the very like that it's
310:51 - like the coolest thing to detect to
310:53 - start with and it
310:54 - has like a very defining feature like
310:56 - detecting squares or
310:57 - detecting a soccer ball is kind of like
310:59 - okay it's kind of cool i guess
311:01 - um i think a face is like pretty cool
311:04 - right so there is a lot more data in
311:06 - this trained algorithm than there is
311:08 - anything else
311:09 - so there was actually just more phase
311:11 - data and this was just trained better
311:13 - than smile was to begin with
311:15 - so that's the first reason why face
311:16 - detection was working so well
311:18 - because it ran out more data for longer
311:20 - yeah while this one probably didn't get
311:22 - much data
311:22 - nice okay just because yeah it's like
311:25 - okay if you want to have like a
311:26 - left finger fingernail detector like
311:28 - there's not going to be as much data as
311:30 - faces just because faces are cooler or
311:31 - like a blade of grass detector like who
311:33 - codes that
311:34 - yeah you don't want to take vigilance
311:35 - and also bleeding guys like if you think
311:37 - about it a
311:38 - face has so many features you have like
311:40 - you have your eyes you have loads of
311:42 - things which
311:42 - which basically are going to tell that
311:44 - model that okay we can be sure that
311:45 - that's the face whereas a smile
311:47 - has a lot less to look for like you just
311:49 - have pretty much like the curvature of
311:51 - your smile
311:52 - that's why you kind of it can easily get
311:53 - confused like the lamp behind aaron has
311:55 - like a little curvature to it so
311:56 - it could get confusing that's a smile
311:58 - whereas a face has several different
312:00 - reference points that it will look for
312:01 - in terms of features so just something
312:03 - to bear in mind as to why
312:05 - you would get that
312:08 - that was the second point i was going to
312:09 - make you stored out of my mouth but that
312:11 - was absolutely correct guys
312:12 - yeah exactly what i was gonna say is
312:14 - yeah there's less features
312:16 - like detecting a tooth is much harder
312:19 - than detecting a face
312:21 - because how do you detect the tooth it's
312:22 - just like a it's just a flat white thing
312:25 - with like a specific shape but it's
312:26 - harder to detect
312:28 - yeah like it might get it might get a
312:29 - tooth and a marshmallow mixed up
312:31 - but it wouldn't get a face in a
312:33 - marshmallow mixed up unless you're the
312:34 - michelin man
312:36 - but uh or the or the or the pillberry
312:39 - tilbury uh guy you know the little
312:40 - little bakery guy but
312:44 - but yeah that's the point that sonny
312:45 - made right that's the second point so
312:46 - first one is
312:47 - face probably just has more data overall
312:49 - just because it's a more defining object
312:51 - and it has more emotional pressure to
312:52 - humans so it's like cool let's detect
312:54 - phases
312:54 - but also it just has more data that i
312:57 - can go by to determine hey is this a
312:58 - face or not versus a smile you're kind
313:00 - of limited
313:00 - nice go ahead so
313:04 - that is absolutely correct so that's why
313:05 - it's performing like ass i mean it could
313:07 - be better
313:08 - it could be better uh if they trained it
313:10 - better with more data
313:11 - yeah um but even then it's still hard
313:14 - harder to detect than a face
313:16 - right so how do we get around this well
313:19 - um
313:19 - first of all there's different
313:20 - parameters we can do so you can actually
313:23 - be like hey if uh something only counts
313:25 - as a smile
313:27 - if there's like two or three things
313:29 - around it that are also a smile because
313:30 - then it kind of thinks okay if this area
313:32 - kind of has like four smiles detected
313:34 - then it's a smile but if it's just one
313:36 - random thing that might kind of be a
313:38 - smile but there's only one instead of
313:39 - like four
313:40 - yeah then um you can go okay that's not
313:42 - small enough so like there's kind of
313:43 - like a
313:44 - redundancy okay code one more time
313:46 - explain that visually
313:48 - right so like here we're just getting a
313:50 - bunch of stuff okay
313:51 - yep um so but you can see like this
313:54 - random one over here just getting
313:55 - they're
313:55 - blipping up every now and then yeah so
313:58 - so are you usually
313:59 - gonna say that can get rid of those
314:01 - right so in a simple sort of like
314:03 - in a one sentence sort of answer like
314:06 - rather than checking the entire
314:08 - sort of webcam view we kind of want to
314:10 - narrow down that
314:12 - that sort of selection down to just your
314:13 - face right
314:16 - um not quite there that's the other
314:17 - optimization i'm gonna show but what i'm
314:19 - saying
314:20 - is um see how there's like random boxes
314:22 - showing up over here
314:23 - yeah like by themselves we can kind of
314:25 - get rid of all the standalone ones that
314:26 - just kind of flash really quick
314:28 - okay but if there's a big group yeah if
314:30 - there's a big
314:31 - group of boxes overlaid on top of each
314:34 - other though we can kind of say the
314:35 - chances of that actually being a smile
314:36 - is a little bit higher
314:37 - like up here we could maybe boil this
314:39 - down to like one smile we'd be like okay
314:41 - there's freaking seven boxes here
314:43 - this is probably a smile there's seven
314:44 - here this is probably a smile
314:46 - there's a bunch here there's probably a
314:48 - smile um but these little ones on the
314:50 - sides that are flashing randomly
314:51 - you can say now we don't want those
314:53 - right and we can actually get rid of
314:54 - that is there some kind of sensitivity
314:56 - or
314:57 - yep that's all it is it's just a
314:58 - sensitivity number and you have to tune
315:00 - it to faces
315:01 - so you find the perfect number which
315:03 - i'll show you guys in a little bit
315:05 - but we can actually do that so let's add
315:07 - that in and you won't see that much of
315:09 - an improvement here on this but i'll
315:11 - show you guys
315:13 - the second optimization which is going
315:15 - to clean everything up and make it go
315:17 - from complete ass to super super
315:19 - accurate which is pretty impressive
315:20 - nice so um
315:25 - detect so this happens in the detect
315:27 - multi-scale okay
315:29 - so there's two different things called
315:31 - or two different parameters you can use
315:32 - called
315:33 - min neighbors and scale factor okay okay
315:37 - so let's get these
315:42 - yep
315:44 - here here we go so this let me actually
315:46 - type it out so this is going to be
315:49 - uh scale factor
315:52 - okay i think i might have spelled it and
315:54 - then this is going to be
315:56 - min neighbors okay
316:00 - um it might be the wrong spelling so it
316:02 - might not work but let's just try it
316:04 - so what this is gonna do is it says
316:06 - skill factor this is an optimization to
316:09 - how much you want to blur the image
316:10 - because if you blurred this image you
316:12 - can still kind of tell it's a face if
316:13 - you don't blur it too much
316:15 - okay and then if you blur it that's
316:16 - another optimization on top of the black
316:18 - and white
316:18 - okay you can kind of like generalize and
316:20 - then you can kind of compare the data a
316:22 - little bit more
316:23 - um because there's less data but you can
316:25 - still kind of tell it's a face so you
316:26 - want to kind of optimize this
316:27 - basically this scale factor is blur like
316:29 - how much do you want to blur the image
316:31 - to make it easier to detect faces and
316:33 - kind of like um
316:35 - get the defining features in brightness
316:37 - um
316:38 - or or not so the higher this number then
316:41 - the more it'll get blurred so
316:42 - i found the 1.7 is the best right
316:45 - so just just to be clear there so you're
316:47 - saying essentially to blur
316:49 - the the the sort of the entire frame so
316:51 - that way it will be easier to detect
316:53 - facial features as opposed to like a
316:55 - curtain or like a
316:57 - lampshade yeah because you get a lot of
317:00 - rid of a lot of the details which are
317:01 - unimportant so like if there was like a
317:03 - 4k
317:03 - image and there's a lot of details then
317:05 - it can get very confused with the data
317:07 - but if you blur it enough you can kind
317:09 - of if you blur it like a crap load you
317:10 - can kind of be like okay
317:12 - um there's kind of a blurry face in the
317:14 - middle and then everything else is just
317:15 - like a blurred mess in the background so
317:16 - it actually kind of like
317:18 - contrasts like the objects you can be
317:20 - like okay there's a face and then
317:22 - there's a bunch of blurred background
317:23 - you can't even tell if it's curtain or
317:24 - wall or whatever but you can kind of be
317:25 - like okay there's a face here
317:27 - go ahead okay nice so that's the idea
317:30 - if you can blur it down more you can
317:32 - actually detect faces even better yeah
317:33 - then mid neighbors is what i was just
317:35 - talking about
317:36 - um there has to be 20 neighboring
317:38 - rectangles in total in that little area
317:40 - for it to actually count as a smile
317:42 - okay so if this was one then literally
317:44 - just everything would be passed through
317:46 - but if you make this higher
317:47 - then it's like okay there needs to be a
317:49 - lot of redundant rectangles on this one
317:51 - little area for this to actually be a
317:53 - smile so it's like i found 20 smiles in
317:54 - this little region
317:56 - of the image because they're all
317:57 - overlapping it has 20 neighbors
317:59 - the minimum amount of neighbors of a
318:02 - rectangle needs to be 20
318:04 - for it to actually be counted as a smile
318:06 - so this will help a little bit
318:08 - yeah let me show you guys and then um
318:12 - well actually not even at all like well
318:13 - actually it helps a lot oh one sec one
318:16 - more than before all right so there we
318:19 - go all right
318:19 - yep right back there you go
318:23 - so as you can see okay it's actually
318:25 - it's actually
318:26 - better a lot better that's
318:30 - what i mean yeah there's still a few
318:32 - things so here yeah i don't know why
318:34 - it's so fixated on this light
318:39 - it's probably thinking that this is
318:40 - teeth it's probably looking for like a
318:42 - yeah a
318:43 - horizontal line of white so it's
318:44 - thinking this is tea
318:46 - okay i mean like you can see why the
318:49 - lamb i mean the top
318:50 - left is a bit of this weird one
318:54 - yeah but i mean you can kind of see like
318:56 - this little white oval and my teeth look
318:57 - similar
318:58 - yeah yeah yeah so it's probably trying
318:59 - to find like teeth and then the
319:00 - curvature of your mouth
319:02 - okay yeah so something like that
319:06 - uh so that works really really well so
319:07 - like a lot of fine tuning needs to be
319:09 - done
319:09 - for things to work properly so just that
319:11 - little change there that worked way
319:12 - better than when i was testing
319:14 - it but uh i mean that's amazing so
319:17 - um tuning tuning different numbers can
319:19 - actually play a big big role
319:21 - in that so like maybe like in a real
319:23 - world application if you're detecting
319:24 - smiles you would want to save these
319:26 - numbers
319:26 - okay and be like okay for smiles always
319:29 - use these parameters this is like
319:31 - additional machine learning on top of
319:33 - all the the crazy numbers machine
319:35 - learning that's in here you have this
319:37 - plus a little bit more so this is kind
319:38 - of like this is kind of like manual
319:40 - machine learning
319:41 - you manually went through and tested a
319:42 - bunch of different sensitivities
319:44 - and you used your eyes to be like okay
319:47 - this is actually machine learning so
319:48 - that you actually taught the computer
319:50 - that these two numbers are closer to a
319:52 - smile than anything else
319:53 - so this is like manual machine learning
319:55 - that that you're doing okay pretty cool
319:57 - yeah nice um
320:00 - okay now going forward uh another
320:02 - optimization that we can do
320:04 - is actually get rid of uh these these
320:07 - errors because like sunny said
320:09 - and what i said in the slides is smiles
320:12 - only show up in faces
320:13 - yeah so why don't we instead of trying
320:16 - to get it across the entire frame
320:18 - just find a face and then only run small
320:20 - detection within that face
320:22 - yeah because we already already did the
320:24 - work of the face detection
320:25 - so why don't we do that that's awesome
320:27 - and that's what we can do next
320:29 - because it makes it faster and more
320:31 - accurate yeah when i first thought about
320:32 - i kind of thought that like oh
320:34 - we're just going to slap a model on the
320:35 - entire webcam and they'll figure it out
320:37 - but guys you have to be prepared like uh
320:41 - take it in mind that you you there's a
320:42 - lot to process it remember in the
320:44 - beginning we said like you pretty much
320:46 - have some kind of input
320:47 - your model and then some kind of output
320:48 - so if you can reduce the amount of input
320:51 - going into the model
320:52 - you can actually speed up the entire
320:53 - thing a lot more like and it's
320:55 - drastically going to be faster
320:57 - and it's also going to be like more
320:58 - reliable in terms of we're only going to
321:00 - select aaron's face and then find the
321:01 - smile inside there
321:03 - so something yeah yeah yeah on the
321:06 - self-driving car
321:07 - live stream we did the car and
321:09 - pedestrian stream tracking one you can
321:10 - see a really good example of this in
321:12 - real time
321:13 - when we're doing it because there's so
321:14 - many cars on a highway so some highway
321:16 - footage there are so many cars
321:17 - and a lot of pedestrians because because
321:20 - here you're only taking like two or
321:21 - three
321:22 - yeah but in those there's like 10 cars
321:24 - and 20 pedestrians so it was going crazy
321:26 - um when you when you do that one when
321:29 - you um
321:29 - scale it down so if you blur the image
321:31 - more it's faster if you make it black
321:33 - and white it's faster
321:34 - and then some other optimizations you
321:35 - can actually see the footage gets played
321:37 - back really really fast so that's a good
321:38 - visualization if you go check it out
321:40 - go watch that stream too it's nice it's
321:42 - badass as well yeah go check that one
321:44 - out guys i'm going to
321:44 - watch that one as well not watching my
321:48 - content
321:49 - i know i do i do i'm the guy smacking
321:51 - the smashing the dislike
321:52 - i'm joking wow okay so
321:56 - we'll go up this morning he was like
321:57 - aaron i'm really grumpy i don't want to
321:58 - do the stream and i was like bro i need
322:00 - you i don't have
322:01 - my internet stuck i need you man and
322:03 - then uh
322:04 - then he's like now now he's all in a
322:05 - better mood because he's been hanging
322:07 - out with me
322:08 - it's fun we'll definitely do some more
322:10 - streams yeah this will be cool we can
322:12 - even probably do some kind of python
322:14 - react
322:15 - you know like yeah dude let's do that we
322:17 - could like tie it together like do like
322:19 - a cool front end app
322:20 - with uh javascript and we can have some
322:22 - cool like back-end python stuff like
322:23 - happening like this you know
322:25 - yeah like a front-end thing where you
322:27 - click like smile detector
322:28 - face detector you know like car
322:30 - pedestrian detector and have like
322:31 - different you pick
322:32 - different files and it feeds it in yeah
322:34 - something some people like that
322:36 - exactly that was awesome uh aaron quick
322:38 - question here from shantao he says
322:40 - is it beginner friendly so just maybe a
322:42 - quick answer to that
322:44 - is this video beginner friendly or is
322:46 - the other ones beginning yeah
322:48 - like just for anyone that's new to the
322:49 - video or who might have joined
322:50 - afterwards
322:51 - is this video beginner friendly like do
322:53 - you need to know python before you do
322:54 - this
322:55 - yes you need to know python but if you
322:57 - know like for loops and all the basic
322:58 - python stuff and how to like call
323:00 - functions then
323:01 - no you know i teach you the rest from
323:03 - there but you do need i don't teach the
323:04 - basics here so you gotta
323:05 - learn the basics then you can come back
323:07 - if you're if you're a complete from zero
323:09 - beginner no if you're just a beginner
323:10 - who knows python but you haven't coded
323:12 - much then yes you can go through this
323:14 - yeah and also just worth mentioning guys
323:15 - i don't code much python but i know
323:17 - javascript so
323:18 - coming to this is actually super super
323:20 - simple in terms of how aaron's broken it
323:22 - down so
323:22 - if you have any coding experience then
323:24 - yeah you can do this so definitely go
323:26 - ahead and do it yeah very straight
323:28 - awesome so i popped back in the faces so
323:30 - let's do this now okay
323:32 - yep let's go back to the terminal
323:35 - and run it again and now we should have
323:38 - uh error oh cause i commented out faces
323:41 - so it's giving me an error
323:43 - because i'm trying to use faces here
323:44 - yeah when i commented it out let's just
323:46 - get rid of that
323:47 - and run it again
323:51 - so there we go so we got the faces here
323:54 - and the smiles
323:55 - nice hey look at that
323:58 - yep awesome but i mean it's still
324:00 - getting this you want to get rid of all
324:01 - these random ones yeah so what we can do
324:03 - like i said is we can actually
324:05 - just run small detection within this
324:07 - window instead of the whole frame
324:08 - which is a smart optimization because i
324:11 - mean in the real world you wouldn't see
324:12 - a smile out in the middle of nowhere
324:13 - unless it was like a piece of art or
324:15 - like dentures or something you know
324:17 - but generally smiles only show up within
324:20 - a face so that's why um we can do this
324:23 - nice okay yep
324:26 - and then i actually show the effect
324:28 - effectiveness of that too i'll get rid
324:29 - of these tuned parameters and actually
324:31 - show you how well
324:32 - that works okay um yeah i mean it kind
324:35 - of works well but those
324:36 - like these scaling factors the
324:37 - sensitivity plus the that little trick
324:39 - together
324:40 - makes it super accurate from what we had
324:42 - before just like
324:43 - freaking right all over the frame just a
324:46 - single smile like
324:47 - like we tuned that down from just two
324:49 - little things so that's
324:51 - it's like really smart clever things to
324:52 - to make your code work using something
324:54 - that
324:54 - doesn't work and making it work yeah
324:56 - with a few numbers
324:57 - awesome yeah so let's continue okay
325:02 - so how do we actually make it so that we
325:05 - only check within
325:06 - a face if there's a smile
325:08 - [Music]
325:16 - so how do we actually make it so that we
325:19 - only check within a face
325:21 - if there's a smile okay so like like we
325:24 - said we're in the
325:25 - the global loop here that is looping
325:27 - over the entire frame
325:28 - we read the frame so from here we keep
325:31 - going down blah blah blah and then we
325:33 - get to
325:34 - uh faces okay okay
325:37 - oops run small detection within each of
325:39 - the faces uh
325:41 - run face detection so some of these
325:42 - comments might have not made sense the
325:43 - entire time because they kept
325:46 - popping them so this is what i had
325:48 - before run face detection
325:50 - but now we want to actually do this
325:52 - within each of those faces this is what
325:54 - we're currently going to be
325:55 - installing so how do we do that okay
325:59 - let's look at it just from here so we
326:02 - we we're in the frame and then we find
326:05 - all the faces
326:06 - and we have all the boxes of frames so
326:08 - we have the box of
326:10 - of a face so we have the box of what a
326:11 - face is yeah we draw that box right
326:14 - okay but we have this box so this is
326:17 - actually
326:17 - the box we want to look at this is
326:19 - actually the sub image of the whole
326:21 - image that we want to find smiles
326:22 - we're actually giving it right here but
326:26 - so we can actually just be like okay
326:29 - instead of looking at the whole frame
326:30 - just look at this rectangle for the
326:32 - smiles instead
326:34 - okay and that's what we're gonna do so
326:36 - how do we do that there could be
326:37 - multiple smiles
326:38 - within a face though right if i mean not
326:41 - technically but if there's errors like
326:42 - it might detect like
326:44 - a little just before your mouth so you
326:46 - just want to make sure you find all of
326:47 - them
326:48 - so what we're going to do is we're
326:49 - actually going to have
326:51 - another loop in here is be nested
326:54 - because within a face
326:55 - you have to find all the smiles okay so
326:57 - we're actually going to need to
327:00 - um
327:03 - find the xy um width height of each
327:06 - smile within the face so same thing
327:07 - we're just nesting it
327:08 - okay does that make sense so far yeah
327:10 - quick thing is though because
327:12 - yeah quick right this is a python
327:14 - question so you have uh
327:16 - are your variable names not gonna clash
327:18 - here or is it gonna be in a scope they
327:20 - will
327:20 - okay no they will they will right um i
327:23 - believe
327:24 - i'm 99 sure i didn't even try because i
327:26 - thought they would
327:27 - uh but i'm pretty sure they will so what
327:28 - you can do is you could use like capital
327:30 - letters or something i believe it's case
327:31 - sensitive
327:32 - yeah but you probably don't want to do
327:33 - that what i did is just a little sloppy
327:35 - but i just did this
327:36 - okay just so they don't contend but it
327:38 - keeps it simpler because if you start
327:40 - doing stuff like this the codes start
327:41 - looking really hard on the eyes
327:43 - yeah um because this is so so clean you
327:45 - know x y x
327:46 - w y plus h yeah keep it nice and clear
327:49 - but if we started doing this then it
327:51 - would look like
327:52 - you know over again x smile plus y smart
327:55 - like
327:55 - yeah it starts looking like that yeah so
327:59 - yeah so i just did this just uh it's a
328:01 - little bit messier but it's it's still
328:02 - easy to understand i just added an
328:03 - underscore to the end
328:05 - okay okay
328:10 - so we're going to need to look over uh
328:14 - the face okay okay um
328:18 - i mean i should probably talk about
328:20 - getting the subset first
328:21 - uh let me go over the logic first so
328:23 - what we want to do is you want to find
328:26 - uh in the face okay so you want to find
328:28 - all the smiles
328:29 - in the face okay so
328:33 - uh find all smiles in the
328:36 - face okay so we're gonna do this doesn't
328:39 - exist yet but i'm just using this as a
328:40 - placeholder thing for right now
328:41 - this code will not work because it's
328:43 - currently broken yeah and then just draw
328:45 - um draw all the rectangles
328:49 - around
328:53 - the smile okay or the rectangles just
328:55 - like that
328:58 - oh shut up dude it must be an american
329:02 - thing okay let me
329:06 - yeah let's just do this so it doesn't
329:07 - break
329:10 - uh oh yeah i was making fun of your
329:12 - spelling before right yeah
329:14 - oh god that's hilarious that that
329:16 - backfired didn't it
329:18 - uh anyways so this is the kind of idea
329:21 - we're gonna iterate over
329:22 - um all the faces and then with each of
329:24 - all within each of those faces we're
329:25 - gonna find all the smiles
329:27 - okay and then we just want to draw the
329:29 - rectangle in there
329:30 - so kind of slimmer to what we did here
329:31 - actually okay the only caveat is you
329:33 - have to change the
329:34 - the names here yeah um so why don't we
329:37 - do that actually let me just
329:40 - uh copy this down here so this is the
329:42 - same exact code as we had before we just
329:43 - want to draw
329:45 - a rectangle around the smile okay
329:49 - okay and then instead of x y uh w and h
329:52 - it's just going to be this
329:54 - okay just add the underscores to the end
329:56 - okay
329:58 - it's kind of hard on the eyes but if you
330:00 - space it out like this it's not too bad
330:02 - so so just to bring everyone to speed
330:05 - right now we had an initial loop which
330:07 - was going through all of the faces
330:10 - and then so that was the first one on
330:12 - line 28.
330:13 - so i was going through all the faces and
330:15 - then on line 34
330:18 - we're going through the individual face
330:20 - that it detects because you might have
330:21 - more than one place
330:23 - and then when you get a rectangle around
330:25 - that individual
330:26 - face right uh no
330:29 - uh within each of those faces you want
330:31 - to find all the smiles
330:33 - and draw a rectangle around all those
330:34 - smiles
330:37 - so what we're going to want to do is um
330:42 - we're going to want to actually not run
330:44 - this here we're going to want to run
330:46 - this
330:48 - oops we're going to want to run this
330:51 - here okay
330:55 - okay yep well i actually not here uh
330:58 - that's incorrect um but i need to
331:01 - explain something else first
331:03 - where do we get actually where do we get
331:05 - the face from is that like placeholder
331:06 - for now or
331:07 - that's um yeah i'm about to explain that
331:10 - this is the tricky part and this is the
331:11 - really cool part
331:12 - so let's just pretend that
331:15 - the face equals this for now okay this
331:18 - code doesn't actually work but this is
331:19 - what it is in flavor
331:21 - okay yeah just pretend this code does
331:23 - not work this code does not work but
331:25 - this is the idea
331:26 - we want the face to be this little mini
331:29 - sub
331:29 - image within the whole image because
331:31 - this is the current face like the little
331:32 - square that surrounds the face
331:34 - so you want this to be like a little
331:36 - image but the thing is
331:37 - um you can't just pass in
331:41 - like these uh detect multi-scale and get
331:45 - the
331:45 - get the smiles out of this we have to do
331:46 - some crafty stuff here with the array
331:49 - and
331:49 - and slicing but just this is the idea is
331:51 - that clear sunny yeah
331:52 - yep oh yeah if it makes sense to you
331:55 - then hopefully
331:56 - kind of playing into an object right
332:00 - kind of well what we're going to do is
332:01 - we're just going to slice and tool into
332:03 - the image and get like a sub image
332:04 - in some cool way i'll show in a bit but
332:06 - i just want to show the overall logic
332:08 - first before i do that
332:09 - yeah yep so let's walk through this
332:12 - again so yeah we have all the faces here
332:14 - then we draw the rectangle around the
332:15 - face then we say okay
332:17 - get this little square image instead of
332:19 - the whole frame just get this little
332:20 - square
332:21 - now within this little square use that
332:24 - to detect multiscale so we want instead
332:26 - of looking at frame grayscale
332:27 - we want to actually look at the face
332:29 - okay
332:31 - so let's um
332:35 - uh of course we have to go to grayscale
332:37 - again though for the same reason
332:39 - we have to convert this face because if
332:41 - this was
332:42 - if this was a color image then we would
332:44 - need to change the face to a black and
332:45 - white color image
332:46 - like actually let me show you here this
332:48 - is actually a good uh
332:51 - thing so i said step one okay we want to
332:53 - find faces in our image
332:54 - yep okay then step two
332:58 - get just this so that we don't we don't
333:00 - have to search we don't have to search
333:01 - the whole image
333:02 - instead of searching the whole image
333:03 - we're only going to search within this
333:05 - face
333:06 - so now this is we're doing that because
333:07 - we were getting like random sort of
333:09 - findings outside the face
333:11 - yeah okay yeah we're kind of just
333:13 - eliminating everything outside of the
333:15 - face
333:15 - as automatically no even if it says yes
333:18 - it's going to say no
333:19 - because we know that smiles only show up
333:20 - on faces right okay
333:22 - then step two we find smiles within
333:24 - those faces so we're only going to
333:25 - search within these bounds
333:27 - and then at the end we'll do a nice
333:29 - little labeling that we haven't gotten
333:30 - to yet
333:31 - go ahead but yeah so the idea is
333:34 - the face this is going to be
333:39 - this okay okay so this is so this is
333:42 - frame
333:43 - this is the whole frame this is the face
333:45 - okay okay so we need to get this but
333:47 - it's still color so we need to make this
333:48 - black and white as well just the same as
333:50 - the other image
333:51 - yeah so let's go back and
333:55 - um call or is it let me just
333:59 - copy paste this
334:07 - and change it to face grayscale
334:11 - okay so face gray scale is going to be
334:17 - the face so same idea here we have the
334:19 - face the colored face
334:20 - but now we want to change the black and
334:22 - white so we use the convert color
334:24 - function again okay and we pass in the
334:26 - face the color face
334:27 - we say change it from color to gray okay
334:30 - and
334:31 - save it as face grayscale right okay
334:34 - then now in the small detector now
334:37 - instead of detecting it on the whole
334:38 - grayscale frame
334:39 - let's only run it on the grayscale face
334:43 - go ahead okay yep right there
334:46 - and now now this should be working but
334:49 - the only caveat is this doesn't exist
334:51 - yet properly this doesn't actually work
334:53 - but this is the general idea so once we
334:55 - have um this then we can run the smile
334:58 - detector
334:59 - only on the face there okay and then
335:02 - uh then then we can draw all the
335:04 - rectangles
335:06 - around the smiles within that face after
335:08 - we find the coordinates
335:09 - of smiles so it's actually going to be
335:13 - smiles right i'm with you now they
335:15 - should be a little more clear
335:16 - yeah awesome great so yep find faces
335:21 - draw the rectangles get the little face
335:23 - change the little face to grayscale
335:25 - run smile detector on that little face
335:27 - then draw all the rectangles on that
335:29 - little
335:29 - face go ahead and then and that's how
335:32 - we're gonna get
335:33 - uh this kind of behavior okay
335:36 - awesome so you can see how there's no no
335:38 - red boxes outside of the face it's only
335:40 - within the face
335:41 - yup yup you said yep like a bajillion
335:44 - times on the stream bro
335:50 - i'm kind of confused on so we have the
335:52 - oh
335:53 - okay no i see now because you're doing
335:54 - it on face grayscale
335:56 - and then that's where smiles comes from
335:58 - okay no that makes sense cool got you
336:01 - so you're writing smiles on the face
336:04 - you're not running smiles on the whole
336:06 - frame
336:06 - yeah that's why i was a bit lost yeah
336:10 - so that's there um so this should work
336:12 - in theory
336:13 - right but the thing is uh this doesn't
336:16 - work
336:16 - so how do we do this one little line of
336:18 - code so this is a little tricky i'm
336:19 - gonna have to explain it
336:20 - but it actually is just a one liner can
336:22 - we can actually achieve this but i need
336:24 - to explain how it's done and there's
336:25 - some weird
336:26 - um details that i'm gonna explain um
336:30 - so let's get rid of this okay run
336:31 - smaller sizes with each of those faces
336:33 - because
336:34 - we actually just copied that from over
336:37 - here we just added the underscores at
336:38 - the end so we don't overlap with the
336:39 - variable names
336:41 - uh this remains unchanged you still want
336:42 - to still want to display the current
336:44 - frame and the weight key of one
336:46 - millisecond and then release everything
336:47 - at the end
336:48 - of the auto but how do we do this
336:51 - okay so
336:54 - um we have the frame
336:58 - right we have the overall frame but
337:01 - uh and then we also have the face xywh
337:05 - so how do we get a sub image
337:09 - of um this whole image like if you have
337:11 - a big image
337:12 - like right here you have a big image
337:15 - how do we find this sub image so you can
337:17 - kind of just how do i
337:19 - cut out just that image right
337:22 - yeah cut out that image right um
337:26 - there's there might be like a sub image
337:28 - function opencv but i didn't want to do
337:29 - it that way because i wanted to show you
337:30 - guys
337:31 - this smarter way of doing it or maybe
337:33 - more efficient way
337:34 - it's it's a little bit different so uh
337:37 - do you are you guys familiar with
337:39 - slicing in python i mean if you know the
337:40 - basics of python
337:43 - okay i mean i'm new to python so i even
337:45 - even if you run through that it'd be
337:46 - kind of cool to see
337:48 - you got it yep okay so let's look at
337:50 - this little environment here let me open
337:52 - up a python environment completely
337:53 - separate you start python
337:55 - and this is python2 it's fine though
337:57 - python2 is fine okay
337:58 - um it's the same thing so let's say we
338:00 - have a list
338:02 - okay yep and let's just call it
338:05 - um list
338:09 - let's just call it l okay whatever so we
338:10 - have a list let's call it color of
338:12 - in colors uh i'm trying to think
338:16 - well people yeah yeah yeah yeah colors
338:19 - let's do colors let's just do
338:21 - red blue
338:24 - oh yeah blue green yellow
338:29 - black white that's good okay so we have
338:32 - six
338:33 - six colors here okay this is a good
338:35 - length list okay
338:36 - and let's hit enter uh
338:39 - red oh because it needs to be strings i
338:42 - was just wondering i was like can you do
338:43 - that in python
338:44 - yeah i wanted to see if you could do
338:46 - that yeah nice okay
338:48 - one second yeah little mistake there
338:53 - there we go okay now we have a list of
338:56 - strings
338:57 - colors plural got it
339:01 - yep colors okay there we go so now we
339:03 - have our list okay we have a list called
339:04 - colors and it has all these in here
339:07 - now as you know we can index in two
339:10 - colors
339:10 - with a zero and we would get what sunny
339:13 - you'd get
339:14 - the red absolutely yeah and we can index
339:18 - that one
339:19 - blue get blue and two to get green so on
339:22 - and so forth okay so we can index
339:24 - pretty straightforward in python you can
339:26 - also slice
339:27 - okay so you can get instead of just
339:30 - indexing at the first one or just the
339:31 - second one you can actually get a subset
339:33 - of it you can get like the first three
339:36 - so you could say like from point
339:38 - zero for two points forward from point
339:40 - zero get me like red blue green or
339:42 - something like that
339:43 - exactly we could get like just these two
339:46 - or we could get just
339:47 - these three or we could get just these
339:49 - four um
339:50 - it's called slicing because you can
339:51 - slice up the list into like some
339:53 - some um you can trim it to whatever you
339:55 - want okay
339:57 - so the way you do that is you use a
339:59 - colon okay you put a colon here
340:03 - and then you just put the first and the
340:04 - last so very simple
340:07 - it's so nice and hyphen dude i know man
340:10 - that's why javascript sucks
340:12 - lasting in javascript a little bit more
340:14 - confusing but yeah that makes sense for
340:16 - you
340:17 - yeah that's all it is so what this is
340:18 - saying is for in colors
340:20 - give me the sub list from zero to three
340:22 - so it'll have
340:24 - red which is zero it'll have blue which
340:26 - is one
340:27 - it'll have green which is two and it
340:30 - won't have yellow which is three so it
340:31 - includes the first one but does not
340:33 - include the last one right so it's going
340:34 - to give us element zero element one and
340:36 - element two
340:38 - but not a limit three so zero one and
340:40 - two it should give us
340:42 - this as a list when i hit enter okay
340:45 - red blue green i'm gonna hit it that's
340:47 - exactly what you get
340:48 - okay nice that's how you slice
340:52 - um of course if i what is it so zero
340:55 - one two three four five if i put five it
340:59 - would ignore white so let's try that
341:02 - it would give us everything except for
341:03 - the white but if i put six
341:06 - okay then it would actually which
341:08 - doesn't exist then it should give us all
341:09 - of it or it might break let me see if it
341:11 - breaks
341:12 - no it doesn't so there's a safe check so
341:14 - six goes past here and it'll
341:17 - give you everything up to six because
341:19 - this is five nice um
341:20 - alternatively because this is the
341:22 - maximum list you can just not give it
341:24 - and it'll just say zero to the end of
341:26 - the list
341:27 - oh nice okay and vice versa you could
341:31 - even
341:31 - be like beginning of the list up to four
341:34 - i've seen that in a tutorial somewhere
341:35 - that's nice yeah
341:36 - awesome yep you can just do that so this
341:39 - is like zero this is the same as saying
341:40 - zero to four
341:41 - yeah um it's cool stuff like that uh one
341:44 - more cool thing i want to teach you guys
341:46 - is
341:47 - you can actually be like from zero to
341:49 - six and you can actually add another
341:51 - colon
341:52 - okay and what this is is the stride
341:55 - so if you put two it's going to skip
341:58 - every two
341:59 - so this one this this would actually
342:01 - give us red
342:02 - stride of two instead of if it was
342:04 - straight of one it would give us every
342:05 - one but straight up two will give us red
342:07 - and then skip one then green skip one
342:09 - black
342:10 - so this should give us red green black
342:12 - okay
342:14 - there you go that's insane dude i love
342:17 - that
342:18 - right right that's nice um yeah that's
342:21 - cool so red green black and again if i
342:23 - put a
342:24 - stride of three it would jump in groups
342:26 - of three so it would go red
342:28 - skip skip yellow skip skip nothing it
342:30 - would just be red yellow
342:32 - so let's try this there you go
342:36 - and then again if you did if you did
342:37 - straddle four it would go
342:39 - red skip skip skip black skip and then
342:42 - nothing else so this would just be red
342:43 - black
342:44 - nice boom but guys that's how you do
342:47 - that that's something
342:48 - new even for me like slicing in python
342:50 - so if you guys found that useful what
342:52 - can they do aaron
342:54 - um they can uh send a money request to
342:57 - my uh
342:58 - request to my paypal yeah
343:02 - now you guys can smash the like button
343:04 - uh show us if you guys if your minds are
343:05 - blown just show us
343:06 - um tell us in the comments or if i'm
343:08 - being boring and going over basics
343:10 - um but oh yeah guys i think that's
343:12 - awesome honestly because like i didn't
343:13 - actually know that
343:14 - you could do that in python so awesome
343:16 - to see how you do that nice
343:18 - and we're not even done yet bro we're
343:19 - only halfway there look at this watch
343:21 - this
343:22 - so this is called striding this is
343:24 - called slicing the first colon is
343:25 - slicing
343:26 - the second colon is called striding
343:28 - because you wanted to define your stride
343:30 - okay you can be like if a stride one is
343:32 - the same as not having a stride at all
343:34 - yeah and if you delete it like having
343:36 - like we said it's like having
343:38 - nothing there okay one by default the
343:41 - cool thing is
343:42 - you can also reverse a list by using
343:45 - negative numbers
343:46 - so now instead of going from zero to six
343:50 - you'll go from six
343:50 - to zero and this will actually reverse
343:52 - the whole list
343:54 - no way wait oops
343:57 - um let's try this there we go
344:00 - so now it's reversed what
344:04 - here let me actually explain that so
344:06 - yeah um actually this didn't work i made
344:08 - a mistake there so zero to six
344:10 - yeah um this determines the direction of
344:11 - this of the stride so it's still going
344:13 - to go from index
344:14 - zero which is red to index
344:17 - six or five which is white but it's
344:19 - going in the right direction
344:20 - should you have done you're starting
344:22 - zero zero exactly bro
344:24 - exactly she done six zero because
344:26 - negative means you want to go in the
344:28 - left direction so you want to start from
344:29 - index six
344:30 - um which is really well actually that's
344:33 - incorrect you wanna start from index
344:35 - five because remember the first one is
344:37 - inclusive yeah
344:38 - so you wanna start from index five it'll
344:40 - include it and it'll exclude this last
344:41 - one
344:42 - kodi kodi joshi actually pointed out in
344:45 - the comments nice he goes also that
344:47 - reverses the list nice
344:48 - yeah awesome yep so if you did that then
344:51 - um it'll go
344:52 - through the reason um this isn't going
344:54 - the first one red at the beginning is
344:55 - getting deleted
344:56 - remember blue there's supposed to be a
344:57 - red at the end but it's getting deleted
344:59 - because it doesn't include zero
345:01 - so you could technically put negative
345:03 - one okay
345:05 - and then um okay it doesn't work but i
345:07 - mean i thought it would but if you just
345:10 - like if you just omit it and don't have
345:11 - it there at all then it kind of says
345:13 - like
345:14 - um to go from the beginning all the way
345:16 - to the beginning but don't stop at zero
345:17 - go like one further
345:19 - okay so this is kind of similar to like
345:20 - like when you omit it you just kind of
345:21 - like go to the end when there's not a
345:23 - number there
345:24 - nice so this would be reversing the lip
345:27 - reversing the list i've been talking too
345:28 - much one second that's really powerful
345:30 - that's massively powerful because even
345:32 - in javascript like to reverse a list
345:34 - you can do i mean there are tricks
345:35 - around it but it's
345:37 - it's not as clean as that like that's
345:38 - that's really nice yeah
345:41 - yeah so python makes it nice for like
345:42 - dealing with complex problems which
345:44 - happens a lot in machine learning you
345:45 - want to be able to express these ideas
345:47 - really simply so this looks simple but
345:50 - when you have to do like crazy slicing
345:52 - and like like seven dimensional arrays
345:54 - on like different images of like
345:56 - things things this adds up quickly so
345:58 - it's difficult in python and impossible
346:00 - in javascript so that's why python is
346:02 - the best sunny
346:02 - crossover and
346:06 - if we do a collab with like a reaction
346:08 - that django
346:09 - it's gonna be bickering the whole time
346:11 - this fight
346:13 - like es6 is better than this
346:15 - slicing
346:20 - [Laughter]
346:23 - but yeah so that's that's slicing and
346:24 - striding and using negative strides okay
346:26 - so very very cool there
346:28 - um so we can do that and then of course
346:31 - we can
346:32 - omit uh omit both of them and by default
346:35 - because it's negative it'll just start
346:36 - because it's negative it'll start from
346:38 - the right most spot and go to the left
346:40 - because negative means going to the left
346:41 - so this will
346:42 - also work for reversing a list so this
346:44 - is how you can reverse any list in
346:45 - python with one little line
346:47 - so you have colors yeah
346:51 - and then you have colors at negative one
346:53 - so this
346:54 - and this are reversed got you cool stuff
346:56 - awesome
346:58 - now i'm gonna talk about slicing
347:00 - multi-dimensional arrays
347:02 - which is what an image is you can
347:03 - actually slice an image
347:05 - by using the same thing and just get a
347:08 - sub multi-dimensional array
347:10 - from that big array by using the same
347:12 - thing okay
347:13 - so that's why this is relevant so let's
347:16 - say
347:17 - you had um
347:22 - a multimeter right because this this can
347:24 - be kind of hard to explain visually with
347:25 - this example
347:26 - uh okay let's clear let's quit out of
347:30 - this
347:31 - okay clear seller
347:34 - clear and then let's go back into python
347:40 - um let's have a
347:45 - multi-dimensional array okay yup
347:48 - and let's have one two
347:51 - three four
347:56 - okay yep five six seven
347:59 - eight because this is and one array with
348:03 - three
348:03 - arrays inside of it so far and four
348:06 - okay we've got four right 14 16. so this
348:09 - should be like
348:10 - a um it might be it's going to be kind
348:13 - of hard to do it in here can i
348:15 - could you have like a new line on here
348:18 - i mean if you log in now if you do mra
348:21 - actually let me
348:23 - let me um
348:26 - i kind of want to explain this uh
348:31 - i don't want to i don't want to dirty i
348:32 - don't want to start editing stuff in
348:33 - here because it might get confusing
348:35 - yeah also guys i just wanted to say we
348:37 - just
348:38 - are nearly about to hit 800 likes so
348:41 - massive thank you guys and if you
348:42 - haven't already
348:43 - smash the thumbs up because aaron's
348:44 - about to drop some knowledge on python
348:46 - tricks and tips
348:47 - nice holy crap uh actually let's just
348:50 - try to jump into the code i feel like
348:51 - people probably understand slicing
348:53 - enough at this point
348:54 - to like like translate over the ideas
348:56 - like i don't want to drag on too long
348:57 - because i spent 20 minutes explaining
348:58 - slicing
348:59 - yeah so this is this is the goal we have
349:02 - a frame
349:03 - we have a face in that frame with our
349:06 - coordinates
349:06 - how do we get this as an image
349:09 - of here as a sub image well we can just
349:11 - use slicing with these numbers
349:14 - to slice a portion of this frame which
349:16 - is just a multi-dimensional array
349:18 - okay and that will actually give us an
349:20 - image instead of just
349:21 - this point because all we have is points
349:23 - and then we're actually drawing a
349:24 - rectangle on it ourself
349:26 - uh up here we're just drawing a
349:27 - rectangle around it but we actually want
349:29 - to get like the full image like all the
349:30 - pixel data of this
349:31 - bounding box okay so the way we do that
349:34 - is instead of doing it this way
349:36 - we actually want to have the face be
349:39 - um a slice so what you want to do is you
349:42 - want to take the frame
349:43 - okay and for a multi-dimensional array
349:47 - you can actually slice in both
349:49 - dimensions so
349:50 - what we could do is we could be like
349:52 - okay from zero to the end
349:54 - in the x dimension and from zero to the
349:57 - end
349:57 - in the y dimension remember how to slice
350:01 - okay so this will just this will just
350:02 - say get the whole frame this is actually
350:05 - the same thing as representing the whole
350:06 - frame because
350:07 - from zero you're getting every single um
350:10 - you're getting every single uh column
350:13 - and every single row and every single
350:15 - column i'm getting the x and y confused
350:17 - i gotta double check which one is which
350:18 - but we'll try both we'll learn together
350:21 - we're fresh together but uh one is x and
350:23 - one is y
350:24 - and um of course if you had like a 3d
350:26 - three-dimensional thing then you could
350:28 - even slice it in three dimensions like
350:29 - if you had a cube
350:30 - and then you want to like find like some
350:32 - subset some cube in there or some
350:34 - rectangle
350:35 - inside there you could also slice that
350:36 - way okay the idea is this
350:38 - zero to the end and zero to the end this
350:40 - will give us the full frame
350:42 - um so you can probably see where i'm
350:44 - going with this
350:45 - uh all we need to do is just utilize
350:47 - these four numbers to actually define
350:48 - the exact frame
350:50 - the exact subframe of the full frame
350:52 - that we want okay
350:54 - yep and so that's really simple i mean
350:56 - all you want to do
350:57 - is just slice so um where do we want to
351:00 - start so from the beginning
351:02 - the top left corner of it is going to be
351:05 - uh
351:06 - x okay and then x plus
351:10 - width okay that's it and then in the y
351:13 - direction we're gonna have y
351:15 - and y plus height that's that's
351:18 - literally it
351:19 - okay so we're going to slice this whole
351:21 - frame and get the sub
351:22 - frame of x x plus w and y y plus h
351:26 - but i'm pretty sure this is backwards i
351:28 - think y needs to come first
351:30 - um i think i just
351:33 - eliminate something so i'm pretty sure y
351:34 - has to come first and then of course if
351:36 - we had a z coordinate as well
351:38 - you would want to do like uh z and then
351:40 - z
351:41 - plus depth or something but we don't
351:42 - have this we're not doing crazy like 3d
351:44 - modeling here we're just doing images
351:46 - but i mean i'm just showing here um that
351:48 - you can do this
351:49 - one thing i do need to point out very
351:51 - very very important
351:52 - is this does actually not work this does
351:56 - not work
351:56 - in vanilla python the reason this does
351:59 - work
352:00 - is because opencv is built on numpy
352:03 - and numpy this works this works in numpy
352:06 - numpy is a library for dealing with
352:08 - numbers and matrices
352:10 - um in python very powerful and it allows
352:12 - you to do cool stuff like this
352:13 - but this is not in vanilla python so
352:15 - that's why in this terminal it wasn't
352:17 - going to work
352:17 - and i didn't want to explain it here
352:19 - because this wouldn't actually work you
352:20 - need to import numpy which is just
352:23 - um numpy like that okay i mean i guess i
352:26 - could have
352:26 - uh defined it here so let me actually
352:28 - show this a little bit
352:30 - uh yeah cause i'm i kinda get it and
352:32 - then there's a little bit of a gap so
352:34 - yeah it'll be handy to go through this
352:35 - yeah
352:36 - yeah um but
352:40 - i think i think it's like a pretty print
352:41 - in in numpy i think it's
352:43 - isn't it oh print f is uh variables uh
352:46 - yeah what is it what is the numpy nice
352:49 - print
352:53 - how to pretty print a numpy array
352:55 - without scientific notation
352:58 - asking if this live will be saved yes
353:00 - this will be available afterwards
353:02 - all of the live streams are available
353:03 - afterwards guys
353:06 - yeah format i mean there might not be a
353:08 - pretty way to print it
353:09 - that's the thing i didn't think there
353:11 - was that's why i can't remember
353:15 - uh
353:19 - yeah i gotta do some some crazy um stuff
353:22 - yeah actually let me just have like is
353:25 - there like a grid of numbers
353:28 - and maybe uh what are we trying to show
353:30 - right now
353:32 - um you wanted to see how how this is
353:33 - getting sliced right yep
353:35 - i think i think maybe we could do it
353:37 - here i think it might be clear on
353:38 - just on the terminal okay the thing is i
353:42 - don't know how to print
353:44 - um okay or let's just try it yeah let's
353:46 - just try it
353:47 - yeah from here so you guys can kind of
353:48 - see like it's not nice and
353:50 - formatted like vertically i was hoping
353:51 - we could like ver because this is a four
353:53 - by four
353:54 - four by four uh um two-dimensional
353:57 - matrices
353:57 - yeah because we have a list of length
354:00 - four and each of those
354:01 - there's a list of length fourth in those
354:02 - so it's like a four by four box actually
354:04 - if we layer these on top of each other
354:06 - okay but we can actually slice like i
354:09 - said
354:10 - using the comma and colons somebody said
354:13 - np
354:13 - dot array i'm not sure if np dot array
354:16 - have you heard of that's what it is yeah
354:18 - you just print
354:19 - um np dot l but thank you kodi
354:22 - joshi for that so it says np dot
354:25 - uh array and then open parentheses and
354:28 - then square brackets inside
354:36 - wait what no i know i know i know what
354:38 - he's saying it's coming back to me
354:40 - because i haven't used numpy in a few
354:43 - weeks so i kind of forget it
354:44 - can you type it uh is it in the comments
354:46 - you could do four line in
354:48 - array ah i don't know i don't iterate
354:51 - over it you know
354:51 - yeah i think it's um
354:55 - array.l or something
355:02 - numpy pretty print
355:05 - array
355:09 - i mean we're back here what did he say
355:12 - exactly
355:13 - somebody said import numpy uh or numpy
355:16 - as
355:16 - mp first and then so then you'd end up
355:20 - doing numpy
355:21 - dot array so you could do numpy.org
355:24 - would you numpy the ori oh yeah because
355:26 - yeah you import numpy
355:28 - so numpy or just or just uh no no
355:32 - i think you do numpy dot array and then
355:34 - open parentheses l
355:39 - ah there we go hey thank you guys that's
355:42 - awesome
355:43 - i thought it was pretty print but i mean
355:44 - that's that's the normal
355:47 - yeah all right there we go so this was
355:48 - talking about we have a double
355:50 - double uh two-dimensional array here
355:52 - yeah uh four by four so this is easier
355:54 - to visualize what i was trying to do
355:55 - from the beginning
355:55 - yeah oh god guys i think i think he
355:58 - deserves a thumbs up
356:01 - terrible
356:04 - oh we'll hire him have him teach it yeah
356:07 - number three
356:08 - nice um i don't know it wasn't popping
356:12 - up
356:12 - because yeah remember it was something
356:14 - simple with the array but they're like
356:15 - iterating through all the crap i'm like
356:16 - okay i don't want to have to do all that
356:18 - again
356:19 - but anyways uh so here the way we can
356:22 - slice this is you can go by the
356:24 - y dimension then the x dimension so
356:28 - um let's just slice this so let's start
356:31 - with
356:32 - the y dimension let's just get the first
356:35 - two
356:36 - okay okay um so this is the first
356:39 - dimension so what we're doing here is
356:40 - we're getting the first element and the
356:42 - second element
356:42 - so in this over array we're getting the
356:44 - first element which is this list and the
356:46 - second element which is this list
356:48 - okay is that clear yep and
356:51 - now so we we're getting this
356:55 - now what if we wanted to get like this
356:57 - three four and the seven eight as like
356:58 - the
356:59 - the sub sub array of the whole thing
357:02 - then all we want to do is just pop in a
357:05 - um
357:12 - oh i think we
357:16 - are no so the element two oh wait we
357:19 - want to go from element
357:20 - two we're back okay we're back i think i
357:23 - lost you for a second aaron did we
357:25 - we lost the stream for a sec uh i don't
357:27 - know if it was i think it was skype i
357:29 - think it might have just been skype
357:32 - oh it just broke down for a sec yeah all
357:34 - right we're good
357:36 - anyways um so if we have
357:39 - uh the first two elements here um
357:42 - slicing from zero to two one two three
357:44 - four
357:44 - and five six seven eight we're
357:46 - essentially getting these first two the
357:47 - first is like
357:48 - elements because zero up to two but not
357:50 - including two
357:51 - yeah uh now if we want to get this sub
357:52 - array three four seven eight
357:54 - then we're going to need to further uh
357:56 - well actually let's do this subarray two
357:58 - three six seven okay how would we get
358:00 - this
358:00 - out of this whole thing okay well again
358:02 - it's just gonna be a simple slice
358:05 - um but within each of these arrays this
358:08 - is element zero and this is element one
358:10 - so we want to go from element one to
358:12 - element
358:13 - uh two but this isn't included so
358:16 - element three
358:17 - um will give us these two if we say
358:19 - element three right
358:21 - yeah it makes sense sunny yep we're good
358:25 - and this but i think it might be
358:26 - backwards yeah it's backwards so
358:28 - um when you're adding when you're adding
358:31 - uh dimensions to the array you need to
358:32 - actually go in reverse order
358:34 - so it's going to be like this okay
358:37 - so this will give us from these two to
358:40 - these two
358:40 - and then also of these first two rays
358:43 - okay
358:43 - i believe yeah i mean it might might
358:45 - break
358:47 - uh indices do you have questions
358:52 - huh do you have to use the opencv uh
358:56 - opencv is built on nonpartners
358:58 - i mean will they utilize numpy opencv is
359:00 - but you're inside of
359:01 - um you're inside of it yeah that's what
359:04 - screw me up
359:04 - yeah because i need to call the numpy
359:06 - stuff yeah
359:21 - getting turned around over and over
359:25 - still not working um
359:29 - i should have brushed up on my numpy
359:30 - syntax before this i wasn't expecting to
359:32 - show it in here i was
359:33 - just going to show the opencv part uh
359:36 - but
359:38 - all right okay guys let's investigate
359:39 - together so whenever you forget code
359:41 - just you know
359:42 - go to google and and figure it out um
359:45 - how to display numpy
359:50 - uh subreddit i mean it should work
359:54 - i just i don't know why it's not working
359:55 - because it was working in the uh
359:57 - opencv here oh maybe you gotta do
360:02 - uh
360:04 - numpy array well let's let's display the
360:06 - type so this should be a numpy array so
360:07 - let's print
360:08 - the type just make sure that typing is
360:10 - all correct so when we
360:12 - actually somebody said store that in a
360:15 - variable and then use that
360:16 - so i think what we need to do is memory
360:18 - thing yeah how
360:19 - about even you see have it as you had it
360:21 - before it's a number array
360:23 - but i have the square brackets outside
360:25 - the parentheses
360:26 - the score back it's outside the
360:28 - parenthesis uh
360:30 - this is so you know you've got um
360:33 - numpy.al
360:35 - yeah yeah do that and then have the
360:37 - square brackets outside the parentheses
360:42 - outside the parentheses what do you mean
360:44 - the score brackets like
360:45 - did you numpy yeah l
360:48 - and then and then out so outside that
360:51 - bracket so i have l inside the brackets
360:54 - yeah outside the brackets have square
360:56 - brackets so so now on the
360:57 - right so on the right uh put the square
361:00 - brackets and do one three zero two would
361:01 - that work no no so outside the
361:03 - parentheses outside the parentheses
361:06 - yeah oh just index like this directly
361:09 - i think this might actually work no no i
361:11 - was saying so so i have numpy.l
361:17 - yeah and then and then change them print
361:19 - yeah and then get rid of the parentheses
361:21 - just make square brackets oh
361:24 - dang coding in this terminal is terrible
361:27 - yeah
361:28 - no yeah like that maybe that will work
361:30 - yeah
361:32 - hey there we go okay because then you
361:35 - then you're doing it on the object yeah
361:36 - you're getting back yeah but i mean this
361:39 - is also wrong this is uh index you get
361:41 - wrong
361:42 - yeah you get all turned around with
361:44 - these numbers um
361:45 - okay let's let's try the other way
361:46 - around
361:49 - zero and two one and three
361:55 - two three six seven let's see there we
361:58 - go
361:58 - nice all right we finally got it guys so
362:01 - the ordering is
362:02 - um if you wanted to get this sub array
362:04 - then
362:05 - in numpy using raw numpy if you're to do
362:07 - it then you need to use the numpy dot
362:09 - array
362:10 - um get the list so this is um
362:14 - because l is just what is l l l yeah l
362:17 - is just a raw python list
362:19 - okay so we have to convert it to an
362:20 - array here yeah
362:22 - you have to explicitly convert it to an
362:24 - array by using numpy dot array
362:26 - change this and then once it's in numpy
362:27 - form then you can index it like i was
362:29 - saying you can't actually do this on
362:30 - vanilla python
362:31 - yeah so that's where um not enough
362:33 - coffee man i run out of coffee
362:34 - and now and and what we're doing with
362:36 - that indexing is we're saying
362:38 - get the first and second array inside of
362:40 - the
362:41 - the sort uh overall array and then we're
362:43 - saying
362:44 - slice it to get the the the first and
362:47 - second
362:48 - uh first and second in the um y
362:51 - direction
362:52 - so in the y direction you know going top
362:54 - and bottom yeah then we want to get the
362:56 - first and second
362:57 - and then in the x direction you want to
362:59 - go from index one to three
363:01 - so we're getting these two and then from
363:03 - one to three it's going to be
363:05 - these two
363:08 - sunny is also becoming pro in python hey
363:11 - let's go
363:14 - yeah but not not as pro as the guy that
363:15 - was helping me out because i'm just here
363:17 - forgetting about numpy
363:21 - it's been a bit but
363:27 - oh
363:31 - i think we lost aaron again but just
363:34 - treat me he's back
363:35 - this ray i think i lost you for a second
363:39 - aaron we're back
363:40 - we're back oh my god this internet man
363:44 - also just yeah just want to add a
363:47 - comment here so surah rajput says hello
363:49 - there i recently joined pwj community
363:51 - it's awesome and i'm really excited
363:52 - welcome dude i love seeing our own
363:54 - students on the on the streams
363:56 - we can see here
364:05 - so here um this is a casting
364:10 - list this python list okay
364:14 - aaron's internet is being a little janky
364:16 - or is it me
364:17 - i'm not sure if it is connecting
364:22 - uh all right now we have it did it cut
364:25 - the stream
364:26 - no no i don't think it's kind of stream
364:27 - i think it's uh
364:29 - it's okay good yeah so
364:33 - just lagging
364:37 - don't worry let's go let's carry on yeah
364:38 - we'll carry on sunny
364:40 - yep okay
364:43 - okay got it i think it's the shoddy
364:46 - connection
364:47 - yeah i i can't hear you man you can't be
364:49 - there
364:51 - okay cool so like
364:55 - the lag i think there's a huge lag
364:58 - okay oh we've lost we've lost aaron on
365:00 - the stream okay so aaron do you want to
365:02 - share your screen
365:07 - yeah can you hear yeah
365:15 - uh bear with us guys a little bit of an
365:18 - internet
365:19 - moment i'm not sure if y'all or aaron
365:23 - okay i think we're back yeah i've got
365:25 - you now i've got you
365:26 - can you come back sonny
365:30 - yeah all right good good yeah i think
365:32 - there's a internet hiccup there
365:34 - can you hear me oh dude before yeah so
365:36 - can you hear me now
365:41 - yep what was happening what's happening
365:43 - yeah we just got a 50
365:45 - i think it's mexican dollars super chat
365:47 - from jessica
365:48 - apollina saying i love your streaming i
365:51 - don't
365:51 - have that's a professional experience in
365:53 - python although i'm fond of learning
365:55 - and build my personal projects huge huge
365:58 - thank you jessica that's that's insane
366:00 - we massively appreciate you watching
366:01 - this
366:02 - and yeah like hope keep on enjoying this
366:04 - the content that's that's insane
366:06 - love that especially when we just had
366:08 - some some streaming difficulties but
366:09 - we're we're back
366:10 - we're back nice
366:14 - let's go and coding difficulties yeah
366:17 - like i'm running on three hours of sleep
366:19 - bro this is not
366:20 - yeah why did i do this uh but
366:24 - um what was that saying so yeah here in
366:26 - the numpy i ironed this out so
366:28 - the issue i was making was this is a
366:29 - python list but you got to make sure i'm
366:32 - pilot so you gotta pop into the right
366:33 - function
366:33 - and then from there you can slice in
366:35 - this manner so what i want to make that
366:37 - that parallel here
366:38 - an opencv it's much easier because
366:40 - everything is
366:41 - a numpy array by default like the frame
366:44 - here is
366:45 - this is a numpy array so you can just
366:47 - slice it normally
366:48 - um instead of having to do the whole the
366:50 - whole numpy i don't you don't have to
366:52 - actually make a numpy right yourself
366:54 - okay um but i'll try not to forget that
366:56 - again
366:58 - but yeah so this numpy right and then we
367:00 - slice it like this and again so we're
367:02 - going to do
367:02 - the y direction first and x direction
367:04 - second so this is actually the correct
367:06 - way of doing this
367:08 - back coming back to our application okay
367:10 - so
367:11 - let's delete this out and
367:14 - the sub a frame
367:18 - yeah using uh
367:21 - high uh n
367:24 - dimensional slicing nice okay all right
367:28 - that might be kind of big
367:29 - but there we go yep so opencv built a
367:33 - numpy superpower
367:35 - and uh going forward this should work so
367:38 - let's walk through this again just to
367:39 - touch base again because that was a long
367:40 - ass tangent these streams go on way too
367:42 - long and
367:43 - just want some breakfast don't worry
367:45 - everybody look at all the faces
367:49 - within the frame
367:55 - yeah i can't even see the stream because
367:56 - i'm just in my code but i'm trusting you
367:58 - there's we have like two viewers right
368:00 - two no no no no we're good we got we got
368:01 - about 250 people here dude
368:07 - dope yeah lag is super bad like you
368:09 - reply like six seconds
368:11 - yeah i know but it's okay so just keep
368:13 - going keep going keep going we're good
368:15 - good um
368:18 - all right sonny i don't know if it's a
368:22 - holy crap this internet man
368:25 - really killing uh anyways so let me i'm
368:28 - just going to keep talking and that way
368:29 - it's like
368:32 - so we get the faces we find the the
368:34 - frame we use numpy slicing to get just
368:36 - the face
368:37 - and then we convert just the face to
368:39 - grayscale
368:41 - yep and then once we have just the face
368:43 - of grayscale then we can run the small
368:44 - detector on that little face
368:46 - and then print all the rectangles around
368:48 - those smiles and this
368:57 - out of here god damn it there we go
369:02 - yep we
369:05 - we there yep we're there that's sunny
369:08 - awesome so quit out let's run this one
369:11 - more time and see
369:11 - if it works
369:15 - hey dude there we go got it something
369:18 - something's uh oh yeah yeah
369:21 - i think the x and y is
369:25 - yeah so this is the one last thing i
369:27 - want to say um the area that's happening
369:29 - here
369:30 - is um so we're finding the faces right
369:33 - in front of the faces we're drawing the
369:35 - face
369:35 - uh we're drawing the rectangle around
369:37 - the face okay we're drawing a rectangle
369:39 - around my face
369:40 - that's the first step yep second step is
369:43 - we're getting
369:44 - the face here so we're creating the
369:46 - sub-array and then we are
369:48 - searching for the um
369:52 - i mean we're making a great scale and
369:53 - then we're searching for the smiles
369:54 - within that face
369:55 - uh once we get those coordinates those
369:57 - are correct
369:58 - the issue is we're actually drawing the
370:00 - rectangle on the frame
370:02 - instead of on the little face
370:05 - so um the reason reason here is we're
370:09 - getting coordinates so within the face
370:10 - it's a little square right it's a little
370:12 - tiny square
370:13 - yep um when we run smiles on this little
370:15 - tiny square
370:16 - we're getting some coordinates back um
370:19 - in of
370:20 - like from for those smiles does that
370:21 - make sense sunny yep
370:23 - that makes sense so like actually it
370:25 - might be easier to explain here on the
370:29 - uh here so here
370:33 - holy crap here uh we're getting
370:37 - getting the face first and then get the
370:40 - sub image
370:41 - and then and then we want to find the
370:42 - smiles in here so the thing is because
370:44 - this is the sub image
370:45 - the xy point is actually pretty small
370:47 - it's starting from here
370:49 - and we're going to say okay go down this
370:50 - much y and go across this much x
370:53 - this is the top left point and this is
370:55 - the bottom right point and we can draw
370:56 - this
370:57 - the thing the problem is i was actually
370:59 - drawing this rectangle
371:01 - based on these coordinates so this was
371:03 - offset way up here in the left so it was
371:05 - actually taking
371:06 - this um y and this x and drawing it on
371:09 - the big
371:10 - big frame oh actually yeah we actually
371:13 - want to draw it within the little face
371:15 - so how we fix that i mean this actually
371:18 - doesn't matter too much because we're
371:19 - going to get rid of it and show small
371:21 - anyways but it just for additional
371:22 - purposes
371:24 - yeah and so i think it is a game of maya
371:26 - i think it is important some people
371:27 - might want to show that that
371:28 - rectangle you know yeah yeah yeah
371:32 - so we need to do is in smiles when we
371:34 - draw the rectangle
371:36 - instead of drawing it on frame right we
371:38 - actually want to draw it on
371:39 - the face so we take this sub image and
371:42 - we draw it on the face
371:44 - because before here oops
371:48 - when i smile see it's drawing like if
371:50 - you took this
371:51 - if you took this green square and put it
371:53 - in the top left you can kind of see that
371:55 - that's where my face would be
371:56 - my smile go ahead you see yeah yeah so
371:59 - we're just drawing it on the wrong frame
372:01 - right now if we go back here and we quit
372:03 - out
372:04 - uh if we quit out
372:08 - just interrupt that then
372:12 - um we can actually draw it on the face
372:14 - instead so
372:15 - uh this is another thing i want to say
372:17 - so the face is actually
372:18 - just a sub array of frame like i said
372:22 - okay but the thing is when you slice
372:24 - like this
372:25 - i believe you're actually just accessing
372:27 - the actual memory of this full frame so
372:29 - you're not making a copy you're not like
372:30 - saying oh
372:31 - this uh this is a new subarray that's
372:35 - equivalent to like this little range but
372:37 - you're actually saying just get me this
372:39 - portion of memory
372:40 - in this weird slice because you have
372:41 - direct access to the memory like that
372:43 - with numpy
372:43 - okay so if i change this data within
372:46 - here
372:46 - if i change the data of the frame within
372:48 - here then it'll actually change it on
372:51 - the mainframe as well because we're just
372:52 - saying okay this little slice of the
372:54 - whole frame
372:54 - um this editing this in here will also
372:57 - edit this which means editing the face
372:59 - will still edit the frame so we can
373:01 - still we can draw on the face
373:03 - which will work uh if you draw on the
373:05 - face then it'll actually also draw on
373:07 - the
373:07 - on the the master frame okay even though
373:09 - we're not drawing on the frame so that's
373:11 - that's how that works there because when
373:12 - you when opencv draws a rectangle it's
373:15 - actually just going into
373:17 - the the memory and just like changing
373:19 - the memory there there you
373:21 - yep so now
373:25 - let's try one more time and
373:28 - oh hey hello hey
373:32 - with that said guys we just hit over 850
373:34 - likes just push that to 900 and if you
373:36 - found that cool
373:38 - and aaron and aaron guys aaron just
373:40 - debugged everything in front of you so i
373:42 - think he deserves
373:43 - a smasher thumbs up and just some just
373:45 - some
373:46 - numpy nightmare man yeah syntax
373:49 - numpy nightmare
373:50 - exactly that's the one thing i hate
373:51 - about numpy i wish they had i wish they
373:53 - had some nice like
373:54 - easier syntax to but it's all like
373:57 - function based that's the one downside
373:58 - but i know i mean numpy is awesome
374:00 - yeah and you used a lot you fixed it
374:02 - exactly so that's the main thing
374:04 - thanks thanks uh with help from the
374:06 - community yeah
374:08 - shout out shout out to whoever that was
374:10 - i couldn't find it on google and i was
374:11 - like ah i give up
374:14 - not important but anyways
374:18 - uh from here um now though but i mean
374:21 - this is cool but i mean this is kind of
374:22 - just like the same as face detection or
374:24 - car pedestrian tracking
374:26 - but it's like outlining it but i think
374:27 - it'd be more cool if it like just
374:29 - detected that i was smiling and put the
374:30 - word smiling underneath
374:32 - [Music]
374:39 - but i think it'd be more cool if it like
374:41 - just detected that i was smiling and put
374:43 - the word smiling underneath because
374:45 - you're
374:45 - only concerned with smiles if it's like
374:47 - a face you're like oh this face is
374:48 - smiling or this face is not smiling
374:50 - yeah so i think it's cool to um do that
374:52 - instead
374:53 - so let's do that next nice let's quit
374:56 - out of
374:56 - here and the very last thing we're going
374:59 - to do is
375:00 - instead of drawing this okay instead of
375:03 - drawing
375:04 - the rectangles around the smiles at all
375:06 - we're not even going to do that we're
375:07 - just going to completely ignore
375:09 - drawing the rectangles um i mean it was
375:12 - relevant because i wanted to show you
375:12 - the cool little
375:13 - like offset thing how the memory is
375:15 - actually being being saved here when you
375:16 - slice it's the same exact memory
375:18 - so it goes into the same memory and
375:20 - changes it um but i do want to show you
375:23 - how to put some text so i don't i want
375:25 - to avoid another syntax mistake though
375:27 - i'm the master copy paster
375:31 - uh yeah i think it was massively
375:33 - valuable to show them how to draw the
375:34 - actual smile
375:35 - because then it gives them context as to
375:37 - what we're gonna do next
375:38 - yeah yeah so i got rid of drawing the
375:41 - smile because i don't want that there
375:43 - but now i pasted this ugly looking thing
375:46 - here
375:47 - so what this is is now instead of
375:51 - drawing the rectangle around the smile i
375:53 - want to actually draw
375:54 - um the word smile uh i mean write the
375:58 - word smile
375:58 - smiling okay i have it right here
376:01 - smiling underneath
376:02 - the little um portion so like when i go
376:06 - here you can see smiling pops up for a
376:07 - few seconds that's that's what we're
376:08 - going to be doing now
376:10 - instead of having the right i think
376:11 - you're going to have an error because
376:12 - you said if smile
376:13 - length if length of smile so go back to
376:16 - the code is it meant to be plural if
376:18 - length of smiles
376:19 - because you've done smiles array
376:23 - um yeah i think so yeah so length of
376:25 - smiles
376:26 - is greater than zero yeah nice yeah
376:28 - because uh let me just double check
376:30 - yeah because down here i think i used um
376:33 - yeah yeah you smiled singular yeah so
376:35 - yep
376:36 - uh so yep so pretty much
376:39 - all i'm gonna say is if length of smiles
376:42 - is greater than zero because remember
376:43 - smiles is a list of all smiles it found
376:46 - within the face if it's greater than
376:48 - zero which means there's one or
376:49 - more smiles then we're just gonna put
376:50 - some text on the screen so this is very
376:52 - simple this whole thing here
376:54 - is just displaying the word smile at
376:55 - some coordinate so similar to a
376:57 - rectangle
376:58 - it's cv opencv.put text we're going to
377:01 - put text on the frame
377:03 - okay and that's the first thing the
377:05 - image the second argument is going to be
377:07 - the words you actually want to put so
377:08 - i'm going to
377:08 - just going to put smiling yeah or you
377:10 - can put like why so serious or something
377:12 - okay and then next is next is the
377:15 - location the top left point
377:17 - of where you want to display the text so
377:20 - in my case
377:22 - since i want to put the word smiling
377:23 - just outside the
377:25 - the green box of the whole face i'm
377:27 - going to use
377:28 - the green box coordinates okay okay
377:31 - so i want to put it below it so the x
377:34 - coordinate will be the same
377:36 - um but the y coordinate will be y
377:38 - coordinate plus the height
377:39 - right so i'm just going to actually draw
377:41 - this as you do it on the screen yeah
377:42 - because i think it might be handy
377:44 - so carry on talking over and i'll draw
377:46 - like as we do it
377:48 - i have it here if you want to yeah we
377:50 - can explain it here yeah let's do that
377:53 - yeah so um we have the coordinates so we
377:56 - know this
377:57 - this picture is smiling but we also but
377:59 - we want to put the word
378:01 - smiling down here instead of having this
378:04 - we want to have
378:04 - this yep so if we have um
378:08 - we know this is a yes so we know to
378:10 - display smiling
378:11 - then but how do we get the coordinates
378:13 - of this so we have the coordinates of
378:15 - the whole face which is what we want
378:17 - so why don't we just have the use this
378:19 - top left point to figure out how to get
378:20 - down here
378:21 - so we have the top left point which is x
378:24 - so we can just say
378:24 - at x is where you want the top left
378:26 - point of the text to start at x
378:28 - yep but then the y point we don't want
378:30 - it to start here because it would say
378:31 - smiling up here so we add
378:33 - um y this is y yeah plus h
378:36 - plus the height right so y and then
378:39 - we're saying
378:40 - plus the height which is this so like y
378:43 - which is going to be right here yeah and
378:45 - then i added and then
378:46 - i added 40 just to have a little bit so
378:48 - it's not touching the box i just added a
378:49 - little bit
378:50 - and then that's it so this is this point
378:52 - is going to be x
378:53 - and then y plus h plus a little bit more
378:57 - right so you guys
378:59 - that'll put it right here exactly we
379:00 - have x and y in the corner
379:02 - uh just go back to that that side for a
379:04 - second
379:05 - uh so we've got x and y in the corner
379:07 - and then we go we've got we're doing y
379:09 - plus the height and that gets us to the
379:11 - bottom of the box
379:12 - and then you see aaron's got smiling
379:13 - exactly but if he didn't add the 40
379:16 - it would be sitting on top of the green
379:18 - right now or like oh
379:19 - yeah pretty much on top of it so it
379:20 - would just be touching yeah so we want
379:22 - to add 40 to basically get push it past
379:24 - that little bit extra so yeah
379:26 - awesome nice yup and that's really it
379:29 - guys
379:29 - so as you can see that's gonna be the x
379:32 - is the same
379:33 - and then y plus h plus 40 is right there
379:35 - so that's the top left point where the
379:36 - text is going to start
379:38 - then from there font scale is just the
379:40 - size of the font
379:41 - so size three um and then the font face
379:45 - is just the font you want to use
379:46 - so um opencv has different fonts so
379:50 - that font is called font underscore
379:52 - hershey underscore plane
379:54 - it's the one that looked the nicest
379:55 - you're kind of limited on the fonts but
379:56 - i mean it gets the job done
379:57 - and then last is the color so vgr again
380:01 - but all three are maxed out so this will
380:03 - be white because
380:05 - if all three channels are at maximum
380:06 - brightness 255 then it'll just be white
380:09 - nice so if we run this
380:12 - hopefully with no hiccups no before you
380:14 - run it before you run it we actually
380:16 - just got a superchat
380:17 - from velocity trading he says my
380:20 - girlfriend introduced me to your videos
380:22 - she has a data scientist in nvidia
380:24 - and she loves your content on react yeah
380:26 - shout out to her princy thing
380:27 - that's amazing nice sonny yeah thank you
380:30 - yeah
380:31 - and look at that how crazy is that it's
380:32 - like two worlds came together react yes
380:34 - now we're talking about data scientists
380:36 - where
380:36 - the majority of data scientists code
380:38 - with python so yeah
380:39 - this is this is dope it's awesome yeah
380:43 - you should do a collab with her like a
380:46 - reactive data science project yeah but
380:49 - nice
380:52 - awesome awesome people are showing sonny
380:54 - the love
380:55 - the hulk you get a you should like you
380:58 - should demand people in the comments
380:59 - call you the hulk
381:00 - anybody who wants to cause honey by the
381:02 - hulk pop that in the comments right
381:04 - now going forward we'll legally change
381:05 - his name to the hulk because he can
381:07 - handle anything except
381:08 - standing we have papa react we have was
381:10 - it the react god
381:12 - now we have the hulk
381:15 - the react called god that's just hulk
381:19 - just talk
381:19 - the british proper hulk um
381:22 - but where were we so yeah so we're gonna
381:26 - we're gonna draw smiles underneath the
381:28 - face instead of actually drawing the box
381:30 - well let's put both for now just
381:32 - for demonstration purposes nice
381:36 - let's run this there we go
381:39 - hey nice that's awesome dude
381:44 - yeah it looks a bit like that horror
381:47 - game you know that that slender man
381:49 - that's what the text looks like
381:53 - yeah yeah oh the slenderman text yeah
381:56 - the smiling i mean
381:59 - that's awesome dude and then now if we
382:02 - just get rid of the
382:04 - if we get rid of the
382:07 - um drawing on the rectangles then it
382:09 - should work nice
382:11 - guys if you find that cool because it is
382:13 - it's like look at this look if now we
382:15 - should see
382:16 - no rectangle but we should see the
382:19 - smiling which means that we have that
382:21 - finished sort of hey look at that
382:23 - that's that's that's nice dude that's
382:26 - awesome
382:27 - and even if we have two faces on there
382:29 - because we have that loop
382:31 - it will actually go ahead and do it for
382:32 - a second face as well right
382:35 - i will yeah so let's uh let me just get
382:38 - guys i wish there was a way to get your
382:39 - face on the screen too but the stream
382:40 - tag kind of limits that
382:42 - but yeah let's go ahead and see it wait
382:45 - look at that nice that is awesome guys
382:49 - if you think that's cool smash the
382:50 - thumbs up button that is
382:51 - awesome and if you haven't already and
382:54 - you
382:54 - are following me and aaron on instagram
382:57 - go ahead and shoot us a story right now
382:59 - so this is my tag and this is aaron's
383:01 - tag right over here so my tag is over
383:03 - here aaron you just
383:04 - point somewhere down there you'll see it
383:07 - uh yeah so go ahead and shoot a story
383:10 - and um
383:11 - yeah tag us in there and let us know
383:13 - that you're watching
383:14 - and yeah you guys can we can have a chat
383:16 - with you guys if you found that cool
383:18 - i think that yeah like it's so
383:21 - impressive like how many lines of code
383:23 - was it in total
383:24 - oh even when you zoom in look at
383:26 - that and guys that's a really good
383:27 - example bro because they're showing the
383:29 - actual dynamic
383:30 - width and height changing yeah yeah
383:33 - that's awesome
383:36 - all the wheels man cool 900 likes
383:40 - as well guys
383:40 - that is insane thank you guys
383:45 - but yeah guys that's pretty much the
383:49 - completed app um there's other things
383:52 - you could probably do to clean up the
383:53 - code you could probably pop some of this
383:54 - stuff in a function you know i just kind
383:55 - of blobbed it all in one go
383:57 - um so not very good code design here uh
384:00 - but other than that yeah i mean we went
384:01 - over the
384:02 - using the face detectors and small
384:04 - detectors using xml files which are
384:06 - pre-trained if you want to learn how
384:07 - these actually work then you can watch
384:08 - the other streams
384:09 - for the actual algorithm um of how that
384:13 - works
384:13 - uh we captured the the webcam footage
384:16 - we're iterating
384:17 - um forever until we're done with the
384:19 - webcam footage we're reading every frame
384:21 - one by one
384:22 - and then for the current frame we are
384:24 - doing a quick check to make sure the
384:25 - frame is good to go
384:26 - then from the frame we're creating the
384:28 - green the frame grayscale
384:30 - so that we can optimize it and we can um
384:32 - speed up the process and the
384:33 - calculations
384:34 - uh once we have a grayscale frame then
384:36 - we find faces within that frame
384:39 - then from all the faces we want to
384:41 - actually draw the rectangle around each
384:43 - face nice and then from each face you
384:45 - want to create the subarray using the
384:47 - numpy
384:48 - slicing here the the um which is numpy
384:51 - under the hood
384:52 - so we got the little sub right here
384:53 - which is the same um data in memory as
384:55 - the regular frame so when we edit this
384:57 - little subreddit it's still going to
384:58 - edit the mainframe
384:59 - yep the mainframe then then we change
385:02 - the face to grayscale
385:03 - um so we can run small detection on the
385:05 - face
385:07 - and then from there um
385:11 - uh once we have that then we can just
385:13 - label it as hey we found a smile
385:16 - instead of drawing the rectangles right
385:19 - so
385:20 - remember guys what we did that nested
385:22 - approach for when we were drawing
385:24 - uh where did that happen again aaron so
385:25 - where we avoided doing it for everything
385:28 - we did it for
385:29 - just the smiles it was line 38 right
385:34 - yeah yep nice
385:37 - that's so cool and then you put the text
385:40 - there
385:40 - and then um at the end then once we have
385:44 - once we have the once we found the face
385:46 - drew the rectangle
385:47 - found the smiles wrote the word smiling
385:50 - once we've done all that and we've
385:51 - edited the complete frame
385:52 - and all the the correct rectangles and
385:54 - words are on the frame at the right
385:56 - locations
385:56 - at the very end of all that at the end
385:58 - of the end of the detection
386:01 - we uh use cv2.imageshow just to show the
386:04 - frame
386:04 - and then we wait for one millisecond and
386:06 - then we repeat to the second frame
386:08 - so all of that's happening every single
386:09 - frame all of this code
386:11 - dude it's insane like if you actually
386:13 - think about it like let's say we went
386:15 - ahead and got rid of the comments and we
386:16 - got rid of everything
386:18 - that's so little code to get that
386:21 - powerful functionality happening
386:22 - right so let's actually do that yeah so
386:24 - let's make this super optimal
386:26 - nice yeah guys drop in the comments how
386:29 - many lines of code you think this might
386:30 - be
386:31 - if we can if we can do that before aaron
386:32 - gets to the top
386:35 - i'm gonna say maybe like 30 i'd say
386:38 - maybe
386:41 - i think it'll be that around there this
386:42 - is insane though like if you used to do
386:44 - this kind of thing in like javascript
386:45 - you would have to write more and i'm a
386:47 - big fan of javascript but
386:48 - i will say it first time like in python
386:50 - you can get a lot of power out of this
386:52 - uh we're just having small amount of
386:54 - code so that's that's still oh again
386:56 - but okay we're near 30.
387:01 - anybody anybody want to put money down
387:05 - dude 22 bro i mean this doesn't even
387:09 - count
387:09 - this doesn't even count holy crap that's
387:12 - insane and actually this because it's
387:14 - just a break statement you could
387:15 - probably get away with doing this i mean
387:16 - probably not good but i'm cheating
387:18 - because i just fall off
387:19 - that's insane we have machine learning
387:22 - ai
387:23 - everything invoked in there at like 22
387:27 - 21 lines of code so yeah oh my god was
387:30 - close he said that 25 abbas
387:32 - abdelius of 32 young ipsex
387:36 - guys it's less than we all thought like
387:37 - somebody wrote one i don't think we
387:39 - could do one
387:40 - i mean just pop this in a function you
387:42 - know just oh yeah
387:44 - section it's fine
387:48 - that's insane i love that dude that's so
387:51 - so cool man like um
387:53 - yeah that's awesome and guys i think
387:55 - this also goes to show you
387:58 - yeah there you go that's that's the hack
388:00 - to everything guys one line
388:03 - nice
388:06 - i'm doing it bro i'm doing it one second
388:08 - just for that guy because
388:10 - i got nothing better to do with my life
388:11 - i see a lot of people saying like this
388:13 - is
388:13 - like calling uh the ha cascade ai
388:16 - isn't really ai guys anything you have
388:19 - when you have a classification model
388:21 - that is current that comes under ai and
388:24 - trust it take it from a guy who's done a
388:25 - masters in this stuff like
388:27 - it is a like that is that is what we
388:29 - classify yeah
388:30 - if you want to if you want to go see how
388:32 - these are actually generated because we
388:34 - did just download this and just used it
388:35 - but
388:36 - if you want to actually see how you
388:37 - create this like how you can train
388:38 - anything to like
388:39 - like recognize what pepsi cans recognize
388:43 - uh coffee mugs whatever you want then i
388:45 - explained that in the face detection
388:47 - video this is like an extension using
388:48 - smiles but
388:49 - i explained that in face detection and
388:50 - the car and pedestrian tracking of like
388:52 - actually how the algorithm actually how
388:53 - the computer actually learns this
388:55 - like how the hell does the computer take
388:57 - an image and know how does the brain
388:59 - like how does it use its brain to figure
389:01 - out what it is so i
389:02 - i explained that there um but it is ai
389:04 - because this is how
389:06 - computers can learn it's not just random
389:08 - stuff
389:09 - yeah and that's the powerful thing guys
389:11 - like once you have trained models and
389:13 - like a lot of people
389:14 - i think even in firebase there's a bunch
389:16 - of like uh trained models that you just
389:17 - have access to
389:19 - which i'll be dropping some videos on so
389:20 - thumbs up if you if you're excited for
389:22 - that
389:22 - but um yeah like you can pretty much go
389:25 - ahead and use pre
389:26 - guys to train a model from by yourself
389:28 - you need to take a long time
389:30 - yeah you need a massive amount of data
389:32 - that's why things like tesla
389:34 - everything gets better over time because
389:36 - you get more data over time which means
389:38 - the model can get more accurate
389:40 - yes like it's not super feasible for us
389:42 - to train our own
389:44 - um if you understand how the algorithm
389:46 - works and then you utilize it that's
389:47 - really all you need to know to innovate
389:49 - we could technically i could technically
389:51 - go and take
389:52 - fake like get faces from the internet a
389:54 - bunch of different faces a bunch of
389:55 - different smiles and find those pictures
389:56 - and trim them all myself get the data
389:58 - set
389:58 - and then run it through some some
390:00 - training software to do it but then even
390:02 - that that's just an extra step of just
390:03 - taking images plugging into this
390:05 - this thing and then going up if you
390:06 - actually want to code up this algorithm
390:08 - that gets pretty deep and nasty i did it
390:10 - i did that at my schooling at georgia
390:12 - tech
390:12 - um it's interesting and fascinating but
390:14 - it's a big headache so like why reinvent
390:16 - the wheel so we're doing that here but
390:17 - if you want to get down in the
390:18 - nitty-gritty
390:19 - then uh by all means go through it
390:21 - there's a there's a free computer vision
390:23 - course
390:23 - from georgia tech on udacity you can
390:25 - look it up it's called computer vision
390:27 - they talk about all this stuff in
390:28 - complete detail
390:29 - they talk about other object tracking
390:31 - like common filters
390:33 - and uh cnns which are convolutional
390:35 - neural networks which is another way to
390:36 - do like tracking and object detection
390:38 - um but har cascade is just the simplest
390:40 - way that i'm showing you because you
390:41 - just download this one file
390:43 - and then you pop it into opencv and it's
390:45 - all nice and free and easy to use
390:47 - but yeah if you do want to get deep in
390:49 - you don't do like legit ai
390:51 - this is just this is like baby stuff
390:52 - compared to real stuff like even me i
390:54 - haven't done too much
390:55 - i haven't worked at tesla on
390:56 - self-driving cars unfortunately i wish i
390:58 - have
390:59 - but um you can get some you can get go
391:01 - pretty deep so if you want to check that
391:02 - out then by all means go check out
391:04 - opencv
391:04 - the opencv course and uh feel free
391:08 - to just go ham yeah for those of you who
391:11 - are javascript developers you can use
391:12 - something like tensorflow
391:14 - tensorflow is pretty much a very similar
391:16 - thing to what we use here
391:17 - but it's not cv2 it'll be tensorflow and
391:19 - then you can actually go ahead and get
391:21 - models
391:21 - just like the hard cascade um and you
391:23 - pretty much plug them into your
391:25 - tensorflow
391:25 - and do the same thing as what we did
391:26 - today so what i challenge
391:28 - everyone on this stream right now to go
391:30 - and do is actually go ahead and like
391:32 - follow along this tutorial build your
391:34 - get it working on yourself
391:35 - but go ahead and swap the um the hard
391:38 - cascade one that you're using and try
391:40 - and detect like an eye or something like
391:41 - that
391:42 - that'd be kind of cool yeah
391:51 - try and detect like an eye or something
391:53 - like that that'd be kind of cool yeah
391:55 - yeah yeah there's there's literally an i
391:56 - one like if you just the google it the
391:58 - opencv documentation
391:59 - or the github github repo there's the i1
392:02 - where you can detect eyes as well
392:04 - um we could even do it really quickly
392:05 - why don't we just do it on the fly
392:06 - really quick as a bonus i'm supposed to
392:08 - be done here but let's uh
392:09 - let's do it because i actually have
392:12 - because i have it downloaded already
392:13 - the eye because i was going to do that
392:15 - but i was like it's not important for
392:16 - small detection but
392:18 - let's do it really quick okay what time
392:20 - is it it's 41
392:21 - okay i'm gonna how fast can we do this
392:24 - let's do it
392:26 - all right boom i dot xml uh
392:30 - in the comments right now let him let's
392:32 - get let's get him let's get him in that
392:34 - flow state
392:35 - uh eye detector so we're gonna want to
392:38 - get is
392:41 - okay so the face we have the face face
392:44 - grayscale
392:45 - smiles smile detector
392:48 - eyes is going to be
392:56 - um
392:58 - eyes will be eye detector dot detect
393:02 - multi scale
393:06 - face gray scale and
393:09 - uh skill factor i don't i didn't tune
393:11 - the eyes so like it might not work
393:13 - but um yeah we'll just we'll see how it
393:17 - goes so eyes equals that
393:18 - yep then we're going to want to draw the
393:21 - smiles
393:22 - and then also we're going to want to
393:23 - draw the eyes
393:26 - and eyes
393:30 - yeah why don't we just go double this is
393:32 - very sloppy but i mean i just
393:37 - well actually i can just use this
393:38 - because the for loops aren't overlapping
393:40 - so let's just leave it like this
393:41 - yeah and then um the i
393:45 - okay and let's just change this to
393:49 - 255 25
393:52 - and 255 in
393:56 - eyes grayscale so this
394:00 - should work nice
394:03 - i mean it should let's see if it works
394:05 - guys if it works
394:06 - destroy that thumbs up button because
394:08 - aaron just done that on the fly
394:10 - like oh the eye is not defined i have a
394:12 - typo somewhere
394:13 - oh i was going to say that yeah because
394:15 - you have the eye but we need to splice
394:16 - it or
394:17 - slice it sorry right
394:20 - oh oh um nope i mean the face
394:24 - okay that's what it takes
394:32 - oh snap dude
394:36 - mouths and eyes look kind of similar
394:38 - sometimes you know
394:39 - you can kind of see yeah let's try to
394:41 - tune it we gotta tune it a little bit
394:43 - let's tune the variables a little bit
394:44 - and see if we can get it working better
394:47 - so that's what that's where these two
394:49 - things come in handy
394:50 - scale factor in mid neighbors so i'm
394:52 - there's probably some ideal number let's
394:54 - just try like i don't know 1.3 and
394:57 - 10 and see what happens okay like some
395:00 - iron man video
395:04 - okay okay not quite not quite let's try
395:07 - 1.1
395:08 - and 10.
395:14 - oh again that dude
395:18 - so what what what was the phone oh i
395:20 - just need to i just because i'm asian
395:23 - but if i open my eyes big it works
395:27 - it's not creepy as hell but
395:30 - like big eyes big smile then it can get
395:32 - it it can get it nicely
395:33 - that is awesome
395:37 - the greatest ever let's get this to 1k
395:39 - likes everyone i think we do
395:42 - yeah this this kind of stuff this kind
395:43 - of stuff is what snapchat instagram use
395:45 - on their filters you know like when you
395:46 - like vomit the rainbow and stuff they're
395:48 - like
395:48 - ah and then when they see it they can
395:51 - locate it and have it like drip down
395:52 - stuff like that so this is actually
395:54 - what's going on behind the scenes when
395:55 - using a snapchat filter like the selfie
395:56 - camera and you know you have like the
395:58 - crazy filters over your face this is
396:00 - what it's doing behind the scenes
396:02 - it might be using convolutional neural
396:04 - networks instead of
396:05 - hard cascades but this is similar
396:07 - principles yeah they would have a model
396:09 - that's already
396:09 - sitting there that's already ready and
396:11 - it's just the input would be the camera
396:12 - that you're saying output being that
396:13 - little tongue
396:14 - emoji or like the dog thing whatever
396:16 - you're using yeah nice
396:21 - yep that's it
396:24 - and about what that took four minutes to
396:25 - get the eye up and running so it's the
396:28 - power of python
396:29 - and having pre-trained of course if you
396:30 - train yourself it's gonna take hours or
396:32 - days
396:33 - or weeks if you have to get your own
396:34 - data it depends where you did it if
396:36 - you're taking your own photos with your
396:37 - own
396:38 - phone you gotta it's gonna take forever
396:42 - or you can just what people have done
396:44 - you got some you got some good comments
396:45 - coming in and says aaron you are awesome
396:48 - aaron apparently not at numpy
396:52 - whoever in the comments i don't know who
396:54 - you were but thanks man you saved you
396:55 - saved my ass
396:56 - man or man or woman whoever that was
396:58 - much appreciated
396:59 - i could stop embarrassing myself the
397:01 - greatest ever says
397:02 - that's amazing information i'm going to
397:04 - squeeze that in when i'm being
397:05 - interviewed
397:06 - that's that's awesome dude that would
397:07 - impress them yeah i will impress
397:09 - this is the real smile look look at that
397:15 - it's so funny
397:18 - that was nice we could we could even be
397:20 - like we could even like have a diamond
397:22 - changing like smiling and wide-eyed
397:24 - like or unasianified or something you
397:26 - know you could be like smiling and have
397:27 - like another piece of text like
397:28 - unasianified underneath let's do that
397:30 - dude you know what you could do i reckon
397:32 - there's probably some kind of model
397:34 - there which tells you the ethnicity of
397:36 - someone and then you have the
397:38 - sensitivities based on ethnicity
397:41 - oh that'll be it'll be hilarious but
397:43 - let's just here let's just look at this
397:44 - code if length of
397:46 - eyes i mean is that racial profiling is
397:49 - that like racist
397:50 - no i mean i mean we've got one we've got
397:53 - one asian we've got one brown
397:58 - asian fried let's just do so literally
398:00 - the greatest ever just said unasianified
398:06 - there we go here let's try this right
398:08 - aaron you're a good teacher i like it
398:10 - nice oh wait uh
398:13 - i think we need to tune this a little
398:15 - bit better to
398:16 - eyes needs to be maybe 20.
398:19 - let's try this and this is way too much
398:21 - let's try
398:23 - 90 and quit this out here
398:33 - [Laughter]
398:39 - i love that
398:48 - that's i think we gotta tune a little
398:50 - bit more let's try uh let's try 30.
398:53 - bro i'm still there i'm supposed to go
398:54 - work out my friend but that's what was
398:56 - probably
398:57 - 20 minutes ago but this the numpy thing
398:59 - you know i really put a cog but
399:01 - whatever oh man
399:05 - oh wow tyler shaw says that's the most
399:08 - amazing live video of programming ever
399:10 - we love that dude that's insane that's
399:13 - furious with my eyes bro
399:17 - and look at the light on my face better
399:25 - so funny i'm having so much fun with
399:27 - this man i wish i could uh
399:29 - send it to you but yeah i do gotta get
399:31 - going no
399:33 - dude you've crushed that and you we
399:34 - didn't even plan on getting the eyes
399:35 - done so we got the eyes in there
399:37 - i mean yeah that's the power of
399:38 - pre-trained models they also have like
399:39 - dog and cat let me just pull up the open
399:41 - cv real quick
399:42 - where did my chrome go oh it's in full
399:44 - screen
399:45 - so if you just go to opencv um
399:48 - har github then
399:52 - you go here hard cascades they have all
399:53 - these pre-trained opencv is like open
399:55 - source so it's free and
399:56 - low weight uh the algorithms and stuff
399:59 - they use at facebook and snapchat like
400:00 - in instagram for real they're trained
400:02 - even better than these are that's why
400:03 - they're so much more accurate
400:05 - these are just kind of like halfway
400:06 - there but they're also like pretty old
400:08 - but here
400:08 - here's the eye um i tree eyeglasses i
400:12 - don't even know what this is
400:13 - uh this is the frontal face default
400:15 - we're using for frontal face
400:17 - there's other frontal faces see how much
400:18 - is frontal cat face
400:20 - uh full body this is what used for the
400:22 - pedestrian tracking
400:24 - um for cars i had to download a heart
400:26 - xml file from somebody else it wasn't
400:28 - provided by opencv but you can go
400:30 - you can find other trained models too
400:32 - like is once an xml file is created from
400:34 - any object section then you can just
400:35 - download and use it for yourself so like
400:37 - here uh like this is literally what i
400:40 - typed in
400:44 - there har car has hard cascade xml file
400:47 - i went here
400:48 - i clicked on it and then i um
400:52 - i literally just downloaded the xml file
400:55 - uh
400:55 - from some it's somewhere linked in here
400:57 - but you can find the xml file once you
400:58 - find it
400:59 - so like literally it could be anything
401:00 - it could be like like what else what
401:01 - else besides car is cool to
401:03 - identify um um
401:07 - our cascade file uh
401:10 - i mean that one might not exist but i
401:12 - mean
401:14 - here soccer ball cascade so use yeah
401:17 - there soccer ball cascade.xml
401:20 - and then so this could probably detect
401:21 - soccer balls in a video without a
401:24 - video or something like that so like
401:25 - it's generic object detection you can
401:27 - you can detect any object
401:28 - um any arbitrary pattern yeah you know
401:31 - in a in a frame so
401:32 - that's the power of that using using my
401:35 - aaron just showed you that
401:36 - you can easily detect like some balls
401:38 - you know like
401:42 - are your your balls round like a soccer
401:44 - ball or are they
401:46 - are they excited like a rugby or
401:48 - football
401:52 - yeah but here there's hard cascades
401:53 - there's also some here there's hog
401:54 - cascades so
401:56 - hog stands for
401:59 - hog is like another way to do it it's
402:00 - like optimization for horror or some
402:02 - something i forget what it stands for
402:04 - but it's another objection algorithm
402:06 - thing that you can use
402:07 - um but here we have all these and then
402:10 - there's cats
402:11 - and uh or if you go into hog what is in
402:15 - here
402:15 - pedestrians okay but
402:19 - yeah guys that's that's it smile
402:21 - detection and asian detection asian
402:23 - asian person detection in um in python
402:26 - awesome
402:27 - guys if you guys enjoyed that let's give
402:29 - aaron a massive thank you because i
402:30 - think he crushed it today with that and
402:32 - even i learned so much
402:34 - with this uh tutorial today so like i
402:36 - thought it was cool thank you aaron that
402:38 - was amazing dude
402:39 - welcome sonny thanks for streaming for
402:40 - me because my computer's a computer is a
402:42 - rock
402:43 - sorob singh says aaron and sunny looking
402:45 - for some more in the future
402:46 - cheers yeah we would definitely be doing
402:48 - more that was fun definitely yeah i am
402:50 - planning on doing some tensorflow
402:52 - because i've kind of exhausted this open
402:53 - cv stuff we got three streams on it but
402:55 - i do want to get into tensorflow and
402:56 - maybe even pi torch
402:58 - yeah um like something mentioned so
402:59 - maybe in the next few weeks
403:01 - stay tuned for that i might have like a
403:02 - tensorflow like crash course stream or
403:04 - something like that
403:04 - yeah they will actually train a model
403:06 - ourself with uh with
403:07 - somebody else's picture data i'm not
403:09 - gonna do it myself yeah but
403:11 - i'll find some online data set of a
403:12 - bunch of images and we can maybe train
403:14 - something
403:15 - and you can watch the neural net get
403:16 - created and then we could do something
403:17 - like this again
403:18 - that would be dope dude that'd be
403:20 - awesome yeah i think um
403:21 - also worth mentioning guys for anyone
403:24 - who joined and maybe missed this in the
403:25 - beginning
403:28 - what's lingering in the description
403:30 - right now
403:32 - yeah so yeah yeah if you guys like
403:34 - coding in python if you enjoyed this and
403:35 - want to do this for a living then that's
403:37 - what we do a clever programmer so we
403:38 - teach people how to take their coding
403:39 - skills
403:40 - and make money from it as uh web
403:43 - developers with javascript as
403:45 - python developers python freelancers
403:47 - whatever it is you want like automating
403:49 - stuff with python
403:50 - or whatever then go check the link in
403:52 - the description there's a free training
403:54 - that teaches you how to do that
403:55 - uh and then there's also a full-blown
403:56 - course that you can join if you want to
403:58 - invest some money into that in time and
404:00 - actually uh pursue becoming a python
404:03 - developer as
404:03 - your career choice if not then feel free
404:05 - to enjoy your free content
404:07 - that's what this is here for and you
404:08 - know make asian stupid stupid-ass apps
404:10 - like this
404:15 - [Laughter]
404:17 - my mom would smack me yo respect your
404:19 - culture
404:20 - okay i love you mom you eating the
404:32 - [Laughter]
404:36 - then ah yeah that's the truth isn't it
404:40 - yeah we're all dropouts here aren't we
404:43 - that's awesome dude i think if there's
404:45 - aaron got any last few things you want
404:46 - to add oh
404:47 - we also got a donation thank you saurabh
404:49 - singh just dropped a nice little
404:50 - donation there appreciate that dude
404:53 - and lots of wicked comments coming in
404:55 - yeah nice i
404:57 - think the last thing with hilarious
404:58 - would be uh actually get rid of the
405:00 - boxes
405:01 - what was that and then um it would be
405:04 - hilarious get rid of the boxes you just
405:05 - have like
405:06 - the full clean app let's do this last
405:07 - demo because i'm i'm all hyped
405:11 - what's that hey let me go ahead and try
405:14 - it on that
405:16 - there we go
405:26 - i think i think it's okay when you when
405:28 - you're you're the same race it's all
405:29 - good
405:32 - half audition if i uh anyways okay i'm
405:35 - gonna stop
405:35 - goofing around because now we're just
405:37 - wasting time
405:38 - all right yeah so if you guys wanna
405:40 - check out the the free training or the
405:41 - course then it's in the description
405:43 - um if not then keep watching our daily
405:44 - streams i think we've been going for
405:46 - what like
405:46 - four weeks now straight i think it's
405:48 - longer dude i think we've gone over
405:50 - a month and a half now yeah how have we
405:53 - not run out of like
405:54 - project ideas dude we have so many
405:57 - project ideas now
405:58 - still to come like tomorrow's a big
406:00 - build another massive build coming up so
406:02 - we'll be amazing what's that yeah yeah
406:04 - we have what's up tomorrow stay tuned
406:06 - guys
406:06 - go ahead and literally set a reminder on
406:08 - your phone right now
406:09 - for that and we're doing that was it in
406:12 - i think it's
406:14 - 9 15 est and 6 15
406:17 - bst that's my time yeah uh yeah so
406:21 - awesome guys
406:22 - hope you guys enjoyed that and with that
406:24 - said uh
406:25 - make sure if you're not following us
406:27 - already go ahead and check us out we
406:28 - always posting some content so you've
406:30 - got me and aaron over there and we'd
406:31 - love to have a chat with you guys
406:32 - but yeah i think i think aaron needs to
406:34 - go and hit uh hit a workout
406:37 - yeah eat some food more coffee totally
406:40 - sleep deprived
406:41 - but yeah guys thanks for joining me in
406:43 - sunny and coating this up there's a lot
406:44 - of fun
406:45 - and uh we'll do it again featuring some
406:47 - time right hulk that's it dude we'll do
406:49 - it again samurai
406:51 - yeah yeah yeah
406:55 - what time all right guys peace out peace
406:59 - out guys
407:00 - thank you
407:13 - so today we're going to be coding up a
407:15 - image classifier
407:17 - app in tensorflow and we're going to be
407:19 - extending a little bit from last week
407:21 - and uh we're going to be building a
407:22 - slightly more advanced uh
407:24 - a slightly more complicated neural
407:26 - network here and we're actually going to
407:27 - be using
407:28 - tensorflow to be able to classify
407:29 - different images so i'm i have this data
407:31 - set here
407:32 - uh that has a bunch of different images
407:34 - of different kind of
407:36 - clothing pieces so shoes and shirts and
407:38 - bags and stuff i'll show you guys a
407:39 - little bit more in a bit
407:40 - but the idea is that we just want to
407:41 - train our neural net on a bunch of these
407:43 - little pixelated images of different
407:44 - clothing types and then
407:46 - eventually be able to recognize these
407:48 - images and classify them correctly
407:50 - uh going forward on on new unseen data
407:52 - so that's kind of what we're good
407:54 - what we're going to be doing today
408:02 - okay let me see if i can find some other
408:05 - other data in here too
408:08 - let me close this i want to show you
408:10 - guys a couple of the pictures i think
408:12 - there is a
408:12 - there was a link i found but i i lost it
408:14 - that had like a better
408:16 - okay here we go so this worked fine so
408:18 - this is another uh
408:20 - image that we're gonna be using so this
408:21 - one kind of looks like a shirt as you
408:22 - guys can
408:23 - probably see and um this data set is
408:26 - actually really big it's actually built
408:27 - into tensorflow because it's kind of
408:29 - like the introductory
408:30 - data set that people can use for image
408:33 - classification so let me
408:34 - look at a couple more and see if um
408:38 - there's a few that we can
408:43 - look at together okay so this one kind
408:44 - of looks like address i guess
408:48 - and let me just keep going through the
408:49 - data a couple more
408:57 - yeah another address here and i think
408:59 - you guys are getting the idea so this
409:00 - basically
409:01 - there's just a bunch of images there's
409:03 - like 70 000 images of different
409:05 - um clothing pieces and what we're going
409:07 - to be doing is we're actually going to
409:08 - be training our null net on about 60
409:10 - 000 of 60 000 of those images and uh
409:13 - properly classifying and training the
409:14 - neural net and then on the remaining 10
409:16 - 000 images we're going to want to
409:19 - actually use that as our test data to
409:20 - see how accurate our
409:22 - our neural net is
409:25 - all right awesome so let's uh get back
409:28 - to the code
409:29 - so yeah i showed you guys a bunch of
409:30 - those images so the idea um is we're
409:32 - going to code up a neural network
409:34 - and um i'm going to kind of like go step
409:36 - by step of how we would solve this
409:38 - problem
409:38 - so the the thing we're trying to achieve
409:40 - is we have 70 000 images
409:42 - of different clothing pieces like we
409:44 - have and there's actually ten different
409:45 - types if i go back to the
409:47 - documentation here um there's ten
409:50 - different types of clothing here and
409:51 - they're just labeled
409:52 - zero zero through nine just for
409:53 - simplicity so as you can see like the
409:55 - first one was an ankle boot like let me
409:57 - go back
409:58 - uh to this and let's just show the first
410:01 - one again
410:02 - and print this out
410:09 - as you can see here this kind looks like
410:10 - an ankle boot or a shoe but i guess they
410:12 - call it ankle boot
410:14 - and uh the label is nine so actually let
410:15 - me show you the the label too just so
410:17 - you guys can get a little bit familiar
410:18 - with the data
410:19 - uh there we go so labels
410:24 - add zero so yeah so um i pulled this
410:27 - data
410:28 - or let me actually show you guys
410:31 - um i should show you guys this in a
410:32 - second let me just show you the label so
410:34 - here i'm actually printing out the label
410:35 - for the
410:36 - for the first image here which is a zero
410:38 - and then this is the shoe
410:40 - like i i just showed you guys but when i
410:42 - print it out it'll actually give us the
410:43 - label as well
410:44 - so i'm going to be quit out of this
410:49 - and run this
410:53 - and as you can see so this is a shoe and
410:55 - it actually print out the label of nine
410:57 - and if we go back to the data here you
410:59 - can see that nine uh corresponds to
411:01 - ankle boots so
411:02 - pretty simple there's 70 000 of these
411:04 - images of different things and then each
411:06 - of them has a label attached to it
411:08 - so we'll be using this data to train our
411:10 - neural network and then uh we'll be
411:11 - using another subset of this data to
411:13 - actually test our network to see how
411:15 - accurate it is
411:16 - and uh it's uh pretty good yeah as you
411:18 - can see here so the fashion
411:20 - this is called the fashion mnist data
411:21 - set um mnist is this thing i actually
411:23 - don't know what it stands for but i mean
411:24 - there's a lot of like pre-trained and
411:26 - pre-labeled data sets that
411:27 - mnist uh provides for us there's like uh
411:30 - there's like handwriting ones and
411:31 - and other stuff so um this one just
411:33 - happens to be like a bunch of fashion
411:34 - stuff
411:35 - uh and yeah as we said here i just
411:38 - mentioned this
411:38 - we're going to be using 60 000 um images
411:41 - grayscale images of different
411:42 - different clothing pieces and then we'll
411:43 - use the remaining 10 000 for for testing
411:46 - so uh now let's just jump into the code
411:48 - and let me start explaining these
411:50 - uh each line one by one so you guys can
411:52 - can follow along and everything will
411:53 - make sense
411:54 - [Music]
412:02 - any questions up to this point or is
412:04 - everybody uh following the law
412:07 - following along perfect
412:11 - what is this uh thing i have heard a lot
412:15 - about
412:15 - it like what this is karis is like uh
412:18 - okay let me just spend
412:20 - a quick second on this it's basically
412:22 - like a
412:23 - or let's just go to the actual
412:24 - documentation
412:26 - so it's just like a library that allows
412:28 - you to like build neural nets so
412:30 - um tensorflow itself like is like a
412:33 - wrapper or
412:34 - it utilizes keras because kerose allows
412:36 - you to like make like
412:38 - um graphs in different structures like
412:39 - graph structures so it's perfect for
412:41 - neural nets
412:42 - and you can look into it if you want the
412:44 - idea is though that just tensorflow is
412:45 - just built on top of keras like it
412:47 - utilizes
412:48 - terrace uh keras to build the neural
412:50 - nets and all the other graphs
412:52 - so and like you can also think of it
412:53 - like a neural network
412:55 - you know the basis neural networks and
412:57 - on top of that machine learning spirit
412:59 - right
412:59 - so machine learning is actually like so
413:01 - in neural network
413:02 - a part of machine learning and karaoke
413:04 - allows us to do that
413:05 - yeah that's a good way to explain it
413:07 - yeah so keras is good for creating
413:08 - neural networks but then tensorflow is
413:10 - actually good for
413:11 - pumping data through that to actually
413:12 - achieve machine learning and like
413:14 - solve machine learning problems but
413:16 - keras is just for building the structure
413:17 - like the data structure
413:19 - and defining that and then tensorflow on
413:21 - top of that allows you to like oh train
413:22 - and import data
413:24 - and pump the data through and do all the
413:25 - number crunching
413:29 - does that make sense from zero
413:33 - yeah i think that i think so this is
413:34 - basically that guys
413:39 - yeah all right so let's just start going
413:40 - through all the code here so that you
413:42 - guys can
413:43 - follow along and then i'll answer any
413:44 - questions as we go but this one's going
413:46 - to be a little more interesting than
413:48 - last week
414:05 - so uh let's just start one by one so
414:07 - this stuff up here you guys can actually
414:08 - pretty much ignore this i was running
414:09 - into some
414:10 - downloading errors when i was trying to
414:11 - download the data i just had to do some
414:12 - permission stuff so just completely
414:14 - ignore this
414:15 - um the proper way to do it is to
414:16 - actually uh
414:18 - install a different package on your
414:19 - computer but i just pop this this hacky
414:21 - thing in the code so just ignore it i'm
414:23 - just gonna
414:24 - not even show it um so let's start here
414:29 - we just go one by one and uh of course
414:31 - we want to import tensorflow
414:33 - uh that's the first thing we're going to
414:34 - want to do and then also import keras
414:36 - because we're going to need both
414:37 - and also done pi because numpy is how we
414:40 - are going to be dealing with all of our
414:41 - data
414:42 - so actually uh like this here this is
414:45 - actually just a numpy array so this
414:47 - image
414:48 - is um a 28 by 28
414:51 - grid of grayscale images and um
414:54 - it's actually stored as a numpy array so
414:56 - we need numpy to
414:58 - uh to hold this data and then we're just
415:00 - going to be pumping it into our donet
415:02 - so that's what we need numpy here
415:05 - and then also we need uh matplop just uh
415:09 - uh map flop is just to
415:13 - display the images so that's why i'm
415:14 - displaying it here um so you guys can
415:16 - kind of just ignore that it's just for
415:18 - for visualization purposes
415:28 - so this is where the code actually
415:29 - starts
415:31 - um so the first thing we're going to do
415:33 - for any kind of machine learning thing
415:34 - is we're going to need
415:36 - a bunch of data so unfortunately for us
415:39 - they have this
415:40 - all of this labeled data like with the
415:41 - shirts and shoes and stuff already
415:44 - pre-installed in tensorflow for us so
415:46 - it's as simple as just downloading it
415:47 - here and just accessing the built-in
415:49 - data set
415:50 - which is nice um in the real world if
415:52 - you're trying to collect your own data
415:54 - which
415:54 - sometimes happens sometimes like if
415:56 - you're working on a team like i did this
415:58 - um at my i had a machine learning
416:01 - artificial intelligence paid internship
416:02 - thing
416:03 - where they actually went and would uh
416:05 - like capture their own data and you'd
416:06 - have to like
416:07 - label it yourself and it was kind of
416:08 - annoying um so i mean i guess you do
416:10 - have to do it in the field if you are
416:12 - if you are going to be doing that in the
416:13 - future but ideally you just have the
416:15 - data already labeled and somebody
416:16 - already did it for you um so that's what
416:18 - we have here a bunch of the data here
416:20 - so i'm just gonna get handle here to
416:22 - that data set
416:24 - and um you just do that by calling cara
416:26 - so within keras we have the
416:27 - the fashion mnist which is what i was
416:29 - just looking at in the documentation
416:30 - here um
416:32 - wherever it went i don't know where it
416:36 - went
416:36 - uh keras fashion
416:39 - feminist there we go
416:44 - so like i said keras has like these
416:47 - data sets built in so i just basically
416:49 - call this code so
416:51 - fashion.mnis.loaddata is what i called
416:53 - here
416:54 - um or actually i call it down here but
416:57 - this is
416:58 - uh this this is just like saving um the
417:00 - the handle to the data
417:02 - but down here uh you can just call
417:04 - fashionmnis.loaddata just like it says
417:06 - in the documentation here
417:07 - and we get the data in so this might
417:09 - differ if you're using a different
417:10 - dataset but for this dataset this is
417:12 - how we're getting it and the way this is
417:15 - returned is by default it returns um
417:19 - 60 000 of the images here for training
417:21 - and then the remaining 10 000 of the
417:23 - images here
417:24 - for testing so now we have these these
417:28 - four variables here that we can use for
417:31 - uh
417:31 - training and data so these are just
417:32 - simply just lists of a bunch of
417:34 - different images
417:35 - and whatnot this is actually how i was
417:37 - displaying all of the
417:38 - images so right here i'm displaying uh
417:40 - the first element of the training images
417:43 - which is actually this boot image that
417:45 - we see so
417:46 - uh very straightforward so if i index
417:48 - train images at zero then it just spits
417:50 - out this numpy array and then i just use
417:52 - uh matplotlib to display it so you can
417:54 - see that and then i showed you guys the
417:55 - dresses and stuff i like the first index
417:57 - and second index and it goes all the way
417:58 - up to 60 000. so
418:00 - uh that's how the data is structured so
418:02 - all you guys gotta
418:03 - remember really is just that these four
418:06 - these four
418:07 - variables here is how we're going to
418:08 - access our data so and then these are
418:10 - just lists of numpy arrays or
418:11 - images and and that's that's all it is
418:15 - this here is just for printing so we
418:17 - don't have to worry about this too much
418:19 - this is just using some matplotlib i'll
418:21 - actually show you guys this this is kind
418:22 - of interesting because you can even see
418:24 - the actual data in the terminal
418:26 - if i quit out of here
418:36 - oops
418:40 - there we go so what i'm doing here is i
418:43 - i get the data like i said i have the 60
418:45 - 000
418:46 - uh images and labels here and then the
418:48 - 10 000 images and labels here
418:50 - and all i'm doing is i'm printing out
418:51 - the label and then the actual image in
418:53 - the terminal so if you look in the
418:54 - terminal you can actually see like the
418:56 - the the data here so this is the actual
418:59 - image that we're seeing of the shoe but
419:00 - i mean of course it doesn't look like a
419:01 - shoe in here because it's just a bunch
419:03 - of numbers
419:04 - but um it's just a black and white image
419:07 - so on the range from 0 to 255
419:10 - is the uh range of numbers um that they
419:13 - can be it's just kind of like the
419:14 - brightness of each pixel but then that's
419:16 - reflected here so i'm just using
419:18 - matplotlib to show that and that's
419:19 - through the image shown in the show here
419:21 - so uh any questions up to this point is
419:24 - that is that pretty
419:25 - clear cut for everybody or does anybody
419:26 - have any questions is that just for one
419:28 - image
419:30 - yes yeah just for one image so we can
419:33 - actually
419:34 - get rid of this because i don't want to
419:35 - print it in the terminal and like
419:36 - clutter it
419:37 - but all that's happening here is i'm
419:39 - using uh matplotlib i just
419:41 - renamed it to plot for simplicity and
419:43 - then you call
419:44 - image show and then you just pop in
419:46 - whatever numpy array you want
419:48 - um and then this is just for uh making
419:50 - sure that it's it's a gray scale so you
419:52 - just
419:52 - kind of say like yeah it's the color map
419:54 - is gray scale and then min and max
419:56 - values is that
419:58 - um you have to specify those and then
420:00 - you just show it and then that's
420:02 - how the uh this image shows
420:07 - was that you tom was that it sounded
420:09 - like tom
420:11 - yeah it was yeah so i'm not well sweet
420:13 - i'm staying on mute
420:15 - oh goodness hold up make sure you drink
420:17 - some water and
420:19 - get some food in your something
420:22 - it's not the corona is it or that
420:25 - no no i had to get my kid tested it came
420:29 - back negative but it's just
420:30 - fluid yeah we all got tested here too at
420:33 - uh
420:33 - all the guys here clever programmer
420:35 - because we all kind of live together or
420:36 - work together on a daily basis and then
420:38 - we're all negative so that's
420:39 - positive sign because i know los angeles
420:41 - is kind of
420:42 - kind of iffy what is your
420:48 - is that the 28 by 28 that's the matrix
420:51 - matrices uh matrix that
420:53 - the 70 000 of 28 by 28
420:56 - yeah so uh if i go back to this data set
420:59 - then uh this predefined data set in
421:02 - keras is yeah a bunch of 28 by 28
421:04 - grayscale images of
421:06 - different fashion categories so like
421:08 - shoes or
421:09 - dresses and stuff that i showed you guys
421:11 - before
421:13 - so uh we keep it small just because
421:15 - there's so many and
421:16 - um if it's recognizable by a human by
421:19 - the eye then
421:20 - it's prob then it's are arguably
421:23 - recognizable to uh
421:24 - to a computer like if you if it's like
421:26 - if it was like two by two then yeah then
421:28 - you can't you wouldn't go to recognize
421:29 - it but 20 by 28 is like
421:30 - as small as they could get uh reasonably
421:33 - by still being recognizable as these
421:35 - different things what you printed out
421:40 - was
421:41 - because it didn't have 28 columns so
421:43 - what was the
421:45 - mapping of what you printed out again um
421:48 - you mean this or the actual the image
421:50 - when i produce
421:51 - that whatever that's showing yeah that
421:54 - 28 by 28 is that what that's
421:56 - representing well
421:57 - yeah this should be i mean it should be
421:59 - is it not 28 1
422:00 - 2 3 4 5 6 7
422:03 - 8 9 10 11 12 13 14 15 16 17 18
422:08 - 19 20 21 3 45 seconds yeah 20 so it is
422:12 - 28 so this is 28 long
422:13 - this is the first row and then this is
422:15 - the second row and then it just now it's
422:17 - just the formatting is kind of crappy
422:18 - that's why
422:19 - because i was dealing with it from the
422:20 - top only i didn't i didn't follow the uh
422:23 - ending yeah so this is just a
422:25 - two-dimensional numpy array so this is
422:27 - the outer wrapper and then each of these
422:28 - are the rows right
422:31 - and then yeah as you can see so like
422:32 - this is all zeros so like there's
422:34 - nothing on the top and then when we
422:35 - actually
422:37 - run it then you can see
422:43 - yeah that the whole top row is
422:44 - completely black which is what zero
422:46 - stands for because those pixels are off
422:48 - so the first row is all black the first
422:50 - row is all black there
422:53 - awesome so that's the data we're going
422:55 - to be dealing with and now we can
422:56 - actually jump into creating a neural net
422:58 - for it
422:59 - so let me just go line by line
423:15 - there we go so like last week
423:18 - uh we're going to be creating a very
423:20 - similar the the code is going to be very
423:22 - similar but
423:22 - the neural nets is actually going to be
423:24 - uh a lot more complicated but that's
423:26 - what's nice about tensorflow because it
423:27 - you're able to
423:29 - create really really complex neural nets
423:31 - and the code is is pretty concise and
423:33 - straightforward like it never gets too
423:34 - advanced and
423:35 - that's that's a really good thing so uh
423:38 - let me do a little recap too just so for
423:40 - anybody
423:41 - who doesn't remember let me annotate
423:47 - [Music]
423:53 - uh i think red is good okay can you guys
423:56 - see
423:58 - you guys can see me i'm annotating right
424:02 - yes all right cool so let's just have
424:05 - like a
424:07 - a sample neural net here so anybody who
424:10 - doesn't know what a neurologist it's
424:11 - just like a
424:12 - a bunch of different layers of nodes and
424:14 - they
424:15 - call them like neurons and then um
424:17 - they're all they're all connected so let
424:19 - me just draw this out really quick
424:22 - and
424:27 - there we go so
424:31 - um oh it's kind of covering the code
424:34 - here
424:34 - let me put out can you guys see down
424:37 - here this code down here
424:40 - so line 28 it says model um so the first
424:44 - thing we want to do when we're we have a
424:45 - machine learning problem or
424:47 - something like in tensorflow is you want
424:48 - to design our model in
424:50 - a way that will
424:54 - be compatible with our input data and
424:56 - also our output data
424:58 - so in this case for anybody who doesn't
425:00 - know a model is just a
425:02 - a neural net so this here is the example
425:04 - of a neural net that has three
425:05 - uh three layers so one input layer here
425:08 - with three
425:08 - three nodes um and then one hidden layer
425:11 - with four nodes and then one output
425:12 - layer with two nodes
425:14 - uh so this is kind of like a model that
425:16 - that um i just dropped here r is gonna
425:18 - look a little bit different but i just
425:19 - want to visually represent it here
425:20 - so um in keras like we we
425:24 - established earlier keras allows us to
425:26 - um define different
425:28 - uh graph structures so it's really good
425:30 - for for this purpose
425:32 - and um so that's we're utilizing keras
425:34 - here so keras uh there's a
425:35 - thing called sequential we were this
425:37 - last week and this just means that
425:38 - there's a
425:39 - sequence of horizon a vertical vertical
425:42 - columns like this
425:43 - of different layers and then they go in
425:44 - a row so
425:46 - um this this column of nodes can only
425:49 - connect to the next one and so forth you
425:51 - can't like skip and hop over
425:52 - so this is like the most um basic type
425:55 - so sequential is the first one we want
425:56 - to do
425:57 - and um we're gonna make this a
425:59 - sequential
426:01 - neural net so from there all we need to
426:04 - do is just within this list is just
426:05 - define all of the different layers that
426:07 - we have
426:08 - so let me get rid of this drawing real
426:10 - quick
426:14 - clear all drawings
426:21 - okay
426:22 - [Music]
426:30 - so um the sequential so for the first
426:33 - thing we want to do when we're dealing
426:35 - with
426:35 - a uh machine learning problem or or
426:38 - for for an old nets is we want to make
426:40 - sure that the input and the output is
426:41 - correct
426:42 - so for the first one remember let me
426:44 - just show you guys the first one
426:46 - the first layer um
426:51 - so the first the first layer that we're
426:53 - going to want to have in our neural net
426:55 - is going to be the input layer
426:57 - and as we know the data that we're
426:58 - dealing with is going to be a 28 by 28
427:01 - um
427:02 - image and those are the the the data
427:05 - we're going to be pumping in
427:06 - so the way i shouldn't deleted that
427:08 - neural net
427:15 - you see i'll just make a little bit
427:17 - simpler so i'm not going to draw the
427:19 - lines just because it's it's kind of
427:22 - long but
427:25 - something like that so um the idea is uh
427:30 - for our input
427:31 - we want to have a 28 by 20 input
427:34 - for um our input here a 28 by 28 matrix
427:38 - and uh what we want to do is we actually
427:39 - want to flatten that out into one
427:41 - long layer so the input layer actually
427:43 - each node is going to have one pixel
427:45 - um so that of of each of those images so
427:48 - that we can
427:49 - um pump in the the full data all the way
427:51 - across and then from there
427:52 - the data will filter through and
427:54 - eventually at the end will spit out be
427:56 - like okay
427:56 - is this a is this a boot is this a dress
427:58 - is this a shirt
428:00 - um and that's that's the overarching
428:02 - idea
428:03 - so
428:07 - um the first the the first thing we're
428:10 - going to want to do is yeah just
428:11 - make sure the first layer is compatible
428:13 - with our input so again
428:15 - we just we just call this here so it
428:16 - takes in a 28 by 28 image
428:19 - um and we actually want to flatten this
428:21 - so
428:22 - uh like i said each layer of the neural
428:25 - net is just one
428:26 - long vertical column of
428:29 - our our data and
428:32 - um so we want to make sure that we
428:34 - flatten this 28 by 28 thing into
428:36 - one flat one flat layer and then i think
428:39 - it comes out to 784
428:42 - 28 times 28
428:45 - yeah 784 so let me actually just copy
428:48 - this
428:49 - code out or the comments
428:56 - um yeah i wrote here so the flatten the
428:58 - flatten here just flattens this 28 by 20
428:59 - matrix into one
429:01 - um flat 784 by one input layer so
429:04 - actually this
429:05 - uh neuron that we that we started
429:06 - building up to this point so this only
429:08 - has one single layer
429:10 - will actually look like this
429:16 - annotate so uh it's sequential of course
429:20 - but right now we only have one layer
429:22 - and what this is gonna be is this is
429:24 - actually gonna have
429:26 - um a bunch of input layers here and this
429:31 - is actually gonna be 784
429:34 - uh long so this this whole
429:38 - input layer is gonna be 784
429:41 - um neurons long so this is the first
429:44 - layer okay
429:45 - and then we're gonna have a hidden layer
429:46 - and then we're gonna have an output
429:47 - layer
429:48 - uh but does does that make sense so far
429:50 - so that we have one little node for each
429:52 - pixel of each of these images
429:56 - [Music]
430:02 - is there a reason why you need to
430:04 - flatten it
430:06 - um it's to simplify it's to simplify the
430:09 - the structure of the neural net um
430:13 - it's because each each layer of the
430:16 - neural net is just a singular column
430:19 - so instead of treating it as a
430:20 - multi-dimensional array then we just
430:22 - kind of want to flatten it because
430:23 - at the end of the day like each pixel is
430:25 - just a piece of data it doesn't really
430:26 - matter where it is we can just kind of
430:28 - treat like okay the top left pixel is
430:29 - the top left pixel
430:30 - and as long as that's consistent across
430:33 - all the images when we're training and
430:34 - testing then
430:35 - it should be okay so it's just a way to
430:36 - simplify the data into one
430:38 - one long layer to make sure that every
430:40 - pixel is represented in a clean way
430:43 - is it more efficient more efficient it
430:47 - actually doesn't really matter
430:48 - like the implementation under the hood
430:50 - everything is just it's boiled down to
430:52 - optimize matrix multiplications at a at
430:55 - the lowest level like tensorflow
430:56 - abstracts all that away
430:58 - uh this here is just kind of to like
430:59 - make it more
431:01 - um understandable for like a human when
431:05 - you're thinking about a neural net like
431:06 - okay we have this long
431:07 - this whole input layer is just one long
431:09 - column and every single pixel has its
431:11 - own little node
431:12 - and then each of those pixels has its
431:13 - numbers so like if this was black then
431:15 - this would be like zero
431:16 - if it was white it would be 255 um in
431:19 - this node and then it's just every pixel
431:20 - is represented then we can kind of be
431:22 - like okay
431:23 - this set of numbers this long 784 list
431:25 - of numbers represents this first image
431:29 - like if i
431:34 - if i run this
431:42 - yeah so um this first input layer will
431:46 - just take like
431:46 - all of these this um all these pixels so
431:49 - the first row will just be like up here
431:50 - second then the second row would just be
431:52 - right after
431:52 - the third row will be right after that
431:54 - just going all the way down until the
431:55 - very last row
431:56 - and these last two pixels down here in
431:58 - the bottom right are these two little
432:00 - nodes here
432:00 - just so that every pixel is represented
432:02 - then from there we've fully
432:04 - um gotten all the data of this image and
432:06 - then from there we can kind of like
432:07 - tweak the
432:08 - the different parts of the neural net
432:10 - and eventually we will be able to like
432:12 - filter
432:12 - um this image through and then by the
432:15 - end of it it'll it'll spit out like okay
432:16 - this is an ankle
432:18 - uh ankle boot and not a shirt or
432:19 - something like that
432:26 - [Music]
432:28 - actually i've just thought of a question
432:30 - um why
432:31 - why is the um grayscale numbering from
432:34 - zero to two five five
432:36 - ah so um
432:41 - it's just a uh the way the computer
432:44 - hardware
432:44 - has been implemented uh like as
432:47 - computers evolve from like the 1940s
432:48 - till now
432:49 - uh 250 0-255
432:53 - actually just means there's 256 numbers
432:55 - because 0 is the first one
432:56 - so 256 is just the power of 2 so it's
432:58 - just a way to stand
433:00 - to encode the data so i think this is
433:03 - what 2 to the
433:05 - not two to the eighth yeah so two to the
433:07 - eighth which just means that there's
433:09 - eight it's just eight bit
433:10 - so this is an eight bit image of black
433:12 - and white
433:15 - that's all that means so we can be on a
433:17 - scale from
433:18 - yeah so this is that's the range of all
433:20 - the different steps there's 255 steps of
433:22 - colors
433:22 - from zero from black to white and then
433:24 - there's 255 colors of gray between that
433:27 - that you can
433:28 - um specify and that's all it is
433:32 - um okay let's go
433:38 - so if you didn't it would still
433:41 - it would still come out and
433:44 - your output would still be the same or
433:47 - um
433:48 - i actually don't know i mean i just
433:50 - always use flattened just because it's
433:51 - easier to understand
433:53 - i mean we can try because i mean
433:54 - remember last week we used dents and
433:56 - we're going to be using dents going
433:57 - forward
433:58 - um but this kind of just like just uh
434:02 - um defines it so it kind of what this
434:04 - does i
434:05 - i think is it has kind of like this 28
434:07 - by 28 thing
434:09 - and then um but it says hey just flatten
434:11 - that so there's actually a layer there's
434:12 - actually a matrices over here
434:14 - over here of 25 28 and then it just kind
434:16 - of like magically
434:17 - turns it into one layer and then we kind
434:19 - of just treat it as our first layer but
434:20 - it kind of like maps the matrices 28 by
434:22 - 28
434:23 - to this one single input layer which is
434:25 - simpler for our neural net design
434:28 - because ideally down the road we're
434:29 - going to i mean not ideally but we
434:32 - actually are going to be doing is
434:33 - creating like a
434:33 - another layer of stuff here and then at
434:36 - the end we'll have like
434:38 - um a bunch of different notes here
434:40 - that's just like okay what's the
434:41 - probability that this is a shoe
434:43 - versus uh you know probably versus a
434:46 - shirt
434:48 - it's really hard to write with this
434:51 - but and then so on and so forth and
434:54 - there's going to be 10 different ones
434:56 - as we saw here there's there's about
434:59 - um t-shirts trousers pull over's dress
435:01 - coat sandal
435:02 - sure all these so there'll be one of
435:13 - so yeah actually uh let's talk about
435:15 - that a little bit so what this our
435:17 - neural eventually going to look like is
435:19 - we're going to have this input layer
435:20 - which is just the image
435:21 - then we're going to have one hidden
435:22 - layer that's going to kind of try to
435:24 - capture the patterns
435:25 - of what actually a shoe is what a shirt
435:27 - is what a dress is stuff like that
435:30 - um and then from there we're going to
435:31 - have an output layer that's going to
435:33 - have
435:34 - 0 to 9 so it's going to have 10 nodes in
435:35 - the output layer
435:37 - and each of these nodes is going to tell
435:39 - you the probability
435:40 - of um how much the neuron that believes
435:43 - that it's going to be a shirt or a shoe
435:45 - or something else
435:46 - so there's only six here but you can
435:48 - just imagine that there's gonna be
435:49 - there's gonna be ten
435:50 - um like it's going that
435:54 - be 10 10 notes there
435:57 - and um then so the idea is if we put in
436:00 - an image um like the like the first shoe
436:03 - image would be pass it in
436:05 - and say okay this shoe should be uh
436:08 - really close to one it might be like 0.9
436:10 - or something because
436:11 - this is a probability um then we want
436:13 - this to be really high and everything
436:14 - else would be low
436:15 - and then from there we can kind of uh
436:17 - train it
436:18 - eventually to the point where when when
436:20 - we pass in a new image
436:22 - the new image will pass through here
436:23 - every single pixel it'll filter through
436:25 - all of the hidden layers that we're
436:26 - about to create
436:27 - and then at the end it should say like
436:29 - okay uh the second image might be a
436:31 - shirt so this should be really close to
436:32 - one and everything else should be
436:33 - like lower closer to zero
436:36 - is uh is that yeah and your hidden
436:40 - layers
436:40 - represent the model is that what the
436:43 - model is
436:44 - the um the whole neural net itself is a
436:47 - model
436:48 - so uh like i like we went over last time
436:52 - um this annotates a little bit i gotta
436:54 - find a better tool for drawing
436:56 - i think oh but it'll it'll be okay
436:58 - that's everything
436:59 - yeah so the model is the model is
437:02 - inclusive the entire neural net
437:04 - is the the model and we're going to be
437:05 - designing it so right now we we only
437:07 - built the 28 by 20 matrice and we
437:09 - flattened it into the 784
437:11 - input layer and you can kind of ignore
437:13 - the 28 by 28 now because it's just a
437:14 - simplification to make the neural net
437:16 - look nicer because if you have this
437:17 - weird
437:18 - matrices that pumps into this column
437:20 - layer and everything is just kind of
437:21 - like a weird thing we just want it to be
437:23 - a sequential
437:24 - uh series of columns of nodes and
437:27 - eventually
437:27 - you you pass in an image it goes through
437:29 - all this magic and
437:31 - figure out all the patterns and then
437:32 - spits out the probabilities here at the
437:34 - end
437:34 - and it's like okay shoes max is the
437:36 - biggest one so
437:37 - we can probably say that this image with
437:39 - all these pixels filtered through this
437:40 - known that
437:41 - is issue we can confidently say with the
437:43 - 90 accuracy that it's issue
437:46 - but this entire thing is going to be um
437:49 - the the model so again these are going
437:52 - to be connected i just didn't draw these
437:53 - and then
437:54 - there's a bunch of lines everywhere
437:55 - connect like every node is connected to
437:57 - every other node
437:58 - uh the way it can and and then these are
438:01 - just going to be numbers multiplied um
438:04 - together
438:05 - like going through the neural net so
438:09 - um uh let's let's go back to the code a
438:13 - little bit i want to
438:14 - explain the input and output a little
438:16 - bit to you guys and then i'll explain a
438:17 - little bit more about how the neural
438:18 - that is actually going to do the work
438:28 - let's go back to the code and let's
438:30 - actually just delete all this because
438:31 - it's getting too messy
438:35 - there we go
438:40 - so this is the first layer is going to
438:42 - be a flattened layer okay
438:44 - and um like i said before
438:47 - uh that's the input and then the output
438:49 - is going to be
438:50 - um uh a series of numbers from
438:54 - from zero to nine and those are the
438:56 - probabilities that it's going to be
438:58 - each of those so the output layer is
439:00 - actually going to need ten nodes
439:02 - okay it's gonna need ten nodes from zero
439:04 - to nine
439:05 - and um from there then then um
439:08 - then we can create the hidden layers
439:09 - after that so the first thing we want to
439:11 - do
439:11 - is uh let's grab the output layer so the
439:14 - you always want to go like input layer
439:16 - and output layer first and then you can
439:17 - kind of
439:18 - um experiment with the hidden layers to
439:20 - see what you get you get like the most
439:23 - the biggest bang for your buck because
439:25 - uh there's always that trade-off of
439:26 - accuracy and speed
439:27 - so and this one we're only going to have
439:29 - one hidden layer and it
439:30 - it works pretty well uh but let's just
439:32 - start with this so input layer is again
439:34 - the 28 by 28 image
439:36 - and then we flatten that so this is just
439:37 - the input layer of 784
439:40 - and now the output layer is just going
439:42 - to be um
439:43 - 10 10 nodes going up and down
439:47 - um and each of those going to correspond
439:49 - to one of these
439:50 - numbers is that clear so far or is
439:53 - anybody
439:55 - did anybody get lost
440:03 - awesome awesome and
440:08 - so so that's the uh first things we want
440:10 - to do is
440:11 - the input and the output and again we're
440:13 - using dents here
440:14 - dense just means that every node in each
440:16 - column is connected to every other node
440:17 - in each column so there's a bunch of
440:19 - like
440:19 - crossing over lines uh between each
440:21 - neural net let me just find an image
440:23 - actually
440:25 - densely connected neural
440:28 - network like i showed some of these last
440:31 - week
440:32 - but here this one works
440:36 - nice
440:45 - ah it's not working
440:48 - here we go so this here
440:52 - um
440:55 - is uh like this one has a bunch of
440:57 - inputs so for us we're gonna have the
440:58 - image
440:58 - and all the pixels in here and then
441:00 - we're gonna have the
441:02 - the ten different um numbers here
441:05 - uh corresponding to each each of the the
441:07 - clothing types
441:10 - uh ignore this for now this this thing
441:12 - here um i'll explain this in a little
441:14 - bit but just
441:14 - remember that the i'm i think
441:18 - i did this last time to make it a little
441:19 - bit clearer so units will actually
441:21 - define how many
441:22 - nodes are in this column so the type of
441:24 - column is going to be dense
441:26 - this layer the the layer or column i'm
441:29 - kind of using those terms
441:30 - interchangeably but they're the same
441:31 - thing so that layer is going to have 10
441:34 - units
441:34 - out of the coming out of the back this
441:36 - only has 4 but just pretend there's 10
441:38 - and then the input has 784 again so
441:42 - once we have those specified then
441:44 - usually you can just start off by just
441:47 - testing it with one hidden layer and
441:48 - then kind of see how well your
441:50 - neural net performs
441:59 - testing it with one hidden layer and
442:01 - then kind of see how well your
442:03 - neural net performs because simpler is
442:05 - better and then
442:07 - um and in our case it'll work pretty
442:09 - well only one
442:10 - one hidden layer and we're about to
442:11 - build that
442:13 - uh but sometimes you need really really
442:14 - deep layers to actually create robust
442:16 - systems so for us like we're simply
442:18 - classifying like like 10 different types
442:20 - of
442:22 - clothing which is pretty pretty simple
442:25 - um but sometimes you want to have like a
442:27 - really really deep neural network and
442:28 - that's actually where deep learning
442:29 - comes in
442:30 - is this is where like there could be
442:31 - like a lot of hidden layers like tens
442:33 - hundreds of hidden layers
442:34 - and that's why it's called deep learning
442:36 - just because the neural outlook is
442:37 - really really deep
442:38 - but those can get really powerful like
442:40 - if they opt people have like learned how
442:42 - to optimize it enough to
442:43 - not take like years and years to train
442:46 - um but then it's able to like be really
442:48 - really powerful for like
442:49 - recognizing like a large large array of
442:52 - different uh things like
442:54 - it can tell what a cat is what a coffee
442:56 - mug is um what an airplane is
442:58 - like who obama is and stuff like that um
443:02 - uh all in one neural net but you need a
443:04 - lot of hidden layers but for ours it's
443:06 - pretty simple so we only need one one
443:08 - hidden layer and we'll just start with
443:09 - one and we'll see that it actually works
443:11 - pretty well
443:12 - so let me go pull that out next
443:17 - uh we're currently designing our our
443:20 - neural network structure
443:21 - using keras so um
443:24 - so this here is actually the final
443:26 - neural network that we're going to be
443:27 - building so we have the entire thing
443:29 - specified here
443:30 - um the the the hidden layer we're going
443:33 - to be using is another dense layer so
443:35 - again it's going
443:36 - to be fully connected like this as in
443:38 - every layer column layer here is fully
443:40 - connected densely to the
443:41 - to the next one um so it's this is what
443:44 - it's going to look like but we're only
443:45 - going to have one hidden layer so you
443:46 - can ignore
443:47 - two and three you can pretend those
443:48 - aren't there and
443:50 - um and then we're gonna have 128 again
443:53 - let me type in units
443:54 - to be a little bit clearer uh we're
443:56 - going to have 128 nodes in that one
443:59 - okay so there's actually going to be 128
444:00 - tall so the first the first one is going
444:03 - to be 778 tall
444:05 - second one is going to be 128 tall so
444:06 - smaller and the last one is going to be
444:08 - 10 tall so you can kind of see like
444:09 - we're filtering from a big image
444:11 - and then we're going to we're pulling it
444:12 - down to like a little bit a few patterns
444:14 - and eventually we're going to um um
444:17 - we're going to
444:18 - boil it down to 10 probabilities of of
444:20 - these different clothing types
444:23 - uh so that's kind of the structure of
444:24 - our uh neural net
444:26 - um you can kind of just you kind of just
444:28 - want to like guess
444:29 - for this one uh you can just kind of
444:33 - like like last week we started with a
444:34 - very very simple one
444:36 - um but for images you usually want to
444:37 - try like some some decent numbers so you
444:40 - might want to start you could even start
444:41 - with like 60
444:42 - 64 or something and then you can just
444:44 - jump up to 128
444:46 - but 128 is like a good medium ground
444:47 - like it's not too big of a number for a
444:49 - computer to do with
444:50 - uh but it it captures a good amount of
444:52 - relationships you kind of just have to
444:54 - like play with it
444:55 - and stuff for for pre-built projects
444:57 - usually people figure out these
444:58 - fine-tuned numbers for you but for us
445:00 - you can
445:01 - just kind of like just pick a number and
445:03 - see what happens you kind of have to
445:04 - play with it and see how the computer
445:06 - learns like how accurate it learns
445:10 - okay so is everybody following up to
445:12 - this point we
445:13 - um this is just all kind of like
445:14 - preliminary code stuff of like importing
445:16 - the data and everything but here
445:17 - designing our neural net we have a
445:19 - sequential neural net with uh input of
445:21 - an image
445:22 - um one hidden layer of 128 nodes and
445:26 - a output layer of 10 nodes is that clear
445:29 - to everybody
445:33 - is it a good i don't know common
445:35 - practice to make the hidden layer
445:37 - some um factor of two or power
445:40 - two um not really uh it can be anything
445:44 - i don't know why they actually choose
445:45 - 128
445:46 - um because i i found this project online
445:48 - and
445:49 - um it's like neural nets can
445:52 - you can use any number of nodes it's
445:54 - just uh arbitrary
445:56 - um number of nodes and then you can
445:58 - capture relationships so i
446:00 - actually don't think it needs to be uh
446:02 - like some special number
446:04 - actually i mean we could probably even
446:05 - choose a different number but
446:07 - um did they just i guess people just
446:10 - like like powers of two because it kind
446:12 - of
446:13 - goes nicely with like how computers work
446:15 - internally so maybe maybe it's good
446:16 - practice maybe not but i mean in theory
446:18 - you don't need to have
446:19 - it be a power of two but maybe in
446:22 - implementation
446:25 - yeah i didn't know those conventions or
446:27 - something
446:28 - yeah um i
446:31 - i guess i mean yeah a lot of stuff in
446:33 - code in general is like based on powers
446:34 - of two so maybe it's a
446:35 - it's a it doesn't hurt to just start
446:37 - there if you're choosing a random number
446:39 - then that you just choose a power of two
446:40 - because it might
446:41 - might simplify things but it should it
446:44 - shouldn't doesn't matter like on a
446:45 - theoretical level
446:47 - so uh from here we have our entire
446:50 - neural net created in design so
446:53 - let me actually just draw this out
446:55 - visually once so that anybody watching
446:56 - the recording can see exactly what it
446:58 - looks like so
447:07 - we have our entire neural net created in
447:09 - design so
447:10 - um let me actually just draw this out
447:13 - visually once so that anybody watching
447:14 - the recording can see exactly what it
447:16 - looks like so
447:17 - first layer is going to be 784 layers
447:20 - of like that
447:24 - it's going to be
447:28 - 7 84
447:32 - flattened and then this one is going to
447:34 - be
447:36 - 128.
447:39 - oh hello i think my i think my
447:43 - connection cut out for a second you guys
447:44 - there
447:46 - yes all right perfect
447:50 - then this is going to be um 128
447:57 - and then the last one is going to be
448:00 - 10
448:06 - 10 here
448:09 - is going to be 10. and then of course
448:12 - these are all
448:12 - connected there's all those crazy lines
448:14 - between each of these just like we have
448:17 - um here okay so you can kind of just
448:21 - assume
448:22 - that this is the neural net but then
448:23 - just pretend the lines are all there so
448:24 - this is the what our doorknob actually
448:26 - looks like that we just built
448:28 - um again it's just as simple as uh
448:32 - just calling uh terrace and the type of
448:34 - neural net and then just listing the
448:36 - layers in this list
448:38 - one by one so layer layer layer input
448:41 - hidden and output okay i think i
448:46 - explained that adequately enough let me
448:49 - get rid of these
448:51 - drawings so we can continue on oops
449:04 - um aaron i have a i had a question
449:07 - actually
449:08 - yeah what's up hi uh so
449:12 - uh when these uh when we add a hidden
449:15 - layers
449:16 - okay so does that uh number have to be
449:19 - um
449:20 - consistent for example we have a 128
449:23 - nodes
449:23 - in the first hidden layer so for example
449:26 - if we are creating
449:27 - uh further hidden layers so for example
449:30 - we are creating five hidden layers so it
449:31 - has to be 128 128
449:34 - and 128 for all five layers or it can
449:37 - increase and decrease based on
449:39 - it can increase and decrease based on
449:41 - anything um this is where the neural net
449:43 - design gets kind of like
449:45 - uh up in the air
449:48 - um for this one this is a pretty simple
449:50 - problem like relatively because we're
449:52 - dealing with small black and white
449:53 - images we're not
449:54 - dealing with like 4k big images or
449:55 - anything uh
449:57 - so but yeah it can be anything usually
449:59 - what you want to do
450:00 - is the neural net usually starts big and
450:02 - then eventually gets smaller and smaller
450:04 - into something small
450:05 - um because you want to take like a big
450:08 - thing of data
450:09 - and then like all the pixel data and
450:11 - then just say shoot or
450:12 - a bunch of pixel data and say okay okay
450:14 - this is
450:16 - um like martin luther king jr or
450:18 - something if it's his face like you just
450:19 - want to like have like simple labels at
450:21 - the end so usually the neural network
450:23 - starts big and eventually filters down
450:24 - smaller and smaller into some
450:26 - some set of outputs in our case it's
450:28 - going to be a list of 10 numbers
450:30 - which again correspond to the
450:31 - probabilities listed here for each of
450:33 - these
450:35 - okay so the number of nodes in the
450:38 - hidden layer
450:39 - has to be less than the input layer or
450:42 - it can no it can be it can be anything
450:44 - it can increase as well
450:46 - um because you could theoretically
450:48 - capture more um patterns
450:50 - the the thing is the data uh that's
450:53 - there
450:54 - is um 784 tall right the input layer we
450:57 - have all that
450:58 - um so you can kind of
451:01 - if if the input layer is also the same
451:04 - size then you're kind of like
451:07 - not boiling it down to like smaller
451:08 - patterns you can because there's like
451:10 - weird
451:11 - like uh
451:14 - how to explain this um there's there's
451:18 - patterns you could pick up on if it's
451:19 - bigger you kind of like find like weird
451:21 - like underlying patterns in the data
451:23 - that you can't really like visualize
451:25 - like like a human wouldn't really
451:26 - understand it but like you can kind of
451:28 - uh pick up these patterns in numbers if
451:30 - you get more complex but then
451:32 - also at the same time as you create more
451:33 - hidden layers it takes longer to train
451:35 - so as a general rule of thumb it's
451:37 - usually better to just get smaller and
451:38 - smaller and smaller or stay the same
451:40 - size you could go like big
451:41 - and then have like two layers of 16 or
451:43 - three layers of 16
451:44 - and then like go down to like a layer of
451:48 - output of two if like if it was like
451:49 - you're trying to be like oh is this a
451:50 - cat or a dog
451:51 - or something like that it could be like
451:53 - image then 16 16 16 then two
451:56 - for for that neural net for like if
451:57 - you're trying to do like a dog
452:00 - okay so what would be an efficient
452:02 - approach uh to have
452:03 - us like for the example uh 128 is two
452:06 - power
452:06 - six i guess or eight or something yeah
452:09 - yeah some power of two
452:12 - yeah uh okay
452:14 - so two power of seven so what if uh i
452:17 - wanna split it
452:18 - uh maybe uh 128 into like uh seven right
452:22 - so it will be
452:22 - uh uh two part three and two power four
452:25 - i wanna have two hidden layers so
452:27 - is that will that be a more uh efficient
452:30 - approach or
452:30 - having it both in a single hidden layer
452:33 - will be
452:35 - um more similar actually less layers is
452:38 - better
452:38 - uh if you can get it to the the least
452:41 - amount of layers possible that's usually
452:43 - better because it keeps the neural net
452:44 - simpler and they're not as deep
452:46 - um but as you go deeper you can actually
452:47 - yeah you can like pick up on different
452:49 - patterns so like
452:50 - um for us it might be like
452:54 - okay for a shirt like i might pick up
452:56 - like long like
452:58 - or actually let me just print let me
453:00 - give an example
453:01 - so when you say uh going deep into the
453:04 - neural network so does that mean uh
453:08 - going into more into hidden layer number
453:10 - one hidden layer number two
453:11 - or increasing the length of the hidden
453:14 - layer
453:18 - oh you mean like like you mean making uh
453:20 - a hidden layer
453:22 - versus having two hidden layers exactly
453:25 - so what if i want to have that hidden
453:26 - layer just
453:28 - uh beneath the hidden layer one
453:31 - i want to append the hidden layer to
453:32 - under hidden layer one
453:34 - maybe yeah well again there's like
453:37 - there's a fine tuning thing of like the
453:39 - complexity of the neural net versus how
453:40 - much you have so like
453:42 - uh the more the more nodes you have in a
453:44 - layer
453:45 - in principle the more patterns you'll be
453:47 - able to pick up um
453:48 - but then also it'll take longer to train
453:50 - so yeah you could just have like
453:52 - um you could you could like like you
453:55 - could have
453:56 - are you asking like one like one 128
453:58 - layer versus two
454:00 - 64 layers or something like that yeah
454:02 - usually you'd want to pile it into just
454:03 - one 128 layer which is what we're doing
454:05 - now because
454:06 - it gets the job done with one layer
454:08 - because each layer you add kind of adds
454:10 - a
454:10 - level of like exponent it gets
454:12 - exponentially more complicated
454:14 - uh faster than than um
454:18 - okay so keeping it to us in into a
454:20 - single layer makes it like keeps it
454:21 - simple
454:22 - yeah for now um okay there are yeah
454:25 - there's
454:26 - there's a lot of different trade-offs
454:27 - but i mean just as a general rule of
454:28 - thumb just try to keep the layers as low
454:30 - as possible
454:31 - because it uh keeps its and also i mean
454:33 - like if 64. like this is 128 but like if
454:36 - 64 gets us decent results that's a
454:38 - better
454:38 - uh choice to go with 128 seems to be the
454:42 - sweet spot that will be
454:43 - that would be the number of units would
454:45 - be the minimum number which would
454:47 - get us a result of a decent accuracy
454:51 - yeah something like that yeah so you
454:53 - just kind of want to optimize this
454:54 - neural net for this task and that's kind
454:55 - of like the name of the game is like
454:57 - figuring out the neural net design the
454:59 - numbers and the training set
455:01 - to get it working pretty good for
455:03 - whatever problem you're facing for us
455:05 - we're just trying to classify
455:06 - clothing types versus
455:09 - so our aim would be to keep minimum
455:12 - number of nodes
455:13 - and minimum number of hidden layers to
455:15 - get the maximum accuracy
455:17 - yeah yeah like that you just find that
455:19 - find that balance point for whatever
455:20 - you're trying to solve like if you need
455:22 - like a real-time solution
455:23 - you'd probably sacrifice some accuracy
455:25 - to be like instant instantaneous
455:27 - classification like for
455:29 - like for tesla's self-driving cars it's
455:30 - like okay that's a person walking
455:32 - that's a telephone pole it needs to be
455:34 - real time so um they'll probably
455:37 - rather have it be real time and be a
455:38 - little bit less accurate and then just
455:40 - kind of like
455:40 - be extra careful uh with their things
455:43 - it's like okay
455:44 - i'm not sure if that's a human i'm just
455:45 - gonna say it's a human so i don't hit it
455:47 - you know like just kind of like
455:48 - sacrifice accuracy but make sure it's
455:50 - fast so you just gotta
455:51 - depending on the problem you're trying
455:52 - to solve you have to kind of like
455:53 - balance that out
455:55 - okay okay yeah thank you thanks
455:58 - aaron yeah i was going to ask something
456:00 - similar um
456:03 - um is it almost the same thing or
456:06 - equivalent
456:07 - of the the increase as you increase your
456:10 - hidden layers that increases the
456:14 - time complexity meaning it's like almost
456:16 - like exponential so if you added a
456:18 - second one it's
456:19 - you know i forgot to go through here
456:22 - this is sequential
456:25 - wait say that again yeah so is it
456:28 - is it more like you know it adds a
456:30 - number of permutations or combinations
456:32 - because
456:32 - the node has to touch yeah because it
456:35 - increases the
456:35 - increase yeah yeah it's going to be i
456:38 - think i might have gotten backwards i
456:39 - know like putting if you just want to
456:41 - like trim it down as much as you can
456:42 - but yeah as you increase the nodes and
456:44 - stuff then because every node and every
456:47 - connection or they're called neurons or
456:49 - synapse like neurons and synapses like
456:51 - to reflect the human brain but it's just
456:52 - nodes and connections between those
456:54 - nodes
456:55 - [Music]
457:03 - like here so like these these are nodes
457:05 - these are the connections or synapses or
457:07 - these are neurons in these
457:08 - synapses whatever you want to call it
457:10 - each of these lines has a weight
457:11 - so like you would have the pixel and
457:13 - then you would have the weight of each
457:14 - of these lines then you just multiply
457:16 - that pixel value by that weight
457:18 - and you get a different a different
457:20 - number here um and then from there
457:22 - you do it again and again and again and
457:23 - then eventually all these little numbers
457:25 - together
457:26 - kind of like represent a function that
457:28 - captures the patterns
457:29 - and eventually spit out um the correct
457:31 - numbers
457:32 - so since every single line and every
457:35 - single node has its own number
457:37 - um and then there's a bunch of like
457:38 - crazy uh multiplications going on
457:41 - they're at the at the bottom level
457:42 - they're just matrix multiplications
457:44 - which has been highly optimized with
457:45 - numpy so it's
457:46 - as fast as it can get pretty much um and
457:50 - once those are all like multiplied
457:51 - together then
457:52 - then that's how this this is all
457:53 - computed and it goes through but yeah as
457:55 - you
457:55 - as you add more layers you can see that
457:57 - each um each
457:59 - extra layer and each extra node adds
458:01 - like an exponential kind of
458:03 - um thing to it so the computation goes
458:05 - up and then i guess also that the time
458:07 - the space comes the space complexity too
458:11 - okay and so there may be times where
458:15 - you may have a higher number of nodes in
458:18 - your hidden layer if like your input
458:20 - layer
458:21 - i guess you don't have that many nodes
458:23 - to increase
458:24 - your uh uh pattern
458:28 - you know increase the number of patterns
458:29 - that you might be able to yeah
458:32 - because yeah because sometimes there can
458:33 - be like weird nuanced patterns
458:35 - in the data that aren't really clear uh
458:38 - so like yeah like if your input was like
458:39 - really small
458:40 - um like what's a good example like
458:44 - yeah like maybe you maybe you had some
458:46 - training data of like maybe you had some
458:48 - stats like you're trying to do some
458:49 - stocks and you're like okay
458:50 - these are the prices of the stocks over
458:52 - here and you only have like a small
458:53 - little thing like the input layers maybe
458:54 - like only 64 long
458:56 - but you kind of want to like capture
458:57 - some weird like numerical patterns
458:59 - between everything you could have like
459:00 - your hidden layers be much bigger to try
459:02 - to capture some
459:03 - some patterns that the human couldn't
459:04 - pick up on right
459:06 - okay some something like that
459:09 - yeah i'm just trying to understand the
459:10 - strategy of how you design your uh
459:13 - layers and then the length of them yeah
459:16 - uh the the best the simplest way like
459:18 - like i'm explaining here is you just
459:20 - want to start with your input
459:22 - um and then your output first always
459:24 - start with that and then the hidden
459:25 - layer
459:26 - just start with one and see what happens
459:27 - you know and play with the number and
459:29 - then maybe it's like okay this is doing
459:30 - crap
459:31 - um i can then you can play with the
459:32 - activation functions too i'll touch on
459:34 - these in a second because this is
459:36 - another kind of
459:37 - uh number crunching thing that happens
459:39 - and then there's different things you
459:40 - can pick like these two are different
459:42 - like they're both activation functions
459:43 - but these two do do different things
459:46 - um and so it's kind of just like you
459:48 - play with it and you play with all the
459:50 - different numbers and different types
459:52 - and hopefully get some um some
459:55 - useful uh use out of out of your neural
459:58 - net
459:59 - uh but yeah just just start with one and
460:01 - then you can always expand out from
460:02 - there
460:06 - uh okay let's continue on unless there's
460:08 - any any more like burning questions from
460:10 - people
460:10 - about about this
460:14 - [Music]
460:23 - uh all right i'll take that as a note
460:24 - that is that is good
460:27 - okay so we designed our neural net here
460:29 - uh now let's continue on there's
460:30 - actually not too much left because
460:31 - tensorflow makes everything nice and
460:33 - concise so we
460:34 - only have a few more lines of code here
460:36 - uh let's just go one by
460:38 - one so let's grab this
460:42 - paste it in
460:45 - so anybody who remembers from last uh
460:48 - from last week
460:49 - then after you create your model we have
460:51 - to compile it
460:52 - uh which basically just means take all
460:54 - the stuff that kara's built because we
460:56 - just specified the nodes and the numbers
460:58 - and the types and all that like you know
460:59 - densely connected
461:00 - make this flattened make it this big
461:02 - make this hidden layer 128 tall make
461:04 - sure sequential all the stuff that
461:05 - kara's put
461:06 - together now we want to actually compile
461:07 - it so it's ready to be trained
461:09 - which um just means kind of like i
461:12 - actually don't know exactly what's
461:13 - happening under the hood when keras but
461:14 - it just kind of says like okay take all
461:16 - this
461:16 - put it into a form where it's ready to
461:18 - do to do stuff and then we also have to
461:20 - specify an optimizer function and a loss
461:23 - function so let me just touch on this
461:24 - again really quickly one more time for
461:26 - anybody who
461:27 - forgot or is new so um
461:31 - just remember remember there's a lost
461:32 - thing and an optimizer thing so let me
461:34 - go to this
461:35 - uh neural net here and kind of explain
461:36 - visually what's happening
461:38 - so what happens is when you put in an
461:40 - image in input layer you would put one
461:42 - through
461:42 - and um you would want to pick random
461:44 - numbers for all these lines
461:46 - and for all these lines and just filter
461:48 - it through so
461:49 - once you have an image come in you'd
461:51 - multiply it by all these random numbers
461:53 - and then you'd get another set of
461:54 - numbers here you take those and
461:56 - multiply by all these random numbers on
461:58 - all these lines and then you get it all
462:00 - um all here and then again and again to
462:01 - get to the very end and you'll get some
462:03 - output
462:04 - um so again you're going to get we're
462:06 - going to get 10 outputs in hours that
462:08 - correspond to the probabilities of it
462:09 - being these 10 things
462:11 - and uh basically whichever one is the
462:13 - highest we can kind of say that neural
462:14 - net believes that the image we passed in
462:17 - is that thing and then we can compare
462:19 - that
462:20 - um that answer that the neuron that gave
462:22 - us to the actual label
462:24 - of what the data set gave us because the
462:26 - the training data actually tells us what
462:28 - it is what it's supposed to be like like
462:30 - a human went in there and actually
462:31 - labeled it for us um
462:33 - and so uh what we want to do is the loss
462:36 - function here will tell us how correct
462:38 - or how incorrect we are
462:40 - and basically it'll say like okay the
462:43 - neural net said it was
462:44 - uh like maybe move the neural that said
462:46 - it was a t-shirt but it was actually a
462:48 - boot
462:48 - for like this first one um for the for
462:51 - the
462:51 - for the boot image that i showed earlier
462:53 - then we know that that it's very wrong
462:55 - and we can kind of see the loss function
462:56 - is like okay you're this much
462:57 - wrong but how do we get better uh so
463:00 - it tells if we're super wrong then we
463:02 - want to get closer to being right and
463:03 - that's where the optimizer comes in
463:05 - uh which just kind of tells us like okay
463:07 - make these changes to all these
463:09 - these weights here to be a little bit
463:11 - more correct because um we can just like
463:13 - we can alter these by saying okay if we
463:16 - if we
463:17 - um if we know it's an ankle boot but it
463:20 - thought it was a t-shirt all we need to
463:21 - do is just kind of like adjust all the
463:23 - weights that connect to the t-shirt node
463:25 - at the end
463:26 - and be like okay lower all those weights
463:27 - because that was way wrong um
463:29 - but we know it is a boot so it's like
463:31 - okay well
463:32 - we know it's a boot so let's increase
463:34 - all of the the numbers that were
463:36 - connected to the boot because
463:37 - this should be higher and the t-shirt
463:39 - should be lower and then that's how
463:40 - that changes all these weights here and
463:42 - then we repeat the same process here
463:44 - and then here and then here again and
463:46 - then that's one that's kind of that's
463:48 - what one epoch
463:48 - is with one image and then we um
463:52 - for anybody from last week remember the
463:53 - whole epoch conversation we had
463:56 - uh and then then we can repeat that
463:58 - again with um
464:00 - another image so uh to cover that again
464:03 - so the loss function we we pass
464:05 - in some data it goes through all these
464:06 - random numbers and then we get something
464:08 - out
464:08 - then the loss function will tell us how
464:10 - wrong we are so we're just you can
464:12 - this fancy name is just like a name of a
464:14 - function that we can use
464:16 - to tell us how wrong we are and then the
464:18 - optimizer is a way to
464:20 - alter these weights in a way um to make
464:23 - this normal a little bit more
464:25 - accurate in being able to classify
464:28 - different images as
464:30 - these these data types i mean as these
464:33 - uh clothing types
464:35 - does uh does that kind of make sense
464:37 - it's kind of a
464:39 - complicated thing to explain i think
464:40 - there's probably people on the internet
464:41 - who've explained it better but i i hope
464:43 - i didn't lose you guys
464:48 - again
464:51 - hello hello is anybody anybody there
464:55 - no it's good yeah it's clear okay
464:57 - awesome
464:59 - awesome awesome
465:02 - okay so yep loss tells us how long we
465:04 - are optimizer tweaks all the numbers in
465:06 - the neural net
465:07 - um and actually
465:11 - yeah did somebody say something um i'm
465:13 - just i'm trying to remember it from last
465:15 - week was that the
465:16 - is that a different optimizer and loss
465:18 - functions that we used in the last weeks
465:20 - yes so the thing about loss functions
465:23 - and optimizer functions
465:24 - is and even knowledge too like there's
465:27 - different neural nets and different
465:28 - optimizers
465:29 - and different loss functions that are
465:30 - useful for different types so for images
465:32 - these are actually pretty good for image
465:35 - data like last time we were
465:36 - working with just like straight numbers
465:38 - a very very simple one-to-one number
465:40 - relationship but now we're trying to map
465:42 - a 28 by 28
465:44 - image to like a series of ten numbers
465:47 - which is the probability of okay maybe
465:48 - this is a shirt maybe it's a shoe
465:50 - um so these are different uh but
465:53 - basically there's just a bunch you can
465:54 - use
465:55 - and you can go and test all of them but
465:58 - um and then all the math behind this uh
466:01 - is there i don't actually understand
466:02 - i don't remember i don't remember what
466:03 - atom is or sparse categorical crossing
466:06 - should be whatever this is
466:07 - but um they're just things you can
466:10 - specify
466:11 - you can just like choose whichever one
466:13 - works so these are
466:14 - are i'm pretty sure are good for for
466:16 - images so i'm guessing
466:17 - i'm guessing like tensorflow or keras
466:19 - whatever whatever it's coming from it's
466:21 - got
466:21 - um like pre-defined libraries
466:24 - of all these functions and and somewhere
466:27 - on
466:28 - on the internet somewhere there'll be a
466:29 - i'll list them with like an explanation
466:31 - of what they're good for
466:32 - yeah probably like that i mean we can
466:34 - maybe look a little bit like
466:36 - what is this sparse i'm curious because
466:38 - i actually didn't learn the specific
466:40 - there's just so many
466:42 - sparse i mean the documentation is a
466:44 - good place to go so like if you look
466:46 - here
466:47 - so tensorflow.keras.losses so this is
466:50 - lost function so that's why it's losses
466:52 - and
466:52 - this is called sparse categorical cross
466:54 - entropy so i mean just from the name i
466:57 - mean it sounds scary i mean the first
466:58 - thing that comes to mind is
467:00 - um it's probably trying to pick up on
467:02 - like different splotches of like
467:04 - brightness and darkness in each image
467:06 - and then it's trying to like find like
467:08 - the amount of chaos and randomness
467:10 - inside of
467:11 - those um images and then like
467:14 - i don't know what categorical means but
467:16 - it's probably doing something like that
467:17 - and trying to like translate that to
467:18 - like how right or wrong you are
467:20 - um i mean i kind of just pulled out my
467:22 - my ass but
467:24 - that's what it sounds like it says
467:25 - computes the sparse i mean okay what's
467:27 - just explaining itself here that's not
467:29 - very helpful
467:30 - um
467:36 - yeah i don't i don't know the math
467:37 - behind this one but uh the idea is it
467:39 - just tells you how right or
467:40 - how wrong you are you just get a number
467:42 - from zero to one at the end of it
467:43 - or something like that uh for this for
467:46 - this specific one
467:48 - but someone documented it
467:52 - like a dummy's guide yeah hopefully
467:55 - there's some crazy math behind it and
467:57 - and stuff yeah i mean it's it's a whole
468:00 - it's a whole like
468:01 - um field of thought right you know
468:02 - machine learning and all these different
468:04 - there's always like new papers and
468:06 - research coming out about like all these
468:08 - different things like
468:09 - this actually is uh something fairly
468:12 - fairly new uh really i'll touch on this
468:14 - in a second
468:15 - um relu is something that they they
468:17 - started doing more recently there used
468:18 - to be a different one but this is like a
468:20 - huge optimization thing that makes throw
468:21 - that's like 10 times faster but still
468:23 - get pretty good accuracy
468:24 - they started using this instead of
468:26 - something else and now it's kind of like
468:27 - a
468:27 - like accepted standard to use this relu
468:30 - thing um
468:31 - i forget what it stands for but
468:34 - oh yeah i wrote right here relu so um
468:37 - okay let me let me explain this a little
468:39 - bit i forgot to touch on the activation
468:41 - functions actually
468:50 - okay let me let me explain this a little
468:51 - bit i forgot to touch on the activation
468:53 - functions actually
468:54 - um so how the neural net works is again
468:58 - we have all the pixel numbers here from
468:59 - 0 to 255 on each of these nodes then we
469:02 - have a bunch of weights here that could
469:03 - be
469:03 - any any numbers at all it could be 0.1
469:06 - could be 4.6
469:07 - could be anything could be negative
469:08 - numbers too and you just multiply it and
469:10 - then you get like hidden layer stuff
469:12 - then from here when you get numbers you
469:14 - want to you want to pass this into
469:15 - another function
469:16 - um called the activation function like
469:18 - once we get the pixel data we multiply
469:20 - it by all these crazy numbers and we get
469:22 - like a new column
469:23 - of data here of new numbers
469:26 - these we also want to do an extra step
469:28 - that's hidden within these nodes that's
469:29 - called the activation function which
469:31 - kind of
469:32 - um treats it as it's like an another
469:34 - layer of filtering it kind of like
469:36 - specifies the threshold of like okay
469:38 - this is good enough or not good enough
469:40 - like um
469:42 - like for like like one good example is
469:44 - in the output layer
469:45 - we can say okay if the output is above
469:48 - 0.9
469:49 - aka above 90 we can confidently say that
469:52 - this is a shoe
469:53 - but maybe it's a sandal you know like
469:55 - maybe shoe and sandal are both above 9.9
469:58 - and that can we can specify that
469:59 - threshold of 0.9 um but then just the
470:02 - highest one will be the actual
470:03 - the actual answer like maybe it's like
470:05 - 0.95 and then 0.99 so the 0.99 would win
470:08 - but we can kind of like specify some
470:10 - threshold of what gets passed on and
470:12 - stuff
470:12 - so you can kind of filter that stuff
470:13 - there you can be like okay anything
470:14 - above 0.9
470:15 - let it keep going anything below 0.9
470:18 - completely turn off because we're
470:19 - we're sure it's not a shirt we're sure
470:21 - it's not a bag and stuff like that
470:23 - so the activation function just acts as
470:25 - like a filtering mechanism
470:26 - within each layer um that can further
470:29 - filter out our data
470:30 - um does that make sense with that whole
470:33 - like 0.9 example
470:34 - of like in the last layer
470:38 - yup it didn't make sense okay okay good
470:41 - uh so that's what that does and
470:43 - basically so what what we're doing here
470:45 - is um before they they had some crazy
470:48 - function called the sigmoid function uh
470:50 - it's not important it just
470:52 - it's this thing that kind of like uh
470:54 - it's a perfect continuous it's a nice
470:56 - pretty curve
470:57 - function that kind of like okay if we're
470:59 - above this little threshold then let it
471:01 - buy
471:01 - um but it's really computationally
471:03 - intense when you get really big neural
471:05 - nets so basically what they did is this
471:06 - relu thing
471:07 - they said okay literally if anything is
471:09 - zero like below zero just return
471:11 - zero this passes zero through um but if
471:14 - it's above zero just pass the actual
471:15 - number it is so basically it's just like
471:17 - chopping off all negative it's just
471:18 - getting rid of number
471:19 - negative numbers that's all it's doing
471:21 - and it sounds really simplistic but it
471:23 - seems to work
471:24 - in in practice so uh t-o-tf is
471:26 - tensorflow
471:27 - and and i believe this neural network um
471:31 - then uh relu is uh it just gets rid of
471:34 - negative numbers so basically like i
471:35 - said these weights can have negative
471:36 - numbers
471:37 - but once it gets here if it's a negative
471:39 - number it automatically just
471:41 - gets turned to a zero and then any
471:43 - positive numbers just stay what they are
471:44 - and it kind of um simplifies like the
471:47 - pattern stuff i don't i don't
471:49 - remember the the exact theory behind it
471:51 - but it does that and it actually
471:52 - improves the
471:54 - the um performance of the neural net and
471:55 - it does that for for um
471:57 - for each layer that has really specified
471:59 - so bradley is like really a really
472:01 - popular one
472:02 - um uh this one down here
472:05 - is so the activation function here so uh
472:08 - this one is softmax and all softmax does
472:10 - is it just picks the greatest number out
472:13 - of everything so
472:14 - in our point um because i said that the
472:17 - the last
472:18 - layer is going to be ten layers here
472:20 - from zero to nine and it's gonna have
472:22 - the probability
472:23 - of each one it being one of these um
472:26 - then it'll just pick the one that has
472:27 - the highest the highest probability and
472:30 - spit that out
472:31 - so for our case if i go back to
472:34 - [Music]
472:36 - this quit out of this
472:39 - and run the code again
472:45 - so this is our first data um data image
472:48 - then we know this is a shoe um so
472:51 - uh this probability would probably be
472:53 - the highest like the this bottom node
472:55 - might be like 0.99 or something or 0.97
472:58 - and all these might be like zero point
473:00 - one zero point four zero point three
473:02 - like it's not
473:02 - it it's pretty sure it's not all of
473:04 - these and since this is the highest
473:06 - it'll just give us nine it'll just give
473:08 - us nine and then we know nine is is uh
473:10 - mapped to ankle boot but it'll just pump
473:12 - out the number nine
473:14 - so um soft max basically just gets the
473:17 - the maximum um number within that layer
473:20 - and that's all that activation function
473:22 - does very simple because
473:23 - that's all we need to do in this last
473:25 - layer is just kind of like
473:27 - which one is the highest like that's the
473:28 - final filtering mathematical thing we
473:31 - want to do
473:31 - in this last layer um to to finish off
473:34 - the neural net is just find that find
473:36 - the greatest one
473:37 - in in actual practice what it does is i
473:40 - believe
473:40 - it does this like it might be like 0.1
473:43 - you know
473:44 - 0.3 0.4 0.2 blah blah blah
473:47 - blah and then all the way to 0.99 for
473:50 - the last one
473:51 - um all it really does is it just does
473:54 - this
473:54 - so it just
473:58 - it just makes all these zero oh wait i
474:01 - screwed it up
474:02 - it just makes all these zero and then
474:05 - makes the greatest one one
474:09 - it would be like that so that's really
474:11 - what it's doing that's what soft max is
474:13 - actually doing
474:13 - just kind of like boiling this down to
474:16 - this and then from there we can like
474:17 - okay so the ninth one
474:18 - is the one that's on okay this is a shoe
474:22 - and that that's kind of what's happening
474:24 - uh within the neural net
474:26 - is that clear so far
474:38 - yeah it's kind of clear but i have a
474:40 - doubt
474:43 - and that so basically what's happening
474:46 - is the hidden layer
474:47 - is filtering out all the negative values
474:51 - and it's just keeping the positive
474:52 - values and the outer layer
474:54 - what it's doing it's it's just picking
474:56 - up selecting the max value and setting
474:58 - it to one
474:59 - or like it's telling us oh yeah it's
475:01 - it's gonna it's the max value zero point
475:04 - nine and so it's gonna be a shoe
475:06 - yeah so uh like why are we
475:10 - introducing uh the hidden layer
475:13 - if can we do uh this uh operation using
475:16 - a function
475:18 - maybe like
475:20 - a simple function or like why are we why
475:22 - is the need to introduce the hidden
475:24 - layer can we
475:25 - uh do it without the hidden layer is it
475:28 - possible or
475:29 - like is it computationally tough or like
475:33 - it's not possible or like
475:35 - what is what could be the solution
475:40 - so um the point of the hidden layer is
475:42 - to actually
475:44 - well i mean you need the hidden layer
475:45 - for it to be like a knurled in the first
475:46 - place like if we just went from
475:48 - um what happens if
475:52 - if we eliminate the middle layer what
475:53 - happens then everything
475:55 - wouldn't it wouldn't work that well at
475:57 - all because the
475:58 - here let me draw it out let me annotate
476:00 - a little bit so you would have
476:02 - the you know the 784 here the 784 input
476:05 - layers here which is just the pixel data
476:07 - and then you would simply have the 10
476:10 - the 10 output layers here right
476:11 - which is what you're asking yeah so
476:15 - we'll just let me just draw this out
476:17 - so you have the 10 here and you have the
476:20 - 784 here
476:24 - like that and then um we want this to be
476:28 - like densely connected
476:29 - so um
476:33 - this you would get i mean i didn't
476:36 - haven't actually tried it you would get
476:37 - like decent results
476:38 - maybe but the idea is you have all the
476:40 - pixel data then you want to multiply all
476:42 - the pixels by certain numbers and get an
476:44 - output
476:45 - uh the problem with this is there's no
476:48 - this actually really isn't a neural net
476:49 - because there is no hidden layer the
476:51 - idea of the hidden layer is to capture
476:52 - some kind of pattern
476:53 - and kind of generalize like some visual
476:56 - patterns or any any
476:57 - in this case visual because it's image
476:59 - stuff but any pattern in any data
477:01 - and i'll capture those patterns and then
477:03 - eventually filter through enough time to
477:05 - get some kind of
477:06 - results so i mean this does qualify as a
477:08 - neural net but
477:09 - if you delete if you get rid of the
477:11 - hidden layer um
477:13 - the idea of the hidden layers is the
477:14 - more hidden layers you have when the
477:15 - bigger the hidden layers are then the
477:17 - more patterns you can pick up on and the
477:18 - more accurate you can get
477:19 - so this kind of completely eliminates
477:21 - like all that pattern
477:22 - seeking stuff because you only have like
477:25 - uh one layer
477:26 - of of numbers to tweak so it probably
477:28 - wouldn't work that well
477:30 - uh but one single hidden layer does work
477:32 - pretty well
477:33 - um comments nigel says
477:37 - the hidden layer and its connection is
477:39 - the function
477:40 - so pretty much yeah it kind of like it's
477:44 - yeah it is i mean it's a function in the
477:46 - sense that you have input
477:48 - and then it does a bunch of computations
477:49 - and then you have some output um
477:51 - so the whole neural net itself is a
477:52 - function but also each layer is like a
477:54 - mini function within that
477:56 - so um yeah but then i mean the function
477:59 - we're trying to do here is
478:00 - input image output label of what the
478:02 - heck it is
478:03 - so that's the the high level function
478:05 - but then the inner function would be
478:07 - like okay
478:08 - um maybe for for this it's like okay
478:11 - does it have a curve like is there like
478:13 - a weird looking curve thing here because
478:15 - that
478:15 - it might pick up this curve and be like
478:16 - okay this might be a shoot because most
478:18 - uh shoes have a little curve you know
478:20 - like where your toe goes up to your
478:21 - ankle there's
478:22 - there's a curve in um and shoes a lot
478:25 - and does it
478:25 - does this look like an l you know
478:27 - something like that like a zork out of
478:28 - here
478:29 - are we gonna dive into the computations
478:31 - and how
478:32 - these neural networks work are we gonna
478:34 - dive into that or it's just the basic
478:37 - um outlay off a little bit i i want to
478:40 - touch on a
478:41 - touchdown a little bit but not too much
478:42 - because i mean yeah you can go you can
478:43 - go down the whole math rabbit hole if
478:45 - you want
478:46 - um but then it doesn't get too
478:48 - applicable i've touched on a little bit
478:49 - before but i don't want to go too deep
478:51 - into it
478:52 - so is it a good practice to dive into
478:54 - what like what this neural networks do
478:56 - or it's just like
478:57 - oh yeah this functions uh does this
478:59 - thing so i need not worry about
479:01 - what's going on within the hidden layer
479:03 - and it's just like
479:04 - one of those things it depends what you
479:06 - want to do or if you're trying to become
479:08 - a professor or become like an academic
479:10 - or research kind of person then yeah you
479:11 - should understand the math but if you're
479:12 - just trying to create apps and you want
479:14 - to find a way to
479:14 - apply this and make money from it like
479:16 - as a freelancer then you probably can
479:17 - you don't need to worry about the math
479:19 - so it really depends what your personal
479:20 - goals are um i'm trying to find like a
479:23 - good middle ground between both just to
479:24 - kind of give like a general
479:26 - understanding of okay the underlying
479:27 - math
479:28 - so somebody could like converse about it
479:30 - in a more intelligent way but then also
479:32 - have some kind of tangible result at the
479:33 - end without getting lost in the calculus
479:35 - because
479:36 - it gets really messy and i don't
479:37 - remember half of it i'd have to review
479:39 - all the
479:40 - the dirty math actually i'm uh pursuing
479:43 - my master's degree in data science
479:45 - okay a little bit uh curious i'm just
479:48 - starting off so this was a little bit
479:50 - curious about what's
479:51 - really going on within the hidden layers
479:54 - so as of now let's keep it simple maybe
479:55 - i'll go through your previous videos
479:57 - it's my first like uh coaching call with
480:01 - you
480:01 - i think oh welcome welcome so i'll
480:04 - definitely go through those
480:06 - uh your previous videos as well and grab
480:08 - uh most of the information from there
480:10 - and maybe
480:10 - i will get back to you later yeah
480:13 - awesome yeah i can pass you a couple
480:14 - resources too like if you're actually
480:15 - studying it there i know
480:17 - a couple other guys are doing similar
480:18 - stuff they're getting their masters
480:20 - um i was i i dropped out a few months
480:22 - ago but i was i was also pursuing my
480:24 - master's in
480:24 - machine learning but then i stopped to
480:26 - work here full-time so
480:28 - uh yeah i'll pass you a couple what is
480:30 - your or just message me on slack and
480:31 - then i'll pass you a couple of resources
480:33 - you can check out that you might find
480:34 - interesting
480:35 - yeah definitely yeah for that for the
480:37 - math stuff yeah of course yeah
480:39 - thanks aaron yeah um
480:42 - what was i saying oh yeah so the hidden
480:44 - layers are definitely
480:45 - needed because that's kind of like where
480:47 - the power the the work
480:48 - gets done it's like like that's the
480:50 - function the function like the main part
480:51 - of the function
480:52 - like this is just an input function this
480:54 - is just an output function but then you
480:55 - need like the pattern
480:56 - recognition like okay what is happening
480:58 - function which is the hidden layers
481:02 - okay uh let's continue on so
481:10 - [Music]
481:16 - okay uh let's continue on so
481:21 - um i'll leave that there because it
481:23 - might be useful later
481:27 - okie doke
481:31 - i was talking about the activation
481:32 - functions and then okay loss functions
481:34 - again loss functions tells us how wrong
481:37 - the neural net is
481:38 - and then optimizer tells us how to tweak
481:39 - all the numbers um
481:41 - and that's what we need for compiling
481:43 - just because we need to specify like how
481:45 - to do the correct calculations
481:46 - like once we pass data into the neural
481:48 - net we need to know what function to use
481:50 - once it's gone all the way through to
481:52 - measure our incorrectness
481:53 - and then also what function we need to
481:54 - use to opt to change all the numbers
481:57 - and uh repeat that with every image over
481:59 - and over and over again
482:00 - so that's what compiled us we're just
482:02 - getting our model our neural net model
482:04 - ready for uh training now we're just
482:07 - specifying all these things
482:09 - so next step from here is just to
482:11 - probably just pass in the data and
482:13 - get it going so let's do that next
482:21 - how many people are still on here you
482:22 - see one two four fifteen people or so
482:36 - hey aaron hey joe what is up
482:39 - i'm trying to make sense of what the
482:40 - hell is going on here
482:43 - ah did you come in were you here from
482:44 - the beginning or did you just jump no
482:46 - this is my first coaching call
482:48 - i mean i i was on a first first call
482:51 - but this is the first call with
482:54 - tensorflow is this
482:55 - is this the first call where you're
482:56 - starting tensorflow you did one before
482:58 - last week we did one yeah i missed that
483:01 - then okay
483:02 - yeah but the recording's in the course
483:03 - you can go watch it that one yeah it's
483:05 - about two hours it's a little bit
483:06 - messy yeah so if you if you can give me
483:09 - like a quick
483:10 - two-minute pitch of what what's the
483:12 - final
483:13 - goal here are we trying to achieve and
483:15 - yeah sure
483:16 - yeah i'll do that again because doing
483:18 - doing that over and over again is not a
483:20 - bad idea either just because it helps
483:21 - kind of solidify the ideas so
483:23 - again yeah tensorflow we're using this
483:24 - to design neural networks
483:26 - and um solve problems so we're creating
483:30 - a neural network like this within
483:31 - tensorflow
483:32 - the idea is we want to pass in um a
483:34 - bunch of images here
483:36 - uh within here each one of these
483:38 - correlates to a pixel
483:39 - brightness and then from there it'll
483:41 - filter through um the neural net all
483:43 - that
483:44 - all that means is each of these numbers
483:45 - has each of these lines has a number
483:47 - and you multiply that number by all the
483:49 - pixel values and over time you can pick
483:51 - up
483:51 - weird patterns and at the very end we
483:54 - can be like okay
483:55 - um this might be a shoe or this might be
483:58 - a shirt because the data we're looking
483:59 - at
484:00 - is actually um some
484:03 - oops was it supposed to do that
484:08 - well what happened one second one second
484:24 - there we go this one
484:30 - there we go uh did you see the the data
484:33 - that we were
484:34 - um looking at were you here from the
484:36 - beginning of the call joe
484:38 - no i just joined like maybe five oh okay
484:41 - got it yeah so we have a bunch of images
484:43 - like this is a shoe
484:44 - and then um let me just show you one
484:47 - more so this one
484:48 - is a
484:52 - um oops
484:57 - ah yeah it's running all this stuff
484:58 - because we have all the the code in
485:00 - there just ignore that for now
485:02 - so we had a shoe before and then we also
485:04 - have a shirt here okay
485:06 - so what we do is we have a bunch of
485:09 - images of different types
485:10 - and it's just like 20 by 28 images like
485:13 - this for shirts
485:14 - and basically they're of these 10
485:16 - different types so boots
485:18 - bags shirts t-shirt top trousers address
485:20 - all this stuff and the idea is
485:23 - we want to train our neural net on a
485:24 - bunch of these images that are labeled
485:25 - like this is a shirt the one before it
485:27 - was a shoe
485:28 - and we want to go through our neural net
485:29 - here and uh train this neural net so
485:32 - that going forward we can put in new
485:33 - images that look like this
485:34 - and then properly identify what they are
485:37 - gotcha so that's the
485:38 - so that is the practical example of it
485:41 - basically you're training
485:42 - you're training the network to recognize
485:45 - certain
485:45 - images associated it's like how your
485:48 - brain functions when you see something
485:49 - then next time when you see kind of
485:51 - associated with that correct
485:53 - yep that's it so that's what we're doing
485:55 - so what we did is we designed the whole
485:57 - model we designed the whole neural net
485:59 - um we have the whole input layer
486:00 - correspond to the whole image so 28 by
486:03 - 28
486:04 - we we flatten this out into a 784 by one
486:07 - column which is here so every pixel is
486:09 - represented then we filter it through
486:10 - all these crazy numbers so each of these
486:12 - lines has a number you multiply the
486:13 - number by the pixel value
486:14 - and you get a new set of numbers and
486:16 - then you do some other stuff and then
486:17 - you keep doing it over and over
486:19 - and at the end we're gonna have 10
486:20 - different nodes and then each of those
486:22 - is going to have a probability of how
486:24 - much it believes it's one of those
486:25 - things
486:26 - so in this case this is probably going
486:28 - to be
486:29 - probably shirt probably spit out a 6.
486:33 - and then the one before is was an ankle
486:34 - boot um and so so that's what
486:36 - that's what we're currently doing okay
486:40 - yep and let me just quit out
486:44 - if it will my computer is kind of
486:46 - screaming right now
486:51 - there we go oh no
486:56 - i think i broke it
487:04 - um dang it okay i'm gonna need a new
487:12 - all right cd desktop
487:15 - tensorflow app and
487:19 - uh source
487:22 - v and uh bin
487:26 - activate i think does anybody remember
487:27 - what the command for
487:30 - let me just find it
487:37 - why is even opening
487:43 - there we go bin yeah bin activate
487:46 - that's correct so this should work
487:50 - okay and then python 3
487:53 - image classifier that pi
487:59 - and okay there we go
488:03 - add though
488:07 - okay yeah this is the annoying thing
488:08 - because it's training the model every
488:09 - single time
488:10 - over five epochs just wait wait a second
488:13 - guys
488:14 - okay let's get rid of this one because
488:16 - this one is broken
488:18 - and there we go okay back to where we
488:22 - were
488:24 - so welcome joe so that's what we're
488:25 - doing uh now let me continue on
488:27 - in the code so each of these just uh
488:30 - just to interject so each of these lines
488:32 - uh when you say model uh so if you
488:37 - no scroll not not here go back to your
488:39 - code up
488:40 - scroll up for a second so
488:43 - model are you assigning this like a is
488:46 - that a
488:46 - library keras not sequential
488:50 - yeah okay so really really quick um you
488:52 - can watch the recording later to get the
488:53 - full explanation but really quick
488:54 - uh keras is a library that tensorflow
488:57 - uses
488:58 - to create graphs which is what matches
489:00 - it for the things and then tensorflow
489:01 - allows us to do the actual computations
489:03 - all this means sequential just means
489:05 - that there's a sequential thing of
489:07 - columns one by one one at a time
489:08 - there's no jumping between there's no
489:10 - jumping that's each is in sequence
489:13 - so that's the overall neural net then we
489:15 - specify three layers so the first layer
489:16 - for us
489:17 - is a layer of 128
489:20 - and then i mean of 28 by 28 which comes
489:22 - out to 784 and then we have one hidden
489:24 - layer of 128
489:26 - and then ignore these two pretend these
489:28 - two layers aren't here and then there's
489:29 - an output layer of 10
489:31 - um which is going to correspond to these
489:33 - 10 which is going to have the
489:34 - probability that each of these
489:36 - what how much it believes it's the image
489:38 - is one of these 10 things
489:39 - all right so that's how we create the
489:41 - model
489:42 - then from there then we created uh we
489:44 - have to compile it we have to specify
489:46 - a loss function and optimizer function
489:48 - so this just tells us how wrong the
489:49 - neural net is
489:50 - and this tells us how to up to change
489:53 - the neural net to make it a little bit
489:54 - more correct
489:55 - uh we just specify those two there uh
489:58 - you can choose a bunch like these names
489:59 - aren't important it's just there's a
490:00 - bunch you can choose from
490:02 - then from there then we can just start
490:03 - training so once we have the model built
490:05 - and we tell it which functions to use
490:07 - then we can
490:08 - uh start training the model here so
490:11 - this is how we do it so all you do is
490:13 - you call model.fit and fit just means
490:14 - we're going to fit our current model
490:16 - that we just created
490:17 - to the data set that we have uh given to
490:20 - it
490:20 - so in our case we have a bunch of these
490:22 - images like the the the clothing images
490:24 - there's 60 thousand
490:25 - so the 60 000 images in the training and
490:28 - each of those is also labeled 60
490:30 - 000 somebody some crazy person went
490:31 - through all 60 000 and manually
490:33 - label all of them um
490:36 - which is something i would not want to
490:38 - do and then we also want to specify how
490:40 - many times you want to
490:41 - go through this whole thing so an epoch
490:44 - is just one
490:45 - um one pass of this so you would
490:48 - put pass through all of the the images
490:51 - all 60 000 images see how wrong all of
490:53 - them were
490:53 - and optimize all them 60 000 times for
490:56 - all 60 000 images because there's 60
490:58 - 000 in here and then you would you would
491:00 - change everything in the neural net one
491:01 - time so what we're doing is we're
491:03 - actually adjusting all the weights
491:04 - in the neural net five times and that's
491:06 - what it does is
491:08 - we pass all the images and see how wrong
491:10 - they all are take the average of all how
491:12 - wrong it is overall
491:14 - and then optimize it overall and then we
491:16 - do that five times and that's actually
491:17 - what you're seeing here you can see that
491:18 - it runs five epochs here
491:20 - you pop one of five two five blah blah
491:22 - blah from this this was covered last
491:24 - week too if you wanna watch the
491:24 - recording
491:26 - um so that's what this does we're just
491:28 - taking our model and we want to fit it
491:30 - to our training images and labels so you
491:32 - just pass it in in this way images first
491:34 - then labels
491:35 - and then you specify them on an epochs
491:37 - and five seems to actually be pretty
491:39 - good
491:40 - because the images are pretty small only
491:42 - 20 by 28 we're not they're not even like
491:44 - they're they're really really tiny um so
491:46 - eat five epochs
491:47 - is sufficient here um cool
491:51 - yup uh last thing is now that we've that
491:53 - we trained our model
491:54 - now we just want to actually uh test it
491:57 - so
491:57 - all you do is you call the evaluate
491:59 - function instead so because after we run
492:01 - fit it's trained our model is now
492:02 - trained
492:03 - uh across five epochs that's why it was
492:04 - taking a while you saw that
492:06 - let me just run it again so when we run
492:08 - this
492:09 - you can see that the image is going to
492:11 - pop up um
492:13 - just ignore that so
492:16 - um here so you can see the epoch is
492:18 - running so it's actually running all 60
492:20 - 000 images
492:21 - and then it's it's seeing how wrong it
492:22 - is and then optimizing then how wrong it
492:24 - is and optimizing how wrong it is
492:25 - optimizing across all 60 000 images and
492:27 - it does that five times
492:29 - and then then it stops so that's that
492:31 - was the training and then at this and
492:33 - then you can actually see the loss so
492:34 - it's telling you how wrong it was after
492:35 - the first epoch
492:36 - and then you can see the loss is
492:37 - actually getting smaller and smaller and
492:39 - smaller
492:41 - and then i believe this is the uh
492:43 - average or something i think this is
492:44 - like some overall arcing
492:46 - uh loss or something like some global
492:48 - loss the whole neural net overall
492:50 - um and then from there so that's what's
492:52 - happening here now we can actually
492:54 - is it is it is it just learning one
492:56 - image or is it learning all the ten
492:58 - images
492:59 - across when you feed it in um so it's
493:02 - actually taking all of the
493:03 - 60 000 uh images and it's it's training
493:06 - it on all 60 000.
493:08 - oh okay and that error is and that error
493:11 - is across
493:11 - all those images right averages of all
493:13 - the images yeah how wrong they all work
493:15 - because we know the correct answer and
493:17 - then we know the answer the neural net
493:18 - thought it was and then we can kind of
493:20 - like measure how wrong it was and then
493:21 - from there
493:22 - which is what this does and then the
493:24 - optimizer will tell us how to optimize
493:25 - the weights
493:26 - a little bit better
493:33 - [Music]
493:35 - cool and if quick question then if
493:37 - you're only running
493:38 - five epochs on that and it's still down
493:40 - to what was it like 0.5 something
493:43 - for an error if
493:46 - presumably if you ran that like 10
493:48 - epochs could you get that you would get
493:50 - that down even closer
493:51 - i mean i guess let's try it i don't
493:53 - actually know um
493:54 - i just know that the the numbers within
493:56 - this app were actually pretty finely
493:58 - tuned to be
493:59 - like decent performance so let's run
494:01 - this for 10 and see what happens
494:08 - so first loss was three and then it got
494:11 - down pretty small
494:12 - i mean it's a pretty big jump and then
494:14 - the jumps get kind of smaller
494:16 - [Music]
494:18 - so i think there's yeah there's like a
494:19 - point of diminishing returns it doesn't
494:21 - look like it's getting
494:23 - too much smaller you can see it's kind
494:25 - of leveling out there
494:27 - yeah there's probably the data set isn't
494:29 - good enough and the image would be just
494:30 - too small
494:31 - so at a certain point it's just
494:33 - proportionally steeped in levels out
494:35 - right
494:35 - yeah so i mean that's also kind of like
494:38 - you need to like just use
494:39 - some human brain power there and just
494:40 - kind of be like okay well this seems
494:42 - kind of
494:43 - useless for the amount of time it took
494:44 - like this got eighty percent of the
494:45 - results so maybe we can just keep it the
494:47 - five
494:48 - um so we'll just put it back to five but
494:58 - okay i need a faster computer
495:07 - so if you increase the number of epochs
495:09 - this image
495:11 - won't get any clearer right now it's
495:13 - blurry
495:14 - no so what's happening is um there's a
495:17 - bunch of different images
495:19 - uh so like i just show you the first and
495:20 - second image the shoe and the shirt
495:22 - there's actually 60
495:23 - 000 in here so i i could even go like
495:24 - you know 50 000 if i wanted i could show
495:26 - you this image
495:27 - um why don't i do that just out of
495:29 - demonstration purposes but the idea is
495:31 - you're just passing in all these
495:32 - different images and then you want to
495:35 - um train across all those images but the
495:36 - image will always be 28 by 28 so this is
495:39 - just another issue so the 50
495:40 - 50 000 image in this data set is another
495:43 - issue
495:44 - but a little slightly different shoe
495:49 - okay oh my goodness
495:52 - i gotta i gotta stop doing that because
495:54 - it's gonna it keeps retraining the whole
495:56 - neural net over and over again every
495:57 - time
495:59 - okay so you're only focusing on a shoe
496:02 - you're focusing on even the shirt and
496:04 - the other 10 10 all together images
496:07 - combined oh we are so i mean if i chose
496:09 - like 40 000 hopefully this is not a shoe
496:11 - but there's ten different types of
496:13 - clothing types
496:14 - and it's just shuffle it's just
496:15 - randomized data label all right
496:18 - so here's another shoe okay i keep
496:19 - getting shoes for some reason
496:21 - but well and then again with the the one
496:24 - and ten chance
496:27 - yeah i mean how many times am i gonna
496:28 - get a shoe versus like dresses or bags
496:31 - or something
496:32 - by the time yeah i mean i wish they had
496:35 - images in here they don't have you know
496:36 - they don't like show you like the images
496:38 - like they'll be nice to actually have
496:39 - some
496:39 - sample but you have to go into the data
496:41 - set yourself so
496:42 - it is what it is but i can use you can
496:44 - just kind of take it with a grain of
496:46 - salt that this is
496:47 - what the data is it's just like
496:48 - randomized images that look like these
496:50 - things
496:51 - um so let's see what we have here so
496:55 - uh yeah so we trained our model across
496:57 - five epochs and we saw kind of like the
496:59 - diminishing returns there so epochs 5
497:01 - seems to be like a nice finely tuned
497:02 - number there
497:03 - for this uh this specific training data
497:07 - um and then the next thing we want to do
497:09 - is want to test our model
497:18 - the next thing we want to do is we want
497:19 - to test our model so we do that from
497:21 - using model.evaluate
497:22 - and very similar similarly to here
497:25 - instead of training it or fitting it on
497:27 - the training data we just want to test
497:28 - it on the test data
497:29 - so like i said at the beginning there's
497:30 - actually seventy thousand images
497:32 - uh within this data set we use sixty
497:34 - thousand for training and the remaining
497:36 - ten thousand for test
497:37 - so we we um put the sixty thousand in
497:40 - here and we're going to use remaining
497:41 - ten thousand images to see how accurate
497:43 - our neural net actually
497:44 - uh performed and and the thing is going
497:46 - to return is just
497:47 - um test uh the loss the overall loss
497:51 - which is
497:51 - it's actually just going to spit out
497:52 - this number this last one i think this
497:54 - is like some kind of loss average or
497:56 - something like that um
497:58 - but it's not super important i just kind
498:00 - of put there to save it i mean there is
498:01 - an accuracy
498:02 - number we can get i think uh there's
498:05 - like measure accuracy or something
498:06 - we can actually add that in a second but
498:08 - let me just finish off that first and
498:09 - then we can add it at the end
498:11 - um so when i do that then
498:15 - we kind of have to do all this code
498:16 - together because it nothing's gonna show
498:18 - but what happens here is it's basically
498:20 - evaluating and tells us how wrong it is
498:22 - but then we can also
498:23 - um make predictions so
498:27 - um let's do that next
498:31 - uh so yeah this will get us accuracy
498:34 - i'll do that in a second after
498:35 - afterwards but the predictions here so
498:37 - what we can do is we can actually take
498:39 - the test images
498:40 - that we have the remaining 10 000 and we
498:42 - can use our model to predict
498:44 - um each of these images and then we can
498:47 - actually compare that to the actual
498:48 - data the actual labels we have because
498:50 - we have the correct labels here the test
498:52 - labels but we don't want to give it the
498:53 - labels you just want to give it just the
498:54 - image and see how well it performs
498:56 - so this is going to give us predictions
498:58 - and um what predictions is is it's
499:00 - actually
499:01 - just going to give us the 10
499:02 - probabilities of each of these last 10
499:03 - things
499:04 - so let's start with that and let me just
499:06 - actually show you
499:08 - predictions at zero
499:11 - and predictions at i mean uh
499:17 - well actually let's
499:24 - let's do this so i'm going to get rid of
499:28 - this stuff
499:32 - and go down here so what we're going to
499:35 - do is
499:36 - on instead of train images we're going
499:38 - to go on test images so let's go to the
499:39 - first test image here
499:42 - i want to show you guys the first test
499:43 - image uh and then show that and let's
499:46 - actually just comment all this out first
499:47 - so we can go step by step together
499:49 - so we have the whole model trained and
499:51 - built and all that stuff
499:52 - now i just want to show the first test
499:54 - image and then let's just see what it is
499:55 - together because i actually don't know
499:56 - what it's going to be
500:01 - aaron i have a question instead of uh
500:05 - running the whole program again and
500:06 - again like it will again train the data
500:08 - in this thing we can use jupyter
500:10 - notebooks for just running the
500:12 - cell right yeah we could use jupyter
500:14 - notebooks yeah there's like a thing
500:16 - that has tensorflow built in um and it's
500:19 - called
500:19 - the google collaboratory but i i just
500:22 - prefer running it locally but i guess
500:23 - i guess we could i still haven't looked
500:24 - into that uh
500:27 - tori collaboratory google collab
500:31 - tensorflow i think i mentioned this last
500:33 - week
500:34 - oh yeah or we could just use regular
500:35 - jupiter notebook if we wanted to
500:38 - but i'm i came from c so i'm a big fan
500:41 - of just writing it
500:42 - in the local machine
500:45 - yeah because even for testing a single
500:47 - data we need to train the entire model
500:49 - that's
500:50 - yeah over and over yeah it doesn't keep
500:51 - the state i mean there's probably some
500:52 - way to keep the state
500:54 - um there between between runs
500:57 - in some way like actually you can
500:58 - probably save the neural net
501:00 - um in its current state and they just
501:02 - keep keep running it but
501:06 - yeah i haven't looked into the jupiter
501:08 - notebooks i haven't used juvenile books
501:09 - that much
501:10 - actually at all uh in my in my time
501:13 - programming but i'll try to look into it
501:16 - if it streams like
501:17 - streamlines the process for for next
501:18 - week
501:20 - yeah thank you thank you for the
501:23 - suggestion
501:24 - but uh okay so this is the first test
501:27 - data so again another shoe so apparently
501:29 - this
501:30 - data set is very shoe heavy and um
501:34 - let's actually also print out the
501:38 - uh label so let's go down here
501:43 - and print out the label of this first
501:46 - one so this should be test labels
501:48 - at zero uh
501:54 - yeah so we're just gonna have to wait
501:55 - for the it's
501:57 - train each time for now
502:15 - all right cool so it's a shoe here and
502:17 - then when i put out of this it should
502:18 - say
502:19 - nine which is uh ankle boot so nine is
502:23 - ankle boot
502:24 - so that's the correct label um so that's
502:26 - what we want to see we want to see the
502:28 - correct label here
502:29 - so we're just focusing on this chunk of
502:31 - code here
502:32 - the first test image is issue and the
502:34 - label is nine so now we want to use our
502:36 - trained model to actually predict
502:38 - um what is going to predict what it's
502:42 - going to be
502:42 - so if we print predictions at zero so
502:45 - this is the first image of
502:48 - a shoe in the label then we call
502:50 - model.predict and we pass in all the
502:52 - test images
502:53 - and it's going to give us all the
502:54 - predictions so and then all we need to
502:56 - do is this this is just a list of a
502:58 - bunch of
502:59 - outputs from the neural net so if we go
503:01 - at predictions at zero
503:03 - what we're going to get is we're
503:04 - actually going to get the the list of 10
503:06 - probabilities
503:07 - for the first image and then if we this
503:09 - if this was predictions at one
503:11 - we would get the list of 10
503:12 - probabilities for the second image so on
503:14 - and so forth but let's just focus on one
503:16 - at a time
503:17 - so let's um go back to
503:20 - here and run it again
503:28 - yeah i'll look into jupiter notebooks
503:30 - because this is going to get
503:32 - tedious at least it doesn't take it just
503:33 - takes like seven eight seconds
503:35 - not so bad
503:41 - all right and there we go so you see
503:43 - this here this is actually
503:45 - the the list of probabilities that our
503:47 - trained neural net popped out
503:49 - for that test image of that shoe that we
503:51 - just saw pop up so it needs to be nine
503:53 - so um ideally this is going to be the
503:55 - biggest number and it looks like it is
503:57 - like this is all scientific notation so
503:59 - um as this gets bigger that means it's a
504:02 - smaller number so 19 13 38 15
504:04 - 38 3 18 3 12 yeah one so this is
504:08 - actually the biggest number which is the
504:10 - ninth place
504:11 - because this is the probability of it
504:12 - being uh the first thing second thing
504:14 - and last one is ankle boot so this is
504:16 - the biggest number
504:18 - um and uh we can see it's actually
504:21 - performing correctly there
504:22 - but this is really messy and ugly so
504:23 - what i did is i put in a little hack to
504:26 - make it nicer to look at so let's do
504:28 - that together now and that's actually
504:31 - these two lines and all this is doing
504:34 - here
504:35 - is instead of printing out that nasty
504:36 - list of all these probabilities here for
504:38 - each of the 10 different things in the
504:39 - neural net
504:40 - um all i do is i find i use the max
504:43 - function
504:44 - so the max function here so
504:47 - look at this highlighted portion of code
504:48 - here this max function finds the
504:51 - the max number within this list for us
504:54 - which is going to be this last one it'll
504:56 - find this
504:56 - and then i just call index on it
505:00 - so uh so that i can find the the um
505:03 - the index of the the max number in that
505:06 - list so all this is doing here this is
505:07 - kind of messy is
505:08 - it's just getting the index of the
505:10 - biggest number in this list
505:12 - in this case it's going to be 9. so this
505:14 - will just return us the index of the
505:15 - biggest number
505:16 - and that's what i'm printing here
505:17 - instead so let's
505:20 - print that out and see what happens
505:24 - predictions and labels at zero
505:33 - oh again it's got a train okay one last
505:35 - time for this demonstration purpose
505:37 - and then i'll do one more image too
505:39 - because i think it it gets these correct
505:47 - there we go so here's the shoe of the
505:49 - first test image
505:50 - and it's labeled the label is supposed
505:51 - to be nine which pops up
505:53 - and then as you can see here's the 10
505:55 - probabilities again the probabilities
505:57 - are a little bit different this time
505:58 - because it i guess it trains it in
505:59 - different
506:00 - it trains the neural net in random
506:02 - orders of the images or something like
506:04 - that so it's not always exactly the same
506:06 - but as you can see the it says that this
506:08 - number is the highest because it's the
506:10 - last one so
506:11 - uh it actually predicted this image
506:12 - correctly um i don't know if i printed
506:14 - out twice i think i'm
506:16 - printing it oh because i i print out
506:18 - this again now i don't need this
506:22 - actually let's get rid of that one
506:26 - so as you can see it's well actually put
506:29 - that back let me get rid of this last
506:30 - one
506:32 - um so as you can see it actually
506:33 - predicted it correctly so it's supposed
506:35 - to be 9 and then the neural net
506:36 - predicted it to be 9 as well and if we
506:39 - go to the
506:43 - second image which hopefully is an issue
506:46 - this is
506:46 - bad coding design just popping in the
506:50 - one there like that but just to show you
506:51 - guys
506:52 - so let's see what this is uh hopefully
506:54 - it's a shirt or something
507:09 - okay
507:13 - ah nice a shirt okay or some some type i
507:15 - don't actually don't know what it is it
507:17 - might be
507:17 - it might be pull over or probably
507:20 - probably going to be pull over because
507:21 - it's long sleeve it looks like it's a
507:22 - sweater
507:23 - or something so this is the image the
507:25 - second test image
507:26 - and we see that it's a two labeled as
507:29 - two so yeah
507:30 - it is a pullover too and then this is
507:32 - the probabilities of everything
507:34 - and it seems like a pretty predicted it
507:36 - to be correct
507:37 - so it it accurately predicted predicted
507:39 - it to be a
507:40 - pullover and if we look at this 0
507:45 - one two yeah it looks like this index is
507:47 - the biggest number
507:48 - because this is only negative one
507:49 - compared to everything else is a little
507:50 - bit bigger
507:51 - don't know what this is it's a little
507:53 - funky
507:55 - um i'm not sure why these are zeroed out
507:58 - but uh yeah it looks like um
508:01 - it's it's predicting it pretty pretty
508:03 - accurately so
508:06 - uh that there is actually it for the for
508:09 - the app let me see if i can get that
508:10 - accuracy thing because this
508:11 - will actually uh test the accuracy of
508:13 - the thing overall
508:15 - i think it was
508:18 - measure accuracy
508:29 - matrix equals
508:46 - accuracy class there you go
508:56 - maybe this yeah so when you're compiling
508:58 - the model you can actually also specify
509:00 - uh different metrics for it to spit out
509:02 - um so if you go back up to compile and i
509:05 - add it
509:05 - here i think it's metrics equals
509:09 - see i think
509:13 - um and then let's just try that and see
509:16 - if it breaks it might break
509:26 - um
509:29 - actually i think it worked well i think
509:33 - it's gonna give an error right now
509:35 - because i didn't specify
509:39 - the oh okay i didn't complain um i think
509:45 - i think they changed some stuff in the
509:47 - new version tensorflow um
509:50 - matrix accuracy maybe this one let's try
509:54 - this since that's what they're telling
509:55 - me to use
509:56 - no actually the accuracy is written
509:58 - there uh
509:59 - below under each epoch open the terminal
510:02 - maybe i noticed did you see something
510:07 - yeah yeah right 81.97 accuracy
510:10 - oh nice i didn't even see that because
510:12 - it was okay
510:14 - pocket shows that finally i didn't see
510:17 - that at all
510:18 - good eye good eye thank you oh nice
510:22 - yeah i only i'll usually only look at
510:24 - lost because you
510:26 - because uh all of all of the machine
510:27 - learning is when the neural net is
510:28 - you're just trying to minimize the loss
510:30 - like at the end of the day you want to
510:31 - get this as close to zero as possible
510:33 - and then this has like an inverse
510:34 - portion to the accuracy so cool so we
510:37 - didn't even have to worry about it
510:38 - um wait was this actually running oh no
510:41 - when i did pop in accuracy it added it
510:43 - on
510:43 - nice so like when i added on this this
510:45 - metrics accuracy so this actually is
510:47 - correct
510:47 - what it is does is i guess it it um
510:51 - added on the the the accuracy metric
510:54 - here so we have the loss
510:56 - um and then i guess uh not sure what
510:59 - this is probably just the timing but
511:00 - yeah the accuracy is is here
511:02 - which is good so we don't have to that's
511:04 - it so that actually that was correct i
511:06 - just didn't i didn't notice it
511:08 - thanks for noticing that um was that you
511:10 - ruben
511:12 - yep is it you thank you ruben no problem
511:15 - so yeah the accuracy there so we can
511:17 - actually say that
511:18 - uh across everything it has a 0.81
511:22 - accuracy uh for all of the test data so
511:24 - when it's running those 10 000 test
511:26 - images then the accuracy is about about
511:28 - that much
511:30 - oh pretty cool i mean if we run 10
511:33 - epochs i wonder how much that will
511:34 - actually
511:35 - improve the accuracy of the neural net
511:45 - and i think this can be the last thing
511:47 - we do to wrap it up
511:56 - seven
511:58 - okay yeah it looks like it's increasing
512:02 - slowly
512:05 - nice and then there's the second test
512:09 - image of the shirt
512:11 - but yeah it looks like it's going up
512:12 - slowly i mean it's probably going to
512:13 - level out at some point
512:15 - um because of the structure of the of
512:17 - the neural net like if you have a deeper
512:18 - neural net
512:19 - we might be able to get this up into the
512:20 - 90s or something the accuracy
512:23 - but i mean this is this is pretty good i
512:24 - mean if it's if it's right
512:26 - 83 at the time i feel like that's a
512:27 - pretty decent neural net for the time it
512:29 - took to train it it only took like
512:31 - what 20 seconds 30 seconds so
512:44 - um that that kind of completes it guys
512:46 - for the
512:48 - uh like computer vision example of using
512:51 - tensorflow
512:52 - so a lot more interesting than last week
512:53 - i know last week we kind of just did
512:55 - this
512:55 - this uh this cute little number mapping
512:57 - thing wasn't that interesting and it
512:58 - wasn't that
512:59 - that uh it was just kind of numbers and
513:02 - stuff but
513:03 - this one i think it it kind of shows the
513:05 - power of tensorflow a little bit better
513:06 - because it's so easy to define your
513:08 - models and then flatten it you can tweak
513:10 - all the numbers and all the different
513:11 - functions already implemented for you
513:13 - all different types like dense and flat
513:14 - and it's all there for you which is
513:16 - which is amazing um so
513:20 - i mean that really concludes it for the
513:21 - for this image classification of course
513:23 - we can get a lot more complex and a lot
513:25 - deeper than this but this kind of
513:27 - gives a a good uh introductory example
513:30 - to um computer vision and image
513:33 - classification with tensorflow
513:34 - so uh does anybody have any any
513:37 - questions about anything
513:38 - at all um regarding regarding this
513:42 - just a quick one um
513:45 - if you go up to the where you've got
513:47 - your hidden layer again
513:50 - is it as simple if you were if you
513:52 - wanted to create a
513:54 - network with more than one hidden layer
513:56 - is it just duplicating that piece of
513:58 - code there
513:59 - and having it
514:02 - yep just like that so why don't we try
514:05 - to see what happens
514:06 - um hopefully it doesn't break anything i
514:09 - mean
514:10 - sometimes like i don't know like this
514:11 - might be some memory issues or
514:13 - because you know it exponentially
514:14 - changes stuff or let's
514:17 - let's just make this 64. and see what
514:19 - the heck happens
514:20 - um because yeah the input and the output
514:22 - is still consistent with our data
514:24 - um that we're dealing with the hidden
514:26 - layers can be abstracted to anything we
514:28 - want
514:29 - so uh yeah let's see
514:34 - actually let's run it for that's fine i
514:37 - can just cut it if it
514:44 - breaks
514:46 - all right nice
514:57 - all right there we go so it ran
515:00 - and um it seems like the first loss is a
515:04 - little bit lower than general
515:05 - it doesn't look like it really improved
515:06 - the effectiveness that much
515:08 - i mean also the time didn't go up too
515:10 - much either so it kind of really didn't
515:11 - do
515:12 - anything um
515:15 - yeah i didn't really do much with this
515:17 - data set in this this problem but i mean
515:20 - i mean why don't we try to add oh it's i
515:22 - mean if adding a second one didn't do
515:24 - anything adding a third one is not going
515:25 - to do anything either
515:26 - that's usually how it goes uh well let's
515:29 - try to go to up to 128 and see if that
515:31 - changes anything
515:34 - just see what the heck happens i mean it
515:37 - still predicted it correctly because we
515:38 - added
515:39 - we added more accuracy to it so it makes
515:42 - sense that it's still correct
515:43 - when it when it predicts
515:47 - and the actors actually was a little bit
515:49 - higher right i think it was a little bit
515:50 - higher
515:51 - by like two percent but it's kind of
515:55 - um okay well it seems like this one got
515:57 - worse even though i increased the the
515:58 - length of the hidden layer
516:00 - so yeah i guess
516:03 - this is where the fine tuning comes in
516:05 - and then like there's also like you
516:06 - might over
516:06 - fit to like your training data sometimes
516:08 - like sometimes if you train it too much
516:10 - then it gets so so familiar with the
516:12 - training data that it actually has a
516:14 - reverse effect
516:15 - on um new data like it gets so so well
516:18 - trained to
516:18 - the training data and like that data
516:20 - exactly that it gets stupider
516:22 - the more you train it so there's like a
516:23 - weird trade-off there too you kind of
516:24 - want to
516:25 - don't train it too much because then you
516:26 - can kind of preserve the generic
516:28 - patterns that are
516:29 - existing in the training set without
516:31 - over fitting it the term is overfitting
516:33 - so when you fit it to this training
516:35 - thing that you kind of want to like
516:37 - not do it too much it's this is balance
516:39 - act this balancing act
516:41 - [Music]
516:49 - all right um what would be a practical
516:53 - example of this
516:54 - uh you know in the real life kind of is
516:56 - it like a facial recognition
516:58 - that does the c you know the fbi
517:01 - and they they run is that something
517:02 - similar yeah so i mean
517:04 - tensorflow like there's a lot of
517:06 - applications for machine learning in
517:07 - general uh one that i like to use
517:09 - that just kind of like uh let me just
517:11 - pop up the tensorflow
517:13 - the docket classifier the
517:18 - cat classifier yeah yeah i mean
517:22 - from a standpoint of like okay where is
517:24 - this useful it's just like you could use
517:26 - it for anything like
517:27 - one of the classes i mean i didn't take
517:29 - it but i did a little bit
517:30 - in my time it georgia tech was using
517:33 - machine
517:34 - learning for trading so it's like doing
517:36 - um stocks and understanding trends and
517:38 - stuff in the economy
517:39 - um for day trading and stuff like that
517:41 - but yeah so like uh
517:42 - you can you can use it for applications
517:44 - like that joe
517:45 - to um maybe like find patterns and like
517:48 - stock prices and you're like okay you
517:49 - can kind of
517:50 - use machine learning to figure out like
517:52 - okay tesla stock is going to keep rising
517:54 - because historically it has you can like
517:55 - pick up patterns that humans really
517:57 - can't
517:57 - pick up that that well um
518:00 - so there's stuff like that there but
518:02 - little projects like this are just kind
518:03 - of to
518:04 - just kind of showcase your ability to
518:06 - use tensorflow and stuff like that
518:07 - um but you do need to understand you
518:09 - need to understand like the general
518:10 - machine learning concepts you need to
518:12 - understand how to
518:12 - actually code tensorflow itself and all
518:14 - the little different nuances and the
518:15 - syntax stuff there
518:17 - but then also how you can apply this to
518:18 - like the real world if you actually want
518:20 - to use
518:20 - machine learning uh to your advantage to
518:22 - make it like
518:23 - you know a monetizable skill for
518:25 - yourself uh as a freelancer or as
518:27 - a full-time developer or something so if
518:30 - if
518:30 - you take your uh stock trade an
518:33 - analogy how would that uh transpose
518:37 - uh when you're talking images versus uh
518:40 - numeric data right
518:43 - at the end of the day the images are
518:45 - just
518:46 - a two by two matrix of numbers which is
518:48 - the pixel brightness
518:50 - so it's just picking up arbitrary
518:52 - patterns in
518:53 - a two by two matrices of numbers so you
518:55 - can actually even pick up
518:56 - similar data within like stock prices
519:00 - and historical data or something like
519:01 - that pick up patterns there be like okay
519:04 - this is a good trend this is a bad trend
519:06 - of a stock price this is a good stock
519:07 - this is a bad stock
519:08 - stuff like that and then you can kind of
519:10 - like label it as this trend is good
519:12 - this trend is bad train it train and
519:14 - train it pop in new trends and then it
519:15 - can kind of tell you if it's good or bad
519:17 - stuff like that's the kind of have you
519:19 - have you thought about doing a
519:21 - class project to do the lot of numbers
519:24 - oh lotto numbers um
519:26 - that would be kind of interesting
519:29 - training to pick a lot of numbers for
519:31 - you
519:31 - well a lot of numbers are kind of com
519:34 - aren't they completely randomized so i
519:35 - mean i don't know if machine learning i
519:37 - mean maybe no but
519:38 - you you get the data on on the uh if you
519:40 - go to the lottery
519:41 - website they give you the past 10 years
519:44 - of data and based on
519:46 - based on historical you know that there
519:48 - are very good chance that they repeat
519:49 - the numbers
519:51 - on that day for that day like they run
519:54 - if you do the
519:54 - what is that it's not truly randomized
519:56 - wait the lotto isn't truly randomized
519:58 - no i'm not this is a friend of mine i
520:02 - think he figured out a way
520:03 - so you know how you play in the one one
520:05 - is at the two o'clock
520:07 - and there's another uh at ten o'clock at
520:09 - night
520:10 - yeah i've never actually done it but i'm
520:12 - so if you if you so
520:13 - this guy he he would download five years
520:16 - of history
520:17 - from the lotto website and then he he
520:20 - had a excel macro
520:22 - created that would color chart basically
520:26 - and then he would just play the numbers
520:28 - that get that the macro would spit out
520:31 - and he was making 42 grand a year
520:35 - oh wow really yeah i mean this is no
520:38 - joke this is
520:39 - the guy i work with and
520:43 - yeah i mean machine learning yeah it's
520:45 - it's powerful yeah because like a lot of
520:46 - stuff i know guys in poker who use it
520:48 - you know they like use it to like
520:50 - play poker and maximize stuff using
520:51 - machine learning by like doing that
520:53 - you can apply it to anything it's just
520:55 - like at the end of the day yeah it's
520:56 - just picking up patterns and data and i
520:57 - guess yeah if the lottery isn't 100
520:59 - randomized like truly randomized then
521:01 - yeah you can pick up
521:02 - patterns over time and kind of like bend
521:04 - it to your um
521:06 - gambling benefits but uh
521:09 - i've never personally done that i mean
521:11 - it sounds like a cool project though i
521:12 - mean
521:12 - i touched on a good amount of tensorflow
521:14 - so far because it doesn't get too much
521:16 - from here like it doesn't get too much
521:18 - in depth like i've kind of covered like
521:20 - half or sixty percent of like the basic
521:23 - like skills you need to like kind of get
521:25 - started
521:25 - then of course there's all these
521:26 - different functions and then you have to
521:27 - kind of figure out like okay like
521:29 - which optimizer is good for this thing
521:30 - and the different data types and making
521:32 - sure everything is like lined up
521:33 - correctly
521:34 - um maybe i've only done like five or six
521:36 - projects with it like
521:37 - in depth um but
521:41 - uh from there then i mean yeah we could
521:43 - probably
521:44 - it might be interesting to do something
521:45 - like that like i'll like just kind of
521:47 - build a lotto
521:48 - lotto thing together just to see you you
521:51 - you train the model and then you pick a
521:52 - ticket it's a buck
521:54 - and see you know you close like actually
521:57 - you want to like actually get a real
521:58 - a real live number i mean it's not like
522:01 - a dollar or something right
522:02 - yeah maybe and they and then they have
522:05 - the uh
522:06 - they draw a drawing at two o'clock in
522:08 - the afternoon and then they draw it
522:10 - 10 o'clock at night i don't know in
522:12 - connecticut at least they do it i don't
522:13 - know
522:14 - how they do it up in la uh might be
522:16 - different
522:18 - yeah i've never even looked into it i
522:19 - try to stay away from that because i
522:20 - feel like it's just
522:22 - it's like i'd rather just go to vegas
522:23 - you know like at least have some fun
522:25 - with it
522:25 - instead of oh they picked my number no
522:28 - they didn't
522:28 - like vegas you know there's there's
522:30 - people and there's
522:32 - yeah more fun than lotto but
522:36 - um yeah i mean that that's a cool idea
522:39 - i did want to ask though because i have
522:41 - been doing tensorflow stuff and i mean
522:42 - it's been kind of like a two-month
522:43 - process of like teaching you guys like
522:45 - the algorithms insertion sword and going
522:46 - through numpy and pandas and everything
522:49 - slowly up to this point um
522:52 - but i was talking to kazi the other day
522:53 - too and then he was like yeah like i
522:55 - mean the idea clever programmer is to
522:56 - get you guys the results like maximize
522:58 - results like maximize value for you guys
523:00 - so this stuff i mean it interests me and
523:02 - i'm teaching you guys and i feel i
523:03 - finally got into this point of teaching
523:05 - you guys
523:05 - um a good chunk of tensorflow you guys
523:07 - kind of get your feet wet in it
523:09 - um if you're if you're not pursuing your
523:11 - master's in data science like some some
523:12 - people are in the course which is great
523:14 - but uh i want to ask you guys what would
523:17 - be most of value to you like would it be
523:19 - more
523:19 - of value to you to like go back to web
523:21 - development and like the freelancing
523:22 - stuff because i can kind of brush up on
523:24 - that because i know nasir was
523:25 - talking about he would learn some django
523:26 - rest api stuff so i'm pretty rusty on
523:29 - that but i could i could try to brush up
523:30 - for
523:31 - uh the following weeks and then i know i
523:33 - know your ecommerce website tom i i see
523:35 - you posting
523:35 - about that periodically um stuff like
523:38 - that
523:38 - so i just want you guys input if you
523:41 - guys like doing this
523:42 - this tensorflow stuff or if you guys
523:44 - would prefer to like go back to web
523:45 - development
523:46 - um and we're still in the process
523:48 - process of looking for a really good
523:49 - python developer
523:50 - we're trying to find a guy that can um
523:53 - who has more experience than me
523:54 - to really help you guys
523:58 - scale up
524:05 - you know you are doing good aaron i
524:07 - really like the content of the
524:09 - it was today today was my first class
524:11 - after the first coaching call actually
524:13 - with you and
524:14 - i pretty much pretty much learned a lot
524:16 - of things out of it
524:17 - so i think like you had a machine
524:20 - learning
524:20 - uh career in the past and you are
524:23 - teaching
524:24 - machine learning related stuff so you i
524:26 - think you should pretty much
524:27 - um focus on this maybe like maybe for a
524:31 - bit of change or something you can uh
524:34 - skip on to
524:35 - web development just for the taste of it
524:37 - but maybe you should keep your
524:39 - uh like the path clear
524:42 - in like in which you are comfortable
524:44 - with which is which suits more for you
524:46 - most
524:50 - yeah i mean i could the only thing is
524:52 - that like
524:53 - there are a lot of beginners so that's
524:55 - the problem you run into when you have
524:56 - group
524:57 - like group calls and group sessions is
524:58 - everybody's kind of at a different spot
525:00 - so it's kind of hard to figure out
525:01 - something that's good for everybody
525:02 - without being too beginner or too
525:04 - advanced
525:05 - um machine learning i mean there's
525:07 - probably only like a few edge cases
525:08 - where you'd actually need it like for
525:09 - people if they're advanced and they
525:10 - could probably like land clients or it'd
525:12 - be applicable to some project they're
525:13 - working on but usually they're more
525:15 - advanced usually like whipping up like
525:17 - you know like the amazon club or
525:18 - something or something front end might
525:19 - be
525:20 - a little bit better like the way um like
525:23 - they are within the javascript course or
525:24 - something
525:25 - but about combining say you have
525:28 - create a web interface with maybe a rest
525:31 - interface and you run
525:33 - this algorithm or another algorithm
525:35 - algorithm on the back end and then you
525:37 - output it to the browser
525:39 - or something that'll be cool yeah like
525:41 - tying it together um i mean it'd be cool
525:44 - to like like just take this
525:45 - this project we just did and then like
525:47 - kind of wrap it in like a front-end
525:48 - thing and like maybe save something
525:49 - maybe save the state of the neural net
525:51 - in like some django database so that we
525:53 - have to keep like
525:54 - training it like we did and then maybe
525:55 - we could do something big or something
525:56 - like that could be cool
525:58 - uh okay uh anybody else have
526:01 - have anything they want to say about
526:02 - that though like would they feel like
526:04 - web development might have a little bit
526:06 - more
526:06 - um value for them when it comes to like
526:09 - actually
526:10 - yeah i mean if you look at any anything
526:12 - that's on upwork or any others you know
526:14 - that's more
526:16 - i don't see any tensorflow tensorflow
526:18 - stuff
526:19 - that's i mean unless you unless you have
526:22 - that skill and niche
526:23 - and it's very hard to find that kind of
526:25 - projects but
526:27 - you would find a lot of web development
526:28 - projects there
526:30 - yeah yeah i think like more than 60
526:32 - percent of the web development i mean
526:34 - whereas we've suggested a kind of a
526:36 - blend
526:37 - of both where you know leverage and you
526:40 - get machine learning learning um
526:43 - output yeah definitely i mean it would
526:45 - be cool and fun to blend it
526:47 - um it would be a fun a fun thing to do
526:49 - but these are all recorded which is why
526:51 - i kind of
526:51 - touch on it because anybody wants to
526:53 - learn all this thing there's like a
526:54 - series of like six videos recorded
526:56 - sessions
526:56 - that they can go through and kind of get
526:58 - started with it which is the great thing
526:59 - with these live calls because they're
527:00 - kind of like they stay there forever
527:03 - um but going forward um i just don't
527:05 - know if that would be more useful for
527:07 - you guys like
527:08 - yeah looking here i've been i haven't
527:09 - been on i've been through that in a long
527:10 - time but
527:11 - tensorflow machine learning data
527:15 - i need to look under jobs not people
527:20 - in my opinion um javascript has a more
527:23 - solid grip in web development and
527:26 - python is more oriented towards machine
527:29 - learning data science it
527:31 - has more to do with the data than
527:34 - the side effect yeah
527:38 - aaron have you what the content you
527:41 - produced on youtube why don't you go
527:43 - over some of that
527:44 - image recognition or car face
527:47 - detection i mean why don't you go over
527:49 - that
527:50 - i could yeah um open cv heavy
527:54 - so i was i didn't really use tensorflow
527:56 - too much for that stuff and then
527:57 - actually we
527:58 - implement i mean because i was it i was
528:00 - at georgia tech so they're
528:02 - very much about like academic research
528:03 - and everything like that that kind of
528:05 - school they're very much about like you
528:06 - know cutting edge research blah blah
528:07 - blah
528:08 - so like we actually had to code like
528:09 - stuff up from scratch like
528:11 - why didn't we use opencv but we would
528:13 - code things like not even using
528:15 - tensorflow
528:16 - um at the beginning yeah i mean
528:19 - yeah i didn't mean it to be specific to
528:22 - uh
528:22 - tensorflow but you know just as the
528:25 - projects
528:26 - oh like opencv um
528:30 - i'm trying to think of what i did yeah
528:32 - there is some word
528:34 - the issue with that is some of the stuff
528:35 - i learned is is like it's fascinating to
528:37 - me because like we get into the dirty
528:38 - math but at the same time i don't
528:40 - it's kind of hard to explain these
528:41 - really complicated concepts too because
528:43 - like it requires like
528:45 - understanding of a lot of calculus and
528:46 - weird things so it's
528:48 - sometimes it's hard to like regurgitate
528:49 - what i learned to you guys so i
528:52 - the stuff on youtube was great though
528:53 - because i kind of boil it down to like
528:54 - the general principles of you know like
528:56 - self-driving cars and car and
528:57 - pedestrian tracking and everything uh
529:00 - face detection small detection all that
529:01 - stuff was cool
529:02 - but um just it's more tangible you can't
529:06 - relate
529:07 - you can show and demonstrate and then
529:09 - people can understand is that
529:12 - yeah i just try to like trying to find
529:14 - like the the good middle ground
529:16 - of um just like interesting content but
529:18 - useful i mean i could go into opencv a
529:20 - little bit more maybe i could find some
529:21 - cool projects there instead of
529:23 - tensorflow
529:24 - or even tie it together both but
529:27 - um
529:30 - um just on that last topic i was just
529:33 - thinking
529:34 - like where would ai be used
529:37 - in commerce like on a commerce site or
529:40 - something where
529:40 - people are like um matching up buying
529:45 - and selling or search algorithms or
529:48 - yeah so i mean i guess like you know
529:50 - like recommend you know amazon
529:52 - like you know amazon has like that'll be
529:53 - actually pretty cool because i know
529:54 - sunny and then they did the amazon clone
529:56 - and stuff it'd be cool if we implemented
529:57 - like uh
529:58 - you know like a recommended item yeah
530:00 - that's exactly yeah
530:03 - recommended systems are huge in ai or
530:06 - machine learning yeah definitely like
530:09 - that or like or like netflix clone you
530:10 - could have like recommended shows
530:12 - or or spotify clone you got recommended
530:14 - songs
530:15 - um you know how is it trends in people's
530:18 - behavior
530:19 - in netflix it's a if you look if you
530:20 - watch a certain genre movie
530:23 - it recommends hey since you watched this
530:25 - maybe you would interested in
530:27 - and the others like words recommended so
530:36 - yeah right here inspired by your
530:37 - purchases so apparently i was uh
530:40 - why is it recommending this stuff i
530:42 - don't know what this is
530:44 - i reckon it's a regular menu this is why
530:46 - i should get a topic because
530:48 - amazon does this to me all the time i
530:50 - think an insight into your life here
530:52 - flour water salt yeast so apparently i
530:54 - want to learn how to cook bread
530:56 - at some point you bought something
531:00 - today i searched for pizza and i got
531:02 - results for bikinis
531:06 - again this could be someone tagged you
531:08 - on facebook that
531:10 - they they do a lot of cross they do a
531:12 - lot of cross
531:13 - uh hashing too meaning you know
531:16 - yeah one of your friends who tagged you
531:18 - and
531:26 - either the algorithm is weak or the user
531:28 - or the buyers are stupid
531:32 - it could yeah i mean if
531:36 - i had to give any feedback on it this
531:38 - stuff's really interesting i've never
531:39 - never heard of tensorflow before the
531:42 - last week of the week before
531:43 - um i mean so i would probably just echo
531:46 - what the other guys were saying you know
531:48 - just
531:48 - just kind of played your strengths if
531:49 - this is the stuff that you know
531:51 - um yeah and stick with it i think
531:54 - the only thing i would say being new to
531:56 - this is it's
531:57 - all really um it's very abstract um
532:02 - yeah so behind it yeah but i mean
532:06 - the whole concept of what it's doing
532:07 - it's it's kind of you know it's really
532:09 - abstract and um
532:11 - i think if you can find something like
532:14 - what you're just looking here you know
532:15 - the recommended things and how
532:17 - how it could be applied in real world
532:20 - situations
532:21 - um yeah if you can come up if you can
532:23 - come up with something like just a
532:24 - really obvious one like
532:26 - like you said amazon recommended or
532:27 - whatever um
532:31 - this is how you can leverage what you
532:33 - know sort of stuff
532:34 - whether it's tensorflow specifically or
532:36 - this you know
532:37 - the same similar sort of theory just you
532:39 - know different platform whatever they're
532:40 - using
532:42 - um would tensorflow be used in like
532:46 - speech
532:46 - recognition and we have like you have
532:48 - 1000 different languages across the
532:50 - world right yeah absolutely yeah you can
532:52 - use it for voice recognition too
532:54 - because voice recognition at that it's a
532:56 - little different because
532:58 - the files the data is like a little bit
533:00 - different
533:01 - um i mean like once it's once it's
533:03 - within the correct
533:04 - form then it's fine but like voice data
533:06 - is like a continuous stream rather than
533:08 - like you know an image
533:10 - but i mean with like so when i buy the
533:13 - alexa right
533:14 - it's it's that
533:17 - is this thing is this thing built into
533:20 - alexa or
533:21 - or when you speak when you talk to
533:23 - alexites it's communicating with another
533:26 - server that has the machine level being
533:29 - constantly updated it's constantly
533:31 - learning
533:32 - and oh um i actually don't know how it
533:34 - works probably something yeah
533:36 - i think you need to be connected because
533:37 - every time i get disconnected from my
533:39 - my uh echo or whatever devices
533:43 - it doesn't respond mostly the second
533:46 - case
533:47 - joe actually i read about it somewhere
533:49 - that it actually
533:50 - the server trains your data
533:53 - are received by this echo dot it's like
533:56 - it continuously trains your data
533:57 - so so there is dropping on me or they
534:00 - can
534:01 - see they have yep they have all your
534:03 - data actually
534:05 - yeah and it's always it's always
534:07 - learning because i've looked at my
534:08 - election and it's got
534:09 - comes up with like a yellow flashing
534:11 - band on it and it's just you say what
534:13 - are you doing and it says i'm listening
534:14 - to you like
534:16 - it's listening it's listening yeah it
534:18 - says
534:19 - i'm listening to your speech and things
534:21 - going on in the background to like
534:23 - to learn as long as it's powered if you
534:25 - if you don't want it to listen
534:27 - if i take out the power it it won't
534:29 - right no there supposed to be options to
534:31 - disable it
534:32 - i mean this was a huge issue years ago
534:34 - that people it was very big issue
534:36 - a couple years ago yeah the privacy and
534:38 - everything consent and all that right
534:40 - yeah i know mark zuckerberg got busted
534:42 - right for like a similar thing right
534:44 - like
534:45 - yeah because of the data analytica
534:48 - the
534:52 - they did the whole rig the whole
534:53 - election thing well they took the data
534:56 - and
534:56 - they did and they used it for for
534:59 - you know whatever the ads without
535:02 - um yeah but this is interesting
535:05 - it's it's washed um
535:11 - like whoever's doing the machine data
535:12 - science for them
535:14 - you know they have this like you know as
535:16 - a part of the curriculum then it's
535:17 - awesome but
535:19 - for us we'll get into like you know
535:22 - trying to get a project make money make
535:24 - money off of it having
535:26 - but the blended would make more sense in
535:29 - this way at least
535:30 - you can put it in a portfolio that you
535:32 - did this and
535:35 - i'll look it up no worries thank you
535:37 - guys appreciate it
535:38 - yeah absolutely all right i think we've
535:41 - been going on for like almost two and a
535:42 - half hours now
535:43 - um any less questions or
535:46 - um is it time to go get some lunch
535:53 - you guys are on the east coast or
535:54 - something
535:56 - it's 3 30 am over here
536:04 - all right you guys well thanks for
536:05 - sticking to the end um all right guys
536:09 - talk to you guys next week
536:14 - [Music]
536:21 - yeah guys and that's really it so i
536:22 - hand-picked these four projects for you
536:24 - because i feel like they're
536:25 - just really like a good bite-sized
536:27 - project for beginner to go from
536:28 - complete beginner to maybe like beginner
536:30 - intermediate um in ai and really get you
536:32 - started okay other than that you guys
536:34 - i hope you enjoyed the video but if
536:36 - you're interested in actually um
536:38 - excelling your skills on python and
536:39 - actually making a real income from it a
536:41 - real living then
536:42 - um please click on the link below to
536:44 - check out our course profit with python
536:46 - which does just that it pretty much
536:47 - assumes you're a beginner and takes you
536:49 - through the complete roadmap from
536:50 - beginner
536:50 - to actually making an income from
536:52 - beginning to end using python and to
536:54 - actually become a full-fledged
536:56 - python developer all right you guys i
536:57 - know we've been sleeping on python for a
536:58 - long time we've been doing all the
537:00 - javascript stuff you know
537:01 - this might have been plugged in by the
537:02 - way but we've we've been doing
537:04 - uh javascript react stack all that stuff
537:07 - but don't sleep on python because python
537:08 - is huge okay on the back end pretty much
537:10 - everything uses python python's
537:12 - everywhere so you really need to know
537:13 - python as well
537:14 - make sure you know your python
537:24 - [Music]
537:28 - you

Cleaned transcript:

what is up guys welcome to the python ai tutorial 2021 for beginners all right so i'm aaron if you haven't seen me before i'm on the channel a little bit i'm not cozy um i look different than cozy but uh this is gonna be a crazy tutorial we're looking around on youtube a few months back and we didn't see that much ai stuff so i started dropping these cool tutorials um i was doing some face detection and everything and we kind of lumped all these projects together into one so that you guys can learn how to actually start your ai journey and take the first steps towards being a actual data scientist so this is very beginner friendly it's not too advanced if you've never coded in um anything related to artificial intelligence before that's totally okay this is built for you uh i explain everything in detail me and then there's some other instructors too i think nas and kazi and sunny also teach a little bit in here but i'm throughout the whole thing so i hope you like me because if you don't then um all right so we're gonna be building four amazing projects okay four of them the first one is gonna be the face detector app so this is very useful for things like instagram or snapchat where people you know that you have your phone and you're like hey you have like the the face filters so this is actually what they're using to be able to like detect your face and like superimpose something over so that's really cool the second project is actually going to be a selfdriving car app um so it's gonna be like car detection and pedestrian detection in real time and this is the kind of stuff that tesla uses and companies like lyft and uber are actually starting to implement over time because computer vision is the way that they want to go forward with selfdriving cars okay so elon musk has even said that um it's all it's all computer vision no no weird sensors and stuff it's just complete ai okay so we're gonna be doing that as well the last one is smile detection that's pretty cool because it can actually like distinguish uh two different expressions on your face and we're going to be detecting that in real time and the fourth project is we're actually going to be doing a intro to tensorflow which is a pretty much the most popular machine learning platform library framework whatever you want to call it out there that's available for python and a few other languages but we're going to be doing an intro to that pretty much building a our own neural network from scratch and actually having a cool image classification out that can actually like classify different types of images so if you're excited for this please let us know in the comments below yeah guys and that's really it so i handpicked these four projects for you because i feel like they're just really like a good bitesized project for beginner to go from complete beginner to maybe like beginner intermediate um in ai and really get you started okay other than that you guys i hope you enjoyed the video but if you're interested in actually excelling your skills on python and actually making a real income from it a real living then um please click on the link below to check out our course profitwood python which does just that it pretty much assumes you're a beginner and takes you through the complete roadmap from beginner to actually making an income from beginning to end using python and to actually become a fullfledged python developer all right you guys i know we've been sleeping on python for a long time we've been doing all the javascript stuff you know this might have been plugged in by the way but we've we've been doing javascript react merge stack all that stuff but don't sleep on python because python is huge okay from the back end pretty much everything uses python python's everywhere so you really need to know python as well make sure you know your python so other than that i hope you guys are excited let's get started bernap what's up you guys guys for the python tutorial and by the way guys i want to kind of show you what we're going to be working on today look at the screen yo aaron what are we looking at right now uh this is uh robert downey jr's glorious face with his uh going to be learning real time face detection with python if you are excited please drop it in the comments below and let us know that you are excited about this this took us forever to put together i apologize we were late today to the stream we're 45 minutes behind but get a lot of things set up for you guys and make sure that you guys get a great experience now that we're here guys take a look at this here is aaron's face and it is actually what's up right now right so look at that he can move around right it detects his face uh with a pretty high level of confidence and this is all real time you guys this is with python and today the biggest thing we want to do for you is show you how you can do this yourself with a few lines of code and we want to make it as simple as possible because um there's so many different places to show you how to do this but they don't make it simple right aaron yeah a lot of the other tutorials like they added a bunch of unnecessary code to get up and working like this is actually a pretty small app to be honest there's not that much code but there's a lot going on behind the scenes and we're gonna build it first because that's the fun part we're gonna get it all going you guys can have it on your own computer running you can detect your own face and whatever other embarrassing videos you have of yourself um but then i'm also going to explain it at the end of actually what's going on instead of just like a bunch of like code in your face i'm going to explain in layman's terms so it's going to be interesting a different approach than what you've probably seen before but it's going to be good you guys excited awesome okay beautiful we are pumped so i think at this point um what should we take a look at now aaron should we go ahead and look at like how the algorithm works yeah so oh first of all here's the robert downey jr photo i i caught from the internet just to prove that it's uh what didn't already have the green square yeah but yeah i have this little presentation here okay so let's just start this up first just to give you a little debriefing before you jump into the code you guys yeah so first thing here uh in a super simplified way but just to give everybody context because i know a lot of you guys are beginners um we are all beginners ones me quasi all of us yeah and i just want to give you a a short stepbystep thing of how like face detection actually works with python all right so first step um the first thing you want to do is of course this is going to be a machine learning thing that's the really the only way or the most popular way to do this kind of thing is you have to train it on what a face actually is and then from there then you're able to classify faces down the road so step one get a crapload of faces clear good yeah and from there um we actually um don't need it to be colored so step two we're just gonna just real quick go back to step one i wanna highlight what you're saying because you're saying something really awesome there and i wanna make sure everybody truly really understands this you guys so this is awesome how aaron is putting this together for you take a look at that like the first thing we do is like we give our algebra like we want to give it tons of faces so it knows how to detect a face so we're just giving a ton of faces you can see george w bush in the middle and then you can see like their thousands of faces around it so that's our first thing that we're doing get all of the faces right um so what are we doing then on step two so after you have all the faces uh we actually don't need to be color uh the reason being for this is because what defines a face isn't so much the color it's more so the composition of like this set of pixels like okay there's two eyes and nose and then there's like some reddish or like dark color or lighter colored lips depending on maybe some teeth or something like that um so we get rid of the colors because it it it um hurts the the performance of the algorithm i believe but the way opencv does it which we're going to be using it opencv if you if you don't know what opencv is opencv is an open source computer vision library um that some people put together i don't know who put it together but it's called opencv we're going to be using that and they have a lot of cool computer vision functions that we can use to build our app so the first step we're going to do is we're going to turn everything black and white all of those faces that we had at the beginning here the very first step and we turned them black and white because the computer the only way that algorithm knows how to look at a face is in black and white so you want to give it that it's not going to be looking at it in color so we turn it into what we call grayscale grayscale that's the word yeah and then from here once we have all of our gray uh our black and white images our face images we can pump those into the algorithm and it will eventually learn how to detect faces so as you can see here it's detecting all these different faces here whether you have glasses open mouth frowning smiling eyes closed hair i mean the hair is all similar here but you get the idea if you train it on enough data it can it can recognize babies females um males uh even monkeys so uh that's that's pretty much the oversimplified threestep thing you just get a bunch of faces you change them to black and white and then you train it and then you run your class your face classification um code and it will find all the faces in your image awesome so that's a pretty simple threestep formula right so step one just go to step one real quick step one get a crapload of faces step two turn them black and white step three train the algorithm that's it guys it's just simple three steps okay hopefully you guys understand that so again get lots of faces two turn in black and white and then three just train the freaking algorithm and now you're good to go now it's gonna start detecting everything so like to actually use it you guys is stupid simple it's like ten lines of code and then boom your webcam is working and everything is working so like step one get away from the fear of like what it means to actually use these types of algorithms first use them play with them and then go deeper into the complexity and everything so you can start to understand and make your own models wow we have 664 people live that is awesome what's up that is awesome welcome you guys anybody just coming in we're making a face detector if you came in a little bit late but yeah so um with that said this simple threestep process let's just jump straight into the code you guys okay let me give one more quick demo in case there's anybody um you know aaron and what i was actually even thinking of maybe you could have code on the left hand side so you could actually like make your code like on the left hand side on the right hand side you could have the webcam open the entire time ah you see what i'm saying yeah the thing is the way this is implemented oh yeah yeah it's kind of you have to keep running it you have to keep running it yeah that's okay that's okay no worries let's keep going so we'll just keep it this way is the code is big enough for you guys to see right i think that's that's big and by the way you guys if you are enjoying this video erin open up your face detection again just so we can see it unless you comment so guys if you guys are enjoying this and if you think this is cool i think this is so freaking cool that we're doing this with python right now make sure to hit that like button it's free it doesn't cost you anything it helps us get the video out to so many places so please go down below and like smash that like button subscribe to the channel if you want to learn from aaron myself and all of us that we just give you so much value so please please please hit that like button and let's keep it rolling by the way puge says i read this comment there and he says aaron taught me how to code in python today i finally completed my titanic data set thank you titanic dataset titanic probably something you like he probably learned from you and then went and like applied it on something else right on i don't know what that means but it sounds like something i wouldn't understand so keep that that is awesome all right you guys there's 826 people live 826 what's up you guys let me okay let me just keep this running it seems like people keep flooding in where is the here we go you guys okay we're this is what we're building you guys let's just jump into the code i think we're almost at a thousand so let's just get started all right so let me comment out all the code that is preexisting here um so we can start from scratch for all you guys and actually just all of it okay so the very first thing that we're gonna have to do is obviously install opencv so if you're following along with me then please install opencv and you can do that with the command wait i gotta quit out of this one second it should be uh pip if you're on linux or unix system do me a favor a few things aaron do me a favor take your terminal put in the middle one and then also hit command plus multiple times hit command plus just to zoom in and make your screen smaller and then it's easier to see for everybody terrible habit is that that's big enough right that's really good that's really good it's easier to see for everybody all right you guys so the first thing you wanna gonna um gonna want to run is pip install python dash open cv okay i've already installed it uh oh also maybe add headless here if you're getting errors this is optional but like if you're getting weird errors try running this as well and it might work but this dash headless is optional but point is install opencv that's the very first step um honestly there's no way i can help you install it i forget there's an endless amount of errors you could get but you're going to have probably google it and look on opencv so like if you are getting issues let me just do that let's see opencv installing issues or something i'll just give like a brief thing um find the stack overflow here opencv installation problems you probably come into here and there's no answers on this one but uh i mean point is yeah i just installed opencv and hopefully that that command should work for you the one that we were just looking at here and um once that's installed then you're pretty much ready to go all right so from here you can come into our code and the first thing we're going to want to do is simply well first you're going to want to make a face detector.pi file of course so start with making your first uh python file phase detector there and just to make sure that it's running let's just do this this is a little big shot just a real quick shout out to pratik uh he says today i had an interview and i showed yesterday's project of amazon price detector and i got selected holy crap that is amazing guys go team jacob yo we literally built the price detector exactly we built the price detector yesterday you guys with jacob so that is huge that is awesome all right let's keep it going yeah that is so sick all right you guys so once uh you have your python file created face detector.pi then let's just make sure it's working correctly okay so the first thing you're going to want to do is just run pi well make sure you're in the right directory so you want to make sure that the face detector.pi file is in my um in in the in the same directory and then from there then you can just run python and run face detector.pi just like that okay nice and then hit enter and as you can see it says code completed here which is the print statement so everything is hooked up and working correctly that's the very first step and i like personally when i'm coding i like to keep this at the end of my program because then i know that if this shows up everything in my code ran and no errors popped up so i leave this at the end so that's just kind of an errand convention that you can adopt if you like but um now that we have opencv installed the first thing you you're going to want to do is actually import that library so that library is called cv2 this is i think the 2 just means version 2. it's been cb2 for a long time but just it's called cb2 you have no choice just type it in and from here go again and then let's see if we get any errors run the same command and as you can see it says code completed which means it ran this in imported library without any issues because it reached this line so from here now we can actually start coding with open cv so coming back down here um one thing you're gonna have to do is here actually let me let me go here so opencv like i mentioned earlier is a open source computer vision library provided by some people um and they provide a lot of preexisting code of course it's a library so they have code that we can use that we're going to be using that we just imported but they also have some data files for us so what this is here is actually pretrained data so if you look here there's uh what okay so har cascade is an algorithm we'll get into that a little bit but just ignore this big scary word heart cascade and then it might say this is the one we're gonna be using the front frontal face default because this uh they provided us with a bunch of data and they actually trained um this on a bunch of face images like the ones i showed you in the presentation before like this but they're basically like that yeah so that data is actually trained on tons and tons of faces like frontal faces right just like this one hundreds yeah like all of these like all ages all that kind of stuff but frontals you know so there's no like blockages there's no side faces yep um none of that just just front faces yeah um so from there they they provide all that so what you're gonna have to do is actually download this so if you can just go to this url okay github slash opencv slash opencv slash tree blah blah blah and just go to the default front this one frontal face.default.exe and download it it'll be right here and it's just a big xml file and all this is this is basically a machine learning um machine and when you pump an image through all of these all of these numbers it'll tell us and find if there's a face in the image or not and as you can see this goes on forever so this is actually what was already trained on like thousands of images so um you want to download this because openc provides it for you training it yourself is a gargantuan task of its own so we're not doing that in this video we're just using what they're providing for us maybe we can do that in a future video but point is download this from this url and then we can continue on from there so any comments quasi awesome no i love it uh basically guys to summarize it all we did so far is literally just downloaded that file that's it um so it's really simple just hard cascade frontal faces i think default or whatever and then download it put it in the same directory that you're in and that's all we've really done so far and i have mine right here see right parallel to here along with my uh robert downey junior photos and stuff oops not not this one so once you have this installed then we can go and import it into our app so the first thing is uh well first first of all i like i called my variable trained face data because that's what the heck it is and um this is the name of the file we just downloaded an xml file i'd actually don't i think i forgot what xml stands for but it just looks like it looks like this with all these tags from here you're gonna want to call the opencv library and call this function to make a classifier so all the classifier is it's a fancy word for um detectors so uh detector so we're making a face detector app a classifier can classify something as a face that's all really is and then cascade is again the algorithm the hard cascade i was talking about uh we'll get into that later just ignore the scary word but what we're going to do is we're just going to pass in that training data and create a classifier for this and since this is the frontfacing training data then this classifier now will be able to detect front uh front frontwardfacing faces and that's what we have here okay so as you can see i put a comment here to load some pretrained data on face frontals from opencv from there we can continue to um choose an image or a video stream or our webcam and then we can actually pass that um into this classifier and be able to find the location of faces and then we can put the rectangle around it and you have to like draw the rectangle on the image or the video and we'll get to all of that but moving on the first thing we're going to do let's just do the robert downey jr uh photo i'm just going to copy and paste it just so i have to type it out but i'll go slowly so you guys can type it out yourself so uh the thing we're going to want to do is choose an image to detect the faces in so mine is the robert downey jr photo so the way you do this is you want to call the image read function from opencv so very sim very simple the image you're going to read it in and it's going to be um the the photo that i just had of robert downey so that should be this one okay so it's on my desktop here and once you have it over there somebody just donated to us bro that is awesome uh really really yeah hashtag yo garage i can buy lunch today yeah finally thank you appreciate that uh so that's awesome thank you so much for that it's like please make a uber or ola clone app using react native so we might not be using react native but we're going to be making a bunch of clones with react so uber is not on our list yet we might think about putting it on our list we are definitely going to be doing tick tock and i think spotify and stuff like that and then uber we might do it at some point as well i'm not sure what ola is yeah i'm not sure i'll look that up later but anyways this is how you import an image into opencv okay so this is actually i mean an image is just an array like a big matrix of a bunch of numbers you know pixels are just numbers so really what this is you're just reading the image into a big like double um twodimensional array so a big image a bunch of numbers and bits from there um now we can actually um change it to grayscale so again if i let me see if i can actually show this yeah so let's let's just go one step before xml file link so maybe you want to just go to that github real quick and maybe just show the url and then they can pause it on there so just go there and show the url so you guys can pause it here and type that in um and then go to it okay maybe we should put in the description or something that might help yeah we'll put in the description too at some point for sure after okay here and make sure you're downloading the frontal face default this one okay there's also cat faces and stuff i mean you could actually use all these other ones like lower body upper body the just the profile of the face you can detect smile all this stuff cool yeah just eyes um yeah what's cool about this is you can detect anything pretty much you could you could detect cocacola cans and stuff but we're just doing faces like the same algorithm works for anything like it's very generic and robust i don't know what that is oh probably like a car license probably a license plate right yeah like for russian cars yep but anyways yep so here again url download this one okay and once you have that then we can continue on so let me just show uh this this image first so i imported the robert downey jr image and um so image read we read it in and then to show this image there's another opencv function called image show i am show and um this string here is just going to be the name of the window that pops up and then this is the image you want to display so let's just save this and run this to show you that the robert downey jr stuff is going to pop up and what is wrong oh i forgot you you also need this thing uh let me just make sure it works first before i because the weight key basically waits for it yep so the weight key you it because otherwise it just closes instantly go ahead yeah so what this does is it actually pauses the execution of your code so it will show the image and then it will continue on to the end of the program and it'll it'll terminate the program because they got they got to the last line here and it's like okay i'm done so it'll open this for a split second you won't even see it then it'll close it immediately so what this means is this will wait until a key is pressed so you can press any key to continue in the execution so it gets here and it waits and it keeps this open so that you can um view the image that does that that's just the way opencv is implemented um i mean if you like it or hate it it's just how it is but once you have that then you can run the program and of course robert downey jr pops up here in color just like i said okay and of course you can hit any any button on the keyboard i just hit spacebar and it just closes it and then it's of course it says code completed and i'm back to the terminal so i'll show you step by step as we're going uh what it looks like so we'll just keep these two together okay at the very bottom and okay so we have a robert downey jr image in here next we are going to like we said in the presentation we got to make it black and white because the algorithm that we're going to be using the the har cascade algorithm the way it's implemented only takes grayscale images because we can still identify faces in grayscale we don't need the color i mean you can do color but that's a much more complicated like if you want to classify like skin color or race or even like actually identify people that's even more advanced that's what facebook does you know how you can like tag your friends it automatically knows their face um that's way more you need way more training of like one person to do that so we're not going to be doing that here but i just want to mention that so aaron one real quick uh side note uh what can they do if they want to learn not only these types of skills but also learn how to make an income with these skills where can they go uh yeah so if you like coding in python and you want to learn how to actually make a living from it so if you want to start coding and landing clients or land a job and just like get your skills and your confidence up and have projects on our portfolio and all those things and really just do this for a living then we have a course called profit python formerly a profitable programmer so if you hear either name or either name they're the same and the link is in the description if you want to join that yep um we can actually and i'm showing it on the screen actually so i don't know if you you can probably not see my screen but yeah i'm showing it on the screen so guys the program is called profit with python so in this program we show you all of these things that you're going to be learning today you know whether it's like detecting faces or building ecommerce stores or any kind of project that you can take from upwork web scraping as advanced as you can think it and then we show you how to actually land those clients our biggest one of the biggest things we focus on is like how can you actually earn a killing with python that's huge for us we have dedicated python success coaches and really one of the most important things in this program is the fact that you get weekly live python training calls now aaron like what do you think is a benefit um of those like live calls uh you know for for the python like live training calls um live training calls i mean humans learn live that's how you've been learning all throughout history so having somebody there to give you realtime feedback and answer your questions right then and there is like evolutionarily the that's even a word the best way to learn um so it's pretty much like you're in a college course you know but i mean but a cool one because you have a cool teacher and you can show up and do whatever you want but there's live calls where you build apps together and you can ask all your questions yeah directly to a python expert you guys are literally building traffic projects every week so like jacob is building an ecommerce store like you guys think we're building live projects on our youtube wait till you get inside of the program because there the conversation turns over to you and you are the one building all these projects and then we're giving you personal video feedback on each of your projects that you build and we get tons and tons of submissions from people like even right now you know if i show you guys here like we have tons of projects that people are sending in that they're building with python that they're building like people are building covet trackers and all kinds of stuff so here's an example of a project uh boom here's something that was built and i can switch it up into any different country and you can see that it pulls the queries it shows all this data and people are using these skills to freelance so if you guys want to learn these skills you want to you want to be able to make an income with python then definitely go and check out in the description below the program is called profit with python and we would love to see you inside of there yeah so because coding is fun you know building projects like this this is all fun but i mean if it's fun then it's just a hobby if you can make a living from it uh i mean i say why not because then you can have your fun and make a living from it and do it more so that's why we provide um these courses we love helping people like do what they love be that being coding and just live the lifestyle they want instead of you know slaving away at a job they hate whether it be like retail or fast food or whatever it is yeah so that's worth mentioning that um optional for you but definitely there we would highly recommend it and just check it out let me just keep going for the for the viewers yep where was i i was i imported the image so like i said we need to make it grayscale because the algorithm requires to be grayscale because it's just easier to only deal with one number on each pixel the the color there's it's like on a range from like black to white instead of like our there's no rgb in each pixel it's just one one number instead of three numbers across red green blue channels so we got to change it to grayscale so of course opencv allows us to do that too and let me just go grab that code down here and i will just paste it and you guys can type it out yourself as well so as i as i said here in the comment you must convert it to grayscale and so i just called the variable grayscaled image because it's the same image but grayscale and the function that you want to call is convert color so opencv dot convert color and then you give it the image you want is the first argument and then the second one is what kind of conversion you want to do because this function actually you can do a lot of different things why don't we pull the documentation i'll just show you a little bit really quick convert color so open cv documentation and let's just go here not this one uh this one should look ugly yeah it is i got out of there quick we just lost 600 people in 10 milliseconds um where is it probably i guess there's a bunch uh gray basics thresholding options is this the right documentation open cv twopoint okay once here we go okay cb2.com color awesome yeah so here uh convert color you have a bunch so the first one is the source image which is the robert downey jr image that we had first and then there's a bunch of different things you can do so for us we're going to be using uh grayscale but you can also change like you can change the gray you could change color to just the red channel or just a blue channel or you could like dim the whole thing pretty much you can convert the image to whatever you want there's a bunch of stuff in here to definitely check out documentation but just wanted to show you guys that because this is actually where you would find how to do that instead of just like oh aaron told me to type it no the documentation has all the information you need so you can go check it out you can play with it but for now we're just going to do the very simple one cv2.color bgr to gray one caveat to or one little quirk to opencv is i'm sure everybody knows what rgb is red green blue that's how each pixel can like mix those three channels colors together and make any color on for each pixel uh but an open cv the channels are actually backwards so instead of rgb it's bgr and that was very frustrating when i was first learning it but just be aware of that and that's why it is bgr to gray because it's taking this image and then turning it to gray so let's just show you uh what that looks like so instead of displaying the color image i'm going to display the grayscale image let's go back to our terminal and type in python face detector dot pi again enter and voila we have a grayscale robert downey jr beautiful looks just as sexy that is nice that is nice all right you guys and then of course any button to quit out and we are back to our terminal and now we can continue so once so that's pretty simple straightforward i'm sure you guys all understand at that point again go check out these different settings there's a bunch you can do and of course you could even convert it from gr from gray back to rgb and it would be considered an rgb but the thing is when you lose the color and it's gray then it actually is just gray so you won't actually get the color back but it'll technically be a color image but it's not actually going to look like it but i'm getting off topic there um from here uh the thing we're going to want to do next is going back to our our little presentation here is we want to train the algorithm right but that already happened opencv was already able to do that so all we want to do now is to plug that gray image into our algorithm that we're given by opencv the xml file we downloaded and from there it'll be able to open up all these or detect all of these faces so like this is actually one image and it detected all eight and um that's what we're going to be doing next so let's just quit out of here go back and let's just detect faces so yes yes some of you guys are probably like oh maybe this this is kind of fake it's just one liner that is technically faces that is true but like i said at the end of this video i'm actually going to go through the whole algorithm and explain it in layman's terms so that you can actually understand um how this is working and why it's working and all of that because then you have a full understanding um and there's no point of coding yourself if it already exists so this is actually a better approach because you can understand it you can get the result and that's all you need once you have those two things then you can innovate further and go on and optimize or create your own algorithms for your own problems so yes this is just one land to defeat um the face to detect the faces uh but i mean shorter code is better right quasi shorter code is better because like look here what was that but shorter shorter code is always better less errors i hate having a lot of code i even try to get my functions never to be more than like four lines of code um or i'll refactor it yeah nice having nice encapsulated code that's the word for it like if your function is just it does one thing and one tiny thing then you want to encapsulate it in one thing and keep keep your code very modular so you can plug and play uh functions all over the place so then says you guys are amazing you guys are putting so much effort to make us understand things like python and you were doing this at midnight as well so amazing you guys love you all thank you so much johnson we are not doing this at midnight it's my time for me yeah really early for aaron but uh thank you we appreciate the support guys and thank you for the positivity that really keeps us going yeah guys you wouldn't be doing we wouldn't be doing this if it wasn't for you guys like there's no there's no reason if nobody's watching them what's the point so yeah thanks for thanks for sticking around and putting up with us um all right so here uh what this is what what's happening here is before we we created our classifier the trained face data that opencv supplied for us within this xml document that we downloaded and from there we're going to call a function called detect multiscale okay so this probably sounds a little bit maybe scary maybe not to others but all this means is whatever this classifier is which is a face face classifier since that's what we trained it on the train face data then we want to detect all of the faces with a multiscale thing so all that means is no matter the scale of the face if it gets smaller or bigger then if it's small or big then it'll detect it anyways it's just looking for the overall composition like the relations of the eyes to the nose to the mouth whether it's smaller up close or if there's multiple of them then it just wants to detect all of them so that's what detect multiscale is too why don't i actually pull this up on the um documentation quick question aaron prakar says can we use phone camera for detecting the face in real time um phone camera i mean you would have to somehow connect your phone camera to your laptop so that you could run opencv on there uh i think opencv has mobile support or to some extent i actually i've never done opencv on mobile but they might take a look at it and do it yeah but uh you would have to somehow hook up your phone camera i mean i'm sure it's possible somehow i haven't personally done it but you'd have to hook up your phone camera to your laptop and then pipe that into opencv somehow like maybe you make it your default camera i actually think yeah i'll take i'll take a look at that you don't have to worry about that i'll take a look look at it and see if something like that exists but uh if you guys do understand how to use it this way then you'll be able to even use it later for phone camera and things like that yeah we're focused on teaching a thorough understanding of the basics the basic building blocks like all encompassing everything so that when you learn this then you're equipped to actually go to your own innovation your implement your own creativity and do those kinds of things because that's where the real learning happens and then you can be original like i'm just gonna be like hey here's this project it's like oh here's the skill now you can go do what you want with it awesome all right let's keep going so let's just open up this detect multiscale here we go cascade classifier and here we go so detect multiscale uh this one it basically detects objects of different sizes in the input image so objects is just faces in our case because that's what we trained it with we could have trained it with dogs we could have trained it with cars with houses but in our case it's faces and from there the detected objects are returned as a list of rectangles so pretty much it just returns the coordinates of those green rectangles and once we have those coordinates we're able to actually draw those rectangles on our image so that's what we're going to be doing next okay so from here detect multiscale we feed in the grayscale image which is a robert downey jr image and like like we said this returns the this returns the the coordinates of the rectangles so that's why i call that face coordinates because it'll give us the coordinates of the rectangles surrounding the face and then from here once we have these coordinates it's it's very simple to just draw rectangles onto the image or the the current frame of the video if we're doing a video and it just runs on every frame so from here why don't we actually print out first of all we don't need to display robert downey jr anymore but why don't we actually print out the coordinates okay so face coordinates did i spell that correctly yeah and let's just run the code okay so the the coordinates of robert downey jr's face should be displayed in the terminal and can you make your can you do me a favor can you make your terminal like wider that way your line of code can show on one line instead of wrapping perfect perfect perfect yeah my dirty coding habits right i've gotten bad habits beaten into me but all right you guys so this is the location of robert downey's face in the image is it possible aaron is it is it possible to also later show the face coordinates but with your face with the webcam open and so then as you move it like actually prints out the console logs in the terminal yes actually yeah okay so let's do it like that let's do that yeah let's do that once we get to the webcam but right now we're going to focus on getting one single image up and running got it so i'll explain this so what this is like i said it returns the coordinates of a um of the face so all this is is the upper left coordinate of the face and this is the bottom right coordinate so just a bounding rectangle that's all it is can you just show it visually like can you open up the dot robert donnie jr uh robert donnie jr's photo and then like show what you mean yeah so like i was saying um of course this is going to be gray scaled in within our app right now but just for demonstration purposes the face is about right here okay so this 307 115 would probably be right around here the upper left hand of the um face and then this 336 uh 336 would be right around here the bottom right corner bottom right so you have a bounding rectangle and then from here it's very easy to just actually draw the green um the green box surrounding the face and that's how it happens okay we're doing all that manually we're actually drawing we're finding the location of the face and then we're drawing the rectangle around the face and then we're displaying that new image with so that's exactly what's happening with it and the rectangle that we're drawing we're drawing it from a module an open cv lets you draw as well yes got it wait how do i get rid of yo tony how's it going uh awesome this is tony that was actually yeah you you know him right here yeah yeah tony orbis what's up man yeah this is awesome um dang it i think my terminal bugged out let me just terminate and open a new one cool terminal and that's desktop and clear and again python is going to be face detector you're not in that file i think you have to go in that file why don't you open up your terminal in uh visual studio code um i could do that is it command j yep all right and go to my bash you can you can be in your so that's my desktop and from here we can run python um i think it was face detector or dot pi and there we go awesome i actually haven't run it from here let's see if it actually displays the image i haven't actually hmm swipe up no no it's it's running it's running so use your four fingers to swipe up on your mouse pad um and then it'll like yeah and then it'll show oh it doesn't have yeah it's i thought it would visually show up it's because i'm printing the coordinates and then the weight key but it's not um displaying something it's just bugging out so got it just let's just terminate this is how you terminate it yeah just open up a new yeah perfect you can just open up a new terminal if you want yeah oh stick to this one because then i can um because i like having the full code open the whole thing at one time okay got it so okay back to desktop python face detector not pi okay there we go so from here then we can continue yeah the weight the weight key bugged out because there was nothing popping up there there was nothing to close so nothing to actually capture a key and then continue but that's not that important oh hello kazi hi guys and yeah so those are the coordinates now from there now like i said we want to superimpose a rectangle over the image so that we can display it back and of course we want to do it with the color image again so once we have the coordinate we can go back to the color image and draw the rectangle on the color image once we get the coordinate from the grayscale image in the algorithm so let's just comment this out and the next thing is we're just going to draw rectangles and of course if there's multiple faces then it'll draw rectangles around all of them so we have a loop um but actually let's just let's just delete that for now let's just start with one rectangle so to draw a rectangle uh this is the function so opencv again allows us to just call something called rectangle and what it takes is an image that you want to draw a rectangle on so of course we'll use our color image originally then it the next one it takes a tuple of the upper left hand um the upper left hand coordinate got it this is the lower right hand coordinate so this x y and x this doesn't work because i had the loop so let's actually just delete this for now and like i said the face coordinates is what we want so the upper left hand would be whatever this gives us yeah so phase coordinates gave us like that that uh 305 thing right like 305 116 whatever we had in the command line earlier for the robert downey junior's face yeah so actually why don't we yeah just yeah run it type that out perfect like actually just like manually put in the numbers just to show you guys that it actually works okay so i'm just gonna show visually what we're doing here you might not be able to see my screen for a second okay so just hold on and i'm gonna just explain this also visually um all right guys so basically you know if you guys are with us so far what aaron is about to do right now is we're going to have robert donny jr's face like this okay and um i don't know if he's smiling or whatever and then around this we're going to draw a rectangle now what we need is the top left so aaron the 307 and then the 116 do both of those coordinates refer to like x and y pixels x and y pixels okay so one is like okay the top so basically just two points right one is the top left point and one is the bottom right point yep that's it okay so this is going to be and what are the first two numbers aaron is it 305 comma one what are they can you tell me 307 and 115. okay so guys that's that point over there okay then we have the second point here and what are what is the coordinates for the second point three three six three three six okay so it's three three six three three six all right so here are the two tuples this is tuple one this says tuple two right over here and that's how we're gonna draw the rectangle around somebody's face we need those two points once we get those two points cv2 allows us to actually make a rectangle around the face okay so that's what aaron the line of code that aaron has if we go look at his screen right now right here yep so that's those coordinates that he's referring to um these right here yep and that's what we're gonna do i just hard coded them in just to show you guys for now exactly and then i imagine the zero two five five or whatever that's the color like it's gonna make a green color or something i choose green so this of course opencv is backwards so this is bgr instead of rgb so if this was 255 this would be blue if this was 255 this would be red if i zeroed this one out but i like green so i just chose green but you could you could even make it white you can make it black that's why the heck you want now what's the last two at the end the thickness of the rectangle okay perfect how thin that's all it is so of course if it's 10 it's going to be really thick but two is a nice it's a nice thin line awesome so this is guys this is a cartoon way of looking more cartoony way of looking at it how is it drawn here you saw aaron's lot what the one line of code that he has right over there so now let's go ahead and actually run it got it so here we have the the rectangle being drawn on image okay and then down here we have an image show and here we still have the grayscale image so all we got to do is just change this back to image because now image has the green rectangle drawn on it around his face let's give it a save let's go to the terminal and let's run it and something is wrong um might have these backwards um yeah that's pop i'm trying to think uh dude let's just get right angle documentation what it does is it adds them so if we actually look at the code that we had earlier and the one we commented out or whatever it's like uh x plus w and then y plus h so you want to take the x coordinate exactly so you want to take the x coordinate and add the width to it and then you want to take the ycoordinate add the height to it and that will give you what you're looking for so just add the width and add the height whatever yeah you're right i forgot that detail it's so this is actually the upper lefthand point let's go back to there let's let's um confirm that so the whoever developed opencv decided to implement it this way probably because it was smarter in the long term instead of having the top left point and bottom right point they actually have the top left point and then the width and height of the rectangle so that you can just add this to these points to get the bottom right point so i guess equally effective it's the same data just in a different way so actually what this would be would be 307 plus 336 and that would make sense why it's 336 because it's a square it's the same number because the width and height of a square is the same so now now let's try it now it should run correctly back to the terminal oops yeah and ah much better nice okay so that bug was fixed and there we go so this is a solution is it still true that the top left point is um is 307 and 115 is that still true and the bottom bottom right point is 336 comma 336 no the bottom right point this is the width and height of the square because it's a square so width and height is the same so so what's the bottom right point then that would have to be this point um to get the i mean it's just some some coordinate math so 307 is the x is the x uh location of the top left point so this is 307 this way uh okay and then the bottom right bottom right is just one one five yeah and then this is this is one one five no no no you have to come on quasi you got to add the you got to add the 336 to um the width and the height to this point and once you add 336 it'll come out here and go down so that's how you get the rectangle got it get the offset so from there uh we have robert downey jr's face okay the problem with this though is of course we hardcoded it in so we do not want to do that okay uh what we do want to do is actually just get the points dynamically and then print those out so like we just did it's going to be like this nice the thing is we are going to want to make sure we are getting the coordinates from the face coordinates correctly so x y width and height like we said in the terminal okay so this is x y width and height here and we can do that using a four tuple and just set this equal to phase coordinates okay and this will automatically assign each of those four numbers one two three four to these four variables one two three four another two nice and a two pole then we can just pull those x y and the x y um wh out just like this and this should work unless i got my math wrong again which could be very awesome we just broke a thousand likes i heard on the video that is amazing thank you guys thank you one more value to unpack what is the last coordinate wait what was it complaining about face and line equals face coordinates value error need more than uh you never differ oh yeah you actually did define um buggy maybe wait hold on isn't it face coordinates of zero or something because it's an array with that it's a list within a list so you might have to like the double brackets there right yeah i don't know what that is but yeah that'll probably work so let's give this a shot there we go yeah oh that i guess that makes sense because it's a list of here that would make sense because if there's multiple faces then you want a list of lists yeah yeah okay that's why that's like that makes sense yeah um but there you go there you go guys so now we have it dynamically getting the the face with the coordinates here that is so cool that is so cool can you turn it red real quick just like in just real quick like that's awesome so there we go sunny was telling me you have like scary amount of knowledge on color oh yeah i worked at a i worked at a i had a data science gig for eight months doing opencv stuff like exclusively like four years back oops oh i killed the terminal guys this is the right person uh keep opening it up and once you open it up do let me know but guys this is the right person to learn opencv stuff from like he just was doing this for almost a whole year yeah edge detection motion detection background like you can you can do a lot of cool stuff but right now we're just doing face detection so desktop and again let's go python face detector yo aaron maybe like upcoming few weeks just like go crazy edge detection like bring all of that back so yeah you guys look at that we just turned it red super fast super easy green yeah it's awesome change the color i mean minor detail but yeah let's change it back to green because i like green better and although of course this is the thickness so let's let's just do a quick yeah change it to real thick like five or ten that would be awesome kaboom nice that looks that actually looks great i like that level of thickness like it all right let's keep it there yeah so we'll keep that there that is so cool like we're detecting a face in real time and drawing the circle dynamically around it and this code already works on any image you give it that is mindblowing you could even you could even have a circle instead of a rectangle but it's only gonna but right now it's only gonna make draw it on the first person it sees you guys so if there are two people it'll only draw it on one person's face but once we write a loop it's so cool we're looping through humans like that blows like you literally are looping through human beings that is insane it kind of blows my mind i almost want to take a picture i almost want to take a picture of us right now and send it can i do that can i just take a picture of both of us split side by side and then you open that image up and run it on it or is that just go for it no it should work okay cool yeah this this algorithm isn't 100 accurate they um the algorithm the hard cascade algorithm is more concerned with speed than accuracy so it might not 100 work but like 90 percent it'll work so let's okay just make sure you have good lighting and then it should work fine yeah i got good lighting let's uh detect it right now so i pulled it from our live stream and i'm sending it over to you in slack so what you can do in the meantime is uh just go ahead and pop it in to your like it's so cool to me so just go in slack and then pop it into your image see what i'm saying okay cool but like guys this is so mindblowing to me the fact that you can actually like detect images so like what i'm talking about looping through human faces here right if i can just draw it out for you guys so let's go over here and i'm gonna draw it out but let's say that we had i'm gonna clean this up but let's say the image i gave aaron has two people in it so if you have actually two human beings here like this right what we're about to do right now which is mindblowing is for right now our code all it's going to do is draw a circle around like one person's face it's going to decide who whether it's aaron or me and that's it but then once we write a for loop it's actually going to make a square around aaron so that's person one and then it's gonna loop through find me right this is causie it's gonna find me and then it's gonna make a circle around my face like a for loop that loops through human beings that is just cool like that's the power of you know being able to actually do like face detection and uh ai with python or really any language like it's so freaking cool to me you know if you guys think it's cool go ahead and smash that like button but to me it's kind of mindblowing and then whenever you're ready aaron just let me know got it yeah so i got the picture of me and qazi here on my desktop and instead of reading the robert downey jr photo i just want to read in this photo so i just named it qazi aaron okay and i'm gonna comment is it in the same directory okay yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah just on my desktop it's kind of cool cool that's fine but that's why i just uh keep it there just to get it up and running can you show the image first can you show the image first by itself so they don't think i sent it to you with green squares around it there we go so this is the image okay um i wonder no i think yeah it'll detect my face there yeah maybe we'll see so that is the um image now we're using that instead yeah and from there we want to um detect the all the faces so right now we only gonna detect one so let's run it and see who it detects first aaron or kazi yeah just give it a shot or if it breaks we'll see we'll find out and hey whoa that is so cool and for that reason it probably goes i think it gets me first because it it scans from the bottom yeah can you can you do me a favor and change that in like dude this is an array of us two like in one array like i'm sorry guys excuse the language but like in one list it's two human beings can you index that array can you index it list with one so then it puts me maybe let's take a look yeah so because you're second in the list so if you did yes then it would oh dude this is about to blow my freaking mind right now i'm so pumped oh my god dude that is cool like that is so cool let's see if there's a three let's see if i got your shirt let's see oh if it got oh my god maybe it did yeah maybe maybe maybe it detects my face this is so cool this is so cool i can't get over it i cannot get over it i don't care if people think it's cool or not i think it's so freaking oh my god that's what i was talking about you guys when it says multiscale it's what it's doing is it's taking the train data and it's checking for all sizes so it's starting big or starting small and then it's iterating so it's called a sliding window so it'll like slide the window all the way across tiny did nothing nothing nothing nothing bing found a match they go a little bit bigger nothing good that is sick it's an array with it's array of three items of three human beings in a little list three human beings in a list how does it make you feel um yo that is so cool like i'm blowing like logan is like damn paulo is like insane i know right and all we did is copy and paste like six lines of code it's amazing it's so crazy it's six lines of code that's right uh people are like oh we got somebody's like that's actually epic um dude can you can you now can we loop through it and draw the squares around all of us i don't know about that man i don't know if my skills are up to par for that but i mean i mean you know we had the loop you wrote the loop earlier yeah okay all right all right we got you guys so now we're just gonna have this be a loop so we have a list and a list of three of three faces that we detected in that image and now we just want to loop over them instead of just doing it one by one of course we could probably do this this is a sloppy way to do it but why don't we do it just for um sake so this is actually like running a loop three times but just manually yeah it's just listing it out okay got it and run it and kaboom oh man that is nice so this is just manually doing it yeah and let's make this nice and big purl nice nice thumbnail you know wow oh that should have been the thumbnail of the video nah i mean robert jenny jr is too sexy man justin timberlake that's true that's true that's true you're right or ugly bro yeah six lines of code man like that is so cool to me yeah even logan is going he's like bro just literally input in the six lines of code what the hell it'd be cool if you can change the color you know like you even like like label them and stuff but anyways let's go back and make this actually loop the proper way so uh the way we're gonna do that is oh yeah change uh also yeah once you write the loop let's also like change the colors between 0 and 255 it just picks randomly so then it'll be different colors oh that's fun all right yeah okay dude on the on the webcam when we're doing a live webcam it's going to be like rainbow it's going to be like going crazy it's going to be pretty cool yeah yeah yeah yeah but all right so let me just go in here so i'm going to type it out here's the loop all right and we're just going to replace this top line this one we're going to replace it with this okay so instead of manually getting it here and getting the first the first face in this list of faces and then assigning it we're just actually going to loop through all of them so because this is a list we can loop over it using the word in so for this tuple in this list which means it's going to iterate over everything then um it's going to have the same functionality okay so do this make sure you tab correctly so for this tuple x y uh with height in phase coordinates then this is unchanged okay because we have the variables exactly the same so this is actually going to work uh minus the randomization of the colors but let's just give this a run and see what happens and it might even pick up extra stuff if it if it failed there might be like a fourth phase somewhere no there is none but there we go you guys so this is functioning so far that loop worked yeah it did we're looping through three human beings right now or two human beings beings in one cartoon man this is so crazy to me wow why do you look so dirty we have the same glasses this is awesome yo okay i got you with the i got you with the different colors so aaron go all the way to the top of the file and um and just do um do hold on import so do from random import rand range although at the top like that yep um i am so you misspelled import yep and then um where you have that 255 you can you see where you have zero comma 255. so just do ran range uh no no no no don't do that don't do that don't do that don't do that just the 255 just wrap the 255 in the function rand range got it and right you can do 250 yeah 256 because it's going to go up to but not including okay so now it should be randomly like making the colors so now if you hit save and run it everybody should have like a different uh color hopefully it would be really unlucky if all three of them were randomly generated well this is just the green this is just the green channel so it's going to be different scales of green but not different colors oh so then you can actually just do rand range for all of them like for all of the coordinates you could do so go back you could do for like for zero you could do that and all three of them you could do the same thing there we go and yeah now let's run it and now it should be random colors that is so cool and green damn okay awesome that would be useful for identification like if you ever actually trained if you got enough of your images enough of my images and enough of this little shirt we could uh we could actually like train it and be like okay it's red aaron's blue i just can't get over that we're in a list we are in a list right now in a python like that okay dude i can't get over that all right let's keep going we know uh one thing i do want to try though is i feel like those colors a little bit dark but if we keep the the range in the upper half of the 256 then they won't be so dull all the time so let's actually go um 128 to 256. okay oh i try this and then i think the colors the colors will always be brighter color science oh i mean it kind of looks it's fine but that's fine you can remove the one yeah just so it's less confusing for them but yeah ran range is awesome right guys it's pretty cool quasi logan goes kazia 20 20. i'm in a list for you getting excited coronavirus got us all screwed up you know like we're getting excited about a list like awesome all right thank you guys we just broke a thousand likes thank you guys so much really appreciate you guys uh we our team just notified us frankie just notifies like thousand likes on this video frankie's pumped awesome you guys thanks for all the support we appreciate it uh i don't know how long we've been going for like almost an hour already right yeah way longer than one hour for six lines this is so fun this is so fun i think everybody's pumped i think everybody's totally like what do you guys think but in my i honestly think that everybody's freaking pumped out of their minds because i think this is the coolest freaking tutorial that's out there on face detection everything else is like so boring every time i try to learn it i go to fall asleep wait wait till wait till i explain actually how it works like mathematically like it's not complicated but like that'll blow your mind because right here we're just calling a piece of code anybody can copy and paste this but if you actually understand how it works that's the mindblowing part so stay tuned to the end for that okay guys uh we're almost done so we're gonna move on to um video now because actually our our image is done so we are have already gotten the image and we're displaying it here and then we did i would display it here so we display the image here play the image with the faces and then we have the wait key of course which is just waiting until we press a key to close and once it closes then code says code completed and we are done so okay we are detecting faces on a single image but what if we want to detect faces in a video but what if we want to detect faces in a video well all a video is is a bunch of images one after another so um we can actually just run this code on every single frame of an image of a video i mean whether it be a video file or our webcam stream we're going to be using the webcam stream and that will basically give us realtime face detection so it's pretty much the same exact code with just a loop added on the outside so let's do that now okay i'm just going to mod i'm just going to continue modifying this code so let's go down here and the first thing we're gonna have to do is actually instead of capturing an image we're gonna want to capture the webcam so let's start from here let's comment out the image and instead let's paste in this okay so instead of calling image read on an image file to wait um to get an image like this we instead are going to call cd2 video capture so all video capture means is you're going to capture a video if you put a zero in here it's gonna get your default webcam so for the person asking about your iphone if you can make your iphone the default cam i think using xero would actually work you just have to like specify it on your computer assistantly i went unfortunately i went and checked and opencv does not work with ios but i honestly think that if you figure out how to make this work you can easily make something with javascript and then host it online and then people can go and use it but the most important thing is to get experience using it learn how this technology works and then it you can go and implement it in any language you want on any system absolutely so i mean i i think it might be possible like look into it maybe uh it won't work natively on the iphone but you could use your iphone camera hook it up your computer and then use your iphone and look around and have that being in this app but the point i was saying was if you have zero it automatically goes to your default webcam um but if you put a file name in here then you could have like you know video.np4 or something if that was on my desktop it doesn't exist um well actually i do have a video here or is it it was a funny detective face that's actually cool lol memes so let's just do this oh nice i didn't know you could give it a video that is so nice yeah you can oh it's actually not going to work because we haven't coded it all out so let's actually do this later but first step is calling video capture which allows you to get the webcam or a video file with the same function which is nice so thank you opencv for being smart and efficient so ahmed asks where's the training part the training part is on line six that's where we trained it the that's where we train the data but keep going yeah we actually didn't train opencv because training takes a lot of time like we would be sitting here for anywhere from probably like half an hour to multiple days depending on what kind of data you're training um so that's why we didn't do that here we just we stole the training the train data that opencv already trained for us like years ago and then they just supplied supplied this machine learning network for us to use and we just downloaded that which is right here so this is actually the train data so all these numbers the negative four the negative two and all these crazy numbers if you pump an image through all these crazy numbers it just filters through and it finds the faces magically you know the same way your eye can find a face when you look at a picture this is doing something remotely similar that your brain is doing but in a different like in a computer computerized way so that's what that's what this is so yes the training is happening um in here in essence hope that's clear quasi i cannot hear anybody no you're good you're good to go keep going got it so um let's just get this going and then actually display the webcam okay um i believe we need weight key as well yeah pretty sure we need weight key and webcam release let's see if this works and this is awesome we still have 685 people live this just tells us we got to be doing a lot more of this aaron because it seems like everybody loves this stuff because most of the times by now we drop to like 100 live people watching this is awesome yeah people are loving it right oh says yeah well it's not gonna work because we need the loop so this is a little bit confusing um what i so if i was if i were to do this and display what this gave us it would only give us the first frame so we're gonna have to kind of do a big chunk of um logic together guys we're gonna have to cut up the whole loop and get it going as one um so just bear with me and and we'll get that going so uh once you get the the webcam here uh what you're gonna want to do is um get a a while loop okay so this loop is going to go right here and what this does is we just want it to loop over all the frames in the video forever until the video ends or until we kill the webcam so for the webcam we just want to run forever because it's just gonna is a real time until we tell it to stop so that's why we want a while loop running forever and then from here now we can actually go and fetch the current frame and display the current frame so um let's go down and get this so this is the next um call so this is actually how you would get the image out from the video you could technically run this outside the loop but then like i said it would only get the first frame and it's essentially just an image again which is kind of the same as what we did before so i'm just jumping into the loop so uh there is this webcam that we made okay from the video capture we called it webcam and webcam allows you to read from it so you just call the read function here and what this returns is two things uh tuples so the first thing it returns is if the reading the frame was successful or not this is just a boolean it'll be true or false and then this is the actual image so the frame that is being read currently from the from the the webcam uh this we actually don't need but we need we need to be there just to like for placeholder but we're never gonna use this this should always be true okay but this is all we want we just want the frame so once we have the frame now we can actually take the frame and instead of frame um use the frame instead of image so before we're using image with robert downey jr and everything and being causey and all that but now we just want to actually change the image to frame because this is the the image we're using it's the current frame so why don't we actually do that and let's comment this out and um just show the webcam in grayscale okay so we're not going to do any detecting yet let's take this paste that in here and show this okay remembered yeah so um the one thing about weight key is actually let me demonstrate it first and i think that'll be better so let me just run this and see what pops up i don't think anything's gonna there we go so as you can see this is just a single frame it's not moving because uh the wait key is is waiting on something and i got a little bit screwed up so actually what we need to do if i had an image though you can see it skips to the next frame so i can move around and then when i hit my space bar then it automatically goes to that frame because it's waiting for the key so one way to get um out of this i gotta force quit this because there's no way out of it forks quit force quit python there we go we are um going to put a delay in here so um wait key here if there's nothing in here it'll wait infinitely until you hit a key for it to quit or to go to the next frame like we did but if you put a number in here it'll wait this amount of milliseconds before it automatically hits a key for yourself so we can wait one millisecond then it'll auto hit a key which means each frame will be um happening every millisecond so let's try this all right and this should actually be live webcam footage um in grayscale from our webcam so as you can see it's just grayscale there's no face detection yet or anything i'm just doing this and then the wait key every millisecond is um it keeps just keeps pressing a key every millisecond already wait it so hold on one second so that's so sick that already has you in great scale in real time like from python i did not know you could do that that is so cool um and what are you saying about this one millisecond thing i'm not understanding it like what is it what is it doing it's a little no no no no just show your show your screen show your camera so like okay so what's happening like without it would it close would the window close no so wait key what weight key does in opencv the ways it's coded the way it's implemented is um it's going to wait for a key press to execute code so the code will just wait at wait key that's why it's called weight key it's waiting for a key to be pressed i'm just i'm just trying to understand in english like what happens if it's not there or you don't do it the right way like does the code break like does the video stop playing does the next frame not load like just in pure english like what is it that it actually does weight key um it's stuck if it's not there then it just won't work okay what's great is it's like like you need you need weight key to actually display something like you cannot just in opencv the way the way it's designed is you cannot display something if you don't call way key okay that's it that's all that's the most important thing i care about like if i just want to use this like all that's for me that's really important so okay so if i don't have weight it won't display it's not actually what it is but that's the behavior that okay beautiful beautiful got it okay so yeah because if it's not here then it'll just it won't work so let's quit this um again you gotta force quit we'll fix that in a bit you guys will be able to like hit the q button and it'll it'll it'll quit instead of having the force quit uh but here if i run this then i don't think it's gonna work it'll like pop up for a second or something and then disappear yes it just freezes up and there's nothing over here yeah so it gets there and then it gets stuck in an infinite loop so that's not a good idea nothing pops up you need weight key because you want it to wait here and you want to show a frame and then wait at that frame that's what you want got it okay uh so let's close see python not responding because if we're stuck in this infinite loop with no way to get out so it just just bugged out all right continuing on now so let's put this back you can think of it as display but what i was saying was if it's if there's nothing in here it'll wait forever and wait for you to actually press a button for it to continue to the next iteration of the loop so if you go back to the code this is a while loop right and it's going to run over and over and over again and each time it runs it's getting the current frame and then displaying it in grayscale to the screen okay it's getting it's turning at the grayscale and then displaying it with image show right here the current frame then it waits here forever until a key is pressed so that's why the behavior is weird it's frozen it's the current frame and then when i hit a key then it goes to the next iteration of the loop the next one next one and if i spam it then you can see that i'm kind of like moving but then if i stop then it breaks so what weight key does is it waits for a key infinitely but if you put a number in here then it'll only wait for that many milliseconds before it automatically just continues on and goes here so that's why we're saying then i don't have to press any buttons it'll wait for one millisecond then automatically go to the next iteration aka the next frame and so we're getting one frame every millisecond i mean i mean the the camera rate will be lower but that that's uh that's what it does so we'll quit out of this again one last time force quit this and run this to get the correct behavior and there we go so we're in real time every millisecond the loop is automatically restarting with the weight key because we put a one here you could even put like a thousand in here and then every 10 seconds it would go automatically so but we'll leave it at one because we want to be real time now moving on from here we have the grayscale but now we want to plug in the face detection into this so just the same as before um we are going to want to take the detect uh detect faces and of course we want to apply it to the grayscaled frame so instead of just displaying the grayscale image we want to find the coordinates of that and then display it display um display over it so the grayscale image this is all the same code the face coordinates are going to be using the trained face data and then of course the detect multiscale and then we're giving it the grayscale image from right here just the same as the image then we need to draw the rectangle so this is the same thing again let's just steal this loop that we wrote earlier and pop it in right there and this should work as well so let's just double check image actually this won't work because image was the image before this actually needs to be frame instead okay and um i think that is it it's just the frame has to change so what we're doing is we're detecting oh i see it's pulling the frame just to be clear because i got confused at this i'm sure people are going to get sometimes confused it's pulling the frame from line 18 when webcam.read unpacks okay cool the the current frame of this loop every millisecond the current frame is called frame so you want to we want to detect the face in this frame grayscale and then we want to draw the rectangle on the frame not on the robert downey image that we had before but on the current frame of the webcam because we have webcam now so that's how that works now let's um just run this and see how it goes i think i think it's everything so of course you're going to need to force quit this again and go to terminal and why is it not working ah because i am displaying the grayscale image not the um colored colored one one second i must got a bug somewhere so yeah so the image show it's showing the grayscaled image what we want to show is actually frame okay because that's where that's the colored frame going back to color and then we color we put the rectangle on top of it so we want to display that instead of grayscale so now it should work but knowing my luck probably won't there we go and there's the rand range oh nice and the colors changing every second look at that that is so nice so you can so you can see that you can see the one million the one millisecond refresh rate that's actually pretty cool the color you can see like in real time yeah actually you can see every time so cool every time the loop uh iterates it's getting my face it's not perfect though because this is actually a pretty lean algorithm there's there's more powerful algorithms but of course there's always a tradeoff of um speed and accuracy whenever you're doing algorithms for everything in like computer science and data science there's always multiple algorithms you can use to solve a problem this one we're using har cascade um specifically because this is the most commonly used one like this like on your little camera's digital cameras your iphone is probably using this that's so cool that we're you like we're looping through on your face and like drawing like looping through and making new colors like that is just the coolest thing and we're gonna have to force quit this wow okay and let's continue on so we can actually get rid of this stuff and keep code completed so uh oh i forgot one more thing so i i kept having the force quit which is pretty pretty dang annoying to be honest um so i threw in this thing uh earlier today of giving us the ability to oh we gotta clean up after two but of being able to actually quit using a key a specific key so did i copy the right one yeah this one so if i pop this in here um all this means is um oh first of all i screwed this up so actually when you're getting the wake key you can actually capture which key was pressed on the keyboard so it's waiting for a key and then you can actually get it so if if if if i don't press a key then this is probably like zero or null or something or none in in python um but if you press a key then it'll go into this so what i decided was i um if you press the q key then q for quit then it'll quit out so i looked up the ascii characters for q very simple you can just type in ascii if you didn't know every every keyboard character has its own ascii code ascii is just a sci i don't know what it actually stands for but every every letter has its own number so if you go to q you can see q is 113. lowercase q is 113. uppercase q is 81. so 113 and 81 that's where i got these numbers from 113 and 81. so uppercase or lowercase q will actually break out of this infinite loop and that allows us to exit the realtime face detection without needing to force quit the way i was doing it all this time okay so let's give this a shot and see what happens run it and it's going good and let me hit the q key q are you connected q unless i had a bug let me um let me go double check what is wrong oh yeah i forgot the webcam release i always forgot these things uh good things like especially when you're doing um memory allocation or any any kind of like streams of data you should always clean up your code afterwards so in this case you're going to have to release so i think this might be the case um let me see the yeah let's try let's try it again there we go now let's hit q i think it's lagging i think it was actually working but it's just taking a long time to actually there we go okay so what's working i think i think the color maybe the random color was um doing some stuff uh i don't know it's just being laggy but pretty much it has the the working functionality i'm actually curious let me just try to change this and see if this is actually what is holding it up and let's run this again go here so it's just green back to what i had before and then hit q nope my computer is just slow i think it's just bogged down from the live streaming and everything at once i think that's why it's slow really slow anyways it'll close after a few seconds not important but let's change this back to the multicolors because that was cool and um that there guys is pretty much the completed uh realtime face detector app okay uh we have the ability to detect faces in images to detect faces in webcam and even video so actually let's uh i have a video here um called lol memes that you guys have probably seen before and let's pop this in so instead of reading from the webcam we're going to be reading a a video file on my desktop so if you give it if you give it an argument of zero it reads it from your webcam but if you give it all and if you give it a name it actually looks for that file path it's just capturing video from somewhere you've got to tell it where to cap your video from awesome that's all it's doing so now let's try to run this and we can see it work whoa what is going on whoa that is crazy it's getting that guy a little bit now you can see it's not perfect i mean it's really difficult like this is a crazy video and it's already pulling it like that's insane wow i pulled this this video and you can see it's getting his face at the end there people are like wow it's amazing very nice awesome and then of course if you hit q it will quit and that one happened a lot faster can you oh i see okay interesting um i'm trying to think okay cool is there any other videos you have on your computer that it can pull from yeah i have this funny baby that i got okay let's see so yeah right there i was testing these earlier nice and there's no audio but here's another oh my god that is so cute that is so cute i love that i love that the dad is basically like tormenting the baby by making them say stuff but yeah logan says super impressive aaron logan's super impressive aaron thank you for the content absolutely we haven't even gotten to the interesting part yet this is the fun part but the interesting part is about to happen so this is working here again i'm going to try capital q this time and it should quit wow our loop is still working and going through the random colors i love that yeah i think i think we're giving the baby epilepsy that's what's happening here he's going crazy you know what you can even do is like like right next to it draw random captions like draw like random you know so like how have that people have that like speech thinking bubble next to them uh yeah something like that so we could even exactly so you can detect faces and automatically put like speech bubbles in real time next to it that like writes out text or or morty i think we could superimpose our i don't know i don't know about that rick yeah we're thinking doing that we're gonna superimpose rick and morty's faces over our faces but uh it was too hard to do that with the stream at the same time we couldn't technically figure it out the stream oh oh geez i mean i mean we could we could probably do that you guys you you would really you would really have to just let us know if that's something you're going to like i mean i mean you you can go ahead i mean oh geez just go ahead and smash that like button that that'll be so awesome yeah morty i didn't actually had a i didn't actually know you had a head on your shoulders morty but i'm proud of you today people are loving it they're like this is amazing they're like i wish i could code like this i still hate you morgan you piece of logan is laughing yeah i love rick and morty man i love brick and morty yeah awesome anyways um that is that and that completes the app but now i mean this is a lot of hand wavy woowoo stuff we just called this detect multiscale and downloaded this file and it just kind of magically started detecting faces like cool like a fiveyearold could have done this which is true but which is also awesome because i mean you got this up and running with like minimal work but i do want to give you guys understanding of how the algorithm is actually doing it but i do want to give you guys understanding of how the algorithm is actually doing it like how the heck is a computer looking at an image and how does it know what a face looks like and actually understand it so um that's where i want to actually go to here okay so let's just look at this for now i put together a little presentation um to actually transition people over into thinking like a data scientist because um most data scientists are coders but not all coders are data scientists like you can be a coder you can be a frontend developer which is amazing web developer and stuff but like if if you don't actually understand like some of the underlying algorithms and stuff you you can't actually pursue anything in data science if that's what you want to do and that's what python is known for so that's why i want to touch on it so um instead of being a coder and just like copy pasting what i just i taught you now you need to actually understand what's happening behind the scenes so that in all the little tricks that are happening so that you can actually innovate on that and continue forward and actually come up with like new and faster and better face detection down the road so but you got to understand the basics before so let's continue on okay um face detection so what the hell is har cascade that's the big question because if we go back to the code then um all this stuff was like hard cascade hard cascade what like what the heck is hard cascade why does it say har cascade and we just downloaded this thing um well this is just an algorithm okay so har is the name of a dude who invented the algorithm and cascade is just the word cascade so cascade is like a chain of events pretty much and you're just going down like you're going down a funnel so what it's doing is it's like it's going down a funnel until it finds a face at the bottom of the funnel and then it's like here's one face and it keeps doing it over and over again for every phase you're cascading down um that's the one paragraph explanation but let's actually go to one second and real quick uh if you want to cue me to show your face just you know just be like his you know camera one or something like that and i'll switch over to your face or you can just tell me so right now i'm i'm i have the camera on both of us so now when you're drawing like moving your hands physically it'll show and now i'll hit two and it'll go back to the screen got it yeah we'll just show me really quick while i'm explaining it so um like i was saying the hard cascade is just like a chain of machine learning things that that the image is being passed through and then it's going to funnel it down to until it finds the exact square where there where there's a face it kind of looks at like every square of every size on the image and it passes each of those squares through this machine learning thing and then it cascades down eventually it's like okay if you pass all of the cascades and you get to the bottom it's like okay this is close enough to a face to actually be considered a face and that's why it's called cascade horror is just a name you can kind of ignore that but hopefully this makes it seem a little less scary you can't understand but now it's time to reveal the magic trick of face detection okay it's pretty mindblowing like honestly i wouldn't have been able to figure this out on my own like these geniuses did it but i learned it in my in my schooling at georgia tech when i took computer vision and i'm just gonna share it with you okay so yep time to reveal the magic trick uh don't be this guy um i have this gif here so it's actually it's actually pretty simple how it works and i want you to understand instead of being like this guy like how the hell does faces section work i want you to just know like how it works because it actually is this simple you can see it from the third one like once you understand it's that simple i love that that is awesome let's continue on yeah so as you know the algorithm is called har cascade so let's start with haar so what heart cascade does you can also by the way you can full screen this you can just hit command enter and it'll full screen it so everybody can see it in a better way and and you can actually use a pointer so at the bottom left click pointer and then when you actually move your mouse around like people you can yeah so it's easier to know what what you're talking about okay see i'm just i'm just a coder i don't know all this fancy google google side stuff but anyways so these are har features so this is the first part of the hard cascade algorithm it's a very very simple thing um what you can think of hard features as as rudimentary building blocks so this is a one heart feature this is another hard feature this is in the hard feature this is one and this is one all this really is is a little block so what we're going to be doing is we're going to be placing this over a portion of an image that has a face in it or it doesn't have a face in it and all it's doing is it's kind of showing the relationship from the white portion to the black portion and then what this allows us to do is it kind of allows us to approximate the relationship of these pixels within this box so if we overlay this over um somebody's face then we could be like okay um down here in relation to the pixels up here there's some kind of relationship and then um or or this way you could be like okay the pixels on the left have some kind of relationship to the pixels on the right or like this um you can do the three thing like okay there's there's a relationship a threeway here or um a diagonal and this is like the the most elementary ones that you don't have to go any bigger because you can just kind of chain them together but these starting blocks is what you start with and if you chain these together over and over again and you layer enough you can actually some combination of these five things will actually give you a template for a face it'll look like a face and then that's how they actually find faces by layering this over and over again and cascading all the way down these different layers um and then actually finding one that matches the face and though the way it does that is you give it faces so it finds out the combination of these things to know what a face is and then you can just filter through it again so that's kind of the um the idea of of heart features so far so these are hard features and uh let's continue on to the next slide i think i'll make more sense when i show this one so this is how a hard feature is applied to an image so like these let's say these are blank images or background images i have no faces in them um one heart feature is here and um here's another one different a different type where it has three um three columns another one is here and as you can see this is uh how you would overlay it on an image so this is the raw image but then if you have the heart the heart feature here what we're looking for here is oh the relationship of this black box to this white box and um what's cool is if you look on this face here you can kind of tell that this rectangle here of his eyes is a little bit darker than his cheeks and his nose and you see how that corresponds to the black and the white here so we can actually say that this heart feature is closer to a face than something else like placing this like all the way on the bottom left where it's kind of like not because there's kind of like a black bar here in the white part here so white so the white one means that that is more like a face and then the black the area that's black is like that's less like a face the the black is like you can think of it as like it being darker and the white is it being lighter so you're saying that there's some kind of like going from light to dark in this direction or dark to light to dark in this direction so oh wow so like the electric so like bar going to a light bar you see right here is exactly what this okay so one second so i'm so basically the face detection it's literally it doesn't look for facial features it's just looking for like how dark and light it usually is around faces and that's why you only need greyscale crap that is well this is this is only one algorithm there's like there's a bunch of different ones but this is the most well known and most widely used like literally just looking at so for this one specifically it's just looking at like yo here are 100 different faces you'll frank you bring your face in real quick so like it's like it'll like have like a certain thing for like dark and light for his face versus a dark and light yeah so then it's just looking for white and black like okay okay cool like if you if we went back like this would even be a better match because you have forehead then eyes then cheeks you see what i mean if we had that here you could also have a white bar up here you can kind of see it's like white then dark than white so we're basically saying there's some kind of three layered relationship of this block of pixels and this is only one layer of hard cascades basically we're going to layer a thousand of these little matches together and eventually those added up will add add up to a face wow you can see the second one here you can kind of see like okay the eyes are darker and the bridge of the nose is lighter see the eyes are dark and the bridge of the nose is darker so this heart feature plus this heart feature is even closer to what the heck of faces yeah this is what this is what logan is saying he's like ah he goes this is why we use grayscale right aaron and he goes because color is irrelevant we're actually just looking for brightness yes exactly well you can you can start using color when you want to get like really like if you want to like profile like race or skin color or if somebody has freckles or not you could even start doing that if but it would of course you would need more data and longer time to train but this is the most generic case but i want to teach you guys from the ground up so that you understand how this works because this is the prerequisite to everything else okay yeah um so this is how a hard feature is applied to an image and of course you would just take this box and you just drag it all the way around the image you would even resize it like um because again you could have like this similar thing might be like it might match on the mouth a little bit but let's move on okay so these are hard features these are the five rudimentary heart har features and this is how hard features are applied to an image and if it's like this then there's no match you know there's like it's just a white but like flat background or if it was like a landscape or like your wall or something then there's gonna probably be nothing there um but let's go on there's a little bit more nuances but that's the general idea so far so now actually how did opencv train that face detector that we downloaded that xml file because that's where the magic is we just called we just downloaded it and just like called a few lines of code which is kind of like okay cool but how do they actually do it because from here if you understand it then you can actually start thinking correctly and do some real data science stuff like you're not a data scientist unless you actually understand the algorithms so step one like we mentioned the very beginning of the call you want to start out with your training data so in machine learning the the way it works is you have positive images and negative images and all these are are just labels so this would be labeled as face label as face labeled as face this would be labeled as not face not face not face that's all it is you just need faces labeled as faces so just to contrast just to just to contrast that guys so here is a face right but here is like this would be a negative image right a phone would be a nonface so like it's not a face so again nonface is happy cup of coffee this is a nonface when it sees it this is a face when it sees it right and this was through supervised learning so it fed the data to the hurricane cascade right and it told it yo these are all faces and these are all nonfaces yeah so this is yeah yeah so this is called supervised learning we're probably not going to go too much into unsupervised supervised but like at a high level it's like a human being's telling it what is a face and what isn't and then feeding it like lots and lots of data yeah uh another way maybe another way to explain if somebody didn't catch that is there's two fields of machine learning there's supervised machine learning and unsupervised machine learning which is what causes just said supervised means you know these are all faces and you know these are all nonfaces it's supervised you're supervising the actual data and you can tell it like these are faces okay that's what it faces these are not phases okay that's not what a face not is um but if you're doing unsupervised you're literally just given a bunch of stuff and you have no labels and then you can just at the end be like oh was it right or wrong so you have even less data but that also is a lot better because when you're gathering photos from the real world or data from the real world usually it's not labeled you'd have to go in there and manually label it by human because how else would you know these are faces so there's kind of two fields of thought supervised is better to learn first but unsupervised gets very very messy and just kind of like the cutting edge right now yeah yeah that's where like you really get into ai and all that like deep deep neural nets and all that stuff deep deep girl nets awesome this is just yeah machine learning so uh star one start out with training your data so you have a bunch of labeled images and from here you'll go to um the next thing so after you have all of your images so you have face images and then also nonface images you want to find um the winning har features so like i said this heart feature matches nicely with the eyes and the cheek and then even if we had like the other heart feature with the with the lighter bar on the forehead that would even be a better match but for this one is we're just using this this is a fairly good match and this one is also a good match okay so basically what we want to do is we just want to chain together all the hard features that kind of match and add them together sum them up until we get a face template these are like little lego blocks to like doing it and this is why it works for nothing because they're rudimentary building blocks this can work for a cocacola can you can distinguish a cocacola can from a pepsi can eventually because it looks different and like the the brightness and the brightness relationships within these boxes and sizes of boxes is all different that's why there's you just start with like plain old boxes and you add them up i have insane that you can tell the difference of everything based on brightness like this is where algorithms are so freaking cool because i mean it's what your brain is doing right like what is your brain doing it's doing the exact same thing it recognizes a face versus not a face and we're just teaching the computer how to do the same thing dang damn so it blows your like selfdriving cars this is this is absolutely like essential like tesla you know tesla stock is going up like crazy elon musk just passed warren buffett and his net worth as of like three days ago like go elon are you serious protect yeah he's 70 billion warren buffett is 69 billion whoa but he's now elon musk is now number seven in the world he's exploding bro but um but yeah the tesla selfdriving cars they use this heavily um it like with other things but there's a lot of computer vision so like you could like um you could detect pedestrians whoa i am showing that on my screen using the same heart function that is insane i just um i have an ad blocker on so i have to turn that off real quick but um i'm just showing them on the screen that elon musk actually passed oh my god is this website annoying holy crap jesus christ okay i'm out of here they can they can keep their we don't need to look at that business insider yeah elon musk just passed them officially that is insane yeah elon musk is my guy man like daniel works at blue origin right that's like the competitor of elon musk's spacex well we have a guy here a programmer who works at a competitor jeff yeah he worked for jeff bezos company and he works on an actual rocket ship at clever he's gonna actually be here next week and he's gonna be teaching everybody algorithms and maybe even some stuff with python yeah he makes me look like a baby yeah awesome so keep going but yes so after we have all of the images the face images and the nonface images we want to find the winning heart feature so which har features um align with a face and then on the reverse for non feet um for non um nonhard features we want to see which heart features don't match so like you're doing the reverse you want to make you want to find heart features that like do the antimatch and then eventually if you do enough reps then you can kind of understand the heart feature that determines the face versus not a face so this is how it works so we have if we go back to this you have a bunch of faces and a bunch of nonfaces so the way the algorithm actually works is i'm actually going to come out of here for now and can i zoom in no this is big enough though so we have to test every heart feature okay that's pretty much it there's only five but of course we can scale the size so what we want to do is you literally want to start here and check check check check check check and then go down check check check check check of course and do this across the entire thing and then again do it with a smaller one check check check check check blah blah blah and then go to the second heart feature and the third the fourth and fifth and you keep doing this on every single image until you can find which ones actually match your face so after um yeah every like i said every type of heart feature every size of our feature and every location cause you there's a lot of background noise my bad there's a um and every location of every image okay and each heart feature after it goes through the whole thing it'll give you a number and um this number tells you whether it is a face or not a face like what this heart feature will say so after this heart feature goes through this entire image okay or let's make a little bit bigger like there so this is this is the good matching one so after this goes through the entire image um each of these spots it's going to get a number so um the way it does this number is it takes all the pixels in the black and adds them up to one number then takes all the pixels in the white this box adds them up into one number again grayscale is useful because we only have to deal with one number instead of rgb and from there um you have a white number and a black number then you just minus them to get the difference like how far away are these numbers from each other like if this was if this was 0 and this was 100 then the difference would be 100 or this was 20 this was 70 the difference would be 50 they're 50 apart from each other so this would be a 50 and we could say okay this match is 50. so this this horror feature in this location on this image has the number 50 and then we give it a threshold of saying okay if if it's 50 or higher say it matches good for a face if it's 50 or lower then say it's not good for a face and so that's what we do so you say okay this hard feature goes all the way through and here and then at the end it gets a it gets a final number for itself and you and then you can say at the end of this you're like okay this hard feature in this location was really good let's keep this okay this is level one this was the best performing par feature um let's keep this because it was the highest like maybe it was like like closer to 100 or something and then um after you do that that was just one heart feature on one image you'd have to do this on every single image to um find it because it would also find the same kind of pattern on other people's faces because you know their eyes are going to be dark and their cheeks are going to be light too because that's what a face is and then after that you could be like okay this this is the winner that's cascade one that's level one so whichever heart feature matches the training images closest is our first winner so if you go back here um it matched this one like her eyes are darker than her cheeks and you can say okay that's a match that's the first winner then we would go to the second one and go here and and then see that this is another good match because the light nose plus the dark eyes and um we would do that too but of course you would have to iterate through the whole thing and then of course all the different sizes too you'd even go like tiny on every single image and all the background images too but that's how that works and eventually at the end because if you take this black segment add it to this black segment and then subtract it from this white segment you get a number at the end again and then if it's above 50 or closer to 100 that's the idea then you can say okay this is a pretty good match versus here where it would be like not a very good match and you just do this over and over again and you want to get like a thousand hearts harf on features that match right now we're only looking at two but you want to do this over and over again that's why computer's so powerful and that's how you actually train the cascade object detector or in our case the face detector but you can detect any object depending on this on the on the training data so that's how that works you have to test every cart um har feature and then after that after you've gotten a thousand winner har features you can take that and then put it all together into a big um machine learning algorithm for face detection so that's what this diagram here is so step three this is the cascade which is just the chain of heart features a chain of heart features this was the first best match this was second best third best fourth best all the up to a thousand a thousandth best and you would go through an order and if a picture passes all a thousand then you can definitively say hey this is a face if it only passes 900 it doesn't get to a thousand you'd be like ah it's not good enough to be a face so that's the kind of the the mark there that's how that would work so you take all the images that are faces all the images that are not faces um then you train it with uh these hard features you find the one thousand one or it can be any number is you can kind of decide like when it's close enough but you choose let's just say a thousand winner heart features in order and then we can chain them together into our face detector which is called a cascade classifier because you cascade from stage one to stage two to stage three all the way down to stage 1000 and then that is stored as an xml file which is exactly the data that is stored in here so in here it probably has a thousand of these little things so this here is one heart feature could be one heart feature like from this tag to this tag is one single heart feature that's the idea okay and then all these numbers are actually the heart feature we're looking at has the the brightness and the color and the location and the size of it and um you would go through and then of course there's like a thousand so you just fish the the image through here and then it looks for every single um thing in the image until it finds faces so that's why it's called a cascade classifier you or a hard cascade because using hard figures and then you're cascading down all the matches hard figures until you find a face okay so that's the explanation of how it actually works one final thing i want to um do is uh the way it actually will actually continue on in the slides can you full screen it please yeah so the nice thing about that is opencv does the hard work for us okay um opencv provides all the pretrained classifier um data that has the chain of heart features that best match the frontal face which is exactly what we downloaded remember when we were at the github i said download har cascade frontal face default they have all of that data for us they trained it already and they have that data um and then from there then after uh it's classified we can just pass a sliding window so a sliding window is just a window over the image or the current frame or whatever into the and pump it into this classifier and run it through all 1000 hard cascades and if it makes it past all 1000 it's a face if it only gets to 999 it's not a face that's the threshold and so yeah if it gets all the way to the end it's a face but if it doesn't then it's not so that's why it's called a cascade because you're like funneling down into what a face actually is uh one last thing let me just explain how that actually works so what you what we would be doing is you would have a have like a sliding window so you would have or let me make this full screen or actually i can actually just add a square can't i shape nice so let's just say we have a square here a question by evil namekian he said is it possible to use face detection into a flask application absolutely yeah i've never done it personally but i mean yeah you can you can tie you can tie this into web development you can take this and then you can somehow call the opencv code in your flask application um i mean you would like you could use flask like house something or house a web page but you would need some way to get the um opencv code running on your flask but it's definitely possible django might be better but flash might be cleaner but look into it but it's definitely possible just got it beautiful check it out that's homework for you but uh the way this works is you would take this little square pass it through all a thousand hearts it's like oh no this is not a face not a face not a face not a face not a face not a face and this is so tiny this would be not a face the entire time and eventually then you would check a little bit bigger not a face not if it's not if it's not a face but eventually when you got this big you'd be like okay not a face not a face match is 900 um blah blah blah matches nine um 950 not quite a thousand yet matches 950 but 950 boom and then boom it matches a thousand and then that's when you get the face so that's how it would work and then it says ding ding ding that's a face and if there's multiple faces then it'll find all of them in the current frame and that's kind of the full algorithm of how the face detection actually works in practice and actually like threw it through with the method numbers okay so now i want to show you the romano one interesting thing romano says you can adjust the sensitivity of face detection and he basically says that that phase classifier detect multiscale thing you have the last argument is actually for sensitivity so you can actually yeah change the scent sensitivity you're looking for yeah you can go here detect multiscale so you will have all of these parameters you can do um min neighbors scale factor so you can say like okay how many faces can be close to each other like do the faces have to be far away you know how we're getting random little squares here and there you can say oh if there's a little square next to a big square um prioritize that big score and just omit those little squares to kind of clean it up so you can kind of finetune it um that's the nature of algorithms you want to finetune things until they're working nicely but you just want to get it really close to working effectively and of course there's always a tradeoff of speed and accuracy that's always the case that's just how the universe works um there's always going to be that tradeoff so but yes you're correct go check it out you can play with all of these um things like scale factor is one by one by 1.1 by default midnight versus three and it explains what all these things do and there's even other things like set image that i didn't go over there's a bunch i mean it would take forever to go over everything but definitely look at the documentation for opencv but good catch that that that is correct uh now let's go to this um video so this is actually hard code visualization happening live so everything i just explained and everything we just coded this is what's happening after the har code is trained um this is actually how the algorithm goes forward okay so let's start here we have a lady here and as you can see like i said though the window will go across right and as you can see whenever the red the current red red square will run a bunch it through a bunch of har features so you can see it's spamming a bunch and it's saying okay all those a thousand heart features within this red square did this red square pass through all those hard features yes or no and it's saying no no no because it's not the face obviously the face is down here so it's saying okay is this box's face no is this face no is this a face no is this a face no by running through all these crazy hard features for each of these red boxes that's why it's going so freaking fast and it'll keep doing this um at for every for every face at every size until it finds the face so let's just speed this up and um we're getting close so as you can see the stage let's see it says 100 match here features 16 of 135 it's matching there's 135 instead of a thousand in this case and you can see that this is what makes up a face you can see the match is pretty close oh there's 22 stages so see how it's seeing seeing these red squares are a match and then at the end it probably averages all those red scares and the red squares to find the actual face and that's where those tweaking things that's where those tweaking those tweaking numbers come into play because you can be like okay if all these squares are so close together you can kind of approximate and just make it one square instead of six faces that's the same phase just be like math this is just one face with a bunch of square matches damn so this is cool it happening in real time and of course if it's multiple faces then it'll catch all of us people want to go people want to see the video they're like can you share the link of the video maybe you can just uh uh show us our description yeah just um just no but hit just hit escape for now so you can show the url and hold on give me one second just show the url and so you guys can pause search this up anchor divi car visualization yeah there you go and you guys can also just type in the url at the top there you go and that's that's really it you guys so that's the entire algorithm you guys coded it up you guys followed along with how it actually works mathematically why it works and how effective it works and the efficiency and all that and the tradeoffs and then also the extensions of it like you could do um actually start like recognizing people like we could distinguish like jeff bezos from elon musk or you could distinguish from coke cans and stuff like that if you if you do it enough depends how much you want to train the data um i mean train the algorithm how much data you want to do it but as you can see this is getting pretty see how it got bigger the red square is getting bigger because it's a sliding window algorithm which is how most of like selfdriving cars same stuff it's very very similar kind of idea and that's really it you guys so it's getting close to the end here and boom there at the end it got all the boxes and it approximated that that is the face um in the huge i love that that all of that is happening in literally milliseconds like that to me is insane can you open up the webcam again like i want to just see it happening in real time that is crazy yeah i did omit one optimization so um i didn't get into the nitty gritty math i'm just explaining the general idea because the math is really simple once you like if you know one plus one you'll understand the math i just didn't bother because it would it gets really indepth if you want to read it you can read the paper i'll link that in the description too but let's go back to the to the code and then you can actually see it happening with the um camp for this one so you might have to go at the top and change the mp uh for ah yeah yeah you're right you're right zero save that and run this and get that going and quasi text me a picture um text me a picture there we go to my phone to my phone because i'm going to pull up my phone i'm going to hold it up uh send you is it the webcam oh i see okay i'll send it to your slack right now got it okay cool so it's working in real time every single frame it's doing the sliding window thing all the way across the entire thing and it's doing it's doing the entire har cascade of all the har features that it was trained to within each of these squares until it finds this square at this size and finds my face and it's doing that in real time just because the computer is so dang fast so all right about okay i'm having trouble actually i got different ones so we can actually so real time we can oh wow my face and all of my faces it's kind of not getting cozy but see there we go it got me i want to close yeah dude it is looping through in real time that is insane it is literally looping through in real time every frame every size square across the entire image with all the thousands of heart functions and it's just like number crunching you know fast enough that's all it is wow it's really it's really cool and you get an appreciation once you understand how it works aaron this is how we gotta demo it next time we gotta just have like you holding like three phones one with your foot and then just like showing the three phones in your face at the same time that's like mindblowing one issue is going sideways doesn't work so it's not super robust but you can do that there's also side profile like there's different like this looks different than a frontal but you could like get your you could combine a frontal um machine learning algorithm with a with a side you can be like oh if it matches either of them then detect it you know then you can be like okay this or even a back hit you could even be like okay if it matches any like any anything and of course like different hairstyles mine might be different than a girl or a bald guy um but i mean eventually you could you could really detect anything and damn that's really it you guys face detection with open cv and python with the entire theory and math behind it so you guys understand it through and through uh hope hope you guys had your curiosity spiked and maybe you're inspired to go learn how to do selfdriving cars and work at tesla because that's what i want to do that is so exciting that was awesome dude thank you so much for that demonstration guys if you enjoyed this so far you know first of all drop it in the comments and like let us know if you enjoyed this and also go ahead and smash that like button because if you enjoyed this chances are somebody else will get value out of it somebody else will also enjoy it all you gotta do is smash that like button to get this video out as many people as possible and if you haven't already subscribed to the channel yup awesome i think that's it guys thank you hopefully this gave you value uh and taught you guys something new this was a mindblowing experience for me hopefully it was also a mindblowing experience for you with that said guys we love your face this is qazi and this is aaron what's up you see me yep and that's it with that said we'll see you guys in the next video peace out guys bye okay let's check out what we are going to do what's up guys so this is the app we're going to be building i just let this demo running so what we got here is uh some urban city driving some guy on a motorcycle there's some cars and pedestrians these guys are about to get hit and yeah as you can see the pedestrians are outlined in yellow and the car is in red and blue so yep this organ building you guys are python super excited as you can see here the cars in the background some girls crossing the street here it's it's doing a decent job it's not perfect but you know it's good enough so this is some guys this is some tesla right here i'm not kidding i'm gonna take a take a look at this right it's able to detect pedestrians it is able to detect cars which is just crazy right i mean it's like imagine basically you know you got your new tesla right and you have to figure out you know what cars in front of you right you need to figure out when to stop you need to figure out when to go this is a system that something that tesla would build for their cars like who is up to build a system like that guys huh tesla autopilot man elon we're coming for you guys elon exactly we're building our own startup company to compete with you elon there we go that's how we're doing it i mean that's that's the hope that's the hope exactly exactly so guys yeah it's like i said who's excited who's excited to build this drop that in the comments below this is an epic system again we are building an ai for detecting what detecting pedestrians and cars with bikes and car tracking tracking exactly pedestrian car tracking and this is what this is beginner friendly right this is beginner friendly yeah beginner friendly the app is not hard at all if you're a beginner you should be able to follow along pretty easily we're gonna be using python and opencv so opencv is an open source computer vision uh library so that's it just python opencv and that should get this entire app finished yep guys now before we get going guys so here's what you do i want you to make sure that we defeat the youtube algorithm system help us defeat the ai of youtube by smashing the like button subscribing to this youtube channel and of course of course sharing the video is that right yep yep that's it so if you want to see more stuff like this in your in your feed then help the youtube algorithm like this video and then youtube will show you more coding stuff and that's what you want right so yeah definitely do that yeah guys i mean look look how cool this is such an awesome tutorial look at this guys it's just like it's making boxes around the actual cars and right and it's able to detect them like in real time we're talking like split seconds we're talking milliseconds this is i mean maybe not milliseconds like it's pretty good it's not quite milliseconds i mean i mean i mean life is happening really fast right so it needs to detect really fast right yeah it's good like even like pretty like you can like see that pedestrian the distance for a split second at least yeah but yeah i'll just let this demo keep running it's pretty dope um i'll probably probably move forward uh oh by the way guys if you're interested if you guys like coding and um i mean to assume you guys are because you're watching this video then here clever programmer we um what we do is we teach people how to become developers like we teach them how to make a living from coding pretty much so we have we offer courses we have a python course called profitwood python that gives you a whole 15week roadmap of becoming a big beginner to expert and landing your first job or client with python so um check that out if not uh feel free to watch the free content youtube this is this video is free and we also have a free training if you wanna check it out too in the description they're both down there yeah other than that yeah that's that's really good we have a master master class training in the description below if you want to check that out and one thing i really want to mention we we recently had a really an amazing store from our students how about you tell this aaron huh oh yeah yeah this morning so or this morning or yesterday morning i think yesterday uh we had a student land a 90 000 a year ago um ninety five ninety ninety thousand dollar a year job uh so the story is she she lost her job through the covid she enrolled in our course she got a forty five thousand dollar at your job um through by being in the course lost that job and then a couple days later just happened just just yesterday she got a call randomly um for a job offer for 90k so twice as much really awesome there but just shows that yeah we do get our students results but check it out um but other than that let's get into the code not because that's what we've got here do it guys who's excited who's excited to build an ai system like this drop that in the comment below and we're gonna be doing this together guys we're gonna be learning this together so make sure to smash that like button subscribe and let's get into it aaron heck yeah man okay so um yep i think it's been going on long enough let me just cut this and clear my terminal and let's go to a presentation so i just want to give you guys a quick quick presentation a little bit of context before we actually start coding if you want to skip this and just skip right to the code feel free to jump to the time stamp the link will be in description uh this will take like five or ten minutes it's fine i'm just explaining um how the algorithm works and stuff so let's get started so card tracking with python okay uh with a couple of cute little emojis there so first of all we're only using computer vision so you guys might have seen some selfdriving cars that have like this weird radar thing on the roof of the car and like spins and stuff it's like like the google one like the google one yeah like the google one and i mean that's like using lasers and radar and stuff and it kind of sucks uh but we're not doing that we're only using computer vision because that's how human works you just use your eyeballs you don't have like a laser sensor okay so only computer vision yeah um and the reason we're doing that the reason we're doing that is because says so okay elon musk he's uh he's a my dad i coined him as my daddy daddy elon but i'll show you sure sure okay sure computer science only and damn tesla stock is up tesla stock is up so this this don't smoke though but not encourage smoking okay yeah none of us smoke anything exactly exactly uh anyways so yeah this is the little article that i found there's actually a video of elon saying it he's kind of cursed about it he's like anyone using uh lidar is doomed and pretty much the reason for that is it's bulky it's expensive it's not effective and humans can do it with just her eyes so a car can too okay so we're gonna be using computer vision just like this and not like this all right beautiful beautiful that's really it so let's explain how this works okay yeah let's do it man i'm i'm very curious oh what the slide didn't load oh there you go anderson now okay let's keep going all right so let me get rid of this zoom thing is in the way all right so step one so how does this actually work good question this is gone one second guys there we go what happened there that's all right guys that's okay we got we got we got you know there we go but anyways so step one is to get a a bunch of car images so what's supposed to be here is actually this image but in color okay so just pretend that that's there so step one get a bunch of car images that look like this step two you want to make them all black and white so that's what it'll look like and the reason we do that i believe nazi asked earlier is because when it's black and white it just makes the algorithm faster because there's less data you don't have to worry about color data it's just relationships and you can still tell that it's a car even though it's black and white am i right that's that no that is true they can still take a lot of things but yeah i mean yeah and if you have rgb color right so you have to have colors i'm guessing it's going to take a lot longer to process because it's just so much more data in there and so we kind of kind of scrap that and be like nope no we don't do that and actually enough actually if you look deeper i think tesla does the same thing so tesla when they actually go ahead and process their videos they process there you know the video that comes to cameras they turn that into black and white guys and we are doing the exact same thing like how epic is that you know yeah i think so i mean yeah it's the first step you've got to turn black and white because it makes things faster and tesla's all about being fast but and then step three once we have the um all the images in black and white like you get a bunch of car images make them black and white just like tesla then you're able to detect and track cars all right and basically the same thing pedestrians but i'm just using cars as the example here yeah so that's kind of the brief explanation of how it works like overall i'm going to go into a little bit more detail here for some context and then we'll get into the code shortly so so how does the computer train the algorithm like how does it go from this to knowing what a car is in each of these images how come it didn't put the red like square like over here where it was incorrect it's actually correcting all of these yeah how does it do that so very good yeah i mean the computer algorithm behind it we're just gonna explain it um in simple terms for people to understand so very simple we use these so these little box shape things are called a heart features and pretty much what they are are like little building blocks like little lego blocks that you can you can use to define um something and that doesn't make any sense but on the next slide i'll show you how it works so pretty much we just do this let me zoom here so i can show you guys so as you can see this is a picture of a car here okay a rear end view and as you can see this little window is is like a dark patch right and this little thing down here is a little bit lighter like this area is lighter and then again the shadow is a little bit darker so what we can actually do is we can take one of these hard features like we have right here this one like this one but inverted and we can actually say that this kind of matches right over here because it's kind of darker up here and lighter down here so we can say that this hard feature matches this location on a car better than it would match here where it's just flat or flat green up here okay so right and the way it does that is it just takes all of the pixels it just takes all the pixels in that black square and adds them up and then all the pixels in this white square and adds them up to one number which is just like a um the way to really boil down like to a single number how dark or how light that entire box as a whole is and then you can compare those two numbers to be like if those two numbers are far enough away from each other you can be like okay this this rectangle is a lot darker than this rectangle or this rectangle is a lot lighter than this rectangle and that's what exactly what's happening here because this rectangle is and so so it almost creates like a shape it also creates like a shape basically because if it basically if it knows right darker up top white at the bottom and then i can continue on doing with that it creates like a shape and and it remembers that shape basically right it'll just find that this match is pretty good when you're training the data and you're like okay this heart feature um of this size kind of matches the car pretty good right okay and then we can also say likewise like i said there's a shadow down here um and this one's a little bit bigger and there's a white strip you can kind of say that this heart feature would match down here because if you cover the shadow it's kind of darker on the shadow and lighter on the bumper so you can actually see that this is also a good match for a car and then these two in added together you can actually see that this dark window and the bumper and then this dark shadow and the bumper are kind of like these two hard features together kind of define a car even better than any of them by themselves yeah so you guys want to take a look at the shuttle at the shuttle below and if you look if you look at all the other cars guys they have a shadow below as well right so that's kind of how it kind of starts to recognize that so that that honestly is so interesting like guys who's like who's who's excited to learn something like this because honestly applying this into your real world into your life is so extremely important mainly because like like you know with tesla with gm with all these companies if they are going towards this they are going towards either autopilot so just imagine right so let's just imagine the amount of jobs that this will create right like it's just jobs with python with machine learning that's going to create in the future in the coming future and already is is insane bro yeah yeah the uber uber's going out of business man like ilama said that there's going to be robo taxi soon so i might have already said this but if you're if you're an uber driver you're going to lose your job so you should probably become a programmer instead because then you can program the cars instead of driving exactly like exactly profit with python descriptions maybe 10 years max and then your job is done so well okay we don't know about that but let's not be let's not be so harsh but let's continue on bro i got faith in elon man like what are you doing my daddy don't do that bro end this stream right now but anyways so that's how it works the idea is these two hard features match nicely for a car um and you can chain like thousands of these together and all added up all of those hard features added up will kind of match to what a car is so these are just two examples and um same thing works for detecting pedestrians so i'll show that next okay okay let's go to the next slide real quick so yeah the same exact idea with pedestrians you get a bunch of images okay of pedestrians you make them all black and white you want to run all of these hard features over all these images to find which ones match in which locations and then eventually you'll train it enough for it to be able to detect actual pedestrians so for example like if you look at this pedestrian here then maybe this hard feature will be really good like if you took this hard feature and stretched it taller and put it over you can kind of say that like maybe here is like a darker person or here is a darker person darker person darker person um and then you have the white the lighter areas on the sides okay so you can kind of use that that's kind of a good match also you can see her her pants are very dark here they're basically like dark blue or black or something you could say that this heart feature if it was a little bit stretched taller too and skinnier then you can say okay this our feature matches good and same here because usually people are wearing pants and shirts of different colors so you could say that that also matches a human yeah a pedestrian so and so and so again it basically it almost like creates a shape again you know it creates it uses all those black and white boxes it counts them in and it creates a shape and knows okay so if this this kind of shape matches right this kind of shape is created it matches a human if this kind of a shape is created it matches a car or a match as a pedestrian right so that is the interior what about this or a coat can yeah you know or or an apple i don't know whatever you want anything anything you know yeah but this is distinguishing apples from pears like that's a little bit trickier and then you probably need to keep the color in there at that point but i mean this is just a generalized explanation of course you there's always a tradeoff of accuracy and speed so yeah um it takes a lot more work to distinguish an apple from a pair than it does from a human to a car because they're just very different things sure that show that sweet man all right let's continue on yep that's it so let's just jump into the code let's code it up hey let's go guys we're probably like 12 15 minutes in but um again timestamps in the description if you rewatch stuff or skip anything yeah but let's get into the code okay guys are we still alive nice maybe we are alive we're all good we're all good we're all good we're all good let's continue on guys who's pumped to build who's pumped to build an ai system like this who's pumped to build an is system for a car and pedestrian tracking i'll jump put in the comments below and we're gonna we're going to get started right now got it all right guys so i got the code up here and running this is what was running the the demo code it's actually not that long as you can see it's just a few lines all this here was doing all of that it was taking in the image um not the image it was taking in the um the video of the the guy the dash cam and the pedestrians and then it was finding everything detecting everything and displaying it to the screen that's all happening right here right okay okay so let's just jump into it we're going to start with just an image and then we'll go to video a second but yeah feel free to follow along so if you guys don't have vs code you're going to want to download vs code you're probably going to want to pause this video and download it because i'm going to be going a little bit faster but download vs code get it all set up and that's it next what you're going to want to do is you're going to want to create a python file um you can call it whatever you want but i call the car and pedestrian tracking dot pi okay this is the one i had before i'm just going to be copying pasting code um over to show you guys how it works i don't want to have to type it out it's the same thing pretty much but you want to start here okay next thing you want to do is install opencv so you can do that through the command pip install opencv dash python okay and if that doesn't work then try running pip install the same thing but just add headless at the end okay there might be an issue there um one of those should work if you're running on a mac or a linux computer if using linux you're probably already a badass programmer so you don't even need to you need to know this stuff but again you can just do a google search like how to how to install opencv on your computer if if these don't work you're going to kind of have to figure it out yourself because i can't help with every error but like i said we're about to cost 100 likes so let's keep liking the video guys about to cost 100 likes like the video let's and let's continue on yeah uh where was i uh yeah oh yeah install opencv so once you have that installed you should be good okay um the way you can the way you can test that is you can just put python okay and you have your little python of arm here in your terminal and um oh if you know what this is this is terminal so you wanna go you can do command space on mac and then this little spotlight thing pops up and type in terminal and just hit enter and then it'll pop this up and this kind of tells you um gives you access to your computer so if you type in python then you can do stuff like hello okay yeah and then it'll print hello whatever says there or you know nice nice nice nice daddy oh my god elon is not your dad bro come on man you look very different no no no don't even think about it don't even think about it no no aaron you think about it back on track so to make sure you have opencv installed you can just import cv2 which is short for computer vision 2. and if you hit enter then you this will happen nothing will happen it'll be fine if you get an error it means it installed incorrectly so just make sure that when you run this it just goes to the next line there's nothing happens that means it's installed correctly then you're good to get out of python you can just do control d and it'll go back here and i'm just going to type clear so that we're back to the terminal uh but once you have open cv installed and you have your python file created and you have it open in vs code we are ready to start coding okay okay so now guys guys looks like edwin edwin uh just gave us a one euro super chat edwin thanks so much appreciate it and let's continue on yeah i think my lunch now right now i know right i know anyway so let's just start with a simple um code completed so this is a little thing i like to do i put this print statement at the end of my program so that i know if it prints that the whole program completed without any errors so let's just run this first so this is the first thing that i'm going to run go to the terminal make sure you are in your desktop so pwd stands for present working directory and as you can see i'm on my desktop if you're not then um like if you're not if i'm not my desktop let's say just i'm at my user's user file then you want to put in cd which is change directory and then just type desktop just like that with a capital d okay and then once i do that then i am in desktop okay then once you're in desktop that's where i have my files housed or if it's on if you're if you have all your files housed in a folder then you got to go there instead of desktop but for me i just have it on desktop right here that's that's that's that that's a messy messy file structure bro but anyway are you teaching them how to code like i don't know how to keep my computer organized this is free free content you know all right all right all right okay this is aaron's stream rogue off the stream knives i need you to help me anyway so let's run this code so the way we do that is we just write python because this is a python program and then we wants to run um car i think i gotta put dashes car there we go so car and pedestrian tracking dot pi okay these little slashes and it's a space because it's kind of silly when it when there's actual spaces like i had underscores in the other file but ignore that yeah and then and the way by the way and the way aaron was able to get that is he simply started with so he typed in car and then he pressed tab right away right so he pressed tab and that's basically right away it autofilled because you know we got autofocus yeah it tried to auto find any any files that has car at the beginning and then it gives you all the options exactly you can just type it all the way out maybe just use underscores because then it gets sort of this nasty complicated thing with this stuff if you just use underscores and all your file names and you can just type out this exact thing and then you won't have all this weird stuff it'll just look like it'll look like like that yeah yeah okay it looks nicer nice but uh this video will just use this okay that's fine so when i run this because it says code completed then we should see code completed pop up here and voila it does so that then okay surprisingly because there's just a print statement but like i said when you're running opencv you want to run import cv2 make sure you save and if we run this now then and this prints out we know that this is working correctly if this doesn't print out and that means there's an error here importing and then we'll see it but i mean i think it's going to work so you can press the up arrow key to repeat your last command and just hit enter again and as you can see no errors so guys and that's it our program has been completed thank you very much no no i'm kidding get out of here all right so let's start with just detecting cars and images all right so i have a little mini program up here let me just comment this out it's a comment out in python um you can just use triple quotations like that and everything everything between will be commented out and these and there we go save this and here we go so it's even shorter for just an image but we're going to go through all of them one by one and explain how it works okay so let's start with this all right so first thing we're gonna do is we're gonna want to um decide on an image of course if we're gonna be detecting cars we need an image that has a car in it to detect okay so i just have a image on my desktop called car image.jpg right here car image.jpg this is the same one that was in the slides i was using i just cropped it out yeah the same exact image and we literally and we literally and we literally got guys we really just got these images from the internet so don't think it's anything special it's just an image from the internet and we're going to yeah yeah yeah yeah kind of videos i'm actually using in this in this tutorial the links to the youtube videos i stole them from are in the description so credit to those people the guy on the motorcycle he has like 2 million subscribers for riding his motorcycle around cities and like revving his engine at hot chicks like it's pretty cool but all right all right okay i use a video from him and that's where i get it from so this isn't spoofed i'll go check it out there you can also use a youtube downloader to get the videos yourself if you wanna use the same videos then by all means do it so this is the car image.jpg okay right here and um that's it so the image file we have is just car image.jpg very simple okay and let's just run this this is called unit testing every time you write a new line of code or like a different different group of code i'm a little bit ocd and psychotic and do it every single line i run it to make sure code completed prints because if it doesn't that means the line i just added screwed something up right okay okay called unit testing because you want to test every single unit of change in your code right um even you can be redundant even if it's like as simple as oh i deleted something like you maybe you thought you deleted the d but you actually deleted this that's going to screw you it's going to it's going to break the code true um but yeah pretty selfexplanatory that's the importing the image there second thing is we are going to want some way to be able to detect and track cars okay and pedestrians but let's just start with just cars okay so let's start here so these are um our image we put in some comments because comments are good it's good coding practice and our pretrained car classifier okay so this is a little bit wordy but all it is is like i said when you when you train the algorithm with the hard features and you have a big list of heart features that defines a car when they're all added up like the dark boxes and the light boxes all of those added up define what a car is like it kind of captures the pattern of what a card looks like on in an image or in a frame of a video then you encapsulate all of those numbers and heart features in a file an xml file so um i think yeah so what this looks like i can actually open it right here okay i'll take a look if i just open this up then this is what it looks like so cartesian xml so all this is this is the result of training the algorithm this is what the algorithm at the end spit out after you put in thousands of images oh by the way i totally forgot the car images the data set that that i stole sorry guys we borrowed the hey i got who you bought right now i'm gonna i'm gonna die on the stream you got some water you gotta get it okay what's up get some water you know yeah i got some right here actually so okay i'm gonna drink while i'm talking all right cool cool should be awesome conquering hiccups okay anyways all right so we're not actually going to train the algorithm ourselves on this on this video that takes way too long because like it takes like like a long time for a human to learn and build a habit it takes a long time for a baby to understand what a car and a pedestrian is the same way it takes a long time for a computer to learn what a car is because you have to give it thousands of images and run all the thousands of heart features at every location of every size of every orientation until you eventually decide on the hard features that match nicely for a car and then once you have all those then you're good to go but the end result is pretty much this okay so this is just like some encoding i actually don't know how this works exactly it's just the xml xml encoding is what they use but the idea is you can generate one of these files um and it has all the numbers like these numbers are like different coordinates and different colors and different thresholds of like okay is this a hard feature is this good enough it needs to be above this number below this number and it just goes through the entire list of thousands and thousands and thousands oh yeah guys cause he called me i don't know if you guys can hear one second guys oh we got another donation dope it yeah i'm not in the chat guys i think we've overlooked that but somebody somebody uh donated uh are we still live nos yeah we're live of course all right yeah let's keep going let's keep going there's no no i was just i was just talking with maybe we were like you know yeah yeah yeah all right guys we're back on track somebody else donated i think we missed in the chat because we're focused on the code so we overlooked that but don's keep an eye so whoever that was i don't know their name but appreciate that very appreciate that appreciate the gesture and where was that yeah so the so this is the long list of hard features it's gonna go through all of these and if the image passes all of these you can say okay yeah this is a car awesome or like a little patch of an image if the little patch passes through all these and it's it's a yes all the way through and it it counts as a car if not it's not a car and then that's how we know where they are so you're gonna need to specify this file because this is what's gonna tell us what a car is and what a car isn't and the link to this file is actually in the description so you can just go download this this is just a url just go file save as and you can download this um it's actually just called car.xml but i added a detector for for the video so download that okay that's explanation of that a lot of explanation for one line of code but i don't just want to be like hey just download the work like nah i'm gonna explain i'm gonna explain how it works so they have an overall understanding that's the proper way to do stuff okay we're actually programmers i mean we're lazy half the time but it's fine um all right so moving on um now the next thing we're going to want to do is we're actually going to want to create an image within the opencv format so this here of course this is actually just a string okay car image is just a string in python but we want to give it to opencd remember cv2 and actually read the image so that opencv can actually use it correctly okay so all we're going to do is we're going to call opencv.imageread and pop in the image file the name of the image file which is just car image.jpg again car image.jpg right here so we're reading this in our program and from there we have it in here image so that image is actually now in this variable here in our program okay so why don't we just show uh i believe so the image image image read file imagery file basically like takes in the image and all the and it processes it as like data is that what it does right yep so it just reads it just reads in all the pixel data from that image file and then reads it into some double um multidimensional array so you know like a big array a double array of an array of arrays so that every pixel has its own data and then it's just all encoded into this one variable here image right right right right gotcha gotcha and now what we're gonna do is we're actually just going to this is not a face detector this is a car detector okay we're going to display this image so there is a um we're also going to need this just once so so these two lines of code that we're currently working on we got the image in our program next we're going to need to show the image so opencv has a function or method called image show and the first thing is the name of the window so the name of the window like here is car and pedestrian tracking.pi that's what'll pop up there and then the actual image won't show okay okay that shows up and then in opencv this basically just means display so opencv.wait key you need to you need to run this line of code so that it actually displays otherwise it'll display for a split second basically one frame so like literally a split second then it'll disappear but this says wait until you hit a key before it disappears so it kind of like this displays for a millisecond but this makes it pause and so you need okay okay okay okay it's kind of just like display by the way by the way i just want to say thanks to lars lars donate looks like a euro as well so appreciate that man and we got sony pete guys we got so many people in the comments between abdullah between kristen between tracks between kent usa usma vicky right joshua so many of you guys amazing and so excited in the comments i'm excited that we have such such a great community man literally so yeah i just wanted to mention that because you know so many amazing people that's yeah well let's go ahead and continue on awesome you guys so let's just run this code now all right so again we imported opencv we got the image file we have our car classifier we import the image okay okay um and i just want to show you the image now real quick okay to prove that the image is actually showing up and is within our python program so this will actually pop up a little window with the image and that's it it's not detecting anything yet it's just going to show the actual image so boom right there as you can see it says clever programmer car detector and that's the image right okay okay and remember this this title is from here okay so that's that all right now let's just quit out of this so it's waiting for a key press if i hit space bar or any key it'll just quit out and now we can continue on all right okay so so now we're going to be coding in here because of course at the end we want to make sure we're displaying the image at the end um but now we have our image in our file okay so now that we have the image and we have a classifier how do we actually find where the car is in that image because i mean there's a car here there's a car here there's a car all down here i mean granted these are half cars so it might not detect these i don't think it will but these full cars it definitely will okay well kazi's calling again hey what's up quasi live stream is dead oh stream is dead now uh no you're not mute no it's running is it is the stream up guys in the comments can you guys it's running it should be running guys right it's running you guys hear us it's working yeah it's all good guys always good got it it's all good it's working now all right we don't want another uh dead dead livestream you know you guys it's terrible because it keeps getting cut off but yeah i think we're good right i think we're good yeah we're good we're good we're good we're good we're good we're good anyways so this is the image that's going to be read in and from here we want to be able to classify that this right here is a car so it's like if we pass this little rectangle of the image through that whole xml file and if it gets all the way to the end it's like okay cool this square counts as a car and this square does not count as a car okay okay that's what we're gonna be doing so the next step to do is to actually create our classifier so that's pretty simple that's just this line right here let me show you guys i'll copy and paste this and we want to create our car classifier so all it is is we run this function opencv.cascade classifier because again we're running a har cascade algorithm that's why it's called cascade because there's a cascade a long list a long chain of heart features that we're going to run it through and classifier is just classifying something as a car or classifying it as a pedestrian or classifying it as a face or an apple or whatever but in this case a car and the classifier file is what we just specified the xml file file so we just pop that into here and so opencv we're just going to create a classifier from that file and then we're just going to call it car tracker because once you have a car tracker now we can apply this car tracker to this image and we can actually find where in this image if there is a car or not so here there's a bunch but it might only it might only detect a few but that's the idea okay so in an image we have a car tracker now we just want to apply this car tracker to the image and then spit out the rectangles okay right so let's move on um i mean again this doesn't show anything we just have the car tracker created if i displayed it it's just gonna be the image again so i'm gonna move on like i said in our presentation we do want to convert it to black and white though first so let's just do that next and the reason for this is because it speeds up the algorithm makes it essentially three times as fast because instead of three colors rgb we can just focus on black and white that's it so you're simply converting basically from from color to to to to black and white yep okay question if you guys wanna why why don't why don't you do why don't you do that before you classify is my question like why don't you do that before the classifier i mean you're just creating it yeah we can shuffle this up it doesn't really matter it doesn't matter okay yeah doesn't matter i mean this might make more sense because you have the image then then you change it to black and white and then create the classifier gotcha i mean we could even do this you know we could like keep away or different so like we've got an image here yeah and then we read in the image and then we change it to black and white and then we get a classifier and then we create the classifier and then but the point is what we want is we want to have this uh classifier and this a black and white image ready so once we have both of these we can do this in any order then we can pair these together and actually get the images okay nice so i mean i guess i'm gonna put it back here because i like keeping all of the static stuff together because these can change like you can change the file very easily here or the file very easily here just by changing this and all this code remains unchanged right all right so here we go we got somebody asking how can i how can i donate oh my gosh some of you guys are asking how can i donate dang i really appreciate that guys that is so awesome my paypal is my my venmo my only fans like i got everything just faith all of that you know yeah my snapchat no um i actually don't know how you can do that do you know nas i don't know i think kaz has got it kaiju's got it he's got taken care of all is good yeah cool yeah or we can hook you up with something maybe there's something uh a itch like a fighter course something i don't know yeah it's something up who knows anyways back to the code you guys so once you have the image right in you want to change it to black and white like we said because it speeds up the algorithm and you can still you can still tell what a car is and what a car isn't in black and white images so it's totally fine um you want all the improvements you can have there's always a tradeoff of speed and accuracy pretty much in everything in life um so algorithms are no different so you kind of want to change like again like an apple and a pair if you go black and white it's going to be much harder to distinguish the difference um but a car and a human very easy to distinguish okay right yeah that's true the way we do that is opencv you just there's a function called convert color so all you're gonna do is this allows you to to convert color to black and white it allows you to convert black and white to color and there's all different kind of color encodings i'm not going to get into crazy details but the point is this allows you to convert the color stuff of an image to whatever you want i could even make it all red like have only the red channel it'll look really red and stuff like that all right so i'm not going to demonstrate that here um but well let me see actually now i don't i don't want to go down that rabbit hole um the but yeah the point is you can you can convert any the color of any image so we're going to feed in the regular color image here and then all we're going to do is we're going to say we want to go from color from bgr to gray so bgr is just rgb backwards in openc um rgb rgb is like you know the color of a pixel everybody should know that if you don't well now you do um then they just use it backwards so it's bgr a little bit confusing i don't know why that's so weird that's that's so weird like how about it's like the stan was like but wait if you didn't know if you didn't guys didn't know rgb it's red green and blue those are the three main colors that all the other colors are made up of if you didn't know that so yeah that's that's something interesting for you yeah yeah each pixel has a r uh a red a green and a blue light and then it just like makes the brightness of those three different levels and the combination of those three levels can make any color pretty much if they're all max white if they're all off it's black okay for rgb but for gray it's just one number there's no there's no three channels it's just oh is it zero to like a hundred or something yeah yeah okay from your 100 like what's the brightness that's all it is so we're just converting rgb to gray and once we have that i just call it black and white because why not now we can actually display this black and white image so let's take this and in our image show down here which was showing the color image before let's just change this to the black and white image and of course we need this to display for longer than millisecond and this should actually give us the black and white image okay so let's just run the same thing again again your up arrow key will allow you to go to the last command you ran in your terminal hit enter and voila we have a black ops okay interesting guys give give some give us aaron some round of applause in the comments below i ran six lines of code you know i've been coding for eight years and we converted an image to a black and white image that's what we just did this is all i learned in eight years guys exactly eight years in college eight years in college you know grad school pursuing masters and everything um anyways so that's the black and white image so now that we have the black and white image we can actually apply the card classifier to that image and then we can get the um the the car um in the image out okay yeah so the next thing we're going to want to do is actually detect where the cars are in the image so let's run that next okay okay so i'm going to got it are you trying to figure out what line or line to write this on no no i just kind of want to like submit like these are files shut up it's just like wait don't run down this line or this line guys well guys drop in the comments below what what line should should should aaron write write the piece of code actually cool good question who would win the fight a good question i mean drop that in the comments drop it down in the comment below i'm very i'm very curious we'll see we'll see we'll see one day one day anyways uh yeah so the way you you detect things in opencv is once you have a classifier object okay a car tracker you can apply this to an image so all we're going to do is we're going to say car tracker and we want to detect multiscale so what that means is detect cars of any size of any scale okay so we're going to detect cars it doesn't matter if the car is big or small it's going to detect it matter what or even if it was even bigger it'll detect that too okay got it got it got it got it editor is this guy this is using vs code guys okay visco so like just download this code is the the most the most important one you'll ever use as a developer so yeah it looks like what yep oh by the way um if you guys want to have the the the documentation for opencv um i'll link that link in description too so you can check all these files because there's a lot of cool little things you can tweak i'm not gonna go over all them extensively i'm just getting the app done uh but detect multiscale there's cool things you can add on to the end to kind of like tweak the algorithm to make it perform better or worse yeah that's linked in the description i'll just show it right here though detect multiscale so this is the documentation again link in description just click there it'll zoom in guys yeah cool cool link in bio link in description instagram i'm used to that you know i know i know you dirty millennial okay listen let's just let's just let's focus on the work here okay [Laughter] like i don't like those no boring videos boring live streams anyways so um yeah detect multiscale so of course you take the image in first which is what we were doing here we're just passing in the black and white image but then there's other stuff you can add on there's all this cool stuff reject level scale factor minimum neighbors you can read all the details here if you're interested but you don't need it for the app to work i'm not using it so that's really it so detect multiscale you just plug in the black and white image with the car tracker that we got again from this xml file which was trained with the images and the heart features so that's the whole entire holistic view and once we apply this tracker to this black and white image it'll pick out all the places in that image where there's a square that contains a car and it'll give us the coordinates of all of those cars okay okay so why don't we just print this out and see what the hell is in cars okay okay guys this is this is getting interesting guys this is getting really interesting all right let's see let's see let's run it and boom so again the black and white image is popping up because i still have these two lines of code down here running okay but okay that i printed out cars so all cars is just the numbers yes relative to that really yeah i mean uh i guess it's only taking two cars in this we'll see exactly where they are in a bit um i already know ahead of time because i ran this before but it detects this big car in front and this little car on the right reason being is because these are all half cars so it's not quite smart enough to get the half car well actually actually actually that's a good question guys guys which cars do you think it will actually detect let us know in the comments below like okay man yeah i know you give it away but like this is come on gotta not give it away so easily you know but easy mode i mean like it's impossible to predict bro like not even us you just run the program and see what happens like come on yeah but uh yeah but anyways so yeah it's gonna detect this one and this one okay so there's only two spoilers but these are the two these are the two cars so these are just the coordinates of where the car is it just kind of like defines the square that's all it's doing okay okay so there's two cars one car here one car here if there's ten cars like in the video stream there's going to be like 10 of these in here instead of just two right all right so that's really it let's go back and now all we need to do is once we have these coordinates we just print out we just want to draw a rectangle around that car so we can actually see it because we know where it is we just can't see it because there's no rectangle drawn on the image yet wait so those so those numbers were actually rectangles is what you're saying yeah they kind of define the coordinates oh this is guys yes this one yeah interesting okay okay okay okay okay okay the top left point the top left point of the of the rectangle and this is the width the height see it's the same because it's the square this is the height it's the square yeah yeah that's all interesting okay okay okay gotcha gotcha gotcha gotcha yeah applause for that this is really cool stuff you guys don't hear aaron you don't hear the sound of the chat you know i'm in the chat i'm gonna chat aaron you don't have you you don't have the center fox but we have some amazing sound effects going on in the background just so you know it's amazing sound effects yep yep yep yep you'll you'll see it later don't worry that we'll see you later oh in the stream okay i thought i thought it was like you know it was like dying outside in my background but there's nothing happening bro yeah awesome all right anyway yeah so this is just like because they're squares by default um we're detecting things within a square so this is the width and height of the square because it's the same number within height square and then this is the left the top left point in the image of where it is so from here we can be like okay this is the top left point and i just draw a square of these dimensions at that point going down to the right and that's actually where the um the car is in the image so there's two in this one okay so we have top left point and width and height okay if you guys watched the face detection video a couple weeks ago very similar we're just detecting different things and applying it differently but um same idea okay got it um so guys who's ready who's ready to see some squares and detection squares huh who's ready you guys ready you guys ready drop in the comment below and aaron let's see it let's see it bro got it all right you guys so um okay it's gonna be what's up e uh bgr so this is actually wrong let me okay let me explain this i just copied and pasted um actually let's get rid of this for now i don't want to okay ignore this loop for now actually let me just get it straight up delete it because i want to explain it line by line all right all right all right oops let's go logan hey so here we go here is the um the line to draw a rectangle so opencv allows you to draw a rectangle on any image very straightforward and simple so it's just called dot rectangle so opencv opencd.rectangle and then it's like okay what rectangle of what size what color what thickness and where do you want to draw that rectangle so this is all these specifications here and of course we have that data within cars so if we have the data in there then we can just print it out here okay but where you get the x and the y those are the question where is the x and y coming from uh from here so we're going to get that data out of here so remember okay okay remember we have these here so this is going to be x it's going to be y y it's going to be width and this is going to be height and then from there we can just x y and then x plus width and y plus height and then this is the color this is the color of the rectangle and this is the thickness of the rectangle oh that makes so much sense now guys actually that's not that's not that's not so bad at all guys you get this like drop down below do you get that like it's actually not bad you're simply drawing a rectangle with x y coordinates and you're saying here's the height and here's the width like that is pretty pretty interesting and it's actually not that bad to understand as well you can do it like we can do it you can do it too trust me if they watch their face detection stuff this is very similar they'll probably breathe through this right now just watching us bigger which is awesome exactly that was that was that one was with kazi you know so a little bit hard to make fun of him to make you know yeah he's more of a challenge anyways um so let's just actually prove that this is is working so we're gonna want to unpack um uh this so in cars it was actually an array right so there's an array here and then within the array there's two arrays within the array so let's just grab out these two arrays okay okay so this is going to be array at index zero and this is gonna be arrayed index one okay because there's two elements in this and there's a list of numbers in there okay so all we're gonna do is say um i guess cars at zero so this would be car one okay okay and then why why car zero cars let's just ignore the um let's just ignore the the second car for now okay okay so car one equals cars zero so if we print out if we print out car one car one just like that let's go here run it again as you can see we have just the first car so 375 375 that's what we're looking for and from there we just want to get the um x y within height so what we're going to say is we're going to unpack this i'm going to unpack this this this list here and say this is x this is y this is width and this is height okay okay seems to you guys you're still with us guys guys give us a thumbs up if you're still with us this is kind of like it's all coming together it is honestly not that difficult give us a thumbs up if you're still with us and aaron let's go let's go ahead and start seeing you know the result of all this hell yeah so um all we're doing here is we're unpacking this okay so car one again is this these four numbers and we just want to pack these four numbers into these four variables x y and height okay and then from here now this code should work so x and y is the top left point okay okay we have the we have the image you want to put it on the color image not the black and white image we want to color on the color image um and then put the top left point xy and then the bottom left the bottom right point which is going to be x plus width and y plus height okay that's how the graph works um and then from there this is just going to be uh should be red color so bgr remember instead of rgb so b so blue is zero g green is zero but red is maximum 255 is the highest value you can have so we're creating a rectangle basically that's it yeah a red rectangle of thickness two two pixels thick on this image at this top left point and this bottom right point that's all it is because that's all the rectangle is it's two points thanks and then you just the rectangle between those two points okay so let's run this and see what the heck happens guys ready actually nothing's gonna happen um so we drew it on the color image not on the black and white image but we're still displaying the black and white image so let's just display the color image which has the rectangle drawn on it now okay so now it should work so again let's go i got the perfect gift for it look at that oh look at that oh look at that you don't see it aaron but trust me we see it it's hilarious i'm looking at my code yo but i'm appreciating funny or something i'm making very much fun of aaron guys give aaron a thumbs up in the comments guys this is so epic look at this we already we did we just detected we actually just detected a one car like how crazy is that with how many lines of code directly directly in front of you oh i don't know one two three four five six seven eight nine ten eleven twelve thirteen lines of code fourteen lines of code guys thirteen bro learn to count you count okay you learn how to count okay i'll i can't find it minus one all right guys yeah that's just epic stuff so okay we got one rectangle now my question is how do we get the second rectangle if you guys know how to do that drop down the comments below and a lot of you guys are are a lot of you guys are like whoa let's go we got abdullah in the house we got harsha like yeah we got logan whoa we got oh man you guys are pumped for this look at that you guys are pumped i love it like this when this stream is done definitely go check out the face detection too because it's similar but it's a different application and it's pretty damn cool yeah yeah yeah sweet but this one for car and pedestrians all right so let's see let's see how do we go ahead and actually like get into the second car yeah okay cool well first of all why don't we just change this because this is a very easy change we're currently looking at the first car why don't we just get the second car instead by changing so here instead of grabbing this first car we just grab the second car and let's just draw the rectangle around that we simply do that by just changing this to grab the second car instead of the first car so second car right and let's change this to two just to be clean about and that there should just change all of this to the second car instead and we'll display it to the screen so let's just run it let's see it ready you say bro i'm not kidding abdullah abdullah is like in the comments like damn aaron and nas seem like siblings fighting yeah pretty much i mean like we spend pretty much every day together working on stuff all the time coding like we practically live together it's kind of annoying yeah i know i'm i'm i'm an artist that's it yeah yeah i hate everybody too much too much but anyways let's continue on we're here to learn right let's go yeah yeah yeah um so there that's the second car and like i said in this in this uh image this trained classifier is only good enough to train to like identify fullon cars from the back like this um these half cars you can't actually get them but actually if you trained um something to detect half cars like the right half of a car or the left half of a car you could actually find a way to detect all of these as well but you'd have to train it even further yeah and so on or like the bottom half of a car you know something's being but right now like this pattern is what we're is what we're checking is the the full a full back of the car right okay so now the point is all we want to do is instead of manually going through the array like this we just want to loop through all of them and draw every rectangle on the image for every car that we find okay so that's that's what i had before i'm just gonna have a a loop and this is gonna make it super super simple so let's just start from scratch i'm leaving this here for reference but just ignore just pretend we deleted all this okay so what we're going to want to do is just like in cars so in cars which is an array of an array of arrays we want to or is it an array of arrays we want to iterate through every subarray so we would iterate through this first one and the second one and the third and fourth and fifth if there's any of those so basically we're saying um in cars you wanna take out the xy and the width and the height of every one of every list in there so actually i think if i just if i copy and paste this it'll be a little bit clearer yeah yeah so i think and that's another thing and the thing sorry let's cut you off so really so one important thing guys to mention one one important thing guys to mention is the way that this is works the way the whole y w h right this right here is interpolation like interpolation or there's a special name for it where basically it will take the object that's in cars right it will loop for that and it will basically grab the x y the width and the height out of those numbers right so it will abstract those numbers from those different places and so that is actually in python right i think i'm not sure what it's called interpolation but what it is but you're getting super confusing but no no no but but it's important because they're like okay where's this x y w h coming from right but because here's the thing it's looping through one single object so that maybe i can do like a screen brush on show screen brush if i can do it so yeah right there right so this is the first object right so this first object is going to be on here right in here and it's going to map to the x to here the y to here the w to here and the h to here and you don't see it but i'm drawing basically on your screen so yeah yeah so yeah that's that's the really cool part about python and javascript actually does this too but i just want to explain that and so that you guys know but anyways yeah let's keep going awesome yeah yeah i have the stream up on my phone looks like it's still live yeah we're good we're going we're in the bottom right that's we got 300 people in the house yo wait wait wait 300 which way are you that way can i punch you wait i think i can wait wait wait there we go go there you go hold on hold on hold on hold on ready punch hold on no no no no no no no no beat him up man i wish i wish i wish i wish we could like yeah yeah i wish there's like a real you know maybe you can punch you yeah that'd be good and then you're gonna get in the cage bro let's go i'm ready i'm ready i'm ready man i'm ready have you seen the fight club have you seen warrior with tom hardy steve is like please punch him if he was like please punch him wait punch who punch who's the question each other bro they want to see us in a ring it's like logan paul in the ksi guys who wants to see a live caller who wants to see a live call like that or conor mcgregor in uh mayweather we can do it like that yeah but yeah let's let's keep going we're here we're here let's keep going bro yeah anyways so this is like the longest explanation of a loop ever yeah we're having fun you guys i mean we're having fun um so yeah we're going to loop over all these and then within each of these we're just going to unpack the x y w and h okay so that's all that's happening there and once we have x y w and h we just want to draw all of those rectangles on the screen we can get rid of this hardcoded so we're going to iterate through every um pair of coordinates in that list we're going to get all of them and then it's just the same exact line of code here we're just going to draw every rectangle on the screen but actually what i want to do is um a screw it that's fine what nothing nothing there's a little little flavor styling thing i was going to do but i'll do it later so right here this should work so if we run this this will actually loop through both cars and draw both rectangles both both squares so why don't we just save this and give this a run um so we just give this a run up arrow and hit enter and tada boom oh upper left hand point then we know the width and the height and then we with the width and the height and this point we can calculate this point so it's just boom boom red pixel width boom boom red two pixel width and bam that's it and that's it guys video that's it and then for videos you just want to do this for every single frame of the video over and over guys guys if we just did this for we just did this for a picture guys who's pumped to see this for a video drop that in the comment below aaron are you ready are you ready to show this in the video because i'll be epic oh girl i get up all night coding and i just i'm kind of like bored you know but uh hey let's go stuff is awesome like i'm gonna send this video to eli musk and be like adopt me please you know like uh you know like big bang theory yeah howard howard everyone's yeah yeah that's basically but you know pay me money pay me money i just i just did this for you you're welcome you know you're welcome yeah yeah or maybe he'll hire me who knows i mean maybe one day i'm not sure i'm not sure about it i don't know i don't know why you hired but aaron but anyways yeah i'll be a mma fighter like joe rogan and then i'll have elon musk smoke beat on my podcast oh man abdullah abdullah abdullah was like i put all my bets on nas thank you abdullah oh really all all his it's unknowns i think knowledge would be too scared to hit me i think that's what happened to too scared not sure about that i'm not sure about that whatever whatever okay okay all right let's continue on let's see let's go now that we have it done for one image now it's as simple as getting it into a loop okay all right so um i have that here uh it's pretty simple to add it the only difference is you have to read a video in instead of a um a video in instead of an image so let's go up here and actually change that so instead of image it's going to be a video um video okay so i have a video on my on my desktop called tesla dash cam accident so this is actually real dash cam footage from a real tesla that was running autopilot and avoided an accident okay so let's just um here tesla dash cam accident okay okay okay and this is just this is just a video basically you got from somewhere but like from youtube i think right in the description yeah it's in the description yeah yeah it got you know like selfdriving tesla so as you can see this tesla almost it like auto drove and like got out of the lane and safely did that so we're gonna be detecting all these cars in this video okay it's almost over so that's it that's the car i have i trimmed it to that just that little clip but that's the first clip of the video in the description if you go check it out okay so that's first thing so instead of an image we just wanted a video okay and um from there so all the video is is just a bunch of images so we can just grab out each frame of this video and just apply the same thing as we did to this image to every frame and then display the rectangles on every frame and just loop forever into them okay so let's do that okay so i'm really interested to see how this one this actually works out okay cool cool yeah um i'm gonna hey what's up caesar caesar in the house hey what's up copy paste it you know oh yeah that's the best best way especially the code guys i would just copy and paste don't ever don't ever create your own code i'm kidding by the way i'm kidding so um yeah i'm just taking a peek here so yeah we need a while loop and everything so well i'll type out this one because it's because it's short this is the first line of code i'm actually coding on the stream i copy and pasted everything up to this point okay okay but pretty much what we're going to want to do is we're going to want to have a while loop okay not caps supposed to be and we just want it to run forever okay because the video might be if you're driving a car you don't know how long the video is going to be like a real selfdriving car so you just want it to run forever and then at some point when the car is turned off or like it reaches its destination you could be like okay turn this to false and then it'll stop reading it'll stop reading um stuff from the camera so we're just this is just going to run forever so that's the first step now within here we want to run this same logic on every frame so again we had an image here but instead of an image we want to get a frame from the video so we're actually not going to read an image we're going to be reading a frame from a video and that's what this thing here is so let's just copy and paste this okay okay let's see it's indented properly so the way we do that is okay run forever until car stops or something or crashes okay yeah um yeah there we go i've still until what the car crashes oh i don't get sued by tesla um but yeah so there's in in um an open cv uh once we have the video here okay we have one it's called video capture so see opencv two dot video capture and the name of the the file then you can just uh run this and we can just run read so all this will do is it'll read one frame from the video okay and that's a function part of it's a function part of cv okay interesting okay so once you've got another video capture object here called video then you can call dot read on that video capture object which is just the video so you're just going to read you're going to read a single frame from this video okay and then once it reads a single frame it keeps track of it so when it when you call this the second time it gets the second frame when you call this the third time it gets the third frame again through all the and that's how this is implemented and uh what it returns is it actually returns two values so the first value is if the read was successful or not it might be might be actually keep this in parentheses yeah if the read was successful or not and then the second the second value is if the frame is the actual frame so like this frame is actually the image which is just going to be the same as this so this frame here is actually what we want instead of instead of using image and reading an image in we're reading a frame from this video got it got it got it so we got the frame here and then this here is if the frame was read successfully so we definitely want to have good code and make sure that there wasn't errors before we try to display it yeah okay and the way and the way i see it is like this biscuit this video that read basically returns an array which we simply basically map the first portion so no when you call it a tuple a tuple it's called no it's a tuple right it's a tuple yeah a tuple a tuple returns a tuple until we map the first the first okay fine fine fine fine fine fine because five it's tuple because we map the first part of the tuple to the two here and then the second part of the tuple is going to map to here now we don't actually see this you know but in the background that's actually what happened so i just want to make sure that you guys understand this but yeah anyways let's keep going it's the same thing as here we're unlocking a four pole here i mean it's just a four a four variable two four a fourth ball i can't even say that of course we're unpacking these four variables out of this array same thing we're packing these two values out of this array okay okay okay and this ray is a frame which is itself an array it's an image and then this is a boolean yes or no yo kaz is in the house yo what's up all right keep going what's up quasi all right so next what you want to do is of course i'll just type this one out what you want to do is you only want to handle this frame if it was successful so you want to make sure you're checking so here we'll call this safe coding use protection you guys [Laughter] save coding uh was successful i mean i there's a little optional live stream it's like is this video made for kids i was like uh no i turned that i turned that option on hard so if there's any kids here you're not supposed to be here okay you're supposed to um this guy you can still look at it so you can still learn it's fine but but yeah so here if if read is successful yeah then you want to operate on this frame okay so i'm just going to copy paste the rest because okay so um so if the read was successful okay only then do you want to continue so then at that point we'll get the frame which is here and then we'll convert the grayscale okay because if you um if you if the frame didn't read correctly okay if this returns false because the frame is broken you can't actually call this on this next step is this needs to be a valid frame for it to be converted to grayscale so if this is an invalid frame because the read like screwed up then you just want to skip this and just break out the loop okay all right just when would it ever be a non invalid frame last on when the last frame of a video it'll automatically end video by itself automatically okay okay if you air out or if you manually say hey stop this video yeah but wait guys we're really late guys we're completely kidding about the kids thing if you're a kid it's okay to say a lot of you guys like oh my kid i'm a kid and i'm a kid i'm a kid i'm a kid you know i'm like guys it's okay we're completely joking about this stuff guys i mean it's it's already forgotten at this point yeah yeah yeah welcome kids welcome to woody wonka's chocolate factory oh god all right that's that's let's keep it let's continue um oh man hi mom so where are we at yes it's gonna break out so once we have the grayscale grayscaled frame here the same idea of an image and black and white we can actually change this to black i'll just keep it grayscale that's the proper term instead of black and white then we have a grayscaled frame from here okay okay and why don't we just um display that so okay let's see it actually um let's comment all of this out because it's gonna it's gonna break something okay okay okay and and let's just this is not going to do anything because it's not displaying anything so we do need the display code again okay remember the display code want to display the current frame in this case it'll be scaled frame instead of image okay instead of image it'll be grayscaled frame and it'll only get here if the frame was successful remember that you guys because else we break out of this while loop and then we don't even get to this code so it avoids the errors i'll ask you a question let me ask you a question we have logan actually asked a question would it be better to or to would it be better to only what would it be better to only use every other frame for speed yeah yeah you could do that of course you would have a little bit lowered um quality you could even lower the resolution of each frame to go even faster because just because the resolution of an image is halved like if this was kind of blurry you as a human could still tell this is a car if it was super blurry you could probably still tell it's kind of like a car you could kind of make it out you're like okay this is a highway and a car so there's many things you can do to speed it up you can down scale it um actually i'll touch on quick if you go to detect multiscale that's the scale factor actually be like okay blur this image little bit to make it faster you can like increase factor oh interesting okay that's yeah that was good i think that was a good question yeah like if you have 4k footage it's gonna be kind of like really hard to run all the algorithms but if you scale it down to like scale 4k down to like 360 pixels 360p or 480p it'll be a lot faster and it might still work so you can that's probably and that's probably what tesla does as well right because they probably scale down the image so that they can process it much faster right because you can't pass like 4k yeah yeah there's some tradeoff between having accuracy with high resolution images and also speed because when you're driving a real car you need to have real like realtime feedback so they go as high as as high as the accuracy can be while keeping it real time because speed is speed and accuracy are both important it's like oh this car is going to hit me and then two hours later you don't turn you know you're still getting there yeah yeah you got it like too late yeah just like this playing like this guy crashing before remember like like tesla here it sees this and as soon as he comes over he's instantly it's quick it's quick it's really cool yeah it's like instantaneous so there's a tradeoff of accuracy and speed there yeah yeah okay cool sweet all right moving on so uh from here we're gonna display the gray scaled frame and then of course you need to have um this because this will just display for a split second then disappear so we want it to stay on the frame the current frame and this actually tells us stay on the frame for one second or one millisecond or something like that okay okay and then and then it'll loop up and show the second frame it'll read the frame it will if it's successful it'll turn it gray and then it'll display it the gray the gray skilled frame and then it'll wait a second one millisecond and repeat and it'll do this for every single one so this is basically not you're not creating a video no no i'm creating a video okay you are so this is going to be a black and white version of that same video god okay okay okay okay i get it i get it okay okay okay okay uhhuh is right no i don't know what blue is is it red all i have to right every joke bro like it turns unfunny when you say it anyways hey hey look at that oh this is like it's like sped up why is it so sped up he cut because we changed the gray scale so it can compute it faster oh see okay okay okay okay interesting so it's going faster and this is the whole video the video is going and then when the video ends it automatically closes guys do you understand like in trouble cosplay do you understand how this even like displaying that specific video right because like i mean look like drop in the comments below if you understand like the way this is working right the way i understand it personally the way i understand it personally is literally right if we have the way i see it is like yes we have a video right we have a video right here what we literally do after that point is we literally we unpack the video and we go through frame by frame and then we output that frame again to create yet another basically video it's just at this time we added the video simply because we changed it to grayscale so every single frame as you guys know every video right is created it's created with frames right what we do is literally take that frame we convert it to grayscale and then we show it again and again you went from video to another video except this time it is grayscale so i just thought it was really interesting if you know what i'm talking about like drop in the comments below because that's just that's mindblowing to me you know yeah what he said yeah what i said [Laughter] all right guys so we have the gray skilled images here in a loop and it's properly looping through every frame of the video now all we need to do is run the detection code again and then from there once we have the detection code we can draw the rectangles again on the colored image and then display the colored image the colored frame instead of the grayscale frame and interesting that pretty much does it and then at that point that we also want to introduce pedestrians and use different kinds of videos with both and mix them together but that's the last step so yeah yeah let's go with that next so the next thing is once we have our grayscaled frame we want to run the car classifier on it remember we have our um oh i don't even have it it's uh i deleted it didn't i what cart tracker so let's get this back okay so let's get our car classifier back and paste it up here once we have the classifier file then you want to feed that into cascade classifier and we have a car tracker now so this is the pretrained data that we downloaded from this file okay now with this car tracker we can do the same thing we can just go down here and copy paste the code because laziness and detect cars especially i mean yo copy and paste as much as you can because what's the point of typing it out like you want to show bigger and bigger problems sure at the same time this is literally cutting the stream length in half and we could fill it up with jokes yeah yeah okay okay okay so now we want to detect all the cars in this current frame so again um we have our car tracker up here auto highlights for us and then again we want to detect all of our cars regardless of the scale of the of the um car match and then what we're feeding in is the grayscaled frame okay because this is the current frame in black and white and black and white is much faster okay okay okay and if any and if you just just so you know guys like when we say frame a frame is simply hold on motion a frame is simply just a still image it's just a image from the video right that's why it's able to detect the car so it's not actually moving it's just one image right that's the interesting part about it right we took that image out so yeah let's let's get on and that's how we were able to detect right multiple detect those cars in there hell yeah what he said yeah what i said what he said [Laughter] hey no no no not hitting me let's take it outside okay we'll take it outside next time after this corona things done i'm back in l.a kidding me man man guys man but this can be a live stream okay i'll cough on you bro that's not gonna do anything to me yeah you can cough at your own pace coffee your own plows you know don't don't cough here don't cough in that way this is the stupidest stream ever but whatever um we paid like two dollars right like people have donated to us i know we made two euros we can go get coffee you can get the dollar coffee from mcdonald's hey let's go let's go anyway so yeah we have the cars here and again remember this is an array of a bunch of different coordinates of the cars so why don't we actually print out um print that out so let's print out cars and each time for each frame you're gonna see a bunch of different stuff print out because every frame there's multiple cars so you're gonna see a bunch of stuff printed on the terminal forever because it's a it's a loop so let's actually run this okay and as you can see wow we have a lot of cars detected in each frame we just haven't drawn them on the video yet you can see them all getting spit out here you know top left point bottom right point the width and the height that's insane the width and the height is always the same that's insane by default and then you get and you can see some of them and you can see some of them don't even have a car yeah some of the yeah they don't have cars correctly but there is no car in that frame and it just skips it and then once it gets to the end um this when there's no frames left this actually becomes false because it can't read anymore so this actually does air out so it actually does get to this break statement on the last frame of the video and that's what you're seeing gotcha screen happens okay and then and then it gets to the code completed remember got it that's why it's good to have this because you can see got it there dope so now last step is just drawing the rectangles on the colored image just the same as with the image okay so pretty simple uh we don't need print cards anymore and of course on the copper paste master of course um yeah this one right i think so rectangles there we go so uh pretty much this should work now only only error is that this image is not an image it should be actually uh frame should not be image because we're not doing images anymore we're doing frames so we just pop frame in there so it'll iterate over every single car it finds in each frame and then it'll just draw a rectangle around that car on that current frame again with a red color and a two thickness got it got it so let's just run this and see what happens let's run this baby guys ready are you guys ready for this you guys ready all right let's see what happens actually on okay oh dang uh it is not working and oh no oh man oh no oh no bueno this is not good no good it's not good no good no reason is we are still displaying the grayscale image we actually display the frame because we drew the rectangle on the frame so okay okay little bug there actually did you guys see that did you guys get that did you guys get that i hope you did yeah because it was black and like when i ran it i'll run it again okay it was oh okay so now it's working oh hold on hold on you guys are you guys ready you guys ready you're ready for this you ready for this it's black and white no come on because when i ran it yep still black and white okay because it says grayscaled frame here but if we're explaining the colored frame which has the squares drawn on it then i can save this and display the frame so let's go um back here this is normal frames right now clear again okay now now we're displaying the colored image with the rectangles drawn on each frame over and over and over again okay within the while loop because you want to make sure all right you ready ready hey let's go oh but i mean hey it's not random you can tell that it's more correct than it is incorrect like it's not just random words all over the image it's fairly it's pretty damn accurate like we think about it this is like amazing accuracy that's not nearly good enough for like real world scenarios and cars but you're we're 80 there bro that is insane this is some magic guys seriously like this is some magical stuff like how how pumped are you to see this or to even build something like this especially the fact that we just built this like guys we literally just built this in like what and how many and what i mean an hour an hour and a half and two or maybe holy i mean holy bro chill out guys i only okay i only have i only have one gift to show to show how i think we we feel like right now are you ready ready to see this i'm sorry aaron you don't see this but they will see this so only one only one way only this way oh yeah peace out peace out guys this is how we do it all right let me check this drop in the comments guys for some you'll see it it's there's gonna be a small delay but that's all right who is that there's some random random logan's like this is awesome valley this is epic we got logan wow i mean we haven't even gone to pedestrians yet how do we how do we detect pedestrians and cars in the city oh wait so we haven't got the pedestrians yet no not real we haven't even touched that yet we still got to download that classifier and get that running you have to scan across every frame from both of them so that we can detect pedestrians and cars okay and then you can also you could train them for anything like you could train to detect nas you know um in videos and stuff if you want to that's important detecting who would want to do that everybody okay guys but uh what i'm gonna do is i also want to show you some other videos so i actually have a bunch here okay let's see um i have a couple other videos that i pulled out from youtube this is all from the same video linked in the description there's like okay it's like within the first three or four all three of these clips are in that video i skipped some of them because it was like dark and rainy and it wasn't performing that well but i mean this is pretty good performance for stuff you downloaded off the internet of course if you trained your own hardcast classifier extensively and you let it run for like three weeks and you traded it then that have really really really good results but these are just ones i just downloaded off the internet like like i said like the car data set this was created by people like caltech the california institute of technology um but these cars all look old so this must have been done in the freaking 80s you know so like this is old data um that we're using but they did use this to train their hard cascade but we could go out and take our own thousands of images but i mean i'm not going to do that sorry guys okay yeah yeah that's too much work that's too much work why we define the wheel but it's already defined for you you know yeah yeah and you know it's like use use a library because it exists but hey we got robert robin donated a hundred i don't know what might that i don't know what money that is a hundred you're not euro something i don't know how much money that is it's like robin yeah anyways 100 something thank you robin appreciate it what was his name robin robin yeah appreciate that rob yep appreciate that now um let's continue on so the next step would be um oh yeah i was going to show the other videos so let's just change up this video so this one this one is actually one where um the tesla selfdriving car actually can detected and avoided a tumbleweed so it was a huge thing on the road and it actually avoids it so let's run this footage so this happens here okay it's running in color and then boom tumbleweed where and it just dodged it bro you missed it i missed it oh man oh there it is there it is oh dang so that is insane yeah in an actual video the guy's talking and then somebody behind him actually hits it so i don't know but hopefully they're okay but it's just a tumbleweed it'll damage your car but unless they swerve they might cause an accident but if they just hit it it should be fine i hope and uh yep so that's that's another video from that clip and then here's another one i just pulled this off like randomly off the internet i just did tesla dash cam footage and i just found this video and then here this last one um is some highway footage also from that same clip so feel free to go watch that same clip that's damn guys how cool is that like how cool is that the fact that we just created a system that you know i mean i would say tesla like i mean i would say it's not perfect right but but the gist of it and that now you understand kind of how it works i want to point that out see how this is constantly saying it's a car because think about that there's the dark window the light bumper the dark shadow so it keeps mistaking this for a car because it has that same profile remember the heart feature of light and dark dark and light and then light and dark remember yeah from here so this matches these things this thing kind of looks like this because there's a dark window a light bumper and a dark shadow underneath the car see dark window light bumper and a shadow underneath the car so that's why it is it's miss miss classifying this so false that's why it's not a perfect system right it needs a lot more classification basically for this yeah i mean if you ran it super extensively you could you could detect every single car in the single image perfectly but it would take forever to run it wouldn't be running that fast that makes sense that makes sense uhhuh okay and so that's it so these these clips are in the description um you're gonna have to download the youtube video yourself and then trim it trim out the the clips but you can definitely do that and then just name it whatever you want it's an mp4 file so make sure you download the video got it got it got it that's really it so i had those three um examples okay and one thing i did forget the show is uh nah that's okay it's too late i already showed the image thing yeah uh with the with that video so what should we do now so what what's the next step aaron well why don't we detect this the thing i started off with the demo where there's cars and pedestrians okay both in the same video i don't know if you guys can hear that but okay but yeah this is the the original footage i showed so now we want to actually introduce pedestrians as well all right let's do it bro we got cars next thing is pedestrians then we got cats and dogs no okay we're just going to do pedestrians i think yeah pedestrians so yeah who's probably going to do cats and dogs next time but i mean i think selfdriving cars is cooler yeah yeah maybe next time maybe next time but yeah if you're pumped to see that let's get into it actually drop in the comments below too drop in the comments below yeah so what we're going to want to do is we are going to want to actually download another um classifier okay okay so we have a card classifier and that's what's doing all the work for our car classifier but we're also going to want a classifier for pedestrians and have both of them running okay okay so how we do that is we're just simply going to download another pedestrian classifier so again the link is in the description this one is actually supplied to us from opencv by default there's a hard cascade file xml file again called power cascade full body right here on my desktop open this up so it's the same exact thing again it has the all these crazy numbers and it goes on for thousands and thousands of har features um and it filters through all of it but this series of heart features kind of matches up with what a pedestrian would look like whether they're standing or walking or running or whatever or even like on a scooter they would still they would still be able to detect it yeah yeah so a bunch you can see it goes on forever and it takes forever to train this and actually generate these correct numbers just capturing the relationship in the patterns evil aval aval aval is like wow this is amazing wow oh robin robin just donated another 200 i think it's called v v dollars i don't know what it's called but another 200 dang i don't know what the videls are but it sounds like thank you robin appreciate it oh wait well actually he actually asked a question he asked the question actually his question was and i can't i can't put up on the screen because i don't have a for example for some reason actually show up on ecam but his question was if a different ide is used while speed and accuracy get impacted and output a different ide yeah no no reason being is this ide is just a code editor it just makes the color it makes the colors nice it makes strings orange it makes comments in green it does all that nice stuff but when you're running code from the terminal it's literally just getting this raw text file this raw python file which is just a text file that has python code in it and then it runs that python code so like i could even open up this python code i could open it in text edit okay got it like this is the code for running in vs code so it doesn't matter what you're using to edit it it's just running this raw text code it's just translating this to ones and zeros the computer understands so actually what's running all that stuff is literally just this text file this text file is generating all of this this tracking so it's reading the file name getting all the stuff it's making the classifier i mean you know i can't see but like yeah so to answer so to answer your question quickly no will not biscuit would not matter it will not impact any processing or anything like that at all zero yeah yeah yeah zero sweet and um yeah so let's just move on to pedestrians okay yeah so let's just move on to pedestrians okay so i have a video here a dash cam of dashcam pedestrians which is this video of a lot of pedestrians here there's not so many cars because i want to show this first okay okay okay and what we're gonna have to do is we're gonna have to actually get the um pedestrian classifier as well so actually let's just grab this okay and paste this here okay so classifier file is car detector really this should be called car tracker so actually let's change that so it's only popping up here and here but let's change this to car tracker all right okay okay to car tracker so now it's a little bit clear that this is a car tracker and um well actually what we have two different trackers right one is a car tracker and then wait so yeah yeah i uh screwed it up a little bit so we should actually no no this is car tracker down here so this should be car tracker file oops and this should be car tracker file okay okay so ignore this stuff let me just delete it because it might be confusing so let me ignore that for now so what i did was i changed this name to car tracker file to be a little bit more descriptive with the name and then again we're just popping this car tracker file into here to get the class k classifier which create gives us our car tracker now let's repeat these two lines of code but for pedestrians okay so for us it's going to be pedestrian file tracker no pedestrian tracker file equals this okay so it's the same thing as this line but here for pedestrians okay we have a different xml file for cars a different xml file for for pedestrians and let me just comment this again and actually i think it'll be better to keep these together so our our pretrained cats our pretrained car and pedestrian classifiers with an s okay so we have both of them here and now we can have our pedestrian tracker so this would actually be this is where we actually well actually i don't even have to do it i can just copy and paste this here the cascade classifier okay so pedestrian track is going to be this i'll just type it out this time so cv2 and cascade classifier and it autocompletes for me and then from here then you want to get the pedestrian tracker file and paste that in here so that should make sense we did it once for car car file car tracker now we have pedestrian file and pedestrian tracker all right so we have both now that we have both all we want to do is detect both and every frame and draw rectangles around both in every frame very straightforward so the thing we're going to want to do is um of course for every every frame we want to run the loop we want to read the frame that doesn't change but um and then we create it we change it to grayscale okay that doesn't change either once we have the grayscale image then we want to detect cars and pedestrians okay see that we're only detecting cars right now but we want to detect cars and pedestrians so that would be something like this okay pedestrians equals pedestrian tracker okay pedestrian tracker dot again detect multiscale because you want to detect pedestrians of all scales in all sizes and we're just going to in the grayscale frame so this is just exactly the same code as for cars we're just using a different classifier okay which means it's going to give us different coordinates different squares of different um of different um what you'll for like pedestrians and stuff like that oh yeah i get i get it yeah yeah so this is a bunch a list of cars and this is listed pedestrians that's all it is okay yeah okay um so if you so if you guys if you guys yeah so if you guys don't know it's basically yeah we got pedestrians so we're attacking different pedestrians we're using one classifier for pedestrians right and then we're using another cluster for a classifier for cars right and that's that again is detect that is detected through where through here well i don't think if you can draw but yeah you can see one for car tracker and another one for pedestrian tracker so that is really cool okay all right let's keep going let's keep going yeah and once we have these then we can just repeat the same exact process with the rectangles for drawing the pedestrians that we do for drawing the cars so it's literally the same exact thing i'm just going to draw the pedestrians in yellow instead of red okay and that's really it okay that's it that's it yeah oh man all right so all right okay pasted it the only difference is um for cars you want to iterate through all the cars again for those points then you want to draw on the current frame the current color frame top left point top bottom right of the top left point the bottom right point and make it red with thickness of two now for the pedestrians we want to again we can just reuse the same variables of x y w and h because at this point we're done with them so we can just overwrite them x y w h and pedestrians so again this is a list its own list of pedestrians then we want to draw a rectangle again on the colored frame top left point bottom right point this time we want to do yellow so this is the color for yellow so if um the green and the red are maxed out it becomes yellow i don't know and again guys it's not it's not so much about like you know red green like we simply just picked those colors because you know because why not you just pick the random colors right but you can pick any color you want right that's those zeros yeah this would be completely white so everything you can pretty much you can pretty much change it to anything you want yeah unimportant detail i mean to be honest in on tesla when they're doing selfdriving cars they don't even bother drawing the rectangles around the car because from this point they just know where the car is and the car doesn't need to see it i mean the car already does see the other cars or the pedestrians with this data it doesn't actually need to draw a rectangle no the rectangles are just for humans so yeah on this okay look look look in life logan in the live stream man logan logan appreciate your freaking energy bro logan says like i love this live stream this is so much helpful much nicer way to expose myself to opencv with this then arena communication you know yeah oh yeah yeah apple apple is like aaron you're crushing it buddy keep it up bro you're crushing it bro what watch our video and our jokes yeah let's just let's just read this through the live stream you know that's all we do that's all we do let's read the commentation classifier colon colon detect multiscale detects objects of different sizes of the input image the detected objects are returned as a list of rectangles i mean this is exactly what we're saying right it's just it sounds very nerdy you detect objects in our case cars and pedestrians of different sizes because it's multiscale okay the input images are framed yeah yeah the detected objects are returned as a list of rectangle points and then we just draw them so that's it all right let's do let's see man i'm like so excited let's go guys we're gonna see a bunch of pedestrians because the video we're using okay there's there's a bunch of pedestrians but not very many cars like i think there's like one car here but all these pedestrians will all get um get identified okay so let's just go for it right wait did i delete something ready ready where'd you delete oh i deleted the whole loop oops i was no no i didn't i deleted a bunch of the code i just typed out and then i didn't even run it yet but i caught myself okay okay okay all right let's just do this nastiness all right let's run the python file so car and pedestrian tracking dot pod and boom oh see it's oh deep down taking the pedestrians guys holy moly hey guys this is a wow okay okay holy wait so wait okay this is just pedestrians right now you guys ready check this out how cool is that how cool is that guys drop that in the comment below that is sweet oh man that is amazing all right so wow is that it that is that that's pretty much it what i want to do is i want to add a little bit of flavor to something and then add a couple other um safe keeping things that we're going to go over all right and then add a little bit of style and then and then run it on some new videos and then that'll conclude it pretty much pretty consistent that's that's my face right there guys that that that is that this right here is probably your face right now i'm kidding i'm not kidding like like make that face right now and as you're watching the video make that face right now you know the face i'm talking about oh it's cloudy with a chance of meatballs is that is that okay yeah exactly um bro didn't you grow up when that came out you were like 12 when it came out hey this is still an awesome movie bro yeah who doesn't watch that come on come on man incredibles is better come on man what people are like this is guys what i want to do is um i don't know about you guys but in the thumbnail of this live stream i had like a little quirky styling thing where for the cars it was red and blue and then for pedestrians it was just yellow so i just want to chuck that in so all i did was i'm just drawing two rectangles here instead uh just you know for a little bit of flavor and just pop that in so i actually for each car i actually draw two rectangles one red rectangle and one blue rectangle so this is the reference what's the reason for that i'm just curious just because you want to be fancy yeah i just want to be fancy real quick okay fine i mean so all i did was i just drew a red background here with the red channel max everything else closed and the blue channel here 255 enclosed but i offset it by one and two pixels a little bit so you can see it changing you know this is like this is completely useless code it's just for a little bit of you know frontend development but when you run it you can see i mean there's not that many cars here but you can see whenever a car pops up there's a little bit of blue as well as oh man a little bit of flavor put that image in the center put the video in the center oh never mind just keep going never mind just keep going you're fine you're fine like that guys how cool is that how cool is that to go like okay that that that makes me excited bro honestly all right all right i don't know let's calm down i love this ai stuff i used to i actually guys actually interesting enough i i used to do ai stuff as well for a company but we did we did a yeah so interestingly enough i'll just tell you a really quick story i i did ai for i did ai for um for actually detecting signatures detecting fake signatures so we use the similar we also used alpinstv as well and we detected if signatures were fake or they were real and we had i'm not kidding we had signatures from like thousands and thousands of like images and we will be able to detect like if the images was like real or not by the way i don't really know robin robin seriously holy moly thanks again donated 400 400 v v something v dollars i don't even know i don't know robin you're the best thank you appreciate it what was appreciating donations you know oh man yeah yeah right but anyways fire yeah that was a fight he's like robin's like yo let's go we just hit the goal [Laughter] all right we're almost done you guys just a couple more things and we can run on some extra videos and then we can just let it run and yeah that'll complete the app you guys yeah so uh last things i want to do are actually um when you're running the the video i want to be able to actually quit the the window um with the key so guys there's a robin donated right there i appreciate it bro right there you guys can see it yeah there we go hey all right let's continue on by the way i don't see you do i see you no i don't see you oh there we go there now i see you there you are now there you go am i good no you're good you're good keep going keep going okay got it yeah so here on the code i'm just gonna copy and paste in a little um housekeeping here so if the q key is pressed q for quit then i want to break out of this loop which means it'll abort the video stream like whenever you type that key so the key for a lowercase q and uppercase q are 81 and 113. you can learn look that up online every letter and every keyboard button has its own number and you can just find it with a google search you just be like lowercase q and uppercase q what are the numbers you just put that in and um once you have these numbers then if either of those are pressed if key equals um that or that then it will just break out and we'll just stop okay and the key is automatically whatever you press from wait key because it's waiting for a key you see what i mean and so if it's waiting for a key and you press q automatically it goes to the next one and then key becomes q and it'll it'll match and that's really it cool okay last thing is you want to release the video capture so wait what is the release why release what so um video here our video is the video capture object that we got from our video file all right and it's it's constantly reading a file okay and so video is constantly reading a file so when we're done doing it we just want to release reading of the file so it's just like it's like it's like okay stream of data coming in so it's like you stop basically stop bringing the file you're good that's what it's saying yeah okay it says we're done reading this file just release all resources from trying to read this file so we're done okay that's really it's just a clean up like a memory management thing yeah and that's really it you guys um guys i don't think that's pretty much it i haven't planned that change all right so let's see driving car all right i'm excited to see some videos bro let's do it yeah let's go here and let's run it again oh your name is ready it's not you guys hey guys oh there's an error here it says key is not defined because you guys know what the key is you guys know what the problem is drop in the comment below you guys huh i think i know i know it is do you know aaron yep of course i do not are you sure you do i'm not sure i'm not sure about that so yeah the problem is that this key variable doesn't actually exist and the problem for that the reason for that is we didn't actually set that equal to here so this does wait for a key to be pressed but it never captures that so we gotta capture it in key and now when key is pressed then it should work okay back here let's just clear this out so it's nice and clean run it again and there we go so it's going hey okay if i press the q key it should quit quit sweet okay cool cool cool all right damn guys this is crazy guys this is amazing holy like we just created a system that detects pedestrians and cars within you know an hour two hours with some training data that's it that we didn't create we just bought it we did we you borrowed download all this off the internet like you can download xml files for anything you can probably download xml file for a cat for a dog for a water bottle for a football or anything you can download somebody else probably somewhere on the planet has trained a hard cascade file for you somewhere and uploaded it somewhere you could probably download it and you could probably use it and do a very similar thing depending on how well they trained it and of course you can train your own too if you want to go that route i'm sure it that exists on google how to do that but that's a much longer process you have to find all your own data yeah cool cool your own images wait wait guys so let's let's give you some more videos what has we got yeah so we have a couple more all right um so that was just that was that was like a pedestrian heavy let's run it again this was a very pedestrian heavy video okay lots of pedestrians so what do you guys see what do you guys see you guys see just a lot of pedestrians walking right and it's able to detect those systems and if you think about it right what would a system do you can now since you cannot detect something you basically can now tell a system hey you know if you detected it stop to stop the car or hey you know stop anything you want so that's kind of why this stuff works really well you know what i mean yup so let's just do this okay so another another video file i have is dash cam cars and pedestrians because it has a little bit more mix of both this is actually the video file that i um showed you at the beginning okay so how long is this video all right okay that's a different video it's like four minutes long all right um so let's go and let's just let it run so this is the video i showed you at the beginning oh man that's cool damn guys give us some fire in the comments guys that is cool all right look at this guy's walking what is that you see how it's able to detect that like little pothole at the bottom i thought that was interesting yeah it's not perfect but yeah of course it's better than nothing better than random much better than random and there we go you guys if you can see it looks a little bit slower because it's doing double compute power yeah yeah you see so you can think about it for tesla like a real selfdriving car think about it it has to detect pedestrians it has to detect cars it has to detect signs all different kinds of signs speed limits stop signs has to detect traffic lights have to detect different night time and daytime things have to detect rainy conditions and nonraining conditions it has to actually send those values to the car to break or turn accordingly there's so much going on so this is just scraping the surface this is pretty cool but this is just the very very surface of what actually of what's actually going on i mean in general honestly in general it's like it's it's crazy right because the amount of data that it has to process right in terms of pixels right in terms of in terms of how fast it has to do it as well it's insane but you can see what's real like i think guys what's really interesting and how long i'm actually not let's let's keep watching the video as you guys can see right the really interesting part is like the fact that the relationship part is like all we simply did is if we divide a problem right into different little into certain little parts right into into small little parts right which is how do we divide this up like drop in the comments below how do we divide up this huge problem which is we wanted to detect right we want to detect like um you know pedestrians and cars in the video how do we divide that well first is we found a lot of training data that's part one right two right we basically we first did training we trained uh we first did testing on the pictures individual individual pictures right individual pictures and then what happened is once we got the pictures right we were able to bring in a video we were able to take certain pictures right every single frame from that video and the next thing you know we're able to display it back to the user so but if i'm dividing this up into three or four different parts you're literally just able are able to solve this humongous issue not an issue but this this crazy epic you know thing in an hour or two do you guys see that yeah just drop that in the comment below if you agree with me like seriously because that is to me is insane you know a lot of people think that this is this is crazy stuff but you know honestly you just you know just some work and you're good am i right yeah man look at it go well there i think it's slow motion yeah yeah i mean it's detecting that sign wrong but it's getting the girl is getting some of the cars in the back yeah yeah right there right there screens a little bit yeah yeah and there's ways to optimize this you can be like okay if there's like two if there's two um rectangles in the general same area twice in a row you can kind of be like okay there's a higher chance this actually is a pedestrian it's not just a random thing a random detection so hold on i want to ask you a question so somebody asked a question actually george asked the question how can i get this source code uh if i can take a look at it please so i can take a look at it uh i'll post it in the in the description i'll like upload it to like a riplet or something or i t and then you can download the code if you didn't type it out yourself with us yeah granted it won't work in riplet like you're gonna have to download opencv the opencv package within riplet itself and run it there but you can just i'm just gonna post it there for like code reasons and you can just copy paste it to your own visual studio code yeah wait but can we just put host on github or no we could do that too yeah right that's it yeah either or github's probably the proper way to do it but yeah riplet fanboy so yeah we'll post it to github how is that that's the proper way to do it post the game you can download the code from there exactly exactly exactly so guys how sick was this how sick was that to create such an insane python tutorial such as saying python program aaron i think it's pretty dope i'm just like admiring the the work that other people admire your work okay don't get too cocky bro don't get too cocky on this you know it's just like you know i said i'm admiring the work that other people have done bro that's the option okay okay okay i thought i said admiring my work you know open your ears i mean what i wrote like 20 lines of code it's pretty badass but i mean you know yeah yeah i didn't do all the training the training that's the hardest part yeah yeah but that that to me is insane so yeah but awesome job guys guys give aaron a give aaron a round of applause in the comments right he worked on this all of us give all yourselves you know i was partially involved in the code i was just like you know okay good look at this wow holy crap he's getting these pedestrians super accurately it's like stop stop stop stop you know pedestrians in front yeah yeah yeah and then the bigger the bigger the rectangle the closer it is you know you can do stuff like that like if there's a big rectangle you can tell that the thing is close to you yeah yeah look at that that's insane that's cool that is so cool okay this one's not working at all this one's terrible it's like i think it's just too many people man probably yeah there's too much information confused with crowds and stuff yeah yeah if you had just people walking like on a white sand beach just a single person walking it would track it almost perfectly but just because there's so much noise and stuff it's not quite perfect yeah yeah but dude this this motorcycle driver is like freaking he's trying to run people over you know yeah people are like how are you going his name is royal jordanian so maybe yeah yeah i mean i never i found him this morning because i needed this video but he has like two million subs it's ridiculous oh wow for riding his motorcycle he just rides his motorcycle and he records it is that it i guess so i mean he probably talks about his motorcycle and stuff too i don't i didn't really look at his channel even evil evil is like evil i'm not i don't know how to say that evil was like aaron do a project with me whoa look at this truck i got that truck hard did you hear me did you hear me evan yo it's getting it's getting the the cars in the advertisement it's funny where all the up top yeah are those even cars oh they're not even cars i don't know their cars yeah i mean guys obviously it's not perfect right this is not perfect yeah but still it's insane it's more right than it is wrong yeah yeah yeah that's that's a monumental task yeah hey guys let me ask you a question like what else let me see a question what else would you like us to see like what else would you like us to do in terms of you know ai or face detection anything that you want us to do like let us know in the co drop it in the comments below right because we read your comments right so we have great ideas for you know what to come next before we have great ideas of what you guys want from us right we read those comments i am not kidding so if you got any suggestions right if you got any suggestions on what to do yeah just drop in the comments below we'll take a look at it and then aaron is just going to take a crack at it you know and then create something amazing right there am i amazing bro i mean you know just whip it up yes i'm amazing like onefourth amazing onefourth amazing yep and boom cool projects any cool ideas you guys have for projects going forward related to python and and any kind of artificial intelligence then drop it in the comments too then you can consider it maybe we'll make something maybe we'll use opencv again maybe we'll use something else or else something else something somebody said so we have idol said idol said i don't know ido said to detect numbers okay we could do that actually detecting numbers like you want to yeah you could detect you could yeah you could detect numbers on a page like if you had a piece of paper okay you had opencv you could you could technically um scan that and then find out like all of the places where there's words like that's actually how pdfs are able to like scan the numbers and letters in it and like auto populate all the numbers in the numbers and letters is through scan it doesn't use i don't think it uses hard cascades it uses something different but um yeah same principle you can detect different letters and shapes on a piece of paper same exact principle gotcha gotcha what about somebody said something you said sprush sparsh sparsh asked uh age detection i'm not sure if we can do that that that's a little bit harder yeah i mean in theory it's possible like if you had if you had like facial recognition you know how facebook can can recognize your face and be like oh this is quasi this is nas this is area tag your friend automatically if it can recognize an actual independent face it can easily recognize old versus young um so yeah you could but you would take more training and you would need you would need a lot of picture of old people and a lot of picture uh pictures of a lot of young people and to distinguish between those yeah that's true but i think it's like when you get to like you know when you're 20s or 30s it's really hard to get the exact age like if it can get an exact age it could be like it could be like old middleaged child infant you could just split it into four groups you know infant yeah kid middleaged adult and elder senior citizen you could have like those four that's close that's true so guys if you want us to do like an age detection system that would be actually interesting and then we could age attacked air and they'll probably say like 50 you know or something yeah the thing with that is i don't know if that exists on the internet we have to train our own hard cascades and there's other algorithms hardcast i'm sure there is the algorithm used for this um but maybe we had someone say hold on it's itzhak said face expression detection oh like smile sad like mad you know be like no i'm mad i'm like your smile you know yeah we could do a smile detection a smile that's interesting it's like smiling or not smiling because let's just keep it simple smiling versus not smiling faces it could say like smile on top yeah that's not a bad idea we can look into it some guys anything else would you want us to create a face expression system a smile detector a smile find a small detector system yeah because because that way if you guys don't smile you know we could i don't know we detect some points you know you like points for me i don't know i don't know how but we did we would detect points if you guys smile so yeah sweet i think that's pretty much it bro right we're good yeah that's it so again if you guys are interested in coding more and actually making a living from it if you're not currently doing that if you're uber driver or working at a retail or fast food place or something like that yup um we offer courses here at cleverprogrammer to help you learn how to do that so we teach you a bunch of different projects in python and how to actually monetize those skills so this is a 15week program um hosted by uh qazi and um our other python expert jacob yep and then um also there's a little bit of me in there we're gonna add in um some stuff in there at some point with me and we all teach python and how to actually use python to make a living from it so if you're interested in that then definitely give it a click in the description there's a free threepart master class and also um the actual course is there so you can check out both um if not then yeah just keep watching us on youtube and thanks for watching you guys yeah sweet guys and i just want to say guys is it you just want one one small thing guys if you're interested like i said with the profit with python you get amazing success coaches you get you know you get to learn how to make a live a killing with python right so it's not just about teaching you skills right but it's also teaching you about how to actually make money from that because that's the most important thing that you know you're going to get from a course right we get weekly training calls literally every single week you get a coaching call from a developer who knows his stuff right you have an amazing community who loves each other and you have an amazing facebook community at the same time so yeah if you're interested in you know becoming a python developer or learning python and just making a killing with python where do they go aaron they can go to the link in the description and check it out there profit with python profit guys on course yep and then there's also a free threepart master class it gives you a little bit more information about making money as a python developer you can check that out it's just about like the opportunity there is and stuff and there's some activities in there you can check it out and then you can join the course after if you want or something like that but exactly yep that option is there for those who are interested for those who are not um yeah come back for the small detector next yeah the small detector all right guys awesome guys this was amazing this was so much fun guys oh hold on something evil said my heart my evil says my heart is python my heart is played my heart is python yes what about javascript bro what about javascript that was cool too you guys you guys you guys are not you know not cool anyways but sweet awesome guys in that case i think we're done here hope you guys have a great day if you guys have well i don't know if you hope you guys have a great day and other than that we will see you in the next video right aaron yep next yeah probably probably tomorrow right yeah probably tomorrow schedule for tomorrow yeah i think so awesome guys stay tuned stay tuned and have a great day guys let's go so we are going to be building a realtime ai smile detection app in python i am sunny and today i am here with aaron what's up guys remember me i'm the python guy apparently super pumped guys super super pumped for today aaron what we building today uh all right can they see my screen right now uh coming through now yeah let me pause this like mute this all right guys so this is what we're building i got my little app here and i got a multi detection app let me go ahead and share the screen one sec all right let's go yup they can see you all right here's my face and when i smile it should be able to notify uh detect that i'm smiling and then it displays i mean it's bugging out a little bit right now so go ahead and throw a smile hey look at that there we go guys and what we do how are we getting that to work right now uh this is the code bro that's how stuff works what are we using that's pretty much so that's we're using ai right and we're using what what in particular to get that working uh opencv so we're gonna be using the open computer vision library um as usual if you guys are watching the other couple streams in similar but uh this one has some cool some cool optimizations in uh in the code so it's pretty short so it's pretty powerful library i mean what 50 lines of code with comments and spaces so yeah pretty bitesized but you can do some cool stuff with it awesome dude okay so let's go back to us guys there we go nice so let's go ahead and see where everyone's at nice we've already got 250 people in here that's dope hope you guys okay okay this is the first time guys me and aaron are going live together so this will be exciting yeah first time very first time exactly and also guys i'm not actually a python developer so many of you guys know me for react so this will be cool for me as well so i've never done machine learning with python so i'm excited for today um yeah let's go sonny let's do it so aaron let's go ahead and like let's just jump straight in i think yeah all right yeah let's get straight to the to the project okay so uh here's the stream uh all right got a little presentation here for you guys let's just start off to get a little bit of context um so smile detection with python all right uh first of all you just want to you know pay uh pay respects to the joker himself the the infinite smiler i mean he's always smiling but really not the legend heath ledger residents rest in peace bro but uh yeah guys just make sure you're spying a lot because it's important it's good for your mental health and people will probably like you more or just think you're freaking crazy so how are we gonna do this uh sunny smiles a lot i've noticed so you can be blessed with his super white teeth it's a british thing now you guys just misspelled words that's all it is it's the spilled word all right so how are we gonna do this so you guys guessed it it's all um all things go to machine learning okay all thanks go to machine learning so we're gonna be doing that we're not gonna be training anything but we're gonna be doing some pretty crafty stuff uh in the app with some pretrained models this time it gets a little bit fancy here and there but i'll explain how it's how it's happening so here's a quick code breakdown of our app i just kind of want to give like the overall idea of the code logic just so that people um have some context going before we start coding because i don't like when they just jump in they're like oh what are we doing but this kind of gives you a holistic view so uh so step one the very first thing we gotta do is uh find faces in our photo in our case it's gonna be a frame from the webcam that's what i'm gonna be using an app but here awesome the first thing you want to do is find yeah you want to find faces and that's using the har algorithm what is the heart algorithm yeah so i'm not actually going to be explaining the algorithm in this video but if you want to know how the algorithm actually works in depth you can watch the uh our face detection video for our car and pedestrian tracking video uh from a week or a couple weeks back and in those two videos i explained them in depth uh different explanations in both at the face detection it's at the end um and then the other video it's at the beginning but if you want to actually see how it works you can go watch those videos those are cool but this apps a little bit longer and more complicated so i'm just glossing over it okay awesome also i just want to say so so step one is find the faces so at this point we're literally just finding the face right so we're not actually finding that yeah no smiles yet so so you want to find just the face like that yep step one that step find the face very simple yep and then we also want to crop it out just so we're dealing with this okay okay uh step two we want to find smiles within those faces because i mean it's pretty rare you have a smile outside the face i mean maybe if you had like some dentures lying around or like a weird piece of art on the wall but i mean nine times out of ten a smile is always going to be within a face yeah okay again this is the heart algorithm so again if you want to see how it works it's uh it can it's just generic object detection but we can detect smiles on the faces okay so we just detect the smile there then then step three all we need to do is just put the rest of the image back get rid of that bounding box and give it a nice little label on the bottom because this makes more sense you know i mean you could have a box around the mouth i guess that's kind of cool but this is cooler because then you just kind of want to know if the face is smiling or not it just seems more more human so that was the design choice there for the app nice and that's really it guys so yeah i know it's you basically you found the face first and then what then we found the smile within that box right yep and then why did why do we do that instead of just doing the whole um you'll actually see uh once we get to there okay uh a lot of a lot of yeah a lot of ai stuff you kind of need to get clever with the optimizing and um layering different layers because if we did smile detection just every word the performance is actually really really terrible okay so i'll show you guys that i'll show you guys that uh once we're coding and then you'll see because it's actually pretty accurate like when i'm running the code yeah well here so i actually ran it here on the i mean here it's a little bit bad because it's blurry the lighting's bad but i just wanted to run it on this gif before to show you that it's kind of working like when he's smiling you can kind of see it picking it up a little bit here and there um but on the webcam is pretty accurate so yeah you'll see you'll see how ass though how ass the performance is if you run it on the whole thing but there's there's a little trick to make it like really really accurate so guys let's get to the code yeah so guys for this just all we ask is that before we get started just smash the thumbs up button what we got here what was that yeah i had the i have the other from the car and pedestrian tracking i just forgot to delete it anyways um yeah so let's get to the code okay uh real quick guys before we start though just got a donation dude from tushar near us he says character doing a shadow sign with his hand saying cool oh okay no he actually sent in something uh like we can't actually see it properly on the superchat guys but it's it's some guy waving cool so thank you for that cheers all right uh real quick sonny um you want to show them the stream about the the free training yeah real quick yes let's do it guys so we have a free python master class that i recommend everyone goes ahead and signs up to you uh i haven't actually got the link aaron uh i've got the i've got profit with one second let me go ahead and show this so guys let me go do you mind just slacking me the link for the where's it going yeah or i can do it you just share my screen and then i can go through it let's do it yeah yep there we go there we go can they see my screen i got you yeah what's up guys so uh so if you guys are interested in learning how to actually make a make a living from python then we have a free python training here that teaches you the three secrets of how to become a python freelancer so link is in description you can click down there to check it out or if you just want to jump straight to our python course and we also have a course which teaches you how to do that as well this is a paid course though so if you're interested in that there's also the link in description okay a lot of cool stuff in here free trainings uh private communities weekly live calls um with a couple instructors and yeah feel free to check it out but other than that let's just get to the code okay guys also guys just want to point out one thing with that said the something that i really want to point out that i think is always cool is that we actually offer weekly live training calls in that program so if you do want to go ahead and like and you get a bit bored of the sort of udemy courses that you see online then make sure you go and check it out but before any of that be sure to sign up to that free training guys because it's completely free so you have nothing to lose go ahead and check it out if you enjoy the video awesome all right let's do it dude all right man is the focus back on my screen the focus is back on your screen let's go guys okay so uh let's just jump right in all right so remember we're going to be finding faces first and then from there finding smiles and layering it over so this is the full app again opencv very powerful uh we can do some stuff in a pretty short app um so first thing is you're gonna need to download um a couple files these are in the in the description down below so just go to those web pages and download these two xml files to start out i'll explain this in a second and once you've done that uh you just need to make a python file so start with a small detector.pi yep um and actually i think i'll just i'll just code in here yeah let's do that it's always nice to see a bit of fresh code yeah oh yeah of course but i was gonna make a new file but and i'm not feeling it so we'll just pretend this is a new file okay so just make it make a new file in a new directory um we just got another donation as well we got vishal s dropped a 20 rupee super chat thank you very much dude and i dropped another one thank you guys good show thanks to sure thank you everyone appreciate that much appreciated man yeah all right so let's get started okay so first thing we're gonna need to do is install opencv if you don't already have that so i think that is through the command well let me quit out of this there we are hey get out of that um you're gonna need to install it from pip install open cv dash python okay i'm new to python so what is pip firstly like for for those that don't know uh uh python uh i forget what it stands for but it's it's a package oh package installer python or something okay so it's like it's a bit like npm then right yeah yeah so it just allows you to install um a bunch of libraries that are for python so there's pip there's anaconda um there's homebrew there's a there's a few you can use to download different things but we're just using pip it's the it's the simplest one in my opinion so yep just run pip and then this is a command install and then we're gonna be installing opencv dash python it might be python opencv just try both okay and the one that works works and if you're having issues with that then adding headless at the end um can sometimes fix stuff but yeah just do that or do google search if you really can't figure it out once you have opencv installed then um then we can start coding okay yep so um you can we can just import cb2 so that's the very first step it's just importing um opencvs this two is uh the second version there's the second version of cv2 i actually don't know why it's like that but cv2 is the library for opencv okay and let's just start with uh this just to make sure that our code is running correctly so opencv 2 yeah i mean import cv2 and then it's big enough right yeah yeah very good yeah and that's how we run our python script we write python with the file name dot pi and that's it right yep just make sure you're in the same directory so in my case i'm actually um in a folder but and then make sure you're in a folder here if you guys don't know how to do that then um i mean yeah i don't want to make this too much of a command line thing but cd is change directory yep yeah so actually let me just go back here so see i'm on the desktop here you probably well actually you'll probably be here when you open your terminal it might look different but you'll probably want above the desktop you're going to want to put cd and then just type in desktop to go to your desktop i'm in the desktop and then from there you're going to want a cd to open cv well this is the name of my folder it's opencv default uh smile detection and then from there and now i'm in this folder and then i can run this command okay because the file is located okay yeah i don't know so it's modified dot pi yep and if we run this it should just print what's up because that's all we have in here okay so it's working correctly um that also means this is working correctly it'll pop an error for you if you don't actually have it installed correctly but this one it just doesn't say anything if it says nothing you mean you got it installed correctly if it says something you gotta install it correctly go ahead all right so let's just move on okay let's do it uh let me pull some of these code from down here so first thing i said is we're gonna actually start with just the face section so let me copy the comments as well just so like we have a nice um nice app with comments and everything nice so face class all right so here this is a pretrained model for detecting faces like all the fancy machine learning stuff happens in here it's just a bunch of numbers that the image gets passed through and then it tells you face or not that's all it is you pop in an image to this and then it says yes or no and it gives you an answer again if you want to see how this is actually made the whole algorithm and step by step without everything that's happening inside the computer then you can go watch one of the other face detection or car and pedestrian tracking videos yeah i think it's worth saying well let's just start with just just like uh from my understanding all right like a classifier is something where we have like some kind of input right and then we have this model so in this case we have the har cascade frontal face so some kind of like model is is inside of that classifier and then so let me go ahead and i'm just dropping on the screen so we have some kind of model and then from that so we have some kind of input right then we have a model and then we have a sec and then we have some kind of output and what would that output say whether like a certain value which says if you're smiling or not right yeah literally just a one or a zero yeah okay it'll just say yeah one or yes or no but yeah but well technically it'll give you coordinates on your image of where the box is around the face in practice but i mean basically it just kind of says yes or no okay um kinda i mean it the implementation is different but the idea is it'll just say smile or not smile that's all it'll say right so we have some kind of input a classifier which is what we're using here which is a hard cascade and then some kind of output which is whether it's telling us if it's smiling or not or some kind of coordinate but that's that's how it roughly works guys so as aaron said you pretty much this is the line of code to go ahead and get that working nice yeah carry on yeah actually i guess i can explain a little tiny bit technically if you have a whole entire image or a frame from the video then it will look over every little box inside that and then it'll tell you if each boxes of different sizes if that's a face or not or if that's a smile or not no so that's what it's actually saying if it's a yes it sends you the coordinates within the whole image of the little box and then that's how we draw the little box because we have the coordinate and we can just draw a box at that coordinate so that's actually what's happening so it's the whole image and then you just go over the whole thing and then choose it like no no no no no no oh found a face that's a yes give me the coordinate and then no no no again so if there's multiple faces it'll find multiple faces as well awesome okay so it's not just one phase we can support mobile faces or nice surab yeah we just dropped a 100 rupee donation says thank you so much for sharing awesome thank you dude let's carry on thank you yeah here actually let's uh let's run the code really quick yep um i want to show it with two faces i didn't show with two oh nice yeah i should have shown it with you real quick i can just use my phone there we go well i mean hopefully it works it might bug out because one of them is an image yeah but we'll see oh nice that's dope dude this is smiling yeah and it's real time and it's quite performant like that's that's pretty like fast like it's as you move your phone around if you try and move it around fast yeah look at that that's just smooth nice okay and so there's some kind of loop i'm guessing this running or like some kind of thing that's gonna happen there yeah yeah we're just pulling out the let me clear this we're just pulling out the the webcam footage okay webcam it's the easiest way to get some realtime footage yeah i mean this could be a security camera could be a whatever um but in our case we're just gonna be using the webcam go ahead nice all right so let's do that next let's just pull up the webcam and show you how to get the webcam with opencv if you guys are watching the other streams you guys know how to do this you'd be very comfortable by now the third time we're doing it but let's just do this right there and this is the best way to do it because then there's no typos and i don't embarrass myself right sunny sure that happens a lot yeah but anyways so this is how you want to grab your webcam um we just call it webcam a variable you're gonna need to have a variable for that because this is how we access all the webcam stream footage uh but really it's just video capture so um you just call the opencv library dot video capture and if you put zero this is the webcam but you could actually also put like something like whatever dot mp4 okay you could also get video files and run it on there um like that joker like the joker one that i had yeah over here this is how i did that i just imported this file and then i ran it through and then i recorded it and put it back here but for us zero is webcam nice quick so with popup zero and let's just uh i think you'll see that m show okay no no no not m show uh what is it i always get confused between between uh footage and yeah it is m show okay i always get confused between um images so yeah show the current frame so let's just pop in a quick loop and just show the webcam live to the screen okay so and from here then it should be uh we should clean up i think it's destroy all windows yeah cv2 and and uh oh okay you have to release the webcam as well yes yeah i just clean i mean you technically don't have to but i mean it's just like good practice so this here is what's actually going to show so while true um we're just going to be uh showing the frame oh i forgot another line of code we're actually going to need um one more this is actually a big chunk side let me go line by line let me just get this last one here yep get it here it is read the current frame all right nice let me go line by line because this this kind of was a big chunk so what's happening here is after we get the webcam the webcam variable um uh how we how we get a frame is we actually uh actually let me just show this real quick so let me comment out all this just so that we can go step by step is a better way doing this on the fly guys yeah so here here we go look at this single line here ignore everything after that okay okay um we can okay we'll do this why the way i like to do it code completed so if this prints yeah it means if it prints then there is no errors because it's at the end but so this is how we actually read the webcam so you call dot read on the webcam and what this returns is a tuple so this is actually a two a two tuple so this is the first one first element this is the second element okay and oops what this is this is just the boolean of if it was a successful frame read or not and the second one is uh the actual frame so this is like an image that we can actually um run things on so let's actually just show that okay now i can grab the cv2.image show but right there and this is the name of the window so i just put why so serious but you can put smile detector if you want yeah okay and let's go back to the terminal oops what did i do there we go small detector yep and there's oh i forgot one more so after this you're gonna need to run cb2 dot weight key okay and what does this do okay let's what this does is so what happens is we get the webcam okay and then we call webcam.read which is just reading from the webcam stream and it'll get the first frame the very first frame of the webcam video yeah and then if it succeeded now but ignore this for now it'll get the first frame then from here it'll say cv2 dot image show uh image show means it'll show that image to the screen we're going to show frame what the and then the window name will have small detector like up here at the top of the window will be small detector nice the thing is this shows only for a split second as long as it needs to and then it quits out right what this does is it says let's wait for a key before we continue to the end of the program so it'll stay open till we press a key okay this basically means display right okay so this is so this means that without this line of code it pretty much hides it super quick so now we're saying wait until wait until you press a key on the keyboard to hide it right yeah pretty much and this is here because once we're going frame by frame you don't want to be pressing a key every time the frame changes it's going to automatically change in real time okay so we really only need this for uh this case of doing just the the first frame of the image so let's run this and see what happens there we go so that's the first frame okay so like not it's not an actual video it's just one frame okay um but we're gonna wrap this in a loop and then we'll see it in real time okay oh i see okay so you just got a single frame okay i got you i'm with you yep yep yep because dot read will read a single frame okay and then it keeps track of where it is so every time it calls dot read it'll read the next frame next next frame so we just wrap this in a loop and that's how you can get the realtime webcam footage right so i'm just going to read a single frame right read single frame oops yeah nice okay i'm taking notes for them yeah there we go what's nice bro i'm running out of coffee this is uh this is a disaster so this makes sense yeah we're going to read a single frame and then we're going to wrap it in some kind of loop so we get that realtime functionality exactly which is what we're going to do down here uh so let's get back to here now but i'm just going to plug in things one by one so like i said uh just the webcam and then read a single frame display that frame and then display that frame like wait until a key is pressed before you hide before you hide the frame okay so now all we want to do is just pop this in a loop okay so we got the webcam here now um the loop is going to be here because once we have the webcam we want to keep calling dot read on each frame over and over again yeah okay so we would just want to run this forever and that's why it's a while true loopy it's going to run forever until we're done so let's pop all of this into there and uh from here oh like let me get the cleanup code okay so this here at the end let me let me show you guys this real quick this here is just some cleanup okay so it's not super important it's kind of boring code but i'm just going to say at the end of the whole app you want to make sure you have a webcam dot release it's just letting the operating system know that hey this app is done using the webcam uh free up all resources so that something else can use like zoom or skype can now use the webcam without any uh memory issues go ahead and then and then the last thing is uh cv2 to destroy all windows so this just kind of closes all windows to make sure nothing's still open okay because sometimes that happens yeah this is a cool little thing i forgot about what i found recently so very handy yeah um okay so after this then we get a webcam we have a while loop and same exact thing so this should work the only caveat is uh if this is empty it's gonna keep waiting for a key press so let's let's run this and then i'll show you how that works so here we go it's a frozen frame but as i press a key it keeps going to different iterations of loops so it keeps running it keeps yeah and each time i hit it it gets the current frame because it's calling dot read alright so calls.read on the frame yep dot free and if i spam it and then kind of like real time but that's annoying so what we actually want to do is yeah what we actually want to do is dot weight key actually just waits until the key is pressed uh forever but if we put something in here this is how many milliseconds it'll wait before it automatically goes by right so if we put one it'll automatically spam a key every one millisecond and that's kind of like the behavior if i put like a million then it would just wait a million that'd be too long would be like 10 minutes yeah but if i just put one millisecond now when i run this this should be updating every millisecond by itself and i should be in real time so let's give it a shot nice well let me quit out let me quit out of the old one oh wait i gotta i gotta kill it one second how do you kill it in uh uh it should be as h it should be control c yeah so if you just spam control c sometimes it takes a little bit uh oh it's not working i'll just force quit yeah also guys just want to drop in before wire and sorting now we have one comment over there there's one says bernard you people are really amazing awesome i have no words to express my feelings it's only because of you people today i got a job at google at google he got a job at google did that's insane damn like seeing that holy crap i couldn't even get a job of google what is bro bro get this guy in the stream he should be teaching not me i know yeah not a same we love that guys and we also got another donation from tech programmer thank you very much dude we massively appreciate that and also yeah that's amazing guys drop us questions in the chat and we'll literally we'll be happy to answer it as the stream goes on we really love when you guys engage with us and let us know yeah yeah hey whoever landed the job at google send uh send me and send me a dm on instagram and then uh we want to hear a little about your story that's awesome i don't know that's exciting yeah what was his name sunny what did he say he said yeah let me go ahead and find it again so what is his name it's i don't have it on i don't get removed so i've just popped it open it says ajax got it all right we'll meet yeah we'll be expecting you to dm us okay yeah awesome yeah i'm the google guy yeah i'm the google guy that's insane dude we love that nice kind of jealous actually yeah you soured my mood [Laughter] that's amazing great that's that's exciting we have another awesome comment by she goes you guys are just amazing i've learned a lot from these live stream your work is very inspiring thank you so much that's awesome dude thank you for watching all right let's go all right let's go yeah yeah it did the control c didn't work so i don't know what's happening but i just killed it manually yeah um so where were we before i got distracted oh i was running the frames yeah so when i run this again it should actually refresh every millisecond by itself okay so that's how we we fetch this let's run this and go back here and there we go so i'm feeding the webcam footage i mean opencv is getting the webcam footage the webcam stream and it's just displaying it in this window and then i called it small detector right okay so so that that by putting one inside of the weight key that's pretty much saying every second every second like go to the next frame right yeah like it says only wait for one second it says wait for one second then press it press a key like like a fake key like a pretend key and then it presses a key every one second right okay so this waits one this way it's one millisecond yeah but nothing waits infinitely nice that's the difference awesome or ten we could do ten ten milliseconds is fast so this would still work but it doesn't really matter awesome all right yep nice and okay let's see if it'll kill okay so now control c is working nice i don't know what this red thing is means sunny sunny have you installed this weird shell thing zsh i've only used it like once but i ran away but he says it's colorful yeah usually i think that's when your branch is dirty i think so i mean that's usually i got it something like that yeah yeah yeah i changed the i probably changed the code in here and then it changed but no big deal just ignore this like the color of the arrow but yeah let's just move on okay so i can actually get rid of this stuff because we actually pulled everything out so now we're back to the code ran without errors nice okay uh here let me just pop in some comments we have 350 people watching right now so thank you so much for watching and yeah if you're enjoying what you're what you're seeing right now um with the face detection you think it's pretty cool all we ask is that you just smash the thumbs up button and that will help this video get out to more people nice yeah yeah like smash the track pad like slam your mouse just hit it as hard as you can keep that domestic violence and domestic violence in the software program that's a terrible joke but uh so yeah this is step one all right so we got we got the webcam footage in here all right you guys should be comfortable if you guys done this before pretty straightforward now uh once it one check we want to put in though is actually this so i mean it wasn't it wasn't breaking before but we do want to put in a check here uh right here so after we read the the frame okay the first frame with the dot read method the first variable or i mean the first element is actually a boolean of if the read was successful or not okay so all i want to do is put yeah because sometimes it might bug out um what the webcam is usually fine but for a video file if you're reading an mp4 or something like you put a video file in here like sometimes if one of the frames is corrupted or whatever then it'll not work so you just kind of put a safe check in here so if it wasn't a successful successful frame rate just break out of this while loop and just like abort the program and it'll go down to here and close everything so that it doesn't break it just kind of quits so yep that's that's all that is just a quick quick little aaron somebody asked a decent question they said how can i install the face xml file so the one that we used at the top where did you actually get that from again uh the opencv github document github repo so they they provide all of that the link is in the description so you can just go down and scroll to the bottom and just download this uh the face xml file there's also a smile one but we haven't gotten there yet we're going to be using both we need both to make this work um you'll see you guys will see later why that is yeah but yeah let's let's just continue let's do it uh huh so after we get the frame read and we have this little check here then uh let's actually start detecting faces okay so if you guys watched the face detection video you guys already know how to do this pretty straightforward it's a very similar but there's a little trick here that you guys are probably gonna lower your minds at some point uh hopefully but but maybe not uh okay so after we got the frame to actually run uh face detection on the current frame using this xml we need to use i mean we're using opencv of course it's a very simple code it's just like detects faces pretty much but we do need to yeah we do need to change the frame to black and white though this is just an optimization because in a black and white image you can still you can still tell what a face is you know if a human can can still tell then the computer can still tell and then there's less data to deal with but the actual like you know recognition ability of a face isn't hindered by it being black and white so we just converted to black and white to greatly optimize it it increases it by a lot actually because rgb has three channels black and white only has one channel that's super interesting i had no idea that that would be an optimization so we're making a grayscale so that it actually reduces like the sort of not the amount of processing they have to do on the the video yeah because you're kind of just like jumbling rgmb together into one number you know red green and blue because then you can just kind of be like oh then you can just play with brightness you can be like okay um somebody's eyes look a little bit darker than their right cheeks something like that or somebody's eyebrows are darker than the forehead you can just you just want to see the relationship of brightness between different areas on the thing and those all added together if you do it enough you'll eventually define a face like okay eyebrows darker than forehead eyebrows darker than nose lips a little bit darker than cheeks eyes a little bit darker than cheeks stuff like that like hairline a little bit darker than um if you have dark hair so like it's just those kinds of things over and over um you eventually can can um explain to a computer what a face looks like after thousands of those little relationships or a car or pedestrian or anything or a smile in this case also like teeth you know teeth are whiter than your lips so like it would understand what a smile is nice okay that's that's awesome i would never have thought i would be optimization so that's that's cool also just to jump in chin moy kalia says again because of you i'm able to make my college fees by freelancing just wanted to throw that in i love stuff like that thank you i feel like these people are making making more money than us like i'm kind of kind of upset i know guys that's a guy make money so we can go to school to learn from people that are not us is that is that actually a win for us honey is that actually a win for us let's think about this for a second i think we should cut the stream okay abort yeah nice cut off signals oh got it what i love though anyways is that is this like literally so few lines of code to get this all working yeah that's what i love about it too and then if you if you optimize everything under the hood which is how you should be doing stuff like if you like c or c plus plus under the hood um then it's still pretty fast but you can be very expressive with your stuff i think that's why they choose it for machine learning because there's a lot of weird yeah there's a lot of weird nasty stuff and you actually see the power of python here later on if this was written in javascript it'd probably be like two or three times as long you know like yeah maybe not yeah i could vouch for that yeah of course this is this is this is nice and clean compared to javascript all right let's carry on yeah i don't like javascript yeah yeah i know no javascript is amazing sonny i don't want to hurt your feelings i know it's going to make me hook out guys you just see a video yeah reconnecting it but yeah let's continue on so once it's gray once it's gray okay this is actually requirement like opencv you have to take it um and so oh i should explain all this so what this is is opencv has a function called convert color which allows you to convert the color of an image um to to black and white or back and forth or just the red channel or just a blue channel you can do all different kinds of things but in our case we just want to change something from a color image to um gray okay i mean well this is a bgr which is rgb backwards and then two gray so that's all this means there's like different encodings we can use so we're gonna be using this one to convert this from a color image to gray so let's actually run this now go ahead and actually we need to display the actual black and white frame i feel like i've done this a bajillion times because i actually have it might be boring some people who've seen the other streams but whatever and there we go oh black and white webcam yep so you can still tell that this is the face you can still tell but my mouth is smiling so we don't need color to be already and stuff it actually looks like it's smoother it actually looks a bit smoother when it is yeah because there's there's only a third of the data you know with color you have three channels or four channels actually there's a brightness channel as well yeah um but on this one it's just the brightness channel that's nice that's it so it's actually four times as fast because there's one channel versus four channels awesome and let me just quit out on the terminal control c and let's just clear this up because it's getting messy nice all right so there we go black and white frame now it's literally as simple as popping this grayscale frame into our classifier for faces yeah and it'll spit out the coordinates of where my face is and then we can just draw a rectangle on my face and bada bing bada boom that's a face detector um that's the first and then we gotta do smiles you have to like overlap them in some weird way and there's some cool little there's a little trick i'll show you guys later that is critical for this to work and then some tuning you have to uh tune some variables at the end too which actually make it work properly but i love a simple you make it like yeah you know we just gotta use this machine learning classifier and then you know we're gonna get some coordinates right and then we just gotta draw a box around the face yeah there's no big use you gotta do that infinite loop i mean i'm explaining every line so i feel like people can follow along if they know python if not then uh you know i'll fire myself yeah donald trump nice yeah so let's go down here and actually just detect faces okay let's do that stop here i might go a little bit faster because i'm just kind of this is like repeating the face detection stream yeah we haven't even gotten to the smile stuff yet but here here's the line for detecting the actual faces okay so yep so how this is gonna work is we have our classifier up here okay face detection face detector which we created from this xml file which has like all the data about like what a face actually looks like depending on the brightness relationships like we talked about okay um like and then from there so we have this this phase detector now with this face detector okay with this face detector we can call a function called detect multiscale okay okay and then it just takes in an image and then um so what this will do it will tell us where all the faces are in this image okay it'll say oh there's a face here there's a face here there's a face here and that's what it'll do so is it returning an array yes an array of points okay an array of rectangles so the reason it's called detect multiscale is because you just want to detect uh faces of any scale so if there's a small face you want to detect a small face if there's a big face you want to take the big big face and you want to take multiples of them so you detect all of them that's why it's called detect multiscale uh uh because we can really pop in we can i mean we can use any detector like we have a dog detector or a cat detector we could also detect multiscale of cats or dogs okay so that's why it's called that nice okay so it takes in a frame a black and white frame and then it'll say okay at these at these places there are faces in this image and that's what this is so this is just an array of points yeah uh in my case there's it's gonna be array of length one because there's only one face but when i had the joker on the face um when i had joker on the screen too yeah and let me quick then there would actually be so when there was both of us yeah then there would be these faces would be a length two because there's two faces in the the in the video go ahead it makes sense yep so from there uh let's just print out actually uh faces okay so this is just gonna be a list let's just show this and it's going to spam the terminal here over and over again because we're in an infinite loop remember so as i'm here oh nice you can see the you can see the location of my face is being detected and then it's just being spit out here okay so like x y coordinates you know like blah blah blah yeah and then from this we can just draw a rectangle on the face that's it that's clean man i was expecting like some really intense stuff for that that's super clean how it comes back like yeah that's it so it's it's a it's a list of lists so if there's two faces so actually watch this now there's two faces hey look at that see how there's two faces on the screen yeah and then when i get rid of it we're back to one face the list is linked one not a list of of length two and there's two per them that's nice okay quiet and if there's three then you know three if there's a bajillion yeah or in the matrix you know mr anderson agents going i think it's what i'm saying guys like just from like that classifier you're able to do all of this so this is just the power of machine learning like and like yeah and as i said this is a face detector human face detector but you could easily go and pick up like a dog detector put that here and i guess it would do the same thing right you can detect anything so a hard cascade is a single algorithm that can detect any arbitrary object so basically we're you're like if the computer was a person we're literally downloading this is what a face looks like into its brain that's literally what this is doing you just have to teach this before we give it to it so this was a result of machine learning with a bunch of face images uh that somebody created and it takes probably like a few hours or a few days to create it but then once it's created then anybody can use it so that's kind of the power of it awesome got you yep and of course heart cascade is just one algorithm for for object detection whether whatever object happens to be in our case of face or smile yeah there's many algorithms but this is the simplest and oldest one it's actually based on viola jones um these names probably mean nothing but if you don't look it up look up viola jones algorithm yeah and then um our cascade so these are just names of people who came up with them back in like the 70s or 60s or whatever nice but awesome smart smart people yeah very smart people so okay so that's the face so uh from here we just want to draw those rectangles back on the image here and then when we show it then it'll actually have the rectangles drawn on this as well instead of just showing just the raw frame okay so that's really all we're doing uh then from there then we can get to the smile stuff so at this point we probably should at the beginning oh if you want to get to the smile part just skip ahead but it's too late this is a stream yeah for anybody watching the replay but i mean i guess it is what it is yeah 45 at 0.45 45 minutes or so like that's when we start the smart stuff so yeah we can add that in the comments afterwards uh yeah let's put the timestamps and then you know like the youtube has that nice that thing now or like where the play bar is like segmented that thing might blow exactly yeah that's insane bro you should do that that would be a cool clone to do you should be like youtube you know segmentation clone like you scrape out like the the stuff and you segment the video or something i don't know it would be cool yeah all right stay tuned tomorrow for that because sonny's the beast can code things in five minutes wait guys just as another reminder we actually have quite a few people on this live stream right now tomorrow if you're excited we are building a whatsapp clone so we are building a whatsapp film tomorrow it's going to use firebase it's going to have a realtime chat functionality so if you're excited about that smash the thumbs up and make sure you set a reminder have you coded imessages yet an imessage clone no that's a good idea yeah we'll do that as well yeah you should do that because either facebook messenger but you should do imessage too instead of whatsapp you know what i mean what's that is more internationally yeah yeah forget the android people all right okay so now what we want to do is we just want to run um we just want to draw some rectangles on the frame so i'm going to kind of go over this quickly if you're getting confused then again there the other videos go a little bit uh slower to explain this in detail but i'm just going to go a little bit faster okay because we're going a little longer longer than i thought it's already been an hour bro yeah but uh so are we going to do like i said faces is a list of points so we just want to iterate over all of the points so all of the faces that the the algorithm found let's just kind of list let's just iterate over all of them and pull out those points so like i said there's four points here for each face so um we're just going to iterate over all of them okay go ahead so uh the first point is x the x coordinate the second point is the y coordinate this is the top left point of the face yep and then this is the width and this is the height of how big that uh square a rectangle should be so for a face it's squares by default but for smiles it can be any shaped rectangle so it just gives us like the width and height of the rectangle so we're given a point and a height from that from there that's all we need to actually draw because we can say at this point go this far and then go down and you can just you can you can figure out the rest with math which is what we're going to do here go ahead okay nice so here uh cv2 allows you to draw stuff on frames so like like this we can draw rectangles we can also put text on the screen which is how i put the smiling little thing when it says smiling so you can also put text we'll do that later but for now we're just going to draw a rectangle okay so the way this works is you just give it the image you want to pop it on so in our case we want to we want to draw the rectangle back on the colored frame not the grayscale frame but the colored frame oh okay because we're only doing the calculations on the grayscale on the grayscale frame because the coordinates and everything is exactly the same but once we have the data of where the face is we can just use the color again okay so it's an optimization yep because you're doing the calculations on the black and white image but then we're actually still only seeing the color image which is what you want okay and for rectangle all you need is the top left point and bottom right point of the rectangle for it to draw because those two points it makes it easy to draw the rectangle so the top left point like we mentioned is x y that's what we have here then the bottom right point is just going to be x y but you add the width and the height to the correct coordinate so uh x you want to go an extra width because that's the width of the rectangle just go you just add w to it okay and then why you just want to add the height to it and those two together will be the bottom right point of the rectangle okay if you guys don't know this then just like look at your geometry yeah brush up a little bit x plus the width and then y plus the height and that will give us the square right like the rectangle sorry yep yep go ahead yep square root in our case it'll be a square but uh any rectangle you can draw any rectangle go ahead and what's the numbers on the right so what are these this so this is rgb the color of the rectangle okay um well technically bgr because it's backwards and opencv uh this is just a random color you can put whatever you want you can play these can go from zero to 255. okay uh you can use whatever color you want but i just chose this as a nice green color okay because like it kind of like it matched nicely with the joker the joker screenshot so this is just a random green color you can use use this if you want but you use whatever color you want then this is just the thickness of the rectangle okay nice or four pixels thick that's all so this is just like customization stuff this one line is going to draw the rectangle on that on that frame yep yep i'm just gonna draw on that frame well a single face on that single frame yeah so we're gonna draw all the faces on the frame then we're gonna display that frame nice and then on the second frame it'll detect all the faces in the second frame and then show all the faces in the second frame and then again third frame because we're in remember we're in another loop so this is a nested loop yeah and uh and there's going to be another nested loop within this one which is going to be crazy later on but yeah okay let's go ahead and run this to see if we can actually see the the rectangles that you just you just talked about yeah definitely so um displaying the colored frame here which is what we drew the rectangles on colored frame yeah and let's just run this as you can see here um this is the x point this is the y point yep this is the width and this is the height nice and faces are always squares by default because that's just the parameter they set so you can see the width and height is always the same within height is always the same but different sizes sometimes because detect multiscale it can be smaller or bigger okay awesome let's run this and there we go magic oh snap dude that's insane in javascript that would be like 30 lines of code you know just yeah yeah i know yeah it'd be something you know yeah this is where like i really do come back to python a bit like whoa yeah man you know you can do web development with python too you know you don't actually need javascript you know you just use django i'll fight you and i'll fight you and nas both yeah you might have a green circle around your face but you took it to the hook yeah with no legs right there's an enjoying goat guys i think we should just tell the community like sunny's good is so much stuff so when he joined the team a few months back um i was like one day we're on a team meeting i was like yo sonny you're so good at everything there has to be something effed up about you but he lives in uk we're all in los angeles so kazi was like hmm you know we've never seen sonny's legs and we're like he must be in a wheelchair or something like there's something here everyone thinks i don't have legs so he's always insecure and showing his legs in the in the video chats like yeah but guys at least at least today i i'm not the only one wearing a black shirt so you know is that is that a thing are you always wearing a black shirt that's always a thing dude everyone's always like yes and he's all sunny doesn't have any other shirts besides black tshirt he's like he's like steve jobs wears a whole um you know what's it called um turtleneck right yeah row neck and then they're like sonny wears a black tshirt every single time zuckerberg wears a blue tshirt right yeah like a gray tshirt it saves you time in the morning guys so that's why technically this is dark gray it's not black so you're still by yourself sonny oh but uh anyways let's get back to this so that's the face detection app basically you just repeated the face detection video but whatever so now um that's pretty good so like wouldn't wouldn't a small sector be as simple as just changing this out for a smile and writing the same thing well yeah let's try it i mean you would think so you would think so but you guys about to see some really really weird crap and then really really cool trick to fix that weird crap which is interesting it's a smart thing to do so let's create our smile detector okay let's create our smile detector okay yep so they smoke all correctly yeah there we go smile detect so same exact thing uh we're gonna be using hard cascade and um to detect faces but we can also use use it to detect smiles so in this case there's another file and description it's just called heart cascade dot smile i think let me double check down here yeah our cascade underscores smile yep and we just use this pretrained classifier instead so this took a bunch of images of people smiling with their teeth showing it doesn't it doesn't detect like regular smiles that good it's mostly like teeth smiles um from the training data but you can teach you to do both but in our case you kind of have to show your teeth for it to work like really well uh but that's there so why don't we just use this instead of the face like because it's detecting the face so well right like it was cracking my face perfectly and if there's multiple faces yeah shouldn't be able to detect smiles too supposedly supposedly so let's go down this code and make the changes okay so we have to we we get the webcam uh we want to iterate over every frame we want to read every frame in each iteration and then a little check and then frame grayscale so we get the current frame you change the grayscale now instead of detecting faces let's actually detect oops smiles okay nice okay like smiles and instead of on face detector let's call smile detector and we want to call it on this on the same frame so grayscale frame yeah and then again let's just copy this exact code but instead of and we can use the same variables because this and this loop will never overlap like this loop will completely finish before this loop starts so we can we can use the same variables which is fine okay keep it nice and clean look yep there's no if it was nested we cannot because then they would get um they'd fight over the variables but loop completes before this even starts so it's okay to use the same variables here right um but instead of faces let's draw smiles okay so now this is going to be so this is what it's doing is the same exact thing it's going to find all the smiles in the image and then return a list of points the exact same thing upper left hand point um upper lefthand point here and then the width and height of the smile in this case it's going to be like a horizontal rectangle instead of a square okay so it's returning the same thing right the same coordinates uh the same form yeah it's going to look just like this but instead of giving us the coordinates of faces is going to give us the coordinates of smiles it's like just a different rectangle on the image it's smaller around the mouth and it's like horizontal looking right uh let's change the color though i had a pre uh this color okay that's the color i chose it's like a nice red color yeah and because right now it's the same color as the face but i want to change it to this red color go ahead uh like i said bgr so r is at the end that's why it's so high so it looks more red because the r channel is the highest right okay red so let's run this and let's um let's actually not draw the sm the faces let's just get rid of the faces so i'm not even going to draw the faces okay so we're just going to we should just see yeah so not even faces it should just have things of smiles on my face right okay i mean they just have rectangles around the smile on my face yeah so let's run this and whoa voila as you can see it's working perfectly holy crap okay so this is well this one okay this is what you meant by it's just a lot it doesn't work for yeah yeah it doesn't it does not work but it does uh and i'll explain that in a second and how that actually works but as you can see right now the default it's like this isn't even working properly like what the hell like how like okay is that it's actually getting my smile look at my smile i was actually getting the smile yeah it's actually getting it so it's smart enough to find it but there's a lot of false positives like it's things this stuff over here like this little window sill is there because it probably thinks this white is like teeth and this is my lip or something yeah but i mean there's also getting things here on the freaking freaking curtain which makes no sense you know like like what i mean this may be a little bit too like it looks like the upper teeth and the lower teeth and the little gray line is like maybe the gap between the teeth a little bit we kind of understand maybe we just built a ghost detector or some you know like yeah that's what they said in the face detection video or the pedestrian tracking but yeah point is this is working like ass okay yeah uh so how do we fix this it's like this isn't even working um first let me explain why this is happening so there's a there's probably a couple reasons why i saw what this is happening and i'm gonna explain both okay uh first thing is so let's just quit out of this first so why is this performing so yeah i realize it's wearing screen it's fine it's fine first reason is to be honest uh faces are one of the very first things that people detected from the beginning um that's like the very like that it's like the coolest thing to detect to start with and it has like a very defining feature like detecting squares or detecting a soccer ball is kind of like okay it's kind of cool i guess um i think a face is like pretty cool right so there is a lot more data in this trained algorithm than there is anything else so there was actually just more phase data and this was just trained better than smile was to begin with so that's the first reason why face detection was working so well because it ran out more data for longer yeah while this one probably didn't get much data nice okay just because yeah it's like okay if you want to have like a left finger fingernail detector like there's not going to be as much data as faces just because faces are cooler or like a blade of grass detector like who codes that yeah you don't want to take vigilance and also bleeding guys like if you think about it a face has so many features you have like you have your eyes you have loads of things which which basically are going to tell that model that okay we can be sure that that's the face whereas a smile has a lot less to look for like you just have pretty much like the curvature of your smile that's why you kind of it can easily get confused like the lamp behind aaron has like a little curvature to it so it could get confusing that's a smile whereas a face has several different reference points that it will look for in terms of features so just something to bear in mind as to why you would get that that was the second point i was going to make you stored out of my mouth but that was absolutely correct guys yeah exactly what i was gonna say is yeah there's less features like detecting a tooth is much harder than detecting a face because how do you detect the tooth it's just like a it's just a flat white thing with like a specific shape but it's harder to detect yeah like it might get it might get a tooth and a marshmallow mixed up but it wouldn't get a face in a marshmallow mixed up unless you're the michelin man but uh or the or the or the pillberry tilbury uh guy you know the little little bakery guy but but yeah that's the point that sonny made right that's the second point so first one is face probably just has more data overall just because it's a more defining object and it has more emotional pressure to humans so it's like cool let's detect phases but also it just has more data that i can go by to determine hey is this a face or not versus a smile you're kind of limited nice go ahead so that is absolutely correct so that's why it's performing like ass i mean it could be better it could be better uh if they trained it better with more data yeah um but even then it's still hard harder to detect than a face right so how do we get around this well um first of all there's different parameters we can do so you can actually be like hey if uh something only counts as a smile if there's like two or three things around it that are also a smile because then it kind of thinks okay if this area kind of has like four smiles detected then it's a smile but if it's just one random thing that might kind of be a smile but there's only one instead of like four yeah then um you can go okay that's not small enough so like there's kind of like a redundancy okay code one more time explain that visually right so like here we're just getting a bunch of stuff okay yep um so but you can see like this random one over here just getting they're blipping up every now and then yeah so so are you usually gonna say that can get rid of those right so in a simple sort of like in a one sentence sort of answer like rather than checking the entire sort of webcam view we kind of want to narrow down that that sort of selection down to just your face right um not quite there that's the other optimization i'm gonna show but what i'm saying is um see how there's like random boxes showing up over here yeah like by themselves we can kind of get rid of all the standalone ones that just kind of flash really quick okay but if there's a big group yeah if there's a big group of boxes overlaid on top of each other though we can kind of say the chances of that actually being a smile is a little bit higher like up here we could maybe boil this down to like one smile we'd be like okay there's freaking seven boxes here this is probably a smile there's seven here this is probably a smile there's a bunch here there's probably a smile um but these little ones on the sides that are flashing randomly you can say now we don't want those right and we can actually get rid of that is there some kind of sensitivity or yep that's all it is it's just a sensitivity number and you have to tune it to faces so you find the perfect number which i'll show you guys in a little bit but we can actually do that so let's add that in and you won't see that much of an improvement here on this but i'll show you guys the second optimization which is going to clean everything up and make it go from complete ass to super super accurate which is pretty impressive nice so um detect so this happens in the detect multiscale okay so there's two different things called or two different parameters you can use called min neighbors and scale factor okay okay so let's get these yep here here we go so this let me actually type it out so this is going to be uh scale factor okay i think i might have spelled it and then this is going to be min neighbors okay um it might be the wrong spelling so it might not work but let's just try it so what this is gonna do is it says skill factor this is an optimization to how much you want to blur the image because if you blurred this image you can still kind of tell it's a face if you don't blur it too much okay and then if you blur it that's another optimization on top of the black and white okay you can kind of like generalize and then you can kind of compare the data a little bit more um because there's less data but you can still kind of tell it's a face so you want to kind of optimize this basically this scale factor is blur like how much do you want to blur the image to make it easier to detect faces and kind of like um get the defining features in brightness um or or not so the higher this number then the more it'll get blurred so i found the 1.7 is the best right so just just to be clear there so you're saying essentially to blur the the the sort of the entire frame so that way it will be easier to detect facial features as opposed to like a curtain or like a lampshade yeah because you get a lot of rid of a lot of the details which are unimportant so like if there was like a 4k image and there's a lot of details then it can get very confused with the data but if you blur it enough you can kind of if you blur it like a crap load you can kind of be like okay um there's kind of a blurry face in the middle and then everything else is just like a blurred mess in the background so it actually kind of like contrasts like the objects you can be like okay there's a face and then there's a bunch of blurred background you can't even tell if it's curtain or wall or whatever but you can kind of be like okay there's a face here go ahead okay nice so that's the idea if you can blur it down more you can actually detect faces even better yeah then mid neighbors is what i was just talking about um there has to be 20 neighboring rectangles in total in that little area for it to actually count as a smile okay so if this was one then literally just everything would be passed through but if you make this higher then it's like okay there needs to be a lot of redundant rectangles on this one little area for this to actually be a smile so it's like i found 20 smiles in this little region of the image because they're all overlapping it has 20 neighbors the minimum amount of neighbors of a rectangle needs to be 20 for it to actually be counted as a smile so this will help a little bit yeah let me show you guys and then um well actually not even at all like well actually it helps a lot oh one sec one more than before all right so there we go all right yep right back there you go so as you can see okay it's actually it's actually better a lot better that's what i mean yeah there's still a few things so here yeah i don't know why it's so fixated on this light it's probably thinking that this is teeth it's probably looking for like a yeah a horizontal line of white so it's thinking this is tea okay i mean like you can see why the lamb i mean the top left is a bit of this weird one yeah but i mean you can kind of see like this little white oval and my teeth look similar yeah yeah yeah so it's probably trying to find like teeth and then the curvature of your mouth okay yeah so something like that uh so that works really really well so like a lot of fine tuning needs to be done for things to work properly so just that little change there that worked way better than when i was testing it but uh i mean that's amazing so um tuning tuning different numbers can actually play a big big role in that so like maybe like in a real world application if you're detecting smiles you would want to save these numbers okay and be like okay for smiles always use these parameters this is like additional machine learning on top of all the the crazy numbers machine learning that's in here you have this plus a little bit more so this is kind of like this is kind of like manual machine learning you manually went through and tested a bunch of different sensitivities and you used your eyes to be like okay this is actually machine learning so that you actually taught the computer that these two numbers are closer to a smile than anything else so this is like manual machine learning that that you're doing okay pretty cool yeah nice um okay now going forward uh another optimization that we can do is actually get rid of uh these these errors because like sunny said and what i said in the slides is smiles only show up in faces yeah so why don't we instead of trying to get it across the entire frame just find a face and then only run small detection within that face yeah because we already already did the work of the face detection so why don't we do that that's awesome and that's what we can do next because it makes it faster and more accurate yeah when i first thought about i kind of thought that like oh we're just going to slap a model on the entire webcam and they'll figure it out but guys you have to be prepared like uh take it in mind that you you there's a lot to process it remember in the beginning we said like you pretty much have some kind of input your model and then some kind of output so if you can reduce the amount of input going into the model you can actually speed up the entire thing a lot more like and it's drastically going to be faster and it's also going to be like more reliable in terms of we're only going to select aaron's face and then find the smile inside there so something yeah yeah yeah on the selfdriving car live stream we did the car and pedestrian stream tracking one you can see a really good example of this in real time when we're doing it because there's so many cars on a highway so some highway footage there are so many cars and a lot of pedestrians because because here you're only taking like two or three yeah but in those there's like 10 cars and 20 pedestrians so it was going crazy um when you when you do that one when you um scale it down so if you blur the image more it's faster if you make it black and white it's faster and then some other optimizations you can actually see the footage gets played back really really fast so that's a good visualization if you go check it out go watch that stream too it's nice it's badass as well yeah go check that one out guys i'm going to watch that one as well not watching my content i know i do i do i'm the guy smacking the smashing the dislike i'm joking wow okay so we'll go up this morning he was like aaron i'm really grumpy i don't want to do the stream and i was like bro i need you i don't have my internet stuck i need you man and then uh then he's like now now he's all in a better mood because he's been hanging out with me it's fun we'll definitely do some more streams yeah this will be cool we can even probably do some kind of python react you know like yeah dude let's do that we could like tie it together like do like a cool front end app with uh javascript and we can have some cool like backend python stuff like happening like this you know yeah like a frontend thing where you click like smile detector face detector you know like car pedestrian detector and have like different you pick different files and it feeds it in yeah something some people like that exactly that was awesome uh aaron quick question here from shantao he says is it beginner friendly so just maybe a quick answer to that is this video beginner friendly or is the other ones beginning yeah like just for anyone that's new to the video or who might have joined afterwards is this video beginner friendly like do you need to know python before you do this yes you need to know python but if you know like for loops and all the basic python stuff and how to like call functions then no you know i teach you the rest from there but you do need i don't teach the basics here so you gotta learn the basics then you can come back if you're if you're a complete from zero beginner no if you're just a beginner who knows python but you haven't coded much then yes you can go through this yeah and also just worth mentioning guys i don't code much python but i know javascript so coming to this is actually super super simple in terms of how aaron's broken it down so if you have any coding experience then yeah you can do this so definitely go ahead and do it yeah very straight awesome so i popped back in the faces so let's do this now okay yep let's go back to the terminal and run it again and now we should have uh error oh cause i commented out faces so it's giving me an error because i'm trying to use faces here yeah when i commented it out let's just get rid of that and run it again so there we go so we got the faces here and the smiles nice hey look at that yep awesome but i mean it's still getting this you want to get rid of all these random ones yeah so what we can do like i said is we can actually just run small detection within this window instead of the whole frame which is a smart optimization because i mean in the real world you wouldn't see a smile out in the middle of nowhere unless it was like a piece of art or like dentures or something you know but generally smiles only show up within a face so that's why um we can do this nice okay yep and then i actually show the effect effectiveness of that too i'll get rid of these tuned parameters and actually show you how well that works okay um yeah i mean it kind of works well but those like these scaling factors the sensitivity plus the that little trick together makes it super accurate from what we had before just like freaking right all over the frame just a single smile like like we tuned that down from just two little things so that's it's like really smart clever things to to make your code work using something that doesn't work and making it work yeah with a few numbers awesome yeah so let's continue okay so how do we actually make it so that we only check within a face if there's a smile so how do we actually make it so that we only check within a face if there's a smile okay so like like we said we're in the the global loop here that is looping over the entire frame we read the frame so from here we keep going down blah blah blah and then we get to uh faces okay okay oops run small detection within each of the faces uh run face detection so some of these comments might have not made sense the entire time because they kept popping them so this is what i had before run face detection but now we want to actually do this within each of those faces this is what we're currently going to be installing so how do we do that okay let's look at it just from here so we we we're in the frame and then we find all the faces and we have all the boxes of frames so we have the box of of a face so we have the box of what a face is yeah we draw that box right okay but we have this box so this is actually the box we want to look at this is actually the sub image of the whole image that we want to find smiles we're actually giving it right here but so we can actually just be like okay instead of looking at the whole frame just look at this rectangle for the smiles instead okay and that's what we're gonna do so how do we do that there could be multiple smiles within a face though right if i mean not technically but if there's errors like it might detect like a little just before your mouth so you just want to make sure you find all of them so what we're going to do is we're actually going to have another loop in here is be nested because within a face you have to find all the smiles okay so we're actually going to need to um find the xy um width height of each smile within the face so same thing we're just nesting it okay does that make sense so far yeah quick thing is though because yeah quick right this is a python question so you have uh are your variable names not gonna clash here or is it gonna be in a scope they will okay no they will they will right um i believe i'm 99 sure i didn't even try because i thought they would uh but i'm pretty sure they will so what you can do is you could use like capital letters or something i believe it's case sensitive yeah but you probably don't want to do that what i did is just a little sloppy but i just did this okay just so they don't contend but it keeps it simpler because if you start doing stuff like this the codes start looking really hard on the eyes yeah um because this is so so clean you know x y x w y plus h yeah keep it nice and clear but if we started doing this then it would look like you know over again x smile plus y smart like yeah it starts looking like that yeah so yeah so i just did this just uh it's a little bit messier but it's it's still easy to understand i just added an underscore to the end okay okay so we're going to need to look over uh the face okay okay um i mean i should probably talk about getting the subset first uh let me go over the logic first so what we want to do is you want to find uh in the face okay so you want to find all the smiles in the face okay so uh find all smiles in the face okay so we're gonna do this doesn't exist yet but i'm just using this as a placeholder thing for right now this code will not work because it's currently broken yeah and then just draw um draw all the rectangles around the smile okay or the rectangles just like that oh shut up dude it must be an american thing okay let me yeah let's just do this so it doesn't break uh oh yeah i was making fun of your spelling before right yeah oh god that's hilarious that that backfired didn't it uh anyways so this is the kind of idea we're gonna iterate over um all the faces and then with each of all within each of those faces we're gonna find all the smiles okay and then we just want to draw the rectangle in there so kind of slimmer to what we did here actually okay the only caveat is you have to change the the names here yeah um so why don't we do that actually let me just uh copy this down here so this is the same exact code as we had before we just want to draw a rectangle around the smile okay okay and then instead of x y uh w and h it's just going to be this okay just add the underscores to the end okay it's kind of hard on the eyes but if you space it out like this it's not too bad so so just to bring everyone to speed right now we had an initial loop which was going through all of the faces and then so that was the first one on line 28. so i was going through all the faces and then on line 34 we're going through the individual face that it detects because you might have more than one place and then when you get a rectangle around that individual face right uh no uh within each of those faces you want to find all the smiles and draw a rectangle around all those smiles so what we're going to want to do is um we're going to want to actually not run this here we're going to want to run this oops we're going to want to run this here okay okay yep well i actually not here uh that's incorrect um but i need to explain something else first where do we get actually where do we get the face from is that like placeholder for now or that's um yeah i'm about to explain that this is the tricky part and this is the really cool part so let's just pretend that the face equals this for now okay this code doesn't actually work but this is what it is in flavor okay yeah just pretend this code does not work this code does not work but this is the idea we want the face to be this little mini sub image within the whole image because this is the current face like the little square that surrounds the face so you want this to be like a little image but the thing is um you can't just pass in like these uh detect multiscale and get the get the smiles out of this we have to do some crafty stuff here with the array and and slicing but just this is the idea is that clear sunny yeah yep oh yeah if it makes sense to you then hopefully kind of playing into an object right kind of well what we're going to do is we're just going to slice and tool into the image and get like a sub image in some cool way i'll show in a bit but i just want to show the overall logic first before i do that yeah yep so let's walk through this again so yeah we have all the faces here then we draw the rectangle around the face then we say okay get this little square image instead of the whole frame just get this little square now within this little square use that to detect multiscale so we want instead of looking at frame grayscale we want to actually look at the face okay so let's um uh of course we have to go to grayscale again though for the same reason we have to convert this face because if this was if this was a color image then we would need to change the face to a black and white color image like actually let me show you here this is actually a good uh thing so i said step one okay we want to find faces in our image yep okay then step two get just this so that we don't we don't have to search we don't have to search the whole image instead of searching the whole image we're only going to search within this face so now this is we're doing that because we were getting like random sort of findings outside the face yeah okay yeah we're kind of just eliminating everything outside of the face as automatically no even if it says yes it's going to say no because we know that smiles only show up on faces right okay then step two we find smiles within those faces so we're only going to search within these bounds and then at the end we'll do a nice little labeling that we haven't gotten to yet go ahead but yeah so the idea is the face this is going to be this okay okay so this is so this is frame this is the whole frame this is the face okay okay so we need to get this but it's still color so we need to make this black and white as well just the same as the other image yeah so let's go back and um call or is it let me just copy paste this and change it to face grayscale okay so face gray scale is going to be the face so same idea here we have the face the colored face but now we want to change the black and white so we use the convert color function again okay and we pass in the face the color face we say change it from color to gray okay and save it as face grayscale right okay then now in the small detector now instead of detecting it on the whole grayscale frame let's only run it on the grayscale face go ahead okay yep right there and now now this should be working but the only caveat is this doesn't exist yet properly this doesn't actually work but this is the general idea so once we have um this then we can run the smile detector only on the face there okay and then uh then then we can draw all the rectangles around the smiles within that face after we find the coordinates of smiles so it's actually going to be smiles right i'm with you now they should be a little more clear yeah awesome great so yep find faces draw the rectangles get the little face change the little face to grayscale run smile detector on that little face then draw all the rectangles on that little face go ahead and then and that's how we're gonna get uh this kind of behavior okay awesome so you can see how there's no no red boxes outside of the face it's only within the face yup yup you said yep like a bajillion times on the stream bro i'm kind of confused on so we have the oh okay no i see now because you're doing it on face grayscale and then that's where smiles comes from okay no that makes sense cool got you so you're writing smiles on the face you're not running smiles on the whole frame yeah that's why i was a bit lost yeah so that's there um so this should work in theory right but the thing is uh this doesn't work so how do we do this one little line of code so this is a little tricky i'm gonna have to explain it but it actually is just a one liner can we can actually achieve this but i need to explain how it's done and there's some weird um details that i'm gonna explain um so let's get rid of this okay run smaller sizes with each of those faces because we actually just copied that from over here we just added the underscores at the end so we don't overlap with the variable names uh this remains unchanged you still want to still want to display the current frame and the weight key of one millisecond and then release everything at the end of the auto but how do we do this okay so um we have the frame right we have the overall frame but uh and then we also have the face xywh so how do we get a sub image of um this whole image like if you have a big image like right here you have a big image how do we find this sub image so you can kind of just how do i cut out just that image right yeah cut out that image right um there's there might be like a sub image function opencv but i didn't want to do it that way because i wanted to show you guys this smarter way of doing it or maybe more efficient way it's it's a little bit different so uh do you are you guys familiar with slicing in python i mean if you know the basics of python okay i mean i'm new to python so i even even if you run through that it'd be kind of cool to see you got it yep okay so let's look at this little environment here let me open up a python environment completely separate you start python and this is python2 it's fine though python2 is fine okay um it's the same thing so let's say we have a list okay yep and let's just call it um list let's just call it l okay whatever so we have a list let's call it color of in colors uh i'm trying to think well people yeah yeah yeah yeah colors let's do colors let's just do red blue oh yeah blue green yellow black white that's good okay so we have six six colors here okay this is a good length list okay and let's hit enter uh red oh because it needs to be strings i was just wondering i was like can you do that in python yeah i wanted to see if you could do that yeah nice okay one second yeah little mistake there there we go okay now we have a list of strings colors plural got it yep colors okay there we go so now we have our list okay we have a list called colors and it has all these in here now as you know we can index in two colors with a zero and we would get what sunny you'd get the red absolutely yeah and we can index that one blue get blue and two to get green so on and so forth okay so we can index pretty straightforward in python you can also slice okay so you can get instead of just indexing at the first one or just the second one you can actually get a subset of it you can get like the first three so you could say like from point zero for two points forward from point zero get me like red blue green or something like that exactly we could get like just these two or we could get just these three or we could get just these four um it's called slicing because you can slice up the list into like some some um you can trim it to whatever you want okay so the way you do that is you use a colon okay you put a colon here and then you just put the first and the last so very simple it's so nice and hyphen dude i know man that's why javascript sucks lasting in javascript a little bit more confusing but yeah that makes sense for you yeah that's all it is so what this is saying is for in colors give me the sub list from zero to three so it'll have red which is zero it'll have blue which is one it'll have green which is two and it won't have yellow which is three so it includes the first one but does not include the last one right so it's going to give us element zero element one and element two but not a limit three so zero one and two it should give us this as a list when i hit enter okay red blue green i'm gonna hit it that's exactly what you get okay nice that's how you slice um of course if i what is it so zero one two three four five if i put five it would ignore white so let's try that it would give us everything except for the white but if i put six okay then it would actually which doesn't exist then it should give us all of it or it might break let me see if it breaks no it doesn't so there's a safe check so six goes past here and it'll give you everything up to six because this is five nice um alternatively because this is the maximum list you can just not give it and it'll just say zero to the end of the list oh nice okay and vice versa you could even be like beginning of the list up to four i've seen that in a tutorial somewhere that's nice yeah awesome yep you can just do that so this is like zero this is the same as saying zero to four yeah um it's cool stuff like that uh one more cool thing i want to teach you guys is you can actually be like from zero to six and you can actually add another colon okay and what this is is the stride so if you put two it's going to skip every two so this one this this would actually give us red stride of two instead of if it was straight of one it would give us every one but straight up two will give us red and then skip one then green skip one black so this should give us red green black okay there you go that's insane dude i love that right right that's nice um yeah that's cool so red green black and again if i put a stride of three it would jump in groups of three so it would go red skip skip yellow skip skip nothing it would just be red yellow so let's try this there you go and then again if you did if you did straddle four it would go red skip skip skip black skip and then nothing else so this would just be red black nice boom but guys that's how you do that that's something new even for me like slicing in python so if you guys found that useful what can they do aaron um they can uh send a money request to my uh request to my paypal yeah now you guys can smash the like button uh show us if you guys if your minds are blown just show us um tell us in the comments or if i'm being boring and going over basics um but oh yeah guys i think that's awesome honestly because like i didn't actually know that you could do that in python so awesome to see how you do that nice and we're not even done yet bro we're only halfway there look at this watch this so this is called striding this is called slicing the first colon is slicing the second colon is called striding because you wanted to define your stride okay you can be like if a stride one is the same as not having a stride at all yeah and if you delete it like having like we said it's like having nothing there okay one by default the cool thing is you can also reverse a list by using negative numbers so now instead of going from zero to six you'll go from six to zero and this will actually reverse the whole list no way wait oops um let's try this there we go so now it's reversed what here let me actually explain that so yeah um actually this didn't work i made a mistake there so zero to six yeah um this determines the direction of this of the stride so it's still going to go from index zero which is red to index six or five which is white but it's going in the right direction should you have done you're starting zero zero exactly bro exactly she done six zero because negative means you want to go in the left direction so you want to start from index six um which is really well actually that's incorrect you wanna start from index five because remember the first one is inclusive yeah so you wanna start from index five it'll include it and it'll exclude this last one kodi kodi joshi actually pointed out in the comments nice he goes also that reverses the list nice yeah awesome yep so if you did that then um it'll go through the reason um this isn't going the first one red at the beginning is getting deleted remember blue there's supposed to be a red at the end but it's getting deleted because it doesn't include zero so you could technically put negative one okay and then um okay it doesn't work but i mean i thought it would but if you just like if you just omit it and don't have it there at all then it kind of says like um to go from the beginning all the way to the beginning but don't stop at zero go like one further okay so this is kind of similar to like like when you omit it you just kind of like go to the end when there's not a number there nice so this would be reversing the lip reversing the list i've been talking too much one second that's really powerful that's massively powerful because even in javascript like to reverse a list you can do i mean there are tricks around it but it's it's not as clean as that like that's that's really nice yeah yeah so python makes it nice for like dealing with complex problems which happens a lot in machine learning you want to be able to express these ideas really simply so this looks simple but when you have to do like crazy slicing and like like seven dimensional arrays on like different images of like things things this adds up quickly so it's difficult in python and impossible in javascript so that's why python is the best sunny crossover and if we do a collab with like a reaction that django it's gonna be bickering the whole time this fight like es6 is better than this slicing [Laughter] but yeah so that's that's slicing and striding and using negative strides okay so very very cool there um so we can do that and then of course we can omit uh omit both of them and by default because it's negative it'll just start because it's negative it'll start from the right most spot and go to the left because negative means going to the left so this will also work for reversing a list so this is how you can reverse any list in python with one little line so you have colors yeah and then you have colors at negative one so this and this are reversed got you cool stuff awesome now i'm gonna talk about slicing multidimensional arrays which is what an image is you can actually slice an image by using the same thing and just get a sub multidimensional array from that big array by using the same thing okay so that's why this is relevant so let's say you had um a multimeter right because this this can be kind of hard to explain visually with this example uh okay let's clear let's quit out of this okay clear seller clear and then let's go back into python um let's have a multidimensional array okay yup and let's have one two three four okay yep five six seven eight because this is and one array with three arrays inside of it so far and four okay we've got four right 14 16. so this should be like a um it might be it's going to be kind of hard to do it in here can i could you have like a new line on here i mean if you log in now if you do mra actually let me let me um i kind of want to explain this uh i don't want to i don't want to dirty i don't want to start editing stuff in here because it might get confusing yeah also guys i just wanted to say we just are nearly about to hit 800 likes so massive thank you guys and if you haven't already smash the thumbs up because aaron's about to drop some knowledge on python tricks and tips nice holy crap uh actually let's just try to jump into the code i feel like people probably understand slicing enough at this point to like like translate over the ideas like i don't want to drag on too long because i spent 20 minutes explaining slicing yeah so this is this is the goal we have a frame we have a face in that frame with our coordinates how do we get this as an image of here as a sub image well we can just use slicing with these numbers to slice a portion of this frame which is just a multidimensional array okay and that will actually give us an image instead of just this point because all we have is points and then we're actually drawing a rectangle on it ourself uh up here we're just drawing a rectangle around it but we actually want to get like the full image like all the pixel data of this bounding box okay so the way we do that is instead of doing it this way we actually want to have the face be um a slice so what you want to do is you want to take the frame okay and for a multidimensional array you can actually slice in both dimensions so what we could do is we could be like okay from zero to the end in the x dimension and from zero to the end in the y dimension remember how to slice okay so this will just this will just say get the whole frame this is actually the same thing as representing the whole frame because from zero you're getting every single um you're getting every single uh column and every single row and every single column i'm getting the x and y confused i gotta double check which one is which but we'll try both we'll learn together we're fresh together but uh one is x and one is y and um of course if you had like a 3d threedimensional thing then you could even slice it in three dimensions like if you had a cube and then you want to like find like some subset some cube in there or some rectangle inside there you could also slice that way okay the idea is this zero to the end and zero to the end this will give us the full frame um so you can probably see where i'm going with this uh all we need to do is just utilize these four numbers to actually define the exact frame the exact subframe of the full frame that we want okay yep and so that's really simple i mean all you want to do is just slice so um where do we want to start so from the beginning the top left corner of it is going to be uh x okay and then x plus width okay that's it and then in the y direction we're gonna have y and y plus height that's that's literally it okay so we're going to slice this whole frame and get the sub frame of x x plus w and y y plus h but i'm pretty sure this is backwards i think y needs to come first um i think i just eliminate something so i'm pretty sure y has to come first and then of course if we had a z coordinate as well you would want to do like uh z and then z plus depth or something but we don't have this we're not doing crazy like 3d modeling here we're just doing images but i mean i'm just showing here um that you can do this one thing i do need to point out very very very important is this does actually not work this does not work in vanilla python the reason this does work is because opencv is built on numpy and numpy this works this works in numpy numpy is a library for dealing with numbers and matrices um in python very powerful and it allows you to do cool stuff like this but this is not in vanilla python so that's why in this terminal it wasn't going to work and i didn't want to explain it here because this wouldn't actually work you need to import numpy which is just um numpy like that okay i mean i guess i could have uh defined it here so let me actually show this a little bit uh yeah cause i'm i kinda get it and then there's a little bit of a gap so yeah it'll be handy to go through this yeah yeah um but i think i think it's like a pretty print in in numpy i think it's isn't it oh print f is uh variables uh yeah what is it what is the numpy nice print how to pretty print a numpy array without scientific notation asking if this live will be saved yes this will be available afterwards all of the live streams are available afterwards guys yeah format i mean there might not be a pretty way to print it that's the thing i didn't think there was that's why i can't remember uh yeah i gotta do some some crazy um stuff yeah actually let me just have like is there like a grid of numbers and maybe uh what are we trying to show right now um you wanted to see how how this is getting sliced right yep i think i think maybe we could do it here i think it might be clear on just on the terminal okay the thing is i don't know how to print um okay or let's just try it yeah let's just try it yeah from here so you guys can kind of see like it's not nice and formatted like vertically i was hoping we could like ver because this is a four by four four by four uh um twodimensional matrices yeah because we have a list of length four and each of those there's a list of length fourth in those so it's like a four by four box actually if we layer these on top of each other okay but we can actually slice like i said using the comma and colons somebody said np dot array i'm not sure if np dot array have you heard of that's what it is yeah you just print um np dot l but thank you kodi joshi for that so it says np dot uh array and then open parentheses and then square brackets inside wait what no i know i know i know what he's saying it's coming back to me because i haven't used numpy in a few weeks so i kind of forget it can you type it uh is it in the comments you could do four line in array ah i don't know i don't iterate over it you know yeah i think it's um array.l or something numpy pretty print array i mean we're back here what did he say exactly somebody said import numpy uh or numpy as mp first and then so then you'd end up doing numpy dot array so you could do numpy.org would you numpy the ori oh yeah because yeah you import numpy so numpy or just or just uh no no i think you do numpy dot array and then open parentheses l ah there we go hey thank you guys that's awesome i thought it was pretty print but i mean that's that's the normal yeah all right there we go so this was talking about we have a double double uh twodimensional array here yeah uh four by four so this is easier to visualize what i was trying to do from the beginning yeah oh god guys i think i think he deserves a thumbs up terrible oh we'll hire him have him teach it yeah number three nice um i don't know it wasn't popping up because yeah remember it was something simple with the array but they're like iterating through all the crap i'm like okay i don't want to have to do all that again but anyways uh so here the way we can slice this is you can go by the y dimension then the x dimension so um let's just slice this so let's start with the y dimension let's just get the first two okay okay um so this is the first dimension so what we're doing here is we're getting the first element and the second element so in this over array we're getting the first element which is this list and the second element which is this list okay is that clear yep and now so we we're getting this now what if we wanted to get like this three four and the seven eight as like the the sub sub array of the whole thing then all we want to do is just pop in a um oh i think we are no so the element two oh wait we want to go from element two we're back okay we're back i think i lost you for a second aaron did we we lost the stream for a sec uh i don't know if it was i think it was skype i think it might have just been skype oh it just broke down for a sec yeah all right we're good anyways um so if we have uh the first two elements here um slicing from zero to two one two three four and five six seven eight we're essentially getting these first two the first is like elements because zero up to two but not including two yeah uh now if we want to get this sub array three four seven eight then we're going to need to further uh well actually let's do this subarray two three six seven okay how would we get this out of this whole thing okay well again it's just gonna be a simple slice um but within each of these arrays this is element zero and this is element one so we want to go from element one to element uh two but this isn't included so element three um will give us these two if we say element three right yeah it makes sense sunny yep we're good and this but i think it might be backwards yeah it's backwards so um when you're adding when you're adding uh dimensions to the array you need to actually go in reverse order so it's going to be like this okay so this will give us from these two to these two and then also of these first two rays okay i believe yeah i mean it might might break uh indices do you have questions huh do you have to use the opencv uh opencv is built on nonpartners i mean will they utilize numpy opencv is but you're inside of um you're inside of it yeah that's what screw me up yeah because i need to call the numpy stuff yeah getting turned around over and over still not working um i should have brushed up on my numpy syntax before this i wasn't expecting to show it in here i was just going to show the opencv part uh but all right okay guys let's investigate together so whenever you forget code just you know go to google and and figure it out um how to display numpy uh subreddit i mean it should work i just i don't know why it's not working because it was working in the uh opencv here oh maybe you gotta do uh numpy array well let's let's display the type so this should be a numpy array so let's print the type just make sure that typing is all correct so when we actually somebody said store that in a variable and then use that so i think what we need to do is memory thing yeah how about even you see have it as you had it before it's a number array but i have the square brackets outside the parentheses the score back it's outside the parenthesis uh this is so you know you've got um numpy.al yeah yeah do that and then have the square brackets outside the parentheses outside the parentheses what do you mean the score brackets like did you numpy yeah l and then and then out so outside that bracket so i have l inside the brackets yeah outside the brackets have square brackets so so now on the right so on the right uh put the square brackets and do one three zero two would that work no no so outside the parentheses outside the parentheses yeah oh just index like this directly i think this might actually work no no i was saying so so i have numpy.l yeah and then and then change them print yeah and then get rid of the parentheses just make square brackets oh dang coding in this terminal is terrible yeah no yeah like that maybe that will work yeah hey there we go okay because then you then you're doing it on the object yeah you're getting back yeah but i mean this is also wrong this is uh index you get wrong yeah you get all turned around with these numbers um okay let's let's try the other way around zero and two one and three two three six seven let's see there we go nice all right we finally got it guys so the ordering is um if you wanted to get this sub array then in numpy using raw numpy if you're to do it then you need to use the numpy dot array um get the list so this is um because l is just what is l l l yeah l is just a raw python list okay so we have to convert it to an array here yeah you have to explicitly convert it to an array by using numpy dot array change this and then once it's in numpy form then you can index it like i was saying you can't actually do this on vanilla python yeah so that's where um not enough coffee man i run out of coffee and now and and what we're doing with that indexing is we're saying get the first and second array inside of the the sort uh overall array and then we're saying slice it to get the the the first and second uh first and second in the um y direction so in the y direction you know going top and bottom yeah then we want to get the first and second and then in the x direction you want to go from index one to three so we're getting these two and then from one to three it's going to be these two sunny is also becoming pro in python hey let's go yeah but not not as pro as the guy that was helping me out because i'm just here forgetting about numpy it's been a bit but oh i think we lost aaron again but just treat me he's back this ray i think i lost you for a second aaron we're back we're back oh my god this internet man also just yeah just want to add a comment here so surah rajput says hello there i recently joined pwj community it's awesome and i'm really excited welcome dude i love seeing our own students on the on the streams we can see here so here um this is a casting list this python list okay aaron's internet is being a little janky or is it me i'm not sure if it is connecting uh all right now we have it did it cut the stream no no i don't think it's kind of stream i think it's uh it's okay good yeah so just lagging don't worry let's go let's carry on yeah we'll carry on sunny yep okay okay got it i think it's the shoddy connection yeah i i can't hear you man you can't be there okay cool so like the lag i think there's a huge lag okay oh we've lost we've lost aaron on the stream okay so aaron do you want to share your screen yeah can you hear yeah uh bear with us guys a little bit of an internet moment i'm not sure if y'all or aaron okay i think we're back yeah i've got you now i've got you can you come back sonny yeah all right good good yeah i think there's a internet hiccup there can you hear me oh dude before yeah so can you hear me now yep what was happening what's happening yeah we just got a 50 i think it's mexican dollars super chat from jessica apollina saying i love your streaming i don't have that's a professional experience in python although i'm fond of learning and build my personal projects huge huge thank you jessica that's that's insane we massively appreciate you watching this and yeah like hope keep on enjoying this the content that's that's insane love that especially when we just had some some streaming difficulties but we're we're back we're back nice let's go and coding difficulties yeah like i'm running on three hours of sleep bro this is not yeah why did i do this uh but um what was that saying so yeah here in the numpy i ironed this out so the issue i was making was this is a python list but you got to make sure i'm pilot so you gotta pop into the right function and then from there you can slice in this manner so what i want to make that that parallel here an opencv it's much easier because everything is a numpy array by default like the frame here is this is a numpy array so you can just slice it normally um instead of having to do the whole the whole numpy i don't you don't have to actually make a numpy right yourself okay um but i'll try not to forget that again but yeah so this numpy right and then we slice it like this and again so we're going to do the y direction first and x direction second so this is actually the correct way of doing this back coming back to our application okay so let's delete this out and the sub a frame yeah using uh high uh n dimensional slicing nice okay all right that might be kind of big but there we go yep so opencv built a numpy superpower and uh going forward this should work so let's walk through this again just to touch base again because that was a long ass tangent these streams go on way too long and just want some breakfast don't worry everybody look at all the faces within the frame yeah i can't even see the stream because i'm just in my code but i'm trusting you there's we have like two viewers right two no no no no we're good we got we got about 250 people here dude dope yeah lag is super bad like you reply like six seconds yeah i know but it's okay so just keep going keep going keep going we're good good um all right sonny i don't know if it's a holy crap this internet man really killing uh anyways so let me i'm just going to keep talking and that way it's like so we get the faces we find the the frame we use numpy slicing to get just the face and then we convert just the face to grayscale yep and then once we have just the face of grayscale then we can run the small detector on that little face and then print all the rectangles around those smiles and this out of here god damn it there we go yep we we there yep we're there that's sunny awesome so quit out let's run this one more time and see if it works hey dude there we go got it something something's uh oh yeah yeah i think the x and y is yeah so this is the one last thing i want to say um the area that's happening here is um so we're finding the faces right in front of the faces we're drawing the face uh we're drawing the rectangle around the face okay we're drawing a rectangle around my face that's the first step yep second step is we're getting the face here so we're creating the subarray and then we are searching for the um i mean we're making a great scale and then we're searching for the smiles within that face uh once we get those coordinates those are correct the issue is we're actually drawing the rectangle on the frame instead of on the little face so um the reason reason here is we're getting coordinates so within the face it's a little square right it's a little tiny square yep um when we run smiles on this little tiny square we're getting some coordinates back um in of like from for those smiles does that make sense sunny yep that makes sense so like actually it might be easier to explain here on the uh here so here holy crap here uh we're getting getting the face first and then get the sub image and then and then we want to find the smiles in here so the thing is because this is the sub image the xy point is actually pretty small it's starting from here and we're going to say okay go down this much y and go across this much x this is the top left point and this is the bottom right point and we can draw this the thing the problem is i was actually drawing this rectangle based on these coordinates so this was offset way up here in the left so it was actually taking this um y and this x and drawing it on the big big frame oh actually yeah we actually want to draw it within the little face so how we fix that i mean this actually doesn't matter too much because we're going to get rid of it and show small anyways but it just for additional purposes yeah and so i think it is a game of maya i think it is important some people might want to show that that rectangle you know yeah yeah yeah so we need to do is in smiles when we draw the rectangle instead of drawing it on frame right we actually want to draw it on the face so we take this sub image and we draw it on the face because before here oops when i smile see it's drawing like if you took this if you took this green square and put it in the top left you can kind of see that that's where my face would be my smile go ahead you see yeah yeah so we're just drawing it on the wrong frame right now if we go back here and we quit out uh if we quit out just interrupt that then um we can actually draw it on the face instead so uh this is another thing i want to say so the face is actually just a sub array of frame like i said okay but the thing is when you slice like this i believe you're actually just accessing the actual memory of this full frame so you're not making a copy you're not like saying oh this uh this is a new subarray that's equivalent to like this little range but you're actually saying just get me this portion of memory in this weird slice because you have direct access to the memory like that with numpy okay so if i change this data within here if i change the data of the frame within here then it'll actually change it on the mainframe as well because we're just saying okay this little slice of the whole frame um this editing this in here will also edit this which means editing the face will still edit the frame so we can still we can draw on the face which will work uh if you draw on the face then it'll actually also draw on the on the the master frame okay even though we're not drawing on the frame so that's that's how that works there because when you when opencv draws a rectangle it's actually just going into the the memory and just like changing the memory there there you yep so now let's try one more time and oh hey hello hey with that said guys we just hit over 850 likes just push that to 900 and if you found that cool and aaron and aaron guys aaron just debugged everything in front of you so i think he deserves a smasher thumbs up and just some just some numpy nightmare man yeah syntax numpy nightmare exactly that's the one thing i hate about numpy i wish they had i wish they had some nice like easier syntax to but it's all like function based that's the one downside but i know i mean numpy is awesome yeah and you used a lot you fixed it exactly so that's the main thing thanks thanks uh with help from the community yeah shout out shout out to whoever that was i couldn't find it on google and i was like ah i give up not important but anyways uh from here um now though but i mean this is cool but i mean this is kind of just like the same as face detection or car pedestrian tracking but it's like outlining it but i think it'd be more cool if it like just detected that i was smiling and put the word smiling underneath but i think it'd be more cool if it like just detected that i was smiling and put the word smiling underneath because you're only concerned with smiles if it's like a face you're like oh this face is smiling or this face is not smiling yeah so i think it's cool to um do that instead so let's do that next nice let's quit out of here and the very last thing we're going to do is instead of drawing this okay instead of drawing the rectangles around the smiles at all we're not even going to do that we're just going to completely ignore drawing the rectangles um i mean it was relevant because i wanted to show you the cool little like offset thing how the memory is actually being being saved here when you slice it's the same exact memory so it goes into the same memory and changes it um but i do want to show you how to put some text so i don't i want to avoid another syntax mistake though i'm the master copy paster uh yeah i think it was massively valuable to show them how to draw the actual smile because then it gives them context as to what we're gonna do next yeah yeah so i got rid of drawing the smile because i don't want that there but now i pasted this ugly looking thing here so what this is is now instead of drawing the rectangle around the smile i want to actually draw um the word smile uh i mean write the word smile smiling okay i have it right here smiling underneath the little um portion so like when i go here you can see smiling pops up for a few seconds that's that's what we're going to be doing now instead of having the right i think you're going to have an error because you said if smile length if length of smile so go back to the code is it meant to be plural if length of smiles because you've done smiles array um yeah i think so yeah so length of smiles is greater than zero yeah nice yeah because uh let me just double check yeah because down here i think i used um yeah yeah you smiled singular yeah so yep uh so yep so pretty much all i'm gonna say is if length of smiles is greater than zero because remember smiles is a list of all smiles it found within the face if it's greater than zero which means there's one or more smiles then we're just gonna put some text on the screen so this is very simple this whole thing here is just displaying the word smile at some coordinate so similar to a rectangle it's cv opencv.put text we're going to put text on the frame okay and that's the first thing the image the second argument is going to be the words you actually want to put so i'm going to just going to put smiling yeah or you can put like why so serious or something okay and then next is next is the location the top left point of where you want to display the text so in my case since i want to put the word smiling just outside the the green box of the whole face i'm going to use the green box coordinates okay okay so i want to put it below it so the x coordinate will be the same um but the y coordinate will be y coordinate plus the height right so i'm just going to actually draw this as you do it on the screen yeah because i think it might be handy so carry on talking over and i'll draw like as we do it i have it here if you want to yeah we can explain it here yeah let's do that yeah so um we have the coordinates so we know this this picture is smiling but we also but we want to put the word smiling down here instead of having this we want to have this yep so if we have um we know this is a yes so we know to display smiling then but how do we get the coordinates of this so we have the coordinates of the whole face which is what we want so why don't we just have the use this top left point to figure out how to get down here so we have the top left point which is x so we can just say at x is where you want the top left point of the text to start at x yep but then the y point we don't want it to start here because it would say smiling up here so we add um y this is y yeah plus h plus the height right so y and then we're saying plus the height which is this so like y which is going to be right here yeah and then i added and then i added 40 just to have a little bit so it's not touching the box i just added a little bit and then that's it so this is this point is going to be x and then y plus h plus a little bit more right so you guys that'll put it right here exactly we have x and y in the corner uh just go back to that that side for a second uh so we've got x and y in the corner and then we go we've got we're doing y plus the height and that gets us to the bottom of the box and then you see aaron's got smiling exactly but if he didn't add the 40 it would be sitting on top of the green right now or like oh yeah pretty much on top of it so it would just be touching yeah so we want to add 40 to basically get push it past that little bit extra so yeah awesome nice yup and that's really it guys so as you can see that's gonna be the x is the same and then y plus h plus 40 is right there so that's the top left point where the text is going to start then from there font scale is just the size of the font so size three um and then the font face is just the font you want to use so um opencv has different fonts so that font is called font underscore hershey underscore plane it's the one that looked the nicest you're kind of limited on the fonts but i mean it gets the job done and then last is the color so vgr again but all three are maxed out so this will be white because if all three channels are at maximum brightness 255 then it'll just be white nice so if we run this hopefully with no hiccups no before you run it before you run it we actually just got a superchat from velocity trading he says my girlfriend introduced me to your videos she has a data scientist in nvidia and she loves your content on react yeah shout out to her princy thing that's amazing nice sonny yeah thank you yeah and look at that how crazy is that it's like two worlds came together react yes now we're talking about data scientists where the majority of data scientists code with python so yeah this is this is dope it's awesome yeah you should do a collab with her like a reactive data science project yeah but nice awesome awesome people are showing sonny the love the hulk you get a you should like you should demand people in the comments call you the hulk anybody who wants to cause honey by the hulk pop that in the comments right now going forward we'll legally change his name to the hulk because he can handle anything except standing we have papa react we have was it the react god now we have the hulk the react called god that's just hulk just talk the british proper hulk um but where were we so yeah so we're gonna we're gonna draw smiles underneath the face instead of actually drawing the box well let's put both for now just for demonstration purposes nice let's run this there we go hey nice that's awesome dude yeah it looks a bit like that horror game you know that that slender man that's what the text looks like yeah yeah oh the slenderman text yeah the smiling i mean that's awesome dude and then now if we just get rid of the if we get rid of the um drawing on the rectangles then it should work nice guys if you find that cool because it is it's like look at this look if now we should see no rectangle but we should see the smiling which means that we have that finished sort of hey look at that that's that's that's nice dude that's awesome and even if we have two faces on there because we have that loop it will actually go ahead and do it for a second face as well right i will yeah so let's uh let me just get guys i wish there was a way to get your face on the screen too but the stream tag kind of limits that but yeah let's go ahead and see it wait look at that nice that is awesome guys if you think that's cool smash the thumbs up button that is awesome and if you haven't already and you are following me and aaron on instagram go ahead and shoot us a story right now so this is my tag and this is aaron's tag right over here so my tag is over here aaron you just point somewhere down there you'll see it uh yeah so go ahead and shoot a story and um yeah tag us in there and let us know that you're watching and yeah you guys can we can have a chat with you guys if you found that cool i think that yeah like it's so impressive like how many lines of code was it in total oh even when you zoom in look at that and guys that's a really good example bro because they're showing the actual dynamic width and height changing yeah yeah that's awesome all the wheels man cool 900 likes as well guys that is insane thank you guys but yeah guys that's pretty much the completed app um there's other things you could probably do to clean up the code you could probably pop some of this stuff in a function you know i just kind of blobbed it all in one go um so not very good code design here uh but other than that yeah i mean we went over the using the face detectors and small detectors using xml files which are pretrained if you want to learn how these actually work then you can watch the other streams for the actual algorithm um of how that works uh we captured the the webcam footage we're iterating um forever until we're done with the webcam footage we're reading every frame one by one and then for the current frame we are doing a quick check to make sure the frame is good to go then from the frame we're creating the green the frame grayscale so that we can optimize it and we can um speed up the process and the calculations uh once we have a grayscale frame then we find faces within that frame then from all the faces we want to actually draw the rectangle around each face nice and then from each face you want to create the subarray using the numpy slicing here the the um which is numpy under the hood so we got the little sub right here which is the same um data in memory as the regular frame so when we edit this little subreddit it's still going to edit the mainframe yep the mainframe then then we change the face to grayscale um so we can run small detection on the face and then from there um uh once we have that then we can just label it as hey we found a smile instead of drawing the rectangles right so remember guys what we did that nested approach for when we were drawing uh where did that happen again aaron so where we avoided doing it for everything we did it for just the smiles it was line 38 right yeah yep nice that's so cool and then you put the text there and then um at the end then once we have once we have the once we found the face drew the rectangle found the smiles wrote the word smiling once we've done all that and we've edited the complete frame and all the the correct rectangles and words are on the frame at the right locations at the very end of all that at the end of the end of the detection we uh use cv2.imageshow just to show the frame and then we wait for one millisecond and then we repeat to the second frame so all of that's happening every single frame all of this code dude it's insane like if you actually think about it like let's say we went ahead and got rid of the comments and we got rid of everything that's so little code to get that powerful functionality happening right so let's actually do that yeah so let's make this super optimal nice yeah guys drop in the comments how many lines of code you think this might be if we can if we can do that before aaron gets to the top i'm gonna say maybe like 30 i'd say maybe i think it'll be that around there this is insane though like if you used to do this kind of thing in like javascript you would have to write more and i'm a big fan of javascript but i will say it first time like in python you can get a lot of power out of this uh we're just having small amount of code so that's that's still oh again but okay we're near 30. anybody anybody want to put money down dude 22 bro i mean this doesn't even count this doesn't even count holy crap that's insane and actually this because it's just a break statement you could probably get away with doing this i mean probably not good but i'm cheating because i just fall off that's insane we have machine learning ai everything invoked in there at like 22 21 lines of code so yeah oh my god was close he said that 25 abbas abdelius of 32 young ipsex guys it's less than we all thought like somebody wrote one i don't think we could do one i mean just pop this in a function you know just oh yeah section it's fine that's insane i love that dude that's so so cool man like um yeah that's awesome and guys i think this also goes to show you yeah there you go that's that's the hack to everything guys one line nice i'm doing it bro i'm doing it one second just for that guy because i got nothing better to do with my life i see a lot of people saying like this is like calling uh the ha cascade ai isn't really ai guys anything you have when you have a classification model that is current that comes under ai and trust it take it from a guy who's done a masters in this stuff like it is a like that is that is what we classify yeah if you want to if you want to go see how these are actually generated because we did just download this and just used it but if you want to actually see how you create this like how you can train anything to like like recognize what pepsi cans recognize uh coffee mugs whatever you want then i explained that in the face detection video this is like an extension using smiles but i explained that in face detection and the car and pedestrian tracking of like actually how the algorithm actually how the computer actually learns this like how the hell does the computer take an image and know how does the brain like how does it use its brain to figure out what it is so i i explained that there um but it is ai because this is how computers can learn it's not just random stuff yeah and that's the powerful thing guys like once you have trained models and like a lot of people i think even in firebase there's a bunch of like uh trained models that you just have access to which i'll be dropping some videos on so thumbs up if you if you're excited for that but um yeah like you can pretty much go ahead and use pre guys to train a model from by yourself you need to take a long time yeah you need a massive amount of data that's why things like tesla everything gets better over time because you get more data over time which means the model can get more accurate yes like it's not super feasible for us to train our own um if you understand how the algorithm works and then you utilize it that's really all you need to know to innovate we could technically i could technically go and take fake like get faces from the internet a bunch of different faces a bunch of different smiles and find those pictures and trim them all myself get the data set and then run it through some some training software to do it but then even that that's just an extra step of just taking images plugging into this this thing and then going up if you actually want to code up this algorithm that gets pretty deep and nasty i did it i did that at my schooling at georgia tech um it's interesting and fascinating but it's a big headache so like why reinvent the wheel so we're doing that here but if you want to get down in the nittygritty then uh by all means go through it there's a there's a free computer vision course from georgia tech on udacity you can look it up it's called computer vision they talk about all this stuff in complete detail they talk about other object tracking like common filters and uh cnns which are convolutional neural networks which is another way to do like tracking and object detection um but har cascade is just the simplest way that i'm showing you because you just download this one file and then you pop it into opencv and it's all nice and free and easy to use but yeah if you do want to get deep in you don't do like legit ai this is just this is like baby stuff compared to real stuff like even me i haven't done too much i haven't worked at tesla on selfdriving cars unfortunately i wish i have but um you can get some you can get go pretty deep so if you want to check that out then by all means go check out opencv the opencv course and uh feel free to just go ham yeah for those of you who are javascript developers you can use something like tensorflow tensorflow is pretty much a very similar thing to what we use here but it's not cv2 it'll be tensorflow and then you can actually go ahead and get models just like the hard cascade um and you pretty much plug them into your tensorflow and do the same thing as what we did today so what i challenge everyone on this stream right now to go and do is actually go ahead and like follow along this tutorial build your get it working on yourself but go ahead and swap the um the hard cascade one that you're using and try and detect like an eye or something like that that'd be kind of cool yeah try and detect like an eye or something like that that'd be kind of cool yeah yeah yeah there's there's literally an i one like if you just the google it the opencv documentation or the github github repo there's the i1 where you can detect eyes as well um we could even do it really quickly why don't we just do it on the fly really quick as a bonus i'm supposed to be done here but let's uh let's do it because i actually have because i have it downloaded already the eye because i was going to do that but i was like it's not important for small detection but let's do it really quick okay what time is it it's 41 okay i'm gonna how fast can we do this let's do it all right boom i dot xml uh in the comments right now let him let's get let's get him let's get him in that flow state uh eye detector so we're gonna want to get is okay so the face we have the face face grayscale smiles smile detector eyes is going to be um eyes will be eye detector dot detect multi scale face gray scale and uh skill factor i don't i didn't tune the eyes so like it might not work but um yeah we'll just we'll see how it goes so eyes equals that yep then we're going to want to draw the smiles and then also we're going to want to draw the eyes and eyes yeah why don't we just go double this is very sloppy but i mean i just well actually i can just use this because the for loops aren't overlapping so let's just leave it like this yeah and then um the i okay and let's just change this to 255 25 and 255 in eyes grayscale so this should work nice i mean it should let's see if it works guys if it works destroy that thumbs up button because aaron just done that on the fly like oh the eye is not defined i have a typo somewhere oh i was going to say that yeah because you have the eye but we need to splice it or slice it sorry right oh oh um nope i mean the face okay that's what it takes oh snap dude mouths and eyes look kind of similar sometimes you know you can kind of see yeah let's try to tune it we gotta tune it a little bit let's tune the variables a little bit and see if we can get it working better so that's what that's where these two things come in handy scale factor in mid neighbors so i'm there's probably some ideal number let's just try like i don't know 1.3 and 10 and see what happens okay like some iron man video okay okay not quite not quite let's try 1.1 and 10. oh again that dude so what what what was the phone oh i just need to i just because i'm asian but if i open my eyes big it works it's not creepy as hell but like big eyes big smile then it can get it it can get it nicely that is awesome the greatest ever let's get this to 1k likes everyone i think we do yeah this this kind of stuff this kind of stuff is what snapchat instagram use on their filters you know like when you like vomit the rainbow and stuff they're like ah and then when they see it they can locate it and have it like drip down stuff like that so this is actually what's going on behind the scenes when using a snapchat filter like the selfie camera and you know you have like the crazy filters over your face this is what it's doing behind the scenes it might be using convolutional neural networks instead of hard cascades but this is similar principles yeah they would have a model that's already sitting there that's already ready and it's just the input would be the camera that you're saying output being that little tongue emoji or like the dog thing whatever you're using yeah nice yep that's it and about what that took four minutes to get the eye up and running so it's the power of python and having pretrained of course if you train yourself it's gonna take hours or days or weeks if you have to get your own data it depends where you did it if you're taking your own photos with your own phone you gotta it's gonna take forever or you can just what people have done you got some you got some good comments coming in and says aaron you are awesome aaron apparently not at numpy whoever in the comments i don't know who you were but thanks man you saved you saved my ass man or man or woman whoever that was much appreciated i could stop embarrassing myself the greatest ever says that's amazing information i'm going to squeeze that in when i'm being interviewed that's that's awesome dude that would impress them yeah i will impress this is the real smile look look at that it's so funny that was nice we could we could even be like we could even like have a diamond changing like smiling and wideeyed like or unasianified or something you know you could be like smiling and have like another piece of text like unasianified underneath let's do that dude you know what you could do i reckon there's probably some kind of model there which tells you the ethnicity of someone and then you have the sensitivities based on ethnicity oh that'll be it'll be hilarious but let's just here let's just look at this code if length of eyes i mean is that racial profiling is that like racist no i mean i mean we've got one we've got one asian we've got one brown asian fried let's just do so literally the greatest ever just said unasianified there we go here let's try this right aaron you're a good teacher i like it nice oh wait uh i think we need to tune this a little bit better to eyes needs to be maybe 20. let's try this and this is way too much let's try 90 and quit this out here [Laughter] i love that that's i think we gotta tune a little bit more let's try uh let's try 30. bro i'm still there i'm supposed to go work out my friend but that's what was probably 20 minutes ago but this the numpy thing you know i really put a cog but whatever oh man oh wow tyler shaw says that's the most amazing live video of programming ever we love that dude that's insane that's furious with my eyes bro and look at the light on my face better so funny i'm having so much fun with this man i wish i could uh send it to you but yeah i do gotta get going no dude you've crushed that and you we didn't even plan on getting the eyes done so we got the eyes in there i mean yeah that's the power of pretrained models they also have like dog and cat let me just pull up the open cv real quick where did my chrome go oh it's in full screen so if you just go to opencv um har github then you go here hard cascades they have all these pretrained opencv is like open source so it's free and low weight uh the algorithms and stuff they use at facebook and snapchat like in instagram for real they're trained even better than these are that's why they're so much more accurate these are just kind of like halfway there but they're also like pretty old but here here's the eye um i tree eyeglasses i don't even know what this is uh this is the frontal face default we're using for frontal face there's other frontal faces see how much is frontal cat face uh full body this is what used for the pedestrian tracking um for cars i had to download a heart xml file from somebody else it wasn't provided by opencv but you can go you can find other trained models too like is once an xml file is created from any object section then you can just download and use it for yourself so like here uh like this is literally what i typed in there har car has hard cascade xml file i went here i clicked on it and then i um i literally just downloaded the xml file uh from some it's somewhere linked in here but you can find the xml file once you find it so like literally it could be anything it could be like like what else what else besides car is cool to identify um um our cascade file uh i mean that one might not exist but i mean here soccer ball cascade so use yeah there soccer ball cascade.xml and then so this could probably detect soccer balls in a video without a video or something like that so like it's generic object detection you can you can detect any object um any arbitrary pattern yeah you know in a in a frame so that's the power of that using using my aaron just showed you that you can easily detect like some balls you know like are your your balls round like a soccer ball or are they are they excited like a rugby or football yeah but here there's hard cascades there's also some here there's hog cascades so hog stands for hog is like another way to do it it's like optimization for horror or some something i forget what it stands for but it's another objection algorithm thing that you can use um but here we have all these and then there's cats and uh or if you go into hog what is in here pedestrians okay but yeah guys that's that's it smile detection and asian detection asian asian person detection in um in python awesome guys if you guys enjoyed that let's give aaron a massive thank you because i think he crushed it today with that and even i learned so much with this uh tutorial today so like i thought it was cool thank you aaron that was amazing dude welcome sonny thanks for streaming for me because my computer's a computer is a rock sorob singh says aaron and sunny looking for some more in the future cheers yeah we would definitely be doing more that was fun definitely yeah i am planning on doing some tensorflow because i've kind of exhausted this open cv stuff we got three streams on it but i do want to get into tensorflow and maybe even pi torch yeah um like something mentioned so maybe in the next few weeks stay tuned for that i might have like a tensorflow like crash course stream or something like that yeah they will actually train a model ourself with uh with somebody else's picture data i'm not gonna do it myself yeah but i'll find some online data set of a bunch of images and we can maybe train something and you can watch the neural net get created and then we could do something like this again that would be dope dude that'd be awesome yeah i think um also worth mentioning guys for anyone who joined and maybe missed this in the beginning what's lingering in the description right now yeah so yeah yeah if you guys like coding in python if you enjoyed this and want to do this for a living then that's what we do a clever programmer so we teach people how to take their coding skills and make money from it as uh web developers with javascript as python developers python freelancers whatever it is you want like automating stuff with python or whatever then go check the link in the description there's a free training that teaches you how to do that uh and then there's also a fullblown course that you can join if you want to invest some money into that in time and actually uh pursue becoming a python developer as your career choice if not then feel free to enjoy your free content that's what this is here for and you know make asian stupid stupidass apps like this [Laughter] my mom would smack me yo respect your culture okay i love you mom you eating the [Laughter] then ah yeah that's the truth isn't it yeah we're all dropouts here aren't we that's awesome dude i think if there's aaron got any last few things you want to add oh we also got a donation thank you saurabh singh just dropped a nice little donation there appreciate that dude and lots of wicked comments coming in yeah nice i think the last thing with hilarious would be uh actually get rid of the boxes what was that and then um it would be hilarious get rid of the boxes you just have like the full clean app let's do this last demo because i'm i'm all hyped what's that hey let me go ahead and try it on that there we go i think i think it's okay when you when you're you're the same race it's all good half audition if i uh anyways okay i'm gonna stop goofing around because now we're just wasting time all right yeah so if you guys wanna check out the the free training or the course then it's in the description um if not then keep watching our daily streams i think we've been going for what like four weeks now straight i think it's longer dude i think we've gone over a month and a half now yeah how have we not run out of like project ideas dude we have so many project ideas now still to come like tomorrow's a big build another massive build coming up so we'll be amazing what's that yeah yeah we have what's up tomorrow stay tuned guys go ahead and literally set a reminder on your phone right now for that and we're doing that was it in i think it's 9 15 est and 6 15 bst that's my time yeah uh yeah so awesome guys hope you guys enjoyed that and with that said uh make sure if you're not following us already go ahead and check us out we always posting some content so you've got me and aaron over there and we'd love to have a chat with you guys but yeah i think i think aaron needs to go and hit uh hit a workout yeah eat some food more coffee totally sleep deprived but yeah guys thanks for joining me in sunny and coating this up there's a lot of fun and uh we'll do it again featuring some time right hulk that's it dude we'll do it again samurai yeah yeah yeah what time all right guys peace out peace out guys thank you so today we're going to be coding up a image classifier app in tensorflow and we're going to be extending a little bit from last week and uh we're going to be building a slightly more advanced uh a slightly more complicated neural network here and we're actually going to be using tensorflow to be able to classify different images so i'm i have this data set here uh that has a bunch of different images of different kind of clothing pieces so shoes and shirts and bags and stuff i'll show you guys a little bit more in a bit but the idea is that we just want to train our neural net on a bunch of these little pixelated images of different clothing types and then eventually be able to recognize these images and classify them correctly uh going forward on on new unseen data so that's kind of what we're good what we're going to be doing today okay let me see if i can find some other other data in here too let me close this i want to show you guys a couple of the pictures i think there is a there was a link i found but i i lost it that had like a better okay here we go so this worked fine so this is another uh image that we're gonna be using so this one kind of looks like a shirt as you guys can probably see and um this data set is actually really big it's actually built into tensorflow because it's kind of like the introductory data set that people can use for image classification so let me look at a couple more and see if um there's a few that we can look at together okay so this one kind of looks like address i guess and let me just keep going through the data a couple more yeah another address here and i think you guys are getting the idea so this basically there's just a bunch of images there's like 70 000 images of different um clothing pieces and what we're going to be doing is we're actually going to be training our null net on about 60 000 of 60 000 of those images and uh properly classifying and training the neural net and then on the remaining 10 000 images we're going to want to actually use that as our test data to see how accurate our our neural net is all right awesome so let's uh get back to the code so yeah i showed you guys a bunch of those images so the idea um is we're going to code up a neural network and um i'm going to kind of like go step by step of how we would solve this problem so the the thing we're trying to achieve is we have 70 000 images of different clothing pieces like we have and there's actually ten different types if i go back to the documentation here um there's ten different types of clothing here and they're just labeled zero zero through nine just for simplicity so as you can see like the first one was an ankle boot like let me go back uh to this and let's just show the first one again and print this out as you can see here this kind looks like an ankle boot or a shoe but i guess they call it ankle boot and uh the label is nine so actually let me show you the the label too just so you guys can get a little bit familiar with the data uh there we go so labels add zero so yeah so um i pulled this data or let me actually show you guys um i should show you guys this in a second let me just show you the label so here i'm actually printing out the label for the for the first image here which is a zero and then this is the shoe like i i just showed you guys but when i print it out it'll actually give us the label as well so i'm going to be quit out of this and run this and as you can see so this is a shoe and it actually print out the label of nine and if we go back to the data here you can see that nine uh corresponds to ankle boots so pretty simple there's 70 000 of these images of different things and then each of them has a label attached to it so we'll be using this data to train our neural network and then uh we'll be using another subset of this data to actually test our network to see how accurate it is and uh it's uh pretty good yeah as you can see here so the fashion this is called the fashion mnist data set um mnist is this thing i actually don't know what it stands for but i mean there's a lot of like pretrained and prelabeled data sets that mnist uh provides for us there's like uh there's like handwriting ones and and other stuff so um this one just happens to be like a bunch of fashion stuff uh and yeah as we said here i just mentioned this we're going to be using 60 000 um images grayscale images of different different clothing pieces and then we'll use the remaining 10 000 for for testing so uh now let's just jump into the code and let me start explaining these uh each line one by one so you guys can can follow along and everything will make sense any questions up to this point or is everybody uh following the law following along perfect what is this uh thing i have heard a lot about it like what this is karis is like uh okay let me just spend a quick second on this it's basically like a or let's just go to the actual documentation so it's just like a library that allows you to like build neural nets so um tensorflow itself like is like a wrapper or it utilizes keras because kerose allows you to like make like um graphs in different structures like graph structures so it's perfect for neural nets and you can look into it if you want the idea is though that just tensorflow is just built on top of keras like it utilizes terrace uh keras to build the neural nets and all the other graphs so and like you can also think of it like a neural network you know the basis neural networks and on top of that machine learning spirit right so machine learning is actually like so in neural network a part of machine learning and karaoke allows us to do that yeah that's a good way to explain it yeah so keras is good for creating neural networks but then tensorflow is actually good for pumping data through that to actually achieve machine learning and like solve machine learning problems but keras is just for building the structure like the data structure and defining that and then tensorflow on top of that allows you to like oh train and import data and pump the data through and do all the number crunching does that make sense from zero yeah i think that i think so this is basically that guys yeah all right so let's just start going through all the code here so that you guys can follow along and then i'll answer any questions as we go but this one's going to be a little more interesting than last week so uh let's just start one by one so this stuff up here you guys can actually pretty much ignore this i was running into some downloading errors when i was trying to download the data i just had to do some permission stuff so just completely ignore this um the proper way to do it is to actually uh install a different package on your computer but i just pop this this hacky thing in the code so just ignore it i'm just gonna not even show it um so let's start here we just go one by one and uh of course we want to import tensorflow uh that's the first thing we're going to want to do and then also import keras because we're going to need both and also done pi because numpy is how we are going to be dealing with all of our data so actually uh like this here this is actually just a numpy array so this image is um a 28 by 28 grid of grayscale images and um it's actually stored as a numpy array so we need numpy to uh to hold this data and then we're just going to be pumping it into our donet so that's what we need numpy here and then also we need uh matplop just uh uh map flop is just to display the images so that's why i'm displaying it here um so you guys can kind of just ignore that it's just for for visualization purposes so this is where the code actually starts um so the first thing we're going to do for any kind of machine learning thing is we're going to need a bunch of data so unfortunately for us they have this all of this labeled data like with the shirts and shoes and stuff already preinstalled in tensorflow for us so it's as simple as just downloading it here and just accessing the builtin data set which is nice um in the real world if you're trying to collect your own data which sometimes happens sometimes like if you're working on a team like i did this um at my i had a machine learning artificial intelligence paid internship thing where they actually went and would uh like capture their own data and you'd have to like label it yourself and it was kind of annoying um so i mean i guess you do have to do it in the field if you are if you are going to be doing that in the future but ideally you just have the data already labeled and somebody already did it for you um so that's what we have here a bunch of the data here so i'm just gonna get handle here to that data set and um you just do that by calling cara so within keras we have the the fashion mnist which is what i was just looking at in the documentation here um wherever it went i don't know where it went uh keras fashion feminist there we go so like i said keras has like these data sets built in so i just basically call this code so fashion.mnis.loaddata is what i called here um or actually i call it down here but this is uh this this is just like saving um the the handle to the data but down here uh you can just call fashionmnis.loaddata just like it says in the documentation here and we get the data in so this might differ if you're using a different dataset but for this dataset this is how we're getting it and the way this is returned is by default it returns um 60 000 of the images here for training and then the remaining 10 000 of the images here for testing so now we have these these four variables here that we can use for uh training and data so these are just simply just lists of a bunch of different images and whatnot this is actually how i was displaying all of the images so right here i'm displaying uh the first element of the training images which is actually this boot image that we see so uh very straightforward so if i index train images at zero then it just spits out this numpy array and then i just use uh matplotlib to display it so you can see that and then i showed you guys the dresses and stuff i like the first index and second index and it goes all the way up to 60 000. so uh that's how the data is structured so all you guys gotta remember really is just that these four these four variables here is how we're going to access our data so and then these are just lists of numpy arrays or images and and that's that's all it is this here is just for printing so we don't have to worry about this too much this is just using some matplotlib i'll actually show you guys this this is kind of interesting because you can even see the actual data in the terminal if i quit out of here oops there we go so what i'm doing here is i i get the data like i said i have the 60 000 uh images and labels here and then the 10 000 images and labels here and all i'm doing is i'm printing out the label and then the actual image in the terminal so if you look in the terminal you can actually see like the the the data here so this is the actual image that we're seeing of the shoe but i mean of course it doesn't look like a shoe in here because it's just a bunch of numbers but um it's just a black and white image so on the range from 0 to 255 is the uh range of numbers um that they can be it's just kind of like the brightness of each pixel but then that's reflected here so i'm just using matplotlib to show that and that's through the image shown in the show here so uh any questions up to this point is that is that pretty clear cut for everybody or does anybody have any questions is that just for one image yes yeah just for one image so we can actually get rid of this because i don't want to print it in the terminal and like clutter it but all that's happening here is i'm using uh matplotlib i just renamed it to plot for simplicity and then you call image show and then you just pop in whatever numpy array you want um and then this is just for uh making sure that it's it's a gray scale so you just kind of say like yeah it's the color map is gray scale and then min and max values is that um you have to specify those and then you just show it and then that's how the uh this image shows was that you tom was that it sounded like tom yeah it was yeah so i'm not well sweet i'm staying on mute oh goodness hold up make sure you drink some water and get some food in your something it's not the corona is it or that no no i had to get my kid tested it came back negative but it's just fluid yeah we all got tested here too at uh all the guys here clever programmer because we all kind of live together or work together on a daily basis and then we're all negative so that's positive sign because i know los angeles is kind of kind of iffy what is your is that the 28 by 28 that's the matrix matrices uh matrix that the 70 000 of 28 by 28 yeah so uh if i go back to this data set then uh this predefined data set in keras is yeah a bunch of 28 by 28 grayscale images of different fashion categories so like shoes or dresses and stuff that i showed you guys before so uh we keep it small just because there's so many and um if it's recognizable by a human by the eye then it's prob then it's are arguably recognizable to uh to a computer like if you if it's like if it was like two by two then yeah then you can't you wouldn't go to recognize it but 20 by 28 is like as small as they could get uh reasonably by still being recognizable as these different things what you printed out was because it didn't have 28 columns so what was the mapping of what you printed out again um you mean this or the actual the image when i produce that whatever that's showing yeah that 28 by 28 is that what that's representing well yeah this should be i mean it should be is it not 28 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 3 45 seconds yeah 20 so it is 28 so this is 28 long this is the first row and then this is the second row and then it just now it's just the formatting is kind of crappy that's why because i was dealing with it from the top only i didn't i didn't follow the uh ending yeah so this is just a twodimensional numpy array so this is the outer wrapper and then each of these are the rows right and then yeah as you can see so like this is all zeros so like there's nothing on the top and then when we actually run it then you can see yeah that the whole top row is completely black which is what zero stands for because those pixels are off so the first row is all black the first row is all black there awesome so that's the data we're going to be dealing with and now we can actually jump into creating a neural net for it so let me just go line by line there we go so like last week uh we're going to be creating a very similar the the code is going to be very similar but the neural nets is actually going to be uh a lot more complicated but that's what's nice about tensorflow because it you're able to create really really complex neural nets and the code is is pretty concise and straightforward like it never gets too advanced and that's that's a really good thing so uh let me do a little recap too just so for anybody who doesn't remember let me annotate uh i think red is good okay can you guys see you guys can see me i'm annotating right yes all right cool so let's just have like a a sample neural net here so anybody who doesn't know what a neurologist it's just like a a bunch of different layers of nodes and they call them like neurons and then um they're all they're all connected so let me just draw this out really quick and there we go so um oh it's kind of covering the code here let me put out can you guys see down here this code down here so line 28 it says model um so the first thing we want to do when we're we have a machine learning problem or something like in tensorflow is you want to design our model in a way that will be compatible with our input data and also our output data so in this case for anybody who doesn't know a model is just a a neural net so this here is the example of a neural net that has three uh three layers so one input layer here with three three nodes um and then one hidden layer with four nodes and then one output layer with two nodes uh so this is kind of like a model that that um i just dropped here r is gonna look a little bit different but i just want to visually represent it here so um in keras like we we established earlier keras allows us to um define different uh graph structures so it's really good for for this purpose and um so that's we're utilizing keras here so keras uh there's a thing called sequential we were this last week and this just means that there's a sequence of horizon a vertical vertical columns like this of different layers and then they go in a row so um this this column of nodes can only connect to the next one and so forth you can't like skip and hop over so this is like the most um basic type so sequential is the first one we want to do and um we're gonna make this a sequential neural net so from there all we need to do is just within this list is just define all of the different layers that we have so let me get rid of this drawing real quick clear all drawings okay so um the sequential so for the first thing we want to do when we're dealing with a uh machine learning problem or or for for an old nets is we want to make sure that the input and the output is correct so for the first one remember let me just show you guys the first one the first layer um so the first the first layer that we're going to want to have in our neural net is going to be the input layer and as we know the data that we're dealing with is going to be a 28 by 28 um image and those are the the the data we're going to be pumping in so the way i shouldn't deleted that neural net you see i'll just make a little bit simpler so i'm not going to draw the lines just because it's it's kind of long but something like that so um the idea is uh for our input we want to have a 28 by 20 input for um our input here a 28 by 28 matrix and uh what we want to do is we actually want to flatten that out into one long layer so the input layer actually each node is going to have one pixel um so that of of each of those images so that we can um pump in the the full data all the way across and then from there the data will filter through and eventually at the end will spit out be like okay is this a is this a boot is this a dress is this a shirt um and that's that's the overarching idea so um the first the the first thing we're going to want to do is yeah just make sure the first layer is compatible with our input so again we just we just call this here so it takes in a 28 by 28 image um and we actually want to flatten this so uh like i said each layer of the neural net is just one long vertical column of our our data and um so we want to make sure that we flatten this 28 by 28 thing into one flat one flat layer and then i think it comes out to 784 28 times 28 yeah 784 so let me actually just copy this code out or the comments um yeah i wrote here so the flatten the flatten here just flattens this 28 by 20 matrix into one um flat 784 by one input layer so actually this uh neuron that we that we started building up to this point so this only has one single layer will actually look like this annotate so uh it's sequential of course but right now we only have one layer and what this is gonna be is this is actually gonna have um a bunch of input layers here and this is actually gonna be 784 uh long so this this whole input layer is gonna be 784 um neurons long so this is the first layer okay and then we're gonna have a hidden layer and then we're gonna have an output layer uh but does does that make sense so far so that we have one little node for each pixel of each of these images is there a reason why you need to flatten it um it's to simplify it's to simplify the the structure of the neural net um it's because each each layer of the neural net is just a singular column so instead of treating it as a multidimensional array then we just kind of want to flatten it because at the end of the day like each pixel is just a piece of data it doesn't really matter where it is we can just kind of treat like okay the top left pixel is the top left pixel and as long as that's consistent across all the images when we're training and testing then it should be okay so it's just a way to simplify the data into one one long layer to make sure that every pixel is represented in a clean way is it more efficient more efficient it actually doesn't really matter like the implementation under the hood everything is just it's boiled down to optimize matrix multiplications at a at the lowest level like tensorflow abstracts all that away uh this here is just kind of to like make it more um understandable for like a human when you're thinking about a neural net like okay we have this long this whole input layer is just one long column and every single pixel has its own little node and then each of those pixels has its numbers so like if this was black then this would be like zero if it was white it would be 255 um in this node and then it's just every pixel is represented then we can kind of be like okay this set of numbers this long 784 list of numbers represents this first image like if i if i run this yeah so um this first input layer will just take like all of these this um all these pixels so the first row will just be like up here second then the second row would just be right after the third row will be right after that just going all the way down until the very last row and these last two pixels down here in the bottom right are these two little nodes here just so that every pixel is represented then from there we've fully um gotten all the data of this image and then from there we can kind of like tweak the the different parts of the neural net and eventually we will be able to like filter um this image through and then by the end of it it'll it'll spit out like okay this is an ankle uh ankle boot and not a shirt or something like that actually i've just thought of a question um why why is the um grayscale numbering from zero to two five five ah so um it's just a uh the way the computer hardware has been implemented uh like as computers evolve from like the 1940s till now uh 250 0255 actually just means there's 256 numbers because 0 is the first one so 256 is just the power of 2 so it's just a way to stand to encode the data so i think this is what 2 to the not two to the eighth yeah so two to the eighth which just means that there's eight it's just eight bit so this is an eight bit image of black and white that's all that means so we can be on a scale from yeah so this is that's the range of all the different steps there's 255 steps of colors from zero from black to white and then there's 255 colors of gray between that that you can um specify and that's all it is um okay let's go so if you didn't it would still it would still come out and your output would still be the same or um i actually don't know i mean i just always use flattened just because it's easier to understand i mean we can try because i mean remember last week we used dents and we're going to be using dents going forward um but this kind of just like just uh um defines it so it kind of what this does i i think is it has kind of like this 28 by 28 thing and then um but it says hey just flatten that so there's actually a layer there's actually a matrices over here over here of 25 28 and then it just kind of like magically turns it into one layer and then we kind of just treat it as our first layer but it kind of like maps the matrices 28 by 28 to this one single input layer which is simpler for our neural net design because ideally down the road we're going to i mean not ideally but we actually are going to be doing is creating like a another layer of stuff here and then at the end we'll have like um a bunch of different notes here that's just like okay what's the probability that this is a shoe versus uh you know probably versus a shirt it's really hard to write with this but and then so on and so forth and there's going to be 10 different ones as we saw here there's there's about um tshirts trousers pull over's dress coat sandal sure all these so there'll be one of so yeah actually uh let's talk about that a little bit so what this our neural eventually going to look like is we're going to have this input layer which is just the image then we're going to have one hidden layer that's going to kind of try to capture the patterns of what actually a shoe is what a shirt is what a dress is stuff like that um and then from there we're going to have an output layer that's going to have 0 to 9 so it's going to have 10 nodes in the output layer and each of these nodes is going to tell you the probability of um how much the neuron that believes that it's going to be a shirt or a shoe or something else so there's only six here but you can just imagine that there's gonna be there's gonna be ten um like it's going that be 10 10 notes there and um then so the idea is if we put in an image um like the like the first shoe image would be pass it in and say okay this shoe should be uh really close to one it might be like 0.9 or something because this is a probability um then we want this to be really high and everything else would be low and then from there we can kind of uh train it eventually to the point where when when we pass in a new image the new image will pass through here every single pixel it'll filter through all of the hidden layers that we're about to create and then at the end it should say like okay uh the second image might be a shirt so this should be really close to one and everything else should be like lower closer to zero is uh is that yeah and your hidden layers represent the model is that what the model is the um the whole neural net itself is a model so uh like i like we went over last time um this annotates a little bit i gotta find a better tool for drawing i think oh but it'll it'll be okay that's everything yeah so the model is the model is inclusive the entire neural net is the the model and we're going to be designing it so right now we we only built the 28 by 20 matrice and we flattened it into the 784 input layer and you can kind of ignore the 28 by 28 now because it's just a simplification to make the neural net look nicer because if you have this weird matrices that pumps into this column layer and everything is just kind of like a weird thing we just want it to be a sequential uh series of columns of nodes and eventually you you pass in an image it goes through all this magic and figure out all the patterns and then spits out the probabilities here at the end and it's like okay shoes max is the biggest one so we can probably say that this image with all these pixels filtered through this known that is issue we can confidently say with the 90 accuracy that it's issue but this entire thing is going to be um the the model so again these are going to be connected i just didn't draw these and then there's a bunch of lines everywhere connect like every node is connected to every other node uh the way it can and and then these are just going to be numbers multiplied um together like going through the neural net so um uh let's let's go back to the code a little bit i want to explain the input and output a little bit to you guys and then i'll explain a little bit more about how the neural that is actually going to do the work let's go back to the code and let's actually just delete all this because it's getting too messy there we go so this is the first layer is going to be a flattened layer okay and um like i said before uh that's the input and then the output is going to be um uh a series of numbers from from zero to nine and those are the probabilities that it's going to be each of those so the output layer is actually going to need ten nodes okay it's gonna need ten nodes from zero to nine and um from there then then um then we can create the hidden layers after that so the first thing we want to do is uh let's grab the output layer so the you always want to go like input layer and output layer first and then you can kind of um experiment with the hidden layers to see what you get you get like the most the biggest bang for your buck because uh there's always that tradeoff of accuracy and speed so and this one we're only going to have one hidden layer and it it works pretty well uh but let's just start with this so input layer is again the 28 by 28 image and then we flatten that so this is just the input layer of 784 and now the output layer is just going to be um 10 10 nodes going up and down um and each of those going to correspond to one of these numbers is that clear so far or is anybody did anybody get lost awesome awesome and so so that's the uh first things we want to do is the input and the output and again we're using dents here dense just means that every node in each column is connected to every other node in each column so there's a bunch of like crossing over lines uh between each neural net let me just find an image actually densely connected neural network like i showed some of these last week but here this one works nice ah it's not working here we go so this here um is uh like this one has a bunch of inputs so for us we're gonna have the image and all the pixels in here and then we're gonna have the the ten different um numbers here uh corresponding to each each of the the clothing types uh ignore this for now this this thing here um i'll explain this in a little bit but just remember that the i'm i think i did this last time to make it a little bit clearer so units will actually define how many nodes are in this column so the type of column is going to be dense this layer the the layer or column i'm kind of using those terms interchangeably but they're the same thing so that layer is going to have 10 units out of the coming out of the back this only has 4 but just pretend there's 10 and then the input has 784 again so once we have those specified then usually you can just start off by just testing it with one hidden layer and then kind of see how well your neural net performs testing it with one hidden layer and then kind of see how well your neural net performs because simpler is better and then um and in our case it'll work pretty well only one one hidden layer and we're about to build that uh but sometimes you need really really deep layers to actually create robust systems so for us like we're simply classifying like like 10 different types of clothing which is pretty pretty simple um but sometimes you want to have like a really really deep neural network and that's actually where deep learning comes in is this is where like there could be like a lot of hidden layers like tens hundreds of hidden layers and that's why it's called deep learning just because the neural outlook is really really deep but those can get really powerful like if they opt people have like learned how to optimize it enough to not take like years and years to train um but then it's able to like be really really powerful for like recognizing like a large large array of different uh things like it can tell what a cat is what a coffee mug is um what an airplane is like who obama is and stuff like that um uh all in one neural net but you need a lot of hidden layers but for ours it's pretty simple so we only need one one hidden layer and we'll just start with one and we'll see that it actually works pretty well so let me go pull that out next uh we're currently designing our our neural network structure using keras so um so this here is actually the final neural network that we're going to be building so we have the entire thing specified here um the the the hidden layer we're going to be using is another dense layer so again it's going to be fully connected like this as in every layer column layer here is fully connected densely to the to the next one um so it's this is what it's going to look like but we're only going to have one hidden layer so you can ignore two and three you can pretend those aren't there and um and then we're gonna have 128 again let me type in units to be a little bit clearer uh we're going to have 128 nodes in that one okay so there's actually going to be 128 tall so the first the first one is going to be 778 tall second one is going to be 128 tall so smaller and the last one is going to be 10 tall so you can kind of see like we're filtering from a big image and then we're going to we're pulling it down to like a little bit a few patterns and eventually we're going to um um we're going to boil it down to 10 probabilities of of these different clothing types uh so that's kind of the structure of our uh neural net um you can kind of just you kind of just want to like guess for this one uh you can just kind of like like last week we started with a very very simple one um but for images you usually want to try like some some decent numbers so you might want to start you could even start with like 60 64 or something and then you can just jump up to 128 but 128 is like a good medium ground like it's not too big of a number for a computer to do with uh but it it captures a good amount of relationships you kind of just have to like play with it and stuff for for prebuilt projects usually people figure out these finetuned numbers for you but for us you can just kind of like just pick a number and see what happens you kind of have to play with it and see how the computer learns like how accurate it learns okay so is everybody following up to this point we um this is just all kind of like preliminary code stuff of like importing the data and everything but here designing our neural net we have a sequential neural net with uh input of an image um one hidden layer of 128 nodes and a output layer of 10 nodes is that clear to everybody is it a good i don't know common practice to make the hidden layer some um factor of two or power two um not really uh it can be anything i don't know why they actually choose 128 um because i i found this project online and um it's like neural nets can you can use any number of nodes it's just uh arbitrary um number of nodes and then you can capture relationships so i actually don't think it needs to be uh like some special number actually i mean we could probably even choose a different number but um did they just i guess people just like like powers of two because it kind of goes nicely with like how computers work internally so maybe maybe it's good practice maybe not but i mean in theory you don't need to have it be a power of two but maybe in implementation yeah i didn't know those conventions or something yeah um i i guess i mean yeah a lot of stuff in code in general is like based on powers of two so maybe it's a it's a it doesn't hurt to just start there if you're choosing a random number then that you just choose a power of two because it might might simplify things but it should it shouldn't doesn't matter like on a theoretical level so uh from here we have our entire neural net created in design so let me actually just draw this out visually once so that anybody watching the recording can see exactly what it looks like so we have our entire neural net created in design so um let me actually just draw this out visually once so that anybody watching the recording can see exactly what it looks like so first layer is going to be 784 layers of like that it's going to be 7 84 flattened and then this one is going to be 128. oh hello i think my i think my connection cut out for a second you guys there yes all right perfect then this is going to be um 128 and then the last one is going to be 10 10 here is going to be 10. and then of course these are all connected there's all those crazy lines between each of these just like we have um here okay so you can kind of just assume that this is the neural net but then just pretend the lines are all there so this is the what our doorknob actually looks like that we just built um again it's just as simple as uh just calling uh terrace and the type of neural net and then just listing the layers in this list one by one so layer layer layer input hidden and output okay i think i explained that adequately enough let me get rid of these drawings so we can continue on oops um aaron i have a i had a question actually yeah what's up hi uh so uh when these uh when we add a hidden layers okay so does that uh number have to be um consistent for example we have a 128 nodes in the first hidden layer so for example if we are creating uh further hidden layers so for example we are creating five hidden layers so it has to be 128 128 and 128 for all five layers or it can increase and decrease based on it can increase and decrease based on anything um this is where the neural net design gets kind of like uh up in the air um for this one this is a pretty simple problem like relatively because we're dealing with small black and white images we're not dealing with like 4k big images or anything uh so but yeah it can be anything usually what you want to do is the neural net usually starts big and then eventually gets smaller and smaller into something small um because you want to take like a big thing of data and then like all the pixel data and then just say shoot or a bunch of pixel data and say okay okay this is um like martin luther king jr or something if it's his face like you just want to like have like simple labels at the end so usually the neural network starts big and eventually filters down smaller and smaller into some some set of outputs in our case it's going to be a list of 10 numbers which again correspond to the probabilities listed here for each of these okay so the number of nodes in the hidden layer has to be less than the input layer or it can no it can be it can be anything it can increase as well um because you could theoretically capture more um patterns the the thing is the data uh that's there is um 784 tall right the input layer we have all that um so you can kind of if if the input layer is also the same size then you're kind of like not boiling it down to like smaller patterns you can because there's like weird like uh how to explain this um there's there's patterns you could pick up on if it's bigger you kind of like find like weird like underlying patterns in the data that you can't really like visualize like like a human wouldn't really understand it but like you can kind of uh pick up these patterns in numbers if you get more complex but then also at the same time as you create more hidden layers it takes longer to train so as a general rule of thumb it's usually better to just get smaller and smaller and smaller or stay the same size you could go like big and then have like two layers of 16 or three layers of 16 and then like go down to like a layer of output of two if like if it was like you're trying to be like oh is this a cat or a dog or something like that it could be like image then 16 16 16 then two for for that neural net for like if you're trying to do like a dog okay so what would be an efficient approach uh to have us like for the example uh 128 is two power six i guess or eight or something yeah yeah some power of two yeah uh okay so two power of seven so what if uh i wanna split it uh maybe uh 128 into like uh seven right so it will be uh uh two part three and two power four i wanna have two hidden layers so is that will that be a more uh efficient approach or having it both in a single hidden layer will be um more similar actually less layers is better uh if you can get it to the the least amount of layers possible that's usually better because it keeps the neural net simpler and they're not as deep um but as you go deeper you can actually yeah you can like pick up on different patterns so like um for us it might be like okay for a shirt like i might pick up like long like or actually let me just print let me give an example so when you say uh going deep into the neural network so does that mean uh going into more into hidden layer number one hidden layer number two or increasing the length of the hidden layer oh you mean like like you mean making uh a hidden layer versus having two hidden layers exactly so what if i want to have that hidden layer just uh beneath the hidden layer one i want to append the hidden layer to under hidden layer one maybe yeah well again there's like there's a fine tuning thing of like the complexity of the neural net versus how much you have so like uh the more the more nodes you have in a layer in principle the more patterns you'll be able to pick up um but then also it'll take longer to train so yeah you could just have like um you could you could like like you could have are you asking like one like one 128 layer versus two 64 layers or something like that yeah usually you'd want to pile it into just one 128 layer which is what we're doing now because it gets the job done with one layer because each layer you add kind of adds a level of like exponent it gets exponentially more complicated uh faster than than um okay so keeping it to us in into a single layer makes it like keeps it simple yeah for now um okay there are yeah there's there's a lot of different tradeoffs but i mean just as a general rule of thumb just try to keep the layers as low as possible because it uh keeps its and also i mean like if 64. like this is 128 but like if 64 gets us decent results that's a better uh choice to go with 128 seems to be the sweet spot that will be that would be the number of units would be the minimum number which would get us a result of a decent accuracy yeah something like that yeah so you just kind of want to optimize this neural net for this task and that's kind of like the name of the game is like figuring out the neural net design the numbers and the training set to get it working pretty good for whatever problem you're facing for us we're just trying to classify clothing types versus so our aim would be to keep minimum number of nodes and minimum number of hidden layers to get the maximum accuracy yeah yeah like that you just find that find that balance point for whatever you're trying to solve like if you need like a realtime solution you'd probably sacrifice some accuracy to be like instant instantaneous classification like for like for tesla's selfdriving cars it's like okay that's a person walking that's a telephone pole it needs to be real time so um they'll probably rather have it be real time and be a little bit less accurate and then just kind of like be extra careful uh with their things it's like okay i'm not sure if that's a human i'm just gonna say it's a human so i don't hit it you know like just kind of like sacrifice accuracy but make sure it's fast so you just gotta depending on the problem you're trying to solve you have to kind of like balance that out okay okay yeah thank you thanks aaron yeah i was going to ask something similar um um is it almost the same thing or equivalent of the the increase as you increase your hidden layers that increases the time complexity meaning it's like almost like exponential so if you added a second one it's you know i forgot to go through here this is sequential wait say that again yeah so is it is it more like you know it adds a number of permutations or combinations because the node has to touch yeah because it increases the increase yeah yeah it's going to be i think i might have gotten backwards i know like putting if you just want to like trim it down as much as you can but yeah as you increase the nodes and stuff then because every node and every connection or they're called neurons or synapse like neurons and synapses like to reflect the human brain but it's just nodes and connections between those nodes like here so like these these are nodes these are the connections or synapses or these are neurons in these synapses whatever you want to call it each of these lines has a weight so like you would have the pixel and then you would have the weight of each of these lines then you just multiply that pixel value by that weight and you get a different a different number here um and then from there you do it again and again and again and then eventually all these little numbers together kind of like represent a function that captures the patterns and eventually spit out um the correct numbers so since every single line and every single node has its own number um and then there's a bunch of like crazy uh multiplications going on they're at the at the bottom level they're just matrix multiplications which has been highly optimized with numpy so it's as fast as it can get pretty much um and once those are all like multiplied together then then that's how this this is all computed and it goes through but yeah as you as you add more layers you can see that each um each extra layer and each extra node adds like an exponential kind of um thing to it so the computation goes up and then i guess also that the time the space comes the space complexity too okay and so there may be times where you may have a higher number of nodes in your hidden layer if like your input layer i guess you don't have that many nodes to increase your uh uh pattern you know increase the number of patterns that you might be able to yeah because yeah because sometimes there can be like weird nuanced patterns in the data that aren't really clear uh so like yeah like if your input was like really small um like what's a good example like yeah like maybe you maybe you had some training data of like maybe you had some stats like you're trying to do some stocks and you're like okay these are the prices of the stocks over here and you only have like a small little thing like the input layers maybe like only 64 long but you kind of want to like capture some weird like numerical patterns between everything you could have like your hidden layers be much bigger to try to capture some some patterns that the human couldn't pick up on right okay some something like that yeah i'm just trying to understand the strategy of how you design your uh layers and then the length of them yeah uh the the best the simplest way like like i'm explaining here is you just want to start with your input um and then your output first always start with that and then the hidden layer just start with one and see what happens you know and play with the number and then maybe it's like okay this is doing crap um i can then you can play with the activation functions too i'll touch on these in a second because this is another kind of uh number crunching thing that happens and then there's different things you can pick like these two are different like they're both activation functions but these two do do different things um and so it's kind of just like you play with it and you play with all the different numbers and different types and hopefully get some um some useful uh use out of out of your neural net uh but yeah just just start with one and then you can always expand out from there uh okay let's continue on unless there's any any more like burning questions from people about about this uh all right i'll take that as a note that is that is good okay so we designed our neural net here uh now let's continue on there's actually not too much left because tensorflow makes everything nice and concise so we only have a few more lines of code here uh let's just go one by one so let's grab this paste it in so anybody who remembers from last uh from last week then after you create your model we have to compile it uh which basically just means take all the stuff that kara's built because we just specified the nodes and the numbers and the types and all that like you know densely connected make this flattened make it this big make this hidden layer 128 tall make sure sequential all the stuff that kara's put together now we want to actually compile it so it's ready to be trained which um just means kind of like i actually don't know exactly what's happening under the hood when keras but it just kind of says like okay take all this put it into a form where it's ready to do to do stuff and then we also have to specify an optimizer function and a loss function so let me just touch on this again really quickly one more time for anybody who forgot or is new so um just remember remember there's a lost thing and an optimizer thing so let me go to this uh neural net here and kind of explain visually what's happening so what happens is when you put in an image in input layer you would put one through and um you would want to pick random numbers for all these lines and for all these lines and just filter it through so once you have an image come in you'd multiply it by all these random numbers and then you'd get another set of numbers here you take those and multiply by all these random numbers on all these lines and then you get it all um all here and then again and again to get to the very end and you'll get some output um so again you're going to get we're going to get 10 outputs in hours that correspond to the probabilities of it being these 10 things and uh basically whichever one is the highest we can kind of say that neural net believes that the image we passed in is that thing and then we can compare that um that answer that the neuron that gave us to the actual label of what the data set gave us because the the training data actually tells us what it is what it's supposed to be like like a human went in there and actually labeled it for us um and so uh what we want to do is the loss function here will tell us how correct or how incorrect we are and basically it'll say like okay the neural net said it was uh like maybe move the neural that said it was a tshirt but it was actually a boot for like this first one um for the for the for the boot image that i showed earlier then we know that that it's very wrong and we can kind of see the loss function is like okay you're this much wrong but how do we get better uh so it tells if we're super wrong then we want to get closer to being right and that's where the optimizer comes in uh which just kind of tells us like okay make these changes to all these these weights here to be a little bit more correct because um we can just like we can alter these by saying okay if we if we um if we know it's an ankle boot but it thought it was a tshirt all we need to do is just kind of like adjust all the weights that connect to the tshirt node at the end and be like okay lower all those weights because that was way wrong um but we know it is a boot so it's like okay well we know it's a boot so let's increase all of the the numbers that were connected to the boot because this should be higher and the tshirt should be lower and then that's how that changes all these weights here and then we repeat the same process here and then here and then here again and then that's one that's kind of that's what one epoch is with one image and then we um for anybody from last week remember the whole epoch conversation we had uh and then then we can repeat that again with um another image so uh to cover that again so the loss function we we pass in some data it goes through all these random numbers and then we get something out then the loss function will tell us how wrong we are so we're just you can this fancy name is just like a name of a function that we can use to tell us how wrong we are and then the optimizer is a way to alter these weights in a way um to make this normal a little bit more accurate in being able to classify different images as these these data types i mean as these uh clothing types does uh does that kind of make sense it's kind of a complicated thing to explain i think there's probably people on the internet who've explained it better but i i hope i didn't lose you guys again hello hello is anybody anybody there no it's good yeah it's clear okay awesome awesome awesome okay so yep loss tells us how long we are optimizer tweaks all the numbers in the neural net um and actually yeah did somebody say something um i'm just i'm trying to remember it from last week was that the is that a different optimizer and loss functions that we used in the last weeks yes so the thing about loss functions and optimizer functions is and even knowledge too like there's different neural nets and different optimizers and different loss functions that are useful for different types so for images these are actually pretty good for image data like last time we were working with just like straight numbers a very very simple onetoone number relationship but now we're trying to map a 28 by 28 image to like a series of ten numbers which is the probability of okay maybe this is a shirt maybe it's a shoe um so these are different uh but basically there's just a bunch you can use and you can go and test all of them but um and then all the math behind this uh is there i don't actually understand i don't remember i don't remember what atom is or sparse categorical crossing should be whatever this is but um they're just things you can specify you can just like choose whichever one works so these are are i'm pretty sure are good for for images so i'm guessing i'm guessing like tensorflow or keras whatever whatever it's coming from it's got um like predefined libraries of all these functions and and somewhere on on the internet somewhere there'll be a i'll list them with like an explanation of what they're good for yeah probably like that i mean we can maybe look a little bit like what is this sparse i'm curious because i actually didn't learn the specific there's just so many sparse i mean the documentation is a good place to go so like if you look here so tensorflow.keras.losses so this is lost function so that's why it's losses and this is called sparse categorical cross entropy so i mean just from the name i mean it sounds scary i mean the first thing that comes to mind is um it's probably trying to pick up on like different splotches of like brightness and darkness in each image and then it's trying to like find like the amount of chaos and randomness inside of those um images and then like i don't know what categorical means but it's probably doing something like that and trying to like translate that to like how right or wrong you are um i mean i kind of just pulled out my my ass but that's what it sounds like it says computes the sparse i mean okay what's just explaining itself here that's not very helpful um yeah i don't i don't know the math behind this one but uh the idea is it just tells you how right or how wrong you are you just get a number from zero to one at the end of it or something like that uh for this for this specific one but someone documented it like a dummy's guide yeah hopefully there's some crazy math behind it and and stuff yeah i mean it's it's a whole it's a whole like um field of thought right you know machine learning and all these different there's always like new papers and research coming out about like all these different things like this actually is uh something fairly fairly new uh really i'll touch on this in a second um relu is something that they they started doing more recently there used to be a different one but this is like a huge optimization thing that makes throw that's like 10 times faster but still get pretty good accuracy they started using this instead of something else and now it's kind of like a like accepted standard to use this relu thing um i forget what it stands for but oh yeah i wrote right here relu so um okay let me let me explain this a little bit i forgot to touch on the activation functions actually okay let me let me explain this a little bit i forgot to touch on the activation functions actually um so how the neural net works is again we have all the pixel numbers here from 0 to 255 on each of these nodes then we have a bunch of weights here that could be any any numbers at all it could be 0.1 could be 4.6 could be anything could be negative numbers too and you just multiply it and then you get like hidden layer stuff then from here when you get numbers you want to you want to pass this into another function um called the activation function like once we get the pixel data we multiply it by all these crazy numbers and we get like a new column of data here of new numbers these we also want to do an extra step that's hidden within these nodes that's called the activation function which kind of um treats it as it's like an another layer of filtering it kind of like specifies the threshold of like okay this is good enough or not good enough like um like for like like one good example is in the output layer we can say okay if the output is above 0.9 aka above 90 we can confidently say that this is a shoe but maybe it's a sandal you know like maybe shoe and sandal are both above 9.9 and that can we can specify that threshold of 0.9 um but then just the highest one will be the actual the actual answer like maybe it's like 0.95 and then 0.99 so the 0.99 would win but we can kind of like specify some threshold of what gets passed on and stuff so you can kind of filter that stuff there you can be like okay anything above 0.9 let it keep going anything below 0.9 completely turn off because we're we're sure it's not a shirt we're sure it's not a bag and stuff like that so the activation function just acts as like a filtering mechanism within each layer um that can further filter out our data um does that make sense with that whole like 0.9 example of like in the last layer yup it didn't make sense okay okay good uh so that's what that does and basically so what what we're doing here is um before they they had some crazy function called the sigmoid function uh it's not important it just it's this thing that kind of like uh it's a perfect continuous it's a nice pretty curve function that kind of like okay if we're above this little threshold then let it buy um but it's really computationally intense when you get really big neural nets so basically what they did is this relu thing they said okay literally if anything is zero like below zero just return zero this passes zero through um but if it's above zero just pass the actual number it is so basically it's just like chopping off all negative it's just getting rid of number negative numbers that's all it's doing and it sounds really simplistic but it seems to work in in practice so uh totf is tensorflow and and i believe this neural network um then uh relu is uh it just gets rid of negative numbers so basically like i said these weights can have negative numbers but once it gets here if it's a negative number it automatically just gets turned to a zero and then any positive numbers just stay what they are and it kind of um simplifies like the pattern stuff i don't i don't remember the the exact theory behind it but it does that and it actually improves the the um performance of the neural net and it does that for for um for each layer that has really specified so bradley is like really a really popular one um uh this one down here is so the activation function here so uh this one is softmax and all softmax does is it just picks the greatest number out of everything so in our point um because i said that the the last layer is going to be ten layers here from zero to nine and it's gonna have the probability of each one it being one of these um then it'll just pick the one that has the highest the highest probability and spit that out so for our case if i go back to this quit out of this and run the code again so this is our first data um data image then we know this is a shoe um so uh this probability would probably be the highest like the this bottom node might be like 0.99 or something or 0.97 and all these might be like zero point one zero point four zero point three like it's not it it's pretty sure it's not all of these and since this is the highest it'll just give us nine it'll just give us nine and then we know nine is is uh mapped to ankle boot but it'll just pump out the number nine so um soft max basically just gets the the maximum um number within that layer and that's all that activation function does very simple because that's all we need to do in this last layer is just kind of like which one is the highest like that's the final filtering mathematical thing we want to do in this last layer um to to finish off the neural net is just find that find the greatest one in in actual practice what it does is i believe it does this like it might be like 0.1 you know 0.3 0.4 0.2 blah blah blah blah and then all the way to 0.99 for the last one um all it really does is it just does this so it just it just makes all these zero oh wait i screwed it up it just makes all these zero and then makes the greatest one one it would be like that so that's really what it's doing that's what soft max is actually doing just kind of like boiling this down to this and then from there we can like okay so the ninth one is the one that's on okay this is a shoe and that that's kind of what's happening uh within the neural net is that clear so far yeah it's kind of clear but i have a doubt and that so basically what's happening is the hidden layer is filtering out all the negative values and it's just keeping the positive values and the outer layer what it's doing it's it's just picking up selecting the max value and setting it to one or like it's telling us oh yeah it's it's gonna it's the max value zero point nine and so it's gonna be a shoe yeah so uh like why are we introducing uh the hidden layer if can we do uh this uh operation using a function maybe like a simple function or like why are we why is the need to introduce the hidden layer can we uh do it without the hidden layer is it possible or like is it computationally tough or like it's not possible or like what is what could be the solution so um the point of the hidden layer is to actually well i mean you need the hidden layer for it to be like a knurled in the first place like if we just went from um what happens if if we eliminate the middle layer what happens then everything wouldn't it wouldn't work that well at all because the here let me draw it out let me annotate a little bit so you would have the you know the 784 here the 784 input layers here which is just the pixel data and then you would simply have the 10 the 10 output layers here right which is what you're asking yeah so we'll just let me just draw this out so you have the 10 here and you have the 784 here like that and then um we want this to be like densely connected so um this you would get i mean i didn't haven't actually tried it you would get like decent results maybe but the idea is you have all the pixel data then you want to multiply all the pixels by certain numbers and get an output uh the problem with this is there's no this actually really isn't a neural net because there is no hidden layer the idea of the hidden layer is to capture some kind of pattern and kind of generalize like some visual patterns or any any in this case visual because it's image stuff but any pattern in any data and i'll capture those patterns and then eventually filter through enough time to get some kind of results so i mean this does qualify as a neural net but if you delete if you get rid of the hidden layer um the idea of the hidden layers is the more hidden layers you have when the bigger the hidden layers are then the more patterns you can pick up on and the more accurate you can get so this kind of completely eliminates like all that pattern seeking stuff because you only have like uh one layer of of numbers to tweak so it probably wouldn't work that well uh but one single hidden layer does work pretty well um comments nigel says the hidden layer and its connection is the function so pretty much yeah it kind of like it's yeah it is i mean it's a function in the sense that you have input and then it does a bunch of computations and then you have some output um so the whole neural net itself is a function but also each layer is like a mini function within that so um yeah but then i mean the function we're trying to do here is input image output label of what the heck it is so that's the the high level function but then the inner function would be like okay um maybe for for this it's like okay does it have a curve like is there like a weird looking curve thing here because that it might pick up this curve and be like okay this might be a shoot because most uh shoes have a little curve you know like where your toe goes up to your ankle there's there's a curve in um and shoes a lot and does it does this look like an l you know something like that like a zork out of here are we gonna dive into the computations and how these neural networks work are we gonna dive into that or it's just the basic um outlay off a little bit i i want to touch on a touchdown a little bit but not too much because i mean yeah you can go you can go down the whole math rabbit hole if you want um but then it doesn't get too applicable i've touched on a little bit before but i don't want to go too deep into it so is it a good practice to dive into what like what this neural networks do or it's just like oh yeah this functions uh does this thing so i need not worry about what's going on within the hidden layer and it's just like one of those things it depends what you want to do or if you're trying to become a professor or become like an academic or research kind of person then yeah you should understand the math but if you're just trying to create apps and you want to find a way to apply this and make money from it like as a freelancer then you probably can you don't need to worry about the math so it really depends what your personal goals are um i'm trying to find like a good middle ground between both just to kind of give like a general understanding of okay the underlying math so somebody could like converse about it in a more intelligent way but then also have some kind of tangible result at the end without getting lost in the calculus because it gets really messy and i don't remember half of it i'd have to review all the the dirty math actually i'm uh pursuing my master's degree in data science okay a little bit uh curious i'm just starting off so this was a little bit curious about what's really going on within the hidden layers so as of now let's keep it simple maybe i'll go through your previous videos it's my first like uh coaching call with you i think oh welcome welcome so i'll definitely go through those uh your previous videos as well and grab uh most of the information from there and maybe i will get back to you later yeah awesome yeah i can pass you a couple resources too like if you're actually studying it there i know a couple other guys are doing similar stuff they're getting their masters um i was i i dropped out a few months ago but i was i was also pursuing my master's in machine learning but then i stopped to work here fulltime so uh yeah i'll pass you a couple what is your or just message me on slack and then i'll pass you a couple of resources you can check out that you might find interesting yeah definitely yeah for that for the math stuff yeah of course yeah thanks aaron yeah um what was i saying oh yeah so the hidden layers are definitely needed because that's kind of like where the power the the work gets done it's like like that's the function the function like the main part of the function like this is just an input function this is just an output function but then you need like the pattern recognition like okay what is happening function which is the hidden layers okay uh let's continue on so okay uh let's continue on so um i'll leave that there because it might be useful later okie doke i was talking about the activation functions and then okay loss functions again loss functions tells us how wrong the neural net is and then optimizer tells us how to tweak all the numbers um and that's what we need for compiling just because we need to specify like how to do the correct calculations like once we pass data into the neural net we need to know what function to use once it's gone all the way through to measure our incorrectness and then also what function we need to use to opt to change all the numbers and uh repeat that with every image over and over and over again so that's what compiled us we're just getting our model our neural net model ready for uh training now we're just specifying all these things so next step from here is just to probably just pass in the data and get it going so let's do that next how many people are still on here you see one two four fifteen people or so hey aaron hey joe what is up i'm trying to make sense of what the hell is going on here ah did you come in were you here from the beginning or did you just jump no this is my first coaching call i mean i i was on a first first call but this is the first call with tensorflow is this is this the first call where you're starting tensorflow you did one before last week we did one yeah i missed that then okay yeah but the recording's in the course you can go watch it that one yeah it's about two hours it's a little bit messy yeah so if you if you can give me like a quick twominute pitch of what what's the final goal here are we trying to achieve and yeah sure yeah i'll do that again because doing doing that over and over again is not a bad idea either just because it helps kind of solidify the ideas so again yeah tensorflow we're using this to design neural networks and um solve problems so we're creating a neural network like this within tensorflow the idea is we want to pass in um a bunch of images here uh within here each one of these correlates to a pixel brightness and then from there it'll filter through um the neural net all that all that means is each of these numbers has each of these lines has a number and you multiply that number by all the pixel values and over time you can pick up weird patterns and at the very end we can be like okay um this might be a shoe or this might be a shirt because the data we're looking at is actually um some oops was it supposed to do that well what happened one second one second there we go this one there we go uh did you see the the data that we were um looking at were you here from the beginning of the call joe no i just joined like maybe five oh okay got it yeah so we have a bunch of images like this is a shoe and then um let me just show you one more so this one is a um oops ah yeah it's running all this stuff because we have all the the code in there just ignore that for now so we had a shoe before and then we also have a shirt here okay so what we do is we have a bunch of images of different types and it's just like 20 by 28 images like this for shirts and basically they're of these 10 different types so boots bags shirts tshirt top trousers address all this stuff and the idea is we want to train our neural net on a bunch of these images that are labeled like this is a shirt the one before it was a shoe and we want to go through our neural net here and uh train this neural net so that going forward we can put in new images that look like this and then properly identify what they are gotcha so that's the so that is the practical example of it basically you're training you're training the network to recognize certain images associated it's like how your brain functions when you see something then next time when you see kind of associated with that correct yep that's it so that's what we're doing so what we did is we designed the whole model we designed the whole neural net um we have the whole input layer correspond to the whole image so 28 by 28 we we flatten this out into a 784 by one column which is here so every pixel is represented then we filter it through all these crazy numbers so each of these lines has a number you multiply the number by the pixel value and you get a new set of numbers and then you do some other stuff and then you keep doing it over and over and at the end we're gonna have 10 different nodes and then each of those is going to have a probability of how much it believes it's one of those things so in this case this is probably going to be probably shirt probably spit out a 6. and then the one before is was an ankle boot um and so so that's what that's what we're currently doing okay yep and let me just quit out if it will my computer is kind of screaming right now there we go oh no i think i broke it um dang it okay i'm gonna need a new all right cd desktop tensorflow app and uh source v and uh bin activate i think does anybody remember what the command for let me just find it why is even opening there we go bin yeah bin activate that's correct so this should work okay and then python 3 image classifier that pi and okay there we go add though okay yeah this is the annoying thing because it's training the model every single time over five epochs just wait wait a second guys okay let's get rid of this one because this one is broken and there we go okay back to where we were so welcome joe so that's what we're doing uh now let me continue on in the code so each of these just uh just to interject so each of these lines uh when you say model uh so if you no scroll not not here go back to your code up scroll up for a second so model are you assigning this like a is that a library keras not sequential yeah okay so really really quick um you can watch the recording later to get the full explanation but really quick uh keras is a library that tensorflow uses to create graphs which is what matches it for the things and then tensorflow allows us to do the actual computations all this means sequential just means that there's a sequential thing of columns one by one one at a time there's no jumping between there's no jumping that's each is in sequence so that's the overall neural net then we specify three layers so the first layer for us is a layer of 128 and then i mean of 28 by 28 which comes out to 784 and then we have one hidden layer of 128 and then ignore these two pretend these two layers aren't here and then there's an output layer of 10 um which is going to correspond to these 10 which is going to have the probability that each of these what how much it believes it's the image is one of these 10 things all right so that's how we create the model then from there then we created uh we have to compile it we have to specify a loss function and optimizer function so this just tells us how wrong the neural net is and this tells us how to up to change the neural net to make it a little bit more correct uh we just specify those two there uh you can choose a bunch like these names aren't important it's just there's a bunch you can choose from then from there then we can just start training so once we have the model built and we tell it which functions to use then we can uh start training the model here so this is how we do it so all you do is you call model.fit and fit just means we're going to fit our current model that we just created to the data set that we have uh given to it so in our case we have a bunch of these images like the the the clothing images there's 60 thousand so the 60 000 images in the training and each of those is also labeled 60 000 somebody some crazy person went through all 60 000 and manually label all of them um which is something i would not want to do and then we also want to specify how many times you want to go through this whole thing so an epoch is just one um one pass of this so you would put pass through all of the the images all 60 000 images see how wrong all of them were and optimize all them 60 000 times for all 60 000 images because there's 60 000 in here and then you would you would change everything in the neural net one time so what we're doing is we're actually adjusting all the weights in the neural net five times and that's what it does is we pass all the images and see how wrong they all are take the average of all how wrong it is overall and then optimize it overall and then we do that five times and that's actually what you're seeing here you can see that it runs five epochs here you pop one of five two five blah blah blah from this this was covered last week too if you wanna watch the recording um so that's what this does we're just taking our model and we want to fit it to our training images and labels so you just pass it in in this way images first then labels and then you specify them on an epochs and five seems to actually be pretty good because the images are pretty small only 20 by 28 we're not they're not even like they're they're really really tiny um so eat five epochs is sufficient here um cool yup uh last thing is now that we've that we trained our model now we just want to actually uh test it so all you do is you call the evaluate function instead so because after we run fit it's trained our model is now trained uh across five epochs that's why it was taking a while you saw that let me just run it again so when we run this you can see that the image is going to pop up um just ignore that so um here so you can see the epoch is running so it's actually running all 60 000 images and then it's it's seeing how wrong it is and then optimizing then how wrong it is and optimizing how wrong it is optimizing across all 60 000 images and it does that five times and then then it stops so that's that was the training and then at this and then you can actually see the loss so it's telling you how wrong it was after the first epoch and then you can see the loss is actually getting smaller and smaller and smaller and then i believe this is the uh average or something i think this is like some overall arcing uh loss or something like some global loss the whole neural net overall um and then from there so that's what's happening here now we can actually is it is it is it just learning one image or is it learning all the ten images across when you feed it in um so it's actually taking all of the 60 000 uh images and it's it's training it on all 60 000. oh okay and that error is and that error is across all those images right averages of all the images yeah how wrong they all work because we know the correct answer and then we know the answer the neural net thought it was and then we can kind of like measure how wrong it was and then from there which is what this does and then the optimizer will tell us how to optimize the weights a little bit better cool and if quick question then if you're only running five epochs on that and it's still down to what was it like 0.5 something for an error if presumably if you ran that like 10 epochs could you get that you would get that down even closer i mean i guess let's try it i don't actually know um i just know that the the numbers within this app were actually pretty finely tuned to be like decent performance so let's run this for 10 and see what happens so first loss was three and then it got down pretty small i mean it's a pretty big jump and then the jumps get kind of smaller so i think there's yeah there's like a point of diminishing returns it doesn't look like it's getting too much smaller you can see it's kind of leveling out there yeah there's probably the data set isn't good enough and the image would be just too small so at a certain point it's just proportionally steeped in levels out right yeah so i mean that's also kind of like you need to like just use some human brain power there and just kind of be like okay well this seems kind of useless for the amount of time it took like this got eighty percent of the results so maybe we can just keep it the five um so we'll just put it back to five but okay i need a faster computer so if you increase the number of epochs this image won't get any clearer right now it's blurry no so what's happening is um there's a bunch of different images uh so like i just show you the first and second image the shoe and the shirt there's actually 60 000 in here so i i could even go like you know 50 000 if i wanted i could show you this image um why don't i do that just out of demonstration purposes but the idea is you're just passing in all these different images and then you want to um train across all those images but the image will always be 28 by 28 so this is just another issue so the 50 50 000 image in this data set is another issue but a little slightly different shoe okay oh my goodness i gotta i gotta stop doing that because it's gonna it keeps retraining the whole neural net over and over again every time okay so you're only focusing on a shoe you're focusing on even the shirt and the other 10 10 all together images combined oh we are so i mean if i chose like 40 000 hopefully this is not a shoe but there's ten different types of clothing types and it's just shuffle it's just randomized data label all right so here's another shoe okay i keep getting shoes for some reason but well and then again with the the one and ten chance yeah i mean how many times am i gonna get a shoe versus like dresses or bags or something by the time yeah i mean i wish they had images in here they don't have you know they don't like show you like the images like they'll be nice to actually have some sample but you have to go into the data set yourself so it is what it is but i can use you can just kind of take it with a grain of salt that this is what the data is it's just like randomized images that look like these things um so let's see what we have here so uh yeah so we trained our model across five epochs and we saw kind of like the diminishing returns there so epochs 5 seems to be like a nice finely tuned number there for this uh this specific training data um and then the next thing we want to do is want to test our model the next thing we want to do is we want to test our model so we do that from using model.evaluate and very similar similarly to here instead of training it or fitting it on the training data we just want to test it on the test data so like i said at the beginning there's actually seventy thousand images uh within this data set we use sixty thousand for training and the remaining ten thousand for test so we we um put the sixty thousand in here and we're going to use remaining ten thousand images to see how accurate our neural net actually uh performed and and the thing is going to return is just um test uh the loss the overall loss which is it's actually just going to spit out this number this last one i think this is like some kind of loss average or something like that um but it's not super important i just kind of put there to save it i mean there is an accuracy number we can get i think uh there's like measure accuracy or something we can actually add that in a second but let me just finish off that first and then we can add it at the end um so when i do that then we kind of have to do all this code together because it nothing's gonna show but what happens here is it's basically evaluating and tells us how wrong it is but then we can also um make predictions so um let's do that next uh so yeah this will get us accuracy i'll do that in a second after afterwards but the predictions here so what we can do is we can actually take the test images that we have the remaining 10 000 and we can use our model to predict um each of these images and then we can actually compare that to the actual data the actual labels we have because we have the correct labels here the test labels but we don't want to give it the labels you just want to give it just the image and see how well it performs so this is going to give us predictions and um what predictions is is it's actually just going to give us the 10 probabilities of each of these last 10 things so let's start with that and let me just actually show you predictions at zero and predictions at i mean uh well actually let's let's do this so i'm going to get rid of this stuff and go down here so what we're going to do is on instead of train images we're going to go on test images so let's go to the first test image here i want to show you guys the first test image uh and then show that and let's actually just comment all this out first so we can go step by step together so we have the whole model trained and built and all that stuff now i just want to show the first test image and then let's just see what it is together because i actually don't know what it's going to be aaron i have a question instead of uh running the whole program again and again like it will again train the data in this thing we can use jupyter notebooks for just running the cell right yeah we could use jupyter notebooks yeah there's like a thing that has tensorflow built in um and it's called the google collaboratory but i i just prefer running it locally but i guess i guess we could i still haven't looked into that uh tori collaboratory google collab tensorflow i think i mentioned this last week oh yeah or we could just use regular jupiter notebook if we wanted to but i'm i came from c so i'm a big fan of just writing it in the local machine yeah because even for testing a single data we need to train the entire model that's yeah over and over yeah it doesn't keep the state i mean there's probably some way to keep the state um there between between runs in some way like actually you can probably save the neural net um in its current state and they just keep keep running it but yeah i haven't looked into the jupiter notebooks i haven't used juvenile books that much actually at all uh in my in my time programming but i'll try to look into it if it streams like streamlines the process for for next week yeah thank you thank you for the suggestion but uh okay so this is the first test data so again another shoe so apparently this data set is very shoe heavy and um let's actually also print out the uh label so let's go down here and print out the label of this first one so this should be test labels at zero uh yeah so we're just gonna have to wait for the it's train each time for now all right cool so it's a shoe here and then when i put out of this it should say nine which is uh ankle boot so nine is ankle boot so that's the correct label um so that's what we want to see we want to see the correct label here so we're just focusing on this chunk of code here the first test image is issue and the label is nine so now we want to use our trained model to actually predict um what is going to predict what it's going to be so if we print predictions at zero so this is the first image of a shoe in the label then we call model.predict and we pass in all the test images and it's going to give us all the predictions so and then all we need to do is this this is just a list of a bunch of outputs from the neural net so if we go at predictions at zero what we're going to get is we're actually going to get the the list of 10 probabilities for the first image and then if we this if this was predictions at one we would get the list of 10 probabilities for the second image so on and so forth but let's just focus on one at a time so let's um go back to here and run it again yeah i'll look into jupiter notebooks because this is going to get tedious at least it doesn't take it just takes like seven eight seconds not so bad all right and there we go so you see this here this is actually the the list of probabilities that our trained neural net popped out for that test image of that shoe that we just saw pop up so it needs to be nine so um ideally this is going to be the biggest number and it looks like it is like this is all scientific notation so um as this gets bigger that means it's a smaller number so 19 13 38 15 38 3 18 3 12 yeah one so this is actually the biggest number which is the ninth place because this is the probability of it being uh the first thing second thing and last one is ankle boot so this is the biggest number um and uh we can see it's actually performing correctly there but this is really messy and ugly so what i did is i put in a little hack to make it nicer to look at so let's do that together now and that's actually these two lines and all this is doing here is instead of printing out that nasty list of all these probabilities here for each of the 10 different things in the neural net um all i do is i find i use the max function so the max function here so look at this highlighted portion of code here this max function finds the the max number within this list for us which is going to be this last one it'll find this and then i just call index on it so uh so that i can find the the um the index of the the max number in that list so all this is doing here this is kind of messy is it's just getting the index of the biggest number in this list in this case it's going to be 9. so this will just return us the index of the biggest number and that's what i'm printing here instead so let's print that out and see what happens predictions and labels at zero oh again it's got a train okay one last time for this demonstration purpose and then i'll do one more image too because i think it it gets these correct there we go so here's the shoe of the first test image and it's labeled the label is supposed to be nine which pops up and then as you can see here's the 10 probabilities again the probabilities are a little bit different this time because it i guess it trains it in different it trains the neural net in random orders of the images or something like that so it's not always exactly the same but as you can see the it says that this number is the highest because it's the last one so uh it actually predicted this image correctly um i don't know if i printed out twice i think i'm printing it oh because i i print out this again now i don't need this actually let's get rid of that one so as you can see it's well actually put that back let me get rid of this last one um so as you can see it actually predicted it correctly so it's supposed to be 9 and then the neural net predicted it to be 9 as well and if we go to the second image which hopefully is an issue this is bad coding design just popping in the one there like that but just to show you guys so let's see what this is uh hopefully it's a shirt or something okay ah nice a shirt okay or some some type i don't actually don't know what it is it might be it might be pull over or probably probably going to be pull over because it's long sleeve it looks like it's a sweater or something so this is the image the second test image and we see that it's a two labeled as two so yeah it is a pullover too and then this is the probabilities of everything and it seems like a pretty predicted it to be correct so it it accurately predicted predicted it to be a pullover and if we look at this 0 one two yeah it looks like this index is the biggest number because this is only negative one compared to everything else is a little bit bigger don't know what this is it's a little funky um i'm not sure why these are zeroed out but uh yeah it looks like um it's it's predicting it pretty pretty accurately so uh that there is actually it for the for the app let me see if i can get that accuracy thing because this will actually uh test the accuracy of the thing overall i think it was measure accuracy matrix equals accuracy class there you go maybe this yeah so when you're compiling the model you can actually also specify uh different metrics for it to spit out um so if you go back up to compile and i add it here i think it's metrics equals see i think um and then let's just try that and see if it breaks it might break um actually i think it worked well i think it's gonna give an error right now because i didn't specify the oh okay i didn't complain um i think i think they changed some stuff in the new version tensorflow um matrix accuracy maybe this one let's try this since that's what they're telling me to use no actually the accuracy is written there uh below under each epoch open the terminal maybe i noticed did you see something yeah yeah right 81.97 accuracy oh nice i didn't even see that because it was okay pocket shows that finally i didn't see that at all good eye good eye thank you oh nice yeah i only i'll usually only look at lost because you because uh all of all of the machine learning is when the neural net is you're just trying to minimize the loss like at the end of the day you want to get this as close to zero as possible and then this has like an inverse portion to the accuracy so cool so we didn't even have to worry about it um wait was this actually running oh no when i did pop in accuracy it added it on nice so like when i added on this this metrics accuracy so this actually is correct what it is does is i guess it it um added on the the the accuracy metric here so we have the loss um and then i guess uh not sure what this is probably just the timing but yeah the accuracy is is here which is good so we don't have to that's it so that actually that was correct i just didn't i didn't notice it thanks for noticing that um was that you ruben yep is it you thank you ruben no problem so yeah the accuracy there so we can actually say that uh across everything it has a 0.81 accuracy uh for all of the test data so when it's running those 10 000 test images then the accuracy is about about that much oh pretty cool i mean if we run 10 epochs i wonder how much that will actually improve the accuracy of the neural net and i think this can be the last thing we do to wrap it up seven okay yeah it looks like it's increasing slowly nice and then there's the second test image of the shirt but yeah it looks like it's going up slowly i mean it's probably going to level out at some point um because of the structure of the of the neural net like if you have a deeper neural net we might be able to get this up into the 90s or something the accuracy but i mean this is this is pretty good i mean if it's if it's right 83 at the time i feel like that's a pretty decent neural net for the time it took to train it it only took like what 20 seconds 30 seconds so um that that kind of completes it guys for the uh like computer vision example of using tensorflow so a lot more interesting than last week i know last week we kind of just did this this uh this cute little number mapping thing wasn't that interesting and it wasn't that that uh it was just kind of numbers and stuff but this one i think it it kind of shows the power of tensorflow a little bit better because it's so easy to define your models and then flatten it you can tweak all the numbers and all the different functions already implemented for you all different types like dense and flat and it's all there for you which is which is amazing um so i mean that really concludes it for the for this image classification of course we can get a lot more complex and a lot deeper than this but this kind of gives a a good uh introductory example to um computer vision and image classification with tensorflow so uh does anybody have any any questions about anything at all um regarding regarding this just a quick one um if you go up to the where you've got your hidden layer again is it as simple if you were if you wanted to create a network with more than one hidden layer is it just duplicating that piece of code there and having it yep just like that so why don't we try to see what happens um hopefully it doesn't break anything i mean sometimes like i don't know like this might be some memory issues or because you know it exponentially changes stuff or let's let's just make this 64. and see what the heck happens um because yeah the input and the output is still consistent with our data um that we're dealing with the hidden layers can be abstracted to anything we want so uh yeah let's see actually let's run it for that's fine i can just cut it if it breaks all right nice all right there we go so it ran and um it seems like the first loss is a little bit lower than general it doesn't look like it really improved the effectiveness that much i mean also the time didn't go up too much either so it kind of really didn't do anything um yeah i didn't really do much with this data set in this this problem but i mean i mean why don't we try to add oh it's i mean if adding a second one didn't do anything adding a third one is not going to do anything either that's usually how it goes uh well let's try to go to up to 128 and see if that changes anything just see what the heck happens i mean it still predicted it correctly because we added we added more accuracy to it so it makes sense that it's still correct when it when it predicts and the actors actually was a little bit higher right i think it was a little bit higher by like two percent but it's kind of um okay well it seems like this one got worse even though i increased the the length of the hidden layer so yeah i guess this is where the fine tuning comes in and then like there's also like you might over fit to like your training data sometimes like sometimes if you train it too much then it gets so so familiar with the training data that it actually has a reverse effect on um new data like it gets so so well trained to the training data and like that data exactly that it gets stupider the more you train it so there's like a weird tradeoff there too you kind of want to don't train it too much because then you can kind of preserve the generic patterns that are existing in the training set without over fitting it the term is overfitting so when you fit it to this training thing that you kind of want to like not do it too much it's this is balance act this balancing act all right um what would be a practical example of this uh you know in the real life kind of is it like a facial recognition that does the c you know the fbi and they they run is that something similar yeah so i mean tensorflow like there's a lot of applications for machine learning in general uh one that i like to use that just kind of like uh let me just pop up the tensorflow the docket classifier the cat classifier yeah yeah i mean from a standpoint of like okay where is this useful it's just like you could use it for anything like one of the classes i mean i didn't take it but i did a little bit in my time it georgia tech was using machine learning for trading so it's like doing um stocks and understanding trends and stuff in the economy um for day trading and stuff like that but yeah so like uh you can you can use it for applications like that joe to um maybe like find patterns and like stock prices and you're like okay you can kind of use machine learning to figure out like okay tesla stock is going to keep rising because historically it has you can like pick up patterns that humans really can't pick up that that well um so there's stuff like that there but little projects like this are just kind of to just kind of showcase your ability to use tensorflow and stuff like that um but you do need to understand you need to understand like the general machine learning concepts you need to understand how to actually code tensorflow itself and all the little different nuances and the syntax stuff there but then also how you can apply this to like the real world if you actually want to use machine learning uh to your advantage to make it like you know a monetizable skill for yourself uh as a freelancer or as a fulltime developer or something so if if you take your uh stock trade an analogy how would that uh transpose uh when you're talking images versus uh numeric data right at the end of the day the images are just a two by two matrix of numbers which is the pixel brightness so it's just picking up arbitrary patterns in a two by two matrices of numbers so you can actually even pick up similar data within like stock prices and historical data or something like that pick up patterns there be like okay this is a good trend this is a bad trend of a stock price this is a good stock this is a bad stock stuff like that and then you can kind of like label it as this trend is good this trend is bad train it train and train it pop in new trends and then it can kind of tell you if it's good or bad stuff like that's the kind of have you have you thought about doing a class project to do the lot of numbers oh lotto numbers um that would be kind of interesting training to pick a lot of numbers for you well a lot of numbers are kind of com aren't they completely randomized so i mean i don't know if machine learning i mean maybe no but you you get the data on on the uh if you go to the lottery website they give you the past 10 years of data and based on based on historical you know that there are very good chance that they repeat the numbers on that day for that day like they run if you do the what is that it's not truly randomized wait the lotto isn't truly randomized no i'm not this is a friend of mine i think he figured out a way so you know how you play in the one one is at the two o'clock and there's another uh at ten o'clock at night yeah i've never actually done it but i'm so if you if you so this guy he he would download five years of history from the lotto website and then he he had a excel macro created that would color chart basically and then he would just play the numbers that get that the macro would spit out and he was making 42 grand a year oh wow really yeah i mean this is no joke this is the guy i work with and yeah i mean machine learning yeah it's it's powerful yeah because like a lot of stuff i know guys in poker who use it you know they like use it to like play poker and maximize stuff using machine learning by like doing that you can apply it to anything it's just like at the end of the day yeah it's just picking up patterns and data and i guess yeah if the lottery isn't 100 randomized like truly randomized then yeah you can pick up patterns over time and kind of like bend it to your um gambling benefits but uh i've never personally done that i mean it sounds like a cool project though i mean i touched on a good amount of tensorflow so far because it doesn't get too much from here like it doesn't get too much in depth like i've kind of covered like half or sixty percent of like the basic like skills you need to like kind of get started then of course there's all these different functions and then you have to kind of figure out like okay like which optimizer is good for this thing and the different data types and making sure everything is like lined up correctly um maybe i've only done like five or six projects with it like in depth um but uh from there then i mean yeah we could probably it might be interesting to do something like that like i'll like just kind of build a lotto lotto thing together just to see you you you train the model and then you pick a ticket it's a buck and see you know you close like actually you want to like actually get a real a real live number i mean it's not like a dollar or something right yeah maybe and they and then they have the uh they draw a drawing at two o'clock in the afternoon and then they draw it 10 o'clock at night i don't know in connecticut at least they do it i don't know how they do it up in la uh might be different yeah i've never even looked into it i try to stay away from that because i feel like it's just it's like i'd rather just go to vegas you know like at least have some fun with it instead of oh they picked my number no they didn't like vegas you know there's there's people and there's yeah more fun than lotto but um yeah i mean that that's a cool idea i did want to ask though because i have been doing tensorflow stuff and i mean it's been kind of like a twomonth process of like teaching you guys like the algorithms insertion sword and going through numpy and pandas and everything slowly up to this point um but i was talking to kazi the other day too and then he was like yeah like i mean the idea clever programmer is to get you guys the results like maximize results like maximize value for you guys so this stuff i mean it interests me and i'm teaching you guys and i feel i finally got into this point of teaching you guys um a good chunk of tensorflow you guys kind of get your feet wet in it um if you're if you're not pursuing your master's in data science like some some people are in the course which is great but uh i want to ask you guys what would be most of value to you like would it be more of value to you to like go back to web development and like the freelancing stuff because i can kind of brush up on that because i know nasir was talking about he would learn some django rest api stuff so i'm pretty rusty on that but i could i could try to brush up for uh the following weeks and then i know i know your ecommerce website tom i i see you posting about that periodically um stuff like that so i just want you guys input if you guys like doing this this tensorflow stuff or if you guys would prefer to like go back to web development um and we're still in the process process of looking for a really good python developer we're trying to find a guy that can um who has more experience than me to really help you guys scale up you know you are doing good aaron i really like the content of the it was today today was my first class after the first coaching call actually with you and i pretty much pretty much learned a lot of things out of it so i think like you had a machine learning uh career in the past and you are teaching machine learning related stuff so you i think you should pretty much um focus on this maybe like maybe for a bit of change or something you can uh skip on to web development just for the taste of it but maybe you should keep your uh like the path clear in like in which you are comfortable with which is which suits more for you most yeah i mean i could the only thing is that like there are a lot of beginners so that's the problem you run into when you have group like group calls and group sessions is everybody's kind of at a different spot so it's kind of hard to figure out something that's good for everybody without being too beginner or too advanced um machine learning i mean there's probably only like a few edge cases where you'd actually need it like for people if they're advanced and they could probably like land clients or it'd be applicable to some project they're working on but usually they're more advanced usually like whipping up like you know like the amazon club or something or something front end might be a little bit better like the way um like they are within the javascript course or something but about combining say you have create a web interface with maybe a rest interface and you run this algorithm or another algorithm algorithm on the back end and then you output it to the browser or something that'll be cool yeah like tying it together um i mean it'd be cool to like like just take this this project we just did and then like kind of wrap it in like a frontend thing and like maybe save something maybe save the state of the neural net in like some django database so that we have to keep like training it like we did and then maybe we could do something big or something like that could be cool uh okay uh anybody else have have anything they want to say about that though like would they feel like web development might have a little bit more um value for them when it comes to like actually yeah i mean if you look at any anything that's on upwork or any others you know that's more i don't see any tensorflow tensorflow stuff that's i mean unless you unless you have that skill and niche and it's very hard to find that kind of projects but you would find a lot of web development projects there yeah yeah i think like more than 60 percent of the web development i mean whereas we've suggested a kind of a blend of both where you know leverage and you get machine learning learning um output yeah definitely i mean it would be cool and fun to blend it um it would be a fun a fun thing to do but these are all recorded which is why i kind of touch on it because anybody wants to learn all this thing there's like a series of like six videos recorded sessions that they can go through and kind of get started with it which is the great thing with these live calls because they're kind of like they stay there forever um but going forward um i just don't know if that would be more useful for you guys like yeah looking here i've been i haven't been on i've been through that in a long time but tensorflow machine learning data i need to look under jobs not people in my opinion um javascript has a more solid grip in web development and python is more oriented towards machine learning data science it has more to do with the data than the side effect yeah aaron have you what the content you produced on youtube why don't you go over some of that image recognition or car face detection i mean why don't you go over that i could yeah um open cv heavy so i was i didn't really use tensorflow too much for that stuff and then actually we implement i mean because i was it i was at georgia tech so they're very much about like academic research and everything like that that kind of school they're very much about like you know cutting edge research blah blah blah so like we actually had to code like stuff up from scratch like why didn't we use opencv but we would code things like not even using tensorflow um at the beginning yeah i mean yeah i didn't mean it to be specific to uh tensorflow but you know just as the projects oh like opencv um i'm trying to think of what i did yeah there is some word the issue with that is some of the stuff i learned is is like it's fascinating to me because like we get into the dirty math but at the same time i don't it's kind of hard to explain these really complicated concepts too because like it requires like understanding of a lot of calculus and weird things so it's sometimes it's hard to like regurgitate what i learned to you guys so i the stuff on youtube was great though because i kind of boil it down to like the general principles of you know like selfdriving cars and car and pedestrian tracking and everything uh face detection small detection all that stuff was cool but um just it's more tangible you can't relate you can show and demonstrate and then people can understand is that yeah i just try to like trying to find like the the good middle ground of um just like interesting content but useful i mean i could go into opencv a little bit more maybe i could find some cool projects there instead of tensorflow or even tie it together both but um um just on that last topic i was just thinking like where would ai be used in commerce like on a commerce site or something where people are like um matching up buying and selling or search algorithms or yeah so i mean i guess like you know like recommend you know amazon like you know amazon has like that'll be actually pretty cool because i know sunny and then they did the amazon clone and stuff it'd be cool if we implemented like uh you know like a recommended item yeah that's exactly yeah recommended systems are huge in ai or machine learning yeah definitely like that or like or like netflix clone you could have like recommended shows or or spotify clone you got recommended songs um you know how is it trends in people's behavior in netflix it's a if you look if you watch a certain genre movie it recommends hey since you watched this maybe you would interested in and the others like words recommended so yeah right here inspired by your purchases so apparently i was uh why is it recommending this stuff i don't know what this is i reckon it's a regular menu this is why i should get a topic because amazon does this to me all the time i think an insight into your life here flour water salt yeast so apparently i want to learn how to cook bread at some point you bought something today i searched for pizza and i got results for bikinis again this could be someone tagged you on facebook that they they do a lot of cross they do a lot of cross uh hashing too meaning you know yeah one of your friends who tagged you and either the algorithm is weak or the user or the buyers are stupid it could yeah i mean if i had to give any feedback on it this stuff's really interesting i've never never heard of tensorflow before the last week of the week before um i mean so i would probably just echo what the other guys were saying you know just just kind of played your strengths if this is the stuff that you know um yeah and stick with it i think the only thing i would say being new to this is it's all really um it's very abstract um yeah so behind it yeah but i mean the whole concept of what it's doing it's it's kind of you know it's really abstract and um i think if you can find something like what you're just looking here you know the recommended things and how how it could be applied in real world situations um yeah if you can come up if you can come up with something like just a really obvious one like like you said amazon recommended or whatever um this is how you can leverage what you know sort of stuff whether it's tensorflow specifically or this you know the same similar sort of theory just you know different platform whatever they're using um would tensorflow be used in like speech recognition and we have like you have 1000 different languages across the world right yeah absolutely yeah you can use it for voice recognition too because voice recognition at that it's a little different because the files the data is like a little bit different um i mean like once it's once it's within the correct form then it's fine but like voice data is like a continuous stream rather than like you know an image but i mean with like so when i buy the alexa right it's it's that is this thing is this thing built into alexa or or when you speak when you talk to alexites it's communicating with another server that has the machine level being constantly updated it's constantly learning and oh um i actually don't know how it works probably something yeah i think you need to be connected because every time i get disconnected from my my uh echo or whatever devices it doesn't respond mostly the second case joe actually i read about it somewhere that it actually the server trains your data are received by this echo dot it's like it continuously trains your data so so there is dropping on me or they can see they have yep they have all your data actually yeah and it's always it's always learning because i've looked at my election and it's got comes up with like a yellow flashing band on it and it's just you say what are you doing and it says i'm listening to you like it's listening it's listening yeah it says i'm listening to your speech and things going on in the background to like to learn as long as it's powered if you if you don't want it to listen if i take out the power it it won't right no there supposed to be options to disable it i mean this was a huge issue years ago that people it was very big issue a couple years ago yeah the privacy and everything consent and all that right yeah i know mark zuckerberg got busted right for like a similar thing right like yeah because of the data analytica the they did the whole rig the whole election thing well they took the data and they did and they used it for for you know whatever the ads without um yeah but this is interesting it's it's washed um like whoever's doing the machine data science for them you know they have this like you know as a part of the curriculum then it's awesome but for us we'll get into like you know trying to get a project make money make money off of it having but the blended would make more sense in this way at least you can put it in a portfolio that you did this and i'll look it up no worries thank you guys appreciate it yeah absolutely all right i think we've been going on for like almost two and a half hours now um any less questions or um is it time to go get some lunch you guys are on the east coast or something it's 3 30 am over here all right you guys well thanks for sticking to the end um all right guys talk to you guys next week yeah guys and that's really it so i handpicked these four projects for you because i feel like they're just really like a good bitesized project for beginner to go from complete beginner to maybe like beginner intermediate um in ai and really get you started okay other than that you guys i hope you enjoyed the video but if you're interested in actually um excelling your skills on python and actually making a real income from it a real living then um please click on the link below to check out our course profit with python which does just that it pretty much assumes you're a beginner and takes you through the complete roadmap from beginner to actually making an income from beginning to end using python and to actually become a fullfledged python developer all right you guys i know we've been sleeping on python for a long time we've been doing all the javascript stuff you know this might have been plugged in by the way but we've we've been doing uh javascript react stack all that stuff but don't sleep on python because python is huge okay on the back end pretty much everything uses python python's everywhere so you really need to know python as well make sure you know your python you
