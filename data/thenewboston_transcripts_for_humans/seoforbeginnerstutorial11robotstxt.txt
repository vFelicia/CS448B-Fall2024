With timestamps:

00:00 - what is going on ladies and gentlemen
00:01 - welcome back and in this video I'm gonna
00:04 - start talking to you guys about Google's
00:05 - webmaster guidelines now Google's
00:09 - webmaster guidelines are essentially
00:10 - just guidelines made by Google obviously
00:12 - for making a quality website and they
00:16 - have a couple different guidelines and
00:18 - I'm going to talk to you guys about all
00:19 - the different ones but for right now I
00:21 - just want to show you guys this real
00:22 - cool tool I found online and this is VA
00:26 - rvy com VAR v com I guess that's how you
00:30 - pronounce it and what you can do is you
00:32 - can actually just paste in the URL of
00:35 - your website and test it and what this
00:38 - is going to do is it's going to look at
00:40 - your website and it's going to go
00:42 - through and test for every single
00:44 - guideline so this one's good this one's
00:47 - good whenever you see a X it's basically
00:49 - saying hey this website doesn't follow
00:52 - this guideline so my website right now
00:54 - it doesn't have a sitemap and we'll talk
00:56 - a little bit about what that is but
00:58 - essentially it's a really useful tool
01:00 - and it's free so that's pretty cool so
01:03 - as we can see there's a bunch of
01:05 - different guidelines robots.txt on a
01:08 - sitemap make sure you have alt tags in
01:11 - your images yada yada so let's go ahead
01:13 - and break it down and we'll just start
01:15 - with the very first one for this video
01:16 - which is robots dot text so basically
01:21 - any time you make a website you should
01:24 - have a robots I say robots robots dot
01:27 - txt file now what this is is it's
01:30 - basically a plain text file and it goes
01:33 - in the root directory or right after the
01:36 - home directory of your website so
01:38 - whenever you're making one just go ahead
01:40 - and right click new file and just name
01:43 - it robots dot txt all right so what the
01:49 - heck is this this is basically a file
01:52 - that essentially instructs bots on what
01:56 - they're allowed to crawl and what
01:58 - they're not allowed to curl so usually
02:00 - by default what's going to happen is
02:02 - you're going to have some you know
02:04 - search engine BOTS whether it's from
02:06 - being Yahoo whatever and it's just going
02:08 - to start crawling your website every
02:10 - single page that it can possibly find
02:12 - however
02:13 - chances are that you have some resources
02:16 - or webpages that you don't want it to
02:18 - curl for example like the admin page or
02:21 - maybe the moderator panel or maybe just
02:24 - some I don't know like nude pictures
02:26 - that you have online by K this is
02:28 - actually for me so can you leave these
02:30 - out of your search results so basically
02:33 - the way it works is is really simple you
02:35 - only need to remember two things the
02:37 - first is user agent so what you can do
02:40 - is you can write star and that means
02:42 - that these rules that I'm going to tell
02:45 - you they apply to all search engine BOTS
02:48 - however you can also do something like
02:51 - this say that you only want to do make
02:54 - some rules for like Google's search
02:56 - engine BOTS well the name for that is
02:58 - Googlebot so you can do that but the
03:01 - majority of the time you just say user
03:03 - agent star so this means I'm making
03:06 - these rules for all search engine
03:09 - crawlers or BOTS whatever you want to
03:11 - call them now after this line let me
03:13 - pull this up again you essentially have
03:16 - a bunch of these disallowed this allowed
03:18 - disallow now disallow basically says all
03:23 - right you're allowed to crawl every
03:25 - single web page except the ones I'm
03:27 - telling you now if you just wanted to
03:30 - have the search engine mods ignore an
03:33 - entire directory or folder what you can
03:36 - do is write it like this so whenever you
03:41 - write this this means hey don't look at
03:44 - anything in my private directory those
03:46 - are like my personal things I don't want
03:48 - them indexed on your search engine now
03:51 - if you only want to say hey can you
03:55 - ignore one specific page you can do
03:58 - something like this
03:59 - private new pics the HTML or you can say
04:03 - like a admin the HTML and if you have
04:08 - multiple rules say we wanted to disallow
04:12 - admin and the entire private directory
04:15 - and I don't know like a personal
04:20 - password text then this would say hey
04:24 - whenever you're on my site leave these
04:27 - out so again it's just basically
04:30 - instructions on what the search engine
04:32 - but is not allowed to crawl now one
04:34 - other thing and this is actually a
04:36 - really important thing that I want to
04:37 - point out is that keep note that this
04:40 - file is actually used a lot by hackers
04:43 - and malicious people why is that
04:46 - well basically whenever someone goes
04:48 - your site they say hmm I wonder if they
04:50 - got any you know sensitive areas any you
04:54 - know web pages on here that they really
04:56 - don't want the public to know about well
04:58 - what they do is they just look for a
05:00 - robots.txt file and again the majority
05:02 - of the time this is just going to be
05:03 - used by search engines but it's actually
05:05 - readable by anyone so if they see a file
05:09 - or you know some directory in here like
05:11 - passwords or database or you know
05:15 - personal stuff then they're pretty much
05:17 - just going to go to it so again make
05:19 - sure that you never upload any sensitive
05:21 - information and also just be aware that
05:25 - hackers may look for these pages and
05:28 - these are pretty much um I know for a
05:31 - lot of people who don't know this it's
05:34 - basically like giving hackers the
05:36 - blueprint to what to attack on your
05:39 - website so holy moly
05:42 - Hot Tamale so there you go robots that
05:44 - text and since we have a little bit of
05:46 - time I'll show you guys this
05:48 - I created a patreon account I think
05:51 - that's how you pronounce it so this is
05:54 - basically for donations if you guys feel
05:57 - like donating my goal is for the end of
06:00 - the week I want to raise $25 and by the
06:02 - end of next week I want to raise 7
06:04 - billion dollars so yeah we'll see how
06:06 - that goes and also a cool little thing I
06:09 - did this interview for a website called
06:12 - human fox and they basically just asked
06:15 - me you know how I got started
06:16 - programming um asked me about like
06:19 - education and what my dreams my passions
06:23 - are and you know some pretty cool stuff
06:25 - so if you guys want to check that out
06:27 - feel free human fox comm slash capsule
06:31 - slash
06:31 - bucky so there you go we learned a
06:34 - little bit about robots.txt files and in
06:37 - the next videos we're going to be
06:38 - covering the rest of these guidelines
06:40 - it's going to be shweet so i'll see you
06:42 - guys next time

Cleaned transcript:

what is going on ladies and gentlemen welcome back and in this video I'm gonna start talking to you guys about Google's webmaster guidelines now Google's webmaster guidelines are essentially just guidelines made by Google obviously for making a quality website and they have a couple different guidelines and I'm going to talk to you guys about all the different ones but for right now I just want to show you guys this real cool tool I found online and this is VA rvy com VAR v com I guess that's how you pronounce it and what you can do is you can actually just paste in the URL of your website and test it and what this is going to do is it's going to look at your website and it's going to go through and test for every single guideline so this one's good this one's good whenever you see a X it's basically saying hey this website doesn't follow this guideline so my website right now it doesn't have a sitemap and we'll talk a little bit about what that is but essentially it's a really useful tool and it's free so that's pretty cool so as we can see there's a bunch of different guidelines robots.txt on a sitemap make sure you have alt tags in your images yada yada so let's go ahead and break it down and we'll just start with the very first one for this video which is robots dot text so basically any time you make a website you should have a robots I say robots robots dot txt file now what this is is it's basically a plain text file and it goes in the root directory or right after the home directory of your website so whenever you're making one just go ahead and right click new file and just name it robots dot txt all right so what the heck is this this is basically a file that essentially instructs bots on what they're allowed to crawl and what they're not allowed to curl so usually by default what's going to happen is you're going to have some you know search engine BOTS whether it's from being Yahoo whatever and it's just going to start crawling your website every single page that it can possibly find however chances are that you have some resources or webpages that you don't want it to curl for example like the admin page or maybe the moderator panel or maybe just some I don't know like nude pictures that you have online by K this is actually for me so can you leave these out of your search results so basically the way it works is is really simple you only need to remember two things the first is user agent so what you can do is you can write star and that means that these rules that I'm going to tell you they apply to all search engine BOTS however you can also do something like this say that you only want to do make some rules for like Google's search engine BOTS well the name for that is Googlebot so you can do that but the majority of the time you just say user agent star so this means I'm making these rules for all search engine crawlers or BOTS whatever you want to call them now after this line let me pull this up again you essentially have a bunch of these disallowed this allowed disallow now disallow basically says all right you're allowed to crawl every single web page except the ones I'm telling you now if you just wanted to have the search engine mods ignore an entire directory or folder what you can do is write it like this so whenever you write this this means hey don't look at anything in my private directory those are like my personal things I don't want them indexed on your search engine now if you only want to say hey can you ignore one specific page you can do something like this private new pics the HTML or you can say like a admin the HTML and if you have multiple rules say we wanted to disallow admin and the entire private directory and I don't know like a personal password text then this would say hey whenever you're on my site leave these out so again it's just basically instructions on what the search engine but is not allowed to crawl now one other thing and this is actually a really important thing that I want to point out is that keep note that this file is actually used a lot by hackers and malicious people why is that well basically whenever someone goes your site they say hmm I wonder if they got any you know sensitive areas any you know web pages on here that they really don't want the public to know about well what they do is they just look for a robots.txt file and again the majority of the time this is just going to be used by search engines but it's actually readable by anyone so if they see a file or you know some directory in here like passwords or database or you know personal stuff then they're pretty much just going to go to it so again make sure that you never upload any sensitive information and also just be aware that hackers may look for these pages and these are pretty much um I know for a lot of people who don't know this it's basically like giving hackers the blueprint to what to attack on your website so holy moly Hot Tamale so there you go robots that text and since we have a little bit of time I'll show you guys this I created a patreon account I think that's how you pronounce it so this is basically for donations if you guys feel like donating my goal is for the end of the week I want to raise $25 and by the end of next week I want to raise 7 billion dollars so yeah we'll see how that goes and also a cool little thing I did this interview for a website called human fox and they basically just asked me you know how I got started programming um asked me about like education and what my dreams my passions are and you know some pretty cool stuff so if you guys want to check that out feel free human fox comm slash capsule slash bucky so there you go we learned a little bit about robots.txt files and in the next videos we're going to be covering the rest of these guidelines it's going to be shweet so i'll see you guys next time
