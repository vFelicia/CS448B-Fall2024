With timestamps:

00:00 - in this lesson, we will see how to deduce
00:04 - and calculate
00:06 - running time of an algorithm
00:08 - and analyze the
00:09 - time complexity of it
00:11 - the actual time taken by an algorithm
00:13 - or what we also call the
00:15 - running time of the algorithm
00:17 - may depend upon a number of factors
00:20 - and let us see what those factors are, so we will say that
00:23 - running time
00:24 - depends upon
00:26 - factors like
00:27 - whether your machine
00:28 - is a single processor machine
00:30 - or a multiple processor machine
00:35 - and may be also upon which generation of processor you have
00:39 - running time also depends upon what is the read or write speed
00:44 - onto
00:45 - the memory of your machine, so we will say
that
00:48 - read or write speed to memory
00:50 - or disk because
00:52 - your program may have or will surely have
00:55 - a lot of input-output
00:57 - operations
00:59 - running time also depends upon whether
your machine is a thirty two-bit
01:02 - architecture
01:04 - or a 64 bit architecture
01:06 - and it may also depend upon
01:07 - couple of other factors or aspects
01:10 - relating the configuration of the machine on which you're running your program
01:14 - and last but not least, it also depends upon what input you're giving to your
01:19 - program or algorithm
01:21 - now when we
01:22 - talk about
01:23 - time complexity analysis of an algorithm
01:26 - we do not bother about
01:28 - all these factors
01:30 - all we bother about is that how our 
01:32 - program behaves
01:33 - for various inputs or how the time taken
by the program grows
01:38 - with the input to the program
01:39 - so mostly, we are interested in the rate of growth
01:43 - of time taken
01:45 - with respect to
01:46 - the input
01:49 - now how do we calculate an expression that
01:51 - gives us the rate of growth of time
01:55 - of an algorithm with respect to the input
01:58 - To do so, we first define a model machine
02:01 - where we will
02:02 - execute our program
02:03 - so let's say be defined a hypothetical
02:07 - model machine with
02:08 - below characteristics
02:10 - it is a single processor machine
02:13 - the architecture of the machine is 32-bit
02:17 - it executes the instructions in the
program
02:20 - sequentially
02:22 - and let us say
02:23 - it takes
02:24 - one unit of time for
02:26 - simple arithmetical and logical
operations like
02:30 - addition subtraction multiplication
division
02:35 - so, 1 unit time for arithmetical and logical operations
02:42 - and it also takes
02:43 - one unit of time
02:46 - assignment to a variable and also one
unit of time
02:49 - to return from a function
02:52 - so one unit for assignment and
02:55 - return
02:56 - and let's say all other costs are negligible
and we do not account for it
03:01 - now this is a hypothetical model machine
that i have defined
03:05 - and you can define
03:07 - a model machine of your own choice where
you can say that hey, this takes
03:11 - the machine takes
03:12 - this much amount of time for this operation
03:15 - but because eventually we are interested
in calculating a function that gives us
03:19 - the rate of growth of
03:21 - time with respect to input
03:23 - the analysis
03:25 - the analysis will still be the same
03:28 - Now, let us pick up some very simple
examples and try to
03:31 - deduce the functions
03:33 - that define the rate of growth
03:36 - with respect to the input
03:38 - and i will clear this a little bit
03:41 - let's say we want to write a program
03:43 - to find the sum of two numbers
03:45 - a and b, so i will write a function
here
03:49 - that we take
03:49 - two integers 
03:51 - a and b
03:52 - and simply return
03:54 - a + b
03:56 - and i'm only writing a pseudo-code here
03:58 - Now, if i want to go in this particular
04:01 - function using the modal machine
04:05 - then let's say if the time taken is T
04:09 - and let's say this is T(sum)
04:12 - then one unit of time
04:14 - for the arithmetic operation, addition and
one unit of time
04:19 - for the return statement
04:20 - so the total time
04:22 - would be equal to
04:23 - 2 units
04:24 - so in this case irrespective of the input
to the program
04:28 - the time taken is exactly 2 units
04:31 - or we can also say that the time taken
 is always constant so this particular
04:35 - program is a
04:37 - constant
04:40 - time algorithm
04:43 - now let's pick up another example
04:46 - let's say we want to write a program
04:49 - that gives me
04:50 - the some of all the elements in a list
04:53 - so i would write
04:54 - a function sum of list that will take
04:58 - a one-dimensional array
05:00 - A as input and
05:02 - let's say it also takes as argument to the function the size
05:06 - of the array
05:08 - so the size of the array is n
05:10 - so in this case the program goes like
05:13 - so we start with a variable total and we initialize it to 
05:18 - zero
05:19 - and then we run a loop
05:20 - and keep on adding the elements
05:23 - of the array
05:25 - into this particular variable and finally
05:27 - return it after we come out of the loop
05:30 - and before we calculate the time taken, let's
05:33 - do something
05:35 - here, i will
05:36 - label these
05:38 - statements with line numbers one two three
and four
05:41 - now line one has one assignment
05:44 - so the cost will be one unit
05:46 - and this particular statement will be
executed exactly once
05:51 - line 2 has one
05:54 - comparision
05:55 - which is often there in a loop and since i have written a pseudo-code here only
05:59 - so let's assume that we have one comparison and one increment and 
06:03 - both have cost one unit each
06:05 - and the total cost to execute line 2 is
06:08 - 2 units
06:11 - and this will execute
06:13 - n +1 times
06:15 - one extra time for the false condition when
06:18 - the program actually exits the loop
06:21 - and this
06:22 - also has a cost of two units one for the addition and one for assignment here, so
06:28 - this executes
06:28 - n times
06:30 - and the last line is a simpl return which
executes
06:33 - once and has a cost of one
06:35 - so the total cost let's say is
06:39 - T(SumOfList)
06:40 - is equal to
06:41 - one plus
06:44 - 2*(n +1)
06:47 - + 2*n
06:48 - +1
06:51 - and this eventually
06:52 - evaluates to
06:53 - 4n + 4
06:57 - Now, if this sounds a little messy to
07:00 - mark these absolute terms here in cost
07:04 - we can also write some constants here like the cost of executing Line 1 is say 
07:08 - c1
07:09 - and the cost of executing line 2
07:12 - can be called c2 and we can go on like
this
07:16 - and then also, we can try to 
07:19 - calculate the total cost. So in that case we will arrive at some expression like
07:25 - time taken is a function of n
07:28 - T(n) which is equal to
07:30 - some constant let's say c times n
07:34 - plus another constant c'
07:37 - where c
07:39 - is equal to
07:40 -  c2+ c3
07:42 - and c' is equal to
07:46 - c1 + c2 + c4
07:49 - but these constants are not so  important
because
07:51 - we are interested in the rate of growth of  the time taken
07:55 - and in this case, clearly
07:57 - the time taken grows as a linear function
08:01 - simply because it's proportional to n
08:05 - so for the first example that we had picked
08:08 - we had the time taken
08:10 - to sum up two elements
08:12 - equal to some constant let's say this
constant was k
08:16 - the second example was where we wanted to have
08:19 - sum of
08:20 - elements in a list
08:22 - and in this case
08:23 - our time taken
08:25 - was a linear function of n,  something
like c*n + c' where
08:30 - c and c'
08:31 - are some constants
08:32 - if  we want to print
08:35 - or calculate the sum of
08:37 - elements in a two dimensional matrix of size n*n, then
08:42 - if you try to deduce
08:45 - the time taken in that particular situation
08:48 - the expression
08:49 - would be something like
08:52 - an^2 + bn + c, where a, b 
08:56 - and c are  some constants. so you will get ome
08:58 - quadratic equation like this, quadratic
function like this
09:02 - and if we
09:03 - try to plot these three
09:05 - functions on this graph
09:08 - then  we get something like this
09:13 - in fact x-aixs here is
09:15 - and should be
09:16 - input size
09:18 - so we can call it, let's say n
09:21 - clearly, for higher values of n, the rate of growth
09:24 - of
09:25 - the quadratic function
09:27 - is a lot more than the rate of growth of the linear function
09:31 - We often classify these
09:33 - functions in set
09:36 - where the rate of growth of all the
functions in a particular set is
09:42 - very similar
09:44 - for example big-oh of
09:47 - n square
09:49 - will define the set of 
09:51 - all the functions
09:53 - of the form an^2 + bn + c
09:56 - similarly
09:57 - all the functions like linear  functions
10:00 - like cn + c'
10:02 - would be defined by O(n), so O(n) is the 
the set of
10:05 - all the functions
10:07 - of this particular farm
10:09 - All the functions 
10:11 - of the form
10:12 - time equal to some constant
10:14 - belong to the set
10:16 - O(1) and this is the same big -oh
notation that
10:19 - we're talking about all this while, we
have been talking about all this
10:23 - this classification of  functions into these sets
10:28 - is done using
10:30 - the concept of
10:31 - asymptotic
10:32 - bbounds which is a very fundamental concept in
10:35 - time complexity analysis
10:37 - big-oh is actually called an
10:40 - asymptotic notation
10:42 - so this big-h that we
10:44 - often write is
10:46 - called an
10:47 - asymptotic
10:48 - notation
10:50 - and we also have others asymptotic notations like
10:53 - theta and
10:55 - omega
10:56 - and we'll learn about all of them
10:59 - in the next lesson
11:00 - so thanks for watching

Cleaned transcript:

in this lesson, we will see how to deduce and calculate running time of an algorithm and analyze the time complexity of it the actual time taken by an algorithm or what we also call the running time of the algorithm may depend upon a number of factors and let us see what those factors are, so we will say that running time depends upon factors like whether your machine is a single processor machine or a multiple processor machine and may be also upon which generation of processor you have running time also depends upon what is the read or write speed onto the memory of your machine, so we will say that read or write speed to memory or disk because your program may have or will surely have a lot of inputoutput operations running time also depends upon whether your machine is a thirty twobit architecture or a 64 bit architecture and it may also depend upon couple of other factors or aspects relating the configuration of the machine on which you're running your program and last but not least, it also depends upon what input you're giving to your program or algorithm now when we talk about time complexity analysis of an algorithm we do not bother about all these factors all we bother about is that how our program behaves for various inputs or how the time taken by the program grows with the input to the program so mostly, we are interested in the rate of growth of time taken with respect to the input now how do we calculate an expression that gives us the rate of growth of time of an algorithm with respect to the input To do so, we first define a model machine where we will execute our program so let's say be defined a hypothetical model machine with below characteristics it is a single processor machine the architecture of the machine is 32bit it executes the instructions in the program sequentially and let us say it takes one unit of time for simple arithmetical and logical operations like addition subtraction multiplication division so, 1 unit time for arithmetical and logical operations and it also takes one unit of time assignment to a variable and also one unit of time to return from a function so one unit for assignment and return and let's say all other costs are negligible and we do not account for it now this is a hypothetical model machine that i have defined and you can define a model machine of your own choice where you can say that hey, this takes the machine takes this much amount of time for this operation but because eventually we are interested in calculating a function that gives us the rate of growth of time with respect to input the analysis the analysis will still be the same Now, let us pick up some very simple examples and try to deduce the functions that define the rate of growth with respect to the input and i will clear this a little bit let's say we want to write a program to find the sum of two numbers a and b, so i will write a function here that we take two integers a and b and simply return a + b and i'm only writing a pseudocode here Now, if i want to go in this particular function using the modal machine then let's say if the time taken is T and let's say this is T(sum) then one unit of time for the arithmetic operation, addition and one unit of time for the return statement so the total time would be equal to 2 units so in this case irrespective of the input to the program the time taken is exactly 2 units or we can also say that the time taken is always constant so this particular program is a constant time algorithm now let's pick up another example let's say we want to write a program that gives me the some of all the elements in a list so i would write a function sum of list that will take a onedimensional array A as input and let's say it also takes as argument to the function the size of the array so the size of the array is n so in this case the program goes like so we start with a variable total and we initialize it to zero and then we run a loop and keep on adding the elements of the array into this particular variable and finally return it after we come out of the loop and before we calculate the time taken, let's do something here, i will label these statements with line numbers one two three and four now line one has one assignment so the cost will be one unit and this particular statement will be executed exactly once line 2 has one comparision which is often there in a loop and since i have written a pseudocode here only so let's assume that we have one comparison and one increment and both have cost one unit each and the total cost to execute line 2 is 2 units and this will execute n +1 times one extra time for the false condition when the program actually exits the loop and this also has a cost of two units one for the addition and one for assignment here, so this executes n times and the last line is a simpl return which executes once and has a cost of one so the total cost let's say is T(SumOfList) is equal to one plus 2*(n +1) + 2*n +1 and this eventually evaluates to 4n + 4 Now, if this sounds a little messy to mark these absolute terms here in cost we can also write some constants here like the cost of executing Line 1 is say c1 and the cost of executing line 2 can be called c2 and we can go on like this and then also, we can try to calculate the total cost. So in that case we will arrive at some expression like time taken is a function of n T(n) which is equal to some constant let's say c times n plus another constant c' where c is equal to c2+ c3 and c' is equal to c1 + c2 + c4 but these constants are not so important because we are interested in the rate of growth of the time taken and in this case, clearly the time taken grows as a linear function simply because it's proportional to n so for the first example that we had picked we had the time taken to sum up two elements equal to some constant let's say this constant was k the second example was where we wanted to have sum of elements in a list and in this case our time taken was a linear function of n, something like c*n + c' where c and c' are some constants if we want to print or calculate the sum of elements in a two dimensional matrix of size n*n, then if you try to deduce the time taken in that particular situation the expression would be something like an^2 + bn + c, where a, b and c are some constants. so you will get ome quadratic equation like this, quadratic function like this and if we try to plot these three functions on this graph then we get something like this in fact xaixs here is and should be input size so we can call it, let's say n clearly, for higher values of n, the rate of growth of the quadratic function is a lot more than the rate of growth of the linear function We often classify these functions in set where the rate of growth of all the functions in a particular set is very similar for example bigoh of n square will define the set of all the functions of the form an^2 + bn + c similarly all the functions like linear functions like cn + c' would be defined by O(n), so O(n) is the the set of all the functions of this particular farm All the functions of the form time equal to some constant belong to the set O(1) and this is the same big oh notation that we're talking about all this while, we have been talking about all this this classification of functions into these sets is done using the concept of asymptotic bbounds which is a very fundamental concept in time complexity analysis bigoh is actually called an asymptotic notation so this bigh that we often write is called an asymptotic notation and we also have others asymptotic notations like theta and omega and we'll learn about all of them in the next lesson so thanks for watching
