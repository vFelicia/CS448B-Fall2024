With timestamps:

00:00 - so in our previous lesson we talked
00:02 - about adjacency matrix as a way to store
00:07 - and represent graph and as we discussed
00:09 - and analyzed this data structure we saw
00:12 - that it's very efficient in terms of
00:15 - time cost of operations with this data
00:19 - structure it costs Big O of 1 that is
00:23 - constant time to find if two nodes are
00:26 - connected or not and it costs Big O of V
00:30 - where V is number of vertices to find
00:34 - all nodes adjacent to a given node but
00:38 - we also saw that adjacency matrix is not
00:41 - very efficient when it comes to space
00:44 - consumption we consume space in order of
00:47 - square of number of vertices in
00:50 - adjacency matrix representation as you
00:53 - know we store edges in a two-dimensional
00:56 - array or matrix of size V cross V where
00:59 - V is number of vertices in my example
01:03 - graph here we have 8 vertices that's why
01:06 - I have an 8 cross 8 matrix here we are
01:09 - consuming 8 square that is 64 units of
01:13 - space here now what's basically
01:15 - happening is that for each vertex for
01:18 - each node we have a row in this matrix
01:21 - where we are storing information about
01:24 - all its connections this is the row for
01:27 - the zeroth node that is a this is the
01:30 - row for the one at node that is B this
01:33 - is for C and we can go on like this so
01:36 - each node has got a row and a row is
01:40 - basically a one dimensional array of
01:42 - size equal to number of vertices that is
01:46 - V and what exactly are we storing in a
01:50 - row let's just look at this first row in
01:53 - which we are storing connections of node
01:56 - a this two-dimensional matrix or array
01:59 - that we have here is basically an array
02:02 - of one-dimensional arrays so each row
02:05 - has to be one dimensional array so how
02:08 - are we storing the connections of node a
02:10 - in these eight cells in
02:13 - is one dimensional array of size 8/0
02:17 - in the zeroeth position means that there
02:21 - is no edge starting a and ending at zero
02:26 - at node which again is a an edge
02:30 - starting and ending at itself is called
02:32 - a self-loop and there is no self loop on
02:36 - a of one in one at position here means
02:40 - that there is an edge from a to 1 at
02:45 - node that is B the way via storing
02:48 - information here is that index or
02:51 - position in this one-dimensional array
02:53 - is being used to represent endpoint of
02:57 - an edge for this complete row for this
02:59 - complete one-dimensional array
03:01 - start is always the same it's always the
03:05 - zeroth node that is a in general in the
03:08 - adjacency matrix row index represents
03:10 - the start point and column index
03:14 - represents the end point now here when
03:17 - we are looking only at the first row
03:19 - start is always a and the indices 0 1 2
03:24 - and so on are representing the endpoints
03:27 - and the value at a particular index or
03:30 - position tells us whether we have an
03:33 - edge ending at that node or not 1 here
03:38 - means that the edge exists 0 would have
03:41 - meant that that edge does not exist now
03:44 - when we are storing information like
03:46 - this if you can see we are not just
03:48 - storing that b c and d are connected to
03:52 - a we are also storing the knot of it
03:55 - we are also storing the information that
03:57 - a e f g and h are not connected to a if
04:03 - we are storing what all nodes are
04:05 - connected through that we can also
04:07 - deduce what all nodes are not connected
04:10 - these zeros in my opinion are redundant
04:14 - information causing extra consumption of
04:16 - memory most real-world graphs are sparse
04:19 - that is number of connections is really
04:22 - small compared to total number of
04:24 - possible connections so more
04:27 - often there would be too many zeros and
04:30 - very few once think about it let's say
04:34 - we are trying to store connections in a
04:36 - social network like Facebook in an
04:38 - adjacency matrix which would be the most
04:42 - impractical thing to do in my opinion
04:44 - but anyway for the sake of argument
04:47 - let's say we are trying to do it just to
04:50 - store connections of one user I would
04:54 - have a row or one dimensional matrix of
04:57 - size 10 to the power 9 on an average in
05:00 - a social network you would not have more
05:02 - than thousand friends if I have thousand
05:06 - friends then in the row used to store my
05:08 - connections I would only have thousand
05:12 - ones and rest that is 10 to the power 9
05:16 - minus thousand would be citizen and I'm
05:20 - not trying to force you to agree but
05:22 - just like me if you also think that
05:25 - these zeros are storing redundant
05:28 - information and our extra consumption of
05:31 - memory then even if we are storing these
05:34 - ones and zeros in just one byte as
05:38 - boolean values these many zeros here is
05:42 - almost one gigabyte of memory once are
05:47 - just of one kilobyte so given this
05:51 - problem let's try to do something
05:52 - different here let's just try to keep
05:55 - the information that these nodes are
05:58 - connected and get rid of the information
06:01 - that these nodes are not connected
06:03 - because it can be inferred it can be
06:06 - deduced and there are a couple of ways
06:09 - in which we can do this here to store
06:12 - connections of a instead of using an
06:14 - array such that index represents
06:18 - endpoint of an edge and value at that
06:21 - particular index represents whether we
06:23 - have an edge ending there or not we can
06:26 - simply keep a list of all the nodes to
06:29 - which we are connected this is the list
06:31 - or set of nodes to which a is connected
06:35 - we can represent this list either using
06:39 - the indices or
06:41 - using the actual names for the notes
06:44 - let's just use indices because names can
06:48 - be long and may consume more memory you
06:51 - can always look at the vertex list and
06:53 - find out the name in constant time now
06:56 - in a machine we can store this set of
06:58 - nodes which basically is a set of
07:01 - integers in something as simple as an
07:04 - array and this array as you can see is a
07:07 - different arrangement from our previous
07:09 - array in our earlier arrangement index
07:13 - was representing index of one node in
07:16 - the graph and value was representing
07:18 - whether there was a connection to that
07:21 - node or not here index does not
07:24 - represent anything and the values are
07:27 - the actual indices of the nodes to which
07:31 - we are connected now instead of using an
07:34 - array here to store this set of integers
07:36 - we can also use a linked list and widest
07:41 - array or linked list I would argue that
07:43 - we can also use a true here in fact a
07:47 - binary search tree is a good way to
07:50 - store a set of values there are ways to
07:53 - keep a binary search tree balanced and
07:55 - if you always keep a binary search tree
07:57 - balanced you can perform search
08:01 - insertion and deletion all three
08:04 - operations in order of log of number of
08:08 - nodes we will discuss cost of operations
08:11 - for any of these possible ways in some
08:14 - time right now all I want to say is that
08:16 - there are a bunch of ways in which we
08:19 - can store connections of a node for our
08:22 - example graph that we started with
08:24 - instead of an adjacency matrix we can
08:28 - try to do something like this we are
08:31 - still storing the same information we
08:33 - are still saying that 0 each node is
08:36 - connected to one at to it and 3 at node
08:38 - one eighth note is connected to 0 at
08:41 - fourth and fifth node to Earth node is
08:44 - connected to 0 eighth and sixth node and
08:47 - so on but we are consuming a lot less
08:50 - memory here programmatically this
08:53 - adjacency matrix here
08:55 - is just a two-dimensional array of size
08:58 - 8 cross 8 so we are consuming 64 units
09:03 - of space in total but this structure in
09:07 - right does not have all the rules of
09:10 - same size how do you think we can create
09:14 - such a structure programmatically well
09:18 - it depends in c or c++ if you understand
09:22 - pointers then we can create an array of
09:25 - pointers of size 8 and each pointer can
09:31 - point to a 1 dimensional array of
09:34 - different size 0 8 pointer can point to
09:38 - an array of size 3 because 0 8th node
09:42 - has 3 connections and we need an array
09:46 - of size 3 one at pointer can point to an
09:51 - array of size 3 because one it's node
09:53 - also has 3 connections to its node
09:56 - however has only 2 connections so 2 its
10:00 - pointer should point to an array of size
10:03 - 2 and we can go on like this the 7th
10:07 - node has four connections so 7th pointer
10:12 - should should point to an array of size
10:15 - 4 if you do not understand any of this
10:19 - point to think that I am doing right now
10:21 - you can refer to my code schools lesson
10:25 - titled pointers and arrays the link to
10:29 - which you can find in the description of
10:31 - this video but think about it the basic
10:34 - idea is that each row can be a
10:37 - one-dimensional array of different size
10:39 - and you can implement this with whatever
10:42 - tools you have in your favorite
10:44 - programming language now let's quickly
10:47 - see what are the pros and cons of this
10:51 - structure in the write in comparison to
10:54 - the matrix in the left
10:56 - we are definitely consuming less memory
10:58 - with the structure in right with
11:01 - adjacency matrix our space consumption
11:04 - is proportional to square of number of
11:06 - vertices while with this second
11:09 - structure space consumption is
11:11 - proportional to number of edges and we
11:16 - know that most real world graphs are
11:18 - sparse that is the number of edges is
11:22 - really small in comparison to square of
11:26 - number of vertices square of number of
11:28 - vertices is basically total number of
11:31 - possible edges and for us to reach this
11:34 - number every node should be connected to
11:37 - every other node in most graphs a node
11:40 - is connected to few other nodes and not
11:43 - all other nodes in the second structure
11:46 - we are avoiding this typical problem of
11:49 - too much space consumption in an
11:51 - adjacency matrix by only keeping the
11:55 - ones and getting rid of the redundant
11:59 - zeros here for an undirected graph like
12:03 - this one we would consume exactly 2 into
12:06 - number of edges units of memory and for
12:10 - a directed graph we would consume
12:12 - exactly ethat is number of edges units
12:16 - of memory but all in all space
12:19 - consumption will be proportional to
12:21 - number of edges or in other words space
12:24 - complexity would be big o of e so the
12:29 - second structure is definitely better in
12:31 - terms of space consumption but let's now
12:34 - also try to compare these two structures
12:36 - for time cost of operations what do you
12:40 - think would be the time cost of finding
12:42 - if two nodes are connected or not we
12:45 - know that it's constant time or Big O of
12:48 - 1 for an adjacency matrix because if we
12:52 - know the start and end point we know the
12:55 - cell in which to look for 0 or 1 but in
13:00 - the second structure we cannot do this
13:03 - we will have to scan through a row so if
13:07 - I ask you something like can you tell me
13:09 - if there is a connection from node 0 to
13:12 - 7 then you will have to scan this 0 at
13:16 - row you will have to perform a linear
13:19 - search on this 0 at row to find 7
13:23 - right now all the rows in this structure
13:27 - are sorted you can argue that I can keep
13:30 - all the rules sorted and then I can
13:33 - perform a binary search which would be a
13:37 - lot less costlier that's fine but if you
13:41 - just perform a linear search then in
13:44 - worst case we can have exactly V that is
13:48 - number of vertices cells in a row so if
13:53 - we perform a linear search in worst case
13:56 - we will take time proportional to number
14:00 - of vertices and of course the time cost
14:04 - would be big-oh of log V if we would
14:08 - perform a binary search logarithmic run
14:12 - times are really good but to get this
14:15 - here we always need to keep our rows
14:17 - sorted keeping an array always sorted is
14:22 - costly in other ways and I'll come back
14:25 - to it later for now let's just say that
14:28 - this would cost us big o of V now what
14:34 - do you think would be the time cost of
14:36 - finding all nodes adjacent to a given
14:40 - node that is finding all neighbors of a
14:44 - node well even in case of a jason c
14:47 - matrix we now have to scan a complete
14:50 - row so it would be Big O of V for the
14:55 - matrix as well as this second structure
14:59 - here because here also in worst case we
15:02 - can have V cells in a row equivalent to
15:06 - having all one's in a row in an
15:09 - adjacency matrix when we try to see the
15:12 - time cost of an operation and we mostly
15:14 - analyze the worst case so for this
15:17 - operation we are Big O of V for both so
15:21 - this is the picture that we are getting
15:23 - looks like we are saving some space with
15:26 - the second structure but we are not
15:28 - saving much on time well I would still
15:32 - argue that it's not true when we analyze
15:36 - time
15:37 - city we mostly analyze it for the worst
15:39 - case but what if we already know that we
15:43 - are not going to hit the worst case if
15:45 - we can go back to our previous
15:47 - assumption that we are dealing with a
15:50 - sparse graph that we are dealing with a
15:54 - graph in which a node would be connected
15:57 - to few other nodes and not all other
16:00 - nodes then the second structure will
16:03 - definitely save us time things would
16:06 - look better once again if we would
16:07 - analyze them in context of a social
16:10 - network
16:11 - I'll set some assumptions let's say we
16:14 - have a billion users in our social
16:17 - network and the maximum number of
16:19 - friends that anybody has is 10,000 and
16:24 - let's also assume computational power of
16:27 - our machine let's say our machine or
16:30 - system can scan or read 10 to the power
16:35 - 6 cells in a second and this is a
16:38 - reasonable assumption because machines
16:40 - often execute a couple of millions
16:43 - instructions per second now what would
16:46 - be the actual cost of finding all nodes
16:49 - adjacent to a given node in a Jason Z
16:53 - matrix well we will have to scan a
16:55 - complete row in the matrix that would be
16:58 - 10 to the power 9 cells because in a
17:02 - matrix we would always have cells equal
17:05 - to number of vertices and if we would
17:09 - divide this by a million we would get
17:12 - the time in seconds to scan a row of 10
17:17 - to the power 9 cells we would take
17:20 - thousand seconds which is also sixteen
17:24 - point six six minutes this is
17:27 - unreasonably high but with the second
17:30 - structure maximum number of cells in a
17:33 - row would be 10,000 because the number
17:37 - of cells would exactly be equal to
17:39 - number of connections and this is the
17:42 - maximum number of friends or connections
17:44 - a person in the network has so here we
17:48 - would take 10 to the power 4 upon 10th
17:50 - the power 6 that is 10 to the power
17:53 - minus 2 seconds which is equal to 10
17:57 - milliseconds 10 milliseconds is not
18:01 - unreasonable now let's try to deduce the
18:04 - cost for the second operation finding if
18:07 - two nodes are connected or not
18:09 - in case of adjacency matrix we would
18:12 - know exactly what cell to read we would
18:15 - know the memory location of that
18:17 - specific cell and reading that one cell
18:21 - would cost us 1 upon 10 to the power 6
18:24 - seconds which is 1 microsecond in the
18:30 - second structure we would not know the
18:31 - exact cell we will have to scan a row so
18:36 - once again maximum time taken would be
18:38 - 10 milliseconds just like finding
18:42 - adjacent nodes so now given this
18:47 - analysis if you would have to design a
18:49 - social network
18:51 - what structure would you choose
18:53 - no-brainer isn't it
18:56 - machine cannot make a user wait for 16
19:00 - minutes would you ever use such a system
19:03 - milliseconds is fine but minutes it's
19:07 - just too much so now we know that for
19:10 - most real-world crafts this second
19:13 - structure is better because it saves us
19:15 - space as well as time and remember I'm
19:19 - saying most and not all because for this
19:23 - logic to be true for my reasoning to be
19:26 - valid graph has to be sparse number of
19:30 - edges has to be significantly lesser
19:32 - than square of number of vertices so now
19:35 - having analyzed space consumption and
19:38 - time cost of at least two most
19:40 - frequently performed operations looks
19:43 - like this second structure would be
19:45 - better for most graphs well and there
19:49 - can be a bunch of operations in a graph
19:51 - and we should account for all kind of
19:54 - operations so before making up my mind I
19:58 - would analyze cost of few more
20:01 - operations what if after storing
20:04 - this example graph in computer's memory
20:07 - in any of these structures we decide to
20:12 - add a new edge let's say we got a new
20:15 - connection in the graph from A to G then
20:19 - how do you think we can store this new
20:22 - information this new edge in both these
20:25 - structures the idea here is to assess
20:29 - that once the structures are created in
20:32 - computer's memory how would we do if the
20:35 - graph changes how would we do if a node
20:38 - or edge is inserted or deleted if a new
20:43 - edge is inserted in case of an adjacency
20:46 - matrix we just need to go to a specific
20:50 - cell and flip the zero at that cell to 1
20:54 - in this case we would go to silhouette
20:58 - row and sixth column and overwrite it
21:02 - with value 1 and if it was a deletion
21:07 - then we would go to a specific cell and
21:10 - make the 1 0 now how about this second
21:14 - structure how would you do it here we
21:18 - need to add a 6 in the first row and if
21:24 - you have followed this series on data
21:26 - structures then you know that it's not
21:29 - possible to dynamically increase size of
21:33 - an existing array this would not be so
21:37 - straightforward we will have to create a
21:41 - new array of size 4 for the zeroth row
21:44 - then we will have to copy content off
21:49 - the old array write the new value and
21:53 - then wipe off the old one from the
21:56 - memory it's tricky implementing dynamic
22:00 - or changing lists using arrays this
22:03 - creation of new array and copying of old
22:06 - data is costly and this is the precise
22:11 - reason why we often use another data
22:14 - structure to store dynamic or changing
22:18 - lists
22:18 - and this another data structure is
22:21 - linked list so why not use a linked list
22:26 - why can't eat Ruby a linked list
22:29 - something like this logically we still
22:33 - have a list here but concrete
22:35 - implementation wise we are no more using
22:38 - an array that we need to change
22:42 - dynamically we are using a linked list
22:45 - it's a lot easier to do insertions and
22:48 - deletions in a linked list now
22:51 - programmatically to create this kind of
22:54 - structure in computer's memory we need
22:57 - to create a linked list for each node to
23:00 - store its neighbors so what we can do is
23:03 - we can create an array of pointers just
23:07 - like what we have done when we were
23:10 - using arrays the only difference would
23:13 - be that this time each of these pointers
23:16 - would point to head of a linked list
23:20 - that would be unknown I have defined
23:24 - node of a linked list here node of a
23:27 - linked list would have two fields one to
23:30 - store data and another to store address
23:33 - of the next node a zero would be a
23:37 - pointer to head our first node of linked
23:41 - list for a a one would be a pointer to
23:44 - head of linked list for B and we will go
23:49 - on like a 2 for C a 3 for D and so on
23:52 - actually I have drawn the linked lists
23:55 - here in the left but I have not drawn
23:56 - the array of pointers let's say this is
24:01 - my array of pointers now a 0 here this
24:04 - one is a pointer to node and it points
24:08 - to the head of linked list containing
24:11 - the neighbors of a let's assume that
24:14 - head of linked list for a has address
24:17 - 400 so in a 0 we would have 400 it's
24:24 - really important to understand what is
24:25 - what here in this structure this one a 0
24:29 - is a pointer to node and all appointed
24:32 - is store an address or reference this
24:36 - one is a node and it has two fields one
24:40 - to store data and another a pointer to
24:44 - node to store the address off next node
24:47 - let's assume that the address of next
24:50 - node in this first linked list is 450
24:53 - then we should have 450 here and if the
24:58 - next one is at let's say 500 then we
25:04 - should have 500 in address part of the
25:06 - second node the address and last one
25:09 - would be zero or null now this kind of
25:13 - structure in which we store information
25:15 - about neighbors of a node in a linked
25:18 - list is what we typically call an
25:21 - adjacency list what I have here is an
25:25 - adjacency list for an undirected
25:27 - unweighted graph to store a weighted
25:31 - graph in an adjacency list I would have
25:35 - one more field in node to store weight I
25:38 - have written some random weights next to
25:41 - the edges in this graph and to store
25:44 - this extra information I have added one
25:47 - extra field in node both in logical
25:52 - structure and the code all right now
25:56 - finally with this particular structure
25:58 - that we are calling adjacency list we
26:01 - should be fine with space consumption
26:03 - space consumed will be proportional to
26:06 - number of edges and not to square of
26:10 - number of vertices most graphs are
26:13 - sparse and number of edges in most cases
26:16 - is significantly lesser than square of
26:19 - number of vertices ideally for space
26:22 - complexity I should say Big O of number
26:25 - of edges plus number of vertices because
26:28 - storing vertices will also consume some
26:31 - memory but if we can assume that number
26:34 - of vertices will be significantly lesser
26:37 - in comparison to number of edges then we
26:40 - can simply say Big O of number of edges
26:42 - but it's always good if we do the
26:45 - counting
26:46 - right now for time cost of operations
26:50 - the argument that we were earlier making
26:52 - using a sparse graph like social network
26:56 - is still true adjacency list would
26:59 - overall be better than adjacency matrix
27:02 - finally let's come back to the question
27:05 - how flexible are we with this structure
27:08 - if we need to add a new connection or
27:11 - delete an existing connection and is
27:15 - there any way we can improve upon it
27:17 - well I leave this for you to think but
27:21 - I'll give you a hint what if instead of
27:23 - using a linked list to store information
27:26 - about all the neighbors we use a binary
27:29 - search tree do you think we would do
27:33 - better for some of these operations I
27:35 - think we would do better because the
27:38 - time cost for searching inserting and
27:41 - deleting a neighbor would reduce with
27:45 - this thought I'll sign off this is it
27:47 - for this lesson thanks for watching

Cleaned transcript:

so in our previous lesson we talked about adjacency matrix as a way to store and represent graph and as we discussed and analyzed this data structure we saw that it's very efficient in terms of time cost of operations with this data structure it costs Big O of 1 that is constant time to find if two nodes are connected or not and it costs Big O of V where V is number of vertices to find all nodes adjacent to a given node but we also saw that adjacency matrix is not very efficient when it comes to space consumption we consume space in order of square of number of vertices in adjacency matrix representation as you know we store edges in a twodimensional array or matrix of size V cross V where V is number of vertices in my example graph here we have 8 vertices that's why I have an 8 cross 8 matrix here we are consuming 8 square that is 64 units of space here now what's basically happening is that for each vertex for each node we have a row in this matrix where we are storing information about all its connections this is the row for the zeroth node that is a this is the row for the one at node that is B this is for C and we can go on like this so each node has got a row and a row is basically a one dimensional array of size equal to number of vertices that is V and what exactly are we storing in a row let's just look at this first row in which we are storing connections of node a this twodimensional matrix or array that we have here is basically an array of onedimensional arrays so each row has to be one dimensional array so how are we storing the connections of node a in these eight cells in is one dimensional array of size 8/0 in the zeroeth position means that there is no edge starting a and ending at zero at node which again is a an edge starting and ending at itself is called a selfloop and there is no self loop on a of one in one at position here means that there is an edge from a to 1 at node that is B the way via storing information here is that index or position in this onedimensional array is being used to represent endpoint of an edge for this complete row for this complete onedimensional array start is always the same it's always the zeroth node that is a in general in the adjacency matrix row index represents the start point and column index represents the end point now here when we are looking only at the first row start is always a and the indices 0 1 2 and so on are representing the endpoints and the value at a particular index or position tells us whether we have an edge ending at that node or not 1 here means that the edge exists 0 would have meant that that edge does not exist now when we are storing information like this if you can see we are not just storing that b c and d are connected to a we are also storing the knot of it we are also storing the information that a e f g and h are not connected to a if we are storing what all nodes are connected through that we can also deduce what all nodes are not connected these zeros in my opinion are redundant information causing extra consumption of memory most realworld graphs are sparse that is number of connections is really small compared to total number of possible connections so more often there would be too many zeros and very few once think about it let's say we are trying to store connections in a social network like Facebook in an adjacency matrix which would be the most impractical thing to do in my opinion but anyway for the sake of argument let's say we are trying to do it just to store connections of one user I would have a row or one dimensional matrix of size 10 to the power 9 on an average in a social network you would not have more than thousand friends if I have thousand friends then in the row used to store my connections I would only have thousand ones and rest that is 10 to the power 9 minus thousand would be citizen and I'm not trying to force you to agree but just like me if you also think that these zeros are storing redundant information and our extra consumption of memory then even if we are storing these ones and zeros in just one byte as boolean values these many zeros here is almost one gigabyte of memory once are just of one kilobyte so given this problem let's try to do something different here let's just try to keep the information that these nodes are connected and get rid of the information that these nodes are not connected because it can be inferred it can be deduced and there are a couple of ways in which we can do this here to store connections of a instead of using an array such that index represents endpoint of an edge and value at that particular index represents whether we have an edge ending there or not we can simply keep a list of all the nodes to which we are connected this is the list or set of nodes to which a is connected we can represent this list either using the indices or using the actual names for the notes let's just use indices because names can be long and may consume more memory you can always look at the vertex list and find out the name in constant time now in a machine we can store this set of nodes which basically is a set of integers in something as simple as an array and this array as you can see is a different arrangement from our previous array in our earlier arrangement index was representing index of one node in the graph and value was representing whether there was a connection to that node or not here index does not represent anything and the values are the actual indices of the nodes to which we are connected now instead of using an array here to store this set of integers we can also use a linked list and widest array or linked list I would argue that we can also use a true here in fact a binary search tree is a good way to store a set of values there are ways to keep a binary search tree balanced and if you always keep a binary search tree balanced you can perform search insertion and deletion all three operations in order of log of number of nodes we will discuss cost of operations for any of these possible ways in some time right now all I want to say is that there are a bunch of ways in which we can store connections of a node for our example graph that we started with instead of an adjacency matrix we can try to do something like this we are still storing the same information we are still saying that 0 each node is connected to one at to it and 3 at node one eighth note is connected to 0 at fourth and fifth node to Earth node is connected to 0 eighth and sixth node and so on but we are consuming a lot less memory here programmatically this adjacency matrix here is just a twodimensional array of size 8 cross 8 so we are consuming 64 units of space in total but this structure in right does not have all the rules of same size how do you think we can create such a structure programmatically well it depends in c or c++ if you understand pointers then we can create an array of pointers of size 8 and each pointer can point to a 1 dimensional array of different size 0 8 pointer can point to an array of size 3 because 0 8th node has 3 connections and we need an array of size 3 one at pointer can point to an array of size 3 because one it's node also has 3 connections to its node however has only 2 connections so 2 its pointer should point to an array of size 2 and we can go on like this the 7th node has four connections so 7th pointer should should point to an array of size 4 if you do not understand any of this point to think that I am doing right now you can refer to my code schools lesson titled pointers and arrays the link to which you can find in the description of this video but think about it the basic idea is that each row can be a onedimensional array of different size and you can implement this with whatever tools you have in your favorite programming language now let's quickly see what are the pros and cons of this structure in the write in comparison to the matrix in the left we are definitely consuming less memory with the structure in right with adjacency matrix our space consumption is proportional to square of number of vertices while with this second structure space consumption is proportional to number of edges and we know that most real world graphs are sparse that is the number of edges is really small in comparison to square of number of vertices square of number of vertices is basically total number of possible edges and for us to reach this number every node should be connected to every other node in most graphs a node is connected to few other nodes and not all other nodes in the second structure we are avoiding this typical problem of too much space consumption in an adjacency matrix by only keeping the ones and getting rid of the redundant zeros here for an undirected graph like this one we would consume exactly 2 into number of edges units of memory and for a directed graph we would consume exactly ethat is number of edges units of memory but all in all space consumption will be proportional to number of edges or in other words space complexity would be big o of e so the second structure is definitely better in terms of space consumption but let's now also try to compare these two structures for time cost of operations what do you think would be the time cost of finding if two nodes are connected or not we know that it's constant time or Big O of 1 for an adjacency matrix because if we know the start and end point we know the cell in which to look for 0 or 1 but in the second structure we cannot do this we will have to scan through a row so if I ask you something like can you tell me if there is a connection from node 0 to 7 then you will have to scan this 0 at row you will have to perform a linear search on this 0 at row to find 7 right now all the rows in this structure are sorted you can argue that I can keep all the rules sorted and then I can perform a binary search which would be a lot less costlier that's fine but if you just perform a linear search then in worst case we can have exactly V that is number of vertices cells in a row so if we perform a linear search in worst case we will take time proportional to number of vertices and of course the time cost would be bigoh of log V if we would perform a binary search logarithmic run times are really good but to get this here we always need to keep our rows sorted keeping an array always sorted is costly in other ways and I'll come back to it later for now let's just say that this would cost us big o of V now what do you think would be the time cost of finding all nodes adjacent to a given node that is finding all neighbors of a node well even in case of a jason c matrix we now have to scan a complete row so it would be Big O of V for the matrix as well as this second structure here because here also in worst case we can have V cells in a row equivalent to having all one's in a row in an adjacency matrix when we try to see the time cost of an operation and we mostly analyze the worst case so for this operation we are Big O of V for both so this is the picture that we are getting looks like we are saving some space with the second structure but we are not saving much on time well I would still argue that it's not true when we analyze time city we mostly analyze it for the worst case but what if we already know that we are not going to hit the worst case if we can go back to our previous assumption that we are dealing with a sparse graph that we are dealing with a graph in which a node would be connected to few other nodes and not all other nodes then the second structure will definitely save us time things would look better once again if we would analyze them in context of a social network I'll set some assumptions let's say we have a billion users in our social network and the maximum number of friends that anybody has is 10,000 and let's also assume computational power of our machine let's say our machine or system can scan or read 10 to the power 6 cells in a second and this is a reasonable assumption because machines often execute a couple of millions instructions per second now what would be the actual cost of finding all nodes adjacent to a given node in a Jason Z matrix well we will have to scan a complete row in the matrix that would be 10 to the power 9 cells because in a matrix we would always have cells equal to number of vertices and if we would divide this by a million we would get the time in seconds to scan a row of 10 to the power 9 cells we would take thousand seconds which is also sixteen point six six minutes this is unreasonably high but with the second structure maximum number of cells in a row would be 10,000 because the number of cells would exactly be equal to number of connections and this is the maximum number of friends or connections a person in the network has so here we would take 10 to the power 4 upon 10th the power 6 that is 10 to the power minus 2 seconds which is equal to 10 milliseconds 10 milliseconds is not unreasonable now let's try to deduce the cost for the second operation finding if two nodes are connected or not in case of adjacency matrix we would know exactly what cell to read we would know the memory location of that specific cell and reading that one cell would cost us 1 upon 10 to the power 6 seconds which is 1 microsecond in the second structure we would not know the exact cell we will have to scan a row so once again maximum time taken would be 10 milliseconds just like finding adjacent nodes so now given this analysis if you would have to design a social network what structure would you choose nobrainer isn't it machine cannot make a user wait for 16 minutes would you ever use such a system milliseconds is fine but minutes it's just too much so now we know that for most realworld crafts this second structure is better because it saves us space as well as time and remember I'm saying most and not all because for this logic to be true for my reasoning to be valid graph has to be sparse number of edges has to be significantly lesser than square of number of vertices so now having analyzed space consumption and time cost of at least two most frequently performed operations looks like this second structure would be better for most graphs well and there can be a bunch of operations in a graph and we should account for all kind of operations so before making up my mind I would analyze cost of few more operations what if after storing this example graph in computer's memory in any of these structures we decide to add a new edge let's say we got a new connection in the graph from A to G then how do you think we can store this new information this new edge in both these structures the idea here is to assess that once the structures are created in computer's memory how would we do if the graph changes how would we do if a node or edge is inserted or deleted if a new edge is inserted in case of an adjacency matrix we just need to go to a specific cell and flip the zero at that cell to 1 in this case we would go to silhouette row and sixth column and overwrite it with value 1 and if it was a deletion then we would go to a specific cell and make the 1 0 now how about this second structure how would you do it here we need to add a 6 in the first row and if you have followed this series on data structures then you know that it's not possible to dynamically increase size of an existing array this would not be so straightforward we will have to create a new array of size 4 for the zeroth row then we will have to copy content off the old array write the new value and then wipe off the old one from the memory it's tricky implementing dynamic or changing lists using arrays this creation of new array and copying of old data is costly and this is the precise reason why we often use another data structure to store dynamic or changing lists and this another data structure is linked list so why not use a linked list why can't eat Ruby a linked list something like this logically we still have a list here but concrete implementation wise we are no more using an array that we need to change dynamically we are using a linked list it's a lot easier to do insertions and deletions in a linked list now programmatically to create this kind of structure in computer's memory we need to create a linked list for each node to store its neighbors so what we can do is we can create an array of pointers just like what we have done when we were using arrays the only difference would be that this time each of these pointers would point to head of a linked list that would be unknown I have defined node of a linked list here node of a linked list would have two fields one to store data and another to store address of the next node a zero would be a pointer to head our first node of linked list for a a one would be a pointer to head of linked list for B and we will go on like a 2 for C a 3 for D and so on actually I have drawn the linked lists here in the left but I have not drawn the array of pointers let's say this is my array of pointers now a 0 here this one is a pointer to node and it points to the head of linked list containing the neighbors of a let's assume that head of linked list for a has address 400 so in a 0 we would have 400 it's really important to understand what is what here in this structure this one a 0 is a pointer to node and all appointed is store an address or reference this one is a node and it has two fields one to store data and another a pointer to node to store the address off next node let's assume that the address of next node in this first linked list is 450 then we should have 450 here and if the next one is at let's say 500 then we should have 500 in address part of the second node the address and last one would be zero or null now this kind of structure in which we store information about neighbors of a node in a linked list is what we typically call an adjacency list what I have here is an adjacency list for an undirected unweighted graph to store a weighted graph in an adjacency list I would have one more field in node to store weight I have written some random weights next to the edges in this graph and to store this extra information I have added one extra field in node both in logical structure and the code all right now finally with this particular structure that we are calling adjacency list we should be fine with space consumption space consumed will be proportional to number of edges and not to square of number of vertices most graphs are sparse and number of edges in most cases is significantly lesser than square of number of vertices ideally for space complexity I should say Big O of number of edges plus number of vertices because storing vertices will also consume some memory but if we can assume that number of vertices will be significantly lesser in comparison to number of edges then we can simply say Big O of number of edges but it's always good if we do the counting right now for time cost of operations the argument that we were earlier making using a sparse graph like social network is still true adjacency list would overall be better than adjacency matrix finally let's come back to the question how flexible are we with this structure if we need to add a new connection or delete an existing connection and is there any way we can improve upon it well I leave this for you to think but I'll give you a hint what if instead of using a linked list to store information about all the neighbors we use a binary search tree do you think we would do better for some of these operations I think we would do better because the time cost for searching inserting and deleting a neighbor would reduce with this thought I'll sign off this is it for this lesson thanks for watching
