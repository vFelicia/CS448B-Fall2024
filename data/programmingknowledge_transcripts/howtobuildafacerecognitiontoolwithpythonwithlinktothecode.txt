00:00 - in this video we are going to do a new
00:02 - machine learning project that is real
00:03 - time facial recognition so let me give
00:06 - you a brief overview that what is the
00:08 - output of the project then we will move
00:10 - to the roadmap that what we are going to
00:12 - do step by step okay so the output of
00:14 - the project is like this we will open up
00:16 - a laptops camera camera or webcam and a
00:20 - colored box
00:21 - uh will surround our face and our name
00:24 - will do that in the box so basically our
00:26 - laptop will recognize our face that who
00:30 - we are in partners of a name so let me
00:32 - just give you an example of that
00:35 - yeah so I've just run my test sample and
00:38 - this is my phase as you can see
00:48 - so basically our camera is recognizing
00:51 - that what is my name and what is the
00:53 - name associated that with that face okay
00:55 - so this is a real-time face recognition
00:58 - whichever system is doing so let us see
01:00 - that how we will proceed to just project
01:03 - so let me give you a road now of this
01:05 - that what we are going to do step by
01:07 - step so basically first we are gonna We
01:10 - Are Gonna feed our video that like we
01:13 - should open our camera and we should
01:15 - record that what phase is in front of
01:17 - the camera right so
01:19 - I have made several separates a snippet
01:23 - of video record it is just to check that
01:25 - whether the camera is working or not so
01:28 - by this code we can check that our
01:30 - camera is working or not
01:33 - um don't be stressed out I will explain
01:34 - each time of the code step by step I'm
01:37 - just sitting the roadmap right now okay
01:38 - so this is about just checking this this
01:42 - code stick that whether our camera is
01:44 - working or not okay so this is a real
01:48 - test and after this
01:51 - okay so after this we are gonna We Are
01:54 - Gonna collect our phase data so
01:57 - basically in this snippet uh this the
02:00 - function of this code is like this this
02:03 - code opens up a camera and uh asks ask
02:06 - ourselves to write our name okay so if I
02:09 - play this sample so it is asking my name
02:13 - so I will enter my name here and after
02:15 - that
02:16 - when I enter Then camera will open and
02:18 - it will start recording my face it will
02:21 - start uh memorizing my face and will put
02:25 - each and every data in an array okay I
02:28 - will explain this entire thing step by
02:30 - step I'm just like giving an overview
02:33 - overview right now okay so it this code
02:36 - recognizes uh this code basically
02:39 - collects our facial facial data and
02:41 - stores it in an array and that array is
02:44 - useful recognition afterwards so after
02:46 - collecting our facial data
02:48 - we will run this code this is basically
02:52 - facial recognition Okay so after
02:55 - collecting our data we will store that
02:58 - data in another area and we will start
03:00 - another live streaming I mean we will
03:03 - start our camera again and it will match
03:06 - that this current phase matches with the
03:09 - previous array and it Maps down the name
03:12 - of the person with that signal okay
03:15 - so basically first step is data data
03:18 - collection over faces and then after
03:20 - that you will do a face evaluation and
03:23 - we will use basically k-means algorithm
03:25 - in this and a classifier that is hard
03:28 - casket classifier okay so this is a
03:31 - brief overview of the project that what
03:33 - we are going to do and now I'm gonna
03:35 - explain you okay so before deeping uh so
03:39 - because before diving into the project
03:42 - let us first see that what is hard
03:44 - casket classifier okay after explaining
03:47 - this Hardcastle classifier I will
03:49 - explain you each and every lines on the
03:50 - code that but we have done step by step
03:52 - okay
04:00 - features line features and many or other
04:03 - features so basic purpose of Hawk asset
04:06 - classifier is it detects each and every
04:09 - feature of our face okay so this is a
04:11 - box it moves in every direction in the
04:14 - in the entire image and it just collects
04:18 - the data that varies our eyes where is
04:20 - our nose I'll show you the animation
04:22 - that how it works before that list you
04:25 - can just see on this website that how uh
04:28 - what is the basic documentation of
04:29 - Hardcastle classical
04:31 - um after this I will show you the
04:33 - animation of this okay so I've done the
04:35 - basic of this so if I enter my image
04:39 - here and the Hardcastle classifier will
04:41 - basically uh classify that where is our
04:45 - eyes and where is our face located in
04:47 - that that entire image okay so as you
04:50 - can see that here is my face and these
04:52 - are my eyes so this simple code which
04:55 - uses hard casket player has just
04:57 - recognized that where are my eyes and
05:00 - where is my face in the entire image
05:02 - okay so now let us see that uh this
05:05 - anyway hard gasket animation
05:09 - foreign
05:13 - classifier is just moving in the entire
05:15 - image and it is just classifying that
05:18 - where is our face and where are the
05:20 - other components of the face so as you
05:23 - can see that uh The Edge features uh
05:25 - line features and the other features of
05:27 - the casket classifier just checking that
05:31 - where are the main features of our face
05:34 - okay so it is traversing the whole image
05:36 - by increasing the size so just see the
05:39 - animation
05:45 - I've increased the size of the uh the
05:47 - speed of the video to 5.5 X so you can
05:50 - see clearly
05:53 - okay so this is how hard cast can
05:55 - classifier works okay
05:58 - so I hope that you will get and you have
06:00 - got a basic idea of that how and
06:03 - Hardcastle classifier works so in this
06:06 - video in this project we are we will be
06:08 - using that hard casket classifier to
06:11 - detect our facial components and after
06:14 - detecting that storing that face into an
06:16 - array mapping that with the name of the
06:19 - person and just recognizing that again
06:21 - by our key means algorithm okay so
06:24 - before that before starting data
06:27 - correction let us check that whether
06:29 - your camera is working or not okay so by
06:33 - this code we will just take that whether
06:35 - our camera is working yes or no okay so
06:39 - let me just explain you this code
06:40 - so this code starting with like we will
06:43 - import CB2 like we will we are importing
06:45 - opencv library and by this cap is equal
06:49 - to CB2 let me just
06:51 - zoom in zoom in okay so second line that
06:54 - cap is CV dot video capture it means
06:57 - that just open our webcam okay so this
07:01 - Line opens up a webcam and
07:03 - this Loop just tells that if our webcam
07:07 - is reading our image
07:10 - then just continue and if it is false
07:14 - then move out of the loop okay so it
07:18 - shows like a video frame it uh okay so
07:21 - let me just open the camera
07:24 - I'm playing this
07:26 - and
07:40 - so as you can see that our camera has
07:42 - been opened and after that this camera
07:46 - name just uh the name of a camera is
07:48 - frame as okay as you can as you have
07:51 - just seen before and after this I have
07:55 - entered this logic that if I press q q
07:59 - as the key if I press the key Cube then
08:02 - it uh breaks the camera and closes the
08:05 - window and the camera will not be closed
08:08 - by the simple uh closing function it
08:12 - will be only closed if you enter queue
08:13 - okay so this is a logic which I entered
08:16 - and I will explain you the purpose of
08:18 - that why I have entered this okay and
08:21 - this is a key pressed this line simply
08:23 - means that uh
08:25 - if our currently pressed key matches
08:28 - with this key or not
08:30 - this is that's it and I will explain
08:32 - this in the meaning of this line later
08:34 - in this project when we are doing data
08:36 - collection
08:37 - okay I will explain the logic behind
08:39 - this that why I am bitwise why I have
08:43 - used bid base and here with ux FM okay
08:47 - so for right now you have to just
08:49 - understand that we have just opened the
08:52 - camera and just checked that if return
08:54 - is equal to false then we will just
08:56 - continue and if our camera is reading
08:58 - then we will just move
09:00 - to move forward and just show the camera
09:04 - that and to stick that with the camera
09:06 - is open or not and we'll just uh close
09:08 - that camera by pressing the Key Queue
09:11 - okay and after that we will release our
09:14 - camera tapped or at least if when we
09:17 - break out of the loop then we just uh
09:20 - the ease of a camera by this line This
09:23 - Means closing the camera and by this it
09:26 - means you're destroying all windows
09:27 - means
09:29 - um
09:29 - disabling all the cookies that has been
09:32 - formed by opening the captain and
09:34 - deleting all the data which has been
09:36 - captured in the back memory okay so this
09:39 - is basically a video Read we are just
09:42 - checking that our camera is reading the
09:44 - video or not
09:45 - okay so I hope that you have got a clear
09:48 - idea that what is this okay so after
09:52 - that we'll do facial data collection we
09:55 - have covered this video Read part like
09:57 - we are just thinking that how video is
09:59 - being readed from your webcam of the
10:01 - laptop or computer and how it has been
10:04 - processed and how it is the video has
10:07 - been stopping so in today's video we're
10:09 - gonna see that how the laptop camera or
10:13 - webcam is reading your face data and
10:16 - storing it in an array to like detect
10:19 - further okay
10:21 - so this file phase data consists that
10:24 - how a phase data is being storing in the
10:28 - memory of computer and we will process
10:30 - it later when we are doing phase
10:32 - detection using knot Okay so
10:36 - so let's get started about it so I will
10:39 - explain you line by line that what each
10:41 - line is doing
10:42 - so so let's get started
10:45 - so first we import two libraries like
10:48 - opencv and numpy Library opencv2 like
10:51 - read the camera feed or open the camera
10:53 - and numpy has basic array operations and
10:57 - some more operations okay so by this
10:59 - line we are just reading we are just
11:00 - opening our webcam and
11:03 - um in this variable cap our webcam has
11:06 - been storing the data is being storing
11:08 - in this cap okay so after that we are
11:11 - using like in previous video I've shown
11:13 - you a hard casket classifier that that
11:15 - is classifying the facial components of
11:18 - the face okay so we have just imported
11:21 - this hard casket classifier in this
11:23 - variable and
11:25 - like this is the location of our gasket
11:28 - classifier so before starting the
11:30 - project uh just see here it is in my D
11:33 - folder D drive and this folder
11:39 - uh we will just download this from the
11:42 - internet it is easily available on
11:44 - GitHub so just download it or I'll give
11:46 - the link in the description okay we do
11:50 - have to store this hard casket file in
11:52 - this directory only so like
11:56 - just wait a second
11:58 - so in my data in my D drive I have a
12:01 - folder called face immigration project
12:03 - and in this folder I have this file hard
12:07 - casket classifier file okay this is hard
12:10 - casket frontal face
12:12 - so you have to just download This by
12:14 - only and this is the mainly classifier
12:17 - we are going to use here so
12:20 - we have just imported this classify here
12:22 - in this variable so let's move forward
12:26 - this script variable just means that uh
12:29 - it I will experience this later when we
12:31 - are just using the script variable here
12:33 - for now just ignore it and in this space
12:37 - data array this is basically a list in
12:40 - which we will be storing each phase data
12:43 - okay so don't be confused you will get
12:46 - clear understanding later when we are
12:49 - proceeding towards it and this data set
12:51 - path is Page data set so this means that
12:56 - the faces which we are storing has to be
12:58 - downloaded or has to be stored in the
13:01 - computer's membrane okay so like if I
13:03 - open my camera and store my face
13:06 - so my computer has to download that face
13:09 - and store that file in a particular
13:11 - folder right so I have just created this
13:14 - folder here so
13:17 - so as you can see that in my D drive
13:19 - I've created a folder field data set by
13:21 - this line okay and this phase data set
13:24 - contains all the files that has been
13:27 - deleted through my camera so if I open
13:29 - it I have just
13:33 - um I have just recorded my face and
13:35 - given my name to this like anything and
13:39 - this uh every data of my camera feed is
13:43 - stored in this data folder in this
13:45 - folder Okay so
13:48 - let's move forward so um so like when we
13:51 - open our camera then we will enter our
13:54 - name there as I just shown you in the
13:56 - previous video when we open the camera
13:58 - we enter our name and after that video
14:01 - starts recording and our face is
14:04 - starting getting recognized and feeding
14:06 - the camera Okay so
14:09 - or we are just giving the input that
14:11 - when we open the camera
14:13 - just enter our name and index and in the
14:17 - console uh this dialog box will appear
14:20 - in where we have to enter our name don't
14:23 - worry I will just when I will just play
14:25 - this video like when I play this code
14:27 - then you will see that but this line is
14:29 - actually doing here in the console
14:31 - okay
14:33 - okay so let us just now uh play it once
14:37 - so when we play this file then this cons
14:40 - in this console you can see that here it
14:42 - is coming like enter your name like
14:45 - enter the name of person so when I write
14:47 - my name here like this and press enter
14:49 - Then the camera will open okay so as of
14:52 - now I'm just stopping this program we
14:54 - will do this later okay so I've just
14:57 - shown you that what how it is being
14:59 - appeared in the console
15:01 - okay so let us move further so now we
15:05 - are opening our camera and we will store
15:07 - our data field now okay so in in a while
15:10 - loop which is always true we are just
15:13 - doing this code so let me just explain
15:14 - that what we are doing here
15:16 - okay so this red comma frame is equal to
15:20 - Capital it means that red is basically a
15:22 - Boolean variable which just check that
15:24 - camera is open or not and frame
15:26 - basically captures uh as a variable
15:29 - where we are defining our camera Okay so
15:33 - and here we are just checking that if
15:36 - the camera is not open then just
15:37 - continue and don't do this iteration and
15:41 - this lines means that we are just
15:44 - converting our uh like initially we will
15:48 - be having a colorful image like we all
15:50 - are colorful right so initially our
15:52 - images are RGB image
15:55 - and in Python we just like RGB like we
15:58 - like we let BGR instead of RGB every
16:00 - time so in this line we are converting
16:04 - our
16:05 - RGB image to a grayscale image okay and
16:09 - to convert that we use this type of
16:12 - syntax like CV2 dot CVT color
16:16 - and frame which is storing your camera
16:19 - feed and CV2 dot color BGR to create BGR
16:24 - to gray means we are converting pgr like
16:27 - R it means RGB we are converting RGB to
16:31 - grayscale take it so this is a syntax
16:35 - so our gray so initially we are having
16:38 - frame in this Frame we are we are having
16:41 - a colorful image and now in this gray
16:44 - frame we will have we will be having a
16:46 - gray scale image okay so grayscale we
16:49 - have converted it to graysk limit
16:51 - because in KN and Quantum it is much
16:53 - easier to like understand a grayscale
16:56 - image and do the algorithm like do the
16:59 - functionalities and Grace Kelly which it
17:01 - is much easier than a colorful image and
17:03 - it doesn't affect the output output is
17:05 - much better in grayscale okay so when we
17:09 - are processing rescue okay so let us
17:11 - move forward
17:13 - and this line like phase is equal to
17:16 - face Cascade dot detect multiscale
17:19 - okay so I will I'm explaining the
17:21 - parameter that is used here so this is a
17:24 - three frame that is we just created here
17:27 - and this is a scaling Factor this is the
17:30 - number of neighbors okay so let me just
17:34 - give a comment here like
17:39 - premium
17:41 - parameters are frame name scaling Factor
17:48 - and number of Neighbors
17:51 - that we defined by K and just we write
17:57 - number of
18:01 - number of tables okay so uh number of
18:04 - neighbors is basically used in KN and
18:06 - Gotham if you don't know that clear then
18:08 - Quantum for now just keep this line I
18:11 - will explain the each and every
18:12 - functionality of scaling Factor K and
18:16 - the whole functionality of this line
18:17 - later when we IMB I will be explaining
18:20 - the KL algorithm because you will get a
18:22 - clear understanding pin Okay so
18:25 - so uh just let me give you a quick
18:27 - overview overview that what is the
18:29 - scaling Factor so initially if our image
18:31 - size if we scale down our image to 1
18:34 - then if we are doing 1.3 then simply
18:37 - means that we are just shrinking our
18:39 - image to 30 percent don't worry I will
18:42 - just explain you this step later when we
18:44 - are doing k n in algorithm so for now
18:46 - let us move further so in this line we
18:49 - are just checking that it faces length
18:51 - equal equal to 0 like if this
18:55 - um
18:56 - if this space is equal equal to 0 then
18:59 - just continue we don't have any phase
19:00 - here okay
19:02 - so as of now just understand that this
19:05 - line like this function just returns you
19:07 - the coordinates of the face captured
19:09 - like if I open the camera and the camera
19:12 - will capture my face then this function
19:14 - will return the coordinates of my face
19:17 - like top left top right bottom left
19:20 - bottom right okay so all the coordinates
19:22 - will be returned by this function to
19:25 - this faces variable okay so this so This
19:28 - lines this function is only doing this
19:30 - this is just telling the coordinates of
19:32 - faces to us okay okay so let me explain
19:36 - you that what actually
19:37 - returning us and what type of
19:39 - coordinates are they okay so just let me
19:42 - open my Notepad
19:46 - okay so this function like this function
19:49 - so let me just select uh
19:54 - okay so that's function like paste
19:56 - casket dot detect multiscale which is uh
19:59 - this variable faces just means that this
20:04 - faces is a list
20:05 - and this list is storing the coordinates
20:08 - of the face so if I draw here like
20:10 - different draw stitches like like if
20:13 - this is the person here
20:21 - [Music]
20:23 - okay so these both are faces Okay so
20:28 - these are the top coordinates like XY is
20:31 - the top coordinates of the faces and
20:32 - this is the width
20:34 - this is the height
20:36 - okay so a box it returns like this
20:40 - detect multi scale returns a block to
20:43 - you I delete it as a box in which we
20:46 - have the top left and
20:49 - we have the top left coordinates of x y
20:52 - and the height is H
20:55 - and the width is W okay so this function
20:59 - just returns
21:01 - X this function returns x y w and z
21:06 - so the W and H
21:09 - x y w n h okay so these are the
21:12 - coordinates and by this W and H we can
21:14 - just calculate it what are what can be
21:16 - these coordinates like this can be like
21:18 - X Plus H and the and pi plus W right
21:23 - like you can just calculate it by adding
21:25 - W and H in X and Y so we can get this
21:28 - these and this coordinate also so this
21:31 - function is just returning as the
21:32 - coordinates so that
21:34 - we can just make a box into the field
21:38 - around the face okay that's it about
21:41 - this latest
21:44 - okay so now let us see that the further
21:46 - code so this line like faces is sorted
21:50 - faces key Lambda X2 into X3 so what is
21:54 - it is doing so it is just arranging your
21:57 - faces like if you have multiple faces in
21:59 - the video field like if I show my face
22:01 - my sister's face my brother says
22:10 - in increasing or decreasing water as per
22:13 - our need okay so what we are doing here
22:15 - is we are passing a function name sorted
22:19 - and we are just using using a laptop
22:21 - option okay so in this uh this time
22:24 - being that we are passing our faces list
22:27 - here like in this basis list
22:31 - we have a x y h and W coordinates uh
22:36 - numbers okay and we pass this list here
22:39 - and we are just calculating so this
22:42 - means that
22:45 - okay so like faces wishes like if your
22:48 - faces
22:49 - then faces contains a list of
22:52 - X by
22:54 - W and H
22:57 - okay so it is zero Index this is bar
23:00 - Index this is three index okay so the
23:03 - area of image is what area of any image
23:06 - is
23:07 - weight into height okay
23:10 - you get into height and good thing to
23:13 - hide basically here is faces
23:16 - two
23:18 - into faces three okay this is width into
23:22 - height and this is basically area
23:24 - and the image which has larger area will
23:28 - obviously come first if we are sorting
23:30 - it in a decreasing order and if the area
23:32 - is less then it will come first in uh
23:35 - the sorted order if we are sorting it in
23:38 - an ascending order right so this so in
23:41 - this here so Lambda X is just
23:44 - representing our faces
23:46 - and we are just using the Lambda
23:49 - function here if you don't like what is
23:50 - Lambda function so that like just get a
23:53 - quick overview by seeing the documents
23:56 - okay so X is representing this faces and
24:01 - X2 into X3 basically is area of image
24:04 - area of the face or the area of the box
24:06 - which has been made okay and reverse is
24:09 - equal to True means which we are just
24:12 - arranging this in a descending order
24:14 - like we are sorting it in a descending
24:16 - order right so and these like if we are
24:20 - having faces like this first faces this
24:23 - second phase is this third phase is like
24:25 - small phase then big face and small
24:28 - piece and these all faces will be sorted
24:30 - in a descending order like first welcome
24:32 - big and small and then small this one
24:35 - okay so in this way we sort our faces
24:39 - and every data will be stored in this
24:44 - in this variable okay
24:46 - so I hope that you get a clear
24:48 - understanding of what we are actually
24:49 - doing here and now just forget this line
24:53 - as of now so now we are just we will
24:56 - just hydrate to the every phases and we
25:00 - will restore every face in our data
25:03 - so now we are we are just alternating in
25:05 - our faces again so uh let us see that we
25:09 - are starting a for Loop here and four
25:12 - Loop is going till end okay and this x y
25:15 - w h is are the coordinates of the face
25:19 - so face and faces means that it is like
25:23 - this is Phase One this is phase two this
25:26 - is phase three this is phase four like
25:28 - these are the faces and the coordinates
25:30 - of each and every phase will come in
25:33 - this x y w and H variables okay as we
25:36 - iterate over every faces then the uh
25:39 - coordinates of every face will come in X
25:42 - by W and H okay and this offset simply
25:45 - means that we are providing a padding so
25:48 - if we have done HTML before before you
25:51 - might know that what is padding what is
25:53 - margin so padding is basically a
26:01 - so if we are having our face here this
26:03 - is our face then this Gap is basically
26:06 - padding okay so this Gap is padding
26:10 - sorry about handwriting uh actually pen
26:13 - is quite cold here okay so if you are
26:15 - having a face here like
26:18 - and this is covered in a box then this
26:22 - box is having a padding of file okay so
26:26 - this length is basically five or five
26:28 - card
26:29 - okay so we are just given the padding of
26:31 - five to like uh show a clear user
26:34 - interface okay
26:37 - so as before we are just having this uh
26:40 - this box as outer box which is at which
26:43 - we are having the coordinates x y and
26:46 - everything so now here we are just
26:48 - extracting the face section so this line
26:51 - is basically extracting the section of a
26:54 - face so it is subtracting the offset so
26:58 - basically it is subtracting the padding
27:00 - and it is just uh calculating a
27:03 - particular section of a face initially
27:06 - this was padding and now we are
27:07 - discovering the particular section of
27:09 - the face okay and after that like you
27:12 - will see you can understand this easily
27:14 - like we are just subtracting offset from
27:17 - length from top and bottom and
27:20 - subtracting from left and right okay we
27:23 - are just subtracting over starting and
27:25 - just getting the section of Face by this
27:27 - line okay just go through it once and by
27:31 - this space selection we are just
27:32 - reselling a phase 200 cross 100 image
27:36 - okay so I hope that you understand it
27:39 - and now this skip so this skip just
27:43 - means that when we start recording our
27:45 - face then after every second our skip
27:49 - after every second or after
27:51 - hydration this tip will increment okay
27:54 - like we have recorded one first page
27:57 - second phase third phase like a
27:59 - particular uh time frame of the face is
28:02 - being recorded by this script by the
28:05 - script okay so after every 10 space like
28:09 - when I started the recording when I
28:11 - started recording my face so I record it
28:13 - at first second second third second
28:16 - fourth second I'm recording my face and
28:19 - every second okay so when I read the
28:21 - 10th second of camera I will just do a
28:25 - skip operation okay and after every 10th
28:30 - phase I will be recording this 10th
28:32 - phase into my array
28:34 - okay I'll be recording each 10th
28:37 - iterated face in my array so that I
28:40 - don't have many faces in my array and I
28:42 - have a good feeling and a good video
28:44 - feed like recognize later
28:49 - so as you can see that like after each
28:51 - 10th
28:53 - in titration I'm just appending my face
28:56 - into the phase data and sprinting the
28:59 - length of face that's it like
29:01 - understanding this line this line simply
29:03 - means that we are just creating a
29:05 - rectangular box
29:06 - towards our frame like frame is
29:08 - basically a section of frame a section
29:10 - of face which we are having and this
29:13 - these are the coordinates like top left
29:16 - top left coordinates and these are the
29:18 - bottom right coordinates we pass this
29:21 - these parameters at the color of the box
29:23 - which we have to display okay so this is
29:26 - RGB red green and blue so basically we
29:30 - have given green to its full number and
29:33 - red in blue to zero zero so basically a
29:36 - green color box will uh will appear out
29:39 - of your face okay so like let me show
29:42 - you that
29:43 - so so when I when I will open my camera
29:46 - so what will happen like
29:48 - a camera will open like this
29:51 - it will be a frame and my face will be
29:53 - here like I will be standing or sitting
29:56 - here and a green color box will appear
29:59 - around my face like or down the section
30:01 - of face a green color box will appear
30:04 - okay and
30:06 - by this like this is basically RGB I
30:10 - have given 0 to r0 to Blue and 255 to
30:13 - Green 255 is the maximum number that's
30:16 - why a green color box will appear if I
30:18 - give like 255
30:21 - 0 0 then a red color box will appear
30:24 - around my face red color box will appear
30:27 - so this is simply your this line is
30:29 - simply creating a rectangular box which
30:31 - will appear around this Frame frame is
30:34 - basically uh this stream Okay so
30:39 - and but this this will just show the
30:42 - frame
30:43 - like it is understandable and this uh
30:46 - this is like that if we have if a webcam
30:50 - is open then if we place an EQ
30:53 - if we press Q then the webcam will just
30:55 - switch off like I will explain the
30:58 - function of this later so let us move
31:00 - forward about things as of now
31:04 - so now after when we have stored our
31:06 - faces then after that we will we are we
31:09 - will be having a list of faces like we
31:11 - are having a list of Faces in which
31:13 - faces are faces data are stored okay so
31:16 - now to implement a KB is algorithm here
31:19 - we have to implement
31:20 - foreign
31:25 - works best in some scenarios and the
31:28 - compilation power is pretty much higher
31:31 - than list okay so we will convert our
31:34 - list so face data is basically list now
31:37 - we will convert this list to one numpy
31:40 - array by this function by NP dot array
31:44 - phase data error we are basically
31:47 - converting our space
31:49 - this is a list here as of now we will we
31:52 - are converting this to a numpy array
31:54 - okay so to have a faster computation and
31:57 - to better fit in again after converting
32:01 - it to a numpy array we will just reshape
32:03 - it okay so reshaping is a basic like
32:07 - basic concept
32:08 - you would know it and if you don't know
32:10 - like what is reshaping I would say that
32:12 - just look at the documentation like what
32:15 - it is doing
32:17 - and after this reshaping we are just
32:20 - printing our face not shape face data
32:22 - shape like whatever like what is the
32:25 - shape of the face as of now
32:27 - after that we are just saving our data
32:30 - in
32:31 - our folder which we have just made
32:34 - like this let me explain you this so
32:36 - this data set path is basically the D
32:39 - drive path which I have just uh stated
32:41 - earlier so
32:44 - so basically this this is a data set
32:46 - path and now we are the story cover like
32:51 - current data into this folder okay so to
32:54 - store our data in this folder what we
32:56 - are doing is like we are just saving our
32:58 - current data data paths file name in
33:01 - Phase data okay so file name is
33:03 - basically this
33:04 - uh when we are entering our name the
33:07 - name is stored in this file name okay so
33:10 - now just see that what we have done we
33:13 - have saved our data set plus file name
33:15 - and phase data and so if we print this
33:19 - it will be like data set like let me
33:22 - just show you if we print this what will
33:24 - happen if
33:25 - so now when we print it like it will
33:27 - come like this if the folder name is my
33:30 - data if data is my folder named in it
33:33 - and my file name is if I write my my
33:35 - name like arbit
33:39 - and extension is basically Dot npy
33:44 - because we storing this so this will be
33:47 - our
33:48 - location or Source where we are
33:50 - storybook current data okay so this this
33:54 - perfect dot npy will contain all the
33:57 - faces all the my phase data which is
33:59 - being stored in the camera feed and we
34:01 - will use this data to recognize and pass
34:04 - this data in our KN inverter
34:07 - [Music]
34:14 - webcam and this lens is just destroying
34:17 - all the windows which have been created
34:19 - by the camera like basically the frames
34:21 - which have been created here okay so
34:23 - this is the basically everything about
34:25 - is data reading and data collection so
34:29 - now we will see that how we can
34:31 - recognize the data by using algorithm
34:35 - so this is the basically the order of
34:37 - the face recognition and here I've
34:40 - implemented a Kalin algorithm that what
34:43 - the algorithm is doing okay so I will
34:45 - explain line by line that every like
34:47 - what every line of function is doing
34:49 - I'll explain everything and uh if you
34:52 - have any confusion like if you don't
34:54 - want to make KN and algorithm from
34:56 - scratch like here in this video I've
34:58 - made the this algorithm from scratch you
35:01 - can also use inbuilt Library like in
35:03 - inbuilt library comes it just works in
35:07 - simple one line and here I've used like
35:10 - two very lines here to implement it from
35:13 - scratch okay so you can use like direct
35:15 - Library function also and you can also
35:18 - like implement it from scratch
35:21 - okay so don't worry about that we'll
35:22 - just discuss everything you
35:24 - okay so before starting like a face
35:27 - recognition
35:29 - give you a quick overview that what is
35:32 - scale and got them doing
35:34 - okay so now let's see this
35:36 - okay so now let me give you an example
35:38 - of like what is Karen in a very very
35:41 - simplest way and I will show you that
35:43 - how our gains can be implemented in this
35:45 - project also okay so let us see that so
35:48 - if we are having a suppose we are having
35:52 - suppose I will give you a small example
35:54 - before like we are having a class one
35:57 - here so let me just
35:59 - so
36:02 - it is a it is my class one
36:06 - [Music]
36:07 - okay
36:10 - and I am just just like to change my
36:13 - color and
36:15 - this is my class too
36:20 - class 2.
36:27 - and in between this class one and class
36:29 - two I have a person here
36:32 - like suppose this is me
36:35 - now I have to like go to class one or
36:37 - class two and we have to find that this
36:40 - one belong to which class Like This one
36:43 - belongs to this class or this class we
36:45 - don't know as of now so what we do is we
36:48 - will find distance of current point with
36:51 - all the points and find the nearest
36:53 - point to this Green Point okay we find
36:57 - distance to every point and we'll check
36:59 - that what is the average nearest
37:00 - distance we have so suppose if
37:05 - so what we do is we find distance of
37:08 - this screen percent to every person of
37:11 - the class and we will find the top K
37:13 - persons like suppose we find distance to
37:16 - every every person in the class and
37:18 - after that finding we just categorize
37:20 - the top five percent like if we write K
37:23 - is equal to 5 then these five people are
37:26 - the nearest people to this like if a is
37:29 - equal to 5 then this three people like
37:31 - this this this three people of plasma
37:34 - and these two people of class two are
37:36 - the nearest people to this green Okay so
37:41 - a is equal to 5 simply means that these
37:44 - five peoples are the nearest K people to
37:47 - this cream color
37:49 - this green person
37:51 - okay now there are three persons of
37:54 - class one and two persons of class two
37:56 - this simply means that the we will just
38:00 - check that at which class we have the
38:03 - most number of uh nearest neighbors okay
38:06 - so this class one has the most number of
38:09 - nearest neighbors to this green green
38:11 - person okay so as class one has three
38:14 - neighbors class two has two nearest
38:16 - table so obviously we will categorize
38:18 - our this green person to class one
38:20 - because these are more nearest neighbors
38:23 - as compared to plus two okay so here
38:26 - class class one wins
38:29 - so basically this point belongs to class
38:32 - one is it is a basic overview like what
38:34 - is k n and I will explain this in this
38:37 - further videos like by giving more
38:39 - detailed examples to explain you the
38:41 - complete like how to take facial data
38:43 - and store into a numpy array and also
38:47 - shown in the basic quick overview that
38:49 - what is KN and algorithm and in today's
38:52 - video we're going to see that how Kanan
38:55 - algorithm can be implemented here and
38:57 - why should we implemented here okay so
38:59 - like
39:01 - like in this project we are like
39:03 - recognize recognizing our face with this
39:07 - but this is not the only way there are
39:10 - many other other algorithms like uh
39:13 - convolution neural networks and like
39:15 - many other things by which we can like
39:19 - recognizable face so this is what this
39:22 - is one of the method came in by which we
39:24 - recognize so let me give you example
39:27 - that how kerin can be implemented here
39:29 - so just see this
39:31 - so suppose that it is my graph and
39:35 - suppose I have stored the data of five
39:39 - people like uh four people I have state
39:42 - I have recorded the data of four people
39:44 - four of my friends and one of one it's
39:47 - me one is me and uh other three are my
39:50 - friends okay
39:52 - and total is I have four people okay one
39:56 - is one is me and three are friends so
39:59 - just let's see that suppose this is my
40:02 - this is me uh
40:05 - this is these are my face chords like
40:07 - artists I have just told you that I am
40:10 - recording my faces after every 10th
40:13 - iteration in uh and
40:15 - it will depend like when the number of
40:19 - the number of minutes or seconds or
40:21 - hours I will open my camera it my face
40:24 - will be get recorded and and due to that
40:27 - I have I will be having number of faces
40:30 - like if I open my camera for 10 minutes
40:31 - then I will be having a lot of faces
40:33 - recorded if I open my camera for one
40:36 - minute then I'll be having only six
40:38 - spaces recorded because the my faces are
40:41 - recording after every 10 seconds okay it
40:44 - is just a overview example so suppose I
40:47 - am I am I am having like my six faces
40:51 - and every friend of mine is having six
40:53 - faces story okay so this is person one
40:57 - and these are the faces of person one
40:59 - and let me change the color
41:03 - this is like this is me and suppose this
41:07 - is my friend face
41:10 - okay this is my friend's face
41:13 - and like like friend one
41:16 - and this is me
41:18 - and suppose
41:21 - time having one more friend stays told
41:26 - okay so this is my friend's three phase
41:28 - like a second frame face and
41:42 - this is these are the faces of my friend
41:44 - three okay and now I am just like these
41:48 - are just these are stored in my data
41:49 - these all pieces are stored in my data
41:52 - and now I open my camera feed to
41:54 - recognize and use gain in algorithm now
41:57 - so suppose I open my camera and I open
42:01 - up my camera like my camera face has
42:04 - been opened and a random person comes in
42:06 - the camera like it is none of us so it
42:09 - will not match with any of them and it
42:11 - will just simply cannot recognize okay
42:13 - so if I if I open my camera and I show
42:17 - my face to it like I show my face to it
42:20 - and it will recognize my face as like
42:24 - this so how it is happening so if I open
42:26 - my camera my face will come here like
42:29 - this is my camera and my face will come
42:31 - here so now my face will calculate the
42:34 - distance from every spatial data
42:37 - okay so I have to tell you that I have
42:40 - used hard casket classifier so my heart
42:42 - ask a class where I am just calculating
42:44 - my difference between faces okay so I
42:49 - will calculate the difference my of my
42:51 - face every other face is told okay
42:54 - while every other face is told I will
42:57 - calculate the difference between wire
42:58 - phase and other faces okay
43:01 - like every faces
43:03 - okay and I will just calculate like if I
43:06 - take K as 3 then
43:10 - I will just get the three nearest
43:12 - Neighbors
43:14 - three nearest Neighbors and
43:18 - obviously I will be having the least
43:20 - favorite facial difference with me only
43:23 - if I am wearing in the front of the
43:25 - camera then I will be having the least
43:27 - facial defense with me only okay so by
43:30 - this algorithm we can just state that I
43:34 - am having like
43:36 - this space means this is me and if if it
43:40 - recognize that this phase means a bit
43:42 - like my name is arpit so it will just
43:45 - recognize it and show my name on the box
43:48 - like don't be confused I will explain
43:51 - everything step by step after like
43:53 - moving into the cold so let us get
43:56 - started about that
43:58 - okay so let us get further like
44:00 - explaining that what is going down here
44:02 - so in this record phase organization
44:04 - file what we have done is we have just
44:06 - imported imported our numpy library
44:09 - opencv and Os Library here okay so this
44:13 - is the code of k n algorithm and if you
44:17 - don't know like mathematics okay and
44:20 - Wortham then I prefer you that like just
44:23 - read the documentation or just see it
44:25 - any video just see any video at or see
44:28 - any code and try to implement it by own
44:31 - by role okay if you try to implement it
44:33 - by own you will get a clear clear
44:35 - understanding that what this is doing in
44:38 - actual I have explained you like like
44:40 - what are the Logics which has been done
44:43 - and these Logics are simply coded here
44:45 - okay like sorting on the basis of this
44:49 - and frequency of each level finding them
44:51 - back frequency I've just explained you
44:53 - everything about this you have to just
44:54 - understand like what code is doing so I
44:57 - add this is basically your distance like
45:01 - this point distance from this is
45:03 - basically euclidean distance which is
45:07 - a
45:08 - x 1 minus X2 whole square plus y1 minus
45:12 - y 2 whole Square so this is basically
45:14 - euclidean distance you might know this
45:16 - as everyone has started this in school
45:18 - so here the euclidean distance is been
45:22 - calculated and here is a basic logic of
45:25 - k n so I
45:27 - like
45:29 - give the task to you and to find that
45:32 - what this game is actually doing so I
45:34 - have explained the logic just go through
45:37 - it once and understand that which and
45:39 - what is this k n code is doing if you
45:42 - don't understand this write in the
45:43 - comment box like I will explain
45:44 - everything about that and make another
45:46 - video Kaylin if you don't understand but
45:48 - this is very logical thing I will
45:49 - explain the logic just go through this
45:51 - cold ones and understand that what it is
45:54 - doing
45:54 - okay this is quite simple so like like
45:57 - uh so now let's move to our main logic
45:59 - that how to recognize that using
46:01 - inverter
46:03 - so I have just changed my IDE because uh
46:06 - previously I was having spider ID that's
46:08 - come that comes from anaconda and now I
46:11 - have an ID of python so it doesn't
46:15 - affect our code and so let's start it so
46:19 - like in the previous video we have seen
46:21 - that like uh all the things like paste
46:24 - data connection video camera on like how
46:27 - to how to do that please recognition
46:29 - Okay all of that and now like we have to
46:32 - do like the last practical part of it
46:34 - like we have to recognize our face after
46:36 - after loading and loading the data of
46:40 - the faces right like I will open my
46:42 - webcam and I will upload my data like I
46:44 - will start the webcam and my camera feed
46:47 - will constantly and consecutively uh
46:50 - load my data okay and after that like my
46:53 - facial data will be stored in a number
46:55 - array and in prediction I will use that
46:58 - number array for in my KN and algorithm
47:01 - to predict my new phase okay
47:04 - but
47:05 - but so basic overview that like in your
47:07 - family just record the faces of four or
47:09 - five people and after that in the data
47:12 - collection we got that and while the
47:14 - data recognition just one person coming
47:17 - the camera or multiple persons and a
47:20 - label will be come at around your face
47:22 - and a box will come I will show you that
47:24 - later okay
47:26 - so till then just see here so this is
47:29 - our face organization code okay so like
47:32 - we have done this
47:33 - [Music]
47:35 - previous data collection and like
47:38 - everything we have done till in the
47:40 - later the earlier classes as this is a
47:43 - Hardcastle classifier
47:44 - which we have used for detecting the
47:46 - facial components and now like let us
47:49 - see our face recognition file so
47:52 - basically like we have like now like we
47:56 - have discussed k n Gotham in the under
47:58 - glass like how our base is detected in
48:01 - the bunch of many cases okay so like
48:04 - this is my kenil algorithm I have not
48:07 - used a library function rather than I
48:09 - have coded it from scratch okay like I
48:11 - will show you later like I also told you
48:13 - to study the scaling code by yourself so
48:16 - basically it is nothing just calculating
48:18 - the euclidean distance and just
48:20 - calculating that which phase is the
48:21 - nearest face to the point of convergence
48:25 - like two of a new phase how many
48:27 - previous spaces are near tools okay so
48:30 - like like that thing is done here like I
48:33 - have also given comments and this you
48:35 - can read that okay and like I will share
48:38 - this code I will share the data
48:39 - repository so that you can read the code
48:42 - and understand it and run it in your
48:44 - computer okay and as of now let me just
48:49 - unhide the scale code
48:51 - foreign it
48:57 - okay so I have just minimized my k n
48:59 - code so let us see now like what further
49:01 - things are done in this in this part so
49:04 - like initially like while we while I
49:06 - have to recognize my face so before that
49:09 - like basic steps has to be done as we
49:11 - have done in previous classes like okay
49:13 - so like we have to first open the camera
49:16 - like when we open the camera then only
49:19 - we can like put our face in front of it
49:21 - right so first we open our camera by CV2
49:24 - dot video capture Zero by this we are
49:27 - opening our webcam like this opencv
49:30 - function video capture and by this you
49:33 - open a webcam and like with c and I have
49:36 - stored my webcam in this cap variable so
49:39 - cap will contain my webcam okay my video
49:42 - feed basically and after that like I
49:45 - have called my classifier that is
49:46 - Hardcastle classifier and the function
49:48 - to call our classifier in is Cascade
49:51 - classifier okay and there are multiple
49:54 - classifier like hard casket class
49:55 - frontal face classifier is only used for
49:58 - like uh
50:01 - and there are multiple classifiers like
50:04 - which are which are used for detection
50:06 - the number plate of the car or a person
50:08 - is the tender of person or many things
50:10 - so there are like a lot of classifiers
50:13 - which I've already been made so we have
50:14 - used Hardcastle classifier to to
50:17 - classify a particular part of the faces
50:19 - okay and after that after that the
50:21 - series data set paths so initial like in
50:25 - previous video we have seen that
50:26 - whenever we are we are capturing our
50:29 - face then we are storing that phase in a
50:31 - particular data file okay so uh just see
50:34 - here face data collection
50:36 - here we have stored our face
50:39 - um I think you
50:42 - just see here like we have stored our
50:44 - face in this data set path okay and this
50:49 - data set path is basically this folder
50:52 - now like when I show you this folder so
50:55 - just see here I think this is a folder
50:58 - okay
51:02 - uh just see this okay so this is a
51:05 - folder that is like my like this is my
51:08 - folder basically which contains my all
51:10 - the files python files and this is my
51:12 - face data set folder in which all the
51:14 - faces like whatever the name I've given
51:17 - in the data collection is being written
51:19 - here in the dot npy format so if I open
51:22 - this like face data
51:25 - then you can see that when I was
51:27 - printing it then I was printing in such
51:29 - a way like
51:30 - dot format data set path plus file name
51:33 - plus dot np1 okay so you can see that
51:37 - like it is my data set path space data
51:40 - and data set nay and uh file name is
51:43 - this like
51:48 - it is my name and this is a file name
51:51 - and Dot npysa extension okay so like
51:54 - dismiss store data and now I have to use
51:56 - this data so like in
51:59 - basic organization I have uh I will be
52:03 - using my this facial data for the
52:05 - recognition part okay and
52:09 - this is a normal arrays by which we are
52:11 - just calculating our facial data like
52:13 - with where we are storing your data and
52:16 - label are the the name of the data like
52:18 - what is the label like currently and
52:20 - class I like I have made two new
52:22 - variables here class ID and names so
52:24 - class ID will be basically labels for
52:26 - every q and file okay and names are like
52:29 - we are mapping a particular name with a
52:31 - particular data file okay and now let us
52:35 - see like how to do data preparation okay
52:38 - so like just see this line just see this
52:41 - Loop for FX in OS Dot
52:45 - I always do it list directory data set
52:48 - path so basically OS is a another
52:52 - library in Python which is used to for
52:55 - interaction with our operating system OS
52:57 - basically means operating system okay so
53:00 - here you can see that like I have also
53:02 - imported this OS file OS Library
53:04 - basically and now I'm using that so by
53:08 - this OS dot list dire it means list
53:11 - directory and data set path so this this
53:15 - line is basically looping in by this
53:18 - folder okay this is my folder face data
53:21 - set and here my
53:25 - like this Loop is this line is iterating
53:29 - over this uh folder okay so every file
53:33 - like every file which is present here
53:34 - will be in the FX like we will be
53:37 - iterating over every file and like in
53:39 - this line FX dot with end width it is
53:42 - just finding that which file ends with
53:45 - this extension dot npy so basically if I
53:49 - made some new file here like if I made a
53:51 - new folder here
53:52 - suppose new folder and
53:55 - suppose I make
53:58 - a word doc here okay so like I have made
54:01 - a new folder and a Word document dot
54:03 - word doc so basically if these folders
54:06 - are present in my file so I have to just
54:08 - find the dot mpy files okay
54:12 - so with if f x dot ends with DOT mpy I
54:18 - am finding just only dot mpy files where
54:20 - my data are stored okay where the
54:23 - different faces data are stored and
54:25 - responding those files Okay and like you
54:28 - see names
54:30 - bracket class ID is equal to f x colon
54:34 - minus one so I hope that you remember
54:36 - the slicing operator we have discussed
54:38 - in previous class also like if it is a
54:40 - slicing operator so basically
54:44 - just see this we are we are taking all
54:47 - the waiting all the characters
54:49 - uh except the last four okay so last
54:53 - order basically this dot npy are the
54:56 - last four indices right and
55:00 - everything before dot npy is our name so
55:03 - basically this names class ID contains
55:06 - our name basically okay and here we are
55:09 - just loading our data and appending this
55:12 - particular name and data item in my face
55:15 - data array okay so phase data array is
55:19 - this so we are just appending every data
55:21 - data in this page face data area okay
55:25 - and now you see that
55:28 - now we are making a particular Target
55:30 - variable like like suppose we have five
55:33 - persons person number one two zero five
55:35 - and these five person are the family
55:37 - members okay and now like we have to
55:39 - make a particular array a particular
55:41 - scale down array with that five percent
55:43 - okay so just see that like we have to
55:46 - meet different Target and scores at so
55:48 - initially my class ID is zero so like
55:51 - the series line so basically like we
55:53 - have Target variables for different
55:54 - phases like we have stored over facial
55:56 - data and now we are just simplifying
55:57 - that data into Target variables okay so
56:00 - Target are nothing just a simple array
56:02 - okay so basically what we are doing is
56:04 - like initially like we are having
56:06 - classes like initial class is 0 and
56:09 - after that like VR will be increment
56:10 - incrementing our class ID with every
56:13 - iteration so a particular class ID is
56:16 - associated with every phase data okay
56:19 - initially my class ID is zero and now
56:21 - you see this like I have got my day uh
56:25 - data item and I'm just taking the shape
56:28 - of the data item like the length of my
56:30 - data items data items are basically the
56:32 - number of times our face has been stored
56:34 - okay so like I'm just calculating the
56:37 - length of the data item and like
56:39 - converting that
56:40 - into an array of ones so I'll be forming
56:45 - a area of ones with the length of the
56:49 - day diet okay the size will be length of
56:52 - the data item and I am multiplying it by
56:54 - class ID so my class ID is 0 so when 0
56:57 - is Multiplied with then one uh npt once
57:00 - it will become an array of zeros okay so
57:03 - this will be my target number one
57:05 - after that like I will increase my class
57:07 - ID I'll increment it I'll store the
57:09 - Target in the labels area and I will
57:12 - just move to the next iteration after
57:15 - that I will go to my second phase okay
57:17 - and what I will do is like I will get
57:20 - another data item I will tell you the
57:22 - size of the data item because I'm having
57:24 - a different person now and I will
57:27 - convert
57:29 - array of once and the size of that array
57:32 - will be data item size okay and I will
57:36 - multiply that by class ID so whenever an
57:39 - area of once is Multiplied with class ID
57:41 - which is one so it will become the same
57:44 - area again so that will be my target
57:46 - number two and similarly when I class ID
57:48 - are being incremented so basically like
57:51 - when class had equal to when 2 is
57:53 - multiplied by array of ones then it will
57:56 - become an array of two okay the basic
57:58 - difference is that the size of this
58:00 - these all the target arrays are
58:02 - different okay based on a particular
58:05 - faces the size of errors are different
58:06 - and the number of the areas are
58:08 - difference okay so that's how like we
58:11 - are just modifying the facial data into
58:13 - Target variables and storing all the
58:16 - data in this labels so labels is also an
58:19 - array we are just storing all the
58:21 - different phase data and labels
58:23 - now and now we are just printing that
58:25 - data like the word or the phase data we
58:28 - have what are the face labels we have
58:30 - all that simple stuff and just combining
58:33 - that into like NP or concatenate base
58:36 - data and phase labels space data is the
58:39 - phase data and phase labels are the
58:41 - labels of the faces associated with that
58:43 - okay and now just see that
58:46 - like we have printed that stuff and now
58:49 - it is my font this line doesn't care as
58:52 - of now and now just see that like
58:55 - like this this line
59:04 - okay so now I just read that like um
59:10 - so now like we have like stored our
59:13 - facial data like we have extracted our
59:15 - data from the data set and we have
59:17 - stored that data okay now like we have
59:20 - to implement table like we have to call
59:22 - our K9 function and we are we have to
59:24 - make a box around our face so what will
59:27 - happen is that when you store your face
59:29 - data Okay and like one part is storing
59:32 - over phase data in Phase data dot py
59:35 - file and now like when we are
59:36 - recognizing it like open your camera and
59:38 - play this file your camera will be open
59:40 - and then you will show your face in
59:42 - front of the camera a box will become
59:45 - around your face and your name will be
59:48 - written above that box okay suppose uh
59:51 - if I show you this
60:07 - so we'll just just see this suppose like
60:10 - we are having a face like this and like
60:12 - what what will happen is like when I
60:14 - open my webcam suppose this is my webcam
60:17 - okay this this whole screen is my webcam
60:20 - and this is my face like I'm having neck
60:22 - also and like so
60:26 - okay like rest of the body and a face so
60:30 - basically whatever algorithm will do is
60:32 - like when you open up a camera then a
60:34 - colored box will be covered on your face
60:37 - which will be like this which will cover
60:40 - only our face part okay like
60:45 - okay so a square box will be formed
60:48 - around our face and our name will become
60:50 - here at the top okay so our like our
60:55 - algorithm will do that so like this is
60:57 - our webcam and this is me or anything or
61:00 - you and a particular green color box
61:03 - will be covered on this and this is due
61:04 - to this Hardcastle classifier which is
61:06 - like uh defining our face basically and
61:10 - our name will be written over that so
61:12 - let me just show you that code
61:14 - so
61:16 - basically like
61:18 - like we are just doing the same thing
61:20 - again which we have seen earlier also
61:23 - like we will start a loop an infinite
61:25 - Loop which will be recording our camera
61:27 - so we will start our camera by Capital
61:29 - read and this is the rate and frame will
61:32 - basically have be having our camera
61:34 - variables like webcam variables return
61:37 - is basically like telling us that
61:38 - whether the camera is on or off okay
61:40 - frame is basically our main camera
61:43 - pinning which will be used okay so first
61:45 - like we have just converted our image to
61:48 - a grayscale image okay like whatever the
61:50 - video we are having we have just
61:52 - converted that into a gray scale video
61:54 - and after that like we are done same
61:56 - thing like we have just detect multi
61:59 - scale and these are the scaling factor
62:00 - and the number of neighbors like we have
62:03 - seen all this part in earlier video also
62:05 - okay
62:07 - just get over the here so this basis
62:10 - will basically contain our coordinates
62:12 - of the faces like X by W and H so
62:17 - basically uh if I change the thing so
62:19 - this this this top left corner will
62:23 - contain the will having the point number
62:25 - X and Y sorry I don't have the mouse so
62:27 - I'm starting like this so X and Y are
62:29 - the coordinates and this is our width
62:33 - and this is our height basically okay so
62:37 - basically our
62:39 - this function will give us the X Y width
62:42 - and height so that that all will be
62:45 - stored in in the face array okay and now
62:48 - like we are just starting a loop okay so
62:50 - like in the new Loop we are having a
62:52 - face and with a phase we are having the
62:55 - coordinates and these coordinates are
62:56 - stored are got from the space okay
63:00 - so this space is basically the one phase
63:02 - on which we are iterating
63:06 - and everything this is same just we are
63:08 - just cutting the part of the
63:10 - camera frame and just converting that to
63:13 - 100 cross hundred frame size and now
63:15 - just see this out is equal to k n
63:19 - we are calling our function just see
63:21 - just concentrate here we are calling our
63:24 - function k n and now like train train
63:26 - set and phase section flatten
63:34 - which we are carrying over from the past
63:36 - time and phase section dot platter means
63:39 - like we have defined this earlier also
63:41 - like we are having a phase section just
63:43 - here
63:44 - we are having a phase section basically
63:46 - the camera frame which is just uh
63:49 - captured in our face so we're just
63:51 - flattening that to convert that into a
63:53 - array okay of one column in multiple
63:56 - rows we are just starting that because
63:58 - in k n our parameter should be a
64:01 - flattened array only array of one call
64:03 - okay so our train set we have that we
64:06 - have our new phase which is we are just
64:09 - passing the two parameters
64:11 - and this will give us the output output
64:14 - will be that phase a training set we
64:17 - have trained and space section is the
64:20 - section we got here so it will basically
64:22 - guess the output that which frame we are
64:25 - having correctly so trains that we got
64:27 - from data paste data okay all the phase
64:31 - data we have so it will just iterate our
64:33 - every data and just apply our k n
64:36 - algorithm on that
64:37 - okay which is having a training set and
64:40 - a test set okay on the base of that it
64:42 - will give us the prediction which is
64:44 - this
64:45 - and it will tell us that which point it
64:48 - belongs to okay it's like if we have
64:50 - this
64:52 - um
64:58 - basically like this is a stuff like if
65:00 - you are having a face in between so it
65:02 - will just tell us that which face does
65:05 - our page belong to from this rest of the
65:07 - five faces basically okay and now like
65:10 - we have done that like we got the output
65:12 - base from here and now we we have to
65:15 - make a box around the face and a text on
65:20 - the face basically okay so see we do dot
65:22 - rectangle dot rectangle is a function
65:24 - which is used to make a shape by opencv
65:27 - so what we are doing is just we are
65:29 - passing a frame the coordinates the top
65:32 - left coordinates and the bottom right
65:34 - coordinates okay top left x y and bottom
65:38 - right are X Plus will be y plus h we are
65:40 - passing the coordinates okay and it will
65:43 - make a face around it will make a
65:45 - rectangle in these coordinates and this
65:47 - is the color and this is the width the
65:51 - width of the Box color is 255 25 which
65:55 - this is basically BGR colored okay three
65:57 - blue green red
65:59 - okay like if I do zero here and if I do
66:02 - Z 0 L so BGR means b g and r
66:07 - so if my B and gr 0 and my R is 255 it
66:12 - will make a box of
66:14 - a red color okay and if I make this like
66:19 - if I make this two multiple here
66:21 - so it will make a green color box okay
66:23 - this is just a color color format and
66:27 - now like to put a text like here like we
66:30 - write a function CO2 to Output text and
66:32 - it will just uh put a text here and this
66:35 - is the font of the text and this is the
66:38 - and this is the coordinates where I have
66:40 - to put my text
66:41 - and this is my color of the text like
66:44 - pgr format B is 255 so my text will be
66:47 - of blue color okay and this is a bit
66:50 - okay and similarly like that we are just
66:52 - putting everything and now like we are
66:54 - just displaying our face
66:56 - okay like we are just showing our camera
66:58 - feed and all of that okay and after that
67:03 - everything just be a make a function
67:05 - like if I press a Key Queue so my
67:07 - function will be end there and I can
67:09 - close my webcam and my webcam will not
67:12 - be closed
67:13 - buy anything except pressing Q okay and
67:17 - now like after all everything we just
67:19 - will just destroy the window and close
67:21 - the program that's all okay like this is
67:25 - a project of face recognition and I hope
67:27 - that like this is a very beginner level
67:29 - project
67:30 - in machine learning okay it's like I
67:33 - hope that this will this will be clear
67:34 - to all of you and
67:37 - just write the let's just give the
67:39 - comment below that how like
67:42 - like um how much do you like this
67:44 - playlist of this project okay and
67:47 - okay so let's end this video now okay
67:50 - bye