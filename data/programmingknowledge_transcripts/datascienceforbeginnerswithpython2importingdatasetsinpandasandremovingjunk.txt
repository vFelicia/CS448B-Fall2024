00:00 - okay one more thing I want to add here
00:02 - is that this is for Mac and Linux so if
00:10 - we have a Windows machine then you can
00:13 - run the OS dots e-hdi are open close and
00:17 - inside that let's say you're having
00:20 - files in D Drive
00:22 - so to drive then backward slash and then
00:27 - the name of the directory for example
00:29 - pandas okay so this will change
00:34 - directory in the detail in the pandas
00:37 - trajectory these four windows because
00:41 - windows and linux or mac path patterns
00:46 - are different so now we got our files
00:52 - so the pandas actually contain two types
00:56 - of structures so one is series so series
01:00 - is a used for one dimensional array and
01:08 - and another only skater frame so data
01:13 - frame is used for state it is a data
01:18 - structure which uses which helps us to
01:23 - store tables in the form of rows and
01:27 - columns so it is a two dimensional array
01:32 - so we'll use data frames mostly people
01:35 - use data frames because it helps us to
01:37 - store tables in the form of
01:39 - two-dimensional arrays and it is also
01:41 - very faster because under the hood
01:45 - pandas use C and Python for efficient
01:50 - programming so now we will import our
01:55 - CSV file so let's say a variable name
02:00 - we'll take theta underscore CSV then we
02:06 - will equate it to will call now the PD
02:10 - that is pandas short form
02:12 - then read CSV read underscore CSV so
02:19 - inside that will give the name of the
02:21 - file so we'll import the CSV so we'll
02:25 - copy this and we'll paste it here so
02:29 - this should be in a single inverted
02:33 - commas and now if we run this cell so it
02:38 - is imported if you say data CSV it is
02:50 - showing us the data frame all content so
02:56 - we have one two three four five six six
03:00 - columns and these columns are called as
03:04 - attributes and these rows are called as
03:07 - tuples okay and they can see the species
03:14 - the petal width centimeter petal length
03:18 - centimeters sepal width centimeter and
03:20 - cycle length centimeter
03:23 - okay so we'll so it is gone data set of
03:26 - 150 rows into six columns as you can see
03:31 - it is not showing us completely it is
03:33 - hiding it because the space will not be
03:36 - a enough for showing us the way all the
03:39 - values if you if you look at it
03:42 - carefully some values are not there so
03:45 - these values are called as not a null so
03:50 - if values are not there so what pandas
03:53 - will do automatically it will fill these
03:55 - values with not a null operator okay and
04:00 - some values you can see are like missing
04:05 - values or not proper values so some
04:07 - values are tipple hash some values are
04:11 - double question mark so I will show you
04:14 - how to replace these values by numeric
04:21 - ones okay and also
04:24 - fill these empty values so now we have
04:30 - one extra column ID so we'll remove this
04:34 - so for that you go down okay so for that
04:39 - we'll call that top data frame later CSV
04:43 - I mean that will pass we really thought
04:46 - read CSV so while reading only if you
04:50 - pass one more parameter that is index
05:06 - underscore column it is called index
05:09 - underscore call equal to zero so what
05:14 - this will do this will not consider this
05:19 - first column it is index column and if
05:22 - we run it and now if you show it you can
05:30 - see the extra column is removed so what
05:34 - pandas does it automatically puts that
05:36 - column so we can remove that by and we
05:38 - can set the index column s sepal then
05:41 - sandwich over the first attribute of the
05:45 - table so this is how we can remove the
05:50 - first column or the you can set the
05:53 - index column so if you want to set index
05:56 - column as one two you can set so now we
06:00 - have done that we I will show you how to
06:05 - replace the improper values that is a
06:10 - question mark and triple hash so we can
06:16 - remove these junk values by passing them
06:21 - is released to the parameter na
06:23 - underscore values so for that we will
06:25 - copy this command and
06:36 - I'll put comments also replace to set
06:41 - index column okay and now to remove or
06:52 - replace the better part would be the to
06:58 - replace the junk values okay so for this
07:08 - you can call this statement data CSV
07:13 - equal to P read or read CSV the name of
07:16 - the file and then we will just take this
07:22 - down then we will just add one more
07:26 - parameter which is any underscore sorry
07:32 - any underscore values and this takes a
07:37 - list so in that list we pass the
07:39 - parameters so now we have two parameters
07:42 - that we want to replace so one is double
07:46 - question mark and third one is triple
07:56 - hash so if we now run this and we can
08:02 - check it so for that we will type data
08:08 - CSV dot head so that we can get only
08:13 - four starting five values so you can see
08:17 - the improper data is removed or filled
08:24 - with not a null values
08:27 - so earlier if you see we had third row
08:33 - second column we had improper data so
08:37 - now third row filled with not a null
08:40 - values so the the junk values are filled
08:46 - with the knotted null and we can confirm
08:51 - that by running down or by calling the
08:55 - data frame directly so we can see all
08:58 - the junk variability is a question mark
09:02 - question mark and triple hash attribute
09:12 - so now I will show you how you can
09:18 - import excel file so import Excel so for
09:33 - that we take a data frame Excel s X
09:39 - equal to now jumpy dot read Excel and
09:47 - inside that we will take the name of the
09:51 - file so we had a list it a simple dot it
09:58 - should be xlsx and you know if we have
10:04 - seen the excel sheet they have different
10:10 - sheets so this is one sheet you can see
10:14 - the bottom this is Google sheet actually
10:16 - then she too will be having other values
10:19 - so like that we have different sheets so
10:22 - if we have like that different sheets
10:25 - then we can now select the sheet with by
10:29 - name so for that we'll call sheet
10:31 - underscore name equal to so we call iris
10:39 - later so this sheet is already dead in
10:43 - this excel sheet so we are just
10:45 - selecting that sheet so feed on that and
10:50 - now if we run data X and X X you just
10:56 - take first 5 values you can see though
11:00 - it is loaded in the data frame here you
11:04 - can so we can see there are this junk
11:07 - values so you can remove that by using
11:11 - the same any values equal to this method
11:16 - so I hope you can do that and if you
11:19 - want to import txt file so for that we
11:25 - can just call so importing test files is
11:37 - also easy we just you get data and X t1
11:45 - equal to PD dot read table so for text
11:51 - files we have to call read table
11:53 - function and inside thread will pass the
11:59 - name of the file dot txt okay what I
12:08 - have done okay inside that will call txt
12:13 - yeah so that is also now imported if you
12:17 - just taught it it shows us the values so
12:25 - what happened in here is the all columns
12:30 - really all columns read and stored in a
12:33 - single column of data frame suppose in
12:37 - this sepal length centimeter so what
12:40 - they have done they have created one
12:41 - single column inside that I have stored
12:45 - all the values so to avoid this what you
12:51 - can do is
12:52 - you can use the limiter or separate or
12:56 - variable so for that what you have to do
12:58 - just add a CP so this recipe is the
13:05 - default or this separator so by default
13:09 - they have a tab in between them so how
13:12 - can define debbie's backward slash end
13:16 - of T and now if you run it is now
13:24 - properly taken so tab delimiter might
13:30 - always not work so you can also try with
13:36 - okay we've got error let's say okay so
13:40 - we should not put it like this and now
13:44 - see you got the values properly in the
13:48 - proper columns so in the separator in
13:52 - the Vale separator attribute we have to
13:55 - pass a blank white space so that it will
13:59 - properly fill in all the columns and one
14:04 - more way is that you can use either way
14:10 - so this waits you can use telemeter
14:16 - huge white space in string so you can
14:20 - see it is properly top now so these are
14:23 - the two ways in which you can do and now
14:28 - you have seen how to import different
14:31 - types of files so other commonly use the
14:36 - delimiters are commas and blanks so you
14:43 - can also use comma if we have all that
14:45 - tough data set with hair with heads
14:48 - commas in between the values the future
14:53 - a comma EQ same because it is not taking
14:58 - comma salty only takes the blank space
15:08 - dude it's a commas and relax
15:16 - also tab so this is how you put
15:23 - different types of files using pandas