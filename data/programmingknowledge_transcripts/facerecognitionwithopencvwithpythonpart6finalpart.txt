00:00 - hi guys my name is this is the part
00:03 - number six of this
00:04 - project playlist and it's been quite
00:06 - late after predict the path number five
00:09 - so i just changed my ide because uh
00:12 - previously i was having spider id
00:14 - that that comes from anaconda and now i
00:17 - have
00:17 - id of pyjama so it doesn't affect our
00:21 - code
00:22 - and so let's start it so like in the
00:25 - previous
00:26 - video we have seen that like uh all the
00:29 - things like base
00:30 - data collection video camera on like how
00:32 - to how to do that
00:34 - base recognition okay all of that and
00:37 - now like
00:38 - we have to do like the last practical
00:40 - part of it like we have to recognize our
00:42 - face after
00:43 - after loading and loading the data of
00:46 - the faces
00:46 - right like i will open my webcam and i
00:48 - will upload my data
00:50 - like i will start the webcam and my
00:52 - camera feed will constantly
00:54 - and consecutively uh load my data okay
00:58 - and after that like my facial data would
01:00 - be stored in a numpy array
01:02 - and in prediction i will use that numpy
01:04 - array for
01:06 - in my k n algorithm to predict my new
01:08 - face okay
01:09 - so but okay so basic overview that
01:13 - like in your family just record the
01:14 - faces of four or five people
01:16 - and after that in the data collection
01:18 - record that
01:19 - and while the data recognition just one
01:22 - person coming the camera or
01:24 - multiple persons and a label will be
01:26 - come at
01:27 - around your face and a box will come i
01:30 - will show you that later
01:31 - okay so till then just see here
01:35 - so this is our face organization code
01:37 - okay so like we have done
01:39 - uh this place data collection
01:43 - and like everything we have done till
01:46 - in the later in the earlier classes and
01:48 - this is a hard casket classifier
01:50 - which we have used for detecting the
01:52 - facial components
01:53 - and now like let us see our face
01:56 - recognition
01:57 - file so basically like we have
02:00 - like now like we have discussed kane and
02:03 - gotham in the earlier class
02:04 - like how our base is detected in the
02:07 - bunch of many phases
02:09 - okay so like this is my canon algorithm
02:12 - i have not used a library function
02:14 - rather than i have quoted it from
02:16 - scratch
02:17 - okay like i will show you later like i
02:19 - also told you to study this scaling code
02:20 - by yourself
02:22 - so basically it is nothing just
02:23 - calculating the equilibrium distance
02:25 - and just calculating that which face is
02:27 - the nearest phase
02:29 - to the point of convergence like two of
02:31 - a new phase
02:32 - how many previous places are near to us
02:34 - okay
02:35 - so like like that thing is done here
02:39 - like
02:39 - i have also given comments and just you
02:41 - can read that
02:42 - okay and like i will share this code i
02:45 - will share the repository so that you
02:46 - can
02:48 - read the code and understand it and run
02:49 - it in your computer
02:51 - okay and as of now let me just
02:55 - unhide the scale code okay so now let me
02:59 - just unhide it
03:03 - okay so i have just minimized my canon
03:05 - code so let us see now like what further
03:07 - things i've done in this
03:08 - in this part so like initially like
03:11 - while we
03:12 - while i have to recognize my face so
03:14 - before that like basic steps has to be
03:16 - done
03:16 - as we have done in previous classes like
03:18 - okay so like
03:20 - we have to first open the camera like
03:23 - when we open the camera then only we can
03:25 - like put our face in front of it right
03:27 - so first we open our camera by cb2 dot
03:30 - video capture
03:31 - zero by this we are opening our webcam
03:35 - like this opencv function video capture
03:38 - and by this you open our webcam and like
03:41 - with c
03:41 - and i have stored my webcam in this cap
03:44 - variable
03:45 - so cap will contain my webcam okay my
03:47 - video field
03:48 - basically and after that like i have
03:51 - called my classifier that is hardcaster
03:53 - classifier
03:54 - and the function to call our classifier
03:56 - is cascade classifier
03:58 - okay and there are multiple classifiers
04:00 - like aspect class frontal phase
04:02 - classifier is only used
04:04 - for like uh directing over faces
04:08 - and there are multiple classifiers like
04:10 - which are which are used for detection
04:12 - the number rate of the car or a person
04:14 - is the gender of a person or many things
04:17 - so there are like a lot of classifiers
04:18 - which have already been made
04:20 - so we have used hardcast classifier to
04:22 - do to classify a particular part of the
04:24 - faces
04:25 - okay and after that after that just see
04:27 - those data set paths
04:29 - so initial like in previous video we
04:32 - have seen that whenever we are
04:34 - we are capturing our face then we are
04:35 - storing that face in a particular data
04:37 - file
04:38 - okay so uh just see here face data
04:41 - collection
04:42 - here we have stored our face um i think
04:45 - here
04:48 - just see here like we have stored our
04:50 - face in this
04:52 - data set path okay and this data set
04:55 - path is basically this folder
04:58 - now like when i show this folder so just
05:01 - see here
05:02 - i think this is a folder okay
05:08 - just see this okay so this is a folder
05:11 - that is like
05:13 - my like this is my folder basically
05:15 - which contains my all the files python
05:17 - files and this is my face data set
05:18 - folder
05:19 - in which all the faces like whatever the
05:22 - name i have given
05:23 - in the data collection is being written
05:25 - here in the dot npy format
05:27 - so if i open this like face data
05:31 - then you can see that uh when i was
05:33 - printing it
05:34 - then i was printing in such a way like
05:37 - dot format data set path
05:38 - plus file name plus dot npy okay
05:42 - so you can see that like it is my data
05:45 - set path is space data
05:46 - and data set name and uh file name is
05:49 - this like
05:54 - this is my name and this is the file
05:56 - name and dot np by say extension
05:59 - okay so like this my store data and now
06:02 - i have to use this data
06:03 - so like in basic organization i have
06:07 - uh i will be using my this facial data
06:10 - for the recognition part
06:12 - okay and this is the normal areas by
06:16 - which we are just
06:18 - calculating our facial daylight with
06:20 - where we are storing the data
06:21 - and label are the the name of the data
06:23 - like what is the label like currently
06:26 - and class i like i have made two new
06:28 - variables here
06:29 - class id and names so class id will be
06:31 - basically labels for every given file
06:34 - okay and names are like we are mapping a
06:36 - particular name with a particular data
06:38 - file
06:39 - okay and now let us see like how to do
06:42 - data preparation
06:43 - okay so like just see this line
06:47 - just see this loop for fx in os dot
06:52 - os dot list directory data set path
06:55 - so basically os is a another library in
06:58 - python
06:59 - which is used to for interaction with
07:01 - our operating system
07:03 - os basically means operating system okay
07:06 - so here you can see that like i have
07:07 - also imported this os file
07:09 - os library basically and now i'm using
07:12 - that
07:13 - so by this os dot list dire
07:16 - it means list directory and data set
07:19 - path
07:20 - so this this line is basically looping
07:23 - in
07:23 - by this folder okay this is my folder
07:26 - face
07:27 - data set and here my uh
07:31 - like this loop is i this line is
07:34 - iterating over this
07:36 - uh folder okay so every file like every
07:39 - file which is present here will be in
07:41 - the
07:41 - effects like i will be iterating over
07:44 - every file
07:45 - and like in this line fx dot with end
07:47 - with
07:48 - it is just finding that which file ends
07:50 - with this
07:51 - extension dot npy so basically if i made
07:55 - some new file layer like if i made a new
07:57 - folder here
07:58 - suppose a new folder and
08:02 - suppose i make a word doc here
08:06 - okay so like i made a new folder and a
08:08 - word document dot word doc
08:10 - so basically if these folders are
08:12 - present in my file
08:13 - so i have to just uh find the dot mpy
08:16 - files
08:17 - okay so with
08:20 - if fx dot ends with dot mpy
08:23 - i am finding just only dot np wi-fi is
08:26 - where my data are stored
08:28 - okay where the different faces data are
08:30 - stored i'm just finding those files
08:32 - okay and like just see names
08:36 - names bracket class ids go to fx colon
08:40 - minus 4
08:41 - so i hope that you remember the slicing
08:43 - operator we have discussed in
08:44 - previous class also like what is the
08:46 - slicing operator so basically
08:50 - you see this we are we are taking all
08:52 - the num we are taking all the characters
08:55 - uh except the last four okay so last
08:59 - order basically this
09:00 - dot npy are the last four indices
09:03 - right and everything before dot npy
09:08 - is our name so basically this names
09:11 - class id contains
09:12 - our name basically okay and here we are
09:15 - just loading our data
09:17 - and appending this particular name and
09:19 - data item
09:21 - in my face data array okay so phase data
09:24 - is this so we are just appending every
09:27 - data
09:28 - data in this phase data area okay
09:31 - and now you see that now we are making a
09:35 - particular
09:36 - target variable like like suppose we
09:38 - have five persons
09:40 - person number one two zero five and
09:41 - these five percent are the family
09:43 - members okay
09:44 - and now like we have to make a
09:45 - particular area a particular scaled down
09:48 - array
09:48 - with that five percent okay so just see
09:50 - that like we have to meet different
09:52 - target errors for that so initially my
09:55 - class id is zero
09:56 - so let's just see this line so basically
09:58 - like we have target variables for
10:00 - different phases like we have stored our
10:01 - facial data and now we are just
10:03 - simplifying that data into target
10:04 - variables
10:05 - okay so target are nothing just a simple
10:08 - array okay
10:09 - so basically what we are doing is like
10:11 - initially like we are having classes
10:12 - like initial class is zero
10:14 - and after that like we are will be
10:16 - implement incrementing our class id
10:18 - with every iteration so a particular
10:21 - class id is associated with every phase
10:23 - data
10:24 - okay initially my class id is zero and
10:27 - now just say this
10:28 - like i have got my data item
10:32 - and this i'm just taking the shape of
10:34 - the data item like the length of my data
10:36 - items
10:37 - data items are basically the number of
10:39 - times our phase has been stored
10:41 - okay so like i'm just calculating the
10:43 - length of the data item
10:44 - and like converting that into
10:47 - an array of once so i i'll be forming an
10:51 - area of once
10:52 - with the length of the data item okay
10:56 - the size will be length of the rate item
10:58 - and i am multiplying it by class id
11:00 - so my class id is zero so when zero is
11:03 - multiplied with then
11:04 - one uh np dot once it will become an
11:07 - area of zeros
11:08 - okay so this will be my target number
11:10 - one
11:11 - after that like i will increase my class
11:13 - id i'll increment it
11:15 - i'll store that target in the labels
11:16 - area and i will just
11:18 - move to the next iteration after that i
11:21 - will go at my second phase
11:23 - okay and what i will do is like i will
11:25 - get another data item
11:27 - i will tell you the size of the data
11:29 - item because i'm having a different
11:31 - person now
11:32 - and i will convert i will make a np
11:35 - array of once and the size of that array
11:38 - will be
11:38 - data item size okay and i will multiply
11:42 - that by class id
11:43 - so whenever an area of once is
11:46 - multiplied with class id
11:47 - which is one so it will become the same
11:50 - area again
11:50 - so that will be my target number two and
11:53 - similarly when i class id are being
11:55 - incremented
11:56 - so basically like when class id equal to
11:59 - when two is multiplied by area of once
12:01 - then it will become an area of two okay
12:04 - the basic difference is that the size of
12:06 - this
12:07 - these all the target arrays are
12:08 - different okay
12:10 - based on the particular faces the size
12:11 - of errors are different
12:13 - and the number on there is our
12:14 - difference okay so that's how like we
12:16 - are just
12:17 - modifying the facial data into target
12:20 - variables and
12:21 - storing all the data in this labels so
12:24 - labels is also an area
12:25 - we are storing all the different phase
12:27 - data and labels
12:30 - now and now we are just printing that
12:31 - data like
12:33 - whatever the face data we have what the
12:34 - base labels we have
12:36 - all that simple stuff and just combining
12:39 - that
12:39 - into np like np or concatenate based
12:42 - data and phase labels
12:44 - space data is the phase data and phase
12:46 - labels are the labels of the faces
12:48 - associated with that okay and now i just
12:51 - see that
12:52 - like we have printed that stuff and now
12:55 - it
12:55 - is my font this line doesn't care as of
12:58 - now
12:58 - and now just see that like like this
13:02 - this line
13:10 - okay so now let's see that like
13:17 - so now like we have like stored our
13:19 - facial data like we have extracted our
13:21 - data from the data set and we have
13:23 - stored that data
13:24 - okay now like we have to implement ever
13:27 - like we have to call our gain
13:29 - function and we have to make a box
13:31 - around our face
13:32 - so what will happen is that when you
13:34 - store your face data
13:36 - okay and like one part is storing our
13:38 - face data in face data dot py file
13:41 - and now like when we are recognizing it
13:43 - like open your camera like play this
13:45 - file
13:45 - your camera will be open and then you
13:47 - will show your face in front of the
13:49 - camera
13:49 - a box will become around your face
13:53 - and your name will be written above that
13:54 - box okay suppose
13:56 - uh if i show you this
14:13 - we just just see this suppose like we
14:16 - having a face like this
14:17 - and like what what will happen is like
14:19 - when i open my webcam
14:21 - suppose this is my webcam okay this this
14:25 - whole screen is my webcam
14:26 - and this is my face like i'm having neck
14:28 - also and like
14:30 - so okay
14:33 - like rest of the body and a face so
14:36 - basically
14:37 - whatever got some will do is like when
14:38 - you open up the camera then
14:40 - a colored box will be covered on our
14:43 - face
14:44 - which will be like this which will cover
14:46 - only our face part
14:47 - okay like
14:51 - okay so a squared box will be formed
14:53 - around our face
14:54 - and our name will become at the top
14:58 - okay so our from our like our
15:01 - algorithm will do that so like this is
15:03 - our webcam and this is
15:05 - me or anything or you and a particular
15:08 - green color box will be covered on this
15:10 - and this is due to this classifier which
15:12 - is
15:13 - like uh defining our face basically and
15:16 - our name will be written over that let
15:18 - me just show you that code
15:20 - so basically like
15:24 - like we are just doing the same thing
15:26 - again which we have seen earlier also
15:29 - like we will start a loop an infinite
15:31 - loop which will be recording our camera
15:33 - so we will start our camera by cap dot
15:35 - read
15:36 - and this red and frame will basically
15:39 - we having our camera variables like
15:41 - webcam variables
15:42 - return is basically like telling us that
15:44 - whether the camera is on or off
15:46 - okay the frame is basically our main
15:48 - camera opening which we will be using
15:50 - okay so first like we have just
15:52 - converted our image to a grayscale image
15:55 - okay like whatever the video will we are
15:57 - having we have just converted that into
15:58 - a grayscale video
16:00 - and after that like we are done same
16:02 - thing like we have just
16:04 - detect multiscale and these are the
16:05 - scaling factor and the number of
16:07 - neighbors
16:08 - like we have seen all this part in
16:10 - earlier video also
16:11 - okay just get over
16:14 - here so this spaces will basically
16:16 - contain our
16:18 - coordinates of the faces like x y
16:21 - w and h so basically uh if i change the
16:24 - plane
16:25 - so this this this corner like top left
16:28 - corner will contain the
16:30 - will having the point number x and y
16:32 - sorry i don't have the mouse so i'm
16:33 - talking like this
16:34 - so x and y are the coordinates and this
16:37 - is our width and this is our height
16:41 - basically
16:42 - okay so basically our
16:45 - this function will give us the x by
16:48 - width and height
16:49 - so that that all will be stored in in
16:51 - the face area
16:52 - okay and now like we are just starting a
16:54 - loop
16:55 - okay so like in the new loop we are
16:58 - having a face
16:59 - and with a face we are having the
17:00 - coordinates and these coordinates are
17:02 - stored
17:03 - are got from the space okay so this
17:06 - space is basically the one phase
17:09 - on which we are iterating and everything
17:12 - this is same
17:13 - just we are just cutting the part of the
17:16 - camera frame and just converting that to
17:19 - 100 cross 100 frame size
17:21 - and now just say this out is equal to k
17:23 - n
17:25 - we are calling our function this c just
17:28 - concentrate here
17:29 - we are calling our function k in and now
17:31 - like train
17:32 - train set and face section flatten
17:35 - so face section dot plating so basically
17:38 - training set is our training set
17:40 - which we have which we are carrying over
17:41 - from the past time and phase section dot
17:44 - platinum means
17:45 - like we have defined this earlier also
17:47 - like we are having a face section
17:49 - just here we are having a face section
17:52 - basically the camera frame
17:53 - which is just uh uh calibrating our face
17:56 - so we are just plotting that to convert
17:58 - that into a area
18:00 - okay of one column in multiple rows we
18:02 - are just starting that
18:04 - because in canon our parameter should be
18:07 - a flattened array
18:08 - only area of one column okay so with
18:11 - train set we have that we have
18:13 - our new face just we are just parting
18:15 - passing the two parameters
18:17 - and this will give us the output output
18:20 - will be that face
18:21 - like training set we have trained and
18:24 - space section
18:25 - is the section we got here so it will
18:28 - basically
18:28 - guess the output that which frame we are
18:31 - having currently
18:32 - so trains that we got from data phase
18:34 - data
18:35 - okay all the phase data we have so it
18:38 - will just iterate over every data and
18:40 - just
18:40 - apply our k n algorithm on that okay
18:44 - which is having a training set and a
18:46 - test set okay on
18:47 - on the basis of that it will give us the
18:49 - prediction which is this
18:51 - and it will tell us that which point it
18:53 - belongs to
18:54 - okay it's like if we have this
19:04 - basically like this is a stuff like if
19:06 - you're having a phase in between so it
19:08 - will just tell us that
19:10 - which face does our face belong to from
19:12 - this rest of the five faces
19:14 - basically okay and now like we have done
19:17 - that like we got the output face
19:19 - from here and now we we have to make a
19:22 - box on the face
19:23 - and a text on the face basically
19:27 - okay so cv2 dot rectangle dot rectangle
19:30 - is a function which is used to make a
19:31 - shape
19:32 - by opencv so what we are doing is just
19:34 - we are passing a frame
19:36 - the coordinates the top left coordinates
19:39 - and the bottom right coordinates okay
19:42 - top left
19:43 - x y and bottom right are explicitly y
19:45 - plus h we are passing the coordinates
19:48 - okay and it will make a face round it
19:50 - will make a
19:51 - rectangle in these coordinates and this
19:53 - is the color
19:54 - and this is the width width of the box
19:58 - color is 255 25 this is basically bgr
20:02 - color
20:03 - okay blue green red okay like if i do
20:06 - zero here
20:08 - and if i do g zero here so bgr means
20:11 - b g and r so if my b
20:14 - and g are zero and my r is 255
20:18 - it will make a box of a
20:21 - red color okay and if i make this like
20:25 - uh if i make this 25 here it will make a
20:28 - green color box
20:29 - okay this is just a color color format
20:33 - and now like to put a text like here
20:35 - like we
20:36 - write a function co2.put text and it
20:38 - will just uh
20:40 - put a text here and this is the font of
20:42 - the text
20:43 - and this is the and this is the
20:44 - coordinates where i have to put my text
20:47 - and
20:48 - this is my color of the text like bgr
20:50 - format b
20:51 - is 255 so my text will be of blue color
20:54 - okay and this is a width
20:56 - okay and similarly like that we are just
20:58 - putting everything
20:59 - and now like we are just displaying our
21:01 - face
21:02 - okay like we are just showing our camera
21:04 - feed and
21:06 - all of that okay and after that
21:09 - everything just peer make a function
21:11 - like if i press a key
21:12 - q so my function will be end there and i
21:15 - can close my webcam
21:16 - and my webcam will not be closed
21:20 - by anything except pressing q okay
21:23 - and now like after all everything we
21:25 - just will just destroy the window and
21:27 - close the program that's all okay like
21:30 - this is a
21:31 - project of face cognition and i hope
21:33 - that like this is a very beginner level
21:35 - project
21:36 - in machine learning okay it's like i
21:38 - hope that this will
21:39 - this will be clear to all of you and
21:43 - just write the let's just give the
21:45 - comment below that how
21:46 - like like um how much you like this
21:49 - playlist of
21:50 - this project okay and
21:54 - okay so let's end this video now okay
21:56 - bye