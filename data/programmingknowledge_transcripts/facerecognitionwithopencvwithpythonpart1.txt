00:00 - in this video we are going to do a new
00:01 - machine learning project that
00:03 - is real time facial recognition so let
00:06 - me give you a brief overview that
00:08 - what is the output of the project then
00:09 - we will move to the roadmap that what we
00:12 - are going to do step by step
00:13 - okay so the output of the project is
00:15 - like this we will open
00:16 - with laptops camera camera or webcam and
00:19 - a colored box uh will surround our face
00:23 - and our name will do that in the box so
00:25 - basically our laptop
00:27 - will recognize our face that who we are
00:30 - and what is our name
00:31 - so let me just give you an example of
00:33 - that
00:35 - yeah so i have just run my test sample
00:37 - and this is my face as you can see
00:48 - so basically our camera is recognizing
00:51 - that what is my name and what is the
00:52 - name associated with that with that face
00:55 - okay so this is a real-time face
00:57 - recognition which our system is doing
00:59 - so let us see that how we will proceed
01:01 - to this project
01:03 - so let me give you a roadblock just that
01:05 - what we are going to do step by step
01:07 - so basically first we are gonna we are
01:10 - gonna feed
01:10 - our video that like we should open with
01:13 - camera and we should record that
01:16 - what face is in front of the camera
01:17 - right so
01:19 - i have made a several a separate snippet
01:22 - of video record
01:24 - it is just to check that uh whether the
01:26 - camera is working or not
01:28 - so by this code we can check that uh our
01:30 - camera is working or not
01:32 - um don't be stressed out i will explain
01:35 - each time of the code step by step i'm
01:36 - just
01:37 - in the roadmap right now okay so this is
01:40 - about just checking
01:41 - this this codes check that whether our
01:44 - camera is working or not
01:45 - okay so this is a real test
01:49 - and after this okay so after this
01:52 - we are gonna we are gonna uh collect our
01:55 - face data
01:56 - so basically in this snippet uh
02:00 - this the function of this code is like
02:01 - this this code
02:03 - opens up a camera and uh ask ask
02:06 - ourselves to write our name
02:08 - okay so if i play this sample so
02:11 - it is asking my name so i will enter my
02:14 - name here
02:14 - and after that when i enter then camera
02:17 - will open and it will start recording my
02:19 - face
02:20 - it will start memorizing my face
02:23 - and will put each and every data in an
02:26 - array
02:27 - okay i will explain this uh entire thing
02:30 - step by step i'm just like giving an
02:32 - overview
02:33 - overview right now okay so it this code
02:36 - recognizes
02:38 - this code basically collects our facial
02:40 - data
02:41 - and stores it in an array and that area
02:44 - is used for recognition afterwards
02:46 - so after collecting our facial data we
02:49 - will
02:50 - run this code this is basically facial
02:52 - recognition
02:53 - okay so after collecting our data
02:56 - we will store that data in another area
02:59 - and we will start another live streaming
03:02 - i mean
03:02 - we will we'll start with camera again
03:05 - and it will match
03:06 - that this current phase matches with the
03:09 - previous array
03:10 - and it maps down the name of the person
03:13 - with that figure
03:14 - okay so basically first step is data
03:18 - data collection over faces and then
03:20 - after that we will do
03:21 - a face recognition and we will use
03:23 - basically k means algorithm in this
03:26 - and a classifier that is hard cascade
03:28 - classifier
03:29 - okay so this is a brief overview
03:32 - overview of the project that what we are
03:33 - going to do
03:34 - and now i'm gonna explain you okay so
03:37 - before go
03:38 - deeping uh so because before diving into
03:40 - the project
03:42 - let us first see that what is hard
03:44 - casket classifier okay after explaining
03:47 - this hardcasket classifier i will
03:48 - explain you each and every line of the
03:50 - code that what we have
03:51 - we have done step by step okay
03:56 - because of what our casket classifier do
03:58 - is it is a collection of features
04:00 - like edge features line features and
04:02 - many or other features
04:04 - so basic purpose of hard casket
04:06 - classifier is it detects
04:08 - each and every feature of our face okay
04:10 - so this is a box it moves in every
04:13 - direction
04:14 - in the in the entire image and it
04:17 - just collects the data that where is our
04:19 - eyes where is our nose
04:20 - i'll show you the animation that how it
04:22 - works uh before that list
04:25 - you can just see on this website that
04:26 - how uh what is the basic documentation
04:29 - of our casket classifier
04:30 - um after this i will show you the
04:32 - animation of this
04:34 - okay so i've done the basic of this so
04:37 - if i enter my image here and the hard
04:40 - casket classifier will
04:41 - basically uh classify that where is our
04:44 - eyes and where is
04:45 - our face located in that that entire
04:48 - image okay
04:49 - so as you can see that here is my face
04:51 - and these are my eyes
04:52 - so this simple code which uses hard
04:55 - casket classifier has just recognized
04:57 - that
04:58 - where are my eyes and where is my face
05:00 - in the entire image
05:02 - okay so now let us see that
05:05 - this hard casket animation
05:10 - okay so as you can see that this hard
05:13 - casket classifier
05:14 - is just moving in the entire image and
05:17 - it is just classifying that
05:18 - where is our face and where are the
05:20 - other components of the face
05:21 - so as you can see that uh the edge
05:24 - features the
05:25 - line features and the other features of
05:27 - the casket
05:29 - classifier just checking that where are
05:31 - the main features of our face
05:34 - okay so it is traversing the whole image
05:36 - by increasing the size
05:38 - so just see the animation
05:45 - i have increased the size of the speed
05:47 - of the video to 5.5 x
05:49 - so you can see clearly
05:53 - okay so this is how hard casket
05:55 - classifier works okay
05:58 - so i hope that you will get and you have
06:00 - got a
06:01 - basic idea of that how and hard casted
06:03 - transfer works
06:04 - so in this video in this project we are
06:08 - we will be using that hard casket
06:09 - classifier to detect our facial
06:12 - components and
06:13 - after detecting that storing that face
06:16 - into an array mapping that with the name
06:18 - of the person and just recognizing that
06:21 - again
06:21 - by our k means algorithm okay so
06:25 - before that before starting data
06:27 - collection let us check that
06:28 - whether camera is working or not okay so
06:32 - by this code we will just check that
06:35 - whether our camera is working
06:36 - yes or no okay so let me just explain
06:39 - you this code
06:40 - so this code starting with like we will
06:42 - import cv2
06:44 - like we will we are importing opencv
06:46 - library
06:47 - and by this cap is equal to cv2 let me
06:50 - just
06:51 - zoom in zoom in okay so second line that
06:54 - cap is
06:54 - cv dot video capture it means that just
06:58 - open our webcam okay so this line opens
07:01 - our webcam
07:02 - and this loop just tells that
07:06 - if a webcam is reading our image
07:10 - then just uh continue and if it is false
07:13 - then
07:14 - move out of the loop okay so
07:17 - it shows like a video frame it
07:20 - okay so let me just open the camera
07:24 - i'm playing this and
07:40 - so as you can see that our camera has
07:42 - been opened
07:43 - and after that this camera name just the
07:46 - uh the
07:47 - name of uh camera is frame as okay as
07:50 - you can see as you have just seen before
07:52 - and after this i have entered this
07:56 - logic that if i press q q as a key
08:00 - if i press the key q then it
08:03 - breaks the camera and closes the window
08:05 - and the camera will not
08:07 - not be closed by the simple closing
08:10 - function
08:11 - it will be only closed if you enter q
08:14 - okay so this is a logic which i have
08:15 - entered and i will explain to the
08:17 - purpose of that
08:18 - why i have entered this okay and this is
08:21 - a key pressed
08:22 - this line simply means that uh
08:25 - if our currently pressed key matches
08:28 - with this key
08:29 - or not this is that's it and i will
08:32 - explain this in the meaning of this line
08:34 - later in this project when we are doing
08:35 - data collection
08:37 - okay i will explain the logic behind
08:39 - this that why i have
08:40 - bit wise why i have used with bitwise
08:44 - and
08:44 - here with zero xfs okay so
08:48 - for right now you have to just
08:49 - understand that we have just opened up a
08:51 - camera and just check that
08:53 - if return is equal to false then we will
08:55 - just continue and
08:56 - if our camera is reading then we will
08:59 - just move
09:00 - move forward and just show the camera
09:04 - that and just check that whether the
09:06 - camera is open or not and we'll just
09:08 - uh close that camera by pressing the key
09:10 - q
09:11 - okay and after that we will release our
09:14 - camera
09:14 - tab dot release if when we break out of
09:17 - the loop
09:18 - then we just release a camera by this
09:21 - line
09:22 - this means closing the camera and by
09:25 - this
09:25 - it means that destroying all windows
09:27 - means uh
09:30 - disabling all the cookies that have been
09:32 - formed by opening the camera
09:33 - and deleting all the data which has been
09:36 - captioned
09:37 - in the back memory okay so this is
09:39 - basically a video read
09:41 - we are just checking that our camera is
09:43 - reading the video or not
09:45 - okay so i hope that you have got a clear
09:48 - idea that what
09:49 - is this okay so after that
09:52 - we'll do facial data collection by this