00:00 - welcome to programming knowledge so in
00:03 - the last video I've shown you the Kanan
00:07 - model and how to build it and we had
00:09 - also shaped the Kelvin accuracy and we
00:12 - got it around 83% which are less than
00:16 - the hoisting model you can see we had
00:20 - misclassified samples as one four five
00:22 - five now today I will show you the
00:24 - effect of K value on the classifier what
00:27 - we will do we create a list until it's
00:30 - called misclassified sample that is
00:36 - equal to lambda leashed and next thing
00:41 - will be you calculate the error for K
00:44 - values between 1 and 20 so we get best
00:50 - among them so we had tried for only 5
00:53 - plus 10 as you can see here your
00:56 - neighbors we are given 5 so we'll knock
00:58 - you 1 to 20 you will select the best one
01:01 - which has better accuracy and less
01:03 - number of
01:04 - misclassified samples so let's do that
01:07 - so we call our for loop so for I in
01:11 - range will queue from 1 to 20 what we
01:18 - want to will create one instance of the
01:21 - km class file so Kanan equals 2k leavers
01:28 - classifier inside that will give
01:31 - neighbors and will give the value is I
01:34 - and then we will just fit the model that
01:38 - is input and output on the model
01:41 - distance so you put would be train X and
01:49 - output will be train Y so these are the
01:53 - data frames next thing would be we
01:57 - create from variable color prediction I
02:00 - so it will iterate over the loop and it
02:04 - will save all the predictions so we will
02:07 - just try to pass the prediction to date
02:10 - so Kanan dot predict function
02:16 - inside this will pass our test frame
02:19 - that is test X and then we'll just call
02:23 - our leashed that is misclassified
02:27 - you
02:31 - we didn't run it understand it now you
02:35 - can just use tab and now you can see
02:37 - misclassified simple dot append and
02:43 - inside this you just pass over dashed by
02:50 - is not equals to
02:54 - the prediction of hi then just some
02:59 - Braley's
03:01 - and just from this
03:06 - it will take some time the positive is
03:09 - collecting for
03:11 - each case from 1 to 20 for all the
03:15 - neighbors so we'll start off from
03:18 - neighbor 1 and it will go till neighbor
03:21 - 20 so we will wait for some time till
03:28 - that we can type misclassified sample
03:36 - you
03:39 - okay it has run so we'll just print the
03:43 - leashed and we can see the values so we
03:46 - will find out which one has the lowest
03:49 - you
03:54 - so we have two values one 4:05 and which
03:59 - comes around so 14 14 then 16 are the
04:05 - neighbors which will give us the best
04:07 - values
04:09 - your we can try it out
04:14 - we'll just right here as 14
04:22 - [Music]
04:24 - Pettit then just very tripped - Dex
04:32 - this and the confusion matrix a quickie
04:36 - error because you can see in the last
04:39 - record showing
04:41 - so - takes in test-drive you have to run
04:44 - it again so you can see the test train
04:50 - state method on top so this we have to
04:55 - run it again
04:57 - mr. SIL from all over
05:01 - that should do the job and we'll go down
05:05 - more key neighbors name is runs now we
05:15 - should not get error out for confusion
05:16 - metrics can see it has can on classified
05:21 - 69 it correctly and one two four six
05:23 - correctly these for less than fifty
05:25 - thousand visits for greater than two
05:26 - thousand just illustrate the kicker is
05:29 - accuracy and it is increased to eighty
05:32 - four percent
05:33 - as you can see finding out the right
05:36 - neighbors number so it was fourteen this
05:40 - time we get higher accuracy you can just
05:44 - set the misclassified samples is one
05:46 - four five five for the neighbors is five
05:49 - now check for forty so you can see it is
05:53 - reduced to one 4:05 that is 15 plus ion
05:58 - fifties no samples are classified
06:00 - correctly so this will help you in
06:04 - classifying or improving the accuracy of
06:07 - your model so now we'll go for the case
06:14 - story to that is regression analysis so
06:18 - this is the regression case study and
06:22 - occasionally we'll be ready picking the
06:24 - price of pre-owned cars so as compared
06:28 - to the earlier case study that was
06:29 - classification we had two categories in
06:31 - that in which we have 2 class classifier
06:34 - if a person is falls under the less than
06:39 - 50,000 category all greater than 2000
06:42 - category of the salary
06:44 - so this one is function approximation
06:48 - that is a regression so we'll find a
06:52 - price for the pre-owned cars so many
06:55 - websites such as car they co.com use
06:58 - this algorithm so let's look at the
07:02 - problem statement so storm Motors is an
07:05 - e-commerce company who act as mediators
07:08 - between parties interested in selling
07:10 - and buying pre-owned cars so for the
07:13 - year 2015
07:15 - till they have recorded data about the
07:17 - seller and a car including some
07:20 - attributes such as specification details
07:22 - condition of car salary details
07:26 - registration details web web
07:29 - advertisement details make and model
07:31 - information and price so I'll be showing
07:34 - all this information in the CSV file so
07:40 - the store Motors wishes to develop an
07:43 - algorithm to predict the price of the
07:45 - cars based on the various attributes
07:47 - associated with the car so in order to
07:51 - set up favorable price which will invite
07:57 - the seller also and the buyer also
08:02 - the storm motors want to use this
08:05 - algorithm that is regression analysis
08:06 - and come when conclusion of a price it
08:11 - will be favorable to both of the parties
08:15 - let me show how to go ahead with this
08:18 - your next video thank you for watching
08:20 - now seen next very