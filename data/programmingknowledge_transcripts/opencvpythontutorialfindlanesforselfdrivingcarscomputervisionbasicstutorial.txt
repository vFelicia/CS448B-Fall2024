00:00 - hello everyone in this tutorial I will
00:01 - teach you to use effective computer
00:04 - vision techniques with open CV and
00:05 - Python ultimately to detect lane lines
00:08 - for a simulated self-driving car this
00:10 - video was done in collaboration with the
00:12 - programming knowledge YouTube channel
00:14 - and by the time you finish this tutorial
00:16 - if you're interested in more
00:17 - self-driving car content feel free to
00:19 - check out the link in the description
00:20 - below but without further ado let's
00:22 - start this tutorial welcome to your
00:26 - first lesson this lesson is quite simple
00:28 - as all we're going to be doing is
00:29 - installing the Anaconda distribution
00:31 - we'll start this off by going over to
00:34 - anaconda dot-com / download the anaconda
00:41 - distribution conveniently installs
00:43 - python the jupiter notebook app which
00:46 - we're going to use quite often
00:47 - throughout this course and over a
00:49 - hundred and fifty other scientific
00:51 - packages since we're installing python
00:54 - for mac make sure to navigate to the Mac
00:57 - section
01:05 - and we're going to install Python 3 not
01:08 - Python 2 it's very likely that you're
01:11 - seeing different versions of Python and
01:13 - the ones I'm seeing right now
01:15 - but regardless since Python 2 is no
01:18 - longer being updated it's imperative
01:21 - that you download the latest version
01:23 - python 3 to keep compatibility with
01:26 - future Python improvements and to also
01:29 - follow along with this course click on
01:32 - the download button no thanks
01:40 - once your download is finished will open
01:43 - this package continue keep pressing
01:47 - continue continue agree to the terms and
01:50 - conditions that you have read the
01:52 - agreement and simply enough press
01:54 - install once your installation is
01:59 - complete press Continue again close and
02:02 - move to trash that is all very easy and
02:06 - intuitive to ensure that this works
02:08 - whatever terminal window you had
02:09 - previously opens make sure to close it I
02:13 - already had one open so I'll close mine
02:15 - if you don't have one open then you
02:17 - should be fine what we'll do is we'll
02:20 - open up a new terminal window by
02:22 - performing a spotlight search what you
02:25 - can do by pressing command + space
02:30 - right terminal and press Enter
02:39 - alternatively you could have just access
02:41 - your terminal by presing on f4 and
02:44 - performing the search here but
02:46 - regardless to ensure a successful
02:48 - installation write the command Python 3
02:52 - double dash version
03:00 - and I get a version of three point six
03:04 - point four make sure you also get a
03:06 - Python 3 version that is all hope you
03:09 - were able to follow along if you have
03:11 - any issues with the installation feel
03:13 - free to ask me in the Q&A section
03:15 - welcome back we'll be making use of the
03:18 - atom text editor in the computer vision
03:19 - section you can feel free to use any
03:21 - text editor you want like sublime or vim
03:24 - in which case feel free to skip this
03:26 - lesson otherwise if you don't have any
03:29 - text editor installed let's get to it
03:31 - downloading it is quite simple for both
03:34 - Mac and Windows I'll be proceeding with
03:36 - the Mac installation by going over to
03:38 - Adam dot IO and inside of atom dot IO
03:44 - just clicking download this is also
03:47 - downloadable from tech spot by also
03:50 - going over to Google and then searching
03:53 - tech spot atom download and going into
03:58 - the first link where if you just simply
04:02 - click on the appropriate link and then
04:04 - wait for it to finish setting up the
04:05 - download whether you're on Mac or
04:07 - Windows alright once your installation
04:12 - is complete it should be inside of your
04:14 - downloads folder let us just open up
04:16 - atom and see what it's like it's
04:20 - verifying this new application we're
04:24 - going to open it all right we're going
04:28 - to close the following and then what
04:30 - we'll do is click on packages and inside
04:34 - of packages we're going to go to
04:35 - settings you and open the settings if
04:41 - you're using a PC I imagine the process
04:44 - to get to your settings you should be
04:45 - quite similar and now inside of editor
04:48 - we can modify some settings for example
04:52 - the font family I'm quite satisfied with
04:54 - the current font and font size 16 seems
04:58 - pretty reasonable and two other boxes I
05:01 - like to have checked are showing the
05:04 - cursor on selection and showing
05:06 - indentation indicators indentation is
05:09 - fundamental to pythonic code as it
05:12 - distinguishes between different blocks
05:14 - of code so it will definitely be useful
05:16 - to always have indentation indicators
05:19 - and finally one more thing that's pretty
05:21 - important is the tab length the default
05:25 - tab length should be 2 I believe but I
05:28 - personally prefer using 4 spaces per tab
05:30 - and just one more thing I want to do
05:33 - before moving on is enabling autosave so
05:37 - we'll go back to packaged and this will
05:40 - be very convenient in our code since it
05:43 - would keep us from having to save our
05:45 - code every time we need to run it so
05:47 - what we'll do is inside of core packages
05:49 - scroll down until you find autosave
05:53 - right over here and make sure that you
05:56 - enable it I already have it enabled
05:58 - alright and that concludes the
06:01 - installation section
06:05 - the purpose of this section is to build
06:07 - a program that can identify lane lines
06:09 - in a picture or a video when you and I
06:12 - drive a car we can see where the lane
06:14 - lines are using our ice a car doesn't
06:17 - have any ice and that's where computer
06:19 - vision comes in which through complex
06:22 - algorithms helps the computer see the
06:24 - world as we do in our case we'll be
06:26 - using it to see the road
06:28 - and identify Lane lines in a series of
06:30 - camera images this lesson in particular
06:32 - will be quite simple as all we're going
06:34 - to do is set up the initial stages of
06:36 - our project and display an image on to
06:39 - which we'll be identifying lane lines
06:41 - you'll start by opening up your terminal
06:43 - or command prompt and navigate to the
06:46 - desktop directory with the command CD
06:49 - desktop change the rectory desktop
06:53 - inside of desktop we'll make a new
06:55 - folder with the command mkdir make
06:58 - directory finding lanes this folder you
07:03 - just made inside of desktop you're going
07:05 - to open up with atom by going to file
07:08 - open desktop finding lengths instead of
07:14 - finding lanes make a new python file
07:16 - called lanes py
07:20 - inside of the lanes file we're going to
07:22 - start by writing a program that can
07:24 - identify lanes in a JPEG image I posted
07:28 - the image on my github to access it make
07:30 - sure to go to the following link the
07:32 - link is also available in the
07:34 - description below and so once you get to
07:37 - this github page click on test image
07:40 - JPEG and what we're gonna do is actually
07:43 - download the image or better yet just
07:45 - save the image and make sure to save it
07:49 - as a JPEG image it doesn't matter where
07:52 - you save it and make sure this says test
07:54 - image such that there are no extra ones
07:57 - or twos in there so that you're naming
07:59 - remains consistent with what I have in
08:01 - the videos alright save your image once
08:06 - you download it wherever you have it
08:08 - downloaded make sure to drag it into
08:10 - your project folder like so and now to
08:12 - display the image we're going to use
08:14 - open CV an open source computer vision
08:17 - library so inside of your terminal we're
08:22 - going to write the command pip install
08:24 - will make use of the package manager pip
08:27 - to install OpenCV - TREB - python
08:35 - if it is installing it back to visual
08:36 - studio we're going to import the library
08:39 - CV to and from this library for now we
08:43 - will access to functions Emory and M
08:46 - show to load our image will first make
08:49 - use of the M read function by setting
08:51 - image is equal to CB - dot M read and in
08:57 - this argument is where you will specify
08:58 - the image the file name as a string ours
09:02 - is test image dot JPEG and what this
09:09 - function will do is read the image from
09:11 - our file and return it as a
09:13 - multi-dimensional numpy array containing
09:16 - the relative intensities of each pixel
09:18 - in the image we now have our image data
09:20 - in a number right the next step is to
09:23 - actually render it with the M show
09:24 - function so we'll write C v2 dot M show
09:30 - this takes in two arguments the first
09:33 - one is the name of the window that we're
09:35 - going to open up we'll just call it a
09:36 - result and the second argument is the
09:39 - image that we want to show itself if I
09:43 - run the code now to my terminal navigate
09:46 - to my project folder by writing CD our
09:49 - project is named finding lanes and run
09:52 - the python file python elaine's dot py
09:56 - notice that nothing is going to happen
09:59 - that's because this function should be
10:02 - followed by the weight key function c v2
10:05 - dot weight key and what this function
10:08 - does that displays the image for a
10:10 - specified amount of milliseconds we'll
10:13 - set a time of 0 what this will do is it
10:16 - will display our window our result to
10:19 - window infinitely until we press
10:21 - anything in our keyboard if we rerun the
10:24 - code python Lanes the image is displayed
10:28 - and notice our window name results will
10:31 - keep this lesson short and stop here you
10:33 - learn how to load and display images
10:35 - using the opencv library in the next
10:37 - lesson we'll start discussing canny edge
10:39 - detection a technique that we'll use to
10:42 - write a program that can detect edges in
10:44 - an image
10:45 - and thereby single out the lane lines
10:48 - welcome to lesson number two the goal of
10:51 - the next few videos will be to make use
10:53 - of an edge detection algorithm the canny
10:56 - edge detection technique the goal of
10:58 - edge detection is to identify the
11:00 - boundaries of objects within images in
11:02 - essence will be using edge detection to
11:05 - try and find regions in an image where
11:07 - there is a sharp change in intensity a
11:09 - sharp change in color before diving into
11:12 - this it's important to recognize that an
11:14 - image can be read as a matrix an array
11:16 - of pixels a pixel contains the light
11:19 - intensity at some location in the image
11:21 - each pixels intensity denoted by a
11:24 - numeric value that ranges from 0 to 255
11:27 - an intensity value of 0 indicates no
11:31 - intensity if something is completely
11:33 - black whereas 255 represents maximum
11:37 - intensity something being completely
11:39 - white that being said a gradient is the
11:43 - change in brightness over a series of
11:45 - pixels a strong gradient indicates a
11:48 - steep change whereas a small gradient
11:51 - represents a shallow change
11:56 - on the right-hand side you're looking at
11:58 - the gradient of the soccer ball the
12:00 - outline of white pixels corresponds to
12:03 - the discontinuity and brightness at the
12:05 - points the strength ingredient this
12:08 - helps us identify edges in our image
12:10 - since an edge is defined by the
12:13 - difference in intensity values in
12:15 - adjacent pixels and wherever there's a
12:17 - sharp change in intensity a rapid change
12:20 - in brightness wherever there's a strong
12:22 - gradient there is a corresponding bright
12:26 - pixel in the gradient image by tracing
12:29 - out all of these pixels we obtain the
12:31 - edges we're going to use this intuition
12:34 - to detect the edges in our out image
12:36 - this is a multi-step process step one
12:40 - being to convert our image to grayscale
12:42 - why convert it to grayscale well as we
12:46 - discussed earlier images are made up of
12:48 - pixels a three-channel color image would
12:52 - have red green and blue channels each
12:55 - pixel a combination of three intensity
12:57 - values whereas a grayscale image only
13:00 - has one channel each pixel with only one
13:03 - intensity value ranging from 0 to 255
13:07 - the point being by using a grayscale
13:10 - image processing a single channel is
13:14 - faster than processing a three channel
13:16 - color image and less computational
13:18 - intensive let's start implementing this
13:22 - inside of Adam we've already loaded in
13:24 - red our image into an array now what
13:27 - we'll do is import numpy as the alias NP
13:33 - we're going to work with a copy of this
13:36 - array by setting lane image is equal to
13:40 - numpy copy image thus copying our array
13:46 - into a new variable it's imperative that
13:49 - you actually make a copy of this array
13:52 - instead of just setting Lane image is
13:54 - equal to image if we do this any changes
13:58 - we make to Lane image will also be
14:01 - reflected in the original mutable array
14:03 - always ensure that you make a copy
14:06 - whenever working with a race instead of
14:08 - just setting them equal directly so what
14:13 - we'll do now is we'll create a grayscale
14:15 - from the color image well do that by
14:17 - setting a variable gray is equal to cv
14:21 - to and from our OpenCV library will call
14:25 - the function CVT color which converts an
14:30 - image from one color space to another
14:32 - we'll be converting Lane image and in
14:36 - the second argument for an RGB to
14:40 - greyscale conversion we can use the flag
14:44 - C v2 dot color underscore RGB to gray
14:51 - very intuitive and now instead of
14:55 - showing the color image will show the
14:59 - grayscale image if we go to our terminal
15:04 - Python lanes that py everything works
15:09 - out accordingly this was step number one
15:12 - step number two of edge detection will
15:14 - be to next apply a Gaussian blur on this
15:17 - image let's talk about that in the next
15:20 - video
15:22 - welcome to lesson number three in the
15:24 - last lesson we applied step number one
15:26 - which was to convert our image to
15:28 - grayscale step two is to now reduce
15:30 - noise and smooth an our image when
15:34 - detecting edges while it's important to
15:36 - accurately catch as many edges in the
15:38 - image as possible
15:39 - we must filter out any image noise image
15:42 - noise can create false edges and
15:44 - ultimately affect edge detection that's
15:47 - why it's imperative to filter it out and
15:49 - thus smoothen the image filtering out
15:53 - image noise and smoothening will be done
15:55 - with a Gaussian filter to understand the
15:58 - concept of a Gaussian filter recall that
16:01 - an image is stored as a collection of
16:03 - discreet pixels each of the pixels for a
16:07 - grayscale image is represented by a
16:09 - single number that describes the
16:11 - brightness of the pixel for the sake of
16:14 - example how do we smoothen the following
16:16 - image the typical answer would be to
16:19 - modify the value of a pixel with the
16:21 - average value of the pixel intensities
16:23 - around it
16:26 - averaging out the pixels in the image to
16:28 - reduce noise will be done with a kernel
16:31 - essentially this kernel of normally
16:33 - distributed numbers is run across our
16:35 - entire image and sets each pixel value
16:39 - equal to the weighted average of its
16:41 - neighboring pixels
16:42 - thus smoothening our image we're not
16:46 - going to go over kernel convolution and
16:48 - how it doesn't just know that when we
16:50 - write this line of code inside of our
16:52 - editor blur is equal to cv - Gaussian
16:55 - blur what we're doing is applying a
16:58 - Gaussian blur on a grayscale image with
17:01 - a 5x5 kernel the size of the kernel is
17:04 - dependent on specific situations a 5x5
17:08 - kernel is a good size for most cases but
17:11 - ultimately what that will do is return a
17:13 - new image that we simply called blur
17:16 - applying the Gaussian blur by convolving
17:18 - our image with a kernel of Gaussian
17:21 - values reduces noise in our image back
17:25 - to our project set blur is equal to cv -
17:29 - Gaussian blur we'll apply this blur in
17:34 - our greyscale image with our 5x5 kernel
17:38 - and we'll just leave the deviation as
17:40 - zero the main thing you should take away
17:43 - from this is that we're using a Gaussian
17:44 - blur to reduce noise in our greyscale
17:48 - image and now we'll simply show the
17:50 - blurred image if we run this code Python
17:54 - lanes dot py there is our blurred
17:58 - greyscale image later on when we apply
18:02 - the canny method it should be noted that
18:05 - this step was actually optional since
18:09 - the canny function is going to
18:10 - internally apply a 5x5 Gaussian when we
18:14 - call it a regardless now we know the
18:17 - theory we've obtained our grayscale we
18:19 - smooth and it introduced noise with a
18:21 - Gaussian blur now it's time to apply the
18:24 - canny function we'll do that in the next
18:27 - video in the last lesson we smoothen our
18:29 - image and reduce noise now it's time to
18:32 - apply the canny method to identify edges
18:34 - in our image recall that an edge
18:37 - corresponds to a region in an in
18:39 - where there is a sharp change in
18:40 - intensity or a sharp change in color
18:43 - between adjacent pixels in the image the
18:46 - change in brightness over a series of
18:48 - pixels is the gradients a strong
18:51 - gradient indicates a steep change
18:52 - whereas a small gradient a shallow
18:55 - change we first established that an
18:58 - image as it's composed of pixels can
19:00 - therefore be read as a matrix an array
19:03 - of pixel intensities to compute the
19:05 - gradients in an image one must recognize
19:07 - that we can also represent an image in a
19:10 - two dimensional coordinate space x and y
19:13 - the x axis traverses the images width
19:16 - and the y axis goes along the images
19:19 - heights with representing the number of
19:22 - columns in the image and height the
19:24 - number of rows such that the product of
19:27 - both width and height gives you the
19:29 - total number of pixels in your image
19:31 - the point being not only can we look at
19:34 - our image as an array but also as a
19:36 - continuous function of x and y since
19:39 - it's a mathematical function we can
19:41 - perform mathematical operation which
19:44 - begs the question what operator can we
19:47 - use to determine a rapid changes in
19:49 - brightness in our image what the candy
19:53 - function will do for us is perform a
19:55 - derivative on our function in both x and
19:58 - y directions there by measuring the
20:01 - change in intensity with respect to
20:03 - adjacent pixels a small derivative is a
20:07 - small change in intensity whereas a big
20:10 - derivative is a big change by computing
20:13 - the derivative in all directions of the
20:15 - image we're computing the gradients
20:17 - since recall the gradient is the change
20:21 - in brightness over a series of pixels so
20:24 - when we call the canny function it does
20:26 - all of that for us it computes the
20:29 - gradient in all directions of our
20:31 - blurred image and is then going to trace
20:34 - our strongest gradients as a series of
20:37 - white pixels but notice these two
20:40 - arguments low threshold and high
20:42 - threshold while this actually allows us
20:45 - to isolate the adjacent pixels that
20:48 - follow the strongest gradients if the
20:51 - gradient is large
20:52 - the upper threshold then it is accepted
20:55 - as an edge pixel if it is below the
20:57 - lower threshold it is rejected if the
21:00 - gradient is between the thresholds then
21:03 - it will be accepted only if it is
21:05 - connected to a strong edge the
21:07 - documentation itself recommends to use a
21:10 - ratio of one to two or one to three as
21:13 - such will use a low high threshold ratio
21:16 - of one to three fifty to one fifty now
21:20 - that we know what goes on under the hood
21:21 - we can call this function inside of our
21:24 - project by writing Kenny is equal to cv
21:29 - to DA Kenny will apply the canny method
21:34 - on the blurred image with low and high
21:38 - thresholds of 50 and 150 and now we'll
21:42 - show the image gradient instead of the
21:45 - blurred image Kenny if we go ahead and
21:49 - run the code python lanes dot py and
21:54 - there's the gradient image which clearly
21:58 - traces an outline of the edges that
22:01 - correspond to the most sharp changes in
22:04 - intensity gradients that exceed the high
22:07 - threshold are traced as bright pixels
22:11 - identifying adjacent pixels in the image
22:13 - with the most rapid changes in
22:16 - brightness small changes and brightness
22:19 - are not traced at all and accordingly
22:21 - they are black as they fall below the
22:23 - lower threshold that's it for the candy
22:26 - method we used it to outline the
22:28 - strongest gradients in our image now
22:30 - this was a lot of explanation for just
22:33 - three lines of code but it's good to
22:35 - have a grasp of what's going on under
22:37 - the hood before we proceed any further
22:39 - and now that we've computed the
22:42 - strongest gradients in the next few
22:44 - videos we'll apply the Hough transform
22:46 - method to detect our lanes in the last
22:49 - lesson we used the candy function to
22:51 - outline the strongest gradients in our
22:53 - image now we'll focus on how we can
22:55 - identify lane lines in the image before
22:58 - doing that what we'll do now is specify
22:59 - a region of interest in our image that
23:01 - we're going to use to detect our
23:04 - landlines asked currently shovin before
23:07 - proceeding any further what we'll do
23:08 - first is actually wrap our code inside
23:11 - of a function by defining a function
23:13 - Kenny
23:14 - which takes in an image and what we'll
23:18 - do is copy the Kenny algorithm code
23:21 - inside of the function
23:29 - and specify Kenny as the return value
23:32 - return Kenny and what we can do now is
23:36 - simply set
23:37 - Kenny equal to the return value of our
23:39 - candy function passing in the initial
23:43 - RGB color image and rerunning this code
23:46 - back into our terminal Python leads that
23:49 - py everything is still intact what we'll
23:53 - do now is we'll specify this area as a
23:55 - region of interest before doing so
23:58 - instead of showing our image gradient
24:00 - with OpenCV will use the matplotlib
24:01 - library to better clarify how we're
24:04 - going to isolate this region you should
24:06 - already have matplotlib installed
24:08 - courtesy of the anti counter
24:09 - distribution so what we can do now is
24:12 - imports matplotlib and we're going to
24:17 - need the sub package from matplotlib
24:19 - called pi plots as an alias
24:22 - PLT conveniently pi plot contains the
24:28 - function m show so we can just replace
24:31 - cv to web PLT and in this case no need
24:37 - to specify a window name just the image
24:40 - the equivalent of open Stevie's await
24:42 - key function would simply be PLT so if
24:47 - we go back and run the code in our
24:49 - terminal python lines the py we get the
24:52 - same image along with x and y axis
24:55 - notice how the y axis starts from the
24:57 - first row of pixels and then goes
24:59 - downwards with our axes we're going to
25:03 - limit the extent of our field of view
25:05 - based on their region of interest with
25:07 - chalten mainly traces a triangle where
25:10 - the vertices of 200 along the X and 700
25:14 - pixels along the Y which would simply be
25:17 - the bottom of the image 1100 pixels
25:20 - along the X and once again the bottom of
25:22 - the image 700 pixels out the Y the very
25:25 - bottom and the last vertex will simply
25:27 - be 550 pixels along the X and 250
25:31 - traveling down the Y ultimately tracing
25:34 - a triangle that isolates the region
25:36 - where we want to identify the lane lines
25:38 - so the goal of this video will be to
25:40 - create an image that's completely black
25:42 - a
25:43 - with the same dimensions our road image
25:46 - and fill part of its area with a
25:49 - triangular polygon first and foremost
25:52 - will revert showing the image to being
25:54 - number the opencv rather than matplotlib
25:58 - and what we'll do now is define a
26:00 - function deff a region of interest which
26:06 - also takes in an image and what this
26:09 - function will do is pretty
26:10 - self-explanatory it will return the
26:12 - enclosed region of our field of view and
26:15 - recall that the enclosed region was
26:18 - triangular in shape so we'll set a
26:21 - variable named triangle it's equal to
26:24 - and this polygon this triangle we'll
26:27 - declare as a numpy array and P dot array
26:32 - inside of this array is where you
26:34 - specify its vertices recall that while
26:36 - limiting the extent of our field of view
26:38 - we traced a triangle with vertices that
26:41 - go 200 along the X and vertically until
26:45 - the extent of our image until the bottom
26:47 - which in this case is the height we can
26:49 - get the height of our image by setting
26:51 - height is equal to image dot shape at
26:55 - the end X 0
26:56 - recall from the numpy crash course that
26:58 - the shape of an array is denoted by two
27:00 - pool of integers since we're dealing
27:02 - with a two-dimensional array the first
27:04 - integer corresponding to the number of
27:06 - rows the y-axis traverses the images
27:09 - height and height accordingly is the
27:11 - number of rows so you can already assume
27:13 - that this value will be something very
27:15 - close to 700 since that's what we saw in
27:18 - matplotlib so we'll simply set the
27:20 - height to complete our first vertex the
27:22 - second one being 1100 pixels along the X
27:25 - and vertically
27:28 - once again right up until the extent of
27:31 - our image being the height the vertical
27:33 - extent and lastly in the last vertex was
27:38 - 550 pixels along the X and 250 pixels
27:43 - along the Y this polygon we're going to
27:46 - apply it onto a black mask with the same
27:49 - dimensions as our road image so we'll
27:52 - set mask is equal to num pi dot zeros
27:57 - like image recall that an image can be
28:03 - read as an array of pixels zeros like
28:05 - creates an array of zeros with the same
28:08 - shape as the images corresponding array
28:10 - both arrays will therefore have the same
28:13 - number of rows and columns which means
28:15 - that the mask will have the same amount
28:18 - of pixels and thus the same dimensions
28:20 - as our canny image that we're going to
28:23 - pass it in a bit although it's pixels
28:25 - will be completely black as all of them
28:28 - will have a zero intensity what we have
28:31 - to do now is fill this mask there's some
28:34 - black image with our polygon using open
28:38 - series fill poly function that is CV to
28:42 - the fill poly
28:46 - we will fill our mask with our triangle
28:50 - the third argument specifies that the
28:53 - color of our polygon which we're going
28:55 - to have be completely white so what
28:59 - we're going to do is take a triangle
29:01 - whose boundaries we defined over here
29:04 - and apply it on the mask such that the
29:07 - area bounded by the polygonal contour
29:10 - will be completely white what we'll do
29:13 - now is return our modified mask return
29:16 - mask and instead of showing the Ken
29:21 - image will be showing the return value
29:24 - of our function region of interest and
29:28 - the image that we're going to pass in is
29:30 - simply going to be the Kenny image let's
29:33 - run the code
29:34 - let's run Python Alain's dot py and it
29:39 - would throw an exception and that's
29:41 - because fill poly the fill poly function
29:45 - fills an area bounded by several
29:48 - polygons not just one even though you
29:51 - and I both know that we're dealing with
29:52 - only a single polygon we'll rename this
29:55 - variable from triangle to polygons for
29:58 - consistency and we'll set it equal to an
30:01 - array of polygons in our case an array
30:04 - of simply one polygons change this from
30:07 - triangle to polygons if we rerun this
30:11 - code there is our mask and inside of the
30:17 - mask there is the enclosed region the
30:20 - polygon with the specified vertices now
30:23 - you might be asking yourself why did we
30:25 - go through all of this well this video
30:27 - has gone on long enough
30:28 - so let's talk about that in the next
30:30 - lesson previously we created a mask with
30:34 - the same dimensions as our road image we
30:36 - then identified a region of interest and
30:39 - our road image with very specific
30:41 - vertices along the x and y axis that we
30:44 - then used to fill our mask the image on
30:47 - the right why is it important well we're
30:50 - going to use it to only show a specific
30:52 - portion of the image
30:55 - everything else we want to mask
31:00 - so to understand how we're going to use
31:02 - this image to mask our canny image to
31:05 - only show the region of interest traced
31:07 - by the triangular polygons you'll
31:09 - require a basic understanding of binary
31:12 - numbers if you're already familiar with
31:16 - binary numbers feel free to skip the
31:18 - next two minutes or so of this video
31:20 - otherwise I'll introduce it now and I'll
31:23 - do it very quickly commonly when one
31:26 - thinks of binary representations they
31:27 - think of zeros and ones well more
31:30 - specifically binary numbers are
31:32 - expressed in the base-2 numeral system
31:34 - which uses only two symbols typically
31:37 - zeros and ones what does that mean for
31:41 - example the number 23 it's a binary
31:43 - representation is 1 0 1 1 1 how did I
31:47 - obtain that number well let's imagine 8
31:50 - placeholders 8 boxes as we're dealing
31:53 - with a base-2 numeral system each box
31:56 - represents a power of 2 each numerical
31:59 - place will correspond to an increasing
32:02 - power of 2 the first box 2 to the power
32:05 - of 0 which simply equals 1 then 2 to the
32:09 - power of 1 which equals 2 all the way up
32:12 - until 2 to the power of 7 up until 128
32:16 - we'll come back to this now each box can
32:20 - only accept one of two values 0 or 1 so
32:23 - we want to put in binary the number 23
32:26 - we wish to represent this number in
32:28 - binary format so what we do is we start
32:31 - with the highest value 128 and ask
32:34 - ourselves is this value in the number 23
32:38 - 128 is clearly not in the number 23 it's
32:41 - way too big so we leave that as 0 64 is
32:45 - not in 23rd we also leave that is 0 32
32:49 - is certainly greater than 23 we leave
32:52 - that as 0 16 this goes into 23 so it's
32:56 - assigned the number 1 and so far we've
32:59 - used up 16 23 minus 16 equals 7 there
33:03 - are 7 left we have to account for this 8
33:05 - going to 7 nope we leave that as 0 does
33:08 - 4 go into 7 of course that takes a value
33:11 - of 1 so now we've used the forest
33:13 - seven minus four equals three and
33:15 - there's three left that we have to
33:17 - account for just to go into three yep
33:19 - now there's only one left does one go
33:21 - into one indeed and there is the binary
33:25 - representation of 23 we can cut off the
33:28 - zeros in the beginning and it's just as
33:30 - we said earlier 1 0 1 1 1
33:35 - all right so why don't I just randomly
33:37 - start talking about binary numbers while
33:40 - the image on the right I went ahead and
33:42 - printed out its pixel representation I
33:44 - resized the array simply because it was
33:47 - too large but never mind that
33:49 - notice how the triangular polygon
33:51 - translates the pixel intensities of 255
33:54 - and the black surrounding region
33:56 - translates the pixel intensities of 0
33:58 - what's the binary representation of 0
34:01 - while none of these numbers go into 0 so
34:05 - we leave 0 for each placeholder leaving
34:07 - us with a binary representation of 0 0 0
34:10 - 0
34:10 - what about 255 well for that we'll need
34:14 - 8 placeholders 2 to the 0 up until 2 to
34:18 - the 7 and so if you do the math we just
34:20 - talked about you'll realize that it's a
34:23 - binary representation is all one's 8
34:25 - ones as all of these numbers add up
34:27 - exactly to obtain 255 as a side note if
34:31 - we think of this in terms of bits where
34:34 - each bit holds a single binary value and
34:37 - 8 bits form 1 byte 255 is actually the
34:42 - maximum representable value by an 8-bit
34:45 - byte so we can conclude since the
34:49 - surrounding region is completely black
34:51 - each pixel with a value of 0 than the
34:54 - binary representation of every pixel
34:56 - intensity in that region would be all
34:59 - zeros 0 0 0 0
35:01 - as for the polygonal contour whose
35:04 - region is completely white than the
35:07 - binary representation of every pixel
35:09 - intensity in that region would be all
35:11 - ones why is this important well we're
35:15 - going to apply this mask on to our canny
35:17 - image to ultimately only show the region
35:21 - of interest the region traced by the
35:23 - polygonal contour we do this by applying
35:27 - the bitwise and operation between the
35:30 - two images the bitwise and operation
35:33 - occurs element-wise between the two
35:35 - images between the two arrays of pixels
35:38 - now both of these images have the same
35:41 - array shape and therefore the same
35:43 - dimensions and the same amount of pixels
35:46 - by applying the bitwise end
35:49 - since it occurs element-wise then we're
35:52 - taking the bitwise end of each
35:55 - homologous pixel on both arrays and the
35:59 - way bitwise and works is let's imagine
36:02 - two binary numbers 0 1 1 0 0 1 which if
36:07 - you do the math you saw earlier
36:08 - you'll realizes the number 25 and 1 1 0
36:13 - 0 1 0 which would be the number 50 this
36:17 - is a pretty standard example but
36:20 - regardless let's take their bitwise and
36:22 - and what n will do is it puts a 0 unless
36:27 - both pairs are ones in the first pair
36:31 - since one of these is 0 we put a 0 and
36:34 - the second one both of them are ones so
36:37 - we put a 1 in this one one of them is
36:40 - zero so we put a 0 and we keep doing
36:43 - this until eventually the resultant end
36:45 - operation would yield 0 1 0 0 0 0 what
36:51 - if we took the bitwise end of all zeros
36:54 - with any other value well no matter what
36:56 - during the operation you're always going
36:59 - to have at least one 0 which means the
37:02 - result of the end operation will yield
37:05 - all zeros no matter what value we choose
37:08 - to operate against it so going back to
37:11 - our two images the black region whose
37:13 - pixels have intensity values which
37:15 - correspond to the binary number we just
37:17 - talked about zero zero zero zero by
37:20 - taking the bitwise and by operating it
37:23 - against the pixel values in the
37:25 - corresponding region of the other array
37:27 - the result is always going to be a
37:29 - binary value of 0 0 0 0 this translates
37:34 - to the number 0 which means all pixel
37:37 - intensities in that region will have a
37:40 - value of 0 that's what the results going
37:41 - to be they will be completely black
37:44 - thereby masking the entire region we
37:48 - know the operation occurs element wise
37:50 - so all the white pixels in this region
37:53 - of the array will be operated against
37:55 - the corresponding region of the other
37:57 - array well this region will remain
38:01 - unaffected
38:02 - why you might ask well we already
38:05 - concluded that since the polygonal
38:06 - contour is completely White's than the
38:09 - binary representation of each pixel
38:11 - intensity in that region would be all
38:14 - once if you take the bitwise and of the
38:17 - ones with any other binary value it's
38:20 - not going to have an effect we could try
38:23 - this out as we take the bitwise and of
38:26 - these two values to one so we put a 1
38:29 - here same case here here and here and we
38:33 - keep doing this to obtain the following
38:35 - results which notice is the same as one
38:38 - of our values meaning that taking its
38:41 - bitwise end with the ones didn't have an
38:44 - effect and so in our image taking the
38:47 - bitwise end of these two regions would
38:50 - also have zero effect which means we've
38:53 - successfully masked our canny image to
38:56 - ultimately only show the region of
38:59 - interest the region traced by the
39:01 - polygonal contour
39:05 - we can implement this by setting mast
39:07 - image is equal to C v2 dot bitwise and
39:13 - and we'll compute the bitwise and of
39:16 - both the canny
39:18 - and mask erase this Universal function
39:22 - implements the Python operator end
39:32 - finally we'll return masked image and
39:37 - we'll just set cropped image is equal to
39:43 - the return value of a region of interest
39:47 - we'll pass in the Kenny image as we did
39:49 - in the previous video and we'll show the
39:51 - corrupt image instead back to our
39:54 - terminal
39:55 - Python Lane's py and everything worked
40:01 - out accordingly we isolated the region
40:04 - of interest and masked everything else
40:06 - the final step of Lane detection will be
40:09 - to use the Hough transform technique to
40:11 - detect straight lines in our region of
40:13 - interest and thus identify the lane
40:16 - lines
40:16 - so far we've identified the edges in our
40:19 - image and isolated the region of
40:21 - interest now we'll make use of a
40:23 - technique that will detect straight
40:24 - lines in the image and thus identify the
40:27 - lane lines this technique is known as
40:29 - Hough transform we'll start by drawing a
40:31 - 2d coordinate space of x and y and
40:33 - inside of it a straight line we know
40:36 - that a straight line is represented by
40:38 - the equation y is equal to MX plus B
40:41 - nothing new so far just simple math our
40:45 - straight line has two parameters M and B
40:50 - we're currently plotting it as a
40:52 - function of x and y but we can also
40:55 - represent this line in parametric space
40:57 - which we will call Hough space as B
41:01 - versus M we know the y intercept of this
41:03 - line is 2 and the slope of the line is
41:06 - simply rise over run the change in Y
41:09 - over the change in X which evaluates to
41:12 - 3 given the y-intercept and slope this
41:15 - entire line can be plotted as a single
41:18 - point in Hough space now imagine that
41:21 - instead of a line we had a single dots
41:23 - located at the coordinates 12 and 2
41:26 - there are many possible lines that can
41:30 - pass through this dot each line with
41:33 - different values for M and B you could
41:36 - have a line that crosses that with M and
41:37 - B values of 2 and 8 3 & 6
41:42 - 4 & 4 5 & 2 6 & 0 so on and so forth
41:51 - notice that a single point in X&Y space
41:54 - is represented by a line in Hough space
41:57 - in other words by plotting the family of
42:00 - lines that goes through our points each
42:03 - line with its own distinct M and B value
42:06 - pair this produces an entire line of M
42:09 - and B value pairs in Hough space
42:13 - what if we also had a point at eight and
42:15 - one once again there are many lines that
42:18 - can cross this point each line with
42:20 - different values for M and B all of
42:23 - these different values for M and B
42:25 - represented by a line in parametric
42:27 - space the point being
42:30 - whenever you see a series of points and
42:33 - we're told that these points are
42:35 - connected by some line ask yourself this
42:38 - question what is that line as previously
42:42 - mentioned there are many possible lines
42:45 - that can cross each point individually
42:48 - each line with different slope and
42:50 - y-intercept values however there is one
42:53 - line that is consistent with both points
42:56 - we can determine that by looking at the
42:59 - point of intersection in Hough space
43:01 - because that point of intersection
43:04 - represents the M and B values of a line
43:07 - consistent with crossing both of our
43:10 - points which in this case has slope and
43:13 - y-intercept of 4
43:16 - suppose there is one more point than our
43:19 - image space at the point 16 and 3 this
43:23 - point is also represented by a line in
43:25 - parametric space each point in that line
43:28 - the notes different values for M and B
43:30 - which once again correspond to different
43:34 - lines that can pass through this points
43:38 - but notice that there is another
43:41 - intersection at the same point which
43:43 - means that the line with the following
43:45 - slope and y-intercept four and four
43:47 - crosses all three of our dots why is
43:51 - this relevant
43:52 - well this idea of identifying possible
43:56 - lines from a series of points is how
43:59 - we're going to find lines in our
44:01 - gradient image recall that the gradient
44:04 - image is just a series of white points
44:07 - which represent edges in our image space
44:10 - you and I can look at the various series
44:12 - of points in our image and automatically
44:15 - assume these points belong to a line
44:17 - this series of points belongs to a line
44:20 - so on and so forth but what are the
44:23 - lines what are their parameters how do
44:25 - we identify them well take these four
44:29 - points for example in our image space
44:31 - which correspond to the following Hough
44:34 - space what we're gonna do is first split
44:37 - our Hough space into a grid each bin
44:40 - inside of our grid corresponding to the
44:43 - slope and y-intercept value of a
44:45 - candidate line for example what if I
44:48 - told you these points belong to a line
44:51 - what is that line well I can see that
44:53 - there's points of intersection here
44:55 - there's some here and some here as well
44:58 - well all of these points of intersection
45:00 - are inside of a single bin for every
45:04 - point of intersection we're going to
45:07 - cast of votes inside of the bin that it
45:10 - belongs to the bin with the maximum
45:12 - number of votes that's gonna be your
45:15 - line whatever M and B value that this
45:18 - bin belongs to that's the line that
45:21 - we're going to draw since it was voted
45:23 - as the line of best fit in describing
45:26 - our data now that we know the theory of
45:29 - how we're going to identify lines in our
45:32 - gradient image you would think to
45:34 - yourself alright enough talking time the
45:37 - code well not so fast
45:39 - there's just one tiny problem we still
45:43 - haven't taken into account two vertical
45:45 - lines obviously if you try to compute
45:48 - the slope of a vertical line the change
45:50 - in X is zero
45:52 - ultimately will always evaluate to a
45:54 - slope of infinity which is not something
45:57 - that we can represent in Hough space
45:59 - infinity is not really something we can
46:01 - work with anyway we need a more robust
46:04 - representation of lines so that we don't
46:07 - encounter any numeric problems because
46:10 - clearly this form y is equal to MX plus
46:13 - B cannot represent vertical lines that
46:17 - being said instead of expressing our
46:19 - line with Cartesian coordinate system
46:20 - parameters m and B well instead express
46:23 - it in the polar coordinate system Rho
46:26 - and theta such that our line equation
46:29 - can be written as Rho is equal to X cos
46:32 - theta plus y sine theta if you're really
46:35 - interested in how this equation is
46:37 - derived feel free to ask me in the qat
46:39 - but the main idea is that this is still
46:43 - the equation of a line but in polar
46:45 - coordinates if I am to draw some line in
46:48 - Cartesian space the variable Rho is the
46:52 - perpendicular distance from the origin
46:55 - to that line and theta indicates the
46:59 - angle of inclination of the normal line
47:01 - from the x-axis which is measured in
47:04 - radians clockwise with respect to the
47:08 - positive x-axis let's look at some
47:10 - examples suppose I had a point with X
47:13 - position 5 and Y is equal to 2 as you
47:16 - know this is a point and many lines can
47:20 - pass through this point including a
47:22 - vertical line we used to define lines
47:25 - passing through our points by their
47:27 - slope and y-intercept M and B but now
47:30 - they will be the fine based on a row in
47:32 - theta if we want to measure the
47:35 - perpendicular distance from the origin
47:37 - to the top of the line the angle of
47:40 - inclination of the normal line from the
47:42 - axis is simply 0 which works out to a
47:44 - distance of 5 another possible line that
47:48 - could pass through our point is a
47:49 - horizontal line the perpendicular
47:52 - distance from the origin to our line
47:53 - would correspond to an angle of 90
47:55 - degrees which in radians is PI over 2
47:58 - which ultimately works out to a distance
48:01 - of 2 this line therefore is
48:05 - characterized by an angle theta of pi
48:07 - over two and a distance Rho of two just
48:12 - to strengthen our knowledge another
48:13 - possible line is the following whose
48:16 - perpendicular distance from origin to
48:18 - our line corresponds to an angle of 45
48:21 - degrees from the positive axis that is
48:24 - PI over 4 radians which works out to a
48:27 - distance a row of about 4.9
48:31 - the point of all this being is that
48:34 - previously a point in image space
48:36 - representing a line in Hough space
48:38 - whereas now with polar coordinates for a
48:40 - given points by plotting the family of
48:43 - lines that go through it each line with
48:45 - a distinct value for theta and Rho we
48:48 - get a sinusoidal curve this curve
48:50 - represents all of the different values
48:52 - for Rho and theta of lines that pass
48:55 - through our points this might look a bit
48:57 - intimidating but the concept is the
48:59 - exact same because imagine instead of
49:02 - one point we had ten points which in
49:04 - turn results in 10 sinusoidal curves as
49:07 - previously noted if the curves of
49:10 - different points intersect in Hough
49:12 - space then these points belong to the
49:14 - same line characterized by some Rho and
49:17 - theta value so this like before a line
49:21 - can be detected by finding the number of
49:23 - intersections between curves the more
49:26 - curves intercepting means that the line
49:29 - are represented by that intersection
49:31 - crosses more points in our case all 10
49:36 - of our curves intersect at a single
49:37 - points which means that there is a
49:41 - single line with some Muro and theta
49:43 - value that crosses all ten of our dots
49:49 - we can look at a more specific example
49:51 - with three dots in our Cartesian which
49:54 - represent the following sinusoidal
49:55 - curves all three lines intersect at the
49:59 - same points characterized by a theta
50:02 - value of 0.92 radians
50:06 - and perpendicular distance of about nine
50:09 - point six six so that's the idea finding
50:13 - which line best fits our data in our
50:17 - case it's the one with the following
50:19 - parameters we can also apply the concept
50:22 - of voting that we discussed earlier such
50:25 - that our Hough space is still in the
50:27 - form of a grid and obviously this bin
50:30 - would have the maximum number of votes
50:32 - and just like before the bin with the
50:35 - maximum number of votes that's going to
50:38 - be your line whatever theta in our value
50:41 - that this bin belongs to that's the line
50:43 - that we draw since it was voted as the
50:46 - line of best fit in the scribing our
50:48 - data later on when we start implementing
50:51 - this we'll talk about the concept of
50:53 - thresholds but for now that is all for
50:55 - Hough transform we're just trying to
50:57 - find the lines that best describe our
50:59 - points and that's what we're going to
51:02 - use to find the lines that best define
51:05 - the edge points in our gradient image
51:07 - let's start implementing that in the
51:10 - next video
51:15 - previously we looked at the theory
51:17 - behind the technique possible lines from
51:19 - a series of points by looking at the bin
51:21 - with the maximum number of votes that is
51:24 - the maximum number of intersections
51:26 - inside the bin we discussed that the bin
51:28 - with the maximum number of votes is the
51:30 - line we draw through a series of points
51:32 - whatever theta and R value that this bin
51:35 - belongs to that's the line we draw since
51:37 - it was voted as the line of best fit and
51:39 - describing our data will start
51:42 - implementing this by detecting lines in
51:44 - the cropped gradient image by setting
51:47 - lines is equal to C v2 dot Hough lines P
51:53 - the first argument is the image where
51:56 - you want to detect lines which would
51:59 - simply be our cropped image the second
52:04 - and third argument specified the
52:05 - resolution of the Hough accumulator
52:07 - array the Hough accumulator array
52:09 - previously I described as a grid for
52:11 - simplicity but it's actually a
52:13 - two-dimensional array of rows and
52:15 - columns which contain the bins that were
52:17 - going to use to collect votes
52:22 - with each beam represents
52:24 - a distinct value of Rho and theta the
52:27 - second and third arguments are really
52:29 - important as they specify the size of
52:32 - the bins Rho is the distance resolution
52:34 - of the accumulator in pixels and theta
52:36 - is the angle resolution of the
52:38 - accumulator in radians the larger the
52:40 - bins the less precision in which lines
52:43 - are going to be detected for example
52:45 - imagine every bin in our array was so
52:47 - large this is way to course in the sense
52:50 - that too many intersections are going to
52:52 - occur inside of a single bin we need our
52:55 - bins to be sufficiently small the
52:58 - smaller the row and degree intervals we
53:00 - specify for each bin
53:02 - the smaller the bins and the more
53:04 - precision in which we can detect our
53:06 - lines yet you don't want to make your
53:08 - bins too small since that can also
53:10 - result in inaccuracies and takes a
53:13 - longer time to run so what we'll do is
53:15 - we'll specify a precision of two pixels
53:18 - accompanied by a 1 degree precision
53:21 - that's needs to be in radians 180
53:24 - degrees is equal to pi radians so 1
53:26 - degree will simply be PI over 80 that is
53:29 - numpy pi divided by 180 one Radian to
53:35 - demonstrate the effect of this early on
53:37 - here is a sneak peak of the end results
53:39 - when we finally detect our lines in this
53:42 - picture the bin resolution was a row of
53:44 - 20 pixels in 5 degrees whereas here it's
53:47 - 2 pixels with a single degree precision
53:50 - clearly this one is much more precise in
53:52 - its output so that's it for a resolution
53:55 - the fourth argument is very simple it's
53:57 - the threshold to find and display the
54:00 - lines from a series of dots we need to
54:02 - find the bins with the highest number of
54:03 - votes right once you find that bin you
54:06 - take its data in row valley and plot the
54:07 - line however how do we know which bins
54:10 - to choose what's the optimal number of
54:12 - votes where we can say okay draw the
54:14 - line that corresponds to this bin well
54:17 - that's where the threshold comes in
54:19 - threshold is the minimum number of
54:21 - intersections needed to detect a line as
54:24 - previously mentioned in a series of
54:26 - points the points of intersection and
54:28 - Hough space represent the theta and row
54:30 - values of lines that are common between
54:32 - a series of points for every point of
54:34 - intersection of vote
54:36 - inside of the bin that it belongs to
54:37 - which represents a line with some value
54:40 - for Rho and theta
54:45 - there's 500 sections here so five votes
54:47 - and we assign a threshold of three the
54:50 - number of votes in this case exceeds the
54:53 - threshold and that is therefore accepted
54:55 - as a line that describes our series of
54:57 - points if we assign a threshold of some
55:00 - large number let's say twelve in this
55:03 - case we don't have sufficient
55:04 - intersections in our bin to say that the
55:06 - line belonging to this bin describes our
55:08 - data and is therefore rejected in the
55:12 - case of our gradient image we'll have a
55:15 - threshold of 100 which I found to be an
55:18 - optimal value such that the minimum
55:20 - number of intersections in have space
55:21 - for a bin needs to be 100 for it to be
55:25 - accepted as a relevant line in
55:26 - describing our data the fifth argument
55:29 - is just a placeholder array which we
55:32 - need to pass in so just declare an empty
55:34 - array not much to it
55:38 - the sixth argument is the length of a
55:40 - line in pixels that we will accept into
55:43 - the output which we'll declare as a
55:45 - keyword argument min line length is
55:50 - equal to 40 so basically any detected
55:55 - lines traced by less than 40 pixels are
55:58 - rejected and lastly there is the max
56:02 - line gap keyword argument which we're
56:05 - going to set equal to 5 this should be
56:09 - capitalized this indicates the maximum
56:12 - distance in pixels between segmented
56:14 - lines which we will allow to be
56:16 - connected into a single line instead of
56:19 - them being broken up that's all guys we
56:22 - just set up an algorithm that can detect
56:24 - lines in our cropped a gradient image
56:27 - now comes the fun part which is to
56:29 - actually display these lines into our
56:31 - real image what we'll do is we'll define
56:34 - a function def display lines which takes
56:42 - in an image onto which will display the
56:45 - lines as well as the lines themselves
56:47 - and before giving this any logic we're
56:53 - going to go right back here and set the
56:56 - line image
56:58 - equal to the return value of our
57:00 - function which we're going to specify
57:02 - momentarily but we'll just set it equal
57:04 - to the return value for now display
57:06 - lines pass in our lane image as well as
57:13 - the detected lines and back to our
57:16 - function similar to what we have in
57:17 - region of interest we'll declare an
57:20 - array of zeros line image is equal to NP
57:26 - dot zeros like with the same shape as
57:31 - the lane images corresponding array so
57:34 - it will have the same dimensions as our
57:36 - image although its pixels will be
57:37 - completely black as all then we'll have
57:39 - zero intensity and now all of the lines
57:42 - that we detected in our gradient image
57:44 - will display them on - there's a black
57:46 - image this is a three dimensional array
57:49 - to check if it even detected any lines
57:52 - we have to check if the array is not
57:56 - empty that is if lines is not none if
58:03 - it's not empty we'll loop through it
58:06 - four line in lines if you print each
58:11 - line that we iterate through print line
58:15 - back to our terminal run Python lanes
58:18 - that py if you print each line notice
58:22 - each line is a two-dimensional array
58:24 - with one row and four columns what we're
58:28 - going to do is a reshape every line into
58:32 - a one dimensional array such that line
58:35 - is going to equal line reshape and we're
58:39 - going to reshape it into a one
58:41 - dimensional array with four elements and
58:43 - you know what instead of setting line is
58:46 - equal to line dot reshape for we can
58:48 - simply unpack the array elements into
58:51 - four different variables x1 y1 x2 y2
58:58 - and now what we'll do is take each line
59:02 - that we're iterating through and draw it
59:04 - onto our blank image thanks to open CV
59:08 - we can write CV to line this function
59:13 - draws a line segment connecting two
59:16 - points well draw our lines on the line
59:19 - image the black image we just created
59:23 - the second and third arguments specify
59:27 - in which coordinates of the image space
59:29 - that we want to draw the lines so the
59:31 - second argument will be the first point
59:34 - of the line segment which is simply x1
59:38 - y1 and the third argument is the second
59:43 - point of the line segment x2 y2 all
59:47 - right so we've specified the coordinates
59:49 - in which we want our lines to be drawn
59:52 - with respect to the image space the next
59:56 - argument is what color we want the lines
59:59 - to be so we'll specify a BG our color of
60:04 - 255 0 and 0 this should result in a blue
60:10 - color since the red and green channels
60:12 - will have zero intensity and finally the
60:16 - line thickness which is going to have a
60:19 - value of 10 obviously the higher the
60:21 - value the thicker the lines and that is
60:24 - all all of the lines we detected in the
60:28 - gradient image and our cropped image we
60:31 - just drew them onto a black image which
60:35 - has the same dimensions as our road
60:37 - image now let's just go ahead and return
60:40 - the line image return line image and
60:46 - over here we're going to show the line
60:49 - image instead of cropped image and back
60:53 - to our terminal
60:54 - well rerun our code Python lanes dot py
60:58 - and as expected
61:02 - it shows the lines that we detected
61:05 - using Hough transform and it displayed
61:07 - them on a black image the final step is
61:12 - blend this image to our original color
61:15 - image that way the lines show up on the
61:19 - lanes instead of some black screen so
61:21 - what we'll do is we'll go back to our
61:24 - code and we'll set combo image I'm sure
61:30 - I could have come up with a better name
61:31 - than that but combo image is equal to CB
61:33 - - dot add weighted and so what we're
61:37 - going to do with add weighted is take
61:40 - the sum of our color image with our line
61:44 - image which should now make sense to you
61:47 - as to why the background of line image
61:49 - is completely black since that would
61:52 - signify pixel intensities of 0 and by
61:55 - adding 0 with whatever pixel intensities
61:58 - are inside of this image inside of Lane
62:01 - image the pixel intensities for that
62:03 - image would just stay the same it
62:04 - wouldn't change because 0 plus anything
62:07 - doesn't really make a difference it's
62:08 - only when we add when we blended the
62:11 - pixel intensities of our lines to the
62:14 - original that we'll see a difference
62:16 - since they actually have a nonzero pixel
62:18 - intensity value anyway first argument is
62:22 - going to be the lane image and we're
62:26 - taking the weighted sum between the
62:30 - arrays of these two images will give our
62:33 - Lane image a weight of 0.8 basically
62:38 - that's going to multiply all elements in
62:40 - this array by 0.8 the creasing their
62:45 - pixel intensities which makes it a bit
62:47 - darker it will be more apparent while
62:50 - we're doing this momentarily the third
62:52 - argument is the second and put our rate
62:54 - of the same size and we know it's the
62:56 - same size because we gave it the same
62:59 - shape as our Lane image array but it's
63:01 - all zeros in stud but anyway let's put
63:04 - our aligned image array and we'll give
63:07 - that a weight of 1 multiplying all
63:10 - elements in this array by 1 and now when
63:14 - we add these two arrays up this one will
63:17 - have 20% 2 more weights which means that
63:21 - the lines will be more clearly defined
63:23 - when we blend the two in
63:25 - this image is going to be a bit darker
63:28 - thereby better defining the lines that
63:30 - we're blending it into finally there's
63:32 - the gamma argument where we can choose
63:34 - some value that we'll add to our sum
63:37 - we'll just put a scalar value of one it
63:39 - won't really make a substantial
63:41 - difference and that is all we detected
63:43 - lines in the gradients placed these
63:47 - lines on a black image and then we
63:50 - blended that image with our original
63:53 - color image so if we replace this with
63:56 - combo image run the code
64:00 - Python lanes that py indeed blended both
64:05 - of our images such that the lines are
64:07 - displayed right on top of our lanes that
64:10 - is all for identifying lane lines you
64:13 - learned how to identify lines inside of
64:16 - a gradient image but the Hough transform
64:19 - technique and then we took these lines
64:21 - place them on a random black image which
64:25 - has the exact same dimensions as our
64:27 - original road image thereby by blending
64:30 - the two we were able to ultimately place
64:33 - our detected lines back on to our
64:35 - original image in the next video we'll
64:38 - further optimize how these lines are
64:40 - displayed in the last lesson we detected
64:43 - lines from a series of points in the
64:45 - gradient image using the Hough transform
64:47 - detection algorithm we then took these
64:50 - lines and place them on a blank image
64:51 - which we then merged with our color
64:54 - image ultimately displaying the lines
64:57 - onto our lanes what we'll do now is
64:59 - further optimize how these lines are
65:02 - displayed it's important to first
65:04 - recognize that the lines currently
65:06 - displayed correspond to bins which
65:08 - succeeded the voting threshold they were
65:10 - voted as the lines which best described
65:13 - our data what we'll do now is instead of
65:15 - having multiple lines we can average out
65:17 - their slope and y-intercept into a
65:18 - single line that traces out both of our
65:21 - lanes before getting into it it seems
65:24 - that there is some inconsistency in the
65:26 - code this should be image so as to
65:30 - properly reference the argument and not
65:32 - Lane image
65:34 - the same thing here make sure to
65:36 - reference the argument image not the
65:39 - global variable Kenny it shouldn't have
65:41 - made a difference since they both
65:43 - correspond to the same value the same
65:46 - case for this one but it's always good
65:48 - to be consistent so as to avoid bugs
65:50 - also not a good habit to reuse a
65:54 - variable names so we'll rename this to
65:56 - Kenny image and change it over here
65:59 - accordingly all right we'll start this
66:03 - lesson off by going over here and
66:06 - setting averaged lines is equal to the
66:12 - return value of some function that will
66:14 - declare later on average slope intercept
66:18 - that will be our function name and we'll
66:21 - pass into it our colored alene image as
66:24 - well as the lines that we detected and
66:29 - now we'll simply define the function
66:30 - right on top Def average slope intercept
66:35 - with argument image and lines and what
66:41 - we'll do first is we'll declare two
66:43 - empty lists left fit is equal to an
66:46 - empty list right fit is also equal to an
66:50 - empty lists left fit will contain the
66:52 - coordinates of the averaged lines on the
66:54 - left and intuitively right fits will
66:58 - contain coordinates of the line which
67:00 - will display on the right what we can do
67:02 - now is loop through every line as we did
67:04 - previously for line in lines and reshape
67:10 - each line into a one dimensional array
67:11 - with four elements line dot reshape four
67:15 - and now we'll unpack the elements of the
67:19 - array into four variables where x1 y1 x2
67:23 - y2 will equal the four values in the
67:27 - array respectively nothing new so far
67:29 - these are the points of a line when
67:31 - you're given the points of a line is
67:33 - very easy to compute the slope by
67:34 - calculating the change in Y over the
67:36 - change in X subbing that into our
67:38 - equation to then determine the
67:40 - y-intercept well to determine these
67:42 - parameters in code what we can do is set
67:46 - parameters
67:47 - is equal to numpy Polly fit what Polly
67:52 - fit will do for us is it will fit a
67:54 - first degree polynomial which would
67:56 - simply be a linear function of y is
67:58 - equal to MX plus B it's going to fit
68:01 - this polynomial to our X&Y points and
68:04 - return a vector of coefficients which
68:08 - describe the slope and y-intercept the
68:11 - first argument is where you will place
68:13 - the x coordinates of your two points x1
68:16 - x2 the second argument is where you will
68:19 - place the Y coordinates of your two
68:21 - points y1 and y2 and we'll fit a
68:26 - polynomial of degree 1 to our X&Y points
68:30 - that way we get the parameters of a
68:33 - linear function if you go ahead and
68:36 - print parameters into our terminal
68:40 - python Lanes dot py for each line that
68:44 - we iterate through it prints the slope
68:47 - and the y-intercept the slope is the
68:50 - first element in the array the
68:53 - y-intercept is the second element so
68:55 - what we can do is set slope is equal to
68:58 - parameters index 0 and we'll set
69:02 - intercept is equal to parameters at
69:07 - index 1 and now for each line that we
69:11 - iterate through we need to check if the
69:13 - slope of that line does it correspond to
69:16 - a line on the left side or a line on the
69:20 - right side to determine this it's
69:22 - important to note that our lines
69:23 - depending on which side they're at are
69:26 - all roughly more or less going in the
69:29 - same direction all the lines here are
69:32 - slanted a bit to the left and all the
69:34 - lines here are slanted a bit to their
69:37 - rights here's our image displayed with x
69:40 - and y axis notice that in the image the
69:42 - y axis goes downwards along the rows and
69:45 - if you remember from basic high school
69:47 - math a line has a positive slope when y
69:50 - always increases as x increases so these
69:54 - lines would have a positive slope as
69:56 - their change in Y over the change in X
69:59 - would result in a positive
70:01 - value although for these lines since as
70:04 - x increases Y decreases their slope
70:08 - value would therefore be negative since
70:10 - there are change in Y over the change in
70:12 - X would result in a negative value final
70:15 - conclusion being lines on the Left will
70:17 - have a negative slope lines on the right
70:20 - will have a positive slope so what we
70:22 - can do is back to our code we can write
70:24 - if slope is smaller than 0 if the line
70:31 - we're iterating through has a negative
70:33 - slope value will append it into the left
70:36 - list left
70:38 - fit dot append and we'll append each
70:42 - slope and y-intercept as a tuple slope
70:46 - intercept otherwise else will append it
70:52 - into the right list right fit dot append
70:55 - slope and the y intercept if we print
71:01 - the results outside of the for loop
71:03 - print left fit print right fit back to
71:10 - our terminal
71:12 - Python lines dot py now we have a list
71:15 - that contains all of the slopes and
71:18 - y-intercepts of the lines on the left
71:19 - side and another list that contains all
71:23 - the slopes and y-intercepts of the lines
71:25 - on the right side what we want to do now
71:28 - is average out all of these values into
71:32 - a single slope and y-intercept back to
71:35 - our code we'll do that for both sides
71:37 - but we'll start with the left side we'll
71:40 - set left fit average is equal to num pi
71:45 - dot average and we're going to average
71:47 - out all the values of our left fits and
71:50 - it's really important that you specify
71:53 - an axis is equal to 0 imagine this was
71:57 - an array of multiple rows and two
72:00 - columns what we want to do is operate
72:02 - vertically along the rows to get the
72:05 - average slope and the average
72:06 - y-intercept respectively do the same
72:09 - thing on the right side right fit
72:11 - average
72:13 - is equal to numpy average we'll do that
72:16 - for a right fit with an axis is equal to
72:20 - zero all right we'll go ahead and print
72:24 - left fit average print a right fit
72:29 - average and we'll go ahead and just
72:32 - label them for clarity left and writes
72:36 - back to our terminal
72:41 - we get back to erase this array
72:44 - represents the average slope and
72:46 - y-intercept of a single line through the
72:48 - left side and this array the average
72:51 - slope and y-intercept of a single line
72:53 - through their right side we're not out
72:55 - of the woods yet we have the slopes and
72:58 - y-intercepts of the lines that will
73:01 - eventually draw but we can't actually
73:03 - draw them unless we also specify their
73:05 - coordinates they actually specify where
73:07 - we want our lines to be placed the x1 y1
73:11 - x2 y2 for each line so what we'll do is
73:15 - we'll define a function deff make
73:19 - coordinates with argument image and
73:24 - align parameters with some return value
73:29 - this return value is going to denote x
73:32 - and y-coordinates of the line so back
73:35 - here we'll set left line equal to the
73:40 - return value of May coordinates we'll
73:44 - pass in the respective arguments the
73:46 - image as well as the slope and
73:49 - y-intercept of our left line left fit
73:52 - average same thing for the right line
73:55 - right line is equal to make coordinates
74:00 - image right fit average back to our
74:06 - function we're going to unpack this list
74:10 - of two elements whichever one that's
74:12 - being passed in the slope and intercept
74:14 - into two variables slope intercept is
74:18 - equal to line parameters we'll start
74:22 - with y 1 the initial vertical position
74:25 - of our lines this one is pretty obvious
74:28 - since we want our lines to start at the
74:31 - bottom of the image before we do this if
74:34 - you go ahead and print the shape of the
74:36 - image print image dot shape into your
74:39 - terminal will rerun this code it prints
74:42 - twice since clearly we're calling the
74:43 - function twice but regardless
74:46 - recall that the shape corresponds to
74:48 - your arrays dimensions in this case this
74:51 - represents the images Heights
74:53 - width and number of channels we're only
74:56 - interested in the heights which also
74:59 - corresponds to the bottom coordinate of
75:02 - our image as demonstrated by matplotlib
75:05 - a little counterintuitive that the
75:07 - highest volume is on the bottom of the
75:09 - y-axis but another way to interpret this
75:11 - is to have the y-axis going vertically
75:13 - downwards from 0 to 700 which makes
75:16 - sense since images are simply arrays of
75:18 - pixels and array indices are read from
75:21 - the top down we'll set Y 1 is equal to
75:24 - image dot shape at index 0 since that
75:29 - represented the heights and now y 2 is
75:32 - going to equal Y 1 times 3 over 5 we'll
75:40 - make this into an integer type and so
75:43 - essentially this will be 704 times 3
75:46 - over 5 which is going to evaluate to 422
75:52 - which means that both of our lines will
75:54 - start from the bottom at 704 and goes
75:59 - three-fifths of the way upwards up until
76:02 - the coordinate 420 all right now x1 can
76:07 - simply be determined algebraically we
76:09 - know that Y is equal to MX plus B so X
76:13 - is equal to Y minus B divided by M if
76:16 - you rearrange the variables so we can
76:18 - simply set x1 is equal to y1 minus the
76:25 - intercept divided by the slope
76:30 - we'll make this into an integer as well
76:33 - and the same thing for x2 except that we
76:37 - have to replace this with x2 and y2 now
76:41 - that we have all of our coordinates
76:43 - we'll return them as a numpy array numpy
76:46 - array x1 y1 x2 y2 so both of our lines
76:54 - are going to have the same vertical
76:56 - coordinates they're both going to start
76:59 - at the very bottom but they're going to
77:02 - start at the bottom and go upwards 3/5
77:06 - of the way up
77:07 - until the coordinate 424 but their
77:10 - horizontal coordinates are obviously
77:12 - dependent on their slope and y-intercept
77:14 - which we calculated right here we
77:17 - finally have our lines we can return
77:19 - them as an array return numpy array left
77:25 - line and right line and now comes the
77:30 - fun part which is instead of our line
77:33 - image being populated by the Hough
77:36 - detected lines we're going to pass in
77:39 - the averaged lines if we show the line
77:44 - image instead run the code this looks a
77:50 - lot smoother instead of many lines they
77:54 - were all averaged out into a single line
77:56 - on each side back to our code obviously
78:00 - were still blending the line image with
78:03 - the color image so let's show that
78:06 - instead combo image back to our terminal
78:11 - I'll rerun this and it displays our two
78:16 - lines on our two lanes we took the
78:19 - average of our lines and displayed one
78:22 - line on each side instead this looks a
78:25 - lot smoother than earlier one more thing
78:28 - before we end this lesson is that
78:30 - previously we were passing in a
78:32 - three-dimensional array the Hough lines
78:36 - into our display lines function but now
78:39 - we're passing in the average lines that
78:41 - we created and we know that when we
78:43 - iterate through over this lines array
78:45 - each line is already a one dimensional
78:48 - array so there's no need to reshape it
78:51 - into one it already is one dimensional
78:54 - so feel free to remove there reshape for
78:57 - it's just extra code it doesn't really
79:00 - make a difference whether you have it or
79:02 - nuts and better yet we can simply unpack
79:05 - each line into four variables over here
79:08 - and delete that and that is all let's
79:12 - rerun it to make sure we didn't make any
79:14 - mistakes and everything still works out
79:18 - accordingly in the next lesson well
79:21 - use the code that we currently have and
79:23 - take it up a notch by identifying Lane
79:25 - lines in a video welcome to your last
79:28 - lesson of this section and the last
79:30 - lesson we finally finished our line
79:32 - detection algorithm and identified Lane
79:34 - lines in our image what we'll do now is
79:37 - use that same algorithm to identify
79:39 - lines in a video this is the video and
79:42 - we'll use the algorithm we currently
79:44 - have to detect Lane lines in every
79:47 - single frame this video you can access
79:51 - from the following github link and now
79:52 - this github link you'll find any
79:54 - description below labeled as video link
79:57 - or you can feel free to just type out
79:59 - the link it's up to you now anyway once
80:02 - you're on this page click on test to
80:04 - that mp4 and download it alright and
80:10 - upon downloading it make sure it says
80:12 - test to dot mp4 so as to stay consistent
80:15 - with the videos and once you download it
80:19 - to wherever you have it download it drag
80:22 - it in to your project
80:23 - finding lanes if you are using the Adam
80:26 - text editor don't try and open the video
80:29 - with Adam otherwise it will freeze
80:31 - alternatively we could have placed this
80:33 - video in desktop or some other directory
80:35 - and just referenced its path but we'll
80:38 - go with this for now just to keep things
80:40 - quick regardless to capture this video
80:43 - in our workspace we need to create a
80:45 - video capture object by setting a
80:48 - variable name cap is equal to C v2 dot
80:54 - video capture and we'll capture the
80:59 - video test2 dot mp4 and while cap dot is
81:08 - opened this returns true if video
81:15 - capturing has been initialized we'll
81:17 - enter into a loop where we will first
81:20 - use the read function kappa read to
81:23 - decode every video frame and what this
81:27 - returns is two values which we can
81:29 - unpack the first value is just a boolean
81:32 - that we're not currently interests
81:33 - sit in so leave that is blank the second
81:36 - value is the image the frame that's
81:39 - currently being projected in our video
81:41 - and it's the current frame of our video
81:44 - where we'll be detecting lines so what
81:47 - we'll do is actually copy and paste the
81:49 - code the algorithm we already have for
81:51 - detecting lines we're not going to do it
81:53 - all over again and wherever it says Lane
81:56 - image we're gonna replace that with the
81:59 - current video frame over here here in
82:04 - here as well make sure to get all of
82:06 - them otherwise your code will not make
82:08 - any sense pretty easy all we did was
82:11 - apply the algorithm we already
82:13 - implemented but instead of a static
82:14 - image we're doing it on a video since
82:17 - we're not working with images anymore
82:18 - you can go ahead and comment out this
82:21 - code or delete it it's up to you I
82:23 - myself will comment it out and now with
82:26 - em show we're still showing the current
82:30 - image that's being processed as for
82:33 - weight key if we leave this at weight
82:35 - key 0 you're going to be waiting
82:38 - infinitely between each frame of the
82:40 - video so your video would just freeze up
82:42 - instead we want to wait one millisecond
82:46 - in between frames to then display the
82:49 - next one now before we add any logic to
82:52 - break out of this loop let's just run
82:54 - the code by going to our terminal and
82:56 - running Python main stop py and alright
83:03 - it identifies the lines in every single
83:05 - frame of our video that's pretty cool
83:08 - and this is nothing new it follows the
83:10 - exact same process as how we detected
83:13 - lines in the image we're still applying
83:16 - the canny algorithm to get the gradients
83:18 - detecting lines with Hough transform and
83:20 - then averaging them out except now it's
83:24 - being done in every single frame of the
83:26 - video repeatedly inside of a while loop
83:29 - that is all for this section now just to
83:32 - finish this lesson off if I rerun the
83:34 - code and try to close the video it
83:41 - doesn't work we need a way to actually
83:43 - break out of this for loop and not just
83:46 - to wait until the
83:47 - complete for it to dismiss so we'll go
83:50 - back here upon pressing a keyboard key
83:53 - we want the video to close so we'll put
83:56 - this inside of an if statements such
83:58 - that we're still invoking the wait key
84:00 - function we mentioned that it waits one
84:02 - millisecond in between frames but what
84:04 - it also does is it returns a 32-bit
84:07 - integer value which we can compare to
84:10 - the numeric encoding of the keyboard
84:12 - character that we're going to press the
84:15 - numeric encoding we can obtain from the
84:17 - built-in function Ord and the keyboard
84:20 - character that we're going to press will
84:21 - be q and we'll just set a comparison
84:25 - operation between the two ultimately
84:27 - when we press the keyboard button Q the
84:31 - comparison of these numbers will
84:33 - evaluate to true and once they are equal
84:36 - we'll break out of the loop and once we
84:39 - break out of the loop we'll close the
84:42 - video file by calling cap dot release
84:44 - and we'll also call CV to destroy all
84:49 - windows to destroy the window that we're
84:53 - currently on to close its rerun the code
84:57 - Python means dot py press Q and
85:01 - everything works fine if the keyboard
85:02 - action did not work out for you a common
85:05 - trick is to apply a bitwise and
85:06 - operation with the hexadecimal constants
85:11 - 0xff just know that this operation it
85:16 - masks the integer value we got from
85:19 - weight key to eight bits which
85:21 - ultimately just ensures cross-platform
85:24 - safety when making our comparison it's
85:27 - still the same concept as earlier since
85:29 - when we press Q this comparison still
85:31 - evaluates to true breaking us out of the
85:34 - loop rerunning the code everything
85:40 - should still work as expected that is
85:43 - all for this section we used candy to
85:45 - convert our color image into a gradient
85:47 - image and from the gradient image we
85:49 - detected the most relevant lines
85:51 - averaged out the lines and then
85:53 - displayed them on the image that's
85:55 - currently being processed in the near
85:57 - future we'll be using a more advanced
85:59 - to the tech lanes but for now this is
86:02 - pretty awesome great job and making it
86:05 - this far and that is all to access the
86:07 - complete self-driving car course where
86:09 - you'll learn to build a fully functional
86:11 - self-driving car with deep learning
86:13 - alongside computer vision techniques
86:15 - it's accessible within the link in the
86:17 - description below I'll see you in there