00:00 - hey guys welcome to the first video on
00:03 - opencv tutorial for beginners using
00:05 - python in this video I'm going to give
00:08 - you a brief introduction about opencv
00:11 - but first of all let's see what is
00:14 - computer vision because opencv is an
00:17 - open source computer vision Library
00:20 - so computer vision is the way of
00:23 - teaching intelligence to machines and
00:25 - making them see things just like humans
00:29 - so what happens when a human see an
00:32 - image he will be able to recognize the
00:36 - faces which are there inside the images
00:38 - so in its simplest form computer vision
00:41 - is what allows computers to see and
00:45 - process visual data just like humans
00:47 - computer vision involves analyzing
00:50 - images to produce useful information so
00:54 - to give you some examples a self-driving
00:56 - car it can detect the lanes using
01:00 - computer Visions or you might have
01:02 - wondered how Facebook detects images
01:05 - when you upload the images of you with
01:08 - your friends it becomes possible by
01:11 - Facebook's face and image recognition
01:13 - technology so now let's see what is
01:16 - opencv so opencv which stands for open
01:20 - source computer vision is a library of
01:23 - programming functions mainly aimed at
01:27 - real-time computer vision it is
01:29 - originally developed by Intel and then
01:33 - it was later supported by a developer
01:35 - called Willow garage and now it is
01:38 - supported and maintained by itcs now
01:41 - opencv is available on Mac windows and
01:44 - various Linux operating systems so we
01:47 - can say that opencv is a cross platform
01:50 - library now you can work on opencv using
01:53 - C C plus plus or Python and we will be
01:56 - using python to learn opencv
01:59 - now opencv is a open source and Free
02:02 - Library which is licensed under BSD
02:06 - license I had said that it is very easy
02:09 - to use and install that we will see when
02:12 - we will install opencv on various
02:16 - operating systems now because opencv
02:19 - primarily deals with computer vision
02:22 - that means dealing with mainly images or
02:26 - videos so I wanted to show you how a
02:29 - digital image is seen by a computer so
02:33 - digital images are typically stored in
02:36 - the form of Matrix now if you have heard
02:39 - about PPI or pixel per inch which refers
02:44 - display resolution that means how many
02:47 - individual pixels are displayed in one
02:51 - inch of digital image so when a computer
02:54 - sees a picture it sees it in the form of
02:59 - pixel Matrix now there are two type of
03:02 - digital images One are called grayscale
03:05 - images and other are called colored
03:08 - images so in grayscale images each pixel
03:12 - represents the intensity of only one
03:15 - shade that means how bright or dark the
03:19 - pixel is in other word it is said that
03:22 - it has only one channel so on the right
03:25 - hand side you can see a grayscale image
03:28 - and on the left hand side you can see a
03:32 - colored image so in colored images we
03:36 - have three channels that is r g b which
03:40 - stands for red green blue so grayscale
03:43 - images have one channel and colored
03:47 - images have three channels your standard
03:51 - digital camera have three channels that
03:54 - means red green blue channel so we will
03:56 - learn more about images and how we can
03:59 - process as images using opencv in the
04:02 - later videos now there is one more thing
04:05 - which I want to show you is numpy
04:08 - so we are going to learn opencv using
04:11 - python so when you will install opencv
04:14 - library for python on your operating
04:16 - system numpy will be automatically
04:19 - installed with this Library so first of
04:22 - all what is numpy so numpy is a highly
04:26 - optimized library for numerical
04:29 - operations now as I told you digital
04:31 - images are 2D arrays of pixels and numpy
04:35 - library is a general purpose array
04:37 - processing package Library so it
04:40 - provides a high performance
04:43 - multi-dimensional array object and tools
04:46 - for working with these arrays which
04:49 - makes the processing of images easier
04:53 - now all the opencv array structures are
04:55 - converted to and converted from numpy
04:59 - arrays and in addition you can use more
05:02 - convenient indexing system rather than
05:05 - using for Loops so when you want to
05:09 - learn opencv using python you need to
05:12 - have some knowledge about numpy also so
05:15 - if you have some knowledge of numpy
05:17 - Library it's good but don't worry I will
05:20 - teach you step by step so you will not
05:22 - miss anything so that was a brief
05:25 - introduction about computer vision and
05:27 - opencv in this video I'm going to show
05:30 - you how you can install opencv for
05:33 - python on your Windows operating system
05:36 - so obviously you need to install python
05:39 - on your Windows operating system in
05:42 - order to install opencv for python so
05:45 - first of all I'm going to show you how
05:46 - you can install python on your Windows
05:48 - operating system and then we will see
05:51 - how to install opencv using python now
05:55 - if you have already installed python on
05:57 - your Windows operating system you can
05:59 - skip about five minutes of this video
06:02 - and go directly to the point where I am
06:06 - going to show you how you can install
06:09 - opencv for python so let's get started
06:13 - so first of all open your favorite
06:14 - browser on your Windows 10 operating
06:16 - system and then search for Python and
06:18 - the first link which will appear here
06:20 - will be from python.org so we are going
06:22 - to click on that link and once this
06:24 - python.org website is open you just need
06:27 - to scroll down a little until you see
06:29 - this downloads section and you can see
06:32 - at the time of making this video python
06:35 - 3.7.0 is the latest version of python
06:38 - available so we are going to click on
06:40 - this link which says Python 3.7.0 and
06:42 - you will be redirected to this page
06:45 - which says Python 3.7.0 and now I'm
06:48 - going to scroll down until I see the
06:51 - files here and you will see there are
06:53 - various kinds of installer available
06:54 - here we are going to install the python
06:57 - using the executable installer so we are
06:59 - going to choose this option which says
07:01 - Windows x86 hyphen 64 executable
07:04 - installer and now I will wait for this
07:07 - executable to be downloaded and once
07:09 - this executable is downloaded you just
07:11 - need to click on this exe file and I am
07:14 - going to minimize the browser here so
07:16 - you can see Python's 3.7.0 setup window
07:19 - has been started and on the first window
07:21 - you will see two options here one is
07:24 - install now and other is customize
07:27 - installation so what we are going to
07:29 - choose is this option which says
07:31 - customize installation because when you
07:34 - choose this install now option python
07:36 - will be installed at this path which I
07:40 - don't want to use you can see it's a
07:43 - long path which I don't want to remember
07:45 - so I will use this option which says
07:48 - customize installation and I will also
07:50 - check this option which says add python
07:52 - 3.7 to path so now let's click on
07:55 - customize installation and next you will
07:57 - see this optional feature window and you
08:00 - can see there are some optional feature
08:02 - which this python installer will install
08:05 - for example documentation pip it will
08:08 - install which is a python package
08:10 - manager idle IDE python test suit and
08:14 - other feature it's going to install so
08:16 - I'm going to leave everything as default
08:17 - and then I'm going to click next and now
08:20 - this next window will open which says
08:22 - Advanced option here I'm going to check
08:24 - this option which says install for all
08:27 - users and I'm going to leave other check
08:30 - boxes as checked and then you will see
08:33 - this section here which says customize
08:34 - install location so I want to install
08:36 - python on my C directory so what I'm
08:39 - going to do is I'm going to open the
08:40 - windows Explorer and I'm going to go to
08:43 - the C directory here
08:45 - and once the C directory is open I'm
08:47 - going to right click here and I'm going
08:48 - to create a new directory and I'm going
08:50 - to name this directory as Python and
08:53 - then I'm going to press enter
08:55 - and this path I am going to give here in
08:58 - the customize install location so I am
09:01 - going to just give this path which says
09:03 - C colon slash Python and then backslash
09:07 - Python 3 7.37 here means that we are
09:11 - going to install 3.7 version of python
09:14 - so now python will be installed at this
09:16 - location on my computer and then I'm
09:18 - going to click on the install button
09:20 - here and then you will see the
09:21 - installation will start and it will be
09:23 - finished in a few seconds so just wait
09:25 - for the installation to complete and
09:27 - after some time I can see this message
09:28 - which says setup was successful so I'm
09:30 - going to click on this close button
09:32 - which is going to close this installer
09:34 - so now in order to check whether python
09:36 - is installed on our Windows operating
09:38 - system or not we are going to search for
09:40 - python here and you will see few options
09:43 - here one is this python 3.7 terminal
09:47 - other is Idle IDE so first of all we are
09:51 - going to click on this option which says
09:53 - python 3.7 64-bit which is is going to
09:56 - open this kind of terminal so this is a
09:59 - python terminal and here we can for
10:02 - example print something so I am going to
10:03 - just write print and in the parenthesis
10:05 - and in between the double quotes I can
10:08 - just write hello world and then press
10:11 - enter which is going to in return print
10:14 - hello world that means python 3.7
10:17 - terminal is working so I'm going to
10:19 - close this terminal now and once again
10:21 - I'm going to search for python here and
10:23 - this time I'm going to select this
10:25 - option which says idle okay so just
10:27 - select this option which says idle and
10:30 - in the parenthesis python 3.7 64 bit so
10:33 - this idle is an IDE which comes with
10:36 - python installation at the time of
10:38 - installation we have chosen this option
10:40 - to install idle that's why we can see
10:43 - this option here and also this is an
10:45 - interactive shell so you can once again
10:47 - write a print and inside the parenthesis
10:50 - you can just write for example once
10:52 - again hello world and then press Center
10:55 - and it is going to give you this kind of
10:57 - output here so now python interactive
11:00 - shell is working and idle IDE is also
11:02 - working so I'm going to close this idle
11:05 - IDE and now I want to check whether
11:07 - python is working using my command
11:10 - prompt or not so I'm going to right
11:11 - click on this Windows button and then
11:14 - I'm going to click on command prompt
11:17 - and here I'm going to first of all write
11:19 - Python and then press enter and you can
11:22 - see this python option is working now
11:25 - even on your command prompt right so
11:28 - here also you can just write print and
11:31 - inside the parenthesis you can just
11:33 - print hello
11:35 - world and then press enter and it prints
11:38 - hello world in return
11:43 - now once python is installed on your
11:46 - Windows 10 operating system we are going
11:48 - to install opencv using pip now pip is
11:53 - automatically installed on your Windows
11:55 - operating system with the python
11:58 - installation so you don't need to
12:00 - separately install pip on your Windows
12:03 - operating system it comes automatically
12:05 - with your python installation so to
12:09 - verify this first of all I'm going to
12:11 - check the python version so you can just
12:14 - give this command python hyphen hyphen
12:17 - version and then you can check the PIP
12:21 - version so you can just give this
12:23 - command pip hyphen hyphen version so
12:27 - just give this command and it's going to
12:29 - give you the version of pip which is
12:31 - installed on your Windows operating
12:33 - system so to install opencv using pip
12:36 - you just need to give this command pip
12:38 - install open CV hyphen python and I'm
12:44 - going to press enter so you can see
12:46 - opencv related packages are downloading
12:49 - now
12:50 - so now opencv python package is
12:52 - installed using pip on my Windows
12:54 - operating system now you will observe
12:57 - one more thing here and that is numpy
13:00 - package will be automatically installed
13:03 - with your opencv python package so now
13:06 - once opencv python package is installed
13:09 - we can verify it by just opening our
13:13 - python shell so I'm going to just give a
13:16 - python command to open the python shell
13:18 - and then here I am going to just write
13:21 - import
13:23 - CV2 okay so once you give this command
13:27 - it should not give you any error and if
13:30 - this import gives you error that means
13:32 - opencv is not correctly installed on
13:35 - your operating system now after
13:37 - importing you can just check the version
13:40 - of opencv which you have installed using
13:43 - CV2 dot underscore underscore version
13:48 - underscore underscore and then press
13:51 - enter and it's going to give you the
13:53 - version of opencv which is installed on
13:56 - your operating system and in our case
13:58 - this is 4.0.0 at the time of making this
14:01 - video now you can check the Same by
14:04 - writing your code inside a python file
14:09 - also so here I have opened my visual
14:12 - studio code editor and I have already
14:15 - created sample.py file and here also I
14:18 - am going to import the CV2 package first
14:22 - of all and then I'm going to print the
14:25 - version of CV2 using this print
14:28 - statement so I'm going to just write CV2
14:31 - dot underscore underscore version
14:34 - underscore underscore and then save this
14:38 - script and to open the terminal inside
14:40 - Visual Studio code you can just press
14:43 - Ctrl shift p and then type toggle
14:47 - integrated terminal so just type toggle
14:50 - integrated terminal and then click on
14:52 - this first option which says toggle
14:54 - integrated terminal this is going to
14:56 - open the terminal inside your Visual
14:59 - Studio code editor so here you can run
15:02 - your python script using the python
15:05 - command so Python and then name of the
15:07 - script which is sample.py in my case and
15:10 - then press enter and it's also going to
15:12 - give you the version of opencv which is
15:15 - installed on your operating system
15:17 - so this is how you can install opencv
15:20 - for python on your Windows operating
15:22 - system in the last video we have seen
15:24 - how we can install opencb for python now
15:28 - from this video we will actually start
15:30 - writing some code now moving forward I
15:32 - will be using pycharm IDE to demonstrate
15:35 - how opencv works but you are free to use
15:39 - any IDE or any other editor in order to
15:43 - use opencv
15:45 - now on a pycharm IDE you need to install
15:49 - opencv little bit differently
15:53 - so if you are using opencv you just need
15:56 - to create a project inside opencv and
16:00 - then you just need to click on file and
16:03 - then go to the settings
16:05 - now once the settings window opens you
16:08 - just need to go to the project and then
16:11 - it will say after colon your project
16:14 - name so my project name is opencv
16:17 - examples that's why it's written here
16:20 - opencv examples so project colon your
16:23 - project name so just click on the
16:26 - section and then click on Project
16:28 - interpreter and on the right hand side
16:30 - you will see all the packages which
16:32 - comes pre-installed when you create a
16:35 - project inside pycharm IDE
16:38 - now we want opencv python package so to
16:44 - install opencv python package on pycharm
16:47 - you just need to click on this plus
16:49 - button here and then you just need to
16:52 - type open CV hyphen python now the first
16:57 - result you can see here is opencv hyphen
17:00 - Python and the version which is
17:03 - available right now is
17:06 - 4.0.0.21 which is the latest version so
17:09 - to install this package for your pycharm
17:12 - IDE you just need to click on install
17:14 - package button and then after some time
17:17 - you will see this message which says
17:19 - package opencv hyphen python installed
17:21 - successfully in the green bar that means
17:24 - opencv package is installed successfully
17:27 - so you can close this window and now you
17:30 - will be able to see opencb hyphen python
17:33 - is added to your packages and also numpy
17:37 - is added to your packages which comes
17:39 - with your opencv python package so I'm
17:43 - going to just click OK and now you will
17:45 - be able to import this CV2 package in
17:49 - your python screen now in this video I'm
17:52 - going to show you how you can read
17:54 - images and write images using CV2
17:59 - package now let me show you where you
18:01 - can find some sample images for your
18:04 - project
18:05 - so you can open the browser and then go
18:10 - to this URL github.com forward slash
18:14 - opencv so just go to this URL and then
18:17 - under this opencv project in GitHub you
18:21 - will be able to see these repositories
18:24 - you just need to choose this repository
18:27 - which says opencv
18:29 - and then you can scroll down and all the
18:34 - images you will find inside the samples
18:37 - folder so I'm going to go inside the
18:39 - sample folder and then inside the sample
18:42 - folder you just need to go inside the
18:44 - data folder so here you will find many
18:48 - sample images and videos and other files
18:52 - which you can use in your project for
18:55 - the learning purpose so you can use
18:58 - these images in order to develop your
19:02 - example so what I generally do is I just
19:06 - go to this repository which is under the
19:09 - URL github.com forward slash opencv
19:12 - forward slash opencv and then I either
19:16 - download the zip file of this project or
19:21 - clone this GitHub repository on my
19:25 - operating system and once you clone or
19:29 - down load this repository it will look
19:32 - like this so it will be downloaded as
19:35 - this folder which is opencv hyphen
19:38 - master and once again you can go to the
19:42 - samples folder here and inside the
19:44 - samples folder you can go to the data
19:47 - folder and you will find all those
19:50 - images which I have shown you on the
19:52 - GitHub repository now to start with we
19:55 - will be using this image which is Lena
19:59 - dot jpg so I'm going to just copy this
20:03 - image for now and then I'm going to go
20:06 - to my pycharm IDE and then I'm going to
20:09 - just paste this image inside my project
20:13 - so this jpg image will be directly
20:16 - available inside my project folder
20:20 - now let's see how we can read images
20:23 - using the CV2 module so you just need to
20:28 - use CV2 and there is a method called I
20:32 - am read which enables you to read the
20:36 - images so the first argument which you
20:39 - need to give here is the image name so
20:41 - I'm going to give the image name which
20:44 - is Lana dot jpg and the second argument
20:49 - here is a flag so there are three flags
20:54 - you can give here you can either give 0
20:57 - or 1 or minus one flag here so this
21:04 - second argument is a flag which
21:06 - specifies the way images should be read
21:09 - so let me show you all the flags here so
21:12 - the first flag is CV2 dot I am read
21:16 - underscore color or you can give the
21:19 - integer value of it which is one and
21:22 - whenever you give this flag as the
21:24 - second argument of I am read function
21:26 - it's going to load the colored image if
21:30 - you give this flag which is CV2 dot I am
21:33 - read underscore grayscale or if you give
21:36 - this integer value which is 0 it's going
21:39 - to load your image in grayscale mode and
21:44 - the third flag is I am read underscore
21:46 - unchanged or the value minus 1 which is
21:50 - going to load your image as it is
21:53 - including the alpha channel so for now
21:56 - we are going to just give here 0 flag
22:00 - which means we want to load our image in
22:03 - grayscale so now let's run the code and
22:05 - let's see what happens until this point
22:09 - so you can see our code runs fine
22:11 - without giving any error now let me give
22:15 - any random name here as the file name
22:19 - and once again run this code and once
22:23 - again you will see that there is no
22:25 - exception which is thrown here so even
22:28 - if you give the wrong file path or file
22:33 - name here this function is not going to
22:36 - give you any error now in case of wrong
22:39 - path or wrong file name let's say I'm
22:43 - going to just assign this value to a new
22:47 - variable which is IMG and let's print
22:50 - the value of this IMG using the print
22:55 - method and then let me run the code once
22:58 - again and you can see whenever you will
23:00 - give the wrong file name here or wrong
23:03 - path here as a result of this method you
23:07 - will get none so so you can check the
23:10 - value of image and if it is equal to
23:14 - none then you know that you have done
23:17 - something wrong or you have given some
23:19 - wrong file name or wrong path here let's
23:23 - give the correct file name so I'm going
23:26 - to give the correct file name and then
23:28 - run the code once again and now this
23:32 - time you will see it's going to give you
23:34 - a matrix which means that it has read
23:39 - all the pixels from this image and then
23:42 - assigned it to our IMG variable and the
23:46 - result you can see in the form of this
23:49 - Matrix so until now we have just read
23:51 - the image now we want to display our
23:55 - image so in order to display our image
23:58 - what we can do is we can use a
24:02 - CV2 dot IM show method so just write I
24:08 - am show here which is going to show your
24:11 - image so the first argument here will be
24:14 - the name of your window in which your
24:18 - image will open so you can give any name
24:21 - here for example I am going to give
24:23 - image name here to my window and then
24:27 - the second argument is the image
24:30 - variable which you have read using the I
24:33 - am read method so I'm going to just pass
24:36 - IMG variable which is this variable here
24:40 - so now will it show the image let's
24:42 - check so I am going to run the code once
24:45 - again and you can see the image is shown
24:48 - for a millisecond and then it disappears
24:52 - so now we need to add something which
24:54 - will wait for the image to disappear so
24:58 - I'm going to add one more method here
25:01 - which is CB 2 dot weight key so this CV2
25:06 - dot weight key is the keyboard binding
25:08 - function and the argument which it takes
25:11 - is the number of milliseconds for which
25:13 - you want to show your image window so
25:18 - let's give 5000 value here which means
25:21 - we want to show the image for five
25:23 - seconds and at last what we are going to
25:26 - do is after we have done seeing our
25:29 - image we will destroy the window which
25:32 - we have created so you can just give
25:34 - this method CV2 destroy all windows so
25:39 - destroy all windows simply destroys all
25:42 - the windows which we have created there
25:45 - is one more method which is destroy
25:47 - window and this method you can use to
25:51 - destroy a particular window which we
25:54 - will see little bit later but for now we
25:58 - will just use this method which says
26:00 - destroy all windows so now let's run our
26:04 - code and let's see what happens so now
26:06 - this time you can see our image is
26:10 - loaded for 5 seconds and our image is
26:13 - loaded in grayscale mode now if you give
26:17 - here 0 as the argument of weight key
26:20 - method then let's see what happens so I
26:23 - am going to run my code and now you will
26:25 - observe that your window will not
26:28 - disappear after 5 second or any number
26:31 - of seconds it's going to wait for the
26:34 - closing of this window which we can
26:36 - close from this close button and you can
26:40 - see it's loaded in that grayscale mode
26:43 - I'm going to close this window and here
26:47 - as an argument of IM read image the
26:51 - second argument I want to give here
26:52 - right now is 1 which means the colored
26:56 - image and let's run the code and you can
26:59 - see this image is loaded in the colored
27:02 - mode now let's also check the minus one
27:07 - argument which is unchanged so it is
27:09 - going to just load the image as it is
27:13 - with Alpha channels so let me just close
27:16 - this image once again
27:18 - so now we have understood how we can
27:21 - read an image using IM read function
27:25 - so let's see how we can write an image
27:29 - to a file using a function called I am
27:33 - right
27:34 - so we are going to just use CV 2 once
27:39 - again and then there is a method called
27:41 - I am write which you can use to write an
27:46 - image in the form of a file so the first
27:50 - argument here will be the image name
27:52 - whatever you want to give here so here
27:55 - let us say we want to give the name to
27:58 - our image as Lena underscore copy dot
28:03 - PNG so the image will be saved as the
28:07 - file name Lena underscore copy dot PNG
28:10 - file and the second argument which it
28:12 - takes is the image you want to save so
28:15 - let's save the same image which we have
28:17 - read using the IM read function inside
28:21 - this IMG variable and pass it as the
28:25 - second variable here and let's run the
28:28 - code and let's see what happens so our
28:30 - image is loaded using this I am sure
28:34 - show function and now when I close this
28:37 - window here you will observe one more
28:41 - file will be created here so let me just
28:43 - close this window and now you can see as
28:46 - soon as I close this window this method
28:49 - is called and after this this I am right
28:52 - method will be called and when this
28:55 - method is called this image is created
28:58 - with the name Lena underscore copy dot
29:01 - PNG we can also open this image and you
29:04 - can see it has the same image which we
29:07 - have seen in the case of lemona dot jpg
29:11 - so let me close these two images so now
29:14 - we have understood how we can read the
29:16 - images and write the images using IM
29:19 - read function and I am write function so
29:23 - let's make our code little bit better
29:26 - and what we want to do here now is let's
29:30 - say if somebody presses an Escape key
29:33 - then only we want to destroy all the
29:36 - windows without saving it into a new
29:40 - file otherwise if somebody presses the S
29:43 - key then we are going to save this file
29:47 - with the new name let's say Lena copy
29:50 - dot PNG file so I'm going to just
29:53 - capture the output of my weight key so
29:56 - just create a new variable let's say k
29:59 - so now when we press any key this key
30:02 - will be captured in this variable now as
30:06 - you know every key has its own value so
30:10 - we are going to just use uh if condition
30:13 - and we are going to just check whether
30:16 - the value of K is equal to 27 which
30:20 - means that we have pressed the Escape
30:23 - key and if somebody have pressed the
30:26 - Escape key we are going to Simply
30:28 - destroy all the windows otherwise let's
30:32 - give the second condition Edition which
30:35 - is l f k is equal to ord and this is a
30:40 - built in function and it takes one
30:42 - argument which is the key name which we
30:46 - want to press so let us say somebody
30:48 - presses the S key and if somebody
30:51 - presses the S key we just want to save
30:54 - the image which we have read using the
30:57 - IM read function to a second image which
31:00 - we call Lana underscore copy dot PNG and
31:04 - then we will simply destroy all the
31:07 - windows which we have created using IM
31:11 - show method so let's run the code and
31:13 - let's see what happens so I am going to
31:15 - run the code so this image is loaded and
31:19 - as soon as I press escape button you can
31:23 - see this image disappears that means
31:26 - this condition is met and this method is
31:29 - called and all the windows will be
31:31 - destroyed without saving the image let
31:34 - let's delete this image and let's see
31:37 - what will happen when we press the save
31:40 - key so let me just delete this image and
31:43 - now let's run the code once again and
31:46 - this time I'm going to press the S key
31:49 - and once again you can see the windows
31:52 - are destroyed but this image is created
31:55 - once again using this function that
31:58 - means this time this condition is
32:01 - fulfilled and this image is created and
32:05 - after that all the windows are destroyed
32:08 - so this code is working fine for me but
32:11 - in the documentation it's also written
32:13 - that if you are using a 64-bit machine
32:17 - it's better to use this notation with
32:20 - your weight key method which is weight
32:24 - key and this mask here and then once
32:27 - again when we run our code it works as
32:31 - it is but in case if it doesn't work you
32:33 - can try try using this mask here so this
32:37 - is how you can read and write images
32:39 - using opencv in this video we will see
32:42 - how to read display and save videos
32:45 - using cameras
32:47 - so often we have to capture live stream
32:51 - from camera so first of all we will see
32:53 - how we can capture the live stream from
32:55 - the camera the same method you can use
32:58 - to display the video from a video file
33:01 - so let's get started and let's see how
33:04 - we can capture the live stream from your
33:07 - default camera so I'm going to just
33:09 - create a variable called CAP and then
33:12 - inside your CV2 package there is a class
33:15 - called video capture we are going to
33:18 - take this class and create an object of
33:21 - it and as an argument here you can
33:23 - provide either the input file name so
33:27 - for example if you want to just read the
33:30 - video from a particular file you can
33:33 - give the file name for example my file
33:37 - dot AVI or MP4 or you need to provide
33:41 - the device index of your camera from
33:44 - which you want to read so by default
33:47 - this index will be either 0 or in many
33:51 - devices its also minus one so first of
33:55 - all we are going to try with zero device
33:58 - index which in most cases works so if
34:02 - this device index 0 doesn't work try
34:04 - with
34:06 - -1 now if you have multiple cameras and
34:09 - if you want to use the other camera then
34:13 - you can also try one for the second
34:16 - camera or two for the third camera and
34:19 - so on so we are going to use the default
34:21 - camera which is ADD device index 0 so
34:25 - this is the argument we need to provide
34:27 - here and then we are going to create a
34:30 - while loop in order to capture the frame
34:33 - continuously so let's create a while
34:37 - loop here and this Loop we are going to
34:41 - run indefinitely so we are going to just
34:44 - say that while this Loop is true we want
34:49 - to capture the frames so we are going to
34:52 - just Define these variable r e t and
34:57 - frame and then using this cap instance
35:01 - we are going to call a method called
35:04 - read now this read method is going to
35:08 - return true if the frame is available
35:11 - and this Frame will be saved into this
35:15 - Frame variable so here the true or false
35:19 - will be saved if the frame is available
35:21 - this ret will be true otherwise it will
35:25 - be false and this Frame variable will
35:27 - actually capture or save the frame now
35:31 - in order to show this captured frame we
35:34 - can use I am sure so I am going to just
35:38 - use a CV 2 dot I am show which is going
35:43 - to show this Frame inside the window
35:46 - first of all all you can give the name
35:49 - to your window for example frame and
35:53 - then second argument will be the frame
35:56 - which you are reading which is this
35:58 - variable here now in the next step we
36:01 - have seen in the last video also we are
36:04 - going to use the CV2 dot weight key in
36:08 - order to wait for the user input and if
36:12 - this input will be Q we will quit the
36:16 - window and destroy all windows so we are
36:19 - going to just say CB2 dot weight key and
36:21 - the argument here will be 1 and I have
36:24 - told you you need to provide this mask
36:27 - for 64 bit machines so you can provide
36:33 - this mask and then we are going to
36:35 - adjust see if this key which is pressed
36:39 - is q or not so we are going to use the
36:43 - ORD method for this and we will just
36:46 - check if the Q key is pressed and if
36:49 - this q key is pressed we are going to
36:52 - break from the loop and we will come out
36:55 - of the loop and after we come out of the
36:58 - loop the first thing we need to do is to
37:01 - actually release the capture variable so
37:05 - this is important after reading your
37:07 - video you need to release the resources
37:10 - so you need to just call this method cap
37:13 - dot release and then we will just
37:16 - destroy all windows so let's run this
37:19 - script and let's see what is the output
37:20 - so I'm going to run the script and you
37:23 - can see in this window the input from my
37:27 - default webcam of my laptop right now
37:30 - I'm just showing some book in front of
37:33 - this camera that's why you will see this
37:37 - book and as soon as I press q key our
37:42 - window will be destroyed and we come out
37:44 - of this script now let's say you want to
37:46 - change the frames to gray so we want to
37:49 - convert our video input from the colored
37:54 - image to the grayscale image for that
37:56 - what you can do is you can define a
37:59 - variable called gray or anything else
38:01 - and then there is a method called CV2
38:06 - dot CVT color which is to convert color
38:10 - and the first argument which it takes is
38:13 - the source so in our case the source is
38:16 - the frame which we are capturing from
38:19 - the cap dot read method the second
38:23 - argument is actually the conversion what
38:27 - we want to do so we will just call CV2
38:32 - dot color underscore and by default the
38:36 - default colored image is captured as BGR
38:42 - image that means blue green red Channel
38:45 - images and we want to convert it to a
38:49 - grayscale image so we will just write
38:51 - BGR to gray this means we want to
38:56 - capture the BGR image to the grayscale
38:59 - image and now this is going to give us
39:02 - the gray scale image and this input we
39:05 - can just transfer to the IM show method
39:09 - as the second argument of this I am show
39:12 - method so let's run this script once
39:14 - again and let's see what is the output
39:17 - of the script and now you can see the
39:19 - video captured is in grayscale image and
39:24 - as soon as I press Q it's going to
39:26 - release all the captured resources and
39:30 - then destroy all windows now as I said
39:32 - if you want to display the image from a
39:36 - video file you just need to give the
39:39 - name of the video file for example name
39:41 - and then the extension which is let's
39:44 - say AVI or MP4 or any other format Now
39:48 - using this cap instance you can read few
39:51 - properties about the video which is
39:54 - captured and the first property is if
39:57 - the video is open or not so in case
40:01 - whenever you provide the file name and
40:03 - the file path is wrong then this is
40:06 - going to give you false so there is a
40:10 - method called is opened and this means
40:13 - if the file name of the video which you
40:16 - want to provide here is correct this is
40:18 - going to give us true otherwise this is
40:21 - opened is going to give us false in case
40:25 - the file path is wrong or the index
40:28 - which you give here for the device is
40:30 - wrong so let us give any random index
40:33 - here and then let's see what happens so
40:36 - I am going to run the script and you
40:38 - will see nothing will happen because
40:41 - this is opened is going to give you
40:45 - false let's print that also and let's
40:48 - verify with the print statement the same
40:51 - thing so I am going to just use this and
40:54 - then run the program once again and you
40:56 - can see it prints false that means you
41:00 - cannot capture the video using this
41:04 - index so my device is at index 0 by
41:07 - default so I need to give this index
41:09 - name otherwise for example I provide the
41:13 - wrong file name here also it's going to
41:15 - give us the false value there is a
41:19 - method called cap.open also so if this
41:22 - cap is open gives you false you can try
41:25 - opening your capture video using cap dot
41:30 - open also now there are other properties
41:32 - which you can read using this cap
41:35 - instance and the property you can read
41:37 - using a method called get so you can
41:40 - just write cap dot get and as an
41:44 - argument of this get method you can
41:46 - provide the prop ID so there are
41:49 - different prop IDs which you can read so
41:52 - let us say we want to read the property
41:55 - which is called frame width and frame
41:59 - height which is going to give you the
42:01 - height and width of your frame so for
42:05 - this you just need to write CV2 dot cap
42:09 - underscore prop underscore frame
42:11 - underscore width this is going to give
42:14 - you the width of your frame and if you
42:17 - want to get the height of your frame you
42:19 - can use cap underscore prop underscore
42:22 - frame underscore height and this whole
42:25 - list you can find on the official
42:27 - documentation of opencv so I will
42:30 - provide you this link where you can see
42:34 - different values of the prop ID so right
42:37 - now I have used this ID and this ID but
42:41 - there are several number of IDs
42:43 - available here which you can use to read
42:46 - the prop property of your frame so let's
42:50 - use print method to just print out what
42:54 - property we are reading and let's once
42:57 - again run this script and here you can
43:00 - see in the output you can see the value
43:03 - 640 and 480 which is the width and
43:06 - height of your frame by default now
43:10 - let's see how we can save the image
43:12 - which we have captured from our webcam
43:15 - or the default camera
43:17 - so as we already know that we read frame
43:21 - by frame when we capture the videos from
43:25 - your default camera so for creating the
43:28 - capture you have used video capture
43:31 - class and for saving the video we are
43:34 - going to create the video writer class
43:37 - so I'm going to first of all create a
43:40 - variable called out for output and then
43:42 - I'm going to call a class called video
43:46 - writer so let's call this class which is
43:50 - video writer and now this class takes
43:53 - few argument the first argument is the
43:56 - name of your output file so for example
43:59 - I can just give the name output dot Avi
44:04 - the extension of the file the second
44:07 - argument here is the four CC code now 4
44:10 - cc is a 4 byte code which is used to
44:14 - specify the video Codec and if you want
44:17 - to know more about 4 CC code you can
44:20 - visit this website which is
44:22 - 4cc.org forward slash Kodak dot PHP and
44:26 - here you can find several four CC codes
44:29 - so for now what we are going to do is we
44:32 - are going to just get the four CC code
44:35 - using a class called video writer
44:38 - underscore 4cc so I'm going to declare a
44:41 - variable 4 CC and then I'm going to use
44:43 - CV2 to call a class called video writer
44:48 - 4 CC so as an argument of this class you
44:51 - just need to provide the 4cc code so for
44:55 - example I can give this kind of code so
44:58 - you can provide this argument which is X
45:00 - tricks and then your four CC code which
45:03 - is Xvid in this case or otherwise what
45:07 - you can do here is you can also give
45:10 - this code in this format so for example
45:14 - X comma then second argument is V and
45:19 - then third argument is I and the fourth
45:23 - argument is D so you can either give
45:27 - this type of notation or you can just
45:30 - use asterisks and then in single quotes
45:33 - you can just write x with or any other
45:36 - code here and then this four CC code we
45:39 - are going to pass as the second argument
45:42 - the third argument is the number of
45:44 - frames per second so let's say we just
45:46 - want to use 20 frames per second and the
45:51 - fourth argument is the size so we
45:53 - already know that the size in which we
45:55 - are capturing is 640 by 480 so we are
46:00 - going to provide this in the form of
46:03 - Tuple so 640 comma 480 so this will be
46:08 - the size of the video which will be
46:11 - saved in this file now inside our loop
46:14 - as we have seen we are just reading the
46:17 - frame here here in the frame variable
46:19 - and this is the Boolean variable if the
46:22 - frame is available its true otherwise
46:24 - it's false right so first of all we are
46:27 - going to check if its value is true or
46:30 - false so we can just write f r e t is
46:35 - equal to true then only we are going to
46:38 - just save this file into the output file
46:42 - so I'm going to just put everything
46:44 - inside this if condition otherwise we
46:48 - are going to break out of this Loop so I
46:51 - am going I am going to just say else
46:53 - break now inside this if condition we
46:57 - can just write this Frame into a file
47:01 - using a method called out dot right so
47:05 - out is the instance of video writer so
47:08 - I'm going to just use out dot right and
47:13 - then we are going to just pass the frame
47:16 - which we have captured which is inside
47:19 - the frame variable and now at last we
47:23 - are going to release all the resources
47:25 - using the out instance which is the
47:29 - instance of video writer so I'm going to
47:31 - just write out dot release and then
47:35 - let's run the script and let's see what
47:38 - happens so one thing to note here is our
47:41 - video will be saved as it is that is in
47:45 - the BGR mode that is in the colored mode
47:49 - so let's run the code and let's see what
47:51 - happens so I'm going to just start my
47:54 - script once again and now I am going to
47:58 - just press Q so you can see here our
48:00 - video is shown in the grayscale and our
48:04 - video will be saved in the original from
48:06 - form format because we are saving every
48:09 - frame before the conversion so it will
48:11 - be saved in the original format so I am
48:14 - going to just close this ah of script
48:18 - and as soon as I close the script you
48:21 - can see the output.avi file and in order
48:24 - to verify this file I'm going to go to
48:26 - the project and here I'm going to start
48:29 - this file using let's say VLC media
48:33 - player and you can see it shows the
48:35 - output of the output dot avi file so
48:39 - this is how you can read videos display
48:41 - and save videos using the default camera
48:44 - or the video file in this video we will
48:48 - learn how to draw different geometric
48:50 - shapes using opencv so to start with I
48:54 - have this code and I have already
48:56 - explained what this code does so this I
48:59 - am read is used to read an image and
49:03 - then we are just showing this image into
49:06 - a window using this IM show method and
49:10 - then using the weight key we will wait
49:13 - for the closing event and the destroy
49:17 - all window will destroy all the windows
49:20 - which we have created so this we have
49:23 - already seen now let us say we want to
49:26 - draw some geometric shapes on this image
49:30 - so to start with let's learn how to draw
49:33 - a line on our image which we have read
49:37 - from this read function so what we are
49:41 - going to do is we will overwrite this
49:44 - image so we have already ah created this
49:48 - image variable so what we are going to
49:51 - do is we will draw a line on the same
49:54 - image so I am going to just write IMG is
49:58 - equal to
49:59 - CV2 dot lines and you can see in the
50:03 - suggestion this line method takes few
50:06 - arguments so the first argument is the
50:09 - image itself the second argument is the
50:12 - starting coordinates of point one the
50:15 - third argument is the ending code
50:17 - coordinates of 0.2 and then the fourth
50:21 - argument is the color and fifth argument
50:24 - is the thickness
50:26 - so let's use this line method and then
50:29 - give these arguments one by one so we
50:33 - want to write to the image which we have
50:37 - read using this file so the first
50:40 - argument is the image variable and the
50:43 - second argument is the coordinates so
50:46 - the coordinates should be given in the
50:48 - form of Tuple so let us say we start
50:51 - with 0 comma 0 coordinate and the ending
50:55 - coordinates will be let us say
50:58 - 255 comma 255 okay the fourth argument
51:03 - will be the color and the color you need
51:06 - to give in the BGR format so if you want
51:10 - to give the blue color then you can just
51:13 - write 255 comma 0 comma 0 because first
51:18 - is the blue color second is the green
51:23 - color and third is the red Channel color
51:27 - so if you specify here 255 in the first
51:31 - channel that means the blue Channel then
51:34 - it's going to draw the blue line if you
51:37 - give here 255 and then you make other
51:41 - channels 0 then it's going to draw the
51:45 - green line and if this 255 comes at last
51:50 - and the other channels are 0 then it's
51:52 - going to draw the red line so let's say
51:55 - we want to draw the red line that's why
51:57 - I have given 255 here and the next
52:01 - argument is the thickness so the
52:04 - thickness you provide in the numbers so
52:08 - start starting from 1 1 is the lowest
52:11 - thickness you can increase the thickness
52:13 - two or three or let's say five or ten so
52:18 - it is going to increase the thickness
52:19 - based upon this number so let us say we
52:22 - want to give the thickness to our line
52:24 - five so this is going to draw a red line
52:28 - on our image so let's run the code and
52:31 - let's see what happens so you can see
52:34 - our image is loaded in the grayscale
52:37 - that's why you do not see any color on
52:40 - the line but our line is created here so
52:44 - let's load this image in the colored
52:47 - format by changing this argument to one
52:50 - and let's run the code once again and
52:53 - you will see the image is loaded in the
52:56 - colored format and the line color is red
53:00 - now if you want to change the thickness
53:02 - of this line you can just increase this
53:04 - number and if you want to change the
53:06 - color of this line you can change yet
53:09 - using these color channels so let's
53:12 - change the line color to Green let's say
53:16 - and I'm going to run the code and you
53:19 - can see the thickness of the line is
53:20 - increased and now the color of the line
53:23 - is green now if you want to draw the
53:26 - line with any other color you can just
53:29 - go to your favorite browser and search
53:32 - for RBG Color Picker but always remember
53:36 - our image will be loaded in the BGR
53:40 - format so in the reverse order so blue
53:43 - green and then the red channel so let's
53:47 - say we want this ah color here and its
53:52 - RBG channels are this so I am going to
53:55 - just copy all these channels and then I
53:58 - am going to give these channels in the
54:00 - reverse order so first of all
54:03 - 147 then
54:05 - 96 and then third Channel is the 44 and
54:11 - then I am going to run my code and you
54:14 - can see you get the same color which you
54:17 - have chosen here so this is how you can
54:20 - change the color of your lines now there
54:23 - is a function called arrowed line let's
54:27 - say we want to use this function which
54:31 - is called arrowed line and this is going
54:35 - to draw the arrowed line as it says so
54:39 - let's say we want to just draw this
54:42 - arrowed line in blue color so I am going
54:45 - to just give the color channels here and
54:49 - then run the code and this arrowed line
54:51 - is overlapping on the previous line
54:54 - that's why you don't see the previous
54:56 - line so let's change the coordinate of
55:00 - this line so let's draw this line in
55:05 - this coordinate which is going to draw
55:07 - the straight line in in my opinion let's
55:09 - see what happens when I run the code and
55:12 - you can see it draws the straight line
55:14 - from left to right which is the arrowed
55:18 - line and this was our original line now
55:22 - let's see how to draw the rectangle
55:25 - so to draw the rectangle we will do the
55:28 - same we will just overwrite on the same
55:31 - image so we will just say image is equal
55:34 - to c v 2 dot rectangle which is a method
55:39 - and you can see what are the argument it
55:42 - takes so the first argument is the image
55:45 - itself the second argument is the point
55:47 - 1 and 0.2 this point one and point two
55:51 - coordinate I am going to explain in a
55:53 - bit the third argument is the color
55:55 - which is same as line and the fourth
55:58 - argument is the thickness so let's use
56:02 - this rectangle function to draw the
56:05 - rectangle so first of all I am going to
56:08 - just pass the image variable here the
56:11 - second argument is the top left vertex
56:15 - coordinates so let me just draw
56:19 - something here so you will be able to
56:21 - understand in a better way so when you
56:24 - want to draw a rectangle using opencv
56:27 - this here is a top left vertex
56:30 - coordinates which is X1 and y1 and this
56:34 - is here the lower right vertex
56:37 - coordinates so the top left vertex
56:40 - coordinates you give in the second
56:42 - argument so let's give some coordinates
56:45 - here so 3 84 comma 0 and the lower right
56:50 - coordinates I want to give here is let
56:53 - us say
56:54 - 510 comma 128 so let us say we want to
56:58 - give the red color so I am going to just
57:00 - write 0 comma 0 comma 255 and the
57:05 - thickness I want to give here is 5 and I
57:08 - am going to just remove this because it
57:10 - will just create problems and now let's
57:14 - run the code and you can see the
57:16 - rectangle is drawn with the red color of
57:20 - thickness 5 you can change the thickness
57:23 - of this rectangle by changing the value
57:28 - of the thickness and then you can run
57:31 - the code and now the thickness of this
57:34 - rectangle line is increased now one more
57:38 - thing you can provide here is instead of
57:41 - giving the thickness value if you write
57:43 - here minus 1 then it's going to fill the
57:47 - rectangle with the color which you
57:50 - provide here so when we give minus 1
57:53 - here let's see what happens so now we
57:56 - get the filled rectangle because we have
58:00 - provided minus one option here so if you
58:03 - provide minus 1 then your rectangle or
58:07 - whatever shape you are creating will be
58:10 - filled with the color which you specify
58:13 - here so let me just change the thickness
58:15 - to 10 once again and now let's see how
58:19 - we can draw the circle so to draw the
58:22 - circle we once again use CV2 dot Circle
58:27 - function and once again you can see what
58:30 - are the argument which it takes so the
58:32 - first argument is the image the second
58:34 - argument is the center of the circle the
58:37 - third argument is the radius of the
58:39 - circle and the fourth and fifth argument
58:43 - is the color and the thickness once
58:45 - again so once again we will provide the
58:47 - image the second argument is the center
58:52 - of the circle so let's give the center
58:55 - of the circle which is the coordinate on
58:58 - which you want to ah give the center so
59:01 - I'm going to provide let us say 447
59:05 - comma 63 here and the third argument is
59:10 - the radius so radius we want to provide
59:13 - here is let us say 63 and the fourth
59:16 - argument is the color so let's use 0
59:19 - comma 255 comma 0 which is going to draw
59:24 - the green in color and then let us give
59:28 - minus 1 here so our Circle will be
59:31 - filled with green color and let's run
59:34 - the code and let's see what happens so
59:36 - you can see this circle is drawn here
59:39 - and this circle is filled with the green
59:43 - color now let's see how we can put some
59:46 - text into the image so to put the text
59:50 - on our image we will once again use the
59:53 - image variable and overwrite on it and
59:56 - then we will use a method called put
59:59 - text so this is the method which we are
60:03 - going to use the first argument is the
60:05 - image the second argument here is the
60:08 - text which we want to put so let us say
60:10 - we want to just print opencv on our
60:14 - image so we can just write opencv as the
60:18 - second argument the third argument is
60:21 - the starting point of your text so you
60:24 - need to give the call coordinates where
60:27 - you want to start your text from so the
60:30 - coordinates I want to give here is let's
60:32 - say 10 comma 500 and then the next
60:35 - argument is the font face so the font
60:39 - face you need to give here using a
60:43 - variable so I'm going to create a
60:46 - variable let's say font and then there
60:49 - are many font faces available using CV2
60:53 - so you can just write CB2 dot font in
60:57 - capital and you can see what are the
60:59 - options available here I am going to
61:01 - choose the first one itself which is
61:04 - font Hershey Simplex font and then we
61:08 - are going to pass this font as the
61:11 - fourth argument the fifth argument here
61:14 - will be the font size so let us say I
61:17 - want to give the font size 4 here the
61:21 - sixth argument here is the color of your
61:24 - font so let let us say I want to just
61:28 - draw 255 255 255 which is going to give
61:33 - us a whitish kind of color the next
61:37 - argument we will give here is the
61:39 - thickness so let's say I want to provide
61:41 - the thickness 10 here and the next
61:44 - argument you can give here is the line
61:47 - type so let's say I want to give the
61:49 - line type CV2 dot Capital line
61:54 - underscore a a and now let's run our
61:57 - script and let's see what happens so you
62:00 - can see here opencv is printed in the
62:05 - white color of thickness 10 and if you
62:09 - want to change this color you can change
62:10 - it from here so I'm going to just put
62:13 - the first channel as 0 and now this
62:16 - color is changed to yellow color now one
62:20 - more thing I want to show here is how
62:22 - you can create an image using num Pi
62:26 - zeros method so either you can use a
62:30 - image which you read from I am read
62:33 - method or what you can do here is I'm
62:36 - going to just comment this code and we
62:38 - can create an image using the numpy
62:42 - zeros method so I'm going to create this
62:46 - IMG variable and then I'm going to use
62:50 - the numpy module so just import this
62:52 - numpy as import numpy as NP and then we
62:56 - are going to use this MP to call the
62:59 - zeros method now in order to create a
63:02 - black image using this zeros method you
63:05 - need to give the first argument in the
63:07 - form of list and inside this list the
63:11 - first element will be the height second
63:14 - will be the width and third will be 3.
63:17 - so let us say we want to provide the
63:19 - height 512 we want to provide the width
63:22 - also 512 and and the third argument will
63:27 - be 3 and the next argument you give here
63:30 - is the D type or data type so you can
63:33 - just write NP dot U
63:37 - int 8 here so this method is going to
63:41 - give you a black image of the size 512
63:45 - by 512 so let us run our code and let's
63:48 - see what happens so you can see now you
63:51 - can see the black image and on our black
63:55 - image the line is drawn the erode line
63:58 - is Dawn and the text and the circle and
64:01 - the rectangle are drawn here so this is
64:04 - how you can draw different geometric
64:06 - shapes on your image there are several
64:11 - other methods you can use for example
64:13 - CV2 dot polyline method or CV2 dot
64:17 - Eclipse method to draw eclipse and
64:19 - polygon on your image so just try those
64:23 - method to draw different shapes on your
64:27 - image so in this video we will see how
64:29 - to set some properties to our captured
64:33 - images so in the video capture lesson we
64:37 - we have seen that when we create a cap
64:42 - variable using the video capture class
64:46 - we can get many properties using the
64:49 - cap.get method so we were able to get
64:53 - the width of the frame and the height of
64:56 - the frame similarly we can use the cap
65:00 - dot set function to set some values so
65:05 - you can just write cap dot set and then
65:08 - you can set the values of the property
65:11 - generally all the properties which you
65:14 - can read like this you can also able to
65:18 - set those property using the set method
65:21 - now this notation you can also give in
65:24 - the form of number so every property
65:27 - here has a defined number so for example
65:31 - instead of using CV2 dot cap prop
65:34 - underscore frame width you can just
65:38 - write 3 here and that will work also so
65:42 - every property has a number associated
65:45 - with it so using that number either you
65:49 - can just let us say we want to set the
65:51 - width and height either you can write
65:54 - this as the first argument and the
65:56 - second argument is the actual width you
65:59 - want in the video right or you can just
66:04 - give the number of that property and
66:07 - then give its value so let us say we
66:10 - want to change the width of this video
66:12 - to let us say 1 2 0 8 and then let us
66:17 - just set the height so cap dot set and
66:22 - the associated number for the height
66:24 - parameter will be four so three for
66:27 - width and 4 for the height and let's say
66:31 - we want to just ah move it to 720 and
66:36 - then we will once again print the value
66:39 - of the width and height and this time we
66:42 - are going to just give their Associated
66:44 - numbers which is 3 and 4. so let's run
66:49 - this program you might already know this
66:52 - program what this program is doing so
66:55 - it's just capturing the video from your
66:58 - default device at index 0 and then its
67:03 - just showing all the frames using this
67:07 - IM show method in a window so now I am
67:11 - going to run this script and let's see
67:13 - what happens so when I run the script
67:16 - you can see the size of this Frame is
67:20 - changed so lets see in the terminal also
67:23 - you can see before the original size of
67:28 - the video we are capturing a 640 and 480
67:33 - so width was 640 and the height is 4 a t
67:37 - now once we have changed the width and
67:40 - height you can see the width is changed
67:43 - to one two eight zero and the height is
67:47 - changed to 720 so even if I have given
67:50 - here one two zero eight the default
67:54 - camera will automatically set its value
67:57 - according to its resolution so let us
68:02 - just close this video and let us say we
68:05 - want to just change this value to some
68:08 - random number so let us say 700 by 700
68:12 - will it work or not so let us run the
68:15 - script once again and let's see what
68:17 - happens so the script is running and you
68:21 - can see that even though we have
68:23 - provided the 700 and 700 the camera will
68:27 - automatically take the resolution which
68:30 - is available for your default camera so
68:34 - the resolution Remains the Same even
68:36 - though we have set the different value
68:39 - to it so you need to keep in mind even
68:42 - though you can give any value here but
68:45 - the camera will only set the resolution
68:48 - which is available for it so let us give
68:52 - a very big value here so I am going to
68:55 - provide let us say 3000 here and height
69:00 - also 3000 and let's run the script once
69:04 - again and see what happens so when we
69:07 - run the script you will see the
69:09 - resolution is changed but the resolution
69:13 - will change to the maximum resolution of
69:16 - my default camera which is one two eight
69:19 - zero and 720 this is the maximum
69:22 - resolution which is available for my
69:25 - webcam so let me just close this window
69:28 - so this is how you can set some values
69:31 - so there are many values you can set
69:34 - using this set method you just need to
69:37 - go to the documentation and then search
69:40 - for the value you want to set
69:43 - so in the last two videos we have seen
69:45 - how to capture videos from our default
69:49 - camera device or how to add geometric
69:54 - shapes on the images
69:56 - now in this video we are going to
69:58 - combine the knowledge we have gained in
70:01 - the last two videos so if you haven't
70:04 - seen the last two videos I will
70:06 - recommend you to watch those videos and
70:09 - then come to this video
70:11 - so in this video we will see how we can
70:15 - just draw something on a video and more
70:19 - specifically the aim of this video is
70:22 - how to show the current date and time on
70:28 - a live video so now in the last video we
70:33 - have seen how to draw shapes on images
70:37 - and we have also seen how to put text on
70:42 - our images right so let's say we just
70:45 - want to print the value of width and
70:48 - height on the default camera and let me
70:51 - just remove this line which we have used
70:53 - to convert the BGR image to the
70:56 - grayscale image so we will just see the
71:01 - colored BGR image so now what we want to
71:04 - do is we want to print the width and
71:07 - height which we get from these
71:10 - properties on our video which we are
71:14 - capturing so in the last video we have
71:16 - already seen that we can use a method
71:20 - which is
71:21 - CV2 dot put text yeah so this method we
71:27 - have seen in the last video and first of
71:30 - all we will Define the font which we
71:33 - will pass to our put text method so the
71:37 - font I'm using here is CV2 dot font
71:40 - Hershey underscore simplex and now the
71:44 - first argument here will be the frame
71:46 - which we are capturing because every
71:49 - frame is just like an image and a video
71:52 - is the combination of multiple images so
71:55 - the first argument here will be the
71:58 - frame the second argument here will be
72:01 - your text so the text which we want to
72:04 - show here is let's say width and height
72:07 - so let us Define a variable which we
72:11 - want to show on our video so let us say
72:14 - the variable name is text and first of
72:17 - all I am going to define the width so
72:20 - just say width and then we are going to
72:24 - provide the value of the width using the
72:27 - concatenation operator now because this
72:31 - value will be in integer and we want to
72:35 - convert it to the string so we will use
72:38 - the Str method to convert the integer to
72:42 - the string and then we can pass the
72:45 - width here
72:47 - inside our string variable once again we
72:51 - will use the concatenation operator and
72:53 - then let us provide some space here and
72:56 - then we will just write the height colon
73:00 - and then once again the concatenation
73:03 - operator and once again we will use this
73:06 - string method and inside the string
73:08 - method we will now take the height OK
73:12 - and now we will pass this text to our
73:16 - put text argument now the third argument
73:19 - is the coordinate so let us say I want
73:22 - to just put this text at the coordinate
73:25 - 10 comma 50 the fourth argument is the
73:29 - font which we have already declared the
73:32 - fifth argument is the thickness so let
73:36 - us say the thickness we want is one and
73:39 - then the color so let us say the color
73:41 - we want is 0 comma 255 comma 255 and
73:48 - then the thickness so I think the
73:50 - thickness comes after the color and the
73:53 - value 1 we have set for the font scale
73:56 - so you can change the font scale one two
73:58 - three four any font you can change it
74:01 - from here so this value 1 is for the
74:03 - font scale and the value we are
74:06 - providing right now is for the thickness
74:09 - so let us say the thickness is two and
74:11 - the last argument here will be the line
74:13 - type so I am going to just provide the
74:15 - line type as CB2 dot line underscore a a
74:22 - so what do you think will this ah text
74:24 - will be printed on our image or not so
74:27 - it will not print yet because we need to
74:30 - write on the frame this text so we need
74:34 - to just write frame is equal to and then
74:38 - put the text on the same frame which we
74:42 - are seeing right now so now this will
74:45 - work and let me just break this line so
74:47 - you will see all the code and now let's
74:50 - run the code and let's see what happens
74:53 - when we run the code so let me run this
74:56 - script and you will see here that now we
75:00 - are seeing the width and height on top
75:03 - of this video which is 1 2 8 0 and the
75:08 - height is
75:09 - 720.0 so this is how you can show text
75:13 - on your video which you are capturing
75:16 - from the back camera or from the video
75:19 - file now let me just comment these lines
75:23 - of code because they are changing the
75:25 - resolution of our video and its not
75:29 - fitting this video or screencast so I
75:33 - have commented this code and now let's
75:36 - do something more interesting so now let
75:39 - us say we want to show the current date
75:42 - and time on the video and you might have
75:45 - guessed how to print it but let me show
75:48 - you if you don't know how to print the
75:51 - date and time on your live video so
75:55 - first of all we are going to import the
75:58 - package which is available inside python
76:02 - which is date time and then we are going
76:05 - to create ah this date time variable let
76:08 - us say the date time variable name will
76:11 - be date ah T and then first of all we
76:15 - are going to use the Str method to
76:18 - convert the date and time to string and
76:22 - then there is a method inside this date
76:25 - time Library so we just need to write
76:28 - date time dot date time once again and
76:31 - then the method called now which is
76:34 - going to show you the current date and
76:38 - time so once we have converted our
76:41 - current date and time to the string
76:45 - variable then we can pass this very
76:47 - variable as the second argument and now
76:50 - let us run the script and let's see what
76:54 - happens once again so I am running the
76:57 - script and now you will see that it
77:00 - shows the current time and current date
77:03 - on the video itself so this is how you
77:07 - can put the text on your video you can
77:11 - even put some shapes which we have seen
77:14 - in the last video on this video itself
77:18 - so you can put the line or the rectangle
77:20 - or the circle on your video which you
77:25 - are capturing from the camera or some
77:28 - file so this was some kind of a mini
77:31 - project which we have created from the
77:34 - knowledge which we have gained from the
77:36 - last two videos in this video we will
77:39 - learn how to handle mouse event in
77:41 - opencv now miles event can be anything
77:45 - for example right click event or left
77:49 - Mouse button click event or left button
77:53 - double click event so there are many
77:55 - mouse event available in CV2 package
78:00 - now to list out all the events in the
78:04 - CV2 package you can write this kind of
78:07 - code so first of all I'm going to create
78:09 - a variable called events and then I'm
78:14 - going to just iterate over all the
78:18 - events inside CV2 Library so I'm going
78:22 - to just write I for I in dir inside our
78:29 - CV2 package so this dir method is the
78:35 - inbuilt method which is going to show
78:38 - all the classes and member functions
78:42 - inside your CV2 package okay so we are
78:46 - iterating over all the function names or
78:50 - member variable names and then we want
78:54 - to see what are the events available
78:57 - inside this package so we can just
79:00 - filter those events using a condition so
79:04 - we are going to just say that we want to
79:07 - just see the variables or the member
79:11 - properties which have this keyword event
79:15 - in them so event in I and then we are
79:21 - going to just print out all the events
79:24 - so I am going to just print out all the
79:26 - events and then I'm going to run this
79:30 - code and here you can see the list of
79:32 - all the events which are available
79:34 - inside your CV2 Library
79:37 - so you can see there is an event called
79:40 - event flag R button for the right button
79:45 - for the mouse or there is event for left
79:49 - button double click event or the event
79:53 - for L button down event so there are
79:57 - many such events available here and we
80:00 - are going to use those events to listen
80:03 - for the mouse events so this is how you
80:07 - can print all the events which are
80:10 - available inside your CB2 library and
80:13 - now we will create a script or a program
80:17 - to listen for the mouse event
80:21 - so first of all we will create a mouse
80:24 - callback function which is executed when
80:28 - mouse event takes place so in order to
80:32 - create this callback function we are
80:35 - going to just Define a function and then
80:38 - we will give the name to our function
80:41 - for example
80:43 - click event function and this callback
80:46 - function generally takes few arguments
80:49 - so the first argument will be the event
80:53 - which is taking place when we click our
80:56 - Mouse and then it's going to give us the
81:00 - x and y coordinate on the image where we
81:04 - are clicking with our Mouse so we are
81:07 - going to get the x-axis value and the
81:10 - y-axis value whenever we click the mouse
81:13 - at certain position in our image
81:18 - also we will get the flags
81:21 - and we will get the param so for
81:26 - creating the mouse click callback
81:28 - function it has this kind of specific
81:32 - format which is same everywhere so these
81:36 - are the parameter it takes and then
81:39 - inside your callback function you can
81:42 - Define the logic so let's say whenever I
81:46 - click the left button down then I want
81:51 - to show The X and Y coordinates on the
81:56 - same image so I can just say if the
82:00 - event variable is equal to
82:03 - CV2 dot event and then I will just look
82:10 - for the left button down click event so
82:14 - if this event occurs then I will first
82:18 - of all print the X and Y axis values so
82:21 - let's print X comma Y and you can also
82:26 - provide some space between X and Y
82:29 - coordinates using this kind of string
82:33 - and then what we are going to do is we
82:36 - are going to just put this x and y
82:40 - coordinate values on the same image
82:43 - which we are opening so we have already
82:47 - seen in the last videos how to put text
82:51 - on the videos we just need to create
82:54 - this font variable for the font and then
82:58 - there is a method called CV2 dot put
83:03 - text so we are going to just write CV2
83:07 - dot put text which takes few argument
83:10 - first is the image now you can see this
83:13 - image shows error and this error says
83:16 - unresolved reference but don't worry
83:19 - when we write our code code fully this
83:24 - error will go so first will be the image
83:26 - the second is the string which we want
83:29 - to put so let's say we want to put the
83:32 - string Str for the X and Y value so I'm
83:37 - going to just write x y and then we are
83:41 - going to just print the x value then
83:45 - concatenation operator and then comma
83:48 - and then once again concatenation
83:51 - operator Y and don't forget to convert
83:54 - these coordinate values into the string
83:58 - using the Str function so Str function
84:02 - here and for the y axis also you need to
84:07 - use this Str to convert it to the string
84:11 - value and then the string we pass as the
84:14 - second argument the third argument will
84:17 - be the location where we want to put the
84:20 - text and this location education we
84:22 - already know from this X and Y value so
84:26 - it's easy for us we are going to just
84:28 - say x comma y because we already know
84:32 - the x and y coordinate using this
84:35 - callback event the fourth argument will
84:39 - be the font the fifth argument will be
84:41 - the font scale let us say its 1 and then
84:45 - the next argument is the color so let's
84:47 - say color we want to give here is 255
84:51 - comma 250 5 comma 0 and the last
84:57 - argument I want to give here is the
84:59 - thickness let us say thickness we want
85:01 - to give here is 2 and then we will show
85:04 - this text on the image using CV2 dot I
85:09 - am show method so I am going to just
85:11 - write I am show and then the name of the
85:15 - image window for example image and the
85:19 - image itself which is is IMG so right
85:24 - now this is showing error to us but when
85:27 - we will call this callback function
85:30 - using a standard function called set
85:33 - Mouse callback then this error will go
85:36 - so I'm going to define the IMG variable
85:40 - first of all and let's say we want to
85:43 - create a black image using numpy so we
85:48 - will call NP dot zeros method here so NP
85:53 - dot zeros and the size of this image
85:57 - will be 512 comma 512 comma 3 and the
86:04 - data type will be NP dot U into 8 and
86:11 - once we have this image we are going to
86:14 - show this image using once again the IM
86:17 - show method and this image name Will be
86:22 - the same image and the variable we want
86:26 - to pass here is the image variable which
86:28 - is the black image which we have created
86:30 - using this numpy zeros function now the
86:34 - next and the important step here is
86:36 - calling a method called set Mouse
86:40 - callback a method so this method we are
86:45 - going to use to call our callback
86:48 - function which we have created which is
86:50 - Click event function whenever somebody
86:53 - clicks on the image which we are showing
86:57 - using this I am show window so the first
87:01 - parameter it takes is the name of your
87:04 - image make sure that this name here
87:08 - which you take in the IM show method you
87:11 - can see I am taking the same name here
87:14 - in the I am show method also here so the
87:18 - window name should be the same
87:20 - everywhere then then only it will work
87:23 - so here also you need to just give the
87:27 - parameter first parameter here is the
87:30 - window name so the window name is image
87:34 - and the second parameter is the Callback
87:37 - function which we want to call whenever
87:41 - this event take place so this is the
87:44 - Callback function which we have created
87:46 - now the next step are the obvious steps
87:50 - which we have already seen so first of
87:53 - all we will call the weight key method
87:57 - to wait for the Escape event and the
88:01 - second is the destroy all windows so we
88:05 - will destroy all the windows once we are
88:07 - finished
88:09 - so let's run this code and let's see
88:11 - what happens so now you can see the
88:14 - black image which is created by numpy
88:17 - zeros method and when I click on this
88:21 - image anywhere you can see the
88:23 - coordinates of the position where I have
88:26 - clicked is uh printed here so let's
88:29 - click here you can see when I uh give
88:33 - this left down button click event then
88:37 - the position of the X and Y coordinate
88:42 - is printed on this black image so I'm
88:46 - clicking again and again this left down
88:49 - button and the position is printed okay
88:54 - so let me just close this window now
88:57 - what I want to do is let's just reduce
89:01 - the size of this font 2.5 then the font
89:08 - size will be little bit smaller now what
89:12 - I want to do is I want to listen for
89:15 - some other events so I will go to my
89:17 - callback function once again and I will
89:20 - add one more condition here so once
89:23 - again if event is equal to
89:27 - CV2 and this time I want to listen for
89:31 - the right click event so I'm going to
89:34 - just write event write button down event
89:38 - okay so whenever somebody presses this
89:43 - right button down for the mouse then
89:47 - this event is going to be captured
89:50 - inside this condition now if you see
89:53 - remember I have told you that image is
89:56 - shown in opencv in the form of BGR
89:59 - format and we already have this image
90:03 - you can see we have declared the image
90:04 - variable that's why this error is also
90:07 - gone so using this image we want to find
90:11 - out the red blue and green channel so
90:15 - now inside this condition what I want to
90:16 - do is I want to print out the BGR
90:19 - channels of the image wherever I click
90:23 - okay so you can first of all declare a
90:27 - blue variable name and then we have IMG
90:31 - variable which is this one and using
90:34 - this image variable we can get the blue
90:38 - Channel using the coordinates so first
90:40 - of all you can provide y comma X we
90:44 - already have the y and x coordinates and
90:47 - then the channel for the blue color is
90:51 - channel 0 because it starts from Blue
90:54 - BGR so blue and then green and then red
90:58 - okay so I'm going to just copy it two
91:02 - more times the second is green and the
91:06 - channel for it will be the one or index
91:10 - will be 1 here and for the right channel
91:13 - this index will be 2 here so I'm going
91:15 - to just write Red here and once again
91:18 - I'm going to just copy this code and
91:22 - this time what I want to do is instead
91:25 - of printing in the coordinates I want to
91:30 - print the BGR channel so here I'm going
91:33 - to just write blue and then second will
91:37 - be the green Channel and then the third
91:40 - will be the red channel so I'm going to
91:44 - just write comma and then concatenation
91:47 - operator s t r and then red Channel okay
91:52 - so this will be
91:54 - the string we are going to name it as
91:57 - BGR and this string we will put here the
92:03 - color also we can change so the color
92:06 - for the coordinates will be different
92:08 - and the color for this event will be
92:12 - different 255 okay
92:15 - so it's going to print the BGR channels
92:18 - on your image now because we are
92:21 - creating the black image whenever I just
92:25 - click the right uh click mouse event you
92:28 - can see the BGR
92:31 - channels for this black image will be
92:33 - always 0 0 is 0 right when I click the
92:37 - left click then these are the
92:40 - coordinates when I click the right click
92:42 - these are the BGR channels so let's
92:45 - change this image from the black image
92:49 - to something visible so I already have
92:54 - the Lana image so we can use this lamina
92:59 - image using the CV2 dot IM read method
93:02 - so I'm going to just try CV2 dot I am
93:06 - read and the first will be the name of
93:10 - the file which is Lena dot jpg e so now
93:16 - let's run this code once again and now I
93:19 - have this colored image so we will be
93:22 - able to see these functionality in a
93:25 - better way so first of all the left
93:28 - button click event you see the
93:30 - coordinate and when I click the right
93:33 - click button event then you can see the
93:36 - BGR channels are printed once again here
93:40 - you can see the BGR is different here
93:44 - also these are BGR colors are different
93:48 - so you can see everywhere they are a
93:51 - little bit different because this is the
93:53 - colored image and the color differs at
93:56 - every pixel level
93:59 - so this is how the mouse click event
94:03 - works in the last video we have seen how
94:06 - to use Mouse click event in opencv using
94:10 - python
94:11 - so we have seen how we can create a
94:13 - callback function which listens to a
94:17 - mouse click event and then how to use
94:20 - this callback function using the set
94:23 - Mouse callback method now in this video
94:27 - I will show you some more examples about
94:30 - Mouse click event so the first example I
94:35 - want to show about drawing a point and
94:40 - then connecting points using the line so
94:46 - to start with I'm going to just remove
94:48 - this if condition for the right down
94:52 - button click event and every time
94:56 - somebody clicks the left button down
94:59 - click event of mouse then what I want to
95:03 - do is every time
95:06 - the mouse is clicked down I want to draw
95:10 - a circle very small circle and when he
95:13 - clicks on the next point then I want to
95:16 - join those two points using a line
95:21 - so for that I will need a CV2 Circle so
95:25 - I am going to remove this code which we
95:28 - do not need right now we just need this
95:32 - condition which listens for the left
95:35 - button down click event of mouse and
95:38 - then what we will do is we will just use
95:43 - CV2 to draw a circle so we will just
95:47 - write dot Circle and first of all this
95:51 - circle method takes the image so we are
95:55 - going to pass the image and then the
95:57 - second argument is the coordinates x and
96:00 - y coordinate so we already have x and y
96:04 - coordinate using this callback function
96:06 - with the second and third parameters and
96:10 - then the third parameter will be the
96:12 - radius so I will take the radius 3 which
96:15 - is like very small which will give you a
96:20 - effect like a point on an image and then
96:24 - we can give the color so let's give zero
96:28 - comma 0 comma 255 and then we will give
96:33 - the thickness now the thickness I'm
96:36 - going to give here is minus 1 and you
96:39 - might already know what this minus 1 do
96:42 - so this minus 1 whenever you give as a
96:45 - thickness it fills your circle or any
96:49 - closed shape okay so your closed Circle
96:55 - will be filled with this color which you
96:58 - provide here now next what I want to do
97:01 - is I want to create an array of points
97:04 - so I am going to ah just declare a
97:09 - variable called points and initialize it
97:12 - with an empty array now this MTR
97:17 - variable we can use inside our callback
97:20 - function and what we are going to do is
97:22 - we are going to just add or append every
97:27 - time this mouse is clicked so I am going
97:29 - to just call an append method here and
97:33 - then we are going to append the x and y
97:35 - coordinate to this points array so we
97:40 - know that where this mouse is clicked
97:43 - and we are saving the coordinates
97:46 - wherever the mouse is clicked in the
97:49 - form of array now in The Next Step what
97:51 - we will do is if the mouse is clicked
97:54 - more than two times so we can just test
97:58 - the length of this array which is a
98:02 - point and if the length of this array is
98:06 - greater than or equal to 2 because the
98:09 - first click will be only a point so we
98:13 - cannot connect this point with a line
98:16 - but when we have two or more points then
98:20 - we can connect those points with a line
98:23 - right so if this points array length is
98:27 - greater than 2 then we are going to just
98:31 - create a line between those points or
98:36 - the circles in our case so I am going to
98:38 - just call c v 2 dot line method and
98:42 - first
98:44 - argument here will be uh image the
98:48 - second argument here will be the point
98:51 - one so the coordinate of point one now
98:54 - we want to join the last two points
98:57 - right so we are going to just use this
99:01 - points array and then to get the last
99:05 - value of an array we use minus 1 here so
99:10 - here as an index we will give minus 1
99:13 - which means the last element of an array
99:17 - and then we will join the second last
99:20 - element of an array so I am going to
99:22 - just give this will be points variable
99:26 - not print so let's give the points
99:30 - variable and then we are going to pass
99:32 - the minus 2 here which will be the
99:36 - second last element so last and second
99:39 - last element we want to join and then
99:41 - the next argument will be the color so
99:45 - let's say the color we want here is 255
99:49 - comma 0 comma 0 and the next point will
99:56 - be the thickness so we will give the
99:59 - thickness of 5 here and then we will
100:02 - show this image using IM show method
100:04 - this code I have already shown you in
100:07 - the last video so I will not explain
100:08 - what this code is doing if you want to
100:11 - know more about this code you can see
100:14 - the last video and this time I will use
100:18 - the numpy zeros array which will be a
100:21 - black image so let's run this script and
100:24 - let's see what happens so I'm running
100:26 - the script and now I click on some
100:31 - position on this image and you can see
100:34 - this red circle is created the circle is
100:40 - created using CV2 dot Circle method and
100:44 - because the radius is 3 the circle is
100:47 - very small and because the thickness is
100:50 - minus 1 the circle is filled with the
100:54 - color which you provide here
100:57 - now we have said that if the point is
101:01 - only one then we do not want to create
101:04 - any line if there are points which are
101:08 - two or more then we want to connect
101:11 - those point with the line so let's click
101:14 - here and you can see
101:16 - 0.1 and 0.2 are connected with a line I
101:22 - click here and you can see the last and
101:24 - the second last points are connected
101:27 - with the line that is why we have taken
101:29 - this minus 1 and -2 argument which means
101:33 - the last element of the array and the
101:35 - second last element of the array so when
101:38 - I click at any point it will be now
101:41 - connected with this blue line so this
101:46 - kind of ah line drawing you can use in
101:50 - satellite images where you want to
101:53 - connect two points together with the
101:56 - line now let's see the next example
101:58 - which I want to show you so in the next
102:02 - example what I want to do is I want to
102:05 - first of all read an image and then I
102:09 - want to click on any point on the image
102:13 - and then I want to show the color of the
102:18 - point which on which I have clicked
102:20 - using a second window so for this
102:24 - instead of using the numpy array which
102:27 - is the black image I will use the
102:33 - normal image which is the Lana dot jpg
102:36 - image and now I will just remove this
102:40 - code from here so first of all I want to
102:42 - read the BGR channels so first of all I
102:45 - will just declare these variables first
102:48 - is blue and we have the image and in the
102:52 - last video we have already seen how we
102:54 - can get the BGR channels because we have
102:58 - the x coordinate and the y coordinate
103:01 - and we also know that blue is the first
103:05 - channel so we use the index 0 here to
103:09 - get the blue channel from this image at
103:14 - this coordinate which is X and Y same we
103:18 - will do for the green channel so green I
103:23 - am G and then X comma Y and then the
103:29 - channel index will be 1 here and then we
103:32 - will just uh get the red channel from
103:36 - this image and now what we are going to
103:38 - do is we are going to just draw a circle
103:41 - on this point where ah you will click
103:44 - this Mouse uh down button click event so
103:48 - I'm going to just write CV2 dot Circle
103:51 - and now I will not explain the
103:55 - parameters because you might already
103:57 - know what these parameters are in the
104:01 - next line what we are going to do is we
104:04 - are going to create a numpy zeros image
104:08 - and then we will pass our BGR channels
104:12 - which we got from the particular point
104:15 - on an image so let's create an image so
104:20 - I will just say my color image and then
104:24 - we are going to just use NP for numpy
104:28 - and then we will just call a zeros
104:32 - method here and it takes ah three
104:35 - argument in the form of this list which
104:39 - is the size of your image let us say
104:43 - this size will be 512 comma 512 and the
104:49 - channel will be three channels and then
104:52 - the next argument will be the data type
104:55 - so NP dot U
104:58 - and eight so we have a black image using
105:03 - this numpy zeros and now we want to fill
105:06 - this image with the BGR colors which we
105:12 - got from the particular point of the
105:15 - image so in the next line what we are
105:18 - going to do is we are going to just use
105:20 - this variable and then we are going to
105:24 - just write this kind of notation this
105:27 - means we want to fill every channel or
105:32 - every uh point of ah this list and then
105:37 - we will just pass our BGR Channel values
105:41 - which we got from the image so blue
105:45 - green and then the red Channel values we
105:51 - are going to pass so this will give us
105:54 - the BGR Channel which will be the color
105:56 - of the point where we have clicked and
106:00 - now we have the new image with the color
106:03 - so we can show this image using a new
106:08 - window with let's say this is the color
106:12 - window okay so this is how you will get
106:16 - the new window with the color on which
106:20 - you have clicked so let's run this code
106:23 - and let's see what happens so I'm going
106:25 - to run this code and you can see this is
106:29 - the image which is the colored image
106:31 - let's see I click on this point and you
106:35 - can see the same color on which I have
106:38 - clicked is opened in the next window
106:41 - let's click here on the hat you can see
106:45 - it's going to give you the same color on
106:48 - which I have clicked let's click on the
106:51 - eyes and you will get the same color on
106:55 - which I have clicked let's see what
106:58 - happens when we just load a Black image
107:01 - instead of this colored image so I'm
107:04 - going to just use this
107:06 - numpy zeros ah image which is the black
107:10 - image and let's run this code and now
107:13 - whenever I click on this every time I
107:16 - click on any point it will be the black
107:20 - color window which will open so this is
107:24 - how you can use some examples to
107:29 - understand how Mouse click events can
107:33 - work and you can use them to develop
107:37 - your applications in this video we will
107:41 - see some of the basic and arithmetic
107:44 - operations on images using opencb so
107:48 - let's get started so here I have this
107:51 - code some of this code you already know
107:54 - so you already know how to read the
107:55 - images using I am read method and then
107:59 - show it inside a window using I am show
108:01 - method and destroy all windows using
108:04 - this destroy all windows method but this
108:07 - code in between is little bit new so let
108:10 - me explain line by line what this code
108:13 - does so when you have this image using
108:17 - IM read method or any other method you
108:21 - can use these attributes like shape size
108:24 - and D type to get different
108:27 - values from this image so image dot
108:32 - shape is going to return a tuple which
108:35 - contains the number of rows columns and
108:39 - the number of channels in this image the
108:43 - image dot size will return the total
108:45 - number of pixel which are there in
108:48 - inside the image and image dot d type is
108:53 - going to return the data type of the
108:56 - image which you have obtained
108:59 - now here if you want to split your image
109:02 - in three channels then you can use CB2
109:05 - dot split method and pass your image as
109:08 - an argument and it's going to give you
109:10 - the BGR channel of your image now if you
109:15 - have BGR channels and you want to merge
109:18 - those BGR channel into an image then you
109:22 - can use CV2 dot merge method and pass
109:26 - these BGR channels in the form of Tuple
109:29 - and it is going to give you the image
109:32 - which you can load using I am show
109:35 - method so let's run this code and let's
109:39 - see what we are getting using these
109:42 - attributes so you can see this messy
109:46 - 5.jpg image is loaded and here you can
109:50 - see first of all the shape of the image
109:53 - so the shape Returns the number of rows
109:55 - number of columns and the number of
109:57 - channels so number of rows here is 342
110:01 - columns are 548 and number of channels
110:05 - are 3 here the number of pixel which we
110:09 - have calculated using the size is this
110:13 - number which is five six two two four
110:15 - eight and the data type of an image is
110:19 - uint 8. so sometimes you need to debug
110:23 - the data type of your image and this
110:27 - attribute will be very useful in those
110:31 - cases and you need to debug if something
110:33 - is correct or wrong and because we have
110:37 - splitted this method using this split
110:39 - and remerged these BGR channels using
110:43 - this merge method so we will at the end
110:47 - get the same image which we have at the
110:51 - beginning here in this code so there is
110:55 - no change in the code
110:57 - so once again let me just load this
110:59 - image and now let's talk about the ROI
111:03 - of an image
111:05 - so Roi stands for region of Interest so
111:10 - sometimes you need to work with certain
111:13 - region of the image so let's say you
111:16 - only want to work with the face here or
111:20 - you only want to work with this ball
111:22 - okay so this is called the region of
111:25 - Interest or in short form it's called
111:28 - Roi
111:30 - so let's say we want to just work with
111:34 - this ball here so this will be our
111:38 - region of Interest or Roi and I want to
111:42 - just copy this ball to other place in
111:47 - this picture so I want to just copy this
111:50 - ball and place it on the other place
111:54 - let's say somewhere here okay so how we
111:58 - can do this so I already have the
112:02 - coordinates of the ball but you already
112:04 - know how to get the coordinates of some
112:08 - place in the image we have already
112:10 - discussed this in our previous video so
112:13 - I am not going to show you how to obtain
112:16 - those coordinates but let us say I have
112:19 - those coordinates of the ball so I'm
112:21 - going to create a ball variable and we
112:24 - have our image so we will take our image
112:27 - and there are certain numpy indexing
112:30 - features which we can use here so I am
112:34 - going to just write ah 280 colon 340
112:39 - which is going to give you one point on
112:44 - the ball which is the upper left hand
112:48 - side of this ball and then we will give
112:51 - 3 30 here colon
112:55 - 390 which is going to give us the bottom
112:58 - right hand corner of this ball okay so
113:03 - now we have this ball so this this
113:07 - indexing is going to copy this ball all
113:11 - the pixels of this ball and then now we
113:14 - have the ball so we can place this ball
113:16 - on any place on this messy image which
113:21 - we are reading so what we can do is we
113:24 - can once again use IMG and using those
113:29 - numpy index using features we can place
113:33 - this ball at some other place so let me
113:37 - just give those indexes here so let me
113:41 - give
113:42 - 273 colon 333 I have already tested this
113:47 - code so that's why I know exactly where
113:50 - I want to place this ball but if you are
113:54 - not sure where to place this ball then
113:57 - you might have to first calculate or
114:01 - know the coordinates where you want to
114:03 - place this ball and you already know how
114:05 - to find out the coordinates on an image
114:08 - and you will be able to place ah that
114:13 - Roi or interest of region at some other
114:16 - place so what I am doing here is I have
114:20 - just copied the ball and then I am
114:25 - placing the ball on this coordinate Okay
114:30 - so so I just need to just assign our
114:33 - ball on this coordinate and then this
114:36 - ball will be copied to this index on the
114:40 - image so let's see what happens when we
114:42 - run the code so now you can see we have
114:45 - copied this ball and we have placed this
114:48 - ball here on the image so this is how
114:52 - you work with the ROI or region of
114:56 - Interest okay so let me close this
115:00 - window now the next thing which I want
115:03 - to show here is how you can add two
115:06 - images so for that I need one more image
115:10 - so you can see in my project I have this
115:14 - messy 5.jpg and I have this other image
115:18 - which is opencv hyphen logo dot PNG file
115:22 - which is of the same size as the messy
115:26 - dot jpg image so I'm going to just write
115:30 - I am
115:31 - G2 and then once again CB2 dot I am read
115:36 - method and then I am going to give the
115:39 - name of this file which is opencv hyphen
115:43 - a logo dot PNG file okay so this is this
115:49 - file so this file we are reading and
115:52 - then there is a method called add okay
115:56 - so we are going to use this method here
116:00 - let's use this method CV2
116:03 - dot add and this method I'm going to
116:07 - show you what it does in a moment but
116:10 - this method takes two argument first is
116:13 - the first numpy array so let me show you
116:16 - what this method do first of all so this
116:19 - is the add method inside your CV2
116:23 - package you can also see the
116:25 - documentation on the the
116:29 - opencv.org and what it does is it
116:32 - calculates the pre element sum of two
116:35 - arrays or an array and a scalar okay so
116:40 - here we can just pass our two arrays
116:45 - which we got from the I am read method
116:47 - and pass here as the first and the
116:52 - second argument so I am G and I am G two
116:56 - are the 1 and 2 parameter and there are
117:00 - some other parameters also like output
117:03 - array input array mask and int which is
117:07 - the data type which we which are set by
117:10 - default so we are not going to set them
117:13 - so we are just using CV2 dot add method
117:17 - on these two images and then I just want
117:21 - to assign the new image which we have
117:24 - added to a new variable let us say this
117:27 - is DST for Destination image and then
117:32 - we are going to just show this image
117:34 - using this uh I am show method okay so
117:39 - we have two images let me show you those
117:41 - images one by one first of all so this
117:44 - is the first image I have and the second
117:46 - image is opencv hyphen logo which is
117:49 - like this one okay so those two images
117:52 - we have and when I run this code after
117:56 - adding those two images using add method
117:59 - you will see first of all you will see
118:02 - this error and why this error is coming
118:05 - because you will see here that the size
118:10 - of those two input is not matching okay
118:14 - so in order to add two images you need
118:18 - to have the images or the arrays of same
118:22 - size and then only you will be able to
118:25 - add those two images so let's resize
118:28 - those two images into a size which is
118:33 - common to both of them so you what we
118:37 - are going to do next is we are going to
118:39 - resize those images so once again I am
118:41 - going to just use IMG variable so what I
118:46 - get after the resizing I will once again
118:48 - assign to this IMG variable and there is
118:51 - a method called CV2 dot resize and this
118:57 - helps us to resize the image so first of
119:00 - all we need to give the source which we
119:02 - want to resize and then we are going to
119:05 - give the size which we want to get so
119:09 - the number of columns and number of rows
119:11 - we can give here let us say we want to
119:14 - just resize this image to 512 to comma
119:18 - 512 which is the number of rows and
119:21 - number of columns right same we will do
119:24 - with the next image so I am g 2 and then
119:29 - once again CV2 dot re size and then the
119:34 - Source here will be image 2 and the size
119:37 - which we want here is again Phi 1 2
119:41 - comma five one two in the form of Tuple
119:44 - so we have resized this image and this
119:47 - image which are of different sizes to
119:50 - the same size and now let's run the code
119:53 - once again and now you will see
119:56 - that these two images
119:58 - are merged now okay so you will be able
120:02 - to see the hand here and little bit foot
120:05 - and here the ball of ah this image one
120:11 - which is messy five and then we have the
120:14 - second image which is opencv which is
120:17 - added to the first image so this is how
120:21 - you can add two image
120:23 - using opencv now there is one more
120:26 - method which is called add weighted okay
120:29 - so this add method is going to just add
120:33 - these two images but if you want to add
120:35 - the weight for example you want to give
120:37 - the weight 90 to the first image and 10
120:40 - percent to the second image there is one
120:42 - more method so let's go to the
120:44 - documentation once again and there is
120:46 - this method called add weighted method
120:49 - okay so this add weighted method takes
120:52 - uh
120:54 - several arguments here you can see first
120:56 - is the source of the first array and
121:00 - second argument is the alpha value Alpha
121:03 - is the weight which you want to give to
121:06 - the first image Okay the third argument
121:09 - is the source two so in our case this
121:12 - will be the image two the fourth
121:14 - argument is the beta beta is the weight
121:17 - which you want to give to the second
121:20 - image right so this weight you can can
121:23 - give from 0 to 1 anything and this gamma
121:28 - is the scalar value which you want to
121:30 - provide and this the second last
121:33 - parameter is the destination and the
121:36 - last is the D type or the data type here
121:39 - okay so this is the formula which ah
121:42 - this method is going to use so Source
121:47 - multiplied by Alpha and Source 2
121:50 - multiplied by Beta plus gamma so this is
121:53 - the method which will be used using
121:56 - these arguments or simply you will use
121:59 - this kind of methods Source multiplier
122:01 - by Alpha plus Source 2 multiplied by
122:05 - Beta plus gamma which is the scalar you
122:07 - can add to the image okay so let's use
122:11 - this method so I'm going to just copy
122:13 - this method and then comment this and go
122:17 - to the next line and instead of using
122:19 - add I'm going to use the add weighted
122:23 - method okay so the first argument is the
122:26 - source which is the first source which
122:29 - is IMG in our case second argument is
122:31 - the weight so first this is the messy
122:35 - image right so we want to just give the
122:39 - weight here 90 or you can just give 0.9
122:42 - here and for the second image we want to
122:45 - give the weight uh 0.1 okay so the sum
122:50 - of this weight and this weight will be
122:54 - one and also we are going to give the
122:56 - gamma value here as 0 so we don't want
122:59 - to add any scalar value to uh this add
123:03 - weighted method so the next value here
123:06 - will be 0 which is the value of gamma
123:08 - and let's run this code and you can see
123:10 - now
123:11 - now we have our messy image which is
123:15 - dominant here because it has the weight
123:17 - 0.9 which is 90 percent of the 2 and the
123:22 - opencv image have the weight 0.1 which
123:25 - is 10 percent of the two okay so the
123:30 - opencv image is light and the messy
123:32 - image is a little bit uh you know
123:36 - dominant here you can just give 0.5 and
123:40 - 0.5 so the weight of the two images will
123:43 - be the same and now you will see those
123:46 - two images in the same domination okay
123:50 - so 50 50 percent now let us say we want
123:53 - to increase this value of open CB to 0.8
123:56 - and the messy image weight will be 0.2
124:00 - then the dominant image here will be
124:03 - open CV and in the background kind of
124:06 - thing you will see this messy image so
124:09 - this is how you can add two images with
124:11 - the are weight and the scalar and that's
124:15 - it for this video so in this video you
124:17 - have seen some of the basic operations
124:19 - on the images and some of the arithmetic
124:23 - operations on the images which you can
124:26 - do using opencv in this video we will
124:29 - talk about bitwise operations on images
124:32 - using Python and opencv
124:36 - so bitwise operations can be very useful
124:39 - when working with masks
124:41 - masks are binary images that indicates
124:45 - the pixel in which an operation is to be
124:49 - performed
124:51 - so let us see how we can perform bit
124:54 - wise operations on images so to start
124:58 - with I have here one image which is
125:03 - image underscore one dot PNG file and
125:06 - let me show you the image also so this
125:09 - image is half black and half wide
125:12 - now the second image I'm creating using
125:15 - numpy so first of all I have used NP dot
125:19 - zeros and I'm just creating this image
125:22 - with the same Dimension as this image
125:25 - underscore 1 is having so 250 comma 500
125:30 - is the dimension of this image and the
125:34 - number of channels are three and this
125:37 - code is going to create a black image as
125:40 - you might already know from our previous
125:43 - videos
125:44 - now this code is just creating a white
125:50 - rectangle inside the black image which
125:54 - we got from numpy's zeros array okay so
125:58 - this is the dimension of the rectangle
126:00 - inside your black image and the color of
126:04 - the rectangle will be white because this
126:08 - is 255 comma 255 comma 255 and we are
126:14 - taking thickness as minus 1 that means
126:16 - your rectangle will be filled with white
126:19 - color
126:20 - now here I am just showing both the
126:24 - images using I am show method and this
126:26 - code you might already know what this is
126:29 - doing from our previous videos so let me
126:33 - run this code and let's see what happens
126:35 - first of all so when we run this code
126:38 - you will see first image is this one
126:43 - which we have created using the numpy is
126:46 - zero so this is IMG one and this is the
126:50 - black image and we are just creating a
126:53 - white rectangle inside this numpy zeros
126:57 - image and this is the second image which
127:00 - is half black and half wide
127:04 - now we want to perform some bit wise
127:08 - operations on these two images so let's
127:12 - see how we can perform these bitwise
127:14 - operations on these two images
127:16 - so to perform these bitwise operations
127:20 - we have some methods inside the opencv
127:25 - Library so the first method will be bit
127:29 - and so I am going to just create a
127:31 - variable called bit and with let's say
127:35 - like this and the method inside opencv
127:40 - is CV2 dot bit wise underscore and
127:45 - so this bitwise underscore and takes
127:49 - several arguments as you might see here
127:51 - the source of the first image the source
127:55 - of the second image and the destination
127:58 - which is none by default and The Mask
128:01 - which is also optional so we are going
128:05 - to just provide our images here so I am
128:07 - going to provide the
128:09 - img2 here first of all as the first
128:12 - argument and the second image will be
128:14 - IMG one and once we perform this bitwise
128:20 - and operation on these two images we are
128:24 - going to show the result in the form of
128:27 - Windows I am going to create one more
128:29 - window which is CB2 dot I am show and I
128:34 - am going to name this window as let us
128:38 - say bit
128:40 - and and the second argument will be our
128:44 - variable bit and which we got from the
128:48 - operation bitwise and on these two
128:50 - images so let's run this code once again
128:53 - and let's see what happens so now as a
128:56 - result we have the third image so let me
128:59 - just open all the images so this is our
129:02 - first image this is the second image and
129:06 - the last one is the result which is the
129:09 - bit and operation on these two images so
129:13 - now you might already know how the
129:15 - logical end works but those of you who
129:19 - might not know how the logical and works
129:23 - let me show you the truth table of
129:26 - logical and so this is the truth table
129:30 - of logical end and if the input a and
129:35 - input v b is 0 then we get the result 0
129:41 - okay if input a and input B either of
129:46 - them is 0 then also we get zeros right
129:51 - the result one we will only get when
129:54 - both the sources are one so A and B are
129:59 - 1 then only we will get a 1 in case of
130:03 - and logic so same and logic will work
130:07 - here so this is the zeros array right so
130:13 - we have created this black region from
130:15 - the zeros so here in these images black
130:20 - is performing as zeros and white part is
130:25 - performing as 1. so when 0 and 0 the
130:31 - result will be 0 right so from this
130:35 - truth table we have seen when the input
130:38 - is 0 and 0 the result is 0 same here we
130:43 - are seeing so when the image is black
130:46 - and black we get the result black when
130:49 - the input is white and black this means
130:51 - 0 and 1 the result will be once again 0
130:55 - using the logical end but when the input
131:00 - will be white and white that means 1 and
131:03 - 1 the result will be wide that means the
131:08 - 1 okay so the only reason region white
131:12 - here is the result of this white and
131:15 - this white and the resulting image you
131:18 - can see here and all the other part is
131:22 - black because the and operation on 0 and
131:26 - 0 is 0 and 0 and 1 is also 0. so this is
131:32 - how bit wise end Works let's see how
131:36 - bitwise R and other operation works so
131:40 - I'm going to just comment this code and
131:42 - now we are going to just create the
131:46 - bitwise or operation so for that I'm
131:51 - going to just instead of writing bit and
131:54 - I'm going to just write bit or and
131:57 - instead of bitwise and we are going to
132:00 - just write bit wise or here and then we
132:05 - will simply call this image using I am
132:09 - show method so we are just calling here
132:13 - bit or
132:15 - now let's run the code once again and
132:18 - let's see the result
132:20 - so you can see the result here so let's
132:23 - see the truth table so in the logical or
132:26 - if only one input is 1 then the result
132:30 - will be 1. so either A or B is 1 or both
132:34 - are 1 then the result will be 1 and if
132:38 - both inputs are 0 then the result will
132:41 - be zero so same you will be able to see
132:44 - here so when
132:47 - the First Source and the Second Source
132:50 - is zero the result is zero but when the
132:56 - First Source and Second Source is one or
133:00 - white the result is white when the First
133:04 - Source and the Second Source is 0 and 1
133:08 - or black or white the result is once
133:11 - again 1 or white here okay so this is
133:14 - how the logical R works on the image now
133:19 - let us see how the xor operation work on
133:24 - those images so I'm going to once again
133:27 - comment this code and this time I'm
133:31 - going to just perform the xor operation
133:34 - on these two images
133:43 - and now we are going to run this code
133:47 - once again and you will see this kind of
133:50 - result so once again let's see how the
133:54 - axon logic works so when both the inputs
133:59 - are 0 or both the inputs are 1 then we
134:04 - will get the 0 and if either A or B is 1
134:09 - then only we will get the result one so
134:13 - same you will be able to see here so
134:16 - when both
134:18 - first and second source is 0 the result
134:21 - is 0 when both this first and second
134:26 - source is one you can see here and here
134:29 - the result is once again 0 here right
134:33 - but when the input is 0 and 1 result
134:36 - will be 1 and in this case also the
134:40 - black and white will result in the white
134:43 - image which is The Logical xor operation
134:47 - so once again let us close this and now
134:51 - let me show you how the not operation
134:55 - work so I'm going to just comment this
134:58 - code and then I'm going to just use the
135:02 - bitwise knot so here bit
135:06 - not let us say we will perform the bit
135:09 - not on the first image and the second
135:12 - image so I'm going to just write a bit
135:15 - not on the first image because it only
135:19 - takes one argument bit not is just the
135:23 - opposite of the source so if you get the
135:27 - input 0 then the result will be 1 if you
135:31 - have the input 1 the result will be zero
135:34 - so the opposite of the input so let's
135:38 - perform this operation on image 1 and
135:41 - image two and let's comment this code
135:44 - and we are going to just show these two
135:48 - result Windows using the I am show
135:51 - method and also I need to change
135:55 - this name otherwise we will
135:59 - phase problems and here also I haven't
136:02 - changed the name of these I am show
136:05 - windows so let's change the name of
136:09 - these windows and let's run the code
136:11 - once again and now you will get these
136:14 - results
136:15 - so we will get the first result so the
136:20 - first bit not one is the not of the
136:24 - first image and bit not 2 is the not
136:29 - operation on the second image so you can
136:31 - see wherever we have white we got black
136:34 - and wherever we have black we got white
136:37 - so just the opposite of the input here
136:41 - also wherever we have the black region
136:43 - we got the white ah image here and
136:46 - wherever we have the
136:48 - white pixel we got the black pixel so so
136:52 - this is how bitwise not operation works
136:54 - on the images so these are some of the
136:58 - bitwise operations which you can perform
137:01 - on your images and as I said bitwise
137:05 - operations can be very useful when
137:07 - working with masks which we will see in
137:10 - the later videos in this video we will
137:12 - talk about track bars in opencv now
137:16 - track bars are really useful whenever
137:18 - you want to change some value in your
137:20 - image dynamically at runtime
137:24 - so let's see how we can use drag bars in
137:27 - opencb now to start with I have this
137:30 - simple code which you might know what it
137:33 - does so first of all I have imported CV2
137:36 - as a CV and then I'm creating an image
137:40 - using the numpy zeros array with these
137:44 - dimensions and then I'm creating a named
137:48 - window with the name image so this might
137:52 - seem new to you because I haven't
137:54 - created a named window in the previous
137:57 - video so the named window you can use
138:01 - to create a window with a name and this
138:06 - time we have given the named window name
138:08 - as image now in this while loop we are
138:11 - just using this I am show method to call
138:15 - this window and then loading this image
138:19 - inside this named window
138:22 - now you might already know what this
138:25 - code does it just wait for the key and
138:29 - if the key is Escape key then we will
138:33 - break out of this Loop and in the last
138:36 - we are just destroying all the windows
138:38 - which we have created now in order to
138:41 - create a traged bar you just need to use
138:45 - CV and then call a method called create
138:49 - track bar now the first argument here
138:52 - you need to give is the track bar name
138:55 - because you can create multiple track
138:59 - bars in your image window that's why you
139:03 - need to provide the name which is unique
139:06 - to this track bar so I'm going to just
139:09 - give the name to my track bar as B
139:13 - because what I want to do is I want to
139:17 - change the BGR values of the image using
139:21 - the drag bar so the first track bar will
139:25 - change the B Channel values that's why
139:28 - this first argument is the track bar
139:33 - name which is B and the second argument
139:35 - here we will give is the name of the
139:38 - window so that one that is why we have
139:41 - created this named window so that we can
139:44 - provide the name of the window which is
139:48 - image in this case and that is how we
139:51 - know that in which window we need to add
139:54 - the track bar so in the image window
139:57 - which is this one we want to add the B
140:01 - track bar now the third argument here
140:05 - will be the value which is the initial
140:07 - value at which your track bar is set and
140:11 - the next value here will be the count
140:14 - which is the final value you want to set
140:18 - for your track bar
140:20 - now there is this last thing which we
140:24 - want to set here and this is the
140:27 - Callback function which will be called
140:29 - whenever your track bar value changes so
140:33 - here for example I am going to create a
140:38 - callback function called nothing and
140:42 - this callback function definition or
140:45 - signature I'm going to create here so we
140:48 - can just create a callback function with
140:52 - a name nothing and this function can
140:56 - take this value X and this is the value
141:00 - of the current position of your track
141:03 - bar so we will see what it does little
141:07 - bit later and what we are going to do is
141:09 - we are going to just print the value of
141:11 - x so we will know the current position
141:15 - if this track bar is changed so this is
141:19 - the Callback function which will be
141:21 - called whenever your track bar value
141:24 - changes same we will do with the other
141:28 - track bar so we will create the three
141:30 - track bars in the same window with the
141:34 - name V and the next track bar name will
141:38 - be the G and the last track bar name
141:42 - will be R okay so this will be capital r
141:46 - so now let's run this code and let's see
141:49 - what happens when we run this code so I
141:51 - am going to right click and run this
141:53 - script and you can see here inside this
141:58 - named window with the name image we have
142:01 - this black image which we have created
142:04 - using numpy zeros array and now we have
142:07 - three track bars here with BGR names so
142:13 - these track bar values you can change
142:15 - using this scroller and as you can see
142:19 - here let me show you in this terminal
142:22 - whenever you change the value of any bar
142:28 - the corresponding value will be shown
142:31 - here using this callback function and
142:35 - inside this callback function we have
142:37 - the print statement ok a so as I said
142:39 - whenever you change this value this
142:42 - callback function is called and it will
142:44 - print the value of the current track bar
142:48 - okay so for this functionality what we
142:52 - want to do is we want to get the current
142:55 - position of the track bar and because we
142:59 - can change the value of BGR channels
143:02 - from 0 to 255 that's why I have given
143:06 - the range between 0 to 255 to the track
143:10 - bars also so that you can change these
143:14 - BGR Channel values so now in order to
143:17 - get the current value of your track bar
143:21 - first of all we will just check the
143:23 - value of the B track bar so we will just
143:28 - use CV dot get track bar position which
143:32 - is this method get track bar POS
143:36 - and then we just need to get the name of
143:39 - our track bar so let's say we want to
143:42 - check the position of track bar B then
143:46 - we will just say we want to have this
143:49 - track bar position with the name b and
143:53 - the second argument here will be the
143:56 - name of your window so in which window
143:59 - this track bar is present so the our
144:04 - track bar is present inside the image
144:07 - window right so same we will do for the
144:12 - G and R values also
144:19 - now we have the values of b g r channels
144:24 - from the track bar so now we want to set
144:27 - these values to our image so what we can
144:32 - do here is we can just write for example
144:37 - IMG inside these square brackets you can
144:41 - just give this kind of notation and then
144:45 - give the BGR Channel value so I'm going
144:48 - to just write B comma G comma r that
144:51 - means we want to set the current b g r
144:56 - values to this image so let us run this
145:00 - code and let's see what happens now so I
145:02 - am going to run this code and now when I
145:05 - change the blue Channel values you can
145:08 - see this image becomes blue colored
145:12 - right let us bring it to 0 once again
145:16 - and now let's change the value of G so
145:20 - you can see this image color is changing
145:22 - to green and then we can try changing
145:27 - the red color and you can see when it
145:30 - goes to 255 the color of the image is
145:33 - red you can change the values
145:38 - of different track bars and the
145:42 - corresponding color will be displayed in
145:45 - this window here right so you can see
145:49 - the color is changing you can change any
145:51 - track bar here one more example I want
145:54 - to give here is how to add a switch
145:57 - using a track bar so for that I am going
146:01 - to use one variable called switch and
146:06 - then here I can add first of all the
146:11 - name of the switch
146:17 - and in the next line we will once again
146:20 - call CV2 dot create track bar with the
146:25 - name switch okay so now the name of our
146:30 - track bar will be switch
146:39 - so now we have added one more track bar
146:41 - to our named window and now here we will
146:46 - get the current position of this switch
146:50 - track bar so I'm going to name it as s
146:53 - and the name of the window is switch so
146:56 - we will just give the first argument of
146:59 - this get track bar position as switch
147:02 - okay and the window name is image itself
147:07 - so now we can add some condition here so
147:10 - let us say if this position of the
147:13 - switch which we have if this position is
147:17 - equal to 0 because we only have 0 and 1
147:21 - in this last track bar so if this
147:24 - position is equal to 0 what we want to
147:27 - do is we want to set IM G and then in
147:33 - the square bracket this colon and we do
147:36 - not want to change any value so we will
147:38 - say that I am G uh this square bracket
147:43 - colon is equal to 0 which means that we
147:46 - do not want to do anything
147:48 - or in the other condition which is when
147:52 - your track bar is at position 1 then
147:56 - only we want to change the BGR channel
148:01 - of the image okay so let's run this code
148:04 - and let's see what happens so I am going
148:07 - to run this code and now you can see ah
148:10 - the position of this track bar switch is
148:15 - zero and when I change it to 1 so let us
148:19 - change this position to one you can see
148:21 - the value to 1 and when this position is
148:26 - at 0 you can change anything here any
148:29 - track bar nothing happens because this
148:33 - condition is met which means that we
148:36 - don't want to do anything as soon as we
148:38 - change the switch to 1 that means we
148:41 - want to change the BGR values you can
148:44 - see this color is changed inside the
148:48 - image so the 0 is just like off switch
148:53 - so we do not want to change any color
148:56 - and one is like on switch so when it's 1
149:01 - the value of RBG channels can be changed
149:06 - now I want to give one more example of
149:08 - track bar to use so that's why I have
149:10 - created one more file which is python
149:13 - opencv track bar example two and this
149:16 - time I'm going to use just two track
149:19 - bars here so that's why I'm going to
149:21 - delete some of the code here so using
149:25 - the first track bar let's say I want to
149:27 - just change some values inside our image
149:30 - and I want to print that value on that
149:33 - image so let's say now our range is
149:37 - between 10 to 400 okay so the lower
149:41 - range is 10 and the upper range is 400
149:44 - and using this track bar I want to to
149:48 - print the current value on our image and
149:52 - also I want to have a switch which I can
149:55 - toggle and I want to change the color of
149:59 - the image from the colored value or
150:02 - colored image to the grayscale image
150:07 - so now our switch is between color to
150:10 - the grayscale image now in here what we
150:13 - want to do is we want to just assign
150:16 - this IM show value to the image variable
150:20 - itself and then we want to get the
150:22 - current position of the track bar so we
150:25 - will use this method to get the current
150:29 - position of the track bar and I am going
150:31 - to name this current position as POS
150:34 - variable and the name of this track bar
150:38 - let's change this name to something else
150:41 - let us say CP for current position and
150:45 - also here CP for the current position
150:49 - and the name of the named window is
150:52 - image itself so we are not changing it
150:54 - so now we have the current position so
150:58 - first of all we will just create the
151:01 - font and then we will just use the CV
151:06 - Dot put text method you already know
151:09 - what this method does it just print the
151:13 - text on your image and then we will
151:15 - provide the parameters first argument is
151:18 - the image the second argument is the
151:21 - value which we get from the track bar so
151:25 - this is the position and because it is a
151:27 - number we need to convert it to the
151:29 - string using Str method and then the
151:33 - position at which you want to show this
151:36 - text so let's say it's 50 comma 150 and
151:41 - then next is the font so I am going to
151:44 - just give the font and then the next
151:46 - value is the font scale which is 4 and
151:50 - the next value is for the color of the
151:55 - text so let us say the color here will
151:57 - be 0 comma 0 comma 255 and this should
152:01 - be C V Dot font Hershey complex let's
152:05 - change this font all also let us say
152:08 - this is just the Simplex font okay so
152:12 - this code is going to just print the
152:15 - color current position of the track bar
152:16 - on your image and then inside this
152:20 - condition what we want to do is we want
152:23 - to get the switch value so let's use
152:28 - this s variable and then get the current
152:30 - position of the switch using this switch
152:35 - name from the image window and then if
152:38 - the switch is at zero position then we
152:42 - want to do nothing so we will just pass
152:45 - this situation and in case the value of
152:50 - this switch is 1 then what we want to do
152:53 - is we want to change the image value
152:56 - from color to the grayscale value right
153:00 - so you can just write CV dot CVT color
153:07 - and the first argument is the image
153:10 - which we are loading and the second
153:12 - argument is CV dot color BGR to gray
153:16 - which is to convert this colored image
153:19 - to grayscale image but you can see here
153:21 - we are just creating a black colored
153:24 - image and in our project we also have
153:27 - this image so let's read this image so I
153:30 - am going to just write CV dot IM read
153:34 - and then give the name of the image
153:37 - which is Lena dot jpg so this is our
153:41 - colored image and this way we will be
153:44 - able to see ah the change of color to
153:48 - gray scale image in a better way so let
153:51 - us run this code and let's see what
153:52 - happens and you can see image appears
153:56 - and disappears and there is an error so
154:00 - let's see what is the error so the error
154:02 - here is coming from this line so we need
154:05 - to read this image inside the while loop
154:09 - ok so this is why our error is coming
154:14 - and at the last we want to load this
154:18 - image after this if condition okay so
154:22 - now let's run this code once again and
154:26 - you can see this value is printed on our
154:31 - image which is 10 which is the value of
154:33 - CP and if we change this value it is
154:37 - changing on our image also right and
154:41 - once we change this 0 to 1 then our
154:45 - image is converted from colored image to
154:49 - the grayscale image you can also change
154:53 - the font size here for example let us
154:57 - say its 6 here and the thickness also if
155:01 - you want to change you can change it
155:03 - using this parameter let us say its ah n
155:07 - and let's run this code once again you
155:11 - can see the thickness and the size of
155:14 - the font is changed and you can see this
155:17 - value in a better way okay so this is
155:20 - how you can use track bars in opencv in
155:24 - this video we will see how we can
155:26 - perform object detection using HSV color
155:30 - space
155:31 - now we have already seen how to work
155:33 - with BGR or colored images or gray scale
155:38 - images and we have already seen how we
155:42 - can convert from colored images to
155:45 - grayscale images
155:46 - so there are more than 150 color space
155:49 - conversion methods in opencv and one of
155:54 - them is colored image to HSV image now
155:58 - what is HSV color space
156:00 - so HSV stands for Hue saturation value
156:05 - so H stands for Hue as for saturation
156:08 - and V for the value now generally r g b
156:14 - in RGB color space are all correlated to
156:19 - the color luminance that is what we
156:22 - Loosely call intensity in other words we
156:26 - cannot separate color information from
156:29 - luminance so HSV or hue saturation value
156:34 - is used to separate image luminance from
156:39 - color information so this makes it
156:42 - easier when we are working on or we need
156:47 - luminance in our images that is why
156:50 - generally we use HSV in the situation
156:53 - where color description plays a very
156:56 - important role now as I said HSV stands
157:00 - for huge saturation and value but what
157:03 - is the meaning of each and every single
157:06 - word in HSV now HSV is also known as the
157:11 - hex con color model so this color space
157:16 - can be described in this kind of
157:18 - cylindrical cone model where Hue is this
157:25 - circular angle which varies from 0 to
157:29 - 360 and hence just by selecting the
157:33 - range of hue you can select any color so
157:36 - you can see different colors are
157:39 - available at different angles so these
157:43 - colors are basically red yellow green
157:46 - cyan blue and magenta so Hue is this
157:52 - angle in this cylindrical cone now we
157:56 - have saturation so the saturation is
157:58 - amount of color that is the depth of
158:02 - pigment or the dominance of hue and this
158:06 - value is described from the center
158:10 - towards the outer layer of this
158:15 - cylindrical cone so you here you can see
158:18 - at the center this saturation start at 0
158:21 - and it can go up to 1 at the end of this
158:26 - cylindrical cone and this saturation can
158:29 - be increased from zero to hundred
158:31 - percent
158:32 - similarly the value is basically the
158:35 - brightness of the color so this
158:37 - brightness can be increased from 0 to 1
158:40 - from the bottom of the cone to the top
158:43 - of the cone so all these three value Hue
158:47 - saturation and value can be used to pick
158:51 - any color as we can do with the BGR
158:55 - color space so this is the brief
158:58 - introduction about HSV color space and
159:01 - now let's see how we can use this HSV
159:04 - color space to detect an object in an
159:08 - image so here I have this simple code to
159:12 - load an image using I am read method and
159:15 - show it inside a window so by now you
159:18 - might already know how this code works
159:21 - so let's run this code and let's see
159:23 - what does this code do so I have this
159:27 - image which is called smarties.png and
159:30 - here are some circles in different
159:33 - colors so we have blue circles or green
159:35 - or red orange and brown circles here
159:39 - inside this image so let us say we
159:42 - somehow want to detect only the blue
159:45 - circles or balls or green circles or
159:48 - balls how can we just detect only these
159:52 - balls let us say we just want to detect
159:55 - the green balls how can we achieve this
159:59 - using opencv we are going to see this
160:02 - using this HSV object detection and here
160:06 - we have one more window which is the
160:08 - cracking window which is coming from
160:11 - this code which is CV2 dot named window
160:15 - and the name of the window is tracking
160:18 - so this tracking window we are going to
160:20 - use little bit later when we will add
160:23 - the track bars to our image but let us
160:27 - say we want to use this image and detect
160:30 - these colored balls so first of all ah
160:35 - after this image is read what we want to
160:38 - do is we want to convert our colored
160:41 - image into our HSV image and by now you
160:45 - might already guess how to convert an
160:48 - image you can just write HSV is equal to
160:51 - CV2 dot CVT color and then your frame
160:57 - name which is frame in this case and
160:59 - then CV 2 dot whatever color space you
161:04 - want to convert from and whatever color
161:06 - space you want to convert to so you can
161:09 - just write color underscore BGR to HSV
161:13 - so this is the property we are going to
161:15 - use now in the next step we will
161:17 - threshold the HSV image for a range of
161:21 - blue color so we are going to just
161:23 - Define l underscore B for lower blue
161:27 - color and then we are going to use the
161:30 - numpy array so NP Dot dot array and
161:35 - inside this array we are going to define
161:37 - the lower range of blue color Now by
161:40 - experience I know that these HSV value
161:43 - for lower blue color will be 110 comma
161:47 - 50 comma 50 right but you might not have
161:53 - every time the idea what is the lower
161:56 - color range or the upper color range of
161:59 - some color so that is why later in this
162:02 - video we will use the track bar in order
162:05 - to perfectly Define the lower and upper
162:08 - values for this HSV color space right so
162:14 - right now I am just going with my
162:17 - experience so for the upper value I'm
162:19 - going to define the next variable which
162:20 - is u b is equal to NP dot array and then
162:26 - once again I am going to Define
162:28 - these three ah color channels which is
162:32 - 130 com 255 comma 255 so this will be
162:37 - the upper limit for the blue color for
162:40 - our HSV image now in The Next Step what
162:43 - we are going to do is we are going to
162:44 - threshold the HSV image to get only the
162:48 - blue color let's say so I am going to
162:50 - just Define a variable called mask here
162:53 - and then I am going to use CV2 dot in
162:58 - range method where I will provide first
163:01 - of all my HSV variable or image and then
163:06 - I will provide the upper and lower range
163:09 - for this function so my lower range is
163:15 - this numpy array for the blue color so I
163:17 - am going to just say l underscore B is
163:21 - my lower range and U underscore B is my
163:25 - upper range now we have already seen how
163:27 - we can use bitwise and or bitwise
163:30 - operations on images so what we are
163:34 - going to do next is we are going to
163:36 - Define a variable called res and then we
163:40 - will just call CV2 Dot bitwise and to
163:46 - mask the original image so here the
163:48 - first value will be our frame which
163:51 - which is the colored frame right so this
163:54 - is the frame which we have read from
163:58 - this image which is the smarties image
164:00 - so this is The Source One Source 2 will
164:03 - be the same so the frame itself will be
164:07 - the source two and what we want to do is
164:09 - we want to provide the mask of the lower
164:14 - blue color and the upper blue color
164:16 - values right so here we can just say
164:19 - mask is equal to whatever mask variable
164:24 - we have created so this is the attribute
164:27 - we can set in order to apply the mask
164:30 - for the Lower Blue value and the upper
164:33 - blue values so once we have this result
164:37 - frame what we can do is we can use this
164:41 - CV2 dot IM show method in order to show
164:46 - The Mask let us say so we are going to
164:49 - show the mask and we are going to show
164:51 - the result using res variable so this is
164:55 - going to open three windows and let's
164:58 - see what happens when we run this code
165:01 - so we are going to run this code and
165:03 - this opens three Windows here and now
165:07 - you can see the mask first of all so we
165:10 - are just detecting the blue colored
165:14 - balls using this mask that's why we have
165:18 - defined the lower boundation of the blue
165:22 - color and the upper boundation of the
165:24 - blue color right so that's why it's only
165:27 - detecting you can see the blue uh ball
165:31 - is here here and here and here also you
165:35 - can see the mask also detects only the
165:39 - blue values here right and then in the
165:43 - result you can see when we have applied
165:46 - this mass and we have masked all the
165:49 - other things other than the blue colored
165:52 - ball you can see only the blue balls
165:56 - here so the same method you can apply to
165:58 - detect any other colored ball from this
166:02 - image now as I said it's not easy to
166:05 - detect ah these lower and upper
166:08 - boundation for the colors so that's why
166:12 - you can use the track bar for adjusting
166:16 - these lower and upper boundation of any
166:19 - color so for that what we are going to
166:22 - do is for first of all we will create a
166:25 - named window and then we are going to
166:28 - create a new window which we will use to
166:31 - adjust the lower and upper boundation of
166:34 - HSV values so now I'm going to just use
166:39 - a
166:40 - CV2 dot we have already seen how to
166:43 - create a track bar so I'm not going to
166:46 - explain in detail how this works but let
166:49 - us say this track bar name is lure Hue
166:54 - for LH okay so this is the lower Hue
166:57 - value and then the name of the window
167:01 - which is tracking which is this one so
167:03 - we are going to provide the name of the
167:06 - window and the next argument will be the
167:10 - starting and the ending value so we are
167:12 - going to define the start value 0 and
167:16 - the end value let us say we are going to
167:18 - define the 255 here okay and the last
167:23 - thing we want to give here is the
167:25 - Callback function which I have already
167:27 - created which is this function which is
167:31 - ah just doing nothing we are going to
167:34 - just provide this callback function as a
167:38 - dummy function so it is not going to do
167:40 - anything so this is the track bar for
167:42 - the lower Hue value similarly we are
167:45 - going to define the track bar for lower
167:48 - saturation and lower value and upper
167:52 - saturation upper value and upper Hue
167:55 - okay so this will be lower saturation
167:58 - this will be lower value and then this
168:02 - will be u h which is upper Hue and then
168:07 - this will be u s for upper saturation
168:10 - value and this will be upper value right
168:14 - so HSV lower values and HSV upper values
168:19 - so here we are going to set the initial
168:22 - value you for the upper value so let us
168:24 - say everything is set to the maximum so
168:27 - 255 255 and 255 here okay so the lower
168:33 - values are set to zeros and upper values
168:36 - will be set to 255. now you already know
168:40 - how to get the values from attack track
168:43 - bar so you can use for example L
168:47 - underscore H for the lower Q values is
168:51 - equal to CV2 dot get track bar position
168:55 - so just use get track bar position
168:58 - method and then first of all give the
169:01 - name of the track bar from which you
169:03 - want to get the position so let us say
169:05 - we want to get the position from the l h
169:09 - track bar and then the name of the
169:11 - window which is tracking in our case so
169:14 - here is the second argument and
169:18 - similarly what we are going to do is we
169:20 - are going to define the other low lower
169:23 - values and upper values so
169:31 - and also the name of your track bars
169:38 - so once you have the values of lower HSV
169:42 - and upper HSV you can provide these
169:45 - values here in place of these static
169:48 - values so first element of this array
169:52 - will be LH and then the ls variable and
169:57 - then the L variables similarly for the
170:01 - upper boundation we will provide these
170:04 - three upper boundation variables
170:07 - and now when we will run our code let's
170:11 - see what happens so we are running our
170:13 - code and you can see
170:17 - these uh Windows these three Windows one
170:20 - is the mask
170:22 - other is the result and the third one is
170:25 - the frame and we also have these track
170:28 - bars in order to change the value of
170:31 - lower and upper HSV values so first of
170:35 - all let's set this mask for the blue
170:37 - color so I am going to just move it to
170:41 - 110 as we have done in the last step and
170:47 - then this will be around 50
170:50 - and this also will be around 50 okay so
170:54 - let us move it to 50 and upper value
170:57 - here will be around 130 right so you can
171:01 - see once again using this track bar it's
171:04 - easier to adjust these lower and upper
171:08 - boundation and now you can see all the
171:10 - three blue colored balls so you can
171:13 - refine this object detection by moving
171:17 - these track bars little bit left or
171:20 - little bit right you can see here now
171:22 - let's adjust this value to detect some
171:26 - other balls so let us say we want to
171:28 - detect the green balls so let's see what
171:32 - happens when we just change the
171:35 - saturation values here and you can see
171:38 - now you almost see the green values and
171:43 - the blue color is almost
171:46 - disappearing so you can see now there
171:49 - are only green ah the balls which are
171:52 - detected and all the other balls are
171:55 - masked so you just need to play with
171:58 - this track bar for the lower HSV values
172:02 - and the upper HSB values and you will be
172:05 - able to detect the object whatever
172:06 - colored object you want to detect from
172:09 - the image
172:10 - now this is the object detection from
172:13 - the image similarly we can use the same
172:17 - method in order to track an object from
172:21 - a live video so I'm going to just escape
172:25 - to just close all the windows and in
172:29 - order to change this code for the video
172:33 - input what we can do here is we can just
172:37 - add this code so so we are going to just
172:40 - add the cap variable which is the
172:43 - capture variable is equal to CV2 dot
172:46 - video capture so we are going to use
172:49 - this one and we are going to ah capture
172:52 - the video from our default camera which
172:54 - is at the index 0 and then you already
173:00 - know how we can read the values from the
173:04 - camera input so I'm going to just
173:06 - comment this code and instead of reading
173:10 - the image image what we are going to do
173:12 - is we are going to write underscore
173:16 - comma frame is equal to cap dot read
173:22 - which is going to read the frames from
173:26 - your default camera and at the end when
173:29 - you are done playing with your images
173:31 - you can just destroy this cap using the
173:36 - release method so you can just write cap
173:38 - dot release just going to release all
173:41 - the cameras you are just capturing right
173:45 - so now this is the three line code you
173:48 - need to use in order to capture the
173:52 - camera input and then track any uh
173:55 - object of any color so I am going to run
173:59 - this code now and you can see I am just
174:03 - holding a blue colored object here and
174:07 - I'm moving this object on the left and
174:10 - right light and you can see only blue
174:12 - colored object is detected and every
174:16 - other frame value is masked so this is
174:19 - how you can do the object tracking of
174:23 - any color using the HSV color space so
174:26 - you can see the real image which is
174:29 - captured from the camera and then the
174:32 - mask and then the result of the mask and
174:35 - the real image in this blue colored
174:39 - object tracking so this is how you can
174:42 - do object detection and object tracking
174:45 - using HSV color space in this video we
174:49 - will see how we can perform simple
174:51 - thresholding on images using opencv
174:56 - so first of all what is thresholding
174:59 - so thresholding is a very popular
175:01 - segmentation technique used for
175:05 - separating an object from its background
175:08 - the process of thresholding involves
175:11 - comparing each pixel of an image with a
175:16 - predefined threshold value and this type
175:19 - of comparison of each pixel of an image
175:23 - to a threshold value divides all the
175:26 - pixels of the input image into two
175:29 - groups
175:30 - so the first group involves pixels
175:34 - having intensity value lower than the
175:36 - threshold value and the second group
175:39 - involves the pixels having intensity
175:43 - value greater than the threshold value
175:45 - and using the different thresholding
175:48 - techniques which are available in opencv
175:52 - we can give different values to these
175:56 - pixels which are higher than the
175:59 - threshold value and which have the
176:01 - intensity lower than the threshold value
176:05 - so let's see how we can use Simple
176:08 - thresholding techniques on an image so
176:12 - to start with I have this simple code
176:14 - which loads an image on a window and
176:19 - this image is called gradient dot PNG so
176:22 - let me show you how this image looks
176:25 - like so this image looks like this so as
176:29 - you can see in this image we have on the
176:32 - left hand side the black values and when
176:35 - we gradually move from left to right we
176:38 - move towards the wide value so on the
176:42 - left hand side the pixel value are
176:46 - closer to zero and on the right hand
176:50 - side the pixel values are closer to 255.
176:55 - so now we are going to ah just involve
176:59 - some thresholding techniques and we will
177:03 - see how these this image is affected by
177:07 - the thresholding techniques so first of
177:09 - all what we are going to do is we are
177:11 - going to ah Define two variables one is
177:14 - underscore because the result of the
177:17 - thresholding gives two result one is ret
177:21 - value and the second is the thresholded
177:25 - value of an image so I'm going to just
177:29 - say the second value which is given by
177:33 - the thresholding technique is
177:35 - th1 is equal to CV Dot threshold and
177:41 - this threshold method takes several
177:44 - values the first is the source so our
177:47 - source is image the second is the
177:51 - threshold value so as we I have seen
177:55 - that our image have on the left hand
177:58 - side 0 pixel value and when we move
178:02 - towards the right its pixel value
178:06 - increases to 255 right so let us say our
178:10 - threshold here is
178:12 - 127 and the maximum value of the
178:16 - threshold is 255 which is the white
178:19 - color on the right hand side and then
178:22 - the fourth value here will be the
178:26 - threshold type so there are several
178:29 - threshold type in simple thresholding we
178:33 - are going to see them one by one so the
178:36 - first thresholding type is CV2 dot
178:40 - thresh binary so first of all let me
178:43 - show you how the result looks like and
178:46 - then I will explain what does this trash
178:49 - binary type does so what we are going to
178:54 - do is we are going to use one more CV2
178:56 - dot I am show method to show this
178:59 - thresholded value into a new window so
179:04 - we are going to just show this value
179:07 - into a new window and we already have
179:09 - the original image in the image window
179:13 - so let's run this code and let's see
179:15 - what happens so you can see in this
179:18 - binary thresholding we are comparing
179:21 - each and every pixel of this original
179:24 - image to 127 and if the value of the
179:30 - pixel is less than 127 the value is
179:34 - assigned to 0 and if the value of the
179:39 - pixel is greater than 127 the pixel
179:43 - value is assigned 255 that means wide so
179:47 - if the value of the pixel is 0 it will
179:51 - look black and if the value of the pixel
179:54 - is 255 it will look wide so this is how
180:00 - binary thresholding works and by the
180:03 - name itself you can understand that this
180:07 - is just a binary thresholding so it is
180:11 - either 0 0 or 1. now let us see the
180:15 - other type of thresholding technique so
180:18 - now I will just change the name of this
180:21 - variable as th2 and the next type of
180:25 - thresholding is called thresholding
180:28 - binary inverse and as the name suggests
180:32 - the thresholding binary inverse is going
180:35 - to give the inverse result of what you
180:39 - get from the trash binary so I am going
180:43 - to once again
180:45 - use the IM show method to show the
180:48 - result of this thresholding binary
180:52 - inverse value and let us run the code
180:55 - and let's see what happens so this is
180:57 - the original image and then we have the
181:01 - thresholding one image and the
181:03 - thresholding inverse image so this image
181:07 - you got from the first thresholding
181:10 - which is by using trash binary and the
181:14 - second image you got from this method
181:16 - which is trash binary inverse and this
181:20 - trash binary inverse image is just the
181:24 - inverse of what you get using the thresh
181:28 - binary so if the pixel value is lower
181:32 - than 127 which is our threshold the
181:36 - pixel is assigned 255 otherwise if the
181:41 - value is greater than 127 then the pixel
181:44 - value is assigned Find 0 which is the
181:47 - inverse of what we got in the previous
181:50 - step now let us change this threshold to
181:54 - let's say 50 and here also let us say we
181:58 - change this threshold to 200 and let's
182:02 - see how this result changes when we
182:05 - change the threshold value so I am going
182:08 - to run this code once again and you can
182:10 - see this is the result of thresh binary
182:13 - and now because our threshold is up to
182:18 - 50 that's why our result is like this so
182:23 - until the pixel value is 50 its black
182:28 - otherwise if the pixel value is greater
182:31 - than 50 it is going to give you the
182:34 - white ah pixel value and the thrash
182:37 - binary inverse is going to give you the
182:40 - inverse value of what you get in the
182:43 - thresh binary step so I'm going to once
182:46 - again just close these windows and let's
182:50 - see the next
182:51 - thresholding type so I am going to name
182:54 - my variable as th3 so the next
182:58 - thresholding type is called trash trunk
183:01 - so this is this type and let's first of
183:06 - all see what is the result of this
183:10 - thresholding technique and then I'm
183:12 - going to explain what it does so we are
183:15 - going to just show this
183:18 - thresholded image into a new window and
183:22 - run the code and now we have the result
183:26 - so let's move it like this
183:30 - and we have here the original image and
183:34 - the result of the thresh trunk is this
183:37 - th3 so here what happens is up to the
183:41 - threshold the value of the pixels will
183:46 - not be changed so up to 200 because our
183:49 - threshold is up to 200 so when the pixel
183:53 - value is up to 200 the pixel value will
183:57 - not change and after the threshold which
184:00 - is 200 the pixel value will remain the
184:04 - same which is 200 so from here to here
184:07 - the pixel value will remain 200 let us
184:11 - change this threshold to some other
184:13 - value let us say one twenty seven and
184:15 - then let us run this code and you will
184:19 - see that now
184:21 - from black to 127 pixel value the value
184:27 - of this image will not change so
184:30 - original image up to half is the same
184:34 - and after the pixel value
184:38 - 127 the value remains 127 okay so the
184:43 - pixel intensity value will remain 127
184:47 - until the end so if the value is greater
184:51 - than 127 the value will remain 127 and
184:56 - if the pixel value is lesser than 127
185:00 - then the pixel value will remain
185:03 - unchanged so this is how the trash trunk
185:08 - works and let's see the other method
185:11 - which is let us say th4 and this is the
185:18 - method which is called trash 2 0 so we
185:22 - are going to just use trash to 0 and
185:26 - then we are going to open this th4 into
185:30 - a new window
185:32 - and let's run this code and let's see
185:34 - what happens so now we have this result
185:38 - let's move this to the left and the
185:42 - result of the thresh to 0 is this one so
185:46 - in thresh to zero thresholding whenever
185:50 - your pixel value is lesser than
185:53 - threshold the value assigned to pixel
185:56 - will be zero okay so when the pixel
186:01 - value is lesser than the threshold the
186:04 - pixel value is assigned to 0 that's why
186:06 - you can see half of the image is black
186:09 - and when the pixel value is greater than
186:13 - 127 which is our threshold value the
186:17 - image or pixel value will remain the
186:20 - same so after 127 all the pixels will
186:24 - remain the same let's see the other
186:27 - technique which is called trash to 0
186:31 - inverse which you ah already understood
186:36 - I think what it does so this is thresh
186:39 - to zero inverse and we can just change
186:43 - this variable name to th5 and here we
186:48 - can just open it into a new window and
186:51 - I'm going to run this code once again
186:54 - let me move this here and the result
186:59 - here so you can see this thresh to 0
187:03 - inverse is just the opposite of the
187:07 - thresh to zero so if the value of the
187:10 - pixel is greater than the threshold
187:12 - value which is 127 the value will be
187:15 - assigned to 0 otherwise if the value of
187:19 - the pixel is lesser than threshold the
187:22 - value of the pixel will remain the same
187:25 - so this is how some of the simple
187:27 - thresholding techniques Works in opencv
187:32 - in the last video we have seen how we
187:34 - can perform simple thresholding in
187:36 - opencb using python using various
187:39 - thresholding techniques so we have used
187:42 - trash binary trash binary inverse thresh
187:46 - trunk trash to zero tries to zero
187:49 - inverse so these were all the simple
187:51 - thresholding techniques
187:53 - now in these thresholding techniques we
187:57 - were setting a global value of our
188:00 - threshold so in this example for example
188:03 - here the global value of threshold is 50
188:06 - here 200 here 127 so we were setting in
188:12 - simple thresholding the global value and
188:15 - this means that it is same for all the
188:19 - pixels in the image
188:22 - now in this video we are going to learn
188:24 - how to use adoptive thresholding
188:28 - so adoptive thresholding is the method
188:31 - where the threshold value is calculated
188:34 - for the smaller region so the threshold
188:38 - is not Global for every pixel but it's
188:42 - calculated for a smaller region and
188:45 - therefore there will be different
188:48 - threshold value for different regions
188:51 - now why do we need this type of adoptive
188:55 - thresholding so using simple
188:57 - thresholding might not be a good idea in
189:01 - all the conditions so there might be
189:03 - conditions where the image has different
189:06 - lighting conditions in different regions
189:09 - and in those cases where the lighting
189:13 - conditions in the images
189:15 - varies from point to point in those
189:19 - cases we might want to use adoptive
189:22 - thresholding so as I said adoptive
189:25 - thresholding calculates the threshold
189:29 - for a smaller region of images so we get
189:32 - different thresholding values for
189:34 - different regions of the same image and
189:37 - as a result adoptive thresholding gives
189:41 - us better results for images with
189:44 - varying illumination so let me show you
189:47 - the problem with simple thresholding for
189:50 - the image which have different
189:53 - illumination at different regions so I
189:57 - have this image called Sudoku dot PNG
190:00 - which I am loading using I am read
190:02 - method and then I'm just showing this
190:05 - image using IM show method and then let
190:08 - us use the simple thresholding technique
190:11 - which is trash binary for this and we
190:15 - have set the global threshold value of
190:18 - 127 here and then we will see the result
190:23 - after this threshold is applied to the
190:26 - image so I'm going to run this program
190:29 - and let's see what happens so this is
190:32 - our original image and then this is the
190:35 - result which we got so on in the result
190:39 - you can see when we apply a same Global
190:43 - threshold value some of the region of
190:46 - this image is black and other region of
190:50 - this image is visible right so because
190:55 - the image have different elimination
190:58 - value at different regions that's why we
191:02 - see half of the image which have the
191:05 - good illumination and we do not see half
191:08 - of the image which does not have the
191:11 - better illumination so in that case it
191:14 - is a better idea to use adoptive
191:16 - thresholding so let's see how we can use
191:19 - adoptive thresholding so here what I am
191:22 - going to do is I am going to declare a
191:23 - variable called th2 and then we use CV e
191:28 - dot adoptive threshold so this is the
191:32 - method which we are going to use for
191:34 - performing adopting thresholding and
191:37 - this takes few arguments so first is the
191:40 - source so our source is the image
191:43 - variable now the second parameter here
191:45 - is the max value so the max value is the
191:49 - non zero value assigned to the pixels
191:52 - for which the condition is satisfied so
191:55 - in our case the maximum value which we
191:59 - can provide to a pixel is 255 and we
192:02 - cannot go more than that right now the
192:06 - third parameter here is the adoptive
192:10 - method so this adoptive method is going
192:13 - to decide how the thresholding value is
192:16 - calculated and there are two types of
192:19 - adoptive methods which we can use so the
192:22 - first method is called CB2 dot adoptive
192:27 - Thresh mean c so what is the meaning of
192:31 - this adoptive thresh mean underscore C
192:33 - so using this method the threshold value
192:37 - is the mean of the neighborhood area and
192:41 - here is the documentation of these two
192:44 - methods so adoptive thrash mean c gives
192:48 - us the threshold value using this
192:51 - function and this is going to give us
192:54 - the mean of the block size multiplied by
192:57 - block size neighborhood of X comma y
193:00 - minus C which is the constant and the
193:04 - second adoptive threshold type is this
193:08 - one which is adoptive trash gaussian
193:10 - underscore C and in this adoptive
193:14 - thresholding the threshold value is the
193:17 - weighted sum of neighborhood values
193:19 - where weights are the gaussian window so
193:23 - let us use the first adoptive method
193:26 - which is the adoptive thrash mean
193:29 - underscore C now the next parameter here
193:32 - is the threshold type so the threshold
193:35 - type which we are going to use is the
193:38 - thrash binary which we have also seen in
193:40 - the last video also and then the next
193:44 - value is the block size so block size
193:48 - decides the size of the neighborhood
193:51 - area so here we are going to give the
193:54 - block size 11 and the next parameter
193:57 - here is the value of C so we have seen
194:01 - that we need to ah give the value of C
194:05 - also when we use the adoptive thresh
194:09 - mean c and adopt a thrash gaussian C so
194:13 - this is the value of C which we are
194:15 - going to give and C is just a constant
194:18 - which is subtracted from the mean in the
194:21 - case of this adopted thresh mean method
194:25 - or the weighted mean in the case of
194:28 - gaussian adaptive threshold ok so
194:32 - constant we are going to give here is 2
194:35 - and now what we are going to do is we
194:38 - are going to just load this image which
194:42 - we got after applying this adoptive
194:45 - thresholding and let us just comment the
194:49 - other window so we will just see the
194:53 - original image and the adoptive
194:56 - thresholding result so I'm going to run
194:58 - this code and you can see the original
195:02 - image here and the result of adoptive
195:06 - thresholding which looks much better
195:09 - than the simple thresholding technique
195:12 - so let us uncomment this also so I am
195:15 - going to uncomment this so we will see
195:19 - all the three result at the same time so
195:21 - this is the original image and you can
195:24 - see the simple thresholding gives us
195:26 - this value using the global threshold of
195:31 - 127 and adoptive thresholding gives us
195:35 - this value or this image which is much
195:39 - more readable than the simple
195:42 - thresholding technique image so this is
195:45 - how you can use adoptive fresh mean c
195:47 - method in a same way we are going to use
195:51 - the other adoptive thresholding
195:54 - technique which is called adoptive
195:57 - thrash gaussian C so instead of this we
196:02 - are going to use adoptive thresh
196:04 - gaussian C and then
196:07 - all the parameters we are going to leave
196:09 - as same and let's load the result of
196:14 - this type of thresholding which is
196:17 - stored in th3 so let us run this code
196:20 - and let's see what happens
196:22 - so we have already seen this image which
196:26 - is the simple thresholding this is the
196:29 - result of the adoptive thresholding mean
196:32 - c and this is the result of adoptive
196:36 - thresholding gaussian underscore C so
196:40 - both of the result looks good because
196:42 - the adoptive thresholding algorithm
196:45 - calculates the thresholding value for
196:48 - different regions so the thresholding
196:51 - value is not Global for each and every
196:54 - pixel of the image and we have seen the
196:57 - two adoptive methods which are available
196:59 - in adoptive thresholding so in this way
197:02 - you can use adoptive thresholding in
197:05 - opencv in this video we will talk about
197:07 - a library called matplotlib which you
197:10 - can use with opencv images
197:13 - so first of all what is matplotlib so
197:16 - matplotlib is a plotting library for
197:19 - python which gives you a wide variety of
197:22 - plotting methods
197:24 - and on the official website which is
197:27 - matplotlib.org you can see match plot
197:30 - lib is a python 2D plotting Library
197:33 - which produces publication quality
197:36 - figures so it's primarily a 2d plotting
197:41 - library but its widely used with opencv
197:46 - to display graphs and images and
197:48 - histograms so we will see how we can use
197:51 - matplotlib with opencv it's also written
197:56 - here that for simple plotting the pi
198:00 - plot module provides a Matlab like
198:03 - interface
198:04 - so first of all lets see how we can
198:07 - install matplotlib and then we are going
198:10 - to see how to use matplotlib with opencv
198:15 - so to install matplotlib using pip you
198:18 - just need to open your terminal and then
198:20 - just give this command which is PIP
198:22 - install mat plot lib and then press
198:28 - enter
198:30 - and in some seconds this matplotlib
198:34 - Library will be installed using pip so
198:37 - now you can see matplotlab is installed
198:40 - on my Windows operating system and to
198:43 - check it I'm going to just give the
198:45 - python command and here I'm going to
198:48 - import matplotlib so I'm going to just
198:50 - write from matte plot lib import Pi plot
198:58 - as PLT okay and then press enter and if
199:02 - this import does not give you any error
199:04 - that means it's imported successfully
199:07 - and you can start using matplotlib
199:10 - now as we are using pi charm IDE let me
199:14 - show you how you can install matplotlib
199:17 - on pycharm so just open your pycharm IDE
199:21 - and then here just click on file and
199:25 - then settings
199:26 - and then go to Project colon your
199:29 - project name my project name is opencv
199:32 - examples and then click on interpreter
199:35 - and you can see other packages are
199:38 - already there and we just need to
199:41 - install the matplot lib package so just
199:45 - type here in the search matplotlib and
199:49 - you will be able to find matplotlib here
199:51 - in the results so just click on
199:54 - matplotlib and then just click on the
199:58 - install package so I'm going to just
200:00 - click on the install package and in some
200:02 - seconds mat plot lab Library will be
200:04 - installed in your pycharm IDE so you can
200:08 - see this message which says package
200:10 - matplotlab installed successfully that
200:13 - means we can close this window and then
200:17 - you will be able to see matplotlib is
200:20 - available in your project interpreter so
200:23 - everything is fine and I'm going to just
200:26 - close this and now I will be able to
200:29 - import matplotlab so I am going to just
200:32 - write from matte plot lib
200:37 - import Pi plot
200:41 - as PLT now in order to show the image
200:44 - which you read using the opencv I'm read
200:49 - method you can use this code so just
200:53 - write PLT dot IM show so there is also a
200:59 - method inside your Pi plot Library which
201:03 - is available inside matplotlib and this
201:06 - mesh third you can use to show the image
201:09 - which you have read from the opencvm
201:13 - read method so for now just write this
201:16 - kind of code and to show the mat plot
201:20 - lab window you just need to write PLT
201:23 - dot show so this is going to show this
201:27 - image using the matplotlib library so we
201:31 - are opening this image using the opencv
201:34 - I am show window as well as matplotlib
201:37 - window also so let's run this code and
201:40 - let's see what's the result which we are
201:43 - getting so you can see this is the image
201:46 - which is loaded using the matte plot lib
201:49 - and this was our original image which is
201:53 - loaded using the opencv library and
201:58 - straight away you can see some
201:59 - difference so this is the original image
202:02 - which is the colored image and in the
202:05 - matte plot lib ah window we also want
202:08 - the same result but it is giving us the
202:11 - different result and the reason behind
202:14 - this is opencv reads the image in the
202:18 - BGR format and the matplotlib reads the
202:23 - image in the RBG format so in order to
202:28 - show this kind of colored window using
202:31 - matplotlib you need to convert your
202:34 - image from BGR to RBG and then only you
202:39 - will be able to see this kind of of
202:41 - colored image using matte plot lab so
202:44 - I'm going to just close these windows
202:48 - and now after I'm showing this image
202:51 - using the CV2 I am show method I'm going
202:55 - to convert this image so I'm going to
202:57 - just write I'm G is equal to
203:00 - CV2 dot c v t color and then I'm going
203:06 - to convert this image from BGR image so
203:10 - I'm going to just write CB 2 dot color
203:14 - underscore BGR to RGB okay so our
203:21 - matplotlab library shows the image in
203:24 - the RGB format and the opencv reads the
203:28 - image in BGR format so now we have
203:31 - converted our image from BGR to RGB
203:35 - image and now we are showing this image
203:38 - using the matplotlib and let's run this
203:41 - code and let's see what happens now
203:43 - so now when we run this code you see
203:46 - both the image looks the same right now
203:51 - let's see the advantages of using
203:54 - matplotlib so you can see this is quite
203:59 - static window but when you see in
204:02 - matplotlib when you hover over this
204:04 - image you can see X and Y coordinates of
204:07 - the mouse point and this is helpful you
204:12 - can also save this image in the form of
204:14 - a PNG file so you can just press this
204:16 - and save this image wherever you want
204:19 - you can also Zoom this image if this
204:23 - feature is available there is also
204:25 - configuration subplots options so you
204:29 - can you can just increase
204:32 - these values left bottom wherever you
204:36 - want to place your image you can do that
204:41 - these are some options which are
204:44 - available here you can also reset these
204:46 - options and you can see the coordinates
204:49 - here so because matplotlib is primarily
204:52 - a 2d plotting Library so you can see the
204:56 - x coordinates and Y coordinates and
204:58 - because this image is about 512 by 512
205:04 - pixels that is why here it's showing 0
205:08 - to 512 and here also on the y axis 0 to
205:13 - 512 so this is how you can load your
205:17 - image using matplotlib and now I'm going
205:20 - to show you one more thing and this is
205:23 - when you write PLT dot X takes here and
205:27 - then when you pass m t array here which
205:29 - is empty square bracket comma
205:33 - PLT dot y takes and also here you pass
205:38 - Mt array this is going to hide the tick
205:42 - value on X and Y axis so now when I run
205:46 - this code and you can see now that these
205:52 - X ticks and Y takes on X and Y axis are
205:56 - gone so let me just comment this out
205:59 - once again and you will be able to see
206:02 - this X and Y coordinates here on the
206:05 - image and when you use this code which
206:11 - is to hide the text on the X and Y axis
206:14 - then you will see the image without
206:18 - these X and Y axis ticks so if you
206:23 - remember in the last video we have seen
206:25 - how to use Simple thresholding in opencv
206:29 - and we were using six Windows to show
206:33 - these six different images using opencv
206:38 - now let us say you want to show all
206:41 - these six windows in one matplot lib
206:46 - window how you can do it with the use of
206:49 - matplotlib I am going to show you so
206:52 - first of all we are going to import
206:54 - matplotlib import Pi plot as PLT and
207:00 - then what we are going to do is we are
207:01 - going to define the titles and then we
207:05 - are going to Define these six different
207:08 - titles for six different images so first
207:12 - one is our original image second was the
207:15 - trash binary third was trash binary
207:18 - inverse fourth was trunk fifth was two
207:21 - zero and six was to zero inverse in the
207:25 - same way we are going to Define a
207:28 - variable called images and inside this
207:30 - square bracket we are going to pass
207:32 - first of all our original image and then
207:36 - th1 comma th2 comma th3 comma th 4 comma
207:43 - t H five ok so these are the six value
207:48 - we want to show and these are the six
207:51 - titles of these images and now we are
207:55 - going to use the for Loop so for I in X
208:00 - range so using the Python X range we are
208:04 - going to just iterate over these six
208:08 - values so I am going to just write X
208:10 - range and then the range we are going to
208:12 - provide here is 6 and then inside this
208:15 - for Loop we are going to just call PLT
208:17 - and we are going to call a method called
208:21 - sub plot okay and this subplot method
208:25 - takes few arguments so first argument is
208:27 - the number of rows which we want to show
208:31 - in our matplotlib plot so because we
208:36 - have six images so we are going to
208:37 - divide these images into two rows and
208:41 - three columns so the first argument and
208:44 - here is the number of rows and the
208:47 - second argument here is the number of
208:49 - columns and the third argument here will
208:52 - be the index of the image so the index
208:54 - of the image will be I plus 1 and then
208:58 - we are going to write comma PLT dot I am
209:03 - show so this is going to show this image
209:07 - and the index of the image so we are
209:11 - going to just write images and then
209:14 - square bracket I so this is going to
209:15 - give you a particular image at index I
209:18 - and then we want to show this image as a
209:21 - gray scale image so anyway when you use
209:24 - thresholding you use the grayscale image
209:27 - so you just need to write a gray here
209:30 - then we are going to show the titles of
209:34 - these images so we are going to just
209:35 - write PLT dot title and then this title
209:39 - method takes the title name which we are
209:43 - getting you using this titles array and
209:46 - then at the index I this is going to
209:49 - give you the title name which we have
209:52 - declared in this title array and at last
209:54 - if you don't want to show the text on
209:57 - the images you can give these two method
210:01 - which is PLT dot X takes ah and the
210:04 - argument here is the empty list and also
210:07 - PLT dot y takes and the argument is the
210:11 - empty list and at the end what we want
210:15 - to do is instead of using this kind of
210:19 - code we just want to show our window so
210:24 - we can just say PLT dot show and this is
210:28 - showing us this error unresolved
210:30 - reference yes so this is when you are
210:34 - using python 2 but in Python 3 this x
210:39 - range is changed to a method called
210:41 - range and that's why it was giving us
210:43 - the error so let's run this ah script
210:47 - once again and you can see six different
210:50 - results and six different titles so
210:55 - these are all the titles which are shown
210:58 - here and then the result are shown under
211:02 - these titles so using matplotlib you can
211:06 - include multiple images into one window
211:10 - and this is very useful when you want to
211:14 - show multiple image at the same time in
211:18 - the same window so this is how you can
211:20 - use matplotlib library with
211:23 - opencv images and there is a lot of
211:26 - things which you can do with matplotlib
211:29 - so if you want to learn more you can
211:31 - just go to the official website which is
211:33 - matplot lib dot org and then you will be
211:38 - able to see more documentation here in
211:42 - this video we are going to discuss about
211:44 - morphological transformations in opencv
211:47 - so we will discuss different
211:50 - morphological operations like erosion
211:53 - dilation opening and closing methods Etc
211:58 - but first of all what are morphological
212:01 - transformations
212:03 - so morphological Transformations are
212:06 - some simple operations based on the
212:09 - image shape now morphological
212:13 - transformation is normally performed on
212:16 - a binary image and when we perform
212:19 - morphological transformation
212:21 - there are two things which are required
212:25 - first is the original image and second
212:28 - is called a structuring element or a
212:32 - kernel which decides the nature of the
212:36 - operation
212:37 - now there are different type of
212:39 - morphological Transformations and we are
212:42 - going to see them one by one
212:44 - now to start with I have this simple
212:46 - code which reads the image using opencv
212:50 - IM read method and we are just loading
212:54 - or showing this image using matplotlib
212:57 - now if you are unfamiliar with
213:00 - matplotlib and how to use matplotlib to
213:03 - show images in the last video I have
213:06 - explained this topic in details so if
213:10 - you want to see that video about
213:12 - matplotlib you can see it and this is
213:16 - the code I have used in the last video
213:19 - also and and I have explained this code
213:22 - in details in the last video so if you
213:25 - are confused what this code is doing
213:28 - just see the last video now there is one
213:31 - important thing to notice here is I am
213:34 - reading this image in a grayscale mode
213:39 - okay so either you can provide here as
213:42 - the second argument of I am read CV2 dot
213:45 - I am read underscore grayscale or you
213:49 - can provide simply 0 here in order to
213:51 - read this image in grayscale so let's
213:54 - run this code and let's see what it does
213:57 - so as expected it's just opening the
214:00 - image in the grayscale mode using
214:03 - matplotlib
214:05 - now as I said normally we perform the
214:09 - morphological Transformations on the
214:12 - binary images so that's why we need to
214:15 - provide a mask to our image using the
214:19 - simple thresholding so let's just do
214:22 - that so I am going to just write
214:25 - underscore comma The Mask so I'm going
214:29 - to name my variable as mask here and
214:33 - then I'm going to just write CV2 dot
214:36 - threshold and this threshold take few
214:39 - argument as you might already guess
214:42 - first is the image itself second
214:45 - argument is the value of the threshold
214:47 - so for now I'm going to just provide the
214:51 - threshold of 220 here the maximum value
214:55 - of threshold will be 255 then the next
214:59 - argument here is the type of the
215:02 - threshold so we are going to provide CV
215:05 - 2 dot thresh binary inverse so this is
215:10 - our mask so let's load the mask in the
215:14 - matplot labor window so I'm going to
215:18 - just provide in this titles array one
215:20 - more title which is mask and then we are
215:25 - going to see how this image looks like
215:28 - after the mask okay and here the range I
215:33 - am going to increase it to 2 because now
215:35 - the array is of two elements and the
215:39 - subplot is also let us say 1 by 2 so we
215:43 - want to show two images and I'm going to
215:46 - just run this code and you can see this
215:49 - was ah the image which was the grayscale
215:52 - image and the second image is the masked
215:55 - image
215:56 - now if you see this image carefully let
215:59 - me just ah just increase the size of
216:02 - this image and if you see this image
216:06 - carefully after masking there are some
216:09 - black dots here on the balls and let's
216:14 - say we want to remove these dots which
216:18 - are there in between this white area
216:21 - this black dot or this black dot or you
216:24 - can see some black dots are there inside
216:28 - your ball in the white area and we want
216:32 - to remove these dots from the balls for
216:37 - this we are going to use the dilation
216:41 - transformation so first of all what we
216:44 - are going to do is we are going to just
216:46 - write
216:47 - dilation which will be our variable name
216:51 - and then we are going to use this method
216:55 - called CV2 dot dilate okay so this
217:01 - method uses the source which is mask in
217:07 - our case
217:08 - and then the second thing is the kernel
217:12 - okay so let me explain what the kernel
217:16 - is so a kernel is normally a square or
217:20 - some shape which we want to apply on the
217:25 - image
217:25 - so we are going to define a kernel of
217:29 - numpy ones which means we want to apply
217:33 - white square on our balls so you can see
217:37 - when we run our code once again it shows
217:40 - us error because this kernel is
217:43 - undefined so let me Define this kernel
217:46 - first of all so I'm going to just say
217:48 - kernel is equal to NP dot once and then
217:54 - we are going to define the shape of this
217:59 - kernel let us say this is of 2 comma 2
218:02 - size and then we will just say NP dot U
218:08 - and 8. so this is our kernel and kernel
218:12 - in this case is nothing but a 2 by 2
218:16 - square shape and this square shape
218:19 - kernel is going to be applied on our
218:23 - image wherever these black dots are are
218:26 - there so now we have defined this kernel
218:29 - so let's see after this kernel is
218:33 - applied on our masked image how it looks
218:37 - like so I'm going to just add one more
218:40 - Title Here which is dilation and then
218:43 - I'm going to add the image after the
218:46 - dilation is applied on our image and
218:51 - then we are just going to increase the
218:53 - range to 3 because now we have three
218:55 - images and let's say this plot contains
218:59 - images One by three so one row and three
219:05 - columns right so I'm going to just run
219:08 - this code once again and now you can see
219:11 - all these three images first was the
219:14 - original image second is the masked
219:17 - image and the third one is the image
219:21 - which we got after we applied the
219:24 - dilation let me just increase the size
219:27 - of this image somehow so now you can see
219:31 - that for example here there was a black
219:36 - dot and now it's reduced right the size
219:39 - of this black dot is reduced here also
219:43 - there was a black dot but its size also
219:46 - is reduced but still we can see these
219:50 - black dots here right so how we can ah
219:54 - remove these black dots completely so
219:57 - there is a third parameter which we can
220:00 - provide to this dilate method is called
220:05 - iteration so number of iterations so we
220:09 - can just provide iterations is equal to
220:12 - whatever the number of times we want to
220:15 - perform dilation on our image by default
220:19 - it's one and you can provide let us say
220:22 - two here and lets see what is the result
220:25 - now so I am going to just run this code
220:28 - again and now you can see those black
220:32 - dots which we can see here on the masked
220:35 - image are now gradually gone but still I
220:41 - can see some little dots on the images
220:44 - the small dots are already gone right so
220:48 - now what we can do here is we can
220:51 - increase the size of the rectangle so
220:54 - this rectangle is applied to our area
220:59 - which have these parts so we can
221:02 - increase the size of the rectangle and
221:07 - the bigger the rectangle is the better
221:11 - the result will be but there will be a
221:14 - problem which I am going to show you so
221:16 - let us run this code and you can see now
221:19 - all the black dots from our image is
221:24 - gone so there was a black dot here which
221:27 - you don't see anymore and there was a
221:30 - black dot here here here and here and we
221:33 - don't see these black dots here but you
221:37 - might also observe that the size of this
221:42 - white area is also increased after we
221:46 - applied the dilation on this masked
221:49 - image so now this ball and this ball in
221:53 - the result after the dilation is merging
221:57 - here right so you can see it's merging
222:00 - because the size of our kernel is big
222:03 - and when we apply dilation the pixel
222:06 - element is one if at least one pixel
222:09 - under the kernel is one that's why the
222:13 - shape of these balls are increasing so
222:18 - let's see how our next morphological
222:20 - transformation Works which is called
222:22 - erosion and after that I'm going to
222:26 - explain you how ah this erosion works
222:29 - and what is erosion so I'm going to just
222:32 - declare a variable called erosion and
222:34 - then I'm going to just call a method
222:36 - called CV2 dot erode so the method name
222:41 - is erode and the first argument here is
222:44 - the source the second argument here is
222:47 - the kernel as we have seen in dilate
222:51 - method and the third argument is the
222:54 - optional argument which is the
222:57 - iterations so for now we just apply one
223:02 - iteration which is by default ah also
223:05 - one and now we are going to just add
223:08 - this image to our matte plot live window
223:11 - so I'm going to add the title and the
223:14 - image and now I will increase the range
223:17 - of the array to 4 and let us say now we
223:21 - want two by two ah Matrix of these
223:26 - images right so let's run this code and
223:28 - let's see what happens
223:30 - so now you can see four results here
223:35 - and first was the original image second
223:39 - was the masked image third was the
223:42 - dilation so all the spots in the balls
223:46 - which are black are gone using the
223:50 - dilation but the size was increased and
223:54 - using the erosion
223:56 - you can see the sides of the ball eroded
224:01 - so the basic idea of erosion is just
224:05 - like soil erosion it erodes away the
224:08 - boundary of the foreground object so
224:12 - when this erosion is applied the kernel
224:15 - which we have defined slides through all
224:19 - the image and a pixel in the original
224:22 - image either one or zero will be
224:26 - considered as one only if all the pixels
224:30 - under the kernel is one otherwise it is
224:34 - eroded and this means this value will be
224:37 - set to 0 which means this will be a
224:41 - black area so let's increase the number
224:44 - of iterations here so let us say we want
224:47 - to apply the erosion two times on the
224:52 - same image and I am going to just run
224:55 - this code once again and you can see now
224:58 - these balls are eroded more let's say we
225:02 - want to increase this to 5 times and
225:06 - then run the code and you can see now
225:08 - these balls are really small because we
225:11 - have applied this erosion multiple
225:13 - number of times so let's say this is one
225:17 - once again and let's
225:20 - make this size of our kernel small two
225:24 - by two rectangle size right so you can
225:27 - see now our result is better because all
225:31 - the spots from these balls are gone and
225:35 - these balls are not so much eroded now
225:39 - there are two more morphological
225:41 - transformation methods which are called
225:43 - opening and closing so we are going to
225:46 - first of all see how opening works I'm
225:50 - going to Define a variable called
225:52 - opening and then I will call CV2 2 dot
225:57 - morphology X okay and then we will
226:02 - provide the source which is mask the
226:05 - second method is the type of
226:08 - morphological operation which we want to
226:11 - perform
226:12 - so in this we are going to just call CV2
226:16 - Dot and then we can specify which type
226:19 - of morphological operation we want to
226:22 - perform on the image so just write morph
226:26 - and then the type of operation so we
226:29 - want to perform the morph open for the
226:32 - opening right and then the third
226:35 - argument here is the kernel which we
226:37 - have defined and now we are going to
226:40 - just add this opening to our matplotlab
226:45 - window
226:47 - let's add this and then let's do 5 here
226:52 - and then let's say our
226:55 - matplotlib is going to show these images
226:58 - in a two by three format okay so let's
227:02 - run this code and let's see what happens
227:04 - and let me increase the size of this
227:07 - image now and this is the result of the
227:13 - opening so what is opening in
227:16 - morphological transformations
227:18 - so opening is just another name of
227:22 - erosion followed by dilation so when you
227:25 - perform this opening morphological
227:27 - operation first of all erosion is
227:31 - performed on the image and then the
227:34 - dilation will be performed on the image
227:37 - so you can see the effect of the erosion
227:42 - followed by the dilation still you see
227:45 - some spots here which can go if you can
227:50 - just increase the size of this block so
227:55 - let us rerun the code let's see what
227:58 - happens
228:00 - so now
228:01 - this image somehow looks better than the
228:05 - older image so opening is the erosion
228:09 - followed by dilation
228:11 - now there is a closing method also which
228:16 - is just the opposite of opening in the
228:19 - closing morphological transformation
228:22 - dilation is performed first on the image
228:26 - and then it is followed by the erosion
228:29 - so let's see if we get the better result
228:33 - when we perform the closing
228:36 - morphological operations and the
228:38 - morphological operation here will be
228:41 - close
228:48 - and run this code
228:51 - and now you can see the result here so
228:55 - in closing as I said first of all the
228:58 - dilation is applied and then the erosion
229:01 - is applied in the opening first of all
229:04 - erosion is applied and then the dilation
229:07 - will be applied now there are different
229:09 - type of morphological operations you can
229:12 - apply using this morphology X so for
229:16 - example I am going to just use some of
229:20 - them so the main
229:23 - morphological operations other than
229:26 - opening and closing is let's say
229:29 - morphological gradient so I am going to
229:31 - just say m g for morphological gradient
229:36 - and you just need to change the second
229:39 - argument here so CV2 morph underscore
229:44 - morphological gradient so we are going
229:47 - to just call this morph gradient and it
229:51 - is going to apply the morphological
229:53 - gradient and then the next is the top
229:56 - hat and the black hat so there are
230:00 - different ah morphological techniques
230:03 - you can apply so I'm going to show you
230:06 - one more and then I will leave you with
230:10 - the other techniques so th for top hat
230:14 - and here also the second argument you
230:17 - just need to change it to Top Hat right
230:21 - otherwise you can see there are so many
230:24 - number of techniques you can apply on
230:28 - your image so there is gradient close
230:30 - open we have already seen Black Hat
230:33 - Cross dilate
230:36 - ellipse erode hit Miss rect and then top
230:41 - hat which is ah we are going to use
230:44 - right now right and then we can just add
230:49 - these two things to our list of titles
230:52 - and list of images
230:54 - so mg and then we have th for top hat
231:01 - and now we have eight images so range is
231:05 - increased to 8 and let's say we just
231:10 - want to show them in two by four
231:14 - Matrix here in the
231:19 - matplotlib window
231:21 - so you can see this is the result of
231:24 - morphological gradient so morphological
231:27 - gradient is the difference between the
231:30 - dilation and erosion of an image
231:34 - and this is the result of top hat that
231:38 - means it is the difference between the
231:41 - image and the opening of an image so
231:44 - this is how you can perform some of the
231:46 - morphological operations on the images
231:50 - now I will show you one more example I
231:53 - have a image called J dot PNG so I am
231:59 - going to just load this image also and
232:03 - because this J dot PNG is already a
232:06 - binary image I don't need to apply this
232:09 - mask here so instead of this mask I can
232:12 - just directly use our image variable so
232:16 - I'm going to just write this and let's
232:18 - load this image two times because we
232:22 - already have defined this mask variable
232:25 - inside our title list and image list and
232:29 - now I'm going to just run this code so
232:32 - the original image of this Js a DOT PNG
232:35 - looks like this and after we applied the
232:41 - dilation you can see the dilation
232:43 - increases the area of this J the erosion
232:47 - just erodes away the corners of this J
232:52 - right opening is going to apply the
232:57 - erosion first followed by the dilation
233:01 - and closing is going to first of all
233:04 - perform the dilation followed by the
233:06 - erosion this morphological gradient is
233:10 - going to give you the difference between
233:12 - the dilation and erosion of the image so
233:16 - it is going to give you this kind of
233:18 - result and you can see the top hat
233:21 - result here which is the difference
233:23 - between the input image and the opening
233:26 - of the image so this is how you can use
233:29 - different type of morphological
233:31 - Transformations on your images in this
233:35 - video we will discuss about smoothing or
233:38 - blurring images in opencv
233:41 - so smoothing which is also known as
233:43 - blurring is one of the most commonly
233:46 - used operation in image processing the
233:50 - most common use of smoothing operation
233:52 - is to remove noise in the images now
233:56 - when smoothing or blurring images we can
233:58 - use diverse linear filters because
234:01 - linear filters are easy to achieve and
234:04 - are also relatively fast now there are
234:07 - various kinds of filters available in
234:10 - opencv for example homogeneous gaussian
234:13 - median or bilateral filters which we
234:17 - will see one by one
234:19 - so first of all we will see the
234:22 - homogeneous filter so homogeneous filter
234:25 - is the most simple filter and in
234:28 - homogeneous filter each output pixel is
234:32 - the mean of its kernels neighbors now in
234:36 - homogeneous filter all pixels contribute
234:39 - with the equal weight and that is why
234:42 - they are called homogeneous filters now
234:45 - those of you who don't know what the
234:47 - kernel is I have explained about kernel
234:49 - in the last video so you can see the
234:51 - last video and in simple word a kernel
234:54 - is a shape which we can apply or
234:57 - convolve over an image and you can use
235:01 - for example numpy to create this kind of
235:04 - squared kernel so in homogeneous filter
235:07 - the kernel looks like this image which
235:10 - you see on your screen so in homogeneous
235:14 - filter kernel K is equal to 1 by the
235:17 - width of the kernel multiplied by the
235:20 - height of the kernel so let us say we
235:22 - want to use a kernel of five by five
235:25 - then using this formula we will have K
235:29 - is equal to 1 by 25 and then we will
235:33 - have our kernel Matrix of 5 by 5 once so
235:38 - let's create this kernel first of all
235:41 - and then we will see how to use this
235:44 - kernel for the image filtering using 2D
235:49 - column Evolution or homogeneous filter
235:53 - so what I have right now here is the
235:57 - simple code which loads this image using
236:00 - matplotlib and this code you might
236:03 - already know because I have explained in
236:05 - detail how matplotlib works and how to
236:08 - read the images using opencv one thing
236:12 - to note here is I am just converting the
236:15 - image from BGR to RGB because
236:20 - matplotlib reads the images in the RGB
236:23 - format and opencv reads the images in
236:27 - the BGR format so this conversion is
236:30 - necessary so let's define our kernel so
236:33 - I am going to just say kernel is equal
236:36 - to NP dot once and then we are going to
236:41 - take the kernel of five by five so we
236:44 - are going to Define this kernel 5 comma
236:46 - 5 of once so I am going to just say NP
236:52 - Dot not float 32 here and then we are
236:57 - going to divide this kernel by 25
237:00 - because our kernel is of 5 by 5 because
237:04 - the formula which we have seen in that
237:07 - formula we have the kernel which was a
237:12 - matrix of ones and then we have the
237:16 - multiplication of 1 divided by the width
237:20 - and height of the kernel so that's why
237:23 - the multiplication of the width and
237:25 - height is 25 that's why I have taken 25
237:28 - here so now we have our kernel so we can
237:32 - Define our destination image using this
237:37 - kernel and we are going to use CV2 dot
237:40 - there is a method called filter 2D which
237:43 - we are going to use which is used for
237:46 - this homogeneous filter
237:49 - so here the first argument is the image
237:53 - the second argument is the desired depth
237:56 - of the destination image so for now we
237:59 - are going to take it as -1 the third
238:03 - argument is the kernel so now when we
238:07 - have applied this kernel on our image
238:11 - using 2D filter let's see what the
238:14 - output will look like so I will name
238:17 - this image as 2D convolution and the
238:23 - destination is the final image which we
238:27 - got using filter 2D and let us increase
238:31 - this range by 2 and let us say we want
238:34 - to show this image on matplot live in
238:37 - one by two format okay so I am going to
238:40 - just run this image so this is the
238:43 - result on the left hand side is the
238:46 - original image and on the right hand
238:48 - side
238:49 - is the 2D filter applied image so this
238:54 - is the image which we got by applying
238:56 - the homogeneous filter using filter 2D
238:59 - function so you can see on the corners
239:02 - here there is a little bit noise and
239:06 - after applying this 2D convolution over
239:11 - this image you can see all the corners
239:14 - are now smoothened and overall this
239:17 - image is now smoothened or blurred a
239:21 - little bit so these noises are removed
239:25 - or suppressed by this blurring so this
239:29 - is one way of blurring an image using
239:32 - filter 2D right filter to the function
239:35 - now as in one dimensional signals images
239:38 - also can be filtered with various low
239:41 - pass filters or high pass filters Etc so
239:46 - low pass filter helps in removing the
239:49 - noise or blurring the image Etc and high
239:53 - pass filters helps in finding ages in
239:56 - the images now when you want to achieve
239:59 - image blurring we need to convolve over
240:02 - the image with the low pass filter
240:05 - kernel
240:07 - now there are some algorithm as I said
240:10 - there are various kind of algorithm
240:12 - available in opencv so we will also see
240:16 - them one by one so first algorithm is
240:19 - the blur method or it's also called the
240:22 - averaging so what I'm going to do is I'm
240:25 - going to Define a variable called blur
240:27 - and then I'm going to call a method
240:30 - called CV2 dot blur okay so this is the
240:35 - method which we will use to apply
240:38 - averaging algorithm for blurring the
240:41 - image and this takes two argument one is
240:45 - the image and second is the kernel so
240:48 - the kernel we are going to apply is once
240:50 - again five by five
240:52 - and now we are going to just see with
240:56 - the result of this blurring method so we
240:59 - are going to just
241:01 - loaded using the matplotlib so range I'm
241:05 - going to increase it by 1 once again and
241:09 - let's see this these three images in one
241:12 - by three format on the matplotlib window
241:16 - so this is the result
241:19 - and you can see the original image the
241:23 - result which we got using the filter to
241:26 - the method and the result we got using
241:29 - the blur method which is also called
241:32 - averaging so the result is more or less
241:36 - looks the same to me because we have
241:39 - applied the same kind of Kernel to both
241:42 - the functions so this is the result of
241:46 - filter 2D function and this is the
241:48 - result of the blur function now there
241:52 - are more functions which are available
241:54 - in opencv so let's see them so the next
241:58 - algorithm which we are going to see is
242:01 - the gaussian filter algorithm so the
242:04 - gaussian filter is nothing but using
242:06 - different weight kernel in both X and Y
242:11 - Direction so in the result pixels
242:13 - located in the middle of the kernel have
242:17 - the higher weight or bigger weight and
242:21 - the weights decreases with distance from
242:24 - the neighborhood center so pixels
242:27 - located on the side have smaller weight
242:30 - and the pixels located on the center
242:34 - have the higher weight so when we take a
242:37 - five by five kernel its result is going
242:41 - to look like this which is shown in the
242:44 - image and now let's see how we can use
242:47 - this gaussian blur in our opencv code so
242:51 - I'm going to remove this semicolon which
242:54 - I somehow added here and let's declare a
242:58 - variable called G blur for gaussian blur
243:02 - and then we are going to use CV2 dot
243:07 - gaussian blur so the method name is
243:09 - gaussian blur and the argument here are
243:13 - same as the blur method so first
243:16 - argument is the images cell second
243:19 - argument is our kernel we are going to
243:22 - take the same kernel of five by five and
243:26 - the third argument here is the sigma x
243:28 - value which we are going to take 0 for
243:31 - now let's see the result of the gaussian
243:34 - blur method when it's applied to an
243:37 - image so I'm going to just Define one
243:40 - more title which is G blur or gaussian
243:43 - blur or let us take this name which will
243:46 - be more clear and then our result image
243:50 - is G blur and let's increase the range
243:53 - to 4 and let us say we want to show this
243:57 - image in two by two format so two rows
244:00 - and two columns so I am going to run
244:02 - this code and for opencv logo the
244:07 - results looks the same you can see for
244:12 - the 2D convolution of filter 2D method
244:15 - or blur method using the gaussian blur
244:17 - you can see there is a little bit
244:19 - different between the blur method and
244:22 - gaussian blur method results the
244:26 - gaussian blur result is more better in
244:29 - my eyes than the blur method let's try
244:33 - this gaussian blur method with another
244:35 - image so I have this image called half
244:40 - tone underscore gaussian underscore blur
244:44 - and I'm going to run this code now with
244:48 - the new image and you can see the result
244:52 - now so this was the original image which
244:57 - have too much noise here so you can see
245:00 - ah the pixels here which have too much
245:04 - noise and after applying the gaussian
245:07 - blur you can see this eye image in much
245:11 - better way and all the noise is removed
245:15 - so the gaussian blur method is designed
245:18 - specifically for removing the high
245:21 - frequency noise from the image like this
245:25 - one now let's see the next method which
245:28 - is called the median filter so median
245:31 - filter is something that replaces each
245:35 - pixel value with the median of its
245:38 - neighboring pixel so this method is
245:40 - great when dealing with something which
245:43 - is called salt and pepper noise now if
245:46 - you don't know what the salt and pepper
245:49 - noise is you can open the Wikipedia and
245:52 - under this URL or just search for salt
245:56 - and pepper noise
245:57 - Wikipedia page and you can see ah more
246:01 - details about salt and pepper noise so
246:03 - you can see this is an image and there
246:07 - are some pixels which are distorted here
246:10 - so there are some pixels where the white
246:14 - dots are there or white noise is there
246:17 - and there are some places where the
246:19 - black noise is there so that's why it's
246:22 - called salt and pepper because we have
246:24 - white pixels which are distorted like
246:27 - salt and we have the black pixels which
246:31 - are which looks like pepper so that's
246:34 - why it's called salt and pepper uh noise
246:37 - so I have this same image which I'm
246:41 - going to use as a source now so it's
246:44 - called water dot PNG in my case and now
246:48 - let's see how we can use the median blur
246:51 - method so I'm going to just Define a new
246:54 - variable called median and then I'm
246:57 - going to use CV2 dot median blur method
247:01 - so this method is called median blur
247:04 - where the first argument is the image
247:08 - and the second argument here is the
247:10 - kernel size now one thing to note here
247:13 - is that the kernel size must be odd here
247:18 - so ah this must be a three or five or
247:21 - seven and so on except one okay so when
247:26 - you just give one it is going to show
247:28 - you the original image and let's say we
247:31 - just give three here as the kernel size
247:34 - or in our case we have the kernel size
247:38 - of five so let's take the five kernel
247:40 - size here so let's just show this result
247:43 - of the median filter in the matplotlab
247:47 - window so I am going to just increase
247:50 - the range 5 and let's say this is two by
247:53 - three Matrix now
247:55 - I'm going to run this code
247:57 - and now you can see the results of all
248:01 - the filtering method and you can see the
248:04 - best result you get using the median
248:06 - filter method so when you have this kind
248:10 - of salt and pepper dots on your images
248:13 - then you can use the median filter now
248:18 - let's see the last filter which is
248:19 - called the bilateral filter so by using
248:22 - all these filters for example
248:24 - homogeneous filter or averaging or the
248:28 - gaussian or the median filter we not
248:30 - only dissolve the noise but we also
248:33 - smooth the edges and sometimes we need
248:37 - to preserve the edges that means we need
248:40 - that all the ages must ah remain sharper
248:45 - even if the image is blurred so let me
248:49 - show you one example so I have this Lena
248:53 - dot PNG image so I'm going to Define ah
248:57 - variable called bilateral filter and
249:00 - then there is a method called CV2 dot
249:03 - bilateral filter and this bilateral
249:06 - filter takes the first argument which is
249:08 - the image the second argument is the
249:12 - diameter of each pixel neighborhood that
249:15 - is used during the filter so let us take
249:18 - it as a 9 the third argument is the
249:23 - sigma color and the fourth argument is
249:25 - the sigma space so the spig sigma color
249:29 - is the filter Sigma in the color space
249:31 - and sigma space is the filter Sigma in
249:35 - the coordinate space so for this we are
249:38 - going to take this filter Sigma color
249:40 - and sigma space as 75 and 75 here and
249:46 - let's see it in the result window so
249:51 - bilateral filter and then the result
249:54 - bilateral filter and this gives me error
249:57 - because this image is called Lana dot
249:59 - jpg dot p n g so j p g and then we need
250:04 - to increase this range by 1 to see all
250:08 - the six images and let us run this code
250:11 - and let's see what happens so you can
250:13 - see the result now so let me make it
250:16 - little bit bigger so you can see them
250:18 - and from here also
250:21 - so now you can see by applying the
250:24 - bilateral filter the edges are preserved
250:28 - in a much better way so here you can see
250:32 - the Hat border is blurred but here you
250:36 - can see in the result the border of the
250:40 - head are preserved so the images in
250:45 - which you need to preserve the borders
250:48 - then you can use the bilateral filter so
250:52 - bilateral filter is highly effective in
250:55 - noise removal while keeping the edge
250:57 - sharp so these are some of the methods
251:00 - and algorithms you can use to smoothen
251:04 - or blur your images using opencv in this
251:08 - video we will talk about image gradients
251:11 - in opencv
251:13 - so first of all what is an image
251:15 - gradient so an image gradient is a
251:20 - directional change in the intensity or
251:23 - the color inside the image now the image
251:27 - gradient of an image is one of the
251:29 - fundamental building blocks in image
251:32 - processing for example we use image
251:35 - gradients inside the image to find the
251:38 - edges inside an image
251:41 - now there are several image gradient
251:44 - methods available in opencv and we are
251:48 - going to see three of them
251:51 - first is the laplacian derivatives
251:54 - second is the Sobel X method and third
251:58 - one will be the Sobel y methods and all
252:03 - these methods which I mentioned are
252:05 - different gradient functions which uses
252:09 - different mathematical operations to
252:12 - produce the required image so the
252:15 - laplacian calculates the laplacian
252:18 - derivatives whereas Sobel method is
252:21 - joint gaussian and differentiation
252:24 - operations but don't be overwhelmed with
252:28 - the details you just need to keep in
252:30 - mind that these are just the functions
252:34 - which we use for finding out the
252:37 - gradients of an image to analyze the
252:40 - image so let's use the first method
252:42 - which is called the laplacian gradient
252:46 - now to start with I have this initial
252:49 - code and you might already know what
252:51 - this code is doing so first of all I'm
252:54 - just reading this image messy Five Dot
252:57 - jpg in the grayscale mode using the IM
253:01 - read method and then I'm just loading
253:04 - this image using the matplotlib window
253:08 - so let's first see how the result looks
253:11 - like so this is going to look like this
253:14 - this is just a normal image of messy and
253:19 - let's see how we can apply the laplacian
253:23 - method to find out the laplacian
253:26 - gradient of an image
253:29 - so for that we are going to declare a
253:32 - variable called lap and then there is a
253:38 - function available inside your CV2
253:41 - Library which is called laplacian and
253:46 - this laplacian method takes few argument
253:49 - first argument is the image the second
253:53 - argument here will be the data type
253:55 - which we are going to use which is
253:59 - called CV2 Dot
254:02 - CV underscore 64 F so CV2 dot CV
254:08 - underscore 64 f is just a data type and
254:13 - we are using a 64-bit float due to the
254:18 - negative slope induced by transforming
254:21 - the image from white to black so you
254:24 - just need to keep in mind that this is
254:26 - just a data type which is 64-bit float
254:30 - and it supports the negative numbers
254:34 - which we will be dealing with when the
254:37 - laplacian method is run on our image now
254:43 - in the next line what we are going to do
254:45 - is we are going to take the absolute
254:47 - value of our laplacian image
254:50 - transformation and we are going to
254:52 - convert this value back to the unsigned
254:57 - 8-bit integer which is suitable for our
255:00 - output so I am going to you just write
255:03 - lap and then using the numpy uint
255:07 - methods and NP dot U int 8 and as an
255:13 - argument we are going to pass NP dot
255:16 - absolute and then inside the absolute
255:20 - method we are going to just pass our
255:22 - image which is going to give us the
255:24 - absolute value of our LaPlace in image
255:27 - transformation which is going to convert
255:30 - this into the unsigned 8-bit integer now
255:34 - let us see the result of this laplacian
255:38 - gradient so I am going to just add a new
255:41 - title to my title array which is called
255:44 - laplacian and also inside the images
255:48 - list I am going to add this lap
255:53 - variable which contains this image right
255:57 - after the laplacian gradient is applied
256:00 - here and here the range will be 2 and we
256:05 - are going to see it in one by two format
256:08 - on the mat plot lib window so here you
256:13 - can see the original image which is this
256:15 - one and after the laplacian gradient
256:19 - method is applied on this image you can
256:22 - see all the edges which are detected by
256:27 - this method when we applied this method
256:30 - on this messy Five Dot jpg image and an
256:34 - image gradient as I said is the
256:37 - directional change in the intensity or
256:39 - the color in an image so let us close
256:44 - this window and there is one more
256:47 - argument you can provide here which is
256:50 - the kernel size so you can just say k
256:54 - size is equal to 5 this is the kernel
256:57 - size and I am going to just run this
256:59 - program once again and you can see the
257:02 - kernel size is increased but our result
257:06 - is deteriorated right so let us reduce
257:09 - it to 3 and then once again run this
257:13 - program and the result looks fine and if
257:18 - you apply K size is equal to 1 let's see
257:22 - the result and you can see you get the
257:26 - better result I think so for now I'm
257:29 - going to just use case size is equal to
257:31 - 3 and now let's use the other two image
257:38 - gradient methods which are so Bill X and
257:42 - Sobel y so these methods which are
257:46 - called Sobel X and Sobel y are also
257:49 - called Sobel gradient representation so
257:52 - let's just use them and then we will
257:55 - discuss how they are useful so first of
257:59 - all I'm going to declare a variable
258:01 - called Sobel X and then I'm going to use
258:07 - the method inside this CB2 Library which
258:12 - is called so Bell so this is the method
258:15 - which takes again few arguments first is
258:19 - the image second is again this data type
258:23 - which is CV2 dot CV underscore 64 and
258:30 - the third argument here will be the DX
258:34 - so when you write 1 here this value can
258:38 - be one or zero so when you write 1 here
258:42 - that means we want to use the Sobel X
258:46 - method okay and then the fourth argument
258:50 - here is the d y value okay so this is DX
258:56 - which is for the X Direction and this is
259:02 - for the d y which is for the y direction
259:06 - and DX stands for the order of
259:09 - derivative X and the d y stands for
259:14 - order of derivative y
259:16 - now once again we are going to declare
259:19 - the sobell Y variable so let's declare
259:24 - the Sobel Y and then C V 2 dot so Bell
259:30 - and this also takes a few arguments here
259:34 - the difference will be only the third
259:38 - and fourth argument so I'm going to just
259:41 - use the second argument same the third
259:44 - argument will be 0 for so Bill Y and the
259:48 - fourth argument will be one right so
259:51 - this is the order of derivative X if
259:54 - it's 1 this is called the order of
259:57 - derivative which is in the X Direction
260:00 - and in the second case it is in the y
260:04 - direction and the fifth argument here
260:06 - can be the K size as we have seen in the
260:09 - laplacian method so if you want you can
260:12 - provide the kernel size also here as the
260:16 - fifth argument but we are going to skip
260:18 - it for now now again we are going to
260:22 - convert these values into the unsigned
260:27 - int as we have done in the case of
260:30 - laplacian so what we are going to do is
260:33 - we are going to once again overwrite
260:36 - this variable so we'll X and then we are
260:39 - going to use NP dot u in 8 and in the
260:45 - parenthesis we are going to just write
260:47 - NP dot absolute and then we are going to
260:51 - just pass the value inside the Sobel X
260:55 - variable same we are going to do with
260:57 - the Sobel y variable
261:00 - and now let's see the result how the
261:03 - result looks like so I'm going to just
261:06 - add these elements inside the title and
261:10 - the image list so let's add Sobel X and
261:14 - so we'll y here and here also
261:19 - so so Bill Y and now let's increase the
261:24 - range to 4 and let's see it in the form
261:29 - of 2 by 2 Matrix on the matplotlab
261:33 - window so I'm going to just run this
261:35 - code and you can see
261:38 - the result here so original image
261:41 - laplacian
261:43 - gradient and then Sobel X and so blue y
261:46 - so you can see when you apply the Sobel
261:50 - X gradient method the direction or the
261:54 - change in Direction in the intensity is
261:57 - in the X Direction and when you apply
262:01 - the Sobel y method the change in
262:04 - Direction in the intensity is in the y
262:08 - direction so this is like horizontal and
262:13 - this is in the vertical Direction I have
262:16 - one more image which will illustrate
262:19 - this so we'll X and so y gradient method
262:23 - in a better way I think and this is
262:26 - called
262:27 - Sudoku so I'm going to just write Sudoku
262:31 - dot PNG file file and hopefully I didn't
262:36 - do any mistake in the naming yes it
262:39 - works so you can see ah the laplacian
262:43 - result here and then Sobel X and so y
262:47 - result here so in the Sobel X you can
262:51 - see more vertical lines so because so
262:55 - will Y is good for the directional
262:58 - change in the vertical Direction so you
263:00 - can see more change in intensity in the
263:04 - vertical Direction and using the Sobel y
263:07 - you can see the directional change in
263:10 - the intensity in the horizontal
263:12 - direction or the y-axis you can also
263:15 - combine the result of Sobel X and so
263:18 - Bill Y images and how we can do this
263:22 - let's see so to combine these two result
263:25 - I am going to just create one more
263:27 - method which is called Sobel
263:30 - combined is equal to CV2 dot we are
263:35 - going to use the bitwise or operator in
263:39 - order to merge these two images so we
263:43 - are going to just write bitwise or and
263:47 - then we are going to provide the two
263:49 - sources one is Sobel X and the other is
263:52 - the syllable Y image so this is going to
263:56 - give us the bitwise or result of these
264:00 - two images and then we are going to just
264:04 - add this into the title list so let's
264:07 - say so we'll combined and also in the
264:12 - image list so like this and let's just
264:16 - increase the range to 5 and let's see it
264:19 - in the form of ah 2 by 3 on matplotlib
264:23 - so I'm going to just run this once again
264:27 - and you can see the result
264:30 - now so this here is the combination of
264:35 - Sobel X and Sobel y method and you can
264:38 - see now you can see the directional
264:41 - change in the vertical as well as in the
264:45 - horizontal Direction because this is the
264:48 - combination of Sobe Y and Sobel X images
264:51 - so this is how you can use the image
264:54 - gradients inside opencv in this video we
264:59 - will talk about Kenny Edge detector in
265:02 - opencv so first of all what is Kenny
265:05 - Edge detector so the Kenny Edge detector
265:09 - is an edge detection operator that uses
265:13 - multi-stage algorithm to detect a wide
265:17 - range of edges in images now this Kenny
265:22 - Edge detector was written and developed
265:25 - by John F Kenny in 1986 the that's why
265:30 - it's named after his name which is Kenny
265:35 - as detector now the process of Kenny
265:38 - Edge detection algorithm can be broken
265:41 - down in five different steps
265:44 - the first step is to apply gaussian
265:47 - filter to smooth the image in order to
265:50 - remove the noise
265:52 - the second step is to find the intensity
265:55 - gradients of the image the third step is
265:58 - to apply the non maximum suppression to
266:01 - get rid of spurious response to Edge
266:06 - detection the fourth step is to apply
266:09 - double threshold to determine the
266:13 - potential edges and the fifth step is to
266:17 - track edges by hysteresis that is to
266:21 - finalize the detection of the edges by
266:23 - suppressing all the other edges that are
266:27 - weak or not connected to strong edges
266:31 - so this seems little bit complicated but
266:35 - in opencv it's really simple to use so
266:39 - there is a built-in function in opencv
266:44 - which is called Kenny and we are going
266:47 - to use this function so to start with I
266:51 - have this sample code which loads this
266:54 - image which is called messy.jpg using
266:58 - the matplotlib library I'm going to just
267:01 - run this to show you the result so this
267:04 - is the image and we want to detect the
267:07 - edges of this image so what we are going
267:11 - to do is we are going to first of all
267:13 - declare a variable called Kenny and then
267:18 - there is a method as I already said
267:20 - inside your CV2 Library which is called
267:24 - Kenny method which takes few arguments
267:28 - so the first argument here is the image
267:32 - source itself the second argument and
267:35 - the third argument as you can see is the
267:38 - first threshold value and the second
267:40 - threshold value so this first threshold
267:43 - value and the second threshold value you
267:45 - need to provide for the hysteresis
267:48 - procedure so there is the last step as I
267:52 - I mentioned and in that step hysteresis
267:55 - take place and for that procedure we
267:59 - need to provide the values of the
268:02 - threshold one and the threshold two so
268:06 - for now I am going to provide 100 as the
268:10 - threshold 1 and 200 as the threshold 2
268:14 - but later you might want to add a track
268:18 - bar in order to see the changes in the
268:23 - edges when you just move the track bar
268:26 - from left to right for the threshold one
268:29 - and the threshold two so this might be a
268:32 - small assignment for you you can just
268:35 - add the track bar and see how the edge
268:39 - detection changes when you change the
268:42 - value of threshold 1 and threshold 2 and
268:45 - I have already explained how you can use
268:47 - track bars with opencv so just watch
268:51 - that video and you will be good to go so
268:55 - now we have the result of Kenny Edge
268:58 - detection function so we are going to
269:00 - just add it to our list first to the
269:03 - list of titles and then second to the
269:08 - list of images and the range we are
269:10 - going to increase it to ah 2 and this we
269:14 - are going to just see the images in one
269:18 - by two format so I am going to just run
269:20 - this python script and see the result so
269:24 - you can see we have the original image
269:29 - here which we have loaded in the
269:31 - grayscale and on the right hand side you
269:33 - can see the result of the Kenny Edge
269:36 - detection methods so you can see all the
269:40 - edges which are available here on this
269:44 - messy Five Dot jpg image you can use
269:47 - this on the other images also so for
269:51 - example I have the
269:52 - Lana dot jpg image let's see the result
269:56 - of that and this is the result of the
270:01 - Kenny Edge detection method on this Lana
270:05 - dot jpg method so this Kenny Edge
270:09 - detection is really useful because in
270:13 - the last video we have seen how to find
270:15 - out the image gradients and let's see
270:19 - in comparison to those image gradient
270:22 - methods how Kenny Edge detection method
270:26 - performs so these are all the methods I
270:30 - have explained in the last video
270:32 - laplacian Sobel X and so Bill Y and I
270:36 - have shown you how to combine the result
270:38 - of Sobel X and Sobel Y and additionally
270:41 - I have added this line to the previous
270:45 - code which I have shown you in the last
270:47 - video which is Edges is equal to CB2 dot
270:51 - canny which gives us the result on the
270:54 - same image ah using the Kenny Edge
270:57 - detection method and I have added it to
271:00 - the title and the image right so let us
271:03 - run this script once again and let's see
271:06 - the differences in the result using all
271:10 - these methods
271:12 - so you can see all the six results
271:16 - this is the original image this is the
271:18 - result of the laplacian method this is
271:22 - the result of Sobel X and this is the
271:25 - result of so Bill Y and this is the
271:28 - combination of Sobel X and Y and you can
271:30 - see Kenny Edge detection gives us the
271:33 - result which contains lesser noises so
271:36 - you can see there is a lot of noise
271:37 - present in the other matters you can see
271:41 - here all the noise is present which is
271:45 - removed using Kenny Edge detection or in
271:49 - the laplacian method also you can see
271:51 - some noises around but in the Kenny
271:55 - detection method you can see you get the
271:59 - proper edges and more precise edges
272:03 - without any noise so this is the benefit
272:07 - of using Kenny Edge detection so this is
272:11 - how you can use Kenny Edge detection in
272:14 - this video we will discuss about image
272:16 - pyramids in opencv
272:18 - so till now normally when we have used
272:22 - images we have used the images of
272:24 - constant size but sometimes we need to
272:28 - work with the images of different
272:31 - resolution so for example if I have an
272:36 - image and I want to search the face
272:39 - inside an image this face can be of
272:42 - different sizes
272:44 - so using image pyramids we just create
272:49 - the images of different resolutions and
272:54 - then we search for the object for
272:58 - example face in all of these images so
273:02 - pyramid or pyramid representation is a
273:06 - type of multi-scale signal
273:07 - representation in which a signal or an
273:11 - image is subject to repeated smoothing
273:15 - and sub sampling so a normal pyramid
273:19 - when you create a pyramid of images it
273:23 - will look like this so let's say this is
273:25 - the original image at the bottom then
273:28 - when you down scale an image using a
273:33 - pyramid function it is going to give you
273:35 - this image which have the half
273:39 - resolution than the original image and
273:42 - then when you further go up it's going
273:46 - to give you the 1 4 of the original
273:48 - image and then so on so 1 8 or 1 16 of
273:53 - an image
273:55 - now there are two types of ah image
273:59 - pyramids which are available in opencv
274:02 - first is called gaussian pyramid and
274:05 - second is called laplacian pyramid so
274:09 - first we will discuss about the gaussian
274:11 - pyramid so gaussian pyramid is nothing
274:14 - but repeated filtering and sub sampling
274:17 - of an image
274:19 - now there are two functions available
274:22 - for the gaussian pyramid which is called
274:27 - pair down and pair up so let us see them
274:30 - one by one so I have this sample code
274:35 - which is just reading an image and then
274:38 - showing it using the I am show method
274:41 - now in order to use this pair down
274:45 - function you can just Define a variable
274:47 - let us say
274:48 - l r for lower resolution and then you
274:53 - can use CV2 dot pair down so there are
274:58 - two functions you can see pair down and
275:00 - pair up so first of all we will see pair
275:03 - down and then we are going to pass our
275:07 - image as an argument here so I am going
275:10 - to just pass our image as an argument
275:12 - and we are already showing the original
275:16 - image and let's show the image after we
275:20 - have reduced the resolution of this
275:22 - image using the pair down method so pair
275:26 - down is going to reduce the resolution
275:29 - of an image so I am going to just
275:33 - use LR here and let us say this is the
275:37 - pair down one image okay so let's run
275:42 - this code and let's see what happens so
275:44 - you can see this is the original image
275:47 - and this is about you can see one fourth
275:51 - of this original image right so this
275:56 - pair down method is going to reduce the
275:59 - resolution of an image when you apply
276:02 - the same method on the second image so
276:08 - let's say this is l r 1 and then we
276:13 - create a second variable error LR2 and
276:17 - when we pass l r 1 as an argument for
276:21 - this method to create the LR2 to image
276:25 - then let's see what happens so this will
276:28 - be lr1 and let us just
276:32 - say this is going to give us LR2 the
276:38 - resolution of image will reduce further
276:41 - so let's see what happens so this was
276:44 - the original image this was ah the image
276:48 - which we got from the first pair down
276:51 - method and then we get this image which
276:54 - we which is further reduced in
276:58 - resolution so this is the image after
277:01 - applying the pair down method second
277:04 - time on the lr1 image okay so you can
277:10 - see the resolution of image is reducing
277:14 - and its creating a kind of pyramid and
277:18 - that is why it is called the image
277:20 - pyramid now there is a method called
277:23 - pair up also available in opencv so
277:26 - let's see what this pair up method do so
277:31 - as you can expect it is going to
277:33 - increase the resolution of the image so
277:37 - here I am going to just say h r for
277:40 - higher resolution and then I am going to
277:43 - just say c v 2 dot pair up okay and it's
277:48 - going to increase the resolution of an
277:50 - image now let's say we want to increase
277:53 - the resolution of an of this image which
277:57 - is the smallest image which we got using
278:01 - the pair down method right so we are
278:04 - going to apply the pair up on the last
278:08 - image which we got using the pair down
278:11 - method and let's see what happens so
278:15 - when I am going to use this hr2 here and
278:20 - this we got from pair up method and let
278:24 - us say this is the pair up one and I am
278:27 - going to just run this code and you you
278:30 - are going to see that we have converted
278:33 - this image which was the smallest image
278:36 - to a higher resolution which resulted in
278:40 - this image but when you see this image
278:45 - carefully so let me just move this ah to
278:48 - this side and this was the original
278:50 - image so let me just minimize this so
278:54 - this image we have converted to this
278:57 - image using the pair up method so
279:00 - ideally
279:01 - this image should look like this but you
279:05 - have to remember that this pair up image
279:09 - is not going to be equal to this image
279:13 - because once you decrease the resolution
279:16 - using the pair down method you lose the
279:19 - information about that image so when you
279:23 - use pair up to just increase the
279:26 - resolution of this image then you can
279:30 - see the result looks little bit blurred
279:34 - because some of the information is
279:37 - loosed using the pair down method so you
279:41 - have to keep this in mind that when you
279:44 - want to increase the resolution after
279:46 - you have reduced the resolution you are
279:50 - not going to get the same result as you
279:54 - might expect that this image should look
279:57 - like this but they are not equal images
280:00 - so this image is just a higher
280:03 - resolution of this image and it has
280:05 - nothing to do with this image so these
280:09 - are the two methods which are available
280:10 - in gaussian pyramid now if you want to
280:15 - create a pyramid of multiple resolution
280:20 - instead of just using this pair up or
280:24 - pair down method repeatedly what you can
280:26 - do here is I'm going to just remove this
280:30 - and remove this code also so what I'm
280:34 - going to do is I'm going to copy the
280:36 - image into a new variable so I am going
280:39 - to just say layer is equal to i m g dot
280:44 - copy there is a method available for
280:48 - copying the image which is a copy and
280:52 - then I'm going to create the gaussian
280:56 - pyramid array okay so I'm going to just
281:00 - create a variable called GP for gaussian
281:04 - pyramid is equal to 10 in square bracket
281:08 - I am going to just pass this image here
281:12 - as the first element of this list then
281:16 - what I can do is I can use a for Loop
281:19 - instead of just rewriting this pair down
281:23 - method again and again and you might
281:25 - already know how to use for Loop in
281:28 - Python so for I in range and here we can
281:32 - provide any ah range so let us say we
281:35 - want to create five ah image pyramid ok
281:39 - so five time we want to reduce the
281:42 - resolution so we are going to give 6
281:45 - here because range goes ah the number
281:49 - minus one so whatever you give here
281:52 - minus 1 right so now what we are going
281:57 - to do is we are going to just use our
281:59 - layer
282:01 - parameter once again and then we are
282:03 - going to just call CV2 dot pair down
282:07 - method so pair down and then we want to
282:13 - just ah say layer okay and then we want
282:18 - to append to the gaussian pyramid list
282:23 - okay so we are going to just say GP dot
282:27 - append and we are going to append the
282:31 - result of this pair down to our list
282:36 - which we have created here okay so this
282:39 - is going to just append this image to
282:43 - our list of images and then let's just
282:48 - show this image using CB2 dot I am show
282:53 - method so CV 2 dot I am show and here we
282:58 - can just say s t r
283:01 - for converting the integer to the string
283:05 - because the first parameter you give to
283:08 - I am show is a string parameter that's
283:11 - why I am converting the integer to the
283:14 - string and the second parameter is the
283:16 - image so let's pass this layer here okay
283:19 - so you have the original image which
283:23 - will be shown using this line of code
283:25 - and then you will see multiple number of
283:27 - images of different resolution using
283:30 - this code so let's run this code and
283:33 - let's see what happens so I am going to
283:34 - run this code and you can see there are
283:39 - different images ah resulted using that
283:42 - code which we have written so this was
283:46 - the first image which is 0 and then this
283:51 - is the second image and then this is the
283:54 - third fourth fifth and sixth so sixth
283:57 - you can see have a very small resolution
284:01 - so this is how you can use pair down
284:05 - method multiple times using a for Loop
284:09 - now what are laplacian pyramids so
284:12 - laplacian pyramids are formed from the
284:15 - gaussian pyramids there is no exclusive
284:19 - function for creating the laplacian
284:23 - pyramid so as you have seen that in
284:26 - gaussian pyramids there are two methods
284:29 - available pair up and pair down but
284:31 - there is no exclusive function for
284:34 - creating the laplacian pyramid so how we
284:37 - can create a laplacian pyramid if there
284:40 - is no function available for creating
284:43 - them
284:44 - so you can create a laplacian pyramid or
284:48 - a level of laplacian pyramid is formed
284:51 - by the difference between that level in
284:56 - the gaussian pyramid and the extended
284:59 - version of its upper level in the
285:03 - gaussian pyramid so this definition
285:05 - might be confusing to you guys so let me
285:08 - explain you with the code what I mean by
285:12 - this definition so what I'm going to do
285:16 - is first of all I'm going to take the
285:19 - top level layer of the gaussian pyramid
285:23 - so top level layer of the gaussian
285:27 - pyramid is the last image which is
285:29 - generated using this for Loop so let us
285:32 - say we have six images or five images
285:37 - using this for Loop so what we are going
285:41 - to do is because we have appended
285:43 - each and every image to this list right
285:48 - so we have all the images inside this
285:51 - list so we can just get the last image
285:57 - using the indexing so again I'm going to
286:01 - use the layer variable and then I'm
286:05 - going to just say GP for gaussian
286:08 - Pyramid list and then there is
286:13 - the index 5 because last image will be
286:16 - available at the index 5 of this list so
286:21 - we get the last image of ah that
286:25 - gaussian pyramid and then let's show
286:28 - this image so I am going to just say
286:31 - CV2 dot I am show and this is the upper
286:36 - level or the last image so I'm going to
286:39 - say upper level gaussian pyramid and
286:41 - then we are going to pass this layer
286:44 - variable here so this is going to show
286:46 - just the last image of this list and let
286:51 - us just comment this code out because we
286:54 - don't want to see all the images and
286:56 - then I'm going to create a new list for
286:59 - laplacian Pyramid so I'm going to just
287:02 - say LP for laplacian pyramid and then
287:05 - I'm going to create a list
287:07 - using the layer variable itself as we
287:12 - have done for the gaussian pyramid list
287:15 - also so the first element here is the
287:19 - layer variable itself and now we are
287:21 - going to use the for Loop
287:24 - and then I in range and this time what
287:29 - we are going to do is you might already
287:31 - know how to use the range function and
287:35 - if you don't know you can see you can
287:38 - give the stop integer here or you can
287:43 - give a multiple
287:45 - parameters here so you can see there is
287:48 - one more implementation of this range
287:51 - function so you can give the start
287:55 - parameter and the stop range so start is
288:00 - the starting point stop is the stopping
288:03 - point and also you can give the steps so
288:06 - this step means ah in what number you
288:10 - want to reduce ok so let us say we want
288:13 - to start from 5 and then we want to go
288:17 - until 0 and we want to reduce in the
288:21 - step of minus 1 okay so five four three
288:26 - two one so let's print the value of I
288:30 - first of all if you uh might be
288:33 - interested in the result of this range
288:36 - function then let's just run this code
288:39 - and let's see what happens so this is
288:42 - the images which we get but we are not
288:45 - interested in these images we are
288:47 - interested in the print function output
288:50 - so you can see the output of this print
288:53 - function code is 54321 as I said the
288:58 - lower limit is not reached so if you
289:02 - give 0 here then it's going to go until
289:05 - 1 and not 0 if you give 6 here then it's
289:09 - going to go until 5 not 6.
289:12 - so let me repeat the definition of
289:14 - laplacian pyramid once again so
289:17 - laplacian pyramid is formed by the
289:20 - difference between that level in the
289:23 - gaussian pyramid and the extended
289:26 - version of its upper level in the
289:30 - gaussian pyramid so let us first create
289:33 - the extended version of that level so we
289:37 - are going to just create a variable
289:39 - called gaussian
289:42 - extend or extended and then we are going
289:46 - to extend the level of that image which
289:50 - are there in the gaussian
289:52 - pyramid list by using C V 2 dot dot pair
289:58 - up method and here what you need to give
290:01 - is the gaussian pyramid list and then we
290:06 - just need to get the index I from this
290:10 - so this line gives us the extended
290:12 - version of the upper level in gaussian
290:15 - pyramid now let's create the laplacian
290:18 - Prima pyramid so laplacian is equal to
290:21 - CV2 dot subtract because we want to find
290:25 - out the difference between that level in
290:29 - the gaussian pyramid and the extended
290:31 - version of its upper level so I'm going
290:35 - to just say GP for gaussian pyramid and
290:38 - then we are going to just say I minus 1
290:43 - as the first parameter and the second
290:45 - parameter is the extended version of the
290:50 - gaussian upper limit and now we can use
290:53 - the I am show method to show all these
290:57 - laplacian images so I'm going to just
291:00 - say CV2 dot I am show and once again I'm
291:03 - going to use Str function to convert
291:06 - from a number to string and then in the
291:10 - next parameter I'm going to just pass
291:12 - the laplacian parameter here as an image
291:17 - source so what do you think will this
291:20 - code work so let's see what happens when
291:24 - we are going to run this code so you can
291:26 - see the laplacian pyramid looks just
291:29 - like the edge detection so all the edges
291:34 - are shown here on every image this is
291:38 - the first level this is the second level
291:41 - third level fourth fifth level so these
291:45 - images are called the laplacian pyramid
291:49 - now what is the use of creating those
291:53 - laplacian pyramids or the gaussian
291:56 - pyramids so the laplacian and gaussian
291:59 - pyramid helps us to blend the images and
292:03 - the Reconstruction of the images so
292:06 - these are the two benefits of creating
292:09 - those laplacian and the gaussian
292:12 - pyramids so in the next video we are
292:14 - going to see how we can blend the images
292:16 - or how can we reconstruct the images
292:20 - using the opencv and the image pyramids
292:25 - in the last video we have seen what are
292:28 - image pyramids and I have told you there
292:31 - are two kinds of image pyramids in
292:33 - opencv one is called the gaussian
292:37 - pyramid and the other is called the
292:40 - laplacian pyramid and we have seen in
292:42 - the last video how we can create the
292:46 - gaussian pyramid and the laplacian
292:48 - pyramid
292:49 - now in the last video I have also told
292:52 - you some applications of image pyramids
292:55 - and one of the application of image
292:58 - pyramids is the image blending
293:02 - so let me show you one example so here
293:05 - in this code I have two images one is of
293:09 - apple and other is of orange and I want
293:14 - to blend or merge these two images
293:19 - so let me just run this code first of
293:22 - all so you can see there are two images
293:25 - first is of apple and other is of orange
293:30 - and I have also printed the shape of
293:33 - these two images so you can see the
293:37 - shape is similar 512 by 512 and orange
293:42 - image shape is also 512 by 512.
293:46 - so here what I want to do is I want to
293:52 - blend half of the orange to half of the
293:56 - Apple so let's say I want to just blend
293:59 - right hand side of this orange to the
294:03 - left hand half of this Apple so how can
294:08 - I achieve this now you might say that I
294:12 - can just cut these two images into half
294:16 - and then I can stack these two images
294:18 - side by side and I will get the half and
294:23 - half of the two images and that's how I
294:26 - can just get the result so let's first
294:29 - of all try this technique first of all
294:32 - we are going to just create the half and
294:36 - half of the apple and orange images and
294:39 - we are going to just stack these images
294:41 - side by side so let's say I'm going to
294:44 - create the variable called Apple
294:47 - underscore orange and then here there is
294:52 - a method in numpy so I'm going to just
294:56 - say numpy dot h stack so there is this
295:01 - method called H stack and here what I
295:04 - can do is in the form of Tuple I can
295:07 - provide the half of my Apple image so
295:10 - apple is the image variable name and
295:14 - then what I am going to do is the half
295:17 - of this image because this image is 512
295:21 - by 512 so I am going to just give this
295:25 - kind of expression colon comma and then
295:28 - colon
295:29 - 256 which is the half of the Apple image
295:33 - on the left hand side right and then I
295:37 - am going to just do the same with the
295:41 - orange image so I'm going to just take
295:43 - orange and then colon
295:46 - comma 256
295:49 - colon so one thing to observe here is I
295:52 - have taken colon before 256 in the Apple
295:57 - image and I have taken colon after 256
296:02 - in the orange image and then I am going
296:06 - to just show this apple orange image and
296:11 - let's see what result we get when we run
296:14 - our code
296:16 - so these two are the apple and orange
296:20 - image and this is the result of adding
296:24 - the two halves of the orange and the
296:27 - Apple image but still you can see this
296:29 - line which is clearly visible and from
296:32 - this line you can say half of this is
296:35 - orange and half of this is an apple
296:39 - so in image blending what we need to do
296:42 - is we need to blend this line also so
296:47 - the orange and the Apple image should be
296:50 - merged or Blended in a perfect way so
296:54 - for blending this half apple and half
296:57 - orange image what we can do is we can
297:00 - use the image pyramid techniques to
297:04 - blend these two images now in order to
297:07 - blend two images using image pyramids
297:10 - Technique we need to follow five steps
297:14 - the first step is to load two images in
297:18 - our case these images are of apple and
297:21 - orange which we are already doing so
297:24 - first step is to load these two images
297:27 - the second step is to find out the
297:30 - gaussian Pyramid of our apple and orange
297:34 - image
297:35 - the third step will be from these
297:38 - gaussian pyramids find out the laplacian
297:41 - pyramids ok so we will find out the
297:44 - gaussian pyramid in the second step and
297:47 - then in the third step we are going to
297:49 - find out the laplacian pyramids now in
297:53 - the first step we are going to join the
297:55 - left half of the apple and the right
297:58 - half of the orange in each levels of
298:03 - laplacian pyramid
298:05 - and finally in the fifth step what we
298:08 - are going to do is we are going to just
298:10 - join these image pyramids and
298:13 - reconstruct the original image
298:17 - so let us follow these steps one by one
298:20 - and let's see what result we get so as I
298:24 - said first step is already done which is
298:27 - just loading these two images and the
298:30 - Second Step would be to find out the
298:33 - gaussian pyramid so let me just ah
298:36 - just write this step generate gaussian
298:39 - pyramid for Apple first of all and then
298:42 - we are going to find out the gaussian
298:44 - Pyramid of the orange so first of all
298:48 - what I am going to do is I am going to
298:50 - just copy the Apple image so I'm going
298:53 - to just say apple underscore copy is
298:57 - equal to Apple dot copy so there is a
299:01 - method called copy which you can use to
299:04 - copy the this image so from this copy
299:08 - what we are going to do is we are going
299:09 - to generate the gaussian pyramid so I am
299:12 - going to once again name my variable as
299:15 - GP let's say underscore apple and then
299:20 - we are going to just pass our image
299:24 - which we have copied in the form of list
299:27 - so I am going to just say apple copy
299:30 - here so these steps we have already seen
299:32 - in the last video how to create the
299:35 - gaussian pyramid and the laplacian
299:38 - Pyramid of an image so I am not going to
299:41 - explain this in detail if you want ah
299:44 - the detailed explanation you can see the
299:47 - last video next what I am going to do is
299:50 - I'm going to create a for Loop and I'm
299:53 - going to just say for I in our range so
299:57 - I'm going to use the range function and
300:00 - we are going to use the six levels in
300:05 - this example so I am going to provide
300:07 - the range up to 6 and then what we are
300:10 - going to do is we are going to just say
300:13 - apple copy or you might have named this
300:17 - variable as Apple layer also because we
300:20 - are just creating multiple layer of the
300:24 - Apple image for the gaussian pyramid
300:26 - right and then we are going to use the
300:30 - CV2 dot pair down method to create the
300:35 - gaussian pyramid okay this we have
300:38 - already seen in the last video and now
300:41 - as an argument we are going to pass our
300:44 - Apple copy a variable here and in The
300:47 - Next Step what we are going to do is we
300:49 - are going to just append to our GP
300:52 - underscore Apple variable which is our
300:54 - gaussian pyramid for the Apple image and
300:58 - then we are going to just append this
301:00 - apple copy after we have applied pair
301:03 - down method on the same image so this is
301:06 - just giving us multiple layer of the
301:11 - Apple image right the same method we are
301:16 - going to apply for the orange also so
301:19 - I'm going to just copy this code and
301:22 - then I'm going to just paste this code
301:24 - once again and this time this will be
301:26 - for orange
301:29 - and I am going to just say this is the
301:32 - orange copy and we are going to copy
301:36 - from the orange image and then we are
301:40 - going to just generate the gaussian
301:43 - pyramid for the orange image and this
301:47 - will be passed here and also here and
301:51 - also here and also here and this
301:56 - gaussian pyramid orange will be passed
301:58 - here okay so we have generated the
302:01 - gaussian pyramid for the apple and the
302:04 - orange now we are going to generate the
302:07 - laplacian pyramid for apple and orange
302:10 - so this also we have seen in the last
302:12 - video so I'm going to just comment
302:15 - generate laplacian pyramid for Apple
302:19 - first of all and to find out the
302:22 - laplacian pyramid for the Apple what we
302:25 - are going to do is we are going to once
302:28 - again take our Apple copy and then using
302:34 - our gaussian pyramid so let us take
302:36 - gaussian pyramid for the apple and we
302:39 - are going to use the fifth element of
302:44 - this list so what we have learned in the
302:47 - last video how we can find out the
302:49 - laplacian pyramid a level in the
302:51 - laplacian pyramid is formed by the
302:54 - difference between the level in the
302:57 - gaussian pyramid and extended version of
303:00 - its upper level in the gaussian pyramid
303:03 - so this difference we are going to find
303:05 - out in this step so I am going to just
303:07 - say this is LP for the Apple which
303:13 - stands for laplacian Pyramid for the
303:15 - Apple is equal to in the list we are
303:18 - going to just pass the Apple copy and
303:21 - then we are going to use the for Loop so
303:24 - for I in the range so we are going to
303:29 - take the range and in the last video I
303:31 - have shown you how to take the range for
303:34 - the LaPlace in pyramid so we want to go
303:37 - from 5 until 0 in the steps of minus 1
303:43 - and then in the next step we are going
303:45 - to create the gaussian extended
303:48 - variables gaussian extended is equal to
303:51 - CV 2 dot pair of this time we are going
303:56 - to use the pair up method and then we
303:59 - are going to pass our GP Apple which is
304:02 - gaussian Pyramid for apple and then the
304:06 - index here will be I in the next step we
304:08 - are going to create the laplacian
304:10 - variables is equal to CV2 dot subtract
304:14 - so there is a method in CV2 which is
304:18 - called subtract and then we are going to
304:20 - take our gaussian pyramid for the Apple
304:23 - so GP apple and the index here will be I
304:27 - minus 1 and the second argument for this
304:31 - subtract method will be our gaussian
304:35 - extended variable so we are going to
304:36 - just pass this gaussian extended
304:39 - variable and in the next step we are
304:42 - going to just append to our laplacian
304:44 - pyramid for the Apple so LP underscore
304:47 - Apple dot append and we are going to
304:51 - just append this laplacian variable to
304:55 - the
304:56 - laplacian pyramid for the Apple same we
305:01 - will do for the orange image also so we
305:05 - are going to generate the laplacian
305:07 - pyramid for the orange orange here and
305:12 - this will be the core p of the
305:16 - orange copy here and here also and then
305:21 - this will be the
305:24 - GP Orange right this also will be GP
305:29 - orange this also will be g b orange and
305:33 - here instead of LP Apple we are going to
305:36 - just say LP orange and then we are going
305:40 - to just pass this variable here also so
305:44 - now we have finished three steps one is
305:47 - to load both the images second is to
305:49 - find out or generate the gaussian
305:51 - pyramid and the third step is to
305:54 - generate the laplacian pyramid for both
305:57 - the images now the fourth step is to
306:01 - just join the half of these two images
306:05 - so what I'm going to do is now I'm going
306:08 - to just create one more variable which
306:11 - will be apple underscore orange
306:15 - underscore let's say pyramid is equal to
306:19 - and also we are going to create a
306:21 - variable called n and we are going to
306:24 - see ah later how to use this variable
306:28 - and then we are going to use the for
306:31 - Loop and then we are going to create two
306:35 - variables one for the first image so I'm
306:39 - going to just say
306:41 - Apple
306:43 - and then lap
306:45 - comma orange lab okay so these two
306:49 - variables I am creating just same as
306:54 - this I in this for Loop in zip so there
306:58 - is a method zip which we can use to zip
307:02 - the LaPlace in pyramid one which is for
307:06 - the apple and for the orange also so I
307:09 - am going to just say LP for Apple comma
307:14 - LP for the orange and inside this for
307:18 - Loop first of all we are going to just
307:20 - increment the value of n by 1 each time
307:24 - so n plus equals 1 and in the next step
307:30 - we are going to find out the shape of
307:32 - the Apple image so the Apple image shape
307:35 - gives us three values first is columns
307:39 - so I am going to just say CEO LS for
307:41 - columns then rows and then the third
307:45 - value is the number of channels and then
307:48 - we are going to just say apple lab
307:52 - dot shape in the next step we are going
307:55 - to just create a variable called
307:57 - laplacian and we are going to just join
308:00 - the two halves of these two images which
308:04 - we are getting inside the variable Apple
308:09 - lab and orange lab so we are basically
308:12 - doing this step after applying the
308:16 - gaussian pyramid and the LaPlace in
308:19 - pyramid on both the images so NP dot h
308:23 - take method we are going to apply in
308:26 - this step so I am going to just write NP
308:29 - dot h stack and then as an argument what
308:33 - we are going to do is we in the form of
308:34 - Tuple first of all we are going to take
308:38 - our Apple lamp variable which is this
308:42 - one and in the square bracket we are
308:44 - going to just write colon comma 0 comma
308:49 - int so we are going to just type cast
308:53 - the number of columns in the apple shape
308:58 - so this we got from the shape of the
309:01 - Apple index and then divided by 2 so we
309:07 - are going to just
309:08 - dividing the columns into half and same
309:12 - we will do for the orange lab so we are
309:15 - going to just say orange lap in the
309:18 - square bracket colon comma
309:21 - int and then once again in the
309:26 - parenthesis we are going to just say
309:28 - calls for the number of columns divided
309:31 - by 2 and then Olin as we have done in
309:35 - this step also and at last we are going
309:38 - to just append this laplacian variable
309:40 - to this list which we have created so
309:44 - Apple underscore orange underscore
309:47 - pyramid dot append and then we are going
309:50 - to pass the laplacian variable here now
309:53 - the last and the final step is to
309:55 - reconstruct our image so let's
309:57 - reconstruct our image so now what we are
310:01 - going to do is we are going to once
310:03 - again create a variable called Apple
310:05 - orange underscore reconstruct is equal
310:10 - to this will be the first index of our
310:13 - Apple orange pyramid so I'm going to
310:15 - just say apple orange underscore pyramid
310:18 - and this will be the zeroth index and
310:21 - once again we are going to use the
310:22 - follow so for I in the range so we are
310:28 - going to go from 1 until 6 and the
310:32 - default step is of 1 so we don't need to
310:36 - give the third argument and inside the
310:39 - for Loop we are going to just take this
310:41 - variable once again and then we are
310:44 - going to apply the pair up method on
310:48 - this so CV2 dot pair up and as an
310:52 - argument we are going to pass the same
310:55 - variable so we are going to just apply
310:58 - the pair up on this apple orange
311:02 - reconstruct from the zeroth index of the
311:06 - pyramid up to the sixth level and the
311:09 - last step will be to add all the layers
311:13 - so Apple orange
311:16 - reconstructed once again or reconstruct
311:19 - is equal to CV2 dot add so this is also
311:25 - one method which is called add and here
311:28 - we are adding Apple orange pyramid and
311:32 - the reconstructed Apple orange
311:35 - image okay so this is this variable
311:39 - which we got by just adding the left and
311:43 - right halves of each level and then we
311:46 - are just reconstructing this image using
311:50 - the pair up method and thus just adding
311:53 - the pyramid level so this should be I
311:56 - think the index I right we cannot just
312:00 - add the list to the image directly okay
312:04 - so this will be at each layer we are
312:07 - just reconstructing and adding it to the
312:11 - image which we got by just addition of
312:15 - this half of the images now in the end
312:18 - let's try to just load this
312:21 - reconstructed Apple orange image in the
312:26 - I am show window and let's hope it works
312:29 - I haven't checked it yet so I'm not sure
312:33 - it will work or not and you can see it's
312:35 - working in the first go so that's a good
312:39 - thing so you can see the difference
312:42 - so this
312:44 - result we got by just stacking this
312:48 - apple and orange image side by side but
312:51 - this line is clearly visible but when we
312:56 - applied the gaussian pyramid and the
312:59 - laplacian pyramid technique for blending
313:02 - the images then you can see this line is
313:06 - perfectly Blended and this line is not
313:10 - any more visible so this is the perfect
313:14 - blending of the orange and the Apple
313:17 - image so this is how you can use the
313:21 - laplacian and gaussian pyramids to
313:24 - reconstruct and blend two images
313:27 - together and result is in front of you
313:30 - so you can see how it can blend two
313:33 - images so perfectly so this is how you
313:36 - can blend images using image pyramid
313:38 - technique in this video we are going to
313:41 - understand what Contours are and we are
313:43 - going to see how to find Contours and
313:46 - how to draw Contours
313:48 - so first of all what are Contours
313:50 - so Contours can be explained as the
313:53 - curve joining all the continuous point
313:56 - along the boundary which are having the
313:58 - same color or intensity
314:01 - now Contours can be a useful tool for
314:05 - shape analysis or object detection or
314:08 - object recognition now for better
314:12 - accuracy we generally use binary image
314:15 - for finding the Contour so first of all
314:18 - we are going to generate the binary
314:21 - image and then before finding out the
314:23 - Contours we are going to apply the
314:25 - threshold or Kenny Edge detection to
314:29 - find the Contours on the image so let's
314:32 - start with an example so here I have a
314:35 - simple code which reads an image and
314:37 - then converts this image into a gray
314:39 - scale image and then I am just showing
314:43 - both the images using I am show method
314:46 - so let's run this code and let's see
314:48 - what result we get so this is the
314:51 - original image with these colors and
314:55 - after the conversion of this image to
314:58 - the grayscale image this is the result
315:00 - which we are get typing and then we are
315:03 - going to find out the threshold or the
315:06 - Kenny Edge so in this example we are
315:09 - going to just apply the threshold so for
315:12 - applying the threshold on this image we
315:15 - are going to Define first of all two
315:17 - variable r e t comma thresh is equal to
315:22 - c v e 2 dot threshold so there is a
315:27 - method called threshold which we have
315:29 - already seen how threshold work in
315:32 - detail in the previous videos so the
315:34 - first argument which this threshold
315:36 - method takes is the image so we are
315:38 - going to pass our grayscale image as the
315:42 - source the second argument is the
315:44 - threshold value so because it is a
315:46 - binary image let's set the threshold to
315:49 - 127 which is around half of the 255
315:54 - right the third argument is the maximum
315:58 - value so in the maximum value here will
316:01 - be 255 the next argument will be the
316:04 - type and type here will be zero so this
316:07 - is going to give us the threshold value
316:10 - for this grayscale image and after
316:13 - finding out the threshold of this image
316:15 - we are going to find out the Contours so
316:19 - for this we are going to Define two
316:21 - variables one is Contours and the second
316:24 - is the hierarchy because the method
316:28 - which we are going to use which is CV2
316:31 - dot find Contours
316:34 - this is the method it's going to give us
316:37 - these two values Contours and the
316:39 - hierarchy and we are going to see what
316:42 - are Contours and hierarchy in details
316:45 - after applying this method on this image
316:48 - so the first argument will be the thresh
316:51 - which we got using this threshold method
316:54 - the second argument will be the Contour
316:57 - mode so this is called the Contour
317:01 - retrieval mode also and there can be
317:04 - several possibilities here which we can
317:07 - apply but for Simplicity and in the most
317:11 - common case we use r e t r underscore
317:14 - tree here okay as the mode the third
317:17 - argument here will be the method which
317:20 - we want to apply and this is also called
317:23 - the Contour approximation method and
317:26 - here also several possibilities are
317:29 - possible but for now what we are going
317:32 - to use here is this will be c v two dot
317:36 - approx none so now as you are seeing
317:39 - here this fine Contour method gives us
317:42 - Contours and hierarchy
317:44 - so the Contour is a python list of all
317:48 - Contours in the image and each
317:51 - individual Contour is a numpy array of X
317:55 - comma Y coordinates of boundary points
317:58 - of the object and the hierarchy is the
318:01 - optional output Vector which is
318:04 - containing the information about image
318:07 - topology and this we are going to see in
318:09 - the later videos so for now we are only
318:13 - concerned about finding out the Contours
318:16 - so for this as I said this contains the
318:19 - number of Contours right so we can print
318:23 - out these number of Contours is equal to
318:26 - and then we are going to just convert
318:30 - this number into the string and there is
318:33 - a method called length and then inside
318:36 - this length method we are going to pass
318:38 - our Contour variable so this line is
318:42 - going to print out the number of
318:43 - Contours which are found inside the
318:47 - image which we are providing so let's
318:49 - run this code and let's see what result
318:51 - we get so we already know that this
318:54 - gives us a grayscale image and the
318:57 - original image but we are interested in
318:59 - this print message and the number of
319:03 - Contours which are found is 9 inside the
319:07 - source image which we are providing here
319:10 - now we already found out the number of
319:13 - Contours now we need to draw these
319:16 - controls on the image itself so how can
319:20 - we achieve this but before this let's
319:22 - see the individual Contour also so I am
319:26 - going to just print out the value of the
319:29 - first Contour which will be at index 0
319:32 - so let us run it once again and let's
319:35 - see what happens so we are running this
319:39 - code once again and you can see after
319:41 - printing out the number of Contours it
319:45 - is going to give us the numpy array of
319:49 - the X and Y coordinates so if we plot or
319:54 - join all these X and Y coordinates we
319:57 - are going to get the boundary of the
320:00 - Contour so now we are going to just take
320:02 - these Contours and pass it to a method
320:05 - called Draw Contours which is going to
320:07 - draw or join all these coordinates of
320:10 - those Contours so to get this we are
320:14 - going to just say c v 2 dot draw
320:17 - Contours and then the first argument
320:20 - here will be our original image because
320:23 - we want to draw the Contours on our
320:26 - original image so this will be the IMG
320:29 - and its the original image and the
320:32 - second argument will be the Contours so
320:34 - we are going to just pass the Contours
320:37 - which we found inside the image the
320:40 - third argument will be the Contours
320:42 - indexes so if we ah just give here minus
320:47 - 1 then it's going to draw all the nine
320:50 - Contours which were found inside the
320:53 - image these all Contours so first of all
320:57 - we will give minus 1 here as an argument
320:59 - and then we will see how to give other
321:02 - arguments uh as the numbers here also
321:05 - the fourth argument here will be I think
321:08 - the color so we are going to just give
321:11 - the color 0 comma 255 comma 0 let us say
321:17 - and the next argument will be the
321:20 - thickness so we are going to take the
321:22 - thickness 3 here so using this method
321:25 - what we have achieved is we have drawn
321:28 - the Contours on the original image so
321:32 - let's run this code once again and let's
321:34 - see what result we get so you can see
321:37 - this was the grayscale image and this we
321:40 - have used for finding out the Contours
321:43 - but the interesting image here is this
321:46 - one and here you can see all the
321:49 - Contours are drawn on this image so all
321:54 - the green lines or green
321:57 - boundaries are all Contours so because
322:01 - we have given minus 1 it has drawn all
322:04 - the Contours on this image and we can
322:08 - also give the Contour index so let us
322:11 - say we just want to ah find out the
322:15 - Contour 0 which will be the first
322:17 - Contour which is found inside the image
322:19 - we are going to just run this code once
322:24 - again and the first Contour which was
322:26 - find out found out is this Contours this
322:30 - ah P Contour right in a similar way we
322:34 - can go up to eight so 0 1 and let's
322:38 - rerun this code again you will see that
322:42 - the second Contour is this Contour so
322:46 - this whole Contour from the boundary of
322:50 - this image is the second contour and in
322:53 - a similar way you can go let's say 2 I
322:58 - am going to run this code once again you
323:00 - will see the next Contour here and
323:03 - similarly you can go up to the index 8
323:05 - because the total number of Contours are
323:08 - 9 and we are starting from the index 0
323:11 - that's why we can go up to eight so this
323:14 - value depends on the number of Contours
323:17 - ok so because we found out the number of
323:20 - Contours are nine so that is why we can
323:24 - go up to eight and let's run this code
323:26 - and the last Contour which was find out
323:29 - and we have drawn this Contour here on
323:32 - this blue circle right now if we go
323:36 - Beyond this index let us say we give 9
323:39 - here we are going to get the error right
323:42 - so you can go up to 8 here and if you
323:45 - want to just draw all the Contours then
323:48 - you can just give minus 1 here and it's
323:51 - going to draw all the Contour on the
323:54 - image which you are providing so this is
323:57 - how you can find out the Contours and
324:00 - draw Contours on the images using fine
324:03 - contour and draw Contour methods in
324:06 - opencv in this video I am going to show
324:08 - you how you can create a very basic and
324:11 - simple motion detection and tracking
324:13 - system using Python and opencv
324:16 - so let me show you what we are going to
324:19 - achieve at the end of this video
324:22 - so I have this video which is a sample
324:26 - video and you can see some people are
324:29 - walking around inside this video now
324:33 - what I want to do here is I want to show
324:36 - these rectangles around
324:39 - these moving people or persons so this
324:44 - is tracking and when some movement
324:46 - occurs I also want to show this kind of
324:49 - status that status is movement because
324:52 - somebody is moving inside the video so
324:56 - if nobody is moving this status will be
324:59 - blank and if somebody is moving then the
325:03 - status will be movement so this is what
325:07 - we are going to achieve at the end of
325:09 - this video so we are going to try to
325:14 - track each and every person and also we
325:17 - are going to track this person with this
325:21 - rectangle and also we will show the
325:25 - status as movement when somebody moves
325:28 - inside the video
325:30 - so let's get started so to start with I
325:34 - have this basic code which just reads a
325:39 - video using video capture class and then
325:43 - if this video is valid then I'm going to
325:46 - just show this frame by frame inside I
325:50 - am show window and I am sure you might
325:54 - be knowing all this code because I have
325:57 - shown you step by step how to capture
326:00 - the video or how you can read the video
326:04 - frames using video capture method okay
326:08 - so this is just to load this video and
326:13 - show it frame by frame using amp show
326:15 - methods so let me run this code first of
326:18 - all to start with so our original video
326:22 - looks like this so some people are
326:24 - moving but we want to track the movement
326:27 - of each and every person and also we
326:30 - want to show a rectangle around them
326:33 - whoever is moving so let's get started
326:36 - so under this video capture code line
326:41 - what I'm going to do is first of all I
326:44 - want to read two frames from the cap
326:49 - instance so I'm going to just copy this
326:53 - code and paste it here so this will be
326:57 - our frame 1 let's say and similarly I am
327:01 - going to just read the second frame so
327:05 - ah simply we are just declaring two
327:08 - frame one after another okay and we do
327:12 - not need this code anymore so first of
327:16 - all I'm going to declare a variable diff
327:19 - and using
327:21 - CV2 dot a b s diff method so absolute
327:26 - difference we are going to find out the
327:29 - difference between the first frame and
327:32 - the second in frame so this method ABS
327:36 - diff is for finding out the absolute
327:39 - difference between the first frame and
327:42 - the second frame now once we have the
327:45 - difference then we are going to convert
327:48 - this difference into a gray scale mode
327:53 - so we are going to just say
327:55 - gray is equal to
327:57 - CV2 Dot
328:00 - convert color so CVT color and the first
328:05 - parameter here will be our difference
328:08 - which we have found between the two
328:10 - frames so I am going to just pass diff
328:13 - as the first argument and the second
328:15 - argument will be c v 2 dot we are going
328:18 - to convert this BGR color to the gray
328:23 - scale mode and why we are finding out
328:25 - the grayscale mode of this diff because
328:30 - we are going to find out the Contour in
328:33 - the later stages and in the last video
328:35 - we have learned that it is easier to
328:38 - find out the Contours in this grayscale
328:41 - mode as compared to the colored mode or
328:45 - the B gr mode so once we have this
328:49 - grayscale mode we are going to just blur
328:52 - our grayscale frame so we are going to
328:57 - just declare a variable called blur and
329:01 - then we are going to apply the gaussian
329:04 - blur on our gray variables so CV2 dot
329:10 - gaussian blur the first parameter here
329:14 - will be gray so let's give this gray
329:18 - parameter which we have defined here the
329:21 - second parameter here is the case size
329:24 - or the kernel side so let's say we want
329:26 - to provide the kernel size 5 comma 5 and
329:30 - the third parameter here will be the
329:34 - sigma x value so we are going to just
329:36 - pass 0 here as the sigma x value now we
329:41 - are going to find out the threshold so
329:44 - we are going to just say underscore
329:47 - because we don't need this first
329:49 - variable and then the second variable
329:52 - will be thrash is equal to CV2 dot
329:57 - threshold and the first parameter which
330:00 - it takes is the source so we are going
330:03 - to pass our blurred image as the source
330:07 - and then the second parameter here will
330:11 - be the threshold value so we are going
330:14 - to just provide 20 here then the maximum
330:19 - threshold value will be 255 then the
330:23 - type will be ah CV2 dot thresh binary so
330:28 - in the next step what we are going to do
330:29 - is we are going to dilate the
330:31 - thresholded image to fill in all the
330:35 - holes this will help us to find out the
330:39 - better Contours so there is a method
330:41 - called CV2 dot dilate so we are going to
330:43 - just declare a variable called dilated
330:46 - and then we are going to apply this
330:49 - method so CV2 dot dilate which takes few
330:54 - argument the first argument will be our
330:57 - thresholded version of the image the
331:01 - second argument here will be the kernel
331:03 - so kernel let us say for now we are
331:06 - going to provide none here okay so the
331:08 - kernel size will be none and then third
331:13 - parameter will be the number of
331:15 - iterations so let's provide the number
331:17 - of iterations and the number of
331:19 - iterations we are going to provide here
331:22 - will be three so if it doesn't work we
331:25 - can increase or decrease the number of
331:27 - iterations now in The Next Step what we
331:29 - are going to do is we are going to find
331:31 - out the Contour so as you all know that
331:34 - Contour or fine Contour method is going
331:37 - to give you two Result One Is The
331:40 - Contours and other is the hierarchy so
331:43 - we are going to just say contour and the
331:45 - second result we are going to just say
331:48 - underscore because we are not going to
331:50 - use this second result and then we are
331:54 - going to just say CV2 dot find Contours
331:59 - and we are going to find the Contours on
332:03 - this dilated image so we are going to
332:05 - say dilated now the next argument here
332:08 - will be the mode so the mode which we
332:12 - are going to use here will be writer
332:15 - underscore tree so I'm going to just
332:17 - write ret underscore tree which is most
332:22 - commonly used and then the next argument
332:25 - here will be the method so the method
332:28 - here will be CV2 dot ah chain approx
332:33 - simple and once we have our Contours we
332:37 - are going to just draw the Contours
332:39 - because we already found out the
332:41 - Contours so we are going to just say
332:44 - draw Contours and the first argument
332:47 - here will be frame 1 because we want to
332:50 - apply all the Contours on the original
332:54 - frame right so we are going to apply all
332:58 - the Contours which we have found using
333:00 - all these method on the frame one and
333:04 - then the second argument here will be
333:07 - the Contour so you can just give the
333:12 - Contours here and the third argument
333:15 - here will be uh the Contour ID I can
333:19 - just say minus 1 which is going to apply
333:23 - all the Contours and the third and the
333:26 - next argument will be the color so let's
333:28 - say we want to provide the green color
333:31 - so I'm going to just say 0 comma 255
333:35 - comma 0 and the next will be the
333:39 - thickness so let us say we want to
333:40 - provide the thickness of two here
333:43 - so now it's going to draw all the
333:45 - Contours which we have found with the
333:48 - difference of frame 1 and Frame 2 right
333:51 - and then we are going to just display
333:54 - this Frame one so we can just say this
333:58 - is our feed and the result after
334:03 - applying the Contour will be saved in
334:06 - the frame 1 which we will display now in
334:09 - The Next Step what we are going to do is
334:12 - we are going to assign the value inside
334:15 - Frame 2 into frame 1 so we are going to
334:19 - just say frame 1 is equal to frame 2 and
334:23 - then inside our Frame 2 we are going to
334:26 - read a new value so we are going to just
334:29 - say
334:30 - r e t comma Frame 2 is equal to cap dot
334:37 - read okay so we are reading the new
334:40 - frame in the variable Frame 2 and before
334:44 - reading the new frame we are assigning
334:47 - the value inside the frame 2 to the
334:50 - frame 1 in this way we are reading the
334:53 - two frames and finding out the
334:55 - difference between ah the two frames so
334:58 - let us run this code and let's see if it
335:00 - works or not let us test this so you can
335:04 - see now there are these Contours which
335:08 - are drawn around all the moving ah
335:12 - persons also there are some Contours ah
335:16 - which are drawn around this rope which
335:18 - is also moving right so we have
335:22 - successfully determined the Contours and
335:25 - we have already drawn these Contours on
335:29 - the frame one
335:31 - but this was not the result we are
335:34 - looking for we want to draw the
335:36 - rectangle around these moving persons
335:39 - and also we want uh some noises to be
335:43 - removed so we do not want to draw the
335:47 - Contour on the moving rope let us say ok
335:51 - so how to remove these noises and how to
335:54 - draw these rectangles let's see so now
335:58 - in The Next Step what we are going to do
336:00 - is under or before we are drawing these
336:05 - Contours we do not want to draw the
336:07 - controls now we want to draw the
336:10 - rectangles right so what we are going to
336:13 - do is we are going to iterate over all
336:16 - the controls so we are going to just say
336:18 - for
336:20 - Contour so
336:22 - from Contours we are going to find out
336:24 - Contour in Contours right so this is the
336:31 - list and we are iterating over this list
336:33 - so inside this for Loop the first step
336:36 - will be to save all the coordinates of
336:40 - the found Contours ok so we are going to
336:45 - define the x coordinate then the y
336:49 - coordinate and then we are going to just
336:53 - say width comma height and there is a
336:57 - method called bounding rect which we are
337:00 - going to apply on the Contour so we are
337:03 - going to just say is equal to c v 2 dot
337:07 - bounding rect this is the method which
337:10 - we are going to apply which is going to
337:12 - give us the x and y coordinate and the
337:16 - width and height right and we are going
337:19 - to apply this bounding rect method on
337:22 - the Contour which we are getting using
337:25 - this Contours list now in the next step
337:28 - we are going to find out the area of the
337:31 - Contour and we are going to just say if
337:34 - this area is less than certain value
337:37 - then we don't want to do anything we do
337:40 - not want to ah draw a rectangle or
337:42 - anything we just want to continue
337:45 - otherwise if this ah Contour area is
337:49 - greater then let us say ah some kind of
337:52 - a person's area then we want to draw a
337:56 - rectangle on it so inside this for Loop
337:59 - we are going to just ah Define ah if
338:02 - condition so we can say if c v 2 dot
338:07 - Contour area so there is a method called
338:11 - Contour area which is this one where we
338:16 - can pass our Contour so we are going to
338:18 - pass our contour and if the area of this
338:22 - kind to let us say is less than
338:26 - 700 then we are going to just say
338:29 - continue so this code essentially mean
338:32 - that if the area of the Contour is less
338:36 - than 700 then we are going to do nothing
338:39 - we don't want to draw any rectangle
338:42 - otherwise if the area is greater than
338:45 - 700 then we want to draw the rectangle
338:48 - so we are going to just say CV2 dot
338:52 - rectangle we have already learned how to
338:55 - draw a rectangle on an image using the
338:59 - rectangle method the first argument here
339:01 - will be the source which will be frame
339:05 - one the second argument will be the
339:08 - point one so we are going to just say
339:11 - 0.1 will be X comma y the third argument
339:16 - will be 0.2 so we are going to just say
339:19 - X plus W comma y plus h the next
339:25 - argument will be the the color so let us
339:28 - say the color will be the same 0 comma
339:31 - 255 comma 0 the next argument will be
339:36 - the thickness let us say we want to give
339:39 - the thickness ah 2 as we have done ah
339:43 - with the draw Contour we have provided
339:45 - the thickness of two here right now in
339:49 - the next step we are going to just ah
339:51 - print some text on the image if some
339:55 - moment is observed so we can just say c
339:59 - v 2 dot put text this also we have seen
340:02 - in the previous videos how to put text
340:05 - on an image so this time the source will
340:08 - be our frame 1 the second will be the
340:11 - text so we will just say ah status let
340:15 - us say
340:16 - and if there is some movement we are
340:20 - going to just say ah colon in the curly
340:25 - brackets we are going to just use the
340:27 - format method so this is just formatting
340:31 - the result
340:32 - using the string and we are going to
340:35 - just say movement the next argument here
340:39 - will be the origin so where we want to
340:42 - put this text let's say we want to put
340:44 - this text on 10 comma 20 coordinate and
340:49 - then the next argument will be the font
340:51 - face so we are going to just say font
340:54 - face will be c v 2 dot font font Hershey
340:58 - Simplex let us say so we are going to
341:00 - use this font and the the next argument
341:04 - will be the font scale so let me just ah
341:08 - do this on the next line so what scale
341:11 - will be let us say 1 the next will be
341:17 - the color of the font so let us say the
341:20 - color will be 0 comma 0 comma 255 and
341:25 - then the last argument will be the
341:28 - thickness so let us say the thickness
341:29 - will be 3 and this code is going to put
341:32 - the rectangle around your moving persons
341:35 - if the area of that Contour is greater
341:40 - than 700 ok so let us run this code and
341:44 - lets see if it works or not so I am
341:47 - going to just run this code and you can
341:50 - see that status is moment because all
341:55 - the persons here are moving and you can
341:57 - see these rectangles which are drawn
341:59 - around the moving persons and this noise
342:02 - which we were seeing in the previous
342:06 - result is also gone around the movement
342:09 - of this rope okay so sometimes ah this
342:13 - ah rectangle is drawn on the movement of
342:16 - the Rope also so in this case you can
342:19 - also increase the expected area let us
342:23 - say we just want to find out the
342:26 - Contours which are greater than 900 and
342:29 - we can now you can see ah these
342:33 - rectangles are drawn around these moving
342:36 - persons with the area which have the
342:40 - Contour area more than 900 so you can
342:43 - remove these kind of noises from the
342:48 - frame using this area so this was a very
342:52 - basic example how you can detect the
342:56 - motion and track your moving object
343:00 - inside your video using Python and
343:03 - opencv in this video we are going to see
343:06 - how we can detect simple geometrical
343:08 - shapes using opencv so to start with I
343:13 - have this simple codes which reads an
343:15 - image and then show it into a I am show
343:19 - window so let's run this simple code
343:22 - first of all and let's see what it does
343:25 - so you can see I have this image which
343:28 - I'm loading into a opencv window using
343:31 - IM show method third and here we have
343:34 - some shapes so we have a pentagon Circle
343:39 - rectangle square triangle and this star
343:44 - shape right and let us say we want to
343:47 - detect using opencv which shape it is
343:51 - based upon the geometrical shape and we
343:55 - want to write the name on top of this
344:00 - shape so how we can achieve this lets
344:03 - see using openc beam
344:06 - so as you can see if the first step is
344:09 - to read an image and then in the second
344:12 - line I'm just converting this image into
344:16 - a grayscale mode image so using this
344:20 - code I am just converting this image
344:23 - into a grayscale mode and in the next
344:25 - step we are going to find out the
344:28 - threshold so I am going to just say
344:30 - underscore comma
344:32 - trash is equal to CV 2 dot threshold so
344:38 - CV2 Dot
344:40 - threshold and we are going to pass our
344:43 - image which is a grayscale image which
344:46 - we have converted as a source and then
344:49 - the next two values are the threshold
344:52 - values and the maximum value of the
344:57 - threshold so for now I am giving the
345:02 - threshold value to 40 because I know
345:05 - this will work but if you want to be
345:08 - more flexible you can always use the
345:11 - track bar to find out which threshold
345:14 - will work with your image the second
345:17 - value is the maximum value of the
345:19 - threshold and the next value will be the
345:21 - type so the type here will be CV2 dot
345:25 - thresh binary so we are going to just
345:28 - say CV2 dot thresh binary
345:31 - now in the next step we are going to
345:33 - find out the Contours so Contours we
345:37 - have already ah seen in the last videos
345:40 - how to find out the Contours and what
345:42 - are Contours so for that I am going to
345:44 - Define two variables one is Contours
345:48 - variable other is the underscore
345:50 - variable because we do not need the
345:53 - second
345:54 - result and then I am going to just say
345:58 - CB2 dot find Contours the first argument
346:02 - here will be the thresholded image and
346:07 - then the second argument here will be
346:10 - the mode and third will be the method so
346:12 - let us give these two values so c v two
346:15 - dot r e t r tree
346:19 - and the method will be CV2 dot chain
346:24 - approx none okay so let us give this
346:29 - method so this is the simple procedure
346:32 - to find out the Contours inside an image
346:35 - now in the next step I am going to
346:37 - iterate over all the Contours so I am
346:40 - going to just say for
346:43 - Contour in Contour so we are going to
346:46 - iterate over all the Contours and then
346:49 - we are going to first of all use a
346:54 - method called CV2 dot approx poly DP
346:59 - so I'm going to just declare a variable
347:03 - first of all I'm going to just say
347:05 - approx is equal to c v 2 dot this method
347:10 - which I have mentioned which is called
347:13 - approx poly DP so this method
347:16 - approximates a polygonal curves with a
347:20 - specific precision and the first
347:23 - argument which it takes is the curve so
347:26 - our curve here will be the Contour which
347:29 - we have found on the shape the second
347:33 - argument here will be Epsilon so Epsilon
347:37 - is the parameter specifying the
347:39 - approximation accuracy
347:42 - so here what we are going to do is we
347:44 - are going to Define Epsilon is equal to
347:48 - 0.01 and then we are going to multiply
347:52 - this number by c v 2 dot Arc Length so
347:58 - there is this method called Arc Len and
348:01 - what does this Earth length method do it
348:04 - calculates a Contours parameter or a
348:08 - curve length so here in this Arc Length
348:12 - parameter we are going to pass once
348:15 - again our Contour variable and the
348:18 - second argument here will be if it's
348:21 - closed or the open Contour so in our
348:25 - case we know that all the shapes which
348:28 - you want to detect are closed so we are
348:31 - going to just pass through here and the
348:33 - next argument in the approx poly DP
348:36 - method will be once again if its a
348:41 - closed shape tip or the open shape so
348:43 - once again we are going to pass through
348:46 - here because all the shapes which we
348:48 - have are closed shapes
348:51 - now once we have this approximation we
348:55 - are just going to draw all the Contours
348:58 - first of all so we are going to just say
349:00 - CV2 dot draw Contours on which image on
349:05 - our original image so we are going to
349:07 - draw these Contours on the original
349:10 - image and then we are going to pass the
349:14 - second argument and this will be our
349:17 - approximation so we can in the square
349:21 - bracket this is ah one other notation of
349:25 - ah just giving the number of Contours as
349:29 - an argument to the draw Contours method
349:31 - so in the square brackets you can just
349:34 - pass the approx
349:37 - the next parameter here will be the
349:39 - Contour index so because we are
349:41 - iterating over all the Contours that's
349:45 - why the index will always be zero
349:48 - because there will be only one contour
349:50 - which we are working at a time so this
349:54 - index will be zero the next argument
349:57 - here will be ah the color so you can
350:00 - give any color here I am going to give 0
350:04 - comma 0 comma 0 let us say and then the
350:08 - next will be the thickness so thickness
350:10 - I am going to give here is 5. now the
350:15 - next step is to print out the shape so
350:20 - which shape it is we want to print on
350:23 - the shape which shape it is in simple
350:26 - English let us say so for that we need
350:29 - to find out the coordinates on which we
350:32 - want to ah print this text on the shape
350:37 - so we need to find out the X and Y
350:39 - coordinates so we can find this X and Y
350:42 - coordinates using this approx variable
350:47 - and we can just say approx dot revwell
350:51 - so this is a
350:55 - method called Ravel and then the first
350:59 - index here will be the x coordinate and
351:05 - see in the same way we are going to just
351:07 - say approx dot Ravel
351:12 - and on this method the second argument
351:15 - or the second index at index 1 will be
351:20 - the y coordinate so on these X and Y
351:24 - coordinates we are going to print our
351:27 - text now in The Next Step what we are
351:30 - going to do is so because this approx
351:33 - poly d p is going to approximate the
351:36 - number of polygonal curves so based upon
351:41 - the number of polygonal curves we can
351:44 - just approximate which shape it can be
351:48 - so if
351:50 - this approx length so let us just find
351:54 - out the length of this approx and if the
351:58 - length of this approx
352:00 - variable is equal to 3 then we are going
352:05 - to say that it's a triangle because
352:08 - triangle can be made with three points
352:12 - so this length of approx variable if it
352:15 - is equal to 3 then we are going to say
352:18 - that it is a triangle because if the
352:21 - number of Curves here are three then
352:23 - most probably it is going to be a
352:26 - triangle so if we know that this is a
352:29 - triangle then we can easily ah just
352:33 - print or put text on that image so we
352:37 - are going to just say put text and the
352:40 - first variable here will be the image so
352:43 - we are going to put text on the image
352:45 - the second variable will be the text and
352:49 - we know that this will be a triangle so
352:52 - we are going to just say triangle here
352:56 - and then the next argument here will be
353:00 - the coordinates on which you want to
353:02 - print this text so we already found out
353:07 - the the coordinates at which we want to
353:09 - put this text the next argument here
353:12 - Will be the font so we are going to just
353:15 - say c v 2 dot font Hershey complex and
353:19 - the next argument here will be the font
353:21 - scale so let us say font scale will be
353:24 - 0.5 and the next argument here will be
353:28 - the color so you can give any color
353:31 - let's ah say we just want to print this
353:36 - text in the black color itself so we are
353:39 - going to just say 0 comma 0 comma 0 then
353:42 - using this logic we can also say that if
353:45 - the length of this approx is equal to 4
353:48 - then it can either be ah square or a
353:53 - rectangle so here if the approx length
353:57 - is 4 then it can be a square or a
354:03 - rectangle but we don't know if it is a
354:06 - square or a rectangle so for now we can
354:10 - just write that it's a rectangle and we
354:14 - are going to decide if it is a rectangle
354:17 - or a square in The Next Step but let's
354:21 - define the other if else conditions also
354:25 - so this was L if similarly if number of
354:31 - approx points are 5 then we are going to
354:35 - say that it is a pentagon so we are
354:38 - going to print out
354:39 - the Pentagon text on the X and Y
354:42 - coordinates and if the number of points
354:47 - are 10 then we are going to just say
354:50 - that its a star shape so we are going to
354:54 - just say
354:55 - star because in the star the number of
354:58 - points are 10 and then we are going to
355:01 - say that in any other condition so we
355:05 - are going to just say else and we are
355:08 - going to just remove this condition from
355:10 - here else in any other condition it is
355:14 - going to be a circle okay so if approx
355:19 - length is 3 it's a triangle if approx
355:23 - length is 4 it's a rectangle or a square
355:25 - a 5 Pentagon if it's 10 it's a star if
355:31 - it's nothing out of all these options
355:34 - then it is a circle you can also find
355:37 - out ah for example octagon or hexagon
355:41 - here if it's six it's a hexagon if it's
355:45 - eight it's a ah octagon and so on right
355:49 - now let us once again come to this step
355:53 - and in this step we ah just know that if
355:57 - the number of points are 4 then it's a
356:01 - rectangle or a square but how can we
356:04 - find if it is a rectangle or or a square
356:08 - so let us decide that now so what we are
356:12 - going to do for that is we are going to
356:15 - just say x comma Y and then we are going
356:20 - to just say ah W comma H for width and
356:25 - height and there is a method called CV2
356:29 - dot bounding rect which is going to give
356:34 - us the X and Y coordinates and the width
356:37 - and height of the rectangle right so we
356:42 - are going to apply that method so CV2
356:45 - dot bounding rect on our approximate
356:50 - variable or approx variable which is
356:53 - going to give us the x and y coordinate
356:55 - and width and height now based upon the
356:59 - width and height we can find out the
357:02 - aspect ratio so we are going to just say
357:04 - s fact ratio ratio
357:08 - is equal to float first of all we need
357:13 - to type cast the width into a float so
357:17 - we are going to just say ah float W
357:20 - divided by height and this will be the
357:24 - aspect ratio of the rectangle now if
357:28 - this aspect ratio let's print out the
357:32 - aspect ratio also so we know what aspect
357:36 - ratio we are getting using the rectangle
357:40 - or the square and we are going to just
357:43 - say if this aspect ratio is between ah
357:47 - 0.95 and
357:51 - 1.05 then its going to be a square right
357:55 - because the width and height are almost
357:59 - same okay so we just give some room for
358:05 - some noises that's why we are providing
358:08 - here ideally it should be a one aspect
358:10 - ratio should be one ah in order to have
358:13 - a square but let us say we are just
358:18 - approximating so we can just say if its
358:23 - 0.95 if it's greater than 0.95 and
358:29 - if its less than so aspect ratio is less
358:34 - than or equal to
358:37 - 1.05 then it is a square OK in ideal
358:41 - situation you might want to give here
358:44 - one but in images ah it can be ah little
358:48 - bit different so we are just giving this
358:51 - limit so if ah the spect ratio Falls in
358:55 - this limit then it is going to be ah
358:58 - Square otherwise it is going to be a
359:00 - rectangle right and I am going to just
359:03 - say that if this is the case then it is
359:07 - going to be ah Square otherwise so in
359:10 - the else condition so let us give this
359:13 - else condition here else it is going to
359:17 - be as rectangle so let's print rectangle
359:23 - in the put text okay so this is the code
359:28 - which we we have
359:30 - written and now finally what we are
359:34 - going to do we are going to just show
359:37 - the shapes image including all the
359:41 - Contours and the text which we have put
359:44 - on these shapes so let us run this code
359:48 - and let's see if it works or not
359:50 - so you can see now it is going to work
359:54 - like this so all the Contours are drawn
359:59 - across these shapes and you can see the
360:03 - text on top of these shapes so Circle
360:07 - rectangle Pentagon star triangle and
360:11 - squares what you can also do here is you
360:15 - can just change ah this text position
360:19 - using the X and Y coordinates so let's
360:23 - say I just want to change this y
360:26 - position
360:27 - to just little bit top of the shape so I
360:32 - just added minus 5 offset here in the y
360:35 - axis and now you can see it goes little
360:39 - bit up this text right so now it's much
360:44 - visible this text and you can see
360:48 - rectangle and square text is not going
360:50 - up because we have declared the local X
360:54 - and Y here also so we can just say x 1
360:59 - and y 1 here and then run this code once
361:03 - again and you can see this rectangle and
361:05 - square text is also moved little bit up
361:09 - so I think the offset of 5 is okay to
361:14 - show these text on top of these shapes
361:19 - so this is how you can detect simple
361:23 - geometric shapes using opencb in this
361:27 - video we will discuss about histograms
361:29 - in opencv
361:31 - so what is a histogram so you can
361:35 - consider histogram as a graph or a plot
361:38 - which gives you an overall idea about
361:41 - the intensity distribution of an image
361:45 - so let me give you some examples and
361:48 - then I will be able to explain you
361:50 - better how histogram works and why they
361:54 - are useful
361:55 - so to start with I have this example
361:58 - which is a very normal example here I'm
362:03 - creating 200 by 200 pixel image using a
362:07 - numpy zeros which essentially mean that
362:11 - we are going to get a 200 by 200 pixel
362:15 - image of black pixels so let me just ah
362:20 - just start this example and you can see
362:26 - this is the final result so all the
362:30 - pixels here in this image are black and
362:34 - the size is 200 by 200.
362:37 - now let us say we want to calculate or
362:40 - find out the histogram of this image so
362:45 - there are several ways of finding out
362:47 - histogram of an image so let's see them
362:51 - one by one
362:52 - so first of all we are going to find out
362:55 - the histogram using the mat plot lib
362:58 - because ah the plot using matplotlib you
363:03 - can draw easily so let us use that first
363:07 - of all so for that what I am going to do
363:10 - is I'm going to use PLT because I have
363:13 - already imported this matplot Library as
363:16 - PLT so PLT ah dot hist there is a
363:21 - function called PLT dot hist which
363:25 - calculates the histogram of an image and
363:29 - because it's just a grayscale image or
363:32 - it is just a black image so it's easier
363:36 - to find out the histogram so you what
363:39 - you can do here is the first argument
363:42 - here will be your image or your source
363:47 - so I'm going to just say image dot raw
363:51 - well okay so there is a method called
363:55 - Ravel the second argument here will be a
363:58 - maximum number of pixel values so I am
364:01 - going to just say 256
364:04 - the third argument here will be the
364:06 - range so the range will vary from 0 to
364:10 - 256 okay so this is all you need to find
364:15 - out the histogram using the mat plot lib
364:19 - and you just need to show this plot in a
364:23 - matplotlab window so you can just say ah
364:26 - p l t dot show so that's it so let's run
364:31 - this code and let's see what happens
364:34 - so you see this plot using matplotlib
364:38 - and also our original image so as we
364:44 - have created the image of 200 by 200
364:48 - pixel of black pixels so all the
364:52 - intensity of this graph you can see is
364:56 - zero so you can see here 200 multiplied
364:59 - by 200 is equal to ah 40 000 so these
365:04 - are the number of pixels so on the y
365:06 - axis you will see total number of pixels
365:09 - and here the intensity so intensity
365:13 - starts from
365:15 - 0 to 256 so this graph is showing how
365:19 - many number of pixels inside an image
365:22 - which have this uh pixel values so in
365:27 - our example all the pixels inside this
365:29 - image have the pixel value 0 that's why
365:33 - this graph is like this so all the 40
365:38 - 000 pixels inside the image have the
365:40 - pixel value 0 so you will get this type
365:44 - of histograms so once again the
365:48 - histogram is a graph or a plot which
365:52 - gives you the overall idea about the
365:55 - intensity distribution of an image now
365:59 - histogram is just another way of
366:01 - understanding the image by looking at
366:05 - the histogram of an image you can get
366:07 - the intuition about the contrast
366:09 - brightness
366:11 - intensity distribution Etc now let us
366:14 - improve this example which we have so I
366:17 - am going to just close this window and
366:21 - let us say I want to add some white
366:25 - pixel also inside this image so what I
366:28 - am going to say is I am going to just
366:30 - CV2 dot rectangle so I am going to just
366:34 - add the rectangle inside this image and
366:38 - the source here will be the IMG variable
366:41 - then where I want to introduce this
366:45 - rectangle so I want to introduce this
366:47 - rectangle at this point which will be
366:51 - let us say which starts from 0 comma 100
366:55 - and the second Point here will be let us
366:58 - say 200 comma 200 okay so this will be
367:02 - ah 200 and the next value here will be
367:06 - the color so let us say we want to add
367:08 - the white pixels so this will be
367:12 - 255 which will be the maximum value
367:15 - value and then the next argument will be
367:18 - the thickness so I am going to just say
367:19 - minus 1 which will fill this rectangle
367:22 - inside this image so when I run now this
367:28 - code
367:29 - you will see this graph and this image
367:34 - so you can see half of this image
367:36 - contains black pixels and half of this
367:40 - image contains the white pixels and we
367:43 - already know that the size of this image
367:45 - is 200 by 200 that is why ah here in the
367:49 - graph you will see 20
367:52 - 000 pixels are black which means that 20
367:57 - 000 pixels have the pixel value 0 and 20
368:02 - 000 pixels have the pixel value 255
368:06 - that's why you see this here so you can
368:10 - see you can easily find out the pixel
368:12 - intensity of an image easily using
368:16 - histograms now next we are going to add
368:20 - some more pixels into this image and
368:24 - this time what we are going to do is we
368:26 - are going to add the rectangle ah inside
368:28 - the same image so let us say it goes
368:31 - from 0 comma 50 to 100 comma 100
368:37 - and the color here we are going to
368:40 - provide the pixel value of 127 let us
368:44 - say ok so which is the half of 0 and 255
368:50 - approximately so I am going to run this
368:54 - ah example once again and now you will
368:58 - see this kind of image so you can see
369:01 - half of the pixels here are wide that
369:04 - means 20 000 pixels have the pixel value
369:07 - of 255 so you can see here now around 15
369:12 - 000 pixels here in the half of this
369:16 - image have the pixel value of 0 that's
369:18 - why you can see this line here and we
369:22 - have added the rectangle of pixel value
369:27 - 127 also so around you can see around
369:32 - 5000 pixels here have the pixel value of
369:36 - 1 to 27 so this is how the histogram is
369:40 - going to work so let's use now the
369:44 - original image so some kind of image
369:46 - instead of this black or white image so
369:50 - now what I'm going to do is I'm going to
369:53 - just once again declare a variable and
369:56 - then I'm going to just say CB2 dot I am
370:00 - read
370:02 - and we are going to read some files so
370:05 - let us say I have this Lena dot jpg
370:09 - image so I'm going to just
370:12 - read that
370:14 - I hope the extension is a correct JP uh
370:18 - G and we are going to read this image in
370:20 - the grayscale mode so I am going to just
370:22 - say 0 here and now I'm going to run this
370:27 - example once again and you can see this
370:31 - Lena image is loaded in the grayscale
370:35 - mode and here is the histogram of this
370:39 - image so these are all the pixel
370:43 - intensities inside this image so you can
370:46 - see from this ah graph that most number
370:50 - of pixels contained inside this image
370:54 - have the pixel value around
370:57 - 150. now you can also find out the pixel
371:01 - intensity of different colors so till
371:05 - now we have been just using the
371:08 - grayscale mode or black or white pixels
371:12 - but you can also uh use the same
371:16 - histogram for the BGR values also so
371:20 - let's see how we can undo that so what
371:24 - we are going to do is let me just remove
371:27 - this code or I'm going to just leave it
371:29 - commented and here I'm going to just say
371:34 - B comma G comma R and there is a method
371:39 - we have already seen which is called CV
371:42 - dot split which is going to split your
371:47 - image into BGR values so we are going to
371:51 - just give the source which is our image
371:55 - and then if you want to show these BGR
372:00 - values you can just show in the I'm show
372:05 - window so BG
372:08 - R and here also B
372:11 - G
372:13 - and R and when you want to uh show the
372:18 - histogram of BGR values then also you
372:22 - can use matplotlib dot hist method you
372:26 - just need to change this Source from
372:29 - image to BGR so B
372:32 - uh G and R okay so now what we are going
372:39 - to do is we are going to run our code
372:42 - and let's see what happens
372:44 - so it is giving me ah this error because
372:48 - I'm reading this image in the grayscale
372:51 - mode so I'm going to remove this extra
372:54 - parameter from I am read because we want
372:58 - to read this image in the color form and
373:01 - then only we will be able to get the BGR
373:04 - channels right in the grayscope scale
373:06 - mode there are no BGR channels so I am
373:10 - going to run this script once again and
373:13 - let's see what happens so you can see
373:15 - this histogram of blue channels and
373:18 - green channels and the red channels and
373:21 - these are the images which are loaded in
373:24 - these different channels so this is the
373:27 - image which is loaded in the blue
373:31 - Channel and this is the green and this
373:35 - is the red Channel and you can see the
373:38 - histogram of each Channel differently
373:40 - using
373:42 - matplotlib so let me just close all
373:45 - these windows now there is a method word
373:49 - in CV2 also which is called calc hist
373:53 - which is going to give you the histogram
373:55 - of an image so for that what you can do
374:00 - is I'm going to just just comment all
374:05 - the this code because I just want to
374:08 - show how you can use the CV2 calc hist
374:13 - method okay so what you can do is you
374:19 - can use ah
374:21 - method so let's say
374:23 - hist
374:25 - and then CV Dot calc hist and this
374:31 - method takes few arguments
374:34 - so the first argument here will be the
374:36 - image so it's the source which you give
374:40 - but the only special thing is you just
374:43 - give this image in the square brackets
374:46 - okay the second argument here is the
374:50 - channel so it is the index of channels
374:52 - for which we calculate the histogram so
374:56 - here
374:58 - in our case because we are going to read
375:01 - the image in grayscale mode we can just
375:04 - give the channel 0 here so for one
375:07 - channel you can give 0 here for
375:10 - different Channel you can give 0 1 2
375:12 - value the next argument here is the
375:15 - image mask so to find histogram of full
375:19 - image it is given as a none because our
375:23 - because our image is loaded in the gray
375:28 - scale mode so we can give here none the
375:31 - next value is the hist size so this hiss
375:36 - size is the representation of Bin counts
375:39 - and this is also given in the square
375:42 - bracket so we are going to just say 256
375:45 - here
375:46 - the next argument is the range so range
375:50 - will vary from 0 to 256 so minimum and
375:54 - the maximum range of the x-axis you can
375:57 - say so 256 and then we can just show
376:02 - this uh
376:04 - hist or histogram inside the PLT so PLT
376:10 - Dot Plot method so Dot Plot and then we
376:17 - can just give this histogram value here
376:21 - okay so let us run this code and let's
376:24 - see what happens
376:25 - so you can see you get the histogram of
376:30 - this image using the opencv calc hist
376:33 - method and what are the uses of the
376:36 - histogram so a histogram can tell you
376:39 - whether or not your image has been
376:41 - properly exposed so when you take a
376:45 - digital image ah it's very useful it it
376:49 - can also tell you whether the lighting
376:51 - conditions were flat or harsh when you
376:55 - took that image and using the histogram
376:58 - you can also make the adjustments which
377:02 - will work best for your digital images
377:05 - so this ah the usefulness of the
377:08 - histograms we will see in the later
377:10 - videos this was just the basics about
377:13 - the histograms in opencv
377:16 - in this video we will discuss about
377:19 - template matching in opencb
377:22 - so first of all what is template
377:24 - matching so template matching is a
377:28 - method of searching and finding the
377:30 - location of a template image inside a
377:35 - larger image
377:36 - in opencv there is a method called match
377:40 - template for achieving this purpose so
377:45 - let us get started and let's see an
377:47 - example about it
377:48 - so I have this simple code which just
377:51 - loads this image and let's see ah what
377:55 - this image looks like so this is the
377:59 - image and this is the messy image and
378:02 - what I want to do is I want to match the
378:07 - face template which I have which looks
378:11 - like this which is the smaller template
378:15 - which is also available inside this
378:19 - image so this will act like a template
378:22 - for us and we will try to find this
378:26 - template inside this larger image so
378:29 - let's get started and let's see how we
378:31 - can search this template inside this
378:34 - larger image
378:36 - so first of all what we need to do is
378:39 - obviously we need to load this image and
378:44 - also load our template so before loading
378:49 - our template image I am going to just
378:52 - convert my original image which is the
378:55 - larger image into the grayscale image so
378:59 - I have declared this variable gray
379:01 - underscore image and then I'm going to
379:04 - just say CB to dot CVT color which is
379:09 - going to convert my image IMG
379:14 - and let's convert this image into CB2
379:17 - dot color
379:19 - underscore BGR to Gray
379:21 - now let's load our
379:25 - face image which is called messy
379:28 - underscore face dot jpg so I am going to
379:32 - just change this name as C underscore
379:36 - face dot jpg and this will be our face
379:41 - image or you can also say this is a
379:44 - template and I am going to also load
379:46 - this image as a grayscale image so I'm
379:50 - going to just pass the second argument
379:51 - in the read method as 0 which is going
379:54 - to load this messy image as a grayscale
379:57 - image now in the next line we will
380:00 - simply ah use this method which is
380:03 - called match template and we are going
380:06 - to save it into some variables so we can
380:11 - just say r e s is equal to c v 2 dot
380:16 - match template which is this method
380:20 - which takes few argument first is our
380:23 - image so I'm going to pass our grayscale
380:27 - image here
380:28 - the second argument here will be the
380:30 - template which we are trying to search
380:32 - inside this image so this will be our
380:36 - template
380:37 - the third is the method so the method
380:42 - can be a several method there are
380:45 - several methods available for the
380:48 - template matching so I want to show you
380:51 - these method for the template matching
380:54 - so you can see a type of template
380:56 - matching operations and there is
381:00 - separate formula involved in order to
381:03 - match that template inside that image so
381:06 - so for now we are going to use this
381:08 - method which is TM underscore C Co F
381:12 - underscore
381:13 - normed dot TM underscore C Co F normed
381:20 - which is this method now let us try to
381:22 - print this result and let's see what is
381:25 - the content inside this result so I am
381:28 - going to just print the content inside
381:31 - this result which we got so I'm going to
381:34 - run this code and this image is load
381:37 - loaded but for now we are interested in
381:41 - this array Matrix which you are seeing
381:45 - here
381:46 - so you can see when you observe these
381:49 - values carefully you will see all are
381:54 - relatively smaller values so you can see
381:59 - ah 0.2 0.2 almost every value is around
382:05 - until 0.3 so the maximum value I can see
382:09 - here is 0.3 so let me just show this
382:13 - image once again and the the template
382:16 - also so what this result contains is
382:20 - these all values and there will be one
382:25 - value which contains the number for
382:30 - example 0.8 or
382:33 - the brightest Point okay so if here this
382:38 - ah Matrix contains a value which have
382:42 - the value 1 it is the brightest point
382:45 - and it will be there inside this image
382:48 - after applying this mesh template method
382:51 - which will be around this point at this
382:54 - point at which ah this template matches
382:58 - so top left corner of this template so
383:01 - at the point at which this left top
383:05 - corner of this image will match inside
383:09 - this large image there will be a
383:12 - brightest point there and that brightest
383:16 - point will be reflected inside this
383:19 - image in the form of this decimal number
383:23 - and all the other values will be
383:26 - slightly uh darker darker values ok so
383:31 - that is how ah this Matrix from this
383:33 - Matrix we will come to know the the top
383:37 - left corner of the template inside this
383:40 - larger image so now how can we filter
383:45 - out that value which is the brightest
383:48 - Point inside this Matrix so all the
383:52 - points ah you can see looks like under 0
383:56 - 0.3 but there are some points here you
384:00 - can see three dots and there are
384:02 - thousands and thousands of values will
384:06 - be available here all the values are not
384:09 - printed ok so what we are going to do is
384:13 - we are going to try to find out the
384:15 - brightest point so this we can find out
384:18 - with the numpy method ah there is a
384:21 - method called where
384:23 - ah using which we can find out or filter
384:27 - out those values which are greater than
384:29 - certain number so I'm going to ah first
384:33 - of all declare a variable called
384:36 - threshold is equal to I am going to
384:39 - declare the value of threshold initially
384:42 - as 0.8 which will be ah relatively
384:45 - brighter Point ah inside the Matrix
384:50 - which we are getting using this result
384:53 - variable right and then there is a
384:57 - method called where numpy where so I am
385:01 - going to declare once again loc variable
385:04 - and then P Dot
385:06 - where method and here we are going to
385:10 - pass our result which we got and we are
385:14 - going to filter out using this
385:17 - expression so this will be a Boolean
385:19 - expression so I am going to just say
385:21 - give me all those values which are
385:25 - greater than or equal to the threshold
385:29 - inside this result Matrix okay so this
385:33 - where method is going to uh just
385:37 - evaluate this expression each and every
385:40 - value will be evaluated and if this
385:43 - value inside the Matrix is greater than
385:47 - 0.8 which is our threshold then it is
385:51 - going to ah give those values to us so
385:54 - let us print out those values after the
385:57 - filtering out of most of the values and
386:01 - let us just print this loc variable also
386:04 - so I am going to run this code once
386:06 - again again and you can see here
386:10 - this is the Matrix which we got so you
386:14 - can see this is the array which we got
386:16 - so still we can increase this threshold
386:19 - in order to find out only one point so
386:23 - there are several points available here
386:26 - so let us say I am going to increase
386:28 - this value to 0.9 and let's run this
386:33 - code again and you will see only two
386:37 - points 85 and 220 so this is what we
386:41 - were expecting so we wanted to find out
386:44 - ah this point which will be the
386:46 - brightest Point ah inside this result
386:51 - Matrix so once we got the brightest
386:54 - Point ah which will be around here which
386:58 - will be the top left corner as I said of
387:01 - this template and it will be located
387:04 - somewhere here in the original image
387:06 - then we can draw the rectangle ah around
387:11 - this original image ah same as the size
387:15 - of this template so this will be the
387:18 - easier task because we already know the
387:22 - width and height of this template we
387:25 - already know how to get the width and
387:27 - height of this template and same size
387:30 - rectangle we just want to draw on this
387:34 - original image so let's see how we can
387:38 - do this so there is already a method so
387:42 - I'm going to just declare two variables
387:45 - width and height and you already know
387:49 - the method so template dot shape is
387:52 - going to give you the shape of your
387:57 - image right so I'm going to just say
388:00 - template dot shape and then inside the
388:04 - square brackets we are going to just
388:07 - give two colons and minus one this means
388:10 - that we want to get the
388:14 - column and the rows value in the reverse
388:18 - order so width and height that's why I
388:22 - have given this minus 1 index here now
388:25 - in the next step what we are going to do
388:28 - is we are going to just draw all the
388:31 - rectangles
388:32 - where the template is is matched so by
388:38 - seeing this template image and the
388:40 - original image we know that there is
388:43 - only one messy face inside this image
388:46 - but let us say there are several number
388:48 - of ah matched templates inside original
388:53 - image ah for that we need to iterate
388:56 - over ah the result which we got after
388:59 - applying the filter on the result so for
389:03 - that we are going to just iterate over
389:07 - that result in our case as we know that
389:10 - there is only one point ah so we do not
389:14 - even a need to iterate over it but if
389:17 - there are multiple number of matched
389:20 - templates then this ah for Loop will be
389:25 - ah handy so for p t
389:28 - in your
389:31 - loc variable so we are going to just say
389:34 - zip which is going to iterate over this
389:38 - loc variable so Asterix l o c and then
389:43 - we are going to find out the methanite
389:48 - here also so we are just reversing the x
389:52 - axis and y axis right so we are going to
389:55 - just say colon colon minus 1 here and
390:00 - then once again inside this for Loop so
390:03 - c v 2 dot rectangle method and the first
390:07 - argument here will be our original image
390:09 - because we want to draw the rectangle on
390:12 - the original image
390:14 - the second argument will be the first
390:17 - point of the rectangle so the first
390:20 - point will be this one p t which we are
390:24 - getting using the loc uh uh variable so
390:29 - as you all know that the first point
390:32 - here will be the top left corner of the
390:37 - rectangle and the second Point here will
390:40 - be the bottom right corner so how can we
390:43 - get the bottom right corner we will get
390:46 - the bottom right corner using this PT
390:51 - variable and then on the zeroth index we
390:55 - are going to just add the width
390:59 - comma on the first index so p t ah
391:04 - square bracket first ah we are going to
391:07 - add the height okay so essentially we
391:12 - have just found out the width and height
391:14 - of our template and we are getting the
391:18 - second Point using this addition on the
391:23 - first point width and height so it is
391:25 - going to give us this bottom right
391:28 - corner of this template or this point so
391:33 - this is how we are getting our two
391:36 - points to draw the rectangle now the
391:39 - third and fourth variable will be a
391:41 - simple which are the color so you can
391:45 - just say 0 comma 0 comma 255 which will
391:49 - be the green color and the width let's
391:52 - say 2 here so we want to give the width
391:55 - 2 here so let's run this code and let's
391:58 - see what happens happens so I'm going to
392:00 - run this code and you can see
392:02 - this red rectangle is drawn on the face
392:07 - of the messy and you can s here also see
392:11 - this rectangle will match our template
392:15 - image so whatever image is inside this
392:19 - rectangle will be ah exactly same as our
392:23 - template and once again you can see the
392:26 - result let me explain this code once
392:29 - again so if
392:31 - this point this threshold will be ah
392:36 - 0.08 let us say in the case of point
392:39 - zero nine threshold we are only getting
392:41 - two values ah this 85 and 220 right
392:46 - that's why we are seeing the clear
392:50 - rectangle here when we are
392:54 - giving the threshold 0.8 here let's see
392:58 - what happens so I am going to run this
393:00 - code once again you can see there will
393:02 - be ah this rectangle but it will be much
393:06 - thicker why it's much thicker because we
393:10 - are getting several number of values 1 2
393:13 - 3 4 5 6 7 8 9. so we are getting the
393:17 - nine points on the x axis and the y axis
393:20 - so this for Loop will iterate nine times
393:24 - and this rectangle will be drawn nine
393:28 - times on the image and that's why this
393:31 - rectangle is much thicker let's uh just
393:35 - change this value to 0.9 once again and
393:39 - you will see this rectangle is ah you
393:42 - know the single rectangle that's why
393:45 - it's much thinner right now ah when you
393:49 - give this value let us say we give the
393:52 - value
393:53 - 0.3 so most of the point as you can see
393:56 - here have the value 0.3 and when we run
394:00 - this code you will see so many
394:03 - rectangles here so that's why this
394:06 - thresholding is essential for us to find
394:10 - out the brightest point or the value
394:13 - which have the maximum value right so
394:17 - that's why we were filtering out
394:20 - this these points and finding out the
394:24 - values more than
394:27 - 0.9 threshold and about the method so
394:32 - let's try different methods so let's try
394:35 - to give different methods here these two
394:38 - methods behave little bit differently so
394:42 - we can start with this TM c c o r r
394:48 - normed and we can apply it here and it's
394:52 - going to give us this kind of result you
394:56 - can see we are getting several points
394:59 - here after filtering so ah let us try to
395:03 - increase this value to
395:06 - 0.95 and let's rerun this code
395:09 - and let's see what happens now you are
395:12 - getting four values uh you can also
395:17 - filter that out let us say 0.99
395:22 - now let's see what happens so now you
395:24 - are getting only two values OK so you
395:27 - need to uh try to change this value to
395:31 - the maximum point so try to change this
395:33 - value and you will get this kind of
395:37 - rectangle only one rectangle so every
395:40 - method is going to give you different uh
395:44 - result and that's why you need to uh try
395:48 - all the result not all the result will
395:51 - give you the perfect rectangle or
395:54 - template matching so you need to try
395:56 - different methods on your images so this
396:00 - is how you can do template matching in
396:03 - opencv in this video we will understand
396:05 - the concept behind the half transform
396:09 - so first of all what is half transform
396:12 - so half transform is a popular technique
396:15 - to detect any shape if you can represent
396:18 - that shape in a mathematical form
396:21 - half transform can detect the shape even
396:24 - if it is broken or distorted a little
396:27 - bit
396:28 - now this explanation might seem a little
396:32 - bit confusing so let me explain it by an
396:35 - example
396:36 - so let us say you have an image of this
396:40 - road and you want to detect these Lane
396:44 - lines in ah this road image so the first
396:48 - step in order to detect these Lane lines
396:51 - in this road is to find the edge pixels
396:56 - using Kenny Edge detection or any other
396:59 - Edge detection method now after you
397:01 - found out the edges using any Edge
397:05 - detection method you want a geometrical
397:09 - representation of that edge and in order
397:12 - to find out the geometrical
397:14 - representation for example you want to
397:16 - find out the slope of this Edge or its
397:20 - intercept you can use half transform to
397:24 - represent these pixels or edges in the
397:28 - mathematical or geometrical form so
397:32 - after you find out the edges using any
397:35 - Edge detector you just just have the
397:37 - sequence of pixels so you can Loop
397:40 - through all the pixels and somehow
397:43 - figure out the slope and intercepts but
397:46 - it is a very difficult task so we want
397:49 - some mechanism that gives more weightage
397:52 - to pixels that are already in line and
397:56 - this is what we can achieve using half
397:59 - transform so let's begin and let's start
398:02 - with the lines
398:04 - so a line in the image can be
398:06 - represented by two coordinate systems
398:09 - first is using the Cartesian coordinate
398:13 - system and using this equation you can
398:16 - represent a line which is y is equal to
398:19 - m x plus C and you can also represent
398:23 - this line using polar coordinate system
398:26 - using this equation which is X cos theta
398:30 - plus y sine Theta is equal to r or rho
398:34 - sometimes
398:36 - so lets start with ah this equation
398:39 - first which is a Cartesian coordinate
398:42 - system equation which is y is equal to m
398:45 - x plus c
398:47 - so ah when you represent a line in X and
398:52 - Y coordinates which is also called the x
398:56 - y space
398:57 - ah this equation looks like this so Y is
399:00 - equal to m x plus c
399:02 - where m is the slope of the line and C
399:06 - is The Intercept of this line so if you
399:09 - know the values of M and C you can
399:13 - represent this line in the x and y
399:15 - coordinate now in half transform you can
399:19 - represent this line in other form also
399:22 - and this is called the MC space or the
399:26 - half space
399:27 - so using this equation when you take M
399:31 - on this axis and C on this vertical axis
399:36 - then this is called the MC space so
399:40 - earlier we have represented this line in
399:43 - the x y space and now we are saying that
399:46 - we want to represent this using the m c
399:49 - coordinate where m is on the horizontal
399:52 - line and C is on the vertical line so
399:57 - when you represent this simple line in
400:01 - the m c space or the half space it can
400:04 - be represented as a point so this line
400:07 - can be represented as a point so we all
400:11 - know that a line is a collection of
400:13 - points and managing the collection of
400:16 - points is tougher than managing a single
400:19 - point so if you want to manage a
400:22 - collection of point and if you were to
400:25 - manage a single point which will you
400:28 - prefer and an obvious answer will be to
400:31 - manage the single point and this is what
400:33 - this MC space is doing it's representing
400:37 - a line in the form of a point in MC
400:41 - space or the half space and the opposite
400:45 - of this concept is also possible so if
400:48 - you can represent a point using this
400:51 - coordinate in the x y space then it can
400:55 - be represented as a line in the MC space
400:59 - okay and the formula now will turn into
401:03 - this equation which is C is equal to
401:06 - minus X A M plus y a right so you can
401:12 - represent a point and if you have the x
401:16 - and y coordinate in the MC space you can
401:19 - represent this as a line and this will
401:24 - be the equation where X will be the
401:27 - slope now and Y will be The Intercept
401:30 - earlier M was the slope and C was The
401:34 - Intercept but when you are just
401:37 - transform or just represent this point
401:40 - into MC space then your X becomes or
401:45 - minus X becomes the slope and Y becomes
401:50 - The Intercept so how does these concepts
401:53 - are going to help us
401:55 - so the half transform is all about doing
401:59 - what we have learned converting points
402:02 - in the x y space to the lines in the MC
402:06 - space or the half space so for example
402:09 - you can see Four Points one two three
402:13 - four which are joined by a line right so
402:18 - you can represent these four points and
402:21 - you can join all these four points and
402:25 - its our representation of a line and
402:28 - here slope is equal to M and intercept
402:31 - is equal to C in the x y space
402:35 - the same line you can represent in the
402:39 - MC space uh using these four lines okay
402:43 - so every point is a line in the MC space
402:47 - and you see the intersection Point here
402:51 - which is on the MC chord in it so you
402:55 - have taken an edge detected image and
402:58 - for every point that is a non-black
403:02 - point you draw lines in the MC space and
403:06 - obviously when you draw these lines
403:08 - these lines will intersect with each
403:12 - other and these intersections Mark are
403:15 - the parameter of a line okay so in the
403:18 - MC space you can represent each and
403:21 - every Point as a line and they will
403:25 - intersect on a single point and now this
403:29 - intersection Point can be used to draw a
403:33 - line so this was the represent iteration
403:36 - of points in a line using MC space using
403:40 - a Cartesian coordinate system now let us
403:43 - apply the same Concepts which we have
403:46 - learned using the Cartesian coordinate
403:49 - system ah into a polar coordinate system
403:52 - so
403:54 - as we all know that in the polar
403:57 - coordinate system we can represent a
404:00 - line using this equation also which is R
404:04 - is equal to X multiplied by cos theta
404:07 - plus y multiplied by sine Theta or in
404:11 - other form you can also represent this
404:14 - equation like this where Y is equal to
404:18 - minus cos Theta by sine Theta multiplied
404:21 - by X plus r divided by sine Theta so
404:26 - this is your x y space where line can be
404:30 - represented like this and we are going
404:34 - to transform or represent this line
404:37 - using this equation into the r Theta
404:42 - space or the half space okay so this
404:46 - line using this equation can also be
404:49 - represented as a point in R Theta or the
404:53 - half space like this so let us take an
404:56 - example about this so as I said the
405:00 - equation was R is equal to X multiplied
405:03 - by cos theta plus y multiplied by sine
405:07 - Theta where this Theta is the angle of
405:09 - the line and R is the distance from the
405:13 - origin to the line so let us say we want
405:16 - to represent a point which is from x y
405:19 - space into a half space into R Theta
405:24 - space so we give the values of x 0 and Y
405:28 - 0 which will be the first point we can
405:31 - represent this point in the form of line
405:34 - in the half space or the r Theta space
405:38 - ah in this formation which looks like a
405:42 - sine curve using this equation so this
405:46 - is for the one point representation in x
405:50 - y space to a line representation in the
405:54 - half space so let's say you have
405:56 - multiple points so we take three points
405:59 - then ah it is going to look like this so
406:03 - let us say x 0 is equal to 8 and Y 0 is
406:06 - equal to 6 x 1 is equal to 4 y 1 is
406:09 - equal to 9 and X2 is equal to 12 and Y 2
406:12 - is equal to 3. so we have three points
406:16 - in the x y space they can be represented
406:20 - in the half space using three lines and
406:24 - as we have seen in the Cartesian
406:25 - coordinate system these points can be
406:29 - represented in these lines in the half
406:33 - space in the polar coordinate system
406:36 - also using these curved line and this
406:39 - intersection is going to represent a
406:43 - line in the half space so which
406:46 - representation we are going to use in
406:49 - order to use the half transform so this
406:51 - equation is not able to represent the
406:54 - vertical lines that's why generally we
406:58 - use this equation or a polar coordinate
407:01 - system in order to use half transform so
407:05 - the half transform algorithm involves
407:08 - these four important steps in the first
407:11 - step Edge detection is done using
407:14 - canningh detector or any Edge detection
407:16 - method in the Second Step mapping of the
407:20 - edge points to the half space is done
407:23 - and all these Edge points are stored in
407:26 - an accumulator and the third step
407:28 - interpretation of accumulated yield
407:31 - lines of infinite length is done and
407:34 - this interpretation can be done by
407:36 - thresholding or any other constraint the
407:40 - fourth step involves the conversion of
407:43 - infinite line to finite lines now opencv
407:47 - implements two kind of half line
407:49 - transforms the first is the standard
407:52 - half transform which is done using half
407:56 - lines method the second type is the
408:00 - probabilistic half line transform which
408:03 - is done by half lines P method so this
408:07 - is the half lines method and this is the
408:11 - half lines P method in the last video we
408:13 - have seen a brief Theory introduction
408:16 - about half line transform
408:19 - so I have told you that opencv
408:21 - implements two kind of half line
408:23 - transforms one is a standard half line
408:27 - transform using half lines method and
408:30 - the second is the probabilistic half
408:33 - line transform using half lines capital
408:37 - P method so we are going to use the half
408:42 - line method in this video and see how we
408:45 - can use this half line method to detect
408:48 - the lines inside an image using half
408:52 - transform
408:54 - now I also told you that there are four
408:58 - steps associated with half transform so
409:02 - the first step was the edge detection
409:04 - step using any Edge detection method
409:07 - preferably Kenny Edge detection the
409:11 - second step is the mapping of edge
409:14 - points to the half space and store these
409:18 - H point to an accumulator
409:20 - the third step was the interpretation of
409:23 - accumulator to yield lines of infinite
409:26 - length and the fourth step was the
409:29 - conversion of these lines to the finite
409:33 - lines
409:34 - so let us say we have this image of this
409:39 - Sudoku dot PNG and you can see all these
409:42 - lines here which we want to detect so
409:45 - this is the line and this is the line so
409:47 - all these lines we want to detect using
409:50 - the half line transform so I have
409:53 - already written this code so I am going
409:56 - to go step by step uh to explain how
410:00 - this code works
410:01 - so in the first step you just need to
410:04 - import the normal CV2 and the numpy as
410:08 - the NP then here I'm just reading this
410:12 - image using I am read method in The Next
410:15 - Step I'm converting this image into a
410:18 - grayscale image and storing it into this
410:21 - variable which is gray because for Kenny
410:25 - Edge detection it's preferred to have
410:28 - grayscale images rather than your normal
410:32 - colored images
410:33 - now in the next step we are applying the
410:38 - Kenny Edge detection method on this gray
410:40 - scale image so here this cv2.kenny
410:44 - method takes these arguments first
410:47 - argument is the image second and third
410:49 - argument is the first threshold and the
410:52 - second threshold so I am giving the
410:54 - first threshold as 50 and the second
410:56 - threshold here as 150 and the fourth
411:00 - argument here I'm giving a purchase size
411:03 - is equal to 3. now in the next step I am
411:08 - using this half lines method this is the
411:11 - normal Hub transform method which is
411:14 - implemented in opencv
411:17 - now this half line method takes few
411:20 - argument the first argument is the image
411:24 - so we are just
411:26 - just passing this Edge detected image to
411:31 - the first argument of this half lines
411:34 - method the second argument here is the
411:37 - row value this row value is the distance
411:41 - resolution of the accumulator in pixels
411:44 - normally it's taken as one the third
411:48 - value is the Theta value which is the
411:52 - angle resolution of accumulator in
411:55 - radians so for that we are just using
411:58 - numpy so NP dot pi divided by 180 so
412:02 - this is also typical in this method and
412:06 - the next argument here is the
412:07 - accumulator threshold parameter
412:10 - so what does this mean it's a threshold
412:14 - so only those lines are returned that
412:17 - get enough vote that means that those
412:20 - lines will be returned which have
412:22 - threshold greater than this value so
412:26 - starting value I have taken here as 200
412:30 - as threshold so now this half lines
412:33 - method is going to return the output
412:36 - Vector of lines
412:38 - now I have explained you how polar
412:42 - coordinate works for the half transform
412:45 - in the last video so these lines will be
412:50 - in the polar coordinates so each line is
412:53 - represented by two or three element
412:55 - vectors either rho and Theta or rho
413:00 - Theta and volts so as you can see this
413:03 - is the output Vector of lines so I am
413:06 - going to iterate over each and every
413:09 - line vector and what it gives is the
413:13 - first element of this line is going to
413:17 - give you these two values rho comma
413:20 - Theta it is going to give you rho comma
413:23 - Theta or rho comma Theta comma volt
413:26 - right so right now I'm using just two
413:30 - parameters here row comma Theta so rho
413:34 - is the distance from the coordinate 0
413:37 - comma 0 row which is the top left corner
413:41 - of the image and the Theta is the line
413:44 - rotation angle in radians so all this
413:49 - rho and Theta I have explained you in
413:51 - the last video and we have seen how we
413:54 - can represent these row and Theta values
413:57 - in the half space
414:00 - so first of all what we are going to do
414:02 - is once we get the row and Theta value
414:05 - is we are going to uh just get the COS
414:09 - Theta value and the sine Theta value
414:12 - because we want to convert these polar
414:15 - coordinates into the normal Cartesian
414:18 - coordinates for the line method because
414:22 - this line method as you can imagine
414:25 - takes uh these coordinates right which
414:28 - are the Cartesian coordinates so this is
414:31 - the point one parameter and this is the
414:34 - 0.2 parameter so X1 y1 and X2 Y2
414:38 - so first of all we are just getting the
414:41 - COS Theta value and Theta here is this
414:44 - Theta so cos Theta we are just assigning
414:48 - to a and the sine Theta value we are
414:51 - just assigning to B and we are just uh
414:56 - multiplying this a to the row so this
415:00 - will give us the X 0 value and the Y 0
415:04 - value when you multiply B uh by rho so
415:09 - this row is this row value so this x 0
415:13 - and Y 0 is going to give you the origin
415:16 - which is 0 comma 0 or top left corner of
415:21 - the image
415:22 - but we want the lines not the top left
415:27 - corner of the image so how we can get
415:31 - these X1 and Y one coordinate and X2 and
415:34 - Y to coordinate uh this is uh given in
415:38 - this equation so once you get your x 0
415:42 - and Y 0 value you can get the value of
415:46 - X1 and Y 1 coordinate using this
415:49 - equation so you just need to Typecast
415:51 - everything into integer
415:54 - so this equation x one value stores the
415:57 - rounded off value of rho as I have shown
416:02 - here so this R represent rho so row
416:05 - multiplied by cos Theta cos Theta we
416:08 - have already uh taken in the a variable
416:11 - so we are essentially here multiplying
416:14 - the rho multiplied by cos Theta minus
416:19 - thousand multiplied by sine Theta sine
416:21 - Theta value is the value of the B right
416:26 - so x 0 plus 1000 multiplied by minus B
416:31 - here okay
416:32 - why when we get using this equation so y
416:36 - 1 is equal to INT in the bracket y 0
416:40 - plus thousand multiplied by a which is
416:43 - essentially this equation which is rho
416:46 - multiplied by sine theta plus thousand
416:50 - multiplied by cos Theta so these two
416:52 - values are going to give you the first
416:55 - coordinates and similarly we are going
416:57 - to get the X2 and Y 2 coordinate using
417:00 - these two equations so here everything
417:03 - is same just this minus is Nu right so
417:09 - in this equation you just need to
417:11 - replace a plus by minus and you get the
417:15 - X2 value same you have to do in the case
417:18 - of Y2 so in this equation if you just
417:22 - replace this plus by minus you will get
417:25 - the Y2 value and we have already seen
417:28 - how to use the CB2 dot line method it
417:32 - takes a few argument as you can see here
417:35 - first is the image so image is our
417:37 - original image second is the X1 and Y
417:41 - one coordinate which is the first point
417:43 - comma the second point so as you already
417:47 - know that a line is a collection of
417:49 - point so you need at least two point to
417:53 - create a line right so this is the
417:57 - coordinate of the first point and this
417:59 - is the coordinates of the second point
418:00 - the next argument here is the color so
418:03 - color I have taken simply 0 comma zero
418:06 - comma 255 and the last parameter here is
418:09 - the thickness of the line which I have
418:12 - taken 2 here
418:13 - and the next line of code you already
418:17 - know I think so after this line we come
418:21 - out of the loop and we are just plotting
418:24 - all the lines using this loop on the
418:28 - original image and once we get all these
418:31 - lines on the original image we are just
418:33 - showing it using I am show method and at
418:37 - the last we are just destroying our
418:39 - window once we are done with the image
418:42 - so let's run this code and let's see
418:45 - what happens so I'm going to run this
418:47 - code and you can see all these lines are
418:51 - plotted here let's see the Kenny as
418:56 - detected image also so I'm going to just
419:00 - after the Kenny Edge detection I'm going
419:02 - to once again add this I'm sure method
419:07 - to show the Kenny Edge detected image
419:09 - also so you can see here this is the
419:13 - Kenny Edge detected image all the edges
419:16 - are detected and based upon all these
419:19 - lines which are detected here these
419:22 - lines are drawn but the problem here is
419:26 - these lines are of infinite length so
419:29 - there is no end to this line This these
419:32 - lines just go from the start or the
419:36 - corner of the image to the other corner
419:39 - of the image so you can see they start
419:41 - from here and go to the next Corner they
419:45 - don't just stop here so in this ah half
419:51 - transform you ah see that even for the
419:55 - line with two argument it takes a lot of
419:58 - computation and we don't even get the
420:01 - correct result so this problem can be a
420:05 - solved using the other method which is
420:07 - implemented using this half line P
420:12 - method which is the probabilistic half
420:15 - line transform which I am going to show
420:17 - you in the next video so how we can get
420:20 - the better result using half line P
420:23 - method we are going to see in the next
420:26 - video in the last video we have seen how
420:28 - to use standard half transform using
420:32 - half lines method in opencv now in this
420:36 - video we are going to see how to use
420:38 - probabilistic half line transform using
420:41 - a method called half lines capital P
420:44 - method in opencv
420:46 - so let's go to our editor and this was
420:50 - the code we have written last time and
420:52 - we have used half lines method for
420:56 - detecting lines inside this image which
420:59 - was the Sudoku image so let's run this
421:03 - example really fast to see what was the
421:07 - result which we got last time so this
421:10 - was the result which we got last time
421:12 - and the problem with this result is you
421:16 - can see these lines just go from one end
421:19 - to the other end and in this kind of
421:23 - half transform ah you will be able to
421:26 - see that even for the lines which have
421:30 - two arguments it takes a lot of
421:33 - computation so in opencv there is also a
421:38 - method called half lines capital P which
421:42 - stands for probabilistic half lines
421:45 - transform and this probabilistic half
421:48 - line transform is an optimization of the
421:53 - normal half transform which we have seen
421:56 - in the last video so let me close this
421:59 - example and let's open the example which
422:03 - we are going to see in this video and
422:05 - you can see in this example we have used
422:09 - this Huff lines capital P method so when
422:13 - we use this half lines capital P method
422:16 - it doesn't take all the points into
422:19 - consideration instead it takes only the
422:23 - random subset of the points which is
422:26 - sufficient for the line detection so let
422:29 - us go through this code from the top uh
422:32 - to the end so as you can see I have
422:35 - imported these two packages CV2 and
422:40 - numpy as NP and then I'm reading this
422:43 - image so doku using I'm read method and
422:46 - then I am converting this image to the
422:50 - grayscale image using CVT color method
422:53 - in CV2 now the next step is to find out
422:57 - the edges of the images this we have
423:00 - also seen in the last video so until
423:03 - here everything is same so once we got
423:06 - the edge detected image using Kenny Edge
423:10 - detection instead of using the half
423:13 - lines method we are now using this half
423:16 - lines a capital P method and it takes
423:20 - few arguments the first argument is your
423:23 - Edge detected image the second argument
423:26 - is the row which is the distance
423:28 - resolution of the accumulator in pixels
423:31 - the third argument is the Theta value
423:34 - which we have taken NP dot pi divided by
423:37 - 180 which is the angle resolution of the
423:42 - accumulator in radians
423:44 - the next value is the threshold so it's
423:47 - right now we have taken this threshold
423:49 - as 100 and this threshold is the
423:54 - accumulator threshold parameter which
423:57 - means that only those lines are returned
423:59 - that get enough vote that means greater
424:04 - than the threshold value the extra two
424:08 - argument here are a little bit different
424:11 - from the half lines method so you can
424:14 - see all these arguments are almost same
424:19 - these four arguments but there are two
424:22 - extra
424:23 - arguments here or parameter here which
424:26 - we need to provide so the first
424:28 - parameter here is the Min line length
424:32 - and this we have taken 100 so this Min
424:35 - line length is the minimum length of the
424:38 - line which means that line segments
424:41 - shorter than this length which is 100 it
424:44 - in our case will be rejected
424:47 - the next argument is the maximum line
424:51 - Gap and it is the maximum allowed gap
424:55 - between the line segments to treat them
424:58 - as a single line so these are the two
425:02 - extra argument we have taken and this
425:04 - half lines capital P method is going to
425:06 - return again the output Vector of the
425:10 - lines but the difference between this
425:13 - return value from half line P method and
425:18 - the half lines method is you can see
425:22 - here this line at index 0 is going to
425:26 - directly give you the values of X1 y1
425:29 - and X2 Y2 which are the two points which
425:33 - we will be able to join and we will be
425:36 - able to draw the line using CB2 dot line
425:38 - method in the last video I have shown
425:42 - you that you have to do so much
425:44 - calculation in order to find this X1 y1
425:48 - and X2 Y2 and this probabilistic half
425:51 - line transform method is going to do our
425:55 - job easy and it is going to directly
425:57 - give us these four values so you don't
426:00 - need to do anything you just need to
426:02 - pass this X1 y1 and X2 y to Value to the
426:05 - CB2 dot line method so CV2 dot line
426:10 - method is going to take the first
426:12 - argument which is the image and then the
426:15 - second argument is the point one
426:16 - coordinate which is X1 and Y 1 which we
426:19 - got from the line
426:21 - variable at index 0 and the third
426:25 - parameter here is the point 2 which are
426:28 - the coordinate of the point two which is
426:31 - here x 2 and Y two the next argument
426:35 - here is the color which we have taken
426:38 - right now 0 comma 2 55 5 comma 0 and the
426:44 - last parameter here is the thickness of
426:46 - the line
426:47 - so we have taken 2 here and the next
426:51 - three line are going to just show this
426:54 - image first of all all these lines which
426:57 - we found out are drawn on the image this
427:01 - image which is the original image and
427:03 - then we are just showing this image
427:06 - after drawing all the lines which we got
427:09 - using half lines P method on the
427:12 - original image and then we are just
427:16 - loading this image using this I'm sure
427:18 - method and then after we are done we are
427:21 - just restoring all the windows so let's
427:24 - see what result we get after this script
427:29 - is run so I'm going to run the script
427:31 - and this is the Kenny Edge detected
427:35 - image and this is the image you got when
427:39 - you apply this half lines P method on
427:43 - your Kenny Edge detected image so you
427:47 - can see these lines are no longer going
427:50 - to the end to end these are more ah you
427:55 - know accurately detecting all the lines
427:59 - which are there in this doku image you
428:04 - can see some lines are broken here so
428:06 - that's why these lines are not even you
428:10 - know drawn because they are not even
428:13 - detected by Kenny Edge detection so this
428:15 - one or this one are not detected by
428:18 - Kenny Edge detection so that's why these
428:21 - lines are not drawn so so let me show
428:24 - you these results side by side so this
428:26 - was the result which we got after
428:29 - applying the Hop line transform method
428:32 - which is half lines on our Kenny Edge
428:35 - detected image and you can see all these
428:37 - lines here and this is the result which
428:41 - we got after applying half lines P
428:44 - method which is the probabilistic half
428:47 - line transform so these two methods are
428:51 - available in opencv to detect these
428:55 - lines in an image now let us go back to
428:59 - our script and here instead of this
429:03 - image which is the sudoku.png image I
429:06 - have one more image which is called Road
429:10 - dot JPEG and this is the image which
429:14 - contains a road and inside this road we
429:17 - have some Lane lines so you can see this
429:21 - result now here which is the road and
429:25 - these are the lane lines which are
429:28 - detected using this half lines P method
429:32 - so in case of Lane line detection you
429:36 - can use this half line P method but you
429:39 - need to decide your Roi or region of
429:43 - interest because you can see some lines
429:46 - are detected here here here and here so
429:49 - you just need to ah you know Define your
429:53 - line of Interest region and you will be
429:57 - able to detect all the lines or Lane
430:00 - lines on the road so maybe in the next
430:03 - video we are going to see how we can
430:07 - detect these Lane lines on the road
430:10 - accurately without these noises which we
430:13 - are seeing here ah on the other part of
430:18 - the image so we just need to detect
430:21 - these Lane lines and nothing more and we
430:26 - will do the same on a video so on the
430:30 - video in which these Lane lines are
430:33 - there and we just need to continuously
430:35 - detect these Lane lines so in the case
430:38 - of let's say self-driving car you need
430:40 - to ah detect these Lane lines we are
430:43 - going to see how to detect these Lane
430:46 - lines in the last videos we have learned
430:49 - some important Concepts in opencv now in
430:53 - this video and the next few coming
430:55 - videos I'm going to create a simple
430:59 - project which uses most of these
431:02 - Concepts which we have learned in the
431:05 - previous videos
431:06 - so what we are going to do is we are
431:08 - going to create a very simple Lane
431:11 - detection system so first of all we will
431:16 - start with a still image you can see
431:19 - there is an image which contains uh this
431:22 - road and this road contains Lanes so
431:26 - what we want to achieve is we want to
431:29 - detect these Lanes on which our vehicle
431:33 - is traveling so first of all we will do
431:36 - this with this image and gradually we
431:39 - will move towards the video frames so
431:43 - first of all we will see how to detect
431:45 - these Lanes in this image and then we
431:49 - will see how to detect these Lanes in
431:52 - the moving video so let's get started so
431:56 - I have created this new project in my
431:58 - pycharm IDE you can use any other editor
432:02 - of your choice and first of all
432:04 - obviously you just need to install open
432:06 - CV python package and matplotlib package
432:11 - once you have done that I will create a
432:15 - new file here so I'm going to just right
432:17 - click here and create a new file and I'm
432:20 - going to name this file as detector dot
432:24 - py file so here we are going to import a
432:27 - few packages for example matplotlip so
432:31 - matplotlib dot Pi plot as PLT so let's
432:37 - say as PLT also we are going to import
432:42 - the CV2 package and we are going to
432:46 - import numpy so on import
432:49 - numpy as NP in the next section what we
432:55 - are going to do is we are going to
432:56 - Simply load an image so I am going to
432:59 - create a image variable so image is
433:01 - equal to CV2 dot IM read and we are
433:06 - going to read our image which is the
433:10 - road image so Road dot jpg
433:14 - now in the next line we are going to
433:16 - convert this image into the RGB format
433:21 - because we are going to load this image
433:23 - using matte plot lib so I'm going to
433:27 - just try it once again image so I'm
433:30 - going to overwrite this image variable
433:32 - with the converted image so CV 2 dot CVT
433:39 - color and the source is our image so
433:43 - this is the variable and then CV2 dot
433:47 - color from BGR to RGB right so this is
433:52 - what we want to use now in the next line
433:55 - what we want to do is we want to load
433:58 - our image using uh
434:01 - p l t dot I am show method and at last
434:04 - we are going to just say PLT dot show so
434:09 - this is how we are going to just load
434:12 - our image so I am going to right click
434:14 - on this file and then run this script
434:18 - and you can see this road.jpg image is
434:21 - loaded now on this plot you also see uh
434:25 - these values and one things to observe
434:28 - here is horizontally these values goes
434:33 - from 0 to 1200 something and vertically
434:37 - normally in the graphs you will see that
434:41 - values increases from the bottom to top
434:43 - but in matplotlib this value goes from
434:47 - top to bottom right so 0 is at the top
434:51 - and then the maximum value will be at
434:54 - the bottom so this is a one thing to
434:58 - note because we are going to Define
435:01 - our region of interest and that will be
435:04 - based upon these values now in the next
435:08 - step we want to Define our region of
435:12 - Interest so once again let me just run
435:14 - this code once again and one thing to
435:19 - notice here is this plane in which our
435:23 - vehicle is traveling is parallel so
435:26 - there are two parallel lines and
435:30 - eventually they are going to merge here
435:34 - right so all the Lanes on which the
435:38 - vehicle travels have the same pattern so
435:41 - this Lane and this Lane are parallel to
435:45 - each other and they are going to merge
435:47 - at some point so its not merging but it
435:51 - seems to be merging at some point so we
435:55 - can Define our region of interest from
435:58 - this point to this point point and from
436:02 - this point to this point so this region
436:06 - of interest will be the triangle so this
436:10 - region of Interest we are going to
436:11 - Define for our vehicle will mask any
436:15 - other obstruction for example this is
436:18 - also one lane line for us its not
436:21 - important because this is the other side
436:23 - of the lane so here ah the vehicle will
436:27 - come in the opposite direction so this
436:29 - is our region of Interest so it will
436:32 - mask out this Lane line or any other
436:36 - lines or distortions which we have in
436:40 - this picture we are going to just mask
436:42 - them and we are going to just
436:45 - concentrate on this triangle so let's do
436:49 - this first so first of all we are going
436:52 - to find out the shape of the image so I
436:55 - am going to just print and then we are
436:59 - going to just say image Dot what shape
437:02 - and also we are going to ah just Define
437:06 - the height and width of the image so I
437:08 - am going to just say Okay so let's print
437:12 - this value and let's see what happens so
437:15 - what's at 0 and what's at 1 so you can
437:18 - see it prints seven zero four as our
437:23 - height and one two seven nine as the
437:27 - width so this is what I am just taking
437:30 - from this image shape method so it is
437:34 - going to return this kind of Tuple so at
437:37 - zeroth index there will be height and at
437:40 - the first index there will be ah the
437:43 - width and as I said it starts from 0 to
437:49 - 704 from top to bottom and horizontally
437:53 - it goes from 0 to
437:56 - 1279 from the left hand side to the
437:59 - right hand side right
438:01 - so once we have the width and height we
438:04 - can Define our region of Interest so we
438:07 - are going to Define a variable called
438:10 - region of Interest vertices and here we
438:16 - are going to provide some values
438:19 - so we are going to provide three points
438:21 - which will be the three points of our
438:24 - region of Interest so as I said that our
438:27 - region of Interest we want is this point
438:30 - which is the left
438:32 - bottom corner this point which is the
438:35 - right bottom corner and somewhere in the
438:38 - middle of this image so here so in the
438:42 - image because the vertical height starts
438:47 - from zero so I am going to just say 0
438:49 - comma height and the second point will
438:52 - be the half of the width and half of the
438:55 - height which will be the center of the
438:57 - image so I am going to just say width
438:59 - divided by 2
439:00 - comma height divided by ah 2 and this
439:05 - will be inside these ah
439:09 - parenthesis and the third point will be
439:12 - the next corner so this will be width
439:18 - and then the height so let us try to see
439:21 - these points in our mat plot live window
439:26 - so the first point here is 0 comma
439:29 - 704 which is this point the second point
439:33 - is somewhere here which is the half of
439:35 - the height and half of the width and the
439:38 - third point will be here which is width
439:40 - comma height which is 700 comma
439:45 - 1279 which is this one right so this
439:48 - will be our region of Interest now we
439:52 - are going to Define one function to mask
439:56 - every other thing other than our region
440:00 - of Interest so I will just Define this
440:02 - function def region of interest and this
440:05 - is going to take two parameter first
440:08 - will be the image and second will be the
440:11 - vertices so vertices
440:14 - and inside this function let me just ah
440:18 - minimize this terminal also so you can
440:21 - see the function so inside this function
440:23 - in the first step we are going to define
440:24 - a blank Matrix that matches the image
440:27 - height and the width so this will be the
440:31 - easiest step we are going to Define a
440:33 - variable called mask and we are going to
440:35 - use NP dot zeros like method which is
440:41 - going to take one parameter which will
440:43 - be our image Matrix now in the next step
440:46 - we are going to just retrieve the number
440:49 - of color channels from the image this
440:52 - will be the easy step also so Channel
440:56 - count and then we are going to just say
441:00 - image dot shape and at the second index
441:03 - we are going to find out the channels
441:05 - because we have seen that image.shape is
441:08 - going to give you three values height
441:10 - width and the channel count so this
441:13 - channel count is come coming from this
441:16 - index now in The Next Step what we are
441:20 - going to do is we are going to create a
441:23 - match color with the same color Channel
441:26 - counts so I'm going to just say match
441:29 - underscore mask underscore color this
441:33 - will be our variable name and then we
441:35 - are going to just take 255 comma and
441:41 - then multiply it by the channel count so
441:45 - let's multiply it by the channel count
441:47 - so this is going to create a match color
441:49 - with the same color Channel counts now
441:52 - in the next step we are going to fill
441:53 - inside the polygon using the fill poly
441:57 - method because we have our region of
442:00 - interest and we want to mask every other
442:02 - thing other than our region of Interest
442:04 - so we are going to just say CV2 dot fill
442:09 - poly which is going to takes few
442:11 - arguments first will be our mask second
442:14 - will be the vertices which we are
442:18 - providing using the second argument and
442:21 - the third argument will be our match
442:25 - mask color variable so we are going to
442:27 - pass this variable as the third argument
442:30 - and in the next step we are going to
442:33 - just return the image only where the
442:37 - mask pixel matches so I'm going to just
442:40 - say
442:41 - masked underscore image is equal to CV 2
442:47 - dot bit wise and so we are going to just
442:52 - apply bitwise and using this bitwise and
442:56 - Method and the first argument here will
442:59 - be the image and the second argument is
443:02 - the mask which we got using this zeros
443:07 - like method right and in the last step
443:11 - we are going to just return this so I am
443:13 - going to just write return this masked
443:17 - image and that's it so we are going to
443:20 - just apply our region of interest on the
443:24 - image using this method and then we are
443:28 - going to just get our image which
443:30 - contains region of interest and any
443:33 - other thing will be masked so now it's
443:36 - time to use this method so we are going
443:39 - to just use this method using this
443:43 - variable I am going to just Define a
443:45 - variable called let us say cropped image
443:48 - or masked image whatever you want to
443:51 - write here so let's say cropped
443:53 - underscore image and then we are going
443:58 - to just use this function which is
444:00 - region of Interest function which takes
444:02 - this argument so because we have already
444:05 - read our image in the image variable we
444:09 - are going to pass this as the first
444:11 - argument and the vertices is simply our
444:16 - region of Interest variable so this
444:18 - region of Interest variable we are going
444:20 - to pass using numpy dot array method and
444:25 - let us split this line so we will be
444:28 - able to see what I am doing inside this
444:31 - NP dot array method so first of all the
444:35 - first argument will be our region of
444:37 - Interest
444:38 - variable which is this one region of
444:41 - Interest vertices so in the square
444:43 - bracket we are going to just pass a
444:46 - region of Interest vertices and the
444:49 - second argument here will be NP dot in
444:53 - 32 so NP dot int
444:57 - 32 and now we are going to just show
445:00 - this image using our mat plot lib window
445:05 - so let's run this code and let's see
445:07 - what happens when it runs and there is a
445:10 - problem here so let's see what the
445:12 - problem is so you can see uh this
445:14 - problem is coming from this line and
445:16 - most probably this region of Interest
445:18 - has some problem so you can see we have
445:22 - passed this first element as the Tuple
445:25 - second element as the Tuple and the
445:27 - third element also we need to pass as a
445:30 - tuple and that is why it's giving us the
445:32 - problem so I have just fixed it and
445:35 - let's see what happens when we run this
445:37 - code again and you can see our image is
445:41 - now masked with our region of Interest
445:44 - so we have defined our region of
445:46 - interest from this point to this point
445:49 - to this point so now we have only this
445:52 - region of Interest so we will be able to
445:55 - easily find out this Lane line and this
445:58 - Lane line inside our region of interest
446:00 - and any other distraction will be masked
446:04 - now right so this is the first step
446:08 - which we have achieved which is masking
446:11 - our image and just applying our region
446:14 - of interest on the image in the next
446:17 - step we are going to see how we can
446:20 - apply the edge detection and find out
446:23 - the lane lines on the image in the last
446:28 - video we have started our simple project
446:30 - of detecting Lane lines on the road
446:32 - using opencv and we came to the point
446:36 - where we were able to Define our region
446:39 - of interest and our result was looking
446:42 - like this so let me run this project
446:45 - so we have defined this region of
446:47 - interest and now the only thing which
446:51 - remains here is to detect these Lane
446:55 - lines so we will once again go to the
446:59 - next step and the next step will be to
447:03 - find out the edges and then we are going
447:06 - to apply half line transform to draw the
447:10 - lines so first thing first what I am
447:13 - going to do is I'm going to just move
447:15 - this region of Interest function which
447:17 - we have created in the last video
447:19 - on the top of this script so we can see
447:23 - ah this other code clearly this code
447:26 - which we have written so we have this
447:30 - region of Interest function which we
447:33 - have created then we have just created
447:36 - this region of Interest variable and
447:39 - then we just used our region of Interest
447:42 - function using this region of Interest
447:45 - vertices variable so the next step as I
447:48 - said is to find out the edges and for
447:53 - that we need to First convert our image
447:56 - into our grayscale image so I'm going to
447:59 - just say gray
448:02 - image and then we all know how to find
448:05 - out the gray scale image out of an image
448:09 - so we just need to write CVT color and
448:13 - the source is our cropped image so we
448:16 - are going to pass our cropped image and
448:19 - then we are going to just convert it
448:21 - into a grayscale image using CV2 Dot
448:26 - color
448:27 - underscore
448:29 - rgb2 gray so let's do this so once we
448:34 - got our grayscale image we can apply
448:36 - Kenny H detection on this image so I am
448:39 - going to just write Kenny image
448:43 - and then I'm going to just say CV2 dot
448:47 - ah Kenny which is the function which we
448:50 - want to use which takes few parameter
448:53 - first parameter will be our grayscale
448:55 - image the second parameter will be the
448:58 - first threshold and the second threshold
449:00 - so generally we are going to take here
449:03 - 100 as the first threshold and 200 as
449:07 - the second threshold now in the next
449:12 - step we are going to just uh display
449:16 - this image on our
449:19 - matplotlib window and let's see what
449:22 - happens once ah we apply the scanning
449:26 - Edge detection method on the image so
449:28 - now you can see this result which
449:31 - detects all the edges and here you can
449:34 - see the lane line edges are detected but
449:38 - there is one more thing here which is
449:41 - the edges of our region of Interest are
449:45 - also detected so how to solve this how
449:48 - to remove these edges because these
449:50 - edges doesn't interest us the
449:53 - interesting ah edges here in this image
449:57 - for us are these edges which are of the
450:01 - lanes Road planes right so to solve this
450:04 - problem we can apply the scanning Edge
450:06 - detection before we find out the region
450:10 - of Interest so I am going to just copy
450:12 - this code and paste it just before we
450:15 - apply this region of Interest method
450:18 - which we have created in the last video
450:20 - so now in our Kenny Edge detection ah we
450:25 - will pass the gray scale image but here
450:27 - instead of this ah cropped image which
450:31 - we were getting in the last step from
450:34 - this variable we directly are going to
450:37 - pass our image which we have read using
450:40 - the I am read method right so let me
450:44 - just ah remove all these line breaks so
450:48 - you will be able to see the code at once
450:51 - so here you can see I have directly
450:54 - passed now this image variable to the
450:58 - CVT color or method so we get the
451:02 - grayscale image of the original image
451:04 - and then we apply the Kenny Edge
451:07 - detection on the original image and then
451:09 - we are applying the region of Interest
451:13 - method which we have created in the last
451:15 - video now because we are applying this
451:22 - region of Interest method on the
451:24 - grayscale image or the edge detected
451:27 - image therefore we do not need this
451:32 - channel here so we can comment out this
451:35 - code which was kind counting out the
451:38 - number of channels and for the
451:41 - grayscale image and the Kenny has
451:44 - detected the image we just take this
451:47 - match mask color as 255 because it's
451:49 - only one color right we don't need any
451:53 - color channels here because we are just
451:56 - passing the grayscale image which has
451:58 - only one color so that's why we don't
452:00 - need any channel because there will be
452:02 - only one channel and that is why I have
452:05 - commented this code and the value of the
452:08 - match mask color will be 255 now
452:11 - once you do that let's try to run this
452:14 - code and let's see what happens ah once
452:17 - again we need to load the cropped image
452:20 - not the Kenny image so just replace this
452:23 - variable here in the IM show method and
452:27 - let's run this code once again so you
452:30 - can see now uh there is some mistake
452:33 - here because we were expecting the edge
452:36 - detected image and we are getting this
452:38 - image so let's see what's the problem is
452:41 - so the problem I see here is because we
452:45 - have applied this region of interest on
452:48 - the original image which we do not want
452:50 - now we want to apply this
452:53 - ah region of interest on the Kenny as
452:55 - detected image so we have to pass as the
452:59 - first variable of the region of Interest
453:00 - method the scanning Edge detected image
453:04 - not the original image right so once
453:06 - again for you you can see this code
453:09 - region of Interest method and all this
453:11 - code at a one glance let's run the code
453:14 - and let's see what happens so now we get
453:16 - the better result so we have these edges
453:21 - which are detected by the Kenny Edge
453:23 - detection for only the lane lines inside
453:27 - our region of interest and now it will
453:29 - be easier to draw the lines on these
453:33 - edges which we have detected
453:35 - so the next step will be to draw the
453:39 - lines on these edges using the half line
453:43 - transform
453:44 - so we have in the previous videos have
453:48 - already seen how to use the half line
453:51 - transform so I'm not going to go into
453:54 - the details so let's just directly jump
453:58 - into using that half line transform
454:02 - so what we are going to do is in the
454:05 - next line after we have got our cropped
454:10 - image we are going to just Define a
454:14 - variable called lines and we are going
454:17 - to use this half line transform
454:20 - probabilistic half line transform method
454:22 - so here CB2 dot half line transform
454:28 - and this will be this method which takes
454:30 - few argument first argument will be the
454:33 - image so I am going to pass this cropped
454:36 - image here the second argument here will
454:40 - be the value of rho so let's provide
454:44 - this row value variable value which will
454:47 - be 6 in our case then in the next
454:51 - parameter we have to pass the value of
454:54 - theta and Theta will be ah equal to n p
454:59 - dot Pi which is the method inside the
455:02 - numpy Library so NP dot pi
455:05 - divided by 60 so I am going to pass here
455:09 - divided by 60 then the next parameter
455:12 - here will be the threshold so the
455:15 - threshold value we are going to provide
455:17 - here will be 160 the next parameter here
455:20 - will be lines which is equal to none by
455:23 - default so I am going to provide this
455:25 - variable lines is equal to and then ah
455:30 - we are going to pass the empty numpy
455:33 - array so I am going to just say ah num
455:36 - pi and P dot array and then we are going
455:40 - to just pass the blank square bracket
455:42 - here the next two parameters will be the
455:45 - Min line length so let's Pro provide
455:48 - this Min line length and let us say we
455:52 - want 40 as the minimum line length and
455:55 - the max line Gap so let's provide that
455:58 - also MAX Line Gap and this will be let
456:02 - us say initial value for that will be
456:03 - 25.
456:05 - so now after applying this half line
456:08 - transform you know that it is going to
456:11 - return the line Vector of all the lines
456:15 - which are detected inside our image
456:18 - which we have provided as the source
456:20 - here so if you don't know what are these
456:23 - parameters which I am using here you can
456:26 - see my last videos about probabilistic
456:30 - half line transform and you will be able
456:32 - to know what they actually mean now once
456:36 - we got our line vectors then we can draw
456:41 - the lines easily and for that we are
456:44 - going to Define our next function which
456:47 - is to draw the lines so I am going to
456:50 - just Define this function
456:52 - with the name
456:54 - draw the
456:56 - lines for example and it's going to take
457:00 - few parameters so let's pass these
457:03 - parameters first parameter will be the
457:06 - image or the original image the second
457:09 - parameter will be the line vectors which
457:13 - we have found out and that's it so there
457:18 - are these two ah parameters we are going
457:20 - to pass here now ah inside this function
457:25 - what we are going to do is we are going
457:26 - to first of all copy our image so I am
457:29 - going to just say I'm G is equal to NP
457:32 - Dot copy and then we are going to just
457:37 - make a copy of the image variable which
457:41 - we are providing and then or you can
457:44 - write here copy image whatever I'm just
457:47 - just reassigning this copy the image to
457:50 - the same variable but you can define a
457:53 - new variable here for the copied image
457:55 - also
457:57 - now in the next line we are going to
457:59 - create a blank image that matches the
458:03 - original image size so the dimension
458:06 - should be equal so for this we can just
458:10 - say ah line
458:13 - image
458:15 - and then we are going to just say NP dot
458:18 - zeros inside these parentheses we are
458:21 - going to provide the shape of our image
458:25 - right so you can provide the shape of
458:27 - our image using the image variable so
458:30 - first of all it's going to take the
458:32 - height and then the width and then the
458:35 - number of channels so because we know
458:38 - that this is a colored image which we
458:41 - are working with so we are going to just
458:45 - say IMG dot shape and we all know that
458:49 - the zeroth index parameter here will be
458:53 - the height the second parameter I am g
458:56 - dot shape the
458:59 - value add the first index will be the
459:02 - width and the number of channel for the
459:04 - colored image are always three so we are
459:07 - going to provide the third parameter as
459:09 - three here so this is in the form of
459:11 - Tuple I am providing and the next
459:14 - parameter here will be the data type or
459:16 - D type so let's provide that D type is
459:19 - equal to num Pi dot U in
459:24 - it
459:25 - okay so U and eighth not uninted you
459:30 - into it so this will be ah the second
459:33 - parameter so once we have this image
459:37 - which is exactly same as the size of our
459:41 - original image we are going to loop
459:45 - around these line vectors and then we
459:49 - are going to draw the lines right so
459:52 - let's loop around these uh line vectors
459:55 - and draw all these lines which were
459:58 - found
459:59 - so for that we are going to use the for
460:01 - Loop and then we are going to say line
460:03 - in lines
460:06 - and these this lines variable is coming
460:09 - from this lines variable so we are going
460:13 - to use this draw lines function and we
460:16 - are going to pass this lines Vector as
460:18 - the second parameter here so this is how
460:21 - ah this line variable is coming here
460:25 - so now inside this for Loop we are going
460:28 - to ah just Define one more for Loop
460:32 - because this line is going to give us
460:35 - four parameters which is the coordinates
460:40 - of the first point in the line and the
460:43 - coordinates of the second point in the
460:45 - line so we are going to just once again
460:48 - say for
460:50 - X1 which is the first coordinate of the
460:54 - first point and the Y 1 and then
460:57 - similarly x 2 and the Y 2 so this will
461:01 - be ah the line coordinate in the line ah
461:06 - which we got from the line vector
461:09 - and then inside this for Loop we are
461:12 - going to draw a line and drawing line is
461:15 - really easy by using CV2 dot line method
461:19 - which takes a few parameters as you
461:22 - already know the image and then the
461:26 - second parameter is the coordinate of
461:28 - the first point which we already have
461:30 - using this iteration which is x 1 comma
461:35 - y1 and third parameter here will be the
461:40 - coordinates of the second point x 2
461:43 - comma Y 2 and then you can provide the
461:48 - color and thickness so let's provide
461:50 - this color so the color here I'm going
461:53 - to take let's say 0 comma 255 comma 0
461:58 - you can take any color here and the
462:02 - thickness so the thickness here I'm
462:03 - going to take is ah let's provide this
462:07 - parameter thickness is equal to 3 okay
462:11 - so this is the thickness of the line
462:13 - which we want to draw and here I think
462:16 - this blank image should uh be uh given
462:20 - because we want to draw the line on the
462:22 - blank image and then merge it with the
462:25 - original image so here we have to
462:28 - provide this line image or you can say
462:30 - this is the blank image which is more
462:35 - appropriate in this case so we want to
462:38 - draw the line on the blank image which
462:40 - is of the same size of the original
462:43 - image and now once we draw these lines
462:45 - on the blank image we can merge this
462:48 - blank image and the original image which
462:51 - will give us the a line which are drawn
462:55 - on the original image so outside this
462:57 - for Loop we are going to merge the image
463:01 - with the lines into the original image
463:04 - so our original image is the image ah
463:09 - itself so image variable is the our
463:10 - original image and then we are going to
463:14 - just say CB 2 dot add weighted this
463:18 - function also we have seen in the last
463:20 - videos and this is the function which we
463:25 - use to merge two images with some
463:28 - weights so the first parameter here will
463:31 - be image now the second parameter here
463:34 - will be the value of alpha so which we
463:37 - are going to give here 8 this is like a
463:40 - weight to an image which we want to
463:43 - provide and then the third parameter
463:46 - here will be the second image so we want
463:48 - to merge the blank image with the
463:50 - original image the fourth parameter is
463:53 - the value of beta so this value we are
463:56 - going to take as one and the last value
464:00 - will be of gamma so gamma we are going
464:03 - to take as 0.0 here okay so this add
464:07 - weighted also we have seen in the last
464:10 - video how to use it so I am not going
464:13 - into the details and at last once we
464:17 - have the lines on the image then we are
464:21 - going to Simply return it so let's uh
464:24 - return this image IMG so once we have
464:28 - this function we are going to call this
464:30 - function after applying the half line
464:32 - transform method which is the
464:35 - probabilistic half line transform so
464:37 - here in the next line we are going to
464:39 - just Define a variable called image
464:42 - with lines let us say is equal to our
464:47 - method which is draw the lines method
464:50 - the first argument is the original image
464:52 - so we are going to pass the original
464:54 - image the second argument is the line
464:56 - Vector which we got from this method
464:59 - right so the original image and the line
465:04 - Vector variable which we got here at
465:07 - last we are going to just see what is
465:11 - the result which we got after applying
465:14 - this draw the lines method on the
465:17 - original image so let us run this code
465:21 - and let's see what happens
465:23 - so now you can see let me just maximize
465:27 - it you can see this line is drawn on our
465:31 - image so this is the first line and this
465:35 - is the second line so we got the result
465:37 - which we wanted if you want to change
465:39 - the thickness or the color of this line
465:43 - on the image you can just change it
465:46 - using this draw lines method so this is
465:50 - the line and thickness parameter so for
465:53 - example I want to change this to 255
465:57 - here some different color and the
466:00 - thickness let us say 4 and I'm going to
466:03 - run this code and now you can see this
466:06 - yellow color here right so you can
466:08 - change the thickness and the color using
466:11 - uh this method so let's say for now we
466:15 - want the the red color
466:18 - so we are going to go with this red
466:21 - color on the lane lines so this is what
466:24 - we wanted to achieve we wanted to draw
466:27 - the lane lines on these lanes and we
466:30 - have achieved this in the next video we
466:33 - are going to see how we can apply the
466:36 - same concept on a live video or on a
466:40 - video of this road for example so for
466:44 - example this car is running on the road
466:47 - and we want to continuously draw these
466:51 - lines on the lane lines how we can
466:54 - achieve this using opencv we are going
466:56 - to see in the next video
466:59 - in the last two videos we have seen how
467:01 - we can detect the lane lines on the road
467:04 - using opencv
467:07 - now till now we have only worked with
467:10 - this image and in this video we are
467:12 - going to try to apply what we have
467:15 - written not on an image but with the
467:19 - video frames but you have already
467:22 - learned in the previous videos that a
467:25 - video frame is like an image so a video
467:29 - contains many number of frames so if we
467:33 - apply the same technique on each frame
467:36 - we will be able to detect these Lane
467:39 - lines on the video frames also so let's
467:43 - apply that concept on our script what we
467:47 - have till now
467:48 - so right now I have added this test dot
467:52 - MP4 video inside my project so let me
467:55 - show you how it looks like so our video
467:58 - looks like this so we are going to apply
468:00 - all these concept which we have applied
468:02 - on an image on this video so let's get
468:06 - started so I hope you have this code
468:10 - which we have written in the last two
468:12 - videos the only thing we need to do here
468:14 - is we need to read the video instead of
468:18 - an image and then apply those Concepts
468:23 - on the frame instead of an image so we
468:26 - till now have two functions region of
468:29 - Interest draw the line and we have this
468:32 - code so this all code we are going to
468:35 - enclose inside the function so that it
468:39 - will be easier to apply all this code on
468:43 - the video frames now as you already know
468:46 - that this will not be used because we
468:50 - are reading the videos so we don't need
468:52 - to read the image obviously so we are
468:55 - going to comment these two lines out so
468:58 - we do not need to convert
469:01 - gr to RGB because we are going to use
469:05 - this native CV2 Library not the mat plot
469:10 - lab library for which we have converted
469:12 - this BGR to RGB image so now we are
469:16 - going to define a function so let us
469:18 - Define this function and I am going to
469:19 - name this function as process and it is
469:22 - going to take an argument which will be
469:25 - the image argument and all this code
469:30 - which is under this which we have
469:32 - written in the last video we are going
469:33 - to enclose this code inside this process
469:37 - function we don't need these two lines
469:39 - because we are not going to use
469:42 - matplotlib for processing this video so
469:45 - I am going to remove these two lines and
469:48 - I'm going to just give
469:50 - a space here for this code so it can be
469:54 - enclosed inside this function
469:57 - now at last or at the end of this
470:00 - function we are going to just return
470:03 - this image with lines so we are going to
470:06 - return this image with lines using this
470:10 - process function that means on every
470:12 - frame we are going to draw the lines and
470:14 - return it using this process function
470:16 - next we are going to read the video
470:18 - using the video capture functions so I
470:21 - am going to declare a variable cap is
470:23 - equal to CV2 dot video capture
470:27 - and then we are going to just pass one
470:31 - argument which will be our video file
470:34 - which is test dot MP4 in our case so
470:38 - test dot MP4 and then once we have this
470:42 - video we are going to check if the video
470:45 - frame is available using the while loop
470:48 - so let's use this while loop and we are
470:51 - going to check if cap dot is open is
470:57 - valid or not so is opened and this
471:00 - function is going to return the Boolean
471:02 - value so if this video frame is still
471:06 - available is going to return true and
471:08 - whatever we write inside the while loop
471:11 - is going to be executed now in the next
471:14 - line we are going to just read every
471:17 - frame so we all know from our previous
471:20 - videos that this cap dot read returns to
471:26 - a result or two variables one is re T
471:30 - and the other is the frame and we are
471:35 - going to just say cap dot read and then
471:38 - we are going to apply our process
471:40 - function on this Frame so we are going
471:43 - to once again
471:44 - take this Frame variable and we are
471:47 - going to overwrite this frame with the
471:51 - lines on the frames so this we are going
471:54 - to get from our process functions let's
471:56 - call the process function and pass the
471:59 - frame variable inside it okay so this
472:04 - Frame is going to go to the process
472:06 - function it is going to process
472:07 - everything and then the final result
472:10 - which we get is going to be saved once
472:14 - again into the frame variable with the
472:16 - actual lines on the frame in the next
472:19 - line we are going to just show our
472:20 - result using CB2 dot I am show method
472:23 - and we are going to just pass the frame
472:26 - variable here in the next line we are
472:28 - going to just write the code for the
472:31 - quitting from this Loop so we are going
472:33 - to just say if c v 2 dot weight key
472:39 - is going to be 1 and then we are going
472:42 - to apply the end operator and then write
472:44 - 0xff for the cross platform
472:48 - functionality and then we are going to
472:50 - just say is equal to ord so whenever
472:55 - somebody presses the queue key then we
473:00 - are going to exit from this Loop and
473:03 - then in the next line we are going to
473:05 - just say break so break out of the loop
473:07 - the last two line in the last two line
473:10 - outside this Loop we are going to just
473:14 - ah call the release function on the cap
473:19 - variable and we are going to destroy all
473:22 - the windows in the CV2 so we are going
473:24 - to just say destroy all windows that's
473:27 - it hopefully this is going to work so
473:30 - let's uh just run this script once again
473:33 - and let's see what happens and here we
473:36 - got the error and it's coming from this
473:38 - line which is CV2 dot I am sure we
473:41 - forgot to give the first argument here
473:44 - which will be the name of this window we
473:46 - are going to just say frame here and
473:49 - let's run this script once again and
473:52 - let's see what happens and you can see
473:54 - on this video on this Lane line our
473:58 - lines are drawn right so this is the
474:02 - result which we were expecting we can
474:05 - improve this result by adjusting few
474:08 - variables so we are going to first of
474:11 - all press Q to quit and let's change
474:15 - some of these values here in the half
474:18 - line transform so we are going to just
474:20 - say that the max line Gap is going to be
474:23 - 100 we are going to reduce the threshold
474:26 - value to 50 and row value to 2 okay
474:29 - inside this half lines P method and
474:33 - let's run this code so let's see what
474:36 - result we get this is also OK let us
474:39 - improve it little bit more in the Kenny
474:42 - Edge detection we can reduce this
474:46 - threshold value here to 120 the second
474:49 - threshold value and let's run this code
474:51 - once again and now we get the better
474:54 - result
474:55 - so the problem might be the edge
474:59 - detection so we have reduced our
475:03 - second threshold and now we get the
475:06 - better result you can see on this Middle
475:09 - Lane the lines are drawn clearly so this
475:12 - is how you can write a simple script to
475:14 - detect Lane lines on the road
475:18 - I hope you have enjoyed this video and I
475:20 - will see you in the next video
475:34 - we have already seen how to use half
475:36 - line transform to detect lines in opencv
475:40 - in this video we are going to see how we
475:42 - can use half circle transform to detect
475:45 - circles in an image
475:48 - now as you can see here I have this ah
475:52 - small example which loads an image and
475:55 - shows it into the I am show window so
476:00 - let me run this code and let me show you
476:01 - how this image looks like so you can see
476:05 - there are so many Smarties here inside
476:09 - this image and all the smarties are of
476:13 - circle form right they are not of the
476:17 - perfect circles but they are in the form
476:21 - of circles and we want to detect all
476:24 - these circles forms inside the image we
476:29 - can use half circle transform for that
476:32 - so let's see how we can use this half
476:35 - circle transform to detect the circles
476:38 - in the image
476:40 - so a circle is represented
476:42 - mathematically by this equation which
476:44 - you see on your screen
476:47 - so here X Center and the Y Center are
476:52 - the coordinates of the center and R here
476:56 - is the radius of the circle so if you
476:59 - know these three parameters then you can
477:03 - draw a circle so this coordinates of the
477:06 - circle and the radius of the circle we
477:09 - need to detect
477:11 - so now let's see how half circle method
477:15 - is applied using opencv so you might
477:19 - observe here that I have created a copy
477:22 - of this original image which I have read
477:25 - using this I am a read method in The
477:28 - Next Step I'm going to just convert this
477:32 - image into a grayscale image so I'm
477:33 - going to just write the gray is equal to
477:37 - CV dot CVT color which is going to take
477:43 - two parameters first is the source and
477:46 - second is the method so we are going to
477:49 - convert
477:50 - the color BGR to gray now in The Next
477:54 - Step because our half circle method
477:58 - works better with the Blurred images so
478:02 - we are going to uh create this blurred
478:05 - image using median blur so I'm going to
478:09 - just say gray so we are going to
478:11 - override this gray variable with CV2 dot
478:16 - median blur which is going to take a few
478:19 - arguments first is the image itself so
478:22 - we are going to pass gray here and the
478:25 - second is the case size or the kernel
478:29 - size so we are going to initially
478:31 - provide the kernel size of 5 here
478:34 - now we are going to apply our half
478:38 - circles uh method so I am going to
478:41 - declare this circles variable and then
478:46 - I'm going to just call this method which
478:48 - is called CV dot half circles method so
478:53 - this is the method and you can see it
478:57 - takes few parameters so we are going to
478:59 - give these parameters one by one first
479:03 - is the obvious one which is the image so
479:07 - we are going to provide the gray scale
479:10 - image here which is already blurred so
479:13 - the second parameter here is the method
479:16 - which we want to use currently the only
479:19 - implemented method is half gradient
479:23 - method so the choice is very simple here
479:26 - we are going to just provide this CV dot
479:31 - half gradient method the third parameter
479:36 - here will be DP DP is the inverse ratio
479:40 - of accumulator resolution to the image
479:43 - resolution so for example when DP is
479:46 - equal to 1 the accumulator has the same
479:49 - resolution as the input image and if the
479:53 - DP is equal to 2 then accumulator has
479:57 - the half as big as width and the height
480:01 - so we are going to take this DP value as
480:05 - 1 the next parameter here will be Min
480:09 - dist it is the minimum distance between
480:12 - the center of the detected circles okay
480:16 - so here we are going to give initially
480:20 - the value of 20 and later we will adjust
480:24 - this value if the circles are very near
480:28 - to each other the next parameter which
480:31 - we are going to give here is the value
480:33 - of parameter 1 and parameter 2 or param
480:37 - 1 or param 2. the param 1 is the first
480:41 - method specific parameter in case of
480:45 - half gradient it is higher threshold of
480:48 - the two passed to the Kenny Edge
480:52 - detector param 2 is the second method
480:56 - specific to the method which we have
480:59 - provided here which is the half gradient
481:01 - method it is the accumulator threshold
481:05 - for the circle centers at the detection
481:09 - stage so we are going to provide the
481:12 - value of the param 1 and param 2 here so
481:16 - let's start with the param one value and
481:19 - we are going to provide param 1 value is
481:21 - equal to 50 and param 2 value is equal
481:26 - to ah let us say 30. so those param 1
481:29 - and param 2
481:31 - parameters are specific to this method
481:34 - which we are using the next parameter
481:38 - which we are going to pass here is the
481:40 - Min radius and the Min radius is the
481:44 - minimum Circle radius and we are going
481:48 - to just start with the zero so we are
481:50 - going to say that anything which is
481:52 - greater than 0 we are going to just draw
481:56 - it and then we are going to provide the
481:59 - max
482:01 - radius if this Max radius is greater
482:04 - than or equal to 0 it uses the maximum
482:07 - image Dimension if it's only greater
482:11 - than 0 it returns Center without finding
482:15 - the radius so this also we are going to
482:17 - start with 0 let me just break this
482:20 - function so you can see all the
482:22 - parameters here so this half circle
482:25 - method is going to give us the circle
482:27 - Vector which we can iterate upon but
482:31 - first of all we need to convert those
482:34 - Circle parameters which we got using
482:37 - this circle Vehicles variable that is x
482:41 - and y coordinate and the radius into an
482:44 - integer so to do that we are going to
482:49 - just declare a parameter called detected
482:52 - circles and then we are going to use
482:55 - numpy to convert them into an integer so
482:59 - I am going to just say NP dot u in 16
483:04 - and then in the parenthesis I'm going to
483:06 - just use NP dot around and we are going
483:11 - to pass our circles
483:14 - parameter which we got using the half
483:17 - circles method now in the next step we
483:19 - are going to iterate over those detected
483:22 - circles so we are going to just say ah
483:25 - for and because this circle Vector is
483:30 - going to give us x y and the radius we
483:34 - can directly just extract those values
483:37 - so we are going to just say x comma y
483:39 - comma R and then in our detected circles
483:45 - and those circles will be at this index
483:50 - so 0 comma colon and then inside this
483:54 - for Loop we are going to first of all
483:55 - draw the circle and also we are going to
483:58 - draw the center so to draw the circle we
484:03 - already know that we have this circle
484:06 - method available which takes few
484:09 - parameter first is the image so we are
484:13 - going to pass us the copy of this image
484:16 - here so let's pass this copy which is
484:19 - output the second argument here will be
484:21 - the center which are the coordinate of
484:23 - the center which we already got in the
484:26 - form of X comma y so we will give them
484:29 - uh in the form of Tuple the third
484:32 - argument is the radius so radius is
484:35 - extracted in the r parameter here so we
484:38 - are going to pass the radius here and
484:41 - then the next parameter will be the
484:45 - color so let's start with let's say
484:48 - green color
484:49 - and then the thickness so we are going
484:52 - to give the thickness of let's say 3
484:55 - here
484:57 - similarly when we use the same Circle
485:00 - method and we want to draw the center
485:03 - then we know that this is the center so
485:07 - these are the coordinates of the center
485:09 - and if the radius is very small let us
485:12 - say 2 then it is going to just draw a
485:16 - small point right so that is why I have
485:19 - given very small value for example 2
485:22 - here so it is going to just draw a very
485:25 - small circle which will look like a DOT
485:29 - on the circle that's why this value is
485:32 - very small and we are going to just say
485:36 - that this will be also 3 and let us
485:39 - change the color of this dot let us say
485:42 - this will be this color
485:45 - okay so we are just drawing those circle
485:49 - on the copy of the image which is called
485:53 - the output so let's run this code and
485:56 - let's see what happens when we run this
485:58 - code and you can see this dot is first
486:04 - of all drawn on each circle which is
486:07 - detected which is in the form of yellow
486:10 - and also in the form of green all the
486:14 - circles are drawn so you can see this
486:18 - circle is drawn so every ah circular
486:21 - shape is ah you know enclosed by the
486:27 - detected Circle we also strangely
486:30 - detected this circle
486:33 - somehow because
486:35 - opencv think that this is also a circle
486:39 - I have one more image which is shapes
486:41 - dot jpg so we are going to just ah see
486:46 - that also so I am going to just say
486:48 - shapes dot j p g let me show you this
486:52 - image first of all so it looks like this
486:54 - so it has only one Circle and some other
486:57 - shapes right so we are going to just run
487:00 - this code once again and you can see it
487:03 - just detect the circle and it just draws
487:07 - a small dot on the center and all the
487:11 - other shapes are undetected
487:14 - so this is how you can detect the
487:16 - circles inside an image using half
487:20 - circle transform in this video we are
487:23 - going to discuss about the basics of
487:25 - phase detection using har feature based
487:28 - Cascade classifiers so object detection
487:32 - using har feature based Cascade
487:35 - classifiers is an effective object
487:38 - detection method proposed by Paul Viola
487:42 - and Michael Jones in their paper now har
487:45 - feature based Cascades classifier is a
487:48 - machine learning based approach where a
487:52 - Cascade function is trained for a lot of
487:56 - positive and negative images now what
487:59 - are these positive and negative images
488:02 - so first a classifier is trained with
488:05 - few hundred sample views of particular
488:09 - object that is a face or a car or any
488:13 - other object that is called a positive
488:16 - example so whatever you want to detect
488:18 - if you train your classifier with those
488:22 - kind of values so for example if you
488:24 - want to detect face then you need to
488:27 - train your classifier with the number of
488:29 - images which contain faces so these are
488:33 - called the positive images which
488:35 - contains the object which you want to
488:37 - detect similarly we want the classifier
488:40 - to train with the negative images that
488:44 - means the images which doesn't contain
488:47 - the object which you want to detect so
488:49 - in our case for example we want to
488:52 - detect the face then the image which
488:55 - doesn't contain the face then it is
488:58 - called the negative image and if the
489:00 - image contains phase or number of faces
489:03 - then it is called the positive image and
489:06 - after a classifier is trained it can be
489:08 - applied to a region of interest in an
489:12 - input image and the classifier outputs a
489:16 - 1 if the region is likely to show the
489:19 - object or zero otherwise so let's see
489:22 - how we can use hard Cascade detection in
489:26 - opencv
489:27 - so opencv comes with a trainer as well
489:31 - as a detector so if you want to train
489:33 - your classifier for any object for
489:37 - example a watch or a car or train or
489:41 - anything then you can use this
489:45 - classifier also on open CVS GitHub page
489:49 - you can find some trained classifier XML
489:53 - files so let me show you these
489:56 - classifiers on the open series GitHub
489:59 - page so here is the opencv repository
490:04 - and inside this repository you can see
490:07 - this data folder and then go to Har
490:10 - Cascades I will just share the link with
490:13 - you in the description so you can
490:15 - directly navigate to this website and
490:19 - this location and you can see plenty of
490:23 - trained classifiers are available inside
490:26 - this report repository so for our
490:30 - example we want to detect the face so we
490:33 - are going to use this trained classifier
490:37 - which is called heart crack Cascade
490:39 - underscore frontal phase underscore
490:42 - default dot XML file so you just need to
490:45 - open this file and then download it you
490:48 - can just click on the raw icon here this
490:53 - button and once this raw file is open
490:57 - you can just right click and save it on
491:01 - your computer so you can just say save
491:04 - page as and then you can just save this
491:07 - inside your opencb project so I have
491:11 - already saved this file inside my opencv
491:15 - project you can see this file here which
491:18 - is a XML file which I have downloaded
491:21 - using this repository so as you can see
491:24 - here I have this code which is the
491:26 - minimal code to a load an image and show
491:29 - it using opencv window now in The Next
491:32 - Step what I am going to do is before
491:36 - this reading we are going to just Define
491:40 - our classifiers so because it's a phase
491:42 - classifier I'm going to name my variable
491:45 - as face Cascade and then in opencv there
491:51 - is a method called so I am going to just
491:53 - call this method and there is a method
491:56 - called Cascade classifier so this is
492:00 - this method called Cascade classifier
492:03 - where you can provide your classifier
492:07 - name which is the XML file so just
492:10 - provide your trained classifier file
492:13 - name in our case it's hard Cascade
492:16 - underscore frontal face underscore
492:18 - default dot XML so once we have our
492:22 - classifier we read the image and then
492:26 - because this class if I will work with
492:28 - the grayscale images we are going to
492:31 - convert our image into a grayscale image
492:33 - and it will be really easy to convert
492:36 - our image to a grayscale image now once
492:39 - we have our grayscale image the next
492:42 - step is to detect the faces inside this
492:44 - image so for that we are going to
492:47 - declare this variable let us say faces
492:50 - and then we are going to use this result
492:53 - which we got using this Cascade
492:57 - classifier and then we can call a method
493:02 - called detect multi scale so we are
493:05 - going to ah just call this method which
493:09 - takes few argument first is the image so
493:12 - we are going to provide our gray scale
493:15 - image here and the second argument we
493:18 - are going to use here will be the scale
493:20 - factor so the scale factor parameter
493:23 - specifies how much the image size is
493:26 - reduced at each image scale so to start
493:30 - with we are going to provide a 1.1 ah
493:34 - value here and then the next parameter
493:36 - which we are going to provide here will
493:38 - be the Min neighbors parameter so Min
493:42 - neighbor's parameter is going to specify
493:44 - how many neighbors each candidate
493:47 - rectangle should have to retain it so we
493:51 - are going to provide this value 4 here
493:54 - to start with and if it does not give us
493:57 - the proper result we are going to change
494:00 - it and the last step here will be to
494:02 - iterate over all the faces which we have
494:05 - detected and then draw a rectangle on
494:09 - them so this phase variable will be the
494:11 - vector of rectangle where each rectangle
494:15 - contains the detected object in our case
494:18 - this will be the detected phase so the
494:21 - rectangle may be partially outside the
494:24 - original image if it's on the corner so
494:28 - the if the object or the face is on the
494:32 - corner then this rectangle may be little
494:35 - bit outside the original image so we are
494:38 - going to iterate over this faces uh
494:42 - object and here we are going to get the
494:46 - parameter X comma y comma W comma H
494:51 - which means the values of X and Y and
494:55 - the width and height of the rectangle of
494:59 - the object in our case this is the faces
495:03 - right so we got
495:06 - all the four parameters for drawing the
495:09 - rectangle and then we can just call CV2
495:13 - dot rectangle method to draw the
495:16 - rectangles the first parameter here will
495:18 - be the image the second parameter will
495:21 - be the point one which will be X comma Y
495:24 - which we got using this faces vector and
495:30 - then we need to give the second point
495:33 - which will be X plus W comma y plus
495:38 - height okay and then the next two
495:42 - parameters are the color and the
495:46 - thickness so we are going to give the
495:47 - color 255 comma 0 comma 0 here and the
495:51 - thickness to start with we are going to
495:53 - give 3 here that's it so its this simple
495:57 - to detect faces inside the images using
496:01 - har Cascade classifiers so now I am
496:05 - going to run this this code and let's
496:07 - see what happens
496:08 - so you can see this is the face so this
496:12 - is how you can detect the face or a
496:14 - multiple number of faces inside an image
496:17 - let's try to detect the face inside a
496:21 - video so I'm going to just close this
496:25 - window and now we are going to try to
496:28 - detect the face inside a video so this
496:30 - will be nothing different than this
496:34 - approach we just need to apply this
496:36 - approach on each and every single frame
496:39 - so instead of ah this code we are going
496:44 - to use the video capture method to
496:47 - capture the video so you can see I have
496:50 - this test dot MP4 video here so we are
496:53 - going to define a cap variable is equal
496:57 - to CB2 dot video capture and then in the
497:02 - parenthesis we are going to provide a
497:04 - the test dot mp4 file here or if you
497:09 - have the camera you can provide 0 here
497:11 - as the parameter and then all this code
497:15 - we are going to just enclose inside a
497:18 - while loop so we are going to just say
497:22 - that while cap dot is opened so if cap
497:27 - dot is opened is going to give us ah
497:30 - True Value then we are going to read the
497:34 - frame so ah underscore let us say ah the
497:39 - parameter name will be IMG in this case
497:42 - also normally we take the variable name
497:46 - frame here because we are reading each
497:48 - and every frame and then I am going to
497:51 - just say cap dot read okay so cap dot
497:56 - read this means we are reading every
497:58 - frame and let us enclose this code also
498:02 - inside this while loop so I am going to
498:05 - just provide a little space here so
498:08 - basically we are getting every frame and
498:12 - then applying the same procedure on each
498:15 - and every frame and at last outside our
498:18 - while loop we are going to release our
498:22 - cap so we are going to just say cap dot
498:25 - release and here instead of using this
498:29 - CB2 dot weight key you are going to
498:32 - provide a condition if c v two dot
498:36 - weight key and in the parenthesis we are
498:39 - going to provide one and zero x f f is
498:43 - equal to or D and we are going to listen
498:47 - for the key ah Q so if somebody presses
498:51 - the Key Queue then we are going to break
498:55 - out of this while loop so let's run this
498:59 - script and let's see what happens when
499:01 - we run the same script on a video so
499:04 - this is the wind video and this is in
499:07 - this video so you can see in this video
499:09 - the face is detected in real time in the
499:12 - real live video so this is how you can
499:16 - use har based Cascade classifiers to
499:19 - detect faces or any other object inside
499:22 - an image in the last video we have seen
499:26 - the basics of face detection using har
499:29 - feature based Cascade classifiers
499:32 - in this video we are going to extend our
499:34 - code to detect eyes using the same har
499:38 - Cascade classifier
499:40 - so for that first of all you need to
499:43 - download the pre-trained cross
499:46 - classifier for the eyes from the same
499:49 - source which I have shown you last time
499:51 - also which is the GitHub repository of
499:54 - opencv again I'm going to give you this
499:59 - link in the description so you can
500:00 - directly come to this page and this time
500:03 - we are going to download this XML file
500:07 - with the name Har Cascade I underscore
500:11 - tree underscore I glass dot XML file
500:15 - so this is the pre-trained classifier
500:18 - for detecting eyes so you can just click
500:22 - on draw and then save it as
500:26 - this same file name in your project okay
500:30 - so I have already downloaded this XML
500:34 - file you can see here our Cascade I
500:37 - underscore tree underscore eyeglass dot
500:39 - XML file and now we are ready to write
500:42 - our code so this is the code which we
500:45 - have written last time so if you don't
500:47 - know how this code works you can see the
500:50 - last video I'm going to just extend this
500:53 - code to detect eyes so first thing first
500:56 - we need to create the Cascade classifier
501:01 - for the eyes so instead of phase Cascade
501:05 - we are going to name it as I
501:09 - Cascade and this file name will be the
501:13 - file which we have downloaded which is I
501:16 - underscore tree underscore
501:18 - iglass.xml file so once we have our
501:21 - classifier then in the last video we
501:24 - have already seen how to detect faces so
501:27 - our region of interest will be the phase
501:30 - this time because the eyes will not be
501:34 - present outside the phase right so eyes
501:37 - will always be present inside the face
501:39 - so our region of interest will be the
501:42 - phase and phase we have already detected
501:45 - last time so this phase will be now our
501:50 - region of Interest so go inside this for
501:53 - Loop where we are iterating over this
501:56 - phase variable and then we are going to
502:00 - create our Roi so I am going to create
502:02 - this variable which is called Roi
502:04 - underscore
502:06 - gray and this will be the original
502:11 - grayscale ah image which we have created
502:15 - here but we just want the face out of
502:18 - this image so we can just index the
502:22 - space using Y colon Y plus h comma X
502:27 - colon X plus W which is the width so
502:31 - this line is going to give us the gray
502:34 - scale region of interest but we also
502:37 - want the colored image also so we are
502:40 - going to just say Roi color which will
502:43 - be the colored Roi and here instead of
502:48 - gray we are going to take the direct
502:51 - image which will be before we have
502:54 - converted this BGR image to the
502:57 - grayscale image so we have the colored
503:00 - Roi and the grayscale ROI once we have
503:03 - this we will follow the same ah concept
503:07 - which we have applied for detecting the
503:09 - faces so so we are going to use this
503:12 - detect multi-scale method so I am going
503:15 - to just write eyes
503:18 - is equal to because we already have our
503:21 - I Cascade which is a classifier so we
503:24 - are going to use this variable and then
503:27 - use this method called detect multiscale
503:30 - and then we are going to Simply ah pass
503:33 - our Roi gray which we got using the
503:38 - faces now we are going to iterate over
503:41 - those eyes so inside this for Loop we
503:45 - are going to create one more for Loop to
503:47 - iterate over all the eyes
503:49 - which are found on the face so far and
503:53 - then this will be e x comma e y comma e
503:59 - w comma e h for x y coordinate and the
504:04 - width and height now we will just say in
504:07 - I's and then we are going to just draw
504:11 - this rectangle which is also very simple
504:13 - CB2 dot rectangle and then we are going
504:18 - to pass our image first of all which
504:21 - will be our colored Roi image which is
504:24 - this one so here we will pass this Roi
504:28 - color and then the first point in the
504:32 - rectangle which will be ah e x and e y
504:36 - so I am going to just say e x comma e y
504:39 - and the second point will be
504:43 - E X Plus e w which is X Plus width so we
504:48 - are going to just write this E X Plus e
504:51 - w comma e y plus e h which is the y
504:56 - coordinate and the height
504:59 - the next parameter will be the color so
505:02 - let's provide the color let us say this
505:04 - will be 0 comma 255 comma 0 and then the
505:09 - next parameter will be the width so let
505:12 - us say the width we want here
505:14 - is five so that's it so hopefully this
505:17 - code is going to work out of the box we
505:19 - don't need to do anything else we just
505:22 - need to Define our classifier and then
505:26 - we just need to uh use this detect
505:29 - multi-scale method to detect the eyes
505:32 - and then we just need to draw the
505:35 - rectangle on all the eyes which are
505:37 - detected so let's run this code and
505:39 - let's see what happens so we are going
505:41 - to see you can see eyes are detected but
505:43 - there is some problem because
505:46 - something is wrong so I'm going to just
505:49 - quit this script and see what's going
505:53 - wrong here so you can see this should be
505:56 - x e x comma e y and then our problem
506:01 - will be solved hopefully so I'm going to
506:03 - run this code once again and you can see
506:05 - the eyes are properly detected so this
506:08 - is how you can detect eyes in the face
506:11 - using opencv and Har Cascade classifiers
506:16 - in this video we are going to try to
506:18 - understand how we can find out the
506:20 - corners inside an image using a method
506:24 - called Harris Corner detection
506:27 - now first of all what are corners so
506:30 - Corners are the region in the image with
506:33 - large variation in intensity in all the
506:37 - direction
506:38 - now this Harris Corner detector was
506:40 - first introduced by Chris Harris and
506:44 - Mike Stephens in their paper in 1988.
506:49 - now detecting Corners using Harris
506:52 - Corner detector contains three main
506:55 - steps
506:57 - so the first step is to determine which
507:00 - Windows produces very large variation in
507:04 - intensity when we move in the X
507:08 - Direction and the y direction now what
507:11 - are windows here so windows in this case
507:15 - means that let us say we want to just
507:18 - find out this corner here so windows
507:21 - will be your small box here and then you
507:27 - check for the intensity when you move in
507:31 - the vertical Direction and also in the
507:36 - horizontal Direction so you check for
507:39 - the change or large variation in the
507:43 - intensity when you move in the X
507:45 - Direction and when you move in the y
507:48 - direction in the second step with each
507:51 - such window which we found a score R is
507:55 - computed so this r value which is
507:59 - computed is going to give us the
508:02 - estimate or give us an idea about where
508:05 - this corner is located depending upon
508:09 - the value of R and in the third step
508:12 - after applying a threshold to this score
508:16 - the important Corners are selected and
508:19 - marked so let me explain you all these
508:23 - steps one by one what do I mean by
508:27 - detecting the windows and calculating
508:30 - the value of R's let's see step by step
508:34 - so as I said in the first step we
508:36 - determine which Windows produces very
508:40 - large variation in the intensity in the
508:44 - X Direction and in the y direction so
508:47 - let us say a window or a center is
508:50 - located at the position X comma Y and
508:54 - let's say the intensity of the pixel at
508:57 - this location is i x comma y
509:01 - so if this window is slightly shifted to
509:06 - a new location and let us say this
509:08 - displacement is U comma V then the
509:12 - intensity of the pixel at this location
509:15 - will be X Plus U and Y plus b because
509:21 - our displacement is U comma V so we are
509:25 - just adding it to the x value and the Y
509:28 - value and hence the difference between
509:32 - the shifted intensity and the original
509:36 - intensity will be the difference in the
509:39 - intensities of the windows shift so for
509:44 - a corner this difference will be very
509:47 - large and that's how we detect the
509:51 - corners using this Harris Corner
509:55 - detection method now as you can see here
509:59 - this value will be
510:02 - given in the e u comma V format so we
510:07 - have to maximize this function for the
510:10 - corner detection and this we can achieve
510:13 - by applying a Taylor expansion to this
510:18 - equation which is given here and by
510:21 - using some mathematical steps
510:23 - so I'm not going to go deep into the
510:27 - mathematical steps but after applying
510:29 - the Taylor expansion you will get this
510:33 - kind of approximate value where m is
510:37 - equal to this value and here in this
510:41 - equation i x and I Y are the image
510:44 - derivatives in the X and Y Direction
510:48 - respectively so this can be easily found
510:52 - out using the CV dot Sobel method in
510:58 - opencv
510:59 - now comes the second step and in this
511:03 - step we find out or calculate the score
511:06 - for r
511:08 - so this R is equal to this value and the
511:12 - M we have already ah seen how we can get
511:16 - this m value in the first step right so
511:21 - in this equation d e t m is equal to
511:25 - Lambda 1
511:27 - multiplied by Lambda 2 and Trace m is
511:32 - equal to Lambda 1 plus Lambda 2 where
511:35 - Lambda 1 and Lambda 2 are the eigen
511:38 - values of M so again if you want to go
511:41 - into the details you can refer to some
511:44 - book or you can go to the Wikipedia page
511:48 - to learn more about this equation so
511:51 - once we got the value of R then based
511:55 - upon the value of R we can make some
511:58 - decision and this we can do in the third
512:02 - step
512:03 - so if the value of R is very small that
512:07 - means the value of Lambda 1 and Lambda 2
512:12 - are also very small and we can conclude
512:16 - that the region is a flat region and not
512:19 - the corner
512:21 - if the value of R is less than 0 that
512:24 - means Lambda 1 is very large in
512:28 - comparison to Lambda 2 or vice versa and
512:31 - that means it's an edge and not the
512:34 - corner
512:35 - and if the value of R is large which
512:40 - happens when Lambda 1 and Lambda 2 are
512:43 - large and this means that this region is
512:47 - a corner so if the value of R is very
512:51 - large that means the region is a corner
512:55 - and that's how Harris Corner detector
512:57 - detects if it's a corner or a edge or a
513:01 - flat area so this was the theory about
513:05 - Harris Corner detector let's see how we
513:08 - can use this Harris Corner detection
513:10 - concept inside opencv using our python
513:16 - code
513:17 - so I have this script already written
513:21 - here so just import CV2 and numpy and
513:24 - then we are reading this image called
513:27 - cross board underscore image.png using
513:30 - I'm read method and after we read this
513:35 - image I am just showing the original
513:36 - image so we have the original image and
513:40 - the output at the end to compare
513:43 - now in the next step I am converting
513:46 - this image into a grayscale image to get
513:49 - the better results and because this CV2
513:54 - dot Corner Harris method takes the
513:59 - grayscale image in the float 32 format
514:04 - that's why we need to convert our image
514:07 - into float 32 format so that's why we
514:12 - are using numpy dot float32 to convert
514:15 - this image into a floating Point values
514:19 - because our Corner Harris method which
514:22 - we are going to use in the next step is
514:25 - going to take this kind of value and not
514:28 - the value which comes directly from the
514:32 - conversion of this image to the
514:35 - grayscale image so this step is
514:37 - necessary for the Harris Corner method
514:42 - and in the next ah step we are just
514:44 - applying the CV2 dot Corner Harris
514:47 - method which takes few arguments first
514:51 - is our image in the floating point so
514:55 - this we have passed and the second
514:58 - parameter here is called the block size
515:01 - so here I have given the value 2 here so
515:05 - block size means the window in the first
515:09 - step so we have seen we have to define
515:12 - the window right so for example we
515:15 - Define this block size 2 that means
515:18 - neighborhood size is equal to 2 that
515:21 - means for each pixel value block size
515:24 - multiplied by block size that means two
515:26 - by two neighborhood is considered
515:30 - the next parameter here is called the K
515:33 - size and it's the aperture parameter for
515:36 - the Sobel operation and then we have the
515:40 - next parameter here and this next
515:43 - parameter is called the K which is the
515:47 - Harris detector free parameter in the
515:51 - equation
515:52 - so after applying this Harris card
515:55 - method to our image we get this
515:59 - destination image and to get the better
516:03 - result we need to dilate this result so
516:07 - we apply CV2 dot dialect method on our
516:12 - image which we get using the Harris
516:15 - corner so this image are marked through
516:19 - the dilated corners and then in the next
516:22 - step we are reverting back to the
516:24 - original image with optimal threshold
516:27 - value and we are just just marking all
516:33 - our Corners with this color so basically
516:37 - we want to mark all the corners with the
516:39 - red color here and in the next step we
516:43 - are just showing our result in the I am
516:47 - show window and at last we are
516:50 - destroying all the windows so let's run
516:52 - this code and let's see what happens
516:54 - when we run this code
516:56 - and we will see the results so you can
517:00 - see this is the original image which
517:02 - have so many corners and all the corners
517:07 - are detected and it's marked with this
517:13 - red color here so this is how you can
517:16 - find out and Mark all the corners using
517:19 - Harris Corner detection in opencv in the
517:23 - last video we have seen how we can use
517:25 - Harris Corner detector in order to find
517:29 - out the corners inside an image in this
517:32 - video I am going to show you how you can
517:35 - use sheet tomasi Corner detector method
517:38 - to detect the corners inside an image
517:42 - so in late
517:44 - 1994 JC and C tomasi made a small
517:49 - modification in the Harris Corner
517:52 - detector method in their paper which was
517:55 - called good features to track so this C
517:59 - tomasi method is similar to Harris
518:01 - Corner detector apart from the way the
518:04 - score of R is calculated which we have
518:07 - seen in the last video
518:10 - so this C tomasi method gives us better
518:14 - result in comparison to Harris Corner
518:17 - detector and also when you use this C
518:21 - tomasi method we can find the top and
518:24 - Corners which means we can provide the
518:28 - number of Corners we want and this might
518:32 - be useful in cases where we don't want
518:35 - to detect all the corners inside an
518:38 - image so let's see in the code how we
518:42 - can implement this C tomasi Corner
518:45 - detector in opencv
518:47 - so here I have already written all the
518:50 - code so let me explain you all the lines
518:53 - of the code one by one
518:55 - so as you can see here I'm just
518:57 - importing the libraries in the first two
519:00 - line and in the next line I am just
519:03 - reading the image using I am read method
519:07 - and then I'm converting this image into
519:10 - a grayscale image using this CBT color
519:14 - method so I'm converting this image from
519:18 - BGR to grayscale image
519:21 - now as I said the paper which was
519:24 - published by She and tomasi was named
519:28 - good features to track that's why in
519:32 - opencv this method is also called good
519:36 - features to track
519:38 - so here in this line we are just using
519:42 - this method CV dot good features to
519:45 - track which takes few arguments so first
519:49 - argument here is our input image which
519:52 - is a grayscale image which we are
519:54 - providing as the first parameter the
519:57 - second parameter is the maximum number
520:00 - of Corners so here we can limit the
520:03 - number of Corners we want to detect so
520:06 - for example I have given 25 here that
520:09 - means we just want to detect 25 corners
520:13 - and if there are more than 25 Corners
520:18 - which are present in the image they will
520:21 - not be shown so this value means maximum
520:25 - number of Corners to return and if there
520:28 - are more corners then the corners found
520:32 - then the strongest Corners will be
520:36 - returned right now the third parameter
520:40 - here is called the quality level so this
520:45 - is the parameter characterizing the
520:48 - minimal expected quality of the image
520:51 - Corner the next parameter here is the
520:55 - Min distance which is the minimum
520:57 - possible euclidean distance between the
521:01 - returned Corners so I have taken ah 10
521:05 - here as the minimum distance and 0.01 as
521:10 - the quality level now once all the
521:14 - corners are detected using this good
521:17 - features to track method we convert
521:20 - those Corners into the integer values
521:25 - and here int 0 is a mere Alias for INT
521:31 - 64 and once all the corners are detected
521:35 - we iterate over all the corners and then
521:39 - we find out the value of X and Y using
521:43 - this I and then it's easier to just draw
521:48 - the circles over these values using the
521:53 - CV dot Circle method so this CV dot
521:57 - Circle method takes few arguments first
522:00 - is the input image so the second
522:01 - parameter is the center the third
522:03 - parameter is the radius of the circle
522:06 - which we want to provide the fourth
522:09 - parameter is the color we want to
522:11 - provide and the fifth parameter is the
522:15 - thickness and if it's minus one that
522:17 - means we want to fill the color inside
522:21 - that Circle and at last once all the
522:25 - circles are drawn on the corner which
522:28 - are detected then we are just showing
522:31 - this using I am show method so let's see
522:35 - how this works in the case of
522:39 - method on an image so I am going to run
522:42 - this code so you can see all the corners
522:46 - inside this image are detected and
522:50 - because we have just provided this
522:52 - number 25 here so maximum number of
522:55 - Corners which will be detected here will
522:58 - be 25 and rest of them will not be shown
523:03 - so if we increase the value of the
523:06 - maximum number of Corners let's increase
523:09 - it to 100 let us say so I am going to
523:12 - just increase it to the value 100 you
523:15 - will see more number of circles are
523:19 - drawn on an image now let us compare the
523:22 - result of the Harris Corner detector and
523:26 - C tomasi Corner detector so on the left
523:29 - hand side you can see the original image
523:32 - and this middle image shows the Harris
523:35 - Corner detector method and you can see
523:39 - all the corners are detected using
523:41 - Harris Corner detector and using the
523:45 - sheet omasi Corner detector it gives us
523:48 - better result and we can control the
523:50 - number of Corners we want to detect and
523:54 - you can see all the important Corners
523:56 - are detected using Chi tomasi Corner
524:00 - detector in a better way so that's how
524:04 - she tomasi Corner detector Works in this
524:08 - video we are going to see how to use
524:10 - background subtraction method in opencv
524:14 - so first of all what is background
524:16 - subtraction
524:17 - so background subtraction is common and
524:21 - widely used technique for generating the
524:24 - foreground mask which is also known as
524:28 - the binary image containing the pixels
524:31 - belonging to the moving object of a
524:34 - scene when these images are captured
524:39 - using a static camera and as the name
524:42 - suggests background subtraction
524:44 - calculates the foreground mask
524:47 - performing the subtraction between the
524:50 - current frame and the background model
524:53 - containing the static part of the scene
524:57 - so for example the background
524:59 - subtraction method can be used in the
525:02 - case of visitor counter where you have a
525:06 - static camera capturing the number of
525:08 - visitors entering or leaving the room or
525:13 - you have a traffic camera which wants to
525:16 - count the the various telematic data
525:21 - from the moving car or moving car data
525:25 - which is captured by that traffic camera
525:29 - now there are several algorithms which
525:32 - were introduced for the purpose of this
525:35 - background subtraction and opencv has
525:38 - implemented few of them which we are
525:40 - going to see one by one so as you can
525:44 - see here I have this example which is a
525:48 - very simple example of just taking a
525:52 - video and then we are extracting each
525:55 - and every frame of that video and
525:58 - showing it into a window so using I am
526:02 - show method I'm just showing each and
526:04 - every frame of that video so this you
526:08 - already know from the previous videos
526:11 - how to capture the video frames from a
526:16 - video file or the live camera so when I
526:20 - run this code you will see that there
526:22 - are few persons which are moving here
526:25 - and we want to detect all those moving
526:31 - persons which are moving in the image so
526:35 - for that we are going to use a few
526:38 - methods which are available in opencv so
526:42 - let's first write some code and I will
526:45 - explain you what this code is going to
526:47 - do so I'm going to Define a variable
526:51 - after
526:53 - this line of code and I'm going to
526:56 - Define a variable name f g BG for
527:00 - foreground background and then I'm going
527:03 - to just call CV dot BG s e g m so b g s
527:11 - e g m and then I'm going to call a
527:15 - method called create background
527:16 - subtraction
527:17 - MOG method so this create background
527:21 - subtraction Emoji method is a gaussian
527:24 - mixture based background and foreground
527:27 - segmentation algorithm so using this
527:30 - line what we are doing is we are just
527:33 - creating a background object of the
527:35 - function using this method create
527:38 - background subtraction emoji now ah this
527:43 - method has some optional parameters like
527:47 - history number of gaussian mixtures and
527:51 - threshold but all of them are set by
527:55 - default so you don't need to set
527:58 - anything specifically unless you want to
528:01 - change some of the optional parameters
528:03 - so I'm going to leave everything as
528:05 - default and I'm not going to give any
528:08 - argument here for this method and then
528:11 - after I captured each and every frame
528:15 - inside this while loop what I'm going to
528:18 - do is I'm going to create a new variable
528:20 - called fgmask for foreground mask so I'm
528:24 - going to just write FG mask is equal to
528:28 - and for getting the foreground mask we
528:31 - are going to just call
528:33 - a method called apply on this fgbg or
528:38 - the background subtractor image so we
528:40 - are going to just take
528:42 - fgbg and then we are going to call a
528:46 - method called apply here and it takes
528:49 - one argument which is the frame which we
528:52 - are capturing okay so we have applied
528:56 - this method and then we are just getting
529:01 - the foreground mask using the apply
529:04 - method on this background subtractor
529:07 - variable and that's it so this is your
529:11 - foreground mask so when I just use one
529:15 - more I'm show window and this is for the
529:20 - FG frame let's say so f g uh mask frame
529:24 - let's say okay so FG mask frame and we
529:28 - are going to just pass this argument
529:31 - here so let's see what result we get
529:34 - after we apply create background
529:36 - subtractor MOG method
529:38 - so you can see this normal image here
529:42 - and also you will see uh these are
529:47 - moving persons in the foreground mask
529:50 - right so you have subtracted the
529:53 - background for from the foreground and
529:56 - you can easily detect the moving
530:00 - persons here inside this image using
530:03 - this mask you will also observe that
530:06 - there is a very ah little noise not much
530:10 - ah when you use this kind of subtraction
530:12 - using Create background subtractor MOG
530:17 - method there is one more method which is
530:19 - called background subtractor mog2 which
530:22 - is also gaussian mixture based
530:24 - background for and foreground
530:26 - segmentation algorithm so let's use that
530:29 - method also so this method is directly
530:33 - available under CV2 so you just need to
530:36 - write CV dot create background
530:38 - subtracted a mog2 okay and everything
530:42 - will remain the same so it's going to
530:45 - return you the background subtractor
530:48 - variable which you can use with this
530:51 - apply method to get the foreground a
530:54 - mask okay so let's see how this method
530:58 - performs so you can see the result which
531:01 - is quite different from the first method
531:04 - which we have used so in the previous
531:06 - case we have to create the background
531:09 - subtract object and here in this method
531:13 - you have an option of detecting the
531:16 - Shadows so there is an optional
531:19 - parameter which you can give
531:21 - into this method which is this create
531:25 - background subtractor mog2 which is
531:29 - called detect Shadows so by default this
531:33 - detect Shadows is true that's why you
531:36 - see the Shadows there if you just write
531:40 - the text Shadows is equal to false then
531:43 - it is not going to detect the Shadows so
531:46 - I'm going to just run the code once
531:48 - again and you can see now Shadows are
531:53 - less visible right so let's run the
531:56 - default case once again so let us say we
531:59 - just write true here and you will see
532:03 - the shadows in the gray
532:05 - color right so these shadows in the gray
532:09 - color and when we just make it false so
532:13 - the text Shadows Falls you will not see
532:17 - that gray color okay so Shadows are
532:20 - displayed in the gray color so if you
532:22 - don't see any gray color then Shadows
532:25 - are not detected this is a noise which
532:28 - ah is detected but not the shadow okay
532:32 - so this is the difference between the
532:36 - first background subtractor method and
532:38 - the background subtractor Emoji 2 method
532:41 - there is one more method which is called
532:45 - the background subtractor GMG
532:49 - so this algorithm which we are going to
532:51 - use so let's use this method first of
532:55 - all which is called background
532:57 - subtractor
532:59 - g m g which is available under CV dot BG
533:05 - segment as the first method so just
533:08 - write b g s e g m dot create background
533:13 - subtractor GMG method so this create
533:15 - background subtractor GMG method
533:18 - algorithm combines statistical
533:21 - background image estimation and pre
533:23 - pixel bias in segmentation let's see how
533:28 - this method performs when we just use
533:31 - this GMG method
533:33 - and when you will see here there is
533:36 - nothing on this
533:39 - foreground mask frame so to get the
533:42 - better result you need to apply
533:45 - morphological opening to the result to
533:48 - remove the noises so we are going to do
533:52 - just that so I am going to just override
533:54 - this FG mask frame using a method called
534:00 - CV dot morphology X this also we have
534:05 - seen in the previous videos right so the
534:09 - first
534:11 - parameter here will be FG mask parameter
534:15 - the second parameter here will be the up
534:20 - so CV2 Dot
534:23 - morph open we are going to use the morph
534:26 - open method and then the third parameter
534:29 - will be the kernel so we need to define
534:32 - the kernel also so for defining the
534:35 - kernel let's define the kernel outside
534:37 - this while loop so I am going to just
534:39 - write the
534:41 - kernel which takes few argument first is
534:44 - the shape so we are going to say we want
534:47 - the more Eclipse shape so I'm going to
534:51 - just write
534:52 - morph eclipse and then the kernel size
534:57 - will be let's say 3 comma 3 okay so we
535:00 - are going to apply this kernel using
535:03 - this morphology X
535:05 - method and when we are going to run this
535:09 - code you can see these kind of results
535:12 - which are not as good as you have seen
535:17 - in the first method now let me show you
535:20 - the last background subtraction method
535:22 - which is called the background
535:26 - subtractor k n n method so this method
535:31 - is available under CV2 directly so we
535:35 - are going to just comment this kernel
535:38 - code because for this method we don't
535:40 - need need to Define any kernel so we can
535:44 - just write CV dot create background
535:47 - subtractor and then at last you just
535:49 - need to write K and N in capital okay
535:53 - and it also takes few optional
535:56 - parameters like history and other
535:59 - parameters but these are optional
536:01 - parameters so for now we are not going
536:03 - to set any ah parameter and let's see
536:07 - the result which we get using this k n
536:10 - method so I'm going to run this code and
536:13 - you can see this KNN method result it
536:17 - also shows the shadows in the form of
536:20 - gray pixels so whatever gray pixels you
536:24 - see here in this image are the shadows
536:27 - in this method also there is an optional
536:30 - parameter which is called detect Shadows
536:32 - which is set by default to true so when
536:35 - you make it false the shadows will not
536:38 - be detected so you can see No Gray
536:42 - pixels are visible now when you make it
536:45 - true then the gray pixels will be
536:48 - visible and those gray pixels indicates
536:52 - the Shadows right so these are the few
536:56 - methods which you can use for the
536:58 - background subtraction in opencv in this
537:02 - video we will talk about an object
537:04 - tracking method which is called mean
537:06 - shift
537:08 - so first of all what is object tracking
537:11 - so in simple words object tracking is
537:14 - the process of locating a moving object
537:17 - over time using a camera and what is
537:21 - mean shift the idea behind mean shift is
537:24 - really simple consider you have a set of
537:27 - points it can be a pixel density like
537:30 - histogram bag projection and you are
537:34 - given a window which is a very small
537:37 - window which can be a circle or
537:40 - rectangle or a square and you have to
537:42 - move that window to a area of Maximum
537:45 - pixel density or maximum number of
537:48 - points so in the image you can see this
537:52 - illustration very easily so essentially
537:56 - the working of mean shift algorithm can
537:59 - be summarized in following points so in
538:03 - the first step we pass the initial
538:06 - location of our Target of object and the
538:09 - histogram bag projected image to a mean
538:12 - shift function and then in the Second
538:16 - Step as the object moves the histogram
538:19 - back projected image also changes and in
538:23 - the third step the mean shift function
538:27 - moves the window to the new location
538:30 - with the maximum probability density so
538:34 - we will see all these steps with the
538:36 - help of an example so here I have the
538:40 - simple code where I'm loading a video
538:43 - which is called slow traffic small dot
538:46 - MP4 and I'm just iterating over each and
538:50 - every frame of that video so this code
538:53 - till now you already know how it works
538:56 - so I am going to just run this code
538:59 - and let's say I just want to track this
539:03 - window of the white car okay so let me
539:06 - just run this video once again so I want
539:09 - to track this window of the white car or
539:12 - window in general of each and every car
539:16 - let's say okay so how can I track this
539:19 - window using mean shift algorithm let's
539:24 - see so as I said the first step is the
539:29 - passing of the initial location of our
539:32 - Target so this can be you can say a
539:34 - disadvantage of mean shift that you have
539:38 - to provide the initial location of your
539:41 - Target in our case that Target is the
539:44 - car window so what I have done is I have
539:48 - just calculated the initial position of
539:51 - the white car window and that we are
539:55 - going to see in the next step so first
539:58 - of all we are going to take the first
539:59 - frame of our video so the first frame of
540:03 - our video can be retrieved by this code
540:07 - so ret comma frame is equal to cap we
540:14 - have this cap function and we will read
540:18 - the first frame using the read method
540:20 - and this is going to give you the first
540:23 - frame of the video so this is our first
540:25 - frame now once we have our first frame
540:29 - we are going to Define the initial
540:32 - location of the car window in our case
540:36 - we want to track first of all the white
540:40 - car window right so I'm going to Define
540:42 - four variables first two are X comma Y
540:46 - and the next two are width and height so
540:50 - and because I have already calculated
540:53 - the initial position of the window I am
540:56 - going to hard code this position of the
540:59 - window so 300
541:01 - 200 comma 100 comma 50 okay so this is
541:07 - the hard coded value which I have
541:10 - already calculated which is the initial
541:12 - position of the car window
541:15 - now we can say that this x y and width
541:20 - and height is our track window so we are
541:23 - going to Define a variable called
541:27 - track underscore
541:30 - window let's say and then we are going
541:33 - to just pass all these four variables X
541:35 - comma y comma width comma height okay so
541:41 - let's pass all these four variables and
541:44 - in the next step we are going to Define
541:47 - our region of Interest
541:49 - so let's define this region of Interest
541:53 - with the variable called Roi and we
541:58 - already have our first frame so we are
542:00 - going to take our first frame and then
542:02 - we are going to pass that window so why
542:06 - colon Y plus height
542:10 - comma X
542:13 - colon X Plus width so this is our window
542:18 - or the position of the window
542:20 - so as I said in the first step we will
542:23 - pass the initial location of our Target
542:25 - object and the histogram bag projected
542:29 - image of the mean shift function
542:32 - so histogram bag projection in simple
542:35 - words creates an image of the same size
542:39 - but of a single Channel as of our input
542:44 - image in our case this will be our frame
542:47 - where each pixel corresponds to the
542:50 - probability of that pixel belonging to
542:54 - our object that is the output image will
542:58 - have our object of Interest or region of
543:01 - it in more white color compared to the
543:04 - remaining part of that image so this is
543:09 - back projections so for calculating the
543:12 - histogram back projection there are some
543:14 - steps which are involved so we are going
543:17 - to follow all these steps to calculate
543:21 - the histogram back projection but first
543:23 - of all let's just see the region of
543:28 - interest because we already have a
543:31 - region of Interest so I am going to just
543:32 - right CV dot I am show and our region of
543:37 - Interest so let us say how our region of
543:40 - Interest looks like so I have this video
543:45 - and this image which is our region of
543:49 - Interest right so this is the initial
543:52 - position I'm going to pass to our mean
543:56 - shift function right so now in The Next
544:00 - Step what we are going to do is we are
544:02 - going to
544:04 - define the histogram back projection so
544:07 - we already have our Roi so in the next
544:12 - step we are going to just convert this
544:16 - Roi to the HSV color space so I am going
544:20 - to just write HSV underscore Roi HSB we
544:24 - have already learned in the previous
544:25 - video so I am going not going to go into
544:28 - the details of HSV color space I'm going
544:32 - to just try it CV dot c v t color which
544:39 - is going to convert this
544:42 - image into the HSV color space so our
544:46 - input image will be the ROI and the next
544:51 - parameter will be CV Dot color
544:54 - underscore BGR
544:57 - to HSV
545:00 - okay so we are converting this image to
545:02 - the HSP color space and then we are
545:05 - going to calculate the mask so let's say
545:10 - we Define a variable called mask and for
545:13 - the mask we are going to just write a CV
545:16 - dot in range so this also we have
545:19 - learned in the HSV tutorial so if you
545:24 - want to learn more about all these
545:26 - functions you can just go to that video
545:29 - so first uh parameter we are going to
545:31 - pass is our HSV image and the second
545:36 - parameter and the third parameter will
545:38 - be the lower and the upper bound
545:41 - so the lower limit will be 0 dot comma
545:45 - 60 dot comma 32 dot okay so let's pass
545:51 - this
545:52 - and the upper limit so let's define the
545:55 - upper limit also so the third parameter
545:58 - will be the upper limit in the form of
546:01 - the Tuple but we need to use the numpy
546:04 - for that right so numpy dot array and
546:09 - inside that we just pass this Tuple
546:12 - value which will be 180
546:15 - dot ah
546:18 - 255.2255 okay so 180 dot comma 255 dot
546:23 - comma 255.
546:26 - so why we use the in range function
546:28 - because for the histogram only Hue is
546:32 - considered from HSV right so the first
546:36 - channel right and also to avoid the
546:40 - false value due to low light or low
546:44 - light value we use the in range function
546:49 - okay so these low light values are
546:52 - discarded using the inner range function
546:56 - and then in the next step we are going
546:58 - to calculate our histogram value so I am
547:02 - going to Define this variable called Roi
547:05 - hist
547:06 - also we have learned in the previous
547:09 - video so I am not going to go into the
547:11 - details so I'm going to just use the
547:13 - function called calc hist which takes
547:17 - the first parameter which will be the
547:20 - image so I am going to just pass our HSV
547:24 - Roi so just pass HSB underscore Roi the
547:29 - second value here will be the channels
547:31 - so we are just using only Hue channel
547:35 - the first channel in the HSP space so we
547:38 - are going to just write 0 here ask now
547:41 - the next parameter will be the mass so
547:43 - we have already calculated the mass so
547:45 - we are going to just pass this mask
547:48 - parameter here the next parameter will
547:51 - be the hist size so as we have already
547:53 - learned in the previous videos that this
547:56 - hist size ah starts from 0 to 179 so
548:01 - essentially 180 values and then we just
548:06 - need to pass the ranges so as I said it
548:09 - starts from 0 to 1 and now in the next
548:13 - step we are going to just normalize
548:14 - these values using the normalize
548:18 - function so this normalized function
548:20 - takes few values first is the source so
548:23 - the source is our Roi hist variable
548:27 - the next value is the destination so let
548:31 - us say
548:32 - we have the same destination we just
548:34 - want to overwrite this Roi hist value
548:37 - the next parameter here will be the
548:40 - value of alpha so Alpha will start from
548:43 - 0 and the value of beta will be 255 so
548:48 - we want to normalize these values
548:50 - between 0 to 255 okay and then the next
548:56 - value will be the norm type so the norm
549:00 - type we are going to take is C V Dot Nom
549:06 - min max okay so we are going to just
549:10 - take this one Norm min max so all these
549:15 - steps which we have written here is
549:18 - going to give us the histogram bag
549:20 - projected image now once we have this
549:23 - histogram back projected image we are
549:27 - going to use this histogram bag
549:31 - projected image ah which is also going
549:34 - to change with the moving object so now
549:37 - in the next step we are going to go
549:41 - inside our while loop and read each and
549:45 - every frame one by one and first of all
549:48 - what we are going to do is we are going
549:50 - to calculate the HSV value of the frame
549:54 - as we have done with the first frame
549:57 - also right so we are going to just take
550:02 - the frame and then calculate the HSB Roi
550:07 - value let us say this time we are going
550:10 - to name it as HSB and we are going to
550:13 - pass frame as the source instead of this
550:17 - Roi value
550:18 - now in the next step we are going to use
550:21 - a function called calculate back project
550:24 - so let's define
550:27 - the variable called test for Destination
550:30 - and then CV dot calc back project which
550:35 - is the function for calculating the back
550:38 - projection and this function takes few
550:41 - argument first is the number of images
550:44 - so we only have our HSB image so we are
550:48 - going to pass in the form of the list
550:51 - the second argument will be the channels
550:54 - so as I said we just want to use the Hue
550:58 - values here so only one channel so we
551:00 - are going to just write ah 0 so because
551:03 - Channel starts from 0 1 2 so that's why
551:07 - I have written 0 here the third
551:10 - parameter is the hist value so in this
551:15 - case our hist value is the ROI hist
551:18 - which we have calculated the next
551:21 - parameter is the ranges so we will start
551:25 - from 0 to 180 e as we are talking about
551:30 - the HSV color space and the next value
551:34 - will be the scale so let us say scale
551:37 - for now we take 1 as the scale so this
551:42 - is going to give you the back projected
551:45 - image and then in the next step we are
551:47 - going to apply the mean shift to get the
551:50 - new location so I'm going to just write
551:53 - ret comma
551:55 - track window so I'm going to just say
551:58 - track window which is this variable
552:02 - which we have already ah defined and
552:05 - then we are going to just use CV dot
552:10 - mean shift which is going to take few
552:14 - arguments first is the image which is
552:18 - the destination image which we got from
552:21 - the back project function calc back
552:24 - project
552:25 - and next argument will be our Track
552:30 - image which is the track window so we
552:33 - have to Define this term criteria so I
552:36 - am going to just write
552:38 - term
552:40 - crit for criteria
552:43 - and then we have to Define this outside
552:46 - this while loop so I am going to go here
552:50 - and we are going to set up the
552:53 - termination criteria either 10
552:56 - iterations or move by at least one point
553:00 - okay so we are going to Define that
553:04 - criteria so here in
553:07 - the curly brackets we are going to just
553:10 - say CV dot term criteria ESP or CV dot
553:18 - term criteria count so because we want
553:22 - to either provide the termination
553:25 - criteria for either 10 iterations so we
553:28 - just give 10 or we want to terminate by
553:33 - moving at least one point this is the
553:37 - criteria for the mean shift and we are
553:41 - providing these two track criteria so
553:43 - once we have our track window for the
553:46 - car we can draw a rectangle with the
553:50 - help of this track window and this will
553:52 - be visible on our video so we are going
553:57 - to draw that window we are going to just
554:01 - say x comma y
554:03 - comma W comma H for X Y width and height
554:10 - and this will be our track window and
554:14 - then we are going to just draw a
554:16 - rectangle so I am going to just say we
554:19 - have the final
554:22 - image and then we are going to just
554:25 - write C V Dot
554:28 - rectangle which is going to take the
554:31 - frame and then the point for the first
554:36 - point of the rectangle and the second
554:39 - point of the rectangle which are the
554:41 - coordinates of that point so the first
554:43 - point coordinates will be X comma Y and
554:48 - the second Point coordinate will be X
554:51 - Plus width comma y plus height okay and
554:58 - then the next value will be the color
555:00 - let us say we want to use 255 here and
555:05 - the thickness so thickness we want to
555:08 - take three here for example
555:11 - now we can just show this final image
555:16 - using I am show method so till now we've
555:19 - just uh showing our original frame so we
555:23 - can just say
555:25 - let's say we want to show the final
555:27 - image here also if you want to see
555:32 - the back projected image you can just
555:35 - use
555:37 - this destination so we can print this
555:40 - destination
555:41 - image also and see how does this back
555:44 - projected image looks like so let's run
555:48 - this code and you can see this car
555:51 - window is dragged right so as the car
555:54 - moves this window also moves once this
555:58 - car goes out of the scope it tracks the
556:01 - other window so this is how the mean
556:04 - shift algorithm Works in opencv now as I
556:09 - said this mean shift has few
556:13 - disadvantages or limitations the first
556:16 - limitation is the size of the target
556:20 - window does not change so as we have
556:23 - seen once this car is coming near to us
556:28 - the size of this window is not changing
556:31 - it remains always same so this is one
556:35 - problem the second problem is we have to
556:38 - give the initial position of our region
556:42 - of Interest so for example if initial
556:45 - position of the region of interest is
556:47 - not known then it will be really hard to
556:51 - apply main shift method so there are
556:53 - these two main limitations of this mean
556:58 - shift algorithm and we are going to try
557:00 - to solve these limitations in the next
557:03 - video when we learn cam shift which
557:06 - stands for continuously adaptive mean
557:09 - shift
557:10 - in the last video we have learned how to
557:12 - use mean shift algorithm to find and
557:15 - track objects in the video in this video
557:18 - we are going to learn camshaft algorithm
557:21 - to track the object in the video
557:24 - so if you have seen the last video we
557:27 - have written this code so we are going
557:29 - to use all this code which we have
557:32 - written in the main shift video tutorial
557:35 - and first of all let me just run this
557:39 - mean shift code which we have written in
557:41 - the last video and we have discussed
557:43 - about this problem of this rectangle
557:46 - which always Remains the Same even if
557:49 - the object is coming closer to the
557:52 - camera so we need to adopt the window
557:55 - size with the size and rotation of the
557:58 - target so once again the solution came
558:01 - from opencv labs and this time they
558:04 - introduced an algorithm which is called
558:07 - cam shift which stands for continuously
558:10 - adaptive mean shift so this camshaft
558:13 - algorithm applies mean shift per first
558:16 - and then once the mean shift converges
558:19 - it updates the size of the window in
558:22 - addition it also calculates the
558:24 - orientation of the best fitting Eclipse
558:27 - to it now let's talk about the
558:29 - implementation part of the cam shift so
558:32 - as I said all the code which we have
558:34 - written in the last video will remain
558:36 - the same except one thing which is we
558:39 - have used this main shift algorithm in
558:42 - the last video and in this video we are
558:45 - going to use the cam shift shift so just
558:48 - write CV Dot cam shift and all the
558:52 - parameters also will remain the same
558:55 - which is destination track window and
558:58 - the termination criteria so let's run
559:01 - this code once again and let's see what
559:04 - result came out of this algorithm so you
559:07 - can see this rectangle is changing its
559:10 - size according to the Target now this
559:13 - result which we have seen can be better
559:15 - because the camshaft function returns a
559:19 - rotated rectangle that is our result and
559:23 - also the Box parameters which are used
559:26 - to be passed as the search window in the
559:29 - next iteration so here when we see the
559:34 - result inside the ret variable so let us
559:37 - print the result inside the ret variable
559:40 - I am going to just print it using the
559:43 - print function now let's run this code
559:46 - and let's see what this ret variable
559:49 - prints on the terminal so let me just
559:52 - press Escape so what is this result so
559:56 - here you will see the value of x and y
559:58 - and also you will see these three values
560:01 - which are your width height and the
560:04 - value of rotation so in cam shift you
560:08 - can also rotate your rectangle according
560:11 - to your object size so now we are going
560:16 - to use all these parameters which are
560:19 - there inside this ret variable and we
560:22 - are going to try to draw the rectangle
560:25 - which might be ah rotating so there will
560:29 - be a different approach other than this
560:32 - rectangle we are going to use that
560:35 - approach to print those points which we
560:39 - got using the ret variable so let us
560:42 - draw that rectangle so here we are going
560:46 - to Define a variable called pts and
560:49 - there is is a function called CV dot box
560:53 - points so we are going to use that
560:58 - function here which is box points and it
561:02 - takes a few arguments we just need to uh
561:06 - pass our ret variable here so we are
561:09 - going to just pass our ret so let us see
561:12 - what values this is going to give us so
561:15 - I am going to just print this pts value
561:18 - so I am going to just print the value of
561:20 - pts now let's run this code once again
561:24 - you won't see anything
561:27 - and you will see these values right so
561:31 - it is going to give these floating Point
561:34 - values which we need to convert it into
561:37 - the integers and the error was due to
561:41 - this because this is no longer defined
561:43 - right so for that we are going to just
561:46 - convert these points pts into the
561:51 - integer value so I am going to overwrite
561:53 - this variable pts and then there is a
561:56 - function in numpy which is called int 0
562:00 - and here when you pass this pts variable
562:05 - it is going to convert those Point into
562:07 - the integers and now we can just draw a
562:11 - rectangle but remember this is a
562:13 - rotating rectangle so we cannot use this
562:16 - normal rectangle function so we need to
562:18 - use the other function for drawing those
562:22 - points so I am going to Define this
562:24 - final image variable once again and then
562:27 - then I'm going to use CV dot poly lines
562:30 - so there is this function called poly
562:33 - lines which can you can use to draw
562:35 - those lines which you get using this
562:38 - points variable so we are going to just
562:40 - pass the frame first of all so we need
562:44 - to pass the frame as a first parameter
562:46 - the second parameter will be our pts
562:49 - value and then the third parameter will
562:54 - be the closed or not closed so when we
562:58 - pass true here then this rectangle will
563:03 - be closed right then we need to pass the
563:06 - color so you can pass any color here let
563:09 - us say it 0 comma 255 comma 0
563:12 - and then you can also pass the thickness
563:16 - so let's say we just need to give the
563:20 - thickness of 2 here okay so this is our
563:24 - final image and now we are going to run
563:27 - this example once again and let's see
563:30 - what happens so you can see this
563:33 - rectangle is drawn and it can rotate
563:36 - also with the object so this is how
563:39 - camshaft algorithm works with opencb I
563:43 - hope you've enjoyed this video and I
563:45 - will see you in the next video