a the good boy morning everyone uh well it might not be morning to where you are but it is for me I know the music might be a little bit loud right now uh I will adjust that balance in a moment uh but um let me know if you can hear me okay I'll be getting started in just a minute uh you might hear more of an echo than usual because um the audio filtering that I typically use is not on right now all right just let me know if the this my quick audio check I'll be starting in about a minute and yeah n n a hello everyone let's see here here we go uh let's turn this down just a tiny bit uh welcome everyone to a Monday morning coding train live stream probably not the most optimal time for me to have a live session but it's the time that works for me uh and so here I am I'm attempting to get another uh screen over here with the chat that I might be able to take a look at it but right now I can see the chat over here and I see people um greeting me from San Antonio Texas and chil rainy England it is chilly Sunny New York right now all right so I'm going to try to get right into it today today there's not going to be a lot of the usual coding train uh wasting of time because I have an agenda so let's Jump Right In uh I'm G to open up my web browser here um and see if I can get to this particular page bear with me for a moment and oh the other thing I'm going to do is I'm gonna hit start I'm recording this to dis uh on the off chance I want to try to do something more with it so we'll see unlikely this will just be available as an archive of a live stream but just in case all right so I um first of all hello welcome my name is Dan schiffman you watching the coding drain this is a YouTube channel where I try to do a wide range of things uh but mostly focusing on Creative coding making art with code graphics and animation with code for the beginner and um try uh yeah that's I think that's a good summation of what it is this channel is I also uh this extra screen thing is not going to work for me I don't think well maybe I'll worry about that later um I also happen to have this uh fulltime job which keeps me very busy uh teaching at a program called ITP uh and IMA at TI the Arts New York University and this semester I happen to be teaching a class called programming from A to Z now I think apologies for all this uh e you know what's the word for when I'm taking a really long time to set something up I don't remember yes so U let let me address something quickly in the chat AZ ad says no Pops in the mic today so I did some debugging over the weekend about what was causing the pops in the mic and strangely enough I cannot believe this uh it was Nvidia broadcast the software I use that runs the audio through the graphics card and has various features for audio processing and so this room that I'm in this garage is actually quite large if I'm being perfectly honest for a recording there more space than I need and it is not sound treated and it is very empty and it is very echoey so I've just been using the Reverb uh the echo reduction that's in in video broadcast it works so well that I never bothered to uh sound treat the room but so uh you might be hearing a little bit more of an echo today which is also why I'm recording this to disk in theory if I wanted to uh edit this down to a shorter video tutorial um I could do some audio processing and post all right I did not ask for that I don't know if you could you hear that through the mic this is this uh old uh iPad I found that I was like let me set up to have another screen where I could look at the chat because right now although I see there's one message there oh and Simon got their stickers in the mail that's amazing ah it just says enjoy the Stream So I've got um uh a slight and like what's going on over here this is the yeah this is a little bookshelf here it's kind of like cut off there I'm just not going to worry about all there's a lot of flaws today in my setup we're just gonna move along all right so uh let's see programming with text no yeah introduction yeah let's see if this will get me somewhere UHD is okay okay okay okay you're really gonna show me an ad right now thank you very much okay um so this is a particular um this course that I've been teaching at NYU for quite a long time with this as evidenced by this very old thumbnail design that really should be updated um is about different algorithms that you can use to uh analyze and generate text so I look at things like just how do in JavaScript how do you work with the JavaScript string object loading text from a file looking at regular Expressions uh some word counting stuff some text analysis stuff some node stuff some database stuff some speech stuff oh I used to do Chrome extension in this class so this is kind of what the class was was uh six years ago and the current syllabus uh for the class is here and you can kind of see um all of the weeks right now so um a lot of the video a lot of the uh weeks one through four those old videos pretty much still apply weeks five and six uh I have some um I recently recorded and if you go to the coding train Channel right now you would see and just click on videos the most recent videos that came out were um what what I see on my laptop is what you see over here uh most recent videos that came out are oh okay I need to do this um were for uh working on Bots then I've got some videos on Markov chains and context fre grammar that are coding challenges but the material that has been entirely new this semester I don't know if you noticed it actually just had its oneye uh birthday I believe but uh the world of language models and ways that people interact with textbased interfaces in our daily life now has just changed in extraordinary ways uh that is very complicated and I have lots of complicated feelings about that um so regardless of my own uh confusion and wondering about how I might may or may not want to include some of these new tools and Technologies in my own kinds of work and educational materials I do see it as part of my and riser you asks what is clustering sense edings I'm getting there I do see it as um part of my mission uh n mission's too strong of a word but I at least interested in doing some teach ing around how to explore and um learn about more about language models and in particular I'm very interested in this topic of using embeddings for search and retrieval and other kinds of analysis of data so uh protham says are you checking the YouTube chat or the Discord chat by the fact that I'm reading your message here I would say the YouTube chat I have a slight eye over there in the corner of any like I'll see one message in the Discord chat so any urgent things that need to flag my attention put them there um and uh not a sponsor but this is a um Danielle is mentioning my thermos and it's I really love it it's uh I mean I welcome a sponsorship from a fellow I think it's called fellow I own so many of these yeah it says it on the inside and I have some uh very hot coffee in there that was much too hot okay so um the what I've been having a hard time um figuring out how to find the balance between all the different things I'm working on so coding train it's not like on Hiatus but it's a little bit hit or miss these days so I always like to say at the top thank you for those of you who are engaging and supporting the work that I'm doing even when I'm producing much less as usual most of that uh you I'm not going to go too far into this is because of my obsessive work on this nature of code book uh which will be coming out in the summer but you can read it all online lots more to come about that come 2024 um but uh one of the things uh that happened was actually kind of funny because there was a fire drill I was in the middle of talking about uh embeddings uh and and I don't worry I'll get to what that is as best I can uh and I didn't get to finish some stuff that I wanted to do in class um and I have a bunch of examples here um around working with uh Transformers Js where's this going to go by the way um around uh this thing called umap um so I thought I would come and do a live session around it because I can uh because I I'd like to share this with my students who are in the class but also uh share it with all of you uh any of which might be a student in my class but unlikely they're very busy they don't want to watch me on YouTube so tired of me I would assume by this point um I am in my garage in my home so the other reason why I've been a little slow to do stuff uh just a little behind the scenes here uh is that I set up this whole recording studio that's a little bit strong I set up some equipment in my garage and this semester my teaching schedule is much busier than usual so when I used to record videos at NYU I was just there all the time when I was teaching recording whatever now I've kind of separated that a little bit which I think is a good thing in the long run um but I'm actually at NYU like these last couple weeks of the semester Tuesday through Friday so today is my only day working from home and I have uh uh I mean honestly I have a lot to do I probably shouldn't be doing this right now but at least this is for my class so I I it makes sense got to keep this muscle can't like totally lose the live streaming muscle and um yeah so as long as I get out of here by like noon 1230 at the absolute latest I'll be able to do all my other meetings and office hours and different things this afternoon go in for the rest of my work week and yeah but really here I what I'm excited about so even though so just to set the stage a little bit um so many wonderful questions in the chat I'm sorry I'm not really going to be able to answer them this is this is not intended this is a w I would call this a wintry hoodie sweater hoodie uh it's not intented to be a hoodie related to a very specific holiday that happens around this time of year that I do not celebrate even though my family insists on somehow kind of partially at least mostly celebrating oh they'll get you there those those rascally kids um it's winry themed it's very it's it's actually it's pretty good it's not that cold here in the garage I was running the heater all morning and I turned it off now for sound and it's sunny so I'm getting some sun in here um all right so uh yeah so here's the thing um I think I can just open up this example um and I'm going to log in as the coding train I'm gonna just show you the very end of this I'm going to build the whole thing during this stream let me show you what's coming at the end it'll be slightly different because maybe I want to use a different data set it's it in here no that's not it wait where is it oh I know it is I messed up I overwrote another example and maybe I should fix that uh H hold on it's actually linked in a very weird place which would be here yeah this is it's like I messed some things up but oh no wait this is the right one oh no this is what the slide oh my God I what what everything is wrong okay it's okay I'm gonna find it I know how to find I this is by the way what actually happens in my class I you I feel like I'm so prepared then I can't I messed up a link and I can't find the right thing then nothing works it's very hard it's very hard no no no don't go here okay don't worry I'm gonna get you this example I know exactly where it is it's it's right here okay let's run this I'm going to do share I'm gonna go to full all right I'm sorry for the very flast fast flickering here I'm not doing anything fancy to animate this in any way uh frogo I am streaming from New York State uh that is about I guess the amount of information that I'm going to give here so what you have just witnessed is and I'll have to zoom in here for you to see a little bit more closely is every function from the p5js reference clustered uh according to a similarity metric so I am look uh basically I have taken a lot you can see all of the loading functions are here there's like some uh some key related stuff here some touch related stuff here uh blend mode and texture is here I'm not saying this is perfect or accurate to how it really should be clustered what I have done just to be the whole story is I have taken a data file and uh let me let me get to that as well I'm again I want to build all these examples but I already did them so I might as well kind of show you the pieces first and then I'll step through building it piece by piece um but I not completely prepared here so let me find this other repo that I need to find um which is called save embeddings Json and again you if you don't know what an embedding is you're in the right place I I kind of don't really either I mean maybe I if you don't at all then I probably know like a little bit more than you so I'll be helpful but I'm not claiming to be some e I'm learning this stuff along with all of you I'm old when I learned a code we didn't have you know CH gbt that's not even that's like barely the that's like the you know 1% of what I didn't have Okay um don't think I had this repo why do I have a pass key pass phrase here okay uh just bear with me all right I have this text file that I made manually nothing fancy I just put everything from the P5 reference it's about 400 things into this text file so first of all if you have an idea by okay so first of all I'm as every once a while I'll answer a question in the chat uh wait why why why does this iPad just out of nowhere decide to talk to me I'm I'm gonna yeah I'm not I'm not talking to you Siri oh no wait don't say don't say it uh amirali asks you make a 3D so yes one of my prompts to you will be I'm going to show you how to do it in 3D but I'm I'm not here my overall goal here and I realize I'm jumping around a lot now uh which is why I shouldn't look at the chat probably is to give you a very base level without a design point of view example of how to do this and my hope then is that many of you will find an interesting data set and visualize it in your own way um and I'll show you some other examples the embedding projector from um researchers at Google is a is a really good example of this that I will get to uh all right so this is a tech text file that has everything from the P5 reference and what I have done is I have taken each one of those terms and uh used uh what is called an embedding model to create this embedding which is a list of numbers and then that is being uh brought in to a P5 sketch if I could find it where here um and I'm using a particular algorithm uh uh which is called umap to uh to do dimensionality reduction and what I mean by that is all of those embeddings are long list of numbers in a very highdimensional space and I want to see all those things plotted in a twodimensional space and umap is a particular algorithm that does that so that is the full story from start to finish the fly is back um of this example project that I want to build without a lot of the details filled in so if you will give me a minute here I am going to you can ask a few questions in the chat um and I could maybe answer them but I'm going to just get myself set up here with then I'll put on a little music n e all right I am back so let me uh take a look at the chat see if there's any questions um so let me just answer a few of these questions real quick any reason to use umap in instead of tne uh the reason I'm using umap instead of tne is twofold one I heard it's the newer one it's better I mean that probably is not actually true and there is a lovely uh JavaScript implementation of umap that runs beautifully in the browser and so since that's available that's what I'm using um any chance you'll be doing the Advent of code I'm interested in doing it I this is my busiest time of year teaching so um I wish I think I'm more likely to participate in January which is coming in January but I would love to do at least one Advent of code maybe I can do like solve one and try to do it as like a YouTube short um uh is there a way to Cluster similar things together oh okay that's Raj is just explaining what's going on but yes to be clear my P5 functions is just an example data set and I can use any data set of text and the as long as the text is chunked into individual elements I can do what I'm going to do in this video so for example I could do lines from a Shakespeare play I could do do the list of P5 functions I could do I could do uh uh captions from one of my coding train videos um there are lots of things I could do if you have an idea the reason why I am uh using singular words just as an example is because it's a little easier for me to visualize I can just put the words on the screen if I'm clustering larger blocks paragraphs of text uh maybe I could represent those as dots and you hover over them and then you see the paragraph so I could do that too but if you have an idea for a data set that might make sense for me to do today in this video uh you could drop it into the chat I'll probably miss it I don't know if we have any moderators here today because this was one is I'm disorganized and uh uh I'm trying to uh reorganize for 2024 a new uh group of moderators so if you're interested come join the Discord um but um you could like if if anybody sees an interesting data set and I miss it uh feel free to um I don't know try to highlight it for me certainly in the Discord uh member chat is where I would see it okay so oddly enough you're probably not aware of this but um I did recently uh uh cover a little bit of this in a live stream previously and what I talked about in that live stream was just the idea of I I kind of talked about how I wanted to do this and I hadn't done it yet um so I feel like I just want to like uh kind of recap I'm trying to think of where to start let's start with I just need an eraser let's start with what is an embedding o one of these work have some wipes here just give me a second this is this is why I'm recording to disc cuz maybe uh all right come on little doohickey I guess I should have done this before I started I'll get there uh by the way and I apologies to uh I forget the name of the company who reached out to me and I was in contact with about mounting a whiteboard on this wall anybody's got like a recommendation for like the best whiteboard could ever possibly buy to do diagramming on for videos that I could easily light I've looked into digital ones but don't think that's really going to work for me but this one this one I bought um from like a office supply store and I put it together myself and it's a little one is I did a terrible job putting it together myself it's a little bit clunky uh okay so I'll leave um a bit of what was on this whiteboard from before for um what I'm doing today is very much connected to large language models like chat GPT like the Llama model like uh Claude Claude um in that those models use a particular deep learning architecture called Transformers uh you know you I talked about this a bit in my last live stream there's the famous you know ancient paper now 2018 uh attention is all you need so I'm not going to in this particular session talk through uh what the architecture of a transformer model is how they're trained how they work that's part of the materials of my class and if you poke around in the syllabus you you're be welcome to find that stuff but it is highly connected because the same model architecture that is present in a Transformer a large language model is present in what is called an embedding model and I'm probably going to get this slightly wrong but in essence you don't an embedding mod in my mind and again I'm I'm G to Pro oversimplify this and I'd be curious to hear from the chat or anyone later watching this in the comments how accurate this is but well let's actually so I I'm watch the time have a tendy to over overexplained but let's talk about it in this way this is the way that I think about it and maybe it will be helpful so I've made a lot of videos about transfer learning and again this is I'm going off on a little side to come back to this and with teachable machine for example maybe you've watched some of those uh feature extraction so if I have an image classifier and that image has a cat in it well I let's say I don't have an image classifier yet I have an image of a cat and I'm going to send it into an image classifier that image classifier is presumably going to be a convolutional neural network and it's going to have a bunch of layers and at the very end it's going to produce a layer that's often referred to as logits uh we could call those features and then those will have an algorithm applied to it uh uh usually something called Soft Max which then turns it into a set of probabilities tied to each particular tied to a particular label so the the the the mobilet model which is what I use in a lot of my ml5 Js and other image classification tutorials has 1,000 uh you know 1,000 logits for 1,000 labels and presumably here at the end this cat label after softmax is applied would probably have a very high probability and we get that aha there is a cat in this image so again lots of details skipped here you can find a lot of this in my other you know beginner's guide to machine learning etc etc I'm just KCK me an eye on the chat uh to make sure there's no oh and Nik is in the chat hi Nik oh good well nikil by the way when I get everything wrong nille will correct it you don't have to say n but and I'm going to show the embeddings projector in a little bit which is uh uh thank you for joining nille nille is one of the creators of and if I've gotten that wrong you can correct me in the chat okay so one of the things that happens in a transfer learning process is uh um that a model can be basically retrained to associate different labels with the Logics the features of a particular image so in a transfer learning scenario in a feature extraction scenario the prob abilities and their Associated labels are no longer relevant and instead you just keep this list of Logics which is like a list of 1,000 numbers and guess what in my mind these 1000 numbers are an embedding for this image basically let's say this image is I'm not going to be able to do this math 640 by 480 that's a lot of pixels so what is the data if I wanted to have a numeric signature for this image well I I do I have all of the pixels and every pixel has an r a g and a b and it's a lot of information it's not really it's too much it's not that useful I want to in a machine learning context boil the essence of this image down into something smaller like a list of 1,000 imag 10,00 numbers so that is the idea now with an image it almost you could sort of think of it as like compression it's not exactly right because we started with numbers and now we have fewer numbers but what if I have you know the Cat in the Hat it's sort of like well I guess like these are asky characters but the asy characters aren't really associated with the meaning so there's this whole process in a Transformer model where first these are chopped up into tokens the the tokenization process is perhaps is more nuanced than this but you could think of it as like oh every word is a token or every syllable is a token but the you know the the developers and researchers that make these models have their own ways of tokenizing text and then each one of those tokens has like an embedding associated with it which is like a list of numbers and that's what becomes the input and then there's all these layers of attention and blah blah blah blah blah we're predicting the next token so this is what I kind of talked about previously and it's the thing that I'm not talking about today which is that if I feed the cat in the as a input to a language model I'm going to get um you know a set of pro of of outputs associated with probabilities but in the same way in my mind in the same way that I removed the end the actual predicted label from this image classifier in a Transformer model I could remove predicting the next tokens and just look at a lot of the internal numbers in the hidden layers and somewhere in there might be the meaning of the the the like have a numeric uh representation of the semantic meaning of what I'm passing in so that in my mind is like an embedding so I want to get an embedding for this piece of text now this is such a useful thing to do and you'll see why in a minute with some of the different things I might do a retrieval augmented generation is another topic related to this this is such a useful thing to do that there are models that are specifically trained and built and designed just for this purpose and they're called uh embedding models they're also sometimes especially when I look at transformers. JS uh it's actually called like feature a feature EXT extraction you know feature a feature being a word to describe a uh a property uh I mean that's a very common word in machine learning I think of it as like oh my facial features but we're doing an act there right if I have a if I have my actual face whether it's a 3D model or a photo of it I'm kind of saying like wow look at my nose it's kind of got this uh kind of shape to it or you know boy that tooth of mine is crooked those are my features so machine learning extrapolates features from things and and those features are Quantified into numbers through the you know all the different processes that are involved okay so I'm going to wander back over so that that's loose loose loose explanation I'm going show you a couple other things that might give you a little bit more information wander back over take a quick peek at the chat and move on to now showing you how to use transformers. JS to feed in any sentence of arbitrary length and get back in embedding okay how does everybody feel about that you can't respond to me you can in the chat I guess okay uh um all right um so I'm going to try to answer some of these questions here for a bit uh Ari Sean asks are these logits tied directly to the model oh sorry I didn't change my view here which I can are these logits tied directly to the model for example if you change the weight of the model so I um so this is a great question and I think I want to rephrase it because I think some of the terminologies maybe getting a little mixed up there um so um so I think the the short the short answer though I think is yes in that and and again I don't really have a diagram here but let's just let's think about this so um this is Mo like this is mobilet here this whole thing I should this mobile Net's not here this is the image input this is the model so the Logics that will come out from feeding this image in are the numbers that you get because of the the weights that are in the mobile net model it's been trained if you were to change the weights of the model you'd get different logits so yes if you had two feature extraction models for images maybe they would give kind of like similar Logics in some way because the you if you fed the same image into them because you know lots of models probably look at images in similar ways but uh not you would not be a you know if you wanted to do a similarity search across uh embeddings that were generate with different models you're going to run into issues because in uh I would think because the embeddings you're getting are tied to the way a particular model was trained and that's very important this is not magic none of this is Magic um and it's easy it's a little bit easier to recognize like if the language model is going to predict the word cat after the cat in the it's because of a you know shared it's because of the training data you know there are many me there's many many examples in whatever you know training data set was used of The Cat in the Hat so it's learned the high probability of hat appearing along with those uh that that particular sequence of tokens so with there you can it's easier to sort of then take the next step and realize like oh there's a real danger of cultural bias and problematic Behavior based on how that training data is collected and curated there's all sorts of questions around copyright and authorship so this is a really important big discussion that I am very interested in it's a little sometimes harder to remember that that discussion still exists for the embeddings because even though all we're getting is the numbers associated with it the fact that the Cat in the Hat is similar to maybe some other sentence is because of all the same questions around bias and data collection in whatever whatever data was used to train that model so if two models with the same architecture were trained with the same data set then if I used and I might get kind of like the same results twice would be slightly different but yes I in the end I think that to answer that question I think um if I'm answering it correctly these Logics are calculated you know at through the process of sending the pixels through the different layers of the convolutional neural network and all of the weights and activation functions and all that stuff okay and I realize not everybody knows all of this and that's fine stay with me here um okay uh so I don't see any uh obvious I see I see people answering other people's questions in the chat which I'm thrilled for um okay so let's just come back to this for a second I'm going to show you this particular example so what this example is showing you just as just as as a as another note of what you can do with this so one of the things that um embeddings can be used for uh is um and I might get some of these terms slightly wrong but like a semantic search or a similarity score between two uh uh blocks of text and so one here's a scenario I'll give you um to let's say you're programming a chatbot and your chatbot knows 10 answers and you basically want to like whatever somebody asks you want to give them one of those 10 answers maybe an answer is like I don't know um so let's say the uh question that's asked is what color is the sky and one of your answers that you have is the sky is blue and I think if I go up here so uh or I can oh yeah here is what I'm so what this uh particular example is doing and let's see if I can um do I have it open and this is not what what I'm going to code today even though I'm like and I'm wow I'm at 1115 already um but I think it's good background for this and it is one of the examples you could look at I think it's here no that's just like a test um is uh this so and I'm conf I'm conflating the idea of questions and answers I just put everything into one array but imagine I had an array of questions and an array of answers basically if I can create an embedding if I can turn every one of these sentences into a list of numbers then I can start to do math with those numbers and whatever results I get from that math I can tie it back to the original text so for example I could look and say like which one of these if I if I take what color is the sky which one of these other one two 3 four five sentences has the most similar numbers to what color is the sky now we got to talk about what does it mean to look at whether the two sets of numbers are similar but just from that you can imagine like if if I just had one number like well this one is six and that one is 5.7 those numbers are kind of similar so that's I can match that distance that difference between the numbers so this what this is showing you I think someone said in the chat is like a comparison Matrix uh which basically you can see I'm mapping the similarity of two sentences to a color so all down the diagonal of course it's I'm getting 100% my mug is in the way there a similarity score of one because they're exactly the same 100% the same and here I'm getting a similarity score of 0.07 because the sky is blue and what is an apple aren't very similar in terms of meaning and structure whatever uh other qualities that we might attribute to how the embeddings were created but the sky is blue and what color in the sky that has a 10 times higher similarity score so another thing that I could build right now is like that chatbot question and answer thing um and I'll also just briefly mention I think I talked about this previously if you look up the concept of and there's a great uh replicate by the way is a a hosting service for models that I've been using a lot of uh not not also not a sponsor but uh has generously given me a lot of credits to use because these things cost money although what I'm going to show you with transform transformers. JS runs on device so it does not cost money um but they have a nice um uh rag tutorial uh how to use retrieval augmented generation uh that explains this idea of retrieval augmented generation so what that means and I have some examp I I'm watching the time I want to show you my retrieval augmented generation example that I built in node uh but I'll come back to that if I have time so that's another place where you could use it let me just tell you what I mean and actually Nik was in the chat ah do I have this um I think I have it uh let me just I'm going to open up nille is one of the founders of a startup called lilac um and I think if I um I think this is it here yeah restart this space um I'm restarting lilac uh Nelle helped me build a uh rag for the nature of code book let's see if it uh wakes up here I should disclose that I do have a business relationship with uh lilac but you should Ely check out the work that they're doing um let's see if this can wake up so retrieve what retrieval augmented generation is is this idea of let's say I want to ask a question and I want the answer to not come from a large language models prior knowledge if you will to use that term but instead to actually come from the nature of code book I could do a similarity search across the entire book it's a question of how do I chunk up the book but let's just say I chunked up the book in paragraphs so I could ask a question like how do you code a fractal and then and I have I maybe I'll run my own example of this while we're waiting I'll just show you don't tell me it's not in here uh example rag replicate let's see uh See if this runs um so if I could write a question this is going to take a little while because this is using a replicate platform um and so that they might have to like boot up the model but I'll ask here like how how do you program the canor set I know that's the example in the Lilac oh wow that went really fast oh did I change I think I changed the data I forgot I was messing with this example and I changed the data uh this is now actually not my nature of code book but a transcript a transcript of um my uh processing tutorial I'll show you how I know this for sure um I'm G ask who is Daniel schiffman or let's say who is I'm just going to say who is shiftman because oh no it's fine it's fine let's do that uh right so you can see it's searching for um it's searching for in my video transcript things that are related to that question and you could see I'm about to get started but I want to talk to you a little more about just sort of me and my background and also a little bit about if you'll indulge me the history of processing itself so I could say like uh what is RGB color so this is not searching through the nature of code book it's searching through a transcript of everything I said in a particular video and what R so that's the retrieval the augmented generation is I could say hey take all of this and give it to a language model and say could you answer this question here's the knowledge you need to answer the question don't use your other knowledge and that's the idea of retrieval augmented generation and this uh example does do all of that but I I was mucking around with whatever version the version on GitHub does all of that let's just see uh and and maybe this will come back all right so that's a little bit of um some background so now finally I'm actually getting to what I wanted to do which is let's start getting embeddings now masimo oh oh masimo has a great comment too about llama 2 but bogo's question is really important there are many different models for embeddings uh there are very there are many fewer models for embeddings that work uh on device so one model that works on device is all mini lm L6 dv2 I'm going to use BGE small 1.5 I think today um most all of these models are embeddings for the English language and I my apologies in advance for not being as knowledgeable about what is out there and available for other languages I think it's a bit of a problem that a lot of the research in language and AI is very English language focused and centered and I would love to hear more about initiatives and work that I can support and participate in that is uh expanding the technology to other languages and cultures there's uh so many reasons why that is important um so I haven't done a deep dive into this country name data set that's pretty interesting uh says Yousef that's a great suggestion but so let's look for for the model that I'm going to use uh and um Let Me Close oh I closed that it's fine I'll come back to it um so the model let's go here so first of all so my understanding of the sort of current and I guess I why is my if you're having trouble seeing anything on the screen please let me know um I just lowered the desk because I think it's blocking quite a bit my understanding is that the current latest and greatest model for English uh embeddings and I believe this particular research group also did a version of with the same technique for the for Chinese um is BGE large so we could click over here oh this is uh replicate examples but I think I'm looking for is the paper yeah so this is the paper for um the research group that has worked on these particular models it's from the Beijing Academy of artificial intelligence a lot of these models are published on hugging face which is another uh platform for hosting models and I could see right here I wonder if it's actually going to let me do this without even um logging in I could say you know the Cat in the Hat and I could uh run it and this is going to run on replicate server and give me an embedding right there so uh personally if you look at the GitHub repo that um I will that is accompanying this video under uh save embeddings D Json there are two scripts uh one is uh embeddings replicate JS and this one uses uh the BGE large 1.5 model hosted on replicate but to use this you'll need to sign up for a replicate API token and there's a small cost per query uh to replicate um uh the one that I'm going to use today in this video is using uh transformers. JS and this particular you'll see it here feature extraction model uh runs on device meaning it's actually running just on my it actually can run in the browser but I'm going to run it through node because uh I'll get to why it's a little bit tricky it's not tricky for regular JavaScript people to run in the browser but it's a little bit tricky to get it to work with P5 so I'll get to that when I get to that okay and Kathy's pointing out there are lots of data sets on hugging face as well and that include different languages okay so let's get right to it so this is the particular model I need to raise this up I'm sorry so please let me know I'm going to try to be mindful here about not blocking I guess I could just move myself down and still have my desk higher this is probably a bad idea but I'm going to just do this right now uh uh uh where where am I keyed me okay unlock myself there I'm lower now uh so my desk is still at the same height but it is blocking less of the screen okay oh and thank you munzer for gifting a coding train membership somebody will receive that MBL lab received it wonderful um okay now some more background if you have uh followed me at all you have probably followed the fact that I use a particular Library called ml5.js to do a lot of machine learning examples in JavaScript and boy do I have a lot that I hope to do soon all about this Library coming soon um ml5.js is built on top of tensorflow.js I don't I don't think nil's here anymore but uh looked like nikelle one of the creators of tensorflow.js was in the chat briefly um so tensorflow.js is kind of the OG the original JavaScript library for machine learning and JavaScript there is another one that uh seems to be gaining a lot of popularity particularly in the language model space these days comes out of Microsoft called Onyx JS so uh um what I what you're seeing here is that this particular model uh has been released with Onyx waits to be compatible with transformers. JS oh Nila is still there okay so uh um so what's going on here Transformer the Transformers library is hugging face again this AI uh hosting company platform that I um uh uh find to be quite useful in addition addition all the other ones that I find useful um is uh uh has a python package called Transformers they have recently released a JavaScript version called uh transformers. JS uh it is built on top of Onyx which is the other thing so just like ml5 is built on top of tensorflow.js transformers. JS is built on top of onyx. JS that's probably where the similarity uh stops um but so just want to give you that background and understanding so uh one of the things I'm actually personally investigating is uh if I if if we were as the group who works on ml5 to add language model capabilities to ml5 uh an embeddings model for example could we also include the Onyx backend in addition to the tensorflow back end for that library but all that I want to do here is actually use transformers. JS so that I could get access cths beddings model so let's look at how we can do that now first of all not to overdo it here but um I'm about to wade into the territory of working with node and uh if you are unfamiliar with that you won't you know I guess you could stop watching right now and go look at these but later um I made a couple videos that's about sort of like the tools that I'm using and setting up a node project so I'm not going to do all that detail now but that reference material is there okay so let's go to uh here so this is a new um and I got to just be mindful of where I am so I'm not blocking things too much this is a new empty directory on my Mac I'm going to say npm init Dy just to create an empty node project um then I'm going to open this up in Visual Studio code and I'm going to create a file and I'm going to call it a save embeddings uh doj .js so uh usually the sort of default file for a node project might be index.js or server.js most of the things things I do are making a web server with node but this is just kind of like I just want to write a script that I can just kind of run as a process so I'm like the weirdo who uses node in the way that everybody else might use python or other kinds of command line tools because I'm heavily invested in the JavaScript ecosystem for my teaching and other things that I'm doing so um and so hey there's plenty of other people doing all amazing uh much more sophisticated and highly intelligent uh tutorials and educational materials on machine learning in Python so go find that but I'm here I am just digging into JavaScript again okay so um what am I doing here let's so the first thing I need to do is I need to import transformers. JS if you haven't seen es import statements before I also covered that in those videos but essentially all I need to do and I actually don't is this so I'm just going to uh put this right in here so I want to import this particular node package presumably to use this node package I need to also say um npmi for install I'm going going write install and uh install the Transformers JS node package it'll just take a minute here wow this takes longer than it usually does for me okay now if I go back to uh terminal I mean Visual Studio code you will see here under package.json that I now have this particular dependency uh Transformers uh JS uh from uh version 2.9.0 I should also say that because I'm going to use Imports I need to add to my package.json uh type module um okay and by the way in case anyone is wondering I do use copilot uh been experimenting with it a lot more recently but I've turned it off for the purpose of this live session because I thought it might muck things up too much um so we're we're just writing our own artisanal handcrafted code here in this uh coding train session so I'm going to go back to the documentation and this is what I want I want to uh so the way that transformers. JS works is everything every model is called a pipeline and there is a task and then the particular model you want to use for that task so for example if I go to just the main transformers. JS page and scroll down a bit you'll see like oh I could do a sentiment analysis pipeline or uh these are I could do a uh question answering or sentence similarity or summation or text classification there's all these different there's Vision ones so there's a ton of stuff you can do and for every single one of these like if I just pick I'm going to do um uh image classification if I click here you'll see well there's a video and some other U and it's actually see this is the thing it's showing me quickly it takes me to the python code let's see if there's a JS version so sometimes you have to do a little extra digging because that didn't work I didn't end up on the um maybe if I click here under models or docs yeah this took me to the Transformers JS docs and you can see here and I apologies that my I should make this a little wider now you can see like oh look if I want to do uh image classification I just load this particular model now you might be asking like where is it loading the model all I did was give it the name so this is very common ml5 works the same way I think some uh tfjs models work the same way these libraries have built into themselves the URLs for the cloud hosting P platforms where the actual model files are stored so you could load you could download the model files and load it locally but what I'm doing here is as long as I give it the name trans the Transformers uh JavaScript library knows where to go out into the cloud if you will and retrieve that model now this won't work because it's got the keyword await in it so for me to await the result of loading this model I need to put this in a function that uh is modified with the async keyword and uh if you're not familiar with asynchronous events and async and A8 I won't go to my channel to find them whole set of videos about that as well but I'm just going to write a function called load model who I don't know what that autofill was async function load model and uh I could then write a main function I'm just going to call it Go async function go and I put everything in this F in this function and I'll just like call it I know I should probably put that below and I'm going to say await load model so the first step here is is for me just to load this model and I don't I don't insist for no reason at all okay brain yeah I get it I get it where are we TimeWise 1135 okay uh I don't believe that no JS lets you await in the global context if I'm wrong about that that then my whole life is about to change um let's Also let's also do this and I can say uh uh what do I call this um um I'll just call this the embeddings model or I'll call this like BGE small I'm just like making this up as I go BGE model equals a weight load model okay so now uh let's take a look at this let's make sure this works and again if anybody's having trouble seeing the code or anything please let me know okay so let's run save embeddings and it's going to take a bit right it's got a it's a it's a the small model but it's going to take a little while so while that is going let's go back and so what do I want to do next what I want to do next is get an embedding so uh we can see here I'm just going to copy paste the example this is different than no this is right um um let's just copy this example here and look at what happens and I'm going to just uh have it be I'm just curious can I do it I mean it makes sense to do it with more than one but I thought I could just give it a single string I'm just curious about that because I think that'll be a little bit simpler right now did it load that model yet thanks for my nice typo here we didn't see so uh let's try running this again and see what happens okay uh oh and I need to say await run the BGE model through that Source okay so first of all we see like uh it it's console loged huge uh uh JavaScript object which you can see a lot of the properties and information about the model something that's really important here is this number 384 so that's going to be the length of a particular embedding um all right AR is telling me what about a node version 18.18 which I think is the version I'm using can you really that's insane if I can do that I don't believe you okay good let's try this are you kidding me oh yeah it this is going to work since when what what since when could you do this oh my goodness I did not know that oh wow I got go change all my examples it's going to make my life so much easier we do not need this function okay wow I I didn't think I could love node anymore and I really do love it now all right let's just keep it called as extractor that's fine all right so what's happening here what's Happening Here is I am loading this particular model it's task as feature extraction and the model I'm loading is BGE small English version 1.5 uh there are other models that are compatible with transformers. JS presumably you could train your own embeddings model uh but that's the one that I'm using for here I'm giving a source text hello world I'm uh and you know I this is not me this is not a coding train example if I don't instead put like Choo Cho and then I am passing that text to the model and then these two properties pooling is just modifying a particular aspect of what's Happening inside of the feature extraction process I probably relates to like actually don't know somebody can tell me in the chat probably I'm assuming it relates to like I think of Max pooling with like convolutional neuron networks um but obviously there's some aspect somewhere where it has to imagine has I'm guessing there's like multiple embeddings and maybe mean is saying just average them when you have multiple ones and you need when you to pull a bunch of embeddings together to just get one normalize means it's going to give me the values I'm assuming uh we'll check this the embedding numbers that come out will be between some normalized range maybe between negative 1 and one or between zero and one um so let's run this again uh it's definitely between negative 1 and one based on these okay so we got a uh an embedding uh its dimensions are 1 by 384 because it only ask for one sentence the type is floating point and then the data the actual numeric values are in this particular property called data all right so for example I could say embeddings do dat index0 and that's that first value so for example that fly well all right so let's let's let's go a little further let's just make up a bunch this is where I wish I had um copilot on copilot is the funniest thing if you're like trying to create a fake data set of sentences just starts making up sentences for you it's kind of kind of amazing anyone's experienced that um yeah I can't I still can't believe this thing about me not needing the asynchronous I could just do await in the global spacing node like this is really this changes everything Q like Hollywood you know music or record scratch I don't know what the sound effect that goes with that is all right now we need to decide what is our data set going to be so um oh here I know a place I could look I'm gonna go to corpora on GitHub so this is a GitHub repo that I turn to very often when I'm looking for just like a fun list of things so maybe let's go to film and TV uh Game of Thrones houses popular movies let's try that uh how how long is this this is pretty good has the date U I'm just looking at TV shows how long is this maybe let's do TV shows it's a little it's longer um let's do TV shows so I'm going to do something kind of ridiculous here I mean this is Json so I should load it as Json I kind of want to just load it as plain text because that'll be more common to what you find um but let's grab this oh oh here let's just grab this whole thing raw and let's go uh make a file called tv. txt I'm going paste it in here um and now I'm going to do some fancy regular expression searching uh let's look for a quote the beginning of a beginning of a line and quote and so this is I'm by so uh I got a whole set of videos about regular Expressions so I'm just quickly reformatting this document and then I'm going to search for quote comma quote comma end of line I realize this is kind of a ridiculous way that I'm doing this I'm going to get rid of this let's just now search through did I get everything um actually the reason why I kind of well it's fine let's see if there's anything that was weirdly formatted good enough okay how many TV shows we got here I guess it's 1,000 it said 1,000 didn't it okay all right so let me get rid of this and get rid of that okay great um I don't yeah okay so now I have a list of 1,000 TV shows in a text file called tv. txt okay so now what I would like to do is let's bring in the file system module from node import uh FS from FS I think that should do it and I'm going to say the raw text equals a wait fs. um read file does it just I forget how to use promises I guess I could just use read file sync somebody will tell me I'm just going to use read file sync uh the tv. txt uh with uh the file format is utf8 so now I have the raw t text and just to be sure about this let's console log it to see I'm going to get rid of all this embedding stuff right so there's all of the text files and this I maybe need to like move this in a little bit so it's easier to see so now I want to split it up so shows equals raw dosit by um any number of line breaks and let's look at that array great so now I have an array of all of the TV shows so presumably I could load this model oh I already did I loaded the model here I can now say for let show of shows uh and get now again it would be smart to do some kind of batch process processing where I do like 10 at a time and that certainly makes a lot more sense especially if you're using a model in the cloud but for the sake of Simplicity I'm just going to do it one at a time so I'm going to get an embedding uh for every single show and then I also want to have I'm going to say output Json is an object and and uh and that object is going to have an array maybe called embeddings in it so essentially I want to get the embedding which is in embeddings do dat and for each one I want to say output json. eddings do push and then I'm putting an object in it which is got the show and the embedding which is is embeddings do data and I guess that should be it's a single embedding so I think this makes more sense so let's just see uh you can you can you can all kind of check check on me here if this makes sense so I'm kind of thinking ahead here because I have made this example before uh show can be a const says super crafter that's a good point so could output Json not super in the habit of be that good as using const so what this should do is as I look at and let's let's do console log uh G um uh extracting embedding for uh show I'll put that in as a console log so if I get the embedding then what I want to do and this might make more sense is to say something like let well I'll just leave it it's fine B basically I want to oh this is no semicolon here I want to make a big Json array of the show names with their embeddings because what I'm doing here is creating what you might refer to as an embeddings database now there's no reason why I couldn't bring so you know later I'm going to load this database and do clustering with it there's no reason why that couldn't be in the same app but if it's for in my mind if my goal is to do a visualization of a fixed data set that is not changing it doesn't make sense to rerun the model every single time so I'm going to do these as two separate steps and I'll talk to you about how you could do it as one okay um so here we go let's run this see what happens so doing extracting all of these things it finished so I didn't do anything with the output Jon so I don't know if it worked but let's let's at least console log the output Json let's write it to a file uh let's just write it to a file so FS WR file sync should go to um the file name so let's call it TV embeddings and then I need to give it the uh and I'll do I'm going to do uh const output equals Json stringify and the what is it called output Json so uh what I'm trying to do and I'll I'll add in null comma 2 so these arguments just format it so for me to write this out to a file it's a JavaScript object I need to turn it into a string into raw text so I can write it to the file so this should now you know this isn't a lot of code very simple I'm loading the Transformers JS model I'm loading a data set from with raw text I'm chopping it up I'm feeding every element into the model I'm getting an embedding I'm packaging all that up in a Json object JavaScript object and writing it to a file let's just see could is it possible that I didn't make a mistake here we'll find out okay see how fast that was by the way that's what I like about using an on device model okay this looks pretty good uh why is it is this h no no no no no no no no no no no why did it do that and maybe it's going to be fine in the end but this should be this all right I have to debug this right this I don't want an object with every index being a number uh why did it do that I don't recall this happening in my other experiments but let's see um so let's just do one show here for a second is it something in the way that I did this okay conso log I know I could just type what do I type CL you were saying to me CG I got some Visual Studio code settings I need to figure out um embedding let's just look at this and then let's say break so I'm just going to look at the first one okay so I definitely got a nice plain actual array of numbers all right still just a nice plain array of numbers uh well let's do this console log output Json let's see what happens here oh whoops oh the break the break is before okay sorry about that so let's take this out also just to ah yeah look there it is I wonder if this stringify did so stringify clearly did something uh let's see what's in here now yeah okay uh what if I take this out just huh it isn't an array object oh okay so I have to because it's this special kind of float 32 array thing it's not actually an array you know actually I think Transformers JS has this list I was looking at the documentation I think I saw a list function oh yeah two two list so I wonder if I'm supposed to use two list let's see what that does um so this is this is useful for me to know is it uh two what was it two list oh without the underscore okay let's try this not too L does it does it go here this is how yeah ah okay ah oh it gives it to me okay so this is good so maybe that's what I want so I want uh this embedding to list index zero because I I'm just getting one I think this is will now work let's see what we've got um and see here oh let me put this back I mean I don't need the formatting well I think my visual studio code will format it yeah okay great that fixed it that's what I want I want to actually just see the array of numbers okay so the formatting is very much unnecessary but it it's helpful for me to be able to see it so I'm going to put that back in uh null comma 2 and then I'm going to take out this break and I don't need console log here this should get me and again this is because I'm not batching them so I'm just doing one at a time which is probably not best practice but it'll get us uh it'll get us to the finish line here okay here we go extracting all the embeddings all right we've got all the embeddings now and there there it is now usually in Visual Studio code it lets me like fold these up but doesn't really matter you can sort of see um whoops I I hit save and it did something so you can see that this file is not really human readable uh and actually one thing I'm very curious about is how big is it reveal INF finder 9.5 megabytes so one small problem here is that the I wanted to show you how to do this in the P5 web editor which I think is useful the p5b web editor is um uh can you can only upload files up to 5 megabytes so I have a couple options one is I could do this with fewer TV shows another is I could uh just Host this file in a CDN somewhere if anybody has any suggestions all right I'm going to let's let's go let's go move to the next topic so I'm going to come back back to that so I have my embeddings so you could imagine now there's a lot of things I could do for example I could do make a chat bot where I where I asked the question please suggest a a TV show for me to watch I love TV shows about Farms now again because the embeddings are just associated with the titles of the show this won't work very well but I could now turn my question into an embedding and then do a similarity search across all the TV show and return a suggestion more likely if I really wanted to do this in a more robust way I would want to do like embeddings based on like the description of the shows and all sorts of other more have much more information and data and I would love to see people uh experiment with that I got to come back and do some more of these like search and retrieval things and the secret to it which I had a diagram up on the board is looking at something called cosign similarity okay host on the cloud would be nice on gith yeah I could just host it on GitHub actually so let's let's actually for the sake of argument just so you have access to it's not that different than what I already have but let me just go on GitHub and make a new repo for this live stream um embedding I'll just call it em we can change the name of this later uh make it public uh create the repository um and uh let me just get this here and then I'm going to say get init wait actually let's add a get ignore first there's no environment variables but let's just put that in there just in case I forget later um maybe I don't want to um right now let's not upload the um data files so I'm going to ignore those as well oops code from live stream and then add the remote oh wait the whole point was for me to host it on the CDN okay fine I forgot what I was doing here so I do need to include these things yeah oh and that took out the package.json file too I made so many mistakes there uh I don't know if I need that but I'm just it's a reflex at this point okay so now uh here we go the repo is there there's no uh read me I I don't know like so one I'm a little I'm a little a little bit hesitant about this because I have this whole repo that I already made called save embeddings Json so this makes more s it's like documented and I have like you know in instructions and things so I'm not sure you know I'm not sure if I should deprecate this later and combine them but for right now it'll work because what I want is to be able to uh load this file um you can use a JS deliver link but um I think this will actually work just load the these embeddings from this raw file okay so let's now go to the P5 web editor and let's see if we make the font a little bit bigger so I want to move towards uh clustering and umap where where am I time wise oh I'm at noon I said I was going to be done at noon but we're going to keep going because I want to finish this by golly oh just the TV shows on a gist well that makes more sense okay I should have done that so uh paste bin yeah the gist would have made more sense too late it's too late for me I've done this already okay I'm trying to think so there's there's two steps here one is how to load that embeddings database into P5 that's actually not going to be too hard I'm just going to use load Json so let me skip that for now now the other more complex question is around how am I going to take that data and draw a clustering map of all of those TV shows and for that I am going to use a particular algorithm called umap now let's go to uh the uh embedding projector um this is a research search Project from the uh group at Google uh I you know I've name checked nikelle a bunch of times uh nikil is one of the uh creators of this along with Daniel smov and I'm probably missing lots of other people who worked on this um so apologies to that um this is a visualization of highdimensional data um that has a very thoughtful uh interface and demonstrates various different algorithms you can use to visualize that data so first let's talk about what's here so the demon the the data that is being used to demonstrate uh first when you load the embedding projector is word to VC what is word to VC so you might think this whole idea of embeddings wow large language models AI we're living in the dawn of you know putting words with numbers this is not a new idea and in fact if you go to back to my my syllabus under the embeddings week and I scroll down uh stay at the top here you will see that I even made a couple videos that I never finished so I really should get back to and somebody just gifted like azillion memberships wow okay I've never seen this happen but thank you to uh generate Collective that is uh unbelievably generous and kind of you um so uh uh so I made these videos what is word to VC color vectors that understanding word vectors article is by Allison Parish it's absolutely fantastic I would really recommend reading it um and the original paper around word representation in Vector space is from 2013 so that's like 10 years ago so there have been uh many instances and examples of looking at how to vectorize uh text text um and uh word Tove being a particular model and uh embeddings database that has been used in lots of different projects uh Universal sentence encoder is a tensorflow.js model from 2018 that turn sentences into embedding so this is not new territory I recommend this background reading for you um by the way I've got some other links here to other reading material around embeddings that would also I think it's good background material so what this particular visualization is showing me is 10,000 words um each of those words has an embedding of 200 numbers and yet I'm seeing them in threedimensional space so what does this mean let's go back to the Whiteboard for a brief minute if you'll indulge me a little bit here okay hold on I'm breaking out the Windex everybody I don't like to use this if I don't have to but it's gonna water would be better but you know time is of the essence here the Windex just does the trick now I'm breathing in the fumes hopefully I don't know okay let's just get all of this out of the way get one of these nice cloth all right dry it off okay so let's just say for the sake of argument that I have a word um boy this that I have a word uh like uh rainbow and it's associated with an embedding which is uh 200 numbers and I have a word uh Cy which is associated with an edting and it has 200 numbers now let's think about a different example let's say I have the word red and it's associated with an embedding of just three numbers and I have the word uh blue and it's associated with an embedding oops damn it which is just three numbers I meant to do this the other way around and I I have pink and it's associated with I don't know three numbers I I don't know if that's pink whatever so if I wanted to visualize these three words according to their embeddings well I have a number of ways I could do it I could do it with actual colors but let's say I wanted to plot them in a three dimensional space well I could consider the first number to be the xaxis the second number to be I kind of want to make the second one the zaxis so that I can I make I do that no that's fine the Y AIS and the third number the zaxis and then you could start to think like okay so red R would be like over here because it's at 255 along the x axis and maybe blue would be over here because it's uh so this is blue and this is red and then maybe pink would be kind of like you know somewhere like here this would be where pink is and you could start imagining plotting all these colors because each word is associated with three numbers it Maps easily to three dimensions if I wanted to plot them in two Dimensions I could just do something like well let me just get rid of the Y Dimension you know I'll still just plot them if some of them have a lot of green in it I'm going to lose that information but I'd still kind of have a a basic visualization of the color space what do I do if I have 200 numbers well in an Ideal World I'd be some kind of like alien super being like you know I don't know think of those things in the movie arrival or something but I could just like see 200 I could just like let me draw you uh a 200 dimensional space and you're GNA just my my brain I don't know about you my brain does not work like that I can't even in my mind visualize a four dimensional space I can barely do a threedimensional space if I'm being perfectly honest here so there's not an easy way to visualize these numbers in a high dimensional space that's the information though is in that high dimensional space so what I need is some algorithm for dimensionality reduction if I could figure out a way to take that and just reduce it down to three numbers still retaining the essence of all of the numbers then I could plot that and maybe G glean something about the data I could start to Cluster them I could do K near you know there's all sorts of things I could do uh like in the embedding projector which I'll show in a second so the question is how do I do that well like with I said here like ah why don't I just pick I want to do in 2D or 3D I'll just pick the first three numbers sure I'm losing 197 other numbers but let's try that you could actually do that it's not a big try it go for it I could maybe even do something like well uh what if I want to do it in two Dimensions let me take the first 100 numbers and average them and the second 100 numbers and average them again it's probably not going to do I'm going to lose way too much information it's not going to retain the actual geometric structure and positioning of the 200 dimensional space but that would work that's a dimensionality reduction algorithm so there are this is but this is the task that I need to do my data does not is not originally in twodimensional or threedimensional space but I want to see it visualize it in that space how do I reduce these vectors down to a lower Dimension and still yet retain Ain uh as much of the information I want things that would be near each other in two dimensional space to still be near each other in twodimensional space so that's the problem at hand um I'm thank you fun Planet who seems to be doing a heroic job of moderating the chat I appreciate that um so this is the Energy Savers oh wait what the I'm plugged in let me try we've got a slight minor emergency here which is that my battery apparently I have not been plugged in and the battery is very low I'm plug let me check is this not plugged in there is a plug that's plugged into an outlet is this I'm afraid to turn anything off it's got some cobwebs on it let's try plugging this in wow what is going on here oh okay hold hold on uh I'm going to unplug from the screen for a second just to plug this in directly to this one port that I know works okay something is wrong with my power supply give me a second I have a backup one I have a backup power supply um coming back I mean I could also but people are just like I've never seen this all these gifting of memberships I didn't even I like forgot that I had that turned on this is very kind of you okay I guess I should do these live streams more often um okay uh hold on I'm just getting another plug hopefully you can still hear me let's try this one I cannot have my laptop die before I finish this now this is very dangerous what I'm about to do I'm going to try to plug it in from a different place it's a tripping Hazard where I'm plugging it in so somebody remind me not to trip if I start trying to go to the Whiteboard okay we are saved everybody so I don't know what's wrong with this plug let me let me just make let me put it now that I know it works here I'll put it out of the way where I won't trip cuz as fun as that might be for all of you it won't be good nothing good will come out of me all right yeah so there's something wrong with that other power supply so uh okay did okay hold on we're I'm going to be back to the tutorial in a second I am recording this whole thing to dis so it is possible if there's interest I would be glad to make an editing version of this and editing an edited version that's just the like tutorial part which might make it easier for people to rewatch later um but we'll see okay um all right so I was talking about so I want to make a version the so I was a little bit background around word to V right and so we can see here that if I were to zoom into this I um you know presumably uh words that are near each other are going to have sort of similar uh similar meanings uh because this uh the 200 dimensional space of all of these words has been uh reduced down to three dimensions now how was this done was it done by just taking the first three numbers was it done by averaging no it was done with a particular algorithm called whoops PCA principal component analysis let's take a look at it with a different algorithm called tne which I have no I forgot what that stands for at one point I knew uh so do uh um this will definitely be there this will 100% be available to watch later I just um was wondering if it might be helpful to have a shorter version of it without all of the like me finding my plug and stuff in it now I this doesn't usually run so slow to me I think it has something to do with the fact that I'm plugged into the streaming system but you can see now the tne algorithm is uh moving the dots around uh reducing the 10,000 points to 200 dimensions and at some point it will finish and we could start to explore it um I could even change it to 2D and there's some oh you can't see this down here but there's even some like various parameters and things that you could change but um so uh PCA I you know this is my loose understanding is principal component analysis was one of the uh first algorithms to do this dimensionality reduction tne was all the rage a number of years ago and more recently uh umap is a new algorithm uh that uh uh along some set of metrics uh retains the uh relative similarity position I'm trying to think of like what's the best way to describe this I should really just point you to this article which will explain it uh much better data's Global structure that's the word I'm using umap is a technique that offers advantages over tne most notably increased speed and better preservation of the data's Global structure so this is a wonderful article from Andy Conan and Adam Pierce from Google pair uh people in AI research um that describe I believe these are the same authors as the umap JS library that I'm about to use you can see Canon ey here which I assume is uh the the same name U might be getting some of these details slightly wrong uh we're still going there but so this article does a wonderful job of giving you a high level understanding of umap so first of all this is now what we're seeing here which is nice is the clustering of images so if I were to make a again I'm way over time already here but I would love to do an example of this with images I'm going to do it with text right now but you can see the difference this is this is using a particular data set called fashion mnist which is basically lots of little low resolution images of a whole lot of shirts whole lot of shoes a whole lot of pants and so if we look at this you can see like uh zooming in here you can see like a lot of the shirts and pants uh so sorry coats and pullovers and shirts are here all the shoes sneakers sandals are down here umap has done this amazing job of organizing all of the data according to its similarity it's not matching shirts with shirts it's matching embedded ings with similar embeddings and it just so happens that those embeddings are coming from images um and these are low resolution enough that I'm assuming this is actually just done with the raw pixel data as opposed to what I was talking about earlier with like feature extraction through through some image model um so you can read more there's a wonderful there's there's a couple different properties of umap that we'll see that you can change and you can kind of uh play around with these different visual interfaces to kind of understand like well what does it consider how many neighbors that are near it in high dimensional space is it looking for to kind of map down to to lower dimensional space how far is too far how close is close um and there's a bunch of different demos this is one that was super interesting to me so this is actually taking a three 3D data like from a 3D model and doing umap projection you could also call this dimensionality reduction projection it's no different than how you might do uh projection in a 3D renderer because you've got to take 3D data and create the illusion of seeing it in twodimensional space that is dimensionality reduction as well so but umap dimensionality reduction is doing like you can sort of see how it works here and you can see what these parameters do like if I take uh minimum neighbors all the way down to three and minimum distance down to zero this is how it's arranged this data into two Dimensions versus increasing the number of neighbors and increasing that minimum distance you can see like look at this strange like crazy version of this Mammoth now in 2D so this is ultimately what's happening um and there's a lot more examples and demonstrations and explanations in this article so um I uh you know one is I've read this through it really helped me I cannot you know regurgitate it in an eloquent way right now I'm going to just uh sort of recommend that if you want to learn more about how umap works that this would be your starting point resource for us however what I would like to do is just go to um app.js and there's probably a more elegant way to integrate this into your code oh you can install it through npm but I'm just going to for the sake of using it in the P5 web editor I'm just going to go under lib I'm going to go to umap js. JS and I'm going to just download this file so I downloaded that file and in the P5 web editor I'm going to upload it and where is it under downloads here it is let's upload it and now in my uh index.html I am going to include I don't need this is the sound library right away so I'm just going to get rid of that and instead include uh umap Js s .js so and this is my umap clustering example okay it runs we've got a sketch okay so now what I need to do is two things one is I need to figure out how to run the umap clustering algorithm and in fact let's just do that right now with random data to start and then I'll load in my Json uh embeddings so let's make a uh array called data and let's make 100 random data points and have each one be an embedding uh I don't I'm making this up as I go uh uh a record I don't know what to this is like maybe I'll call this embeddings and I'll call this like data uh let's just make an array with three random numbers in it um and then let's push that into the embeddings so what I have here and U okay I got to keep an eye let me open this which will help make sure that I'm not standing in front of the code okay so this is I'm creating three I'm basically doing um where's the Whiteboard I'm basically starting with this so I'm going to start with this which is just embeddings with three numbers and I'm going to try to do dimensionality reduction down to two Dimensions if I can get that to work then I can load my higher dimensional sentence embeddings okay so now uh I don't know the umap library off the top of my head so we'll follow the documentation um so I don't need to import it because I've just loaded it from the file itself so I'm going to uh just create a new umap object let me close out let me just close out some other things running make my screen a little brighter so I'm going to do map and I'm just going to use let you don't need to tell me cuz I'm in the P5 world now my friendly let place and I'm going to say uh umap equals umap and then literally all I need to do is say um map I'm going to show you how to animate it later but fit uh embeddings so that should do it let's just let's just see if I do it do I get an error or anything oh it's slow wow wait wait wait 100 things just calling fit should not freeze I probably should have paid more attention to to uh what I was doing here because I might not have the data in the right format um I can look at any of my examples oh you know what I think is an issue here is I'm not um setting the uh all right let me look at one I I made this example already and I'm a little bit pressed for time here so let's just go and look at it uh oh right and it's in my a toz uh sketches it would be uh that's interesting this is a different one I'm looking for I thought I made a hello world one but let's just look at this yeah so so let's oh yeah I think I I sort of didn't I sort of forgot about like the important part okay so I got to um kill this page uh let's see if we can get it back okay okay I missed some important things here which is that um and let's just see did I get that right yeah I would like these to be on different lines because okay it's not going to do that that's fine okay so what did I forget so one thing that I forgot that really important is I need to uh give it some initial properties and as that article demonstrated these properties and neighbors minimum distance those are parameters that affect the cluster ing I shouldn't say clustering because clustering to me is really like actually putting them it it affects the structure of the dimensionality reduction how many other elements is it looking to get near uh what is a distance threshold those are really important parameters you can play with this is the what I want to really focus on it is um the dimensions that you want to end up with so I started with threedimensional data I want to end up with twodimensional data now I might have done maybe this like is a problem let me just put in the let me just do this that's kind of not what I wanted to do but just to make sure let's just see if this now will finish and not freeze look at this for a second let's look at what the format of the data is in this one that was working sure okay so this one worked and it's just 120 and I maybe and it is actually using just actual RGB values so maybe I should just try that this one's still frozen oh fix line eight oh oh that's the problem I'm sorry everybody I'm sorry everybody okay see my naming is terrible this is data and also by the way just for fun times now I realize I can make these 255 okay all right everybody we're moving on here with life okay great okay it's working so so all that was wrong in case you weren't following that is I was being a lunatic and trying to put my array into my array and I had an empty array full of itself recurent and then I was trying to you map that definitely not going to work so let's just look at what is the data what does the data look like what are the data is probably the what I should say uh oh no so what are the embeddings umap is expecting a array of arrays so I have 103 dimensional embeddings they're just color values then let's look at what do I get out let's look at umap and maybe I'm supposed to uh if I call fit what well let's look at the documentation uh maybe it's just in there maybe I'm just being um stubborn here so learning rate there's other things I could change random categorical distance function optimization state I'm I'm being so stubborn and not looking at my example like refusing to look at my example where do I get the results I random spread that's giving me my properties I mean I did it I'm just refusing to look at the example I'm gonna look at the example fine you got me uh you map results oh oh you yeah no wait you map results oh that's the array okay hold on what am I do oh I see all right fine everybody it was I'm just being silly okay so how does this work and I kind of hate what's going on here I have so little room on my screen for the code and I really want it to like I'm just going to make it a little smaller you tell me friends if uh you can no longer read this on your giant your tiny little phones that you're watching this stream on okay um wow that's way smaller that's too small I can't even read that now I get 28 okay um so uh I umap is the object that is going to uh execute the algorithm and hold all the parameters the results are return from the fit function now what I would like to look at are those results and here I now see uh I have all that data mapped to two Dimensions now you have to I have to ask the question of what is the range that I'm getting good question I don't know ask the people who wrote that umap JavaScript library um okay hopefully you can um so what what I'm going to do now I think so so it didn't retain like the umap space that it projected it into is kind of an arbitrary space and this is actually a stochastic function meaning it uses random numbers and you're going to get a different result each time there is a way to pass a a seated random function into it so you get the same result each time but that's beyond what I'm doing here basically let's look at the following just really quickly let's go and say for and let's make the background uh black for let I equal 0 I is less than umap results. length i++ and I'm going to say uh I'll call it data point equals umap results index I and then I used the con there even though I said I wouldn't let's say let x equal data point uh index zero and let y equal data point index one maybe I want to translate to the middle of the screen and then just say fill 255 and draw a circle at XY that's you know like eight pixels let's see what we got uh and I'm going to say no stroke so you can see that's all of those points but that's because the range I haven't thought about mapping that range to my pixel space so one way that I could do it is I could say hey let's map it's got a range between negative 1 and one to between uh you know negative 100 and 100 uh and um maybe let's take the Y and do the same thing uh what's going on here so in in other words this isn't a great way to do it because I'm just kind of grasping at straws so what I actually would like to do and I I know I could use like some fancy higher order array functions to do this let's look for the smallest value oh that actually is not so bad let's look for the smallest value and the biggest value so I'm going to uh say x is data point index zero and Y is data point index one let's get rid of the translate I'll just do the mapping through what I'm going to do and then I'm going to have some numbers like the minimum X should be negative negative Infinity Max X is positive Infinity Max X and let's do that for the Y and then uh I don't need these temporary ones I'm going say the minimum X is whichever is lower the minimum between wait do I say the max no the minimum X is infinity the maximum X is negative right because I need to start with the opposite of what I want to get right I want to find the minimum value so first I'm going to check is it less than infinity yeah so I just had that wrong so is the minimum between the actual value and what it thinks the current minimum is uh and same thing for minimum y uh is this for y and now I can do that for the max values whoops and just change this to Max I look forward to all of you suggesting much fancier nicer ways of writing this and then now I can map from minimum X to maximum X maximum X to Zero to width and then minimum y maximum y zero to height and because I my random data is color um let's look at the fill as embeddings index I index zero so I'm going to just use the original embedding values to set the color and this is very clunky because of the 2D array stuff now look at that woohoo okay let's let's make it more Colors Let's do like 500 now there we go see what's happening here look look umap took those and clustered them look at all the greens in their house now these are Rand so let's do random seed just so um I'm just going to show you this so I could say random seed so I get the same random color data set every time but I'm getting a different umap arrangement every time it's because uh umap is uh is a stochastic process and it uses random it tries things randomly and starts moving things around uh based on the random tries that's probably not a super accurate technical way to explain it um okay so we're gonna get to the sentence we're gonna get to the TV shows we're almost there to the end 1236 oh boy okay I gotta I hope I'm not missing a meeting I don't think I am all right so just for the sake of argument though I just want to show you that I could actually give it let's let's um let's put this into like an options object because I think it's a little bit more clear and I can say um I can give it the P5 God I hate how I don't have space here um I can give it the random function in from P5 there we go thank you Auto format um so now because I seeded the random function I'm telling umap to use the P5 random function it's the same orientation every time so that could be that could be important um in different cases okay so this is pretty good and I could move right now to just using the embeddings but let's let me show you one more thing I'm going to duplicate this I'm going to say umap clustering two and what I'm going to change it to now is because especially with a large data set you it can run very slow and so you might be waiting a long time for the final clustering plus it's kind of fun to watch it so I can say uh let's see if it's here fit async looking for a step doesn't seem to be documented here I don't know where I figured this stuff out I must have been looking at an example but uh I can just say initial I think I know how to do this so I'm going to say initialize fit I think that's the right function name and I'm also going to say umap is running or just going to say like yeah let like umap running is false and then I think I say I should just look at the example this is very silly so I thought it would be in the documentation but and there's probably a different documentation that I could look at um but I forgotten what it is uh this one will have it um you step I should have known that and then get embedding okay that's all it is okay so then I'm going to say um umap running at the beginning of draw I want to do one cycle of the algorithm every time through draw I'm going to say umap running is umap Step so step through one cycle of the algorithm and then the uh umap results basically which I guess I can make that a local variable oh so I think I just only need I can just call initialize fit umap results equals umap get embeddings or maybe hold on let me just check this yeah step umap get embedding or result yeah okay then I'm gonna say umap get embeddings okay so what did I miss get embedding there we go ah so now you can see it's doing uh one cycle of the algorithm every time through draw now it's never going to stop but actually it will get to a point when it's finished I just need to tell it to stop stepping so I think that I say if you map running then uh I want to call step because I I still want to oh no if it's not running whoa wait oh but I maybe I need to be running at the start no okay uh wait what did I do wrong hold on let's okay oh it's telling me how many so that's giving it me it's actually giving me a count and is it going to go to like zero or something you can see it getting close huh so this is not what I expected again I've got to look at my example which I keep closing because I really don't want to look at it is yeah that's what I did result my is in the results where else and I started it as true that's interesting okay I mean I guess it doesn't really matter umap running how's this different uh I guess I did the whole thing oh okay I I had the whole thing here in draw so anyway the there's obviously like a so I might not have been doing this correctly but I see that now it's doing it so this is fine I'm going to figure this out so uh I'm going to say if so I know it's going to do it yeah let's just do this umap running is true uh I'm going to say iterations equals map I'm just going to make my own version of this is greater than or greater than or equal to 500 or is less than 500 and maybe there is a way to specify it in the options um umap running equals false and then uh I mean this is silly I I've kind of I will refactor this later as I like to say uh okay uh if I think it makes much more sense for me just to do this okay what did I okay this should work right so basically umap step gives me the number of iterations and um B I want to keep calling step until I get to 500 uh so that should run through 500 and then we should see and EPO is the option name so I could do that so that's so let's do that let uh NE EPO equals 500 uh and then um I could say n EPO here and then and epox here so this would be a more proper way of doing it okay sorry for that uh now you see this is now the umap algorithm running all of its iterations and it's I you know even though it's a little bit there's you could probably make a much nicer animation of this where you actually kept track of the points over time and like interpolated them but even so I kind of love like like now I could do like 2,000 points and it's kind of like this lovely like mash of color uh that slowly over time starts to separate out into its uh positions so even just visually here I think something interesting is going on but let's tie this all together I'm an hour over what I meant to be but that's fine I'm actually doing this stream and this project some amount of you have stuck with me for quite a long period of time many many of you've been very generous in gifting memberships and things let's bring in that sentence data so save one more duplicate and now I'm going to put in function preload I'm going to have a variable called Json data and my Json data is equal to and let's turn off the auto refresh I need to go back to wherever I uploaded that uh embeddings database which is right here let's go to Raw let's grab this URL and let's do low Json that URL and let's just for the sake of argument put in console log Json data just to make sure it's there okay what did I miss semicolon is in the wrong place because I have so little space for my code okay great so you can see I got 999 embeddings so that's good I got 999 embeddings and I don't know what what follows that okay so now the data these are the embeddings so uh I have a global variable called embeddings already so now I'm looping through the length of the Json data and I am saying Json data oh it's in a variable called embeddings so embeddings do length and uh I should really think about renaming these variables because I'm using the word embeddings in probably too many places but I can take uh Json data embeddings index I so I'm putting all of those things into that original this is ridiculous I oh no it's not it makes sense I have to umap requires I'm gonna I'm going to change this to like raw embeddings I think that'll maybe make more sense so what I'm doing and we don't really care about the random seating here right now so I'm going to take that out the raw embeddings are what umap needs my embeddings are coming in with these JavaScript objects that are paired with the TV show name which I also want so I'm going to leave the same options we're going to do all the same stuff but now instead of drawing a circle let's try saying we are so close to being done here text Raw embeddings embeddings oh God I I need a no no not the raw embeddings the Json data again I could organize this better Json data. embeddings indexi dot what did I call it show show do show X comma y okay so I think what this should do now is instead of the random color data I've loaded all of the uh again remember I've loaded all of the TV shows that have a name and an embedding I've reformatted it into a raw embeddings array which is what umap needs and this should be raw embeddings here then I'm getting the results visualizing them but instead of circles I'm drawing the actual text let's see what happens okay great I think this is working so I'm going to stop this because it makes much more sense I need a much bigger pixel space for this to be interesting at all so let's do uh window width and window height and I'm going to do let's take out the console log I think this is done I'm going to do share and go to this full screen view and let's see what happens sorry for how flickery this is probably like destroying YouTube compression after 500 iterations we should see something not whoa okay wow I guess I was expecting to have something with a bit more structure to it but um I guess these show names are really kind of like wildly different Curb Your Enthusiasm in 21 Jump Street yeah those are basically the same show I mean nine to five let's let's double check the code to make sure I didn't mess anything up number of neighbors umap step yeah I mean I didn't change anything so maybe this data set I mean I could try a different data set real quick uh we could try playing with these values um but uh I also think I might need to stop now and and let you all like try this with your own data and make more beautiful interesting visualizations try 3D be more thoughtful about the design and interaction can you zoom in and out all that kind of stuff I'm a little bit disheartened um let's look at let's look at this um let's see if we can uh look here again and kind of like what happens if I so I get things minimum distance yeah so lower minimum distance let's just try using some crazier parameters like let's lower the minimum distance and let's like increase the number of neighbors I was going to put in 50 here and hit save and then hit refresh oh also maybe I hadn't actually hit save before I went to the full screen but let's see what we get so fun Planet says isn't raw in edings the same as embeddings no because the embeddings file is written in this way where the actual embeddings are inside these little Java object objects with show and embedding and umap JS is just looking for a 2d array so that's mean just reinfor re re re um reformatting it okay let's wait for 500 iterations it you know the P5 uh functions worked so well that I just assumed any data set would kind of work but I'm not getting um uh really great results here but I mean it did do something like maybe if we did similarity scores between these we'd see that this actually this Arrangement like really makes a lot of sense but also this data set is kind of silly um Boardwalk Empire and aliens in America are You Smarter Than A Fifth Grader Cupcake Wars that kind of makes sense that those are near Name That Tune yeah Murder She Wrote also like this is like the worst visualization ever uh so A Pup Named Scooby too um so it's sort of hard to evaluate because uh my data I picked a poor data set um I'm missing are you sure am I missing something oh I'm missing yet another I think fun planet in the chat caught something really crucial I think so let's let's let's look at my mistake here so this is my naming problem of calling everything embedding everywhere in my code um look at this yeah this array has objects in it that has the show and that so it is the same so I did I made a huge mistake here this needs to be the the whole point of this was to only put the arrays in it yeah look at that now I have a raise of 384 okay hold on we're going back stop save think we're going to get something now I mean we'll see we still who knows how you know it's going to work other people caught it before fun Planet I just noticed you fun Planet because you have the wrench so thank you everybody yeah William Clark I see says it um yeah now who's it's definitely different um you can see it's quite different and um Easy Street East Street Flamingo Road 21 Jump Street yeah yeah yeah so the embeddings are you know obviously this we're just doing it by show titles you can see this little cluster here the Restless years the light you know Living Color love of life okay now we're getting results again my visualization lacks a leaves a lot to be desired um I am curious I really I think I'm an hour Beyond where I meant to be let's just try I'm just curious um I I would love to do this now in 3D um but you know I got to move on with my day but I just want to try changing those parameters a little bit just to see if we get more structure so you could imagine uh so one thing I give you a lot of prompts here one try doing this with a different data set smaller data set even try doing it in 3D think about if you can make this a navigable space like how could I zoom around move in and out maybe I could hover over one and it would like link all the ones with a certain similarity score could I use like a force directed graph like maybe these things are connected with spring forces and the spring force is related to uh its similarity score there's so many possibilities here I would love I mean maybe I mean there are some of you somehow still watching this um what I'm going to do is I'm going to turn all this off right now and I am going to it'll take might even be till tomorrow although I I I I welcome help with this I will link from the video description to all of the code all of the Articles all of the stuff that I explained in this uh if you think it would be valuable for me to work with Mata who does video editing for the coding training to try to create this was now a 2 and a half hour 1030 11 2 and a half hour live stream I think this could probably get cut down to like an hour um um right a bigger uh right we could try this with I didn't get to start show you how this would look with the replicate embeddings model I mean that the the BGE large so there's so much more to this but I hope that you learned something this open your eyes to some possibilities maybe you're in ired to make your own version of something I kind of would like to do this with YouTube channels actually um so I have to stop I I have too many my my my brain is melted from building this whole example but um so if you want to engage with this more go to the codtracker if it's not there the video description for this live stream should be annotated with all of the links and code that you would need to reproduce this on your own okay uh thank you everybody I'm G to just put on the goodbye stuff and kind of I will put on um this little song here just to see if there's I'll take like one or two last questions um and let me just look at my message okay uh uh sorry I'm I'm like I'm like looking at uh my text messages which I don't need to be I'm just an IP oh Jesus Christ um okay uh I love embeddings the meaningful data thanks Dan uh is there a neural network from hugging face that knows the semantics of your words yes this is the idea of the embeddings models now I think we have to be very cautious about how much intelligence or uh we ascribe and how much we really believe that these models are perfectly encapsulating the semantics of our words they're you know all of the same kinds of cultural biases and issues that language models might have and how they predict and generate text all of those same considerations exist in the embeddings models however I do think it is is quite a tool a powerful tool to be able to work with data sets to create art with data sets to understand your data better um and there's lots of possibilities there for sure this song is much too long because no uh um but let me let me this let me just close out these windows to make sure everything's saved I'm going to hit stop recording on my recording to dis uh hopefully audio quality oh oh you know what okay oh no oh no okay hold on I think it's not a problem because yeah I the recording to dis audio was being passed through NV video broadcast so it probably has all that like popping and stuff in it but I do have the I could archive the audio from the stream and put it together so oops so that might that might make it a little more challenging but um okay all right goodbye everybody I will see you uh I don't know when sometime again I I I like doing this if you like just the live stream where I build a project like this and this is useful to you I'll be curious to see if this video has any life to it after this stream that's why I used to like anyway I don't need to go into all that right now just thanks for watching come come say hello in the coding train Discord and um yeah that's it as always I always forget that this this going to do this this to do this this this this do dot doet do dot dot do do do dot do do dot dot going to do do to do do dot I'm going to do do dot s this dot dot dot never forget this do this dot this dot this do never forget this do I'm going to do the this this dot this dot this dot the this Dot Song never forget the this dot somebody composed that song for me