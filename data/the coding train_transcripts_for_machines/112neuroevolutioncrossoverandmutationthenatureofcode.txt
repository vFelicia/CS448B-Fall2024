hello welcome to part 2 of my neuro evolution series where I am attempting to look at how I can train a neural network or more accurately a population of neural networks with a genetic algorithm I talked about this in the previous video which you could go back and watch if you haven't but the main thing that I want to do in this video is look at okay well if I have a neural network if I have a neural network how can I apply crossover or a mutation to that neural network so that will be the focus of this video I do sort of remember though I did kind of remember that there's a lot of stuff that I haven't talked about yet because one of the reasons why I use the neural network is to be able to give it some inputs and to get some output so that makes sense in the context of the dodol classification example probably but may not make sense to you immediately in terms of this idea of a flappy bird game so I will get to all that but right now I'm gonna focus on saying new neural network and you know what I'm gonna stick with copy like is that I'm gonna get to crossover in a future video I'm gonna stick with copy for simplicity and mutation so let's go back let's go over to the code and let's take care of that now let's start by having I'm gonna create a variable called brain and I'm use I'm in the p5 I'm using I mean using the p5 GS library though what I'm gonna do right now it's totally unnecessary for but because the flappy bird gained this program in p5 that's gonna be helpful later also I use it all the time so I don't need a canvas I'm just gonna say you know canvas and I'm gonna say brain equals new neural network now when I create a new neural network object if you remember the three arguments I need to give it and this is just for this particular neural network implementation it'll work differently if you're using you know say like a different machine learning framework like Kerris or somebody else's neural network library maybe you might want to look at deep learned Dutch is I will come back to that in a future video so I need to give it a certain number of inputs well all of a sudden now we're back to that question so let's actually not worry about that right now let's not worry about that question I'm gonna go back to that question and I'm just gonna make something up so let's take the X or example sort of like a trivial example of okay it has two inputs they're either true true true false false true false false so there may be two inputs let's just have a hidden layer with four nodes and one output so we can create some simple neural network and what I want to be able to do is I want to say let a cultlike child equal brain copy like I want to be able to say let me make a copy of that neural network and I also want to say something like child mutate so let me take that copy and apply a mutation in it mutation which is something I described more in the genetic algorithm video series so what this means is this neural network class needs to have two new functions it needs to have a copy function and needs to have a mutate function so let's go into the neural network library code this is the class there's a lot of stuff in here I have a way to many videos going through all this code luckily we can kind of ignore all of this and I'm just going to go down to the bottom here and I'm gonna say something like adding functions for neuro evolution now the truth of the matter is what is it that I really want to copy well if you recall the neural network structure is such that if there are two inputs and four hidden nodes and one output the neural network looks like this it's connections between the inputs and the hidden layer and connections between the hidden layer and the output and these connections the the sort of dials of the neural network the data of the neural network what controls how the information flows from the inputs and out through the output are all of these weights and these are stored in matrices it's just a whole bunch of numbers so I have a weight matrix which goes from input to hidden I have a weight matrix that goes from hidden to output and with each of these I also have this thing called a bias and if you recall the bias is something you know really all I'm doing in the end is like all of this really boils down to like hey there's a whole bunch of points I just fit into those points and the plastic could be like move the line a little bit up move the line a little bit down so that's really even though this all seems like fancy magic ultimately that's what it just boils down to in the end so I also have the bias for the hidden and I have the bias for the output I don't know I don't know what the best way to write the notation for this is or yeah so all of these things when I want to copy the neural network what I'm really saying I want to do is copy all this stuff so let me go ahead and so what I need probably is a function inside of all these are all matrix objects I need a function probably in the matrix class to say copy so let's start here and say copy and you know clone could be used and I want to make a deep copy I think not a shallow copy these terms get thrown around a lot in computer science deep versus shallow but I don't want to like just point to the data I want just giving my own version of all of those numbers because I'm gonna mess around with them and I want you to keep your numbers I want to mess with your numbers so instead of just saying like I I'm a new neural network can I just point over to your numbers I really want a whole version of those so and if we go back to here so things that I need to do is I need to keep track of these properties input/output the total input output and hidden nodes so I want to say let let's just put this in here so I want to say let input nodes equal this dot input nodes let hidden nodes equal this dot hidden nodes and let output nodes equal this dot I'll put in you know what this this is very poorly named this is sort of silly what I'm doing but I'm going to do it anyway input nodes this is very this is me this is how I like to code I like to make things as longwinded and as possible so that I can really think it through and explain it like all I'm doing right now is taking the properties of the neural net we're going to copy and put them into local variables why because I want to say neural network copy equals new neural network with what I have a better idea how to do this I have a better idea how to do this so this could this could work but I have a better idea so actually what I want to do is I kind of just want to say this return new neural network this now you might be asking me like I mean this is this isn't gonna be mad this isn't just gonna work but what I'm sort of realizing here is maybe I don't want to copy everything here what I actually want to do is call the constructor but give it a reference to the existing neural network and then have that constructor instead of creating a new new wait new wait matrices that are random it'll create wait matrices that are copies of the existing one in other words let me go back up to the constructor and look at this so what if so the constructor gets three things right a B I could just like rename these the parameters of the constructor function for a second and just call them ABC right a being the input nodes B being the hidden nodes C being the output nodes but before I do that what I actually want to say is is a an instance of instance of a neural network else in other words so what I want to do is if if I'm being sent three integers then I want to make the neural network the way I always have however if I'm being sent the first argument and this is this is kind of this is known as overloading typically in a programming language like Java if I had to overload the constructor like there's two different ways I could call the constructor I could give you three numbers to make a brandnew neural network or could give you a neural network to make a copy of yourself I would write two versions of the constructor but in JavaScript you can only have one version of the constructor but you can kind of check what you're passing in and just to be clear about this let me just make sure this instance of thing is correct so if I were to say let a be a new new neural network 4 4 3 2 just arbitrarily and I can say a instance of its without a capital instance of a string I should get false instance of a neural network I should get true okay so that's right this this of should be lowercase though if a is an instance of a neural network then what am i doing then I am saying this dot input nodes equals a dot input nodes like I can start right here's where if it's not a neural network I'm actually assigning it the numbers that are coming in if it is I can just keep going oh actually what am i doing I can say this and this should be hidden and now I can say this maybe I should have somebody has a suggestion for how to name these in a better way I just I didn't want to name them hidden input hit in output anymore because a could be either of those things so you know this this may be like to do document what a be CR uh output nodes that's a little note to myself that I don't like what I've written here and then now let's look at these so I'm not gonna need to randomize the weight matrices because I'm just gonna say equals what am I gonna do here a dot weights dot dot copy write what I want to do is say hey my weights are your weights and now my input to hidden weights are your weights and my hidden to output weights are your weights now is this gonna run I don't think so because I probably have to add a copy method to the matrix object but I'm getting somewhere now what else do I need I need the biases so I need to set the biases so the same thing I'm just doing a lot of like copy/paste stuff here so I need to set the hidden bias values and the output bias values okay so this is me creating this new copy of a previously neural network and then you know right now it looks like learning rate and activation function or at the even though I have different activation functions I can kind of write is this default was getting set to sigmoid its default is getting set to 0.1 so I probably should copy those as well I'm just gonna just be simple about this right now and just assume that my program is never gonna change learning rate or activation function I should that should be a to do to do copy these as well at some point but I don't need to worry about that right now and to be honest the learning rate isn't gonna play a role anymore the learning rate is completely irrelevant the learning rate is specifically a tied to the tied to the gradient descent algorithm which I'm no longer really using with the with the with the genetic algorithm that's what I'm doing now okay we're getting somewhere alright so just out of curiosity remember this is the code I'm making a new neural network and I'm let I know I haven't done mutate yet but is this even working is that was thereby did I maybe in some other universe happened to write a copy function already into the matrix class I seriously doubt it but let's see yeah copy is not a function so what this means is I need to also go into the matrix library and I think this this I think is worth having in here that's not just this isn't exclusive to genetic algorithms are neural evolution like so I'm adding this stuff you know copy and mutate and crossover will be here specifically because of genetic algorithm than the matrix I can the matrix object I can be a little S form about this so what do I want to do I want to write a function copy and what do I do I'm going to say let m equal a new matrix with this dot rows this columns so I create a matrix object with the same number of rows and columns and somebody in the chat I know is going to tell me there's some very fancy way that I could just instantly use some higherorder array function to copy the whole thing over but because I am Who I am I'm gonna say I'm going to write nice little nested loop I can always refactor this later I just know this is gonna work and I'm going to say m dot data index I index J equals this this dot data index I index J so this is manually me looping through the entire matrix it's a grid of numbers it's all the weights of the connection of the neural network and just manually copying them over one by one and I think this will work all right so let's see let me hit refresh there we go so does this work I have two neural networks they both seem to have two for one two for one you know I could go let me look at one of these biases now look at these values so this is bias H these are the values can you memorize those can you remember them let's go down here okay nope nope something is wrong so this stuff did not get copied guess what guess what I forgot I forgot something quite important in this function I did not forget to return the thing that's new but in the matrix I forgot to say in the return n so this new matrix that I'm making I've got to actually return it I made the copy you can make the copy you can take the reservation but you can't hold the return of the copy and I'll sign the full Seinfeld reference for all of you I try should have said that it'd be more interesting if I didn't say that okay so now I can look here and I can see okay look at these numbers memorize these numbers this is the way I actually let me look at I'm just gonna look at one of the biased ones this will be a little bit simpler so here's the bias bias H has these values memorize them memorize them I could write a nice unit test to actually see if this function worked I'll be much better but this has been I ball it 0.20 eight four one five yep these look like the same numbers same numbers say members so I'm gonna just choose at the moment to believe that this worked this is probably a bad idea but this is the reality of what I'm going to do and I'm okay with that so let's move on so we have now implemented copy what I next need to do is implement mutation now I do need in order to do mutation I need to have something called a mutation rate and that mutation rate is essentially a probability of how likely it is for each element of every of sorry each element of every sort of DNA to alter itself randomly when that child DNA is made so what that means in this context is for every single number that's a weight in these matrices for every single number that's in the bias there is a say 1% chance point five percent chance 10% chance then I'll pick a new random number I could also with mutation like nudge of the values so sort of picking an entirely random new number I could like push it a little higher push a little lower but for simplicity right now let's just pick a new random number so what do I need to do I need to go back to neural network J s and I'm gonna add a function called mutate and what am I going to do here I'm going to say there are four things that I need to mutate so I'm gonna say let's think about this what are all those things called there's I just got to go back up to here there's weights ih weights H Oh bias H bias oh so I need to say what I need to do is say weights I'm gonna map a mutation function so remember there's the the V sorry I'm also not able to type the talk at the same time so if you recall the matrix the matrix library has a function called map and what it allows you to do it's a little unfortunate that there's also a JavaScript native function called map which I'm using everywhere it allows you to apply a function to every single element of the array so I can pass in a function and apply it to every single element of the right and the function that I'm gonna pass in is mutate so let's write this function now and it's going to get it receives a value but to be honest I don't care about I I do care about what the value is if I were planning to nudge it higher and nudge it lower but what I'm going to do right now is I'm just going to return a random number so let me actually I sort of for that should probably link these better in some way but when I have this function called randomize and this is the kind of random number that I'm asking for so I am going to just return this ah but am I always going oh I do need the Val guess what if I do this it'll completely randomized every single element so this mutation function needs a mutation rate and what I'm going to do is I'm gonna pick a random number if math dot random is greater than or less than the rate right so only so let's say math dot random will give me a number between zero and one so if the mutation rate is 0.1 that random number between zero and one will be less than point one ten percent of the time otherwise stick with the same value so this is now the function that I want to apply to every element of all of the weight matrices I want to say hey mutate these weights mutate these weights mutate these biases mutate these biases and perhaps there's a more elegant way to write this and I will consider that all in the future with your many comments and pull requests and complaints I look forward to them but this is what I'm gonna leave it at right now so let's see now if what I can do if I go back to this particular program and I say child now just out of curiosity I'm gonna say child mutate one so I'm giving it a mutation rate of one which means everything should be completely random and what I'm gonna do just just as a kind of like a way of testing actually is I'm going to change this to I'm gonna multiply it by like a thousand just cuz I want to see like totally different numbers to see that this is working so I'm gonna go back and I'm going to refresh the code weights i H is not defined oh right I forgot about that this dot that won't surprise any of you you've probably been saying this in the chat all along there we go so let's take a look so here we have once again the biases they're all reasonable numbers between negative 1 & 1 which is how I started the neural network and now if I look at the child neural network and I look at the biases we can see yep so that mutated now let's change the mutation rate let's change it to 0.5 so we have kind of I mean we're not going to get exactly 50% of them because it's supposed to be random but we'll least see some of them didn't you take some of them did so let's change now the mutation rate to 0.5 just to see that this is working this is instead of me writing unit tests manual unit testing let's look here we can see wonderful here's some original values and now let's go down to here in the child object and let's look at the bias ease again and we can see hey it actually worked out exactly as planned it mutated 2 of them and didn't you take two of them which is what a you know most commonly with a 50% probability we're gonna see and I suspect that if I go into the output bias oh the alpha boys just has one value it didn't get mutated right because this is such a simple little neural network if we go into these weights we can see you know 3 out of 4 got mutated I think it's working so we are in good shape here we now and so I want a probably the actual mutation rate I'm going to want to use something like 1% because I want to do it pretty rarely but we now have the ability to both copy a neural network again as the next if you're watching this and the future videos of this tutorial aren't released yet or if you don't feel like watching them just yet try as an exercise to yourself go and implement crossover how could instead of instead of copy could you create a new neural network that's a mixture of all these weight matrices that would be a really interesting thing to try I will do that hopefully in a future video so I've got copy I've got mutation I've got the flappy bird game I've got the neural network library I've added cross or mutation so we're ready now we're actually ready to implement the genetic algorithm I'm going to say this twice I'm someone in the chat pointed out that the neat algorithm evolution augmented topology things refers to a very specific implementation of neuro evolution in a specific paper and obviously being much more informal about this here so technically it's probably isn't the neat algorithm and maybe I'll mention that the beginning of the next video just to emphasize it a bit more alright thanks for watching and I will see you when I continue you