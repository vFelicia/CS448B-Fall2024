all right so in the previous video I went over how to calculate the error in a supervised learning system right the error is just be known answer the system's guess then what I did is talk about well how can I take that error and move it backwards through the system feedback words instead of feeding the data forward to the network feed the error backwards and the way that I can do that is by looking at like JIT each of these contribute to that error let's kind of like make this error like a portion of that error and these were the formulas that I went through right look at this this neuron hidden neuron is connected to this output this is the weight how much is this way to percentage of all the other neurons that are connected it's just two in this case so it's just the sum of these two but there could be many more so what I want to do in the code now is actually add this training function where I send in input data to the network with a known answer and have the training function calculate the error so calculate this basically I want to calculate this vector e1 e2 and I sent vector but this matrix one column matrix that's what I want to calculate that's going to be a really easy part so let's do that first alright so actually I say in a previous video I sort of set up this function I think right this is this is the feedforward function where I just take the inputs and I feed them forwards and return the output here is a function where I take the inputs and get an answer now ultimately I should just be able to use the feedforward function right I might have to tweak this but on the one hand I should just be able to say I should just be I'll say let output equal this dot feedforward inputs no reason why I should be able to do that and then now what I need to do is calculate the error so the error is Error error equals the target so answer maybe I should call this target targets I'll call a target it might be plural right there these are the target output that I want targets outputs so let's call this outputs again the first example that I'm gonna build is gonna have just one output but I want the system to work for as many outputs as there are so in theory I should be able say let error equal math dot subtract targets comma outputs now this is where we get a little bit into the weeds here if I'm not math matrix I didn't even know if I've implemented this function in my matrix library so that's why I need to go and check but this is where we're kind of like oh my goodness if we're only we're using numpy we just use and it just works or maybe there's some other highly optimized javascript matrix math library that will do this for us I'm gonna get to all that yes deep learning is is coming but right now I just want to do this in my code now here there's a little bit of awkwardness here this is an array so this comes out as an array I actually want that to be a matrix so it's a little bit awkward but I'm gonna say outputs equal outputs dot Oh matrix from array outputs so this is me convert convert array to matrix object and then the targets I probably the user is going to send that in as an array so I'm also going to say targets equals matrix from array targets so this is a bit of awkwardness because of the way that I developed my library that probably some day in the future I want to like refactor or rethink but I need to have those things be matrix objects for me it will do this matrix subtraction now let's check the let's check the matrix library I believe there's no subtract function there is an add function which adds to the alright so this is so silly the way that I'm doing this because I probably in a real world if I were really big thoughtful I would make a comprehensive major library that has every possibility that I'm just gonna put it in there what I need so what I need is a static subtract function and I'm gonna have another I'm gonna call it other for the other matrix oh no no matrix a and matrix B so this should return a new matrix a minus B so a couple things one is if the rows and columns aren't the same I mean I want to do this element wise right basically if you've forgotten what's going on here basically I have I have a matrix like this which has these guesses 0.7 0.4 and I want to and I have the known answers 1 0 and I want to take this matrix minus this matrix to give me one that has 0.3 negative point 4 so let me add a function that does that it's too bad I didn't have it for before and I should do some error checking here like check if the rows and columns are the same yeah I'll put that in later I'll put that in later gotta kind of move along here so that'll be in there maybe when you look at the code someday but I'm just gonna say I'm gonna do a first I need to make a result which is a new matrix which is a new matrix that has the same number of rows and columns as either of them I think it called rows and columns right so I need to make a new matrix as the same amount and then I'm gonna use my very subtle silly loop function that I use over and over again to loop over all the elements and just say the result dot data index I which is the row index J equals a dot data index i j b dot data index i index j right so this is we just going through and subtracting everything from one to the other and then i can return this result all right so I had this static subtract function is it silly to have a subtract function when I use have an odd function that then you know add I could be used for subtract by just saying like multiply that whole matrix by negative one but whatever I'm just doing I'm doing it as I'm doing it we'll refactor later all right so now let's think about this I'm going to comment this out and I'm going to say these are my inputs now I'm gonna have my targets and in this case my neural network is two to one so I'm gonna keep that my target is just one I want to get one now what I'm going to do is I want to say neural network instead of feedforward I want to say train with these inputs and these targets so let's just run the code and see if I get any errors then I'll debug the actual output so let's go to the browser where I've kind of got this coach runs output is not defined sketch is line 11 oh there is no output now hey no errors everything thank you I'm done I forget about the thrill network stuff I get it yeah I have more to do I'm afraid to keep going but I'm gonna keep going let's just look in the training function and console.log the inputs the targets look let's just console.log the air actually I just do arrow dot print sorry so I can say outputs dot print because I have this print function and targets targets dot print and error dot print so I just want to look I just want to examine all these things or I got an error oh error dot print all right so ok something went wrong so this is what did I this is the output this is the target this should be the difference so what went wrong here within my subtract matrix dot subtract target's common outputs let's look at this function something must be wrong here all right here's the mistake this dot rows this columns that makes no sense I make I'm writing a static function that's not called on an instance of a matrix object I want to look through everything I've got to look through everything in result or a and B they should all have the same number of rows and columns thank you to Reuben in the chat who pointed that out to me okay result dot rows result columns all right now let's run this again great this looks right this is what the neural network produced this is what it this is the known output and this is the this is the error and just to just to take this one step further if I were to have two outputs I don't know I'm not and and have a second target this is matching what I've drawn over here we could see these are the guest outputs this is the target and these are the errors so we have now written into our code all of the pieces we need to get these two errors get the air the output errors the next step we need to do is calculate the hidden errors I need to calculate the hidden errors so looking at the code I need another step here I need to now say let hidden errors equal and figure that out so what goes here what goes here this is the and I suppose if I'm being consistent I should say errors there right errors are the out pen and and if I'm being really consistent I should say output errors now what I need to do is calculate the hidden errors okay so let's go back to here and I want to do this with matrix math so this looks like hey that could be some matrix math going on here right this looks like a weighted sum or something dot product e like looking thing here's the trick this looks good right but what's all this like fractured stuff well if you look at this this is the same as this this is the same as this these are really normalizing dividing these weights by the sum of all the weights is a way of normalizing everything so they all add up to 100% but in the end we're gonna kind of like multiply everything by this learning rate constant anyway so we could say like make a big step or make a small step so that normalizing of it kind of doesn't matter I mean it's imported important but we can also ignore it and that's kind of a trickier we're gonna just take out the we know we want the amount of the air to be proportional but the fact that we're multiplying by its weight it's going to be proportional we don't have to divide it by the Sun so we can actually take the bottom out and I'm gonna say wait one one here I'm gonna say wait one two here I'm gonna say wait to two here and I'm gonna say wait to one here and look at this by golly doesn't that look like some matrix math right that's got to be the result of some matrix product now I need more space on the whiteboard so how can I do is kind of condense this a little bit well one one times e 1 plus weight of 1 times e to make this take up less space and then weight 1/2 times e 1 plus weight what was that 2 times e to now conveniently I have this matrix here and what matrix would I put here to get this right if I want the matrix product of these two matrices I need to put a row in here that's right the row this row W 1 1 W 2 1 the weighted sum the dot product of this row and this column is exactly this now let's take this 1 1 2 and wait right take this dot product with here boom we've got this this matrix product the matrix product between these two matrices is that hidden errors coming out of the hidden layer this is really exciting but there's something really strange here it's like stare at this now all along I keep getting my indices wrong right I've been getting my indices wrong in these tutorials I had to do the tories over again and this might look wrong right because shouldn't it be wrong column row column row column row column this is Row one how eyes are there looks like I got it backwards well the fact is I did get the backwards I got that backwards on purpose this is actually this weight matrix transposed so these weights are stored in a matrix already in my code that matrix looks like this weight one one weight one wait one weight to transpose this matrix miss and take the dot product with the heirs and boom I've got the hidden errors coming out the good news is I believe in the matrix library I already wrote a function called transpose here's I should be consistent this function transpose returns a new matrix that's the transposition of the previous one and so I should actually make this static and it should require to receive a it should receive some matrix object and so it should be this so I just changed this to be a static function so that what I can do is I can say here back in the library what do I need to turn suppose I need to transpose the weights that are going from hidden to output that's the weights H of so I have this dot weights H oh so let hidden um weights H o transpose T for transpose hmm I could also just change the let Hootie these are the way naming I could use some work on the naming but these are the weights from hidden to output transposed equals matrix dot transpose this dot weights hit an output so the hidden errors now should be matrix multiply output way what did I say we look over here matrix multiply that transposed matrix and those errors that transposed matrix and the output errors so this is calculate the hidden layer errors now if I were writing a proper library that could support multiple layers there'd be some kind of loop going on here because I keep doing this from layer to layer to layer but since I just have this two layer Network I'm just gonna do the output layers I'll put errors and the hidden errors so that I can sort of get this back propagation thing going in just one step I'm getting a nice comment from the chat I was worrying about the dimensions of my matrices and Caitlin writes the dimensions work out when going backwards the transpose right of course because I was worried about the dimensions not working because you know the rows and columns have to match properly when you're doing matrix multiplication but since I'm now going backwards it actually makes sense that the matrices have to be transposed you can pause and think about that for a second but that does make sense now ok so I think I've come oh and I was also but you know if you're looking at this notation in like a textbook or something you'll often see if I have like if you have a weight matrix that's W and maybe it like wi j for rows and columns you'll often see T in the superscript as and you can't see that write it over already over here right you know if this is the weight matrix W and you have columns and rows then you'll often see a superscript of T and that refers to this this matrix trans transposed and so maybe this would be you know weight h.o.t or something so my notation is as you all know is kind of poor but I try to do my best to explain it hopefully it will match up with other other notation that you see in that sort of thing okay so this is now done in terms of back propagation I've computed the error I've computed the I've propagated that error backwards to compute the hidden layers error and now I just need to add the part where I adjust all of the weights these weights based on this error and these weights based on this error and then we just move on and then we're done so I'm gonna do that in the next video I should warn you that the math for doing that is this which I'll discuss in generalities the math of gradient descent for finding these Delta weights is pretty complicated I have two videos that I've made where I kind of do something similar which I will reference as well as all of those three blue one Brown videos that go through the math in detail I'll probably start the next video just by presenting the formula and then implementing kind of talking through the pieces of the formula and then implementing that in code okay you