sorry where'd you go hello computer mouse conference attendees maybe some viewers from the coding train i don't know why are you watching this video i'm gonna try something new i would like to invite the computer mouse to be with me out here in the garden with my desktop i just realized i forgot my train whistle but let's take a trip you and me and explore what it means to learn with the mouse so where do i want to begin 40 years ago a man named douglas engelbart created what he called the xy position indicator for a display system or more commonly as we know it today the computer mouse he presented it in what is famously known as the mother of all demos and so much of what we take for granted today every time we interface with technology can be traced back to this original demo perhaps a little bit less known was that a few weeks before engelbart's mouse was demoed to the public the german company telefunken presented the first official device that displaced a cursor on a monitor this invention was called a roll hugo i'm not sure if i'm pronouncing that correctly but that directly translates to rolling ball and it is just the cutest most delightful rolling ball i have ever seen over the decades the mouse has changed fundamentally in terms of its design in terms of how we the human beings here in the world use the mouse and interface with our computers and here i find myself today at an actual conference all about the computer mouse itself thank you so much mn ashley for inviting me i'm really thrilled to try to do something a little bit out of my comfort zone here i have a bunch of demos to show but ultimately i want to take the question presented by the computer mouse conference itself the fundamental question of computer mouse scholarship and explore it what is it exactly that the mouse sees and how does that shape what humans come on see come on come on come on i want to begin this journey with the image of a mouse itself you might have seen in the news or on social media lots of examples of this blank does not exist or perhaps this ai dreams about cats and it'll haunt your nightmares and you might be wondering should you be worried i mean i'm a little bit scared i have of nightmares i don't want to have nightmares this blank does not exist typically refers to the concept of synthetic media and there are lots of different kinds of techniques to generate imagery but what is grabbing all the headlines today what you're often hearing about is something called a gan or generative adversarial network a gan is a system of two neural networks one is known as the generator the other is the discriminator the generator is just making images generate images images images images maybe it's trying to create images of mice the discriminator's job is to look at an image made by the generator and compare it to a lineup of images of real mice this is the training data set actual photographs of mice from the real world only that discriminator doesn't know which is which it's got to make a determination if it can guess correctly which one is the fake the generator has to go back and try again and it tries again and back and forth this is the a in gan adversarial these two networks are pitted together against each other in a game of cat and mouse if you will early gans produced fuzzy low resolution images ones that aren't very realistic into the human eye are quite distinguishable from real images however over the years these synthetic images have become more and more photorealistic in december 2018 nvidia researchers released something called stylegan a novel technique for generated images with finer control over the style of the image itself in 2020 further improvements were made to this model known as stylegan 2. and this is where i find a really big challenge i can't help but get really excited by this technology and think about the possibilities that sort of like magic output of these pretrained models and what doors they might open when placed in the hands of artists creative people people like who i'm imagining are watching this video right now however it is absolutely critical that my enthusiastic sharing of how to generate your own synthetic images be tempered with a really serious look at the harmful unintended and sometimes rather unfortunately intended consequences of this kind of technology machine learning models are making decisions for us impacting our daily lives all the time there are countless examples of deeply ingrained biases of harm that's being caused this harm disproportionately affects communities of color and other misrepresented identities synthetic media is being used on a regular basis to spread misinformation so here's just one example of a generated twitter profile pictures of fictional amazon workers who love working at amazon and this was used as an attempt to prevent the unionization of workers still there is beauty to be found and much to be learned by these ai dreams as evidenced by a global diverse array of artists and activists making thoughtful impactful work with the new technology these synthetic artifacts can help us to dream and see the small beauties of life take as an example helena sarin's leaves which showcase intricate outputs of a model trained on the colorful leaves fallen in her backyard others like dr nettress r gaskins use a related technique called style transfer to generate portraiture drawing inspiration from other generative techniques and treating the imagery with neural networks these are beautiful examples but ai dreams are often just so ridiculous that they can also bring laughter and levity to our day take for example this foot does not exist by the collective mschf as well as bivalent friends created by golon levin and ling donghuang so who am i to just make some absurd style gan mice i don't know but it's my hope that if i share this technique with you the creative and beautiful people of the world you can educate others spread awareness share your artistic vision and affect positive change so here's how i trained my own stylegan mice to simulate the machine dreaming of the computer mouse and to be clear there's no actual dreaming going on here machine learning these ai dreams really boil down to just numbers and spreadsheets and those spreadsheets being you know multiplied together a lot of times i began by first collecting a data set of mouse imagery so i scraped from flickr i scraped from google images and honestly i just i took a lot of pictures of mice i've been buying some off ebay making a collection and just taking lots of pictures of them from multiple angles using runway ml i uploaded the entire data sets of their servers and started the training process runway makes this process of training a stylegan model easy so first it's got a cloud server that just has all the configurations set up for you so all of the time that you might be configuring your environment and setting settings and trying to like get your machine learning gpu system to not throw an error runway handles all of that for you but even better than that runway has a set of base models from which to train so it would be you need a much larger data set and much more time to train a style gain model from scratch but in this case i started from one trained on objects mostly cars and so without starting from nothing i've got my synthetic mice in no time really just about an hour once the training is complete i can execute the model in runway itself and browse what is known as the latent space so the latent space refers to the universe of all possible dreams the model might have about these mice it's essentially a really really really big graph in many many dimensions when you see a dreamlike sequence of morphing synthetic imagery what you are really seeing is a walk through that latent space anna ridler's mosaic virus is a wonderful example of a walk through a latent space of beautiful flowers what's interesting is how you choose to make that walk and in anna riddler's piece that walk is directed by the price of bitcoin runway ml also has a feature where you can host the model that you've trained so once i've hosted it i can then write my own program to request images and i can make the walk happen however i want what i chose to do is program a node server that would request these images and then a processing sketch that would ask the node server to request the images and the reason why i wanted to use processing is i love this algorithm called open simplex noise it's a wonderful way to smoothly navigate the latent space and by calculating the noise in processing sending the results to node node getting the image from the server then back to processing i'm able to render what i'm about to present to you my short film entitled computer mouse dreams and uh just in case you know i did throw in a couple real mice in there so hopefully this is not gonna haunt your nightmares sorry and there we have it cat versus mouse score one for the mouse but i think i might have jumped ahead maybe done this out of order here i am using generative adversarial networks two neural networks pitted against each other in a fiery battle to generate synthetic mice let's take a step back what is machine learning what is a neural network and can the computer mouse help us to understand the answer to these questions gloria come here kyle mcdonald in his 2018 kik festival talk weird intelligence defines machine learning as programming with examples not instructions so what does this mean exactly programming with instructions is like me attempting to explain and provide instructions to my children on how to do something code works the same way only it requires a highly formal and very specific syntax and generally speaking code tends to listen to me here's a beginner example from my tutorials on conditional logic this is something that you learn in the first couple weeks of learning to code if the mouse's x position is on the right hand side of the canvas or greater than 200 pixels draw a red background else or otherwise if it's on the left hand side less than 200 pixels draw a blue background programming by example works differently instead of you the programmer writing the explicit instructions you show examples to the machine itself and say hey why don't you based on these examples learn what those instructions should be to reproduce what i'm showing you but i can't just show the machine something in the case of machine learning what i really mean is take a data set of examples of inputs paired with outputs and feed those into a particular algorithm so that the machine learning system can learn the instructions to reproduce those same outputs with those inputs a collection of example inputs and outputs is what is known as a training data set and probably one of the most famous wellknown training data sets for machine learning is something called mnist or modified national institute of standards and technology database a large database of handwritten digits that is commonly used for training various i don't have the next page training various image processing systems personally i'm a fan of a twist on that there's a data set called fashion mnist which is an alternative database it has 60 thousand example images of shirts and pants shoes and more all paired with a label so if i want to demonstrate image classification i can show a machine learning system here's all of these fashion mnist examples here's what their labels are now could you go look at some real clothes and correctly classify them but what is the algorithm that we're giving these examples to while there are many machine learning algorithms and sometimes these are called recipes the n in stylegan stands for network or more specifically artificial neural network a computational model based on the brain and probably what is the most popular machine learning recipe being used in today's modern socalled ai systems oh i got it that was really good back to the mouse interaction i've written code very specific instructions for the computer to follow could i reproduce this exact same result but instead of explicitly writing the instructions just create a data set examples of what are some points that happen to be on the left hand side of the canvas versus on the right hand side of the canvas i love this example because it's kind of ridiculous it's very silly and trivial i'm asking a big fancy neural network to learn one of the most basic things that a beginner coder learns how to do when learning to program i find this to be a great entry point into machine learning i can demonstrate the entire machine learning pipeline see it from start to finish with something so obvious that it's very easy to test the results and understand all the pieces of what's going on and figure out whether or not it's working so let's put this into practice i'll use the ml5.js library built on top of google's open source machine learning library tensorflow.js it has a neural network object ready to go first step is to collect training data i can write a quick p5.js sketch that collects data through mouse clicks click on the right hand side of the canvas a bunch of times then on the left hand side all the while making sure to pair those clicks with the correct label now it's time for me to configure the ml5.js neural network i just have two inputs the x and y value of each click and i should note i don't actually even need the y value so that would be another version of this that doesn't bother to use the y and one output a classification that has two discrete possibilities left or right next i call the train function and this is what is known as supervised learning the neural network for each data point makes a guess left or right if it makes the correct guess it doesn't have to do anything just move on to the next point if it makes an incorrect guess there's an error and it can go back inside of itself and just all of its weights and parameters and various internal mechanics to try to get the correct answer the next time over and over again we go many many times with the data every time i send all the data the training data through the neural network that is one epoch the amount of times the neural network has gotten things right or wrong that's all summarized in what's known as a loss function the lower the total loss the fewer the mistakes the loss is going down during your training things are working as planned once the model is trained i can go back to that original if statement take it out and replace it with sending the xy position into a neural network and getting the output from that neural network same exact thing this time neural network classification the fun thing about this is i can start to play with all different kinds of delineations i don't have to just look at left versus right maybe i look at a circle maybe i have sort of like a fuzzy collection of points and ultimately the question i want to ask of you is could you reproduce every single mouse interaction we take for granted that is generally programmed with instructions with machine learning and neural networks so this is the example i use in my introduction to machine learning for the arts course in my video tutorial series about ml5.js i hope that it's helpful i'd be curious to hear your feedback on how how you imagine teaching machine learning uh with thinking about programming with instructions and programming with examples and i also want to give a big thank you to dr rebecca freebrink her work um building the wekinator project another tool for machine learning and all of her examples of interactive machine learning for design systems was a huge inspiration for these examples and the ml5.js project itself gloria now that i've demonstrated how the machine can dream about the mouse how the machine can be trained by data from the mouse i want to explore what can the mouse teach us about ourselves the human beings and how we use the machine physical objects show signs of use over time wear on a piece of clothing or a desire path cutting through a patch of grass whatever the landscape design says about how to get from point a to point b we're going to go the most useful and direct way technology shows this kind of wear in hardware f1 keys are sometimes removed command keys are worn down similarly faded patterns on a mouse pad can give indications on how the mouse itself moves where can we see this where left by our digital presence the mouse is an extension of the self in the digital space which is easy to forget char styles in her sketch nails doesn't let you forget this as you physically grimace and wince scratching the mouse as nails across the screen which has now become a chalkboard in maya man's can i go where you go maya frees us from the limitations of the mouse as agent of the body and the whole body is able to act and move freely in the digital space in do not touch by the amsterdambased studio moniker realtime cursor movements of hundreds of users are collaged into an interactive crowdsourced music video a collaborative symphony of pointers i began my own exploration of these ideas by writing a processing sketch to collect mouse data over long periods of time i was teaching writing emails endless and endless and endless zoom meetings creative coding libraries like processing and p5.js they have built into them mouse x and mouse y variables but you can't actually use these variables they limit you to the pixels of your graphics display window or canvas themselves processing in case you didn't know is built however on top of the java programming language and you have access to all that there is to do with java itself and one of java's classes it's part of the awt package or abstract window toolkit can both track and control mouse movements in real time across any use of the operating system or any application whatsoever so i wrote some code to collect and save all of my mouse pointer positions into a csv file csv stands for comma separated values it's a very standard data format that you can easily reload into all sorts of other things like a spreadsheet you can then take this data and visualize it in a myriad of ways time lapse animations heat maps i tried a few different ones with all of these mouse movements saved i could also use them as training data i can analyze the probability of any moment of the mouse going up down left right and replay a sequence based on those probabilities with something known as a markov chain i could feed this data into something called a recurrent neural network a kind of neural network that's very well suited for sequential data time series text music vector paths there's a wellknown machine learning model called sketch rnn that was trained off of the google quickdraw data set to generate doodles of all sorts of different types of things and i can take the results of that recurrent neural network trained off of my mouse movements to take a nap and let it just take over and control my computer now i didn't include mouse clicks in here well although i could have this way i just you know i'm safe and i'm not going to end up you know who knows what nefarious business the sort of dream version of my recurrent neural network mouse controller might get itself up to thank you so much for spending your time with me at the 2021 computer mouse conference for indulging me in this experiment i have learned a lot about what it means to operate a camera frankly to try to work with a script and i've really enjoyed having the opportunity to sort of put this set of demos uh together for you um i've made all the example code from this video available for you it's at thecodingtrain.com mouse learning and i hope that you find some inspiration to explore dreaming learning and teaching with a computer mouse and that you will share it with me thank you to emma and ashley and everyone who helped put together the computer mouse conference and i will see you sometime later that's my ending gloria come here how did i do it yes no no no no yes help me come in go come on come in yeah okay you