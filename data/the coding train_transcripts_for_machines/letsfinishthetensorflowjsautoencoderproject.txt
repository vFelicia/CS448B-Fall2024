do so do do do check one two hello this is my voice i'm about to get started in approximately two minutes uh if you could if you're in the chat you could let me know that the volume of my voice is coming through and if there's any static or any other issues i should be aware of thank you very much and see you in just a minute or two ugh hello my buttons aren't working properly that's usually the first thing i like to say here on uh when i start a coding trade session good morning happy sunday oh i was all ready to speak and then i pressed the button to bring me live and then i did not show up live and i got completely flustered but i realized actually now that i look at this i was just pressing the wrong button none of this matters let's just give this another try can we please okay going back to here putting the music back on take two everybody hello good morning happy sunday welcome to the coding train my name is dan i will be your conductor for today's journey and um this train has been going for a very long time it was paused it was stopped in the station for at least a week now uh it but we're we're we're put shoveling the maybe this is this an electric train we had solar panels on the roof i don't know yet um but i'm getting it going again today and i'm going to be returning to this project that i've been building which is uh an auto encoder now if that term auto encoder means nothing to you don't worry i will give a brief kind of fiveminute sort of catchup summary over what i've done in the last couple sessions before before i dive right into the code um but before i even get to the project that i'm going to be building today let me just say hi are you a new viewer i see that i have a new member who just joined this is very exciting this hasn't necessarily happened in a little while it's michael michael thank you for joining the coding train membership program for your membership you will receive uh thanks for me at this very moment because i'm just speaking and i saw your name and i'm talking about your name that's probably not why you joined it shouldn't be why you joined access to some member discord channels for support on your code we'll send you some stickers in the mail all of those things ah but before before i go too far uh we must um dedicate these random numbers that i'm about to read we're just going to start this project over everybody it's been a rough year it's been a rough two years it's been a rough 48ish years for me actually hasn't been that rough i i i things i i have i have it very good i i can i i cannot complain um but um i have been uh my i'm on a quest uh many quests one of which is to read this entire book a million random digits with 100 000 normal deviates probably if i had just like started doing this when i started making videos i'd be done by now but no i've tried and then i like do a different system then i change the system again we're going to just 2022 it's all twos with a zero it's a new year i we're going to start this book over but for right now we're going to say thank you to michael and reed from page 113 row 5620 i'm going to read these digits 51940.44169.83459.8888 oh my goodness that's crazy i gotta show this to you this entire book of random numbers it's not an anomaly let's see can i uh there's no light over near to the camera but i'm trying to i don't even remember where it is now here it is look at this look at that sequence is it gonna autofocus on it it's a little dark eight eight eight eight eight eight that's amazing um zero seven seven five two two three two one one two six two six zero zero eight six nine three two nine three six eight nine nine nine five six and uh michael your random number for you your personal number is 99599956 that's page 113 the end of row 5620 uh if we can if i can continue to get my act together some of you have received these um many of you have are waiting but um for the members uh your own very own custom uh train whistle with the coding train laser etched on one side and then a random walk pattern generated with the random numbers in this book uh from your own personal position and number uh is um is what i'm offering we're gonna we're gonna be making a lot more of these starting in january and please join the discord everyone you can find out more all of that stuff there and yeah so um what's next ah let me thank today's sponsor brilliant do you like learning do you like interactivity do you like the holiday season and not know what to get somebody uh you could get them a subscription to brilliant so brilliant i'll come back i have a whole bunch of courses in math and science and interactive lessons and computer science so many things that are just in like complete alignment it's like there's another train that's got the words brilliant on it that's just chugging along alongside a parallel track to the coding train so i'll come back i'd like to do i like you know huge thank you to brilliant for sponsoring the coding train and what's wonderful about it is i get to open up brilliant around the middle of the live stream or taking a break and go through a challenge or a lesson in a course i will do that later but you can sign up for free at brilliant.org codingtrain lets them know that you found brilliant from me the coding train i'm not the code am i the coding i don't know that's another discussion for another time no need for the sort of like metaphysical philosophical quandary that we are am i a train am i a human who knows do i have legs yes a little bit stiff today um uh and um yeah oh oh if you want to unlock all the premium stuff and all the courses uh or or you can give it as a gift you will get 20 off the first 200 people to do so from this link all right now what is happening today first of all my glasses are very dirty and i'm going to uh untuck my tshirt here and clean them off i wore some special clothes for all of you today on a sunday morning i was like let me find my shirt with flowers and my uh cardigan is this a cardigan is that what you call it nice sweater it's cold but i've been running the heat all morning in this garage uh you notice that if you're hearing me and seeing me without interruption the internet is hopefully working here in the garage it is not yet solarpowered um within the next two to six months i will be uh installing i'm not doing this personally but uh solar panels are being installed all on top of this garage where i am hopefully powering all the lights and the computers in here um so i'm excited to sort of see where that leads and talk about that as i go my my um desire to have the coding train you know to the extent of the things that i can control that are in here powered by solar energy uh um and kratos says it has been a while since the last time i've seen his video i think it was before he got his news to new york well boy do i have news for you uh hopefully this is gonna stabilize and i'll be uh broadcasting from here for at least the next year plus probably two years but i am in a new location yet again and mostly i have things going this is what i really want to work on this oh and it's out of focus this um i like to do a lot of diagramming and things in my videos and live streams let's see if i can focus this uh that's hopefully better um but i'm still sort of working on what whiteboard do i want to have how do i want to do diagramming and all of that stuff so coming back over here um all right so let's get going um actually actually before i go into the auto encoder project i i have a bone to pick with you audience i mean it's probably my fault so it's really not on you it's on me but i want to come over here and i want to talk about the fact that i have this video slit scan time displacement effect challenge i believe if you i don't know what happened to the code here on this page uh maybe that's why oh i have a bone to pick with me i've caused my own uh problem here no wonder oh why didn't anybody say anything to me let me let me just do this for a second yeah all right i messed something up here so let's let's see if we can remedy this right now um i think i um i don't know what the issue is and maybe somebody who's watching can do a pull request but let me at least remedy it for you for the year so this my bone that i was going to pick what is where did that expression come from i don't know it sounds kind of i i need a different one i don't like it anymore i want to pick anyone's bones i don't want my bones picked no picking no bones picking please but this is what i wanted to discuss this video came out and i know i'm slow and there hasn't been as much content recently and maybe there's not as many things for you to riff off of but i felt like this slit scan time displacement challenge coding challenge exact set of examples was ripe for creative twisting by you the beautiful passengers of the coding train to make your own special version of it and share back with me this is what this is what i'm here for what i most enjoy about doing the coding train but it seems like there haven't been made any variations first of all i i gotta really work on my language here on the website coming soon based on this coding challenge by the community yet be the first you could be the first and add your own there's a link there that will show you where to add it if you don't know how there's a guide there's a video with me talking about how to do it and even better coming in 2022 there will be a form on the website that you can use probably to just submit um i want to still encourage people to use github and github pull requests as their first foray through the coding train um and to get into that world but um working on some improvements for how um but i i'm realizing now that the code should be on this page and amir hussain says i've just done double pendulum did you submit it please submit it submit it let's see if there's let's see what the most recent community and i uh community contribution time let's see what you the audience have made most recently based on the videos that i have produced here on the coding trade so and then let's find where that code is for that video i'm gonna go to github.com codingtrain website um oh look pull requests there's some things here a lot old stuff not oh okay i'll have to come look at this but let's look at closed yeah nothing nothing 14 days ago the last contribution here we go the last contribution from david beale to the diffusion limit again this is on me i just have not been as present and uh in the sort of like ecosystem of the coding train um so that's you know i'm just kind of like make it through this year and and start a new in 2022 but that is my new year's resolution you heard it here first figure out ways to get more people contributing their own versions um you know um is it raphael who does the like creative coding weekly challenge that seems to be very successful i'm sure there's some things i can learn uh there but let's take a look at this one from david beale so um we can just see it here but i um just so you want to if you want to know where it shows up if i go to here and there it is 3d dla by david beal okay fade out this music let's take a look at this thank you for your submission whoa oh and i love that this is a youtube video cool let's make it full screen wow what did you make this in i would like to know wow that is so cool i love it so um the diffusion limited aggregation uh coding challenge is a simulation of a kind of random motion a brownian motion if you will where which is created by particles entering from outside of a space coming in and when they intersect another particle they're stopped so if you know i i don't know if we can just go back to the beginning of this video to sort of see the big that starting process but you can see it's happening very very fast so each one of these particles it's almost like these branches are coming out and has a very organic um it can have a tree it can create like a tree branching like um pattern but in here i don't know how to characterize this it's very it's almost like um molecular uh in its look so uh thank you for this this is wonderful to see this in 3d there's also something kind of lovely going on color wise here that i can't put my finger on but it seems like there are started as red particles and they're getting more and more blue um you know oh you know i tempted to be like you know just like i just want to make my own version of this i mean i guess i did in some manner but the version i made the example is just 2d and doesn't have this sort of 3d quality to it so wonderful work thank you for this community contribution so i'm hoping um i can kickstart getting more ways for people to share their versions and more ways for me to share them back and i look forward to thinking about ways to do that better in 2022. all right thank you okay i'm going to scan through this just to see where it goes uh whoa oh yeah so it's like zooming out maybe as uh as unchanged colors again this is wild that is a really quite an impressive looking structure um okay um now let's uh close this um just to sort of close the loop on this um if i go here uh you will see this is the actual code from the video and one of the things that i'm doing in this particular example that you didn't see in david's contribution is i'm animating the process of the particles entering and moving randomly and then getting stuck now i'm doing it really fast sped up because uh you know if i were to actually like animate each particle moving like one or two pixels per frame it would take a very long time to build the actual structure oh and i guess i also have some color scheme going on here i say i don't remember what i do in these coding challenges but now i see that color screen scheme is mirrored in the 3d version of it um wonderful i'm just curious here oh it's the iterations probably the iterations is the variable that kind of can i should log in um the iterations is the variable that controls like how many iterations of these particles moving am i skipping so if i went to just like for example one you would see like this is kind of i mean this would be like amazing to watch over an incredibly long period of time but i can only i'm going to talk for a tremendous amount of time and probably not one particle is going to stop and get stuck if i put it at 50 we can see things are kind of moving a little bit faster now maybe we would get there but it was i think i had it at a thousand so you know if i if i did it at 100 000 for example oh that's just going to make things now that now i've lost the sort of frame rate of the sketch itself but you can see okay so that's under anyway you get the idea um i'm i'm lost on this tangent let's try ten thousand there we go um and i presumably i think what i would want to do in this case is actually not draw there's not really once i've have this iteration number up so high there's not a tremendous amount of value in drawing the particles moving themselves because ultimately what we're really just seeing is um the um the pattern that's emerging so just out of curiosity if i wanted to change that those are the walkers we could comment this out and i would see now i'm seeing just the sort of diffusion limited aggregation pattern emerging so there's a lot of parameters to play with here i don't want to save this actually because i've kind of messed it i should or i can maybe just do undo all the way back to where it was and hit save but what the thing that i'm just going to hit leave the thing that i'm curious about here is to take a look at source code now my assumption is what david shared here is a video rendering of it so one that's a beautiful way to share documentation of a project because it's very accessible like yes if you have a p5.js sketch that can run in the browser that's just about as accessible in terms of anyone being who happens to have a phone or a computer with a web browser um can just click that link and see it um but i'm assuming here that this is not done with p5.js because then presumably we could see it just running in the browser rather than have a video render of it although it's possible that it's a slow process that rendering it makes more sense anyway let's go i'm assuming this is going to be processing but i'm excited to find out oh no no oh this is i'm so wrong look at this they're just running in the browser so we got all the possibilities oh and and oh and i can control the camera with my mouse okay okay and i can see that it's running at 30 frames per second down here this is amazing uh so now i have to guess that this is i mean this could be the webgl renderer of p5 it looks like there's a lot going on here so and i don't know why the chat is not scrolling for me or maybe just nobody is making any messages in the chat the last message i see is ro doc saying hi um and like discord member chad is completely also dead am i just talking to myself here hopefully people are there so what did i uh sunday maybe sunday morning is not the best time for me to be live streaming but it worked out for me so here i am maybe you're watching this uh as a playback um i'm going to guess that there's something 3js going on here let's look at a view there's a lot of ways i could do this but i'm just going to go to view source here um and logo manifest drop this is an awkward way okay this is not helping me uh let's do um inspect this is going to be an easier way to look at it and we can see here there are some javascript so this is probably built um let's see let's look here this is probably a sort of built version of this project i'm assuming that this is using 3gs and maybe it's kind of embedded in one of these javascript files here but i don't need to get lost into this right now i can investigate this more later somebody can tell me um i don't know if this is what library this is uh or or what and i could probably click on this and maybe see something more but i assume these are all sort of built in minified files so it's going to be hard to sort of parse through and and find and then i see people saying uh saying hi now in the chat and and minnie jimmy has the same uh reaction that i have by saying sorry i am in awe of the patterns all right all right i've got to get moving here because uh if you've watched any coding train before you'll know that what tends to happen is i it's just a lot of sort of digressions and tangents and sort of going off in arbitrary directions and what i've the thing that i've been enjoying that i've been trying recently just over the last few weeks is picking one project that really requires a a lot of time to sort of dig into and dig through and try to build and debug and iterate and adjust and so on my list for a very long time has been to investigate programming my own auto encoder now not all the way from scratch in the sense that i'm like writing all the neural network code myself but just using a machine learning library like tensorflow.js and i've been doing that over the course of the last live two live streams so i just want to first summarize where i am so far in the project and where i want to go and i also want to address um this pull request that i haven't been able to merge yet i don't know if the chief who submitted this pull request is in the audience right now if you are say hi in the chat um and then also i want to look at this pull request which i did merge and we're going over this so an avaroop question what did you do last time is exactly where i want to be so um let me walk over and i won't be able to see the chat while i'm over there i'm looking to remedy that let me just have a look that looks like the focus is reasonable on there traverse i saw your question about coding challenges i'll try to address that later so the project that i've been building is in some ways like an ancient technology at this point in terms of what is it uh in terms of how synthetic media generative images i just want to see that there's green bars for my audio which there are are created through machine learning now you might have heard of things like again a generative adversarial network you might have heard of style gan or style gan 2 or style game 3 you might have seen this face this person does not exist and this explosion of synthetic cats and dogs and people and cars and all sorts of things that ai models are generating based on a set of training data of real world imagery and there's all sorts of ways they can be fantastical and look very dreamy and artists are making use of this stuff so for me where does learning about how those things work begin well it begins probably in the basics of you know what is a neural network um i do have videos on that but for me in terms of like if if we've got if i'm making this assumption as having sort of gotten through some of the fundamental aspects of the sort of core pieces of neural networkbased machine learning the autoencoder a particular architecture for a neural network is a wonderful starting point to learn about the process by which a model can generate an image and how you you as the sort of artist or the creator or the programmer can manipulate that model to generate images in certain ways um so uh reference most important reference probably for you to watch there's no post production here so i can't just fly this in right now to show you a preview would be the auto encoder video from the youtube channel two minute papers so that's a good two three minute video just you know explaining anything that i'm about to try to do right now in a much better fashion um but the neural network and again my previous sessions i went through this in much more detail i even did a recap of this part in the last session but just to quickly do that again the idea of an auto encoder the starting point of how you think of it as a copying machine an image is the input and we want that same image to come out as the output the trick here is that of course that's a very easy thing to do because we can copy an image i have this many pixels we make a new image and take each pixel and copy it over but what happens if as you're copying the image you're on you're constrained to work with less and less data so in a way you're compressing the image and then decompressing it or encoding it and decoding it what happens is through that process if the neural network learns all these weights the weights are sort of like the make the core sort of like settings the parameters of the neural network itself it learns the weights to copy an image then we could take out the part where the image comes in as input and just ask the neural network to make to make outputs based on what is essentially random inputs or noisy inputs then we're going to generate new images in the style of what we started with that's the idea of an auto encoder and that will lead to ideas like a variational auto encoder and all sorts of other kinds of generative models so where am i i've built this already i think this is where i should go back to my code i have done everything that is in this diagram except for that last part of take off the sort of first half and start to just generate new images that's what i hope and again it's it's not like i've been working on this like i haven't thought about this once when i have thought about it i haven't done anything on this project since the last live stream so i don't know how this is going to go you could go do something else with your sunday and come back and then like watch it on 2x or speed through and just look at the end so that might be advisable but if you're here thank you i appreciate you i'm going to go i'm going to go forward so let's look at the code pieces that exist already um and raj just asks sorry to be alone in a desert first of all nobody i hope nobody watching the coding train the thing that they're coming away from is a feeling of being alone in the desert although i actually have this i've never been to joshua tree and i was looking i'm just i don't know i know why this came up but i was looking at places to go visit joshua tree that's a desert that i could conceivably get to uh i mean i'd have to take an airplane i don't know what we're talking about here i got off track don't feel alone um the the the vibe here the working assumption is that this place is for people who don't know what the thing i'm talking about is and a lot of times i'm just figuring it out myself you should ask of course you know the reality of the situation is i can't every session go back to the very beginning of like what's a variable but you should feel welcome here wherever you are in that journey and there if i've done my job if this is a job correctly i can point you towards resources to find all of the um you know the prerequisites if you will to what i'm working on today so hopefully that explanation helped you a little bit and moby dick is asking would a reverse autoencoder work where you give it more information in the middle so it learns to opposite i don't i don't know i don't know if i fully understand that question if i'm being honest i have to think about this one more it's a fascinating idea and this is this is one of the things that i'm particularly invested and interested in what are the ways that machine learning models that are maybe trained to do a particular kind of task for a real world application can be uh tweaked broken uh done in the sort of like uh turned upside down for creative um and maybe um outputs and hopefully to be sort of critical and investigate um what are some of the sort of issues that the world has and i'm you know being kind of trite about this but uh with the fact that these machine learning models are playing such a sort of fundamental role in our daily lives um odjabi asks do i need to know how tensorflow to follow um it you know so no because my i'm i'm here welcoming you in whether or not you know anything about tensorflow um uh you know and i at least the stuff that i'm gonna do today like a lot of the tensorflow stuff is done already so it won't be the focus so it is um it is a sort of core essential part of what i'm doing right now but i will try to explain things as i go okay um all right lars is asking about generalized ai i don't have uh i don't have an answer for that question around the corner i would say no if i'm guessing but what do i know i'm just here in my garage on a sunny day with a computer trying to make some squares appear out of random numbers all right if you're wondering why i constantly look over here it's because that's where the chat is that's where my monitor is i mean i have it positioned here because then i can sort of gesture at what i'm doing but i feel like sometimes i'm spending too much time live streaming and looking over in this direction okay so um let's look at the pieces of what i have so far and i had the heat running in here all morning to like try to warm it up it is very noisy so i don't run it while i'm streaming but i already feel like it's getting a little bit cold in here so when i take a break i'll crank it up again um it's oilbased heat right now in this garage with like a very old boiler um but i would like to figure out once i have solar panels if i can do some type of like heat pump maybe that'll be quieter i don't know all right so first things first uh i need training data so if we're looking back to this uh this diagram images have to come in right images have to come in what are the what's the training data um it's very sort of rudimentary training data right now it's i have a processing sketch that just draws random squares so i'm going to run it the images it's saving are actually just 28 by 28 pixels because i'm working with very low resolution right now just to have things run fast and sort of work and be easy to deal with um i would like to today start having this generate different kinds of shapes like triangles and circles and squares because i think the sort of ending animation that i'm imagining of sort of like these shapes morphing around in the latent space i'll talk about what that is um would be more interesting so that exists then the next thing that i have which i haven't even opened yet is a node project and the node project is all the code for it is essentially here in index.js and the node project i'm going to talk you through it now i mean if you want to watch like four or five hours of me live streaming building all this you can um the node project is uh architecting this particular uh whoops wrong button this particular um uh neural network architecture i'm sorry to use the same word multiple times uh importing in the training images running the training and then producing output images as well and i i went around in circles with this because i was um you know ultimately i think moving this into the browser will make more sense um but um uh so you can see some things are commenting so i was trying to use like node canvas and different things but i ultimately just using this library called jimp which you can see up here jimp is a library for manipulating images in node so these are the steps we can say i have this like main function where i call build model build model and we'll look at the code in a second creates all of these layers that are in the diagram then i need to load all 550 images i have 500 training images and 50 test images i made a huge mistake which i haven't watched i need to address so this code i'm going to pull in the new code from the pull request in a second so there's a big mistake here but so this code is like slightly wrong but the idea here is the first 500 images are the training images and then the next 50 images are the test images so i can train the model and then generate outputs by running the test images through and see how well the model does copying them essentially and so uh i did i forgot that i did this this is great there's some like refactoring there's basically build model load images train test so if we wanted to look at any of these functions i think looking at build model might be interesting to see this is this is the part that i forgot who just asked this like do i need to know tensorflow no but this is going to look kind of a little bit scary to you it looks scary to me and i i sort of know i know ish tensorflow so the idea is i'm making a sequential model a sequential model this is called sequential because the data flows through all these layers in a sequence feed forward left to right and we could draw it any way we want that's arbitrary but it is sequential and then um uh now i need to add the layers so the first layer receives 784 inputs because the images are 28 by 28 that's 784 pixels the next layer and basically it takes those pixels and sends the data into 256 nodes and then those 256 nodes send their data into 128 that's the encoder so i could actually add a comment here which would be like encoder oh my hands are so cold i'm gonna have to turn the heat on and then decoder what's the temperature outside let me just tell everybody what the temperature outside is where i am uh it's only 40 degrees um and sunny high of 43 today low of 28. this is in fahrenheit of course not of course but of course because i'm an american here who living in the dark ages of measurement systems uh then the decoder is we go back from 128 to 256 and then back to 784 and there's these activation functions and there's the optimizer and the law all these things these are things i've kind of addressed a little bit but you know again this is the territory of other videos i have about um the pieces of the neural network themselves but and then we call this train function where this is interesting normally you're pairing some like if i were training an image classifier i would have the images and the labels so i'd have the training data and the targets but i don't have that because the target of the training data is the training data itself that's the sort of twist here with an auto encoder i'm trying to have data flow in compress it down and the same exact stuff come out so that's really this weird thing it looks like a mistake to me because it should be like x train and y train or x train and y targets but number of epochs is how many times through all the data batch sizes how many data points do i do before i start adjusting some weights et cetera and yeah and there's some stuff about loading the images and i'm using this jimp library so again i don't want to run through all of this but that's the idea so let's try running this right now and see what happens so first thing first oh no let's correct the error so first thing i'm going to do is going to say kit get pull origin main so i've already merged a pull request that came in um and so i merged it on the github website and now this is the command that i can type to receive that image here that that change locally oh i don't know why i'm getting this weird message and i'm also i all right so we have to deal with this two things have gone wrong here one is i guess the way my git is set up on this computer i haven't specified a sort of default way to reconcile so what if you've made changes in more than one place how are those changes reconciled with each other um there are different ways of doing it and i'm not going to get into that right now but i'm going to just i want the default one to just be the one that i'm going to do so i'm going to take this command and type it in now let's call pull origin mean again we're gonna have another issue so it's saying like aha you've made local changes to the following file that would be overwritten because i'm trying to pull in some changes that were made on the github website server itself but i also was messing around with it here so the only change i actually made was just and i can actually see it if i do i think git diff will show me it's just adding these two comments encoder and decoder so i could undo those but what i'm going to do is i'm going to say git add dot git commit i'm going to put a message in i'm adding encoder and decoder comments there we go and then now i should be able to pull the fix no problem it's merging it i'm not going to type in any more information about that and there we go so now that's coming now what was that change let's go take a look uh how does this 40 minutes in this live stream and i've barely gotten anywhere yet i guess that's the hopefully i've been talking a lot in ways that help you understand the world at least focused in on machine learning and javascript and that sort of stuff um and curvers is talking about reducing the latent dimension to something lower from someone yes yes yes my goal actually by the way is to have a browser page with sliders on it where you could manipulate each dimension individually i i i it does not seem realistic but i'm going to get that today i don't think there should be like four parts i really thought i could finish this but that's my goal so having it less so let's look at fixing number one so um and actually we could just look at the issue which maybe um described it better so you're using the same images for training your network and testing it this is due to array.prototype.slicestart returning a copy of the array from the index start to the end and not zero to the start so i had if you what what is this what's happening here i had um this is what i had and i did not realize that slice 500 slices out the array from 500 to the end not 0 to 500 which is what i wanted and then now if i just put 500 it'll take i don't have to put the end number because it'll take that to the end so that is a huge mistake that i had in the end i don't know to what extent it's going to make that much of a difference because everything i'm doing here is is utterly simplistic and somewhat trivial so so what that i use those 50 images but let's try um running it and i think if you were if you were here last time i was talking about how an auto encoder could be used to denoise an image and i wasn't getting that to work this is that's probably why i'm not going to go back to that right now because i think that'll send me down you know at least a half an hour of investigation but let's run this again and it's training the model hopefully now off of 500 images not 50 and it's going to do a 250 epochs we're seeing the loss go down which the loss is sort of a summary of the error like how well is it currently copying the images uh hi omar i'm reading your message and thank you tom i don't know what the penguins are for but i love penguins i we i had not gotten a loss below 0.1 you can see it's really settled so clearly one of the things this we can learn from this is that if the loss is sort of like frozen uh you know it went down to 0.105 but you can see it's not really changing very much at like whatever number of epochs i'm at um so probably training the model for 250 epochs is quite unnecessary but let's let it finish that so after it trains it for those 250 epochs it's then going to generate 50 new images okay great so just let's go look at the directory that i'm in and we can see whoops wait a second where did it load the images from i'm confused well let's just see what's in the output it worked i'm i i'm a little bit confused because where did it load that i don't see the training data actually in the so hold on load data square but there's nothing in this oh no it's there i just don't know why oh yeah it's just the mac os was activated so this is the sorry about that ignore the last minute i was just confused um so this is these are the training images right these are 28 by 28 pixel squares that i generated in processing um and then and i'm getting all sorts of interesting um commentary in the chat so thank you for that i can't it's not possible for me to address all of it as i'm going but i appreciate it and i often do go back and read it afterwards so all right so now what i want to look at just to make sure things are working the way i intended them to is look at the output so these are the generated images now i cannot even discern the difference um in my assumption would be that these are slightly fuzzier like generally speaking my experience with working with an auto encoder is uh the output images are going to have a sort of fuzzier less precise quality to them than the input images but in this case i'm working with such like fixed kinds of images squares um that have of just black and white pixels at such low resolution i'm not sure how we're going to discern the difference so i want to see if i can get this stuff into a place where i can manipulate it so that's what i want to work on i do need to take a break so i wonder if actually that makes sense usually i just keep going and going but maybe i should just take a short break right now if you generate the images as 28 by 28 instead of reducing them the images are sharper i'm not sure what that means mini jimmy um and i'm of the wrong so let's let's let's go let me go a little bit further sort of think about what i'm doing here well um so is there a way this is what i don't know how to do my idea here is that uh and i and i do want to make this like let's actually try this let's let's do a little bit of this let's do it i don't know why i'm let's have the auto encoder go down to 64. i don't know how many layers it makes sense to do what if i just like went to 16 like i want to have 16. that's my goal um could i possibly just go from 128 to 16 is that like a terrible like silly thing to do and then this would go back to 128. should i put more in between i don't know but let's just see what happens if i go down to a really small number and um and then also the number of epochs where is that oh train model that's a parameter i pass in um train model 250 let's just do 100. let me run this again and that while i'm running while it's running i'm going to talk about what it is i don't know how to do so what i'm hoping i can figure out to do is how do i take this neural network architecture and basically make where is it this the input so how do i delete all this and actually add tr add data to produ from predict insert it into here and yes blue tj says i suspect it gets even fuzzier this is what i'm trying to test right now so we got around the same like loss and i could look 1049 these are new images but honestly we can see with 16 no problem i mean it's sort of hard for me to believe that did i like not save the code or something like like like if i change this to two like it really shouldn't work right so let's just make sure that this doesn't work let's change that to two because otherwise maybe something is wrong okay this is good news the loss is not going down i have a lot to say yeah i'm kind of picking the activation functions very arbitrarily i've talked about activation functions in other videos there's relu which is not how you say it but that's how i say it and sigmoid and um so i'm hoping the images that come out are no good here let's see ah they're not so bad they're just uh they're all basically the same it's just like a much bigger fuzzier square it's like only knows how to do one thing so that's great to see um let's try i want to see like what is the minimum can i get it down to eight again i wanted to have more complex imagery so i don't know what the point of getting it down to eight is with this but let's see i recall the loss being at 1.05 all right so this looks pretty good with eight there's yeah and blue tj writes exactly what i was thinking there's leaky relu leaky relu and many rectified linear unit is what that stands for i don't know how much that explains anything to anybody but and many others it's quite hard to find the right one and know which one fits in your use case yeah so to be clear my motivation here is exploration and explanation not optimization not speed not efficiency not even producing a meaningful result i want to understand how these systems work and i want to be able to feel like i have some agency in manipulating how they work in and i feel like i do simply by the fact that i can change the total number of neurons at that middle layer the sort of smallest layer and see a very different result means things are working as expected that match the way that i understand how these systems work so you've got to fix the sigmoid um all right let me let me just see here i what i wanted was i know i want sigmoid as the last activation function because i want my values to be to be between zero and one but i don't know if the suggestion here is that i should just try relu all the way through or even don't worry about it just have it i'm just going to leave it as is right now but um i would love to um and kervers is saying that they got an auto encoder to work fine with just two latent dimensions i have two sigmoids i have three sigmoids i don't know i don't understand the comment okay i'm gonna come back to that i the thing that i want to do now is figure out how do i um how do i start from here once the model i is here so maybe what i should do is first save the save and load the model so hopefully this is as easy as let's look on the tfjs documentation i'll take my break after saving and loading layers model safe sequential model is what i'm using well there's no save function here but is this ultimately a layers model because sequential like extends that or something save model dot save i know a local storage is interesting oh but i'm not in the browser so that i do not want to do i mean i could just move this to the browser it's a little bit silly to be honest that i'm doing this in node but let's try this so what happens if i let's forget about testing the model for a moment oops now let's just try save and what if i do like if i give it a directory we'll put it all in there let's just see and let's let's do this for just like 10 epochs just to sort of see so i'm going to try i'll just call it model let's just see if this will save the model in a directory called model i'm just doing 10 epochs okay model is not defined oh my goodness oh my goodness what is wrong with me it is called autoencoder oh i forgot to address the other pull request um could not find any url well so i don't want it to be a url do i just need to have a folder called model will that do it let's see no no this did not work okay um indexeddb downloads my server what about a file does it really not work just to give it a direct talents okay uh all right let's look at the so let's address the pull request which maybe has a solution for it in it so um where where am i going to auto um yeah here we go all right so let's look at this pull request and actually let's just go to this issue so this is incredible what uh the chief has submitted here um i'm just going to read here want to make the code a bit more readable and organize everything in its own class and file yes yes yes so do i i opened a pull request number three for it i added a data source class which can provide training and testing data and there's an interface for it so more data like random mnist arbitrary images blah blah blah more layers divided into an encoder and decoder it can save its state so you don't have to train it every time the image transformer takes an array of normalized pixel images and saves it to disk so there's so much more here in terms of organizing refactoring the code so i didn't feel like i can merge this because um it's too it's like too too good it's like too much of a radical improvement over what i had before that i won't be able to easily continue this process this explanatory process i have so the chief if you're watching i don't know the best one i don't know what to do here with this one is i could wait and eventually merge this in later once the project is totally finished but i would like to have a version that kind of i'd either or maybe i can draw inspiration from this like implement some of these pieces during a live session but i think what might make sense is for this to live um in uh you know in as documented in the readme for this repo linking out and explaining these improvements so that somebody could sort of see the code that i've written in the live streams follow that along and then see how there is a version of it that's just much more thoughtful in terms of how it is organized so let's think about that the thing that i would really like is an excellent readme documenting all of these pieces um expects a file extension maybe a branch would work but um so a pull request with a nice readme that links to the different live streams and kind of like the um the two minute papers video and it kind of has some sample images in it i mean i should be doing that i just haven't had time so if somebody wants to really think about how this whole process could be documented in readme linking to the chief's work and all of that that would be amazing but let's take a look at the actual pull request because maybe we can get some hints for how to save and load the model from the disk because i'm not seeing it obviously in the tensorflow js documentation so let me just look for save this is for saving the images saving the images auto encoder oh so literally i'm doing it right but i just need to put oh and it's oh and it's divided into an encoder and a decoder so that's also a probably a clue to what i actually want to do i have to understand so let's first just get it to save so is it just this file colon slash model with another slash let's try this a little tiny box here yeah i think this might have worked so one thing we can do is we can look at oh i've got it here what am i doing we can see the model files we can see this um the json which is basically a configuration file describing the architecture of the model it's a sequential model here's all the here's all the layers the kind of layer it is the activation function the number of units etc etc so that's great so then let's save a model trained to a hundred epochs and where do i want to do that so go back to 100 all right almost 200 we got down to .108 of a loss 107. can we get to a six show me a six show me a six before you finish i want to see that six that's fine we got zero point one zero seven now this should be live just to be sure 1101 am yep that's a new model overwrote the previous model by the way this weights.bin file is all of the trained weights so in theory every time i'm saving the model this is not changing at all model.json the weights are what i'm changing so i could have different weights file if i wanted to try different configurations and swap them in and out what are the weights just for any of you who might be kind of just joining right now it is the value the sort of weight of every single connection between any given node in the system and another node uh well the layers are connected sequentially so um you know the first first layers aren't connected to the last layer they're connected through each other all right um all right now in theory then there shouldn't be i should be able to um and it's this is very awkward what i'm doing here but i'm just going to let me just do it this way let me comment out all of this one more time and then let's get test back oh i do have to load the images sorry and let's see can i do auto const auto encoder equals await how do i call load let's just look in our cheat sheet this is terrible i should look in the documentation model.load huh i'm confused all right i'm going to look at let's look at the documentation so where is load save load sync i don't need to load sync load layers model okay that should be it tf load layers model okay and then i should be using the same path but maybe i say model.json here so let's see if this works i'm going to just to be 100 sure i'm going to delete all these outputs that i had previously and now instead of building the model and training the mile i'm just loading the train model from a particular file this is how i'm going to be i'll just move right into the browser because i can um i'll do yeah i mean once i have a saved i'm going to use node just for training the model and then i'll once i've saved it the files will just bring it right into the browser i think i think that makes the most sense to do yeah i was thinking like oh i could set up like a web server and have the browser send like get requests and the the server like generate the images and send it back but that's like a whole lot of unnecessary trouble right now so let's run this okay ah i think this might have worked output yeah 1104 okay we did it yes all right we're in really good shape here um so i'm going to take a short break just so i could turn the heat back on and check out brilliant as a sponsor for a moment but let me just see i saw somebody ask in order to recover the information of the squares you should use relu in the decoder part as activation functions because they are inverse functions the last layer is okay as sigmoid okay that sounds very reasonable to me thank you and k asks what exactly does an auto encoder do um unfortunately so an autoencoder just as like a one sense is a copying machine it's taking inputs and generally trying to generate the same output while compressing the data inside of a neural network there's a lot more to say about that the twominute papers video on autoencoder and my earlier explanation in today's live stream should give you much more detail but just for anybody who just happened to tune in right now so what's coming next i hope everybody can stick around please stick around i'm going to just take a short break but what's coming next is i'm going to take this trained model and move it into the browser so that i can see the images appear in the browser and animate them which will be very exciting so before i do that i want to thank today's sponsor of the coding train brilliant um i can't emphasize how important it is when you're learning a new concept to be able to try it yourself so me demonstrating stuff in this video i hope is entertaining for you i hope it's turning the wheels in your brain maybe you're even doing it along with me or you're trying it later that's the way to learn but brilliant is all about trying it yourself in spades topics in math in science and computer science anything you can think of there are lessons and challenges and courses and puzzles and all of them are interactive that allows you to try it yourself so um i'm gonna switch back over to the brilliant website itself um you just before i do though that's the url you can actually sign up for free there's a ton of stuff you can do on brilliant for free if you use that link it lets them know you found out about brilliant through the coding train thank you and also that link will give you the opportunity to have a 20 discount on the premium subscription but even better than buying it for yourself let me just quickly mention that uh you'll notice this button up here because i already have them logged in with a premium account this gift premium it is gift giving season and uh it's hard to find things to buy for people it's also i don't know you know this is plastic and packaging and so gifting a premium subscription to brilliant for somebody who loves learning i mean that's what i'm going to be doing for people um uh um you can do that you'll get this through the same link you'll get the 20 uh discount that link there so um i can't recommend that enough let's look at this i i was kind of going to go to the logic there's a bunch of courses so i can show you just really quickly like these are what the interactive lessons look like their logic course has been totally redone with lots of new interactivity so you can see like there's a lot of explanation and then interactive things you can do we're talking about neural networks like all these things i'm talking about about weights we can see there's a whole course all about neural networks that you can browse through um it's a great complement um oh and i'm speaking of which daniel montegrano said can you try loss equals mean squared error and if you want to know what mean squared error is and all that stuff i have a feeling that the brilliant course explains that stuff really really well uh so thanks for that chat message so i think what i want to do today is uh i'm kind of again like i didn't have a plan for this so um if i go to courses you can see these are two courses that i would certainly recommend beautiful geometry is personally my favorite right now and then also the logic course we can scroll through and see all of these popular ones recommended for parents and teachers learning paths you know you can you use if you're watching these probably all appeal to you so um but i think today for fun let's try this nine nine plus challenge that i have not looked at sometimes the best way to solve a problem is by just doing something with it uhhuh that's what i've been talking about then slow down and think about what you're doing for example think about what you need to do to solve just one part of the problem here's a warmup challenge try it yourself drag the tiled numbers up into the plus note that the sum of all the available tiles is zero yet the goal is to make the row sum and columns both positive oh i did not know that uh oh i did wait no oh no no no i didn't because that's negative 1. so i didn't do it right when i first see somebody refused to even try to solve it they glance at it and claim it it's impossible yeah it's impossible i can't do it oh i can put this in the middle well hello no this goes here and this goes here i did it yes [Laughter] if you start by filling the rows sum to one how many different ways are they okay three dwell a little bit so so now it's going to explain 2 goes in the middle yeah this is basically what i did thank you very much your solution might look a little different as long as the 0 and negative 1 are together in the same row or column and the one and negative two are together in the other both sums will be correct so we've shown that it's definitely possible to arrange negative two negative one zero one and two into a plus that's a positive let's take that one step further is it true that if you arrange any five number tiles in a plus and put a positive value in the center the row sum plus the column sum will be larger than the sum of the five tiles can you prove why this is true well that totally makes sense intuitively because you're using the the center tile twice and you're using all the other tiles once so no matter what it's going to be more because you're adding more numbers essentially okay wrap things up here's a bonus challenge that's fair bit more complex than the plus arrangement however it can be solved using the same algebraic strategies to make the puzzle above and today's challenge solvable oh i have to get five five five everywhere well should i try this or should i just let me just move on to the challenge or though maybe i should try this uh i mean if the zero my my intuition is that the zeros and ones should just be in the corner oh but that's going to be the zeros i don't have enough zeros to put in the corner but if i did that right that's five that's five this won't be five oh but now i can do this oh but that's only four all right what am i missing here people we've got everything but this one can i what if i move this here and this what if i put a 2 in the corner oh now i'm confused what number should go in the corner okay hold on again if i put the two here the threes can't be together so the threes always have to be in the how many threes are there just three look at the chat no nobody's solving this for me in the chat oh i have to fit him with the awkwardness of not being able to figure it out okay um what am i missing i should have read all the explanation so so the ways to to make five out of these numbers and only have four numbers are one one one two two two one three two zero zero three two zero zero so is is three in the corner gonna help me or is two in the corner gonna one in the corner are gonna help me more what if i put all the ones in the corners there's only three of each other i'm confused yeah there's hold on reset yeah there's three of each i see definitely want high number in the corner to be used twice yeah okay three hello come on three so if that three is there uh let's put this three here let's think about this then now if where could a two go um with the only other place to put it through i could put a three here all right so let's think about this if the 3 is here if i put 2's here oh i can't put everything has to be a 0. what if i did that oh it can't there's not four zeros so one of these has to be a one then one of these can these can be zeros and then three ah no no no no no so close but no because the 1 is going to mess everything up here you have a total of 18 you want to make it add up to 20. so the tile you need to reuse has to add up to 2. well that's interesting so maybe the ones are what needs to be reused just one one oh hey let's think about this this is the strategy oh this is great 3 times 3 is 9. plus 6 is 15 plus 3 is 18 but i need to have a total of 20. so a 1 being reused is one extra and another one being reused is another extra okay this makes sense this makes sense as a way of following it now then these have to be 0. so then a 3 and a 2 can go here 3 can go here a 3 can go here and then a 1 no oh a 3 can go here and a 0. then a one oh i think i did it and a two and a two thank you forever that so that was the logic that was being explained that i like scanned over from first of all by the way these are so fun like if i what i really would like to do is make a p5.js sketch where you can make these puzzles i mean that's um all right oh and uh so i maybe i could have also done this mike on the box says all the corners are zero but one is a two maybe it would also work that way so i i'd love to decide are there two solutions all right so now here's the actual challenge is it possible to arrange five square tiles numbered one two three four five into a plus so the sum of the three tile column and sum of three tile row so we need to add up to 18 and these numbers add up to 9 12 14 15. so i need three more no it's not possible i was gonna put this as a poll but i think it's not possible because there's no number i could put in here twice to give me three extra because one gives me one extra two gives me two extra three gives me oh no three gives me three extra yes three has to go in the center that's totally wrong i don't know what i was thinking there i was thinking three doesn't divide into two like so i can't put a one and a half in the center but no i just need three more did i do that right let's see uh nine i i i you know i usually like to do these with a poll in the chat but there's uh so i could do let's let's just make the poll it possible or not possible while i'm figuring this out i mean i think i hopefully i was right so i'm gonna make the poll possible or not yes or no no no no add another option how do i delete that now no delete okay so there should be a poll that went up into the chat just now it might take a minute to post where you can just give me is it possible or not and i'm going to work it out so we need to add them up to nine wait what i'm so confused eighteen nine how do i do oh no no four okay okay okay the five and the four can't be together obviously that's eight yeah nine okay this one's two why was the other one so much harder for me there we go i've made them hit submit and now we can see the solution which is that 3 the sum of the row and column is 18. the sum of all the tiles is 15. the middle tile is counted twice so the middle tile must be 18 minus 15 or 3. and then of course now we just need the desired sum in the row and then the desired sum in the column okay 93 of you said yes you got it right uh um and so uh thank you i've been like is this not fun like this is what i want to do later today with my free time are you like that and i just want to emphasize like um if you like a lot of the algorithmic art stuff or generative art stuff that i do on the channel the beautiful geometry course is really the one for you so thank you brilliant for sponsoring the coding train if you're watching and have a minute right now i turn the heat on uh to sign up at brilliant.org cutting train you could do that for free if you'd like to buy the premium subscription for yourself or gift it to a friend or loved one or anyone um you'll get the first 200 people to do though will get 20 off okay i'm gonna be back in about uh two or three minutes to see if we can get the auto encoder running in the browser so don't go anywhere come back stay with me i'll be back i'm gonna turn the heat on for two or three minutes warm up my hands and i'll be right back so oh do do all right i am back just out of curiosity how loud is that hum in the background right now which is the heater going so i'm gonna if it's tolerable i think i'll leave it running for a little bit longer all right everyone so the next thing that i need to do um and i'm keeping an eye on the chat in terms of the volume is i want to just really quickly create a webpage that loads the model and draws the output to a canvas so i'm going to use p5 and tensorflow.js and i believe that at some point there's no reason why i couldn't use ml5 which i would like to but i'm right now i'm not sure if ml5 supports all of the sort of things that i'm doing with tensorflow.js you might be asking like what's ml5 so ml5 is a javascript library that i helped to work on with a lot of wonderful collaborators and people that is a sort of helper layer on top of tensorflow.js to use a lot of pretrained models and do a lot of stuff and if you want to learn more about ml5 if you go to thecodingtrain.com under learning uh ml this the this video series um has just a ton more stuff so at some point my hope would be um it's oddly cut i love all the comments about the sound it's oddly soothing tolerable i love me some calming white noise it's audible but we want you to stay warm so it's all right sounds like a vacuum cleaner all right i'll leave it running for a little bit here one of the reasons why i don't want to run it and let me just vamp for a little bit is that i have this idea that one of the things i want to do with the coding terrain in the new year is make some more kind of video essay like video essay like videos about things like an auto encoder and narrate the process using clips from these live streams so that you could get maybe the sense of how to build the whole project in a 10 to 20 minute video and then if you wanted to of course you could go back and watch all the development during the live streams so i'd have to script that edit that have some animations and things i love your feedback i'm trying to think of like you know i'm on sabbatical for my job at nyu starting in the new year so i'm going to be focusing not full time on the coding train of a lot of other projects and things to work on personally and for creative coding community but i do want to ramp up and at least be doubling my time or tripling my time that i'm currently spending on the coding trade which is very very little so thank you by the way to everyone i don't know how many of you are watching but thank you to all of you who continue to support me through all the ways that you do even when i feel like i'm not doing it enough for good enough so i really appreciate that um okay mike on the box is asking about the cabana i've moved the cabana may come back but right now i'm i'm in a garage which is much bigger than the cabana so uh yeah um okay uh okay so let's go back here okay so what i'm gonna do is let's just go into this project and create a new folder i'm going to call it i'll call i mean at some point i could have this be a full stack web application where the you can send a message to the server to like retrain the model so i'm going to like sort of build it in the way that i might do that so i'm going to call this public and in public i'm going to create index.html and another new file called oops ah what am i doing here don't save don't save so index.html and then i want to create another new file called sketch.js it's in the wrong place i'm sorry you can't see what i'm doing oh my goodness i totally forgot to be recording this whole session so much for that whole speech on what i'm trying to do oh my god i'm the worst i'm the worst well i'm going to start recording it now now i'm recording it so that whole i mean they could still use clips obviously it's being recorded in the sense that when i'm broadcasting it's being recorded but ah okay so much for my grand plan there well still still possible okay um the quickest way for me to let me just get let me just go to the p5 web editor this is my html file uh oh whoops that's in the wrong place public yes move and then my sketch file is it's very hard to type when your hands are cold function draw uh what i've got some crazy autofill stuff going on here and um let's just do okay let's move the model into public as well and then when i run the node script to train a model we want this to go into file public but i'm not doing that right now what i'm doing here is i don't need the sound library let's go back to the tensorflow.js documentation no not overview api reference okay maybe overview get started no there's still a nice link there's a nice link to ml5 here that's so lovely um i'm just looking for like the um guide maybe i just want to know what where the script tags i need install but i want tensorflow.js to install ah this is why are things so hard to find is it just me is it me setup there we go i found it it was in an obvious place can i use tfjs 2.0 i hope so why not so let's try this okay so i've got tfjs now what i'm going to do is i'm going to open a separate web server so ultimately again like where i might go with this project is have it all be one application where there is a server that you can like send messages to to like train them retrain the model and do different things and then there's a client that can load the model and do stuff but right now i'm just treating those as separate projects so this is the client and you can see that my p5.js sketch is loading oh style.css i don't need to worry about that so let's i don't know what how this got over here let's get rid of that great so now i have so the goal that i have is to see an output image in that canvas uh yeah sorry everybody about the sound of course now i'm finally recording now is when i have the bad sound and i wasn't recording the whole time when i had the good sound but i just got to get it to warm up a little bit more in here um i don't know this is not something that i really thought about how to once i once i once i solar power this place maybe some electric heaters i can do that i'll be quieter we'll see um okay so now i should be able to have a variable called like auto encoder uh auto encoder equals tf so this should be the same exact code that i'm doing on the server the difference being i shouldn't need the file path anymore and this has to then be an async function and let's do console log auto encoder so let's see if this works well that's a good sign this looks good i feel like it loaded it i got no error and i see an object that looks like a model so now if i go back to the server code and do generate okay x test so now what i want to do is in the draw loop i'm going to just feed at some noise um i'm going to say no loop oh where am i i'm in the web header i don't want to be in the web editor i could be in the web editor but i'm not doing it there um i'm going to say no loop is the font size okay for everybody it's a little smaller than what i usually work with output is auto now x test has to be a tensor so again at some point um where did i make x test images slice so let's think about this what is one image oh i could draw an image okay uh like what if i just make the image a blank array and i know there's a higher order function like that i could use fill and so 784 pixels and if i make that just like a random number i'm just going to feed noise in right now because i'm not sure what else to do um and then uh this would be turn that into a two that image into a 2d tensor and like i only have one so it's just that one image in an array is this right where like images like tensor2d imageslice500 yeah and then and then i should be able to just call predict and then this is an a if this is an async function i get the new image all right let's just try console logging this call this output image so it should just be one and so i'm just doing one image i'm creating a random array of noise i'm turning it into a tensor i'm sending it into the auto encoder i'm getting something back out and just logging it to the console let's see if this works okay good sign why did i do it twice why did i do it three times because i have no loop i wonder if something weird about the async and the no loop let's get rid of draw for a second here and just do this once and let's not log the autoencoder anymore let's run it again okay great once so i got my image now i should be able to and this is very silly what i'm going to do but it's and can i just do this will that work with or do i have to do i probably have to put parentheses around the await so that's the output image okay now what i could do is say load pixels update pixels oh no no no i want to draw it bigger so i'm going to do this this is a little crazy but i'm just going to draw it as a again sorry for all the noise in the background but it's making it possible for me to do this right now um oh i know i need another bracket and then i'm going to say rectangle i i got to fix my vs settings i times 10 j times 10 10 really square is what i want i'm going to say fill out output image i plus and this should be a j i plus j times the width which is 28. and again i'm hardcod i'm just i'm hardcoding all sorts of stuff um i'm looking at the uh all right everybody let's be nice to each other let's be nice to the fact that i need to run a heater let's be nice to the fact that we're all asking questions and not sure what's going on i'm very confused i'm not explaining everything let's be nice to each other in the chat please um so i'm looking for the pixel that corresponds with the square that i'm going to render which is the x plus the y times the width and then multiply this times 255 now this should probably just be noisiness but let's see uh oh what what import uh just trying to auto import stuff i've never seen so excited to see a square in my life that is insanity oh my goodness i didn't even that's funny i could like basically have the latent space be the beginning wow this is crazy i i weirdly i don't know why but i weirdly want to do this just because i like seeing the full square but also that's silly what i could do let's do this this is so this is like the silliest thing i've ever done in my life that this is what i'm focusing on right now how do you do this is that correct css yeah that's what i i just wanted to do that okay right how did it produce the script monothon asks everything that i'm i'm asking right now in my head how did it produce a square if the input wasn't a square that's cool right so i think the denoising should work now all right you would think right can this model let's do the following let's do an a real input square and a real output so um 280 times two 560 right and then i'm going to do this create graphics or create image uh 28 by 28. um oh no i need to do create graphics oh no this is fine i'm drawing it a square i can it's fine i don't need to put it on a separate background 255 now okay so what i want to do now is have the filter invert 100 what i want to do is have an input image and see the output image so let's draw the output image on the other side and now i want to see the input image on this side so the input is so this would be this can be a function a function render sum array image array at some x and y so this would be x x plus that and this is the image array and the width and height i've still got hard coded here in this like scale 10 that should be fixed at some point but now what i should be able to do is render output image at 280 comma zero still getting the same thing a little i'm a little bit suspicious of the fact that the square never changes its size oh no no it's different it's different each time just very subtly so okay now there's no reason why i can't say render image zero zero oh this is insane so i could make this like so i want to get to the browsing the latent space part but weirdly i could just turn this into like a pearl and noise field that's like subtly changing over time and see what happens to my output image like i'm not even like the whole point of this is so i can get down to that reduced dimensionality but i can actually play with this input because it's just 784 values this is this is so i'm so excited by this i can't i mean this is like the most basic of the basic of the basic but i'm uh this is just like really unlocking for me um this like sometimes it just feels like total matte and this feels this even feels like magic but it when you see like these really sophisticated generative models but really being able to like all the pieces of everything going on here we have coded and designed yes the actual machine learning math is coming from the underlying tensorflow.js but how we're manipulating this what data we use of total control over so um what i would like to do now is i would like to put this into the draw loop let's just see what happens here if i just put this async function draw like what if i how okay nope what did i mess up oh the auto no can i read properties of undefined reading predict oh this has to be a wait no what am i doing wrong here wait output array render as if oh no now i didn't get an error but i'm not seeing the i think that a i think a sinking draw is a real problem here so let's not async draw let's let draw go ah this is why i don't like doing this in the browser it's got to be the fact that i'm asyncing draw right so what if i just do like my own loop so let's call this input image oh shoot so this will be an async function this in return output image this isn't really no because all right let's make these glo this is a bad idea but let's just make these global so this is uh and then when you get the next image we make a new one hold on what if i do this let's just let's just initialize them this is sort of i don't i don't like what i'm doing but i just want to make sure it works and then let's just i'm just going to fill them randomly and then this just renders both of them okay oh input image index i i i should see just two random images great so i got two random images um yeah that cr what chris is suggesting you could have draw a whatever is latest finished and your asic function called itself recursively is what i'm going to do there also is an array sync function i think where i can make that conversion to data so mike on the box is asking why do i need a weight so the the three the thing with using tensorflow.js is it's doing all the machine learning math on the gpu and there is uh com there i mean i'm using so little data that this is so unnecessary i should send the back set the back end to cpu but you need to uh have any time that you are taking the data out and turning it in and off of the gpu so that i can manipulate it in my code that needs to be an asynchronous function so this return is unnecessary so what i'm going to do is call await next image so let's just see if i can get one new image no image is not defined where am i still using image uh here okay great so i've got one and now i should be able to just call next image now sometimes this will lock up the browser if i don't like give this a little bit of like daylight here like with a set timeout but let's just see okay great no no problem so this is now working i'm just always drawing the latest thing so now again i want to make this a proper latent space but i cannot resist pearl and noising this so we're going to create x off no i'm going to need to use no this will be z off and then the next image is x offset equals zero no let's do this properly let i equal zero i is less than 28. i hate that i have this hardcoded in here i've got to fix that up so we're going to have j is the y offset gonna have an x offset now you might be like what are you even doing right now so i would assume that let's say 2d purl in noise there we go thank you google for referring to me but um so what i'm doing is i'm taking this concept of having two dimensional purlin noise which you can learn more about in this video from five years ago how long have i been at this oh my god and using that as a way of manipulating the input i really should do the denoising but i can't resist this so you may not understand fully but i'm going to say let value equal noise x off y off z off so every j the y off should go up by some incrementation no stop autofilling things for me the x off should also go up by some incrementation value and then also wait i'm missing a curly bracket right next image curly bracket for what did i do wrong here i just oh oh no that's the end there what just happened ah i forgot that this function has more to it okay we're okay there we go and then z off goes up by that incrementation as well we're going to make it a slow increment let's try this for right now and then the input image in i plus j times 28 equals that value all right so let's see what happens here oh we've got some weird extra imports again uh syntax error in line 26. that should be an equals so here i am i mean yeah so this uh the z offset incrementation is kind of wildly too high oh wait no why did i oh that's x off i guess i should have a different yeah so this is this sort of like cloudy pearl and noise field that is changing and slowly over time we're seeing late so again i'm gonna really need oh it's 11 54. i have to wrap up uh this is definitely needs uh right michael kempt is pointing out a very good point which is just because pearl and noise only moves slightly does not mean the output squares will follow so i got a little sidetrack whereas i really should just be working with just the decoder but i think i can i i've got to go unfortunately about five minutes because let me just check um okay because my um i gotta get back to my kids for her i could give you all the details about that but that's the that's the summary but um and that's why you're excited for the actual latent space it's more likely to be a smooth but i think i can get something a little bit more exciting here um so what i would like to do well first i would like to test the denoising that's going to send me i really want to test the denoising but the two things i wanted one would be testing the denoising i'm pretty sure the denoising is going to work though because even just like random noise gives me a square so you would think that random noise with a sort of darker high square embedded inside of it would really give me the square but i think what might be more interesting is for me to have an output with much more variety so should i stick i also kind of am tempted to bump up the resolution i think i'll stick with 28 by 28 though and what i'm going to do is this is my data generation so i am going to say first of all i want the size of the images to be have much more variety so let's allow it to go all the way down to 25 then let's also say if random is less let's flip a coin and have it either be a square or a circle let's also i mean i think 500 images should i double the number of images just because um just because now i'm doing squares and circles let's see let's so let's try this so now my images are both squares and circles i'd love to introduce triangles in there but i think this will give us something more interesting just to start with because what i want to see with the latent space is the morphing between squares and circles and i i unfortunately the latent space is gonna have to wait till next time although i am planning to live stream this coming friday i could do it tomorrow probably not though tempted to come back tomorrow we'll see so now if i take this data right which should be squares and circles so this is now the new training data and let me just have is the code loading directly from that now i'm going to go back to my training code i could um let's generate whoops ah let's put the training back in ah sorry everybody what is going on i'm so having trouble i'm just going to manually do this so i want to load now 1100 images i want to train train the first 1000 and then the rest will be the tests um image loading where are the images being pulled from when i load all images uh so i think i might liked it to go directly into whatever processing has outputted most recently by the way i'm going to turn since i'm wrapping up i'm going to turn the heat off all right it's plenty warm in here and i'm going to be wrapping up soon so i've turned off the heat um so i'm going to grab this i'm sorry to be rushing a little bit here oh and they're all called square that doesn't matter and there's a thousand of them so oops no but that's fine the last one would be 999. wait a sec like i want to get rid of this and what oh i need four i need uh no no it worked no but let me so this should have a four here let me run that again oh actually ah no stop sorry everybody data is a thing okay delete all this the chat has gone quiet again so what i'm learning by the way is which is totally fine is the those of you who are here thank you it's a small audience for this on sunday morning let's generate the data again 1100 is that right yeah okay so now and then what i wanted to do is have yeah the images come from oh and this is so silly but it's fine i'm going to leave it as saying square that i do need to change because they're not all squares so i should probably use a more generic term but oh oh oh and then now i should be able to put that in there is there another place where i'm numeral formatting things i don't know what this is is this right this is writing the output but that's fine and so this should go to the actual data from processing so let's see what happens and then we want a thousand and then the 100 for the tests okay so now i should be able to train the new model oops line 21. oh i'm not loading anymore oh this is going to take a while for 100 epochs there's a lot more data let's see how the loss goes all right so q who just joined kyu what i'm doing is i have trained an auto encoder to which is a machine learning model to try to reproduce generic images of squares and circles so right now i'm training that model and once it's done i'm going to load a webpage which shows the results of what the model generates when random noise is fed into it there's a lot more pieces to this that i'm sort of missing here at 6 00 p.m yeah um okay we got to 100 okay so now so first of all we have a little we have some test things that i generated just to see so the output folder should now have new oh um i have to look at the noon ones yeah it's like a circle square squirkle is that the term okay great so we're seeing stuff so now in theory if i refresh this page [Laughter] this is so cool you can see this sort of like it's like a latent space browsing but i'm not really doing that yet now could i expand the universe of the inputs like purlin noise is very sort of like limited around the like i'm just curious so this is where i'm going to wrap up today i'm very happy with this result even though clearly i need a part four i need a part four um i would love to like just swap in open simplex noise but one thing i can do very quickly is i can do two times i mean i shouldn't do this but like i'm feeding in like weird negative numbers and stuff that it doesn't know about so just to sort of see this isn't wild um all right let me just go back to i'm not doing this weird thing that i just did here so ah all right oh 1204 okay okay just give me like five more minutes because i just want to see like i want to have a sense of am i capable of doing this at uh double the resolution right now so now unfortunately i've hard coded everything so let's just look for a second in it's like what if i were to uh i don't know about this oh yeah resize everything to so let me just do a little cleanup here just to leave this because i want to leave this in a place where people can play with it so i'm going to delete all the output i'm going to the model can stay there i'm going to delete the training data i want to just go through and then so let's do 28 times 2 which is 56 20 20 plus 20 is 40. 8 plus 8 is 16 56. so let's just try it double um so that's so i'm going to make this training data it's going to be a little bit higher resolution then when i go into the auto encoder do i have it hardcoded anywhere like 700 yes so now that is that the only place where that's hardcoded there's two places and then is 28 anywhere no okay so i need in this oh here it is so i need to have a constant w equals 56 and so this should be w times w this should be w times w and then this should be w times w is there any 28 anywhere w this is w this is w that's just 128 and is there any 784 hardcoded anywhere no then i should be able to go back to the sketch and also have i not really this so this should be uh w times w and this is w times w this is w this is w w this is all right so this i have to think about now so then i also have like little w which equals i'm just going to say height divided by the big w because then that is w times w right is how far over this is w w and then this is little w little w little w i think i did this correct so now all i need to do is like if i want to use a higher resolution image this is like whatever that is i just have to change it in two places here well three places the processing sketch the p5 sketch and the node server so i did it already here i didn't actually make it a variable here just to be consistent let's do that again there's there would be you know tying all these together would be better but now i should be able to train the model it's going to take much longer now i don't know how long like that's one epoch so one epoch was a few seconds there so this is going to take a while line 49 um so i don't know what line 49 was referring to um i think i got it already i'm assuming if it was in here if it wasn't here thank you missed one thank you for that yeah those variable names ouch yeah this is terrible so pull requests that i'm looking for are cleaning up the variable names love that making a nice readme that sort of explains everything and links to these live streams i would love pull request contributions for that i mean in january i'll get to it myself but i'm at epoch 31 oh boy this is going to take a while but this is this is um this is going to be the end for today i i did not the things that i didn't get to is just lopping off the input so the two the three the things that i wanted to try and this could go into the readme if anyone wants who's keeping notes on any of this nobody my mental notes are i want to see if the denoising works and then then i want to uh also actually work with the proper latent space by feeding the input like i just have eight dimensions and creating sliders to manipulate those that's next on the agenda um and you know then also trying training like rgb color could i do how high of a resolution can i push it we can see how long this is taking already just for um a hundred epochs but i'm halfway through i don't know this probably doesn't need to train much longer the loss is still going down um thank you for all these chat messages uh um is my discord even working there's nobody nobody putting messages into the discord but um i've got a supporter channel and discord that i keep open during the live streams okay we're at 80 we're getting there this could use some music right all right 82 83 84 55 86 7 88 89 98 51. seven eight 100 the loss is still going down i could let it train longer okay so now i mean in theory i should just refresh this page and it'll be working at the higher resolution with the new model because everything's pulling from the same directories but how is that how is that possibly going to be true okay yeah working this is wild all right let's move the late let's move oh this is so let's have the numbers move faster so actually let's just do this let's change the incrementation just globally here there we go so i it seems to be just kind of oscillating between a small circle and a big circle um but i think i really need to play oh there we're getting like a square but the purlin noise space is not giving me a tremendous amount of variety actually oh yeah look at that whoa that's cool this is like this is amazing i mean i'm like i you know i'm living like way in the past in terms of like where the current state of machine learning generative models is today but i don't know i just i'm just in love with this weird sort of thing that i've made but um i uh i want to make this go even faster i'm just curious to like let's let's keep pushing this speed of change here yeah what's interesting is how it goes from like small to big through a fade as opposed to actually like having to grow but and then every once in a while it like turns into a square shape um but anyway yeah where are the squares i'm i'm with you michael michael where are the squares um you know one thing that i would do here just out of curiosity is to change from pearl and noise to just randomness again um and sort of see what that gives us ooh whoops oh i'm missing the w times w it really does seem to be that so much more heavily circle making and it's kind of like it's going but i this isn't a proper test because and i'll go gonna go back this isn't a proper test because i'm not actually working with this in a logical way the two things i should be doing are number one if i am actually wanting to see what it does with full in the full input image i should be drawing strange shapes over here and seeing how they match up then i should be actually controlling the latent variables with sliders because i bet you we could find the circle to square that this dimension so this is what unfortunately i mean two hours and 15 minutes is all i can do for today so part four is coming on friday where i want to examine um actually putting in some input images to see if denoising like let's make also some triangles let's make this more sophisticated maybe rgb color could even be added and then working with only the decoder and creating sliders to allow me to manipulate it since you have more input variety you should train longer to recover the shapes properly yeah i also just needed to train this model longer but the initial results are amazing thank you so before i go any further well before i wrap up so what have i changed there's now the public directory that has the model in it and the the p5 sketch i've updated the um the node server to train a new model each time and uh the processing sketch um yes hand drawn circle as an input the output would be a perfect circle oh from perlin oh these are such good ideas file them as issues i mean or pull requests to read me but if these ideas i love these ideas i will not remember them so the purlin noise generate landscapes is a really interesting idea the um drawing and then seeing um seeing if we could make a machine learning model take your squiggly circle that you draw and make it a perfect circle i love all these ideas um so um yes let's do all that add them as issues into the github repo um so let me just do git i did that already git add git commit new this is like code for p5 sketch and training and saving slash loading model that's really what i did today git push origin main and you can see that model is you can actually work just with the p5.js sketch now because the model files i r m committing to the repository so uh if i go here autoencoder demo it's very painful to me that there's no readme here but um this is just the p5.js sketch this is the model that i trained most recently i'm just curious how big is this file 6.4 megabytes very reasonable so everyone can play with this to their heart's content those ideas that you have of things i could try next please file them as issues mini jimmy looks like so if you are taking your own you're making your own version of this um and you add things like colors and do like real expanses of the feature set don't pull request that but either file an issue or pull request a link in a readme to your version with um sample images but what i would love pull requests are documentation of what i have so far um any like small any like real bugs or like significant mistakes that are in the code or small clean up things where like the variable names are changed to be a little bit better i would welcome that but anything that's really significantly changing what i have so far i can't merge because i want to have a record of everything in the live streams but you can i could link to it and review it and incorporate those ideas okay thank you everybody uh thank you to brilliant for being the sponsor of today's live stream check out brilliant brilliant.org codingtrain um and uh i will see you all um whoops maybe on well definitely well hopefully hopefully on friday i'm going to continue this i feel like just leaving this here um i wanted to produce some squares no you don't see this this is like uh i was gonna like usually i'm just gonna leave this here as i play all the outro music and see you on uh the next the next live stream uh this auto encoder project has really been uh fascinating to do i have to think about what how do you think about what to do with this next like i could make proper video tutorials of coding the whole thing that are edited through i could make one video that summarizes it i would love your feedback on that like you're maybe the wrong person to be asking because you're watching this right now but a lot of you just are probably tuned in the last 15 minutes so what would you want if you weren't able to tune into all the live streams or if you wanted to go back and review parts of the live streams what would you want as something that comes out of this as a video i don't know uh i'm gonna be working on that in january okay um see you all do i have just the laptop button no i don't have a button for that here does this work yeah all right so i've removed myself i'm muting myself and i will see you all next time on the coding train um as always i always forget that this dot this this dot this dot i'm realizing something so while i'm playing that music i'm realizing that if i had the latent variables like tied to like frequency levels in the music or something then this output would go along with the music so as like the beat goes the circles would like change as the music slo you know like quiets down it would become more static this is also something for me to try for any of you who are adding issues to the repo for things for me to remember next time having the latent variables tied to input sound would be an awesome thing to do that was the invalid syntax i forgot uh there was one other thing here that i think is important that i will use continuously over and over again all sorts of text generation analysis things that i will use continuously over and over again first thing i need to do is yes kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens next time bye