all right welcome to tend to flow dais the layers API tutorial part 2 so previous previously on its flow test layers API part 1 I created this model using TF dot sequential TF layers and model dot compile with with a training without with a loss function and an optimizer now let's just review that really quickly before I go on to the next step which is looking at fit and predict so I'm gonna add some comments thank you to the chat just suggested that so this is the model create the hidden layer add the layer and the hidden layer has a number of nodes input shape and an activation function which i think is probably pretty selfexplanatory then the output layer is a dense layer so dense is a fully connected layer then the out create an output layer create another layer and here I'm gonna write here the input shape is inferred from the previous layer then an optimizer using gradient descent I must have a video somewhere that talks about what gradient descent is if that's not familiar to you and then I'm done configuring the model so compile it I don't know if this tutorial should be clear to be writing all these comments but it did that's where we are so enum standard are sort of classic machine learning process I would configure my model well actually before I do any of this I should have like collected my data I'd been really thoughtful about that and thought about the ethics of it and why am I doing this saying in the first place is this gonna help people or hurt people I should have been doing all of that but here I'm just looking at potential endogenous it's an API so I I'm kind of skipping those really fundamental the most important parts doing things backwards in a way and I'm just gonna make up data so what I want to do is there's two things one is I want to train the model I want it to adjust all of its weights to fit my training data I have these inputs with these known outputs maybe I'm doing image classification of all these labeled images cats dogs Turtles and I want the model to output cats dogs or Charles some probability value is based on which things that thinks they are and then so that's what this fit function does I could also ask it to do predict which means just take this data I don't know what it is this is not part of my training data and just give me the output so let's do something weird I mean weirder then of what I'm already doing which is talking to myself in a room with the camera and some lights I have like an iPad weird stupid sound effects on it I don't know what's what's happened to me in my life anyway let's let's run predictive not having trained the model will it actually just does it what does it start with it must have a whole bunch of randomly configured weights right must be configure itself randomly let's see if we can get some some output so what do I need to do to call predict let's go look at the API and let's look at again TF sequential so I'm looking for the predict function now here's the thing the pretty odd the predict function is there so it generates output predictions for the input samples model dot predict okay so config there are some configuration options like batch size and how verbose I want it to be but really all I need are the exits the X's are the inputs and I need two of them so what I'm going to do is I'm going to create a tensor I am going to say let input are obvious a Const inputs equals TF tensor one D and let's just give it some numbers like 0.5 0.25 sorry 0.25 0.93 it's a 2 so I just made up some inputs these and look all fake not real data at all I'm just trying to how tensorflow digestible layers API works so now I should be able to say model dot predict inputs now let's go back and look at this model dot predict TF one so interesting dip dip guess I'm good okay so hold on so let's say let outputs equal model dot predict inputs and outputs dot print I don't know could it really be as simple as that let's see and so now I'm gonna go back here uncaught expected dense input to have two dimensions but got array with shape too oh boy I think I might have a big major mistake here alright so what is this error hope oh boy this is the kind of error you're gonna get a lot which is something is wrong with my like shape shape errors error when checking expected dance tense want input to have two dimensions but got array was shaped to what is wrong here I mean after all there are just two inputs I said very specifically that the input shape is one dimensional with two things in it so why is this wrong well it turns out I forgot about this idea of batching so it is quite uncommon but it's possible that you just want to send in a single data point like these two numbers in and get the prediction and so even though this is the array of the inputs that needs to live in an array itself because I might want to send in multiple sets of them and so actually the correct way for me to put this here is to actually have this be the first element in an array and actually this is not a 1d tensor then it's a 2d tensor so now if I run this we should see there we go this these are the outputs and we can see here every time I run it I'm gonna get different outputs because this particular model is initialized randomly now there's probably a way with the layers API I could configure how the weights are initial initialize but it's using some default probably random maybe it's a normalized distribution of random numbers who knows we could look up the documentation and somebody in the comments will tell me okay so but what's interesting about this is now right I could do I could have right I could now send in four inputs and what will I get out all of those results so these are the three output values for the first input the second input at third fourth so this is how the predict function works so I can create a model and I can start predictions now they're useless and pointless and random without me actually trading that model so that's what I need to do next fit so let's now create a scenario where we have some training data right this is my and and by the way there is this really important piece of working with machine learning where you have both training data testing data you can even have something called validation data and then you have the new data the stuff that you're making guesses and predictions with so I'm not getting that far into it yet but let's just in this case I'm just gonna have some training data I'm not gonna have any testing data although we'll see I mean we're gonna look at fit we're gonna see see how this all works fit here we go so now I want to look at fit so here I look at this oh wait oh wait oh wait oh wait oh wait oh wait it just made the video tutorials about the weight so one of the reasons why so working with tensorflow digests natively you're one gonna feel somewhat comfortable with the idea of a JavaScript promise and these new es 8 keywords a weight and a sink so I will I'm gonna use those concepts you might want to check my promises playlist if that's new to you okay so let's figure out how we're gonna do this so model dot fit the parameters are X's X and y so here's the thing unlike here and I really should call these X's and this is really the wise right this is really what I'm doing these are the exes and now I'm getting the wise to fit I want to do the same thing the difference is I'm gonna have some known outputs so in this case I might have like this is my training data these are the X's and now the Y's are I need to make you know dreamily this would come from a spreadsheet or some type of actual database that I fossil Eagle I thought about how it to collect and the data and what I'm doing with it but right now I'm just making up dummy data so each one of these I probably just put in random numbers like weirdly sort of lazy about this I like to you just sort of see it so let's just pretend my training dataset just has instead of four let's just have three things in it and let's let's just make some arbitrary okay so this is now my training data I have the X's right the X's are there are only two of them again if I were doing on my like image classification example that I did previously in a in the with a toy narrow Network library I might have 784 inputs for seven or 84 pixels but here in my madeup scenario there's two inputs and there's three outputs so the X's have two and the Y's have three and you can see that reflected here so now I should be saying model dot fit the XS and the Y's let's look here now here's the thing there are some there's this variable called history that's kind of interesting so let's say Const history equals model dot fit and I got to get into the weight and all that in a second so what the history is is that's an object that's returned that has lots of information about how the training is going like how accurate are things what happened there if I want to start like looking at the properties of the training what's the current that type of thing oh right these mismatched thank you so I just started about three and three these have to match thank you to the chat for mentioning that to me okay so then I have this idea back sighs so batch size is let's look at that number of samples per gradient update if unspecified it will default to 32 so this has to do with the inner workings of how the gradient descent algorithm works right at some point gradient descent is going to look at the error and it's going to make all these adjustments to the weights and so does it does do that well does it do that after ten data points after 20 after thirty two so I'm gonna ignore that and then epochs or epochs or I could never know how to know what to know how to pronounce that word is the number of times to iterate over the training data arrays it's optional I think the default is one so here's the thing I'm actually just gonna let this go without setting any of those those things are going to be certainly important hopefully as I get into future examples or as you have specific scenarios but basically I could add an object here that has things like that has various configuration properties and this would need to be a comma here but I'm going to skip that right now because I believe according to documentation config is completely optional so let's just run this and then ever have to start talking about the asynchronous nature of this alright what happens if I say console dot log history let's just look at that so look at that I got a promise oh it's promising me something so what this means is fit is a function that executes asynchronously now it's possible I can do things with a kind of older style of JavaScript using callbacks because it looks like in the documentation here one of the one of the options I can specify as a callback but I'm going to use promises so what I'm gonna do is I'm gonna say model dot fit then and what I want to look at is I don't know what I'm gonna just sort of see and in this case I think actually the way that I'm doing it I'm not I'm gonna look at what's sent into the promise so this should now this should be a way this is if it returns a promise I can figure out I can get the result of how its what it's done as an argument to a function that's executed when the promise is resolved so this is how this could look just to look at that history and you'll want to look at my promises videos if this syntax doesn't make sense to you and we can see here looks like oh I have a history object and I have a loss there we go so this is actually the response and what I want to look at is the response history dot loss index zero so looking at this there we go now what happens if I give it a lot of now what happens if I start to add in a configuration like because I'm really curious what happens if I say so let me let me actually use a variable call obviously the call it config and I'm gonna say it two things I want to add is I want to say verbose is true and I want to say epi pox is five so because I don't see if it's verbose am I gonna get a lot of stuff in the console that's gonna tell me about what's going on so I want to add in some of those parameters verbose mode is not implemented yet oh okay so I guess I can't use it for Bost mode but I can add five and so this is just the loss after five let's add 100 Oh point to negative point to alright actually something weird was bothering me there for a second which is why do I have a negative loss like you can't have a negative mean squared error right mean squared error has to be positive it's the difference squared averaged over all the data points so I forgot that I still had cosine distance so let me put it back to mean squared error and now we can see that I'm getting something that looks like it could be mean squared error yes so one thing about this okay so I'm gonna get rid of this config and but what I really want to do is I want to see the lost values over time like as I'm fitting the model I'm running the training data in multiple times maybe I'm shuffling the order there's all sorts of things that I've done in previous videos that I want to do with tensorflow da Chasse so how do I have this model dot fit multiple times I mean I could just call it twice right ooh oh it did not like that whoa fascinating so I can't do that I don't know what's wrong with that but that's not really what I want to do anyway I could try to add a loop by the way the chat is really upset that I have these extra commas here so I'm gonna remove them JavaScript doesn't care it's like put your commas wherever you want like I have a lot of commas right oh no no no it doesn't want extra commas because it has blank entries but okay so so what if what if I were to put a loop here say like oh I want to do this two times so I want to fit the model twice again I got an error oh it really doesn't like this so here's the thing I I'm not exactly sure what this error is but uh maybe I'll somebody will tell me in the comments but I was going down the road I didn't want to go down this is where using wherever it was here in the tensorflow dot yes the a weight keyword is crucial so what I want to be able to do is I want to be able to call this fit inside a loop but promises just like everything's happen a synchronously because it's very hard to follow so actually what I really want to do is I want to go back to that syntax of saying Const history equals model dot fit and then this is what I want to do I want to say then console dot log history plus okay this is what I want this is like think Rinna's code blocking code this is what I want I want to fit the model and then see the results it won't do this because that's not how JavaScript works it works asynchronously so there is the await keyword which is new and ESA which says hey wait for this and then to the next line of code right shouldn't that work whoops and a weight is only valid in an async function so again if you watch my async and await tutorials you would know this but I cannot just do this anywhere in my code I have to create a function a function with the keyword async I'm gonna call it train and I have to do this inside that so this is now the correct syntax this actually is valid but it's in an asynchronous function I have to call that function so I could just call train let's just run this now and oh cannot reap repartee zero of undefined and train so what do I have wrong let's put the X's and Y's in that function well that's not the problem history let's just let's just look at the history oh yeah it's their history Oh dot history right I forget you forgetting this is the response so it was fine actually history dot loss index zero so I just want to look at just the loss so these don't need to be in here these I don't want these in here so now we run this again there's the loss now here's the thing I also just want I'm just gonna put a van in here because I also want to have some sort of event for when the training is complete so this function now kind of magically returns a promise because of the way that await and async work so I want to make sure this is working great and now training is complete now guess what I can now do this I can do this ten times so I can now the loop can go in here because of the beauty of this await syntax this is now work functions as if it's blocking code when it's all complete it will return a promise there we go we can see this is what we should have the loss should be going down right let's change that learning rate somewhere I set up a learning rate let's make the learning rate 0.5 you can see the loss is going down and maybe let's go back to 21 let's give it like a thousand basically a thousand iterations and we can see the loss is going down over time so and now what I could do I mean a thousand is a lot the training is now complete now what I could do is I can call remember this I can now call predict now again I'm only working with one data set my training data is my testing data is my validation data is by out by regular data that I'm using in the future once I'm done training the model so but we now see the full process I have X's and Y's I can call model dot fit again this is really hairy stuff not for the faint of heart I'm in the weeds of those sort of like lowerlevel tensorflow dot j s stuff I mean even though I'm in the layers API but using ES 8 syntax but now we should be able to see let's take a look at oh and it's I'm gonna have an issue here where I have these Y's so I'm gonna call this I'm gonna call this outputs so let's take a look let's train it just a hundred times whoops oh whoa silly me look what happened sighs we totally forgot about the asynchronous nature of all this stuff and I got the predictions before the training finished right because this is happening asynchronously which means what I want to do is after the training is complete then then I want to do by prediction so I want to Train using the asynchronous training a hundred times then I want to do my prediction all right so this is running we can see that the loss is going down it's training over time and when it gets to the end I've got the results of my predictions now you can see these don't look very good like first of all these don't resemble these outputs at all the main issue here is that nothing here makes sense I just have the skeleton of the story of data I can fit I can create the model I can fit it with some data and I can ask it to run a prediction with that same data but I'm ignoring like really important considerations and you can see that machine learning is just magic it doesn't just do the right I don't care that was the right answer so let me at least before I go add a couple things to so that we can actually see that it got somewhere so one thing that I want to do is I'm gonna just simplify what's going on here I'm going to make this data something really obvious like zero zero one one point five point five that's my X's and then my Y's I'm gonna I want to get I want to get one I'm gonna just change that to just output 0.5 and 0 whoops what I miss here yeah oh boy syntax there we go so what I'm doing here is I'm just trying to like come up with some ridiculous scheme that's like super simple to learn like they're sort of like an inverse linear relationship here zero goes to one it's like the map basically let's see if there's a neural network can learn the map function but and why using two numbers and one numbers here but whatever so now I am going to I have to change the output to have just one output and now let me run this so we can see look at this the loss function is still pretty high so there is something that's kind of important here you can see it's going down and actually it like a thousand iterations that it kind of got something it got something pretty close so I would just need to give it more time to train to kind of reproduce the known results but I just want to show a couple important things here one thing that's important is I probably should always shuffle the training data so there is actually a kind of important one of the configuration parameters here for the fit function like if I shuffle is true what this will do is whatever you eat X's and Y's are each time it puts it through the training function it'll do it in a different order and this will really help things as you're training with the same data over and over and over again so let me add that in and just see what happens there so I'm gonna add this config here to here so this is shuffle that's the only thing I've turned on doing one epoch at a time still so let's also while I'm here just to make things go a little faster let's add let's do like 10 a pox at a time once again total here a thousand times 10 is 10,000 epochs right but because I want to see it over time I'm not just putting not just doing this once with the number 10,000 there I'm doing it 10 I'm doing it a thousand times with ten but this what I think will make things move a little faster and we could say it got even better here and so now we can see this over time we can see that the the the loss is really going quite far down now I'm gonna have to sit here and wait for a minute which I'm gonna do but you're not gonna have to this will video will now speed up alright I'm back so look at this I reproduce those results right at reproduce the same results that my training data produces should have produced and I got the lost down pretty low so you can again completely meaningless trivial nonsense nothing but hope I'm just I'm hopefully this is helper to you it's helpful to me because I'm trying to figure out just how the library actually works itself so let's review for a second okay let's review everything I have shown you now these two videos that I can create an empty model right the diagram of my neural network architecture is an empty model then what I could do is I can create layers there can be dense layers or other kinds of layers that I might look at in another time in the future and I can add them the order that I add them is very important because it is a feedforward sequential model so this is first in this a second beef you know I'm thinking this is hittin an output but they're really just layer 1 layer 2 ok once I've done that I have to define how what sort of mathematics are going to be used to train the model and there's a loss function mean squared errors what I'm choosing to use and opt an optimization function stochastic gradient descent with a learning rate of 0.1 that's everything from Part 1 and now what I've done here is I've shown you okay if I have some data presumably coming in from a spreadsheet I turn those into tensors I can use the fit function to train the model I can say fit all of the weights with these X's in these Y's once that's complete I can then ask it to predict with presumably new data this skeleton has not used any meaningful data I'm also not really being thoughtful about like well what activation function makes sense or what optimization function makes sense different things work for different scenarios so hopefully we'll see that more in the future as I make more videos I would encourage you to just try to do this baby with some actual data play around with it try different input shapes activation functions play around a little bit see what you get let me know about those results in the comments let me know if this was helpful to you and I will see you next next video I'm gonna do I'm gonna look at that X or a problem again in the context of tensor for about yes okay good bye