okay my glasses on hi uh fixing my hair okay edit that part out uh welcome to another video in the nature of code video series and today I don't have anything in my I I'm missing my pen here it is I have to hold it I feel more comfortable this way today we are making a huge leap forward so if if you actually watched every single video or at least most of them up until now you would have found that all of the simulations there's a circle on the screen a square on the screen some shape on the screen it's really an inanimate object it has no decisionmaking ability it has no life it has no hopes and dreams and fears it's just sitting there and forces in the environment push or pull it around what we want to do in this very moment in this very spot together today is say we want to begin to build simulations where the objects make a decision I think earlier in probably the first video I think I might have talked about a a ball sitting on a table that falls off the table versus a little creature sitting at the end of the table that chooses to jump off that table today we want to be that creature that jumps off the table that that is able to perceive its environment and make a decision as to where it should go now we have we want to do this just for its own sake because this is going to be interesting and allow us to build um different types of motion behaviors that we haven't been able to do so far but we also have another goal in mind so I want to um come over here for a second and look so this is um without the mouse in the center oh I I don't this does not control that Mouse this is this mouse anyway that's irrelevant what we have here is an example that you'll find in processing it's the flocking simulation we're going to get to this example probably at the end of this set of chapter 6 videos but the reason why I want to look at it is this is an example of a complex system what is a complex system complex system is often thought of a system that's more than the sum of its parts well what is the part here the part is this little triangle that's moving around the screen that operates with these really three Simple Rules don't run into my neighbor stay with the group try to go in the direction of the group we're going to look at those rules later more formally but but that simple those Simple Rules we can understand each one of these individual triangles very easily but globally then we get this kind of unpredictable highly intelligent ordered yet chaotic um Behavior it's really quite amazing and and you know there's tons of examples of this in nature ant colonies termites lightning earthquakes the weather uh think about the stock market there we could go on and on and on and come come up with tons of examples of systems of these simple agents that when you put them all together you get this Global intelligence I mean an ant can't be that sophisticated but how does an ant colony build an elaborate set of tunnels and collect lots of food and I don't know protect the queen disclaimer I have no idea what ants actually do but you know something like that I watched I don't know bugs life or be movie or I don't know there's a bunch of them anyway so this is where we want to go if we but but before we get to stuff like this we're going to look at these simple agents now um so I'm going to get to all the details of this I guess this video is kind of like a little bit of an introductory landscape of this topic and I wanted to just point out to you um a couple things that I think um are useful for you to think about so um okay let's take a moment to Define what we mean by autonomous agent so what are the what are the sort of principles that we're going to think about as we start to build these simulations that involve entities that can that can that are more alive okay so one principle is that an anonomous agent has an ability and there's a sort of key word here a limited ability to perceive its environment now this may seem like a trivial detail to you but this will become quite an important factor in in what we end up programming right is are the things on the screen able to see anything within um 25 pixels of itself or perhaps is this object on the screen only able to see things that are in front of it at a certain distance right so what is that limited ability what can it actually see on the screen or smell or sense right we want to build start building entities these objects that have sensors on them you know virtual software sensors so okay the other thing that we want to do is once it's perceiving its environment it it's going to kind of process that environment so let's process the environment and calculate an action so the key thing here is calculate that action so I'm I'm an entity and I'm us I got to get a better word than entity but I'm a thing and I see that there's a bunch of things in front of me and those things look scary so I'm going to calculate my action which is to run away in the opposite direction right what is that calculation going to result in it's going to result in a force so what's really um what what's really important about what we're doing here is we're not we're not really doing anything new we're just thinking about things differently and coming up with some interesting formulas and logic and rules by which we send forces into our objects so even though we're thinking wildly different conceptually this thing is alive this thing is not alive um wind is something that just affects it you know external Force like wind versus an internal Force like fear um in the end they're all just going to be forces and um the last thing I want to put on this list here is that is that there is no Global plan or leader now this isn't some hard and fast rule you know from everything you ever build now in processing you better not have a leader in that program you know we're not say I'm not saying that by any stretch of the imagination but one thing that's important to realize is um we as a kind of exercise here are building entities that just respond to whatever they can perceive around themselves and and and and make a decision and and and and and calculate an action based on that there isn't some Global leader telling them what to do now you may want to build simulations with global plans and leaders in them and that's fine but a true autonomous agent wouldn't have that it really is making its decisions only based on its own perception of the environment so these are the kind of key principles that we're going to see in the programs we're going to build now what are these examples we're going to make and where do they come from so there's a lot of places there's a lot of things we could come up with and think of um ultimately we're going to build our examples off of the work of uh Craig Reynolds and his um uh all based on this paper he wrote called steering behaviors for autonomous characters um which I'm going to get to in a second but before we do that let's just look um at some kind of nice examples of this so I uh I have this video on a loop here which I'm going to try to have no idea where it's going to be in the video but um so this is from Casey Reese's process compendium which I will link to below and you can see here here there's an element with a bunch of rules if you I I highly suggest you go pause this video go watch his video and you can see here are all of these elements that are operating with these very simple rules they perceive their environment what are they near if they hit something if they're if they intersect something turn if they don't intersect something goes straight and all of his work these beautiful artworks are created out of these incredibly simple rules and I can kind of um um scan through this and you can see I'm going to go back to the beginning we can see it as maybe this this di this this this simulation is perhaps a slightly better um representation of that so one of the the reasons why I wanted to just quickly reference um uh Casey Reese's work is because a lot of his inspiration comes from am I still here yes it comes from this book I have a prop now it's a book it is paper oh it's like a Fanning me okay this book called Vehicles by um Valentino brenberg so um Valentine brenberg is a neuroscientist uh and I think if I go here and this is just the page of the book on um Google book and you can see what what's nice about this book is it's kind of exercise in science fiction in a way and creating these ideas of these little robots with sensors that see light and this one is afraid of the light and this one is attracted to the light and um and and brenberg really thinks of um these vehicles as almost like you know pets or little creatures and they respond to fear or love or aggression or foresight and and so I think this is an important place to really think about a a really nice set of inspiration for how you might want to think about and build autonomous characters so I will also link to some material on brenberg vehicles below which you can look at as a kind of source of inspiration for you but the reason why I bring this up is brenberg Vehicles were a main source of inspiration for Craig Reynolds steering behaviors so what we're ultimately going to look at um and build a set of cring examples which are just pure implementations of Reynold steering behaviors for autonomous characters so this is a paper that was uh written in 99 um I I encourage you to take a look at it I'm going to kind of go through a lot of it in a less formal less depth processing speak and so you might want the kind of true uh guts of this by taking a look through this paper yourself but what Reynolds has done is has said okay we don't really care exactly about how things really truly work in the real world what we want to create is the appearance we want to create lifelike and improvisational characters that move about the screen and I one of my favorite examples there's a whole set of behaviors wandering and seeking pursuing a Target uh following a path one of the ones that I think is a great illustration of this is queuing at a doorway and we can see here in this um simulation we have a lot of elements that are all trying to get through this doorway but as they come together they have to slow down and stop so how what is its perception of this environment how does it know where the door is how is it trying to get there how does it see the things around it why does it choose to slow down when it gets near something these are all the types of things that we want to step through so we're going to look at the um this idea of a steering Force how do we calculate a steering force and what are a lot of scenarios whereby we need these steering forces what kind of steering Force do we want when an object wants to catch some you know catch its prey um versus escape from a crowded room because it feels very claustrophobic in that room room strange scenario there's a great I I should link to it below there's a great um uh paper and Sim online simulation that came out recently of simulating a MH pit um so what is what do a mher in a MH pit desire to do and what types of decisions does it make based on how other Mosers are moshing around them right you could ask yourself that question you could come up with a set of rules and then you could simulate that and I encourage you to take a look at that simulation which I will link to below I don't have it prepared here because I don't prepare for any of this just blabbing on and on I will get better at This I Swear okay so um let's talk so we we're this is just a lot of Flowery language and kind of walking through a bunch of things here which which I'm almost done with but what I want to do is kind of talk through how Reynolds thinks of um um what his Vehicles do so Reynolds thinks of his Vehicles as operating with three steps action selection steering and Locomotion so our objects that we're going to build in processing are going to follow these three steps action selection is looking at the environment and choosing an action oh I've got to get that food oh I've got to run away for that Predator oh I really want to get through that doorway oh that path looks lovely it's the yellow bck Road let me follow it right so we have to choose a desire and here this word desire is really really key all of our objects that we're going to build are going to have a desired velocity the velocity the direction and speed at which they really want to go at the moment once they have that desired velocity we're going to calculate a steering Force based on it that steering Force I just want to write the word is a force it's just a vector so just the way we calculated an attraction Force we calculated a friction Force we are now calculating steering forces we're going to have a very specific formula for it which is so simple and elegant and but powerful and that's really the Innovation that that Reynolds came up with with this framework so we're going to look at how we calculate steering forces and the good news here once we have that steering Force we need to apply it to the object's Locomotion it needs to move what are some options for Locomotion well we could have Oiler integration location velocity and acceleration we could use box 2D we could use toxic Libs right the third step is the physics simulation so all we're doing here is we're saying we have an existing physics simulation and now we're going to layer on top of it this methodology for choosing behaviors and applying forces to those objects so th this so everything that we've done all videos long is all building up to this point where we now have this physics engine we could use any one of these we're going to use our own we're just going to use P vector and our own location velocity and acceleration and now starting to apply steering forces to it so um I'm going to stop this video here that's kind of an introduction to the landscape of all of this stuff I think I have this list of things that I covered and in the next video we're going to all we're going to really look at is this very simple calculation for how we calculate a steering force and the first behavior that we're going to look at is Seeking a Target so like ah over there is something I want to get there I'm going to how do I steer in that direction which is very similar to gravitational attraction but I want to look also at like how this model differs from that and how it's in many ways more powerful or at least a better model for entities that might be alive or kind of providing their own set of um uh you moving themselves about a space as opposed to just experiencing a force okay um thank you and uh I'm say good night but it's the afternoon I I'm over here now okay goodbye