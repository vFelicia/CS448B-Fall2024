hello good try good good day intranets it's Friday which means it's time for the coating train Here I am again my name is Dan today is Friday June 2nd the year is 2017 and I'm back for another weekly episode live stream of this internet youtube thing that i do which is something to do with coding hi here that's what I was told as I was wandering down the hallway and somebody said what happens in this room where I am okay so uh I've got a bunch of things to talk about I see that the chat is going strong and lots of people saying hi and choochoo and all sorts of other train related greetings in a variety of languages which is super nice okay I've got some stuff to talk with everybody about today so I don't know if any of you were watching last week if you weren't that's probably for the best but I got a little Mia culpa here which is that I attempted to you know I've got this summer project my summer project I don't know how I ended up doing this but this is my summer project is to teach and create a set of video tutorials about artificial intelligence and machine learning and I'm kind of on the tracks I'd like the train gets derailed quite often but I've been making a variety of tutorials and things and I'm right now I'm in the weeds of building up and trying to set a foundation for neural network based machine learning and who I hear people talking they're talking about me and so one of the things that if I suppose I'm just going to let's let's have some resources here to talk about I'm going to go to this YouTube channel thing and you can see that most recently right now I'm in session three so I'm trying to make a set of videos for a course and I'm not really kind of doing them haphazardly over time in an arbitrary schedule but I'm looking at the chat now and I'm on session three so let me let me get myself centered here if I go to the syllabus session one was all about algorithms and search and graph systems and I have a variety of videos that I made about binary trees and breadthfirst search and a star search in traffic salesperson section two was all about genetic algorithms and I did a variety of videos about kind of walking through what a genetic algorithm is and a few different scenarios and applications and so I'm instill in I'm I'm working this week three session three is designed to set a foundation for session four so the idea session three is to talk about machine learning what was she learning is what are typical tasks performed by machine learning namely classification looking at data and trying to label that data it's hot it's cold it's a name a picture of a cat it's a picture of a dog there are a variety of ways you can think about labelled data as well as regression which is making a prediction based on data that has a continuous output so a regression might be let me try to predict the weather based on icecream sales or the other way around who knows or you know the classic scenario is let me try to guess they have a machine learning algorithm predict or guess the appropriate price for a house based on the properties of that house so this is where I've been okay last week or two weeks ago or at some point I looked at something called linear regression with gradient descent and the idea here oops let me turn this camera on the idea here is to is to look at a very simple scenario okay so ultimately ultimately eventually the idea of deep learning the reason why machine learning based systems can be powerful and interesting and experimental and playful or useful all of these types of things is because we might have a some data that has many many many many many many many many many many many many many many many many many many many many many many I don't know if you could see that yeah you can all my little lines per it many dimensions so if you think about a house you know there's the number of bedrooms and there's the number there's the square footage and there's the zip code and there's maybe the the average temperature there's it something to do this is there's all sorts of nukid you can come up with a very very very very very long list let's try to think of and so something like trying to learn something about an image or a piece of text these are also high dimensional examples of data with many dimensions like an image has like all these millions of pixels in it so have we make sense of so so much data but in order to get a file in order to to understand how the systems work that can approximate a function that will perform a classification or regression with a lot of high dimensional data coming in it's often easiest to start with well I'm just off in the weeds here it's often easiest to start with it and try to understand well what if there was just one data input so the only thing is you know temperature and from temperature you can think of that as X we're trying to predict sales Y and so we might have an own data set which we could plot on this graph of temperature as related to sales and then we might be able to perform what's known as a linear regression which is trying to fit a line of fit a line to this data that approximates it so that if for any given temperature I can make a prediction as to what I think the sales would be okay so this is what I've done so far this is the case that I'm making I want to be able to build and work with systems with high dimensional data so it's not just the temperature I'm using to predict sales it's so much more it's all about the temperature and the humidity and the population of a city and the you know the list goes on and on and on and on that's what I'm trying to do so okay coming back over to here let's see no matter what I talk about anytime I glint whenever I glance at the chat almost all the time the discussion is I think Python is better than Java actually really should program in C++ but Lisp Lisp is the answer to everything but I like a program with JavaScript because it's the best language ever that's always what the discussion is I was able to stop that from being the discussion when by accident I started talking about temperature in Fahrenheit I mentioned I really should use Celsius and then all of a sudden the chat Fahrenheit versus Kelvin versus Celsius nobody was talking about which programming language is better than the other one was the glorious day okay I've only made it worse okay so now so you can perform a linear regression using a statistical approach so with simple data like this and I can even see that it's very small I'm gonna have to write bigger make larger drawings you can perform a linear regression with simple data like this just using a statistical approach so there's a formula to actually figure out where that line goes nicely but if we're looking to make this prediction in this impossible to visualize our parser understand high dimensional space with a lot more than just a single piece of data we can't actually just solve it exactly we don't have the computational power to do that but we could take the approach if let's make a guess let me guess where the line goes and then I can see like well how poorly did that line do let me do some type of evaluation of the error based on the existing data and that line and maybe I'll just like kind of push the line in the direction where I try to like minimize that error and I'll do that over and over and over and over again and this is known as gradient descent okay so this is why are we doing this I want to make sense of high dimensional data that I cannot make sense of easily in order to do that I want to build up some skills to make sense of low dimensional one dimensional data I can do that with distal approach when I get to the high dimensional data I'm going to need to just do a sort of knob twisting trial and error more like approach so why not do the low dimensional data with that and that is the most recent video that I made linear regression with gradient descent okay so I then I did this example without digging into the actual derivation of the formulas for how to add rank those adjustments so you know there's a the formula for a line is y equals MX plus B M being the slope B being the yintercept and so these are the values that I'm tweaking to try to get the line in the right place so when I did the video on a gradient descent I just used the formulas to do those tweaks and then I said I'm going to make some followup videos to derive those formulas and I logged in to my YouTube account Here I am NOT so I but I think if I go under playlists and under session 3 so I have now unlisted these because the derivations of those formulas require a few rules from calculus they require the power rule the chain rule and partial derivatives and I made three videos on those topics those videos weren't very good they're not very good what them um yes some people like them I use 'fl for me in that it forced me to kind of revisit a topic that I had once studied but haven't spent a lot of time working with in my day to day coding life but I did discover something in the feedback and comments that I got which was that I think while watching my channel really enjoy the winging it approach when it comes to coding the making mistakes are trying to debug that sort of part of something that everybody can relate to perhaps people learn the most when they see me trying to figure out an error and finally fix it even if I can't fix it all but getting a suggestion from the chat but I think that it wasn't as use I'm learning that maybe it's not as useful for me to try to walk through a topic from mathematics while winging it and not really knowing what I'm doing or where I'm going so there's not as much of a sort of like live debugging aspect to trying to explain the chain rule in calculus so I think these videos didn't turn out very well now thankfully with some of the feedback I was going to read some of the comments but I guess I don't need to that there is a YouTube channel called I think three blue one brown and three blue one Brown is a YouTube channel that has lots of mathematics and other related tutorials in particular there is a void this essence the Lydian or algebra one I definitely need that one to which I'm going to get to there's this essence of calculus so uh this what I'm going to do now I think is my approach is now if I go back to my playlist so uh right now these are still in the playlist or unlisted I might remove them from the playlist I'm not sure but I think what I'm going to do now I'm still going to have a three point five where I go through and drive the formula but um because I think that's useful because it's a specific formula I'm using in my code and it kind of will relate and tie together I'm gonna use it again and again in future neural network tutorials but I think of what I might do instead is instead of referring people for background calculus background that I'm using to my videos I'll refer people to the three blue one Brown videos which are better and more comprehensive so that's my current plan so for today I really would love if I can today to get to session four and I think the thing to think that I get requested the most is really like do a whole multilayered feedforward fancy superpowered all together magical neural network thing in you know whatever your favorite languages of choice I definitely will not be getting to that today but I would like to build a perceptron today a perceptron being a model of the simplest neural network possible a network that really is in a network at all but a network of one neuron the neuron receives inputs the neuron fires an output and what what how does that process work and how is that the building block for larger multilayered more complex neural network system so that I would really like to do today that's my goal before I get there I think I'm going to attempt to do one followup to the gradient descent video where I derive the formula for how I change the weights do you hear that I feel like there's always these like and then and head and then up and then go into the perceptron how's that sound to you guys I'm looking I'm looking at the slot okay so let's see first well let me just see if anybody's watching me today 500 people are watching well so that's kind of amazing and great I appreciate that i I've been feeling kind of a little blue down the dumps a little bit over the last week cuz I really feel like I botched it up and I kind of lost a little bit of confidence here you know this is all a learning experience for me and uh you know I think one of the things that I try to do is not be afraid to just try to explain something or try something live in a youtube channel and it doesn't always go so well and it can be difficult to read the criticism but I get to say it was really wonderful to read the comments from the last week it's on these calculus videos because they were written in such a thoughtful and constructive way and they were negative but they were helpful and they were kind and so that I really really appreciated the Kota Gabe's so I'm getting the chat Dakota game to switch gears for a little bit and I did um I was thinking all let me take a break from the machine learning stuff today and do something different but I feel like I gotta just keep pushing through it so I think I'm gonna push through it I wanted to do two live streams this week and I fail to make that happen I also wanted to do uh ADA from the slack group had an excellent suggestion to do something for Pride Month and with rainbow colors since you know I have an affinity for rainbow based imagery as you might have noticed so that could be sort of a fun generative graphics things to do today but I think I'm going to stick with my machine learning stuff because now and and and Julian right don't listen to the haters on YouTube so I get a lot of you know you can't be on a YouTube channel without getting a lot of like comments about how terrible you are with making your videos and those uh you know I read them sometimes it so it's a little odd and to read them sometimes they just kind of go right over uh you know I'm pretty lucky to not be harassed and I think that that is definitely an issue that other youtubers have to deal with and it's a big problem with the online community so I want to get to go down that road right now but I you know I think I'm pretty privileged here in terms of the the the kind of audience reaction that I get but I forgot what I was saying but ya know either it wasn't a volume up please if you look at let me know if there's an issue with my volume okay I look at the chat and completely lose my train of thought it's kind of I well this is one thing I've never been able to figure out how to do effectively which is kind of like read a chat and talk and like have a program in a whiteboard all that sort of stuff but um I want to be clear I didn't feel like people were unreasonably commenting negatively about my videos they were explaining what that made sense to them what didn't make sense that they had knowledge about it they were pointing out what could be more helpful less helpful oh that was great okay uh yeah Zerg rush Joe in the slack channel is a great point which is and I always say this to students which is that you know I can be stuck on a problem for so long and I could just go and do something else for a while and somehow this like subconscious thinking about it without the pressure of having to solve it when you come back to it it's much easier to figure out and do and keep your brain thinking about the subject even when you do something else and it helps you get through a wall that's excellent excellent point okay now so what I'm going to do fir okay couple things so I keep mentioning the slack channel I will just do my quick plug for various things if you're interested in supporting the work that doing even if you don't like even if I think supporting me make trying to make videos that are bad and failing at them sometimes you can go to patreon.com/scishow to rewards and things that you can get a slack channel that you can join for by signing up and supporting this crowdfunding platform you can also go to coding train Storenvy comm if you would like to get some coding trade merchandise and i also always like to mention a nonprofit organization that I help to administer called the processing foundation which maintains the open source projects processing p5.js and processing Python and a lot of other community and education based initiatives and if you're interested please join the processing membership program and if you're a you if you're in the United States those donations are taxdeductible okay so those are my three quick plugs let me close this what I really want to do I kind of I'm not going to actually do this but I have this very strong desire oops let me skip this I'm like by accident playing an ad here just play three blue brown videos and like watch them like Mystery Science Theater and like kind of like comment on them as they're going because they're really really good ok alright so now ok but let's see so I'm just now I'm just taking a moment to breathe music has driven me mad yet visible man okay alright so let's see where am i timewise twentyone minutes so okay so I think what I'm going to do is I'm going to take away the pressure of right now this is going to be a recorded edited video tutorial and I'm going to talk through my understanding or going to a practice I'm going to talk through my understanding of the math behind gradient descent and then I'm going to listen to your feedback and look at reading the chat see what makes sense so what notation is Right wrong and then I will try to do it again as a video tutorial and if for some reason whatever I do right now is which it never will which it won't be then maybe I won't even bother to do it again but um let's just see how that goes okay so I'm having a little bit of a runny nose today should I need to mute myself hopefully this won't blow out your ears okay okay feel like I want some kind of ridiculous whiteboard market puttan marker pocket protector thing okay so I'm starting to think about just trying to program Frogger by the way which is a good idea okay so let's let let's think about this okay so to recap I have a bunch of data points in 2d space I have a line in that 2d space the formula for that line is y equals MX plus B now when I try to make a prediction right I get a piece an input of data input X and from there I try to make a guess and I in addition to the guess I have the known Y so this is the correct data that goes with X my machine learning system makes a guess the error is the difference between those two things the error is y the correct answer the guests but what happens when we look at this error right we don't care so much right okay so so that's the error so there's an error okay so this relates to the idea of a cost function loss function so if we want to evaluate how is our machine learning algorithm performing we have this large data set maybe it has n elements so what we want to do is from 1 to n for all n elements we want to minimize that error so the cost function cost equals the sum of Y sub I every known answer the guests sub I squared is that something you can actually see yes it is so this is the formula this is a cost known as a cost function this is the total error for the particular in the particular model being the current M and B values that describe this particular line this is the error now this error hold on I'm thinking here for a second that's rad see people like I like glanced over at the chat and I see Tetris like please none but you know I was everybody wants machine learning man it's like the thing I gotta do it I got it to some machine you gotta teach machine learning it's all I was hearing and so I said I'll try that I could learn that I can understand it I could teach that it's hard I'm having a hard time with it but I'm gonna keep going ok so perhaps we can agree we can agree that our goal is to minimize this cost also known as maybe a loss we want to minimize that loss we want to have the lowest error we want the M and B values for the lowest error so we want to minimize this function now what does it mean to minimize a function I'm trying to find the space on the whiteboard where I want to do this next piece okay I just like to go glance at the chat okay okay so now let me think this might actually make it to be a video just different pieces will get edited in different places okay I'm tempted to okay so I'm gonna yep so I'm just got I'm gonna draw Singh here then I'm going to race it so let's say I have a function like y equals x squared see what's confusing about this what's so confusing I've noticed in reading and doing a lot of reading and reading blog posts or watching other video tutorials and this is something that I think I would be able to improve if I were writing this in a book because it would give you a lot of time to kind of rethink rethink reedit but figuring out an appropriate and clear notation is very difficult because I've got like you know this is a function it's like lime and now I'm going to talk about another function because this is a function there's a y here y equals x squared so actually I think what I want to do I'm gonna erase that for a second or say okay so this function is something equals something squared which is not that different from like me saying just for a moment like y equals x squared so if I were to take a Cartesian coordinate system and graph y equals x squared it would look something like this I'm drawing in purple now because I've stepped away from this notation and syntax for this particular scenario and I'm just talking about a function in general y equals x squared you're going to also write this like f of X equals x squared but I'm graphing y equals x squared so what does it mean to find to minimize this function right I said I want to minimize the loss I want the smallest error I want the whatever line has the smallest error well what it means to minimize a function is that actually find the x value that produces the lowest Y this like the easiest thing in the world that we could ever possibly do right now you don't need any calculus fancy math or anything too fun to minimize this function there it is it's at the bottom it's the lowest point zero its I could I could see it it's quite obvious so this is the thing eventually we're going to in in the machine learning systems that I'm going to get further into neural network based systems with many dimensions of data you know there might be some much more hard to describe crazy function that we're trying to approximate that it's much harder I mean of course we could eyeball this as well but as much harder to sort of mathematically just compute exactly where the minimum is especially if you imagine this as instead of a single line but a bowl and then what happens we can get into three dimensions in four dimensions and five dimensions things get kind of wonky but there is if we know the formula for this function there is another way that you can find that minimum that minima minima minimum I don't know which it is and that is what I keep talking about gradient descent so let's think about what gradient descent means let's say the current error sorry let's say we're looking at this point here and I'm I'm gonna I'm gonna I'm oh I'm gonna walk along this function and I'm like I'm right here I'm like hello I'm looking for the minimum is it over there over there could you help me please can you please provide me can I use my like GPS Google Maps thing to find the minimum how would I find the minimum well if I'm right here I've got two options I could go this way or I could go this way and if I knew which direction I could go I could also say like I should take a big step or I should take a little step right there are all sorts of options so I need to know which way to go and how big of a step to take and there's a way to figure out how to do that and it's known as the derivative so the derivative is a term that comes from calculus and I would refer you to three blue one Brown's calculus series or you can get a bit more background on how what the meaning of derivative is and how it works and how you can sort of think about these concepts from calculus but for us right now what we can think of is it's just the slope of the graph at this particular point and a way to describe that is like a tangent line to that graph so if I'm able to compute this line then I could say well this direction if I go this direction it's going up and I'm going away from the minimum if I go this direction I'm going down and I'm going towards the minimum so I want to go down and you can see like over here the slope is less extreme if I'm right here so maybe I don't need to go very far anymore but if I'm further up that slope is going to point much more this way oh I should take a bigger step down so this idea of being able to compute this slope this derivative of this function tells me how to search and find the bottom pause for a second minima is plural uh yeah guess why do it I would love to see four occur uh I'm sorry I'm not in the wrong screen now oops this camera went off alright so how am i doing so far I'm going to pause for a second you like me to me I'm not going to do Tetris today okay I'm not in the right I'm going to push through this I don't understand this because I'm in the 10th grade says thon okay yeah um okay um all right thumbs up okay okay so I'm going to keep going here okay so I'm gonna come back to here oh look at this this camera is pointing in a weird did I bump it or was it always doing that Green is there there we go all right remember how I said I was going to practice now I just am sort of doing this I might I'm going to should probably record an intro to it okay okay so now now that we have that established that this idea of finding the derivative or the slope the direction is a way of finding the minimum so if this is the function then what I I want to minimize this function if I could somehow find the derivative of this function I could find the okay okay time out we must establish a few more things to get a little further along here okay okay so I want to say a bit more about this function so about about this I'm pulling I'm thinking I'm thinking pausing I'm thinking hold on I'm always by the way completely standing outside of the frame so it should stand over here if I'm thinking I'm thinking about where I'm going next here so I need to talk about okay okay okay so if you think back to the previous video actually don't even think back let's go look in the code do I hold on I don't have this open so I code the point of doing this is because we're programming okay okay so this is the landscape of the puzzle we're trying to solve and pieces of that puzzle but what is the full what's the what's the actual part of the code that I'm trying to give you more background on the actual part of the code that I'm trying to give you more background on is right over here so this is the gradient descent algorithm that I programmed in the previous video where what I did is we looked at every data point we made a guess we got the error the difference between the known output and the guess and then we adjusted the M and B values M equals so the idea here is that we want to say every for as we're training the I don't know which color I'm using right now as we're training this system I want to say M equals M plus plus Delta n some change in M B equals B plus Delta B so I want to know what is a way that I could change the value of M in y equals MX plus B in order to make the error less I would have minimized the error how do I do that how should I change B in order to minimize the error so the answer which is in the code is this just equals a you know why guess times X times the learning rate if we can forget about the learning rate right now right that's the answer that you can see in the code right here the Delta is at error times x4 be the Delta B is just the error so how do I get that okay so I want to try to prove that this why this works now so I need to I want to rewrite the function here in a slightly different way this function which are calling the cost function let's call it J J is a function based on M and B so I want to get the error for Emma B I'm also going to remove the sum and I'm just going to say what's the error for any M and B equals and I'm going to call this I'm going to say this is where I this is where I'm stuck I might need some help with notation I kind of want to call this like error error of x squared hold on I'm stopping to think maybe I should give this a mathematical notation I give that H of X square okay let me start over here okay to do this I'm gonna attempt I'm going to unfortunately start to use some more mathematical looking notation and I'm gonna try to describe it as I go and hopefully we won't get too lost so this cost function I'm going to call j j and it's really a function of M and B right I want to minimize the error for certain M and B values that equals I'm going to get rid of the sum to simplify I could keep the sum in there going to get rid of the sum to simplify that equals and I'm gonna say I'm going to I'm going to take what's written here and call that H a function H of X right what this actually is is y is this something you can see y minus MX plus B right that's the actual and should I should I have reverse that should it be guess why I think I saw that it should be guess why it doesn't really matter because I'm squaring it but maybe I should fix that and this red marker is hard to see so let me go back to purple you this is like continuity all right let's see III guess I'm going back on my like I'm going to do this twice I'm actually just going to do this once but really slowly and back up here and there and match is going to have to do some magical editing I feel like why am I always out of the camera shot I need to turn this more this way yeah like standing in the wrong place okay that's better okay so let me get the purple pen okay you know I realize I kind of messed up its in some ways it doesn't matter because we're squaring this but I think textbook wise I should really be thinking of the error as the guess the noob so let me just switch that for a second okay so notation wise I've now called the cost function J and I want to call I want to take so I have this in my trying to do multiple colors here I want to take this right here guess why and I want to call them to call that H that's a function of X actually it seems weird yeah no no no sorry it's not a function of X what is it a function of I just it doesn't really matter X is wrong I'm going to use the chain rule I know where I'm going with this but I'm trying to think of a notation hold on and now I'm going to have to work this out for a second because what I want to do is if this is equal to H of X then D of J according to M that this will be is going to be the derivative of H of X I'm I lost here H of X times the derivative of H of X right because then I'm going to get Oh but right no no I'm sorry wait of course using a chain rule but is the X misleading in here using the chain rule I'm going to if this is H of x squared then I must say two of that same two times that same function times its derivative you know relative you know d h d h relative to m but does the X make sense there or is that confusing I'm going to look in the check because then this is going to give me this is where this is where I'm going then this is going to get it I can get rid of because the learning rate is going to cancel it out I could have just added a 1/2 but so then this is going to be why this function which is what which is a guess why guess y times the derivative of guess y relative to M which is M X plus B minus y and all X&Y it'swe're cos x and y are constants here I'm doing the derivative relative to M so what I end up getting here is just X so that's why I have the error times the input X that's where I'm going my question is what is the proper what's a good notation for me to use for the function that I'm going to have B this like error function let me go look at the chat now and see if anybody has any suggestions that's what's usually used J as a function of M and B it's the guest that you're differentiating yeah I know it's a function of Y all right it's a function of Y in x2 function so if I I mean usually the notation I see is just right it's a function of Y I mean it's just a function maybe I don't you know what maybe I shouldn't use the maybe it actually what I should do is not even like you know I could go to any let's look at like if I go to let me let me just google something like gradient descent derived am i doing timewise three o'clock like here okay so you can see here the H like these are the weights of X yeah the those are the weights so this is the the theta here the weight is equivalent of my like m and B yeah the x and y's are constants so it's not really I think I should just call that like you can see here it's really also just a function of this is funny this is exactly what I'm doing this was a good this is a good one to pull up see that this I'm trying to stay away from this notation that gets really really difficult to read see what I mean I've already lost my y guess I know is a function of X let me let me come back to the whiteboard here which might help me here I think what might actually be most useful is if I just call this H if I just call that H or just call that error I'm gonna just call that error that's an individual error that's what I'm gonna call that okay let me try this okay I forgot where I was but try this again all right you guys III I almost want to go look and see I'm sure I've lost at least like 100 to 200 viewers let's do buddy I will get back to making things like Tetris and Frogger and that type of thing eventually okay well I don't know why I just erased that okay so when we come back to this point here okay so in order to figure out what these Delta values are I didn't want to rewrite this function again for the millionth time I think I want to use some mmm I'm gonna rewrite this with some from different notation to try to help keep things going here so this cost function I'm going to call J J is a function of M and B so this loss right there are some values there's a value of M and B and when I have a particular value of m and B I can look at all of the errors across all the points sum them up and I want to find the mm to be with the lowest value now another way of writing this up here is I could just take this guess this guess minus y and I could call that error so I'm going to say that this is really a function J is a function of the error squared I want to minimize I want minimize the error squared I want the least squared error so here's the thing what again what value of M how can I change m to minimize what this is I can figure out which way to go along the I could I'm just sorry I'm taking a guess it'll be fun I get to backpropagation okay I think I've got this down but I realized I'm kind of like have a continuity problem so I've got to come back and I got to go back to where there was a time in my life where I made these videos without doing them live okay okay here we go here we go everybody this is take four hundred and eight thousand and twenty million the next step that I want to do is find the minimum cost I want to minimize this function for a particular I want to find the M and B values for the with the lowest error so to do that we've established that gradient descent says if I could find the derivative of a function I know which way to move to minimize it so somehow I need to find the derivative of this function to know which way to move okay so in order to do that though I'm gonna have to rewrite this function in a different way so a couple things one is I think I made a mistake earlier where this should actually be done it's sort of doesn't matter but this should be guess why we were squaring it so in a way the positive negative doesn't matter but I think this is important for later so this should be guess why that's technically the error is a guess why not why guess okay so I'm going to call the error function J and J is a function of M and B so I get something I'm sorry not the error function because I'm about to call something else the error function the loss function the cost function J then I'm actually what I'm going to do is I'm going to say I'm going to just simplify this guess why and I'm going to call that error I'm also going to take out the summation the summation is kind of important it but it this has to do with that stochastic versus batch graded to sent that I talked about in the previous video where I could I want to get the error over everything I just want to look at each error one time so let's simplify things and say we're looking at each error one at a time so I'm going to now say this equals error squared so I have essentially rewritten this function and simplified it the cost J is equal to this error the guess y squared so what I want to do is I want to find the derivative of J relative to M I want to know how do I minimize J how how does J change when M changes dfj relative to M okay so in uh you know again I recommend that you go and check out some of the three blue one Brown calculus videos which will help give you more background here but what I'm actually going to need to do here is you use a use two rules from calculus I'm looking for another pen color for no reason I need to use the power rule that is one rule and I need to use the chain rule these are two rules um so there are two rules that I need to do the power rule for a derivative is actually just take the exponent to take the derivative of something squared I take the exponent I subtract one from it and then I multiply take the X ah let's just do it let's let me let me just put a background okay look I really tried to like somehow I thought like using multiple colored markers would solve all my problems clearly doesn't okay let me let me establish what the power rule is really quickly if I have a function like f of x equals x to the N the power rule says that the derivative is n times X to the N minus 1 so that's the power rule so I'm going to now apply that here and I'm going to say I don't know why I'm in purple now but I am two times error to the first power the other thing however is though I want to know how J changes not according to error but according to M and the error is a function of M error is actually a function of M and B as well so the chain rule says what I can do is now say I can take this error function I could get the derivative which is just 2 times error and then I can multiply it by the derivative of that error itself relative to n so the cost the derivative of this cost function that I'm trying to minimize relative to say M is I really want to swear I never swear how to gentleman I realized like I've got a lost I got you know I there's just so many pieces here that I'm like glossing over and skipping but I'm going to just keep going with this for a second double back I guess if I have to I just this is not an adequate the chain rule is like I'm kind of glossing over this detail so like is there really any point of me driving this if I haven't really explained the chain rule I guess I have that other video where I explain the chain rule but it's like the video really really struggling with what to do here okay but I'm going to keep going two times error tines okay let me maybe I'm going to try to explain the chain rule really quickly okay let me back up for a second I did the power rule okay I'm gonna let me try to okay so the power rule says now two times error okay but I also need the chain rule I'm not done why do I need the chain rule well the chain rule is a rule I'm going to erase this over here use another marker because somehow if I just use multiple colored markers all this will make sense the chain rule states who okay let's say I have a function like why can you reach you see this orange y equals x squared and I have a function like X equals Z squared so Y depends on X X depends on Z well what the chain rule says is if I want to get the derivative of Y relative to Z what I can do is I can get the derivative of Y relative to X to X and then multiply that by the derivative of X relative to Z which is then x to Z so that's the chain rule I can kind of chain these derivative functions I have two functions and I could get the derivative of one but I should stock quit while I was ahead I can change I riveters I could get the derivative of one relative to something time's the derivative of that something relative to something else and that's actually weirdly what's going on here it may not be immediately apparent to you but J is a function of error error is actually a function of M and B right because the gas is some so so whenever I sometimes I just have to like say to statement and move on J is a function of error and error is a function of N and B because I'm computing the error as the guest MX plus B minus a known Y so here I could then say get this derivative 2 times error and multiply that by the derivative of that error function itself relative to M because if I'm trying to get Delta n now I could also also do it relative to B when I want Delta B and this has to do with a partial derivative well see there's so many concepts baked into this that are a lot maybe add again I'm sitting here being like this was all just a bad idea okay but what is this this is actually quite simple to work out and I'm going to do that for you right now I'm gonna get the black marker and what I'm going to do is now I want the derivative of error relative to M okay well what is this actual if I unpack this function guess is M X plus B minus y error equals this so when I say partial derivative means like the derivative relative to M what I mean is everything else is a constant X is a constant B is a constant Y is a constant I mean x and y are actually already constants because those are the things that X is the input data Y is the known output result so this really I should write this as like x times M plus B minus y so this the derivative of this right the power rule says 1 times x times m to the 0 power which means x and the derivative of a constant is 0 because the constant doesn't change right derivative describing how something changes the derivative of this is there so guess what it's just X meaning this whole thing turns out to just be x equals 2 times the error times X and guess what this two we're gonna the whole point is if you watch the previous video is we're going to take this and multiply it by something called a learning rate because we wanted to we want to like we know the direction to go this is giving us the direction to go to minimize that error minimize that cost but do I want to take a big step or a little step well if I'm going to multiply it by a learning rate anyway it's sort of like this too as no point because I can have a learning rate that's twice as big or half as big so ultimately this is all it is error times X all of this math and craziness with power rule and chain rule and partial derivative this it all boils down to just finally we get this error times X that's what should go here in Delta M guess what let's go back over to our code edit point oh yeah yeah okay week Mon thank you for a good okay but where am I here but why did i whoops we go back to our code and we can see there it is error times X air times X there we go that's it that's why that says error times X no look that was a lot that's why it says it I feel so happy that we kind of even though it was not the best explanation and there's lots of confusing this in pieces I feel very happy to have arrived there this was useful for me just making this video makes me feel like something happened today okay so um I just want to make sure I had a comment in the chat and maybe I have yes yes yes yes this should say ah this is a big mistake here wait hold on no it's not hold on yeah that's the chain rule okay okay okay okay that's oh that's not a mistake but okay so okay where's my purple marker I put the wrong cap and put the wrong cap of it I'm putting the caps on the wrong markers my kids do this all the time they put the like they put all like none of the markers have the correct caps on them drives me crazy okay hold on okay two things I want to mention a couple things I want to mention here a a way that I can make this make a little bit more sense here a little just to clarify this chain rule thing a little bit better thank you to K week bond in the slack channel is that I could just to see here on what I'm looking for is the derivative of the cost function you know relative to M what happens when I change the M value what does that do to the cost and the chain rule says that if I look at the derivative of that function start relative to the error I can multiply that by the derivative of the our relative to em right so this is actually the chain rule so I can get this by doing the derivative of relative to error the derivative of error relative to M and that's what's going on here two times error times this and that's where I'm getting all this stuff okay so this is one way of looking at this and you can see like oh yeah it's kind of like the numerator and denominator cancel each other out so that makes sense the other thing is if I get this whole thing again but did the derivative down here relative to B right B instead of M what do I get here well I get this is now a constant so this becomes zero this is a constant this becomes zero and what is this this I take the power rule so I take one times B to the zero I just get one so this becomes a error times rather than times points look at this nest that I wrote here can we please end this video with this at least written is the very nice handwriting so when it's relative to M this was two times error times X but when it's relative to B that's when it's relative to M but when it's relative to B it's two times error times one and again we could get rid of the two so it's really just error times X or error times one and then if I come back over here again there you go error times X M changes by error times xB changes by just error Oh so um that hopefully gives you some more background as to why these formulas exists this way and we'll give a chat and as I go forward in session for what comes after this is now session four where I'm going to build a neural network model for learning you're going to see this formula over and over again change the weight instead of saying m and B I'm going to say the weight well the weight changes based on the input multiplied by the error and then there's going to be a lot of some other pieces of but this formula is going to be everywhere so I hope this was another attempt again you know there's a lot of things I've glossed over here in terms of a lot of the background in terms of you know what really is a derivative why does calculus exist why is the chain rule work the way it works why is the power rule work the way it works what's why what what that partial derivative hon did you things like that partial derivative and so again take a look at this video's description and I'm going to point you towards resources and tutorials that kind of dive into each of those components a bit more deeply but hopefully this gives you some semblance of that overall picture okay thanks for watching and uh I don't know maybe maybe you want to hit like or subscribe but honestly totally totally understand totally totally understand don't you get the thumbs down I get it again it okay I'll see you in a future video maybe okay goodbye people of the chatter oh I can't go if you were actually worried about me or if you just like are tired of watching this because lots of people are saying please take a break from his math stuff the thing is I'm just going to feel so happy once I'm done with all this math stuff and honestly I maybe I should just do this on my own time but I'm kind of figuring this stuff out and okay so alright both I know what both means okay so one thing that I need to do is I need to do a quick since somehow instead of doing what I said I was going to which I was just going to work out the math and then kind of like once I figured it out make a video tutorial I kind of just worked it out and stopped and started and I made a big giant editing puzzle again before machiya and this might be another video that I post and then decide to like tick off the internet but you know anyway when I say take off the internet I'm never going to delete this so anybody wants to watch this and offer some feedback maybe learn something maybe not learn to like it will always be there it's a matter of whether I include it publicly in the playlist as part of the course materials and that's sort of the question I'm wrestling with but I do think I need to now that I've done this I do think I need to now that I've done this come back and just do like a one or two minute spiel for the beginning of this video okay so did I get it am I getting this why guess and guess why thing all wrong all over the place in multiple places I don't know okay so here we go hello it's me coming to you again from the future you might recognize me some from my failed videos as a calculus partial derivative anyway I made some videos with some calculus stuff they didn't turn out very well you can find them if you want they're kind of unlisted now but I just I tried again and so this video if you're watching it this is a followup to my linear regression with gradient descent video that video stands alone it's a programming video where all I do is walk through with the code for how to build an example that demonstrates linear regression with gradient descent and this is a puzzle piece in my machine learning series that will hopefully act as a foundation a building block to your understanding of hopefully some more creative or practical examples that will come later this video that if you're watching it's totally optional to watch as part of this series because you just applied the formula but what I try to do in this video is give some background and I kind of worked it all out here this is the end this is what's on the white board I thought now if I use multiple colored markers would somehow make a better video I don't think I really seems did that but um so I kind of walked through and trying to describe than that I should say that you know this involves topics from calculus and there's a great video series by three blue one brown on YouTube that gives you great background and more depth in calculus so I'll put links to those videos in this video's description honestly if you're really interested in kind of soaking up as much as this as you can I would go and watch those videos first and then come back here it'll give you that background for understanding the pieces that I've done here so I look forward to your feedback positive and negative constructive feedback into whether this was helpful if it made sense and if you then go on and keep watching there'll be some future videos where I'll be getting back into the code but there's no code in this video just the math stuff maths max okay I enjoy okay it's backwards in the code that's why the plus works there oh I see so it should be got it got it got it okay you know I always just try it one way or the other Here I am okay alright so we did it everybody we did it we did we did it we did it whoo whoo we can party time excellent kind of please be done now I just like never make a video again I guess I will keep going all right first I need some water cuz I have to admit I didn't really stay very hydrated throughout that I think is a bit of a problem I saw somebody in the patron group on slack pointed me towards the dance your own PhD thesis competition which is really wonderful I feel like I should do a dance version a gradient descent to be maybe something like this okay so now I think then the next thing there's two things I could do right now there's so many things are good you right now I have I have a fair amount of time I step over an hour before I have to go so there's a good amount of time let's try our little slip I don't know if I should do this drop whole thing it's always a terrible idea but let's whoops so let me talk you through sorry a guy still some water on my trackpad so I'm fixing that okay let me um there's nothing running there I just want to I'm going to show you two things that I could do I could so one thing is there's still one example which is basically this so this is an example that uses a JavaScript library to do regression and you can see here it's exactly what you imagined in that it's just the same as my ordinary leastsquares video but this is just using a library that does the computation behind the scenes and I can also do polynomial regression which means I can try to find a function that's a curve that fits this and you can see this is actually the function that's fitting it best you see this is a width so I could do this which I think has a lot of interesting applications just in terms of visuals and graphics even so that's one example I could build and demonstrate next that says like a one last piece in this week of classification regression the session three or I could go straight to working through the perceptron which actually you know what I have a have some slides of some diagrams so so I could this is the simplest model of a neural network a single perceptron that receives two inputs and as an output and I could walk through the code and the particular algorithm for how it works and build an example the perceptron I want to do both of those today so the question is should I skip the regression and go straight to the perceptron or should I work on the regression with the and I'm trying to decide and should I do it in processing sure do it in JavaScript I don't know like so let me let me strawpoll this because I'm so indecisive and somehow I think this is going to which goes straight to perceptron do poly do do other regression do regression library example first even even if that limits even if that pushes perceptron to next week like which one should I guarantee which one should I guarantee that I do I don't know that I have time for both so I'm going to create this poll I think I should go straight to perceptron I vote this is the poll strawpoll comm slash III gr8 one somebody who's a moderator it could maybe put that in the chat and I'm going to just go to view results there's no results yet I guess you guys are behind Oh mention the dangers of overfitting yeah go straight to perceptron good to see what all right all right that looks pretty clear to me all right so I'm leaning towards go I'm going to do everything that I have on my list at some point it's just sort of like what order do I do those things in I kind of I would be very glad to go straight to the perceptron to be fun to be honest okay that's that's pretty clear so now you know even I I don't see how I don't see how anything that's going to come back okay go straight to the perceptron okay so next I'm going to I'm just curious I'm going to another strawpoll perceptron processing Java p5.js JavaScript so I'm always curious about creep pull okay so now here's the next one five nine three ybe six and I'll take a look at these results in a little bit I suppose I could still look at that other poll but okay Oh fascinating close one everybody tie goes to processing by the way oh yeah that's amazing I'm senior profit gets like 40% of the votes I feel gonna do it prize I have the power to do whatever I want come on folks let's get some more votes for frosting and now let's do it that amazed how many people are voting how many people are actually watching ah good work everybody it's coming back I'll post the link to the whole straw poll comm 5 9 3 decoding trade brought to you by drop hold up do you think if I just like baked random endorsement as people start sending me checks in the mail look at this this is amazing this is like much too exciting okay I gotta give this I was gonna wait till this song is over and yet this song actually is 2 minutes left Python Python is coming I'm gonna do except lights on this summer every day how come why is life so hard there's so many other things I have to do think of how much bang videos I could make it was just you every day Wow look at that you guys are just the opposite of trolling me you're giving me a nightmare okay all right I'm gonna give this here's the thing I have the example I'll make it invoke just about in order to do this okay I'm gonna fade out the music you have one more minute to vote 15 seconds fifteen seconds their goal all right and final tally is processing with 124 votes p5 Jess with 104 boats and I totally didn't influence that at all I mean I was and I was like totally not influencing that at all all right it's nice let's do some processing today it's a good it'll be good it'll be good I will happily do it twice if necessary I will port the code this is not I'm not writing new code what I'm going to do is program and talk through a particular example that is already written about in chapter 10 of nature of code book with a little bit of background and the code on the website is all in processing but I also have if I go to nature of code examples p5.js and I go to chapter 10 there is a JavaScript version of it right here so rest assured that there is a JavaScript and processing version out there for you and what matters here is the concepts the algorithms not the language okay perceptron poka I love that okay so now I need to get myself ready let's see what version of I'm gonna close this I think this might actually might consider this to be a coding challenge video and I should do like a session for introduction okay so there is a newer version of processing let me get that download that by the way once again I will just mention while in downloading processing ah so many thinks I want to do that I'm so behind my todo list is really out of control but anyway please consider becoming a member of processing I know that I often mentioned my patreon and I'm thrilled and honored and for the support that people give me personally via patreon but I think that it's also important and perhaps moment and actually definitely more important to support nonprofit opensource development and you can do so through the processing foundation if you're interested ok now let me get the most recent version of processing which is three point three point three copy that to the desktop here and replace that and I can't it's in use close this close this here we go okay so now let me open up processing let me open up my guess what I have slides can you believe that I have slides it's only because I have the diagrams for the nature of code book and I put them into a PDF so I can use those so let me get this going here how is this font size font size okay maybe it should be a tiny bit bigger I guess maybe it's fine perceptron oh you know what I don't want to call that what do I want to call this hold on what did I do in nature of code I want to have a class the perceptron class so so what did I do we look at the code here simple oh I just I see I called it like simple perceptron and had an example number so yeah when I do that so this is a coding challenge simple perceptron and I will make a new tab when I get to it I'm going to add a set up and draw in advance how's that font size people are I somebody in a slack could tell me if the font size is okay it's too hard for me to follow the oh hi Simon Simon is watching Simon his wonderful viewer hello I love watching your videos make a p5.js version Simon has actually been hoarding a lot of my examples back and forth and so I will definitely make a p5.js version absolutely and if anybody wants to contribute that I welcome that too okay okay let's see looks fine size is good you can see things kind of in 120p okay sorry I lost my train of thought all right you guys okay it's okay for me to erase this beautiful diagram it's looks so dark by the way looking over at my monitor and everything seems so dark I need better lighting okay so I'm going to erase this everybody's okay with that speak now as always I always forget the dis stop this stop this stop this duck and then beating this stop this stop I believe dis dis stock the stock is this stock this stock this done and indeed this stop to stop and you lose this fish stock the stock is done and you do this stock will stop and is not this stop this stock get stuck underneath this stock is stock this stock one of these days I will get one of those glass panels that goes in front of you you could draw on it okay Vista Vista Vista Vista song okay so I think what I'm going to do in this particular so at some point I need to make an intro to session for video which will kind of give a little bit of background about neural network based learning some references and resources to historical references and resources but I'm going to put that aside for right now and so then the first video will simply be a coding challenge where I just launch right into the perceptron so what I need to do in this video is kind of explain what a perceptron is um what perceptron is and define a simple scenario to to solve with a perceptron right all the code for it to implement that and then towards the end I mean kind of reference why the single neuron the simple perceptron model isn't particularly useful but can serve as a building block for larger and multilayered perceptron based systems that can actually do all sorts of things that's kind of my overview of what I meant going to attempt to do and then so that's my overview one thing that I want to reference is I'm in week four okay so I think that this is probably let's look on Wikipedia to see if I'm missing anything really sort of key here in terms of historical background actually okay right 1957 right right right right right okay I mean you know there's a lot of soup okay so I think this is a single I think this is a single video with not very much editing hopefully yeah look at all this interesting sorry I'm like looking at all this stuff on the Wikipedia page okay alright so sorry I'm thinking about what is the best scenario here I'm just gonna get started okay good I'll ollie in the chat ask whether you're going to make it tutorial about Chrome extensions uh soon I hope I mean I do like that's something I'm going to teach in the fall for sure so it's a point I will make those tutorials I should really go the sooner than later because I won't have to do a lot of like math stuff okay yeah yeah yeah okay all right here we go this is going to be coding challenge number what number am I on here what number coding challenge am I on coding challenge number 71 it looks like oh load more nope 72 coding challenge number 72 for a second I thought I forgot that I forgotten to record this to disk but I'm okay okay oh yeah here it is okay let me okay all right all right all right I'm sorry I'm ready I'm ready I'm not really but I'm it's four o'clock so I haven't out this is the last thing I'm going to do today well if there's time I'll answer some questions but I have to be done by 500 which is an hour from now and I can only assume that this won't take an hour but there's a lot of pieces to it this is not the simplest thing to mean that perceptron itself is incredibly simple but in terms of designing a whole system to demonstrate it that can be a little bit trickier so but we're gonna go for it anyway okay here we go No hello it's time for the perceptron okay how's bad idea hello welcome to another coding challenge this coding challenge is part of my intelligence and learning series and in this coding challenge I am going to attempt to make something called a perceptron and know this is a piece of the puzzle I'm working towards this path of eventually can I please start over I have one Mulligan here this is this is this is what happens to be oh it starts to get warm in here okay oh wow sorry hold on I think I'm going to lose the sweatshirt because it's getting a little bit warm here so we will change to just tshirt oops I do have a slight problem here which is that I need to fix the mic yes okay this okay this sound okay still can you everybody hear me okay sound good okay move some stuff over okay this is this coding challenge is really gonna happen now okay here we go hopefully the sound everyone saying yes it sounds okay okay hello welcome to a coding challenge in this coding challenge I am going to attempt to make a perceptron this is part of a whole bunch of videos that I'm doing about neural network based learning and but in this video I'm not kind of getting into too much about the whole broader landscape of everything historywise and future wise about what's happening with neural network based learning in this example I just want to build with code the simplest model of an artificial neural network possible known as a perceptron perceptron the concept of perceptron was invented by Frank Rosenblatt in 1957 at the Cornell aeronautical library laboratory I there's a link here to the original paper which I will include in this video's description if you want to take a look at that and of course you can always find more on the perceptron Wikipedia page but what I'm going to do now is talk about what it is okay so what is a perceptron now I'm going to go back over here I forgot that I had diagrams okay what is a perceptron mmm failure okay whoops hope this can be old ah okay oh yeah okay what is a perceptron so ultimately what would do what I'm doing in this coding challenge is building an artificial neural network now it's using the word okay okay do I need this diagram this is yeah okay okay by the way there will be editing in this coding challenge here by announce I got just I gotta get really in my own head here I just gotta shake it all off and let it go here we go okay what is the perceptron why are we making a perceptron so why what is the deal with this uh okay there we go what does it forcep Tron why are we here why are we making this so the idea here is to be inspired by the way the actual brain works the idea of the brain you know this is not a video on the brain and neuroscience but the idea is that the brain has neurons in them those neurons receive I really am I really really explaining the driver I try really is this diagram really a part of okay okay I wouldn't get some momentum here in a second okay but what does the perceptron why am I even here talking about this so ultimately I want to look at artificial intelligence machine neural network based machine learning systems that are inspired by and modeled loosely off of the idea of the actual brain the actual brain being this thing with like neurons and axons that connect other neurons and dendrites that receive inputs I actually don't know what I'm talking about just reading what's ever on this diet but a perceptron and ultimately where I'm going to start building examples and show you examples of lots of these these components that are all interconnected and inputs are coming in and and outputs are flowing out but I want to start with this idea of the perceptron being a model of a single neuron the simplest possible artificial neural network that we could build and this will serve as the building block for future examples that it will make in future videos okay so let's come over to the whiteboard for a second so if the idea of a perceptron is that there is a single neuron call this a neuron that neuron could have inputs let's say there are two inputs I'm going to call them X 0 X index 1 so inputs 0 and 1 they come into the neuron some type of mathematical process happens in the neuron and then there is an output which I'll call Y or output so these are inputs and again this diagram it might look familiar to you if you've watched some of my other videos because I often talk about this idea of there is some amount of input so long list of inputs that go into some machine learning recipe that processes all those inputs and performs a task maybe it tries to classify or perform a regression but make some sort of output some sort of prediction so this is exactly what this perceptron is designed to do okay here's the thing in order for us to understand and look at all of the pieces of what's happening in here we need some scenario I have these I never have like premade diagrams but since I have these I'm going to go back and forth and use them so this is the premade scenario that I'm going to use what I want to do is clap I want to perform classification I want to find out if some points are on one side of a line or another side of a line and so does this make sense what I'm saying here let me add one maybe I won't I don't need this diagram I'll just draw that and go back oh I'm on the wrong camera so let's come up with a scenario that we can use so let's say I have a two dimensional space you could think of this this will be my canvas my window and what I'm going to do is I'm going to arbitrarily divide the space with some line some points will be on one side of the line and other points will be on another side of the line so essentially I what I want to do is use this perceptron for a classification problem I want to say that these belong to you know Class A and these belong to Class B so and I'm going to use a supervised learning strategy so for background on some of this you could go and watch session three of my intelligence and learning series where I do some other videos about classification and regression using a linear regression model there's a lot of crossover here but anyway you can stay here if you want I'm going to kind of talk through everything but the idea is I want to classify these so I want these inputs to be so x0 at any point right here like this X comma Y is a little bit confusing the way I'm using it's I don't I hate I don't love this because I should really think of the the X is input 0 the Y is input 1 right the X is input 0 the Y is input 1 the output is Class A or Class B the Y so I'm using x and y in two different places in slightly different ways which is a bit confusing but hopefully will make sense as we continue to go along here okay so but I actually want to say instead of instead of a and B what I actually want to say is plus one and negative one so the idea is that my perceptron is going to output a plus one if the point belongs to group a and it's going to output a negative one if the point belongs to group B so how does and we're going to use the technique known as supervised learning and what supervised learning involves is I am going to ask the perceptron to say here is some input give me a guess but I know the correct answer I'm going to give the perceptron a point that I know should be in a and it's going to guess either a and B if it guess is a I'm going to say great job perceptron you keep on going if it guesses B I'm going to say perceptron you made a mistake let's tweak something about your algorithm to try to get you to the correct answer and this tweaking is a process known as gradient descent and it's something I've also covered in a couple different videos that I will also link to down here we're going to go through it as I get through here okay so that's the supervised learning process okay so what is the actual algorithm what happens here inside the neuron so here there's here's the missing piece there's a there's a few different missing pieces that I'm get to over time I was stepping on something enormous these you can think of as connections the input flow into this neuron but our waited waited waited as they flow in so each one of these connections has a weight I'm going to say W 0 W in W 1 so these inputs are weighted and what the perceptron does its algorithm is to create a sum of all of the inputs multiplied by the weights that sum is X input times sorry input 0 times weight 0 plus input 1 times weight 1 now in this case the perceptron only has two inputs so this is a very easy formula to write as you're going to see as I get into future videos you might realize like oh there's a hundred inputs or a thousand inputs or a hundred thousand inputs but this same formula is always going to apply a weighted sum of all the inputs input zero times weight zero input 1 times one add them all up together so that's step one is the some step two before so you could say like okay we'll take that and that's the output but this isn't the output step two is something called an activation function activation function and this is a key concept in neural network based machine learning as I get into future videos we're going to see there's a variety of different kinds of activation functions and wide let you use this one or this one and what do they do and why but typically what an activation function does is it allows you to conform the output to some desired range and do thing and another way another way to think about it is if you think about that idea of the brain like you can think if does the does the neuron fire and continue to send its data along or does it not so what happens as the data comes out of that neuron we're going to use in this particular example were going to use a very very simple activation function you could think okay well I only want two outputs I want a plus one or a negative one how can I take any number I can take any number and convert that number into plus one or negative one how would I do that how about a function called sine take the sine of any number n if that number n is positive then I get a plus one if that number n is negative then I get a negative one okay so that's the activation function this is the whole process it's off it's often referred to as feedforward the inputs come in they get multiplied by the weights they get added together and then that weighted sum gets passed through an activation function and then that activation function gives us a plus one or negative one should the neuron fire or not fire and that gets sent out and that's the output okay pause for a second so there's a lot more to this but I think what I'm going to do is go and write the code for this now I'm going to just check it to see if there's any questions audio sounds fine what about zero yeah that's a good point I can't see what that chat message was I'm reading in the chat there's like a message that says I feel bad for anyone older than like 25 but I've got I've got some serious problems bed is this is the focus on the whiteboard okay can you see it looks like it's fine to me okay okay so there's good questions here okay okay I'm back from check I was just checking a live chat that's going on if you're watching this is an archive of a live chat doesn't exist but there are two important questions before I move on number one is what do you do is 0 I don't know we could just pick we could just arbitrarily right now let's just say this is greater than or equal so 0 will will consider +1 I mean in the case this is just like a toy example just to demonstrate the idea it's a building block you know I don't know how meaningful it is to be able to like classified points into these place by sort of lying in your at but but so if this pointed to make an arbitrary determination for that what if it's on the line you know is it is it above or below I'll pick one the other question that was asked is well how do you pick these weights so this is the essential question and this is where I have to get to so the idea is that what we through the supervised learning process we want to search for we're basically doing the search to find the optimal weights the optimal weight values that will get the best results there's a results with the least amount of errors and so to start we have to pick something to start in this case we could pick random values we could just start with the weight at 0 that could be problematic so there's different ways this is a big topic in the field of machine learning when you start a neural network based system how do you how do you initialize the weights randomly what kind of distribution of random numbers do you do some other kind of like learning process that gets do like a good starting point for the weights that's a big topic of discussion and research but for us I'm going to pick random weights and start to tweak that ok so there's a lot more pieces of this still but I think I'm going to go and start writing some code and the come back two pieces that we're missing okay so I'm going to do this in whoops I'm going to do this in processing which is a Java based programming language and environment you can find out more about it at processing org I will also release a JavaScript version of this that you can run in the browser so check this video's description for links to both source codes after it's over okay so what I want to do is I'm going to create a perceptron class so what is it the what is it that a perceptron needs a perceptron needs weights so actually hold on I think I have some yeah uh do I want to look at this hold on all right let me hold on yeah I want to create a perceptron class so we can see here by the way I have this slide here this is the same algorithm I just talked through let's just make sure we have it right the algorithm is for every input multiply input by the corresponding weight sum all the weighting it weighted inputs and then compute the output based on that sum pass through an activation function the sine of the Sun so we can see we can think of like this could be the point at 12 comma 4 and these could be the weights of the perceptron so what I'm going to do for this particular perceptron is I am going to create an array to store all of those weights and I'm going to say it's an array with two elements in it and in the perceptron constructor I'm going to loop through all of the weights and give them a random value between negative 1 and 1 so but whoops you don't say void with a constructor I don't remember how to program in Java based language okay so this is the constructor and what I want to do in the constructor is initialize the weights randomly okay now what are some things the perceptron should do well I one of one of the things that should do is it should be able to receive inputs and then compute a guess and output we'll call that a guess okay so let's write a function I'm going to call it a guess and it should return an integer plus 1 or negative 1 and it should receive inputs which could also be in the form of an array now I could if I wanted to because the simplicity of the example I could have done something like float W 0 and float W 1 I could just sort of have individual variables for the weights instead of an array but the nice thing about doing this way is this is more flexible that this we could have if we reuse this code later with what we could adjust the number of inputs and that sort of things within our array okay so first thing I need to do is compute that weighted sum so I'm going to create a variable called sum and initialize it at 0 then I'm going to loop through all of the weights and I'm going to say sum plus equal what do I want to do the sum of all the inputs multiplied by their corresponding weights so inputs index I times weights index I so this is now that weighted sum I say that second step start with the summit 0 loop through and multiply all the inputs by the weights then what I'm going to do is I am going to return up I need to get the up so then I'm going to say the output is sine of the sum so it doesn't know what sine is there probably is a like javabased function I could call automatically but let's just write our own up at the top of this code here I'm going to write a function I'm going to say int sine and it gets I guess I could say it gets any I'm going to say if n is greater than or equal to zero return a positive one otherwise return a negative one so this is just that this is the so I could I could write here as a comment this is the activation function I could call it activate or something instead the activation function is a function that receives some value if it's greater than zero positive one if it's less than zero negative one so no matter what number goes in to the what other inputs come in whatever that's weighted sum is no matter what the only thing this perceptron can ever output is a 1 or negative one so and then I can say return output so now I have basically if I kind of give myself hope I really want I guess this is it I don't want to see the whole thing this is if I I have all the code for the almost all the coach of the perceptron a perceptron has a bunch of weights it initialize the weights randomly and it can perform a guess by receiving all the inputs doing a weighted sum passing it through the activation function ok so now if I were to just create something arbitrary just to sort of test if this is working I'm going to say float inputs equals I'm going to just create some random values like negative one zero point five and I'm going to say print line o first I'm going to say I'm going to have a perceptron I'll just call it P for perceptron P equals a new a new perceptron and then I can say P guess inputs and I can say output I can say guess and I can say what's wrong here what doesn't it not like oh oh this should be sorry that should syntax wise that should these are the inputs that's an array and I should say sorry a print line guess so if I run this how come I can't here we go if I run this we should see up I hey I'll put it a 1 let's run it again I got a 1 run it again eventually I should be able to run it a bunch of times and I got a negative 1 negative 1 okay so this I believe is working the system works I have a perceptron object I can feed in inputs and I can get make a guess now here's it so time out for a second let's looking at the chat whoops I broke my bail I just broke my bail I mean I didn't break it I can just reattach it I didn't break it topher J in the chat rightz I believe you can change the color scheme of the processing editor I forget how to do that but I think in that in the sort of like deeper preferences you can change that okay no no it's fine it sounds different yeah I think good alright I'm sorry I just needed a like little mental break for a second it's for 23 for 23 settle down everybody okay alright so let me keep going here okay okay so we have the overall structure now for the perceptron and it works but we need some we need to do more so here's the thing we need to create a if I had an actual data set if I were to try to classify flowers and these were sunflowers and these were daisies and this xaxis was like petal length and this was sepal length or something I could use a real data set here I'm gonna do something really phonybaloney I think I'm going to like kind of almost be really ridiculous about it which is that I'm going to say I'm going to actually just say that anything do I do I really want to do this I'm going to do it this way let's do anything that is I'm going to cut I'm going to use the line but I'm going to use the line that goes across the middle right so if this is X and this is y these are all the points where X is greater than Y well I'm so lost I'm trying to think of what's like a really simple thing I could do hope the camera went off um yeah let's just consider the line y equals x so anything that's above y equals x anything that's above y equals x is a plus 1 anything that's below y equals x should be a negative 1 so I want to create a known data set a known data set that I can use to train the perceptron so let's do that really quickly what I'm going to do is we think about this I'm going to there's so many different ways I could do this whoops sorry I got to thinking my eye good uh so many different ways I could do this I'm gonna do I'm gonna make a tab called training and I'm going to make a class called point and the point is actually just an input array that has three values in it no no let me think about this let me actually have the point have an X and a Y and also a I don't want to call it class a label I'll just call it a label okay so if I make a new point when I make a new point I'm going to say x equals a random with y equals random height am I going to run into trouble without nap just using the pixel coordinates let's try just using the pixel coordinates I don't know if that's going to be a problem and then the label I could say if X is greater than Y the label is one else the label is negative one right that should give me that should give me everything about I don't know what's above what's below let's do that and then let's do let's write a little function called like show where I'm going to say stroke zero and I'm going to say if label equals one fill 255 else fill zero and then I'm going to draw a little ellipse at X comma Y a small lips okay so what I'm going to do is I'm going to make an array of points I'm going to make a hundred of them and I'm going to initialize them and I'm going to say points index I is a new point and then I let's make the size a little bit bigger 500 comma 300 then I'm going to do a background 255 and for every point in points this is an enhanced loop in Java for every point in points I'm going to say pho so if I run this we can see uh yeah I mean let's make this a square so it looks a little less weird and I can also draw just to sort of like see correctly I'll draw a line from 0 0 to with comma height so you can see I picked all these points half of them are on this side and half of them are on this side so I'm reading the chat which I know I shouldn't do I shouldn't I just didn't read the chat sorry ok yeah topher the check points out the reason why I don't use the for each loop in JavaScript I guess there's the four in before each loop in JavaScript it's like asynchronous and like weird things can happen I got to get into that I know I got a bit of a prior five some weird quirks that don't make any sense okay all right now what I'm going to do now is I am going to do it I'm thinking I'm thinking I'm thinking like should be X is greater than equal to Y to be consistent should it be yeah probably that's a good point um oh I'm thinking I'm thinking you going to pause for a second um all right what do I need to do next I got to get to the learning part okay okay all right so now that I have all these points and I can see them correctly categorized this is my known training data so what I need to do process wise is I need to take all of my known training data one at a time I need to pass it in ask the perceptron to give me a guess is it in one is it in one or is it in negative one and then I need to do something based on whether it's correct or incorrect what is it that I need to do okay let's establish something okay actually I've got a problem we've got a problem what time is it we've got a problem that I'm going to run out of time it's 430 I'm trying to figure out when I want to introduce the fact that I need the bias white these are hard things to just like completely talk through all right maybe I don't want to talk about the bias just yet I'll get to that in a little bit maybe I should get to that now thinking here okay all right okay uhhuh all right I'm gonna keep going I mean I'm going to come back to the bias in a little bit okay there are still some missing pieces here I need to that I need to add but I'm going to keep going let's talk about training let's talk about supervised learning here's what I need to do I need to take all of that known data I'm going to take each and every piece of known data I'm going to take the x and y pointer to pass it in it's going to do the weighted sum it's going to it's going to passing the activation function and it's going to guess plus 1 or negative fun 1 plus fond or negative fun are you having we're having some negative fun right now I'm pretty sure so this is going to give me a guess but I also have the answer right so I have both the perceptrons guess and I have the answer if I have both of those things I can compute something known as the error the error I can think of as let's say the answer I always get this wrong backwards one way or the other but it's the difference between the correct value and the incorrect sorry between the correct value with the guests right because if it's if the guest is a plusone and the answer is a plusone what's that error 1 minus 1 that error is 0 and I actually have a little bit of a diagram here to illustrate this is a pretty simple scenario where these are the open the wrong sorry I didn't switch the camera I have a diagram over here where you know you can sort of see these are the only possible correct answers negative 1 or +1 so there's only four possibilities if it's supposed to be a negative one I could guess a negative one or a plus one if it's supposed to be a plus one I could guess the negative one or a plus one so these are all the possible errors the error is either zero or the error is negative 2 or positive 2 or 0 so this is a this is a good starting point I need to have this error the idea here oh come back let me come back to the whiteboard ok so remember what I'm trying to do is find the optimal weights so ultimately what I want to do is I want to figure out if I want to say well the weight should equal itself plus some change in weight I want to adjust the weight if there's a mistake I want to make a tweak I want to like make the weight a little bit higher or a little bit lower right because maybe my weighted sum got me below negative 1 but it should be a plus 1 if I make that weight higher maybe that'll push the output up to positive so the issue becomes how do I calculate that Delta weight how should this weight change based on how should the weight change for weight 0 for weight 1 and if there were many many many more weights so the way that this is calculated with is with a process called gradient descent and I have a couple videos where I go through this in in pretty large detail one way of thinking about this which I'll kind of duplicate here in this video is this really relates back to a lot of my steering examples so I have all these steering examples where I have a vehicle that has a given velocity and it's seeking a given target so this vehicle has a velocity and it also has a desired velocity right because if it should be going towards that target its desired velocity is to go towards that target so you can think of this steering formula if you go back to that Craig Reynolds steering formula the steering formula equals the difference between the desired velocity the way that I want to go and the current velocity which is kind of like my guess and if I get this a steering formula if I get the steering if I get this steering vector and I add it to the velocity it's going to cause me to turn and go towards that target so essentially that's what I want to do here this steering vector is the error the desired velocity is the answer that's where I want to go the velocity is my guess that's where I'm going right now I want to steer in the direction of the error so Delta wait the Delta wait is actually equal to the error multiplied by the input so it's filtered through the input what's that error filtered through the input that's how I change the weight itself so that's the process that I'm going to do over and over again and I have a slide here that I think will walk through that in up so I'm in the wrong keyboard here so this is the process this is the supervised learning algorithm provide the perceptron with inputs for which there is a known answer and ask the perceptron to guess okay the perceptron guessed what's the error is it right or wrong is the error zero is it is it negative to adjust the weights according to the error and go back and do it again and again and again and this is the formula the weight is changed according to the air multiplied by the input and there something called learning rate which I'll get to in a second so let's see now I've kind of explained that in pieces let me see if I can now add that to the code so I'm going to here whoops I'm going to now create a function in the perceptron and I'm not going to call it guess I'm going to call it a train so this is going to receive some inputs and a target right the difference between the guests is the guest is something like oh I just want to receive these inputs and provide a guess with training I want to receive the inputs in the known answer so I can adjust the weights accordingly okay so the first thing actually that I should do is just get the guess which is actually with those inputs so since I already have a function that does the guess I can ask for the guess from that guess then what I want to do is get the error the error equals the error equals the target the guess that's the error so now that I've done that what I can do is I can go through all of the weights and say each weight should change according to that error multiplied by its corresponding input so this is that particular algorithm this is tuned all the weights okay so this is like basically supervised learning says put the data in get the result if the result is right just move on move along nothing to see here if the result is wrong twist some dials in here to try to get it closer to the correct answer and do it again and again and over and over again here keep twisting dials eventually to find that optimal result now there's something important here though if I go back to this steering example you could think about okay so this is the vehicle it's going in this direction it should seek the target it knows what the error is the error is the difference between the way it should go and its current velocity how much should it steer if I steer a lot I could actually like overshoot and start going the wrong way in the other direction but if I steer just a little bit maybe I'm going closer but I'm but any reson we're going to do this with lots and lots of data so one thing that's actually optimal here is not to steer the full amount all the way according to the error but just some percentage of the way and that percentage is referred to it's a key concept here and it's called where's a learning rate so what I would actually do here is say that Delta wait what this plus one here is the error times the input over x a turning rate so that's a key concept here so let's add that into our code if I come back over here I'm at the perceptron is going to have a variable call it LR for learning rate I'm just going to say zero point one so now I'm going to say also x learning rate so there we go now this is going to adjust all of the weights so we should be able to if I go back to here I should be able to now train the perceptron so let's go here and say for all of the points oh I did something terrible I'm doing some awful stuff here which is that I used P for perceptron and then I'm using a local variable P for points so let's call this a PT for point let's actually just call this I'm going to call perceptron I'm going to call this like the brain it's probably like a bad variable name but at least till it says something more than P so for every point what I want to do is I want to say brain train the point the inputs associated with that point and the target pass in the target associated with that point right the point oh it has an X and a Y and a label so ah so the target is actually the label and can I do this I want to make something called inputs which is an array which just has point X and point out why is Java going to let me write that I think so so this is what I want to do I want to train the perceptron I want to send in every point as inputs so X the X and the y make the zero on the one input and then I want to send it into the train function with the label which is the known answer so if I do that okay so in theory it's trading and it's doing this I can't see anything so now I need some sort of way of tracking how well it's doing this is going to be tricky but I have an idea for how to do this so I think what I want to do pause edit for a second just see Steve hey so many the chat just pointed out that you know why am i doing the why am i doing the same loop twice yeah that's what kind of unnecessary here but I'm really just trying to separate out different parts of the code ultimately I probably don't need this original loop but so there's a couple things I do one is I could actually calculate the overall error like I could actually look and this wouldn't be such a bad idea and just sort of print that out I could I could calculate the total squared error and kind of evaluate how well it's doing but I want to just actually look at it visually for a second so I think what I want to do is let me see here what's a good way so I'm going to just actually say guess equals inputs a brain guess inputs and then I'm going to say if guess equals a point label let's just call this let's say target equals points points label just to have these in separate variables if guess equals target what I'm going to do is I'm going to draw a I'm going to say I'm going to draw something that's green I'm going to say no stroke I'm going to draw an ellipse at X like I just keep typing p5 why that's like a smaller size else fill red well everything became green instantly I can't be right all right let's not train it okay so we can see I guess it's just working better than I had imagined I'm trying to think visually if there's a better this is like okay so let me let me make the window bigger and let me make all of the points let me make all the points much bigger so this is a little easier to see and let's run this again okay so you can see without any training everything is wrong so I'm not if I add the train function back in everything is correct now I guess it just like this is such a simple scenario it's like trained and worked so felt so quickly in like a matter of like one or two iterations so I think you could probably if you're watching this be a bit more clever in terms of how you how you visualize this and I'm going to say a few more things about this okay so I'm coming towards the end of this particular video and I think I need to do I'm going to give you some exercises and I think I'm going to do a followup one that kind of add I'm gonna give you some exercises and then I'm going to come back and do another video where I add this these answers in but there's a couple things here what is I've got a serious problem a very serious problem with everything that I've done here let's just say I'm going to let's say that this space that I'm in is actually this zero zero forget about pixel space or anything there's a coordinate space where zero zero is in the middle right here and I want to categorize data as above or below this line or maybe I you know I want to use the same system but I want to categorize above or below this other line so I want to use a perceptron to categorize the same exact code to categorize both of these two scenarios well in one case in the orange case 00 should be a plus 1 in the black case 00 should be a negative 1 but notice something here if I'm actually feeding in 0 0 into this perceptron system no matter what the weights are the only thing I can ever get out of here is a 0 this is a problem because sometimes 0 0 is going to be above or below so it's going to be a Class A so this would be a Class B that can't possibly be right and this is where this idea of a third I'm going to go and get another color here this perceptron will actually not work or perform correctly with this Genet generic scenario other than with having something called a bias so I need another input a third input into the perceptron that is always going to be a 1 input 0 is X input 1 is y and the bias is 1 actually if you think about this this is really I'm really working through the same problem that's from my linear regression with gradient descent videos or what I'm trying to do is solve the Funt formula I'm trying your neural networks are designed to generalize a photic function to solve a function and in this case this very simplistic scenario is actually just looking to solve the formula for this line y equals MX plus B and M being the slope is kind of like rise over run and B being the yintercept so this weight the bias weight is really there to solve that yintercept and these weights are really solving the slope the rise over run so that's what we're doing we're essentially doing linear regression with gradient descent again but just through this perceptron model so if you didn't watch those other videos you could go back and watch them just kind of connect all these systems so what I want you to do an edit point here for a second I'm just going to have this open okay is I have an example here from the nature of codebook this is essentially the same code that I've been writing but it does two different things one is it visualizes what the brain thinks the current line is and also it adds that bias so if you're watching this video I'm going to release the code for this video this I guess is part one of the perceptron coding challenge if you're watching this video you could go right to the next one and I'm going to add the bias in and maybe do a bit more with sort of visualizing what's going on here and have a generic formula for a line but what I might suggest you do is see if you can add those things yourself to this particular perceptron and then when I get to the end of the next video I'm going to talk about why this is such a limited system that can barely actually do anything meaningful in machine learning but it can be a building block for a much more complex system that can do a lot more interesting and powerful things so I hope you've got a sense of what a perceptron is what the algorithm for how a perceptron works is and how the feedforward supervised learning training process of a model perceptron works because this exact building block this scenario is what I'm going to use in the future videos where we start to build more complex neural networks okay thanks for watching and I look forward to your feedback and thoughts in the comments um okay I am going to so I have just kind of like cut that short a little bit because I have to go in about five minutes and you know I sort of felt like that video was getting a little bit long anyway so hopefully that was like I feel like there's some missing pieces here I'm going to come back next week and finish that off it does anyone have any questions or Corrections or things you want to mention I would love to hear them I'm really looking forward to getting out of this machine learning stuff but I am hopefully I'm doing an okay job I'm kind of amazed that this worked and oh yeah oh me I am so me you said try training on mouse click I see what you mean so like run the training once that's a very good so yes I'll hold on let me try that I like this idea so I'm going to put all of this here I should have done this in the video and I'm going to say void a mouse pressed this should just be doing the training but I still need to do this so this should be right now if I do this this is its guess for everything and then if I click train train train oh yeah look at that oh can I go back you think we can insert this match into the middle somewhere that's a really it was such a good suggestion I'm gonna try this might be impossible to do but that was so useful so okay I'm just going to record this and this could get inserted in that'll be wonderful but I don't know if that'll work and I really got to go soon okay me I am so me and the chat had an excellent suggestion where maybe what I should do is actually uh sale me I am so me in the chat had an excellent suggestion which I could demonstrate the training process with a mouse click so I'm going to quickly do that so what I'm actually going to do is I'm going to take this training out here I'm going to take this whole loop and just delete this line of code that actually does the training and I'm going to run it so now it's not training and you can see it's got every time it you know when I run this it's all wrong right but what I can do now is I can say void mousepressed and I can just run the training algorithm so now what I did is only when I click the mouse is it going to run through all the data and actually adjust the weights so now if I run this you can see you can see look at this it's got most wrong but it's got some right it's at most right but some wrong and now if I click the mouse ah a few more correct but some more wrong click the mouse again okay click the mouse again click the mouse again click the mouse again so you can see it's like changing and eventually now it's got everything right and so you can see how that learning process happens over time it only took five or six cycles and maybe this will get that will be the end will gets since amount so I you know there's I think there's a lot more creative ways you could visualize the training you could also visualize the perceptron itself and we can visualize the weights I guess I'm going to come back to this in the that will only make it take a while it's not animating while learns he need to only train a few points at a time oh yeah I could also just train with one point at a time I want to add that in so many good suggestions uh they're all so I can't see who that was in the YouTube chat one other thing that I could do is just train one point at a time so I'm going to draw everything but I could here I could say I could say into training index equals zero so what I'm going to do in draw now is I'm going to say point training equals points training index so I'm just going to take one point and train it off that one point okay and then what I'm going to do is I'm going to say training index plus plus and if training training index equals points length like if I get to the end of the array I will just reset training index back equal to zero so this now in the draw loop what did I get wrong here I'm just spawn training wrong Oh double equal sorry so now in the draw loop it should be training one point at a time and you can see like it's kind of weird all sorts of weird flashy stuff is happening but over time it should eventually settle into at getting everything correct but as it makes these little adjustments it's going to get some things wrong and some things right and you can see now so again there's so many other ways you could think about visualizing the training and you could actually visualize you know one thing you might try is actually visualize the perceptron itself like visualize the weights visualize the connection visualize the data flowing through it so I'll leave that to you creative people watching this video okay so that I've really made the most complicated editing puzzle ever here I've got to go I am going to take I'm going to play my goodbye song I'll see if I can or two questions in the chat thank you guys for thank you guys for tolerating this journey until like some of these esoteric and very highly technical and not so practical make a line object Simon Tiger mentions as well that's a cricket idea so I'm going to leave the more creative ways of doing this stuff to to you guys to all of you watching I've got a run I'm gonna be back next Friday unfortunately I want to be able to try to do additional live streams get further along also take breaks from the machine learning stuff and do some other creative coding challenges challenges but so hopefully I'll another week I'll be able to but I I'm almost sure I won't be back till next Friday so next Friday maybe I'll try to start getting into the neural network stuff maybe I'll just take a break and do some other game coding challenge we will see I'm gonna see if there's any questions in the chat that I can answer somebody posted volcano emoji which I don't know what that means poof what's the next episode I don't know to be determined I'm not feeling super perceptron to calculate the optimal edit points that's a great suggestion I'm not feeling I'm you know I'm definitely like questioning everything I've ever done in my entire life until now what we're good for everything I'm doing good or useful or helpful but doing them but the salsa musics need the salsa music I don't know if that's really salsa music that music kind of thought I was playing is by I'm Adam Lau who is a film and television composer based in LA who is actually working on a new coding train theme song that will be coming I'm sorry shoe doctor this archive will be available as soon as I hit stop of the livestream you can go back and watch the whole thing I've got to be got to be somewhere by 6 o'clock and it's going to take me some time to unplug everything and do everything and get get out of here so uh so um thank you all again do I look I don't think I look frazzled enough I should go over here and you get this oops this is this is how I feel right now good screenshot that or get fit or whatever I'm a little bit weird how obsessed I am with the vanity of people making gifts but um we're am I going I have to pick up my daughter from a playdate so that's where I'm going ah so thanks thanks about the songs over I've got to go I'll be back next week please send me your questions and comments and feedback in in comments in on Twitter at Schiffman I appreciate it if you can encourage if you could subscribe and like and all that stuff and watch and encourage other people to watch all that stuff helps me out the more people find the channel the more watch time I have all that stuff helps so spread the word if you like the stuff if you don't please don't feel don't feel anything of course the only genuine whatever I have really got to go thank you guys and I should get one of Suraj's videos and go slowly over it step by step that's a good idea okay so I will see you guys later good bye