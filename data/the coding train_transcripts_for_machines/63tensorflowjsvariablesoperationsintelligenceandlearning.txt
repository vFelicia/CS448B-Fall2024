all right this is my third tensorflow chance video and I actually just booked oh I made this list so what have I done so far I have made an introduction to where tensorflow day is sort of fits into the kinds of stuff that I'm working on in thinking about I made an intro video to the idea of what a tensor is and how to make a tensor a variable that stores a tensor in your JavaScript code and now you're really what I want to do is I want to get down to my goal is to get to the point where I'm remaking earlier machine learning coding challenges I did but instead but using tensor flow j s as the basis for them the foundation for them so the things that I think that I need to mention and talk about before I get to that is I need to talk about variables and memory management there's something difference between a variable and a tensor there's they're kind of a similar thing but it has to do with memory management I won't talk about operations so mathematical operations that you can do on these tensors the layers API that's a really that's like the topic I'm the most excited about on this list and so once I can do three more a little quick general tensor flow dot J's videos which are by no means comprehensive as to everything that's in tensor flow js2 a much larger api than what I'm going to cover and also I don't actually know any of this stuff I'm just kind of figuring it out as I go so I'm trying to talk you through me learning it so just in case you're thinking you're watching a video by an expert and then and then I'm gonna get to these coding challenges and then I've teased this before but there's a new library called ml five which is built on top of tensor flow Jas which I'm going to eventually do a lot of tutorials and videos and hopefully bring some guests in also to do stuff with ml 5 ok so back to the computer where I left this off I think if we look at this code that I had is I created a tensor I use tensor 3d because I knew this shape was going to be a rank 3 having three dimensions yes and this is the shape I'm putting integers in it I'm console logging it and inside and we can see the result here now incidentally I think I should also note that if I actually want to look at the data just seeing it the string of it like printed out there then what I want to use is actually the data function oh wow I probably shouldn't have called mine data so let's call it a tensor probably shouldn't call it that either let's call it tense very tense and data now this is gonna be a problem I think let's see what happens here and this is this is gonna relate I'm gonna get to the point here you'll see you'll see look at this a promise oh that's so nice of tensor flow not just to promise me something what are you promising so here's the thing there's something weird going on here and this is actually really the topic of this with variables and memory management in that there something is happening here something is happening right here these values are stored in a plain old array that's in the computer's memory and when we make this tensor out of them that data gets copied on to the computers graphics processing unit the GPU that takes some time and we want to minimize the amount of times we have to copy memory back and forth so this is the thing we have to think about as we build more examples in code this here is doing this asynchronous this this here is doing this asynchrony now I wonder if I could give it a callback I'm just gonna experiment here I think they're only using this thing called promises which I made a video tutorial about this yeah there really need to so what happens if I give it a callback to see like oh can I can I give it a callback there oh wait so let's let's do this and see like oh let's give it a callback and then see if we can look at the stuff that comes out of the callback let's see what happens there no because I have too many parentheses yes too many parentheses no nothing happens there so it's not using and and I'll cos told me I could use oh wait but I all this there's so much yes six and Beyond JavaScript going on here so actually what I want to do is if I say tense dot data I can say then and then is this special function that's part of a promise where it's saying like once the promise has been resolved you've made a promise to me you're going to keep that promise and when that promise comes to roost cockadoodledoo then I can can I just write code in there no I have to make a function I can say console dot log stuff so how it works yeah look at that so there we go we can see this is one way but I actually don't want to deal with any of this so because I want to just so this is something that's going to come up let's try to avoid this and there's also a keyword called a weight that I could potentially use but luckily there is also a function called data sync so if I use the function data sync you're going to see this here what this will do is actually give me all the data back but without without the butbutbutbut block but wait wait for it to be done so now we should be able to say boy I really very tense so you can see here it is and then here is I notice it all came back as a onedimensional array okay back to recap this is what the tensor is and this is this is the way that we're thinking about the tensor and how the data is stored and the print function allows us to see that very easily in the console if I want access to the data the data sync function will just give me all of that stuff ultimately just as a list of numbers because this idea of the different the shapes and the dimensions is really for you know us as human beings to think about it and store it but ultimately it's just a bunch of numbers so I should also mention that in addition to data sync there is also a get function so if I were to say tense dot get and I were to say 0 we would see I've got the number 80 which is right there and if I were to say 1 I've got the number 41 and if I were to say you know a 29 which would be last one I've got the number 47 so get is another way I can start to pull that stuff out Data Sync data and I need to come back I really should add an addendum here which is that in order to support this material that I'm covering at some point I need to come back and make a video on promises and how the arrow syntax is often typically used with promises and this then function so these are something I need to come back and do some additional content on as well as a weight and a sync because if you want to work with this particular library how these new ways of handling synchronous and asynchronous things in JavaScript are kind of key foundational elements so I've got to come back and talk about this I would suspect that funfun function has some nice videos on these topics but I don't know so maybe I'll link to those in this video's description ok but the point of what I was saying is what if what I wanted to do right now is I wanted to change some of the numbers for example I wanted to do the equivalent of saying something like 10 set 0 to 10 in other words I'm sure this doesn't exist but what if what I wanted to do is say like oh whatever number is in the first spot in the tensor I want to change it to something else well I actually can't do that these tensors once you've created them are immutable and that means the values can never ever be changed this is different than this like Const declaration which just means you can't like reassign a variable name but you can might be able to like change the internal data of an object that's different these tensors absolutely cannot be changed so if you need to change the values and you might in a kind of learning system you're building right what if you're storing all the weights of a matrix in a tensor and you want to adjust those weights rather than copying into new tensor to new tensor this is where the concept of a TF dot variable comes in so I can say Const bar oh I shouldn't Const V tense oh boy this is getting really weird TF variable tense I can take a tensor and make it into a variable by passing it through TF dot variable so let's just look at this and sort of see what's there and we whoops us we don't want this set thing and you can see now this looks very similar it has a shape it has a data type but it's now stored differently this is because tensorflow dot j as a kind of lowlevel library managing web the data using the graphics card intensively really needs to do different things it has to manage the memory differently if the stuff is never going to change versus if it's going to change and so if I go now to tensorflow gjs and I look here at TF variable we can see this is now something that has a new parameter called trainable so in fact you can add this thing called an optimizer to it and adjust it so that's an important thing I wanted to mention and I'm just going to leave it at that for right now if I need to use a TF variable later we'll come back and look at when when I might want to use a TF variable versus just a TF tensor hi so I'm back actually with a weird edit point because I just went down the rabbit hole of trying to figure something out about memory management and I discovered that actually the memory management stuff makes a lot more sense to talk about after I've already looked at operations so let's actually I'm gonna switch this order here and right now in this video that you are watching I'm gonna talk about operations next and then maybe I'll move maybe I'll take a break and move on to memory management in the next video something like that okay so let me come back and talk about operations if I come back to the tension flow digest webpage there's actually a part of the sidebar here part of the API which is all about operations and when I to get my batteries that's what I mean mathematical operations that I want to perform on the tensor itself what if I want to double every number in the or I want to take two tensors and elementwise multiply every number by every other number what if I want to do matrix multiplication between those two tensors now this would probably merit a whole video series about linear algebra and matrix math luckily or unluckily for you I made a whole series about that already so you could pause here and go and watch that I would also refer you to the three blue one brown video series on linear algebra which is excellent so rather than get into the weeds of all of the mathematical pieces themselves I just want to kind of like look at a few and see how you would use these okay so let's for example say I want to use TF add so if I click on that I can see I add two tensors elementwise a plus B what does elementwise mean well what that means just to sort of recap is if I have two matrices a b c d and i have another one e f g h and i want to add them together and i want to see the results elementwise means a plus e b plus F right I just take them ones that are in the same spot and add them together so we could create we could do that right now in our code and I could say I'm gonna call this tensor a and I'm gonna this is a little bit silly but I'm just gonna make a second one that's with the same numbers in it obviously I'm more likely would have two tensors with two different values and then what I want to do is say TF wait how do I let me look at this Oh a add B sorry so what I want to do is I'm gonna say Const C equals a add B which by the way would be exactly the same as saying B dot a da in this case with other operations the order of the matrix the matrix the tensor so I shouldn't say matrice matrix matrices so that really could play a role so if I say a dot B and I were to say a print B print C print and I come back here and go in refresh we're going to see you know here's a here's B they're the same and then every number is doubled basically because I took a plus B so really obvious I should make two different random sets of numbers but this is this is how an operation works and depending on what you're doing you need different mathematical operations so as you can see there are a lot of things we could subtract multiply divide there's maximum minimum modulus power squared difference all need to be interesting to pursue and I might come back and do more videos about particular mathematical op operations but really I think just showing you ad hopefully now you could kind of look at the documentation and see what each one does I think it's worth at least doing there's a lots of other math functionality but I think it's worth looking at matrix multiplication TF gnat mall because this is a really key concept in building a neural network how to do this weighted sum of all of the inputs and all of the weights passed through you really need matrix multiplication if you go back and watch my other videos so let's look at this one so here we can see a dot mat mole so really it's just another function but we're gonna run this an interesting thing here what if I were to try and I don't need to print I'm not gonna bother printing a and B let's just try this right now so I'm going to write this would work a dot multiply and ul B because that's doing element wise a time you know in this case a times B times FC times G let's go back and I'm gonna hit refresh oh it worked so I guess the way okay of course it works I forgot I was doing L then what of course of course it worked I'm doing element wise multiplication I'm trying to demonstrate here that if I actually want to do matrix multiplication which is a totally different thing mat mole is that what was called now there we go oh I love this is like my favorite error this is very simple these are like kinds of areas are gonna run you all the time who saw this before air matmo inputs must be ranked two got ranks three and three when you do matrix multiplication the number of columns in the first matrix a has to match the number of rows in the second one and by the way you can't even have like a this is fully you can't have a rank three again your matrix month so this by the way this whole thing is flawed because this was only going to work so let's if I have a rank two mate tensor or basically a matrix a two dimensional array so now let's get a different error message now error in map so first of all matrix multiplication is only for matrices in two dimensions tensors in two dimensions and then the error here is the inner shapes three and five of the tensors with shapes five three and five three are in transpose so what's this error message about to do matrix multiplication the number of columns in the first one must match the number of rows in the second major so actually in here this would work this would actually work because these are two by two and so the columns here matches matches the rows here and again if you go back to my video on matrix multiplication you'll see why in more detail about this so but just to follow up here what I must do now in order to do Mitra's multiplication as I probably would have shape for a I could transpose one of them but let's do this first so I'm gonna do shape a and then I'm gonna do shape B this is a good time to cover transpose and shape B and now this should give me something there we go there's my new matrix and out of matrix multiplication if I am doing excuse me a five by three multiplied with the three by five I end up getting a five by five matrix which is correct now another way I could have done this by the way is if I use the same shape for both of them if I backed in here I should be able let's do this okay I should be able to say B dot now let's just see what happens if I say B dot transpose No so here's the thing remember these things are immutable so even transposing it I probably have to say constabie equals B transpose and then I can do a dot a dot Matt Moll BB and there we go so what does transpose do with a matrix transpose if I have a two by three matrix we'll take that matrix and transpose the numbers into a three by two matrix so again why do I I'm not doing anything of any value or meaning here if you go back you could probably go back as an exercise if you want an exercise right now go to my toy neural network look at nnj s go through all of the matrix maths that in that and see if you can rewrite that with the tensor flow the TF operations I don't know why you'd want to do that but if you want to just do everything you could possibly do in this world that's something you could try and maybe I'll try to publish something which is like an answer key to that I don't know you could ask me in the comments or somebody could make one I could post it all right so I think this is about where I want to stop right now again this is not meant to be comprehensive I just want to talk through what are the pieces here we know that there are tensors tensors are ndimensional groups of numbers with we can also those are immutable they can never change if we need them to change we could use this thing called a variable maybe we need to see an actual scenario where we need that variable hopefully that'll come up in one of my videos in the future but you could try it yourself and then we can also perform operations we can perform operations like take these tensors that take this tensor and add this one or double this or find the maximum number in this one and there's plenty plenty more matrix multiplication so I encourage you to explore all of those and maybe I'll come back and go through some of them as we need them but I just want to give you an overview of what's there in the tensor flow jsapi itself so in the next video I'll be talking about something important because I have not been paying attention at all to how whenever I create a tensor I'm using memory in of the computer and sometimes I'm using maybe I'm using memory that's you know in the RAM sometimes using the GPU memory what's going on with all that so I want to in the next video specifically talk about memory management and how to make sure if I'm making all these tensors and doing all these operations how I how to make sure I avoid having a memory leak okay I'll see you in that video you