all right oh this is getting tiring but I am back and I have yet another in this building your own custom color classifier with 1000 GS series now the thing that I want to add to this video and by the way this line moving across is pointless I just have it there so that I could see that the draw loop is animating that I haven't blocked it there's two things that I miss that are kind of important from the previous video what is this is actually not the validation data loss I didn't realize this but I'm going to I'm gonna change this here I'm gonna I'm gonna console.log the full logs object so right what I'm putting on to the screen is logs dot loss let me come to console log what's there so again we have to wait a minute for the first epoch to finish apologies for that okay there are actually two lost values there's the loss function can be computed against the training data and there's the loss function computed against the validation data now to do this properly I really should be using the validation loss because that data that hasn't been done with the training that's that's that's that's protecting against overfitting having my model work really well with the training data only the thing is I have a very small data set 5,000 data points I'm just using 10% as the validation data and the weight to the flow digest works it also takes that 10% from the end and I didn't wasn't careful about shuffling the data around so this is something that I should come back to I don't know maybe this series will go on to infinity but if I were doing this properly I would actually want to show the validation loss here like this log stop validation loss maybe I want to show both and maybe I want to be more thoughtful about shuffling the data first in advance but I that's not what I said I was gonna do the next video so I'm again leaving that temporarily as an exercise to the viewer or I'll come back and do it in a future video I don't know yet that's item number one item number two thank you to me I am so me and others in the coding train sponsor patron group I've made this way more complicated than it needs by trying to make this an async function in here actually this does not need to be an async function if I just return TF dot next frame so if I just return TF next frame it's actually returning the promise and unlocking the draw loop so that makes it simpler actually I really want to do it couldn't be this so simpler what am I doing here at the end of every batch I want TF next frame to be executed and so I actually don't need to write a wrapper function to execute TF next frame what I could just do is set that as the callback the callback again if I wanted to do more with on batch and look at the loss and the logs but really what I want is at the end of every batch to draw a new frame of animation I can just put TF knocked next frame as the function which is the callback there okay so let's this is still working that simplifies the code makes it a little nicer to look at I don't even really need this on on begin and on end but I'll leave those in there just so you see them okay so now I'm ready for what is the purpose of this video the purpose of this video is while I'm training the model I couldn't wait till I finished rigging the model but I'm actually it allowed this to happen while I'm training the model I want to be able to specify a color and see what the neural network thinks that color is so very quickly to do this what I'm going to do is I'm going to create our slider G slider B slider I'm going to make three sliders again this could use a lot of improvements and I'm going to use the p5 Dom library create slider function so the slider is a range between 0 and 255 and let's start with like what's this red and green make yellow let's start with a yellow and so the G's the B slider should be on 0 and then I want the background color to and I don't know what that's doing there I don't need this line anymore it's distracting I want to say are Lichter well let's actually let's so I want to say let our equal our slider value so I want to get the values from the sliders I want G and I won't be eventually I'm gonna send these as inputs into the neural network but right now I just want to be able to see that color our G B okay so here we go so now we should see there are three sliders and as I adjust these sliders I can change the color and so what I want whoops what I want is to be able to and I see though what I want is now to see the neural networks prediction down here so how do I do that okay time to use tensorflow touch yes again whoo so I need to make some input data so the input X's are tensor T F dot tensor 2d and an array with RGB in it now in theory I could be running prediction with multiple RG B's right but I'm not so I need an array of arrays in here so this is my input data then what do I want to do I want to say model dot predict with those X's feel like you know what I need to normalize those right because the it expects to have normalized values between 0 and 1 so I need to divide each of those by 255 then I need to call model dot predict and then look at the results and that happen oh what this doesn't actually happen asynchronously it's the because the data is still on the GPU this is a confusing thing I have to pull I'm gonna use that date I have to pull it out but let's just look at the results of pure results so I should then be able to say results dot print okay so I think this is me just creating the inputs getting the prediction and then I should be able to see that in the console syntax error who I have an extra extra curly bracket alright okay so we can see this and this is exactly what I should be getting right it is a probability distribution over nine labels now whether it's giving me correct ones who knows but look at that so now how do I get the label out of there well remember that what I'm looking for is I'm looking for which probability is at them at the highest level is it a ninety percent chance of it being yellowish and point zero one point zero two point zero three you know 1% 2% 3% of being the other ones and there actually is a function intention flow Jas that will pull out the index of the highest probability value that's called Arg max right I could write a little for loop or or some kind of function to do that but if I look for Arg max TF dot Arg max returns the indices of the maximum values along an axis so this is can be quite more complex because I can have multidimensional data but I actually get to do this in a really simple way I just want to say let index equal results dot Arg max yep and if there's an access of AXI access of 1 the first there's a 1 dimensional here so now let me say index dot print and so let me run this and we can see it's just giving me whom is that right is that a coincidence so I should get some different values yes okay so it's actually changing so that that's giving me that maximum index so as I change so so this is my label here's the thing though that's my label but I need to convert that to one of these so 0 means reddish one means greenish two beads blueish 3 means orangish so I have this label list already I should be able to just say let label equal label list index the only thing is I can't do that because this is a tensor that's a tensor and what I want I need to pull that the tensor is the numbers the data that lives on the GPU the WebGL fancy thing that Tetsuo digest is implemented I need to pull that off and normally I would pull that off with an asynchronous function but the thing is here it's such a little tiny bit of data I think I can pull it off synchronously and not slow down my program from running so actually what I want to say here is Data Sync and then which is a dot data would pull it off asynchronously so let's look at and let's let's say I'm a console dot log index let me get rid of my other console logs that I don't really want to look at right now so okay so I got an array with the number in it I pulled it off and so then I just want to say index 0 so I only need that first value index 0 and so there we go that's the label number I now have the label number and so now I can say this and I can say and let's put it out on a paragraph element so let's say let label P let's have that be first and so now I want to say label P equals creepy and then I should say all the way back down here label P HTML label okay ready for this here we go I've started my training oh wait why this is so silly but I want the label to P above it I really should not be changing this right now so let me just put it here okay so here we go it thinks that's greenish right well it hasn't gotten very far with the training I would imagine that once we train further and the law starts going down it's going to recognize that as yellowish so here I'm gonna just wait a little bit and I'll be back in a minute all right back so he trained over 10 in each box and you can see now it's saying this is yellowish let me tune this down that's greenish turn this up that's bluish we've still got blueish can we get some purple purplish can we get some pink oh it didn't get pink maybe if I add a little more brightness ah now that thinks that's pink so I have now trained the neural network to recognize and let's see if it can get red reddish so we can see I could play with this all day long this is now going to classify the color based on that particular mouse so in a way I'm done I probably want to train it for more epochs what are some things that I want to do so one is I would want to be more thoughtful get more data I would want to be more thoughtful about the validation data and then other thing I would want to start doing is thinking about well does it actually work better what are the hyper parameters that I can play with for example the hidden layer I put 16 units in it well or what happens if I use a different activation function for the hidden layer what happens I use more nodes or less nodes what if I change the learning rate what if I change the optimization function if I use like the atom optimization function so these are things that all these things are things that I could play with and research and think about an experiment with to try to tune the model really well then at some point I also would want to save that model right save it to a JSON file so the trained model somehow so that I could load it back in without having to run through the training process again maybe I'd even want a larger dataset I'd want to Train it over a long time me but I want to port this code to node so I could let it trainlike serverside without having to train in the client there's so many possibilities but I have now built a machine learning model with tensor photos I'm gonna cry I don't know how many videos this took that trains a model based on crowdsource color data and if you want if you just a humor me for a second if you remember if I go here this is the system right this system was used to allow people from the internet to click on and say that's like pinkish that's greenish that's blueish tag a whole bunch of colors save all that data in a firebase database retrieve all that data clean that data put it into JSON file load that JSON file here into this sketch build a model train the model with that data and then pulls a new color from a slider oh and I forgotten something memory management oh I knew there was a step that I'm missing estimating what category out of the fixed set of labels this that color is but I did forget something really quite important which is memory management let's look at this num memory om TF memory dot num tensors so again when I create tensors that are allocated to memory on the GPU to store numbers those don't get cleaned up automatically there's no garbage collector like in kind of regular JavaScript programming so 15,000 485 tensors that one thing and there's still even more and more and more it's growing this is a memory leak so one place where I didn't clean up any of the tensors is right here and there's a easy way I can clean this up by adding in the TF tidy function so what TF tidy does is it says just put all of this code that's inside of this function passed into TF tidy clean up any tensors that are made there so this will clean up everything for me so now let's run this again and we're gonna take a look at the tensors there's 31 73 it's kind of leaking right well let's let it get all the way through 10 a box I'll be back in a minute when that finishes so the training is complete and we can see now ah there we go I am no longer leaking tensors now the thing is do I really did I really need 1628 tensors I don't think that I did I think there is also there is also a leak going on inside of this train function and I think there's an issue with this and so I'm gonna I might have to do a followup video about this because at the moment if I go to github.com TF o DT oh hold on let's go from here I should have had this prepared where do I go github and issues and I'm gonna look for fit memory leak this one so I believe there is at present a memory leak in model dot fit with callbacks and you can see that's exactly what I'm doing right where model dot fits with callbacks so I'm gonna not worry about that particular memory leak right now I'm gonna wait for us to see if that gets corrected by the time you're watching this that might already be corrected and this code might have no more memory leaks in it just by updating the version of tensorflow Tijs or I might still be missing something in here to do a memory leak so you know if you don't want any spoilers and/or the following videos the fallout videos have not been published yet you could kind of kind of like sort that out yourself but I will come back at some point and talk about that okay so thank you for watching I wish you many purplish and pinkish and bluish and greenish days all the colors of the rainbow may they fill your days with joy may you make your own classifier with your own data please with me I don't know has this helped the world this tutorial series I've missed so much about data and data collection of machine learning and bottles and algorithms but hopefully I've got done something this is not the end it's only the beginning ma I'll see you soon in future tutorial videos that up because this playlist probably has about 300 more left ok goodbye