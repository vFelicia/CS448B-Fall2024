hello good evening this is not the evening at all this is the afternoon though welcome to the coding train on a Friday which is my usual day for the coding train but this summer it has not been my usual day I was just having a lot of trouble getting the start streaming button to start I had restricted mode enabled on this laptop for a variety of reasons that I'm not entirely sure of and interestingly enough I cannot start streaming I cannot actually I have to bat it's a long story but I couldn't get that to start streaming the button to work while those in restricted mode I fixed that so here I am how are you what's going on what's what's up what's what's happening got totally weird how you can't speak to me all right there's a chat so you sort of can you could type to me in the chat it's night in India writes Melvin in Israel it is 20 o'clock which i think is 8 p.m. all right so I have to admit something although this is nothing new you know I feel like normally I'm so well prepared and I spent all week big making notes and scheduling things out and knowing exactly what I'm gonna do and then I like I've got all this energy and I turn on the streaming and I'm go go go and I do a tutorial and I turn off the streaming and the day is over right now I feel like it was that I had to make a heroic effort just to make it here and press the start streaming button so I have to admit that I'm a little bit out of sorts but and I but I I have two hours today good news is I am planning for two live streams next week so I am planning to livestream both Wednesday and Thursday it looks like next week and I will publish Tynes to the homepage of this YouTube channel thing soon enough and so I'm hoping to get some get get into I but I really want to do I really want to do something practical a practical is the wrong word I don't do anything Pratt whatsoever I want to do some machine learning demonstrations in the browser with data and data that might interest you or inspire you to use your own data and do something else with it but I'm not there yet let me try to figure out where I am I'm gonna go to YouTube the coding train and I'm going to go to neural networks and machine learning I'm gonna go to session 6 hello and welcome I'm not gonna watch that alright so this is what I this is what I have so far I have to have to do this as beginning of every live stream to sort of recap and refrain recenter myself hi I'm gonna put this over here so it doesn't block the view you may or may not be aware there is something out in the world called tensor flow J yes this is a tensor flow a implementation of the tensor flow API in JavaScript that runs in the browser with no other dependencies all of the math is done and computed using WebGL and shaders and all sorts of amazing gymnastics and ways that I might never understand but enable opens the door and enables possibilities for us the people who like program like this it's a high program to try and experiment and learn a bit about machine learning and get our get our hands in there and and ask the right questions would be critical about the role of AI and machine learning in our world today so that's this I have started doing a series of tutorials these are not super beginner friendly you know there's some advanced JavaScript advanced aspects of the JavaScript language that I'm using that are confusing like promises and weight and they sink you have to do lower level memory management yourself when you make these arrays of data you have to allocate the memory and deallocate the memory and then there's all these like scary weird terms likes get the stochastic gradient descent and that's that's one of them you know optimizer root mean squared so but I'm doing this series for an audience who perhaps has already learned a bit about JavaScript programming maybe watch some of my other basic intro to neural network videos and just kind of like follow along and see how a larger machine learning library works in the browser and can be used so the tutorials that I have so far are sort of an introduction to what tensorflow DOJ's is talking about what it is to be a tensor what is it to be a tensor I want to be more relaxed I want to be a variable instead of a tensor oh look that tents are very bad whatever okay then variables and operations talking about memory management I implemented a version of linear regression which is a kind of like classic machine learning algorithm where you try to fit a line to a bunch of data points kind of serves as the foundation for a lot of machine learning research I also looked at polynomial regression where instead of a line we could fit a polynomial function which curves around and then ah then then then then then I finally finally finally started looking at the layers API and the layers API is a higher level API inside of tension flow j/s which allows you to create machine learning models as sequences of layers and that has you know how that works has to do with how neural networks are architected with inputs and outputs and layers that are in between and there's different kinds of layers and different kinds of math functions that happen with those layers all that sort of stuff so this is where I am at the moment this is where I am where am I going to where am I going to don't ask any more I forgot my ukulele I learned to play the ukulele a couple weeks ago thinking of routing this YouTube with me playing ukulele where am I going don't ask anymore okay ah so what's next let me make a list really for me but you're watching so you can watch X or with T F layers I want to do a classification example I'm thinking of do what I'm thinking of right I want I so I'm gonna go through these one at a time classification and I'll come back to the details of these I want to do image then I want to do image classification then I want to do image classification again with convolutional layer so now I want to talk about what that is do I want to do some type of regression example maybe maybe so classification and then maybe sort of like as inside a Part B of like a basic like regression so this is kind of what I want to do in terms of the basic building blocks of machine learning with neural networks and I want to build all of these with the tensor flow das library so just just just to lower your expectations for a minute if I were able to get even just this done today I will be very happy about that okay so this this is kind of my goal that's my goal for today now I am doing things backwards in one in one sense I'm doing that these these are not super beginner friendly I mean they're as beginner friendly as I can make them I want them to be friendly but you know if I was my first day watching a coding video I might not want to jump into the image classification with the tensorflow layers api video which doesn't exist yet but but I once I get through this or actually once once June 15th hits or maybe even a little bit before June 15 that's next week I'm gonna start doing some beginnerfriendly and hopefully gonna guests come and do these with me maybe somebody was watching this right now who's worked on this ml5 project would like to come beginnerfriendly ml with some hearts and some stars like a little like rainbow and then like there's a train train going by I can't draw a train okay and with a library called ml v dot Jas so I'm gonna come back to this a second so just briefly let me just show you you catch a guess that's a great idea for a so if you go right now on the Internet to a URL ml v JSTOR G you will find this website and this is gonna be fun let's do something fun here we'll see here right here on the homepage is this interactive demonstration this is a picture of a Robin which the mobile net model labeled this as a Robin American Robin turdus migratorius with the confidence of 98.7 so I'm going to upload an image do I have any images here this is good hold on let's go get let's go get a rainbow image is this looks good download we should done a train let's try a rainbow dot jpg where am I going desktop that looks good let's go for a train this one looks good Oh save image as train let's go back to the ml5 webpage and what I'm gonna do I could drag and drop it but I'm just gonna do this let's looks let's try the train trailer truck tractor trailer trucking rig rig articulated lorry semi with a confidence of forty two point ninety four percent let's try doing the dragging and dropping thing with the rainbow bring it over here and now we have a parachute shoot with a confidence of forty nine point twenty nine percent so how does this work well I will show you if you scroll down here you will see here is the code for such a thing and so the ml5 library is a machine learning library built on top of tensorflow das this library would not at all be possible without tension flow chess running behind the scenes to try to create some simple code examples to work with at the moment mostly pretrained models in the browser and there's lots more coming here and I'm gonna do a bunch of tutorials with this but this project is I'm mentioning it now because Hannah Davis at the IO Festival I'm totally not in the slack channel here at the IO festival made talked about ml5 in her presentation when hopefully the IO Festival which is just finished up in Minneapolis the videos that all the talks that are amazing go find their Vimeo channel and all the ones from last year you can watch them the new ones from this year be out soon and we're looking at trying to launch this more officially on June 15th and I will mention that if you're interested in kind of poking around if you go to all of our github repos first let me just go over here oh we can see here's all sorts of wonderful people who have been working on this project more than just these ten people but here are 10 people and what I want to show you here is under projects this is my first or a into using the project management tool that's part of not to okay so but this project management tools the first time I've used it if anyone wants to jump on in and get involved and get bored kind of have a little sprint here from now until June 15th there's a lot if you look at that website there's a lot of stuff that's missing there's a lot of stuff that's broken and so you know reach out to me on Twitter at Schiffman type in a comment somewhere on github if you want to get involved and help us kind of push forward some of this code stuff for the release and okay so that's what I wanted to mention there too looking in the chat looking in the chat looking in the chat okay so now coming back over here so this is what's coming this is what I hope to eventually have on this YouTube channel is a playlist which is machine learning for beginners in the browser and what's to call it exactly and I'm gonna be using ml 5 NP 5gs for that together by the way the 5 in ml 5 is in omage 2 P 5 and processing because the ml 5 library aspires to be friendly and accessible in the same ways that processing in P 5 have been over the years and there we go my camera's still shut off now back to today it's 1 o'clock already so what now I have a pretty clear picture what I want to do with my image classification examples that I'm going to build I want to use the quickdraw data set so one of my goals with making my machine learning tutorials is to use non traditional data sets and but maybe nontraditional is wrong word but data sets that are outside of what you would typically find in machine learning and data science curriculum want them I want to use different ones that are kind of in creative space to get people thinking more creatively about what kinds of data they encounter in their life that they could maybe use I want to use data sets that are really simple and kind of like easy to understand and look at and it also want to use data sets that are representative of the world that we live in and all of the all of the cultures and people that we share this great earth with so you know things like I'm trying to avoid things like M mist which is the classic handwritten digits data set things like the iris data set which is wonderful I have loved flowers nothing could possibly be wrong with the flowers data set but but things that you wouldn't that that kind of made me feel a bit more approachable so I really asked this question a bunch of places a bunch of times don't get any responses because I don't maybe it's hard to find these kind of data sets I feel like the Google quickdraw dataset is a great one for learning about image classification and then what I'm thinking of doing an X or is like it's not really a dataset it's just made up oh wow something else someone add in here okay hold on hold on and then classification what I'm right now the only thing I'm so tensorflow dot yes there's a node version tensorflow yes that used this MLB Major League Baseball dataset to classify pitches and I love that football kind of a little bit of a baseball nerd you know any word so so I so that's kind of interests me but I don't know that baseball is perfect for what I want to do that's going to be you know a lot of people don't know about baseball and ranged in baseball and it's maybe not reaching the the more general audience that I'm imagining for this channel so but something like that that's really simple so all I could think of right now because I from gibreel go check out a CFD science that's the assess of science I can't ever say his channel name it's probably like there's like a really easy way to say that channel name and I just can't do it I don't know why I'm almost falling over for no reason I was talking about something datasets gibreel had this demonstration of a color predictor and what am I it's actually this semester created a variation on that which was kind of predicting more about a color than just a or B and so I was thinking of kind of using that as an inspiration and so like what if what if I made a color classifier that classified colors into like bluish grayish or like like the C I don't know some kind of set of arbitrary labels like five to ten labels that and what I need to so maybe I would crowdsource that Dave said I'm not sure yet so that's what I'm thinking about for classification I kind of hope to do that today but I talk too much and there's a little bit of time but that's that's coming next week another thing I forgot in here I wanted to make like make your own TF playground so just briefly one last thing that I'll mention here on this todo list if you go to I believe it's playground tensorflow dot J s what's that well hold on J or whatever tensorflow playgrounds this is a project from the big picture group the research group from Google that created that where 10th floor address itself came out of and you can kind of create this little playground in the browser where you can configure a neural network you can have this kind of 2d data set you can actually there's like a play button so you can run it and you can watch it try to either classify and there we go sort of classify or I don't know it's doing classification regression it looks like classification to me they're sort of blue and orange so I have no interest in building out something that has this level of sophistication and design visual design but I would like to show you well could you similarly to how I made the linear regression the polynomial regression examples maybe I'll just do like a basic 2d classification problem with drawing stuff okay so that's that's my introductory talk I love this go you little neurons that data whoo all right oh oh I can break it I'm very keen for a fix all right so that's where I am so I think when all is said and done I think right now I'm just going to tackle today from now until about 230 which is an hour and a half X or and I really am torn like I don't want to do it because is it it's sort of but it's good for me so I'm gonna do all right but before I do that let me see if I can get some questions and get myself organized anybody have any questions about ml5 tensorflow J s life the universe how to play the ukulele all right so what do I need to do here it's a couple things that I need number one is if anyone who is a sponsor and patron and there's an interesting question in the YouTube chat that's the might that I might like to answer you can paste it into the sock channel this is not right no no oh totally Papa Delhi doobie doobie wahh there we go alright there's two bits of code that I need to get started with this one is the actual previous XOR there we go coding challenge 92 and then I also want to get under maybe it's under courses intelligence and learning session wait no how come it's not there is this a different go past in a different place I have this in too many places courses intelligence and learning session 6 the layers API I need that and then p5 tensorflow let's put these in there and I don't leave these anymore and let's go over here I don't know which would be better to start from let's start from this this'll be coding challenge what what coding challenge number isn't this the third time we do X or is it really oh you're really torching me because I really feel like I have a thing I have a little bit of a thing like it's kind of a little like you know like I can't if I'm listening to podcasts like I I have to listen to every all of it every minute I can't like not listen to one episode and I have to like so somehow in my stuff like guys like I just have to do I have to do the X or now with ten to flow Jay s because I have to but maybe I should skip it what coding challenge number am I on did somebody tell me no but I can find that out by going here and oops 105 was polynomial regression so this would be 106 okay I totally didn't do this right yeah how come there we go now do I have the atom editor open see here's the thing what's interesting about doing this YouTube channel is if I were teaching a course like I do supposedly he's at NYU I just would not I would just skip a lot of stuff because there's like limited amounts of time and I do to some extent to do that here but I I have this like false it's like this false sense of infinite time and I must do every single step which I need to move away from Cain wheat bun writes it's a good example comma but dot dot and I get it I get it but I'm waiting for what's coming next yeah I think I could I could fill it in but but but I think it's weird that's what I'm doing today unless I'm into that no no okay that's what I do all right all right all right so let's see here we are this is my list huh thank you thank you XOR Shipman see I think I only actually made one even though it's like probably the third or fourth time I'm doing it on this channel I didn't I don't only have one video it appears yeah look here's here's Simon talking about X or some other videos okay all right and now Joe server yes let me open up the browser I would love to do like some kind of little just fun algorithmic thing the equivalent of like phyllotaxis today before I go if there's time but I doubt there is okay all right you had got CGI rights I missed the non machine learning coding challenges totally agree yeah I don't know burger Bob asked could you please read the chat more often I totally get the sentiment I appreciate the question I will sir I can certainly try it is very hard to follow the chat and do the livestream at the same time and maybe someday I will have a better system for doing that I have some ideas for how to do that but it just I need time to get some more screens and maybe have some help with that and the sort of thing all right ADA she writes did he say filing taxes yes and now coding challenge number 327 filing your taxes let's go see IRS tax filing API ooh IRS gov a file providers software developer okay I guess I guess the XOR isn't so bad phyllotaxis the spiral beautiful Fibonacci spiral pattern of a sunflower that's what I was saying alright see what happens burgerbob that's exactly burgerbob Oh what about a giant screen which shows the chat behind the camera that is exactly what I would like and I will snap my fingers and giant screen will be mounted there behind the camera somehow that didn't happen I'm not sure why so I will I I do like that suggestion looks whoops yes Chris writes might be worth having a mod pull interesting questions out of both chats and give them to Dan at Q&A breaks I'm absolutely game for trying that and wants to sort of volunteer at this point I think I would need a volunteer to help facilitate that and that would be great all right let's let's let's let me get over all of my anxiety and hangups about you doing X or again and talk about them when I start and then and then and then and then I will begin I see all these people typing and Ada and Kate week Mon and Eric but I gotta move on I think I got to start because time time is awastin yes thank you okay Eric in the chat rightz sometimes it's important when learning something new to base your exploration around an example which is fairly trivial and you understand intimately well true or were better I could not have put it better myself thank you I'm gonna read that sentence at the beginning of this coding challenge if you don't mind hello welcome to a coding challenge yeah I know what you're thinking I mean I don't know what you're thinking I know what I'm thinking that looks like coding challenge number 92 XOR which is probably one of the less interesting creative like sort of just technical coding challenge demonstrations that you've done why why why are you doing it again well Eric from the coding train community writes thanks explanation because I was just before I started this having a real hangup about this sometimes it's important when learning something new to base your exploration around an example which is fairly trivial and you understand intimately well so here's the thing I I'm learning something new I'll come back here and the thing that I am learning something new is this tension flow a thing and wouldn't it be fun to make like play pacman with it or the emoji scavenger hunt project or teachable machine or play a piano with it all these things all pose that oh my god we got it we're gonna get this I could just sort of go there right now I will get there eventually but I'm trying to learn the basics of how the library works and I'm trying to step through this slowly so I will say that we're if you're watching this video right now where you are is not necessarily in the most beginner or friendly place because I'm working with tensorflow tas natively to implement basically like a weird math problem it's not that weird of a problem actually but a very basic trivial math problem just to see how tensorflow dachi has works that's what I'm trying to do with this coding challenge and about 20 or 30 minutes he'll be coding this coding challenges just look it's right like four hours and 72 minutes long which is why i say 72 minutes cuz that's five hours and twelve minutes I don't know but the trajectory that I'm on is I'm gonna start doing some stuff inching my way towards hell let's actually use some data let's use some more data and maybe some images and so I've got a bunch of things that I'm stepping and I'm trying to get to the point where I'm going to use this other machine learning library called ml5 which at the time of this recording hasn't really officially been released yet but builds on top of tensorflow das thank you everyone who votes wherever you are to try to create some more accessible interfaces to some of the algorithms and models that you things that you can do with tensorflow digest without having to do the lowerlevel memory management and math operations stuff so all that is coming and I just took a lot of time in this coding job to say that to you so but as much as I kind of don't I haven't I'm not so sure but well but it's a why is XOR so here's the thing this is why I want I need an example this is the first time I'm going to ever in any of my videos except for the other one that I made but this is the first time that I'm actually going to use the TF layers API to Train Oh to train a model with a data set to produce a certain output okay I did two tutorials about what the TF layers API is you could pause down and go and watch those and then come back here but in those videos I didn't actually do anything with TF layers just sort of talk through and typed out some code so the problem that I want to solve and apologies for explaining this probably for like the fifteenth time on this YouTube channel is very well known from machine learning X or because when the original perceptron was invented the single perceptron the model of an individual neuron that could receive inputs and generate an output it could not solve X or it just couldn't it's not a linearly separable problem and I've talked about that in other videos about why we need multilayer perceptrons so the nice thing about XOR is I can diagram for you hold on a second look back I can diagram for you the the architecture of the model that we need to create there are two inputs there is one output so that the inputs to the XOR problem are true and false values so unlike a so if I made a little truth table and or XOR right I can have true and true true true false false true false false and and operation would only ever give me true when both are true false false false and or operation would only ever give me would gives me true if just one of them is true true false can you even see that I can't see on my monitor but hopefully you can now XOR the X for exclusive gives me true only if one is true they can't both be true only one so in that case I get false true true false and the idea if linearly separable comes up here because I can draw a line here to separate true from false I can draw a line here to separate true from false but here I could do this but I can't draw a single line to separate true from false we need a more sophisticated model with a hidden layer so the inputs are things like a 1 and a 0 feed forward into the hidden layer activate feed to the output and the output should be a 0 or a 1 it's really in some ways a classification problem but I'm gonna do this as a regression essentially where I'm just gonna get some number between 0 & 1 if you watch the previous coding challenge the reason why that is is because thank you very much good night this video is now I hid that my sound effect by accident because what I'm trying to do is visualize the truefalse space alright pause for a second just taking a pause for a second how long's 10 minutes at least right but I you know it's important it's important for me to talk about what I'm doing all right so I'm just thinking here where am I going next looking at the chat no one's complaining too terribly and I think I'm going to move on I guess I could transition back over here case I'm not you want to edit out the weird sound effect thing oh they're good sounding okay that's good Hugo asks will you ever do non JavaScript videos well I do I do some processing and Java videos those aren't JavaScript but you know at this point I'm kind of I'm kind of I'm kind of doing the JavaScript thing okay let me let me transition back and that to me may be the sound effect little thing was like a funny little bit but I think I'm gonna just transition back because ultimately what I'm going to do is visualize the output of the model and I'm gonna send in numbers all the way between zero and one I know I don't even know what I'm saying it's fine because ultimately I'm gonna visualize the output as grayscale values and I want to see number I want to see grayscale values all the way between zero and once the same thing I did in the previous coding challenge if you if you're happened to have watched that one alright so now I actually I'm gonna also do something where I start from the code from the previous coding challenge and so we can see there's this idea of training data the inputs to the X or problem are zero zero gives me a 0 0 1 gives me a 1 1 0 gives me a 1 at 1 1 gives me a 0 this is the training data and in my previous version of this I used my own neural network library so in theory I'm gonna get rid of the idea of the learning rate slider just before we can add that back in later but let me get rid of the learning rate slider basically I want to do exactly the same thing the difference is I'm going to say neural network equals TF layers sequential and maybe I'll call this the model instead of neural network so the I do this is a neural net here so the idea here is that I want to replace my neural network library with tensorflow yes and so this for me what what the usefulness of this video is a me learn I spent all this time trying to build my own rather sort of terrible neural network javascript library and going through that was sort of helpful in thinking about how the stuff works now if I can translate that into attention flow dot yes I'm gonna things are gonna hopefully start to sell and make more sense into my brain Bruno is asking something in the chat about the true/false table yeah usually you draw it as a I might come back to this later usually you draw it as a matrix and I sort of did something weird there but I think it's fine sorry I'm looking see this is what happens wait look at the chat too much all right okay alright okay so now we need to what this constructor here said and let's just put this back to this this constructor here said would make a neural network with two inputs two hidden nodes and one output so I need to duplicate that idea here with PF layers so let's go to the 10th floor Jas API reference and we're gonna go all scroll down to TF layers and what I want to make is a dense layer TF layers dint a dense layer is a fully connected layer so what I'm going to do is I am going to say let hidden equal TF layers dense and then I can put inside there an object that has the parameters of how I want to configure that layer and so how do I want to configure it the two things that I want need really need to do is this is the hidden layer right I need to give it an input shape right he just say what's coming in what's coming in that's what this is here I need to say how many nodes it has that's the number of units and then I probably has a default one but I can specify an activation function and again I'm just going to use sigmoid as this historical activation function that I've been using in all my videos to date I'm gonna soon talk about softmax what that is as well as some other activation functions like lazy which is maybe more commonly used okay but like nobody pronounces that way foot B so don't get confused alright so I want to say input shape I believe is just there's just two inputs I also want to have two units two nodes and activation is going to be sigmoid so now I have created the hidden layer yay the other layer that I need to create is the output layer and so what am I know the app and layer I don't need to provide an input shape because the input shape can be inferred if I add them sequentially the inputs are not a layer so for this first layer the hidden layer I've got to say how many there are but now once I'm creating this next layer it can just the input shape is gonna be defined by what was before it so now I'm going to say really have to stop it at the sound effects by excellent and now I'm going to say let output equal TF layers dense and all I need to say is units one activation sigmoid okay then ought to do is say Model Model dot add hidden model dot add output okay so this is the model now one thing I need to do is I definitely need to import the tensor flow J's library which I happen to have from one of my previous examples so I'm going right now I only have I have the p5 libraries in my index.html plus my crazy neural network thing and my actual code and sketch J yes someday maybe I'll use the fancy new import syntax stuff let me just just have everything kind of line up let me add this in here so now TFS should be there I should be able to go back and run this and not see any errors aha TF dot layers dot sequential is not a function so I'm seeing things in the chat chats really off the rails with this XOR thing all right so I probably just so I probably just didn't even see half cut layers dot sequential the right thing you know I could go look I by the way made an example oh it's just TF dot sequential okay so all I all I want to say is I just got that wrong it's TF dot sequential so you know I could go look you know hopefully I would find this here at EF dot sequential yeah models creation there it is TF not sequential so I just had that wrong okay let's try refreshing this yet again slider is not defined hold on sorry much ya have to turn the notifications off on my watch I'm getting like phone calls and buzzing things okay take a minute here somebody said that I look I'm good at drinking drinks in profile that I could be like a coating train brought to you I'm buzz marketing Klean Kanteen that's not an official sponsor where was I right alright let me fix this learning rate issue 0.1 I just want the thing to run okay so it's going it's still working with the my neural network library not the new ten so Jeff's one but let's keep stepping through so ah so what am I missing here so when I make a model this is now I've architected the model I've architected this particular architecture but I need to do another step I need to compile the model and I need to define the loss function and the optimizer basically I need to say like okay well this is how I'm going to determine how well the model is currently performing with the training data and testing data potentially but I'm not getting testing data will come in my next video about classification but here I'm not making a distinction between training and testing date I'm conflating those two concepts which is a big mistake and a problem but we're stepping through this stuff later by little by little like a butterfly flapping its wings it's not at all a butterfly but I felt like I was being like a butterfly and then an optimizer is what sort of function what sort of algorithm am I using to adjust all of the weights of all these connections according to the loss function itself so I need to define those things so let me try to type it out how I think it is and then we'll go check so I know I need to create an optimizer GF optimizer like this and with a learning rate something like this like I'm gonna I want to have used to cast a crate to set with some learning rate that's not correct this is me like trying to remember what what the code is and then I need to say like model dot compile and then I think when I compile it I'll say things like this I'm going to compile it with optimizer and this loss function like like root mean squared or something like that so this is what I'm remembering from when I looked at this at one time and I probably got this wrong so let's actually go look at the API Docs well first what's the chance that any of this actually makes sense okay TF optimizers not a function so let's see how do we create the optimizer optimizer yes so it's this is what I want I want a TF train SGD this is how I create the other optimizer is not a keyword in the API just I imagine that for myself so I need to say TF train SGD and then give it a learning rate so TF train SGD and there are other kinds of optimizers that will will that I think I've even shown you and what we'll use more and give it a learning rate like 0.1 then I want to look at model dot compile so look for compile well we can see in some examples here what I'm looking for is where the actual compile there it is compile so the compile function compiles it and give an optimizer a loss and I can also do some metric stuff I'm not going to worry about the metrics too much although maybe I'll try to come back towards the end of this video okay model dot compile optimizer loss I think this might actually be fine is it root mean squared so let's look for the loss functions loss root means mean squared Oh Weiss ago I keep saying root because I have it in my head from some thing that I did a very long time ago where I was always taking the square root of the mean squared error so I always say root mean squared there's no root here involved I guess I have to get back up and continue this tutorial how long was I saying root for and hell annoying will that be for the people who watch this later okay well don't you know I get up slowly others I get kind of lightheaded alright apologies I've been saying root mean squared error for because I'm stuck in this world where you have to take the square root which you don't need to do here so just mean squared error that's all I need this is my loss function mean squared error now let us now go back here hit refresh all right things are happening things are going so the model is built the model is compiled and the next thing that I am ready to do is now actually start putting data in the model time out for a second why did I lose all right just a second here I really have to watch the time I've got an hour I have to be a little league practice I am NOT a strange forty fouryearold person who plays in the league but my son is playing Little League for the first time this year to be at the practice cannot be late so I have another hour though okay hmm I'm not the coach don't worry I'm just stand by the side a cheer do my little debt hold my little signs that's it I don't have any sign should have signs I was actually thinking of sponsoring a little league team like the coding train sponsored little league team I think get it get together this year maybe next year alright all right there too these are two next steps whoops oh why is this completely died I just I know I'm saying 44 a lot because about to be 45 so I feel like it'll say 44 I like number 44 much better than number 45 for a variety of reasons that it will not get into can figure out what I'm talking about all right um it's pretty obvious probably all right so the two things that we need to do now what are the two main steps I don't know why I came over here but since I'm over here first of all I drew this truth table thing a little bit weirdly and so you might recall just to be clear about what's going on this is my little drawing of the canvas right now and the idea of the canvas is that I want to see what the neural network thinks false false is at 00 I want to see what it thinks true false is at this right hands top right hand side the bottom left hand side I wanted to see it 0 1 and then I want to see here 1 1 so false is black 4 0 and true is white for one that's the way I'm gonna map the color so I should see some kind of bands of like I should be getting like something like this so darker here and like this so let's go look does that match yeah that's exactly what I'm seeing here so the reason why I came over here is what I need what I think there's two things that I need to do number one is I need to train the model to produce this output my desired output that I think it should do and then I also need to ask the model to predict so I can draw what it thinks its output is so the two and the and so the two steps here I don't run out of space but in the attention photo chess library I wanted you I need to look at the predict function and the fit function predict for just saying here's the inputs what is your output the fit function for saying here's labeled inputs inputs with no outputs adjust optimize yourself according to that so I'm gonna do things backwards I'm gonna do just the predict step first I just want to see when you starts up with no training what visual output again so coming back to the code let's look here so this this is what I need to replace I need to say now I need to say let whoops y equal model dot predict model dot predict now let's go look at the documentation right I need to send in the inputs so let's go back to the documentation model dot predict I get a better way of browsing this documentation here it is so I need to sorry model dot predict I need to give it the X's what are the X's this are the X's but remember I'm using tensorflow de s now tensorflow s oi oi oi vague volts I have to make them a tensor I can't use regular arrays so I could say let X is equal tensor 1d oh no it's CI sorry I got confused TF tensor one D inputs and then model X's now here's the thing so this is the ID there's many problems what I've done so far ok many problems which I will solve slowly this could be a very long video I apologize in advance you can take a break now pause take a break go do something else go back so what about what's the what's problem number one problem number one is predict happens asynchronously hooboy pause for a second here how did i do this and so i made an example i want i just need to think about this for a second wait my glasses are steaming up why is it getting all warm in here hold on oh and Eric thank you for that pull request I probably shouldn't that and then look at because he probably fixed a bunch of things I just want to see something can we do this as a batch oh no predict happens synchronously it's fit that's asynchronous oh good that's why I'm doing this right predict happens synchrony can happen synchronously let me look at should I should show you what I'm looking at I know why I'm looking on this other computer oops I'm just looking up some stuff for how this stuff works oh wait wait no hold on let me show you what I'm looking at because I don't know why I'm looking at this so I have a repo called 145 it's not called what for I this the time tensorflow jazz examples x or sketch right so I know I have to do as a batch neural network predict Oh or did I do it and so I was putting it in a class which I'm not going to do here tidy return oh I know predict happens synchrony synchronously but then pulling the data off happens asynchronously but I can use data sync even though I probably should be using TF next frame I don't know how to use that yet so I will deal with that later okay sorry okay okay oh here I am back all right sorry we can just back up a bit not you you can splice things however you so feel so inclined whoops so I need to now I need to ask the tensorflow layer sequential model thingy to give me the Y neuro a model dot predict but what does it expect its predict function unlike my predict function cannot get a regular array it expects a tensor so I need to make the X's into TF tensor 1d with those inputs and pass those through predicts now here's the thing there there's a lot of issues with this that I need to resolve and this is gonna run really slow I need to actually do this as a batch process I'm gonna get to all that but just looking at what I've got so far model dot predict there's there's a question of like is this happen synchronously or asynchronously this actually is happening synchronously but the problem is I need to say fill with the result like I need to look get that number out and to get the number out I actually want to call dot data and that happens asynchronously so because I'm working with some teeny bits of data right now I think I'm gonna use data sync and there could be issues with that and as I move more forward we're gonna see when I really need to be more thoughtful about callbacks and promises but I'm gonna use data sync right now so I should be able to predict the output with this input get that data and then let me just say console.log why and I'm gonna make the resolution here of the oh yeah the resolution really big like 50 because I just want to like look at very very little data to start with and let's look I'm not gonna draw anything let's just look and see what's coming out what's coming out here why and then let me just say no loop so let's look in the console and see if we get anything error expected when checking dense dense one input to have two dimensions but it got array with shape too I have the same problem I've had every single time I've done this with 1000 to 400 guess so the good news is I want I don't want to just give this one D tensor so even though my data is just two values 0 1 1 0 1 1 and it's a onedimensional array with two numbers in it I actually want to be able to do something like hey take these 15 data points and give me the results the predictions for all 15 of those and so what I really want to be doing is I always need to send in kind of like one order higher one degree one rank higher so this actually I'm just sending in one data it piece of data endpoint in point input frame stopped work and this now I also have to say tensor 2d now because it's a 2d tensor there we go ah so we could see look at this the results came out for all those little spots you can see in little numbers between 0 and 1 in an array so now I can instead of console logging Y and I just want that it comes back into the Ray but there's only one number I care about I can put this back in here I can take out no loop and I can run it let me see look there is my current visualization of X or I'm not really done I've so much left to do in this video that is recording for the last three or four days alright one thing I want to do is I just want to say stroke 255 I just want to sort of see a little bit more okay that's actually what I'm looking at here I actually want to make the resolution for debugging debugging wise on I also want to make the resolution a little bit bigger so let's see now one thing I'm curious about let's look at the frame rate here oh that's lighting at 30 frames per second so that's fine let me now actually make the resolution much much higher like this oh my goodness oh it's not even getting to the first frame oh well there we go look at the frame rail can't even give me a frame rate it's so stuck you can't even get one frame per second so here's the thing I have done something very very very bad and I needed to stop it no loop stop you don't have to do any more work and let's put the resolution back at 100 and let's think about this what's going on here look at this look at this predict function and look at this data sync function what am i doing I am calling that function multiple times every single for every single spot on that grid when I'm working with something like tensorflow J s whenever I create a tensor or feed data into a model the data has to go from my code onto the GPU and then when it's done that data sync is pulling it off of the GPU so I can use it again in my code that graphics processing unit where all the math is happening behind the scenes I want to do that as few times as possible look how this is I'm creating this twodimensional array with one thing in it you know ten hundred times I could just create one array with a hundred things in it and call predict once that's what I want to do so I what I need is for this nested loop to happen twice once to actually wants to setup the data and another to draw all the results so I'm gonna copy paste this just put it right below so this now what we need to do is create the input data so I'm gonna say let inputs be a blank array then I'm going to say inputs dot push and I'm going to just push in x1 x2 so I'm going to put every single x1 x2 all the way along I don't want to create the tensor or do this here I don't want to do the drawing stuff here I just want to create I just want to have a loop that creates all the data now I can get the X's is all of those inputs into a 2d tensor and the Y's this is now the Y's is and now here's the thing I don't just let's so hold on I got a look at what that's gonna look like let's comment this out for a second let's look at the Y's and see what that looks like oh okay Sketchup 78 error OOP oh no let there just inputs push okay oh I want to say no loop let me leave that no loop in put it back I just won't look at it once so you can see what did I get I got a big array of 16 numbers I got all the results so now what I want to do is back here now I just need to do the drawing and I don't need to the input data I don't need the model all I need to do is draw and I need to say fill wise index what I plus J times the number of columns maybe right because this is a one dimensional array to describe all each spot in that grid I could do something like let me just do this let index equal zero I'm going to say fill based on this particular one and I don't need this even sorry and I just need to say then index plus plus right so what are the steps here create the data get the predictions draw the results okay there we go so now we can see this is working I mean it's not doing anything but now let's check this framerate question we don't need to console.log the Y's I'm going to get rid of the no loop let's let's refresh this let's look at the framerate 30 frames per second let's let's pump it up a little but pump you up a little and where is the resolution there let's make this 20 I don't want to go crazy and look at the framerate there we go 30 frames per second no problem because I'm only one time through draw trying to copy data on to the GPU and get it I'm only calling predict once and we can just to check we can go to 10 and we can look at the framerate yeah you could see it's like kind of running a little bit slow but this is because I'm not being too thoughtful about the asynchronous nature of this stuff I could do other things to optimize it but I'm just going to ignore that and leave it at let me make it 25 hey timeout for a sec this should definitely be multiple parts oh yeah create inputs at the start they are constant oh that's such a good point okay I'm gonna do that right now that's a very good point who said that in the chat probably lots of people have precalculate them set up a bunch of people have yeah okay oh this alright all right everybody's saying that all right the chat is giving me some even further optimization which is why am i bothering to do this in draw this is something that the these inputs is never change I could just do them once at the beginning because they're and and I can I can ask for ask them many times in draw so let's actually fix that so I'm actually gonna I'm gonna take this and say let I'm gonna make this globe these global variables I don't know if you guys can hear the music that's coming from the room next to me but it's there alright then oh but the width and height does not exist until after create canvas so let me do this and let me do this okay so now that's there now I should be able to take this the input data and put this right here in the beginning and then I'm going to make a variable called X's and X is and where did I do that here and then create those X's so I'm now doing this in setup and then in draw the only thing I need to do in draw is run the predict this is going to make things run a lot faster let's make sure it still works here we go okay so you notice we getting like a different color each time i refresh because the neural network model the sequential model is initializing everything randomly but now I get to train it now I think we're ready to train it so here is what I did when I had my previous my own JavaScript neural network library I called neural network trained data inputs data outputs sorry I'm reading the chat you guys couldn't hear the music well alright so if I only I could remember exactly what I wrote when I made that TF layers tutorial but I know that what I need to do here and is I need to do something like this model dot fit some X's and some wise that's the training that's the equivalent and the learning rate is irrelevant and I don't necessarily need to do it this is basically what I want to do every time through draw I want to try to fit the model with some training data so let's first make the training data this is not exactly right I need to figure out and I need to use a weight that need to think asynchronously but this is the idea so if I go back to the top here this is my training data now one thing I definitely need to change is I'm going to keep the X's and Y's separate in training so I'm going to do this is I'm just going to do this kind of manually because I what's the big deal so let me make the training set and then one one those are the the X's now let me look at the Y's and the Y's would be 0 1 1 0 then I need those to be tensors so I need to say Const trait TF exes ah so I've got to think of good naming for this I kind of want them to call actually you know what I'm just gonna call it do I have a global X yeah I have a global X's already hmm hmm hmm tray TF X's equals 10 sir 2 D tensor 2 D OTF tensor 2 D you know what I'm gonna do I don't need these I don't need two separate sets of variables I'm just gonna create it I'm gonna call this ah everything is so much more complicated than I make it so if we're simple then I make it I'm just gonna make these tensors directly by saying TF tensor to D and then I'll put the parentheses around this and there now I made it a tensor then F is a TF tensor to D and now I made this a tensor ok now I've got the training data and I'm gonna get rid of this this is the old way that I had the training data which is totally unnecessary so this the training X's and the training wise are you with me if you're still watching I don't know dude get up and do it some jumping jacks let's see now I need to do model F it now model dot fit happens asynchronously so let's put it in its own async function called train model now if you don't know what it means to write a function that is tagged with the keyword a think this is part of es8 a very newish version of JavaScript and I made a bunch of videos about what that is that you can go back and watch but this is basically a way for me to now say wait model dot fit and then let's look at actually let's look at the fit function model dot evaluate compile predict fit so what I need is is to give it the X's and the Y's there's batch size I'm not going to worry about there's epochs I'm not going to worry about or epochs and so H will give me back the history so let's just see here I'm now gonna say train model dot then H console dot log H dot loss index 0 let's say no loop again so basically what I'm doing here is I want to call this function train model and I'm using this idea of promises it's going to await the model on I need to return do I say a weight return or return a wait no I must say return oh wait return oh wait model dot fit so I'm going to return a promise which will have the result of the fit function and I don't know if this is right I want to just look I want to do that I want to call to train model every time and draw I might need to do this somewhere else just right now and then see what the loss is ok onyx 73 async function async function I've got a save function function it's an async function not an async there we go wise is not defined where a train model oh right this is I forgot to call it train X's and train wise so my training data train X's and train wise isn't that nice other word train just appears over out when you're doing machine learning you drink your glass of milk or whatever it is you're having while you're watching this coding training stuff cannot read property 0 of undefined a train model than H all right let's look just console.log H note that is what I've done okay history loss 0 okay oh no by the way didn't give it any testing data so whatsit computing the loss from history so this is I'm gonna call this result result history dot loss index 0 all right there we go there we go now let's let it do that over and over again in draw alright uh so this is a bit of a fail here no very returning the promise that's a good point all right so I let this run a little bit and unfortunately see it's getting nowhere this loss which I'm not sure exactly how it's country things I don't think about that come back to it is not going down anymore so what could be some problems here remember one is maybe my learning rate is no good not that it's no good maybe it's too low so where did I set up that learning rate again let me get rid of by the way I just want to now delete I want to make sure I'm not using any of my old neural network code so I'm deleting all references to that so this is now purely tensorflow Jess and and let me refresh and run this again and let me look into sketch dot yes and find where did I set the learning rate right here let's set it to 0.5 and see what we get yes getting better I'm gonna let this run for a little bit and I'll be back let me look at so one thing I want to do also is I want to write it looks nice if I write in the numbers actually of what the output is where it is you can see that it's actually getting there just very slowly I just want to see what settings I used in my other example try different optimizers and activation functions yeah I'm going to do that in a second I want to get it to work with this first I just want to see what settings I used oh did I forget to put shuffle in but shuffle it by default I wonder if I ah you know what I forgot to put shuffle in it's actually working alright I'm back and you can see the losses now kind of much lower and you can start to see the visual that I'm expecting which has a true value in this corner a true value in the top corner and sort of darker false values in those corners but it's still kind of performing rather poorly one thing that I forgot to do is when I call the fit function there are a set of options that I can pass in for the number of epochs and all sort of thing but one of the ones that I really want to pass in here is called shuffle shuffle takes the training data and it shuffles the order of it each time right now I'm trading it with the same four data points in the same order every time which could be a bit of a problem and okay so let me now let me hit refresh here and run this again oops I can't see the frame rate because time out a sec 0.5 optimizer Oh optimizer yep this was all the same sigmoid sigmoid did I am I giving it you know what I probably did No I thought maybe I was giving it more epochs or something shuffle Forex or is not a big help apparently not I'm curious I could do just out of curiosity because if I go to that thing I was showing you everybody where this is this should be hosted hosted via github pages for loop and epochs will really help yeah I just wanted to see like I'm pretty sure I know why this isn't loading I mean the other thing is I probably should create a separate I mean there no such thing as a thread but I probably should have right I should just run the training like this async function I should just like I don't need to like I don't be calling this in draw but I just wanted to start doing that I was gonna fix that later what time is it I have a half an hour and get through this whoops why is this not loading oh is it because oh it's probably cuz this is running I don't know why my example I wanted to see the performance of my example hold on I think I need to restart Chrome oops why is this not working here we go yeah I know I should do like I was gonna do this set interval thing but actually wasn't gonna do set interval I was gonna do set timeout and then have it like recursively call itself when it's done I'm just kidding I'm a got lost and this is not important I just thought I could run the thing that I made before just to see how it performed but I don't know what it's what it's stuck is anybody else anybody else try running this example maybe I'll merge Eric's pull request it's like stuck weird okay yeah that's what I that's what I wanted to do next frame so me I am so me let me come back to that I didn't want to do that first but yeah but thank you for that oh my goodness I forgot to tidy everything oh well but yeah the wise I need to dispose and I also need to tidy this oh yeah well let me at least just go back to where I was I'm gonna let this go for a little bit I just want to did anybody see what that was there it is where is it yeah look at that that's a mess okay okay all right so things are still working but it's still running kind of slow we can see I'm getting the lost down hold on okay things are working it's getting the kind of getting close to the right results you can see the losses going down I've realized thanks to the chat of course that I forgot something really important is I want to try to make it learn faster which I will kind of get to and I want to think about the sort of asynchronous nature of using p5 s draw loop and using the model dot fit at the same time but before I do any of that I just realized I haven't thought about memory management at all and there's a big problems if I just take out for a second this and let me let me do this here take out this console lot log and I run this again and I look at say if I say in the hooks yeah I'm like killing my computer it can barely run it again because watch what TF memory num tensors 3455 4042 79 i'm just generating tensors I'm filling up all the memory it's gonna perform so this is going to be a disaster so let me stop it before it gets too bad and let's see where do I need to do some cleanup so these X's these training tensors I never need to clean those up those I can keep forever but I in train model I should probably TF tidy this whole thing let me think about that let's first actually the Y's after I do this I can just dispose those so the Y's I definitely need to dispose let's at least just do that first and let's see what um let's see where that gets oh oh look at that look at this ah because I use data think I could use TF tidy but what I'm gonna do now is wise and then I'm gonna say let Y underscore values equals ma wise dot data sink I can't clean it up once it's also been data synced so now I do to why it's not disposed oops do I have no loop on nope and still going up that's weird oh this huh this has to be yvalues also I have to change that to Y values so that helped now what I want to do is I need to uh let's just do this TF tidy let's just put the TF tidy here so like whatever happens in this function just tidy it all up I could put it properly up here it's that model that fit the need to tidy but I'm just going to do this let's do this five hundred forty nine hundred missiles being created over and over again that I didn't tidy it's to 2003 to a disaster what did I not tidy I guess maybe I need to put tidy in here like or I can just say like this right to learn Oh mmm I'm so confused like this no I'm so confused hold on I'll have to make the arrow function async yeah I dislike I'm like lost here let me back up for a second this is why I wanted to tidy outside of it you get rid of TF tidy for a second what did I have to start can I just put this here what am I missing I can't use promises in a tidy uh right so I was doing this right hold on a sec what what's wrong with what I had here what was wrong with this like why is this this should be fine right which version of well let me also go back to making the resolution much bigger oh uh I had it right before I just didn't save I'm gonna do a backflip ready what no no I'm not dating back foot I had it right the whole time no that's so weird when the resolution is higher I have a memory leak that's weird what am I missing why do I have three in there that was weird I'm like going out of my mind here so what is it well I have some like weird bug here that I'm not thinking of exes let me see if tidy this whole thing hmm ah so why with a different resolution that's so weird I feel like that's is a bug he had to slower the resolution to less early I sort of feel like there's some bug that's not my code I can't figure it out but tidy here kind of fixes it I don't think that this needs to be this is just an array so this doesn't need to be cleaned up I mean the garbage collector should that's not a tensor but did I make some other tensor in here that I like it's modeled I predict maybe it makes some other tensors behind the scenes okay you know what it is I'm just being silly here I think I'm like forgetting that model that predicts like model dot fit does okay that's yeah I'm going back and talk and I'm gonna do my memory when did I make that three I'm gonna do my and go all the way back and memory leak it again and fix it yeah the epochs will definitely help whoo modeling evolution with tensorflow das from suraj rebel new video all right want to get this down a bit and then I'm going to come back all right here we go here we go I can't look at the chat right now jet all right so you can see it's kind of working I back it's sort of taking a while but I want to get this to train a little faster I want to make this I want to get a little further it's up first of all I was reminded by the chat that I've forgotten something really crucial important which is memory management and I really I really should stop this from running right now because there's a huge memory leak happening which I haven't cleaned up any of my tensors at all whoops look at that well not sure out that it was there this is there just do this again sorry everybody one more time shift ya memory leak really need that ukulele Wow all right wow look at this alright so you know it actually it actually is working it got the correct training result it's a little gray scaly in a way that I would like to be able to like emphasize visually what it's do but you could see the loss has gone way down but it took a while to get there but I want to add a few things to this and try to fix it up a little bit before I do anything I was reminded by the chat being over here that I haven't thought about memory management at all so I'm gonna say like no Luke for a second to just sort of turn this off then I'm going to say memory numb tensors oops no no way TF memory dot numb tensor I know I'm trying to use it I'm gonna say numb tensors TF dot memory numb numb there it is there it is I could get it there it is thirty two thousand two hundred five tensors that's crazy so I need to deal with that I'm just making tensors and letting them leak everywhere so I can manually run dispose but I've got kind of an issue whereas predict is gonna like make a lot of tensors behind the scenes as well as a model dot fit so I can use the TF tidy function so I'm gonna say TF dot tidy and then I just need to I'm gonna use the es6 arrow notation which you can watch my videos about what that is but and I've kind of gone through what tidy is tidy says anything inside of this code clean up the memory afterwards basically and then I'm gonna I probably could put this around everything but I just want to and I don't need this stuff anymore I just want to keep these two areas separate because I think I'm gonna at some point I really should change the way doing the fitting of the model excuse me in draw is somewhat problematic so now I'm gonna just tidy all of this I think that's right I tried an extra parenthesis there yes okay so now let's run this again comment out this console.log I don't want to see that right now oh all right now let's look at the number of tensors 15 15 15 so now I've gotten rid of the memory leak let's check out the frame rate 30 frames per second so this is running for up now let's I just want to be able to look at what's happening a little bit better so I'm actually gonna draw the number of the output inside each one of these things so let's do that so where am i drawing the rectangles here I'm going to say let the brightness value equal this and I'm going to fill the rectangle with that brightness and then I'm going to say fill 255 mind it like the inverse color I'm gonna say text number format the yvalues index with just two decimal places and I'm gonna put that at boy this is awkward I the exercise this is gonna be high x resolution plus resolution / I'm gonna say textaligncenter textaligncenter comma Center and then I'm gonna put the I'm just going to draw in the center of the rectangle and this should be J the text so let's see let's do this now so we can see you look there's lots of numbers there I think my number format thing didn't work 1 comma 2 and let's use a lower resolution just so I can see it better there we go now interestingly I can't see the numbers but there they go right you can see this is what it's getting the output for each one of these and I want to look at the law so you can see because it's just going so slow it's getting over time it's getting a little better but I really want to see a train much faster so let me see I have one idea one last thing I can add to this even though I and I have some suggestions for what I might do next but you can see all the numbers are starting to appear lovely I was because I forgot when it's gray when it's at point 5 2 or 55 minus 0.5 it's gonna be the same card I kind of like that effect so so what I want to do is what happens here if I actually give it tell it don't just do it once like do it 10 times do 10 a pox per cycle of fitting let me run this again and let me look at the let's actually have the loss continue to print out and there we go still running pretty fast you can see the losses going down and relatively quickly I am getting myself to the point where I'm starting to see you know this is definitely all the way got getting all the way down to zero there this is getting way up to 1 there it's getting a little bit stuck it's having trouble with this size side I imagine it'll get there eventually we could do some fun stuff for example I'm going to just let it have it's totally unnecessary but I'm gonna give it 4 hidden nodes and I'm also going to put the resin the resolution back to 25 and let's run this again and let's see how this goes so I'll give it a minute I'll come back oh the font is too big but you can see it's learning pretty quickly right now hold on well let me let me let me go back do that again so I'm gonna give it for no real reason all but just for fun four hidden nodes and I'm also gonna let me change the resolution to twenty five let me make the text size something like eight point and let me oops refresh it yeah one alright I let this run for a bit and you can kind of see here now you can see all the X or values here's a nice beautiful little map grayscale map of all X sorts getting all the way up to true and all the way down to zero at the corners this is pretty good so this is running at if I take out this console.log I can now take a look at the frame rate it's running kind of slow so here's the thing I have done something that I don't like which is and which is this train model is being called inside draw and I really shouldn't be doing that all right because I don't want I'm you know I don't want to call train model over I can call train model only thing about what I'm saying here yeah I how did I finish this up I have to go in just like a minute I'm saying of what I want to finish up here so I don't think I have time to do the TF frame thing but should I do would it make sense for me to at least do something like set time out train model let's just say hey do that and then like what if I did this function train set timeout train model I want to do like a then but well or what if I just did this like something like this right this is what I'm thinking and then this wood right does this make sense so I gonna explain this in a second like this will basically be happening elsewhere but I think I need the set timeout to like yeah this is never gonna release anything oh this is like superfluous because it's just returning a promise yeah I'll do that like what if I did this this is weird though kill this completely killed the browser yeah it's not really that much faster but this this is kind of like what I want to do right yeah now I can get a much faster frame rate and I could actually give it more epochs right yeah the training is happening more slowly but the framerate is happening faster perhaps result in a video about workers what tidy does nothing look look at this crazy way that it learned where's a tidy that does nothing me I am semi right is this an improvement over what I had before you know I I need this TF tidy what because this has to get tidied all right this is what's doing right now if I take that out oh you're right oh I don't I don't need a TF tidy for model that fit okay okay is this an improvement like to have pulled this out at least pulled this out of draw and a wit model that fit is tidied internally okay oh and tidy doesn't work with promises got it got it got it got it got it got it all right is this an improvement or should I just stay where I was and let it be like leave it and draw and talk about how that probably should do TF frame instead webworkers yaddayaddayadda answer fast I gotta go a sink while loop is a definitely good suggestion technically this is a much better way to do it all right thank you that's all I needed to know okay okay so I'm gonna go back to all right so the chat has given me some really helpful tips I've made quite a few little like weird little errors and mistakes here and I want to just fix this up a bit I think it's good actually to be easier to look at and watch if I just go back to a lower resolution so let's make this 40 and let me refresh this okay so here we go so this is now working training itself for X or you can see it's kind of moving along here now what what the real thing that's problem problematic here is the draw loop is happening over and over again and then I'm triggering something asynchronous in draw and I could be asking to train the model before it's even done with the previous training cycle so this really should not be happening in draw now tensorflow digest has a function called TF next frame I want you to explore it and make a version of this with Tia next frame as I can exercise after this video is over but I'm gonna do it a different way without that cuz I gotta come back then in a different video but first of all this I also learned this is totally unnecessary the via wait so a couple things number one is because there's just one thing happening in here I could just return the promise this doesn't actually have to be an async function and then I do not need the TF tidy because monal dot fit kind of will clean itself up automatically for you so this this should still work just fine and I should be able to see the number of tensors is still 15 so that was something that I didn't need that I've now fixed now what I really want to do is I want to get this out of draw so let's comment this out here and what I'm actually going to do is I'm going to write a separate function called train and in that function I'm going to say set time okay wait wait I'm gonna call train model wait hold on I'm gonna call trade model yes yes in that function I'm going to do this so I'm a separate function that does this piece of it that console logs the history and I could use and what I want to do is I want to say set timeout call the train function in 100 milliseconds so I want to just let the program start 200 full effects late later call this train function train the model which does the fitting when that's done log the history and now say set timeout train 100 so I'm good this is sort of like workers like like don't you set interval here because I only want to call train again once it's finished with training the model itself so this is kind of like hey train and and by the way I could just increase the number of epochs or maybe do some kind of loop but I think this would be a sort of nice way to demonstrate it and if I just called train directly without a set timeout I'm never going to be giving back control for a second I couldn't end up with sort of like blocking so I might even be able to get this down to like 10 milliseconds just something really really low so let's run this and sort of see same result we can see there we go things are working but at least now I have gotten that out of draw so draw is happening on its own and in fact what I could really do is I could say hey try doing this with like a hundred epochs each time epochs what is it and you can see the lost function is coming out much more slowly but whoops but the frame rate let me just clear this for a second yeah the frame rate is quite fast hold on this is too confusing I probably need to give give it back more time let's do like another little break let me let me I just want to like take out the console.log thing so I can look at the frame rate I should just put the frame rate in the Dom would that be smart but you can see now I'm getting 60 frames 30 frames of getting like a really pretty high frame rate even though the training is happening it's almost it's kind of like there is no threading in JavaScript so these things are just like passing off and really this might be a place where like web workers or something could do the training behind the scenes in some fancy way which maybe I will get to at some point oh my goodness so Alka is suggesting it might be better to use the draw loop and a boolean to know when it's safe to call it again that would also be a good idea so you can see though you can see what kind of like employing my hair out what kind of sort of like hassle situation we've gotten in but really let's just put this back to like two epochs let's put this to like a little 10 milliseconds and we can sort of feel like there we go and I can look at the frame rate it's running nice 30 frames per second and even though and it's at some point it's going to get there what's that loss I forgot to console.log loss come back to me come on oh but let's see I have an idea what if just before I go just before I go what if we try using a different optimizer what if we try using for example a different loss function hold on this video was already 18 hours long what if oh no no no a different optimizer sorry what if I tried using the the atom optimizer so let's just try that just for fun times let's give it a lower learning rate that was pretty exciting let's go let's go let's uh let's make the resolution back to like 20 let me make the font size like nice and tiny for us we give myself some more space here hit refresh and then let's look at this look at it learning there wow look at that that is beautiful look at it learning XOR so nice and fast I'm just gonna hit refresh again so we could say we really should look at what this atom optimizer is and I will link to a paper and some more information about the some of the what the atom optimizer is you can find out actually we should just go yeah I'm sorry like hold on we should really I should really talk at some point about what some of these other optimizer functions are for now what I would suggest that you do is if I again if I go back to the API reference and I go all the way down and I find let me just look this way the OP if I go here and I go training out Adam we can see here this is what you're gonna want to click on this is the paper that describes the Adam algorithm of its a different but but it's optimizing the lost function in a slightly different way than stochastic gradient descent does you know we could also try starting to like we you know we could we could just never stop and I could start like I think using the rail ooh activation function instead whoops is that not what it's called where are the activation functions oh it's it's there's no it's just all lowercase so there's so many things you can play around with with these things how was a failure I think because I have the all right let's I'm not gonna add I'm gonna go back back to where I was explaining the atom optimizer oh it made this such a mess to edit and I really have to go I really should explain what these optimizers are but if I go back and look under here we can see what some of these are Adam the a da coming from the word adaptive and you could always click here and look at this paper which describes this particular method for optimization which is a little bit different than stochastic gradient descent and apparently things work a lot faster with this XOR problem so as I go forward into more of these videos hopefully we can dig into what some of these different optimizers do and kind of understand why I might pick one over the other in certain situations all right but I'm just going to just leave this B I'm going to hit refresh I'm going to watch it learn and train train train train XOR oh I don't know some things you could do investigate TF dot frame give me a little slider try different architectures different optimizers try some different activation functions I don't know if you actually made it all the way to the end of this video I don't know ashtag something I should Eric is telling me to watch one of those videos reviewing the JavaScript event loop which I definitely need to do so I need I'm gonna be back with more someday well good bye good bye good bye thank you momentum is add a knock for adaptive did I just make that up adaptive estimates so maybe the M is for estimates moments loworder moments and is for moments yeah all right everybody well you know today was one of those days I should really be doing my old style coding challenges again readout of the random numbers book okay okay I really I'm running late I gotta go everyone lie down go to sleep we're gonna let's let's artificially make this happen much slower let's train let's go caddy thirty two thousand nine hundred eighty five twenty six thousand eight hundred and fourteen fifty one thousand eight hundred thirty three fifty seven thousand three hundred and sixty three four thousand and sixty seven eighty four thousand six hundred forty eight eightyfive thousand five hundred five forty one thousand four hundred sixtyfive seventy one thousand seven hundred sixty nine ninety nine thousand five hundred fifty fifty five thousand nine hundred four will there be a second live stream today no unfortunately why life's do on the weekend no unfortunately so apologies I wish I could live stream more often all the time make more stuff yeah blah blah the next live stream will likely be next Wednesday and next Thursday and I'm gonna be working on a lot more of this stuff inbetween hopefully we will the things that I really need to look at or I need to look at that event loop article that I just to get a better sense of how to use this stuff together with the requestanimationframe better and TF dot frame alright so any last if I my real time that I had to leave was three o'clock I got two minutes to answer questions let's try like I like doing it with like a high learning rate you can see like it gets too good sort of see it bouncing maybe this learning rate is too high it's kind of get stuck it kind of can't get there and then if we could do we could do weird stuff like like what if I gave the hidden layer 16 units for like no reason like look how it is there's no correct answer there's only training data at the corners that learn to rainbow people for asking me questions and I are you going to do this convolutional 2t soon that's why I I hope to plan to yes all right everybody so this is my list Oh Thank You Joshua Myers that's very kind of you if I had my Philip's light bulb it would have flashed by the way oh let me just mention if any of you are if any of you are sponsors you can now sponsor the channel through the through the YouTube interface itself make sure you go and check the community tab and look for a post that links to a Google Form to enter your email so I can send you an invitation to the slack group I need a better system for doing that I have a thing set up that it actually like I have a I get alerts in a spreadsheet and I can look but I don't get your email address so there's no automatic way to invite you to slack other than by doing it manually yeah so this is where I'm this is where I am going to next I am going to do a I want to do the TF playground idea and the classification idea so if anybody has any ideas for really simple goofy just like basic numeric data sets probably going to do something where I'm going to look for some color data set which takes any RGB set of RGB numbers and like categorizes it it's like a few with a few different like labels that's one so if you have some suggestions for that please let me know at Schiffman on twitter is probably the best way all right everyone I don't know I had more layers sorry everybody I hope today I hope you enjoyed today somehow uh somehow I I just I don't know maybe I shouldn't be covered next week let me through really maybe I'll try to at least do a coding challenge that's not machine learning related I want to get thrown mean learning content but it is kind of overwhelming and taking over everything weather prediction but I need I want to do classification so I don't want to do time series great all these these things will come but I want to do a really basic classification I don't use images I don't want to use text data that's like I don't use time series sequential data I just want like you know like it's like house prediction the iris data say these are the kind of thing house price prediction wellthat's prediction that's not classification even but regression but something like that but I want it to feel goofy creative in the art world space that kind of thing alright tictactoe game okay goodbye everybody I'm gonna hit stop streaming I guess I will play you out with my weird trailer since that's what I do now while the trailer is playing I will attempt to explain why doesn't it dispose of tensors automatically s asks ray Jackson asks Arnab I don't actually know why it doesn't dispose of tensors automatically but it's this is the thing that there is no way to clean up the memory memory on the GPU with a garbage collector in the same way and this is like a lowerlevel question that I would be curious we have to investigate more about how tend to flow J s works you you