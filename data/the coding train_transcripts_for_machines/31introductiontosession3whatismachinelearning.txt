(bell dings) Hello, welcome to session three of The Nature of Code Intelligence and Learning. So this is one of my opening videos for these sessions. If you are watching this video as part of that playlist for the Intelligence and Learning course, you will see a lot of videos in front of you with a variety of demonstrations and different coding challenges. There will also be a video at the end, where I come back and pose some ideas for an exercise or assignment that you could try. But what I want to do in this particular video is Now, now is the time this course has just started with this little warmup of thinking about artificial intelligence, and search algorithms, and graph systems, and then we took this turn and thought about genetic algorithms and evolutionary systems, but you might be here because you heard about this term, machine learning, maybe even heard about this term deep learning, and you want to get a sense of what does that mean, what are the possibilities with machine learning and deep learning, how do machine learning systems work, what are they for, what's the lingo for this sort of stuff, and now's the time to get into that. Now, session three here, I will not be using any neural network yet. So what I want to do in session three is just talk about what machine learning is, what its applications are. So something that I'm gonna cover here is classification and regression, what do those terms mean, and what are some classic algorithms for performing classification and regression. And so, I'm going to look at something called nearest neighbor similarity, K nearest neighbor. And I'm also going to look at something called linear regression. And so these will be some sort of classic algorithms that you can play around with and actually do stuff with. And then in session four, we'll start looking at what a neural network is and see how we can use that as part of a machine learning system. Okay, are you with me? By the way, I barely know how to do this stuff, so if you're watching this for an expert, you probably wanna find somebody else on YouTube, but I'm learning this stuff, trying it out, and hopefully you're gonna come along and join me on the train, right? Oh, I forgot! We're on a train. (train whistle blows) On this ride on the train in the sky with me as your guide. Do sky and guide rhyme? I think they do. You'll see. I had a point to this, but I digress. Okay, so what is machine learning? So first of all, one thing that I might suggest for you if you wanna watch some videos about somebody who really knows what they're talking about, I would suggest Andrew Ng's Coursera course. A lot of my knowledge and inspiration has come from that course, and Andrew Ng does a good job of giving a nice introduction to machine learning. And two particular references one is this definition, this quote from Arthur Samuels, who is a pioneer in the world of machine learning, defining machine learning as a field of study that gives computers the ability to learn without being explicitly programmed. And so here's an interesting thing we can think about. When we looked at the A* algorithm in session one for pathfinding, we were designing, us the programmer, writing an algorithm to specifically perform a task. The computer would follow those instructions and get to a result. There was an intelligence to that algorithm, there was the disappearance of sort of the computer solving a problem in thinking about it, but ultimately, we had written the instructions, the code for the computer to solve, to arrive at an answer. So what if, instead of us writing the instructions, we would just set up a framework for the computer to figure out what the instructions might be, what are the right parameters for some type of model to perform some sort of task? So this is the idea of machine learning. And I would encourage you to look at the work of Arthur Samuels. One of the things that he did was train a computer to learn to play checkers by just having it play itself over and over and over again, thousands of times, to be able to learn what a good strategy was. But ultimately So one of the things that I want to talk about here is So let me come over the whiteboard here. I have this README that I'll link to in the description. You can read some of the definitions and information that's on that README. But what I want to look at is this model for, this I'm gonna describe to you machine learning in this particular way. So there is some sort of input. That input is going to go into some sort of algorithm, some recipe. I think that's a nice way of thinking about it. Some machine learning recipe. And then out of that machine learning recipe, we are going to get an output. The input into the machine learning recipe is typically numeric. So you could think of it as, you know, a classic example that's always given is what if we want to build a machine learning system that can guess the price of a house based on some inputs. so maybe we might say something like, "Oh, the house has three bedrooms, "and it has two bathrooms, "and it has 1,000 square feet." And etc., etc. This is the input into the machine learning recipe, and the output might come, "The house is $1 million." Something like that. Nice house, apparently. Okay, so this is what machine So typically speaking, another way of thinking about machine learning is making sense of data. So I have some sort of data and I want to make sense of it. I have some input and some output. So two kinds of output that you'll see in most machine learning algorithms are classification. Another kind of output is regression. So what you might not have realized here is this example that I gave to you, where the parameters of a house, a data point, goes into the machine learning recipe and we get this price output, this is actually regression. Regression refers to predicting some sort of continuous numeric output, whereas classification refers to taking an input and classifying it into a discrete set of labels. So here might be another scenario. I have an image of a cat. That is the input into the machine learning recipe. And the output is something like this. Well... I'm getting the usually the output comes numeric, so we have to sort of figure out what this could mean, but I'm speaking in kind of higher level terms here, so I'm just gonna say the output is cat. I am labeling it and maybe the only possible options are cat versus dog, so what that output actually is is something like 0.9, 0.1. Like there's a 90% chance this is a cat, 10% chance it's a dog. So this is classification, attempting to assign a discrete label to something like an image. We could've done something with the house data using the classification. We could say, you know, fancy house, summer house, winter house. You know, we could classify into one of two categories. That's classification. Regression, getting a continuous numeric output. So how does this work? So number one is we've got to, at some point, start talking about what are some different recipes that could go in here. And I could name you a few. For example, K nearest neighbor. This is a particular algorithm that can work for both classification and regression. I could say something like support vector machine, or I could say artificial neural network. And then there are a variety of flavors, so to speak, of styles and of artificial neural networks, convolutional neural network, recurrent neural network. So this is something I ultimately intend to spend a lot of time on. What is an artificial neural network? How does it work? And why is it effective to put it in here? But even with all of the amazing innovation that's happening in machine learning and deep learning right now, there's a lot that you can do without artificial neural networks. A lot of simple, fun exercises and things. So in this particular session, session three, I'm gonna look at the other algorithms that are nonartificial neural network nonneural network based that become the machine learning recipe, like K nearest neighbor. But let's take a moment here to talk about how overall this works, because the thing is this doesn't just happen magically. You can't just The point of doing this is that at some day, we might want to put an unknown image in here and get a classification label for that image. But how could a machine learning recipe do that from nothing? And it can't. So one of the things I wanna talk about here is how does this work. So before you can actually use machine learning to make predictions for unknown data, you need to train the system. So the training step involves So there there are several different strategies for how a machine learning system can learn in order to perform operations like this. One is called supervised learning. And supervised learning is the strategy that I'm going to use in just about everything that I do in this particular course from session three right now and on. Although, I will come back to some other techniques as well. Another kind of learning is unsupervised learning. And another kind of learning that I really love, my favorite kind of learning, is reinforcement learning. In fact, I have a whole book all about reinforcement learning that I'm reading right now. Okay, so what are these different And, you know, there's something called semisupervised learning and there's little variations on this, but these are three core types of learning that can be applied to the machine learning process. Let's start with reinforcement learning for a second. Reinforcement learning is the kind of learning where an agent observes the environment and chooses an action. You can think of a mouse trying to get through a maze. The mouse looks around. There's a wall here. There's a wall here. There's a wall here. The mouse decides to go left, or the mouse decides to go right. And then once the mouse makes that decision, the mouse receives a reward. And that could be a positive or negative reward. And as the mouse receives more positive rewards for certain kinds of actions, it does more of those actions over the long term and gets better and better at things. So that's reinforcement learning. I'm gonna spend a whole session looking at this at some point, and we're gonna see some techniques. I have an example that uses a kind of reinforcementstyle learning to train tp autonomously play the game Flappy Bird. Okay, unsupervised learning is a kind of learning that's generally applied to data that you know nothing about. So I have 100,000 songs, and I just want to kind of learn what patterns are there in the song. So typically, unsupervised learning is applied to problems like clustering. So I have all this data and I want to figure out how can this data be arranged in groups? Could I have a And I don't know anything about it. Could an algorithm figure out, based on patterns in the data, how to group that data, how to cluster that data? So I don't know that this is something that I'm gonna spend any time It's not on my current trajectory/syllabus, but it is something that I would like to do at some point in the future. I actually have some ideas for some stuff I want to do about that eventually. Okay, but here we're gonna give a nice little star, and a heart, and a little smiley face, and a little rainbow for supervised learning, because this is what I'm going to use in most of most of my examples over the next several videos. The idea of supervised learning is I have training data. Training data. So number one, I have training data. Number two, I have test data. And number three, I have the rest of the world, a universe of data. So maybe we could call this unknown. Un un ah! I can't spell. Unknown data. So how does this work? So first, what we do in supervised learning is we take this training data. We have a huge database of a spreadsheet of bedrooms, bathrooms, and square footage for houses with their actual price that they sold at. So we have a data set that has the parameters and some sort of target, often called a target. So this would be like the training data with the inputs and a target. The idea is the inputs go into the machine learning recipe, they come out the other side, and some sort of guess is made. Maybe the house actually sold for $1.5 million, but the guest was $1 million. Ah, so the machine learning recipe got it wrong. So we turn some knobs here, and mess around with it to try to get it to have a better result that's towards what that error So we're gonna talk a lot about this error and that sort of thing. We're gonna come back to this many, many times. So we do this over and over again with lots and lots of training data, turning all the knobs, trying to get it to do a good job. Then what we do is we have test data. Now, test data is just like the training data. It's data that has inputs with a known result, a known result that we should get. But we didn't actually use it while training, because we have this issue a machine learning recipe might perform really, really well with the training data, but not with actual other data. So to see how well it's working, we've actually got to give it data that we didn't use to train, and that's called the test data. So we would feed that, see how well it does, evaluate, and evaluate the performance, and say like, "Ah, you know what? "It got all the test data right." It's ready. It's all grown up. Our machine learning recipe is ready to go, and we send it out into the world to start interacting with unknown data. So this is really the process. This is supervised learning. It's saying, "Hey, I'm the teacher." This is the machine learning system. I'm going to teach the system with my known data, with known output. I'm gonna test the data with separate known inputs and known outputs, and then it's gonna be all grown up. It's gonna graduate. I'm gonna send it out into the world, and yadda, yadda, yadda. You know, more By the way, I plan on doing a lot of yadda, yadda, yadding neural network stuff. We might get to like, "And then you have to "do this calculus thing, yadda, yadda, yadda." (laughs) So I think that's a good practice to yadda, yadda, yadda machine learning as much as possible. Okay, so that's a brief introduction to what machine learning is overall, and what some of the sort of key aspects of how a machine learning system works. But we're going to get into a lot more about the details here, and we're gonna look at a variety of different kinds of recipes that can be put in here, and how they work with different kinds of data, like which recipe do you want to work with images, which recipe would you want for working with text, for this kind of classification, for this kind of regression. But right now I'm going to move on and start looking at nearest neighbor. What is this thing called nearest neighbor? How can I look at two different pieces of data? So let me So I have a bunch of premade examples in some of the If you follow along with the playlist, you're going to see a bunch of examples where I code stuff from scratch. But I won't be able to do I'm not gonna do a video for every single one of these examples. I mean, maybe I will someday. But the first thing I'm really gonna start looking at is and this is an example inspired by this is an example inspired by Rebecca Fiebrink, who has a wonderful course called, I think, Machine Learning for Musicians and Artists from the company Kadenze I'll put a link to that in this video's description where she uses a tool that she built called Wekinator to do classification and regression and a variety of other things. So she does a lot of stuff with gestural interfaces and musical output. So one of the things I wanna look at And I'm gonna hit play here. And what you're gonna see is as I move the mouse near a particular note, the note changes. C, D, E, F. And this is actually a classification This is an example of classification. What I'm doing is I have twodimensional data, a Cartesian coordinate system, and I wanna classify every XY point to a particular note. This is classification. So the nearest note is the note that I play. I can actually switch this example to perform regression, and this is an example now of regression. You can hear I make a prediction based on a weighted distance. So here, I essentially have an average of C and G. I'm hearing a little G. I'm at a frequency between G and C. You can hear G, C, G, C. So this is these are the kind of examples that I wanna build to get you started with understanding the algorithms and I have some ideas for some creative possibilities that you can do. And then we're gonna just keep going. So okay, so stay tuned. There'll be a bunch of videos in this playlist where I go through a few different examples and scenarios. I'll come back with another video with some homework ideas, and hopefully you'll make some stuff and share it with me, and live your life in this world/universe/place, and maybe give somebody a hug or say something nice to somebody, 'cause those are good things to do, too. Okay, see you in a future video. (bell dings) (upbeat music)