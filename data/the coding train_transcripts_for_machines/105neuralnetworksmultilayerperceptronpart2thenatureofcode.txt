welcome back I'm going to actually write some code in this video um not that much so what I'm doing now welcome I made a few introductory videos covered some background uh about uh neural networks and why they exist and where I'm trying to go with this and in this video I'm going to actually begin to write the code for a simple JavaScript neural network library now I've actually already done this it exists here at this repository uh GitHub sh man/ neuralnetwork P5 I'm designing this library to be used with a set of p5js examples with a uh Library a JavaScript library called P5 although ultimately this Library stands alone on itself by itself you don't have to use it with just P5 so before I can write the code let me come over here to the Whiteboard and this is where I last left off talking about how the general structure of a neural network library Works uh of a neur Network system works and so what I need to do here is when in the code I create a neural network I want to create three things I want to create an input layer I want to create a hidden layer and I want to create an output layer so when I create a new the way I want to design this libraries I want to say new neural network and I want to give it can you see this I think you can I want to give it three arguments the number of input neurons let's just use the word neurons the number of hidden neurons and the number of output neurons so I'm doing something which I typically don't do which is usually like to have a specific problem that I'm trying to solve and like write the code for that problem and in here the problem that I want to solve is I want to make a generic kind of useful library that could be used in a bunch of different contexts so I don't know what those numbers are going to be uh I don't know what the data is I'm just kind of working on the skeleton the structure of the library before I start to apply it to things so let's just make up some numbers let's say there's going to be three input neur neur four hidden neurons and two output neurons what this means now is in a feed forward neural network there are three inputs we could imagine again I'm using the kind of classic example of guessing the price of a house this could be number of bedrooms number of bathrooms square footage so those are like three parameters of a house these will connect to one 2 3 four hidden neurons so this is the input layer this is the hidden layer and then I'm kind of running out of space here there will be two outputs and then this is the output layer so this is the configuration the idea of a up and so what I'm building here is what's known as this is a multilayered perceptron these are individual perceptron units essentially that are have multiple layers and it also is an another important term that I want to add here is I want to create a fully connected Network and now there are variations to this that we might see in future examples but the idea of a fully connected network is that every input is connected to every hidden every hidden is connected to every output but I so I can draw those connections and it's not so many that I you know if I were doing some kind of post production I would speed this up but I'm going to just draw this web of all these connections so every input is connected to every hidden and every hidden is connected to every output whoa oops ah ah I messed this up but I'll get it eventually there we go right so you can see that every every node is connected to every node in the next layer so the idea is that those three inputs come in the data feeds forward and those two outputs come out so this is the structure now we have to get into a lot of details here well how do I keep track of all of these connections how do I actually do the loops to like do all the sums of everything and how do I read the outputs I'm going to get to all that but this is the overall structure so let's go back to the code and now let's actually try to like write a little bit of this Library very very little so where am I going here okay so this is my code there's nothing yet I'm going to create a new file and I'm going to call this nn. JS so this is now going to be my so here's the thing ultimately I want this to be like a proper JavaScript library but ultimately what is a JavaScript library but a file with some JavaScript in it so I might later as this gets more sophisticated optimize it and use some sort of like build process or break it up into multiple files but right now I just want to kind of like get the pieces going so I am going to I'm also going to use es5 syntax this is the trajectory that I've been on soon in future videos I'm going to start adopting some es6 syntax But ultimately maybe this Library I'll do a followup and come back and kind of I'm going to do a lot of things maybe not in the most optimal or efficient way but hopefully in the most easy to understand and follow way so I want to create a Constructor function called neural network okay and I should also mention again while we're here that I built this Library already and when I built it I based just about everything out of this book called make your own neural network by trq rashed and so while I'm doing this now kind of a bit more on the Fly I'm sure everything that's in my brain ultimately came from here and probably some other sources too okay so what do I want to do the core thing that I want to do is I want to create the N neural network with a certain number of input nodes number Hidden number of output so I'm going to add those as arguments here I'm going to say um number of input number of hidden number of output I'm going to create a neural network with three arguments and then I'm going to say uh input nodes I think I'm going to be longwinded about this equals number of input and so I'm going to create three uh hidden nodes is this argument and uh output nodes is this argument is that an O yes it is okay so this is we've actually written some code the idea being that what I want to do is say things like VAR brain and brain is a new new neural network that has three inputs with three hidden and one output right this is the idea so I need to figure out what shape and shap using the word shape very specifically does the data come in that's how many input nodes I want what shape is the output that I want am I looking for a single output am I trying to look for a range of outputs that's how many outputs I want then how many hidden neur so I want well that's kind of an open question well maybe I want as many as I could possibly fit in well the program running reasonably fast but it sort of depends on the complexity of the problem and we'll come back to that later and I should also note that I this is a simp oversimplification of how neural network architectures can be this is by definition a thre layer Network and this library is only going to allow for a three layer Network an input a single hidden and a sing and an output but as something might think about for the future how would you write the code to have multiple hidden layers because a lot of neural networkbased Learning Systems need multiple hidden layers to be able to perform optimally but for now I'm going to keep things very simple okay what is the next step written very we did write some code thankfully wrote some code now we got to stop again the next step is the feed forward process the way that the feed forward process works is that we receive these inputs oh there's so much to do so many pieces to this puzzle I'm excited to get through it all though so let's just say for example we're looking at this hidden neuron do you remember from the perceptron videos maybe you didn't watch those so let's talk about it the idea is that we need to do something called a weighted sum so let's pretend this is the house prediction thing and this was the number of bedrooms three this is the number of bathrooms you know this is the number the square feet so each one of these connections right the data is going to flow in the data comes in here the number three comes in here and then look at this there's four outgoing connections each one of those connections has a weight to it now ultimately the whole point of doing this learning neural network based Learning System is we want to tweak those weights we want to train the brain train the neural network to have optimal weights to get good results results that makes sense and that training process is something that I'm going to get to I don't know how many videos down the road from now but not too far away these weights will H typically to start one way of thinking about them is they're going to just have random values between 1 and one and there's a wide variety of techniques and strategies for initializing random weights or not just random to a neural network but for right now a good way for us to get started they all have random weights so even though I'm looking at each one of these flowing out a slightly better way for me to look at this with you is actually just look at all the connections flowing in so this particular hidden neuron has three connections flowing in a three and the input values are three 2 and 1,00 each one of those has a weight so let's pretend this is like 0.5 U let's say this is like uh .5 and this particular weight is one so I'm making using very very simple numbers the idea is that each hidden neuron does something called a weighted sum so it takes the input multiplied by the weight and adds that to the other input multiplied by the weight and adds that to the other input multiplied by the weight so we could actually do this 3 * .5 is 1.5 plus 2 * .5 is 1 plus 1,00 * 1 is + 1,000 so this value now is a 100.5 now we can see there's a huge flaw here which is that the fact that square footage is kind of a big number and number of bedrooms and number of bathrooms are small numbers means this kind of way of summing it is going to produce some like odd results this the square footage is going to be weighted so heavily just by the fact that it's bigger numbers so a lot of time in working with a machine learning or neural network based system we need to do some type of cleaning or normalizing of the data and we might do something where we you know we sample this down so they you know we actually do the number of bedrooms between 0 and five as a value between 0 and one and number of bathroom is always a value between 0 1 and square footage this would actually turn into 0.1 like because the range is between 0 and 10,000 square feet or something so we would do some kind of normalization of these values but this is again further down the road when we start to apply the library in an actual project once this weighted sum is complete the result of that weighted sum gets sent out through the outgoing connections but it gets passed through an activation function so I'm going to come back to the activation function this is something we did with the perceptron and that's going to be a separate video where we look at different activation functions and how they work right now I want to focus on this weighted sum so I could keep going here I could create some type of array of I could create an object that's like each one of these nodes or neurons is an object then I could iterate over I could have connection objects so there's a bunch of different approaches I could take but the classic and standard approach is actually to look at storing all of these weighted Connections in something called a matrix which is really just like a spreadsheet a grid of numbers looking at the inputs as an array and doing some type of math that basically takes take that array of inputs multiply it by that Matrix of weights and generate the outputs of this hidden layer so this is so give me a second here I'm going to erase I'm G to I'm GNA I'm going to make the case for this with a simpler scenario so let's look at this diagram which just has fewer connections it's going to be easier for us to unpack so we can think of these inputs as x0 and X1 let's not even worry about the output right now these are the inputs this is the hidden l layer right hidden layer so let's think about this and and actually let me change these numbers to X1 and X2 you know sometimes I like to count from zero sometimes I like to count from one I don't know why but I I I feel like in this case let's let's call it one and two so this is really like hidden one hidden two so each one of these connections right each one of these weights you could say here this is a weight that goes from one to one this is a weight that goes from one to two this is a weight that goes from 2 to one and this is a weight right here that goes from two to two so notice how there are two inputs two hidden neurons four weights in other words the weights and I'm going to draw I'm going to kind of use start to use Matrix notation a little bit the weights can be expressed like this 1 1 1 2 2 1 2 two okay so this is a way of expressing the weights and a way of expressing the inputs I could write it like this X1 X2 okay so I'm making the case that I have two inputs and I have four weights and I could write it out like a matrix of numbers a 2X two Matrix and this is essentially a 2X one Matrix whenever I'm going to get more into matrices in the next video or am I in that video already I don't even remember I don't know where I am in my world but uh typically when we talk about a matrix a grid of numbers we reference it rows by columns 2 by two 2 by one okay so let me just show you something remember this we need a weighted sum here this weighted sum is X1 times weight 1 one plus X2 times weight 2 one okay that's the weighted sum for this neuron or node the weighted sum for this neuron or node is X1 times the weight from 1 to 2 and X2 times the weight of 2 to 2 plus X2 * the weight of 2 two it so happens I could take these two results I could call this like uh H1 and call this H2 and I could say let me actually say I could I could basically say this times this equals H1 H2 so this is the actual math the way that we described it look at both inputs coming in multiplied by their weights and summed look at both inputs coming in multipli by their weights and summed these are the the it written out but it so just happens that this exact math writing it like this and producing this outcome is exactly the math that is part of a field of study called linear algebra linear algebra involves manipulating vectors and matrices a vector being being a onedimensional list of values a matrix being a twodimensional list of values the inputs are always onedimensional the outputs are always onedimensional the weights are always can always be expressed as twood dimensionals it's every input connected to every hidden you can think of it very much like pixels every row and every column so this is where I need to stop and what I want to do is do a few videos that cover this notation and math with a bit more detail writing a little JavaScript simple JavaScript Matrix library and ultimately once we done that we can come back here and see how if we have that Library written we can then use it to do the math between the inputs and the hidden and the hidd to the output and ultimately later we're also going to go backwards through the network to tweak values and and train it and that's we're also going to use the same Matrix math so this is why we need or why we don't need because we could kind of do it without it but why it's useful to work with this idea of linear algebra and I should note once again that if we were doing this in something like python using a library like something called nump we would get all of this stuff for free and there are JavaScript Matrix libraries and like but I'm going to kind of unpack some of this and and write a lot of the code from scratch just to have a sense of how it's working so hopefully as you were watching the video you saw a little annotation um this is actually incorrect I mean everything about this math is correct this matches this right the weighted sum is X1 * weight one from 1 to one X2 * weight from 2 to one but actually the notation that I the way I wrote this Matrix as we go as I go into the next video where I actually look at how the Matrix math works this really should be written as one two and this should really be written as 21 the reason why that is is is this should be X1 * w11 + X2 * w21 which is written right here so that Matrix math that I'm going to go in more detail in the next video we take this row and multiply it by this column and this row and multiply it by this column and you can see that's what these two things are okay so thanks for bearing with me I there's a lot of little pieces but I am going to get back into the code so in the next video I'm not very confident about the order I'm doing on this in but it's just the way that I'm going to choose to build it and so the ne again I'm saying this again the next video I'm going to look at the Matrix math again and then write a generic library that does that math and then come back and put it back into the neural network itself okay so see you in the next video thanks