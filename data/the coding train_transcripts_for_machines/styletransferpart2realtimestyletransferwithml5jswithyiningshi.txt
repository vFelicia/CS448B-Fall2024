(bell dinging) Alright, we are here in the third Spell video thank you to Spell for sponsoring, sign up at spell.run/codingtrain. Okay so if you watched the first video, where I explain how to set up Spell then you watch the second video which you trained your own style transfer model using transfer flow and Python running it in the cloud on spell.run, now you're ready for that last step. Downloading your trained model from Spell, bringing in to the browser, using the ml5.js open source library, P5.JS open source library, ML5 by the way is build on top of TensorFlow.js. Got to mention all these libraries. All theses libraries come together and you can then take realtime images from your web cam and style it with your style transfer model. So follow this tutorial. If you get this working please please please share it with me. #ThisDotStyle on twitter or share it in the comments here or anywhere you can find to share it. I would know and see what you all make. Okay, enjoy this video from Yining again. So far we set up the environment, we download the dataset, we trained the model with the style Python script, we copied our trained model back to our local computer and then last step is to convert the model to a format that we can use in TensorFlow.js and ml5.js. Okay let's do this. Oh, by the way this is the folder... This is the trained model that we got on the desktop. Okay so... If I go back to my old directory which is livestream here, We're going to use the scripts that is from faststyletransferdeeplearn.js Deeplearn.js is the formal name for TensorFlow.js This is... This ripple is built by Reiichiro Nakano. His work is amazing, he recently contribute a new model called sketch.rn to ml5.js, too. You guys should definitely check out his work. But we're going to use his script to convert the TensorFlow model into a model that we can use in ml5.js. So, the way that we are going to do it is to clone his GitHub ripple. And then we're going inside to this GitHub ripple. And we're going to put all those checkpoint files that we got into one of the folders inside of this GitHub ripple which is... So I'm just going to go to faststyletransferdeeplearn.js Now just copy this folder to the root directory of this GitHub ripple and I just did, it's here and then we can run or we're going to run two Python scripts. The first thing is to dump the checkpoints, to just to convert the format, so what we're going to do is copy, paste this command and to add this in the code I detailed first. Python script and dump this script and then the output directory is src/ckpts/our folder name which would be SpellModel and then the checkpoint file is in the grouped directory of the GitHub ripple. So it's /SpellModel/fns.ckpt. This is the path to our model, which we saw before in this checkpoint file. This is the path to our checkpoint. That's why we have this name here. Okay, so now I'm just going to run this script. And then you can see it's done. So, it's actually created one checkpoint file and 49 other files and we can go to, go there to see what is the output. The output lives in source, checkpoints, and this is our model. And you can see that we got the manifest.jxon. This tells us the structure of the graph. And also 49 files that tells us all those values of those variables in each layer and this is the format we can use in ml5.js and TensorFlow.js. Okay. So now I'm just going to copy this model back to my desktop. Okay. Going to rename it and drag it to my desktop. Okay, so far, we got two models. We have the TensorFlow saved model that can work in TensorFlow, of course. And then we got another model that can work in ml5.js and TensorFlow.js. So this is what we got today. And the next step is to run this model in ml5.js. Here are two demos on ml5's website and we also have this demo here. That you can slack to different styles. You can upload the image, you can change the style here and you can upload the image. I'm going to upload a photo, a photo of a cat. And then click this Transfer My Image. This is the transferred cat. You can also play with different styles too. Oh, I do like this one. And also you can use webcam and then click this button and you can see the transferred version of the... of the images from the webcam. So you can go there and check this demo out but next we're just going to run this model in our p5... In our ml5 demo. So, we can do this quickly. Here, we're just going to clone this GitHub ripple. And then go inside to that folder, styleTransfer_spell and we're going to open this folder in code your editor and in this model's folder there is already one model there. We're going to add our new models inside of this folder. So what I'm going to do is to find that GitHub ripple and inside of our models I'm going to copy, paste this model in. I'm just going to rename it to, "Lotus," because the name of the art is called Lotus. Okay, so now we go back to our code editor We have a new model here and we can take a look at what's inside of the index.html. So to run this... To build this demo, we need p5.js to mainly to get the video from the webcam and also we need p5.dom library to make it easier to create dom elements for us and then in the end we need the ml5 library. And then we have some styles here we can ignore here we can ignore them for now. And we're also running the sketch.js script here. And in the body we have header tag, we have P tag and we're linking the source of the image, the art style image and also we are showing the art image, but I'm going to change this to the lotus image. This is a pre trained model. I'm going to add this image into this image folder. Okay. So here where we can say images/lotus. So we're going to show that image and in the end we have a div container to contain our canvas and now we can go to... Let's save this index.html and then we're going to go to sketch.js. I'm just going to delete all the code here so we can do it ourselves one more time together. So to build this demo we need three things. We need a video that can get the images from our webcam. Right? So we have video, we also need the style transfer from ml5 library to allow us to transfer images. So I'm going to have another variable called style. And in the end, we need a variable to hold our output image so we're going to do let resultImg. Okay, so this is the three things that we need. And in p5 there is a setup function, that's where because once at the beginning. So in this setup function we're going to use p5.js to create a canvas. That is 320 wide and 250 as it's height and then we're going to use this p5 dom library to put this canvas element inside of a div element who's ID is canvasContainer, okay. So we created canvas, that's it and then we're going to create the video. So p5 has this function called createCapture and if we press the uppercase video in, it will try to get the video from your webcam. And we're also going to say video to hide, because we don't really need the original video, we need the transferred video. So we're also going to say video hide And we are also going to create the result image p5 dom library has this. I just want to make it a little bit better. We're going to create this result image equals to create Img, press your empty stream there And we are also going to hide this image. We're going to draw the image on the canvas so we don't really need this image. And in the end we're going to use ml5 to get the style transfer model, right? So, style equals to ml5. style Transfer, and we are going to paste in the path to the model. So it's model... Models not model, models/lotus. Okay and that way we can also tell this style transfer to look for inputs from our video. So we pass in the video and also we have a callback function saying oh if you finish loading this model let me know. So, this is a callback function called modelLoaded, we are going to define this function now. This is a callback function so we are going to do function modelLoaded. Once the model is loaded we can just ask the style transfer to transfer something, but at first I want to change the text on this P tagging to model loaded, just to let people know the model is good to go. So, I'm going to select an element. This is a function from p5 dom library to select a html element from the dom. The ID is status and I want to change it's html to Model Loaded. Okay. And then once the model is loaded I'm going to ask the style to transfer something. So I'm going to say style.transfer and I'm going to pass in another function called result. So this is a callback function, once the model got anything back this function will be called. So let's make up this function, function gotResult. It would get two things, one is if there's any error during this process it would put the error in this error variable and another thing is the output which is image. So in this, once we got the result we are going to give the result image an attribute to hold the image source. So we're going to say resultImg.attribute. We copy the source of this image .source to our result image. And after we got the result we want to call this style.transfer again, over and over again to see... To see more result so we are going to do style.transfer gotResult again. And one thing is missing because we did update the source for result image but this result image is hidden. So, we cannot see it but p5 has a function called draw. It will run over and over again. In the draw function we are going to draw this result image. So, I'm just going to say image, it's lowercase I, image result Img from origin zero, zero, and the size is 320 to 240. Okay that's it. This is the whole sketch.js. Next, finally we are going to run this code. We can do Pyton minus m SimpleHTTPServer. If you are using Pyton three you need to do Pyton minus m Simple.HTTP... Simple.HTTP? no, Simple.Server Anyway, it starts the server at local host 8,000. So now if we go to our local host 8,000. We should be able to see something. So model is loaded, this is the wrong style source. [Daniel] I just have to come in and try. (laughing) That is so cool (laughs). And as you can see this style has more colors so the result is a little bit better than the previous model and yes, this is the demo that we built today. So this is all the resources that I used. This is the... This is Gatys paper from 2015. This is Gene Kogan's, "What Neural Networks See." This is the Transferring Style Tutorial from Spell and also for ml5.js it has a style transfer tutorial made by Chris and I recommend you to check that out too. And this is the link to ml5.js and I also want to recommend this youtube channel because I learned a lot of motion learning papers from it. And I want to give credit to those two project creators, we used the TensorFlow implementation of the fast style transfer made by Logan Engstrom and we used the script to convert the TensorFlow swift model to a format that we can use in TensorFlow.js and ml5.js. It's made by Reiichiro Nakano. And to wrap up today we trained a style transfer model with Spell and we run this model with ml5 in the browser and you can check out the model here and that's it. (bell dinging) Alright, thank you so much Yining for being a wonderful guest on the Coding Train, for showing us how to train our own style transfer model, how to take that style transfer model and bring it into the browser, style our beautiful faces with the style of the image, with the image from the webcam, all that stuff. So, thank you to Yining. Thank you to Spell for sponsoring this. I'm really curious, really curious if people are able to follow this and I really want to know like what kind of creative, weird image combinations can you think of and try. So please make some train style transfer models, style all sorts of images and share those with me on twitter at #ThisDotStyle or right here in the comments as well, but I don't think you can post an image in the comments, but you can link to it I guess. So anyway thank you, see you in future videos. Goodbye. (upbeat music) (bell dinging)