hello all right this is a good moment for me I think I'm excited to see if I can get through this video because if I can implement this last piece of the Train function in the neural network library then I'll have a working version of some kind of neural network library like thing that I can start to finally apply to some projects and it's my goal actually that in some of the future videos I make that make use of the library and eventually other more sophisticated machine learning deep learning libraries like deep learning is a new library which i think is now gonna be called ml5 which i'll talk about in another video that I'll build really well I'm sad about it's to make stuff and show you how to make stuff but I'm kind of working through this because it's just something I have to do so I've started I have to finish I'm just trying to like vamp till you've stopped move on and watch something else because I'm not sure you should continue so but let's let me try to it's actually been a while since I recorded the previous video unfortunately might be watching them one after another let me try to like reset kind of where I think that we are so we have a something like a two layer network it has you know an input quote/unquote airboat layer it has these so these are the inputs this is the hidden and this is the output it is fully connected meaning every input is connected to every hidden and every output is connected to every every hidden is connected every input every output is connected every hidden and so the outputs come out here the inputs come out here all of these connections have a weight so and we can consider them in a weight matrix and I guess I should put this stuff back in here wait if this is like input one two three this is hidden one two this is weight one two one this is weight two to one this so these all end up in a nice weight matrix these end up in weight matrix the outputs come out oh boy in array like y1 y2 a vector the inputs come in in a vector x2 x3 okay don't get back into this I didn't even draw like off the top wonderful so now the idea is we want to do training and the kind of training that I'm doing right now is called supervised learning where I have some known output I've some known inputs with known outputs inputs with target outputs I send the inputs in I feed them forward I get some actual guests output back and I have some sort of error which we can think of as the error equals the guess I'm the guess the target so I'm gonna say like y target okay so this is the error now I should have mentioned before that there are a variety of ways to train a neural network and by training I mean adjusting all of these weights like their knobs to try to actually get the matched target output when you send in the training data so one thing I should mention I really gotta like even just take a minutes and make a video just about this but in most training situations you'll have training data test data and then of course there's the actual unknown data so we want to simply want to say like oh here's some labeled data I'm going to use that to train but I need to save some of that labeled data because what if I train my neural network only to work with the training data but it doesn't actually work with any other data well I can determine that by giving it some saved some data that I didn't train it with but I know the answer to see how it dumps with that and that's how we can evaluate it so I just want to mention that this is going to be the process now this idea of back propagation with gradient descent is one technique and it's a technique I'll put some links in this video's description you read about the history of it it's it's been around for a long time it's a big innovation in training neural networks but there is a lot of questions as to whether that's optimal best for the future etc there's different you know slept weeks of these algorithms and I actually next probably after I get through this plan to use a genetic algorithm to evolve the weights of network which opens up the door for a lot of kinds of projects that I excited to try to make so all that aside here we are what did we get so far we figured out in the previous video we calculated this error and then we calculated the hidden error which I'll just call each error right that's part of back propagation it's while we have this error how do we distribute this error all around so we can adjust all these weights the reason why we're doing this is because we actually did this already twice I've done this twice once with if you look at my videos about a single perceptron right which gets two inputs I forgot about the bias I always I always ever remember the bias I'm biased against the bias I'll come back to that but the single perceptron which just takes in two inputs and one output well it doesn't say it's a single neuron you can take in more than two inputs but a single neuron with multiple inputs and an output I actually did this we did this idea of training this with gradient descent and we also did it I did it we I did it in a video about linear regression where if I have a bunch of points in a two dimensional space I can find the line that fits these points the best and they did this what's interesting here is though this app so for a linear regression if you recall there's actually a mathematical formula to just compute the exact line of best fit called ordinary least squares I think I went through that in a previous video as well but the idea here and so the idea is we're trying to figure out y equals MX plus B the formula for this line well basically what this is doing is this is exactly the same process that we needed here only we have these weights you're going on you can almost think of this as like m and this is B maybe or something if there's just one input and a bias we had to fit we had to fit all the stuff coming through here into a line well this is actually what we need to do with all of these all of these places right we basically need to do the exact same algorithm that we did for this one line to compute this is the weight and this is the bias what we really have right is that why those MX plus B we have y equals M 1 X 1 plus M 2 X 2 plus M 3 can you see that X 3 plus M 4 X 4 but added up plus B we have this we basically have exactly the same problem but in a multidimensional space so I just need to figure out how do I adjust each one of these M one and two and three and four and B all these weights inside of the matrix so the same training method I did for a linear regression gradient descent the same thing we did with the perceptron we now need to apply it here in this multidimensional space so what should I do next now first of all I forgot to thank a bunch of the resources hold on I some viewers rightly pointed out that when I did this previously and I guess the convention is target minus y the nice thing about this is when if you look at a cost function for a machine learning system you'll see that the cost function is the sum of all the errors squared so if you do target minus y or y minus target you square it doesn't really matter but it is an important distinction probably you have to get it right of course otherwise you might start trading in the wrong direction as you'll start to see as we do other stuff okay let me come over here and let me think so I've better come back to this video in a second but let me first say there are three things one is this is a new resource that just came out it's not a new resource but a new page on the ml for a ml for a github IO site this is a site put together by Jean Cogan has a ton of machine learning resources videos examples demos etc it's amazing and there is a nice article here about how neural networks are trained with a lot more detail than I'm gonna get into here but you can see the same sort of idea of talking about linear regression a loss function adding more dimensions this is the idea this is what we're doing of course I highly recommend you watch the three blue one Brown series about rating descent back propagation and back propagation calculus this will give you a massive extreme set background for what I'm gonna attempt to do it's just kind of like let me just tape this in code like kind of squint the press the button hope it works so this is great I highly recommend this and then I also have been using the make your own neural network book which I could hold up and wave around for you by Terry Gross she'd and there's a link to it on the coding train Amazon shop along with some other books that I've been using for videos and then so this is where I what I wanted to do now is try to connect back to here this is from my previous video entitled the mathematics of gradient descent where I go through a long algorithm to arrive at a very simple result which is in this case of y equals MX plus B what I'm looking to do is calculate the change in M and the change in B and so we can now write those formulas over here so in the case of y equals MX plus B we need to calculate Delta M how do we want em to change based on the error and it how we want em to change is the learning rate by the way learning right if you look in textbooks and stuff and sometimes written with this um the reek letter alpha I believe is that how far yeah learning rate times X times error and Delta B equals learning rate times error this is all done through some calculus in looking at the cost function looking at the derivative of the cost function the slope and how to walk around that cost function and find the bottom the minimum error how what values of m and B do we have to have the minimum error and that's what we want to do here what values of w w1 1 W 2 1 Dobie 300 400 I have to have the minimum error and that error each individual error we've got to like back it up and pass around and chop it up okay so how do we take this and move this to a multidimensional scenario I'm gonna rewrite these a little smaller further over to the left so I have more room to write out the formulas for the matrix version okay so these are the formulas for the change in slope and in by offset change and Hammack change and B for y equals MX plus B so I have the same situation except I have a slightly different one I have like the output equals Sigma of like that whole you know weight matrix what is it matrix product with the I guess it's uh with the inputs right I have this kind of before but it's basically the same thing plus the bias plus the bias which is a vector so I have like kind of like basically the same thing but instead of like single dimension these are all matrices Multi multi dimensional so what I'm going to attempt to do now is I'm going to just write out a notation for these formulas using matrices and try to like compare and contrast a little bit and I'm not sure I get it right because I kind of I'm using a bunk combination of trying to keep consistent with my notation from before and some conventions but let's see I've got it written down here let's look at this so let's first just say I just want to figure out Delta for these weights so in other words you can think of what I'm doing is instead just Delta n I want all of these weights so I want to say Delta all of the weights and the weights are from hidden to output the change in each weight IJ each row I column J I think that's what I've been using it's hard for me to remember what I used in the last video equals I'm just gonna look very similar first of all learning rate same I always have a learning rate learning rates gonna basically tune like how big of a step are we gonna take and I don't like the way I kind of want to rewrite this just because to have it match the way I'm gonna write the matrix version error times X I'm gonna write this times the vector E right that's that's the that's the vector of output 1 minus target one output to our target one minus output one right that error vector that talked about and then X in this case is kind of like the input the input to this neuron to each of this output layer so I'm gonna call that a in this form gonna call that like I could call it x1 we call it H it's what's coming out of the hidden layer I'm gonna put that here when I put that at the end H so these are the components that exactly match up here at times H right we have same way of learning rate we have the error right and by the way if I were doing this for this layer if I would say Delta W Eights from I to J from input to hidden ih would equal do learning rate and then I would say times the hidden error right to remember that from the previous videos where I went through how to get the output error and the hidden error how we pass all that around and then this is times the input so this is the same exact formula but two different layers learning rate hearths or hidden errors the hidden output or the input output sort of way to say they hidden output the hidden output is the input to the output the input is the input to the hidden so you can sort of see how this is this formulas is looking at this part and this formula is looking at this part okay but I didn't put one other thing in here there's something funny that's gonna go in this spot right here so what goes here this is the question now this is where we're so happy to have this book make your up a neural network because we can just look up the formula in here but what's actually is gonna go here is the derivative of the output now let's think about this why why don't I come in with your videos you might have remembered back from the mathematics of gradient descent that we had to take the derivative but in this case of Y in this case it's MX plus B it's very simple derivatives a linear function here we have this sigmoid thing we need to calculate the gradient and the gradient is the errors time the error of the output times the derivative of the output what happened well has the output change has the output change relative to the errors so in this case right we need to add here the derivative of sinh way now here's the wonderful thing sigmoid is the function right the derivative of sigmoid s prime X is simply equal to the sigmoid of x times 1 minus can you see what I'm writing is sigmoid of X so in this case we need to calculate this gradient the derivative of sigmoid and right here now one thing I should really clarify here is so learning rate is a scalar number error is a vector learning rate is a scalar number I'm gonna put an asterisk here err a hidden error is a vector so I need to multiply and the output is a vector so these are actually this is element wise multiplication of the out now I've already what's coming out of here out of output has already had the sigmoid pass through it so I just need to say the output plus 1 minus the output the output plus 1 minus the output now what's weird about this is now the H is really this right we have an exact same formula I have the the learning rate the error gradient here you can sort of consider this gradient here is just the error the gradient here is the error times the derivative of the output and then if I'm multiplying I need to get a weight matrix so the input by the way is also a vector but I need to get a matrix so the interesting that happens if I use the matrix product here and transpose this vector right this is element wise multiplication this is just a scalar now here's the thing if I have the sorry if I have this error and type the gradient essentially at a called gradient as a single column vector for columns if I multiply that by a the hidden output which is also a single column vector but transposed if you take a single column matrix and multiply it by a single row matrix as long as it has this has the same number of columns as this has rows let's let's look at what happens right there's a wonderful website that I use often when I get stuck it's called matrix multiplication XYZ and here what I can do is I can make I'm gonna make this exact right here's an arbitrary single column vector and then I'm gonna make a single row vector so a 1 column matrix a 1 row matrix I'm gonna hit multiply so this is I'm just gonna go to the end here we can this is a nice little animation that goes through everything that I did in previous matrix multiplications and you can see we end up with a 4 by 4 matrix so this is exactly what we need to do to be able to get the deltas for all the weights ok so this also has to be I'm going here this has to be transposed and this should be element wise multiplication with the the I lost track here so I'm taking the output error and multiply by the derivative of the output here I'm taking the hidden error and multiplying it by the derivative of the hidden so that would be H plus h plus 1 so not plus Oh what I have plus here have had that wrong for so long times that's another element wise multiplication times 1 and this is a 1 not an I 1 minus H ok I think we've done it I'm gonna just check here my trusty guide but I highly recommend that you read instead of listing reads that are listening to me and I'm gonna look at this the change in weight matrix equals learning rate times the error times sigmoid of the output well I have sigmoid kind of built in here I'm assuming the output if the sigmoid has already been done times 1 minus Sigma or 2 the output I'm assuming Sigma so I've been done with the dot product of the matrix multiplication of the hidden the output transpose well this is right my notation is slightly different okay so I think we're just about right now of course I forgot the bias so I'm gonna have to basically do exactly the same thing with the bias bias is only simpler because I can just get rid of this so I'm assuming I could probably sort of do the same thing here so but I'll get to that in a bit let me at least try to implement this in the code and then I'll do that in the next video and then we'll come back to the bias