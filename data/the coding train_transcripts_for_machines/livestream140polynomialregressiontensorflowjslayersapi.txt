sara is asking any luck with the lights no luck with the light but I will talk about oh and welcome to is it Thursday Thursday afternoon coding train you would think the fact that it's the summer my teaching schedule is freed up that I would be more consistent about the time less late strangely enough my life is just not working out that way so I am apparently less consistent about the time and more late than usual so I have to apologize for that so but the good thing is I'm here I mean I guess that's good you're watching so hopefully that's what you were hoping for I have I have all my supplies train whistle water warm beverage sometimes caffeinated sometimes not caffeinated you can try to guess back to the lapel mic which is here on my coding train branded hoodie and of course not of course but I have today I have a melon medley from an unnamed local shop that sells food items and I paid 359 for this we really bugs me you know I can never get myself to bite you know you go to the grocery store and they have the the bin of sliced melon and it's like $12 for like this large thing of sliced melon which is approximately a single large melon entirely sliced these single melon itself is usually like four or five bucks I can't pay six or seven bucks to have my melon sliced I have to slice it myself soft focus it might be that the focus is messed up there was some weird stuff going on in this room so if the focus is bad I I will fix that let me know if the focus is weird I will I will take a moment look at this this is regular nonspace melon it is of the water variety which goes well with Cody Trent's main sponsor h2o a little bit upset today everything's off focus no but nobody saying anybody's voice now I also have the space Bella the mysterious magical space melon alright alright so this is gonna be tricky but let's see if we can figure this out the good news is I didn't actually put the cloaking device on this yet so this is approximately where I stand you know about here so if I focus on this right here I should be able to fix that focus so let's see if I can do that it's that better thank you for promise I can't see the output very easily oh that looks better let's see how that is have I improved the focus of course when I stand back here I'm a little bit out of focus but such is life I'm hoping this has improved things I'm gonna pop out this oh I don't even have the chat here oh yeah okay hold on hold on everybody pop out I'm sorry I really should get ready before I start but today I just didn't happen all right now oops let me go back to here let me get the chat on my monitor I have to do that um if I go to look at the live stream I'm live right now I go to that page I see myself in the past and then pop out chat so now I can see the chat all right burgerbob in the chat I just pulled the chest saying 20 seconds slow mode is too much please make it 10 seconds I have no issue with doing that whatsoever let me see if I can adjust that easily you know unless the chat is presenting a problem I'm happy to decrease the slow mode I'm just curious if anybody has a youtube sponsor does the slow mode apply to you or no maybe this is under advanced settings enable slow mode limit chat post to every 10 seconds per person let's try that all right so I switched it to 10 seconds let's see how that goes all right let me move this water over here now here's the thing uh one of the reasons we'll have late today it was actually early not really I was here at 1 o'clock to give myself a whole hour you would have thought that maybe I would use that time try to see if I could fix the whole thing with the camera shutting off but of course I did not now be much too practical and useful and logical for me so what I have done instead yes it applies to sponsors okay no who knows I don't know what this means so so I have this light oh we can't turn this off yet this is a Phillips Phillips hue light 600 lumens I have it clipped right here to my table welcome to sponsor Meyer Shaw see this is the thing I was so excited I almost want to tell you Meyer to unspun sir maybe sponsor again later because I also have over here this thing which is a Philips a hue bridge this is the thing that connects to the internet and controls the light it's easy for a second there it's like a six were warm in here and anyway okay I'm fine uh not sleeping well this week all right so what was I saying about this this I would connect to the internet it would control the light then I could use an app on the phone or I could write like a node program all sorts of ways I could control the light in this room and in fact I could use IFTTT which is if then this that what that stands for something something like that I could use that to every time somebody sponsors to blink the lights and possibly I could do something else like if you're in the slack channel and you need to alert me to a horrible bug in the code or the camera shutting off I could set up something like sort of slack bot messaging system to blink the lights but if this then that okay that makes sense if this then that thank you Chris Persian the problem is the problem is I'm starting reading this slack channel at the same time Simon I have seen your barns leaves fern message thank you I'm kind of right now I'm staying away from the matrix graphic stuff with Tesla yes although I would like to return to that but the this is blocked on the NYU Network so I haven't figured out I was trying different ways of like setting up my own network or like getting a network from like on the laptop to give a network but none of that was working so I have to give up now here's the thing I'm thinking about when at least first as an experiment you know maybe I'm here till 4 o'clock which is like an hour and 45 minutes from now in this room streaming I can get this to work downstairs on the 4th floor of this building in my office down there because we have a special sandbox network that I can do connect to things in different ways that the larger NYU network does not work for I also was thinking the reason getting some of these from i/o no if I want people blinking my lights from the internet into my house but so if you're if after today if it's like 400 and I'm kind of things have gone alright I might consider going downstairs and just live streaming from my laptop webcam just to test out the light thing so you might get that to work okay song that I sorted by sent me a super chat do not see that I see a sponsor I don't see that but I believe I believe that it did happen yeah so people I don't want to belabor the whole sponsorship thing but YouTube has a sponsorship feature you click sponsor you get an invitation to the slack channel and I'll mail you some stickers I also have a patreon which is basically the same exact thing you just give your money there instead of there but you don't get all of the the patreon thing has some benefits that YouTube doesn't have but YouTube has all the emoji integration with the chat stuff all right the Philips you bridge that is correct I've never used one of these before so what am I gonna do today what I really like to do is always like to know where I'm not gonna do this but this is what I would like to do I'd like to lie down on the floor I do something like meditation breathing and stretching exercise I feel like I have not found the right I have not found the groove Stella does not have her groove back yet but maybe it will happen today if I start doing some coding all right let's see if we can get the whiteboard camera going yeah yeah buyer it takes I have to send the slack invite which is not so easy for me to do actually I could actually do this during the livestream wakes people time too much but I the the the slack of Nations have to be done manually there's no automatic process for that so if you go to the community tab there is a post there that sponsors only and there's a Google Form putting your email address there and then I'll send you a slack invite if if I if anybody watching has the sort of power authority to figure that out in a different way and invite new sponsors of slack we could we could make that happen but I probably can't do that during the live stream all right there we go all right so I want to continue with tensorflow Jas today and I want to focus on something called the layers API so let's see where let's see what I have so far I'm going to go to this YouTube channel I heard of called the Coty train and I am going to go to neural networks and machine learning session six tensorflow je s and so this is what I have so far you know what I think this might be a tshirt day I think that this hoodie is just it's extra warm in here if it's the New York City weather for what and I'm gonna switch to tshirt that's gonna it's gonna make everything all right again Oh much better you know what it is I was rushing also and is I'm on the ninth floor now and I was down in the fourth floor and I'd go back and forth just took the stairs you know I made a half marathon a few months ago I I'm doing ok but somehow taking the stairs up and down a couple times I think maybe doing that right before a live stream isn't the best idea alright oh you can see this is the light right here see unfortunately I'm gonna just I'm gonna since it's not operable I'm gonna just put it down to the side ah polynomial regression we should change we should do that right I was gonna go right into the layers API and I was gonna go right into the layers API and then maybe do like XOR as a kind of hell open I don't want to use the word hello world but as a kind of basic example to see how the parts of tension flow digest the layers API works but I kind of like this idea of trying polynomial regression let's let's look where I last left off with the linear regression example and see how much that would take okay TF when your regression one of these days I want to do a live stream I say this every time where I want to like update my workflow okay so if we look at the code for this linear regression example so there's some interesting discussion going on in the slack Channel about there is a IFTTT app applet for triggering a light from a YouTube sponsorship so that exists everything else I'd have to do custom and I'd love to do some tutorials about how to do that but that's why I thought I could just get that out of the box but one limit one thing that you have to have working in order for that to work out of the box it's a working light all right informal poll let's see so what would I have to change here I would need some more per amp TF variables I would the loss function could be the same the predict function would be different oh and graphing it would be different so right here I would write the code for a polynomial equation so that would be like something like let's do it let's do that oh let's do that why not why not that's gonna be fun loads of good times for all let's go where's that what's that playground what's that tensorflow playground cuz I wonder if that has a yeah I mean basically what I'm doing is something like this what I want it's like creating an example like this okay so we are now let me just change a few things I don't know if this makes sense to be like a coding challenge part two of that but just go any important comments or feedback feedback before I start okay all right hmm why is this better all right Oh nope all right that's good this just one sec I think I need to read some random numbers it's been a while that's gonna help Randy numbers and melody those are the things you know I'm gonna I'm gonna look at my youtube analytics after this because this will be the point where the graph of the viewership 31,000 okay break album where's the sheet on this one eight hundred thirty seven seventeen thousand eight hundred thirteen whoo music ended anything I'm a person on the internet reading from a book of random numbers eating melon which nobody really likes to be perfectly honest even though I do and people the chakra talk about weather very tippy is like the best editor ever or something like that come on people get with the program free yourself from these worries about your text editor here's the thing this I like the honeydew I like the watermelon this is cantaloupe really it's part of the medley I'll eat it but 13,000 I heard done mostly 1503 55000 I think I could actually read the whole book if I just had a melon although it's probably a little bit down which melon one should eat before you know take off your problems sleep four thousand four seventy I need to save some of this for later if I'm really gonna get to solving extrovert with Vincent Lopez eighty two thousand five hundred fifty six twenty two thousand six hundred ninety seven fifty four thousand nine hundred eighty five sixty four thousand eight hundred fifty two you know when I was in college right click this like performance art / dance class and I was taught by the founders of the dance troupe Pilobolus and the things I've ever heard of pilobolus and I had Joe performance for it and my performance involve a simple Huck bag full of rice rubber banded to my face and there was like a song I have rice on my face that I made up that went along with that so in a way it all led till now Oh welcome I can't believe you bought for sponsoring this nonsense you are all lunatics that's all I have to say to you you I know I am a lunatic but I thought you were very sensible all of you watching I was a little malfunction there's a little hole here that where the liquid comes out and if you don't have that aligned with your mouth perfectly kind of say but I gotta get a beer trimming you know so many things are wrong no the problem is the dance skills through here's the good news I'm having these back problems so I'm gonna just got an appointment for some physical therapy to strengthen core muscles stuff but the good news is standing is kind of the most comfortable for me so that's what I'm doing now all right cracking myself up hello I am in this video going to do something not advisable because really I should be moving on making some interesting weird creative projects that make use of machine learning in ways I could never possibly imagine but I'm not ready for that yet I'm still in the world of implementing kind of technical demonstrations and examples to understand how things work I kind of maybe I'm stuck in that place for a little too long and you should break free of that place and leave here and go somewhere else but if you want to stay that's what we're gonna do so what I'm gonna do in this video you might you might recall that I recently did a coding challenge where I implemented linear regression the idea of linear regression is to have a data set in this case my data set is a point a bunch of points that I'm clicking I'm just sort of adding arbitrary data to a twodimensional plane by clicking the mouse but this could actually represent the xaxis could represent you know think about baseball pitching you know that the speed of a pitch and this could represent the amount of time it takes to get to home plate although that would be inverse anyway you get the point whose actions could represent data so the idea with linear regression is oh can we fit a line that can we can we make a line that fits that data and the formula for line is y equals MX plus B so the variables are of our system are M and B and we need to adjust those variables and we're going to use green a loss function that we try to minimize to follow blah blah blah that's all in the previous video so I thought well we're here why not just see if we can make a curve to fit that data this otherwise known as polynomial regression so what do I mean by polynomial agression regression it would be good if I had a marker this is definitely not the right marker I shouldn't mention that I'm really partial to berries like blueberries blueberries I'd love to happen they're like much more acidic so the belen is more soothing hey where where oh where is my marker gone now ah you know the other thing I purchased a ukulele and in the last week I've been teaching myself to play the ukulele but don't have it with me so stay tuned for by the way uh great YouTube videos for learning the ukulele um there's a woman I forgot her name already I think she's from Hawaii and she does videos on how to play the ukulele they were great Christina maybe I have to look that up um let's just see if this pen works oh this works fine I don't know what's wrong with me oh I didn't forget the cloth but look here's an old paper towel so at least I'm reusing paper towel sorry okay I got the marker so the formula for a polynomial equation might look something like this y equals a x squared plus BX plus C so in this case this is a polynomial equation of order do you say that too but I could also have a X cubed plus BX squared plus CX Plus D but let's just go with this right now so what does it mean actually we should do one with anyway let's see what we're gonna we're gonna see how this goes I'm gonna get somewhere so the point is now really I've already done this already the only I could keep the same loss function I can keep the same data set the same optimizer the predict function the only thing that's different is I have three variables now instead of two and when I write the predict function I'm taking the X values instead of plugging them into this form of a line I'm plugging them in form of this polynomial equation let's go let's go get started on that oh you know what I'm gonna have to do I'm the way I draw lines so simple because I only need two points to draw line but to draw like a curve that's going to require quite a bit more all right let's see what we can do do you know how expensive things are in New York City first of all yelling over crew thank you very much but Barry's one of the reasons why I got the melon this melon at the unnamed local food shop nearby this is $3.99 the berries $4.99 five dollars per berries that fit in here I don't even think they're maybe they're organic I don't even think they're necessary organic Trader Joe's that's the best place to get them at least a soggy vine in New York City to get the lowest price organic berries what did I um let me just check okay it's not a new new channel I'm sorry the new fruit I should totally do a new reviewing fruit like unboxing fruit let me just practice that for a second then what do I do I talk about it if juicy kind of sweet it's a little weird tasting prefer get five bits sitting it was like cut and refrigerated if I like a day old pretty good good all right linear quadratic cubic Simon thank you you're always so helpful no people are just like giving me money for berries I'm gonna go get some berries this evening thank you everybody whoops I had this go off oh I lost the whiteboard Cameron oh there it is so I want to so let me let me just do some quick hygiene here polynomial function quadratic cubic ya know let's go here we go degree 3 degree 3 that's what I was looking for okay this is for the fruit Channel get some organics the coding fruit this is definitely like the coding this might as well the fruity coder I don't know that works for this channel as well the ratio of time I'm talking about fruit to time actually talking about code right now is about 1 to 1 looking up on Wikipedia and thanks to Simon who's watching this live in the chat I will now reminded myself that the the the number here is off is referred to degree so this is a polynomial equation of degree 2 also known as quadratic 3 would be cubic so on and so forth and linear is really I mean this is it's not a polynomial equation but it's a linear equation but it's of degree 1 and if you go and take a look at Wikipedia you'll see like okay well this is what its gonna look like if it's a degree 3 then the degree kind of matched to how many hills and valleys you have we'll see that we're gonna experiment with this we're gonna have some we're gonna do some fun stuff if you think huh you don't feel repression is fun stuff okay so now hmm look back to the code so looking at what I had before I'm gonna just change this to now a B and C and I'm gonna have three variables a B and C instead of M X and B then ah so now this the predict function so what do I need to do I need to stake a multiplied by x squared plus B multiplied by X plus C so how would I write that with tensorflow a is I'm writing y equals ax squared plus BX plus C so this would be constant Y's equal X's square multiplied by a adding X's multiplied by B add C what's the chance this is right x squared times a plus B X plus C I mean it looks kind of right to me I'm gonna wait for the chat to tell me why they think I made an error hills and valleys it is how many times it crosses the xaxis it's a much better way of putting it Thanks can I go back and restate this I need to declare C as a variable I'm pretty sure I did they're all declared as variables yeah all right I got a all right people in the chat are I'm so informal about my math my informal I mean it correct let's come back let's let's redo that explanation because I don't want it hills and valleys you're absolutely right it's the number of times it crosses the xaxis but you know it's got to go up and down to do that it's got a cross but that's a I let me go back to your the live viewers you're gonna have to bear with me today I'm gonna go back to explaining that again I cannot live I won't be able to live with myself if the live chat I mean the comments when the video gets published okay so so alright so let me so I think this is gonna be right Matz yeah oh but let me undo all my code stuff whoaoh the atom editor really is good at remembering undo past when I closed okay all right good I think we're good let me just check here okay okay if we come here and look at the Wikipedia page you can see here this is a graph of a polynomial function of degree 3 meaning a x cubed cubic and notice if we look at this how many times does the graph across the x axis three times of degree one how many times do we cross that xaxis a line just once so squared twice all right so now I think we're ready to go and try to make some edits to our code so the main thing we need to do right is change M and B to a B and C M and B to a B and C so I am going to change this to a B and C then here I'm gonna make this a B and C just about everything else go remain the same of course there's a really really important there's two other things that I have to change one is this this is me writing the tensor dot tensorflow j/s code for y equals MX plus B now what I need to do is change that to y equals ax where's that little hat squared plus BX plus C so this should be let's see if I can figure this out constant y z equals X's square so that's the X is squared multiplied by a adding and then what I want to add to it is B times X so I have to add X is multiplied by B and then I also want to add C I think this is right a x squared plus BX plus C X's squared multiplied by a plus B both two x's multiplied by B plus C I don't know oh let's see maybe this is right maybe this is wrong but now I'm gonna get rid of this and interestingly enough I do in a weird sort of way I don't actually need to change anything else well I do so here's the main thing I mean I could run this right now just to sort of see if I have any errors now weirdly it's first of all I think it's actually just running the old code ooh what's this print line that I don't need I don't need that oh yeah Oh so let's oh I'm having some memory issues now but okay we're gonna figure that stuff out later save it's do we say we're now interestingly enough it's working I'm kind of surprised by this oh it's working of course it's working it's just but I'm drawing a line the carrot carrot stop a hat okay k week mon am i am i messing up did i miss something important so it's doing something but who knows what it's doing the problem is here I have this code here to draw a line between x1 x2 y1 between x1 y1 x2 y2 but now instead of just using two points to draw a line if I'm going to draw something that is a polynomial equation a curve I need to sample a lot of X points and get a bunch of Y points and connect those with begin shape and shape and vertex so let's see if I can put that in here so what I want to do here let's think about this line X interesting so I'm going to say call this curve X I'm gonna make it an empty array I'm gonna save for let I equals 0 I is less than let's do let's say x equals 0 X is less than 1 X plus equal 0 point 1 so we're just gonna I'm just going to example 10 points just for right now then what I'm going to do is I'm going to say curve curve X dot push X I'm sure there's a fill map quick way that I could do this but let's just list I'm putting a bunch of points 0.1 0.2 0.3 0.4 0.5 now I need to get all the Y's I'm still gonna use curve Y I'm still gonna use Data Sync and then now I'm going to say for let I equals 0 I is less than curve X dot length I plus plus and I need to say before I start this I'm gonna say begin shape then I'm gonna say n shape and then I need to get just it an X 1 and a y1 x1 is curve X a mapping curve X index I and y1 is mapping curve Y index I and then let's put the stroke weight here and then I'm going to say vertex x1 y1 so before I was just calculating two points and x1 y1 x2 y2 now I have a whole bunch of X's and a whole bunch of wise and I need to set them all as vertices and then connect them with a line let's see what happens here whoa interesting so first of all something weird is happening it's getting a fill which I don't want so I want to say a no fill so this is kind of doing what I'm expecting right doing what I expected that one in the middle is really throwing it off let's see if I can actually try to draw a curve hmm oh so now I'm being told in the chat degree equals the number of crossing points explanation is a bad explanation uhoh somebody's knocking at the door I wonder if I'm being too loud oh I did I was trying to see if I could find okay thank you yes yes that was me look why went answer the door it took a while it learned it first of all so if you're wondering what that was remember how I was talking about my be reported to NYU Internet services where is that thing where where where where where is my Philip's bridge where did I put it it's my prop that I need right now whoa boy that was really loud for you wasn't it where did I put that the lamp is there yeah if everybody was wondering if this really is live or not I guess now you know the answer of that question I can't find where that thing is anyway I was trying to find on the network to see if that big was on the network so I just did like a port scan of like the whole network which apparently you're not supposed to do so unfortunately also I did it from the computer that's live streaming live stream slowly goes down it's because I got shut down I got shut down but hopefully I should have muted my microphone poor okay all right the crossing point exhalation is wrong because a polynomial function can have no solutions so it's the number of real solutions how many complex solutions equals the degree I should never try to do any math let's read what it says here constant linear quadratic cubic that's quartic zero polynomial okay the commutative law a real polynomial is upon them with real coefficients and a complex polynomials apothem with complex coefficients the argument of the polynomial is not restricted it's plain bubble though degree is the maximum number of real roots okay okay max all right max you're gonna have to work your magic here so that wasn't exactly right see how I could miss it I guess I could do my greenscreen thing concavity yeah that's what I'm that's what I was kind of thinking of all right so I know I did just say that the degree maps the number of times it crosses the xaxis you can think of that sort of like the number of actual real solutions there are to the equation and it's really just a Mac there could be no solutions to a particular polynomial equation with certain certain values for a B and C so uhhuh so it's really I don't I'm getting in the weeds here because this is not my forte and I'm always messing this up but you know the technically the degree is master the maximum number of real solutions to the particular polynomial equation now I'm gonna go on yesno together and not and it cannot be flamed from the chat we'll just go all the way back again look this is one of those live streams where I get nothing done all right let's move on Wow people are really far behind in time so that's why no one's answering my questions all right right always has that many complex solutions oh that's interesting to note it's not relevant for this video yes all right I'm gonna fundamental theorem of algebra certainly is all right so I'm gonna keep going okay so now we've seen here that this actually does both let me run this sorry I had a little interruption there so there was a strange edit but I'm gonna now click with a bunch of points and let's see what happens over time so give it a little time here I'm gonna let the time speed up it's gonna be one of those fast forward things my tía Oh keep going keep going I'm so impatient right alright so uh you can see that it's starting to try to fit the curve to that Dana now there's a couple things here one is I could really play with the learning rate it's real incrementally very very slowly changing look at that it's moving but it's moving very very very slowly so the learning rate is something I could play with I also you can see that the way I'm drawing this is particularly jagged so what I'm gonna do also here is just go and like really increase the resolution of the number of points that I'm drawing and let's go look for the learning rate I have it point five Wow so I'm gonna leave it at point five and I'm just gonna hit refresh and you know I could also make it something easier for it to fit to which is just like this and so over time you can see that it is trying to fit this particular curve to this line now let's make sure we've done our memory management job I'm gonna go back and console.log the number of tensors alright so something went wrong here I'm creating more tensors than I'm disposing so we've got to go and look and see what I've done wrong there so what tents are what new tensors did I add the Y's this gets tidied the Y's are disposed so let's let me do my debugging where let me comment this out let me see if it's in the drawing nope is it in the oh you know what I started with an old version of my code so this just never got tidied so that really needed to be tidied I'm looking for another Oh missing a curly bracket nope 76 and really let's do it this way ah hold on let me go back oh I'm using an old version of the code for some reason that what the coat that I started with doesn't actually have this section tidied so I'm gonna say TF tidy and then I'm going to make this into a function so I need to put a curly bracket here a close curly bracket there this there okay so now this should right I'm only using seven tensors I can put the drawing back in and there we go now what if I want to have it ah yes okay so this is actually another this is actually a good point we could use one thing that that I wasn't thinking about and the chat is suggesting is that I am using stochastic gradient descent as my optimizer but there are other options for other kinds of optimizers let's go look at the tensor flow API and see what out the documentation was I not the documentation and see there's another good suggestion there's another good city sorry everybody so that's one suggestion another idea that someone in the chat is for podcasts a gradient descent so TF train SG is here so we can see momentum a to graph which one I should try Oh cent let's try that does anybody have a craziness learning rates probably way too high learning rate is way too high for this yes yes I agree I agree looking at the chat still perhaps maybe too high oh I forgot to have it at Mouse drag now so I want to take out the I'm gonna just put this basket back to mousepressed interesting whoa look at that come on you know something else I don't love about what I've done is a eita grad and an atom work let's let's try using atom oh yeah that's what I was looking for I don't know I didn't see that how do you pronounce these by the way adda grad ada grad added Delta a 2 Delta atom let's look at the paper Oh fun times let's try I'm by the way I've just gone off the rails I'm forgetting about this really being like I feel like I need to do this again if I'm gonna do it as a video perhaps but yeah now this is working better buttery smooth learning you use a picture of a pencil all right adaptive Adam yeah right all right I know I think it's live stream was going better when I was just talking about melon and reading random numbers all right I'm gonna torture everybody because I think I'm gonna actually just go and do this whole thing from the beginning again because and it's it's gonna be much faster I'm not just not going to do any insane editing there won't be somebody I won't have I'm going to use the correct code and I'm gonna feel like today is a success so all of you watching this live stream I apologize to you you can all revoke your sponsorships right now but I I just got a I've got a I've got to start over so I'm looking down for TF linear regression sketch a yes I want to make sure I'm actually starting with the correct code so many things went wrong here okay all right everyone I should do more things to get banned from the NYU Network I should be so lucky as to get fired from NYU okay let's we're gonna travel back into time you and me together you know I just say doing these live streams is actually quite good for my back because I'm moving around a lot we're gonna race this here and this is now I'm gonna I'm just gonna blaze right through this okay let's cycle the camera hello coding challenge the last one part 2 of the last one something maybe I don't know this is actually my second attempt I started this earlier today and I'm now gonna try it again you should watch this video go something else but I'm making it because I want to make this video I've got to feel like I did something today so in the previous video I did a demonstration of linear regression with Tessa Farias and the idea of linear regression is I have some data set right my data set are a bunch I'm making up a data set just by clicking points but you could imagine the xaxis representing something in the y axis representing something and then I'm trying to fit a line I want my line to fit to that data set and I'm doing that by creating intention float yes these variables that represent the M and the B of the formula for a line and then I create an optimizer and I I try to like figure out the loss like well if I had a line there what's all the differences between all the actual data points and where the line is and minimize that all that stuff that I did in the previous video if you watch that but linear regression can only ever fit a line so what if for example my data looked something like this well you can see the best line you can figure out to fit that data is this line which is it really accurate but I could see pretty easily like oh I could create a polynomial function probably a quadratic function that is a curve that looks like this that fits all those points so this brings me to the topic of what everybody wants to do with their lives so what is a polynomial equation well in some sense this is a polynomial equation it's a degree one I could also have a polynomial equation that's like a constant of degree zero y equals five if I had one of degree two what I have is y equals a x squared plus BX plus C quadratic cubic would be y equals ax cubed plus BX squared plus C now what are these values what is this what does this mean so the degree has to do with the number of solutions whether they're real solutions or complex solutions and there are a bunch of solutions across that I'll always math stuff which is not my forte I'll try to find a good resource for you know the fundamental theory of algebra or whatever that you could read about but the point is if I just want to now adjust my code to use a polynomial equation instead of a linear equation alright so that's not going to be too hard there's actually very little I need to change in the code so let's go back here and let's go to the code and let's look so here's the thing now I'm not gonna do this but really what I want to I mentioned this at the end I have an exercise for you to do if you make it all the way into this video I've got an exercise for you to do which would be totally fun again in the sense in the world we're polynomial regression is fun alright so I had em in B as variables now I need a B and C okay so now I need instead of M and B a B and C a B you know one thing you don't like about this you know I'm gonna fix something first that I never liked about this example which is that my space my twodimensional space goes between 0 and 1 I think it's better just for the world if it went between negative 1 and 1 so let me look at everywhere where I map and it's really gonna be the same negative 1 1 negative 1 and 1 probably gonna miss something negative 1 1 negative 1 and 1 just think the I should have like a Cartesian plane where zero zeros in the middle as my data space just for what I'm doing here so I think and then this should be this so let's look at this whoops okay I missed something yes no shoot shoot I missed somewhere why did I decide to try to do this right now terrible idea was all working fine let me just look everywhere I have map between negative one and one negative one oh one made one oh one negative one one anyone yeah I think I got everywhere Oh such an interesting discussion going on in this black channel I totally totally wanna I'm happy to participate in this later but this is about youtubing and the like line 35 ah there's the mistake that you all saw negative 1 and 1 there we go ok ok so we're back my linear regression is working just to be really sure up into a point here oh no look at this is the quickness down there oh I have it backwards zero too high ah 1 2 negative 1 all right we're really gonna get this there we go ok there we go all right now everything's fine I can now go to changing these too sorry for that little digression a b and c a b c okay then what's the other thing that i need to change so clearly the thing that i need to change is my predict function wherever that is there it is right so this is the formula y equals MX plus b expressed with tensorflow j/s now I just need to express this formula also with tensorflow digest this I feel confident I know how to do cuz I did it earlier today y equals ax carrot or I like to say hat look at x squared plus BX plus C so I'm gonna say constant wise equals so X's squared right x squared multiplied all the stuff in tensorflow J's can be chained the mathematical operation so the X is squared multiplied by a adding the X is multiplied by B that's B X and then finally adding C so this you know takes some getting used to how to like put all this stuff together and I could put it in multiple steps to make it more clear but this is the kind of thing you want to if you want to get into little lowlevel tension flow digest if you want to practice so now I can get rid of I'm just gonna get rid of this this is the predict function now I have another really significant issue here so I'm not gonna let me just run the code to make sure there's no syntax errors but it's obviously not going to do anything that makes any sense because it is what it's that this code down here is designed to just draw a line by the way good see I was doing some earlier in other words I'm picking this point and this point and just drawing a line but in order for me to draw a curve I can't you know I have to sample a lot of points along the xaxis so I need to make a loop and I'm now going between negative 1 and 1 to sample all these points I need to say begin shape vertex to your vertex C a vertex here predicted and shape I'll see that line so instead of having X 1 and X 2 I want an array of X values and I'm going to call that instead of line X curve X and that's going to be an array and I am going to start X at negative 1 go all the way up to 1 say X plus equals and let's use some increment like 0.05 and then I'm gonna say curve X dot push X so I'm just trying to make let me just show you what I'm trying to do here console.log curve X and there's gonna be all sorts of errors here but let's see you can see here that I'm just trying to make an array that has lots of X values but between negative 1 all the way up to 1 so I can now I need to get the Y values that go with that so I can draw this curve and I have the predict function does that so predict curve X get all those wise then curve Y is then again maybe I shouldn't be using data sync here that's kind of gonna be an animation slow down a problem but hopefully it'll be fine curve y is now the regular number the floating point numbers not the tensor anymore version of the Y's then I can get rid of ten sir I'm done with it and instead of drawing a line what I'm gonna do is say now okay now I just need to go through and look at all of the X points and say the x value is map curve X index I which goes between negative 1 and 1 to 0 to width and Y map curve y between negative 1 to 0 to height and then I want to say before this begin shape no fill stroke 255 stroke wait for 2 or whatever I had it and then n shape oh I need to actually set the vertex vertex X comma Y so let's see let's see what happens here look at that so this by the way is the random curve that the coefficients and I should get rid of this console.log so what's interesting about this is that every time i refresh this I'm gonna get a new polynomial quadratic equation because it's picking random a B and C and you know what I didn't pick a random any negative numbers so this would also probably make more sense for it to write couldn't technically these be anywhere like I should start between like negative 1 and 1 does that make more sense right yes that makes more sense so you could see I'm getting all these random curves that's what it's starting with now when I click you can see it's trying to approximate the curve whoa weird huh that looks exactly right but backwards why because I made this mistake again height is flipped negative 1 to 1 oh no no no not there this is hard to keep track of these pixel mappings between height and zero let's run this one more time there we go you can see now it's you can see it's taking a while let me let me be more methodical about this I'm gonna click like a bunch like this it's actually finding it quite nicely but you can see it's good that it's quite lovely let me do it the other way you know what's bothering me is that you can see how this is not getting all the way to the edge it's because when I created those points I really want to say less than or equal to I want to get the last point in there as well oh I don't do this that's a little bad trick there there we go let me let me write draw these now there we go so you can see this is working hooray so now we have polynomial regression now one thing I probably would want to do do is this you know now that I'm getting past just sort of like basic linear regression the optimizers the optimizer that I'm using if we look at the tensorflow code is trained SGD stochastic gradient descent let's just try for a second let's look at the tension flow jsapi and I'm actually already here because I was looking at this earlier you can see there's actually different optimizers that we could try a wellknown one atom the a da here being for adaptive I believe like a de grad a dad a de Delta but if I look at this we can see oh this constructs an atom optimizer that uses the atom algorithm I could click on this link here and I could find this whole paper that explains it beyond the scope of what I'm doing right now but just out of curiosity all I would need to do it oh maybe stochastic gradient descent isn't the best algorithm for fitting this curve let's just change this to Adam and I kind of have a feeling that this learning rate being so high is going to not work forever let's leave it so warning it might flicker quite a bit let's just see what happens with like a very high learning rate yeah you can see look at it like whoa that is really fun actually I kind of like it with the high learning because look how quickly but you can see it's kind of like bouncing around is because it's high learning rate it's gonna overshoot the optimal spot so let's just make that point one and let's also I think it would be fun to change this to Mouse dragged although I'm worried I'm gonna guess at so many points that it's gonna really slow down yeah Oh while I'm adding the points that's interesting so while I'm adding the points let's see this is a little bit weird but let adding points equals false I'm just gonna have this is like a terrible idea adding points equals true adding points equals false this doesn't make any sense why would that be really slow while I'm adding the points because what I want to say is like if and if not adding I was thinking I could like don't run the training if I'm not adding the points only run the training if I'm not adding the points yeah that didn't really help why what am I missing here so do the chat is fascinating oh people are really complaining about my 1.01 fix why not Jim we're gonna this section is so irrelevant to the regression tutorial that is not work that was like a side that I'm not gonna let me think about this right while I'm adding the points it's slow and then it doesn't matter it's happy to have a lot of points Mouse drag gets called multiple times on Mouse oh right so what if I did yeah right I should do Mouse pressed yeah I know what to do all right I'm kind of off in the weeds here a little bit of something that's not irrelevant to this example but I've been noticing that it's like really slow as I'm like drawing and then as soon as I like let go it's perfectly happy to like animate very quickly I'm trying to figure out why this is so one thing I'm gonna try is I'm going to just change I'm going to add mousepressed and I'm gonna say let adding whoops I'm gonna create a new variable let adding points I'm interesting to call it let dragging equal the false and I'm going to say I'm gonna say my mouse press you're gonna say dragging dragging equals true and then I'm gonna add Mouse released and say dragging equals false and then in draw I'm gonna I'm gonna do this now in draw so this way I'm gonna kind of like really keep everything in draw and I'm gonna say if dragging then add points and if you're adding points maybe don't try minimizing the foot just wait till you're done adding points to minimize the function let's see how that works yeah there we go so it's not happening in real time in the same way but at least it's letting me add the points so I'm intrigued why I wonder if there's probably a different way to think about this I really love how you that animation of watching it fit oh it's really just very satisfying so in any case let's try I'm just you know let me just try a smaller learning rate just because I'm curious so you can see with a smaller learning rate it's moving much more slowly so the higher move learning rate it's gonna get there much more quickly if it's gonna bounce you could do something that's called annealing I believe of the learning rate meaning start with a high learning rate but lower it over time we have to potential flow das API to see how that's done but here's thing I really want to do this I want to do this with a equation of degree three just because so I'm gonna do that manually so I'm gonna add a D here and then I'm gonna add a D here and this is gonna lead to my exercise for you and then I'm gonna say ax cubed plus BX squared plus CX Plus D so I want oh is there a cube mathematical operation intend to float a s square operations operations there's a square POW I guess I could do just wondering if there's a TF square is there a cube no so I probably want to do power where is that it's funny how that's under it react so I want to do this POW base exponent so I would do X is POW 3 x a adding X's squared multiplied by B adding C X is multiplied by C and maybe I should start to do something where I put these on different lines so so let's do this X's pal 3 multiply adding X's squared x be adding X is multiplied by C adding D right did I get this right this is now of degree 3 X is power to the power of 3 multiplied by a plus X's squared multiplied by B plus X's plus CX Plus D ok and then I think actually I'm good because this everything else is the same so let's go check this ooh argument exponent past Oh must be a tensor but got a number of course so if I'm saying power 3 I need to say TF scaler 3 so everything's got to be everything's got to be a tensor I can't just use numbers like I'm used to so that's to be TFT scaler dot three and let me put the learning rate back up higher let me put it back up to like point wow that is immensely satisfied so now you can see and by the way if I happen to draw a line it should still be really happy to sort of like fit a line there because it could just make those coefficients zero oh this is great oh hi Murphy glad I made this video for myself at least so here's the thing here's my exercise to you how can you make this so that the degree of the polynomial is like something that can be interactive as well so could I have a dropdown that allows me to try it with a degree 2 degree 3 degree 4 or maybe a slider what other kinds of interactive features could I add to this and how could I maybe like have the data set come into this in a more interesting way besides just kind of drawing with the mouse so um could you make what kinds of things could you could you do with this I think there's some interesting visual possibilities so I hope you enjoyed this video I'm going to publish this code now as a coding challenge called it's really part two of the linear regression now polynomial regression and I'll see you the future videos I'm going to work on that I'm going to look at that tensorflow digests layers API soon enough ok goodbye yes so Tobias in the chat is asking why didn't X less than Ernie let me dress this so this is really weird but I why did this not work why did this not work here's the thing floating point math on a computer is a weird thing and I've encountered this in many videos and tutorials but at least it's somewhere I cover this in an actual tutorial but like let's go to the JavaScript console for a second and I really should let this let me just shut this off so let me show you something oh it's being much too nice to me maybe it's like so there's all sorts of way of rounding stuff that can happen and floatingpoint rounding errors is like a thing because the computer's not actually storing this number as you see it it's storing a representation of this floatingpoint number with a certain number of bits and it has a limited number of bits so it can often kind of like get off by point one which doesn't really matter if you're just doing like a simple graphic simulation but if you're doing some like they're highly specific math that's why in certain programming languages and environments you'll find double which is more memory for decimal numbers you'll also have like kind of like specific math like I bet your tensor flow to deals with this stuff in a much more like lower level and accurate way probably 0.01 plus 0.02 I'm being told no in short oh yes the dangers what are the dangers oh maybe I should try that 0.0100 no I don't know I don't know how to get it to show up the I don't know how to get it to show up it seems to be working perfectly there's nothing wrong at all let's Google that dangers of overfitting polynomial curves all right so maybe I'll mention this real quick I forgot something important that I was told by the chat that I should mention and I'm referring of the dangers of overfitting of polynomial equation and that's what this being represented on this is a Wikipedia page for overfitting which is a term that you'll hear a lot in machine learning meaning what is overfitting so if my data set if those points are my data set a really fancy polynomial equation of some high degree is gonna be able to draw something like really accurately connecting all those but it doesn't actually have any real meaning as applied to the data the data can have a lot of noise in it and a line might actually be an appropriate way to make a prediction even though it doesn't fit it has on like a higher loss than the polynomial so so this idea of generalization you don't want your machine learning model to work so accurately with your known data set that it cannot make good predictions with an unknown data set and this is something that will come up more and more as I do more videos and tutorials with things here's the thing though I kind of like this example that I made for the fact that it does something kind of interesting visually in that it just looked figured out how to make this polynomial function fit this arbitrary set of points so I think we're sort of like some kind of artistic output there might be some value here but yes thinking about actual machine learning and how you want to make predictions is important so that's why I'm here at the with this public service announcement the more you know the more you know the music goodbye oh there we go CJ CJ got something here CJ you're you see J coding garden there we go there is our floatingpoint rounding error thingy what's this sound all awful in that and it won't be usable yes okay CJ yes DJ is rate coding guard of the CG guitar I love that you used the guitar CJ you see everyone should check out Odegard with CJ very I I wish I watched more but I've caught a few of the streams alright ken Haley writes only use higher order polynomials if you know there's a reason to do so not just the data yes will you keep the beard since when have I ever not kept the beard thank you Ken for that clarification alright 340 i could go downstairs and livestream be playing with the philips lamp or i could talk about the layers api i should probably talk about the layers api since that's what i said i was gonna do let me give me a minute here to figure out what I'm gonna do next I have one more piece of space melon the curves array has the mistake what mistake do I have one more piece of space melon I don't know how much longer I can do this we know all right can I stop the infinite loop what infinite loop all right I don't know what's going on let me just make sure NYU is not shutting me down ooh oh I got another sponsor that I missed because I'm getting now I'm getting so I know that Philips like thing will work because I'm getting email notifications thank you to Supriya okay I'm not seeing any emails from the internet services here telling me to stop doing what I'm doing okay all right I think I could move on yes slack channel any more things to say let's I think I'm gonna erase this I'm gonna reuse my paper towel right yeah it's probably what I should do is always do everything twice where is yeah I don't know why can't find that Phillips hue light bridge it's like completely oh there it is this is the prop I was looking to show ya we're over here this is the prop I was looking to show so I'm that's what caused me to get banned from the NYU Network Oh remember when I used different pen colors those were the days I want to do the XOR I'm going to do a video I want to do a tutorial of now about the the layers API and and try to train a model to learn XOR another thing that I'm thinking about to at the tensorflow one of the tensor flow videos is either at Google the Google i/o conference I think it was at the i/o conference not at not at the dev summit but I can't remember which one did and it's part of the TF chess examples did a classification example with Major League Baseball I'm using like pitching data and like sort of looked at the speed of the pitch and different things and then classified it as a I think it's a fastball or curveball or slider so I think that I would like to get to some more actual real world real data examples and then I'm gonna do the doodle classifier I should do all these things then eventually ml5 alright okay let's see here so now let's let's make some changes here I'm just gonna doing some housekeeping here okay would be nice if I kind of knew the lairs API who it there's a big thing of paper towels here that's funny zoomy asks does YouTube create a video ondemand once the livestream ends yes it does it sometimes takes a little while and it actually the way I have it set up is it automatically goes to unlisted but this URL that you're at right now it will be there and then I make it listed once I had a chance to work with matcha Chia to like write the description and all that kind of stuff alright so layers okay just gonna look at some examples that I was making working on should really pin some repositories so let me look at this oh yeah I had all this extra stuff okay right sequential well then you add and create layers create an optimizer and you have to compile it you can you can just set a loss function and then so that's pretty much so they could just call predict okay all right which deaath model that's different than the difference between TF model and TF sequential is that TF model is a more generic supporting an arbitrary graph without cycles of layers TF sequential is less generic and supports only a linear stack of errors Oh interesting how interesting so I'm used to just using TF sequential but I'm not going to worry about TF model right now yeah input what's this alright I haven't used that and then these are the different kind of layers and whoops look at my example Oh I closed that I just don't know any of this stuff off the top of my head units input shape so where I want to look up I just want to see what's in the API so I can things I want to look at our TF sequential I want to look at dents I already have then to this I need dents input shape config okay that I need why do I keep closing my thing that I want things I want to cover our dents a sequential compile so many sequential compile so that's under objects yep okay compile and I need this I think this is going to be enough and then predict I also want all right this should be a predict evaluates predict yep fit we're gonna get into also okay anyone who has experience with this stuff is there anything super important about anything important about TF sequential versus TF model that I should make sure to cover alright I think I'm gonna talk about the lairs API and I think I want to use the toy neural network okay actually just look at the library this make sense so okay to do all right all right I'm not gonna I will just okay yeah dense layers are what I used yeah yeah okay okay hello welcome to another tensorflow das tutorial now I'm very excited about this one I'm generally excited about a lot of things but in this tutorial everything that I've done so far has just used tensors operations to kind of create lists and matrices of numbers and multiply them and add them and optimize loss functions that kind of stuff now and I could keep going and there's a lot that I could do with just that alone but tensorflow digest I talked about this in the first video it has the sort of core API which has the tensors in it the operations and it's what I use to do a linear regression and a polynomial regression demonstration it also has something called the layers API and the layers API might look familiar to you if you've ever used something called Kerris because these are really Kerris layers caris is a lot machine learning library that is a higher level that allows you to create these machine learning models and underneath the hood a lower level code like tensorflow will be running so when tensorflow dot jeff's was created it was created with both the sort of lower level stuff and the slightly higher level stuff and I also am working on with a lot of collaborators here at NYU ITP an even higher level library that's built on top of the layers API called ml 5 I'll be getting to that eventually in this video I just want to talk about what the layers API is and its core features and so the way that I'm gonna do that is by looking at a sort of basic diagram of a neural network and how you would put together that neural network with the layers API and the kind of neural network that I'm going to diagram is the same exact one that I did in my very long tutorial series about Bill writing a neural network all from scratch so the point of this is you don't have to write it all from scratch you could just architect it with the layers API but if you want if you want to like get everything you possibly could ever get you could go back and look at some those videos if you want so what is so I'm gonna look at a simple well it's not simple but a basic feedforward multilayered perceptron it's gonna have just two layers so it often looks like three layers because there's also the inputs there's the inputs the hidden and the outputs that's three things but technically there's only two layers and you'll see why so let's consider that we have this neural network it's going to have inputs let's say that it has I don't know two inputs then it has a hidden layer how many nodes are in the hidden layer I don't know let's say four then it has an output layer how many outputs are there I don't know maybe we're doing some kind of classification task and there's three possibilities it's either a cat a dog or turtle so there will be three outputs you know I started diagramming the next the scenario that I'm gonna do in the next video maybe as a coding challenge is I'm going to solve again the XOR problem I really would like to get to some realworld applicable problems but I'm still here in the weeds of just like I want to see how things work and use kind of trivial and known problems just to see if I can get the solution that I know I'm supposed to get okay so if this is my diagram if you if you've never seen the neural network before again you could go back and look at to my other videos but the ideas are some data X we might call this like x0 and x1 and that data each each of those inputs gets sent to each hidden node there are weights here the inputs get multiplied by the weights added together and then pass through an activation function and then get sent out to each of the outputs and so that happens at each one of these it's very hard to draw this I'm sure I missed the connection by the ways that they called dropout so I've done that correct doesn't dropout caressing if I forgot to draw something but I'll get to that in another video so then then we have the outputs and those are again the weighted sum of all of the outputs of the hidden layer the hidden nodes comes into the output pass through an activation function and we see their result so the idea here is maybe that I have a image with just two pixels in it and two two pixels come in they get multiplied by all these weights activated of the activation function sent to the outputs and then I get some values that tell me the probability of those two pixels were a cat dog or a turtle that would be an image classification task so how do I use how do I use the layers API to create a neural network with this exact architecture so the first thing that I need to do is create something called TF sequential the TF sequential let's go look at that in the API Docs and I'm right here all right TF win is a secretes a sequential model is any model where the outputs of one layer are the inputs to the next layer that's what it says right there guess what and I know I'm sorry that I've kind of gone a little bit too high in my writing but the outputs of one layer are the inputs to the next layer the inputs go into the hidden the outputs of the hidden go down so that's exactly what I want I should say there is also something in the layers API called TF model which I'll click on here and the key difference is that TF model is more generic so there's kind of more possibilities there but if I really just want a simple basic feedforward neural network or the data flows in one direction between layers TF sequential will work so if I'm writing some code I would say Const model equals T f dot sequential so there we go I'm done well not exactly so that's just creating a sort of empty so all I've done is created this kind of empty architecture so what I need to do now and by the way this is what makes working with something like the layers API really powerful if you watch my tutorials where I did the whole neural network from scratch it was so much easier just to have one layer and I never kind of got to like multiple acres cuz I have to rewrite the code and think about the layers and how they're connected and have a loop and all this layer object well guess what the layers API has this for you so I can actually just say TF now add layer so I can I can actually I can create a layer so the kind of layer that I want to create is known as dense so what is a dense layer a dense layer is the terminology for a fully connected layer meaning that every every node in that layer is fully connected to every node from the previous layer and that's exactly what I have here these are dense layers all of the connections are there so and you'll see you'll see there's like other kinds of layers there's a convolutional layer that i'll use one at some point when I talk about convolutional neural networks other things too but dense is where we're gonna get started so let's come back and look at now the API Docs for a dense and I think I've opened that up here yes TF layer sorry it's TF dot layers dense so I need to say Const and I'm gonna call this hidden equals TF layers dense Const output equals TF layers dense so I'm missing a lot of but this is the idea so like I will have a model which is it's a sequential and then I have a hidden layer and output layer we'll talk about the inputs in a second and then I would just say model dot add layer hidden model dot add layer output and I'm like guys like to say outputs I think is it's the output layer whatever nuts to say output so this is the idea this is how in theory simple it is to build your own model using the layers API now what's missing here like I could weirdly enough let's just like run this code and see if we get any errors so it cannot read property name of undefined so okay so so who knows what that error is but thing that I'm really missing here is I need to be more specific like I need to say when I make a layer what is the shape of that layer in other words how many nodes are there with the shape of the inputs how is it connected what activation function am I using those types of things so those are if we look at the API Docs the configuration of the layer so so I need to actually configure the model itself and configure each layer so let's go look at that and see if we can figure that out so let's go look again at TF sequential and you know actually I think we're going to be fine right now with there's an optional this question mark means optional there's an optional optional optional parameter config what I am going to skip that right now and yet it could be I could actually create it with a bunch of layers already and a name but I'm gonna skip that what's more important here is the sorry the the dense the config object for the dense layers which is required so that's why I'm getting error this is required so I need to specify some configuration options and this should be listed for me here units activation use bias kernel initializer bla bla bla bla bla bla bla bla and sorry for these markers here so let's start adding something what that means is I need to create an object I'm gonna call it config I could call it and here is where I'm gonna set up the configuration of this hidden layer so what I'm gonna do here is let's look at what some of these are so units so what I want is what's the unit so in this case I want to have the hidden layer has four units and so I'm gonna say units four maybe I want to specify the activation function so what activation function you use is a fascinating topic that you could go down many rabbit holes for different scenarios but and I'm just going to put sigmoid in there as kind of it for historical reasons and that's also the activation function you in my toy neural network JavaScript library but eventually as I start to build out examples I'm gonna be taking out that sigmoid and using other ones so I'm gonna say sigmoid and I'm gonna put config here and I'll just say config 1 or config hidden again I could put the object itself directly in here there's lots of ways you could probably write this code in much shorter way I'm trying to write it as long away as possible to be most clear so let's do that and let's do config output and what did I say how many outputs do I have 3 and I'll also use sigmoid so I'm going to say 3 and I'm gonna say I'm gonna say config output ok so things are going pretty well now I'm gonna hit refresh here config is not defined sketch let's just line 7 oh right config hidden ooh oh interesting time out for a second I just need to just need to take a pause for a second I need some water how's this going so far is this like kind of helping people clear interesting useful to longwinded because it's not add layer all right let me just take a peek once again at my example Oh input shape that's where I'm forgetting of course that's why I forget okay all right amusingly I got this weird error message which makes no sense at all it actually makes sense but it's because iíve got the p5 library involved here and p5 actually has a function called model so let me just write now p5 is irrelevant for this discussion so I'm just going to comment out the p5 library and then hit refresh here now add layer is not a function so I must have imagined that this is how you add a layer to the model let's actually go and look and where would I find that out once again if I go to so here what I want to look at is all right hard for me to find things ok I know what I want to look for so I'm gonna just search for it I want to look for the TF sequential class so TF not sequential the function creates an object that is a TF not sequential so if I look at this we now look that the function is just add there's no add layer function is just add which is a lot nicer actually so this is meant to just be add and this is meant to just be add okay so now this is really bothered me that it's calling this polynomial regression so I'm going to have to change this to layers API explanation there we go okay uncaught error the first layer in a sequential model must get an input shape or a batch input shape argument all right so what did I miss this is what I was talking about so the inputs are technically not a layer themselves the inputs are in a way part of this hidden layer they are the inputs to that hidden layer the inputs to the output output layer are the outputs of the hidden layer so one of the things one of those properties that I have to specify is the input shape now interestingly enough it says I need an input shape or an input batch shape and what's interesting about this is what is the difference so here I can clearly say that the input shape is two there are two inputs it's just a no actually it's one well no no it's it's an irregular number to it it's confusing this is what it is it's one dimensional it's a one dimensional ray with two spots in it but someday there might come a time where I have a data set that is just each each each each record of that data set is two numbers but I want to send in a hundred of them at once that's known as a batch so the shape might be something like 2 comma 100 but this is not super relevant for right now this is what I need to specify so if we come back to the code I should here oops going back to sketch touch is what I need to specify here is input shape that's it again I beat this up like I'm just saying my my bottle architecture has so now I should be able to no errors so I created that model and I can even take a look at it here there it is you know all this stuff input layers we can see all sorts of stuff here now I there's not much there actually cuz I've forgotten a really crucial step but let me keep going there's some more stuff to discuss so the input shape is what's the thing how come I don't need to specify an input shape here you would think that I might well I'm just doing it with some camera cycling after all I had to say that there were two inputs hidden I don't have to say that there's four inputs to outputs well the reason why I don't is because tensorflow has the layers API can infer the input shape of the outputs layer because it has to be the number of units in that hidden layer and by the way it's you know actually naming these things like hidden and output is almost less relevant now it's really kind of like layer 1 layer 2 that sort of thing so so I could put input shape here and I would put for now let's just see if I have any errors everything's fine now what if I put like a tear am I going to get an error no I didn't get an error that's weird now why didn't I get an error well maybe it should give me an error I don't think so though I should get an air though I'm missing a crucial step here I actually have just set up the idea of this sequential model I have the model object I have the hidden layer I have the output layer I've added them both in but I actually haven't like plugged all the pieces into each other yet and finished it off that has to have come as a separate it's not building up the model as you're creating it or configuring it it's at the layers API so you configure it and then call a function called compile so I know I'm making lists of and this by the way was in TF dot layers dot dense but another really important function here compile is part of a sequential object ad ad was the other one if I'm sure keeping track of the things that I'm looking at so I add I looked at now I also need compile so let's go take a look at that so if I go to the documentation here we can see there's ad evaluate there's a bunch of things I'm looking for compile wait maybe compile is not part of TF sequential oh it is it is it's just listed as part of TF model because TF sequential is based off of TF model so this is what I'm looking for this is me needing to compile the model now I need to compile it with an optimizer and a loss function aha so if you watched my linear regression with tension flow Jas videos you might remember that I had to create something called an optimizer and the optimizers job was to minimize a loss function so the same thing the idea you know I just had y equals MX plus B now I have a more complex architecture to learn about a data set so what I want to do with that architecture is the same though I want to feed it a lot of known data and have it optimize all of the weights of all these connections to fit and this gonna be a very fit that data so I need to specify those things so how do I do that so first I'm gonna make I'm gonna call this just um like config and I'm gonna say optimizer is and so some options here a string or a GF train optimizer so I think what I want actually want to create my own optimizer and I'm gonna go do that I'm by saying a constant optimizer equals TF train SGD zero point one so if you remember this is a way this is I mean this you might not have seen before if you're watching this video for the first time but this is exactly the same code that I had in my linear regression example I'm creating an optimizer from TF train the optimizer uses stochastic gradient descent and the learning rate is point one so this will be the optimizer so I'm gonna say SGD optimizer like that then what else do I need a loss function so the loss function can be I could probably to find my own loss function or I can use a string so I'm not seeing here the options for the loss function strings but let's see loss function like basically what I want to add here is like mean squared error or something that's my loss so I don't think that's right but let's just see now if what I would do is say my mean a model dot compile config so now right what is what does the Routh let's review make create the TF sequential object configure some layers add them to that model then configure the the Optima basically make an optimizer and a loss function to find those and then compile the model with those so I'm sure there's gonna be lots of errors here and there's things that I've done incorrectly let's so unknown loss mean squared error so let's figure out how do I look that up so let's see here means squared look I found it in an example ah so losses let's look at this I'm just looking for the list of them but I'm gonna I'm gonna come back I'm gonna find that and then to come back and show it to you but now that I see it's actually this is just lowercase M so somewhere the documentation I want to find what the options I could put here are let's run let's now hit refresh oh no errors interesting so this is weird I'm surprised know if this is a bug or not but I'm surprised that I didn't get an error for this input shape here for the output maybe once I started feeding it data again there maybe I never would but I'm just getting it refresh though so okay so hmm look pause for a second we were talking about the cameras of the chat so I want to pause here to find the to just look at my example that I made the other day what else did I put in compiled no I just have the optimizer in the loss and then predict can do predicts okay so some X's and I can do the training so I can do fit okay so I probably want to add fit so where do I find in the documentation the possible so my guess is that you can just use this any of these lost functions as a string right where did I write that Oh Simon it's not me I wrote dad where did I write dad compile oh here I know why did that okay there we go fix Y input shape of eight when we said to oh yeah no it shouldn't have an input shape of eight the into the correct input shape sure before so hopefully I didn't make that way too confusing okay let me come back here okay just to be clear the correct input shape here should be for the input shape should that of the next layer should match the number of outputs the number of units in the previous layer if you think of this as layer one and layer two but I don't actually have to include that because it can be inferred so I just want to be clear I was kind of experimenting to see if I could have it give me an error but I haven't figured that out yet okay so I'm actually in good shape here there's no errors here so let me see what can I do now so the two things that I can do now I have created my model I've created my model and I've compiled it and by the way I couldn't find in the documentation necessarily where there's a list of different loss songs as I could put here but my assumption is that these are a whole bunch of different loss functions I could probably just use any of these as a string so for example if I want to use softmax crossentropy oh yeah that's one of my favorite loss functions it's gonna like Oh unknown loss softmax crossentropy so meaning is Nikhil are you in the chat does anybody know I got a pause for a second I don't think it has to be for why because you could add it doesn't matter so why so let me explain this to me what am I why like if I suddenly wanted it in the case where I actually made like six the shape to here these are just some extra random data that I would be required to add in here I think I'm gonna click on loss on top to see all losses so I'm gonna match you I'm gonna go all the way back to just I'm gonna I'm gonna try to explain where you can find the list of loss functions and that this input shape 8 thing was like very misleading so where somebody was saying that I could click on losses at the top I don't know where that is oh here yeah but it's not showing which ones are available as a string so let me just let's just try some of these other ones absolute difference yeah weird it definitely is happy with mean squared error so let me look again can any of these like cosine distance oh maybe you can't use those with this particular optimizer no all right all right so I'm not gonna worry about that too much let me see did anybody so there's a difference Jessa doe in the chat is asking don't you actually have 3 times 4 equals 12 inputs there's a big difference between the weights the weight matrices have 4 times 3 but this is what the layers API is keeping track of for you I should mention that in the part just search the dock near mean squared mean square should be near I think it should be possible maybe a bug maybe that's a bug that I found so I'm just going to I'm gonna like gloss over that unfortunately object functions or names of object functions oh so in other words I think I found a bug oh you know what though I think there's a new version of it so let me make sure I'm at least in the current version somebody factchecked me on my version what was it again shoot mean squared error so let's try this whoops sorry okay it likes that yeah so it's fine with yeah it's fine with it's fine with the other loss functions but not as a string so I think that's a bug yeah so interesting that's really interesting so I'm gonna okay so can anybody so I'm gonna go back again I'm going to redo this part of the tutorial from here and I know how to like fake it now again we can maybe add this as a bug report but what I want to clarify this so here and all right I want to understand is there a reason why you would ever do this or should it give me an error before I move on I need to feel it confident in that my understanding of it was this would just be a mistake and you don't actually put the input shape here because you you're gonna infer it from the units and if you put one there that's wrong it's gonna throw an error I'm waiting for K we c'mon maybe you guys are all um so yet tensorflow digest is brand new so I'm not surprised that there's things like that's always really tricky when you work with like Lauren even worked with p5 you're like oh did I make a mistake or a mistake in the library it's very hard to figure that out it helps when you're live streaming to an audience of lots of people who will help you I know it won't give me an error yeah it might mess with your network okay I think I'm gonna feel confident sort of in my thoughts here comedy I'm gonna go back sorry Matthew for the editing complication but hopefully this makes sense wait I would clarify something really important here because I I kind of put this in here as like a demonstration of some goofiness I was trying to like figure out but the input shape so a couple things let me first let me first mention something somebody in the chat just asked me oh isn't it 12 cuz there's four here and there's 3 here and 4 times 3 equals 12 well the number 12 a just sort of wrote that up too high the number 12 is an important one there are 12 connections meaning 12 Waits but this is now we're in the place of using the larious api that is specified for us we just need to say there are four here there are three here and we need to say there are two coming into here and there are four going into there so two is the input shape two here four is the input shape two here now I have this weird eight in my code because I was like kind of messing around like what happens if you put like the quote unquote incorrect input shape and so this really should if I want my network to be to match what I'm drawing there this should be a four but I don't need it because it can be inferred by here and I think what I'm going to do actually now to make this a little more readable is I think it's as much as I wanted to try to write this in a longwinded way I think I'm gonna take the configuration and just put it right here inside the creation of this layer and then I'm going to take this object I mean I don't need to name these objects and do this I think this is actually easier to follow so now you can see I think this is easier to follow right there's and I you know so there's the model there's the hidden layer the output layer I need to specify the input shape always of the first layer and maybe what I want to do is actually say add that hidden layer then create the output it doesn't really matter what order because I'm gonna compile everything so I have the create that let's review did I already do this I might have to do it again I need to create the sequential object I need to make whatever layers I want configure them add them in and then I need to compile it and notice compiling it I need both an optimizer which I created one stochastic gradient descent I could use the add a blonde or any of the other ones again what these are and what the formulas are there's a lot we could go down many different paths and rabbit holes for a lot of depth here but I'm just kind of looking at the higher level point of view here and then I need to compile it and with a loss function so me and squared error being one of them and I actually the all of the loss functions are listed out here this is where they are so for example so I can name it by the string or I can actually just reference the function name directly like this so this should also not give me any errors and you could see now that if I wanted to use like Oh cosine distance I heard that that's the loss function I should be using I could put that in here and I could also hit refresh again and now I'm using cosine distance so again what the different loss functions are why you should use one versus the other hopefully I might get into these things as I start building examples and have to make those decisions but right now I'm just looking at how you put it together okay um so this is going to be the layers tutorial part one I'm going to do a second part to this because all I've done right now is I've cream all I've done right now is I have created the model and I have compiled it the two things that I need to do with this is I need to send data through it I want to put data through it and look at the outputs what are the things I might want to do the two things I might want to do is use predict predict is a function where I give the model inputs and I get out of predict the outputs presumably I would only be doing predict after I've trained the model so I want to train the bottle with some training data it's finished then I can make predictions with new unknown data so how do I train the model I use a function called fit fit is a function that I can basically say I want to fit just like we had to in the linear regression example I had a lot of points and I had to find the line that fits those points I need to find all the weights of this machine learning neural network model that fit the data and guess what this is what tensorflow digest is going to do behind the scenes it's gonna do all of the stochastic gradient descent math it's going to use its own loss function everything underneath the hood so all the stuff I did in that building neural network from scratch now is now done for us by attention flow J s and it has many more sophisticated options so that's what's coming in the next video looking at fit and predict okay thanks okay alright how are we doing now it is 430 boy I'm way so I'm a little bit a lot on a half an hour overtime if you will just humor me for a second I have got to send some messages to make sure everything okay livestreaming will be done within an hour okay I'm looking at my email I should be looking at my you know okay so I definitely want to try to do the fit and and predict so I'm weirdly gonna do pretty I assume I could just predict even before I do fit which is silly but just to see it give me something okay all right Thank You Carson in the chat always nice to hear possible I really started off was rough today at the start my melon is all gone I'm out of my caffeinated beverage am i there's some more in here whoo there's plenty more in there oh good this might be what I need okay alright alright let me check the slack Channel and let's go let's move on ah let's move on alright very loud in the hallway can you hear that oh my goodness I guess no one's complaining about the sound yeah so I think some people are maybe watching for the first time what you're watching is my almost my like tutorial recording sessions or a lot of a little bit live and so the there are two ways you'll be able to watch this later one is as soon as I finish this we'll get archived online the full what is now two and a half hour long made possibly three hour livestream and then within a week or so edited versions of these different pieces and tutorials will come out add some comments to your code that is a very good idea Chris ray alright let's do that that's what I'm doing alright welcome to tension flow yes the layers API tutorial part 2 so previous previously on its flow test layers API part 1 I created this model using TF dot sequential TF layers and model dot compile with with a training with that with a loss function and an optimizer now let's just review that really quickly before I go onto the next step which is looking at fit and predict so I'm gonna add some comments thank you to the chat to suggest that so this is the model create the hidden layer add the layer and the hidden layer has a number of nodes input shape and an activation function which I think it's probably pretty selfexplanatory then the output layering is a dense layer so dense is a fully connected layer then the out create an output layer create another layer and here I'm gonna write here the input shape is inferred from the previous layer then an optimizer using gradient descent I must have a video somewhere that talks about what gradient descent is if that's not familiar to you and then I'm done configuring the model so compile it I don't know if this tutorial should include to be writing all these comments but it didn't so that's where we are so in a standard parser classic machine learning process I would configure my model well actually before I do any of this I should have like collected my data I've been really thoughtful about that and thought about the ethics of it and why am I doing this saying in the first place is this gonna help people or hurt people I should have been doing all of that but here I'm just looking at hedge fund is an API so I I'm kind of skipping those really fundamentals the most important parts I'm doing things backwards in a way and I'm just gonna make up data so what I want to do is there's two things one is I want to train the model I wanted to adjust all of its weights to fit my training data I have these inputs with these known outputs maybe I'm doing image classification I have all these labeled images cats dogs turtles and I want the model to output cats dogs or turtles some probability value is based on which things that thinks they are and then so that's what this fit function does I could also ask it to do predict which means just take this data I don't know what it is this is not part of my training data and just give me the output so let's do something weird I mean weirder then of what I'm already doing which is talking to myself in a room but the camera and some lights I have like an iPad weird stupid sound effects on it I don't know what's what's happened to me in my life anyway let's let's let's run predict without having trained the model will it actually just does it what does it start with it must have a whole bunch of randomly configured weights right must be configured itself randomly let's see if we can get some some output so what do I need to do to call predict let's go look at the API and let's look at I'm looking at TF sequential sorry I'm not in the right place hold on let's start this over let me get it sequential okay let's go look at the API and let's look at again TF sequential so I'm looking for the predict function now here's the thing to print out the predict function is there so it generates output predictions for the input samples model dot predict okay so config there are some configuration options like batch size and how verbose I want it to be but really all I need are the x's the x's are the inputs and i need two of them so what I'm going to do is I'm going to create a tensor I am going to say let input are abbess a Const inputs equals TF tensor one D and let's just give it some numbers like 0.5 0.25 sorry 0.25 0.93 it's a tiny two so I just made up some input C and look all fake not real data at all I'm just trying to look at how tensorflow da chance the layers API works so now I should be able to say model dot predict inputs now let's go back and look at this model dot predict TF one so interesting dip dip I guess I'm good okay so hold on so let's say let outputs equal model dot predict inputs and outputs dot print I don't know could it really be as simple as that let's see and so now I'm gonna go back here uncaught expected dense input to have two dimensions but got array with shape too oh boy I think I might have a big major mistake here let's think about this the input shape I have to think about this dimensions of inputs should match what did I good timing for the cameras to go off wonder what have I done wrong here is it oh it has to be this no cuz it the first to mention is the batch dimension that worked so then I don't have to say this then the shape is supposed to be 2 D should be 2 1 no oh so it's ok because in theory yeah I see ok ok I got it you go back to this error interesting yeah Wow this is this is tricky okay if it's totally true okay sorry all right huh I got an error here that's weird right this is actually Barry this is the kind of error you're going to live with if you continue down this road a lot which is like requires shape blah blah blah shape oh wait hold on so that's not the right air Wow okay all right so what is this error hope oh boy this is the kind of error you're gonna get a lot which is something is wrong with my like shape shape errors error when checking expected dance tense want input to have two dimensions but got array was shaped to what is wrong here I mean after all there are just two inputs I said very specifically that the input shape is onedimensional with two things in it so why is this wrong well it turns out I forgot about this idea of batching so it is quite uncommon or it's possible that you just want to send in a single data point like these two numbers in and get the prediction and so even though this is the array of the inputs that needs to live in an array itself because I might want to send in multiple sets of them and so actually the correct way for me to put this here is to actually have this be the first element in an array and actually this is not a 1d tensor then it's a 2d tensor so now if I run this we should see there we go this these are the outputs and we can see here every time I run it I'm gonna get different outputs because this particular model is initialized randomly now there's probably a way with the layers API that I could configure how the weights are initial initialize but it's using some default probably random maybe it's a normalized distribution of random numbers who knows we could look up the documentation somebody in the comments will tell me okay so but what's interesting about this is now right I could do I could have right I could now send in four inputs and what will I get out all of those results so these are the three output values for the first input the second input at third fourth so this is how the predict function works so I can create a model and I can start predictions now they're useless and pointless and random without me actually trading that model so that's what I need to do next fit there were some other things I wanted to say about this should I have said 1 comma 2 no 2 comma 1 try input shapes feet Oh is the live closed captioning on I was hoping I would get that feature unlocked for my channel could somebody send me a screenshot at that I'm just curious because I guess I could look at it myself but I would love to see how that works or like a gift for a little quick oh great err hair bow hair man in the chat is looking up alright so I'm gonna move on to Fitz I see that K tweaked mine is typing though so I'm just gonna if you have a 2d input shape you need a 3d tensor for ya ya ya ya ya for predict so it's always one for predicting fit okay okay so let's now create a scenario where we have some training data right this is my and and by the way there is this really important piece of working with machine learning where you have both training data testing data you can even actually go on validation data and then you have the new data the stuff that you're making guesses and predictions with I'm not getting that far into it yet but let's just in this case I'm just gonna have some training data I'm not gonna have any testing data although we'll see I mean we're gonna look at fit we're gonna see see how this all works so let me go back now to the to the the looking for where I was ah predict fit here we go so now I want to look at fit so here I look at this oh wait oh wait oh wait oh wait oh wait oh wait I just made some video tutorials about wait so one of the reasons why so working with tensorflow digests natively your one gonna feel somewhat comfortable with the idea of the JavaScript promise and these new es 8 keywords a weight and a sink so I will I'm gonna use those concepts you might want to check my promises playlist if that's new to you okay so let's figure out how we're gonna do this so model dot fit the parameters are X's x and y so here's the thing unlike here and I really should call these X's and this is really the Y's right this is really what I'm doing these are the X's and now I'm getting the Y's to fit I want to do the same thing the difference is I'm gonna have some known outputs so in this case I might have like this is my training data these are the X's and now the Y's are I need to make you know dreamily this would come from a spreadsheet or some type of actual database that I've thoughtfully collect thought about how it to collect and the data and what I'm doing with it but right now I'm just making up dummy data so you one of these eye supplies just put in random numbers like weirdly sort of lazy about this I like to you just sort of see it so let's just pretend my training dataset just has instead of four let's just have three things in it and let's let's just make some arbitrary okay so this is now my training data I have the X's right the X's are there are only two of them again if I were doing my like image classification example that I did previously in a in the with the toy narrow Network library I might have 784 inputs for 7 or 84 pixels but here it might made up scenarios two inputs and there's three outputs so the X's have two and the Y's have three and you can see that reflected here so now I should be saying model dot fit the x's and the Y's let's look here now here's the thing there are some there's this variable called history that's kind of interesting so let's say Const history equals model dot fit and I got to get into the weight and all that in a second so what the history is is that's an object that's returned that has lots of information about how the training is going like how accurate are things what happened there if I want to start like looking at the properties of the training what's the current lost that type of thing oh right these mismatch thank you so I just ran about three and three these have to match thank you to the chat for mentioning that to me okay so then I have this idea of batch size so batch size is let's look at that number of samples per gradient update if unspecified it will default to 32 so this has to do with the inner workings of how the gradient descent algorithm works right at some point gradient descent is going to look at the error and it's going to make all these adjustments to the weights and so does it does do that um does it do that after ten data points after 20 after 30 so I'm gonna ignore that and then epochs or epochs or I could never know how to know what to know how to pronounce that word is the number of times to iterate over the training data arrays it's optional I think the default is one so here's the thing I'm actually just gonna let this go without setting any of those those things are going to be certainly important hopefully as I get into future examples or as you have specific scenarios but basically I could add an object here that has things like that has various configuration properties and this would need to be a comma here but I'm going to skip that right now because I believe according to documentation config is completely optional so let's just run this and then I'm going to start talking about the asynchronous nature of this all right what happens if I say console dot log history let's just look at that so look at that I got a promise oh it's it's promising me something so what this means is fit is a function that executes asynchronously now it's possible I can do things with a kind of older style of JavaScript using callbacks because it looks like in the documentation here one of the one of the options I can specify as a callback but I'm gonna use promises so what I'm gonna do is I'm gonna say model dot fit then and what I want to look at is I don't know what I'm gonna just sort of see and in this case I think actually the way that I'm doing it I'm not I'm gonna look at what's sent into the promise so this should now this should be a way this is if it returns a promise I can figure out I can get the result of how its what it's done as an argument to a function that's executed when the promise is resolved so this is how this could look just to look at that history and you'll want to look at my promises videos if this syntax doesn't make sense to you and we can see here looks like oh I have a history object and I have a loss there we go so this is actually the response and what I want to look at is the response history dot loss index zero so looking at this there we go now what happens if I give it a lot of now what happens if I start to add in a configuration like because I'm really curious what happens if I say so let me let me actually use a variable call obviously they call it config and I'm gonna say it two things I want to add is I want to say verbose is true and I want to say a pox is five so because I don't see if it's verbose am I gonna get a lot of stuff in the console that's gonna tell me about what's going on so I want to add in some of those parameters verbose mode is not implemented yet oh okay so I guess I can't use it for Bost mode but I can add five and so this is just the loss after five let's add 100 point to negative point two so you can see it's pretty consistent it's some kind of getting about the same being sort of an arbitrary data all right pause I lost the chat I'm sorry I'm looking at the chat see if I missed anything super important EEP ox he box that's all I like to say it okay alright so how if I put this in a loop so let me ask a question to the chat what I want to do is put this in a loop and show the loss changing over time and so oh I have a trailing camera oh yeah oh yeah I'll fix that in a second yeah right why is it negative oh I have a cosine distance all right all right actually something weird was bothering me there for a second which is why do I have a negative loss like you can't have a negative mean squared error right mean squared error has to be positive it's the difference squared averaged over all the data points so I forgot that I still had cosine distance so let me put it back to mean squared error and now we can see that I'm getting something that looks like it could be mean squared error yes so one thing about this okay so I'm gonna get rid of this config actually not you let me go let's try to go back to when I first run this Co no it's fine it's fine what's a good right I'm gonna get rid of this config whoops I'm gonna get rid of this config because what I want to do is I want to look at how what if I want to like run whatever I want to sort of like watch the loss over time and I'm trying to think about the best way to do that but what I think I'm gonna do is I'm going to write a function myself called training train and I'm gonna put this and I'm gonna say Const history equals model dot fit and then I'm gonna add a weight and I'm gonna say async so by the way if I wanted so even though I was using a promise here this is a way that I can put model dot fit in an async function that I defined myself to sort of clean up the syntax a little bit and then I can say return history I guess this is silly is this silly but because what I want to do is call I want to call train recursively I think so I want to say train then ah yes this is exactly what I want to do so I need to just not use the arrow syntax for a second to just sort of figure this out so I want to say train then once I'm done training execute this function that gets the history I want to say console dot log history dot loss index zero and then I want to call train again oh no no and then I want to say yeah then I want to say return huh train oh I'm lost here how do I do this recursively within a promise this is an interesting problem do you see where I'm trying to do when it's done I want to and I'm gonna just add the arrow syntax here now I want to kind of like run train again I could just say then hmm pause for a second kay week nine is pointing me to an example of model dot fit look at this oh of course of course what am i doing the fact the reason why I want to move into an async function is now I can actually put a loop in here so this right the fact that I'm using a weight means I can actually put this here I don't need to return anything right this now what I could do here is I can say I can actually just call train like I don't need anything to happen but I'm going to say train then I think I want to go back hold on I have to figure this maybe figure uh I'm torn whether the whole figuring it out is like super useful or it actually makes more sense for me to like just go back and do this again because it's sort of a mess to edit yeah yeah a loop instead of recursion the recursion idea was like let me go back okay I'm gonna go all the way back to before I added the async function and I'm gonna go okay so now I have loss values that make more sense here's the thing though what I want to do is I want to do this a bunch of times like there's gonna be a lot of scenarios where I want to animate something as it's training I want to graph the loss function over time so how do I do this multiple times well I want to have a loop right I want to be able to say for I mean I could have multiple I could have multiple epochs so I could like add the configuration that gives me multiple epochs oh do I need to good but when I had before sorry but what I really want to do is this I want to just do one epoch at a time so this is weirdly work with like a loop I want to it's really awkward the way that I wrote this I feel like hold on I'm sorry did I delete something back here yeah like let me just run this for a second oh I'm missing another parentheses here sorry about this everybody this tutorial is a mess and 48 oh I had him there already ah zoomed in hey hold on a second let me try this again this one more time yeah that's right model dot fit I'm toil and this is where my brain starts to die yeah there should be another parentheses here there we go okay go back to the chat all right so now I'm getting lost values that make more sense and but what I really want to do is I want to see the lost values over time like as I'm fitting the model I'm running the training data in multiple times maybe I'm shuffling the order there's all sorts of things that I've done in previous videos that I want to do with tenth afloat yes so how do I have this model that fit multiple times I mean I could just call it twice right ooh oh it did not like that whoa Oh fascinating so I can't do that I don't know what's wrong with that but that's not really what I want to do anyway I could try to add a little work by the way the chat is really upset that I have these extra commas here so I'm gonna remove them JavaScript doesn't care it's like put your commas wherever you want like I had a lot of commas right oh no no no it doesn't want extra commas because it has blank entries but okay so so what if what if I were to put a loop here say like oh I want to do this two times so I want to fit the model twice again I got an error oh it really doesn't like this so here's the thing I I'm not exactly sure what this error is but uh maybe I'll somebody will tell me in the comments but I was going down a road I didn't want to go down this is where using wherever it was here in the tensorflow Dutch ass the await keyword is crucial so what I want to be able to do is I want to be able to call this fit inside a loop but promises just like everything's happening asynchronously becomes very hard to follow so actually what I really want to do is I want to go back to that syntax of saying Const history equals model dot fit and then this is what I want to do I want to say then console dot log history plus okay this is what I want this is like synchronous code blocking code this is what I want I want to fit the model and then see the results it won't do this because that's not how JavaScript works asynchronously so there is the awake keyword which is new at ESA which says hey wait for this and then to the next line of code right shouldn't that work whoops and a weight is only valid in an async function so again if you watch my async and await tutorials you would know this but I cannot just do this anywhere in my code I have to create a function a function with the keyword async I'm gonna call it train and I have to do this inside that so this is now the correct syntax this actually is valid but it's in an asynchronous function I have to call that function so I could just call train let's just run this now and oh cannot reap repartee zero of undefined and train so what do I have wrong let's put the X's and Y's in that function oh that's not the problem history hold on let's just let's just look at the history oh yeah it's their history o dot history right I forget you forgetting this is the response so it was fine actually history dot loss index zero so I just want to look at just the loss so these don't need to be in here these I don't want these in here so now we run this again there's the loss now here's the thing I also just want I'm just gonna put it then in here because I also want to have some sort of event for when the training is complete so this function now kind of magically returns a promise because of the way that await and async work so I want to make sure this is working great and now training is complete now guess what I can now do this I can do this ten times so I can now loop can go in here because of the beauty of this await syntax this is now work functions as if it's blocking code when it's all complete it will return a promise there we go we can see this is what we should have the loss should be going down right let's change that learning rate somewhere I set up a learning rate let's make the learning rate 0.5 you can see the loss is going down and maybe let's go back to 21 let's give it like a thousand basically a thousand iterations and we can see the loss is going down over time so and now what I could do I mean a thousand is a lot the training is now complete now what I could do is I can call remember this I can now call predict now again I'm only working with one data set my training data is my testing data is my validation data is my out by regular data that I'm using in the future once I'm done the model so but we now see the full process I have X's and Y's I can call model dot fit again this is a really hairy stuff not for the faint of heart I'm in the weeds of those sort of like lowerlevel tensorflow dot J s stuff I mean even though I'm in the layers API but using yes eight syntax but now we should be able to see let's take a look at oh and it's I'm gonna have an issue here where I have these Y's so I'm gonna call this I'm gonna call this outputs so let's take a look let's train it just a hundred times whoops oh whoa silly me look what happened cipher totally forgot about the asynchronous nature of all this stuff and I got the predictions before the training finished right because this is happening asynchronously which means what I want to do is after the training is complete then then I want to do my prediction so I want to train using the asynchronous training a hundred times then I want to do my prediction train train train train the coding trade and then let's look at this so how do these numbers match with what I said the the outputs should be yeah not so great not so great huh but you know I did my best maybe oops but really the issue here is simply that I'm the I'm working with such like fake for ten small arbitrary data that I can't really do any training an inference here in any meaningful way by the way inference is another word for what's happening here with this predict function but I'm hoping I mean I just wanna while I'm talking I I'll let this run one more time with like you know let's try three thousand three that training it and and let's actually let's try it with three thousand so I'm gonna let this the loss function go down so much further so okay so hopefully now you've seen right the first app I can't refresh the page until it's finished so while this is training hopefully now you've seen here that I have now in these two tutorials covered the basics just the basics of the layers API the layers API you can create a model or TF sequential or TF dot model that has some amount of layers that can be dense layers or other kinds of layers I haven't explored yet I can configure those layers I can add them I could compile the model and once that's done if I have data I can fit the model with that data and then I can ask for predictions with new data and this is what I'm hoping to do so I've got to come up with some actual realworld scenarios and the first thing I'm gonna do is a coding challenge would basically redo all this again is I'm going to try to just do the XOR problem so I have an XOR coding challenge already and I'm gonna do that so that video will be out at some point in the future or right now depending on when you're watching this let's go back and check so the loss got all the way down to 0.5 and we can see the outputs here 0.23 the outputs are very similar for each inputs so I'm just going to assume that the problem I'm having is just the fact that I have just this tiny little bit of data and I also trained it for a very very little bit of time and I might not but actually I want to look for the shuffle option before I go so that's really important I don't know if it's doing it by default by default when you are yeah in this fit there is an option called shuffle whether to shuffle the training data has no effect optional so the question is is the training data shuffled by default when you're training with the same data over and over again if you keep the data in the same order that can really be problematic in terms of how things work how well the it performs so I want to I want to add that so where where do I add that that's real that's important so right here I'm gonna add shuffle true so it's basically just a parameter just a one one print one a field of this configure an object where I want to say shuffle is true and let's just let's just do it a thousand times and go back and let's see if I get that loss much further down yeah not really I'm gonna do one more thing which is I'm going to add a pox 100 so each time through this I'm gonna do it a hundred times and then I'm gonna do that a hundred times so that should give me ten thousand times just to get it going further yeah I think I think this is a fool's errand I'm never gonna get this to produce overfit let's overfit my data so uh matsu we're gonna get rid of all this stuff from the end here all right whoo okay yeah that's like kind of point four point three point four can't remember what I said it was yeah I mean how could you this makes notes okay my data makes no sense so this ended and you could see this as a fools I'm at a fool's errand here it makes us it I got these like little three data points with two numbers in them and I'm trying to get three numbers out of each of those and train the model and then I've looked it's this is this is never gonna go anywhere so I'm gonna do this again in the XOR example you have one more idea just to make it I wanted to get a result that makes sense one more idea just give me give me a second here let's just change this model to have the output just have one output and so now the wise like I'm gonna say 0.1 0.1 I want that to give me like 0.9 and then I want to say like 0.9 0.9 I want that to give me point 1 and then I'm gonna say like 0.5 0.5 give me 0.25 so this is now going to be my data but simpler like I is it it has it like a very simple linear relationship so I think that I should be able to now I'm going to go back to one Apoc I'm going to do this just 200 times and we're going to now fit this model and here we go oh I really got it let's let's let's increase the learning rate man let's increase the learning rate let's do it let's do it a thousand times Teddy box each all right I'll be back in a little bit oh look at this look at that loss I finally got somewhere see this is the machine learning is hard all these parameters of what you're doing but this is going to end in a second I'll be back this can be sped up this can be sped up as its training over and over again this is so silly I don't need to watch this for the whole time by the way I'm gonna be gone going I'm not going to do the XOR thing today because it's already 520 and I'm late anybody have any idea where I am in the number of I got what would you estimate now how long is it gonna take me to get to oh there we go yeah look I need it do something I made it match the exactly over fitted my model basically but I made it match the exact output so my issues were really learning rate and the amount of time I gave it to train and that sort of stuff so hopefully now I'm really at the end of this video apologies that this was maybe a bit convoluted in terms of how it came together if it came together at all but now I've really completed my two tutorials on the layers API and in the next video I will do some coding challenges and actually use the layers API for some hopefully some more practical examples all right see you later good bye yeah Carson is giving me a good some good feedback I mean let me I I have like me I'm gonna go back to I'm gonna do this whole last section again just in case so let me go back just cuz there's a lot of mess there how am i doing this stuff twice so at some point oh right I'm gonna go I'm gonna go from here okay all right Matt you what I'm going to do now is we go all the way back back back back back back back back back to basically the first time I ran it pudding predict inside of here okay so I didn't weigh back back back back so I'm gonna do that okay alright here we go alright so this is running we can see that the loss is going down it's training over time and when it gets to the end I've got the results of my predictions now you can see these don't look very good like first of all these don't resemble these outputs at all the main issue here is that nothing here makes sense I just have the skeleton of the story of data I can fit I can create the model I can fit it with some data and I can ask it to run a prediction with that same data but I'm ignoring like really important considerations and you can see that machine learning isn't just magic it doesn't just do the right I don't care that was the right answer so let me at least before I go add a couple things to so that we can actually see that it got somewhere so one thing that I want to do is I'm gonna just simplify what's going on here I'm going to make this data something really obvious like zero zero one one point five point five that's my X's and then my Y's I'm gonna I want to get I want to get one I'm gonna just change that to just one output point five and zero whoops what I missed here yeah oh boy syntax there we go so what I'm doing here is I just try to like come up with some ridiculous scheme that's like super simple to learn like they're sort of like an inverse linear relationship here zero goes to one it's like the map eventually let's see if there's a neural network can learn the map function but in my using two numbers and one numbers here but whatever so now I am going to I have to change the output to have just one output and now let me run this so we could see look at this the loss function is still pretty high so there is something that's kind of important here you can see it's going down and actually it like a thousand iterations it it kind of got something it got something pretty close so I would just need to give it more time to train to kind of reproduce the known results but I just want to show a couple important things here one thing that's important is I probably should always shuffle the training data so there is actually a kind of important one of the configuration parameters here for the fit function like if I shuffle is true what this will do is whatever each X's and Y's are each time it puts it through the training function they'll do it in a different order and this will really help things as you're trading with the same data over and over and over again so let me add that in and just see what happens there so I'm gonna add this config here to here so this is shuffle true that's the only thing I've turned on doing one epoch at a time still so let's also while I'm here just to make things go a little faster let's add let's do like ten a pox at a time once again total here a thousand times 10 is 10,000 epochs right but because I want to see it over time I'm not just putting not just doing this once with the number 10,000 there I'm doing it ten I'm doing it a thousand times with ten but this what I think will make things move a little faster and we could say I got even better here and so now we can see this over time we can see that the the loss is really going quite far down now have to sit here and wait for a minute which I'm gonna do but you're not gonna have to this video will now speed up but his discussion is going on in the chat right now I'm gonna check my email while this is going Thank You grant Roz Marin for sponsoring my channel alright I'm back so look at this I reproduce those results right at reproduce the same results that my training data produces should have produced and I got the loss down pretty low so you can again completely meaningless trivial nonsense nothing but hope I'm just I'm hopefully this is helper to you it's helpful to me because I'm trying to figure out just how the library actually works itself so let's review for a second okay let's review everything I have shown you now these two videos that I can create an empty model right the diagram of my neural network architecture is an empty model then what I could do is I can create layers there can be dense layers or other kinds of layers that I might look at in another time in the future and I can add them the order that I add them is very important because it is a feedforward sequential model so this is first in this a second beef you know I'm thinking of this is hid in an output but they're really just layer 1 layer 2 ok once I've done that I have to define how what sort of mathematics are going to be used to train the model and there's a loss function mean squared errors what I'm choosing to use and opt an optimization function stochastic gradient descent with a learning rate of 0.1 that's everything from part one and now what I've done here is I've shown you okay if I have some data presumably coming in from a spreadsheet I turn those into tensors I can use the fit function to train the model I can say fit all of the weights with these X's in these Y's once that's complete I can then ask it to predict with presumably new data this skeleton has not used any meaningful data I'm also not really being thoughtful about like well what activation function makes sense or what optimization function makes sense different things work different scenarios so hopefully we'll see that more in the future as I make more videos I would encourage you to just try to do this maybe with some actual data play around with it try different input shapes activation functions play around a little bit see what you get let me know about the results in the comments let me know if this was helpful to you and I will see you next next video I'm gonna do I'm gonna look at that XOR problem again in the context of tensorflow doubts yes okay good bye alright everybody I don't know not sure if you're still watching thank you John you only look once if you were still watching this match yeah hopefully this could be put together and the fact that I did things that section and twenty one thing a little worried I did is I kind of recaps twice so he could cut out my earlier recap but uh you want to seem to figure this out so but if this is really problematic this last section I can always do that again alright everybody unfortunately because I have to go home I don't have time maybe I could bring the stuff home with me I don't have time to live stream the my experiments with these life I've my brain some so brain dead right now so so yeah Sarah much in the patron group and the slack asks who is matchymatchy ax is math blank and match it is the coding train I don't know what the title should be but video editor coding train channel organizer manager extraordinaire oh the sound effect was glitching the sound effects are glitching again tell me if they are sorry this is might hurt your ears turn your volume down three two one so yeah is that gonna be a problem why does that happen after like a while I think it's to do it though where these cables are it sounded kind of find that alright you have nothing changes at all except you have consistent commas at the end oh shoot that's gonna drive people crazy yes choppy I'm so confused by all the chat stuff that's going on you know it sometimes the glitching is actually just in the live stream and the the video that I'm recording might not have the glitching that's a wish that might be wishful thinking but that's happened before that's probably wishful thinking because hold on this is gonna it's gonna glitch again okay but I'm gonna I'm gonna listen to my monitor three two one oh boy that I'm really loud I'm listening it's that well three two one yeah so I'm just gonna at the moment hope that the glitching is not in a recorded video so when this gets edited all right I have to go there's so much activity going on in all these different chats I can't keep track of anything I'm completely braindead this is suddenly but this isn't happening like a four hour livestream so you know how I said I was gonna do two live streams a week I want it I was doing that because I wanted to do two hours at a time twice instead of four hours because everything goes you know I really like this is uh I didn't do a good job of like this is how I feel right now so but this was to live streams this week because I did it for like four hours and I will see you all next week probably Friday not Tuesday possibly Wednesday not Thursday possibly Friday so so yeah okay I got to go I'm gonna play the outro and see you all well usually I try to answer some questions and stuff like that but it's already 530 I just can't I will train I wish I had that ukulele so I could sing you out but I will load the train whistle still waiting for the water ripples and tfj s that might never happen at this point but I really interested in that I will come back and do that I mean maybe I'll do that when I get to like convolutional neural networks pick you on the fastest station will make things that are all creation you you