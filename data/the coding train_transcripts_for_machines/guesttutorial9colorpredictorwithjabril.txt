hello welcome to another guest video on the coding train today I have a very exciting guest for you Cabrillo from SEF science I'm probably saying that wrong gibreel told me like 10 different times how to say it I still couldn't get it right anyway gibreel is awesome I'm a big fan of his YouTube channel he actually came to visit NYU for a whole week and did a workshop and a talk and made a project and it's been sort of been an inspiring presence to have here for all this time and any what you're about to watch is an edited version of a live stream that the two of us did he is going to create or talk about a project that he recently made in JavaScript with his own from scratch neural network code where he makes a color predictor and in fact if you're interested in more about the color predictor you can click on well you can't click on that but I know it's something will come up over here that will maybe suggest that video over there the two of us made together for his channel so enjoy gibreel stay tuned later this week I will do my own coding challenge to try to make my own color predictor so we'll see how that goes thanks gibreel and for being here and hope you enjoy this edited version of the live stream we did together thanks very much alright howdy everyone how is it going so yeah I'm going to give a little brief overview about Who I am for those of you that do not know which I'm sure is all of you so my name is Jibril I run a little YouTube channel called girls here on YouTube and recently I converted my channel to focus on computer science that happened in September and that was probably one of the best things I've ever done because I learned that you know I had a great passion for writing code and write and making products and projects that were based on computer science and so yeah I mean obviously if I had a passion for that it was easy to show that in video projects as well and fast forward so one of the the biggest projects that I've produced to date is the run forest project that got a lot of eyes really grateful for and that really harnessed the power of machine learning which is a really big buzzword these days but yeah that's pretty much the overview I spend about nine months learning how to write learning algorithms from scratch because it was something AI is really cool to me I think and so yeah the rainforest was released and today today what we're gonna do is we're going to examine this really simple JavaScript machine learning application kind of how it was done it's another machine learning application written wrote from scratch so we're gonna take a look at the code and all that good stuff so let's let's get into this so here we have this example it's what I call a color predictor neural network to demo and it ask you a simple question that is white or black look better over this color and so the color is within the circle and it's randomly generated okay so what's important for us to start before we can get into the application we have to understand the the main computational part of this application so we have a color and as you know colors are they're represented as a vector of three or sometimes four if you include the Alpha but we're not including the Alpha we're only going to use the RGB values so we have our inputs which is three is that own friend yes all right so we have red green and blue and these are values between 0 and 255 for each input so we need to build a neural network that will be able to take these inputs and then do a computation on them and then pass into an outputs to predict if it looks better over black or white so let's first draw our outputs just make sure it's all in frame yes that's good and this is going to be it predicts black and this predicts white so now we need a hidden layer is what we call hidden layer with artificial neural networks in the middle that does the computation part and this is our guests and so we are just going to arbitrarily just duplicate the same size of our inputs for our hidden layer we're just gonna say three it's a good place to start if we're really serious about this we could expand it try five try seven and just log the results for all of them and see which one works the best but where it's going to say three for this example make it nice and simple and so we have our RGB and if we go back to our example what's happening here is there's a computation that happens within our network to three one two three one two three and then feel free to interrupt if you think that I'm a little offbase with anything uhhuh uhhuh uhhuh okay so this what did I just do it looks really confusing but it's actually really simple so we we need to somehow get our inputs computation and into our outputs and the way that we do that is we use what I'm using bubbles to represent what are called weights within our known network and so every single node within our hidden layer has the same amount of weights as there are inputs so what that means is there's one way for this input there's one way for this input and there's one way for this input and the same for the rest of them one weight for this input one way for this input one way for that input and repeat I didn't do that right boom boom and so what then happens is that we pass this through we do our input times the weight and then plus our bias and we could repeat the process this will give us a value let's say that we after we compute all these sum them up add a bias it will give us let's just say 0.5 and then we'll pass that to our outputs which is 3 uhhuh uhhuh boom passes to our output and then that will give us a value for each of these let's say this is 0.3 and then point seven and then it's just as simple as we'll just say that this is higher 0.7 so it's guessing white so that's a quick overview on what's going on here with we're gonna Daniel's going to post a a more indepth tutorial on this or you already have or well so I have tutorials yes like this that people could go back so this is you know the same kind of structure that I've used in my neural network library correct yes and I'm I was thinking at some point maybe next week hopefully I might try to recreate your project as like a coding challenge okay so we can put a link to yours okay so we'll put a link to Daniel Shipman series and what she goes in depth with this so if you want to learn more about what's going on here but that's a quick overview on the math on the computation so our inputs it gets times about weight and biases then we get a value and we pass that to our output same computation and then gives us a prediction so oh yeah let's do it all right is does the input have to be from 0 to 255 okay sure inputs have to be normalized what's the from 0 to 1 yes great question great question so again I just glossed over this but so normalizing inputs for colors is actually really simple and it is always best to normalize your your input data so because we know that the the domain for a color value is always going to be 1 the 256 or in computer languages we shift that by 1 0 255 we can simply just divide whenever this value is over 255 and that will remap this between 0 and 1 and so essentially when you're writing your program you would just pass the input through a function that would just divide about 255 so yes great question I have one more question so I'm kind of curious about this too but I sort of think it's probably ok it's with the pressure before you ask it yeah but is there a benefit to having two output nodes it rather than just have one since there's a that's like a ranger to negative one and yes so there's a lot of debate on this and I I and I agree with the side that it's easier when you have like classifiers versus like if you have just one output node that is mapped between negative 1 and 1 and right and then if it's if it's above 1 0 then it's going to be white if it's below 0 then it's going to be black yeah based on the research that I've read it's always best to go on a classifier yeah like maybe this would be fine in the case of there's only two labels or two classes right or the correct correct it's gonna be problematic and so that's all like demonstration and learning even though this might be a very like basic scenario it's useful to demonstrate the multiple outputs cuz you're gonna need to do that if you were to expand this for correcting and to the whole reason for that is because what what happens when you separate them is you get probabilities versus like you get a map of between 0 & 1 which again if it's one output you can get away with that but if you try and encode your outputs using this for like 30 different the neural network might not make good sense of that oh cool so let's let's continue on let's look at some of the code as to how we went about writing that part of our neural network suite so we set up our variables are jeebies our input data and then so one thing that's really important that I should go over just to just to make sense of what's going on here is so so it's really important in order for you to write your algorithm you need to you need to know how to compute this compute both of these so this is really just an array of values so we can call this array G of I right so this is G of 0 and this is G of 1 and G just stands for a guess I put 0 G of 1 right and so we want to know what does G of I or what does G of 0 what the G of one equal how can we get that equation well if we look at our diagram for our network it's actually quite simple so G of I which again is this array this output layer G of I equals the summation of hidden layer this is going to be hidden layer by I and this is going to be inputs of I that's how we define each of these vectors so G of I equals a summation of H L hidden layer and then we have to go into another loop because we can't use the same indicee of I and J because it yeah it won't return the right value so hidden layer of J which is just gonna be 0 1 2 times the weight of G of I right and then we simply just add our bias of G of I and so this is the equation that we can use to compute each of our output nodes and so just to clarify what's going on here this is summation symbol which simply means to add up all within the the array so hidden layer J times the weight this is a function which simply just grabs the weight of whatever output node you're on so if you pass G of 0 for example to do this weight function it will just grab whatever bias or I'm sorry whatever weight of G of I is there so that's actually G of I of J actually hereby up J huh so now we have this equation that tells us exactly what these values equal so now we don't know what HL j equals so we also have to define HL of J and we go about doing that by doing the same exact process after the super hio of I for indices same exact process summation of our inputs right inputs what I use InP inputs J times weight of HL of I so the same exact input we need H ll by M and then we simply just pass our bias and again this this right here is a function all it does is it grabs the bias for whatever node that we pass through it so bias of HL y mmm and there we have it we have our entire equation because we know exactly what inputs input of J equals it's going to be simply the random value of our color and so this is what we need to write in our software okay so same exact thing that you see on the board is what we write here in our code so first before we can get the what the guess no zico we have to first forget what the hidden layer nodes equals so simply put as we did um on the white board hidden layer 0 equals we'll get to what Ray Lu is in a second but hidden there 0 equals we did our input encoder which was a question that was asked earlier about normalizing our input data so this function simply just divides our input divided by Oh 255 and then we'll times that by the weight of our of our hidden layer so this this is an array function that I will go over really quickly that we instantiate to hold all of our weights so color predictor 0 0 0 I'll go over this I think it's important so so the function color predictor variable uhhuh so there's all these for it dimensions to it and I think it's interesting or it's important to go over what the dimensions mean so let's just get two and then let's just do I don't know one so what does this mean if you have color predictor eyes ero to one what does that mean well well so we want to store these arrays into our color predictor variable and we can go about doing that by defining the location of all of these so if the hidden layer is going to be 0 and then the guess is going to be 1 right and so all the notes are then going to have their own assignments so 0 1 and then 2 same here this is going to be 0 and 1 and then the weights are also gonna have their own assignment as well so 0 1 2 3 and the same day 0 1 2 3 and we repeat that for every single weight inside of the nodes right and so how this works is our color predictor is if we want to get grab reference to 0 that is going to be hidden layer and then 2 is going to be the last node and then 1 is going to be the the second way because start 0 1 second way so this variable is grabbing a reference to this way that's exactly what color predictor is 0 to 1 is doing and so you see this eye that's an extra dimension that you might be confused about so let's talk about that real briefly so this so you see this extra eye and what does that mean so traditionally traditionally with such an example you would use back propagation to Train this no network however time was a factor and as well as that we wanted to go over lesson of both neural networks and genetic algorithms so why not combine them together is what we did for this example so that eye is actually just grabbing a reference to what predictor we are currently using so genetic algorithms real quick you have to have a halation yet the assigned Fitness scores to every single what's sorting for the creature within the population and then you have to mutate them and breed them in XY and Z so we have a population of 800 predictors at four at start and then they all have randomly initialized weights and biases which again just to make sure it clear are all of these values waitwaitwait by swim away bias these are all randomly initialized the function that we use for this program is randomized between zero and one and then they all based on their randomly initialized weights we'll make a guess on which one they think is correct and so most of them said that black is the correct color that looks best over this randomized color and then we simply just use a genetic algorithm to train this this predictor to converge on the best possible predictor and yet that's it that's a general overview on this the code is available on github and I left a lot of comments however that it will require a bit more in depth if you if you really want to like get a full grasp on this from learn and have fun knowing absolutely nothing if you already know some stuff about no numbers between learning I'm pretty sure this example is pretty straightforward from you but the benefit of doing of writing neural networks from scratch is that you really have a good grasp on what's going on behind the scenes versus using libraries and you're able to debug you know different problems that might arise when you are writing your no networks would be it from scratch or using libraries that is pretty much a we we do have plans to update it with the actual back propagation algorithm in there so that you can learn from that as well so let me a few more questions okay let's see what I can find here Oh for some first people had asked to is the code already at github are you're gonna on github are you gonna update oh yeah I I slept oh so stay tuned whenever whenever it's on github I will come back and edit the description for this livestream and put a link to but they can currently go to Steph's of the comic /color oh that the link that I use right yeah so you can go to let's let me zoom in here and show you so this one yes if you want to grab the code right now I don't know why whenever I paste links into the YouTube chat they don't seem to work for that interest so but anyway so I would paste this into the chat but that wouldn't even work so you can see it yeah up there that you can grab the code now but I will also include a link to github repository whatever that and it is my intention I think one of the reasons why I love this demo and people are kind of asking this a bit in the chat was like oh like do you really need a neural network for this right and I don't I think to me that I mean that's a perfectly valid and interesting question and probably the answer is no you don't need a neural network for this but when learning about neural networks when trying to build your own machine learning project if you can start with a welldefined small and scoped problem then you can really figure out and because you in some ways I do this similarly with that you're so my genetic algorithm problem projects I take a example where I know the answer right so I can see if the genetic algorithm worked because ultimately what I want to do is use a neural network or a genetic algorithm in some domain where maybe I don't know the answer I couldn't solve right so easily but to figure out how those things work I've got to come up with and so this is a really nice problem for that because it's simple small in scope and for people who want to do creative coding and graphics and design stuff it's got color and then and not to mention once you learn how to do this stuff from scratch this is easily be scalable for the most part you still have to worry about some other stuff like vanishing gradients and stuff like that but most part you can take this and scale this up and it'll work just about the same so there's also that benefit as well so here's a question from I am rashon on Twitter this is a big question ok let's do it I don't know and I think this is a question I've certainly touched on and but how is a I let me read the question how it actually is written how is AI different from a neural network or deep learning or machine learning they often seem to be used interchangeably and cause confusion so first of all I want to say like and I struggle with this question all the time because there's all these different terms so we so let me list those terms artificial intelligence deep learning machine learning and then I might put neural network in a like different category but that's another term as well I don't know if you have a kind of like way that you describe these the terminology of people when they ask those kind of yeah I'd like to start with English is difficult I like to start there but for the most part AI is it's like a grab all for everything a I like you can hard code AI you don't have to use machine learning so that that's kind of like they grab all for at all and then what was the other the code words would so oh boy all these things are coming in AI machine learning deep learning neural network yeah and so machine learning I think it's like the next level down so you don't need to use a neural network to do machine learning there are different ways you can go about teaching a machine how to learn one really good example is decision trees people have developed really complex decision trees and the machine just kind of explores the space and learns the best way to use this this is injury so that's another way of applying machine learning and then would you say neural network and defining yes yeah so no networks is essentially what we showed and even that's kind of to the bay because like recurrent node networks are no networks but they're not really you know neural networks you know if that makes sense so I don't know it's it's if you say no network people will know what you're talking with in most part all right I'm gonna try to give my take on this let's do it let's do it that work to me is a particular algorithm that involves connected nodes that and data flows from one node to the other they're coming different architectures and styles and so that neural network data structure algorithm can be applied in the field of artificial intelligence machine learning and deep learning but neural network is an example of a particular algorithm I would say you could sort of think of it also as a data structure but there's an algorithm there in terms of how the data flows through the structure so that's what that's what I think and then I think that artificial to me artificial intelligence I think that is a very broad umbrella terms are just the big field of like simulated intelligence rather is that is it real intelligence is it the illusion of intelligence is that the same things like kind of a deep philosophical question and then I machine learning to me is a subfield of artificial intelligence involving making sense of data mmhmm so you have data and that's input to a system and you have some output which might be making sense of that data whether it's a prediction for something it's gonna happen in the future or a classification of something and then then I think of deep learning as a kind of read almost like a modern rebranding of machinery with neural networks it's like hey we have bigger datasets now and faster computers now all of a sudden the things that people researched many years ago called neural networks that nobody thought could really do anything or they thought good but couldn't now all the sudden we can do more of them with and so it's really just like it's not meant to be marketing but it's kind of like marketing this idea of big data under all networks and yeah III agree I think it's a lot of the marketing side of things because you'll reach so many different posts like what's their deep learning in machine learning yeah it has two hidden layers that's it yeah like literally I think it's more the marketing side my personal opinion but that's awesome cool well let me see if we have any other oh yeah neural network I like this definition neural network is a universal function approach semadar hi Emily this is actually like a really this is Robin I'm gonna hello let's try this oh this is crazy talk now now I'm coming over here I actually think this is really kind of a good way to think about it I was thinking about this the other day because what if we made like function color predictor and we just had like an if statement in there like and you give it a color so if the brightness blah blah blah of that color is greater than some value then you should put black on that color or white on that color otherwise so this is like a hardcoded function that takes inputs and returns an output right and so we could we could write a lot of if statements we could get really crazy complicated about this we could come up with a whole set of rules and a neural network in a way as a thing that you could put in here to kind of learn to return the value according to in a more mysterious way in a way like in a sense it can learn it could it acts so in a way like does do neural networks in machine learning replace coding right I don't think of them as we're plate maybe someday they will in some weird way but I think of it as like they don't replace coding but they can replace our act as a function in your code so that function that you might have hardcoded a lot of if statements can now have a machine learning system in it take some inputs and generate an output yeah I agree I mean when it's all said and done algorithms are input instructions output yeah and you're just replacing the engine Bert yeah totally thank you so much gibreel for being here for your for participating in the livestream for showing me your color predictor so much inspiration all week I don't know if you know this why you should know this but gibreel only started working with machine learning less than a year ago completely selftaught wrote his own neural network from scratch and JavaScript he did it in unity he's got a whole video project he made on his channel in unity just amazing really inspiring stuff so make sure you subscribe to his channel link in the description below click that alarm bell icon subscribed him on Twitter check out his website all that stuff will be in this video's description stay tuned for later this week I am going to attempt to make my own version of the color predictor with my toy neural network JavaScript library so that will come in as a coding challenge so stay tuned for that and I'll see you in the future good bye