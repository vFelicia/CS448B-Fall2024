hello this is the first video in a series of videos I'm making about the Microsoft Kinect this thing so what is this thing how does it work and how do you write your own software that makes use of this thing how can you do all sorts of creative coding projects now there's a lot of different programming languages environments and frameworks and libraries for how you might make use the Kinect I'm going to use this thing called processing processing 3 the third edition version of processing which is a Java based programming environment open source environment that there is a connect several different connect libraries for eventually I will hope to make a video where I look at p5.js which is a JavaScript framework for doing creative coding in the browser and how might you get the stuff from the Kinect what is this thing called the Kinect in the browser itself which I think will be an exciting thing to see as well but in this first video what I want to do when I get into the code really in the next video and what I want to do in this video is give you an overview so what are the different editions of the Kinect there's a bunch of different ones that you could buy what are the pieces that you need how do you get the library to make use of the Kinect that sort of stuff and you can see I have a basic example that's running behind me with the Kinect version 2 and I will talk through the pieces of this code so first let's think about the different versions of the Kinect so this is this one here Refik glasses I'm gonna this one is the 14 model 14 14 this one is the and I'm going to I'm going to come over here and try not to trip over to myself and I got to grab this eraser for a second so let's make a list here so the two key pieces of information for you or you need to decide are you using the Kinect version one or the Kinect version two I'm probably gonna get lots of stuff wrong here that you can write in the continent so I'll put little annotations on the YouTube video that fix them but hopefully I'll get things loosely right so the original Kinect version one model 1414 is the one that came out I think I was new number 201112 somewhere around there I remember the weekend it came out people people were quoteunquote hacking it but really just making but about hacking at I need making opensource drivers to to read the data driver being a thing that your computer runs to talk to the hardware device and so when that came out a library I worked on the library called open connect for processing and the reason why it's called open connect is because it's making use of the open connect an open connect an open source a driver for for connecting to the connect which is also known as a Lib free net so this is sort of the genesis of all of this the thing that I built for processing is just a thin layer on top of work that lots of lots of other people did which allows you to get the data from the connect now let's come back to the connect like what is it's over here and then I'll get to the other editions in a second like what is this thing so this is the original connect and you can see here that there are three little circles on here it's like a little nice little friend with three eyeballs and what do each of these eyeballs do so one of them if we a camera oh oh Schiffman you i suck at making these videos okay I'm just going to go anyway okay so this is the connect uh and it has three little eyeballs one of which is an infrared projector so this is this is what the 1414 does and I'll talk a little bit about any a different marker here what happens once you get to the connect version to how that works differently it has an infrared projector which sends out infrared light into the room then it has what I would call you know could call it a sensor or a camera but it has an infrared camera to read the infrared light Pacific in the room what is infrared light it's you know light that's all around us but is it visible somebody with a physics degree could explain that better but this is blasting out infrared light this infrared camera is reading it so what what is the value of doing this so that interesting is the kind of light that it's passing out is actually a whole lot of infrared dots it's projecting a lot of infrared dots into the room it looks like this and it's a very specific pattern of dots and the Kinect itself it knows what that pattern of dots is supposed to look like so it's that pattern of dots if I have the Kinect here it's blasting infrared light lands on a flat surface the infrared camera that's reading where those dots landed that's seeing those dots reflecting back is going to see like oh it matches exactly the pattern of dots that I know that's a flat surface but if this surface was curved those dots will appear distorted by analyzing that distortion the Kinect can recognize what things are closer and what things are further away so the value of this is it is often referred to you can think of it as a depth camera or a depth sensor this is what this infrared projector and infrared camera are doing they're measuring the depth in of each pixel in the room so while a regular web camera says here's a 640 by 480 image each pixel has a red green and blue value and it's beautiful isn't it the colors of the rainbow or the hair in this image the Kinect is saying I see I don't see RGB what I see is I see a pixel and instead of telling you what color that pixel is I'm going to tell you how far is that pixel away from the sensor and this is incredibly valuable in computer vision you know one of the classic computer vision problems that people try to solve is background removal you know that's why I have this green screen okay I have to go underneath this here okay I have the obstacle course in my office I'm going underneath this to turn this camera back on and I'm coming back underneath I have this hello I have this I have this green screen here behind me you can see and so the camera is saying every green pixel remove it and put the stuff from the computer behind it but if I had a Kinect I don't have to say look for the green pixels behind me I can just say look for any pixel that's farther than two feet or something out of centimeters I'm trying to be a metric I'm trying to be metric I want to be a metric person but I'm not so you could remove you could you can analyze things makes it really easy to find a human being in the room because the human being has a certain kind of shape it makes it really easy to do quick and dirty 3d scanning there's lots and lots of possibilities of what you can do once you have access to the depth now there was this third little eye here and this by the way is just an RGB camera so one of the things the Kinect can also do is just see the colors in the room so in addition to having this infrared camera it has an RGB camera now there's a bit of a problem here which is that notice how both of these things are not in the same place so the infrared camera sees the depth of a given pixel at a different place that the RGB camera sees that color so this is an alignment problem a calibration problem where the the color pixels don't necessarily line up exactly with the depth pixels and there are lots of strategies for solving this problem and lots of frameworks and libraries in particular the official Microsoft SDK which has on things baked into it that do this for you but one of the nice things that we'll see once we get to the Kinect Veet version 2 is it has something called a registered image which is an image that aligns the depth pixels with the color pixels okay so this is what the Kinect does and I really described here what the Kinect version 1 does there was also a model 1473 that came out I don't know a year or two later um this one has some problems in particular there's a little bit of a bug with currently with running it with the processing library although it does work kind of only will work every other time can't figure it out for the life of me so but both of these will work with the library what you need to look for the library is the version 1 examples so that's that now in between here there was like this Kinect for Windows and I think this was like a version of the Kinect that the Microsoft made to plug into like Windows computers originally this was designed for use with the Xbox for a game for games that you would play by you know dancing I'm kicking my leg by the way if you can't see that and but then Microsoft realized there's I don't know what my what's in Microsoft's cases but I've speculating here but that to make a version that's designed to work with just regular old laptops and computers I'm not sure if this one works with the processing library but more recently and I have this one plugged in and like mounted on the wall over there so I can't hold it up and show it to you the Kinect version 2 is a newer and quite significant upgrade from the first Kinect and it actually uses a completely different technique it uses infrared light but it uses a technique called timeofflight so it sends the infrared light out measures how long it takes for it to bounce back and that how long that takes let's the sensor know how far away things are kind of like a bat maybe does stuff with sound to see I don't know yeah dolphins do stuff like that but all the sound so with light bouncing it back and forth the new Kinect does that and I suppose it's a bit more accurate it's faster and the RGB camera is also in the new Kinect is higher resolution okay so that's the basics overview and if I come back over here you can see now now I'm running an example I have the Kinect right over here you can't see it I could I could maybe like turn like kind of like if I hold it up over here can there you go there it is this is the new one I'm gonna put it back that felt like a little scary like everything was going to fall over and you can see now that what you're seeing in this particular image is an example of a processing sketch which is rendering all of the pieces of what the library what the Kinect offers now oh but I have something more to mention about this but I'll get to that in a second so up top you can see that's just the RGB image so it's like I have a webcam over here I have a webcam over here high webcam that sort of thing right so that's the webcam that's the RGB camera and it's actually I believe I didn't actually check but it's a pretty high resolution image down below this is the raw feed of what the infrared camera is seeing so this is what the infrared camera is seeing and it uses that to extrapolate depth so mostly just looks like this creepy thing but you can make use of that you can get that image as well up top at the top right this is what's known as the depth image so the what the Kinect is measuring is in millimeters it's measuring a value between 0 and 4500 how far is the thing away from the camera and then often a depth image is used to visualize that data so in this case you can see as I start to go further and further back I get brighter as I start to come closer and closer I get darker so it's mapping the the color of every pixel to how far away it is and you can see just from a standpoint now how much easier that might be to pick out my hand right because my hand is the only thing that has this very very dark color as opposed to other things now there is something funny in the back what's up there up oh that's a window I was like what about black square up there that's how window that's the door you can see in all sorts of things inside inside this room that you may not have seen before and then down in the bottom right this is the registered image so this is not part of you use the version one connect with the open connected library this is not part of that however it with version 2 this is the image that aligns all of the RGB values from the webcam with the depth value so if you wanted to hopefully it's something I might be able to demonstrate it in some video is just do background removal where you see only me and I take I get rid of all the pixels that are behind me um that might be something that I could do here with that particular image oh did the oh the laptop went to sleep come back wake up okay so a couple more things so what I want to show you now is how do you get this library to run this like this particular example so a couple things one is here's the I put all this in the description of the video this is the URL the the library is at github.com slash Schiffman open connect for processing you don't need to go to that URL but that's where the source code is there's a little bit of documentation there I want to make give a big THANK YOU to Tomas Sanchez lending I might not have pronounced his last name correctly he wrote all the code for making this library work with the connect version two so I worked on to the version one number of years ago and sort of floundered and Thomas came back and revived this and really helped over the summer and there is also I have a little page that has some additional documentation it's Schiffman dotnet slash P 5 / connect and you know this is some text that kind of goes through the different versions and some of these examples as well that I'm going to cover in the videos now in order to get the actual library itself what you need to do is go to one first you need to download processing if you don't have that already that's at processing org then what you'll need to do is once you have processing it might look just like this to you something empty you're going to go to sketch import library add library now you can see that I have already knife three libraries here I already have that library but I'm going to pretend that I don't for a second I'm going to go to add library which opens up this contributions manager I can type in connect right here and this is something really quite important now to bring up so there are several different libraries there is by the way something called simple open and I which is an older library open and I was an open source platform open source framework for doing skeleton tracking meaning finding of human form where the hands are where the head is which is very very powerful and things that you can do with the Kinect I'm starting with just the raw depth data but open and I think was purchased by Apple have been kind of like shut down as an open thing but there are some efforts to revive it and so you could Google around and that's something that you could possibly use I'll try to include some links but you can see that it's currently this simple open eye it's no longer compatible with processing 3 that's why it's grayed out Connect v2 for processing this is a library that makes use of the Microsoft official SDK and I'm going to demonstrate that using a PC in a later video this is a key this is a really great thing to use if you want to get all of the magic that Microsoft has spent all this time developing so what the Kinect just gives you is raw depth theta raw RGB data but what the Microsoft SDK does is it pulls that data in and on and it analyzes it and finds where's the human being like what kind of muscle are they making like where's their head like is their hand open or closed and it's so much through a layer of analysis on the raw def data that will give you a ton of information so but for that you do need to use a Windows machine of course there are some strategies for like sending the data from windows chained to another machine to like a WebSocket what's a WebSocket all sorts of stuff but we'll come to that in a later video and so those would be the two libraries that but the library I'm using today which you know is already installed you can see by the green checkmark you would just need to click it and click this install button and it would download and install that this is the library I'm using today it uses open source drivers it only looks at the raw depth data so this is good for a bunch of different kind of creative applications that I hope to show you in the next set of videos so this was a long rambling 16 minute explanation about the connect that you may or may not have found useful or interesting but I imagine you've already turned it off if you didn't and in the next video what I will demonstrate is is just how to write a program that gets that depth image and once it I mean bring that back oh it's not running here get gets that depth image and maybe visualizes that depth image in some way so that's where we'll start I'm going to look at a couple other scenarios along the way as well okay and so thanks for being here and watching and talk to you soon