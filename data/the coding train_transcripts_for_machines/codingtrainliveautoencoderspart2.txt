do do do do hello test one two i hope my audio is coming through please let me know in the chat uh in discord in youtube by carrier pigeon smoke signal however you could possibly reach me please let me know apologies for all the stops and starts today i will be beginning in just a few minutes assuming my audio is coming through loud and clear okay see you in a moment momentum hello happy saturday to the coding train with me miner internet personality dan shipman i am the host of the coding train i'm coding train i am coming to you live i know it's some kind of miracle that i'm here right now uh i don't know how this is gonna last i better just very quickly say thank you to curiositystream for sponsoring today's live stream you can get access to all of the documentaries amazing documentaries on curiosity stream as well as the nebula everything that's on nebula can i tell you about something that's on nebula right now let me tell you something that's on nebula right now hold on a sec on nebula right now is let's go to my library right here look at this this particular video which is going to come out probably hopefully by tomorrow on youtube still finishing up but if you want to get some early access to this particular video along with all sorts of other amazing stuff you could get you can sign up the whole year of curiosity stream and nebula um at that link 26 off i think that's 14.79 for the whole year amazing amazing you should totally check out all the documentaries and all the youtube creators that are on uh nebula okay uh the stream's still working so at least i got that out um and what am i here to do today well if you might remember a week or so ago and i'm look just checking the chat here to see if people are watching i'm not seeing any messages which is a little bit weird if i'm being perfectly honest so hopefully i'm not just speaking into a vacuum but um i've been working on a project to create an auto encoder using javascript with the tensorflow.js library library in node.js and i would like to finish that today so this is part two um if you were looking for part one if i come back to here i really don't see any chat messages this is very strange okay codementlike says hi i'm cars waves okay people are there you're there oh thank goodness not very many of you probably because i've totally botched this in the sense that i was supposed to stream this morning at 10 a.m and i had scheduled it i'm using discord events now so you should sign up for the coding train discord somebody post that link into the chat and then i make an event and you know what time and you can like register your interest you'll get a reminder all the things i've always been wanting for wanting to have and then i was like no i can't stream because my internet wasn't working i'm in a garage which is a detached garage from my main house which is where my new studio is and i'm going to be here all the time every day all day starting in january 2022 lots of plans um so i'm working on getting this place wired and uh powered by solar energy so uh uh i disconnected uh i'm gonna say i uh obviously hired people to do a lot of this work but the uh electro electrics was disconnected to this building and then a trend we dug a trench to wire electrics of the house so they could put solar panels here to power the house and the garage ran coax and cat5 underground uh put it in a splitter so i can have internet in both and for whatever reason i can't get internet both to work and i discovered that if i just turn off the internet to the house right now it seems to work here in the garage so that's my temporary solution at least for today to get this live stream in on saturday november 20th and finish off this project ah i was trying to figure find where i was i was here to show you uh part one so this doesn't say part one but you can see oh and look at this so this is also by the way available here i just haven't released it yet it should be out tomorrow i'm just got a lot of slowness here but i'm logged into my account which is why i see it i'm very excited about this video can you please post the discord in the chat i'm gonna go ahead and do that um since uh no one else got around to it just yet and i believe that should be oh my god i posted the wrong link uh discord okay um it's discord dot gg slash coding train okay so um what was i looking for oh so that's part one if you watch part one great you're in the right place if you didn't watch part one well i'll recap it a little bit as i get into um working on the project so i need to find my way back to where i was before let me open up processing because i was using processing to generate the images that i want to um use to train the model and i need to i don't need this and i need to get all right let me just switch myself back over here while i'm getting various windows set up so um let's see um talk amongst yourselves for a minute please you know normally you would think i would have this all set up before i begin streaming i don't know why i'm hiding this from you i'm just opening up so my item and i think the project is in the auto encoder tf demo let's open this up in in visual studio code all right okay let's go back to the auto encoder keras page which is sort of my a model my tutorial that i am following and uh hi bruno hi adrian hi embark hi sorel i'm seeing some nice messages in the chat welcome a bunch of people are joining in that's great um so what do i how am i going to get started here so first let's see if my whiteboard is still working oh looks like i need to work on the focus there and wow it's so i think it's brighter in here today the sun is out so i do get some sunlight in this room so first thing i need to do is focus this camera i think that's better right i think i just focused it let me go back and look here looks better yeah that looks like it's in focus now oh and i need to ah uh okay hold on everyone i'm going back to here i also want to record this session to disc just in case the thought experiment is you know do you really later if you're not here live with me right now part of the process of figuring it out together would you really want to come back and watch four hours of live streaming about building an auto encoder project maybe but my thought is if i can get everything recorded to disk then perhaps i can succinctly package this in like a 30 to 45 minute video which skips a lot of the rambling and all that kind of stuff so let me uh i need to i'm kind of like shocked that i'm doing this because as of this morning i was like i'm just gonna reschedule this to like november 30th so i just need to check my settings here um output streaming recording indistinguishable quality large file size well no wonder high quality medium file size i forgot that i done this start recording so i recorded last session to disk and i looked at the file afterwards and it was 57 gigabytes because i'm recording a 4k uh video to disc which has all of the different it has um just the laptop feed it has me actually me just with the green screen um and it has the whiteboard if i had the ipad here i have a ipad a hookup but it's not hooked up right now so this is my new setup i'm obviously still trying to build up momentum thank you to everybody's patience kindness and consideration as i try to figure out i feel like the coding train is going to be born anew in 2022. that rhymes which is quite lovely okay i've got a little bit of coffee left um i've got to get back to my children but i'm giving myself till 3 30. it's 90 minutes i'm recording to disc um and thank you to all of your thank you sorel you are here with me i appreciate it all right little straw poll here i'm gonna put a little straw poll into the chat um did you watch part one just to give me a sense of who watched part one i can't see by the way who's answering so you know it's not like you know did you study for the test and you don't want to admit it like i would like to know the real information here so uh in the chat now should be a poll asking whether you watched part one or not and as i kind of get um let's just see if things are still working here it looks good um i'm just sort of checking out my code from before still seems to be running um that's fine there but this i term needs to be a little bit more over ah come on i term why do you do me like that okay i think that should be good and then processing i don't actually know that i'm even going to need i actually will want this for sure i just realized okay um i also remember um k weekman how would you like to be referred to like i do it all sorts of different ways but i remember you saying that um i should reconsider maybe the optimizer or the loss function i'm using um so again the my my sort of working sort of uh the working philosophy here right now is just to get all the pieces plugged in and then i want to add more layers and sort of think more thoughtfully about the various hyper parameters of the system that i'm building and then also hook it up to p5 so i can see the results in the browser oh by 3 30 today no problem there's probably gonna be a part three i'm being perfectly honest um but um i seem to recall you had left some comments in the discord um so i let me make sure i come back and revisit that although maybe i'm not going to right now i am seeing the poll results that uh 60 of you 73 people have voted 61 percent of you have did not watch part one and 39 of you did watch part one so i think this means uh this swings the pendulum for me i'm gonna give you a quick recap of kind of everything i did in part one and let's um let's put a timer on here let's time box this uh 10 minute timer so i don't want to allow myself more than 10 minutes where oh what's i'm using up so much of my time just to put this in the page here okay okay so there's my 10 minute timer i don't want to i want to be starting on the new stuff by the time that hits zero okay um so quickly i am very interested in machine learning generative machine learning models models that generate synthetic images text perhaps sound other kinds of media uh if you have been following the world of deep learning today the what you probably have heard of is something like oh again or stylegan or stylegand2 or stylegand3 and then there's this like latent space oh all these images are in the latent space and i can walk through the latent space and look at this ai is dreaming about cats in a style gantu layton space of all cats cats and many more cats if you have no idea what any of that means how could you possibly get started to learn some of the vocabulary feel comfortable with working with these systems even if you're ultimately just an end user of pretrained models you're not designing and training the models yourself for me the process of me trying to sort out how all this stuff works and understand be able to read the style gand paper and maybe understand a bit more about it begins with auto encoders an auto encoder is a very simple um well i don't shouldn't say very simple because none of this is particularly simple but it is a good starting point to think about how generative models work and uh the last live stream i went through building this whole diagram to talk about how we could build something called a copying machine out of a neural network so if an image is sent into the neural network if we could just get that same image back out then somehow the neural network would have learned some type of like represent internal representation of that image in a way that it can reproduce it so obviously to copy an image is a simple well this is a simple process with an algorithm i can just say for every pixel make a new image take an existing image for every pixel put the new pixel in the new image so the auto encoder is not an efficient copying machine but it does give us this ability to copy the image while also compressing the data because the idea is if we start if i have a 28 by 28 image with 784 pixels as the data moves through these layers of the neural network we have fewer like i have 784 inputs the first layer might only have half of that in neurons and then another layer might have half of that and then so these numbers have to somehow be compressed into a smaller amount of numbers that then get expanded back out to the original image so this is like a copying machine and an image compression engine it is not an efficient image compression engine because if we really want to do image compression to save high resolution image with less file space on a on our hard drive we could just use jpeg or other kind of known tried and true image compression algorithms but if we are able to take the these images compress them down and have the neural network the auto code to learn how to uh decode them right we have an encoder and a decoder then at some point and hopefully i'll get to this part today i can take off after i've trained it i can take out the encoder and just start with the decoder feed in noise and generate new images in the style of the original training data set or i could do certain kinds of operations like image denoising for example what if i sent a noisy image in right if these are all the the example i'm using is i'm just using geometric shapes so if the auto encoder learns the internal and internal representation of what it means to render a square if i send in a noisy square it will then take that and in theory rerender it back out without the noise that's the idea so this is what i'm working with i went through this diagram i probably in a much longer period of time and then um looked at if i come back over here um and i see some comments so hold on come back over here now and i've still got five minutes left in my recap of before and if i come back here what was i trying to say francois yes okay so this is an article from 2016 so quite a while ago where i first encountered the idea of an autoencoder this encoder and decoder this original input compressed representation reconstructed input the output is the reconstructed input and there is sort of a guide here explanation as well as a guide for how to build these layers using a library called keras which was a sort of higher level which is some i should know this maybe somebody in the chat could could kind of explain but like does keras still exist or is it really just now fully integrated into tensorflow and not called keras anymore but when keras was first developed it was a kind of higher level layer if you will above lower level machine learning libraries so you could say things like create a neural network with this kind of architecture in keras in a sort of higher level way and you could plug tensorflow into it to do the actual lower level institution or pi torch or other ones so the way i know and work with keras is by working in tensorflow js which i want to look at the um this is i want to i think it's just like js.tensorflow um let's see if this yeah um and i want to go to the api um in the tensorflow.js api there is a particular set of functions objects that are part of the layers that are called layers tf.layers layers model sequential layers here we go and this is a net this is essentially the uh original modeled after or directly ported from the keras python library oh i hear somebody hello take a short intermission i've got uh i've got a visitor help me right be right back i'm just putting on intermission and i'll be right back music okay i'm back okay i'm back um oh oh i need to stretch all right um i disconnected the internet in the house which is causing some some problems but we're gonna we're all we're all gonna get through this together uh okay um i forgot where i was well i was talking about uh tensorflow.js so oh and you don't see that now let me come back here so the code that i began to write is as follows so obviously i went through this in greater detail in the previous stream but i've got a node i'm eventually going to turn this into a web server but this is just a node script ultimately right now a little node project where i'm creating a sequential model that is exactly i'm trying to recreate this exact model in code now i'm calling it an autoencoder because that's the application that i'm doing it starts with an encoder which is a dense layer that receives 784 inputs because my images are going to be 28 by 28 i'm arbitrarily having it be 32 units then it decodes back to 784 it's just those it's this is like it's just two layers just uh one layer for the encoder and one layer for the decoder and then i've set up an optimizer a loss function these are things i also talked about in the previous i've only got a minute left here in my recap so you know i can touch on those as we go and then i just fed it with random noise so where i left off is i now would like to and i have this processing sketch which generates a variety of square images of squares i have those hopefully if i could find them here in a folder called data so now i would like to feed the auto encoder these actual images expand the number of layers um and um i'm reading the chat yeah so my uh things are complicated these days for me as they are for everybody my kids are home i disconnected their internet my wife is out of town so um they're having a couple hours of free time um but um and i wanted to get this out of the way because oh oh my god what is beeping at me oh it's the timer do you hear that i'm like what's happening there's a paper going on uh okay okay okay i got you we're gonna get started with the code uh whoops um but i know i've lost track of what i'm saying but i i've got lots of things to do with them tomorrow next week through thanksgiving and so i was just if i could just do this stream today then i can kind of figure everything out next week so here i am um hi computational mama in the chat so um um let's see okay how are we all feeling about that any questions about uh what i've covered so far before i get started here and i'm thinking i'm going to need to read in the images how do i want to read in the images um anybody got a suggestion for a node package that i should use i mean i could use just the file system package to read the files then i need to unpack them into their pixels and turn those into tensors oh gloria pickle oh you know what now i'm feeling kind of guilty but she was out all day uh earlier today with me as i was going around and we had a nice walk she's in her sleeping in her crate she's she's crate trained she loves her great she feels very safe in there if there's ever a try about my dog by the way not my daughter who gets your confused my children are free range right now in the house the dog i often have her with me but she's sleeping in her crate um i was about to say like um that's her favorite spot like if there's a thunderstorm she's terrified she just wants to be in her crate so she sleeps in her crate at night very comfortable there but i don't want to leave her there for more than a couple hours then i need to let her out after her nap to roam free outside and be here okay i want to make me some coffee after watching but don't want to leave the stream l.a noob um i really think l.a noob you should uh make yourself some coffee you're not going to miss anything trust me got a couple minutes to make some coffee i really doubt you're going to miss anything critical all right can you restate what you need to do with the files okay i need i have all these images i want to load them so i want to write let's write some pseudo code i'm going to do it right here i'm going to write a function i will call it load images i am going to load all image files in the data folder read the pixels convert the pixels to tensors for tfjs so this is what i need to do i know how to do the last stop because i'm familiar with tensorflow.js it's stuff that i've done i know how to load image files in general i would use the node file system package okay the door open you got your phone you're good does it it'll connect automatically right okay okay um it's a little chilly in there because i didn't turn the heat on but you can turn the heat on if you want um the thermostat on the wall it's a little thing you just go there you're closing the door okay um okay so i could use the file system package and the file system package allows me to load files let's just what no no just turn it to like 70 where it says 70. i think it's a good number um so let's see so let's see load read image pixels node.js get an array of pixels from an image using node.js image pixels get pixels i just feel like um jimp i could use the jimp package and this seems promising javascript image manipulation program an image processing live preferred node written entirely javascript with zero dependencies this is good does it support promises doesn't look like using promises yes okay this looks good there's no no so helmer yeah i gotta talk about this no internet no heat this is a detached garage and it is um i'm trying to get all the stuff in here to make it more livable i mean we don't live in the garage but to have some more loungy relaxing space we have a ping pong table to have enough like power and internet to power my coding train stuff but you know i don't run the heat in here all day because we're not in here and that would be very wasteful anyway how do you all feel about this jimp library i think this is looking good for me so i am going to give it a try until someone tells me not to do it npm install jimp uh yep so let's run that so i'm now loading this package okay great by the way i'm always curious it always says though some of the packages are looking for funding so i'm always good to support open source projects so see there's some of the open source projects that i'm using somehow through these dependencies um maybe i will come back to that later um now up there goes to see the heats on so now that's the boiler going so hopefully that doesn't mess my audio up too much ammon in the chat on pixel data in oh i could just use tensorflow.js to load the pixel data oh tf image that's a great point okay i should probably use that great point okay so this was interesting to explore but let's um let's look at i forgot about that thank you for that that is a great note so let's go to tf.image yeah look at this extra but does it look will it load an image for me so these are all operations if hold on what does it expect like it expects an image does it expect like like an image html image element all right let's see uh from pixels uh this is all stuff happening in the from pixels yeah ah okay there is the from pixels function oh but this is all only in the browser so i'm not in the browser right now i mean i could be doing all this in the browser tf image decode okay image.decode how come i didn't see that tf image decode i don't see that as a function tf io decode image interesting oh but this is tensorflow not tf yeah so it doesn't look like some of those that like decoding an image file is present here um it probably wants to work with images from the browser check this out what i just sent should work says cirelli so the thing is like of course we could improve this later um image data right so the parameters are image data so uh pixel data image data image data can i use this in yeah this is all canvas stuff so i'm kind of in headless mode right now so i sort of feel like node.js canvas image data so i could use the node canvas module so i could use node canvas and then load an image what's the load image function oh okay ah all right maybe i should do that maybe that makes sense uh so all right this is interesting let's try this because the other reason to do this is it'll translate nicely to working in p5 but i'm a little bit skeptical of this working in node but i'll give myself a little bit of time let's try installing canvas so um let's comment all this stuff out right now come back to it so and let's say import how do i do an import with this can i do this import how do i do this is it like this could that possibly be right uh um all right so let's see um import create let's just see okay so now let's try load image let's make this an async function data square 0 0 0. yeah and then see what happens so i'm just testing this canvas load image function to see if it will load the file um import from and see what happens okay is it really called canvas it's not called node canvas but okay create canvas not found import oh i see let's try this okay look at this image 28 by 28 data square complete huh okay this is interesting import star as canvas i don't think my my uh import is right so hold on is this this work now i don't know how to use these es6 imports so for whatever reason this works but this is not the correct way to do it i'll have to revisit that later i'm so used to using require okay so um first of all let's just for a minute here um i just want to no i guess i want to leave tf.js loaded for right now it is that what is its console logging there yeah okay so now if i want to load all the images um i mean i could use file system to like figure that out but i'm just going to hard code this um i have how many i have a hundred um and then let's make this a template literal and so how do i do number formatting in node is that native oh there's numeral all right let's try numeral this looks cool and this might be over overkill for what i need to do but import load image from canvas what if i want to import more than one thing um okay so now let's see uh how do i use numeral uh import if i want to like call it uh nl for numeral i don't know uh and then nl this this might not actually be format okay uh nli format um this is like the format i want is ah so it's that's the format i want so now this i think this should give me all of the file names i to string pad start okay okay import abc from x yeah um thank you for all these helpful tips in the chat uh okay i'm i'm running out of space here let's see if i can get myself some more room okay so then let's just do console.log image let's just do 10 images to start see if this works no no no so numeral i didn't need because i could just do it with string let's try did i did i install numeral i did so how come this didn't work import numeral from numeral maybe it's that load image is not a function didn't like this pour it i don't know what how did i get it working okay so i'm doing things in some awkward unnecessary ways like first of all i don't need this numeral package because i could just use like number to string or something but it works nicely for me and i don't understand why i'm doing it this way uh import mode image that no i don't i still don't understand how es i should read up on how these uh import statements work but this works um yeah i tried that import load image from canvas all right look watch i don't want to get stuck on this stuff but right i believe this should work and it's not so you got me as to why that doesn't work but this is working okay so now the question is can i then uh the point of this was to convert them to tensors um now from pixels image uh t no not wait so i've loaded them the problem is with browser so i don't have a browser i should just have done it the way i was starting to do it uh uh yeah yes that's a good um so just out of curiosity i'm gonna take sorel's i'm probably mispronouncing your name import and then i could say it's a little bit more verbose yeah i i'm lost but also how do i convert it now to a tensor can i just say see this is what i want to do but i don't think it's going to let me it's not a function can i get this to work from node just added support to tf from pixels in node it's from 2018. this supposedly this should work according to this am i in the wrong version of tf.js somehow do i need core fixed tf from pixels you know why supposedly tf from pixels is not a function must have changed so let me just see which version am i using three is this somehow like different if it's like should be fine no this is the node version so did that go away oh tf image no i mean can i just put the browser in there and it'll figure it out is it as simple as that did i forget just pixels passed to tf browser must other be image data in brower hmm i should go back to my original solution oh tf from pixels was deprecated [Laughter] i should just go back to my original solution i'm going to go back to my original solution i'm using gym because i really don't i can make a tensor very easily with this small amount of data we could come back if there's like a more efficient way of doing this let's just go back to jimp or i could probably read the pixels just with node canvas but um which might be useful because then if i want to ever just do this in the browser but so let's not do it this way well actually what if i just can i just read the pixels here this is what comes up first in my search image data imagedata.data is it there is it there do i have the pixels no it's such a weird thing for it to console log yeah sean this is such a good question i don't really know why i started doing i was kind of imagining that at some point i wanted to like process huge amounts of data and like i don't know there's not really a good reason it's just kind of where i started because it was easier for me to sort of like work it out um and i could just use the file system like i said this is sort of silly i could come back to get image data i said i have to draw it as i go okay all right all right i've gone far enough with this silly way okay get array of pixels from an image file um image pixel color okay right this is where i started okay great so we're going to use promises and we're going to read so import jimp i don't know maybe that's right um and then um now we should be able to say let's just try this just real quick and oh no let's see what happens here jim dot read is not a function i don't know how to import anything okay we got something decoders how do i okay uh oh okay instead of using require ah there we go oh just as simple as that okay i over complicated it okay oh and look it drew the it redrew the image great okay so this is working uh let's go back boy boy this stuff takes forever okay so just to just to figure out where we are for a moment and um i'm gonna take a short break in a second um to check on my daughter and talk about curiosity stream but um this is where we are let's see um i am currently just trying to load the image to read the pixels to put it into a tensor and i'm going to say this now and the question is how do i where is the jimp documentation contain scale auto crop crop blit composite mask convolute flip pixelate displace clone resize align looking for like pixels okay no there's got to be a way to just read the pixels directly to get the pixels as an array some neighbor pixels boy i'm making this so hard let's see if this gives us anything can use data all right that's promising there's get base64 get buffer get pixel color well that's kind of useful but i don't want to go through and get the pixel colors one at a time undefined wasn't there something called data oh bitmap bitmap okay there's the raw data of the image get buffer let's see what this looks like mine must be a string i got some weird error there that didn't work i can't believe how much trouble i have in getting the pixels am i really gonna get the pixels one at a time all right let's just do it this is so crazy what i'm doing get pixel color j comma k what oh pixel's i doesn't even mean anything okay sorry um this is me reconstructing the pixel array oh what what are you doing automating things for me that i don't want you to do this actually makes kind of sense this bit image scan hey wait armor is giving me something scan is that from jimp uh here's a good reference your your url probably won't work sorrell so this is giving me the probably like the integer um this bitmap data this is in the gymp documentation oh image.scan thank you okay um a scan ah scan a region image bitmap data got it got it got it got it okay okay let's see scan jimp enables low volume of images and memory through the bitmap property of each jimp object why is this this is so weird our jeez this is so this is so insane how much this is like driving me crazy like how much i'm getting stuck in this this makes you want to go back to the browser all right let's let's go for this this is really weird but scans a region of the bitmap and calls the function f on every pixel um but couldn't i just do this myself it's the is the date hold on a second bitmap data okay so let me just try something let r equal image bitmap data zero is it just can i operate the bitmap like an array ah there we go this was so easy oh i'm such a dummy okay okay there we go so now i can do um but uh index equals zero index i'm just gonna i know it's everything's 28 by 28 so i'm just hard coding it in you just use n and then the actual pixel the actual index is n times four the r is is n plus zero n plus one n plus 2 but i'm not doing an rgb image so i can just use the r and now if i console log r i could oh i could just use the map function but i'll raw date i'm just gonna make an array so i could do some kind of higher order array function to just like do and i've got i could basically turn the bitmap into a tensor directly but since i've got grayscale images that's probably what i should do actually but i'm just going to say raw data just for now raw data n equals r and then console log raw data okay great so this is all of the raw grayscale values there we go we're getting somewhere so now uh remember when i was doing this before i uh though these are the x inputs so this generate image we returned a function so um train model x train i'm just sorry i'm a little lost here oh okay so x inputs so loading all the images we have x inputs and then x inputs index i is that raw data so basically i'm loading every single image into an array and then putting it in my x inputs array because and i can take all this other stuff out because and let's get rid of the random one because when it's time to train the get the training data so this i need a curly bracket there to close this out then the training data is a tensor out of all of these images and then i'm not going to call train model just yet but let's sort of see i is not found why is i not found oh right because this does need to be in here there we go okay so now that's one image as a tensor so now i can actually go ahead and load all 100 images okay i loaded 100 images into those tensors by the way the reason why you're seeing 255 everywhere is those images are all white around the edges and all of the the data that wouldn't be 255 should be dot dot yeah i need to refactor this stuff chris is saying should make getting the raw data into a separate function absolutely so i will refactor this later but now i should be able to say await train model and let's see what happens here oh uh oh x train is not defined oh because i made that those global okay well here i'm going to just be very silly about i need to rethink how all these functions are organized remember this is something i talked about last last time this is very weird why are my inputs and my outputs the training data this is unique to this auto encoder problem where instead of like an image classification problem where i would have a whole bunch of images paired with their target labels those images the the training the correct output for each image is that image itself okay let me come over here and so something happened i don't get what this loss is it's a negative number i'm a little confused by that um but this is also so few images so i think i'm at a good place where now i can just take a short break i'm gonna turn the heat on for a little bit to warm it up in here and so the things that i need to do after i take this short break are let me make more images let me think about the hyper parameters and configuration of this network like if i just like right now if i just change this to the encoder having 784 units interesting i wonder i need to think about the learning rate the loss i don't know what's going on here exactly i need to rethink the hyper parameters normalize the data thank you aman ah why did i forget why did i forget that thank you all right let me do that quickly so important i forgot to normalize the data no wonder it's like exploding there we go okay we're getting somewhere the loss is like a number that makes sense now it started with 0.683 went all the way down to 0.1 i could try more epochs but i'm going to get more data i'm going to um you know just uh i should be able to get a loss of zero essentially if i have 700 yeah look at this look at that oh the loss that's going on i mean of course they've defeated the purpose by not actually compressing the data but okay warming up then that's what i'm about to do all right okay okay thank you thank you i forgot to normalize the data okay everybody i'm i'm really close now this was a lot a lot of time that i spent like trying to just figure out how to load the images sorry for all of those um kind of strange tangents and different libraries this is still kind of awkward and weird but the fact that the data can be read from the file with jimp and then the actual pixel information is just in this bitmap.data property this this could definitely be improved but it's getting me all the way there now okay so um um i want to uh take a break for a minute uh before i take my break let me thank today's sponsor oh the sponsor um this is uh uh this a sponsor is curiosity stream and i i some of you probably weren't here at the beginning of the live stream where i showed this to you so curiosity stream i'm just gonna quickly play this brief ad for you from curiosity stream directly so you can learn all about what curiosity's stream is but don't go away because after i play this i'm going to talk to you about why you should sign up through my link coding train to get access to some extra cool stuff from another thing called nebula so just hold your horses here we go from the founder of discovery channel comes a new independent streaming service curiosity stream home of groundbreaking documentaries and awardwinning original series follow your curiosity this is curiosity stream oh i'm really i'm so getting fired i know okay okay so i'm talking to you so at least that start over start over i'm exit exit stage right i'm coming back don't make don't make don't don't everybody sign up so don't get fired okay hello everyone uh you just saw that wonderful 30 second promo about curiosity stream which is one of my favorite streaming services because it is chock full of so many wonderful educational documentaries the things that i like to watch the most is all the nature stuff um so we can see here just realm of the volga whoa the volga flows 2 000 miles oh i've got to check this one out um i was just saying that um one of the ones that i have watched with my kids that i really love which was under here under kids is ancient earth which is uh all about life that existed in the permian triassic and cretaceous periods so right and hudu says even without the sound i want to watch that sea lion show so just curiosity stream if you sign up through my link and i believe if i go slash coding train it'll sort of show us that because i'm already logged in so if i wasn't logged in it would have a nice little banner at the top that says you get 26 off of the annual subscription that comes to 14.79 it's barely over a dolla uh barely over a dollar per month at 14.79 for the entire year but i think the thing that i really want to tell you that i'm really excited about is this is a bundle so if you sign up for curiosity stream bundle through the link you will also get access to nebula so nebula is a streaming service built by youtube creators many of my favorites here if i go to my library there's some that i'm following um renee ritchie um if you like ai and want uh machine learning want to learn more about machine learning you should definitely be checking out jordan harrid's videos there's some other ones that are here um in my and look at this all of these uh daniel shiffman coding train videos and in particular one of the things that you get with nebula is early access and so this is a video that isn't yet out on the channel will be hopefully tomorrow if you want early access to it the full um um the full um if you want early access to it you'll you'll get that through the nebula bundle so so many wonderful creators um the other thing that you know a lot of this stuff is also on youtube but it's without ads on nebula um and um there are all these wonderful nebula originals so um this is a really awesome um uh like compilation of different creators i i wonder if i could make one of these i don't know but each uh different creators on youtube they're all making videos about the opening title sequences of different um television shows so um you can see renee ritchie did one about buffy the vampire slayer we've got soap's notes one about pokemon oh i've got to check this out so all these these originals are really just wonderful i'm just like poking through to look for some other ones um a big fan of legal eagle so you got this all of this bad law words good so uh so mikhail is asking did he say built by youtube creators or youtube's creators no built by creators so everyone that you see here on nebula participated in the making of nebula itself um and um um it you know this isn't really true for me but i know that one of the benefits for many youtube creators of nebula is certain kinds of content a lot of the um like historical um videos um that um certain kinds of content can't be on youtube it will get demonetized or it will get sort of um uh just if it's about a kind of a kind of topic like about you know world war ii for example so um i'm not saying this very eloquently but creators are free basically on to publish certain kinds of videos on nebula that would might cost them issues on youtube itself so that's one of the motivations as well as all these originals about being able to have no ads so you can get this for free not for free well you get it for free if you sign up for the oh oh i'm so be gonna get fired i'm really basically like i i i'm just i just got a cop to it today has been such a mess for me i had this all planned out this morning and everything i knew i wanted to say and do in this live stream i really do love this service nebula i participated it i'm i'm it's it's meaningful to me and it's like as i get to become uh spend more and more time on coding train i'm really hoping that come this january i'm gonna be able to dive more into nebula and make some maybe make a nebula original myself so if you want to get involved learn more about it also support the coding train itself get access to this incredible library of documentaries you can go right now to um curiositystream.com codingtrain that's the link right there keradostream.com codingtrain um thank you everybody for uh tolerating this like really terrible sponsor read i'm gonna do better next time i'm to take a like a two or three minute break you can sign up now if you have nothing to do in this two or three minutes i'll be right back to finish off this auto encoder project i'm gonna go feel bad about myself over there now be right back so all right i have returned i took some deep breaths did a very short 20second meditation and john says well you got me to sign up so you didn't do too badly all right um those are those pity sign ups i appreciate it um all right let me get back into what we're all here for which is my building of an auto encoder all right so i think we're really close here to actually seeing some images generated from the auto encoder now if i wanted to go all the way through with this i would i want to eventually reconnect this back to the browser itself i mean maybe i should just have the model in the browser i don't really need a node server so um maybe run the training i'm not really sure where i want to go with this ultimately it so turns out but i do want to see the results of the auto encoder in the browser and start to understand how to manipulate the latent space but my goal for today given that i would like to wrap this up in about 20 to 30 minutes is to simply see an image generated from the auto encoder even just one so i'm trying to decide i think it would be worth me putting in a few more layers um so i mean i suppose like maybe i don't need to worry about improving this so much and let's just work with what i've got which is a hundred images um let's see what happens if i give it a 100 epochs and i'm just going to go down i'm going to compress the 784 pixels down to 64. oh and mikhail is asking a great great question in his image loading he's normalizing the pixels to between zero and one but all the tf tutorials i've seen use negative one to one is there any practical difference or just personal preference i would love to know the answer to that question um i think at the moment because i'm using this output i'm using the sigmoid function as the output activation function it's got to be between zero and one because the um the outputs are only going to be between zero and one with sigmoid but if i were using tan h then i could have outputs between negative one and one has to do with the um so but again i'm kind of flying blind i'm just sort of like throwing all the spaghetti at the wall to see what sticks just trying to get something working that i can go back and kind of finetune more thoughtfully um i don't need to print this out anymore let's just try uh training this let's see what happens with the loss so the loss seems to settle at um with a probably settled around 100 epochs at 0.07 that's great so could i now if i wanted to generate an image from this let's go back to the original so i i'm done with sort of like part two and a half of three parts this is in three parts part one was just building the auto encoder giving it noisy data part two a was getting actual data into the auto encoder part two b is looking at the results of the autoencoder after it's been trained so if i'm coming back to this what did uh what did this tutorial do and i'm not having any test data yeah right this is also by the way normalizing between zero and one decoded images oh using predict okay so if i can use predict to see okay great so let's do this let's follow this so i want to use predict let's refactor this a little bit to make it less weird okay so also known as the scientific method yeah um so let's let's get a little bit better here so basically i want to have a fun i'm going to write a function called like main which is a little bit silly fungshom function function and it's going to be an async function and the things that i'm going to do in it are load all image data convert image data to a tensor train the model uh uh test the model so i've done everything but this last step of test the model so this async function load images i can just say return x inputs so let's just call this all images and return all images so first thing i'm going to say is const images equals await load images okay then and there was a question about why this is a 2d tensor i'll talk about that if the data is flattened into one dimension i will talk about that in a moment so let's do this does this need an await no it doesn't so that's the trading data i should save some to be testing data but i'll just worry about that later i'm just going to reuse this is very bad idea very bad idea but i'm going to reuse some of the training data for my testing of the model we could separate out we can get new data later i promise and then training the model is as follows let's write a function called async train model and we're going to get data in so i'm going to say await async function a weight train model with x train and then is auto encoder still just a global variable yeah so you know it would make sense for me also to have a function that is build model so basically well auto encoder is a sequential model the build model function puts all the stuff into it why i'm i'm so i should be calling build model first the model what did i do wrong here there we go so let's bring this up here build model auto encoder again i'm not so sure this really makes a lot of sense the way i'm doing this um so now i need to pass this business arguments um this is pretty arbitrary what i'm doing but i'm trying to get rid of sort of global variables and so now i've created the sequential model i think actually i'd like to do this and then return it so what am i doing i am build the model load the image data convert the image data to a tensor so that i can train the model with that data then and let's just make sure this all still runs oh i think i have to call this function all right so everything still works everything still works training the model then i would like to test the model so i need one image so all the images are here so what i could do let's do the following let's be a little more rigorous about this i'm going to rerun my uh training data creation and make 500 images 550 images oh let me let me make i'm going to make 550 images okay they're all squares okay we're almost there making 550 squares all done i'm going to get this data i'm going to bring it into um the autoencoder project going to replace it then i'm going to rerun this sketch it's not a sketch we run this code uh with uh i'm going to put an argument in here with for 500 images let's just see how this goes loss is getting better when i've got 500 images i'm able to get the loss much further down although it seems to have settled by the time i'm at like 100 epochs so certainly there's not a huge reason for me to train it for long for that long let's just say 75 to make things run faster um and i think actually what i want to do is load all 550 but i want to take out just a slice of them right so how do you do a slice javascript array slice returns a shallow copy of a portion array into a new array object so if i wanted just 500 i would do this and then if i want to do test x test i could create a tensor out of those same images but slice from 500 to 550 right um let's skip um let's skip training the model for a second okay all right right so this makes sense i've got 500 training images 50 test images so now i should be able to say uh auto encoder predict x test let's see after it's trained is that all i need to do predict encoded images oh it's got the encoder and the decoder as separate things oh we made two separate i made encoder model anyway i'm going to do this my own way because eventually i want to like chop off the encoder and just feed in noise from the middle layer but let's just sort of see what happens here so i'm training and then ah look look look we're getting images out yes now we just need to turn those into um now we just need to turn those into images i bet you jim will do that for us so how do i uh write a new image by the way it's freezing in here create an image and write it in a text uh can i make a new image okay can i can i set the pixels and we're about to find out this this frozen mountain behind me is no joke i should really just turn the heat on in here but normally what i do is i warm it up before before i stream but i thought i wasn't going to i can't believe this is working okay so um i need to get the data so back to tensorflow.js uh where are we back to tensorflow.js tf data array no how do i get the tensor tf tensor uh tf image ones can't isn't there like how do i get the data data this is what i want gives me the data oh but i can actually just get it as an array returns the tensor data as a nested array okay so const uh did i already use the word images yeah like new images equals output uh array await let me just do console log new images index zero it's a little silly that i'm training the model every single time but okay great so now i got an array of 784 pixel values so i should be able to say you know i could use base64 encoding probably as a way as writing the images but this is fine and let's just do it with just one so now what i'm doing is i want to say image equals jimp quiz it creates really help if i really knew jimp writing text how do i create an image oh man new gym oh maybe just this oh okay creating new images here we go okay you can call the gym constructor can i do this with buffer data buffer raw image buffer four channel rgba image data okay just now can i do a weight so i'm making it what if i just make the buffer how do i do that thing where i like fill an array yeah all right so um all right let's just go ahead and do this buffer is an array and then for n equals zero n is less than new images index i dot length n plus plus buffer index n n times four plus zero right is is new images in okay so current is new images index i so if basically i want to take all of those values and expand them back out by 255. the reason why i'm multiplying by 4 is i i i took my grayscale image of rgba and made it just like one value so now i'm paying for that because i've got to expand it back out to four values and this one should always just be 255 so there's no alpha transparency and these are this is just putting whatever that value is in the rgb channels and then i should be able to make a new image and then how do i write the file right image right um right should be able to say image dot write test dot png now that's gonna let's just do it with one i'm just doing it with one image so it's fine obviously i need to number these i'll get to that and let's just see if uh output okay let's just see what's happened i'm sure i mes missed something important okay uh the first argument must be of type string or instance of buffer array buffer array array like object receive null where so close to having this working what did i miss uh log buffer let's just take a look at it let's also i'm just going to train the model for um and let's let's put the number of epochs in here just do 10 epochs so i can like test this more quickly okay so now i should be able to see the buffer after 10 epochs almost done i'm almost done okay this is the buffer that looks right oh maybe i can't use a weight here no matching so maybe maybe a weight doesn't work i need to follow um follow it's um call back methodology let's see what happens here what is it that last argument is error image is the function i'm a little lost now a little lost in my syntax new jimp and the arguments are oh this is first oh this is a separate argument it doesn't go in there okay so it does not go in this object there we go okay image and what if i actually just did it just as a test well okay let's try it with the data buffer data buffer error image and then if i said image write let's see if this works okay here we go cannot read properties of undefined we're gonna get there folks no matching constructor overloading was found do i need to round my output values to integers i don't think that should matter but yeah i could see how that's an issue the floor is not defined yeah yeah yeah all right let's just try um this for a second see if i can get a red image oh by the way there's something here oh nothing is there just now i'm i'm not trying to use my actual data from the neural network i just literally put the jimp code to draw a red image that's 256x256 there just to know that this works okay now do we have a red image yes or pink okay so image writing out does work now the question is what if i how do i fill create the buffer correctly so if i wanted to follow so why does this not work and this does um data i mean i must not have made the buffer correctly buffer buffer is expected to be a four channel rgba image data yeah which is not just a plain array let's see we can find an example yeah look here's the error huh other people are finding this error cannot create new jim buffer okay that's unfortunate yeah it doesn't seem to work buffer from array okay ah chris manning says buffer from array okay fingers crossed emoji what oh well i think that worked i mean oh but i didn't write the image i think that worked oh i think that worked oh this is very exciting i think that might have worked yes yes i've never been so excited to see a total like noise nonsense image [Laughter] oh my god that's amazing um okay wait wait wait all right so now hold on hold on first of all i need to train the model better and then okay so what do i need to do this i can get rid of i need to train the model with more epochs let's do 100 epochs then where was my crazy numeral thing i did um to let's find that yeah then i need to save it um so what am i am i an n am i in i i don't even remember i mean i still i output square num dot png okay so this should do so now basically i am and i should do all of them so new images.length and i've got a lot of like these prints here that i don't need okay so what this should be doing now and um and i should call i i have this main function let's take this out let's do oh and this should say a weight oh no it doesn't need in a weight it only needs in a weight if i'm converting it to data that i can actually use that's interesting so hold on so this is the train data this is loading all then i'm taking 500 images to train it with then testing the model i'm going to say await generate generate tests and i want to give it the auto encoder and the test data so this should all be in its own function which is an async function generate tests which gets the autoencoder and the test data then writes it out okay so there we go these are the steps now right build the model load all of the images train the model test the model so train the model with 500 images test the model with 50 images okay ready everybody this definitely merits a here we go oh by the way it's funny how this poll is still up i'm gonna hit end pull yes thank you to chris ray train whistle for chris ray here we go huh i mean did it write all those images out that fast i found that hard to believe it looks like it no that's what oops i couldn't output oh yeah it did but something is wacky my images don't look anything like what was fed into them oh shoot what could i have done wrong oh we got everything to work just looking at this so i'm getting the output i mean to be fair this model is kind of ridiculous what if i go back to my just like let it like literally copy everything oops i can't tell if it re did it regenerate the output i mean maybe i need to rethink my model yeah no what is going on i mean there's images there it's outputting a zoomed in square you've set it to 28 pixels width in height i think yeah did you write the pixels out in the same order you read them in not necessarily so let's think about this this is me reading the images the data in right and then should be 784 this is very silly i have to run through a hundred epochs of training this model just yeah yeah okay just to see that that number was 784. i am not reading the discord shot chat um simon is saying uh maybe you should add more layers i don't think you did anything wrong i think the my model is just bad more layers okay i believe in i believe that could be that that is the case okay let's let's let's add more layers um so let's do it let's do it by half so 784 divided by 2 is 392. now let's just let's just use powers of twos so let's start with should i be using relu for all the encoder activation functions so let's just do encoder one encoder two is i don't need the input shape anymore uh is 128 and then decoder 1 would be 256. and again this is a little bit silly now i don't need to name all of them i could just do decoder two is 784 okay so and let me be a little bit more i think it'll be nicer actually i don't need to i'm just going to add them in directly so let's add in add in this layer then add in another layer and then i wonder if there's a nicer way to write this but i'm just going to do this like this another layer and another layer back to 784 okay so we're putting in um you should take one of your input images create the buffer the exact same way you are with the output yeah that's a very good idea chris manning i will do that i'm also going to do that so here are my layers the first layer gets 784 down to 256 then down to 128 then back up to 256 then back up to 784 and out and i don't need this anymore so let's see how this does um 351 yeah still okay so let me do i let's do um let's do some jimp tests so i'm gonna do test.js so i've got too much stuff going on here to really know what's happening so let me do the following i'm going to take i'm in my in this test i'm going to just get rid of um everything but jimp and get rid of all the tensorflow stuff just for a second so i want to oh i lost some stuff so i want to uh test images so let's test images one so i'm going to read the image i'm going to get the raw data then let's try writing the image back out um to make sure that actually works the way i expected it to so now that i have the raw data this is this is the equivalent of raw data to expand it back out and write the image out so let us get rid of output so this should just be a nice little test to read one image in and write it back out just to make sure that that actually works probably takes longer to train says k weekman yeah so let's just do node test image right oh what's going on here oh there's a mistake here there's a mistake here n times four i'm using n to pull the colors that should be index whoa whoa that's a huge mistake that i've just caught right now any idea what the batch size should be also this is so arbitrary let's just say 32. i'm gonna make that lower cause i don't have that much data look at this this is a huge error huge error huge error huge error [Laughter] i think that might actually be i might have just found the issue clearly i need more time to train but we could actually look at what just came out yeah i did it i did it it worked look what comes out look at that that is beautiful beautiful auto encoder worked oh okay okay okay this is way too exciting hold on hold on everybody just everybody relax okay this is really exciting okay um now i i have to wrap up i'm way over time there's so much more that could be done to this part three i maybe will come at some point maybe this will all get edited into some video and i'll narrate it who knows i have no idea but what i want to do is a couple things one let's train it for much longer where's the training oh yeah i just want to see let's give it 200 epochs i just want to see like when does the loss stop going down still going down i mean eventually i need to just save the model and not do this every time but i just want to see i want to see if i can denoise some images so where are we yeah i mean so 250 we'll do 250 epochs so what i would like to do actually now just as an experiment is let me make a bunch of images with a lot of noise in them so let's do this a point so i'm just adding a lot of noise into the image maybe i need to add more let's add a lot more okay so i'm gonna make a whole bunch with uh that are very noisy i'm just gonna take the last 50. i'm just going to take the last 50. um where's the processing sketch that's not right here it is so i just need 500 to 549 right do these look even noisy hold on let's look at some of these oh you know what in the sampling down of it the noise is really gone so let's do um this this will be better i think this is so silly what i'm doing but it's fine uh this might be too noisy but let's uh let's give it a whirl okay so i'm gonna take these just these last 49 images and i'll put them in here apply to all replace so just so we're clear the first 499 images right if we're looking at these right these are just plain squares but then my test images look like this can i denoise these images with my auto encoder we're about to find out so i'm now training the model off the first 499 images letting it kind of loss get down as low as i can get it and then we're going to look at what came out um so the output is the output has the noise in it is it we should we need to compare it one to one so that's it's a little less noisy wouldn't you say right these are the two it's slightly denoised [Laughter] interesting um so this is not the application that i'm looking to do what i would like to do and i think i'll have to wait for part three is i want to first of all bump up the resolution a little bit perhaps um then it looks like it smoothed the noise yeah um no i didn't train with the mini mini jimmy says the output has the noise because the noisy pictures were trained at the end i shouldn't have got those shouldn't have been part of the training the way i've written the code is i'm only training it with the first 500 images so it shouldn't have any of the and i just put in the last 50. so if i manipulated my files correctly in terms of the input images there should be no noise all the way just all the way until 4.99 and then they should be noisy so these are the training images and then these are the test images um something happened with the loss and acceleration yeah so let's let me post this code um um let's see i don't want this jpeg i'm gonna do a couple things one is no jpegs let me also get the training data generator into um here so this should be so i'm adding now that test file i don't need anymore because i just wasn't sure about i mean but i'll leave that in there so get ignore index package could it be pulling in image 500 that might be an issue i don't think so though oh they should be part of the training versus no noise in the target yeah that's interesting right that makes more sense um so uh yes and so now um code after part two now i'm pushing it i gotta go to the grocery stores it's not it's not five o'clock yet is it it's four o'clock okay i'm way over time here um i'm sorry looking at my oh text messages okay more epochs i don't think it's going to get down below but so so there's so much that could be done to improve this this is just a start here are some suggestions if anybody wants to pick up and continue this i'll try to come back and do this part three number one is you know i kind of haven't been too thoughtful about the layers i'm putting in here in terms of the number of units what activation functions i'm doing and this kind of stuff so i would love for any of you who's interested to sort of play around with this see what kind of results you get ultimately what i would like to do is take this model and be able to start feeding in data just from here um so i want to take random data and um i i basically want to start looking at this as a way to browse the latent space to as and the other thing is like this is just a plain vanilla auto encoder um and there is something called a variational auto encoder so what would i need to do to this to make it from a just this sort of like beginner starting point auto encoder and make a variational autoencoder i would like to know um right and simon is saying you didn't get to generating new images with the decoder only so that's got to be in part three so if you would like to pick this up and run with it on your own you can go to github.com codingtrain you can uh come here and check out the auto encoder demo i would take i probably wouldn't i'm not looking right now for pull requests that improve this um because i want to build keep improving it on my own but i a hundred percent would accept a pull request that adds a readme file that documents all this links to the live streams etc um and i would accept uh issues that propose improvements or document and you know link to your own version of it so i'll try to come back at some point it's probably going to be december this is probably the last live stream for november uh you know as i said if you wanted to watch my newest video all right if you want to watch my newest video all you need to do is go sign up for the curiosity stream and nebula bundle curiositystream.com codingtrain 26 off yeah adversarial autoencoder says andrea that's what i should be doing but i'm doing this very slowly so one step at a time um so uh if but this new video also should be out on youtube itself tomorrow or hopefully at least by monday sometime very very soon huge shout out to tim rodenbroker who donated to the crossing foundation fundraiser which uh inspired this video thank you to the sponsor curiosity stream curiositystream.com codingtrain tons of wonderful documentaries um as well as access full access to uh the nebula streaming service all right so this wraps up my uh demonstration explanation attempts at auto encoder we've got auto encoder part two done i'm gonna put on a sweater i'm gonna turn on the heat i'm gonna plug the internet back into the house i'm gonna go work on uh answering my students emails make some dinner for my children and i really appreciate everybody here uh participating in this cheering me on i'm very excited that this actually works um so more soon all right goodbye everybody see you next time on the coding train uh i can't find my music uh here we go as always i always forget that this stock this stock is this i'm going to do this this dot this dot this dot this dot song never forget this dot somebody composed that song for me i'm going to say once again here we go coordinate song it's the forward to cartesian coordinate song autotune and the internet will fix that for me it's cartesian coordinates unicorns and rainbows and cupcakes what else is there yes kittens thank you very much kittens and rainbows and cupcakes notice that look what i get i'm really losing my mind okay let's do it the kids the kittens kittens the kittens the kittens i feel just sort of like a nice feeling of relaxation everything's gonna be okay today dream is not broken it has not frozen this is a this is a wonderful thing okay we're gonna do it i'm really getting to something i need my sound effects what else is there all sorts of text generation analysis things that i will use continuously over and over again first thing i need to do is yes kittens the kittens that doesn't you