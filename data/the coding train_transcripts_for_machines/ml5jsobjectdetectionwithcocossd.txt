hi everyone welcome to another ml5.js video in this video i am going to talk about the object detector in ml5 which is a new feature as of 0.5.0 so you want to make sure you are on at least that version before you get started and try the same code that i'm about to demonstrate to you what do i mean by object detection so far i have covered image classification meaning we have an image maybe it has a cat in it and when that image is sent into the machine learning model in the case of the previous examples a model called mobilenet i get back a list of labels and confidence scores and most likely in this case i would get the label cat with hopefully a confidence score of something like 95 percent there might be some other guesses with lower confidence scores but ultimately the goal is to have a single classification a single label come out and be assigned as the result of the prediction of this image now what happens in the case of object detection let's say i have this same image an object detection model will not only label something in the image but give a bounding box as to where that object it detects is so instead of just saying this image is classified as cat an object detection model will say in this image there is an object of type cat that is located at a particular xy location with a particular width and a particular height the model will also return a confidence score for how certain it is that there is a cat at this exact location so maybe that would also be something like 95 percent and what's special about object detection instead of just classifying the image with one label here if you're detecting an object in an image it could detect more than one thing so maybe there's also i don't know i'm drawing the rest of the cat maybe there's also a dog there's my dog if the image is of a cat and a dog we could get two bounding boxes a second one with the label dog and another x y width and height for its bounding box and right here on the ml5 reference page we can see an example of this here's an image of a cat the bounding box is marked the label cat is indicated along with the confidence score here of 65.41 now this doesn't happen by magic this happens because there is a pretrained model that presumably has been trained already on image many images of cats and dogs with those bounding boxes marked and labeled how does a data set like that even exist something new that is now in the ml5 documentation is a section called model and data providence you'll find this for every single pretrained model that's in the ml5 library this is a project that's been started by ellen nichols and i encourage you to click the link to find out more about ellen and her work on model and data provenance and what she has done here is created model biographies and data biographies anytime you're using a machine learning model you want to ask yourself the question what data was used to train this model who trained this model in what context and for what reasons anytime you're going to use a pretrained model in a project you want to think about the ethical implications of where that model came from and how you're using it and researching into the the biography so to speak of the data behind the model and the model itself is incredibly important when considering those kinds of questions in this case the data set behind the object detection model that i'm going to use is a data set called coco coco or common objects in context is a large scale object detection segmentation and captioning data set so before you watch the rest of this video i would pause go to the cocodataset website click explore and poke around a little bit also in this video series you'll find videos about the posnet pretrained model um in coco in addition to the object detection data there's also a set of 200 000 images with 250 000 instances of people labeled with particular key points on their body coco also includes image segmentation which is a very similar concept to object detection but instead of a particular bounding box every single pixel is labeled as part of a particular category so there are all the pixels for the giraffe versus the pixels for the clouds in the sky and so on and so forth i also want to suggest to you two readings if you're interested in learning more about data sets for machine learning um the humans of ai project by philip schmidt is a project that explores specifically the cocoa image data set and you can learn a lot more about where did those images come from who took those photos and how philip schmidt puts it exposing the myth of magically intelligent machines i also would highly suggest reading excavating ai the politics of images and machine learning training sets by kate crawford and trevor paglin this essay explores the imagenet database another very wellknown uh image database that is the data set behind the mobilenet model which serves as the foundation for many of the ml5 um image classification and transfer learning examples that are throughout this particular playlist circling back to ml5 if you use the object detector there are two pretrained models you can select from at present hopefully in the future maybe you'll even train your own model or we'll be able to incorporate other open source object detection models but right now there's yolo or stands which stands for you only look once and coco sd in this video i'm going to demonstrate using coco sd but i encourage you to explore and experiment and do your research about the yolo model as well the coco ssd model comes from tensorflow so the there's the tensorflow tensorflow.js port of the tensorflow coco ssd model that's what ml5 is using certainly um on the github page for that model you can find code for using it in javascript without the ml5 library that you could explore as well as more background about how it was trained and what it does now one thing i'll note is it only detects 80 classes of object not a huge number if you think about it you can find that list of labels as part of the ml5 materials themselves as well all right it's time to write some code the first thing that i want to do is have an image to try to detect objects in there we go so i've made a simple p5 sketch that uses the preload function to load a particular image that i've uploaded to the p5 web editor and in the setup function i'm making a canvas and drawing that image you might recognize gloria pickle from my coding in the cabana series along with her good friend greta goose unfortunately evie mango is not pictured here but you can learn more about them on their instagram which i'll link to in the video's description now that i've got my image the next step is for me to load the coco sd model itself for this basic example i'm making heavy use of the preload function which allows me to load images and pretrained models without any callbacks and everything is ready to go once i get to the setup function but certainly in other contexts you might want to use a callback or write your code in a different way and you'll find all that in the actual official ml5 examples themselves let's double check that things are working correctly by just console logging the detector object oh and i should put that in setup to see that it's loaded properly whoops by accident i put a capital o there it should be lowercase o object detector the console isn't necessarily going to show us anything useful here just a lot of the stuff that's part of that detector object in ml5 but it's more clear for us to look at the documentation than see what's logged here in the console i happen to know that what i need to do is call detector.predict pass it the image and then a callback for when i've got the detections so i'll say got detections as the name of my callback function let's write that function and let's log the results so this is the same pattern in many other ml5 pretrained models load the model call predict get a result error first in the callback in case there's an error and maybe i should check for that and then do something with the results i just want to log them right now detector.predict is not a function oops looking at the documentation the function is not predict it's detect so predict is a general word for when you want to ask the machine a machine learning model to give you the output associated with a given input but in this specific case um the ml5 function is named detect because it's a it's a more descriptive word of what we're actually doing i'm going to change this to detect let's also comment out this unnecessary console log and run it again aha look at this three objects okay there's a cat there's a dog what's the third one it's something in this list of 80 things did you see it there object zero is the dog here's the confidence score and the x y width and height it also looks like it gives you something called normalized which are probably all of these values but mapped to a range between zero and one object one is the couch it detected the couch and then object three i'm going to assume is the cat let's draw those bounding boxes so i can write a loop to look at all of the elements of the array and of course there's countless other ways you can do this with different types of array functionality but this simplest way i'll just say let object equals results index i let's first just draw the bounding box at object x object y with the width and height let's give it a sort of distinctive color just so it really is emphasized with a given uh thickness and make sure there's no fill blocking it out there we go i've got three rectangles one drawn around the dog one around the cat and one around the couch let's add the labels just so we can see them and where do i want to draw it at the x location but shifted a little over and the y location but shifted a little bit down maybe i want to put it in the center there's no rules here i'm just going to do it however i'm going to do it run it again there we go couch dog cat now of course i want to think about visual design and contrast this isn't the uh best visualization of it but you can see it's working maybe if you're following along pause this video try to add the confidence score that's a nice little exercise for you to do hopefully you have some creative ideas of how you might want to use this or experiment with this an application that i would imagine you might want to try is try this model out on a realtime video feed so i have a webcam here on this laptop i can rewrite this code to use the p5 create capture object and then pass the video as the thing we're looking at into the machine learning model same as we did with the mobilenet image classification examples so i'm going to save this code as is and you'll find it linked in the video's description and i'm going to duplicate it and rewrite it with the capture object call it webcam comment out the image and add a video instead i need a draw function because now i'm going to be looping and drawing every frame of the video in real time let's make sure the video is the same size as the canvas and let's run this and see what happens so i see my video there i console log the detections but i only detected things once and i found nothing why is that that's because i called detect in setup with the video once got the results and never called detect again so now i need to create this kind of loop system where i first call detect i get the detections and once i've gotten the detections let's call it again oh why did i say object i should be saying detector and look it's recognizing me now i don't love the way that i've written this because drawing the results here outside of drawn and happening in this sort of like separate sequence is a little bit prone to error so i want to just adjust the way i'm doing this i'm going to take this loop and i'm going to put it into draw this way i know my drawing sequence is always happening in the right order draw the video draw the results on top of it but this isn't where i got the results where i got the results is in the got detections function so i'll just use a global variable here to sort of link those two things so let's create a variable called detections i'm going to make it an empty array to start then in the got detections function i will just set detections equal to the results so now it's a global variable that gets set whenever there are new detections and whatever the latest detections are they'll always be drawn in draw by me adding detections here let's run this and let's see if i can get some object detecting going oh boy things froze error what went wrong results is not defined sketch line 33 oh detections is the global variable but i'm still using results here i need to change that also to detections notice how when the error happened the sort of video element is still going but the canvas where i'm separately drawing the video got frozen i probably only want to see one of those so i don't need to see the original video uh element i can call video.hide to remove that run it again all right person cell phone hope it's still no it still sees me how about book this is a book that i'm currently reading it's called weapons of math destruction also highly recommended when thinking about algorithms and machine learning i happen to have a paintbrush scissors baseball bat okay batter up all right so you get the idea um something that i might want to add to this is some kind of debouncing or interpolation you can see that it's very very uh very noisy so that's something that um i will also include some references for in the video subscription maybe even an extra example that adds that um but this wraps up this video so thank you for watching this video tutorial on the ml5 object detector if you have some creative ideas or things you want to try let me know write something in the comments and you can also go to the coding train webpage associated with this video and submit your creative um examples and experiments there thanks for watching and i'll see you in another ml5 video goodbye you