I think I'm streaming he everybody welcome good morning I've been having technical difficulties for like the last 20 minutes and I think this is actually working oh my God it's working they YouTube changed the way things work good morning welcome this thing is called the coding rainbow uh and I had a whole thing prepared to say that I don't have prepared to say anymore because I just spent 15 minutes trying to make all this stuff work I feel very stressed out but I'm here in New York City at place called ITP at New York University uh Tish School of the Arts and I'm here to talk about I have a prop the Microsoft Connect uh how do you program with this thing how do you do interactive stuff with this thing how do you use this thing with something called processing uh which is running behind me here uh oops I didn't even configure my window or anything so um I people in the chat tell me if you are there uh tell me if you can hear me tell me if you can read this font um tell me if uh you can see me over here I need to test to make sure this whiteboard is working I mean the the Whiteboard is working but if the focus is pretty decent uh I think that's pretty good I'm going to walk over here I've got Periscope live going hi Periscope um so I'm like d triple double streaming something hi I'm talking to Periscope so now I'm on I'm Live on YouTube Periscope so I'm going to put you down so so you could see the URL over here and you can go there uh this is like the most ridiculous thing I've ever done there you go okay so that's where you can go Periscope or you can at least hear the audio so um uh okay everybody can hear me it works like a charm that's great that's exciting to hear um okay so I've got to get started um and I have uh I think I'll be doing this for about an hour or so uh I'm glad to take questions uh the first thing I want to do so I'm kind of going to talk this through first to figure out the kinds of things I'm going to cover um I'll look for any questions or ideas in the chat um and then what I'm going to do as I always do but I'll explain it again is during various parts of this um live stream I'm going to hit a record button to like save a particular chunk as a standalone video Lesson which I will upload to Youtube later so my goal is to have like four or five 10minute video lessons about using the connect and this live stream will be kind of a mess of like trying all sorts of stuff out and in between making those videos um and sometimes I stop and start and redo the redo the same content if I feel like I went in the wrong direction and so you just turn it off if this is like driving you crazy um so I'm checking in the chat hello ah Cardiff again and hello France uh if one thing that's really important if if the audio stops working or if some weird thing happens you can't see me uh please type that in the chat I'm not doing anything with Twitter today so I don't need people to tweet while I'm doing well but you know welcome to um you know let people know this is happening uh it's a holiday tomorrow here in the United States called Thanksgiving NYU is actually closed today but it's a busy active time the end of the semester so um but the reason why I'm doing this actually is because um a lot of students are trying to do projects with the connect around here and I thought this would be helpful we'll see um okay I I'm gonna drink a little water and get set up so I think the first thing that I'm going to do I um first thing I'm going to do is just talk about the connect in general what the different versions of the connect are uh how it works and show you how to install a library in processing that uses the connect open the window for a minute to get some cool air in here lights some get a little bit hot uh so I'm going to just talk about the connect in general and like run some examples to show what it does and then then I am going to uh try to look at a few different scenarios for example um finding the closest thing maybe to the connect maybe finding uh the the top of a human being like where's the top of your head uh I want to look at like taking the depth map and maybe just like dividing it into sections like a grid um somebody had a idea for a project ITP which is to have like the connect pointed at a a sand box and you could manipulate the sand and the height of the sand would play different musical notes so maybe some kind I don't have a Sandbox or and I have the connect in sort of a weird place so I don't know how this is all going to go but I want to try to build a few examples from scratch basically while we're here um okay um great I'm seeing some nice people say hello yes if you're listening to the Periscope audio and the YouTube audio you're in trouble because they're they're definitely going to be out of sync um and that's that so um let me get myself a little bit oriented here uh and I'm going to so here by the way so let me see so let me get this particular example up and running I'm going to hit stop um I need a little bit more room here I'm going to do this interesting I think I actually need this statement in there and I'm going to do this and okay so this is the first thing that I'll just talk about which is that you can get the uh the regular image from the connect the depth image which you can see the darker the color is the closer it is this is um using the connect version two there's the the what the camera is actually seeing the infrared that the cam the camera the sensor the connect whatever you want to call it is seeing and the um this thing called a registered image which aligns the col colors with the depth uh okay uh I think it runs on Linux um I don't know that's a good question I mean I'm so a lot of this work I have to credit Thomas Sanchez lling does anybody know how to pronounce his name let me pull let me pull up uh let me pull up the person I would like to credit for a lot of this work to who helped bring have the library work with the connect version too Thomas Sanchez lling uh here he is a cod codigo generao is his website which I'm probably butchering the um butchering the name so w Works in portfolio of Thomas Sanchez L leling leling if anybody knows how to pronounce that so write it phonetically in the chat otherwise I'll probably mispronounce his name but I do want to thank him uh when I when I start making some of these videos I guess this is a video I'm making right now I'm already thanking him um but he's done a lot of work with the connect and in this part this particular Library so what I should probably bring up here is open connect for processing the uh GitHub page to look at this uh as well as uh sorry let me I'm just getting set here to make this first video uh and um the uh open connect for processing and then this is my page which could use some work but it has some documentation and stuff about it as well okay um yes you can install the connect Library directly from processing and you don't need to install anything else unless you're on Windows maybe you do but you follow the instructions okay uh so I'm getting ready I'm going to make this first uh video I'm going to just drink a little bit of water over here wow I've got 31 people watching that's fantastic um I'm actually just going to send a quick email um to ITP students um because uh hold on a sec because a lot of them were interested in maybe joining so live stream on connect happening now uh okay I'm just sending that out uh okay so I think I'm good to go wow I I just took oh it's eight minutes to get started here but uh I'm going to uh open this up and so in the first video which I'm about to hit record and do the things I'm going to cover are how to install the library um uh what the different kind what the different um versions of the connect are the hardware the different editions and which ones work which ones don't work maybe they all work uh and then the basic functionality of the connect in terms of the pieces of the things the RGB image the infrared image the depth image the raw depth data and um excuse me the uh registered image which is only part of the connect version 2 so that's what I'm going to cover in the first video section and then in the second one I'll probably do some type of visualization of the depth data something like that okay um so it's your last chance to ask a question in the chat oh a lot of you might be interested I just um uh was reminded um that there is something called the key motion or the kimotion or the K motion k i m o t i o n which is a library framework uh for using the connect with um p5js which is another programming environment that I make a lot of video lessons about so don't know if I'm going to get to that today honestly because I haven't had the chance to like really like get it set up and running myself but I definitely you know I imagine this to be a new playlist about the connect I'm going to do raw depth I'm going to do skeleton tracking with the Microsoft SDK I'm going to do using probably this key motion thing for p5js because lots of other people are making stuff and I hope to be able to mention those things and and help people get started with those things as well okay uh here we go in three two one something like that I need like I I need somebody to like be behind the camera going in three two except nobody's there I'm just doing that for myself uh my nose is running but it'll be fine Okay click the mouse mouse goes live and hello okay wait wait wait wait I I like lost track of what I was doing hello this is the first video in a series of videos about using the Microsoft Connect in your own software and the software I'm going to use is this thing called processing uh eventually I will also get to looking at how you might use the Microsoft Connect with p5js in the browser but the first uh this I got to start over too longwinded too longwinded I've been looking too much at my like YouTube analytics and see how like people are watching they whole drop off when I start to ramble at the beginning of a video but I really should care about that I'm way into into my own inside my own head too much I'm just going to make this video hello this is the first video in a series of videos I'm making about the Microsoft Connect this thing so what is this thing how does it work and how do you write your own software that makes use of this thing how can you do all sorts of creative coding projects now there's a lot of different programming languages and environments and Frameworks and libraries for how you might make use the connect um I'm going to use this thing called processing processing 3 the Third Edition version of processing uh which is a Java based programming environment open source uh environment um that there is a connect several different connect libraries for uh eventually I will hope to make a video where I look at p5js which is a JavaScript framework uh for doing creative coding in the browser and how might you get the the stuff from the connect what is this thing called The Connect in the browser itself which I think will be an exciting thing to see as well um but in this first video what I want to do I'm going to get into the code really in the next video and what I want to do in this video is give you an overview so what are the different uh editions of the connect there's a bunch of different ones that you could buy what are the pieces that you need how do you get the library to make use of the connect that sort of stuff and you can see I have a basic example that's running behind me with the connect version two and I will talk through the pieces of this code so first let's think about the different versions of the connect so this is this one here I need reading glass I'm going to this one is the 14 model 1414 this one is the and I'm going to I'm going to come over here and try not to trip over to myself um and I got to grab this uh eraser for a second um so let's make a list here so the the two key pieces of information for you are you need to decide are you using the connect version one or the connect version two I'm probably going to get lots of stuff wrong here that you can write in the comments and I'll put little annotations on the YouTube video that fix them but hopefully I'll get things Loosely right so the original connect version one model 1414 is the one that came out I think it was November 2011 12 somewhere around there I remember the weekend it came out people people were quote unquote hacking it but really just making but by hacking it I mean making open source drivers to to read the data driver being a thing that your computer runs to talk to the hardware device um and so when that came out uh a library I worked on a library called open connect for processing and the reason why it's called Uh open connect is because it's making use of the open connect an open connect an open source uh driver for for uh connecting to the connect which is also known as a lib Free Net so this is sort of the Genesis of all of this um the thing that I built for processing is just a thin layer on top of work that lots and lots of other people did which allows you to get the data from the connect now let's come back to the connect like what is this over here and then I'll get i'll get to the other additions in a second like what is this thing so this is the original connect and you can see here that there are three little circles on here it's like a little nice little friend with three eyeballs and what do each of these eyeballs do so one of them them if we oh camera oh oh shift menu I suck at making these videos okay I'm just I'm going to go anyway okay so this is the connect uh uh um and it has three little eyeballs one of which is an infrared projector so this is this is what the 144 does and I'll talk a little bit about any a different marker here what happens once you get to the connect version two how that works differently um it has an infrared projector which sends out infrared light into the room then it has what I would call you know you could call it a sensor a camera but it has an infrared camera to read the infrared light that's in the in the room what is infrared light it's you know light that's all around us but is invisible somebody with a Physics degree could explain that better but this is blasting out infrared light this infrared camera is reading it so what what is the value of doing this so the interesting thing is the kind of light that it's passing out is actually a whole lot of infrared dots it's projecting a lot of infrared dots into the room that look like this and it's a very specific pattern of dots and the connect itself it knows what that pattern of dots is supposed to look like so if that pattern of dots if I have the connect here it's blasting the infrared light lands on a flat surface the infrared camera that's reading where those dots landed that's seeing those dots reflecting back is going to see like oh it matches exactly the pattern of dots that I know that's a flat surface but if this surface was curved those dots will appear distorted by analyzing that Distortion the connect can recognize what things are closer and what things are further away so the value of this is it uh is often referred to you can think of it as a depth camera or a depth sensor this is what this infrared projector and infrared camera are doing they're measuring the depth in of of each pixel in the room so while a regular web camera says here's a 640x480 image each pixel has a red green and blue value and it's beautiful isn't it the colors of the rainbow are there in this image um The Connect is saying I see I don't see RGB what I see is I see a pixel and instead of telling you what color that pixel is I'm going to tell you how far is that pixel away from the sensor and this is incredibly valuable in computer vision you know one of the classic computer vision problems that people try to solve is background removal you know that's why I have this oh green screen oh I have to go underneath this here okay I have an obstacle course in my office I'm going underneath this to turn this camera back on and I'm coming back underneath here I have this hello I have this um I have this green screen here behind me that you can see um and so the the uh camera is saying every Green pixel remove it and put the stuff from the computer behind it but if I had to connect I don't have to say look for the green pixels behind me I could just say look for any pixel that's farther than 2 ft or or some amount of centimeters I'm trying to be a metric I'm trying to be metric I want to be a metric person but I'm not um so uh you could remove you could you could analyze things it makes it really easy to find a human being in the room because a human being has a certain kind of shape it makes it really easy to do quick and dirty 3D scanning there's lots and lots of possibilities of what you can do once you have access to the depth now there was this third little eye here and this by the way is just an RGB camera so one of the things the connect can also do is just see the colors in the room so in addition to having this infrared camera it has an RGB camera now there's a bit of a problem here which is that notice how both of these things are not in the same place so the infrared camera sees the depth of a given pixel at a different place that the RGB camera sees that color so this is an alignment problem a calibration problem where the the color pixels don't necessarily line up exactly with the depth pixels and there are lots of strategies for solving this problem uh and lots of Frameworks and libraries in particular the official Microsoft SDK which has um things baked into it that do this for you but one of the nice things that we'll see once we get to the connect V version two is it has something called a registered image which is an image that aligns the depth pixels with the color pixels okay so this is what the connect does and I really described here what the connect version one does there was also a model 1473 that came out I don't know a year or two later um this one has some problems in particular there's a little bit of a bug uh with currently with running it with the processing Library although it does work kind of only will work every other time can't figure it out for the life of me um so but both of these will work with the library what you need to look for in the library is the version one examples so that's now in between here there was like this connect for Windows and I think this was like a version of The Connect that the Microsoft made to plug into like Windows computers originally this was designed for use with the Xbox for a game for games that you would play by you know dancing I'm kicking my leg by the way if you can't see that um and uh um but you know then Microsoft realized there's I don't know what mic what's in Microsoft has but I'm speculating here but that to make a version that's designed to work with just regular old laptops and computers um I'm not sure if this one works with the processing library but more recently and I I I have this one plugged in and like mounted on the wall over there so I can't hold it up and show it to you the connect version two is a newer and quite significant upgrade from the first connect um and it actually uses a completely different technique it's uses infrared light but it uses a technique called time of flight so it sends the infrared light out measures how long it takes for it to bounce back and that how long that takes uh lets the sensor know how far away things are kind of like a bat maybe does stuff with sound to see I don't know you dolphins do stuff like that but all with sound so with light bouncing it back and forth um the new connect does that and I suppose it's a bit more accurate it's faster uh and uh the RGB camera is also in the new connect is higher resolution okay so that's the basics overview and if I come back over here you can see now now I'm running an example have the connect right over here you can't see it I could I could maybe like turn like kind of like if I hold it up over here can there you go there it is this is the new one I'm G to put it back that felt like a little scary like everything was going to fall over um and you can see now that uh what you're seeing in this particular image is an example of a processing sketch which is rendering all of the pieces of what the library what the connect offers now oh I but I have something more to mention about this but I'll get to that in a second so up top you can see that's just the RGB image so it's like I have a webcam over here I have a webcam over here hi webcam hey that sort of thing right so that's the webcam uh that's that's the RGB camera and it's actually I believe I didn't actually check but it's a it's pretty high resolution image um down below this is the Raw Feed of what the infrared camera is seeing so this is what the infrared camera is seeing and it uses that to extrapolate depth so mostly it just looks like this creepy thing but you can make use of that you can get that image as well um up top up the top right this is what's known as the depth image so the what the connect is measuring is in millimeters it's measuring uh a value between 0 and 4500 how far is the thing away from the camera and then often a depth image is used to visualize that data so in this case you can see as I start to go further and further back I get brighter as I start to come closer and closer I get darker so it's mapping the uh theor color of every pixel to how far away it is and you can see just from a standpoint now how much easier that might be to pick out my hand right because my hand is the only thing that has this very very dark color uh as opposed to other things now there is something funny in the back what's up there above oh that's a window I like what's that Black square up there that's a window that's the door you can seeing all sorts of things inside inside this room that you may not have seen before and then down in the bottom right this is the registered image so this is not part of if you use the version one connect with the open connect Library this is not part of that however uh with version two this is the image that aligns all of the RGB values from the webcam with the depth values so if you wanted to hopefully something I might be able to demonstrate at some video is just do background removal where you see only me and I take I get rid of all the pixels that are behind me um that might be something that I could do here with with that particular image oh did the oh the laptop went to sleep come back or wake up okay so uh couple more things so what I want to show you now is how do you get this library to run this like this particular example so a couple things one is here's the I'll put all this in the in the description of the video this is the URL the the uh library is at github.com shiftman open connect for processing you don't need to go to that URL but that's where the source code is there's a little bit of documentation there I want to make give a big thank you to Thomas sanche as lenling I I might not have pronounced his last name correctly he wrote all the code for making this Library work with the connect version two so I worked on the version one a number of years ago and sort of floundered and Thomas came back and revived this and really helped uh over the summer um and there is also I have a little a page that has some additional documentation it's shiffman Donnet p5c connect and you know this is some text that kind of goes through uh the different versions uh and some of these examples as well that I'm going to cover in the videos now in order to get the actual Library itself what you need to do is go to uh one you know first you need to download processing if you don't have that already that's at processing.org then what you'll need to do is once you have processing uh it might look just like this to you something empty you're going to go to sketch import Library add library now you can see that I have already you know I have three libraries here I already have that library but I'm going to pretend that I don't for a second I'm going to go to add Library which opens up up this contributions manager I can type in Connect right here and this is something really quite important now to bring up so there are several different libraries there is by the way something called Simple openni which is an older library openni was an open source platform open source framework for doing skeleton tracking meaning finding the human form where the hands are where the head is which is very very powerful and things that you can do with the connect I'm starting with just the raw depth data um but open and I think was purchased by Apple and then kind of like shut down as an open thing but there are some efforts to revive it and so uh you could Google around and that's something that you could possibly use I'll try to include some links but you can see that it's currently this simple open eye it's no longer compatible with processing three that's why it's gray out connect V2 for processing this is a library that makes use of the Microsoft official SDK and I'm going to demonstrate that using a PC in a later video um this is a key uh this is a really a great thing to use if you want to get all of the magic that Microsoft has spent all this time developing so what the connect just gives you is raw depth data raw RGB data but what the Microsoft SDK does is it pulls that data in and on and it analyzes it and finds where's the human being like what kind of muscle are they making like where is their head like is their hand open or closed and it's so much a sort of a layer of analysis on the raw def data that will give you a ton of information so but for that you do need to use a Windows machine of course there are some strategies for like sending the data from a Windows machine to another machine through like a websocket what's a websocket all sorts of stuff but we'll come to that in a later video um and uh so those would be the two libraries that but the library I'm using today which you know is already installed you can see by the green check mark you would just need to click it and uh click this install button and it would download and install um that this is the library I'm using today it uses opensource drivers it only looks at the raw depth data so this is good for a bunch of different kind of creative applications that I hope to show you in the next set of videos so this was a long rambling 16minute explanation about the connect that you may or may not have found useful or interesting but I imagine you already turned it off if you didn't and in the next video what I will demonstrate is is just how to write a program that gets that depth image and once it uh I bring that back oh it's not running here get gets that depth image and maybe visualizes that depth image in some way so that's where we'll start and then I'll look at a couple other scenarios along the way as well okay and so thanks for being here and watching and talk to you soon okay everybody uh uh all right did that could people hear me through all that and that worked and everything I don't know what's going I feel like a little lost here um all right I'm looking to see if there are any questions uh um some people are asking things from various place I would like to sing a coding Rainbow theme okay uh uh the white line on his shirt there's a there's a is there something transparent on my shirt oh there's a green it's not white this is a I wore this because this is a shirt that I have that has a rainbow on it and this this line right here is green so it's transparent because the it's picking up the green screen behind me okay um glad that was helpful okay so now what I'm going to do I think maybe what I'm going to do right now you guys is I'm going to try building a little example uh and like the practice and then I'm going to do the video where I build the example again so I'm going to do it now with a little less like personality whatever that means um and you can it's uh ask any questions if you want um so I think the first thing to do would be to actually just look at the depth image and then like take each pixel and map its Z location according to its depth so let me go and grab um ex uh open recent uh this one and I'm going to say um depth dep depth image viz so I'm going to make a sketch that's 640 by 480 uh I'm I'm going to just do this uh so I'm just looking at the depth and I'm going to say p image so I'm I'm I'm going to explain all this when I make the video but I'm just sort of trying out to make see if this this example makes any sense uh and then I'm going to say 4 int xals z x is less than image. width uh x++ for in y = z y is less than image. height y ++ I have a syntax error here uh and then can you guys read this font size okay should I make it bigger uh and then going to take out all this stuff uh and then I'm going to um say int off uh index = x + y * image. width and um color or like uh depth equals uh the brightness of image. pixels at index maybe I'm going to turn off the code completion oh no I want that oh I don't know I'll leave it it's fine uh and um then I'm going to uh I'm going to have a variable called like w is 10 uh oh maybe I call this Skip and that's kind of useful skip uh plus equals Skip and then I'm going to draw I'm just going to draw a rectangle at X comma y uh Skip Skip and I'm going to say fill D and uh I just want to see if this works whoa I'm missing a semicolon uh so I just want I'm just trying to like make it a grid here um what did I miss ah image. load pixels image. load pixels oops I have a capital I there uh oh I totally someone's asking a really good question I totally should have mentioned that in the video you do not need to install any extra drivers or anything it just works um the idea is the library just works um right out of the box yeah so most of the time when you're working with the connect you got to install all this other stuff maybe I'll like I don't know I'll have to put that in an annotation in the video because that was like kind of a big thing that I missed there I should just remake that one but it was too long okay what did I miss here array index bounds array oh X Plus y times width okay okay so you can see great so this is the first thing that I wanted to do which was just and why oh you know what it isn't 640 by 480 what is it uh I forget what's the connect version two with I guess uh it's actually a little bit lower resolution it's uh um uh I forget what it is somebody might know image. width image. height uh come on Console how come I'm not seeing anything in the console don't I have a print line there oh yeah 512 by 424 I forgot about that 512 424 so this is working you can see I'm getting so I just wanted to do something first really quick where I kind of make this grid like lower resolution grid because then what I can do is translate each one of those into 3D based on the brightness and I I'm pretty confident that I can do that in the video so um I think what I'm going to do dare I just delete all this code because I'm going to write it again from scratch in the particular video all right that's what I'm going to do delete okay so I'm going to just make a simp simple video where I look at looping through all the depth pixels and doing something with them uh any questions 512 by 400 thank you thank you for um for pointing out the errors uh wow I've got good I've got a great number of live people today that's wonderful okay so um and then I'll do one where I look at the raw depth data I think so I want to look at the difference between the color data and the Raw depth data um but I think I'll just I'm going to try to do these small little chunks okay here we go um I'm ready let me let me cycle these cameras and um I'm going to erase this diagram I'm over here right now by the way people um erase this cuz I probably need to do a quick pixel diagram uh for this video especially if people haven't worked with pixel processing before and um and now I'm ready okay uh here we go uh got my weird seethrough tshirt I can see the G like like that's like hole in my body it's disturbing okay um the okay so the same exact Library will work with the connect version one as well and the techniques would be the same I just happen to be demonstrating it with the connect version two thinking that that would be a little bit more current okay so um U stop here I I wish there was um okay that's fine and uh okay so I think I can make this a little bit smaller I can minimize the browser here sorry I'm just getting my window all set up uh this one I can close and I'm going to close this and then go open ah come on uh this one great and U make the console a little bit bigger there we go I think we're good what about the font size I feel like it needs to be a little bit bigger it's looking a little smaller to me that's a little bit better right okay um here we go ah the sun is coming sunlight is here today excellent hello in this video I'm going to look at how you can get the depth image from the connect in processing and what you might do with that so this is a very very very first step I have a completely blank sort of like set of code here I just filled a little bit in there in advance but I'm going to write this program from scratch in this video so uh if you didn't watch the prev hello in this video I'm going to look at how you get access to the depth image from the Microsoft Connect in processing and how you write some code to do some stuff with those pixels with that depth image so if you missed the previous video that's where I talked about the connect in general about um how you install the processing Library one thing I did miss which I think is important to mention is that you do not need to install anything else if you're on Mac OS X um so uh the library just uh works it comes with all the libf free neck stuff sort of packaged inside of it uh I believe on Windows there might be one other thing you have to install uh well I should really look this up right now ah crap I'm going to make this I don't want to get this wrong in the video Let's look this up uh here uh connect V2 uh for Windows 8 you have to install some uh this driver um which I'll mention for the V2 okay going do this one more time uh okay here we go hello in this video I'm going to look at how you can uh work with the depth image from the Microsoft Connect in processing I'm going to I need my prop I need my prop I swear this is the last time I'm doing this I just feel like having the prop will be good it's stuck underneath the table help it's funny how I've left my phone on Periscope is still like streaming an index card I don't know if there's anybody there okay uh okay I swear this is the last time I'm making this video now come come some hello I have a prop in this video I'm going to look at how do you use this I'm going to actually look at the code for using this Microsoft Connect in processing using the open connect for processing library now uh one thing I want to mention it that I did not mention in the previous videoos that is if you install the open connect for processing Library you need nothing else whatsoever it just works with the connect there is one exception on Windows 8 with the connect version two you do need to install an extra dri libus I will put that in the description below um but so this is the connect version one model 1414 it would work with this example but I'm going to show you instead I have the connect version two over here and you can see the only code that I filled in so far is having a variable called connect 2 so if you're using the connect version one the only thing you would change this code would work mostly identically um is just say connect uh instead of connect two so it's not connect one and connect two it's just connect and connect two I'm pretty sure about that if I get that wrong somebody will correct me um okay so uh let's look at how you get started so I filled in a little bit of code but the only things that you need really to get started are an import statement at the top that import statement is saying hey I'm here to use this Library uh you need to declare a variable that's variable is going to like hold all the information about this connect that you are using so it's the thing that you're going to create and I create it by saying new connect to this now there is a way to use multiple connects to use a version one and a version two to specify which connect you want to use that's beyond the scope of what I'm doing here in this video I'm only going to look at you just have one connect connected to one connect connected to your computer it's the default one all you need to do is say equals new connect to this so once you've got that going what is the next step well you need to decide what it is you want to do and in this example all I want to do is use the depth image so I'm going to say init depth so the connect uh the connect doesn't the library doesn't start all of the feeds automatically it's not going to start getting the infrared image the raw depth the depth image the video image it's only going to start using what you ask for so in this case I want to say init depth and then I also want to say uh init device which will kind of get things going and by the way this is where if I had multiple devices I could put an argument in there say init device zero one or two that type of thing so once I have that I'm ready to go and I can run this program and we will see nothing nothing on the screen so but a lot of stuff like spit out here which is kind of promising device firmware serial the library is going to like put a lot of stuff in the console which is um some basic information that you can see if it's working it will say like no nothing connected uh if you if you if you don't have it um connected I realized some other things I forgot in the first video but that's okay okay so uh what's the next thing that you want to do so let's just make sure things are working one of the things the connect gives you is that depth image because I said and it depth so in nit depth there are two ways I can look at the depth I can look at the raw depth values with the connect version two these are numbers between 0 and 4500 with the connect version one these are numbers between 0 and 248 U these relate to millimeter measurements um but what I want is get depth image and you can see I what I'm you doing here is I'm asking the connect to give me this depth image and store it in a variable called image and now what I can do is just draw that image on the screen to make sure things are working so we can see here and there it is so there is the depth image you can see I've got it and now it's on the screen so this is the goal of the library it's pretty easy to work with in terms of just getting the data so let's think about what you might want to do so I think most almost all of the uh almost everything that you would do where you're working with the raw depth data or with the depth image involves iterating over all the pixels you want to look at all the pixels and see which ones are the ones that are closest you want to look at all the pixels and see what's the highest point of the closest thing or you want to look at all the pixels and say what's the sort of topology of the entire thing so all of those statements I said involved look at all the pixels so before I get to doing anything here let's talk about what it means to look look at all look at all the pixels so this is something that I've covered in some other videos a whole set of videos about just image processing um from you know jpegs pngs webcams that sort of thing you could refer back to those I'll I'll make sure I link to those at this moment in the video um but just to remind you if you have an image whether it's a depth image or an RGB image that image is a grid of pixels and we typically as human beings look at this as a thing that's twodimensional and it has a bunch of columns and it has a bunch of rows and usually we think of the columns as the X values and the rows as the Y values so you might think of this as like the columns numbered like there's five columns numbered 0 through four and there's uh four columns numbered 0 through three and so if I were over here this is pixel 3 comma one so this is how uh I think of pixels and images and this is the this image over here this depth image is a big grid of pixels columns and rows the thing that you have to remember when working with stuff like this is that the computer is actually storing all of those depth values all of those brightness depth values in this singular onedimensional array 0 1 2 3 4 5 6 7 8 9 Etc and those numbers correspond like this the counting goes across comes down here uh comes down here comes down here so you can see I've got 20 pixels because I've got a five 5 by 4 grid 5 * 4 is 20 the pixels are numbers 0 through 19 so what we need is a methodology for if we're thinking of the XY how do I convert that to the location that's in this onedimensional array the index into that onedimensional array and the formula for doing that is x + y * width and you can see how that works because if I look at this column index two over here 2 + 5 is 7 7 + 5 is 12 12 + 5 is 17 so the width to finds those numbers as they go sort of down row by row by row so if I say 3 + 1 * 5 that's 3 + 5 which is 8 and you can see that's eight right here so this is the formula that you're going to have to get used to because what I'm going to add is Loops I'm going to say Loop through every column and loop through every row row to look at every spot in this depth array so if I come back over here we can now add that to our code so for example I can say right here for every X from zero to and I'm going to say image. width uh not I and I'm going to say four every Y and again if this this idea of a nested Loop is confusing to you I would refer back to some previous videos about image processing but what we can see what I would like you to see here is how this is the loop to say I want to look at every single depth pixel so it could be I want to search for the closest one or I want to search for the for the the furthest away one right or I want to just visualize every pixel in threedimensional space so for every X from zero to the width for every y from zero to the height and now what I could do is say what is that index how to apply that formula now x + y * image. width and then the color is is the color that's in that pixel even though it's a depth value it's turned into a grayscale color is the image. pixels at that index so this is now a loop that you will see in just about all the examples I intend to make today where I'm looking at every single Pixel and finding its index into the depth the the into that depth image and pulling out the color that's there so what might I do with that I could make a point in threedimensional space Let's do let's okay let's do something thing here let's turn what we're seeing on the screen let me run this let's turn this into a lower resolution grid so let's look what I'm going to change this program to do right now is just look at every 10 pixels or every 20 pixels and draw a rectangle with that particular uh color there so let's do that real quick and I'm going to say so what one thing I'm going to do is I'm going to change this to uh brightness I'm just going to look at the um I'm going to look at the brightness of that pixel which is just a single value between 0 and 255 and I want to draw a rectangle at XY now I'm going up by one pixel so what I want to do and you'll see this in some of my examples is I want to introduce a variable called Skip and I'll say skip equals 20 because that's how many pixels I'm going to skip instead of looking at every single Pixel right now I'm going to look at every 20 pixels um and EV then I'm going to draw a rectangle at every 20 pixels and I'm going to fill that rectangle with that particular color so if we run this we should see exactly what I had before but just it's much lower resolution so that you can see I'm still looking at all of the pixels finding its color uh uh from the from the pixel array and then drawing a rectangle of some size arbitary size 20 at that spot so you can see as I move around in front of the connect you can see my hands here and you can start to see like ah this is the kind of thing that computer visionwise it might be easy to pick out my hands as the sort of singular blobs the rectangle but by through a translation because ultimately I want to translate along the threedimensional axis so I use push Matrix and pop Matrix to save and restore um that transformation State these might be Concepts that are unfamiliar to you I will refer you to a different video about Transformations but you can see I have the same exact thing here so instead of drawing the rectangle at XY I've now translated to XY and drawn the rectangle at 0 why am I doing this because now I could add something I could add a z here so the first thing I might try is just say okay well what is this Z let's make this Z equal to brightness and you can see here what do we got we've got as I uh it's kind of hard to see but you can see some uh some rectangles are further in front than other ones that are further away so the brighter ones are closer and the darker ones are further back this isn't really this isn't really doing me any good because actually I think what might make more sense is to have the Clos closer ones be more forward and the further ones way be more behind so I want to essentially position all these rectangles about where they actually are in physical space and so to do that I might do the map use the map function right because we know the brightness has a range between 0 and 255 but what I want is to now have a z value this zv value that's coming out of the screen I want things that are dark to appear close and things that are bright to appear far away so maybe I'll have the things that are looking at their brightness value and mapping it now the truth of the matter is if if I was really doing this what I probably would want to do is actually just look at that raw depth data if I'm trying to visualize the data in 3D this is not exactly the quote unquote correct way of doing it so that's what I'm going to show you in the next video how instead of using the depth image how you might make use of the raw depth data those numbers which are between zero and 4500 okay thanks for watching and I'll maybe see you in the next video okay uh okay um um so is the is it in the in Connect I'm seeing some in the chat I wonder if with the connect version one it's not in it device which is something that I'm learning right now let's go let me open up one of the examples for The Connect version one uh yeah I don't think you actually need the init device for The Connect version one I'm looking at the example right now the the init depth and init video stuff just turns it on um so I think you don't need that function um let me open that uh I'm looking in the chat to see if there are any more the depth range is different I believe between the two models I believe the second version has like a longer depth range um yeah uh okay so that wasn't my best work uh okay so I'm trying to think I'm going to trying to think of what would be most useful to do next um I said I was going to look at the raw depth data um so I think will and then maybe with the raw depth data I'm going to do a thresholding thing where I'm going to uh only show you pixels between certain distances and in that sense I'm going to get just the human form I wonder if I should do that in um Advance who's coming to get me Victor um okay uh I'm trying to think of what else I might be missing um uh uh yeah okay um all right um okay sorry everybody I'm I'm spaced out for a second everybody doing okay Sirens oh yes the sirens are coming to get me thank you uh okay so let's go on to the next topic what I'm going to do is open recent so I think I'm just gonna not going to build this one from scratch this one I have ready in advance which is just doing the point Cloud why did this break had this working a second ago um oh something's already running that's why um um yeah so this is a more accurate way of doing the um the the thing that I did in the previous one um so I think I will show this example which uses the raw depth data and then I'm going to use that to um to do some sort of thresholding as well so I will change this into something else uh okay I think my live stream is like way behind me um like 10 minutes behind um but who knows okay I better get on to the next topic uh so let me close this one okay um okay Point Cloud uh uh sorry everybody I'm just getting this ready that's funny because the X and the Y okay hold on I'm doing something here okay okay this is going to do and I'm going to have that go a lot slower okay sorry I'm ready for the next video let me cycle the cameras and drink a little water my phone battery must have died by now let me see where the okay here we go everybody um s over I need a little I need a little energy boost here should have gotten more coffee this morning okay hello in this video I want to look at look I want to hello in this video but that hello was like a little bit creepy hello in this video I plan and hope and I'm excited to look at the raw depth data meaning not the depth image not the depth values um converted to a grayscale image but actually the raw depth data that's coming out of the connect itself so again with the version two connect you're getting numbers between 0 and 4500 with the version one connect you're getting numbers between 0 and 2 48 and to demonstrate this what I have over here is a simple processing sketch that's drawing a whole lot of dots on a plane in threedimensional space and that plane is rotating rather slowly so what I want to do is and this is what's known as a point Cloud I want to take every point on this plane and give it its actual physical reals space no wait wait wait let me say that again okay the connect is seeing all these points I am all these points in a room and the connect is seeing me and I want to move these points around but this is like the weirdest thing I've ever had to explain and it's like the it's like totally simple and it would just make sense if I just showed it to you yet I insist on trying to explain it in this weird way but I want to take all the points that the connects are seeing in this physical threedimensional space where I am and I want to move these virtual dots which are on the screen in this virtual 3D space and that's known as a point Cloud this is how you might start to build a 3D model of what the connect is seeing in the space so the the the the key difference here uh so one thing that I had before in the previous video is we were looking at this pixelbased image right this idea of each image each pixel of the depth image has a value between 0 and 255 and it's a brightness value based on how far or close it is now the information is stored in exactly the same way inside of this a big array um but uh instead the numbers are between 0 and 4500 so how do we work with these numbers so let's come over here and uh going to do a couple things in this video but this first point Cloud example I mostly have the code already so you can see here that what I'm doing is looping through the connects width and height again I'm skipping because I don't need to do every single point I don't need to do all the points just to visually get this effect um and then I'm finding the offset off set into that array so x + y * connect to.wi so that's how I'm going to look up into that big array of all those depth values now what is that array that array is called is I get that array by saying connect 2 dot get raw depth so when I said get depth image that gives me a p image object with pixel values all in it now I just get a big integer array again those integers are between zero and 4500 so they're in that array and I can say the depth is uh I already use the depth is the offset into that array now there's something else going on now in this function what it's doing is there's a function here called depth to point Cloud position xyd X is the pixel X Y is the pixel y d is the depth that the connect is seeing there's sort of there's a strange thing that's happening which is that the pixel we we look at all these these uh pixels in a grid and we get this raw depth value but the connect itself um there's some math involved in how that can actually converted to real measurements in physical space like where is the actual X where's the actual y based on like how the camera is seeing it so in order to do that this particular example has just this function which essentially you want to download these examples and copy this verbatim um but this function is using all of these kind of uh par parameters that are built into the hardware itself so these are like a whole set of numbers and values that are just part of the connect calibration and you kind of multiply and divide by these numbers and you get the actual value of where it is in space sort of an interesting problem I would love to like go through it at some point but right now I'm sort of inclined to sort of skip it and say the interesting thing is what you're getting is if you give the raw depth value the pixel X and the pixel Y and use that function you're going to get the X Y and depth values in millimeters back of where those things are in physical space so I don't want to in fact draw the this is what you're seeing in this particular visualization right now is just all of these pixels at their exact XY and XY value with a zero depth so what I want to do is change this program to say this actual physical point this P Vector the P Vector is an object that has an x a y and a z i want to draw the vertex at point dox point doy and now point point doz and in order to make this a little bit better I'm going to skip fewer pixels I'm going to skip only four and I'm going to run this again and now you'll see here I am this is the point Cloud this is me in threedimensional space so if I zoom in on this you can start to see like what's going on this over here by the way is the wall it's funny how I can like put my hands on the wall it's almost as if I'm distorting the wall but really what I'm doing is I'm casting a shadow um so it's a little bit strange to see this view of me and my connect I could like no I would give myself a hug that's a little bit weird too I was like punching is weird hugging anything that you do I don't know just scratch all that but you can see here this is now a visualization in threedimensional space you could connect these points with lines you could color them there's a way of actually getting the RGB values and so you could see like the colors that are on my shirt on these points as well this is a road you could go down and I find this road to be particularly interesting but what uh and uh you can see that I'm I'm using just a simple y rotation so now I'm kind of like spinning around this image which is now gone off screen um but if I zoom back in you can sort of see it's over there um so this is kind of the start of sort of thinking of like what can you do with these raw depth values I think what would be a useful demonstration now is to look at how might I actually pick out just me so you can visually see just me but there's a sort of Nest there's like all this stuff over here there's this over here um there's actually like this pole over here that's being picked up by the connect so what I you know what if I just wanted to like even only get my hand right here what I want to do is try to calibrate a threshold so what if I want the connect only to see the connect's over here remember so it's it's to the left of me I don't know what what side that is you're viewing but what if I want to say only look at the pixels in between here and here and that would conceivably get my hand right how would I do that how would I look only look at the pixels between a certain minimum and a certain maximum let's look at that so one thing I'm going to do is I'm going to save this as um I know what to call this min max threshold um and I'm going to get rid of all this 3D stuff for right now uh because I'm not going to do this with you could do this with visualizing the point Cloud still but I'm going to do this with just uh and I'm going to look at all the pixels so I want to do x++ and Y ++ and somebody remind me what's the size 4 512 484 is that right I don't know if that's right um and so hopefully that's right and then what I want to do is I don't need end shape I don't need I don't need begin shape I don't need any of this stuff what I want to do again and I don't need this depth to point Cloud thing I'm taking all of that out because what I want to do right now is just go through this double nested Loop and look at every depth value 0 and 4500 but I only want to like count the ones that are between 200 and 400 or between 500 and 800 what is that what's that minimum and what's that maximum threshold okay let's make this happen so the first thing that I should do probably is uh I would like to make myself just to be able to see this I'm going to make myself an image and I'm going to create a blank image which is the same as the width and height of the connect uh and it's an RGB image so this is a function in processing create image that just makes a blank image and then uh whoops and then what I'm going to do right now is I am going to in here I'm going to right here I'm going to say image. load pixels because I want to operate I need to operate on the pixels of that image I'm going to set pixels in that image based on the raw depth and the end I'm going to need to say image. update pixels and I'm also then going to want to draw that image so just to make sure that things are working what I'm going to do is right here inside sorry this is where all of the important code needs to happen right now it needs to happen right here inside this double Loop right for every X for every y I want to set a pixel in the image image. pixels index offset equals and I'm I'm just going to set it to be you know some color right now some purplish color and run this and we should see that that's working U okay so you can see this purplish color I clearly got the size of the window wrong let me just let me just get that for you guys really quick so if I go back and look at my RGB depth test um ah this isn't telling me Oh actually you know what let's just be smart about this um I want to just know what those values are I'm going to print out I'm going to print out the the the depth width and the depth height really quickly uh we can look in the console 512 424 I knew I had some was close so let me just get that right now and I I don't need this much of the console here and I can get back to the important part of the code we can run this we can see okay purple so I have now filled every pixel on the screen with purple but what I want to do is fill every pixel on the screen based on the depth so for example what if I were to just say if d is greater than 300 and D is less than 1500 image. pixels offset uh is that otherwise image. pixels offset is black so what I'm doing is I'm saying only if the only if the distance is between 300 and 1500 let me see a purple color otherwise let me see a black color and when I run this we should see oh my God I can't believe what I guessed I'm like a genius here I somehow guessed a pretty reasonable uh threshold so you can see here that now what I've done and now you see like all computer vision problems Melt Away in a way like uh what I could do now is like it's so easy to find the I mean not easy but it's much easier now to find the Contours I have this problem of this wall over here so how do I get rid of this wall well first of all the real way that I get rid of that wall is by not doing my connect stuff right next to a wall so unfortunately this is like a bad I need a better setup I think for doing these videos which someday maybe I will find but what I want to do let's at least see if I can get the hands so one thing you'll notice here is that the hands go away once you're about a foot and a half from the connect so what I really want is between about I don't know between zero and maybe like 500 so there's probably a better way for me to calibrate this than just randomly picking numbers but let's give this a try you can see nothing nothing nothing nothing nothing nothing nothing nothing nothing oh that didn't do much any good so so let's uh uh so I you know I whoops that's not going to do me any good either uh let's do between like 200 and a th000 nothing you can see uh like right but if I come in theit so you can see here how like I'm able to pick out only my hand uh again I've got this problem with the wall so I'm going to do something about that in a second uh to maybe try to like just like not look at the pixels on this side of the window I guess um but you can see how you I'm starting to find this idea of a minimum and a maximum threshold and really I should make these variables so I'm going to say A Min thresh is 200 and Max thresh is 1,000 and you know I might as well make these floats because what could be also useful I think the way to I could calibrate this right here's a great way I could calibrate this so in between the minimum threshold and the maximum threshold what I might do is up here I might say Min threshold equals map the mouse's x value which goes between zero and width to between 0 and 4500 uh and the maximum threshold I'm going to do Y which between 0 and height 0 and 4500 and then I'm just going to print out those values I could draw them on the screen which would probably be let's draw them on the screen so then down here I'm going to just fill 255 text size uh 32 two uh text Min thresh plus oh I got to use um double quotes Max thresh you know 10 comma 64 so here we should see on the screen these values so now what I need to do is figure out like what's a good uh whoops wait X is going between I'm doing I'm lost what I'm doing something is wrong here uh Mouse X between oh this is Max thresh yeah that's a problem uh okay so now you can see I'm able to like calibrate the minimum threshold and let's calibrate the maximum threshold like how far back am I seeing but the minimum needs to be higher and then I don't want to see too far back so there we go so this I feel like is good if I'm getting my hand right now it's between about 480 and 827 so let's like only if I'm standing right here of course but you know you could design an interactive exhibit where you put some footprints on the floor and the person has to stand there so I'm now going to keep my hand boy this is a long video I'm at 15 minutes I'm going to keep my hand around here I'm going to make the minimum and maximum 480 and 830 so now I can comment these lines of code out and I'm going to say uh 480 and 830 and I'm going to run this again and we can see I'm kind of I'm getting my hand like really I'm getting a pretty good tracking of my hand so one thing that I'm going to do now of course which I think would be useful is try to get rid of this wall over here so you know the wall is a bit of a problem but I can kind of uh do a little bit of a cheat here I think which is also to say if and and X is greater than I don't know what how many pixels do you think that was that was probably about uh 75 pixels so uh maybe it's a little bit more so I'm just like not allowing me to measure anything that's like 100 pixels over so you can see I kind of got rid of that wall and now I have my hand so this is great you can see like this really nice clean outline of my hand because this is my other hand coming in it's not inside until it gets there right it's outside of that maximum threshold and now it's inside of that minimum threshold it's funny how it like oh no my arm is coming in so of course if my whole body comes in now you can see my whole body is here which is another thing that I want to look at so um you can see how this minimum and maximum threshold is working pretty well so I think this is this wraps up this video I'm going to continue this exact example you could try this on your own as an exercise before you get to the next video how would I actually just find the center of my hand so I could control a processing sketch Now by moving my hand around or moving this hand around or what if I do both hands so how would I do that this is I feel like I'm like I'm some sort of like magic person here um so that's what I'm going to look at in the next video how do I find the center of my hand and control something else like a little like snake that's moving around the screen or make a particle system come out of my hand we'll look at that in the next video and another thing I want to look at is how would I find the top of my head so if I'm the human being here how do I know if I'm bending down or standing up okay so we'll look at that in the next video thanks for sticking with me here I think this is actually starting to come together okay all right chat is anybody there um okay how is the hand Edge drawn in black um okay 424 you guys are telling me in the chat you're so nice uh boy the the live stream is like way behind me I think oh no I've DVR I'm I'm like I'm behind okay I don't need to sorry I'm how's everybody doing uh I got to refresh this page that's my problem oh no I just need to be here ah no wonder I'm in the wrong place uh sorry everybody um I gotta close this come back here there is 23 people watching um uh hi Sean uh welcome everyone I'm about to do in the next video I'm going to demonstrate how to find the center of my hand so and then I'll make a particle system come out of it which I think will be loads of fun for every all the family it's a family holiday family edition of the coding rainbow today and Thanksgiving uh I'm going to drink a little water here um I got to cycle the cameras okay um so I'm just about ready I'm seeing if there's um somebody asked when do you think you can upload the videos uh I will most likely upload the videos uh by the end of the day today tonight um or certainly tomorrow morning guess I'm going to do it as soon as I can uh and if they're not there you can always twe but this will always be there um this will automatically be archived and on YouTube this like a long thing but the so far I've made two three videos they're each about 15 minutes those will be uploaded tonight I don't so many Sean's asking if anyone ordered me pizza yet first of all I don't eat dairy so don't order me a pizza a little like you know vegan tofu quinoa salad things is like more in my speed um but don't order me any food I'm fine I ate a big breakfast I'm feeling good I got to probably this Thanksgiving thing is going to happen tomorrow and I'm going to have to eat this like giant meal uh so don't worry about me I'm fine uh um okay uh what was I going to say I don't remember I think I'm ready for the next video okay so in this next one what I'm going to do is look at how to find the center of my hand right we did this thresholding here and now I'm going to find the center of my hand and let me get a particle system example open it's probably overkill for me to bring that in but it's uh I'm let's let's do it it's totally worth it uh so I'm g go under topics simulate a simple particle system I'm going to change something here really quick about this particular example um uh I really wish I didn't make the example the way that I made it uh uh yeah what did I oh add particle H shf man okay let's see if this works okay so I'm going to make this these particles come out of my hand as I move that's going to be fantastic okay that's going to be the next example yeah yeah read only read only shme only okay so I'm going to go back to minmax threshold and here we go I'm going to hit run here uh and I'm ready to do this video uh thanks for sticking around both XP goodbye Cardiff England uh Wales which is part of the UK and whatever I my geography is off sorry okay here we go ready uh did I cycle the cameras did any remember if I did that I don't remember so I'm going to do that uh let's see oh I'm running low on battery for the microphones but I think I've got a full bar and I've got three bars on the one in my pocket so it should be okay try to keep an eye on that and over here if I stand about here that's where the hands are okay great okay here we go in three I'm going to close this in three I have to press the button there's nobody here to press the button but me hello um in this video I'm going to demonstrate some really basic basic hand tracking with the with the connect and I'm going to make a particle system come out of my hand that's what we're going to look at in this particular video so in the previous video what I did is create this sketch where I calibrated a minimum threshold and a maximum threshold so I'm only looking at depth pixels between those values so if I stand exactly here and move my hand around I can you can kind of see a pretty clean outline of my hand of course this breaks down if I stand too close or if I stand too far away but you know and so I should mention that ultimately this type of of hand tracking might be better suited for the official Microsoft SDK and I'll get to that eventually using a PC and different uh uh processing connect library but I think it's still nice to see these examples of how you can do this stuff with the raw depth okay so let's look at how you might do this so this is where we are we're looking for all pixels that are in between a minimum threshold and a maximum threshold so how might I find the center of all of those pixels right here in the center of my hand well the way that you find the center of something off sometimes called the centroid if you want to sound like you're from the future let's look at the centroid um is by finding the average location so let's say we have a collection of pixels you know that are Loosely this is some strange like threefingered hand right these are all the pixels we care about we can plainly see that this is the scent about around the center but how would I find out the average well let's say you just had these X values this is the x value zero three uh you know 4 8 12 to find the average of some numbers add them all together and then divide by the total 0 + 3 + 4+ 8 + 12 divided by 1 2 3 4 five divid five is the average so if we add up all add all x's and we add all y's and we divide by total pixel not the total pixels in the entire image just the pixels that we've picked out that are in between this minimum and maximum threshold then we'll find the center of that area of pixels so let's look at that how do we inside that Loop add up all the X's add up all the Y's divide by the total number of pixels it's actually a pretty simple thing to do this might be the shortest video I've ever made um I'm going to start I need some value to keep track of the the sum of all the X pixels so I'll add that in then I need another variable to keep track of uh summing up all the Y pixels so I'll add that in then what I also need is a just a total pixels zero now I'm making all these floats because I think it's going to be a bit more accurate to use floating Point math doesn't really matter they're they're technically the they're integers there's no like pixel 3.21 but it's a little simpler to work with floats so this value is where I'm going to add up all the X's this value is we're going to add up all the Y's this is going to be the total number of pixels remember that's not a fixed number like depending on where my hand is how many pixels is it picking up that's um that's going to be the total once I have that I can divide some X by total some y by total and that's going to be average X and average y so let's look at that so right here these are the pixels that count right these pixels right here are the ones that are pink those are the ones that are between the minimum maximum threshold that X is greater than 100 was just to get rid of the wall that's over here because the wall is 100 pixels and over um so in order to do that now I'm going to say right in here I'm going to say sum X Plus equal x sum y plus equal y like I'm literally just adding up all the X's adding up all the Y's and then total pixels plus plus so for every single Pixel just add one I need to add up the X values for the X the Y values for the Y and then figure out how many pixels are there and then at the end what do I got I've I don't need to um draw this text on the screen anymore what do I need to say I need to say the average X right the average X is the sum x divided by the total pixels the average Y is some y divided by total pixels and then now why don't I just draw let's make this a different color why don't I draw an ellipse at average X average Y and 100 um I don't know what what size should that ellipse be 64 by 64 so let's run this con that says add particle Mouse X Mouse y right so it's just as easy now as bringing all this particle system code over and saying instead of adding the particles at Mouse X Mouse y add them at average X average y so uh let's see if we can make that happen I'm going to bring I'm going to do a quick little I should have probably do like the cooking show thing where I have an now coming out of the oven I already premade this but I'm just going to copy paste everything over real quickly I'm going to bring the particle system object I'm going to put this in my setup over here and I'm going to put this stuff in draw and at the end here and then what do I need I need all this particle code so I don't actually need this camera prams tab for this example uh oh hold on uh uh hand tracking sort of particles I don't know what to call this uh I'm going to get rid of this uh tab C camera prams uh and then I'm going to add a new tab I really shouldn't be doing this in the video I think I crashed processing hold on no everything's fine I'm gonna add a new tab called this was not this was not good you fast forward fast forward a minute I'm gonna move the particle system over that was the particle class and I'm GNA duke it doesn't matter I'm to move the particle over just imagine that I did that correctly I'm going to run this which we can see right the particles the the circle is following my hand the particles are following the mouse how do I make those do the same exact thing now all I need to do is say make the particles not at the mouse but at average X average Y and you know what let's let's actually add about 10 particles per frame to make it kind of make more particles and let's run this and we can see now as I put my hand here I can like control where the particle I can make this like fiery thing come out of my it's not fiery but come out of my hand so you can see I'm now using my hand to control particles coming out I can do my dance and it you know works with anything like I can I can have part like this stuff like emanating from my it's like alien and like bursting out or something I don't this is all getting a little bit weird but you can see I can I can strike this pose and uh it's running kind of slow because I'm drawing like so many circles on the screen um it was a little bit unnecessary to like do that much but you can see anyway so I can make the particles move faster you can you can get where this is going here so this is one example of what you can do by having a kind of specific setup knowing where all the pixels are thresholding them finding the center of something um this is what you can do now let me say a couple more things before I go into the next scenario number one uh um and let's um let's turn the particles off for a second number one is we have this issue of one hand two hands the thing in the center on the one hand this is kind of cool I'm like I am a magician levitating a ball around I I forgot that I was making a video for a second on one hand that's sort of an effect on its own feature not a bug type thing on the other hand you might actually want to have a circle for each hand and in that sense you need to employ a more sophisticated blob detection mechanism for example you don't want just the average of all of the pixels you want the average of a bunch of pixels but don't include pixels that are over a certain distance threshold from other ones so this is something that I could potentially demonstrate in a future video in this series I'd be happy to add one in but also in this case one thing you can do if you have this very clean image you can pass it to a library that might do that type of edge detection blob detection Contour detection for you and there's two libraries I'll try to link to them in the description that I might recommend one is called blob detection does kind of what you're thinking another library is called open CV which has a lot of computer vision functionality built to it but one of the things in it is blob detection so maybe I'll try to like show that at a certain point but you can see the basic idea here is still just working even without uh an extra sophisticated layer of looking for separate chunks um okay thanks for watching this I think in the next video I have two more that I intended to do today although it is 1210 I wanted to see if I could look at for the top like how do you find the highest pixel um or Theo you know closest pixel is something you could also find but I think highest might be interesting because uh somebody here at ITP has a project that she's working on which is uh having somebody move up and down so I think that's a useful demonstration and then also maybe looking back at that grid again um but averaging all of the depth points within cells of a grid okay that's what I intend to make next I'm G to hit stop on the record button uh come on wake up okay everyone uh all right everyone yeah I see some are chatting about me in the Stream it is true actually I didn't actually code start programming until 2001 I was 27 years old 2001 you can figure out how old I am now I did take some programming classes in middle school middle uh Assembly Language and basic uh I also took an evening C++ Course once because I thought it might be interesting in programming and I was like this didn't like it uh but then I think being in a creative environment like ITP I got kind of obsessed with it so that is true uh um okay so uh I forgot when my I have to check when my office hours are because I have to go soon unfortunately I have to grab something to eat before let me just I'm looking this up right now uh they start at uh shiffman shiffman shiffman where's shiffman uh at one I I'm not going to give the time okay yeah 120 I need to take a break obviously to eat something between them so so I think I could manage a little bit more because I want to do I think I could try to do these two examples real quick um so let's look at the um yeah there's a problem where I need to file the open CV is not showing up in processing 3 but it actually works in processing 3 it probably just needs a few little fixes um uh I I would love to I uh Greg Borstein who did a tremendous amount of work creating this Library um I should look at it and see if I can uh just put a pull request quickly on GitHub to or to make sure that it shows up uh in processing 3 because it does work in processing 3 there's probably just a few little things that need to be fixed um okay I'm going to I'm going to get a little more water I'm going out into the hallway and I'll be right back okay are you watching this from here okay you were sorry thanks Sean okay okay I'm back everybody uh I'm going to just get a little cool air in here for a second um I'm going to turn off and on the cameras Oh I have to go around this side okay uh let's see here I'm over here I'm going to erase so the next video that I'm going to make here oh wow there's quite a glare from the sunshine over here wonder if I write over here if you can't see it yeah you can't see that very well so I'll just be conscientious of that I I just can't bear to like black out the window in this room it's I did that last year and it's like miserable to be in here so much rather have the sun infecting me uh let's see okay this is pretty good um okay so in this next video the next thing that I'm going to do is look for the closest point or the top of someone's head uh the highest point that type of thing um which is a kind of common algorithm in computer vision that you need uh uh oh yeah right there was a hot mic again uh and um okay and I'm going to um um here we go I got to close the window I'm going to try to I'm going to try to do this by the way for 15 more minutes I don't know if I can get through both of these topics in 15 more minutes um and then I have to go uh I guess I've been doing this for 1 hour and 36 minutes so far okay here we go uh water's here and getting myself ready I I cycled the cameras didn't I just do that right I can't remember do it again I'm going to check the battery is at one bar still so my mic shouldn't go out in the middle of this okay hello um in this video I'm going to look at how you might using the connect fine the closest thing in the room or the highest thing in the room um this type of algorithm is kind of common in a lot of computer vision applications I think which involves similar hi um in this video I want to look at an algorithm that lets you do the kinds of things like find the closest thing in the room or find I'm doing all sorts of like Vogue poses find the highest thing in the room I don't know why I need to do that for the highest thing but whatever um or uh and this is a similar type of algorithm if you've ever looked at like a color tracking algorithm find the brightest thing or find the most red thing in the room I like to refer to this as like the world record algorithm which means like I've got to look at every single Pixel and keep track of which pixel is the record holder and hold on to that record holder the closest thing the highest thing the most red thing and when I get to the end have that XY coordinate that I can use for something else so a lot of things that you might do with the raw depth data of the connect could involve this like if you know the person is always standing like this in a fencing pose what is where is their hand because their hand is always the closest thing or if you want to determine if a person is moving up and down how do you find the top of their head what's the highest thing within a given threshold so let me uh go over to the Whiteboard for a second to just talk in generally speaking about how this kind of algorithm works and then we'll go and implement it in a couple different scenarios okay so as with just about everything that involves IM and pixels or depth points you've got this grid right and the grid has a bunch of x's and a bunch of y's and there's always this Loop all the examples have this for every X for every I look at every pixel now I've got some glare here so hopefully you're going to be able to see what I'm writing but I was to to say shout at me just shout at your computer screen or wherever you're watching this and I will hopefully hear you someday um if you can't read what I'm about to write but uh but so the way that this works is you need to find the record holder so what let's say we wanted to find the um uh the closest thing so remember the depth values are between 0 and 4500 so we could start by saying the initial record right the world record for the closest thing would be 4500 because that's the furthest back so any pixel that beats 4500 is the is by definition the new record holder so we have to say something like if I have the current depth in a variable I need to say if that depth is less than the record then the record is now that depth so this is the core algorithm for every pixel is the first one beating the record it is that's the record holder is the next one beating that record no is the next one beating that record no is the next one beating that record yes okay that's the record holder and while we're doing this we could also keep track of you know the record X and the record y so if we went every time we get that new record we store that X and Y so that by the time we get to the end of this Loop in those variables are the X and Y that win this record so let's look at how we might do that um and I will come over here and let's look at let's do um okay let me save this I kind of want to do the closest thing this what we talked about but you'll see that it's not going to work in the most perfect way but let me save this as uh a closest uh thing and I'm going to um I just want to delete the particle system tabs which are no longer relevant uh oops don't delete that tab ah I think I made a mistake earlier and I'm going to get rid of all this particle system stuff sorry I should have done this before I started recording this but it's too late now um we can get rid of all this particle system stuff and and I'm going to get rid of the average thing that was interesting that we were doing in the previous video um and even such I'm going to keep this I'm going to keep this thresholding in here because I think that's maybe a little bit useful um to kind of keep at the moment actually you know what I'm going to take that thresholding out but I'm going to keep this x is greater than 100 and uh what I would like to do is H too much too much going on that I didn't think to do in advance it's okay everything's fine just you know Talk Amongst yourselves for a minute or fast forward like 30 seconds in this video and I will be at the point so I just want to take out all this stuff let's keep the um uh and uh yeah this is fine uh what I ah I know what I need to do everything's fine uh I'm going to draw I don't need this image anymore uh right what I'm going to do is what I want to have access to to look at sorry everybody is the um the raw depth image I'm not sorry the depth image as well so I'm going to call this the D image equals connect to.get depth uh image so that way I can draw that image on the screen and so let's just make sure this is now working so you can see okay I've got the depth image on the screen so what I want to do now is look look for the pixel that is the closest okay and we've got a bit of a problem here because some of these there's a window back there and it's going to give me some weird zero values so I think this this might not work oh and I should have kept the thresholding crap I should really you know what I'm GNA I'm going to hit stop on the recorder for a second and I'm going to just uh Stitch these Stitch This Together from when I move from over here over here ah crap I I wasn't thinking straight there okay I'm pausing for a second uh all right um so let let me let me figure this out here closest let's just see how this works I'm going to build this I'm going to pause the video I don't I I should have checked this in advance I'm going to close this so what I'm doing now I'm going to come back and record again in a second what I'm doing here is and I can delete all this stuff I'm need that threshold again in a second what I'm doing here is um looking for okay okay so I need the uh record is 4500 and the record X is zero and the record y uh record Y is zero and I'm going to say uh if D is less than record then record equals D Record xal X record yal Y and I need to close curly bracket and then at the end of all this looping I can say uh draw an ellipse at record X record y that is some size that's kind of big uh and let's see how this goes okay so you can see the problem is that it's always in the top left U it's a good thing so what I should probably okay so one thing that I was going to do right is Skip uh skip these pixels uh let's try this and let's see can I get it to be something problem is there's too much glare and reflection back there so I should do the top I should just do oh I I as I got over here something became closer than what's back there my head oh yeah I'm kind of able to get this to work if I come really close but not it doesn't work so great because I really should be there we go why is it if I move I must have messed something up record yals y record xals x no that's right um what I probably I probably should do the top of the head thing why is it not it's interesting how so I think this is a bad demonstration I um which is a mostly because of the setup I have here like if I had if I had the connect over here and had this flat wall behind me it would work pretty well um I could look for the thing that's closest within a minimum Max maximum threshold which is probably I should have kept that um but I think what I might do is put the threshold back in and look for the I should put the threshold back in so let me bring that back uh I still have that here so I want to say if uh so let's bring the threshold back in if so I only want to consider stuff that's if D is greater than Min thresh and D is less than Max thresh and um X is greater than 100 I think is what I had then then I can look for the record uh thresh so this should right now this is working you can see how much it jumps around but you can see it works with anything that's within that threshold that's closest which right now if I bend down is also my head but course as I move out of the threshold so you can see how like unstable this is but I think that could sort of do the demonstration I actually want now also to have that image back now uh which is that I should say um uh what I should be doing is uh I think this would be hold on I you're kind all to stay uh set the initial record to the highest possible didn't I do that um so what I want to do is put that that um the uh image back in too so uh image that load pixels so I'm going to say um uh image dot here let me turn off I'm going to turn off the code completion uh else else uh image. pixels uh offset equals D image. pixels offset and I'm going to here say uh image. pixels offset equals uh color uh 2550 150 and then uh this should be a different color uh so I oh and then I need to draw that image also let's see up whoa hello connect that is the weirdest thing I've ever seen what just happened there whoa what is going on oh some other imag is there whoa what is going on oh I didn't say image. update pixels must be why there we go so I should see like when the stuff is within the threshold I'm finding the closest thing within the threshold um which might be like my elbow uh that sort of thing maybe that minimum threshold should be actually like lower anyway um okay so sorry okay I'm gonna I'm going to I'm gonna start this over and I'm going to start it I'm going to take this out and I'm going to take this out this is the stuff that I'm going to add in and I'm going to take this out so now what it should be I've just got something where it's showing the only the threshold of pixels but also all the rest of them and then I I really want to do the top of the head thing because I think that might actually work much more accurately um to find the highest pixel that's within the threshold but I'll do the closest and then the top why not right okay um so I now have to pretend where was I I was over here and I was talking about this stuff and then I finished and went over to the computer to talk about something else so I'm going to do that again shoot this is going to be this is definitely going to be uh whoops this is definitely going to be um come back come back this is definitely going to be it for today once I get through these two examples because I really I'm I'm like sort of late now we have 45 minutes till my first appointment I need to eat something in between so but I I want to I want to get through this so to have this done okay so here we go I think I can do this now um with this particular example uh so I'm gonna have to like cut this somehow I I I hate it when I do editing this is I'm not really going to do editing I'm just going to splice these things together and I'm going to uh pretend okay so I'm going to walk into the scene over here I'm afraid am I recording this I am yes okay okay so to demonstrate this example now what I have is I've I've adjusted this example a little bit and what it's doing now is it's showing you both the depth image as well as coloring particular pixels of that depth image this pink color that are within this threshold so now I need to figure out what pixel in that threshold is perhaps a record holder of some sort of record so we'll look at the closest thing and also the highest thing and I'm pretty sure the closest thing is going to not work that well but the highest thing I'm hoping is going to work pretty well so let's do the thing that's not going to work as well first um and let's just look at a little bit of what's changed in the code just to to show you so first of all I'm looking at the depth image as well and then what I'm doing is if the pixel if this um depth value is in the the threshold I'm setting that particular color to this pink value if or purple value I don't know what color it is I can't tell uh if it's not um then I'm just pulling the color value from the depth image itself then updating the pixels and drawing the depth image so that is why you are seeing this particular result it's essentially what I had earlier in the previous examples with just also adding in those depth pixels instead of black so now we need to figure out this way of a getting a record holder so the first thing we need to do is say what at the beginning what's the record distance I'm looking for the thing that's closest so the thing that's closest the record to start would be something really really high so the record would be 4500 that's as far as it as something is possible to be from the connect then I need the record X which will be at zero and the record Y which will be at zero so I want to test every pixel X and Y if it beats the record if it does beat the record set RX to that new X and set r y to New Y and then draw a circle at that record value at the end so right here I'm going to check only inside the threshold you know in a different scenario where I had the connect in like an open space and a and a sort of flat wall and people just came into the middle I don't wouldn't really need to do this thresholding thing because I but there's so much stuff in this room there's a desk there's a computer there's a wall that it's not so I think using the threshold here helps it be a little bit more accurate so I can say if that distance is less than the record then the new record is that particular distance right for every single Pixel does that pixel beat the record if it does I've got a new record and if it beats the record then I need to save that particular X and Y in RX and r y so all we need to do this kind of record algorithm is a starting record a starting RX and r y and then every time we beat that record save those two values and then at the end I can draw a circle at RX and r y and I'll just make that Circle uh White uh so it kind of we pick it up and we can see now okay now first of all you can see that circle is just jumping around that's because first of all there's very little there's like stray pixels that are that are making it in the threshold so now you can see that it's kind of working now you can see that white circle is following my hand now notice this is much less accurate than what I did before with a sort of average section of pixels um mostly because anytime you're looking for a single Pixel it's not such a great thing I kind of want to find a group of pixels that are like beating that record but that aside you can see the basic idea is working but it's really like if I come and stand in here like there's a lot of me that's in the threshold but my head as I'm bending over is closer so you can see if I move my hands out they're a little bit closer if my shoulder comes in my shoulder is the closest thing so you can see it's jumping around a lot but it's always finding the particular pixel that is closest it's just sort of demonstrating the idea but let's change it now let's have it find I'm going to stand here to I've beaten that record so record equals that y value save this save the X and the Y and then draw it so the same exact idea I'm just changing what the test is like the height is the yv value if it's less than that record so now we'll run this and we can see it's picking up a lot of noise but if I come in and bend down so there's too many pixels up top you can see that it's flickering there's too many pixels up top that are pulling up some sort of value so I'm going to try to do like a little bit of a hack here again we're going to say and I'm say let's skip uh let's skip the first like 50 pixels I'm only going to look and let's see if this helps there we go so now you can see I'm getting the top of my head pretty accurately if I move my hand up here I'm getting the top of my hand so if I had a particular uh project that wanted to have something move based on whether I'm moving up and down this is good I'm going do some X squats here um you can see that this works so you know I had to sort of like Cal and do some goofy things but you can see this is a very simple way of just finding the top so like people always get obsessed with like finger tracking like let me find the finger but you can see how accurate this is I'm just getting like the tip of my finger now there's no finger tracking here just like if I go like this it's getting the top of my elbow but if you tell people to stand like this and wave their finger you can see how like kind of super accurate that tracking is just from looking this is like the simplest thing ever I'm just looking for the top pixel inside this threshold so hopefully this shows you a few types of things you can can do uh we've seen a range of things of just sort of visualizing the 3D data from like looking for thresholding it in between for tracking the the height of something the average location um this is where I'm finishing this video set today um but there will be some more ones I guess who knows when you're watching this the more ones might already exist the more ones and you'll see them in the next video okay so thanks for watching uh this how oh yeah right uh and I will uh talk to you soon okay goodbye all right everybody um so that's it for today um and uh so if you have any questions I can take questions for like maybe five minutes it's 1236 and I'm going to go in about five minutes um and uh I can take questions and um then I'll go sorry my brain is like totally fried this has been an hour and 58 minutes that I've been on this live stream um so I'll give it a minute to see if anybody wants to ask anything uh uh whoops um see if anybody is um okay uh any important info here um uh okay let's see if anybody ask any questions uh any tips on using more than one connect uh what you want to do if you want to use more than one connect is uh go look at the examples uh in the examples I'm going to come back up here under contributed exam uh oh oh no no contributed libraries under open connect um so this one here multiconnect version this one is showing you actually how to use more than one connect and even a connect version one and a connect version two in the same sketch and here under connect one multiconnect and here in Connect for multiconnect 2 so for example if I just come to multiconnect 2 you can see here um that you can create uh two different connect objects and then init them as init device zero and init device one which will make them separate so you can actually everything works exactly the same way it's pretty simple to be able to do that yeah uh what is the update rate of connect depth data I'm pretty sure it's 60 frames per second but kind of I don't actually know uh I bet you if you Google that there'll be an answer on stack Overflow or something I would love to know the answer to that for sure I I I seem to remember hearing 60 frames per second I don't know that the first version one connect was that but I think the new one is um okay oh yes sorry so okay great so I this is technically how you could have more than one connect hooked up to your computer but you do have certain issues with like you point them at each other the infrared light starts to interfere with each other so trial and error is your best friend here sometimes it just seems to work anyway sometimes it can be a problem if you have a lot of the sunlight it can interfere you can't put a mirror in the room because the mirror is can to reflect all the light so there's a lot of issues around that but um you know for the most part you can have two connects you know if they're pointed in different directions and the infrared stuff doesn't cross they'll definitely work if they do cross I feel like with the new version too they seem to like operate on different frequencies or something and it kind of still works anyway but i'm to be honest I I haven't you know done a lot of stuff with the connect I'm kind of just trying to teach it from like making examples but I haven't with the new connect I haven't really like made a lot of projects with it um okay 2 hours is generally my limit uh I hope next week I've got a real schedule problem but I hope to be back to do at least one day next week but it might not happen but I'm going to be doing these uh in January I might even do these live streams twice a week I'm hoping and then in February I'm going to be doing them a lot is my plan so um so but uh keep in touch ask questions over Twitter put uh comments and questions the YouTube videos is super helpful especially if I mention something that I forgot to put in the description or I could put an annotation in that corrects something that's great so please keep in touch let me know hope this is helpful and I will see you guys soon I'm going to hit stop on this stream