00:00 - hello and welcome i'm your code monkey
00:02 - and here let's learn one of the more
00:04 - basic tasks related to machine learning
00:06 - let's teach the machine how to drive a
00:07 - car this is a classic example and it's
00:09 - pretty easy to do when working with
00:11 - unity ml agents
00:12 - i cover the complete getting start guide
00:14 - in another video so go watch that if
00:16 - you're not familiar with the toolkit
00:17 - machine learning in unity is actually
00:19 - very simple and easy to use once you
00:21 - understand the basics
00:22 - there's a link in the description for
00:23 - the entire machine learning playlist now
00:25 - here we want to teach the ai to drive a
00:27 - car
00:28 - for that we first need a car controller
00:29 - so here i have a very simple one
00:31 - i can move it with the arrow keys and
00:33 - works pretty much exactly like you would
00:34 - expect just a very basic car controller
00:37 - now how this is implemented isn't
00:39 - important for training the ai
00:40 - all that matters is that we have some
00:42 - way that we can interact with this
00:43 - controller by setting forward and
00:45 - turning amounts
00:46 - in this case i have this symbol function
00:48 - set the inputs where i can set the for
00:49 - the mount and turn them out
00:50 - so the ai won't work on any car
00:52 - controller you want to use doesn't have
00:54 - to be this specific one all it needs is
00:56 - to expose a function where the ai can
00:57 - take these actions
00:59 - in order to get our final ai we're first
01:01 - going to teach to drive it in a simple
01:02 - track just doing some left turns
01:04 - then we're going to teach it on a track
01:06 - where the some right turns
01:08 - and then finally we're going to train it
01:09 - on a much more complex track
01:11 - but before we look at the training let's
01:13 - first think of the big picture of what
01:15 - it is that we need for the ai to drive a
01:17 - car
01:17 - so i've got a car here and the goal is
01:20 - for the car to go all the way around the
01:21 - track
01:22 - so think about what information does the
01:23 - ai need in order to achieve this goal
01:26 - well first it needs to know where the
01:28 - track is so we can tell it that by
01:30 - essentially placing some invisible walls
01:31 - on each side of the track and firing
01:33 - some raycasts
01:34 - so just place a bunch of walls all
01:36 - alongside the track and this way the
01:38 - ai won't be able to tell where there's a
01:39 - wall and where there isn't so it will
01:41 - learn what's around it so it can learn
01:43 - to stay away from the walls
01:44 - and then we also need to tell the ai
01:46 - that it's actually making progress
01:47 - so for that there are some invisible
01:49 - checkpoints placed around the track
01:51 - so i can make them a bit visible and yep
01:53 - there they go all the checkpoints
01:55 - so every time the ai goes through one
01:57 - checkpoint it receives a reward
01:58 - as usual when it comes to machine
02:00 - learning the tricky part isn't really on
02:02 - the code
02:02 - that part is very easy as you saw in the
02:04 - getting started video
02:06 - the tricky part is making a good
02:07 - training environment
02:09 - so this is why before you start writing
02:11 - any code you should stop and think about
02:13 - what does the ai need to know
02:14 - just like we did right now so over here
02:16 - i have a brain that i trained previously
02:18 - as you can see it follows correctly
02:20 - alongside the track and goes through all
02:22 - the checkpoints and goes all the way
02:23 - around it
02:24 - so it works on this one with just left
02:26 - turns it also works on this one with
02:28 - right turns there you go they all keep
02:29 - going at it
02:30 - and it also works on this much more
02:32 - complex strap there you go they start in
02:34 - there they go through they manage to go
02:36 - through that turn through that turn
02:37 - then over here this complex one yep
02:39 - there you go they succeed and they keep
02:41 - going all the way
02:42 - the ai isn't completely perfect there
02:43 - are still some times where they hit the
02:45 - invisible walls
02:46 - but the model is working so the solution
02:48 - to fix all that is simply much more
02:49 - training
02:50 - so that's the setup that i've got i have
02:53 - a simple nice car model that i grabbed
02:55 - from a racing asset pack
02:56 - there's a link if you want to grab it on
02:58 - the car object i have a simple
03:00 - collider a rigid body and a car driver
03:02 - script
03:03 - so these are the components for the car
03:05 - controller to work like i said you can
03:06 - use any car controller you want so don't
03:08 - worry about these specific components
03:10 - so those handle the car and then over
03:12 - here i have all the machine learning
03:14 - components
03:14 - so in here is the car driver agent the
03:16 - behavior parameters and the
03:18 - decision requester so these are the
03:20 - standard machine learning components i
03:21 - cover them in detail in the getting
03:23 - started video
03:24 - the one big difference here is over here
03:26 - on the decision requester
03:28 - i'm requesting a decision on every step
03:30 - rather than default which would be on
03:31 - every five steps
03:32 - i'm requesting it on every single one
03:34 - because the car drives pretty fast so it
03:36 - does need to make a decision quite often
03:38 - now the one new thing here is this
03:40 - component the array perception sensor
03:42 - so this is a default ml agent's
03:44 - component what it does is it
03:46 - automatically handles firing some
03:47 - raycasts
03:48 - and adding them to the observations it
03:50 - also has a nice editor script so we can
03:52 - see it over here in the editor in action
03:54 - so if i move the car yep there you go
03:56 - you can see it happening you can see as
03:58 - it collides
03:59 - so this is the information that the ai
04:00 - won't receive for the parameters here
04:02 - you can play around with how many rays
04:04 - per direction so there you go right here
04:05 - we have three so one two three and one
04:07 - down the center
04:08 - so you can increase as many as you want
04:10 - then you've got the max rate degree so
04:12 - right now the maximum is just 70
04:14 - degrees in there but if you want you can
04:15 - make it go 360.
04:17 - then the sphere cast radius so that's
04:18 - the size of the sphere
04:20 - so this isn't actually a raycast rather
04:22 - than sphere cast
04:23 - so this is helpful if the object you're
04:24 - trying to detect with raycast is quite
04:26 - tiny
04:27 - so just increase the size of the sphere
04:28 - cast like that
04:30 - then you can also define a length so
04:32 - this is how far the raycast will go
04:34 - so naturally needs to be big enough in
04:36 - order to actually detect the objects in
04:38 - front of it
04:39 - then we also have a start and end
04:41 - vertical offsets
04:42 - so here for example the object the
04:44 - origin is right down there but i don't
04:45 - want it to start firing
04:47 - right from the floor since that i put it
04:49 - on a vertical offset of one so it starts
04:50 - one unit above
04:51 - then you can also have the n vertical
04:53 - offset so for example you could put this
04:54 - one to go down and there you go all the
04:56 - raycasts go down
04:58 - so for example if you want to teach the
04:59 - machine to avoid falling off the map you
05:01 - would simply add this
05:02 - make it start higher and then lower okay
05:05 - so those are the basics then you have
05:07 - the
05:07 - layer mask so this is what layers the
05:09 - rays won't collide against
05:11 - and once again you need to think like a
05:12 - machine like we did a while ago
05:14 - so in order for the ai to learn how to
05:16 - drive it needs to know about the walls
05:17 - as well as the checkpoints so that's
05:19 - exactly what i said here
05:20 - by using this layer mask the rays will
05:22 - only collide with these layers
05:24 - so for example i've got a car here and
05:26 - as you can see this second car
05:27 - is right in front there you go the array
05:30 - goes through it but it doesn't collide
05:31 - with that one since that one is not on
05:33 - the walls or checkpoints layer
05:34 - then we also have the detectable tags so
05:37 - this is how the ai knows what object it
05:39 - hits
05:40 - so they are based on the game object
05:41 - tags right in here so as you can see on
05:43 - the wall
05:44 - they've got the wall tag as well as the
05:45 - one layer and the checkpoint the same
05:47 - thing same thing
05:48 - so with this sensor the ai now knows if
05:50 - it hits something at what distance that
05:52 - object is
05:53 - and what type of object it is so with
05:55 - this the ai has knowledge that there's a
05:56 - wall over here onto this side at this
05:58 - distance and knows that it's a wall and
06:00 - right in front it knows that there's a
06:02 - checkpoint at this distance
06:03 - i mean again the ai really only works
06:05 - with numbers so it doesn't really
06:06 - understand what is a checkpoint and what
06:08 - is a wall
06:09 - but over time it will learn to increase
06:11 - the distance from this object type
06:12 - and decrease distance towards this
06:14 - object type so as you can see the setup
06:16 - is very simple
06:17 - the only new thing compared to what i
06:19 - covered in the getting started video is
06:20 - really just a sensor
06:22 - now let's look at the agent code and by
06:24 - the way if you find the video helpful
06:26 - consider subscribing and hitting the
06:27 - like button
06:28 - it really helps out the channel here it
06:30 - is it's a pretty simple script as you
06:32 - can see it's less than 100 lines long
06:34 - the tricky part is really only on the
06:36 - training setup and not on the code
06:38 - itself
06:38 - so here on start i'm just listening to
06:40 - the track checkpoints
06:42 - so this is the script that handles when
06:43 - the car goes through a checkpoint
06:45 - i cover this checkpoint system in detail
06:47 - in another video
06:48 - then over here it's very simple if it
06:49 - goes through the correct checkpoint gets
06:51 - a positive reward and through the wrong
06:52 - checkpoint gets a negative reward
06:54 - then down here on our episode begin we
06:56 - just place the car on start with a bit
06:58 - of randomness
06:59 - we make it point the same forward as the
07:01 - spawn position
07:02 - we reset the checkpoints and we stop the
07:04 - car driver then over here for the
07:06 - observations
07:07 - as we saw we use the sensor and that one
07:09 - automatically handles most of them
07:11 - over here i just have an extra one for
07:13 - the dot product between the transform
07:15 - forward and the checkpoint forward
07:16 - so with this the i should learn to face
07:18 - the same direction as the checkpoint
07:20 - and then we have the actions and for
07:22 - actions we really just have two of them
07:24 - so just forward and turn and that one is
07:26 - handled by discrete actions
07:28 - so we've got accelerate brake slash
07:31 - reverse and don't move
07:32 - and also turn right turn left and don't
07:35 - turn then after coming up with the
07:36 - tournament for mount i just send that
07:38 - over to the car driver again it doesn't
07:40 - matter what car controller i'm using
07:42 - here it can be anything as long as
07:44 - i can make it work with these two types
07:45 - of inputs then for the heuristics very
07:47 - basic just using the arrow keys
07:49 - and then down here we've got the
07:50 - collisions here on the uncollision enter
07:53 - so when a collision first happens when
07:54 - it first hits a wall i'm giving it a
07:56 - rather large negative reward
07:58 - and then on the collision say which is
08:00 - triggered for every physics update that
08:02 - the collision is happening for that one
08:04 - i give it a small reward
08:05 - so with this i'm trying to encourage the
08:07 - ai to keep off the walls because before
08:09 - i added this
08:09 - the i was essentially just sliding along
08:11 - the wall and that's it there's nothing
08:13 - else so as you can see it's a very
08:14 - simple script
08:15 - the code is all very basic the training
08:17 - setup is really the only tricky part
08:19 - so i just placed all the tracks placed
08:20 - all the checkpoints alongside it as well
08:22 - as all the walls
08:23 - and again the only thing that matters is
08:25 - really just the physics system
08:26 - so here i can easily make the walls
08:28 - invisible and everything still works
08:30 - perfectly
08:31 - then for the checkpoints themselves i'm
08:32 - using the checkpoint system that i
08:34 - covered in detail in another video
08:36 - it handles the logic for ensuring that
08:38 - each car is passing through the correct
08:39 - checkpoint
08:40 - now here it is important not to place
08:42 - them too far apart
08:43 - so they should be relatively evenly
08:45 - spaced and have
08:46 - a bunch more on the turns you have to
08:48 - remember that the ai really only knows
08:50 - it did something good when it gets a
08:51 - reward
08:52 - so adding more rewards on complex turns
08:54 - does make it helpful
08:56 - so for example here i have quite a lot
08:58 - of checkpoints in order to make sure
08:59 - that it learns how to do this really
09:00 - complex turn
09:01 - okay now we can try training it just
09:03 - like this so here it is just using
09:05 - reinforcement learning and it's trying
09:07 - to learn
09:08 - right away you've seen that they
09:09 - actually start going backwards instead
09:11 - of forwards
09:12 - the reason is because i made the
09:13 - breaking speed long's moving forward is
09:14 - pretty fast
09:15 - so if he tries a bunch of random actions
09:17 - then he just ends up going backwards
09:19 - now the one big change that i made since
09:21 - my first attempt at this project was
09:22 - with regards to the walls
09:24 - first i made the ai and lose instantly
09:26 - when they touch the walls
09:27 - that makes logical sense but it also
09:29 - made it so that every episode was very
09:31 - short so it was hard for the
09:32 - ai to actually randomly try moving
09:34 - forward and getting the first reward so
09:36 - i just made the wall solid
09:38 - and disable the ending of the episode as
09:40 - i said the tricky part is really the
09:41 - training setup and your goal is to help
09:43 - your ai learn by any means necessary
09:45 - so you start by teaching it the simplest
09:47 - example possible and then over time you
09:49 - can make the training scenario more
09:50 - difficult so with this it's just doing
09:52 - normal reinforcement training
09:53 - so as you can see even after some time
09:55 - it still hasn't figured out that the
09:57 - obvious thing is to go forward
09:59 - so that's just basic reinforcement
10:01 - training but like i covered in the
10:03 - last video we can use the awesome power
10:04 - of imitation learning
10:06 - if you haven't seen it yet go watch that
10:07 - video it's really a very powerful tool
10:09 - for that i have some demos here that i
10:11 - prepared previously
10:12 - essentially i just went through the
10:14 - track a bunch of times and recorded it
10:15 - so over here got 4 000 steps
10:18 - going through eight episodes with a nice
10:20 - mean reward so i recorded it for the
10:22 - left turn track and the one for the
10:23 - right turn track
10:24 - then on the config file just enable it
10:26 - to use the demos by enabling both gale
10:28 - and behavioral cloning
10:30 - and for starters i want the agent to
10:32 - learn how to behave excel like the demos
10:34 - so leave the strength of both of these
10:36 - close to one and for the extrinsic
10:38 - rewards we can now leave it at just 0.1
10:40 - so let's see with imitation learning how
10:42 - much faster it learns and for the first
10:44 - attempt for some reason it sounds dry is
10:46 - going backwards
10:47 - but afterwards it does start to learn
10:49 - from the demos and there you go right
10:50 - away it instantly learns to go forwards
10:52 - now obviously it's still getting stuck
10:54 - so it still hasn't learned but in just
10:56 - pretty much just
10:57 - a couple of steps then it already
10:58 - learned quite a lot more than just with
11:00 - reinforcement learning
11:01 - so as you can see imitation and learning
11:03 - is really very powerful
11:04 - in order to enable it it's really very
11:06 - simple you just had a bunch of things
11:08 - over here on the config
11:10 - and there you go they automatically
11:11 - start using it so here you can see a
11:13 - handful of them have already managed to
11:15 - go through the first turn go through
11:16 - there and these ones manage to go and
11:18 - look at that one
11:19 - okay so that's what i did i first used
11:20 - the demo on this track and trained it
11:22 - enough
11:23 - so that they'll learn how to achieve
11:24 - this so trained it using
11:26 - bc gale and reinforcement learning then
11:29 - when it learned this track
11:31 - i set it to training on this second
11:32 - track i used a different demo
11:35 - i lowered the strength on the imitation
11:37 - learning components
11:38 - and increased a bit on the extrinsic
11:40 - rewards and then when it learned how to
11:42 - go through this track
11:43 - then i set it to train on all five
11:45 - tracks and just let it go
11:46 - using only reinforcement learning so
11:48 - here i have a brain that i've trained
11:50 - for about five million steps
11:52 - and right away you can see all of them
11:53 - go so there they go on this track and
11:56 - they also go successfully on this track
11:58 - and then down here on the complex track
11:59 - yep look at that they go through that
12:01 - turn
12:01 - and this come like certain down poor
12:02 - thing got stuck but most of them
12:04 - actually go through
12:05 - they come into that one and they do nice
12:07 - turn and there they go
12:09 - so here you can see just how powerful
12:10 - this is if for example you have a game
12:12 - where you want to support custom player
12:14 - tracks
12:15 - you would just make a handful of pieces
12:17 - all of them with built-in walls and
12:18 - checkpoints and you'll let the player
12:20 - create any track shape you want
12:21 - then the cars would still be able to
12:23 - race through any track custom made by
12:25 - the player
12:26 - you would simply include a trained brain
12:27 - model where you would train it for
12:29 - something like 50 million steps
12:31 - and the agent would perfectly follow any
12:32 - track with any shape
12:34 - alright so there you have it yet another
12:36 - excellent use case for using machine
12:37 - learning and another example of how easy
12:39 - it is to use ml agency in unity
12:42 - check the phone playlist linked in the
12:43 - description where i'm adding all of my
12:45 - machine learning videos
12:46 - as always you can download the project
12:47 - files and utilities from
12:48 - unitycodemonkey.com
12:49 - this video is made possible thanks to
12:51 - these awesome supporters
12:52 - go to patreon.com unitycodemonkey to get
12:55 - some perks and help keep the videos free
12:57 - for everyone
12:58 - if you found this video helpful consider
13:00 - liking and subscribing post any
13:01 - questions have any comments and i'll see
13:02 - you next time
13:08 - [Music]
13:12 - you