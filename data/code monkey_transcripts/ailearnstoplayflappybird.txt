00:00 - hello and welcome i'm your code monkey
00:02 - and the goal here is to get an ai to
00:03 - play flappy bird it's a simple game
00:05 - although it's quite challenging for a
00:07 - human so let's see if i can build an
00:09 - ai to beat my high score and go
00:10 - superhuman doing this using machine
00:12 - learning in unity is actually quite
00:14 - simple
00:15 - although as usual the training process
00:16 - was very interesting
00:18 - i had to essentially train the ai bit by
00:20 - bit so first make it learn just how to
00:22 - avoid the floor
00:23 - then slowly up the difficulty by adding
00:25 - randomness and smaller gaps as the
00:27 - i learned more and more i'll cover what
00:29 - i did to train it in more detail in a
00:31 - bit
00:31 - now the project that i have here is a
00:33 - fully functioning game
00:35 - this was actually created completely
00:36 - from scratch in another video a long
00:38 - time ago so go watch that if you want to
00:40 - know how the base game was made
00:42 - so i can play it and it works exactly as
00:44 - you would expect so
00:45 - just press the button to jump and for
00:46 - every pipe that i go through i get one
00:48 - score
00:49 - then over time the gaps become smaller
00:51 - and the pipe height becomes more and
00:53 - more random so everything becomes much
00:55 - more difficult
00:56 - so that's it's a very simple design now
00:58 - i wanted to make an
00:59 - ai to play the game flawlessly so for
01:01 - that i use unt
01:02 - ml agents to train the brain model i
01:05 - covered a complete getting start guide
01:07 - in another video so go watch that if
01:08 - you're not familiar with the toolkit
01:10 - machine learning in unity is actually
01:12 - very simple and easy to use once you
01:14 - understand the basics
01:15 - there's a complete plan list in
01:16 - description also quick note here
01:18 - unity is having a machine learning ai
01:20 - summit on december 10th
01:22 - it's a free one-day event with
01:24 - presentations panel discussions and
01:25 - hands-on workshops all about spatial
01:28 - simulation play testing robotics ml
01:30 - agents and more
01:31 - all of it presented by experts and
01:32 - industry leaders so if you're interested
01:34 - in machine learning or ai check out the
01:36 - link in the description
01:37 - as i've mentioned previously the real
01:39 - tricky thing about machine learning
01:40 - isn't really the code
01:42 - i'm going to showcase the agent class in
01:43 - a bit but the code is actually super
01:45 - simple
01:46 - the tricky part is setting up the
01:47 - training environment in a good way that
01:49 - allows for the agent to learn
01:50 - so the first question is always what
01:52 - does the ai need to know and what
01:54 - actions does it need to take in order to
01:55 - accomplish the task
01:56 - flippy bird is a pretty simple game
01:58 - there's only one action
02:00 - jump so adding the actions is very
02:02 - simple just set it to discrete with a
02:04 - single action with two possible values
02:05 - so jump or no jump
02:07 - then for the observations this is how
02:09 - the agent gathers information about its
02:11 - environment
02:12 - it needs to know where the various walls
02:14 - are so adding a ray perception sensor is
02:16 - perfect for this scenario
02:18 - so it adds a couple of rays they get
02:20 - fired in front of the bird on all sorts
02:22 - of angles
02:23 - and they are set up to detect
02:24 - checkpoints and walls so if i play the
02:26 - game side by side you can see yep look
02:28 - at that look at how the rays are
02:30 - behaving
02:30 - so there's an invisible checkpoint right
02:32 - down the middle and the rays correctly
02:33 - identify both the walls and the
02:35 - checkpoints
02:36 - then i also added a few more manual
02:38 - observations so here i gave it knowledge
02:40 - of its own transform position y
02:42 - so essentially it knows the height of
02:44 - the burnt and then also knowing how far
02:46 - the next pipe is
02:48 - as well as a normalized value for the
02:50 - current velocity so with all of that
02:51 - yeah i should have enough information in
02:53 - order to be able to complete the task
02:55 - then for the level setup itself like i
02:57 - said i made this whole thing from
02:58 - scratch in another video a long time ago
03:00 - so go watch that for a more detailed
03:02 - guide
03:02 - essentially as you can see the pipes are
03:04 - spawned on the right side and they move
03:06 - towards the left side soon as they get
03:07 - there they get de-spawn more spawn and
03:08 - so on and everything is pretty random
03:10 - and finally if the bird actually touches
03:12 - a pipe then yep we have our game over
03:15 - now as i mentioned in the beginning in
03:17 - order to train this ai i had to do it
03:19 - bit by bit
03:20 - i first tried to train it right with the
03:22 - final game but it just kept failing and
03:24 - failing
03:25 - so it kept hitting either the ceiling or
03:27 - the floor so constantly failing
03:29 - now in theory if i had enough processing
03:31 - power i could train it just like that
03:32 - through sheer brute force
03:34 - but i just have my humble machine not a
03:36 - massive gpu farm so i need to be a bit
03:38 - more clever with how i handle training
03:40 - so what i ended up doing here is
03:42 - essentially called curriculum learning
03:43 - devil agents does have a proper way of
03:46 - scripting a curriculum but here i did it
03:48 - manually
03:49 - essentially you teach the ai starting
03:50 - from an easy scenario and as it learns
03:52 - to complete the task you
03:53 - slowly increase the difficulty i will
03:56 - cover the proper way to script a
03:57 - curriculum so stay tuned for that
03:59 - but here like i said i made it manually
04:01 - so first i trained it pretty much with
04:02 - no pipes so
04:04 - just a massive huge gap and everything
04:06 - right down the middle
04:07 - so essentially just trying to teach the
04:09 - ai to avoid the top and the bottom
04:11 - also in order to get to this point
04:13 - quickly i used imitation learning which
04:14 - i covered in detail
04:15 - in another video i use it with a pretty
04:18 - high strength so it learned almost
04:19 - exclusively from my demos
04:21 - so on the config itself i enabled both
04:23 - bc
04:24 - and gale and using them both with a
04:26 - pretty good strength so essentially the
04:28 - goal is to get the ai to behave
04:30 - exactly as i told it to then once the ai
04:33 - figured out how to avoid both the top
04:35 - and the bottom
04:35 - i closed the gap for a little bit i also
04:38 - upped the strength of the extrinsic
04:39 - rewards up to 1.0 whilst reducing
04:42 - both gale and bc down to 0.4 so the goal
04:44 - was to make it start learning based on
04:46 - its own rewards and become better than
04:48 - me
04:48 - the result of that was quite interesting
04:50 - so first it had some trouble figuring it
04:53 - out so the reward dropped quite
04:54 - significantly
04:55 - so it was at 13 then dropped all the way
04:57 - under 5
04:58 - but then it started to learn from its
05:00 - extrinsic rewards
05:01 - and the cumulative reward shot up to the
05:03 - maximum now up until
05:04 - that point the gap height was always
05:06 - down the middle so next up i added some
05:08 - randomness to the gap height even though
05:10 - with a rather large gap so with that
05:13 - there's a lot more randomness to how the
05:14 - levels are created
05:15 - and then i also lowered both types of
05:18 - imitation learning so both gale and bc
05:20 - all the way down to 0.1 so the demo
05:22 - barely impacts learning
05:24 - at this point really the extrinsic
05:25 - rewards is all i wanted to
05:27 - learn from and this time the ai didn't
05:29 - even stumble with this new scenario so
05:31 - it instantly adapted the changes and
05:32 - constantly got a perfect score
05:34 - now here the reward essentially has a
05:36 - maximum cap because of the value that i
05:38 - set for the max steps
05:39 - so if it survives for a total of 2000
05:41 - subs and it automatically ends the
05:43 - episode
05:43 - and by the way if you find the video
05:45 - helpful consider subscribing and hitting
05:47 - the like button
05:48 - it really helps out the channel then for
05:50 - a pretty big jump in difficulty i
05:52 - tightened the gap size by quite a bit
05:54 - which also means that the random gap
05:56 - height is even more random
05:58 - so this is a pretty big jump in
05:59 - difficulty and it showed in the actual
06:02 - graphs
06:03 - so on the previous one it instantly went
06:05 - up to 40 which was the current maximum
06:07 - and as soon as i changed it it dropped
06:09 - all the way down to 13.
06:10 - so clearly it had a bit of trouble
06:12 - adapting to such randomness on the pipe
06:14 - height
06:15 - but once again the ai never quits on
06:17 - training so it pushed through its own
06:19 - difficulties and slowly adapted to its
06:21 - own environment
06:22 - so you can see right in here it was only
06:23 - getting 13 reward then it improved and
06:25 - got a bit worse and improved and slowly
06:27 - and surely it got quite a lot better
06:30 - and then all the way over here after 1.5
06:32 - million steps it was reaching the
06:34 - maximum once again
06:36 - you can see the results are quite a lot
06:37 - more choppy due to how much randomness
06:39 - this environment has
06:41 - so with that the ai was already pretty
06:43 - good so i made two more levels of
06:45 - difficulty
06:46 - and again the results were the same so
06:47 - it instantly drops down and then slowly
06:49 - learns over time
06:50 - so on that one as well as on this one
06:52 - and then finally i set the max tab back
06:54 - into zero so now the episode only ends
06:56 - when the ai actually
06:57 - loses and then look at those results so
07:00 - as it started right away it got only 20
07:03 - but it instantly shot up on the way up
07:05 - to 220
07:06 - then for some reason it actually dropped
07:08 - down a bit so i guess the ai became so
07:10 - good that it kind of scared itself
07:12 - and then slowly started improving
07:13 - constantly making higher highs
07:15 - so the results are quite a lot more
07:16 - choppy but it was consistently improving
07:18 - and at this point in order to achieve
07:19 - perfect scores it would really just
07:21 - require more brute force training
07:23 - so as you can see ml agents can really
07:25 - learn anything if given enough time
07:27 - and if you take the proper time to
07:28 - construct a good training scenario then
07:31 - it learns actually pretty fast
07:32 - there's also one really interesting
07:34 - thing that i use for training this
07:36 - essentially i had to use a different
07:37 - method from what i covered in my other
07:39 - machine learning videos
07:40 - in those i usually put the training
07:42 - environment inside of prefab and just
07:44 - copy paste the environment a whole bunch
07:45 - of times
07:46 - so that's a great approach however here
07:48 - when i initially made this game i didn't
07:50 - make it with machine learning in mind
07:52 - so i didn't set up everything in order
07:54 - to easily support multiple environments
07:56 - the game expects a single bird and a
07:58 - single level so adding support for
08:00 - multiple environments would mean an
08:01 - almost complete rewrite of the whole
08:03 - game
08:03 - now thankfully ml agents has an awesome
08:05 - feature where you can run training on
08:07 - normal builds
08:08 - and in order to do that you really just
08:10 - have to set up your build to require no
08:11 - input
08:12 - so as i hit play it instantly starts
08:15 - playing the level so it doesn't require
08:16 - any input click on any play button or
08:18 - anything so that's all it takes
08:20 - then just make sure that your agent is
08:22 - set to default so that it actually
08:23 - learns
08:24 - and then you make a normal build so just
08:25 - go into build settings make sure your
08:27 - build is in there
08:28 - and just make an arm build now another
08:31 - thing is if you don't use any visuals
08:33 - for your own logic
08:34 - so for example if you don't use any
08:35 - camera sensors or any input from any
08:37 - camera
08:38 - then you can make it a server build
08:40 - which means that the game will run much
08:42 - faster without having to do any
08:43 - rendering
08:44 - so let me do it and just make the build
08:46 - over here i have my build
08:48 - and here it is the executable and if i
08:50 - run it yep it runs in a normal command
08:52 - prompt and here i've got some logs so as
08:54 - you can see the game is actually running
08:55 - right now
08:56 - so i have this build that i can use in
08:58 - order to run this for training
09:00 - i just open up the command prompt on my
09:02 - virtual environment
09:03 - again i covered all of this in detail in
09:05 - the getting started video
09:06 - then doing the normal command which is
09:08 - running ml agents dash learn
09:10 - then passing in the config file
09:14 - and then you add the parameter dash dash
09:16 - inf so this is the
09:18 - environment which is related build so
09:19 - over here i've got my project folder
09:21 - i've got the inside this underscore
09:22 - builds folder
09:23 - and inside flippy bird and inside it's
09:25 - named mlagents.xa
09:28 - so here i just put exactly that path
09:32 - so exactly like that without the final
09:34 - extension
09:35 - this is how we tell it what build to run
09:37 - and then adding dash dash
09:39 - numinifs so this is how many instances
09:42 - you want to run at once
09:44 - now running more instances takes quite a
09:45 - lot more resources like for example
09:47 - memory and hard drive space
09:49 - so actually initially i tried running 20
09:51 - instances
09:52 - and my hard drive actually ran out of
09:54 - space because it used up almost
09:55 - 30 gigs so i ended up doing most of the
09:58 - training with just
09:59 - eight instances which is still quite
10:00 - enough to make it go quick
10:02 - then you just have dash dash run id so
10:04 - just the normal stuff
10:07 - and just press on enter
10:15 - and yep all eight builds are now
10:16 - currently running you can even inspect
10:18 - the task manager and see yep we've got
10:20 - eight sentences running
10:22 - then to stop training on windows you
10:23 - just hit control c and everything stops
10:25 - and it saves the model okay so that's
10:27 - how you run training on an external
10:28 - build so this is pretty much essential
10:30 - for most real
10:31 - use cases since when working on proper
10:33 - games you probably won't be able to
10:34 - easily create multiple environments
10:36 - whilst inside the game
10:37 - okay so let's try out our final ai so
10:40 - first of all here i am
10:41 - as a human player trying to get a nice
10:43 - high score so let's see how far i can
10:45 - push it
11:04 - okay there it is i did actually pretty
11:06 - well getting a high score of 39 so
11:07 - that's pretty good
11:09 - now let's see the final trend ai and see
11:10 - how it goes all right so there it is and
11:12 - it goes through the first
11:14 - few pipes okay so far so good let's see
11:16 - how much it goes
11:26 - and 37 38 39 and yep there goes my high
11:30 - score
11:31 - all right so that's it let's see how far
11:34 - it can go
11:49 - okay it's over 200 so at this point i
11:52 - guess it's safe to say that the machines
11:53 - have finally beaten the humans
11:55 - or at least this ai has been this human
11:58 - alright so this was another real example
12:00 - of machine learning in action
12:01 - as you can see it's actually really
12:03 - quite simple it took me only a few hours
12:05 - to write the agent and adapt the game to
12:07 - work with ml agents
12:08 - then it was just letting the training
12:10 - run over time while periodically
12:12 - increasing the difficulty
12:13 - so doing some classic ai would have
12:15 - probably taken quite a lot more time
12:17 - so here is another example use case of
12:19 - machine learning in action
12:20 - check the phone playlist linked in the
12:22 - description where i'm adding all machine
12:23 - learning
12:24 - videos as always you can download the
12:25 - project files and utilities from
12:27 - unitycodemonkey.com
12:28 - this video is made possible thanks to
12:30 - these awesome supporters go to
12:31 - patreon.com
12:32 - unitycodemonkey to get some perks and
12:34 - help keep the videos free for everyone
12:36 - if you found this video helpful consider
12:38 - liking and subscribing post any
12:39 - questions have any comments and i'll see
12:41 - you next time