right now you are watching an ai that teaches itself how to play the game of pong now it's doing so using an algorithm called neat which stands for neural evolution of augmented topologies now in this video i'm going to explain to you how that algorithm works and then show you how to implement it into this game now although we will be focused on pong the techniques and strategies i show you in this video will work for pretty much any game so if you're interested in building ai and building ai for games in general then definitely watch through this video and i'm sure that you will learn a lot now i do want to mention that we're not going to code out pong from scratch like i did in kind of the last video of this where i coded a ai that played flappy bird i'll link that in the description by the way what i'm going to do is give you some starting code that has a functioning pong game and then we'll look at how we actually implement the neat algorithm and move the different paddles and well train in ai so with that said let's go ahead and get into the content after a quick word from our sponsor before we get started i need to thank appify for sponsoring this video appify lets you turn any website into an api and can automate anything you do manually in a web browser at scale with appify you can perform web scraping web automation web integration and more as a developer you can build your own custom scrapers using the appify sdk which is a fully featured nodejs library or you can use their python api client now if you do end up making a custom scraper or automation tool you can monetize your work by publishing your solution to the appify store and rent your software to earn passive income each month now if you don't want to write a scraper from scratch you can also fork the code of hundreds of premade tools in the appify store and modify it to your liking you can get started with appify today for free by clicking the link in the description and get a 5 us dollar credit every single month without even needing a credit card however if you do need to upgrade you can use the code tim20 for a 20 discount thanks again to appify for sponsoring this video now let's get into it so i want to get right into the code but i just need to mention that this video here is not designed for complete beginners so i'm going to assume that you have a solid understanding of python that you have some understanding of neural networks now if you don't don't worry i will leave some links in the description and some resources to help you so first of all if you don't understand python or maybe you're just kind of a beginner programmer you can check out my course it's called programmingexpert.io teaches you fundamental programming concepts mostly in python that'll be linked in the description you can also check out my neural networks for beginners tutorial series that's free that's on youtube if you just want to learn a little bit about neural networks before going through all of the content here with that said please do feel free to follow along you'll most likely be able to get a functioning ai you may just not understand everything that you're doing all right so now that we've talked about that i will also mention all the code for this video will be linked in the description as well as all of the documentation and research papers that i reference now i apologize for the long introduction let's actually get into the code and let's start creating this ai alright so on the right hand side of my screen here you can see that i actually have a finished version of this ai so the right hand side is the ai and i'm on the left hand side and this is going to be the goal for this video is to train the ai watch how it trains and kind of understand the genetic algorithm but then be able to actually play against the ai in a game of pong or to have two ais play against each other so that is the end goal just wanted to show that to you and now what we're going to do is just get into some setup steps here because as i mentioned we're not going to be coding out pong from scratch what we're going to do is start with an implementation of pong and then i'm going to show you how to implement the ai for it now if you do want to code pong from scratch i do have an entire tutorial on how to do that so i'll link that in the description but for now i want to get started with the starting code so what i'm actually going to do is just open up a new folder here in vs code and then walk through the setup steps with you so i've just opened up a new folder in vs code that's the editor i'm going to use for this video feel free to use whatever you want now i also have this github link open uh this will be in the description but this is what contains the starting code for this project and the implementation of pong that we'll use to train the ai with so go to this link again it's in the description and just copy it if you have git installed and if you don't have git installed then what you're going to want to do is just click on the download zip here by clicking on code so code download zip and then extract the zip folder and open up that zip folder but if you do have git then you can just copy the url and you can just clone the repository which is what i'm going to do so i'm going to go to vs code i have my terminal open and i'm just going to type in git clone and then paste the url here and that's going to give me all of those files inside of this directory now i'm just going to start walking you through how this code works then we'll build out kind of a basic implementation of the pong game so we can actually view it and kind of play the game ourselves then we'll start getting into writing the ai so the first thing that we do need to do is actually install a few modules so if you open up requirements.txt you'll see that we need neat python and pygame so if you know how to you can install just this txt file here or you can just go into your command prompt and type pip install and then the modules so the first one is going to be neat python and then after that it's going to be pi game now i already have them installed so you're going to see it says requirement already satisfied but you need both neat python and pygame for this video now for some reason that pip command didn't work for you try the pip3 command if that didn't work for you try python hyphen m pip and then install and then the two modules that are listed there and if that didn't work for you try python3 and if none of those work for you as always i'll put two videos on the screen that show you how to fix that command okay so now that we have that working let's just start having a look inside of this pong folder here because the pong folder it's actually a python package that contains everything you need to create pom so inside of here we have ball dot pi this simply implements the ball okay we have paddle this is one paddle we you know use two paddles in our pond game and we have game.pi which is the class that you're going to be interfacing with so inside of this file you can see that we have two main classes we have game information and we have game now the game information class is going to be returned to us or at least an instance of this class will be returned to us whenever we call the loop method of the game which i'll talk about in one second but it's just going to give us the game information right the number of hits the left paddle has the right paddle has then the score of both the left and the right paddle and the way the scoring works is that if you get the ball across the other player's side you get a point so if i'm the right paddle i hit it to the left side and they miss then the right paddle would get a point obviously we want to know all of this information so that we can understand which ai is performing better and we can train our ai using you know this data right that's what we want then we have the game class this is the main class that we're going to interface with you don't have to understand how the code inside of here works you just need to understand how you simulate the game using the class which i'm going to show you exactly how to do so the first thing we'll do here is initialize an instance and we do that by passing a window a window width and a window height okay pretty straightforward this is going to be a pi game window and then it will handle actually making the game for us we then have a bunch of private methods which we don't even have to look at because we're not going to interface with them and then we have draw now draw is going to actually draw the game for us you don't have to draw the game if you don't draw it you just won't see it so up to you if you want to draw it or not and you may not want to draw it because it'll be faster to actually train the ai if you're not constantly drawing then we have move paddle pretty easy but this allows us to move the left or the right paddle if we pass left true that means we're moving the left paddle if we pass left false we're moving the right paddle up true we're going to move whatever paddle up up false we're going to move it down right and then it will make sure that we actually can move it and it's going to return to us true if we were able to successfully move the paddle and false otherwise so if you're trying to move the paddle off the screen for example it's going to return false saying hey nope you cannot move there okay continuing we have loop this executes a single game loop so what you need to do here to actually run the game is create your own event loop which is just going to be a while loop essentially that's running that's constantly calling this method and then this method every frame is going to return to you the game info which is going to be the hits for the left and right paddle and then the score for the left and the right paddle so at every frame in the game you will know all of the information and you can do with it what you want inside of your main game loop you can decide when to end the game you can decide if you want to train another ai if you want to give an ai more points than another one we'll talk about that later on then we have reset pretty straightforward resets the entire game okay that's the game class that's really all the information you need to know and one last thing we have this init.pi file and this just says from.gameimportgame which means that when i import this pong i guess package is what we'll call it then i'm able to just directly import the game class and start working with it okay continuing we have config.txt this is what we're going to use for the configuration for our neat algorithm talk about all of this stuff when we actually implement neat don't worry about it too much right now then we have main.pi this is the finished code so if you just want to run the ai like you don't care to go through the tutorial then you can just run this file assuming you've installed the python and pi game but what i'm going to be doing in this video is essentially rewriting this file from scratch so we actually understand all of this stuff inside of here and then this header comment here is just one of the examples from neat that we kind of reference or that i've stolen some code from in this file right here okay so that is the gist of this starting code not overly complicated again you don't have to understand everything inside of here i just wanted to give you a brief explanation of what's going on so that when i start writing some code it makes a bit more sense so now let's actually implement a basic pong game so let's use that game class and just see how we can actually move the panel up and down and work with those different methods then we'll start writing out the ai so i'm going to create a file here and i'm going to call this tutorial.pi and inside of here i'm going to say imports i'm going to import pi game and then i'm going to say from and this is going to be pong import and then i'm going to import game now i can do this because pong which is the folder here is a package because it has the init.pi file inside of it that allows me to directly import anything that it imports and since it imports game i get game right here now make sure you put your tutorial.pi file inside of the neat python folder and that is not inside of the pong folder okay now that we have this we want to set up a pie game window the window is where we're going to draw all of this stuff and what we need to pass to the game class so i'm going to say window is equal to pygame.display.set underscore mode and then inside of here i have to pass a width and a height for the window so i'm just going to say width comma height is equal to and then we're going to go 700 500. now make sure that whatever the width and the height is that you set you're going to keep it the same when you're training the ai because if you change the width and the height it's going to affect how the ai performs so just make sure the width and the height you pick right now you're okay with and that you're not going to be changing in say the middle of training because if you were to change that's going to kind of mess everything up just wanted to note that so we'll pass width and height inside of here okay now that we have a window and a width and a height we can initialize the game class so i'm going to say game is equal to game and i'm going to pass my window my width and my height now you're about to see how easy it's going to be to run the game what i can do is create a while loop here so i can say while true for example although i really should just make a variable so i'll say run equals true and then while run and i'm going to say game dot loop and then game dot draw and then i'm going to say pi game dot display where is this here dot update and this will actually run the pi game for us that's literally all we need now i do need some way to quit this while loop i don't want an infinite loop so let's implement that but this is what i was talking about okay i'm going to say game.loop this is just going to constantly run the game loop for me inside of here i'm saying game.draw so it's going to draw it and then i'm updating my display just so i see everything if i don't update the display it's not actually going to show that it's being drawn however as i said we need some way to quit so what i'm going to do is say for event in pygame dot event dot get and i'm going to say if event dot type is equal to pi game dot quit so that means we hit the red x button on the pi game window which you'll see in a second then i just want to say run equals false and i'll just break out of the for loop like that okay and then down here we can just say pie game dot quit just make sure the window closes okay that's literally all we need to run the pong game and of course you need a way to move the paddles but let's run this right now and see if this is working okay so i'm going to bring up actually i don't need to bring up the console i can just click run and let's see and notice that we have the pawn game and there you go now it's going super fast right just because i haven't actually limited how fast the loop is running i'll show you how we can limit that but that's how you utilize the palm game and then if i want to move the paddle i would just need to use that paddle move method for now though i'll show you how we can limit the the speed so what we can do is create a clock let's say pygame.time.clock and then what i will do is go in here and say clock dot tick and you pass the maximum number of frames that you want to render per second so in this case i'm saying 60 so that means this while loop will be limited to running 60 times per second that's exactly what take does for us okay so you just put that inside the loop and it's gonna limit the time let's run this and then notice that now we get a ball moving at a reasonable speed okay and then it's drawing the score for us now a few other things that we can look at here when we draw we have the option to pass two things let's just go back here and i'll show you so looking at draw we have the option to pass draw score and draw hits so draw a score by default is true draw hits is false pretty straightforward what they're doing but if i don't want to draw the score i can pass this false and if i want to draw the number of hits i pass that is true so maybe we'll switch this and just say false and true and now rather than it showing us what the score is it's going to show us the combined number of hits between the two players okay so uh you know unfortunately they have not hit the ball yet now one small thing to note here as well is that you'll probably see that when the ball starts in the middle it's kind of random the direction that it's going that's intended so i have it so it's just randomly coming off at a slight angle so that the ai can't just say sit in the middle of the screen and constantly hit the ball it needs to actually learn to move towards the ball that's something i did in the game class that i want to mention anyways see the hits is being tracked up here that's all good we now pretty much understand how to use this class so last thing i'll do is show you how we can move the panel with the arrow keys and then we'll start building the ai so let's do the following let's say keys we want to get all the keys that the user has pressed we're going to say keys is equal to pygame.key.getunderscore and this is going to be pressed this will give us a list of all of the keys that the user has pressed so i can just check if they've pressed in this case let's go with the w and the s key and then i can move the panel accordingly so going to say if keys and i'm going to pass pie game dot k underscore and then the key i want to check is w so that's what i pass if you want to do a you would do a right if you want to do up it's actually k underscore up if you want down it's in all capitals k underscore down you can look those up from the pi game website but pretty straightforward and then what i will do is say game dot move paddle okay and then what paddle do we want to move want to move the left paddle so let's say left is equal to true and i want to move up when i'm pressing w so i'll say up equals trip okay and then we can copy this put this down here and now we'll say if key is pi game.k underscore s because well that's below w then we'll say left is true okay but up is going to be false nice now this will allow us to move the left paddle so let's run the code and let's see what we get and notice that if i move s and w i can now move the left paddle and if you wanted to you could implement maybe the up arrow keys for the right panel that's as easy as it is though and the last thing to look at is that if i do something like game info is equal to this i can print out for example the game info dot and then let's go left score and the game info dot right score so the game info class again it has left score right score left hits right hits so we'll use this data to figure out when we want to end the game and how well the players are doing i just want to show you that i can print this out and let's move the console up and notice we're constantly getting zero and let's let him score and then we're gonna get zero one right okay there you are nice so now that we have done all of that i wanna start building out the ai so to do that i want to make a class that's going to have a few different methods the first method may be something like train ai the other method may be test ai right i need a few different things and it just makes sense to put all this in a class so let's go ahead and do that so i'm just going to make a class here let's do it at the top and let's say class i'll call it pong game and then we'll define an init and in the init let me just move the mic a bit closer here we'll take in a window a width and a height and we'll initialize a game so what i'm going to do is say game here let's copy this is equal to that but we'll say self.game is equal to game window with height so now each pong game instance will have its own game and then inside of here i just want to grab the ball as well as the left and the right paddle from my game so if i go to game here you can see that in the init we have a left paddle right paddle and ball now i'm going to want the location of the ball location of the left and the right paddle when i'm actually designing the ai so i'm just going to get those things i'm going to say self dot left paddle is equal to self dot game dot left paddle and then self.right pal is equal to self.game.rightpaddle and then self.ball is equal to self.game.ball okay now that we have all of that let's make a method and let's just make this test ai and for now we're just going to take in self and i'm just going to run all of the code that i put right here just so that we're not wasting this code let's put all of it in here okay let's tab all of this forward and now we have a method that actually lets us test the game and then later on we'll make it so that we pass an ai here and that actually uses the ai to play against us okay there we go we already have our first method done nice so now that we've done all of that we need to talk about neat because we're going to start actually using neat to well train an ai and we need to understand how neat works and what that is so let me hop over the whiteboard we'll do a bit of an explanation then we'll start implementing it so i'm on the whiteboard and i'm going to start explaining to you neat now neat is neural evolution of augmented topologies and this is what's known as a genetic algorithm now a genetic algorithm takes inspiration from human history and natural selection and essentially produces multiple generations of what we call genomes now this is a little bit confusing i'm going to explain this more in depth but before i get to that i just want to give you a quick recap on neural networks and how you design a regular neural network because neat is kind of an advanced i don't even know what you would call it layer on top of neural networks so when we're designing a neural network what we want to do is we want to feed some inputs to it then we want to get some outputs now we need to determine how many inputs we're going to have and how many outputs and what inputs are going to make sense to feed to the neural network so we're talking about our pong game let's just draw this out here we have a left paddle a right paddle and a ball now there's all different types of inputs that we could feed to a neural network to try to get the paddle to move but the first thing we should probably determine is what do we want this neural network to tell us what is what is the output going to be well what we want the neural network to tell us is if we're talking about say the left paddle here is if we should move the paddle up down or if we should just keep the paddle in the same location that's really all we care about that's what we want to know from the network so that's what our output's going to be up down or stay still now to try to get the pile to go up down or to stay still what input should we feed the neural network well it's definitely going to need to know the location of the paddle right now in pi game the location is the top left hand corner so in this case we'll pass say the y of the paddle to the neural network now the reason i won't pass the x is because the x is going to be constant and you don't want to pass any constant values to a neural network it's just not necessary to do that so i don't need to pass the x because it's constant of the path let's not change okay so we pass the y of the paddle and then we want to know the location of the ball right that's going to be important so i'm going to pass the y of the ball okay so actually let's not just say p let's say y of ball and then i'll also pass the distance between the paddle and the ball since i'm not going to pass the x of the paddle i'll pass not just the x of the ball but i'll pass the distance between so it knows how close we're getting to right so i'll just say like this i'm standing for the distance between the paddle and the ball nice so those will be my three inputs to the neural network so let's clear the screen here and now let's draw a neural network that's going to have the inputs that we discussed and the outputs so in a neural network we have nodes right we're going to have our input layer which we'll draw in red and this first input we're going to say is going to be the y of the paddle the second input will be the y of the ball and then this will be the distance in x between the ball and the paddle okay and then we're going to have an output layer and for the output layer since there's three possible decisions that we want to make we're going to have three notes right and this first node will say okay we want to stay still this will say go up and this will stay go down and we'll have to interpret which node kind of represents what i'll talk about that later on but the point is we want three nodes because we have three possible decisions and so we can say something like whatever node has the highest value is the decision that we're going to take and then in between here because this is our input layer and this is our output layer we're going to have something called a hidden layer or multiple hidden layers so maybe i have something like two nodes in one hidden layer and then typically what we do is we connect every node from the input layer to the hidden layer okay and then every node from the hidden layer gets connected to every node from the output layer now it's not always the case sometimes we're missing connections or sometimes there's multiple connections all different types of things can happen but generally speaking we have our input layer we have hidden layers so in this case we just have one we could have multiple hidden layers we could have five nodes ten node as many nodes as we want in the hidden layers and then we have our output layer and what we wanna do is pass information it gets sent through the neural network and then we get some output and we don't really care how we get the output we just want to get the most accurate output we possibly can so that is kind of the brief on neural networks again i'm assuming you understand how neural networks work because i'm not going to explain kind of how the data is getting sent through here the main thing that i want to show you by looking at this diagram is that it's kind of random or it's kind of arbitrary the way that we're picking the internal architecture of our network right within this box that i'm drawing can really be anything i don't care what's in the middle of the neural network so long as the output based on my input is valid right that's really all i care about it can kind of just be an invisible black box what's inside of the neural network and for me to try to determine the number of nodes in each hidden layer how many hidden layers i should have that's a pretty difficult thing to do especially if we're trying to solve a task like training an ai to play a game where this isn't really a wellknown task well maybe playing pong is but for any kind of general game or maybe a game you've made yourself there's not a good way to determine how many nodes in our hidden layer we should have as well as how many layers we should have we can you know try to guess but it's not going to be very easy to do that so the reason i keep saying this is because this architecture in the middle is really kind of the question mark this is what's going to determine really the performance of the neural network and that's something that's difficult for us to pick so rather than us deciding it we're going to get the neat algorithm to do that for us so let me zoom out a bit here just so that okay i move this up all right why is it not letting me zoom out okay you know what that's fine we'll just get off the screen i don't need it to be on the screen anymore what our neat algorithm is going to do is it's going to create a bunch of neural networks and these neural networks are going to start with kind of a predefined number of hidden layers a number of hidden nodes we'll decide that on our own and then there'll be some random mutations that are performed to these neural networks so we'll start with kind of a population here so let's say a population of however many neural networks we determine in this case let's say we start with 10 neural networks and these neural networks will all be slightly different and have some kind of minor changes made to them from the starting neural network that we define ourselves so maybe we say that we want to have the network that i said we want to have three input nodes we want to have two hidden nodes and we want to have three output nodes the number of input nodes and the number of output nodes is always going to stay the same no matter what but what's going to change is what's in the middle here the number of hidden nodes the number of connections and all of the parameters to the neural network that's what's going to be modified by the neat algorithm so we start with a population of 10 neural networks and we're going to call these neural networks genomes okay and what we're going to do is we're going to take all of these genomes we're going to test them and we're going to determine what their fitness is now the fitness of a genome is essentially its score it's how well it performs right if we're talking about humans and natural selection which i'm going to get to in a second it would be how long do you survive right natural selection essentially states that over you know tens of thousands of years multiple generations of humans the ones that were the smartest the ones that were able to survive they bred together that created a smarter offspring and then that continued on and on and on and you'll oftentimes see memes and stuff about you know natural selection with the people of today that do very stupid things and end up you know potentially dying obviously that's a little bit dark we don't need to talk about that in here but the point of natural selection is that over tens of thousands of years you have a large population of people they all breed together they create offspring the best of those offspring are going to survive the worst are going to die off and that means that when you get to you know the year 2022 you have a set of humans who are all to some level better than the very first generation again depends on the metrics that you're using but that's what this algorithm is going to attempt to do so we take every single one of our genomes and we grade them we give them a fitness now the fitness is how well they perform our task so in this case when we're playing pong we need to come up with kind of a fitness function and a way to determine what the fitness is of every one of our ais now i'm simply going to use the number of times that the ai hits the ball that's going to be my fitness so if the ai misses the ball which is going to happen a lot at the very beginning it's going to get a fitness of zero but if the ai stays alive for a good amount of time and hits the ball a lot then it's going to get a high fitness that's as simple as it is for the fitness function so we go through we give them all fitness let's just say we have something like one seven three two zero uh three four ten twenty 21 whatever whatever the fitness values are and then what we're going to do is we're going to look at this population of genomes we're going to keep the best genomes that we have so maybe we keep like 21 20 10. uh maybe we keep seven as well we're going to discard some of the worst ones and then we're going to breed the best genomes together and move to the next generation and when i say breed what that really involves is looking at the architecture of each of these neural networks because remember each genome is really just a neural network and taking those properties and kind of merging them together in another new neural network so maybe one neural network has a layer with two nodes the other one has a layer with three maybe we then make a new network that has excuse me two hidden layers one with two nodes one with three nodes whatever the mutation is we make some changes and we're kind of breeding the best networks together and hoping to get a better offspring that's the concept so we take these let me zoom out here and then we move on this is what we call generation one okay and we move on and we make another generation of genomes that goes here so we have one two three four five six seven eight nine ten okay and then same thing with these genomes we take them we grade them on their fitness we keep the best ones we get rid of the worst ones and then we mutate the best ones together create some offspring and move on to the next generation and we continue this until eventually we get a genome or a neural network that meets our criteria for fitness so maybe once the fitness is 500 700 whatever it is we say okay we're done we have found an ai that is sufficiently good at the game of pong we're going to end the algorithm and we can then save that ai and use it in our game hopefully this makes a bit of sense all right so obviously i am giving a vast simplification to how the neat algorithm actually works people way smarter than me wrote the neat algorithm we're not going to write this algorithm we're just going to utilize it that's why we have the config file and we installed that module and neat does a lot more than what i'm explaining here it actually will keep different species of neural networks so what i mean by that is we'll group maybe you know like let's say these these and these together into three separate species and we'll try to make sure that through our different mutations we're keeping at least one or two genomes from each species so we don't have a species go extinct right and the reason we would do that is because there may be a species that's not very good right now but may have a promising architecture for later on now there's all kinds of other considerations like that like how long do you keep a genome that's not performing well if i have a species and i have one genome in there and it's not performing well for say 10 generations is that sufficient for me to say okay i'm going to get rid of it i don't know all kinds of questions like that now there's also the ability to add random mutations to offspring and kind of children of other genomes so what may happen is you may take the best genome and rather than breeding it with another one you may just add a random mutation and a mutation may be disabling a connection or adding another node or slightly changing the weights and biases of the neural network there's all kinds of stuff that can go on and that's why it requires a lot of generations typically to train in artificial intelligence so we're going to start with a population of close to 50 uh genomes and then what we're going to do is run them through about 50 generations until we reach a genome or a neural network that plays the game of pong decently well okay so that's it for the explanation on neat uh hopefully that made a bit of sense now let's hop over the computer we'll start actually implementing this which won't take us too long and then we'll talk about the different strategies on actually testing the fitness because as you're going to notice here the fitness is the most important part we're going to keep the best get rid of the worst generally speaking and so we really need to make sure that we're judging these genomes properly and that we know which ones are the best by giving them the most accurate fitness okay with that said let's hop over to the computer so i'm back on the computer and i just want to spend a second telling you about some resources so first of all this is the neat paper this explains neat gives an overview of it some of the pros and cons and it's obviously going to be a way better explanation of how the algorithm works than what i could have just given you so please do have a read of this it's not super difficult to read it's only six pages long and it will really crystallize probably a lot of the questions or i guess just your understanding of the neat algorithm anyways that's the resources uh that's the resource sorry that's in the description and then continuing here i have this example from the neat documentation so neat python documentation this is one of the examples they provide and it talks about the fitness function running neat getting the results i'm not going to read this too you can feel free to read it on your own and then there's some example code a lot of the code we have is straight from here as well as a configuration file so this is the default configuration file for the example they're using which is the xor example again read this if you want to learn more about it but the configuration file that i have in the project that's already written for us is essentially the exact same as this with just a few minor changes so i will talk about what i've changed but if you want to understand what every single one of these like 70 lines means you can click on configuration file description and it shows you fitness criteria and fitness threshold like all of the different sections in this uh configuration file it talks about how you use them and what you can set them to so again i'm not going to spend the time reading this all out to you that's kind of what you can do on your own time you do not need to go in and touch anything if you don't want to but i know some of you are going to ask you know what does this do what does that do if that's the case please go here and read this it gives you really good explanations okay so now we're back here and we need to start working in this configuration file and understand a few of these important aspects so then we can use it for our neat algorithm so let's start going through this file here these are going to be the three most important things you want to have a look at so just pay attention here fitness criterion is telling us when we reach the fitness threshold essentially so it's kind of confusing the way i explain this but the fitness threshold is when we're going to stop the algorithm and if this is max that means that once we hit this value for at least one genome so once a single genome has a fitness of 400 or more then we're going to stop that's what max means now if i make this mean that means once i have all of my genomes having an average fitness of 400 i'm going to stop and if i make this min that means once the minimum of any genome that i have has a fitness of 400 then i stop so i want this to be max again once i find a single genome having a fitness at or above 400 we stop the algorithm and then we would return that genome and that would be our kind of ai right then population size that's what pop size stands for this is how many we want in our population i'm going to go with 50 and the way we're going to test this is that if you increase this it's going to exponentially increase how long it takes to run so already training this ai could take you know 20 minutes an hour could take a good amount of time depending on how long you run it for so if you make this larger it's going to take significantly longer so i'd recommend you keep it at around 50 but you can mess around with higher lower values i won't make a massive difference to the performance but the speed yes it will so i think 50 is like a good minimum to keep it at some of you may want to do it at like 100 or 150 but for now just go with 50. and by the way everything in this file please feel free to change it a lot of this is just the default that i took right from the neat website and i've just modified a few things so continuing i'm not going to explain a lot of these again you can read the documentation to see that but i want to go to default genome now the default genome we do need to modify a few things here because we need to say set the number of input layers and output layers and all that kind of stuff and we also change the activation function so i'm not going to necessarily explain what the activation function is but essentially what it does is it takes the result from a specific node and it just converts it to a different value so i run the result from a node through the activation function then i pass that value to the next node and this makes it so that our values are going to be within a specific range in this case i've changed the activation function from the default of sigmoid to u which is rectify linear unit and this function actually i have a photo of it right here i'll just pull it up uh this is the relu function uh okay of course you know you can see it on the right hand side of my screen it just makes it so the minimum value we possibly have is zero okay that's rel u uh sigmoid is a different function so i've changed these to value that's the only change i've made there here have not made any changes there's all these other things like okay what's the probability that we add a node or delete a node or all that and continuing where we really want to look at is where was it right here okay network parameters this is what we care about for right now so we need to make sure we change these and they will already be changed for you so the number of inputs is three and the number of outputs is three now the number of hidden is the number of hidden layers you wanna start with by default in this case i'm going with two however you could change this to one three whatever zero again it's kind of a random value that i've picked and this will change over time as the mutations are applied to the neural network so just go with three three you know you can mess with this make it one make it two make it three whatever i'm just gonna make it two for now okay so last thing to explain in this configuration file feed forward make sure this is true again it will be true for you but i've changed this from from false to true now what this means is that we're just going to get a regular neural network where we feed inputs and we get an output if you make this false you get something called a recurrent neural network which means the output of the previous call to the neural network is going to be an input to the next call and that is so you can kind of save information you can save like the history of the neural network if that makes sense we don't care about that here and if you do that you're going to get some weird results so just make this true and then initial connection full direct what this means is that we have directed connections between every single node so we have a fully connected nodes every node in the input layer is connected to every node in the hidden layer every node in the hidden layer every node in the output layer okay all right so now let's actually use the configuration file so to do that i'm going to say import neat and i'm also going to import os just because we need to find the path to the configuration file to load it then i'm going to come down here i'm going to say if underscore underscore name is equal to under squadron square main just making sure that we ran this file not that we imported it i am going to load the configuration file so i'm going to say that my local directory is equal to os.path dot der name and then under square underscore file under squad underscore with a lower case this is a special variable just gives you the current file i can get the directory name of it and then what i'm going to do is say that the config path is equal to os.path.join and i'm going to join the local directory with config.txt okay which is what we have right there now if you change the name of this you're going to have to change that but i assume most you're working with the starting code now that we have that we're going to say config is equal to neat dot config and actually let me just copy this in ah because it's going to be a bit easier than typing all this out okay then we're going to say neat dot default genome neat default reproduction neat defaults bc set neat default stagnation and then the configuration path not going to explain this too much essentially we're just passing the different properties from the configuration file that we want to use i mean you can read this if you want but these are the ones that we want to use right default genome default reproduction default species set default stagnation and so i need to make sure all of those are in my configuration file and they are and then lastly i pass my configuration path so now i've loaded the configuration file now we need the configuration file to actually create a neural network so that's what we had to load it okay now that we've loaded it what i want to do is i want to run the need algorithm so i'm going to make a function and say define run neat okay and this is just going to take in the config okay so here we can go say run neat and we can pass the config now inside of run neat i need to create kind of my meet runner i don't even know what you would necessarily call this i guess my neat population so i'm going to say p is equal to neat dot population and for the population i'm just going to pass the config okay so i'm initializing a population of genomes using the configuration file now that i've done that i'm going to add a few things to this that makes it so we get some output to our screen now all this code again is coming really right from the neat website so you can reference it there as well but i'm just going to say p dot add reporter and i'm going to say neat dot std out reporter and then i'm going to pass true here now this just means we're going to report data to the standard output so we'll actually see what generation we're on the best fitness the average fitness all that kind of stuff i'm then going to say stats is equal to neat dot and then this will be statistics reporter so let's write it like that inside of here we don't have to pass anything and i'm going to say p dot add reporter stats and then finally p dot add reporter and i'm going to add neat dot check pointer one now this is really important that you do this the check pointer is going to actually save a checkpoint after every x generations x being the number i passed here so i'm going to save one after every one generation now what this allows you to do is restart the algorithm from a checkpoint now you want this because it could take an hour two hours a day two days to run this depending on what you have in the config file so obviously you want to save your progress and be able to kind of restart and maybe train differently from a certain point in time so that's why we're checkpointing at every one you may want to checkpoint at every five generations whatever and to actually load from a checkpoint let me just copy this in what you would do is you would comment out this line and you would just put the name of the checkpoint that you want to load from okay pretty straightforward neat.checkpointer.restorecheckpoint checkpoint and then whatever the number is you'll see them being saved as we run this and then that's instead of the population but of course we don't have a checkpoint so we're not going to do that right now all right so now that i've done this i'm going to say p dot run i'm going to pass a function which i've yet to write called eval genomes and i'm going to pass the number of generations that i want to run this for at most now you can read what it's saying here we're passing what's called the fitness function the fitness function is going to take all of my genomes which are in the current population based on whatever generation it is and it's going to give them a fitness and then based on what their fitness is once that function is finished executing then the neat algorithm is going to perform its mutations and then it's going to go to the next generation and get the fitness for that so what i'm going to do is say define eval underscore genomes and i'm going to take inside of here my genomes which are the neural networks in the current population as well as my configuration file okay so let's just quickly talk about what we did we set up our population using the configuration file then we added the reporters and the check pointer just so we see some data on the screen and we're checkpointing at every one generation then we're saying p.run we're passing the function make sure you don't call the function just pass the name of the function it will automatically pass this data for us then the maximum number of generations we want to run for which is 50. now i can actually say winner is equal to p dot run and this will give me the best neural network or the one that hits the fitness threshold while running this so either we'll get to 50 generations and then whatever one has the best fitness will be the winner or if we hit one that or if we get one story that has 400 fitness or more it will be returned to us at whatever generation that occurs okay now we have eval genomes now inside of here what we need to do is we need to set a fitness for every one of our genomes and to do that we need to run them through the pong game all right so let me take a quick pause here and explain the thought process behind how we're going to train this ai because it's a little bit complicated but it is necessary to avoid getting kind of stagnation in training so there's a lot of ways that we could train a pong ai and the whole issue here is that this is a multiplayer game if this was a single player game no problem it'd be really easy to train because the environment's always the same right it's always the same single player environment so everything's consistent and we get a really fair fitness reading however in pong the performance of our player our ai depends on the performance of its opponent and so we need to find a fair way to train all of our ais by either playing them against say the same opponent or maybe each ai against every other ai there's a lot of different possible ways to go about doing this so the first approach you may think of is okay well let's train the ai against the same opponent every single time if we do that then we get a consistent fitness score that's correct but the issue is if we train against the same opponent we need to have a opponent that's as good as can possibly be right because if we have an opponent that's really bad we're going to get a false sense that our ai is good so we need an opponent that's as good as possible to really determine the fitness of our ai but the whole point of making the ai is to find a really good ai at playing pong so we don't have that available right unless we were to hard code something out which is definitely possible you could hard code this without actually making you know the neat ai for it but this is you know much neater much cooler so we're going to eliminate that approach because it doesn't make sense for us to kind of hard code out an opponent to play against the ai so the next approach is let's train the ai against itself now this is a reasonable approach to do this but what's going to happen if you train the ai against itself is that even though you're going to get a very fair fitness reading the ai is going to learn how to play only against itself it's not going to learn how to play against an opponent that makes seemingly random moves and if it's only learning how to play against itself even though it may look like it's going to be very good we have no idea what's going to happen if we put it against an opponent where it can't predict what the move of that opponent is going to be so we can't really go with that approach i mean we can try that but we're probably going to end up with ais that are really good against themselves and look amazing but then when they start playing against me or you they have no idea what to do so the last approach is we need to train each ai against each other so either i take pairs of ais maybe like ai 1 and ai2 and train them against each other and then get their fitness or i take each ai and i train against every single other ai and take kind of a sum of the fitness of all of those games now that's the approach that we're going to go with and the reason we're going with that approach is because again how good your ai is or how good the fitness is is dependent on its opponent so to make everything as fair as possible we want each ai to play against every other ai now that is going to take a long time but it's going to give us the most accurate fitness and actually end up being one of the quicker training routes so that's what i'm about to implement apologize for all this talking but again you got to understand the theory behind what we're doing and some of the potential problems that come up in a multiplayer game so let's try this now i'm going to again be kind of looking at my screen i don't have all this code memorized so if you see me looking over here that's what i'm doing i'm just referencing my code so the first thing i'm going to do is say width height is equal to 700 500 because we need to set up a pi game window so we can pass it to this game instance or to the pong game instance where i'm actually going to write a method that will train the ai for us in kind of a similar way to how we were testing it so i'm going to say with height and then i'm going to say window is equal to pygame.display.window or dot sorry.set underscore mode and then width height okay and now that we passed width height what we can do is say for i comma and i'm going to say genome underscore id genome i think this is correct in and this is going to be enumerate genomes now let's go genome id1 and genome so first thing to understand here is that genomes is going to be a list of tuples where each tuple has the genome id as well as the actual genome object now remember i want each what do you call it genome to play against every other genome and so the reason i'm enumerating here is so that i can make sure we're not repeating games that you're going to see in a second so i'm going to say 4 and then this is going to be genome 2 or genome id2 genome 2 in and then this will be genomes at i plus 1 colon now i spell genome and then colon and then for now we're going to pass so this is kind of the setup of our for loop here we're saying 4i which is the index of each all of these genomes genomic d1 genome 1 in enumerate genomes and then we're saying 4 genome id2 genome 2 in genomes i plus 1 colon now the reason we need i plus 1 colon is to make sure the same genomes don't play against each other multiple times they would be swapping on the left and right hand side but to avoid doing so many operations and to cut it by a significant amount i'm going to make this i plus 1 just so the same genome doesn't play against each other multiple times now the issue with i plus one is that eventually we're gonna get i being equal to the last index and then when i add one to it we're gonna get an index out of range error so i'm just gonna say if i is equal to the len of genomes minus one then break just so that we end okay hopefully that makes sense uh that just avoids having the index out of bounds error here okay so now inside of here what i want to do is i want to create a game and i want to test the two genomes against each other so i'm going to say game is equal to pong game and i'm going to pass my window my width and my height now before i do that if i can type properly here i'm just going to set up here i'm going to say genome 1 dot fitness is equal to 0. now these genomes do not have a fitness attribute on them by default so the reason i'm doing this is so that later on i can add or subtract from the fitness as opposed to setting it because i'm going to be adding and subtracting to it multiple times again this all makes sense when i write more code but i'm saying genome 1.finish equals 0 and then down here in this next for loop i'm going to say genome 2 dot fitness is equal to 0 if genome 2 dot fitness equals none else this is going to be genome 2. fitness now this is an inline if statement and the reason i'm writing this is because for my genome 2 i need to set its fitness equal to 0 when i first pick up this genome when this is the first genome that i'm having a look at now the issue is that i don't want to set its fitness to zero if the genome already has a fitness value from being ran multiple times so if we're looking at this i have genome one right and then this for loop is going to run every time that this for loop runs so on the next iteration of this for loop this for loop kind of restarts and i'm going to be looking at the same genome multiple times as the opponent to this genome so i don't want to set this genome's fitness equal to zero if it already has a fitness value but if it doesn't have a fitness value then i need to initialize its value and so that's why i'm writing this here hopefully that's all good and just to make sure i think this will be fine because this genome will only ever be encountered in this for loop yeah we should be good with that okay so now that we've set the fitness values uh we initialize our pawn game so game is equal to pawn game and then what i'm going to do is i'm going to train my ai so i'm just going to say game dot train underscore ai i need to pass to this genome one genome two and then the configuration file okay uh that's all we'll pass for right now and i'm gonna write this method on the game class and this game class will set the fitness for us okay so this is almost all we need in here we'll make a few slight changes but we're just going to train the ai so we pass genome 1 genome 2 and then it will simulate the game between the two ais and set their fitness so now we're going to go up here and let's just write it from scratch i don't want to copy this i'm going to say define train ai and inside of here i'm going to take genome 1 genome 2 config and then i need to make sure i have self as well okay so self genome one genome two and config and then i need to run both of these genomes uh right and i need to pass my input to the neural networks get the output analyze the output and then make a move for my paddles so similar to what i've done up here i'm going to say run is equal to true i'm going to say wow run and then i'm going to say game so self dot game dot loop self.game and then pygame dot display dot update okay so now that we have this game loop set up similar to what i did here i'm just going to take this event loop and i'm going to say let's get into the right method here for event in pigeon.event.get i just need a way to quit right so i'm putting this in here just so i have a way to quit i'm going to say run equals false but i'm actually you know what i'm not going to say only false i'm just going to return false here and the reason i'm going to return false is because what's going to happen is we're going to constantly call from eval genomes this game right i'm going to constantly be creating a new game and constantly running it and so what happens is if i return false here then that's fine i end the current training but then i'm going to train again and again and again and i want when you click the x button to just completely exit the program so i'm going to say force underscore quit is equal to this and actually i'll say if force quit then quit okay and in fact i don't even know why i'm doing all this this seems a bit too complicated let's just do this let's go here and let's just say quit so if you hit this we just quit the entire program uh quit just completely ends the game okay say quit that's just going to end the program for us so i can avoid having to return values back and do all that stuff okay so now we have a way to exit we're looping we're drawing we're updating the display and what else do we need to do here well let's have a look at the game information so let's say game info is equal to self.game.loop and now that we've done that we need a way to actually move the two paddles using genome 1 and using genome 2. now what we can do is we can create neural networks for both of these genomes then pass inputs and get the output so i'm going to do that here i'm going to say net1 is equal to self actually it's not going to be self it's going to be neat dot nn dot feed forward network dot create i'm going to pass my genome and the configuration file okay so that's net 1 and then net 2 is going to be the same but it's going to be with genome 2. now to use the networks what we need to do is say and we'll do this before we call the game info we're going to say net1 dot activate and we're going to pass the inputs to the network so the inputs that we want is we want the y coordinate of the paddle we want the y coordinate of the ball and we want the distance in the x between the ball and the paddle now it doesn't matter the order that we pass them in so long as we pass them consistently in the same order so let's say output let's go output 1 is equal to this and we'll pass self dot left paddle dot y it has a y attribute on it you can look at the paddle class if you want to see that then self dot ball dot y and again remember we have these up here so that's how i'm accessing them and then we want the absolute value of the self dot left paddle dot x minus the ball dot x okay so this is always going to be positive nice so that's what we have for output one and then we want output two so output two is going to be equal to this but it's gonna be net two and rather than left paddle is gonna be the right path okay and then that's ball.y and that is the right panel nice okay i think that's all good so this is going to give us an output now the output is just going to be the numeric values associated with the three output nodes in our neural network so we need to actually interpret that and we need to select the maximum value from those outputs now since i understand it's a little bit confusing let's just print them out for now and just have a look at what's happening so let's go output one output two now i also need some way to end the game here because i'm not ending the game in this game class i'm relying on whoever's using the game class to end it based on this info so i'm just going to put in a statement here and i'll do this at the bottom i'll say if and this is going to be game info dot left score is greater than or equal to 1 or game info dot write score is greater than or equal to 1 then i'm just going to break but before i break i need to set the fitness of my two genomes now i'm going to say actually it won't be self it's just going to be let's say genome one okay instead of doing that let's go define and this will be calculate fitness and we'll take in self genome one genome two sorry i was just contemplating how i want to do this uh but i want to do it in a method so i'm going to say self dot and then this will be calculate fitness and we'll pass genome one and genome two and actually we will pass the game info as well i guess we need that data in here just pass game info and then inside of here we'll we'll deal with what the fitness calculation should be okay so there's a lot going on here believe it or not we're actually almost done we just need to move the paddles but i want to kind of take a pause explain what i've done so far just so i'm not confusing you guys too badly then we'll run the code see what we're getting right now and then continue from there so let's go right to the beginning we have our local directory configuration path we essentially read the configuration file and then we pass that to our run need function we set up our population all of our reporters and all that and then we run the eval genomes function up to 50 times okay so we come here we set up a pi game window because we need that for our game and then we say 4i genome id1 genome 1. we actually don't care about the genome ids but we'll just leave them there in a numeric genomes and what this whole set of for loop is going to do here is it's going to run each genome here so each genome 1 against every other genome exactly one time and then the fitness for that is going to be the sum of whatever the fitnesses they get for every game okay then we set the fitness because we need to initialize an attribute we then go and loop through all of the other genomes set the fitness if they don't already have one set and then we train the ai okay genome one genome two config coming up here we set up our two neural networks based on our genomes we then run the game okay we have an event that just allows us to actually quit and then we get the output from both of our neural networks now we're going to use this output to move the paddles we're going to do that later we run the game loop which now that i'm thinking about it i guess we can run the game loop here that's fine and then we have self.game.draw so we just draw the game and then we update the display and then hear what i've done i didn't really explain this i'm essentially saying that if either paddle misses the ball once we're immediately going to end the game now the reason i'm doing this is because if the paddle misses the ball i don't want to keep running it like multiple times 50 times 100 times whatever because it's most likely going to miss almost every ball i want to be in a situation where as soon as it misses we just immediately move on to the next paddle and that way it doesn't get any higher fitness score and i just kind of stopped testing that one because it could take a long time just for it to continue to miss balls again i know it might be a little bit confusing but the score is telling me again how many times the ball has gone off the opposite person's side so if the left score is one or the right score is one that means either the left or the right paddle missed the ball and since they missed the ball then we're just going to stop calculate the fitness and then move on now the only issue with doing this here is that what's going to happen is that as soon as even your opponent misses the ball you're going to stop as well we're going to stop calculating your fitness as soon as you or your opponent misses the ball now this is a way for me to quickly train because if i don't do that again it's going to take way way longer to train like significantly longer so you could come up with other approaches and other fitness calculations this has worked for me this far that's why i'm doing this again feel free to change this as you please and then if that happens we're going to end so we're going to calculate the fitness and then break out of this loop and then kind of move on with life all right okay so let's run this so far let's just see if this is working you're not going to see kind of anything moving on the screen really because we're not actually moving the paddles but you will see in the console what our outputs are and you'll see what the need output is as well so let's close cmd let's run this and let's see what we get okay it says name ball is not defined self.ball.y oh i just put ball.x sorry guys let's make that fix so this is now self.ball and this is self as well scroll over so you can see okay nice okay so let's clear and run and see what we get now and there we go okay so we can see that we're getting a bunch of results let me close this we're getting a bunch of results here and what we're going to do is we're just going to take whatever the maximum value is of all of these things right so we'll treat the first column as staying still the second column or the second index as uh moving up and then the next one is moving down and as you can see right we're getting you know sometimes we're getting a bunch of different values sometimes we're just getting zero and these values will start to make more sense as the ai trains itself and gets better so to do that we're going to say let's go here result 1 or we'll say decision 1 is equal to and then this is going to be the maximum of output 1. we're going to index this so i'm going to say output 1 dot index the max of output 1. this is going to give us the index so either zero one or two and we'll say zero stay still one is move up and two is move down hopefully that makes sense we're just getting the index of wherever the maximum value occurs from output one and then we'll say output two is equal to output two dot index the max of output two so now that we know sorry not output two decision two so now that we know the decision we can then write some if statements that say okay if this is a decision move here if this is a session move here so i can say if decision one is equal to zero then we just don't do anything right because we're staying still we can say l if decision is equal to one then we will say uh self dot game dot move paddle and we're gonna say left equals true because the uh net one is going to be our left paddle and then up equals true okay and then else we'll say self dot game dot move paddle left is equal to true and up is equal to false because that's moving down and we'll just copy the exact same thing and just tweak it a little bit so now this is going to be decision two decision two and then we just need to change left to be false because now this is the right pad okay so that's how we'll move the paddles and with that we've actually set up almost all the training for the ai other than the calculate fitness function which we'll do in a second but now if i clear this in rerun you should see that the paddles move right now they're not really doing very well for us but they are moving and yeah there you go so now the pedal is actually moving based on the neural network and once we start implementing the fitness and the different generations then you'll see that they'll slowly start to get better so let's close that i also want to change something here where it says draw so for the draw i'm going to say draw score is equal to false instead i want to draw the number of hits they have so i want to say draw hits is equal to true and just to show you that change let's run it and notice that now we just get this red thing being drawn that's telling us the number of combined hits between the left and the right paddle okay so now that we've done that all we need to do is implement the fitness once the fitness is implemented we're pretty much done with the code and we just need to wait for it to train and i'll show you how to save the best run tested all that stuff so to do this we're simply going to say genome one is equal to or sorry dot fitness is plus equal to this is going to be game info dot left hits like that and then i'm going to say genome 2 dot fitness plus equals game info dot right hits so that's actually all we need for the fitness again we'll just add how many hits they had in the game and we're adding not setting if you set that's no good that means the only the last game they play is going to account for their fitness we care about every game they're playing because we're playing against every single ai now the only thing that we want to implement here is we want some way to essentially end a game when the hits get too large because you'll get to a point where you do have two perfect ais and when they're playing against each other they can play infinitely so we just want to make sure that the number of hits between them doesn't grow so large that we play too much right and that that biases our score so let's say and game info dot let's just go with left hits is greater than 50. sorry not not uh not and we're going to say or so essentially what this is saying is that if the player on the left gets 50 hits or more or gets more than 50 hits then we're just going to stop because they'll still get a very high fitness score but we don't want them to play infinitely right again that's just going to make the training really long and that will actually give us an infinite loop now the reason why i'm not checking the right hits is because the right hits will always be either one more or one less than the left hits so there's no reason for me to check the right hits as well if the left hits is greater than 50 then the right hits will either be 50 or it will be 51 or it will be 49 or something like that right it's very similar so it doesn't really matter and the reason why that will be the case is because when the ball starts on the screen it will randomly start either on the left or the right hand side i don't know where it's going to start randomly left or right yeah hopefully that makes sense but that's why we're checking that okay so now that we've done that let's run this let's just see how it works for a generation or two and then i'll show you how we test it and how we save the best ai okay so let's go ahead and run the code all right so i've just let this run for a few generations and i'll just talk to you about some of the data we're getting here uh then we'll kind of look at the ai see how it's doing now on i guess generation four and um how we can actually test the ai as well so we have the average fitness of 4.0 actually not bad for the first generation that means at least some ais were hitting the ball right we have best fitness of 20 that means one ai through all of the different games that it played hit the ball a total of 20 times so played 49 games and it would have missed the ball i was that 29 times and hit the ball 20 times so not great but for the first generation we can live with that right then we have average adjusted fitness 0.347 mean genetic distance this is the i guess difference between the neural network architectures kind of hard to explain exactly what the magnitude means here but the larger the number the more different the the different neural networks are that you have then you have the population of 50 members in two different species so species with id1 is here species with ids 2 is here tells you how long the species have existed and then the size there's 19 in species 1 31 in species 2 and then we have a fitness of 20 and a fitness of 10. now that's the best fitness in this species and the best fitness in this species and then the adjusted fitness for that species okay coming here we have now 19 in species 1 31 in species 2 fitnesses have now changed and the stag here is telling you the stagnation of the species so how long has it been stagnant for continuing we now come here and now the reason this is getting a one for stagnation is because its fitness score is less than it was last time so it's now being stagnant right based on the mutations that would have been done and you see that we've actually now moved some of these uh neural networks into the other species based on the architecture of the internal neural network okay and continuing we come here we're seeing the fitness is increasing the average fitness goes up best fitness 68 and you will notice that sometimes you will go down so you'll hit a generation where your fitness will drop drastically that's fine that does happen and again that's because we're adding random mutations we're doing changes and it's not always guaranteed to give us a better neural network we just hope it's going to do that now here we're at stagnation of three in the config file i believe we had 20 as the extinct stagnation so once that hits 20 if there's more than two species then it will actually make this species go extinct because it's not been improving over a period of time right so all this different kind of stuff lots to learn lots to look at i'm by no means a pro here but i have figured out how to make a few ais using neat so obviously the tutorial now this is running and you'll notice that we're going to get a lot of low scores right but once in a while you will see kind of a decent rally and it's difficult to really tell how well you're doing based on just watching this because you only need one ai to perform well to really get a good ai right to get a good result out of this and that ai will play against every other ai and since all the other ais are going to be really bad what's going to happen is this ai will hit the ball every time then it will never be returned and so will look like the rallies are always short but that's just because the opponent of the really good ai can't return the ball right so there's all kinds of stuff like that to think about and this took me a few days kind of messing around with to really understand so this is running we'll leave it running for now and while it's running let's just work on actually how we would test the ai and a change or two that we could make here and then what you can do is you can stop it we can rerun the code and then we can return from the checkpoint that we were just at so we don't have to redo all of the training that we already did right because you're going to notice it takes a long time like the average generation i think is about two or three minutes long okay so if we want to train the ai uh or sorry test the and not train it we have test ai and what we're going to take in here is a genome which will just be the best ai right and then from the genome we will create a neural network and then we'll use the neural network to move the ai so we're just going to say net is equal to and then actually we'll need the config as well so we'll say net is equal to neat dot nn for neural network dot feed forward network genome config okay and now that we have the network let's use it inside of here so we're moving the left paddle let's just have the ai move the right paddle and then that's really all we need here i mean there we could implement some way to end the game but i'm not even really going to do that in the test ai because if you want to end the game you can just click the x button right and here rather than drawing the number of hits we'll draw the score and then we'll actually see how the ai is playing against the human and you'll notice that the ai will be unbeatable based on the way that i've coded this pawn came out so let's go here and let's now move the paddle so really what i can do is simply copy output 2 in decision 2 here and just paste that right here now we can just make this output rather than you know decision and change a few of these values here and net 2 will just be net but this will be right panel and i think that will be good yeah that's really all we need and i mean i could get rid of this if decision equals zero pass i'm just putting it there so it's explicit and we know that zero means that we're staying still so now that we've done that we now actually have something that will test the um uh what do you call it here sorry that we'll test the ai for us what i want to do instead of drawing the score or sorry instead of drawing the hits though is i want to draw the score so i'm going to say true false so this means we're going to draw the score not draw the hits and that's what we want when we're actually testing the ai out okay so i think that's good for test ai we have train ai now what we really need is some way to save this best ai now we're not going to get this best ai for a while we need to get to a score of 400 right or 50 generations and obviously i'm not going to sit here and just you know wait for all this to finish before recording the rest of the video so we'll let it run but what i will do is show you that we can use a module called pickle to actually save the object right to save this neural network and then we can load that neural network in so rather than having to retrain this every time we just load the neural network that's really good at doing what it does use the neural network and then we're good to go so i'm going to say import pickle here okay this is built into python so you don't need to install this and we're just going to go down to right where the winner is i'm going to say with open and i'm going to say best dot pickle i'm going to open this in wb mode which stands for write bytes i'm going to open this as f then i'm going to say pickle.dump and i'm going to dump the winner into the file f that's as easy as it is to actually save the neural network so this gives you the best genome sorry not the neural network gives you the best genome so we're going to dump the genome into this pickled file so what pickle allows us to do is actually save an entire python object so that's what we're doing here so we'll open that but then what i can do now is i can write another function i can say define test ai okay i can just take in my config and then here we'll just open the pickle file so we'll say with open best.pickle in rb mode as f now we're going to say the winner is equal to pickle dot and rather than dump we're going to say load and we're just going to load the file so now that we have the winner genome what i'll do is i will just call my game so i'll say game is equal to pong game and then i will pass to this a window so let's just copy the window that we made here okay so let's paste that there so we'll say pong game we'll pass window width height and then we'll say game dot test ai and we'll just pass the winner that's all we need that will run the game for us now we can test the ai so what i can do is i can just after i run my need algorithm i can say test ai i can pass my config and then if i have the best.pickle file so as soon as this training is done what i'll do is i'll comment this out and now i'll just test the ai right right so rather than running the need algorithm we just test the ai and then we'll be good to go okay hopefully that makes sense uh let's go here and okay we just got a funny one there where they were both kind of stuck at the top of the screen just hitting it back and forth but we should notice there's been some pretty decent progress like at least when i'm looking at this right now it looks like a lot of them are rallying this is something that will happen uh it just it's gonna happen the way that i've coded this out it's possible for it to kind of go in that way but since the ball comes off at a random angle it should be rare that that's going to occur and of course if you're playing against the ai then you would be able to hit the ball in a way where you kind of get it off and so the two ais i guess are just uh they don't want to move and they're both staying at the bottom of the screen anyways i'm not going to watch this i have been looking at this like all day before filming this tutorial i'm going to close this and i'm just going to change the fitness threshold to be very small and then i'm going to take whatever the best ai is that we have and show you how we test it even though it's not going to be as good as you can get right and then obviously you guys know you can just train this for longer you'll get a better ai and then you can test that ai but i don't want to wait because it's going to take a really long time right like the average generation time 139 seconds so let's close this now all of our work is not lost we still have checkpoint seven so now what i'm going to do is restore from checkpoint seven right if i wanted to okay so restore from checkpoint seven and i will just actually we're gonna have an issue here i'll talk about what the problem's gonna be in one second but if we restore from checkpoint seven we can just keep training and we'll start start where we stopped off now the issue here is that the configuration file if i make a change now after i already started training and i resume from a checkpoint it's not going to take effect so what i wanted to do is i wanted to just change the fitness to be like 200 or 100 and just wait until we got that which would be a lot faster but since it's not going to take effect any change i make here since we're resuming from a checkpoint what i will do is i'll just make it so that whatever the best ai is of the next generation that we run is the one that we get and the way i'm going to do that is i'm going to change this to just run one generation so we'll resume from checkpoint seven and then we'll resume and then we'll run one generation and whatever we get from that generation will pickle right and then it should test the ai excuse me my voice is starting to go here and then we should just be able to play against it okay so let's clear and let's run and we'll wait for the one generation to finish once that's done i'll be right back and then we'll see how the best ai holds up against me alright so i just finished running the generation you can see bestop pico has been saved now what i've done is i've just commented out run neat and now i have test ai and i just made a small fix here uh in game dot test ai i need to pass config as well so winner and config this code will all be available from the description as well so don't worry if you're missing some of the fixes and then inside of my test ai function here i need to fix a few things so wherever i have game i just need to put self before it because when i copied this in it wasn't in a class i didn't self and then here where i have decision i need to change this from output two to be output and then here where i have game loop this needs to be self and this needs to be self as well so really anywhere there was game just put a self before it and then this was a small fix add output to it need to be output uh anyways let's run this now and again we're just going to be testing the ai so we're just calling this function and it should open best up pickle now i have no idea how well the ai's going to perform because we only ran it for seven generations okay you can see so i missed it looks like it's getting close okay it actually hit the ball that time and it's kind of a bit jittery but let's see how it does okay nice so it's actually working uh slightly right now again we only ran for seven generations it kind of glitched on that one it was weird it looked like it was going then it stopped moving but um if you run this for more generations you will get a perfect ai and i have had many perfect ais when i was kind of testing this beforehand so yeah with that said i think i'm going to end the video here now this was a lot to record i don't know how long the video will end up being because i have to edit a ton of stuff out but it's only almost three hours of me recording this so if you guys appreciated this please do leave a like subscribe to the channel i understand it's a little bit all over the place but something like this is difficult to film because it's hard to know when to either over explain or underexplain something and what the general competence of the audience is going to be because this is a complicated thing requires neural networks machine learning artificial intelligence advanced python code so there's a lot that i could have explained i could have made this video a lot longer anyways love to hear your feedback on it in the comments down below again please like subscribe i look forward to seeing you guys in another youtube video you