hey guys and welcome back to another machine learning tutorial so in today's video we're gonna be continuing with KN n so k nearest neighbors and we're gonna be implementing that algorithm throughout our code I'll be showing you guys some cool things we can do with it how we can actually check the neighbors between different points obviously how we can score it see how well we're doing and test and train our data now I just want to remind you guys in case you want to see any of this stuff textbased you can go to my website tech with Tim done that the link is always in the description down below and currently this page says protected just because at the moment that I'm recording this this video is not out but once these videos come out these pages will be unpassed word protected so you'll be able to access them and essentially obviously this is not the tutorial we're doing right now cuz I haven't yet written this tutorial but you guys will see that on the website okay uh and yeah also if you guys have any questions please feel free to go to the forum and post some stuff in here some people have already posted and I've answered them like right away because I get email notified so if you do this I'll actually probably respond to you excuse me faster then if you leave a comment on the video but again you can feel free to do that as well okay so let's go ahead and get started so you guys might have noticed a trend by now that the first video is typically like collecting our data talking about the data set the next one is then kind of either talking about how the model works and the final one is implementing it if you guys like this kind of process let me know I think this works the best and as we continue to go further and more complex we're probably gonna have to dedicate more videos to talking about how these algorithms really work but I hope you guys noticed by now that collecting the data is usually the hardest process right because we need to get our data in the correct form so that's just something to think about as we continue on with machine learning okay so we're gonna create our classifier and we've already done similar things too so we're just gonna do model equals K nearest classifier like this will give us some brackets here and these brackets actually take one parameter and this is the amount of neighbors so there's a few other ones that we can do in here but essentially remember I was talking about how many neighbors we want now again this is a hyper parameter meaning that you kind of tweak it as you continue to train the model for me I'm just gonna start with five I think actually to do like yeah after ununder squirty neighbors equals five but play around with this do 7 do 9 do 11 do one and see what a Curie score is you're getting based on this and if you guys find like a really good accuracy let me know what neighbors you you use okay so I'm not going to play around with it too much now that we've done this we're gonna do the exact same thing we've done before we're just going to do model dot fit with your X underscore train Y underscore train and again that's literally all we have to do to train the model and now we're just gonna test it for accuracy so we can just do model dot what do you call it score and then in here we're gonna do X underscore test y underscore test and then we can simply print our accuracy to the screen like we've been doing through the other tutorials so let's just go ahead and run this quickly and you see we get a zero point nine percent accuracy so that's okay but let's actually just see what we can get if we're tweaking the amount of neighbors and we do some stuff like that so let's do neighbors equals seven and ninetyone okay maybe let's try nine and see if we can increase this accuracy at all so we're getting 94 then off of nine neighbors so with this data set maybe more neighbors is what's gonna work well again you guys got to play with that I'm not gonna go through all of it okay so I want to do again a similar thing that we did with linear regression where I want to see what the data points are and what our prediction is and what the actual value is so I'm just gonna do a for loop and loop through the test data and print out that test data and then the prediction and what the actual value is so we can see how well we're really doing just by looking at data points so I'm just gonna create a list called names first and this is just gonna be the names that like our classifier classifies our things as right because what our classifier is actually doing is it's classifying from zero to three right where zero is gonna represent on AC C and then three is gonna represent AC see I have the names are very good sorry so I'm just gonna put these names here so we can actually get not just a number we can get the actual value okay so good and we have very good now this is just what the data set uses this name to feel free to change ease if you want but this is what I'm going to do for here okay so now I'm gonna create a full loop and I'm just gonna say four and I guess we're actually got have to do somebody call its will just do X in range and then the Len of X underscore test because we're gonna need the index here so what we'll do now is we'll simply print out pretty cool predicted oh yeah we'll do predicted data first I guess if I can smoke prick predicted correctly and all we'll do there is we're gonna do hmm I am forgetting something our time I need to predict the data first okay so let's do that predicted equals model dot predict and then in here we can just do X underscore test there we go so now we'll get all that predicted data and then instead of X test let's just do predicted here just go that's what I did before and then in here we'll just gonna do predicted and then whatever that x value is and then I don't know if I want to do this on the same line or not you know what maybe it'll look better on the same line really predicted we'll do data and the data is just gonna be this X test data right so X test X and I guess I could actually just do a comma that'll make things a bit easier okay and then we'll just do actual and this is just gonna be be y train data or the Y test data right and that x value so assuming I didn't make any mistakes which I probably did this should just print out all of our test data with the predicted value first the actual data and then what the actual value of that data is okay so let's see here and there we go okay so essentially let's go up to the top I guess we did actually have a lot of testing data here so it predicted to we had this is the actual data and the actual value is two and see if you can find a mistake okay so this one's a mistake too and it the actual value is zero right so you can go through and kind of look for that now I just realized I didn't even end up using this names so what I'm actually gonna do is I'm gonna do names surrounding this predicted here and essentially all this is gonna do a little do the same thing here is it's just gonna use because these numbers are gonna be indexes right they're going to be a 0 through so if the predicted value zero is just gonna print on a cc if it's one it's gonna print a CC and then exact same thing for names that's pretty straightforward how that works so let's run this and there we go so we see it says good and then be good and like you can go through and look at all of that okay so that's essentially it for like predicting and doing that no I just want to go through a few other things we can do with kN and some more values that we can kind of look at in case that's something that we're interested in or we want to like graph some data or whatnot so I'm gonna open up Google here sorry that's not what I want to have open I want to have this open and this is actually I want to show you guys this because the SK learned kind of documentation and essentially this is the documentation for kN so you can see we have Fitz get params neighbors predicts score if we've already used three of these ray we just fit predict and score but if we actually wanted to get the neighbors for each data point that we're predicting we can do that with with neighbors okay so essentially what this is going to return to us and you can kind of just look at it here is well it takes the x value the amount of neighbors and that's gonna return the distance to each of those neighbors so let's just go down and have a look at this documentation and you can see it's gonna give us two arrays if we have this last value true which it's default to be true and it's gonna give us the distance to each point that is the amount of neighbors and it's going to give us the index of that point within our data set so if we want to have a look at exactly what those points are we can index them and look at them so rather than just talking about this let's actually just copy this in and lets you use this so what we can do is underneath here I'll do it in the same loop actually we'll just do a model dot neighbors okay and then we're gonna give it that x value now this is gonna be weird how you give it that data but essentially you just have to put brackets like this and then you do what do you call it X underscore test and X now the reason we have to do this is because you can technically give this where it's actually supposed to take a twodimensional array but when we give it this and we only want one value we just have to put it inside of another like little list thing so then it comes in as two dimensionals because it doesn't know how to look at data that's not twodimensional essentially and I think we can actually do up the amount of neighbors in this case nine and then we'll just put true here even though that's not really necessary and if we wanted to decrease the amount of neighbors we're looking at we could put like five we put three you put one and it'll just give you the closer ones in that case right so let's actually store this under let's just say n and if we want print out this data for each point what we just have to print n right so it's gonna give us two arrays for each of these sets so let's just do like n just so we know what we're kind of looking at here and we'll put comm like that okay so let's try this now can and Wow okay so this outputs not very pretty but we are getting the output that we want so let's try to have a look at this so predicted was good the data was this the actual value is this and then here's our array okay so essentially it's saying that the distance between all these points is one so between the nine neighbors and the O and then we have some distances of 1.41 and yeah you can see that and then it's going to give us the index of all of our different neighbors here so you can see that the first neighbor was this and I had one of the closest values of one and they correspond to obviously the lengths that are here so if you wanted to technically plot this data like on matplotlib it wouldn't be particularly easy to do so but working with this data you could definitely get some kind of a plot going if you want to look at that so with that being said I think I'm gonna wrap it up here essentially I just want to show you guys how we can do this you guys can probably guess how to use the other classifiers by now but I really recommend you keep going through and following along with me because I'm gonna use more and more complex data and you guys already know that the data is kind of the hardest part of this getting it in the right form so understanding how you can do that will help you be able to use your own data in the future which is obviously the goal so if you guys enjoyed the video again make sure you leave a like and subscribe go follow to my Twitter for exclusive updates and video release dates and yeah