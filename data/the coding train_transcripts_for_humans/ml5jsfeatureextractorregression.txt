With timestamps:

00:00 - [WHISTLE]
00:03 - Hello, everyone.
00:05 - In the previous video,
I made this example.
00:08 - What this example is doing,
is it's using something
00:10 - called transfer learning.
00:12 - It's already been trained
to recognize my happy face.
00:16 - And my sad face.
00:18 - My happy.
00:19 - My sad face.
00:20 - The process that
I use is something
00:22 - called transfer learning, where
I'm using a pre-trained model,
00:26 - MobileNet.
00:28 - I am eliminating the last
part of what it does,
00:31 - which is like take
an image and give it
00:33 - a label with some probabilities.
00:34 - I eliminate that.
00:36 - But I'm using all
the steps it does up
00:38 - until that last step where it
basically boils the image down
00:42 - to a nice smaller array of
numbers called the features.
00:45 - And then I assign my own
labels to particular features
00:49 - from images that I'm giving
it and train it again.
00:52 - So now it knows how to
recognize new images.
00:54 - And instead of giving
me the MobileNet
00:56 - labels, giving me my own labels.
00:58 - So that's what I did.
00:59 - That's called classification.
01:01 - In this video,
what I want to do,
01:03 - is use transfer learning
not to do classification,
01:06 - but to do something
called a regression.
01:09 - Now regression really sounds
like some scary, complicated
01:14 - mathematical concept term.
01:16 - It's really quite
simple in this case.
01:19 - Classification says
for this image,
01:22 - I would like to have a label A
or B or C. One of two options
01:28 - or five options
or 1,000 options.
01:30 - I am taking the image and
putting it in a bucket.
01:32 - It is a ukulele, it
is a train whistle.
01:35 - There's no in between.
01:37 - A regression is, I want to make
a prediction from that image,
01:41 - but I'm not making a prediction
as to which bucket it falls in,
01:44 - but I'm making, I'm
going to get a number.
01:47 - It's really more like a slider.
01:49 - So instead of am I happy or sad,
is how happy versus how sad.
01:55 - I want a single number.
01:56 - Of course, a regression
could produce
01:58 - more than a single
number, but in this case,
02:00 - I want a single number.
02:01 - I'm going to train it.
02:03 - I'm going to say this image is
a zero, this image is a one,
02:07 - this image is a 0.5.
02:09 - And then after I
train it, it's going
02:11 - to give me numbers in between.
02:13 - So I'm basically training
the model to look at images
02:17 - and produce the results
that are like a slider.
02:20 - Hopefully that made
somewhat sense.
02:22 - Don't worry if it didn't.
02:23 - I mean, I'm going
to produce the code.
02:26 - I think it'll make
more sense once I do.
02:27 - So once again, I want
to thank Gene Kogan.
02:30 - Check out the ml4a website,
which I'll link to.
02:33 - Gene Kogan made
a set of examples
02:35 - that do exactly this
with tensorflow.js,
02:37 - and this is really taking
inspiration from that
02:40 - and doing the same thing
with the ml5-library.
02:42 - So let me go to my code.
02:45 - This is the code that I left
off in the previous video
02:47 - with the image
classification example.
02:52 - And the main thing I'm
going to change here
02:54 - is, well, there's a lot of
things I'm going to change.
02:56 - But I want to change
this word here.
02:58 - I want a feature extractor
from the MobileNet model.
03:01 - And now I want to
do a regression, not
03:04 - a classification.
03:05 - Then I also want
to have a slider.
03:07 - So these buttons ukulele
vs. Whistle or happy or sad,
03:11 - I don't want these anymore.
03:15 - I'm going to keep
the training button,
03:17 - but I want to have a slider.
03:18 - So I'm going to say a slider,
I going to say let slider.
03:22 - And then in Setup,
I'm going to say
03:25 - slider equals create slider.
03:28 - The slider should have
a range between 0 and 1,
03:31 - should start at 0.5 I guess,
and have incremental values 0.1.
03:38 - Let's just make
sure I see a slider.
03:40 - So now I see a slider and
I'm able to move it around.
03:44 - So I've got a slider and
I can move it around.
03:46 - Now I will need to have
an event that happens
03:50 - whenever I move the slider.
03:54 - So whenever, oh,
yeah, whenever I move
03:57 - the slider, the event
for the p5 dom library.
04:01 - Again, there's a number
of different ways
04:03 - you could do this,
and you can find
04:04 - a link in the video
description too I think.
04:05 - Hopefully, a plain JavaScript
example does the same thing.
04:08 - I think that exists, is input.
04:12 - So let me just say
console.logslider.value.
04:16 - So what this should do, is
now anytime I move the slider,
04:19 - I should see the
value of the slider.
04:22 - So if I move the slider,
yeah, you can see 0.
04:26 - You could see it in the console
all the way up to 1, to all the
04:29 - way down to 0.
04:29 - Perfect.
04:30 - Because what I want to do
whenever I'm moving the slider,
04:34 - is I want to say, and I don't
want to call this classifier.
04:36 - I'm going to call it, I
guess the correct term
04:41 - would be regressor.
04:42 - That sounds really weird.
04:43 - I'm going to call it predictor.
04:45 - Predictor.
04:47 - So I'm going to say predictor
equals mobilenet.regression.
04:51 - And when I move the
slider, I'm going to say,
04:53 - predictor add image
with that slider value.
04:57 - So basically I'm saying,
give me an image.
05:01 - No, sorry, not give me.
05:02 - Assign this image.
05:04 - This image's features
to this number.
05:07 - So basically I'm saying, I'm
going to move the slider,
05:10 - I'm going to move it over
here, move over here,
05:12 - and I'm going to
say, oh, wait, sorry.
05:15 - Oh, it's always doing
it, that's weird.
05:17 - I probably should.
05:19 - I should create and
add image button.
05:21 - Let me create an add,
I was kind of doing it
05:22 - whenever I moved the slider.
05:24 - But I think
interaction-wise, it's
05:26 - going to make more
sense if I do,
05:28 - I'm going to make a button
called add example, add button.
05:34 - And I'm going to say add
Button equals create button.
05:40 - Add example image.
05:43 - And then add button
dot mouse pressed.
05:50 - And then I'm going to
say predictor dot add.
05:52 - I'm going to add it only
when I press the button.
05:54 - So forget about this slider
thing dot input thing.
05:57 - I'm going to add the
slider value only
06:00 - when I press the button.
06:01 - So in other words,
oops, error on line 47.
06:06 - This has to say
function, and then here.
06:09 - I'm putting these anonymous
functions inside here.
06:11 - They're the callback
for mouse pressed.
06:14 - OK, now let's try this again.
06:15 - So basically what I'm saying
is, if I move this to one,
06:19 - I'm going to say add example
image, add example image.
06:22 - Then I move my hand all the way
over here and move this over.
06:24 - I'm going to say, add example
image, add example image,
06:26 - add example image, et cetera.
06:28 - So then I might put
it in the middle
06:30 - and add, add
example, add example.
06:32 - All right, so I'm adding
a bunch of images.
06:34 - So I'm trying to
do something that
06:36 - makes sense to me, which is
map the position of something.
06:39 - But you don't have
to be so literal.
06:41 - You can probably come up
with your own creative way
06:43 - of using this.
06:44 - But let's see if we can
actually get it to work.
06:46 - So I'm going to hit train.
06:47 - I don't know, I probably need
to change some code there.
06:50 - Classifiers not defined, yeah.
06:51 - So schedule, let's try to get
the rest of the code in here.
06:55 - So this has to be
predictor train.
06:57 - So this should be
the same thing.
06:59 - And then once it's
finished, call predictor.
07:05 - And it's probably
now not classified,
07:07 - it's probably predict.
07:09 - Got results.
07:10 - And then the result,
it's not a label anymore.
07:13 - I'm going to, I'm going
to call it a value.
07:16 - And I'm going to say
the value is zero.
07:19 - And then I'm going
to say value equals
07:24 - result and predictor predict.
07:27 - So basically, everything
is the same as before.
07:30 - I'm just changing the
name of some things,
07:31 - because I'm no longer
classifying and getting
07:34 - a label.
07:35 - I'm predicting and
getting a number.
07:37 - I might have missed something.
07:38 - Let's try running this
and see what happens.
07:41 - OK, label is not defined.
07:42 - sketch.js.
07:44 - Lines.
07:44 - So this is now value.
07:47 - OK, so we can see that
these sample values,
07:50 - the starting value
of zero is here.
07:52 - So I'm going to put this here.
07:54 - I'm going to add a
bunch of examples.
07:56 - I'm going to move this
over, move the slider over,
07:58 - add a bunch of examples.
07:59 - I'm going to move this
over, move this over.
08:01 - Add a bunch of examples.
08:02 - I'm going to move this
over, move this over.
08:04 - Add a bunch of
examples, up, down,
08:07 - let's move it back over here.
08:09 - Let's add some more examples.
08:11 - Then let's call train.
08:14 - It's training, it's training,
it's training, it's training,
08:16 - it's finished.
08:17 - And now one down
to zero up to one.
08:24 - Pretty good, pretty,
pretty, pretty good.
08:27 - Not perfect, but pretty good.
08:28 - Boy, wouldn't it be nice if I
drew something on the screen?
08:31 - What the example, the example,
the original example that Gene
08:34 - Kogan had made in the ml5
example, doesn't draw the text,
08:37 - but it actually
draws a, I mean, it's
08:40 - nice to sort of see the text,
but it draws a rectangle.
08:45 - The rectangle at, I'm going
to say, value times width.
08:51 - Height divided by two.
08:54 - 50 comma 50.
08:56 - I'm going to must
say rect mode center.
08:59 - And I'm going to say fill
255 comma zero comma 200.
09:03 - So now we have this
nice rectangle here.
09:05 - Do bear with me one
more time to do this.
09:07 - I got to retrain it.
09:10 - I'm going to say hey,
add example image,
09:12 - add example image, and
move it to the middle.
09:14 - I'm going to add
some example images.
09:16 - That's not really the middle.
09:17 - I'm going to move it over here.
09:18 - I'm not, I could be
more careful about this.
09:20 - I should move it up and down.
09:21 - Agh, up, up, up, up, up,
down, down, down, down, down.
09:25 - Move it back to the middle.
09:26 - Let's add some more
examples in the middle.
09:28 - Example image, example image,
example image, let's move here.
09:31 - Let's add some more
example images.
09:33 - All right, let's train.
09:36 - Train, train.
09:36 - [WHISTLE]
09:37 - Train, train.
09:38 - [WHISTLE]
09:38 - OK, training is complete.
09:40 - And now, oh, where
was I standing?
09:41 - That's actually
kind of important.
09:43 - So look, it's kind of, it
looks like I almost have
09:45 - like a computer vision project.
09:47 - Right?
09:48 - That's following this.
09:48 - But you have to remember,
that's not what's happening.
09:51 - I could have done this with
my, interestingly enough,
09:53 - it's also working
just with my face.
09:55 - Like it sort of got the
sense of like something
09:57 - in front of the
background probably.
09:59 - Even if I hold this up,
it's sort of working.
10:03 - But remember now, I don't
have to be so literal.
10:06 - I mean this could map to sound.
10:08 - I could use different images.
10:10 - Images of cats, for one thing.
10:12 - I don't even know.
10:12 - But the idea here
is now, instead
10:15 - of the image producing a label,
the image produces a number.
10:19 - And that's a regression.
10:20 - And remember, this wasn't
not happening from scratch,
10:23 - this is happening
because I'm basically
10:25 - saying this whole process that's
already been learned, just take
10:29 - out that last part
where it turns it
10:31 - into the fixed set of 1,000
MobileNet layer labels.
10:35 - And turn that into, turn
that into something else.
10:41 - My own labels or my own number.
10:42 - You know, there's
something else that I
10:43 - want to mention that's
really important,
10:45 - because it came up in the chat.
10:48 - Now, where is all
this happening?
10:52 - You might ask, am I like
broadcasting images of myself
10:55 - somewhere out into the
cloud for all this?
10:56 - What's kind of interesting
and amazing about this,
10:59 - is everything is happening
here locally inside the browser
11:04 - of this computer itself.
11:06 - It's all gone.
11:07 - It lives nowhere else.
11:09 - The ml5-library, the
ml5-library and the p5-library
11:14 - are being accessed
from the cloud.
11:16 - They're being downloaded
when the pager.
11:18 - I could have local
copies of them.
11:20 - The MobileNet model, the
thing that I'm starting with,
11:23 - the MobileNet
model is also being
11:25 - downloaded from the cloud.
11:26 - And the ml5-library is
taking care of that for you.
11:29 - But once all of
that is done, it's
11:32 - all happening here
in the browser.
11:34 - And this, by the way, in
theory would work on your phone
11:38 - as well.
11:38 - It's called MobileNet.
11:39 - That model is a small, not
accurate, not super advanced,
11:43 - robust, but it's a
small little model meant
11:46 - to work on a mobile device.
11:47 - So it's important to realize
that everything is happening
11:49 - here locally on the device.
11:52 - OK?
11:53 - Thanks for watching, and
I'll see you, and again,
11:56 - the same issue here, I probably
want to save the train,
11:58 - save my retrained model.
12:00 - That's not possible right now
easily with the ml5-library,
12:05 - but that will come
in the future,
12:06 - and hopefully I'll
do a video on that.
12:07 - OK?
12:07 - Goodbye, and I hope you
make something with this.
12:09 - I enjoyed it.

Cleaned transcript:

[WHISTLE] Hello, everyone. In the previous video, I made this example. What this example is doing, is it's using something called transfer learning. It's already been trained to recognize my happy face. And my sad face. My happy. My sad face. The process that I use is something called transfer learning, where I'm using a pretrained model, MobileNet. I am eliminating the last part of what it does, which is like take an image and give it a label with some probabilities. I eliminate that. But I'm using all the steps it does up until that last step where it basically boils the image down to a nice smaller array of numbers called the features. And then I assign my own labels to particular features from images that I'm giving it and train it again. So now it knows how to recognize new images. And instead of giving me the MobileNet labels, giving me my own labels. So that's what I did. That's called classification. In this video, what I want to do, is use transfer learning not to do classification, but to do something called a regression. Now regression really sounds like some scary, complicated mathematical concept term. It's really quite simple in this case. Classification says for this image, I would like to have a label A or B or C. One of two options or five options or 1,000 options. I am taking the image and putting it in a bucket. It is a ukulele, it is a train whistle. There's no in between. A regression is, I want to make a prediction from that image, but I'm not making a prediction as to which bucket it falls in, but I'm making, I'm going to get a number. It's really more like a slider. So instead of am I happy or sad, is how happy versus how sad. I want a single number. Of course, a regression could produce more than a single number, but in this case, I want a single number. I'm going to train it. I'm going to say this image is a zero, this image is a one, this image is a 0.5. And then after I train it, it's going to give me numbers in between. So I'm basically training the model to look at images and produce the results that are like a slider. Hopefully that made somewhat sense. Don't worry if it didn't. I mean, I'm going to produce the code. I think it'll make more sense once I do. So once again, I want to thank Gene Kogan. Check out the ml4a website, which I'll link to. Gene Kogan made a set of examples that do exactly this with tensorflow.js, and this is really taking inspiration from that and doing the same thing with the ml5library. So let me go to my code. This is the code that I left off in the previous video with the image classification example. And the main thing I'm going to change here is, well, there's a lot of things I'm going to change. But I want to change this word here. I want a feature extractor from the MobileNet model. And now I want to do a regression, not a classification. Then I also want to have a slider. So these buttons ukulele vs. Whistle or happy or sad, I don't want these anymore. I'm going to keep the training button, but I want to have a slider. So I'm going to say a slider, I going to say let slider. And then in Setup, I'm going to say slider equals create slider. The slider should have a range between 0 and 1, should start at 0.5 I guess, and have incremental values 0.1. Let's just make sure I see a slider. So now I see a slider and I'm able to move it around. So I've got a slider and I can move it around. Now I will need to have an event that happens whenever I move the slider. So whenever, oh, yeah, whenever I move the slider, the event for the p5 dom library. Again, there's a number of different ways you could do this, and you can find a link in the video description too I think. Hopefully, a plain JavaScript example does the same thing. I think that exists, is input. So let me just say console.logslider.value. So what this should do, is now anytime I move the slider, I should see the value of the slider. So if I move the slider, yeah, you can see 0. You could see it in the console all the way up to 1, to all the way down to 0. Perfect. Because what I want to do whenever I'm moving the slider, is I want to say, and I don't want to call this classifier. I'm going to call it, I guess the correct term would be regressor. That sounds really weird. I'm going to call it predictor. Predictor. So I'm going to say predictor equals mobilenet.regression. And when I move the slider, I'm going to say, predictor add image with that slider value. So basically I'm saying, give me an image. No, sorry, not give me. Assign this image. This image's features to this number. So basically I'm saying, I'm going to move the slider, I'm going to move it over here, move over here, and I'm going to say, oh, wait, sorry. Oh, it's always doing it, that's weird. I probably should. I should create and add image button. Let me create an add, I was kind of doing it whenever I moved the slider. But I think interactionwise, it's going to make more sense if I do, I'm going to make a button called add example, add button. And I'm going to say add Button equals create button. Add example image. And then add button dot mouse pressed. And then I'm going to say predictor dot add. I'm going to add it only when I press the button. So forget about this slider thing dot input thing. I'm going to add the slider value only when I press the button. So in other words, oops, error on line 47. This has to say function, and then here. I'm putting these anonymous functions inside here. They're the callback for mouse pressed. OK, now let's try this again. So basically what I'm saying is, if I move this to one, I'm going to say add example image, add example image. Then I move my hand all the way over here and move this over. I'm going to say, add example image, add example image, add example image, et cetera. So then I might put it in the middle and add, add example, add example. All right, so I'm adding a bunch of images. So I'm trying to do something that makes sense to me, which is map the position of something. But you don't have to be so literal. You can probably come up with your own creative way of using this. But let's see if we can actually get it to work. So I'm going to hit train. I don't know, I probably need to change some code there. Classifiers not defined, yeah. So schedule, let's try to get the rest of the code in here. So this has to be predictor train. So this should be the same thing. And then once it's finished, call predictor. And it's probably now not classified, it's probably predict. Got results. And then the result, it's not a label anymore. I'm going to, I'm going to call it a value. And I'm going to say the value is zero. And then I'm going to say value equals result and predictor predict. So basically, everything is the same as before. I'm just changing the name of some things, because I'm no longer classifying and getting a label. I'm predicting and getting a number. I might have missed something. Let's try running this and see what happens. OK, label is not defined. sketch.js. Lines. So this is now value. OK, so we can see that these sample values, the starting value of zero is here. So I'm going to put this here. I'm going to add a bunch of examples. I'm going to move this over, move the slider over, add a bunch of examples. I'm going to move this over, move this over. Add a bunch of examples. I'm going to move this over, move this over. Add a bunch of examples, up, down, let's move it back over here. Let's add some more examples. Then let's call train. It's training, it's training, it's training, it's training, it's finished. And now one down to zero up to one. Pretty good, pretty, pretty, pretty good. Not perfect, but pretty good. Boy, wouldn't it be nice if I drew something on the screen? What the example, the example, the original example that Gene Kogan had made in the ml5 example, doesn't draw the text, but it actually draws a, I mean, it's nice to sort of see the text, but it draws a rectangle. The rectangle at, I'm going to say, value times width. Height divided by two. 50 comma 50. I'm going to must say rect mode center. And I'm going to say fill 255 comma zero comma 200. So now we have this nice rectangle here. Do bear with me one more time to do this. I got to retrain it. I'm going to say hey, add example image, add example image, and move it to the middle. I'm going to add some example images. That's not really the middle. I'm going to move it over here. I'm not, I could be more careful about this. I should move it up and down. Agh, up, up, up, up, up, down, down, down, down, down. Move it back to the middle. Let's add some more examples in the middle. Example image, example image, example image, let's move here. Let's add some more example images. All right, let's train. Train, train. [WHISTLE] Train, train. [WHISTLE] OK, training is complete. And now, oh, where was I standing? That's actually kind of important. So look, it's kind of, it looks like I almost have like a computer vision project. Right? That's following this. But you have to remember, that's not what's happening. I could have done this with my, interestingly enough, it's also working just with my face. Like it sort of got the sense of like something in front of the background probably. Even if I hold this up, it's sort of working. But remember now, I don't have to be so literal. I mean this could map to sound. I could use different images. Images of cats, for one thing. I don't even know. But the idea here is now, instead of the image producing a label, the image produces a number. And that's a regression. And remember, this wasn't not happening from scratch, this is happening because I'm basically saying this whole process that's already been learned, just take out that last part where it turns it into the fixed set of 1,000 MobileNet layer labels. And turn that into, turn that into something else. My own labels or my own number. You know, there's something else that I want to mention that's really important, because it came up in the chat. Now, where is all this happening? You might ask, am I like broadcasting images of myself somewhere out into the cloud for all this? What's kind of interesting and amazing about this, is everything is happening here locally inside the browser of this computer itself. It's all gone. It lives nowhere else. The ml5library, the ml5library and the p5library are being accessed from the cloud. They're being downloaded when the pager. I could have local copies of them. The MobileNet model, the thing that I'm starting with, the MobileNet model is also being downloaded from the cloud. And the ml5library is taking care of that for you. But once all of that is done, it's all happening here in the browser. And this, by the way, in theory would work on your phone as well. It's called MobileNet. That model is a small, not accurate, not super advanced, robust, but it's a small little model meant to work on a mobile device. So it's important to realize that everything is happening here locally on the device. OK? Thanks for watching, and I'll see you, and again, the same issue here, I probably want to save the train, save my retrained model. That's not possible right now easily with the ml5library, but that will come in the future, and hopefully I'll do a video on that. OK? Goodbye, and I hope you make something with this. I enjoyed it.
