With timestamps:

00:00 - I think I'm
00:01 - streaming he everybody welcome good
00:04 - morning I've been having technical
00:05 - difficulties for like the last 20
00:06 - minutes and I think this is actually
00:08 - working oh my God it's working they
00:10 - YouTube changed the way things work good
00:13 - morning welcome this thing is called the
00:15 - coding
00:16 - rainbow uh
00:18 - and I had a whole thing prepared to say
00:22 - that I don't have prepared to say
00:23 - anymore because I just spent 15 minutes
00:24 - trying to make all this stuff work I
00:26 - feel very stressed out but I'm here in
00:28 - New York City at place called ITP at New
00:31 - York University uh Tish School of the
00:33 - Arts and I'm here to talk
00:35 - about I have a prop the Microsoft
00:39 - Connect uh how do you program with this
00:41 - thing how do you do interactive stuff
00:42 - with this thing how do you use this
00:44 - thing with something called processing
00:46 - uh which is running behind me here uh
00:48 - oops I didn't even configure my window
00:50 - or anything so um I people in the chat
00:53 - tell me if you are there uh tell me if
00:56 - you can hear me tell me if you can read
00:58 - this font um
01:01 - tell me if uh you can see me over here I
01:06 - need to test to make sure this
01:07 - whiteboard is working I mean the the
01:09 - Whiteboard is working but if the focus
01:12 - is pretty decent uh I think that's
01:15 - pretty good I'm going to walk over here
01:16 - I've got Periscope live going hi
01:18 - Periscope um so I'm like d triple double
01:22 - streaming something hi I'm talking to
01:24 - Periscope so now I'm on I'm Live on
01:26 - YouTube Periscope so I'm going to put
01:29 - you down so so you could see the
01:31 - URL over
01:33 - here and you can go there
01:37 - uh this is like the most ridiculous
01:39 - thing I've ever
01:41 - done there you go okay so that's where
01:44 - you can go Periscope or you can at least
01:45 - hear the audio so
01:48 - um uh okay everybody can hear me it
01:50 - works like a charm that's great that's
01:53 - exciting to hear um okay so I've got to
01:56 - get
01:57 - started um and I have uh I think I'll be
02:00 - doing this for about an hour or so uh
02:02 - I'm glad to take questions uh the first
02:05 - thing I want to do so I'm kind of going
02:06 - to talk this through first to figure out
02:09 - the kinds of things I'm going to cover
02:11 - um I'll look for any questions or ideas
02:12 - in the chat um and then what I'm going
02:14 - to do as I always do but I'll explain it
02:16 - again is during various parts of this um
02:21 - live stream I'm going to hit a record
02:23 - button to like save a particular chunk
02:26 - as a standalone video Lesson which I
02:28 - will upload to Youtube later so my goal
02:30 - is to have like four or five 10minute
02:32 - video lessons about using the connect
02:34 - and this live stream will be kind of a
02:36 - mess of like trying all sorts of stuff
02:38 - out and in between making those
02:41 - videos um and sometimes I stop and start
02:44 - and redo the redo the same content if I
02:47 - feel like I went in the wrong direction
02:49 - and so you just turn it off if this is
02:51 - like driving you crazy um so I'm
02:54 - checking in the chat hello ah Cardiff
02:56 - again and hello France uh if one thing
02:59 - that's really important if if the audio
03:00 - stops working or if some weird thing
03:02 - happens you can't see me uh please type
03:04 - that in the chat I'm not doing anything
03:05 - with Twitter today so I don't need
03:06 - people to tweet while I'm doing well but
03:09 - you know welcome to um you know let
03:11 - people know this is happening uh it's a
03:13 - holiday tomorrow here in the United
03:14 - States called Thanksgiving NYU is
03:16 - actually closed today but it's a busy
03:18 - active time the end of the semester so
03:20 - um but the reason why I'm doing this
03:22 - actually is because um a lot of students
03:24 - are trying to do projects with the
03:25 - connect around here and I thought this
03:27 - would be
03:28 - helpful we'll see um okay I I'm gonna
03:31 - drink a little water and get set up so I
03:33 - think the first thing that I'm going to
03:34 - do I um first thing I'm going to do is
03:37 - just talk
03:38 - about the connect in general what the
03:42 - different versions of the connect are uh
03:44 - how it works and show you how to install
03:46 - a library in processing that uses the
03:48 - connect open the window for a minute to
03:50 - get some cool air in here lights some
03:52 - get a little bit hot uh so I'm going to
03:54 - just talk about the connect in general
03:55 - and like run some examples to show what
03:58 - it does and then then I am going
04:02 - to uh try to look at a few different
04:05 - scenarios for example
04:08 - um finding the closest thing maybe to
04:12 - the connect maybe finding uh the the top
04:16 - of a human being like where's the top of
04:18 - your head uh I want to look at like
04:21 - taking the depth map and maybe just like
04:24 - dividing it into sections like a grid um
04:28 - somebody had a idea for a project ITP
04:30 - which is to have like the connect
04:32 - pointed at a a sand box and you could
04:34 - manipulate the sand and the height of
04:35 - the sand would play different musical
04:37 - notes so maybe some kind I don't have a
04:38 - Sandbox or and I have the connect in
04:40 - sort of a weird place so I don't know
04:41 - how this is all going to go but I want
04:43 - to try to build a few examples from
04:44 - scratch basically while we're here um
04:48 - okay um great I'm seeing some nice
04:51 - people say hello yes if you're listening
04:54 - to the Periscope audio and the YouTube
04:56 - audio you're in trouble because they're
04:58 - they're definitely going to be out of
04:59 - sync um and that's that so um let me get
05:03 - myself a little bit oriented here uh
05:08 - and I'm going to so here by the way so
05:11 - let me see so let me get this particular
05:14 - example up and running I'm going to hit
05:17 - stop
05:19 - um I need a little bit more room here
05:24 - I'm going to do
05:28 - this interesting I think I actually need
05:30 - this statement in there and I'm going to
05:32 - do
05:34 - this and okay so this is the first thing
05:36 - that I'll just talk about which is that
05:38 - you can get the uh the regular image
05:40 - from the connect the depth image which
05:42 - you can see the darker the color is the
05:45 - closer it is this is um using the
05:47 - connect version two there's the the what
05:49 - the camera is actually seeing the
05:50 - infrared that the cam the camera the
05:52 - sensor the connect whatever you want to
05:53 - call it is seeing and the um this thing
05:57 - called a registered image which aligns
05:59 - the col colors with the
06:01 - depth uh
06:04 - okay uh I think it runs on
06:06 - Linux um I don't know that's a good
06:08 - question I mean I'm so a lot of this
06:11 - work I have to credit Thomas Sanchez
06:14 - lling does anybody know how to pronounce
06:16 - his name let me pull let me pull up uh
06:20 - let me pull up the person I would like
06:21 - to credit for a lot of this work to who
06:23 - helped bring have the library work with
06:25 - the connect version too Thomas
06:28 - Sanchez lling uh here he is a cod codigo
06:33 - generao is his website which I'm
06:36 - probably butchering the um butchering
06:40 - the name so w Works in portfolio of
06:42 - Thomas Sanchez L leling leling if
06:46 - anybody knows how to pronounce that so
06:48 - write it phonetically in the chat
06:50 - otherwise I'll probably mispronounce his
06:51 - name but I do want to thank him uh when
06:53 - I when I start making some of these
06:55 - videos I guess this is a video I'm
06:56 - making right now I'm already thanking
06:57 - him um but he's done a lot of work with
07:00 - the connect and in this part this
07:02 - particular Library so what I should
07:04 - probably bring up here is open connect
07:08 - for processing the uh GitHub
07:13 - page to look at this uh as well
07:19 - as uh sorry let me I'm just getting set
07:23 - here to make this first
07:25 - video uh and um
07:30 - the uh open connect for processing and
07:33 - then this is my page which could use
07:34 - some work but it has
07:37 - some documentation and stuff about it as
07:41 - well okay
07:43 - um yes you can install the connect
07:45 - Library directly from processing and you
07:47 - don't need to install anything else
07:49 - unless you're on Windows maybe you do
07:50 - but you follow the
07:52 - instructions okay uh so I'm getting
07:55 - ready I'm going to make this first uh
07:57 - video I'm going to just drink a little
07:58 - bit of water over here
08:02 - wow I've got 31 people watching that's
08:04 - fantastic
08:08 - um I'm actually just going to send a
08:10 - quick email um to ITP students
08:15 - um
08:18 - because uh hold on a sec because a lot
08:21 - of them were interested in maybe joining
08:23 - so live stream on connect happening now
08:28 - uh okay I'm just sending that out
08:30 - uh okay so I think I'm good to go wow I
08:33 - I just took oh it's eight minutes to get
08:36 - started here but uh I'm going
08:39 - to uh open this up and so in the first
08:44 - video which I'm about to hit record and
08:46 - do the things I'm going to cover are how
08:47 - to install the
08:49 - library
08:51 - um uh what the different kind what the
08:54 - different um versions of the connect are
08:56 - the hardware the different editions and
08:59 - which ones work which ones don't work
09:01 - maybe they all work uh and then the
09:04 - basic functionality of the connect in
09:06 - terms of the pieces of the things the
09:08 - RGB image the infrared image the depth
09:10 - image the raw depth data and um excuse
09:15 - me the uh registered image which is only
09:17 - part of the connect version 2 so that's
09:19 - what I'm going to cover in the first
09:20 - video section and then in the second one
09:22 - I'll probably do some type of
09:24 - visualization of the depth data
09:25 - something like that okay um so it's your
09:27 - last chance to ask a question in the
09:32 - chat oh a lot of you might be interested
09:34 - I just um uh was
09:37 - reminded um that there is something
09:39 - called the key motion or the kimotion or
09:40 - the K motion k i m o t i o n which is a
09:45 - library framework uh for using the
09:47 - connect with um p5js which is another
09:50 - programming environment that I make a
09:51 - lot of video lessons about so don't know
09:52 - if I'm going to get to that today
09:54 - honestly because I haven't had the
09:55 - chance to like really like get it set up
09:56 - and running myself but I definitely you
09:58 - know I imagine this to be a new playlist
10:00 - about the connect I'm going to do raw
10:03 - depth I'm going to do skeleton tracking
10:04 - with the Microsoft SDK I'm going to do
10:07 - using probably this key motion thing for
10:08 - p5js because lots of other people are
10:10 - making stuff and I hope to be able to
10:12 - mention those things and and help people
10:14 - get started with those things as well
10:17 - okay uh here we
10:20 - go in
10:24 - three two one something like that I need
10:27 - like I I need somebody to like be behind
10:29 - the camera going in three
10:33 - two except nobody's there I'm just doing
10:36 - that for
10:37 - myself uh my nose is running but it'll
10:39 - be fine Okay click the mouse mouse goes
10:44 - live
10:49 - and
10:50 - hello okay wait wait wait wait I I like
10:53 - lost track of what I was
10:57 - doing hello this is the first video in a
11:00 - series of videos about using the
11:02 - Microsoft Connect in your own software
11:05 - and the software I'm going to use is
11:07 - this thing called processing uh
11:09 - eventually I will also get to looking at
11:11 - how you might use the Microsoft Connect
11:13 - with p5js in the browser but the first
11:16 - uh this I got to start over too
11:18 - longwinded too
11:19 - long-winded I've been looking too much
11:21 - at my like YouTube analytics and see how
11:24 - like people are watching they whole drop
11:26 - off when I start to ramble at the
11:27 - beginning of a video but I really should
11:29 - care about that I'm way into into my own
11:31 - inside my own head too much I'm just
11:33 - going to make this
11:35 - video hello this is the first video in a
11:38 - series of videos I'm making about the
11:39 - Microsoft Connect this thing so what is
11:43 - this thing how does it work and how do
11:45 - you write your own software that makes
11:46 - use of this thing how can you do all
11:48 - sorts of creative coding projects now
11:50 - there's a lot of different programming
11:52 - languages and environments and
11:53 - Frameworks and libraries for how you
11:54 - might make use the connect um I'm going
11:57 - to use this thing called processing
11:59 - processing 3 the Third Edition version
12:01 - of processing uh which is a Java based
12:04 - programming environment open source uh
12:06 - environment um that there is a connect
12:08 - several different connect libraries for
12:10 - uh eventually I will hope to make a
12:12 - video where I look at p5js which is a
12:14 - JavaScript framework uh for doing
12:16 - creative coding in the browser and how
12:18 - might you get the the stuff from the
12:21 - connect what is this thing called The
12:23 - Connect in the browser itself which I
12:25 - think will be an exciting thing to see
12:27 - as well um but in this first video what
12:29 - I want to do I'm going to get into the
12:31 - code really in the next video and what I
12:32 - want to do in this video is give you an
12:34 - overview so what are the different uh
12:37 - editions of the connect there's a bunch
12:39 - of different ones that you could buy
12:40 - what are the pieces that you need how do
12:42 - you get the library to make use of the
12:44 - connect that sort of stuff and you can
12:45 - see I have a basic example that's
12:47 - running behind me with the connect
12:49 - version two and I will talk through the
12:51 - pieces of this code so first let's think
12:54 - about the different versions of the
12:55 - connect so this is this one here I need
12:58 - reading glass I'm going to this one is
13:00 - the 14 model
13:03 - 1414 this one is the and I'm going to
13:05 - I'm going to come over here and try not
13:07 - to trip over to myself um and I got to
13:10 - grab this uh eraser for a second um so
13:15 - let's make a list here so the the two
13:17 - key pieces of information for you are
13:20 - you need to decide are you using the
13:22 - connect version one or the connect
13:26 - version
13:28 - two I'm probably going to get lots of
13:30 - stuff wrong here that you can write in
13:32 - the comments and I'll put little
13:33 - annotations on the YouTube video that
13:34 - fix them but hopefully I'll get things
13:36 - Loosely right so the original connect
13:39 - version one model 1414 is the one that
13:41 - came out I think it was November
13:44 - 2011 12 somewhere around there I
13:46 - remember the weekend it came out people
13:48 - people were quote unquote hacking it but
13:50 - really just making but by hacking it I
13:51 - mean making open source drivers to to
13:53 - read the data driver being a thing that
13:56 - your computer runs to talk to the
13:58 - hardware device
13:59 - um and so when that came out uh a
14:02 - library I worked on a library called
14:05 - open
14:06 - connect for processing and the reason
14:10 - why it's called Uh open connect is
14:12 - because it's making use of the open
14:15 - connect an open connect an open source
14:18 - uh driver for for uh connecting to the
14:21 - connect which is also known as a lib
14:25 - Free Net so this is sort of the Genesis
14:29 - of all of this um the thing that I built
14:31 - for processing is just a thin layer on
14:33 - top of work that lots and lots of other
14:35 - people did which allows you to get the
14:38 - data from the connect now let's come
14:40 - back to the connect like what is this
14:41 - over here and then I'll get i'll get to
14:43 - the other additions in a second like
14:45 - what is this thing so this is the
14:47 - original connect and you can see here
14:49 - that there are three little circles on
14:51 - here it's like a little nice little
14:53 - friend with three eyeballs and what do
14:55 - each of these eyeballs do so one of them
14:59 - them if we oh camera oh oh shift menu I
15:02 - suck at making these
15:04 - videos okay I'm just I'm going to go
15:06 - anyway okay so this is the connect uh uh
15:09 - um and it has three little eyeballs one
15:12 - of which is an infrared
15:17 - projector so this is this is what the
15:19 - 144 does and I'll talk a little bit
15:21 - about any a different marker here what
15:24 - happens once you get to the connect
15:25 - version two how that works differently
15:27 - um it has an infrared projector which
15:30 - sends out infrared light into the room
15:33 - then it has what I would call you know
15:36 - you could call it a sensor a camera but
15:37 - it has an infrared camera to read the
15:41 - infrared light that's in the in the room
15:43 - what is infrared light it's you know
15:44 - light that's all around us but is
15:46 - invisible somebody with a Physics degree
15:48 - could explain that better but this is
15:50 - blasting out infrared light this
15:52 - infrared camera is reading it so what
15:54 - what is the value of doing this so the
15:56 - interesting thing is the kind of light
15:58 - that it's passing out is actually a
16:00 - whole lot of infrared dots it's
16:02 - projecting a lot of infrared dots into
16:04 - the room that look like this and it's a
16:06 - very specific pattern of dots and the
16:10 - connect itself it knows what that
16:12 - pattern of dots is supposed to look like
16:14 - so if that pattern of dots if I have the
16:16 - connect here it's blasting the infrared
16:18 - light lands on a flat surface the
16:20 - infrared camera that's reading where
16:22 - those dots landed that's seeing those
16:24 - dots reflecting back is going to see
16:26 - like oh it matches exactly the pattern
16:28 - of dots that I know that's a flat
16:30 - surface but if this surface was curved
16:33 - those dots will appear distorted by
16:35 - analyzing that Distortion the connect
16:37 - can recognize what things are closer and
16:40 - what things are further away so the
16:43 - value of this is it uh is often referred
16:45 - to you can think of it as a depth camera
16:47 - or a depth sensor this is what this
16:49 - infrared projector and infrared camera
16:51 - are doing they're measuring the depth in
16:54 - of of each pixel in the room so while a
16:57 - regular web camera says here's a 640x480
17:00 - image each pixel has a red green and
17:02 - blue value and it's beautiful isn't it
17:04 - the colors of the rainbow are there in
17:06 - this image um The Connect is saying I
17:10 - see I don't see RGB what I see is I see
17:14 - a pixel and instead of telling you what
17:15 - color that pixel is I'm going to tell
17:16 - you how far is that pixel away from the
17:19 - sensor and this is incredibly valuable
17:22 - in computer vision you know one of the
17:23 - classic computer vision problems that
17:25 - people try to solve is background
17:27 - removal you know that's why I have
17:29 - this oh green screen oh I have to go
17:31 - underneath this here okay I have an
17:33 - obstacle course in my office I'm going
17:35 - underneath this to turn this camera back
17:36 - on and I'm coming back underneath here I
17:39 - have this hello I have this um I have
17:42 - this green screen here behind me that
17:43 - you can see um and so the the uh camera
17:47 - is saying every Green pixel remove it
17:49 - and put the stuff from the computer
17:50 - behind it but if I had to connect I
17:52 - don't have to say look for the green
17:54 - pixels behind me I could just say look
17:55 - for any pixel that's farther than 2 ft
17:58 - or
17:59 - or some amount of centimeters I'm trying
18:02 - to be a metric I'm trying to be metric I
18:04 - want to be a metric person but I'm not
18:07 - um so uh you could remove you could you
18:09 - could analyze things it makes it really
18:11 - easy to find a human being in the room
18:13 - because a human being has a certain kind
18:14 - of shape it makes it really easy to do
18:16 - quick and dirty 3D scanning there's lots
18:19 - and lots of possibilities of what you
18:21 - can do once you have access to the depth
18:22 - now there was this third little eye here
18:25 - and this by the way is just an RGB
18:28 - camera so one of the things the connect
18:30 - can also do is just see the colors in
18:33 - the room so in addition to having this
18:35 - infrared camera it has an RGB camera now
18:38 - there's a bit of a problem here which is
18:40 - that notice how both of these things are
18:44 - not in the same place so the infrared
18:48 - camera sees the depth of a given pixel
18:50 - at a different place that the RGB camera
18:53 - sees that color so this is an alignment
18:55 - problem a calibration problem where the
18:58 - the color pixels don't necessarily line
19:00 - up exactly with the depth pixels and
19:02 - there are lots of strategies for solving
19:04 - this problem uh and lots of Frameworks
19:07 - and libraries in particular the official
19:09 - Microsoft SDK which has um things baked
19:13 - into it that do this for you but one of
19:14 - the nice things that we'll see once we
19:16 - get to the connect V version two is it
19:19 - has something called a registered image
19:21 - which is an image that aligns the depth
19:25 - pixels with the color pixels okay so
19:27 - this is what the connect does
19:29 - and I really described here what the
19:31 - connect version one does there was also
19:34 - a model 1473 that came out I don't know
19:37 - a year or two later um this one has some
19:40 - problems in particular there's a little
19:41 - bit of a bug uh with currently with
19:43 - running it with the processing Library
19:45 - although it does work kind of only will
19:46 - work every other time can't figure it
19:48 - out for the life of me um so but both of
19:51 - these will work with the library what
19:53 - you need to look for in the library is
19:55 - the version one examples so that's
19:59 - now in between here there was like this
20:01 - connect for
20:02 - Windows and I think this was like a
20:04 - version of The Connect that the
20:05 - Microsoft made to plug into like Windows
20:08 - computers originally this was designed
20:09 - for use with the Xbox for a game for
20:12 - games that you would play by you know
20:14 - dancing I'm kicking my leg by the way if
20:16 - you can't see that um and uh um but you
20:20 - know then Microsoft realized there's I
20:22 - don't know what mic what's in Microsoft
20:24 - has but I'm speculating here but that to
20:26 - make a version that's designed to work
20:28 - with just regular old laptops and
20:30 - computers um I'm not sure if this one
20:32 - works with the processing library but
20:34 - more recently and I I I have this one
20:37 - plugged in and like mounted on the wall
20:38 - over there so I can't hold it up and
20:39 - show it to you the connect version two
20:42 - is a newer and quite significant upgrade
20:45 - from the first connect um and it
20:48 - actually uses a completely different
20:50 - technique it's uses infrared light but
20:52 - it uses a technique called time of
20:53 - flight so it sends the infrared light
20:55 - out measures how long it takes for it to
20:57 - bounce back and that how long that takes
21:00 - uh lets the sensor know how far away
21:02 - things are kind of like a bat maybe does
21:04 - stuff with sound to see I don't know you
21:06 - dolphins do stuff like that but all with
21:08 - sound so with light bouncing it back and
21:10 - forth um the new connect does that and I
21:13 - suppose it's a bit more accurate it's
21:15 - faster uh and uh the RGB camera is also
21:19 - in the new connect is higher resolution
21:21 - okay so that's the basics overview and
21:24 - if I come back over here you can see now
21:27 - now I'm running an example have the
21:29 - connect right over here you can't see it
21:31 - I could I could maybe like turn like
21:33 - kind of like if I hold it up over here
21:35 - can there you go there it is this is the
21:37 - new one I'm G to put it back that felt
21:40 - like a little scary like everything was
21:41 - going to fall over um and you can see
21:43 - now that uh what you're seeing in this
21:46 - particular image is an example of a
21:48 - processing sketch which is rendering all
21:51 - of the pieces of what the library what
21:53 - the connect offers now oh I but I have
21:56 - something more to mention about this but
21:57 - I'll get to that in a second so up top
22:00 - you can see that's just the RGB image so
22:02 - it's like I have a webcam over here I
22:04 - have a webcam over here hi webcam hey
22:07 - that sort of thing right so that's the
22:08 - webcam uh that's that's the RGB camera
22:11 - and it's actually I believe I didn't
22:13 - actually check but it's a it's pretty
22:14 - high resolution image um down below this
22:17 - is the Raw Feed of what the infrared
22:19 - camera is seeing so this is what the
22:21 - infrared camera is seeing and it uses
22:23 - that to extrapolate depth so mostly it
22:25 - just looks like this creepy thing but
22:27 - you can make use of that you can get
22:28 - that image as well um up top up the top
22:32 - right this is what's known as the depth
22:34 - image so the what the connect is
22:36 - measuring is in millimeters it's
22:38 - measuring uh a value between 0 and 4500
22:41 - how far is the thing away from the
22:43 - camera and then often a depth image is
22:46 - used to visualize that data so in this
22:48 - case you can see as I start to go
22:50 - further and further back I get brighter
22:52 - as I start to come closer and closer I
22:54 - get darker so it's mapping the uh theor
22:58 - color of every pixel to how far away it
23:00 - is and you can see just from a
23:02 - standpoint now how much easier that
23:03 - might be to pick out my hand right
23:05 - because my hand is the only thing that
23:07 - has this very very dark color uh as
23:09 - opposed to other things now there is
23:11 - something funny in the back what's up
23:14 - there above oh that's a window I like
23:17 - what's that Black square up there that's
23:18 - a window that's the door you can seeing
23:20 - all sorts of things inside inside this
23:22 - room that you may not have seen before
23:24 - and then down in the bottom right this
23:26 - is the registered image so this is not
23:29 - part of if you use the version one
23:32 - connect with the open connect Library
23:34 - this is not part of that however uh with
23:38 - version two this is the image that
23:40 - aligns all of the RGB values from the
23:43 - webcam with the depth values so if you
23:45 - wanted to hopefully something I might be
23:46 - able to demonstrate at some video is
23:48 - just do background removal where you see
23:50 - only me and I take I get rid of all the
23:52 - pixels that are behind me um that might
23:54 - be something that I could do here with
23:56 - with that particular image oh did the oh
23:58 - the laptop went to sleep come back or
23:59 - wake up okay so uh couple more
24:03 - things so what I want to show you now is
24:05 - how do you get this library to run this
24:07 - like this particular example so a couple
24:10 - things one is here's the I'll put all
24:12 - this in the in the description of the
24:13 - video this is the URL the the uh library
24:16 - is at github.com shiftman open connect
24:19 - for processing you don't need to go to
24:20 - that URL but that's where the source
24:21 - code is there's a little bit of
24:23 - documentation there I want to make give
24:25 - a big thank you to Thomas sanche as
24:28 - lenling I I might not have pronounced
24:30 - his last name correctly he wrote all the
24:32 - code for making this Library work with
24:33 - the connect version two so I worked on
24:35 - the version one a number of years ago
24:37 - and sort of floundered and Thomas came
24:40 - back and revived this and really helped
24:41 - uh over the summer um and there is also
24:44 - I have a little a page that has some
24:46 - additional documentation it's shiffman
24:48 - Donnet p5c connect and you know this is
24:52 - some text that kind of goes through uh
24:54 - the different versions uh and some of
24:56 - these examples as well that I'm going to
24:58 - cover in the videos now in order to get
25:00 - the actual Library itself what you need
25:03 - to do is go to uh one you know first you
25:05 - need to download processing if you don't
25:07 - have that already that's at
25:07 - processing.org then what you'll need to
25:10 - do is once you have processing uh it
25:12 - might look just like this to you
25:14 - something empty you're going to go to
25:16 - sketch import Library add library now
25:20 - you can see that I have already you know
25:21 - I have three libraries here I already
25:23 - have that library but I'm going to
25:24 - pretend that I don't for a second I'm
25:26 - going to go to add Library which opens
25:28 - up up this contributions manager I can
25:30 - type in Connect right here and this is
25:32 - something really quite important now to
25:34 - bring up so there are several different
25:37 - libraries there is by the way something
25:39 - called Simple openni which is an older
25:42 - library openni was an open source
25:44 - platform open source framework for doing
25:47 - skeleton tracking meaning finding the
25:49 - human form where the hands are where the
25:51 - head is which is very very powerful and
25:53 - things that you can do with the connect
25:54 - I'm starting with just the raw depth
25:56 - data um but open and I think was
25:58 - purchased by Apple and then kind of like
26:00 - shut down as an open thing but there are
26:02 - some efforts to revive it and so uh you
26:04 - could Google around and that's something
26:06 - that you could possibly use I'll try to
26:07 - include some links but you can see that
26:08 - it's currently this simple open eye it's
26:10 - no longer compatible with processing
26:12 - three that's why it's gray out connect
26:14 - V2 for processing this is a library that
26:17 - makes use of the Microsoft official SDK
26:20 - and I'm going to demonstrate that using
26:21 - a PC in a later video um this is a key
26:26 - uh this is a really a great thing to use
26:29 - if you want to get all of the magic that
26:31 - Microsoft has spent all this time
26:33 - developing so what the connect just
26:35 - gives you is raw depth data raw RGB data
26:38 - but what the Microsoft SDK does is it
26:41 - pulls that data in and on and it
26:43 - analyzes it and finds where's the human
26:45 - being like what kind of muscle are they
26:47 - making like where is their head like is
26:49 - their hand open or closed and it's so
26:51 - much a sort of a layer of analysis on
26:54 - the raw def data that will give you a
26:55 - ton of information so but for that you
26:58 - do need to use a Windows machine of
26:59 - course there are some strategies for
27:00 - like sending the data from a Windows
27:01 - machine to another machine through like
27:03 - a websocket what's a websocket all sorts
27:05 - of stuff but we'll come to that in a
27:07 - later video um and uh so those would be
27:11 - the two libraries that but the library
27:13 - I'm using today which you know is
27:15 - already installed you can see by the
27:16 - green check mark you would just need to
27:17 - click it and uh click this install
27:20 - button and it would download and install
27:22 - um that this is the library I'm using
27:24 - today it uses open-source drivers it
27:27 - only looks at the raw depth data so this
27:30 - is good for a bunch of different kind of
27:31 - creative applications that I hope to
27:33 - show you in the next set of videos so
27:36 - this was a long rambling 16-minute
27:38 - explanation about the connect that you
27:40 - may or may not have found useful or
27:42 - interesting but I imagine you already
27:44 - turned it off if you didn't and in the
27:46 - next video what I will demonstrate is is
27:48 - just how to write a program that gets
27:50 - that depth image and once it uh I bring
27:53 - that back oh it's not running here get
27:55 - gets that depth image and maybe
27:57 - visualizes that depth image in some way
27:59 - so that's where we'll start and then
28:00 - I'll look at a couple other scenarios
28:01 - along the way as well okay and so thanks
28:04 - for being here and watching and talk to
28:05 - you
28:09 - soon okay everybody
28:13 - uh uh all right did that could people
28:15 - hear me through all that and that worked
28:17 - and everything I don't know what's going
28:19 - I feel like a little lost here um all
28:22 - right I'm looking to see if there are
28:23 - any
28:24 - questions uh um
28:29 - some people are asking things from
28:32 - various place I would like to sing a
28:34 - coding Rainbow theme okay uh uh the
28:38 - white line on his shirt there's a
28:39 - there's a is there something transparent
28:41 - on my shirt oh there's a green it's not
28:44 - white this is a I wore this because this
28:46 - is a shirt that I have that has a
28:47 - rainbow on it and this this line right
28:49 - here is green so it's transparent
28:52 - because the it's picking up the green
28:53 - screen behind me okay um glad that was
28:56 - helpful okay so now what I'm going to
29:00 - do I think maybe what I'm going to do
29:02 - right now you guys is I'm going to try
29:04 - building a little
29:06 - example uh and like the practice and
29:08 - then I'm going to do the video where I
29:10 - build the example again so I'm going to
29:12 - do it now with a little less like
29:15 - personality whatever that means um and
29:17 - you can it's uh ask any questions if you
29:22 - want um so I think the first thing to do
29:25 - would be to actually just look at the
29:28 - depth image and then like take each
29:31 - pixel and map its Z location according
29:34 - to its depth so let me go and grab um ex
29:39 - uh open recent uh this one and I'm going
29:42 - to say
29:46 - um
29:48 - depth dep depth image
29:51 - viz so I'm going to make a sketch that's
29:54 - 640 by
29:56 - 480 uh I'm I'm going to just do
30:00 - this uh so I'm just looking at the depth
30:04 - and I'm going to say p image so I'm I'm
30:07 - I'm going to explain all this when I
30:09 - make the video but I'm just sort of
30:10 - trying out to make see if this this
30:12 - example makes any
30:14 - sense
30:16 - uh and then I'm going to say 4 int xals
30:21 - z x is less than image. width uh
30:25 - x++ for in y = z y is less than image.
30:30 - height y ++ I have a syntax error here
30:34 - uh and then can you guys read this font
30:36 - size okay should I make it
30:38 - bigger uh and
30:40 - then going to take out all this
30:44 - stuff uh and then I'm going to um say
30:50 - int off uh index = x + y * image. width
30:57 - and
30:58 - um color or like uh depth equals uh the
31:06 - brightness of image. pixels at
31:10 - index maybe I'm going to turn off the
31:12 - code
31:13 - completion oh no I want
31:17 - that oh I don't know I'll leave it it's
31:19 - fine uh and um then I'm going to
31:25 - uh I'm going to have a variable called
31:28 - like w is
31:30 - 10 uh oh maybe I call this
31:33 - Skip and that's kind of useful
31:36 - skip uh plus equals Skip and then I'm
31:40 - going to draw I'm just going to draw a
31:42 - rectangle at X comma y uh Skip
31:47 - Skip
31:49 - and I'm going to say fill
31:52 - D and uh I just want to see if this
31:57 - works
32:00 - whoa I'm missing a
32:01 - semicolon uh so I just want I'm just
32:03 - trying to like make it a grid here
32:07 - um what did I miss ah image. load pixels
32:11 - image. load
32:14 - pixels oops I have a capital I
32:17 - there
32:20 - uh oh I totally someone's asking a
32:23 - really good question I totally should
32:26 - have mentioned that in the video you do
32:27 - not need to install any extra drivers or
32:30 - anything it just works um the idea is
32:32 - the library just works um right out of
32:35 - the box yeah so most of the time when
32:37 - you're working with the connect you got
32:37 - to install all this other stuff maybe
32:40 - I'll like I don't know I'll have to put
32:42 - that in an annotation in the video
32:43 - because that was like kind of a big
32:44 - thing that I missed there I should just
32:47 - remake that one but it was too long okay
32:49 - what did I miss here array index bounds
32:51 - array oh X Plus y times width
32:55 - okay okay so you can see great so this
32:58 - is the first thing that I wanted to do
32:59 - which was just and why oh you know what
33:03 - it isn't 640 by 480 what is
33:06 - it
33:08 - uh I forget what's the connect version
33:10 - two with I guess uh it's actually a
33:13 - little bit lower resolution it's uh
33:17 - um
33:21 - uh I forget what it
33:24 - is somebody might know image. width
33:27 - image.
33:31 - height
33:33 - uh come on
33:36 - Console how come I'm not seeing anything
33:38 - in the console don't I have a print line
33:41 - there oh yeah 512 by 424 I forgot about
33:46 - that 512
33:51 - 424 so this is working you can see I'm
33:55 - getting so I just wanted to do something
33:57 - first really quick where I kind of make
33:58 - this grid like lower resolution grid
34:00 - because then what I can do is translate
34:03 - each one of those into 3D based on the
34:06 - brightness and I I'm pretty confident
34:08 - that I can do that in the video so um I
34:13 - think what I'm going to do dare I just
34:15 - delete all this code because I'm going
34:17 - to write it again from scratch in the
34:21 - particular video all right that's what
34:23 - I'm going to
34:24 - do delete okay so I'm going to just make
34:27 - a simp simple video where I look at
34:29 - looping through all the depth pixels and
34:32 - doing something with them uh any
34:34 - questions 512 by 400 thank you thank you
34:37 - for um for pointing out the errors uh
34:40 - wow I've got good I've got a great
34:41 - number of live people today that's
34:43 - wonderful okay
34:46 - so um and then I'll do one where I look
34:51 - at the raw depth data I think so I want
34:55 - to look at the difference between the
34:56 - color data and the Raw depth
34:59 - data um but I think I'll just I'm going
35:02 - to try to do these small little
35:04 - chunks okay here we go um I'm ready let
35:08 - me let me cycle these
35:19 - cameras and um I'm going to
35:25 - erase this diagram I'm over here right
35:27 - now by the way people um erase this cuz
35:31 - I probably need to do a quick pixel
35:34 - diagram uh for this video especially if
35:37 - people haven't worked with pixel
35:38 - processing
35:39 - before and um and now I'm
35:47 - ready okay uh here we go uh got my weird
35:50 - see-through t-shirt I can see the G like
35:53 - like that's like hole in my body it's
35:56 - disturbing okay
35:58 - um the okay so the same exact Library
36:01 - will work with the connect version one
36:03 - as well and the techniques would be the
36:05 - same I just happen to be demonstrating
36:07 - it with the connect version two thinking
36:09 - that that would be a little bit more
36:10 - current okay so
36:14 - um U stop here I I wish there was um
36:17 - okay that's fine
36:20 - and
36:26 - uh okay
36:28 - so I think I can make this a little bit
36:30 - smaller I can minimize the browser here
36:33 - sorry I'm just getting my window all set
36:35 - up uh this one I can close and I'm going
36:38 - to close this and then go open ah come
36:42 - on uh this one
36:47 - great
36:49 - and U make the console a little bit
36:51 - bigger there we go I think we're good
36:53 - what about the font size I feel like it
36:54 - needs to be a little bit bigger it's
36:56 - looking a little smaller to me that's a
36:59 - little bit better right okay um here we
37:09 - go ah the sun is coming sunlight is here
37:12 - today
37:17 - excellent hello in this video I'm going
37:20 - to look at how you can get the depth
37:22 - image from the connect in processing and
37:25 - what you might do with that so this is a
37:27 - very very very first step I have a
37:29 - completely blank sort of like set of
37:31 - code here I just filled a little bit in
37:33 - there in advance but I'm going to write
37:34 - this program from scratch in this video
37:37 - so uh if you didn't watch the
37:42 - prev hello in this video I'm going to
37:45 - look at how you get access to the depth
37:48 - image from the Microsoft Connect in
37:50 - processing and how you write some code
37:52 - to do some stuff with those pixels with
37:54 - that depth image so if you missed the
37:56 - previous video that's where I talked
37:57 - about the connect in general about um
38:01 - how you install the processing Library
38:03 - one thing I did miss which I think is
38:04 - important to mention is that you do not
38:06 - need to install anything else if you're
38:08 - on Mac OS X um so uh the library just uh
38:13 - works it comes with all the libf free
38:15 - neck stuff sort of packaged inside of it
38:17 - uh I believe on Windows there might be
38:19 - one other thing you have to install uh
38:21 - well I should really look this up right
38:22 - now ah crap I'm going to make this I
38:25 - don't want to get this wrong in the
38:26 - video Let's look this up
38:28 - uh here uh connect
38:31 - V2 uh for Windows 8 you have to install
38:35 - some uh this driver um which I'll
38:37 - mention for the V2 okay going do this
38:40 - one more
38:43 - time uh okay here we
38:48 - go hello in this video I'm going to look
38:51 - at how you can uh work with the depth
38:54 - image from the Microsoft Connect in
38:56 - processing I'm going to I need my prop I
38:58 - need my prop I swear this is the last
39:00 - time I'm doing this I just feel like
39:02 - having the prop will be
39:08 - good it's stuck underneath the table
39:12 - help it's funny how I've left my phone
39:15 - on Periscope is still like streaming an
39:17 - index card I don't know if there's
39:19 - anybody there okay uh okay I swear this
39:23 - is the last time I'm making this video
39:25 - now come come some
39:28 - hello I have a prop in this video I'm
39:31 - going to look at how do you use this I'm
39:33 - going to actually look at the code for
39:34 - using this Microsoft Connect in
39:36 - processing using the open connect for
39:38 - processing library now uh one thing I
39:40 - want to mention it that I did not
39:41 - mention in the previous videoos that is
39:43 - if you install the open connect for
39:44 - processing Library you need nothing else
39:46 - whatsoever it just works with the
39:48 - connect there is one exception on
39:50 - Windows 8 with the connect version two
39:52 - you do need to install an extra dri
39:54 - libus I will put that in the description
39:57 - below
39:58 - um but so this is the connect version
40:00 - one model 1414 it would work with this
40:03 - example but I'm going to show you
40:04 - instead I have the connect version two
40:06 - over here and you can see the only code
40:08 - that I filled in so far is having a
40:10 - variable called connect 2 so if you're
40:13 - using the connect version one the only
40:14 - thing you would change this code would
40:16 - work mostly identically um is just say
40:19 - connect uh instead of connect two so
40:21 - it's not connect one and connect two
40:22 - it's just connect and connect two I'm
40:24 - pretty sure about that if I get that
40:26 - wrong somebody will correct me
40:28 - um okay so uh let's look at how you get
40:31 - started so I filled in a little bit of
40:33 - code but the only things that you need
40:35 - really to get started are an import
40:36 - statement at the top that import
40:38 - statement is saying hey I'm here to use
40:39 - this Library uh you need to declare a
40:42 - variable that's variable is going to
40:44 - like hold all the information about this
40:46 - connect that you are using so it's the
40:48 - thing that you're going to create and I
40:49 - create it by saying new connect to this
40:52 - now there is a way to use multiple
40:54 - connects to use a version one and a
40:56 - version two to specify which connect you
40:57 - want to use that's beyond the scope of
41:00 - what I'm doing here in this video I'm
41:02 - only going to look at you just have one
41:04 - connect connected to one connect
41:05 - connected to your computer it's the
41:07 - default one all you need to do is say
41:09 - equals new connect to this so once
41:12 - you've got that going what is the next
41:14 - step well you need to decide what it is
41:16 - you want to do and in this example all I
41:18 - want to do is use the depth image so I'm
41:20 - going to say init depth so the connect
41:25 - uh the connect doesn't the library
41:26 - doesn't start all of the feeds
41:28 - automatically it's not going to start
41:30 - getting the infrared image the raw depth
41:32 - the depth image the video image it's
41:33 - only going to start using what you ask
41:35 - for so in this case I want to say init
41:37 - depth and then I also want to say uh
41:40 - init device which will kind of get
41:43 - things going and by the way this is
41:44 - where if I had multiple devices I could
41:46 - put an argument in there say init device
41:48 - zero one or two that type of thing so
41:51 - once I have that I'm ready to go and I
41:53 - can run this program and we will see
41:57 - nothing nothing on the screen so but a
41:59 - lot of stuff like spit out here which is
42:00 - kind of promising device firmware serial
42:03 - the library is going to like put a lot
42:04 - of stuff in the console which is um some
42:06 - basic information that you can see if
42:08 - it's working it will say like no nothing
42:10 - connected uh if you if you if you don't
42:12 - have it um connected I realized some
42:14 - other things I forgot in the first video
42:16 - but that's okay okay so uh what's the
42:19 - next thing that you want to do so let's
42:20 - just make sure things are working one of
42:22 - the things the connect gives you is that
42:25 - depth image because I said and it depth
42:27 - so in nit depth there are two ways I can
42:29 - look at the depth I can look at the raw
42:32 - depth values with the connect version
42:33 - two these are numbers between 0 and 4500
42:36 - with the connect version one these are
42:38 - numbers between 0 and 248 U these relate
42:41 - to millimeter measurements um but what I
42:43 - want is get depth image and you can see
42:48 - I what I'm you doing here is I'm asking
42:50 - the connect to give me this depth image
42:52 - and store it in a variable called image
42:54 - and now what I can do is just draw that
42:56 - image on the screen to make sure things
42:59 - are working so we can see here and there
43:02 - it is so there is the depth image you
43:04 - can see I've got it and now it's on the
43:05 - screen
43:07 - so this is the goal of the library it's
43:09 - pretty easy to work with in terms of
43:11 - just getting the data so let's think
43:14 - about what you might want to do so I
43:16 - think most almost all of the uh almost
43:22 - everything that you would do where
43:23 - you're working with the raw depth data
43:25 - or with the depth image involves
43:27 - iterating over all the pixels you want
43:29 - to look at all the pixels and see which
43:31 - ones are the ones that are closest you
43:32 - want to look at all the pixels and see
43:34 - what's the highest point of the closest
43:36 - thing or you want to look at all the
43:37 - pixels and say what's the sort of
43:38 - topology of the entire thing so all of
43:41 - those statements I said involved look at
43:43 - all the pixels so before I get to doing
43:45 - anything here let's talk about what it
43:47 - means to look look at all look at all
43:50 - the pixels so this is something that
43:52 - I've covered in some other videos a
43:53 - whole set of videos about just image
43:55 - processing um from you know jpegs pngs
43:58 - webcams that sort of thing you could
44:00 - refer back to those I'll I'll make sure
44:02 - I link to those at this moment in the
44:04 - video um but just to remind you if you
44:07 - have an image whether it's a depth image
44:10 - or an RGB image that image is a grid of
44:15 - pixels and we typically as human beings
44:18 - look at this as a thing that's
44:19 - two-dimensional and it has a bunch of
44:22 - columns and it has a bunch of rows and
44:25 - usually we think of the columns as the X
44:27 - values and the rows as the Y values so
44:29 - you might think of this as like the
44:31 - columns numbered like there's five
44:33 - columns numbered 0 through four and
44:36 - there's uh four columns numbered 0
44:38 - through three and so if I were over here
44:41 - this is pixel 3 comma one so this is how
44:45 - uh I think of pixels and images and this
44:48 - is the this image over here this depth
44:51 - image is a big grid of pixels columns
44:53 - and rows the thing that you have to
44:55 - remember when working with stuff like
44:57 - this is that the computer is actually
45:00 - storing all of those depth values all of
45:03 - those brightness depth values in this
45:05 - singular onedimensional array 0 1 2 3 4
45:10 - 5 6 7 8 9
45:12 - Etc and those numbers correspond like
45:15 - this the counting goes across comes down
45:17 - here uh comes down here comes down
45:23 - here so you can see I've got 20 pixels
45:26 - because I've got a five 5 by 4 grid 5 *
45:28 - 4 is 20 the pixels are numbers 0 through
45:30 - 19 so what we need is a methodology for
45:34 - if we're thinking of the XY how do I
45:36 - convert that to the location that's in
45:38 - this onedimensional array the index into
45:40 - that onedimensional array and the
45:42 - formula for doing that is x + y * width
45:46 - and you can see how that works because
45:48 - if I look at this column index two over
45:50 - here 2 + 5 is 7 7 + 5 is 12 12 + 5 is 17
45:55 - so the width to finds those numbers as
45:58 - they go sort of down row by row by row
46:00 - so if I say 3 + 1 * 5 that's 3 + 5 which
46:05 - is 8 and you can see that's eight right
46:07 - here so this is the formula that you're
46:09 - going to have to get used to because
46:11 - what I'm going to add is Loops I'm going
46:14 - to say Loop through every column and
46:16 - loop through every row row to look at
46:18 - every spot in this depth array so if I
46:21 - come back over here we can now add that
46:23 - to our code so for example I can say
46:26 - right here
46:28 - for every X from zero to and I'm going
46:31 - to say image.
46:32 - width uh not I and I'm going to say four
46:37 - every
46:42 - Y and again if this this idea of a
46:45 - nested Loop is confusing to you I would
46:47 - refer back to some previous videos about
46:48 - image processing but what we can see
46:51 - what I would like you to see here is how
46:53 - this is the loop to say I want to look
46:55 - at every single depth pixel so it could
46:58 - be I want to search for the closest one
47:00 - or I want to search for the for the the
47:03 - furthest away one right or I want to
47:05 - just visualize every pixel in
47:07 - three-dimensional space so for every X
47:09 - from zero to the width for every y from
47:12 - zero to the height and now what I could
47:14 - do is say what is that index how to
47:17 - apply that formula now x + y * image.
47:23 - width and then the color is is the color
47:27 - that's in that pixel even though it's a
47:29 - depth value it's turned into a grayscale
47:31 - color is the image. pixels at that index
47:35 - so this is now a loop that you will see
47:37 - in just about all the examples I intend
47:39 - to make today where I'm looking at every
47:41 - single Pixel and finding its index into
47:44 - the depth the the into that depth image
47:47 - and pulling out the color that's there
47:49 - so what might I do with that I could
47:52 - make a point in three-dimensional space
47:54 - Let's do let's okay let's do something
47:56 - thing here let's turn what we're seeing
47:58 - on the screen let me run this let's turn
48:01 - this into a lower resolution grid so
48:04 - let's look what I'm going to change this
48:06 - program to do right now is just look at
48:07 - every 10 pixels or every 20 pixels and
48:10 - draw a rectangle with that particular uh
48:12 - color there so let's do that real quick
48:15 - and I'm going to say so what one thing
48:17 - I'm going to do is I'm going to change
48:18 - this to uh brightness I'm just going to
48:20 - look at
48:21 - the um I'm going to look at the
48:23 - brightness of that pixel which is just a
48:25 - single value between 0 and
48:27 - 255 and I want to draw a rectangle at XY
48:31 - now I'm going up by one pixel so what I
48:34 - want to do and you'll see this in some
48:35 - of my examples is I want to introduce a
48:37 - variable called Skip and I'll say skip
48:40 - equals 20 because that's how many pixels
48:42 - I'm going to skip instead of looking at
48:44 - every single Pixel right now I'm going
48:45 - to look at every 20 pixels um and EV
48:49 - then I'm going to draw a rectangle at
48:51 - every 20 pixels and I'm going to fill
48:53 - that rectangle with that particular
48:55 - color so if we run this we should see
48:57 - exactly what I had before but just it's
48:59 - much lower resolution so that you can
49:01 - see I'm still looking at all of the
49:04 - pixels finding its color uh uh from the
49:08 - from the pixel array and then drawing a
49:10 - rectangle of some size arbitary size 20
49:13 - at that spot so you can see as I move
49:15 - around in front of the connect you can
49:17 - see my hands here and you can start to
49:18 - see like ah this is the kind of thing
49:21 - that computer visionwise it might be
49:23 - easy to pick out my hands as the sort of
49:25 - singular blobs
50:26 - the rectangle but by through a
50:28 - translation because ultimately I want to
50:30 - translate along the three-dimensional
50:31 - axis so I use push Matrix and pop Matrix
50:34 - to save and restore um that
50:36 - transformation State these might be
50:38 - Concepts that are unfamiliar to you I
50:39 - will refer you to a different video
50:42 - about Transformations but you can see I
50:43 - have the same exact thing here so
50:45 - instead of drawing the rectangle at XY
50:47 - I've now translated to XY and drawn the
50:49 - rectangle at 0 why am I doing this
50:52 - because now I could add something I
50:54 - could add a z here so the first thing I
50:57 - might try is just say okay well what is
50:58 - this Z let's make this Z equal to
51:02 - brightness and you can see here what do
51:05 - we got we've got as I uh it's kind of
51:08 - hard to see but you can see some uh some
51:11 - rectangles are further in front than
51:14 - other ones that are further away so the
51:16 - brighter ones are closer and the darker
51:18 - ones are further back this isn't really
51:21 - this isn't really doing me any good
51:23 - because actually I think what might make
51:24 - more sense is to have the Clos closer
51:26 - ones be more forward and the further
51:29 - ones way be more behind so I want to
51:32 - essentially position all these
51:33 - rectangles about where they actually are
51:35 - in physical space and so to do that I
51:38 - might do the map use the map function
51:39 - right because we know the brightness has
51:41 - a range between 0 and 255 but what I
51:44 - want is to now have a z value this zv
51:48 - value that's coming out of the screen I
51:49 - want things that are dark to appear
51:52 - close and things that are bright to
51:53 - appear far away so maybe I'll have the
51:56 - things that are
53:16 - [Music]
53:56 - looking at their brightness value and
53:58 - mapping it now the truth of the matter
53:59 - is if if I was really doing this what I
54:02 - probably would want to do is actually
54:03 - just look at that raw depth data if I'm
54:05 - trying to visualize the data in 3D this
54:08 - is not exactly the quote unquote correct
54:10 - way of doing it so that's what I'm going
54:11 - to show you in the next video how
54:13 - instead of using the depth image how you
54:15 - might make use of the raw depth data
54:17 - those numbers which are between zero and
54:19 - 4500 okay thanks for watching and I'll
54:22 - maybe see you in the next
54:25 - video
54:29 - okay uh okay
54:35 - um um so is the is it in the in Connect
54:40 - I'm seeing some in the chat I wonder if
54:42 - with the connect version one it's not in
54:43 - it device which is something that I'm
54:45 - learning right now let's go let me open
54:47 - up one of the examples for The Connect
54:50 - version
54:51 - one
54:55 - uh yeah I don't think you actually need
54:57 - the init device for The Connect version
55:00 - one I'm looking at the example right now
55:02 - the the init depth and init video stuff
55:05 - just turns it
55:06 - on um so I think you don't need that
55:09 - function um let me
55:12 - open
55:15 - that uh I'm looking in the chat to see
55:19 - if there are any more the depth range is
55:21 - different I believe between the two
55:23 - models I believe the second version has
55:26 - like a longer depth
55:28 - range um
55:30 - yeah uh okay so that wasn't my best
55:35 - work uh okay
55:38 - so I'm trying to
55:45 - think I'm going to trying to think of
55:47 - what would be most useful to do
55:51 - next um I said I was going to look at
55:53 - the raw depth
55:54 - data um so I think will and then maybe
55:57 - with the raw depth data I'm going to do
55:59 - a thresholding thing where I'm going to
56:03 - uh only show you pixels between certain
56:06 - distances and in that sense I'm going to
56:09 - get just the human form I wonder if I
56:13 - should do that in um Advance who's
56:19 - coming to get me
56:21 - Victor
56:23 - um okay uh
56:28 - I'm trying to
56:29 - think of what else I might be
56:33 - missing
56:34 - [Music]
56:37 - um
56:42 - uh
56:44 - uh yeah okay
56:47 - um all right um okay sorry everybody I'm
56:51 - I'm spaced out for a second everybody
56:53 - doing okay Sirens oh yes the sirens are
56:55 - coming to get me thank you uh okay
56:59 - so let's go on to the next
57:04 - topic what I'm going to do is open
57:08 - recent so I think I'm just gonna not
57:11 - going to build this one from scratch
57:13 - this one I have ready in advance which
57:15 - is just doing the point Cloud why did
57:18 - this break had this working a second ago
57:22 - um oh something's already running that's
57:25 - why um
57:29 - um yeah so this is a more accurate way
57:32 - of doing the
57:35 - um the the thing that I did in the
57:37 - previous one um so I think I will show
57:42 - this example which uses the raw depth
57:44 - data and then I'm going to use that to
57:48 - um to do some sort of thresholding as
57:51 - well so I will change this into
57:53 - something else uh
57:59 - okay I think my live stream is like way
58:01 - behind
58:03 - me
58:04 - um like 10 minutes
58:07 - behind um but who knows
58:12 - okay I better get on to the next
58:16 - topic
58:19 - uh so let me close this
58:25 - one okay
58:34 - um okay Point
58:43 - Cloud
58:49 - uh
58:55 - uh
58:56 - sorry everybody I'm just getting this
59:01 - ready that's
59:04 - funny because the X and the
59:23 - Y
59:25 - okay
59:34 - hold on I'm doing something
59:43 - here
59:46 - okay okay this is going to do and I'm
59:50 - going to have that go a lot
59:52 - slower okay sorry I'm ready for the next
59:55 - video
59:58 - let me cycle the
60:07 - cameras and drink a little water my
60:11 - phone battery must have died by
60:15 - now let me see where
60:20 - the okay here we go
60:23 - everybody
60:25 - um
60:30 - s over I need a little I need a little
60:32 - energy boost here should have gotten
60:34 - more coffee this
60:45 - morning
60:48 - okay hello in this video I want to look
60:51 - at look I want
60:54 - to hello in this video but that hello
60:58 - was like a little bit
61:00 - creepy hello in this video I plan and
61:04 - hope and I'm excited to look at the raw
61:08 - depth data meaning not the depth image
61:11 - not the depth values um converted to a
61:14 - grayscale image but actually the raw
61:16 - depth data that's coming out of the
61:17 - connect itself so again with the version
61:19 - two connect you're getting numbers
61:21 - between 0 and 4500 with the version one
61:23 - connect you're getting numbers between 0
61:25 - and 2 48 and to demonstrate this what I
61:28 - have over here is a simple processing
61:31 - sketch that's drawing a whole lot of
61:34 - dots on a plane in three-dimensional
61:36 - space and that plane is rotating rather
61:38 - slowly so what I want to do is and this
61:41 - is what's known as a point Cloud I want
61:43 - to take every point on this plane and
61:46 - give it its actual physical
61:49 - reals space no wait wait wait let me say
61:52 - that again okay the connect is seeing
61:54 - all these points I am all these points
61:56 - in a room and the connect is seeing me
62:00 - and I want to move these points around
62:01 - but this is like the weirdest thing I've
62:03 - ever had to explain and it's like the
62:05 - it's like totally simple and it would
62:06 - just make sense if I just showed it to
62:07 - you yet I insist on trying to explain it
62:09 - in this weird way but I want to take all
62:12 - the points that the connects are seeing
62:13 - in this physical three-dimensional space
62:15 - where I am and I want to move these
62:18 - virtual dots which are on the screen in
62:20 - this virtual 3D space and that's known
62:23 - as a point Cloud this is how you might
62:25 - start to build a 3D model of what the
62:27 - connect is seeing in the space so the
62:30 - the the the key difference here uh so
62:33 - one thing that I had before in the
62:34 - previous video is we were looking at
62:36 - this pixel-based image right this idea
62:39 - of each image each pixel of the depth
62:41 - image has a value between 0 and 255 and
62:45 - it's a brightness value based on how far
62:46 - or close it is now the information is
62:49 - stored in exactly the same way inside of
62:52 - this a big array um but uh instead the
62:56 - numbers are between 0 and 4500 so how do
62:58 - we work with these numbers so let's come
63:00 - over here and uh going to do a couple
63:03 - things in this video but this first
63:05 - point Cloud example I mostly have the
63:07 - code already so you can see here that
63:11 - what I'm doing is looping through the
63:13 - connects width and height again I'm
63:15 - skipping because I don't need to do
63:18 - every single point I don't need to do
63:20 - all the points just to visually get this
63:22 - effect um and then I'm finding the
63:24 - offset off set into that array so x + y
63:29 - * connect to.wi so that's how I'm going
63:32 - to look up into that big array of all
63:34 - those depth values now what is that
63:36 - array that array is called is I get that
63:40 - array by saying connect 2 dot get raw
63:42 - depth so when I said get depth image
63:45 - that gives me a p image object with
63:47 - pixel values all in it now I just get a
63:48 - big integer array again those integers
63:50 - are between zero and 4500 so they're in
63:53 - that array and I can say
63:56 - the depth is uh I already use the depth
64:01 - is the offset into that array now
64:04 - there's something else going on now in
64:07 - this function what it's doing is there's
64:09 - a function here called depth to point
64:11 - Cloud position xyd X is the pixel X Y is
64:15 - the pixel y d is the depth that the
64:18 - connect is seeing there's sort of
64:20 - there's a strange thing that's happening
64:22 - which is that the pixel we we look at
64:25 - all these these
64:26 - uh pixels in a grid and we get this raw
64:29 - depth value but the connect itself um
64:32 - there's some math involved in how that
64:34 - can actually converted to real
64:36 - measurements in physical space like
64:38 - where is the actual X where's the actual
64:40 - y based on like how the camera is seeing
64:42 - it so in order to do that this
64:45 - particular example has just this
64:47 - function which essentially you want to
64:48 - download these examples and copy this
64:50 - verbatim um but this function is using
64:53 - all of these kind of uh par parameters
64:56 - that are built into the hardware itself
64:58 - so these are like a whole set of numbers
65:00 - and values that are just part of the
65:01 - connect calibration and you kind of
65:04 - multiply and divide by these numbers and
65:06 - you get the actual value of where it is
65:07 - in space sort of an interesting problem
65:09 - I would love to like go through it at
65:10 - some point but right now I'm sort of
65:12 - inclined to sort of skip it and say the
65:14 - interesting thing is what you're getting
65:16 - is if you give the raw depth value the
65:18 - pixel X and the pixel Y and use that
65:20 - function you're going to get the X Y and
65:23 - depth values in millimeters back of
65:25 - where those things are in physical space
65:28 - so I don't want to in fact draw the this
65:30 - is what you're seeing in this particular
65:32 - visualization right now is just all of
65:36 - these pixels at their exact XY and XY
65:40 - value with a zero depth so what I want
65:43 - to do is change this program to say this
65:45 - actual physical point this P Vector the
65:47 - P Vector is an object that has an x a y
65:49 - and a z i want to draw the vertex at
65:51 - point dox point doy and now point
65:57 - point doz and in order to make this a
65:59 - little bit better I'm going to skip
66:00 - fewer pixels I'm going to skip only four
66:02 - and I'm going to run this again and now
66:04 - you'll
66:05 - see here I am this is the point Cloud
66:08 - this is me in three-dimensional space so
66:10 - if I zoom in on this you can start to
66:12 - see like what's going on this over here
66:14 - by the way is the wall it's funny how I
66:16 - can like put my hands on the wall it's
66:18 - almost as if I'm distorting the wall but
66:19 - really what I'm doing is I'm casting a
66:21 - shadow um so it's a little bit strange
66:23 - to see this view of me and my connect I
66:25 - could like no I would give myself a hug
66:28 - that's a little bit weird too I was like
66:29 - punching is weird hugging anything that
66:30 - you do I don't know just scratch all
66:32 - that but you can see here this is now a
66:35 - visualization in three-dimensional space
66:37 - you could connect these points with
66:38 - lines you could color them there's a way
66:40 - of actually getting the RGB values and
66:43 - so you could see like the colors that
66:44 - are on my shirt on these points as well
66:47 - this is a road you could go down and I
66:50 - find this road to be particularly
66:51 - interesting but what uh and uh you can
66:54 - see that I'm I'm using just a simple y
66:56 - rotation so now I'm kind of like
66:58 - spinning around this image which is now
66:59 - gone off screen um but if I zoom back in
67:02 - you can sort of see it's over there um
67:05 - so this is kind of the start of sort of
67:08 - thinking of like what can you do with
67:09 - these raw depth values I think what
67:12 - would be a useful demonstration now is
67:15 - to look at how might I actually pick out
67:17 - just me so you can visually see just me
67:19 - but there's a sort of Nest there's like
67:21 - all this stuff over here there's this
67:23 - over here um there's actually like this
67:25 - pole over here that's being picked up by
67:27 - the connect so what I you know what if I
67:29 - just wanted to like even only get my
67:31 - hand right here what I want to do is try
67:32 - to calibrate a threshold so what if I
67:35 - want the connect only to see the
67:36 - connect's over here remember so it's
67:38 - it's to the left of me I don't know what
67:40 - what side that is you're viewing but
67:42 - what if I want to say only look at the
67:43 - pixels in between here and here and that
67:46 - would conceivably get my hand right how
67:48 - would I do that how would I look only
67:50 - look at the pixels between a certain
67:52 - minimum and a certain maximum let's look
67:54 - at that so one thing I'm going to do is
67:56 - I'm going to save this as um I know what
68:00 - to call this min max
68:02 - threshold um and I'm going to get rid of
68:05 - all this 3D stuff for right
68:07 - now uh because I'm not going to do this
68:10 - with you could do this with visualizing
68:11 - the point Cloud still but I'm going to
68:13 - do this with
68:14 - just
68:16 - uh and I'm going to look at all the
68:19 - pixels so I want to do
68:22 - x++ and Y ++ and somebody remind me
68:25 - what's the size 4
68:27 - 512 484 is that right I don't know if
68:31 - that's right um and so hopefully that's
68:33 - right and then what I want to
68:36 - do is I don't need end shape I don't
68:40 - need I don't need begin shape I don't
68:42 - need any of this stuff what I want to do
68:44 - again and I don't need this depth to
68:46 - point Cloud thing I'm taking all of that
68:48 - out because what I want to do right now
68:51 - is just go through this double nested
68:56 - Loop and look at every depth value 0 and
68:59 - 4500 but I only want to like count the
69:01 - ones that are between 200 and 400 or
69:04 - between 500 and 800 what is that what's
69:06 - that minimum and what's that maximum
69:09 - threshold okay let's make this happen so
69:12 - the first thing that I should do
69:13 - probably is uh I would like to make
69:16 - myself just to be able to see this I'm
69:17 - going to make myself an
69:19 - image and I'm going to create a blank
69:22 - image which is the
69:24 - same as the width and height of the
69:27 - connect uh and it's an RGB image so this
69:32 - is a function in processing create image
69:34 - that just makes a blank image and then
69:37 - uh whoops and then what I'm going to do
69:40 - right now is I am going to in here I'm
69:44 - going to right here I'm going to say
69:46 - image. load pixels because I want to
69:49 - operate I need to operate on the pixels
69:51 - of that image I'm going to set pixels in
69:52 - that image based on the raw depth and
69:55 - the end I'm going to need to say image.
69:57 - update
69:59 - pixels and I'm also then going to want
70:02 - to draw that
70:04 - image so just to make sure that things
70:06 - are working what I'm going to do is
70:08 - right here inside sorry this is where
70:11 - all of the important code needs to
70:13 - happen right now it needs to happen
70:15 - right here inside this double Loop right
70:17 - for every X for every y I want to set a
70:20 - pixel in the image image. pixels index
70:23 - offset equals and I'm I'm just going to
70:25 - set it to be you know some color right
70:29 - now some purplish color and run this and
70:32 - we should see that that's working U okay
70:35 - so you can see this purplish color I
70:36 - clearly got the size of the window wrong
70:38 - let me just let me just get that for you
70:40 - guys really quick so if I go back and
70:43 - look at my RGB depth test um ah this
70:46 - isn't telling me Oh actually you know
70:47 - what let's just be smart about this um I
70:50 - want to just know what those values are
70:52 - I'm going to print out I'm going to
70:54 - print out the the the depth width and
70:57 - the depth height really quickly uh we
71:00 - can look in the console 512 424 I knew I
71:03 - had some was close so let me just get
71:06 - that right now and I I don't need this
71:07 - much of the console here and I can get
71:09 - back to the important part of the code
71:10 - we can run this we can see okay purple
71:13 - so I have now filled every pixel on the
71:15 - screen with purple but what I want to do
71:18 - is fill every pixel on the screen based
71:20 - on the depth so for example what if I
71:23 - were to just say if d is greater than
71:26 - 300 and D is less than
71:34 - 1500 image. pixels offset uh is that
71:41 - otherwise image. pixels offset is
71:44 - black so what I'm doing is I'm saying
71:47 - only if the only if the distance is
71:50 - between 300 and 1500 let me see a purple
71:52 - color otherwise let me see a black color
71:55 - and when I run this we should see oh my
71:57 - God I can't believe what I guessed I'm
71:59 - like a genius here I somehow guessed a
72:02 - pretty reasonable uh threshold so you
72:04 - can see here that now what I've done and
72:07 - now you see like all computer vision
72:09 - problems Melt Away in a way like uh what
72:12 - I could do now is like it's so easy to
72:14 - find the I mean not easy but it's much
72:16 - easier now to find the Contours I have
72:18 - this problem of this wall over here so
72:21 - how do I get rid of this wall well first
72:22 - of all the real way that I get rid of
72:24 - that wall is by not doing my connect
72:26 - stuff right next to a wall so
72:28 - unfortunately this is like a bad I need
72:30 - a better setup I think for doing these
72:31 - videos which someday maybe I will find
72:33 - but what I want to do let's at least see
72:35 - if I can get the hands so one thing
72:38 - you'll notice here is that the hands go
72:40 - away once you're about a foot and a half
72:42 - from the connect so what I really want
72:44 - is between about I don't know between
72:46 - zero and maybe like 500 so there's
72:48 - probably a better way for me to
72:50 - calibrate this than just randomly
72:52 - picking numbers but let's give this a
72:54 - try you can see nothing nothing nothing
72:56 - nothing nothing nothing nothing nothing
72:57 - nothing oh that didn't do much any good
73:00 - so so let's uh uh so I you know I whoops
73:03 - that's not going to do me any good
73:04 - either uh let's do between like 200 and
73:06 - a th000 nothing you can see uh like
73:09 - right but if I come in theit so you can
73:10 - see here how like I'm able to pick out
73:12 - only my
73:13 - hand uh again I've got this problem with
73:16 - the wall so I'm going to do something
73:18 - about that in a second uh to maybe try
73:20 - to like just like not look at the pixels
73:22 - on this side of the window I guess um
73:24 - but you can see how you I'm starting to
73:26 - find this idea of a minimum and a
73:28 - maximum threshold and really I should
73:29 - make these variables so I'm going to say
73:32 - A Min thresh is 200 and Max
73:37 - thresh is 1,000 and you know I might as
73:40 - well make these floats because what
73:42 - could be also useful I think the way to
73:44 - I could calibrate this right here's a
73:46 - great way I could calibrate this so in
73:48 - between the minimum threshold and the
73:50 - maximum threshold what I might do is up
73:53 - here I might say Min threshold equals
73:57 - map the mouse's x value which goes
74:00 - between zero and width to between 0 and
74:06 - 4500 uh and the maximum threshold I'm
74:09 - going to do Y which between 0 and height
74:12 - 0 and 4500 and then I'm just going to
74:14 - print out those values I could draw them
74:15 - on the screen which would probably be
74:17 - let's draw them on the screen so then
74:19 - down here I'm going to just fill 255
74:22 - text size uh 32 two uh text Min thresh
74:28 - plus oh I got to use um double quotes
74:31 - Max thresh you know 10 comma 64 so here
74:35 - we should see on the
74:37 - screen these values so now what I need
74:40 - to do is figure out like what's a good
74:43 - uh whoops wait X is going between I'm
74:46 - doing I'm lost what I'm doing something
74:48 - is wrong here uh Mouse X between oh this
74:52 - is Max thresh yeah that's a problem uh
74:55 - okay so now you can see I'm able to like
74:57 - calibrate the minimum
75:00 - threshold and let's calibrate the
75:02 - maximum threshold like how far back am I
75:04 - seeing but the minimum needs to be
75:06 - higher and then I don't want to see too
75:08 - far back so there we go so this I feel
75:11 - like is good if I'm getting my hand
75:13 - right now it's between about 480 and
75:16 - 827 so let's like only if I'm standing
75:19 - right here of course but you know you
75:20 - could design an interactive exhibit
75:22 - where you put some footprints on the
75:23 - floor and the person has to stand there
75:25 - so I'm now going to keep my hand boy
75:27 - this is a long video I'm at 15 minutes
75:28 - I'm going to keep my hand around here
75:30 - I'm going to make the minimum and
75:31 - maximum 480 and 830 so now I can comment
75:34 - these lines of code out and I'm going to
75:37 - say uh 480 and
75:42 - 830 and I'm going to run this
75:45 - again and we can see I'm kind of I'm
75:47 - getting my hand like really I'm getting
75:49 - a pretty good tracking of my hand so one
75:52 - thing that I'm going to do now of course
75:54 - which I think would be useful is try to
75:56 - get rid of this wall over here so you
75:58 - know the wall is a bit of a problem but
76:00 - I can kind of uh do a little bit of a
76:01 - cheat here I think which is also to say
76:05 - if
76:06 - and and X is greater than I don't know
76:09 - what how many pixels do you think that
76:11 - was that was probably about uh 75
76:15 - pixels so uh maybe it's a little bit
76:17 - more so I'm just like not allowing me to
76:19 - measure anything that's like 100 pixels
76:22 - over so you can see I kind of got rid of
76:23 - that wall and now I have my hand so this
76:25 - is great you can see like this really
76:27 - nice clean outline of my hand because
76:30 - this is my other hand coming in it's not
76:32 - inside until it gets there right it's
76:34 - outside of that maximum threshold and
76:36 - now it's inside of that minimum
76:37 - threshold it's funny how it like oh no
76:40 - my arm is coming in so of course if my
76:41 - whole body comes in now you can see my
76:43 - whole body is here which is another
76:45 - thing that I want to look at so um you
76:47 - can see how this minimum and maximum
76:49 - threshold is working pretty well so I
76:51 - think this is this wraps up this video
76:53 - I'm going to continue this exact example
76:55 - you could try this on your own as an
76:56 - exercise before you get to the next
76:58 - video how would I actually just find the
77:00 - center of my hand so I could control a
77:02 - processing sketch Now by moving my hand
77:04 - around or moving this hand around or
77:06 - what if I do both hands so how would I
77:08 - do that this is I feel like I'm like I'm
77:10 - some sort of like magic person here um
77:12 - so that's what I'm going to look at in
77:13 - the next video how do I find the center
77:15 - of my hand and control something else
77:17 - like a little like snake that's moving
77:19 - around the screen or make a particle
77:20 - system come out of my hand we'll look at
77:22 - that in the next video and another thing
77:24 - I want to look at is how would I find
77:25 - the top of my head so if I'm the human
77:28 - being here how do I know if I'm bending
77:30 - down or standing up okay so we'll look
77:32 - at that in the next video thanks for
77:34 - sticking with me here I think this is
77:35 - actually starting to come together
77:39 - okay all right chat is anybody
77:43 - there um okay how is the hand Edge drawn
77:47 - in black
77:49 - um okay 424 you guys are telling me in
77:52 - the chat you're so nice uh boy the the
77:56 - live stream is like way behind me I
77:58 - think oh no I've DVR I'm I'm like I'm
78:01 - behind okay I don't need to sorry I'm
78:04 - how's everybody
78:06 - doing uh I got to refresh this page
78:09 - that's my problem oh no I just need to
78:11 - be here ah no wonder I'm in the wrong
78:15 - place uh sorry everybody um I gotta
78:18 - close this come back here there is 23
78:22 - people
78:23 - watching um uh hi Sean uh welcome
78:28 - everyone I'm about to do in the next
78:30 - video I'm going to demonstrate how to
78:31 - find the center of my hand so and then
78:33 - I'll make a particle system come out of
78:34 - it which I think will be loads of fun
78:36 - for every all the family it's a family
78:40 - holiday family edition of the coding
78:42 - rainbow today and Thanksgiving uh I'm
78:44 - going to drink a little water
78:45 - here
78:48 - um I got to cycle the
78:53 - cameras
79:01 - okay
79:03 - um so I'm just about ready I'm seeing if
79:06 - there's um somebody asked when do you
79:08 - think you can upload the videos uh I
79:10 - will most likely upload the videos uh by
79:12 - the end of the day today tonight um or
79:14 - certainly tomorrow morning guess I'm
79:17 - going to do it as soon as I can uh and
79:19 - if they're not there you can always twe
79:21 - but this will always be there um this
79:23 - will automatically be archived and on
79:25 - YouTube this like a long thing but the
79:27 - so far I've made two three videos
79:29 - they're each about 15 minutes those will
79:31 - be uploaded
79:32 - tonight I don't so many Sean's asking if
79:34 - anyone ordered me pizza yet first of all
79:36 - I don't eat dairy so don't order me a
79:38 - pizza a little like you know vegan tofu
79:42 - quinoa salad things is like more in my
79:45 - speed um but don't order me any food I'm
79:47 - fine I ate a big breakfast I'm feeling
79:49 - good I got to probably this Thanksgiving
79:52 - thing is going to happen tomorrow and
79:53 - I'm going to have to eat this like giant
79:54 - meal
79:56 - uh so don't worry about me I'm fine
80:01 - uh um okay uh what was I going to say I
80:05 - don't
80:05 - remember I think I'm ready for the next
80:08 - video okay so in this next one what I'm
80:11 - going to do is look at how to find the
80:12 - center of my hand right we did this
80:14 - thresholding here and now I'm going to
80:16 - find the center of my hand and let me
80:18 - get a particle system example open it's
80:21 - probably overkill for me to bring that
80:23 - in but it's uh I'm let's let's do it
80:25 - it's totally worth
80:27 - it uh so I'm g go under topics simulate
80:31 - a simple particle system I'm going to
80:33 - change something here really
80:37 - quick about this particular
80:39 - example
80:42 - um uh I really wish I didn't make the
80:45 - example the way that I made it
80:50 - uh
80:52 - uh yeah what did I oh add particle
80:56 - H shf
81:03 - man okay let's see if this works okay so
81:06 - I'm going to make this these particles
81:08 - come out of my hand as I move that's
81:10 - going to be fantastic okay that's going
81:13 - to be the next example yeah yeah read
81:16 - only read only shme only okay so I'm
81:20 - going to go back to minmax threshold and
81:23 - here we go I'm going to hit run here uh
81:27 - and I'm ready to do this
81:29 - video uh thanks for sticking around both
81:32 - XP goodbye Cardiff
81:34 - England uh Wales which is part of the UK
81:38 - and whatever I my geography is off sorry
81:41 - okay here we go ready uh did I cycle the
81:43 - cameras did any remember if I did that I
81:44 - don't remember so I'm going to do
81:48 - that uh let's see oh I'm running low on
81:52 - battery for the microphones but I think
81:55 - I've got a full bar and I've got three
81:57 - bars on the one in my pocket so it
81:58 - should be
81:59 - okay try to keep an eye on that and over
82:03 - here if I stand about here that's where
82:05 - the hands are okay great okay here we
82:09 - go in three I'm going to close
82:13 - this in
82:16 - three I have to press the button there's
82:18 - nobody here to press the button but
82:20 - me hello um in this video I'm going to
82:23 - demonstrate some really basic basic hand
82:25 - tracking with the with the connect and
82:27 - I'm going to make a particle system come
82:28 - out of my hand that's what we're going
82:30 - to look at in this particular video so
82:32 - in the previous video what I did is
82:34 - create this sketch where I calibrated a
82:36 - minimum threshold and a maximum
82:38 - threshold so I'm only looking at depth
82:40 - pixels between those values so if I
82:42 - stand exactly here and move my hand
82:44 - around I can you can kind of see a
82:45 - pretty clean outline of my hand of
82:47 - course this breaks down if I stand too
82:49 - close or if I stand too far away but you
82:52 - know and so I should mention that
82:53 - ultimately this type of of hand tracking
82:55 - might be better suited for the official
82:57 - Microsoft SDK and I'll get to that
82:59 - eventually using a PC and different uh
83:03 - uh processing connect library but I
83:04 - think it's still nice to see these
83:06 - examples of how you can do this stuff
83:07 - with the raw depth okay so let's look at
83:10 - how you might do this so this is where
83:12 - we are we're looking for all pixels that
83:14 - are in between a minimum threshold and a
83:16 - maximum threshold so how might I find
83:19 - the center of all of those pixels right
83:22 - here in the center of my hand well the
83:24 - way that you find the center of
83:26 - something off sometimes called the
83:27 - centroid if you want to sound like
83:28 - you're from the future let's look at the
83:31 - centroid um is by finding the average
83:34 - location so let's say we have a
83:36 - collection of pixels you know that are
83:40 - Loosely this is some strange like
83:41 - three-fingered hand right these are all
83:44 - the pixels we care about we can plainly
83:47 - see that this is the scent about around
83:49 - the center but how would I find out the
83:51 - average well let's say you just had
83:54 - these X values this is the x value zero
83:57 - three uh you know 4 8 12 to find the
84:02 - average of some numbers add them all
84:04 - together and then divide by the total 0
84:07 - + 3 + 4+ 8 + 12 divided by 1 2 3 4 five
84:11 - divid five is the average so if we add
84:14 - up all add all x's and we add all y's
84:21 - and we divide by total pixel
84:25 - not the total pixels in the entire image
84:27 - just the pixels that we've picked out
84:29 - that are in between this minimum and
84:30 - maximum threshold then we'll find the
84:33 - center of that area of pixels so let's
84:35 - look at that how do we inside that Loop
84:37 - add up all the X's add up all the Y's
84:39 - divide by the total number of pixels
84:41 - it's actually a pretty simple thing to
84:43 - do this might be the shortest video I've
84:44 - ever made um I'm going to start I need
84:47 - some value to keep track of the the sum
84:50 - of all the X pixels so I'll add that in
84:53 - then I need another variable to keep
84:55 - track of uh summing up all the Y pixels
85:00 - so I'll add that in then what I also
85:03 - need is a just a total pixels zero now
85:07 - I'm making all these floats because I
85:09 - think it's going to be a bit more
85:10 - accurate to use floating Point math
85:12 - doesn't really matter they're they're
85:14 - technically the they're integers there's
85:15 - no like pixel 3.21 but it's a little
85:18 - simpler to work with floats so this
85:20 - value is where I'm going to add up all
85:21 - the X's this value is we're going to add
85:23 - up all the Y's this is going to be the
85:24 - total number of pixels remember that's
85:26 - not a fixed number like depending on
85:28 - where my hand is how many pixels is it
85:29 - picking up that's um that's going to be
85:32 - the total once I have that I can divide
85:34 - some X by total some y by total and
85:35 - that's going to be average X and average
85:37 - y so let's look at that so right here
85:41 - these are the pixels that count right
85:43 - these pixels right here are the ones
85:45 - that are pink those are the ones that
85:46 - are between the minimum maximum
85:47 - threshold that X is greater than 100 was
85:49 - just to get rid of the wall that's over
85:51 - here because the wall is 100 pixels and
85:53 - over um so in order to do that now I'm
85:56 - going to say right in here I'm going to
85:59 - say sum X Plus equal x sum y plus equal
86:04 - y like I'm literally just adding up all
86:06 - the X's adding up all the Y's and then
86:08 - total pixels plus plus so for every
86:11 - single Pixel just add one I need to add
86:13 - up the X values for the X the Y values
86:15 - for the Y and then figure out how many
86:16 - pixels are there and then at the end
86:19 - what do I got I've I don't need to um
86:23 - draw this text on the screen anymore
86:25 - what do I need to say I need to say the
86:27 - average X right the average X is the sum
86:29 - x divided by the total
86:31 - pixels the average Y is some y divided
86:36 - by total pixels and then now why don't I
86:39 - just draw let's make this a different
86:43 - color why don't I draw an ellipse at
86:45 - average X average Y and 100 um I don't
86:50 - know what what size should that ellipse
86:51 - be 64 by 64 so let's run this
87:54 - con that says add particle Mouse X Mouse
87:57 - y right so it's just as easy now as
88:00 - bringing all this particle system code
88:02 - over and saying instead of adding the
88:04 - particles at Mouse X Mouse y add them at
88:07 - average X average
88:09 - y so uh let's see if we can make that
88:11 - happen I'm going to bring I'm going to
88:13 - do a quick little I should have probably
88:15 - do like the cooking show thing where I
88:17 - have an now coming out of the oven I
88:18 - already pre-made this but I'm just going
88:20 - to copy paste everything over real
88:22 - quickly I'm going to bring the particle
88:24 - system
88:25 - object I'm going to put this in my setup
88:28 - over
88:29 - here and I'm going to put this stuff in
88:33 - draw and at the end here and then what
88:37 - do I need I need all this particle code
88:40 - so I don't actually need this camera
88:42 - prams tab for this example
88:45 - uh oh hold on uh uh hand tracking sort
88:50 - of particles I don't know what to call
88:52 - this uh I'm going to get rid of this uh
88:56 - tab C camera
88:58 - prams uh and then I'm going to add a new
89:01 - tab I really shouldn't be doing this in
89:03 - the
89:03 - video I think I crashed processing hold
89:06 - on no everything's fine I'm gonna add a
89:08 - new tab called this was not this was not
89:11 - good you fast forward fast forward a
89:12 - minute I'm gonna move the particle
89:14 - system over that was the particle
89:16 - class and I'm GNA duke it doesn't matter
89:19 - I'm to move the particle over just
89:20 - imagine that I did that correctly I'm
89:22 - going to run this which we can see right
89:25 - the particles the the circle is
89:26 - following my hand the particles are
89:28 - following the mouse how do I make those
89:30 - do the same exact thing now all I need
89:33 - to do is say make the particles not at
89:35 - the mouse but at average X average Y and
89:38 - you know what let's let's actually
89:41 - add about 10 particles per frame to make
89:44 - it kind of make more particles and let's
89:47 - run this and we can see now as I put my
89:49 - hand here I can like control where the
89:52 - particle I can make this like fiery
89:53 - thing come out of my it's not fiery but
89:56 - come out of my hand so you can see I'm
89:58 - now using my hand to control particles
90:00 - coming out I can do my dance and it you
90:03 - know works with anything like I can I
90:05 - can have part like this stuff like
90:07 - emanating from my it's like alien and
90:10 - like bursting out or something I don't
90:12 - this is all getting a little bit weird
90:13 - but you can see I can I can strike this
90:15 - pose and uh it's running kind of slow
90:18 - because I'm drawing like so many circles
90:20 - on the screen um it was a little bit
90:22 - unnecessary to like do that much but
90:25 - you can see anyway so I can make the
90:26 - particles move faster you can you can
90:27 - get where this is going here so this is
90:29 - one example of what you can do by having
90:32 - a kind of specific setup knowing where
90:34 - all the pixels are thresholding them
90:36 - finding the center of something um this
90:38 - is what you can do now let me say a
90:40 - couple more things before I go into the
90:42 - next scenario number one uh um and let's
90:46 - um let's turn the particles off for a
90:48 - second number one is we have this issue
90:51 - of one hand two hands the thing in the
90:55 - center on the one hand this is kind of
90:57 - cool I'm like I am a
91:00 - magician levitating a ball around I I
91:04 - forgot that I was making a video for a
91:06 - second on one hand that's sort of an
91:08 - effect on its own feature not a bug type
91:10 - thing on the other hand you might
91:11 - actually want to have a circle for each
91:14 - hand and in that sense you need to
91:16 - employ a more sophisticated blob
91:18 - detection mechanism for example you
91:20 - don't want just the average of all of
91:21 - the pixels you want the average of a
91:23 - bunch of pixels but don't include pixels
91:25 - that are over a certain distance
91:27 - threshold from other ones so this is
91:29 - something that I could potentially
91:30 - demonstrate in a future video in this
91:31 - series I'd be happy to add one in but
91:33 - also in this case one thing you can do
91:35 - if you have this very clean image you
91:37 - can pass it to a library that might do
91:40 - that type of edge detection blob
91:42 - detection Contour detection for you and
91:44 - there's two libraries I'll try to link
91:45 - to them in the description that I might
91:46 - recommend one is called blob detection
91:49 - does kind of what you're thinking
91:51 - another library is called open CV which
91:53 - has a lot of computer vision
91:54 - functionality built to it but one of the
91:56 - things in it is blob detection so maybe
91:58 - I'll try to like show that at a certain
91:59 - point but you can see the basic idea
92:01 - here is still just working even without
92:03 - uh an extra sophisticated layer of
92:05 - looking for separate chunks um okay
92:07 - thanks for watching this I think in the
92:09 - next video I have two more that I
92:10 - intended to do today although it is 1210
92:13 - I wanted to see if I could look at for
92:14 - the top like how do you find the highest
92:16 - pixel um or Theo you know closest pixel
92:19 - is something you could also find but I
92:21 - think highest might be interesting
92:22 - because uh somebody here at ITP has a
92:24 - project that she's working on which is
92:26 - uh having somebody move up and down so I
92:28 - think that's a useful demonstration and
92:29 - then also maybe looking back at that
92:31 - grid again um but averaging all of the
92:34 - depth points within cells of a grid okay
92:36 - that's what I intend to make next I'm G
92:38 - to hit stop on the record button uh come
92:41 - on wake
92:43 - up okay
92:46 - everyone
92:48 - uh all right
92:50 - [Music]
92:51 - everyone yeah I see some are chatting
92:54 - about me in the Stream it is true
92:57 - actually I didn't actually code start
92:59 - programming until 2001 I was 27 years
93:03 - old 2001 you can figure out how old I am
93:05 - now I did take some programming classes
93:08 - in middle school middle uh Assembly
93:10 - Language and basic uh I also took an
93:13 - evening C++ Course once because I
93:15 - thought it might be interesting in
93:16 - programming and I was like this didn't
93:17 - like it uh but then I think being in a
93:19 - creative environment like ITP I got kind
93:21 - of obsessed with it so that is true
93:25 - uh um okay so uh I forgot when my I have
93:29 - to check when my office hours are
93:32 - because I have to go soon unfortunately
93:34 - I have to grab something to eat before
93:35 - let me just I'm looking this up right
93:38 - now uh they start at uh shiffman
93:43 - shiffman shiffman where's shiffman uh at
93:46 - one I I'm not going to give the time
93:49 - okay yeah 120 I need to take a break
93:52 - obviously to eat something between them
93:53 - so so I think I could manage a little
93:56 - bit more because I want to do I think I
93:58 - could try to do these two examples real
94:00 - quick um so let's look at the
94:04 - um yeah there's a problem where I need
94:07 - to file the open CV is not showing up in
94:10 - processing 3 but it actually works in
94:11 - processing 3 it probably just needs a
94:12 - few little fixes um uh I I would love to
94:16 - I uh Greg Borstein who did a tremendous
94:18 - amount of work creating this Library um
94:21 - I should look at it and see if I can uh
94:22 - just put a pull request quickly on
94:24 - GitHub to or to make sure that it shows
94:26 - up uh in processing 3 because it does
94:28 - work in processing 3 there's probably
94:29 - just a few little things that need to be
94:31 - fixed um okay I'm going to I'm going to
94:35 - get a little more water I'm going out
94:36 - into the hallway and I'll be right back
94:52 - okay
94:58 - are you watching this from here okay you
95:00 - were
95:01 - sorry thanks
95:07 - Sean okay okay I'm back everybody uh I'm
95:12 - going to just get a little cool air in
95:14 - here for a
95:16 - second um I'm going
95:19 - to turn off and on the cameras Oh I have
95:23 - to go around this
95:31 - side
95:33 - okay
95:36 - uh let's see here I'm over here I'm
95:39 - going to erase so the next video that
95:41 - I'm going to make here oh wow there's
95:43 - quite a glare from the sunshine over
95:45 - here wonder if I write over here if you
95:47 - can't see it yeah you can't see that
95:49 - very well so I'll just be conscientious
95:51 - of that I I just can't bear to like
95:54 - black out the window in this room it's I
95:56 - did that last year and it's like
95:57 - miserable to be in here so much rather
95:59 - have the sun infecting me uh let's see
96:02 - okay this is pretty good um okay so in
96:04 - this next video the next thing that I'm
96:06 - going to do is look for the closest
96:08 - point or the top of someone's head uh
96:12 - the highest point that type of thing um
96:14 - which is a kind of common algorithm in
96:15 - computer vision that you need uh uh oh
96:19 - yeah right there was a hot mic again uh
96:23 - and um okay and I'm going to um um here
96:27 - we go I got to close the
96:29 - window I'm going to try to I'm going to
96:31 - try to do this by the way for 15 more
96:34 - minutes I don't know if I can get
96:36 - through both of these topics in 15 more
96:38 - minutes
96:41 - um and then I have to
96:43 - go uh I guess I've been doing this for 1
96:46 - hour and 36 minutes so
96:48 - far okay here we go uh water's here and
96:54 - getting myself ready I I cycled the
96:57 - cameras didn't I just do that right I
97:00 - can't remember do it
97:04 - again I'm going to check the battery is
97:07 - at one bar still so my mic shouldn't go
97:09 - out in the middle of
97:12 - this
97:18 - okay hello um in this video I'm going to
97:21 - look at how you might using the connect
97:23 - fine the closest thing in the room or
97:25 - the highest thing in the room um this
97:28 - type of algorithm is kind of common in a
97:30 - lot of computer vision applications I
97:32 - think which involves
97:38 - similar hi um in this video I want to
97:41 - look at an algorithm that lets you do
97:42 - the kinds of things like find the
97:44 - closest thing in the room or find I'm
97:47 - doing all sorts of like Vogue poses find
97:49 - the highest thing in the room I don't
97:51 - know why I need to do that for the
97:52 - highest thing but whatever um or uh and
97:56 - this is a similar type of algorithm if
97:57 - you've ever looked at like a color
97:59 - tracking algorithm find the brightest
98:01 - thing or find the most red thing in the
98:03 - room I like to refer to this as like the
98:05 - world record algorithm which means like
98:07 - I've got to look at every single Pixel
98:09 - and keep track of which pixel is the
98:11 - record holder and hold on to that record
98:13 - holder the closest thing the highest
98:14 - thing the most red thing and when I get
98:16 - to the end have that XY coordinate that
98:18 - I can use for something else so a lot of
98:21 - things that you might do with the raw
98:22 - depth data of the connect could involve
98:24 - this like if you know the person is
98:25 - always standing like this in a fencing
98:28 - pose what is where is their hand because
98:30 - their hand is always the closest thing
98:32 - or if you want to determine if a person
98:34 - is moving up and down how do you find
98:36 - the top of their head what's the highest
98:37 - thing within a given threshold so let me
98:40 - uh go over to the Whiteboard for a
98:41 - second to just talk in generally
98:43 - speaking about how this kind of
98:44 - algorithm works and then we'll go and
98:47 - implement it in a couple different
98:48 - scenarios okay so as with just about
98:52 - everything that involves IM and pixels
98:54 - or depth points you've got this grid
98:57 - right and the grid has a bunch of x's
98:59 - and a bunch of y's and there's always
99:01 - this Loop all the examples have this for
99:04 - every X for every I look at every pixel
99:08 - now I've got some glare here so
99:10 - hopefully you're going to be able to see
99:10 - what I'm writing but I was to to say
99:12 - shout at me just shout at your computer
99:14 - screen or wherever you're watching this
99:16 - and I will hopefully hear you someday um
99:18 - if you can't read what I'm about to
99:20 - write but uh but so the way that this
99:22 - works is you need to find the record
99:24 - holder so what let's say we wanted to
99:27 - find the um uh the closest thing so
99:32 - remember the depth values are between 0
99:35 - and
99:37 - 4500 so we could start by saying the
99:40 - initial record right the world record
99:43 - for the closest thing would be 4500
99:46 - because that's the furthest back so any
99:49 - pixel that beats 4500 is the is by
99:51 - definition the new record holder
99:54 - so we have to say something like if I
99:56 - have the current depth in a variable I
99:59 - need to say if that depth is less than
100:03 - the
100:04 - record then the record is now that depth
100:09 - so this is the core algorithm for every
100:11 - pixel is the first one beating the
100:13 - record it is that's the record holder is
100:15 - the next one beating that record no is
100:17 - the next one beating that record no is
100:18 - the next one beating that record yes
100:20 - okay that's the record holder and while
100:22 - we're doing this we could also keep
100:23 - track of you know the record X and the
100:26 - record y so if we went every time we get
100:29 - that new record we store that X and Y so
100:31 - that by the time we get to the end of
100:33 - this Loop in those variables are the X
100:36 - and Y that win this record so let's look
100:39 - at how we might do that um and I will
100:43 - come over here and let's look at let's
100:46 - do um okay let me save this I kind of
100:49 - want to do the closest thing this what
100:51 - we talked about but you'll see that it's
100:53 - not going to work in the most perfect
100:54 - way but let me save this as uh a closest
101:00 - uh
101:01 - thing and I'm going to um I just want to
101:04 - delete the particle system tabs which
101:07 - are no longer
101:08 - relevant uh oops don't delete that tab
101:11 - ah I think I made a mistake earlier and
101:14 - I'm going to get rid of all this
101:15 - particle system stuff sorry I should
101:16 - have done this before I started
101:18 - recording this but it's too late now um
101:20 - we can get rid of all this particle
101:22 - system stuff and and I'm going to get
101:24 - rid of the average thing that was
101:25 - interesting that we were doing in the
101:26 - previous video um and even such I'm
101:30 - going to keep this I'm going to keep
101:31 - this thresholding in here because I
101:34 - think that's maybe a little bit useful
101:36 - um to kind of keep at the moment
101:38 - actually you know what I'm going to take
101:39 - that thresholding out but I'm going to
101:42 - keep this x is greater than
101:44 - 100 and uh what I would like to do
101:50 - is H too much too much going on that I
101:53 - didn't think to do in advance it's okay
101:55 - everything's fine just you know Talk
101:57 - Amongst yourselves for a minute or fast
101:59 - forward like 30 seconds in this video
102:01 - and I will be at the point so I just
102:03 - want to take out all this stuff let's
102:05 - keep the
102:06 - um uh and uh yeah this is
102:11 - fine uh what I ah I know what I need to
102:14 - do everything's
102:16 - fine uh I'm going to draw I don't need
102:18 - this image
102:20 - anymore uh right what I'm going to do is
102:24 - what I want to have access to to look at
102:26 - sorry everybody is the um the raw depth
102:30 - image I'm not sorry the depth image as
102:32 - well so I'm going to call this the D
102:34 - image equals connect
102:37 - to.get depth uh
102:40 - image so that way I can draw that image
102:43 - on the
102:45 - screen and so let's just make sure this
102:47 - is now working so you can see okay I've
102:50 - got the depth image on the screen so
102:51 - what I want to do now is look look for
102:54 - the pixel that is the closest okay and
102:57 - we've got a bit of a problem here
102:58 - because some of these there's a window
103:00 - back there and it's going to give me
103:01 - some weird zero values so I think this
103:04 - this might not work oh and I should have
103:05 - kept the
103:06 - thresholding crap I should really you
103:08 - know what I'm GNA I'm going to hit stop
103:11 - on the recorder for a second and I'm
103:13 - going to just uh Stitch these Stitch
103:15 - This Together from when I move from over
103:16 - here over here ah crap I I wasn't
103:19 - thinking straight there okay I'm pausing
103:21 - for a
103:22 - second uh all right um so let let me let
103:26 - me figure this out
103:29 - here closest let's just see how this
103:31 - works I'm going to build this I'm going
103:33 - to pause the video I don't I I should
103:34 - have checked this in advance I'm going
103:36 - to close this so what I'm doing now I'm
103:38 - going to come back and record again in a
103:40 - second what I'm doing here is and I can
103:43 - delete all this stuff I'm need that
103:46 - threshold again in a second what I'm
103:48 - doing here is um looking for okay okay
103:53 - so I need the uh record is
103:58 - 4500 and the record X is zero and the
104:02 - record y uh record Y is zero and I'm
104:08 - going to
104:09 - say
104:11 - uh if D is less than record then record
104:15 - equals D Record xal X record yal
104:20 - Y and I need to close curly bracket and
104:23 - then at the end of all this looping I
104:26 - can say
104:28 - uh draw an ellipse at record X record y
104:32 - that is some size that's kind of big uh
104:36 - and let's see how this
104:38 - goes okay so you can see the problem is
104:42 - that it's always in the top
104:43 - left U it's a good thing so what I
104:46 - should probably okay so one thing that I
104:48 - was going to do right is Skip
104:51 - uh skip these
104:55 - pixels uh let's try
104:58 - this and let's see can I get it to be
105:01 - something problem is there's too much
105:03 - glare and reflection back there so I
105:05 - should do the top I should just do oh I
105:08 - I as I got over here something became
105:10 - closer than what's back there my
105:14 - head oh yeah I'm kind of able to get
105:17 - this to work if I come really close but
105:20 - not it doesn't work so great because I
105:21 - really should be there we go why is it
105:24 - if I move I must have messed something
105:27 - up record yals y record xals x no that's
105:31 - right um what I probably I probably
105:34 - should do the top of the head thing why
105:36 - is it not it's interesting how so I
105:39 - think this is a bad demonstration I um
105:42 - which is a mostly because of the setup I
105:44 - have here like if I had if I had the
105:46 - connect over here and had this flat wall
105:47 - behind me it would work pretty well um I
105:50 - could look for the thing that's closest
105:52 - within a minimum Max maximum threshold
105:54 - which is probably I should have kept
105:55 - that um but I think what I might do is
105:57 - put the threshold back in and look for
105:59 - the I should put the threshold back in
106:01 - so let me bring that back uh I still
106:05 - have that here so I want to say
106:10 - if uh so let's bring the threshold back
106:12 - in
106:14 - if so I only want to consider stuff
106:17 - that's if D is greater than Min
106:20 - thresh and D is less than Max thresh
106:25 - and
106:27 - um X is greater than 100 I think is what
106:30 - I had then then I can look for the
106:35 - record uh
106:39 - thresh so this should right now this is
106:43 - working you can see how much it jumps
106:44 - around but you can see it works with
106:46 - anything that's within that threshold
106:48 - that's closest which right now if I bend
106:50 - down is also my head but course as I
106:53 - move out of the threshold so you can see
106:55 - how like unstable this is but I think
106:57 - that could sort of do the demonstration
106:59 - I actually want now also to have that
107:01 - image back
107:02 - now uh which is that I should say
107:07 - um uh what I should be doing
107:11 - is uh I think this would be hold on I
107:15 - you're kind all to
107:18 - stay uh set the initial record to the
107:21 - highest possible didn't I do that um so
107:24 - what I want to do is put that that
107:26 - um the uh image back in too so uh image
107:31 - that load pixels so I'm going to say
107:36 - um
107:38 - uh image
107:41 - dot here let me turn off I'm going to
107:43 - turn off the code completion uh else
107:46 - else uh image.
107:49 - pixels uh
107:52 - offset equals D image.
107:55 - pixels
107:58 - offset and I'm going to here say uh
108:04 - image. pixels offset
108:08 - equals uh color uh 2550
108:12 - 150 and then uh this should be a
108:16 - different
108:17 - color uh so I oh and then I need to draw
108:20 - that image
108:22 - also
108:25 - let's see up
108:27 - whoa hello connect that is the weirdest
108:30 - thing I've ever
108:32 - seen what just happened
108:35 - there whoa what is going on oh some
108:38 - other imag is
108:41 - there whoa what is going on oh I didn't
108:44 - say image. update
108:46 - pixels must be
108:49 - why there we go so I should see like
108:53 - when the stuff is within the threshold
108:55 - I'm finding the closest thing within the
108:57 - threshold um which might be like my
109:02 - elbow uh that sort of thing maybe that
109:06 - minimum threshold should be actually
109:08 - like lower anyway um okay so sorry okay
109:13 - I'm gonna I'm going to I'm gonna start
109:16 - this over and I'm going to start it I'm
109:19 - going to take this
109:21 - out and I'm going to
109:24 - take this out this is the stuff that I'm
109:26 - going to add
109:27 - in and I'm going to take this out so now
109:32 - what it should
109:33 - be I've just got something where it's
109:35 - showing the only the threshold of pixels
109:38 - but also all the rest of them and then I
109:40 - I really want to do the top of the head
109:42 - thing because I think that might
109:43 - actually work much more accurately um to
109:46 - find the highest pixel that's within the
109:48 - threshold but I'll do the closest and
109:50 - then the top why not right
109:53 - okay um so I now have to pretend where
109:57 - was I I was over here and I was talking
110:01 - about this stuff and then I finished and
110:04 - went over to the computer to talk about
110:06 - something else so I'm going to do that
110:13 - again shoot this is going to be this is
110:17 - definitely going to be uh whoops this is
110:19 - definitely going to be
110:21 - um come back come back this is
110:24 - definitely going to be it for today once
110:25 - I get through these two examples because
110:27 - I really I'm I'm like sort of late now
110:29 - we have 45 minutes till my first
110:31 - appointment I need to eat something in
110:32 - between so but I I want to I want to get
110:34 - through this so to have this done okay
110:37 - so here we go I think I can do this now
110:40 - um with this particular
110:43 - example uh so I'm gonna have to like cut
110:45 - this somehow I I I hate it when I do
110:48 - editing this is I'm not really going to
110:50 - do editing I'm just going to splice
110:51 - these things together
110:54 - and I'm going to uh pretend okay so I'm
110:57 - going to walk into the scene over
111:01 - here I'm afraid am I recording this I am
111:04 - yes
111:05 - okay okay so to demonstrate this example
111:08 - now what I have is I've I've adjusted
111:10 - this example a little bit and what it's
111:13 - doing now is it's showing you both the
111:15 - depth image as well as coloring
111:18 - particular pixels of that depth image
111:20 - this pink color that are within this
111:21 - threshold so now I need to figure out
111:24 - what pixel in that threshold is perhaps
111:27 - a record holder of some sort of record
111:29 - so we'll look at the closest thing and
111:31 - also the highest thing and I'm pretty
111:32 - sure the closest thing is going to not
111:34 - work that well but the highest thing I'm
111:36 - hoping is going to work pretty well so
111:38 - let's do the thing that's not going to
111:39 - work as well first um and let's just
111:41 - look at a little bit of what's changed
111:43 - in the code just to to show you so first
111:45 - of all I'm looking at the depth image as
111:46 - well and then what I'm doing is if the
111:50 - pixel if this um depth value is in the
111:52 - the threshold I'm setting that
111:54 - particular color to this pink value if
111:57 - or purple value I don't know what color
111:59 - it is I can't tell uh if it's not um
112:03 - then I'm just pulling the color value
112:04 - from the depth image itself then
112:06 - updating the pixels and drawing the
112:07 - depth image so that is why you are
112:09 - seeing this particular result it's
112:12 - essentially what I had earlier in the
112:14 - previous examples with just also adding
112:16 - in those depth pixels instead of black
112:18 - so now we need to figure out this way of
112:21 - a getting a record holder so the first
112:23 - thing we need to do is say what at the
112:25 - beginning what's the record distance I'm
112:27 - looking for the thing that's closest so
112:30 - the thing that's closest the record to
112:32 - start would be something really really
112:33 - high so the record would be 4500 that's
112:36 - as far as it as something is possible to
112:38 - be from the connect then I need the
112:40 - record X which will be at zero and the
112:42 - record Y which will be at zero so I want
112:44 - to test every pixel X and Y if it beats
112:47 - the record if it does beat the record
112:49 - set RX to that new X and set r y to New
112:53 - Y and then draw a circle at that record
112:55 - value at the end so right here I'm going
112:57 - to check only inside the threshold you
113:00 - know in a different scenario where I had
113:02 - the connect in like an open space and a
113:04 - and a sort of flat wall and people just
113:06 - came into the middle I don't wouldn't
113:08 - really need to do this thresholding
113:09 - thing because I but there's so much
113:10 - stuff in this room there's a desk
113:12 - there's a computer there's a wall that
113:13 - it's not so I think using the threshold
113:15 - here helps it be a little bit more
113:17 - accurate so I can say if that distance
113:20 - is less than the record then the new
113:22 - record is that particular distance right
113:24 - for every single Pixel does that pixel
113:26 - beat the record if it does I've got a
113:28 - new record and if it beats the record
113:31 - then I need to save that particular X
113:34 - and Y in RX and r y so all we need to do
113:37 - this kind of record algorithm is a
113:38 - starting record a starting RX and r y
113:41 - and then every time we beat that record
113:43 - save those two values and then at the
113:47 - end I can draw a circle at RX and r y
113:52 - and I'll just make that Circle uh White
113:55 - uh so it kind of we pick it up and we
113:56 - can see now okay now first of all you
113:58 - can see that circle is just jumping
114:00 - around that's because first of all
114:02 - there's very little there's like stray
114:03 - pixels that are that are making it in
114:05 - the threshold so now you can see that
114:07 - it's kind of working now you can see
114:09 - that white circle is following my hand
114:11 - now notice this is much less accurate
114:12 - than what I did before with a sort of
114:14 - average section of pixels um mostly
114:17 - because anytime you're looking for a
114:18 - single Pixel it's not such a great thing
114:20 - I kind of want to find a group of pixels
114:22 - that are like beating that record but
114:24 - that aside you can see the basic idea is
114:26 - working but it's really like if I come
114:28 - and stand in here like there's a lot of
114:30 - me that's in the threshold but my head
114:33 - as I'm bending over is closer so you can
114:35 - see if I move my hands out they're a
114:37 - little bit closer if my shoulder comes
114:39 - in my shoulder is the closest thing so
114:41 - you can see it's jumping around a lot
114:43 - but it's always finding the particular
114:45 - pixel that is closest it's just sort of
114:47 - demonstrating the idea but let's change
114:49 - it now let's have it find I'm going to
114:51 - stand here to
115:52 - I've beaten that record so record equals
115:55 - that y value save this save the X and
115:58 - the Y and then draw it so the same exact
116:00 - idea I'm just changing what the test is
116:02 - like the height is the yv value if it's
116:04 - less than that record so now we'll run
116:07 - this and we can see it's picking up a
116:09 - lot of noise but if I come in and bend
116:12 - down so there's too many pixels up top
116:15 - you can see that it's flickering there's
116:16 - too many pixels up top that are pulling
116:18 - up some sort of value so I'm going to
116:20 - try to do like a little bit of a hack
116:21 - here again we're going to say and I'm
116:24 - say let's skip uh let's skip the first
116:27 - like 50
116:29 - pixels I'm only going to look and let's
116:31 - see if this helps there we go so now you
116:34 - can see I'm getting the top of my head
116:36 - pretty accurately if I move my hand up
116:38 - here I'm getting the top of my hand so
116:40 - if I had a particular uh project that
116:43 - wanted to have something move based on
116:45 - whether I'm moving up and down this is
116:46 - good I'm going do some X squats here um
116:49 - you can see that this works so you know
116:51 - I had to sort of like Cal and do some
116:53 - goofy things but you can see this is a
116:55 - very simple way of just finding the top
116:56 - so like people always get obsessed with
116:58 - like finger tracking like let me find
117:00 - the finger but you can see how accurate
117:02 - this is I'm just getting like the tip of
117:03 - my finger now there's no finger tracking
117:05 - here just like if I go like this it's
117:06 - getting the top of my elbow but if you
117:08 - tell people to stand like this and wave
117:09 - their finger you can see how like kind
117:11 - of super accurate that tracking is just
117:13 - from looking this is like the simplest
117:15 - thing ever I'm just looking for the top
117:18 - pixel inside this threshold so hopefully
117:20 - this shows you a few types of things you
117:22 - can can do uh we've seen a range of
117:24 - things of just sort of visualizing the
117:25 - 3D data from like looking for
117:27 - thresholding it in between for tracking
117:29 - the the height of something the average
117:31 - location um this is where I'm finishing
117:34 - this video set today um but there will
117:36 - be some more ones I guess who knows when
117:38 - you're watching this the more ones might
117:40 - already exist the more ones and you'll
117:41 - see them in the next video okay so
117:43 - thanks for watching uh this how oh yeah
117:46 - right uh and I will uh talk to you soon
117:48 - okay
117:51 - goodbye
117:53 - all right everybody um so that's it for
117:56 - today um and uh so if you have any
118:00 - questions I can take questions for like
118:02 - maybe five minutes it's 12:36 and I'm
118:05 - going to go in about five minutes um and
118:10 - uh I can take questions and um then I'll
118:14 - go sorry my brain is like totally fried
118:17 - this has been an hour and 58 minutes
118:19 - that I've been on this live stream um so
118:22 - I'll give it a minute to see if anybody
118:23 - wants to ask
118:25 - anything
118:29 - uh uh
118:31 - whoops um see if anybody
118:36 - is
118:38 - um okay
118:41 - uh any important info
118:44 - here
118:50 - um uh okay let's see if anybody ask any
118:53 - questions uh any tips on using more than
118:56 - one connect uh what you want to do if
118:58 - you want to use more than one connect is
119:00 - uh go look at the examples uh in the
119:03 - examples I'm going to come back up here
119:05 - under contributed exam uh oh oh no no
119:09 - contributed libraries under open connect
119:11 - um so this one here multiconnect version
119:15 - this one is showing you actually how to
119:16 - use more than one connect and even a
119:17 - connect version one and a connect
119:19 - version two in the same sketch and here
119:21 - under connect one multiconnect and here
119:23 - in Connect for multiconnect 2 so for
119:26 - example if I just come to multiconnect 2
119:28 - you can see here um that you can create
119:32 - uh two different connect objects and
119:34 - then init them as init device zero and
119:36 - init device one which will make them
119:38 - separate so you can actually everything
119:39 - works exactly the same way it's pretty
119:41 - simple to be able to do that
119:44 - yeah uh what is the update rate of
119:46 - connect depth data I'm pretty sure it's
119:48 - 60 frames per second but kind of I don't
119:51 - actually know uh I bet you if you Google
119:53 - that there'll be an answer on stack
119:54 - Overflow or something I would love to
119:55 - know the answer to that for sure I I I
119:57 - seem to remember hearing 60 frames per
119:59 - second I don't know that the first
120:01 - version one connect was that but I think
120:02 - the new one is um
120:05 - okay oh yes sorry so okay great so I
120:08 - this is technically how you could have
120:10 - more than one connect hooked up to your
120:11 - computer but you do have certain issues
120:13 - with like you point them at each other
120:15 - the infrared light starts to interfere
120:16 - with each other so trial and error is
120:18 - your best friend here sometimes it just
120:20 - seems to work anyway sometimes it can be
120:21 - a problem if you have a lot of the
120:22 - sunlight it can interfere you can't put
120:24 - a mirror in the room because the mirror
120:25 - is can to reflect all the light so
120:27 - there's a lot of issues around that but
120:29 - um you know for the most part you can
120:32 - have two connects you know if they're
120:34 - pointed in different directions and the
120:35 - infrared stuff doesn't cross they'll
120:37 - definitely work if they do cross I feel
120:39 - like with the new version too they seem
120:40 - to like operate on different frequencies
120:42 - or something and it kind of still works
120:44 - anyway but i'm to be honest I I haven't
120:46 - you know done a lot of stuff with the
120:48 - connect I'm kind of just trying to teach
120:50 - it from like making examples but I
120:52 - haven't with the new connect I haven't
120:53 - really like made a lot of projects with
120:55 - it
120:57 - um okay 2 hours is generally my limit uh
121:00 - I hope next week I've got a real
121:02 - schedule problem but I hope to be back
121:04 - to do at least one day next week but it
121:06 - might not happen but I'm going to be
121:08 - doing these uh in January I might even
121:10 - do these live streams twice a week I'm
121:12 - hoping and then in February I'm going to
121:13 - be doing them a lot is my plan so um so
121:18 - but uh keep in touch ask questions over
121:20 - Twitter put uh comments and questions
121:22 - the YouTube videos is super helpful
121:24 - especially if I mention something that I
121:25 - forgot to put in the description or I
121:26 - could put an annotation in that corrects
121:29 - something that's great so please keep in
121:31 - touch let me know hope this is helpful
121:33 - and I will see you guys soon I'm going
121:35 - to hit stop on this stream

Cleaned transcript:

I think I'm streaming he everybody welcome good morning I've been having technical difficulties for like the last 20 minutes and I think this is actually working oh my God it's working they YouTube changed the way things work good morning welcome this thing is called the coding rainbow uh and I had a whole thing prepared to say that I don't have prepared to say anymore because I just spent 15 minutes trying to make all this stuff work I feel very stressed out but I'm here in New York City at place called ITP at New York University uh Tish School of the Arts and I'm here to talk about I have a prop the Microsoft Connect uh how do you program with this thing how do you do interactive stuff with this thing how do you use this thing with something called processing uh which is running behind me here uh oops I didn't even configure my window or anything so um I people in the chat tell me if you are there uh tell me if you can hear me tell me if you can read this font um tell me if uh you can see me over here I need to test to make sure this whiteboard is working I mean the the Whiteboard is working but if the focus is pretty decent uh I think that's pretty good I'm going to walk over here I've got Periscope live going hi Periscope um so I'm like d triple double streaming something hi I'm talking to Periscope so now I'm on I'm Live on YouTube Periscope so I'm going to put you down so so you could see the URL over here and you can go there uh this is like the most ridiculous thing I've ever done there you go okay so that's where you can go Periscope or you can at least hear the audio so um uh okay everybody can hear me it works like a charm that's great that's exciting to hear um okay so I've got to get started um and I have uh I think I'll be doing this for about an hour or so uh I'm glad to take questions uh the first thing I want to do so I'm kind of going to talk this through first to figure out the kinds of things I'm going to cover um I'll look for any questions or ideas in the chat um and then what I'm going to do as I always do but I'll explain it again is during various parts of this um live stream I'm going to hit a record button to like save a particular chunk as a standalone video Lesson which I will upload to Youtube later so my goal is to have like four or five 10minute video lessons about using the connect and this live stream will be kind of a mess of like trying all sorts of stuff out and in between making those videos um and sometimes I stop and start and redo the redo the same content if I feel like I went in the wrong direction and so you just turn it off if this is like driving you crazy um so I'm checking in the chat hello ah Cardiff again and hello France uh if one thing that's really important if if the audio stops working or if some weird thing happens you can't see me uh please type that in the chat I'm not doing anything with Twitter today so I don't need people to tweet while I'm doing well but you know welcome to um you know let people know this is happening uh it's a holiday tomorrow here in the United States called Thanksgiving NYU is actually closed today but it's a busy active time the end of the semester so um but the reason why I'm doing this actually is because um a lot of students are trying to do projects with the connect around here and I thought this would be helpful we'll see um okay I I'm gonna drink a little water and get set up so I think the first thing that I'm going to do I um first thing I'm going to do is just talk about the connect in general what the different versions of the connect are uh how it works and show you how to install a library in processing that uses the connect open the window for a minute to get some cool air in here lights some get a little bit hot uh so I'm going to just talk about the connect in general and like run some examples to show what it does and then then I am going to uh try to look at a few different scenarios for example um finding the closest thing maybe to the connect maybe finding uh the the top of a human being like where's the top of your head uh I want to look at like taking the depth map and maybe just like dividing it into sections like a grid um somebody had a idea for a project ITP which is to have like the connect pointed at a a sand box and you could manipulate the sand and the height of the sand would play different musical notes so maybe some kind I don't have a Sandbox or and I have the connect in sort of a weird place so I don't know how this is all going to go but I want to try to build a few examples from scratch basically while we're here um okay um great I'm seeing some nice people say hello yes if you're listening to the Periscope audio and the YouTube audio you're in trouble because they're they're definitely going to be out of sync um and that's that so um let me get myself a little bit oriented here uh and I'm going to so here by the way so let me see so let me get this particular example up and running I'm going to hit stop um I need a little bit more room here I'm going to do this interesting I think I actually need this statement in there and I'm going to do this and okay so this is the first thing that I'll just talk about which is that you can get the uh the regular image from the connect the depth image which you can see the darker the color is the closer it is this is um using the connect version two there's the the what the camera is actually seeing the infrared that the cam the camera the sensor the connect whatever you want to call it is seeing and the um this thing called a registered image which aligns the col colors with the depth uh okay uh I think it runs on Linux um I don't know that's a good question I mean I'm so a lot of this work I have to credit Thomas Sanchez lling does anybody know how to pronounce his name let me pull let me pull up uh let me pull up the person I would like to credit for a lot of this work to who helped bring have the library work with the connect version too Thomas Sanchez lling uh here he is a cod codigo generao is his website which I'm probably butchering the um butchering the name so w Works in portfolio of Thomas Sanchez L leling leling if anybody knows how to pronounce that so write it phonetically in the chat otherwise I'll probably mispronounce his name but I do want to thank him uh when I when I start making some of these videos I guess this is a video I'm making right now I'm already thanking him um but he's done a lot of work with the connect and in this part this particular Library so what I should probably bring up here is open connect for processing the uh GitHub page to look at this uh as well as uh sorry let me I'm just getting set here to make this first video uh and um the uh open connect for processing and then this is my page which could use some work but it has some documentation and stuff about it as well okay um yes you can install the connect Library directly from processing and you don't need to install anything else unless you're on Windows maybe you do but you follow the instructions okay uh so I'm getting ready I'm going to make this first uh video I'm going to just drink a little bit of water over here wow I've got 31 people watching that's fantastic um I'm actually just going to send a quick email um to ITP students um because uh hold on a sec because a lot of them were interested in maybe joining so live stream on connect happening now uh okay I'm just sending that out uh okay so I think I'm good to go wow I I just took oh it's eight minutes to get started here but uh I'm going to uh open this up and so in the first video which I'm about to hit record and do the things I'm going to cover are how to install the library um uh what the different kind what the different um versions of the connect are the hardware the different editions and which ones work which ones don't work maybe they all work uh and then the basic functionality of the connect in terms of the pieces of the things the RGB image the infrared image the depth image the raw depth data and um excuse me the uh registered image which is only part of the connect version 2 so that's what I'm going to cover in the first video section and then in the second one I'll probably do some type of visualization of the depth data something like that okay um so it's your last chance to ask a question in the chat oh a lot of you might be interested I just um uh was reminded um that there is something called the key motion or the kimotion or the K motion k i m o t i o n which is a library framework uh for using the connect with um p5js which is another programming environment that I make a lot of video lessons about so don't know if I'm going to get to that today honestly because I haven't had the chance to like really like get it set up and running myself but I definitely you know I imagine this to be a new playlist about the connect I'm going to do raw depth I'm going to do skeleton tracking with the Microsoft SDK I'm going to do using probably this key motion thing for p5js because lots of other people are making stuff and I hope to be able to mention those things and and help people get started with those things as well okay uh here we go in three two one something like that I need like I I need somebody to like be behind the camera going in three two except nobody's there I'm just doing that for myself uh my nose is running but it'll be fine Okay click the mouse mouse goes live and hello okay wait wait wait wait I I like lost track of what I was doing hello this is the first video in a series of videos about using the Microsoft Connect in your own software and the software I'm going to use is this thing called processing uh eventually I will also get to looking at how you might use the Microsoft Connect with p5js in the browser but the first uh this I got to start over too longwinded too longwinded I've been looking too much at my like YouTube analytics and see how like people are watching they whole drop off when I start to ramble at the beginning of a video but I really should care about that I'm way into into my own inside my own head too much I'm just going to make this video hello this is the first video in a series of videos I'm making about the Microsoft Connect this thing so what is this thing how does it work and how do you write your own software that makes use of this thing how can you do all sorts of creative coding projects now there's a lot of different programming languages and environments and Frameworks and libraries for how you might make use the connect um I'm going to use this thing called processing processing 3 the Third Edition version of processing uh which is a Java based programming environment open source uh environment um that there is a connect several different connect libraries for uh eventually I will hope to make a video where I look at p5js which is a JavaScript framework uh for doing creative coding in the browser and how might you get the the stuff from the connect what is this thing called The Connect in the browser itself which I think will be an exciting thing to see as well um but in this first video what I want to do I'm going to get into the code really in the next video and what I want to do in this video is give you an overview so what are the different uh editions of the connect there's a bunch of different ones that you could buy what are the pieces that you need how do you get the library to make use of the connect that sort of stuff and you can see I have a basic example that's running behind me with the connect version two and I will talk through the pieces of this code so first let's think about the different versions of the connect so this is this one here I need reading glass I'm going to this one is the 14 model 1414 this one is the and I'm going to I'm going to come over here and try not to trip over to myself um and I got to grab this uh eraser for a second um so let's make a list here so the the two key pieces of information for you are you need to decide are you using the connect version one or the connect version two I'm probably going to get lots of stuff wrong here that you can write in the comments and I'll put little annotations on the YouTube video that fix them but hopefully I'll get things Loosely right so the original connect version one model 1414 is the one that came out I think it was November 2011 12 somewhere around there I remember the weekend it came out people people were quote unquote hacking it but really just making but by hacking it I mean making open source drivers to to read the data driver being a thing that your computer runs to talk to the hardware device um and so when that came out uh a library I worked on a library called open connect for processing and the reason why it's called Uh open connect is because it's making use of the open connect an open connect an open source uh driver for for uh connecting to the connect which is also known as a lib Free Net so this is sort of the Genesis of all of this um the thing that I built for processing is just a thin layer on top of work that lots and lots of other people did which allows you to get the data from the connect now let's come back to the connect like what is this over here and then I'll get i'll get to the other additions in a second like what is this thing so this is the original connect and you can see here that there are three little circles on here it's like a little nice little friend with three eyeballs and what do each of these eyeballs do so one of them them if we oh camera oh oh shift menu I suck at making these videos okay I'm just I'm going to go anyway okay so this is the connect uh uh um and it has three little eyeballs one of which is an infrared projector so this is this is what the 144 does and I'll talk a little bit about any a different marker here what happens once you get to the connect version two how that works differently um it has an infrared projector which sends out infrared light into the room then it has what I would call you know you could call it a sensor a camera but it has an infrared camera to read the infrared light that's in the in the room what is infrared light it's you know light that's all around us but is invisible somebody with a Physics degree could explain that better but this is blasting out infrared light this infrared camera is reading it so what what is the value of doing this so the interesting thing is the kind of light that it's passing out is actually a whole lot of infrared dots it's projecting a lot of infrared dots into the room that look like this and it's a very specific pattern of dots and the connect itself it knows what that pattern of dots is supposed to look like so if that pattern of dots if I have the connect here it's blasting the infrared light lands on a flat surface the infrared camera that's reading where those dots landed that's seeing those dots reflecting back is going to see like oh it matches exactly the pattern of dots that I know that's a flat surface but if this surface was curved those dots will appear distorted by analyzing that Distortion the connect can recognize what things are closer and what things are further away so the value of this is it uh is often referred to you can think of it as a depth camera or a depth sensor this is what this infrared projector and infrared camera are doing they're measuring the depth in of of each pixel in the room so while a regular web camera says here's a 640x480 image each pixel has a red green and blue value and it's beautiful isn't it the colors of the rainbow are there in this image um The Connect is saying I see I don't see RGB what I see is I see a pixel and instead of telling you what color that pixel is I'm going to tell you how far is that pixel away from the sensor and this is incredibly valuable in computer vision you know one of the classic computer vision problems that people try to solve is background removal you know that's why I have this oh green screen oh I have to go underneath this here okay I have an obstacle course in my office I'm going underneath this to turn this camera back on and I'm coming back underneath here I have this hello I have this um I have this green screen here behind me that you can see um and so the the uh camera is saying every Green pixel remove it and put the stuff from the computer behind it but if I had to connect I don't have to say look for the green pixels behind me I could just say look for any pixel that's farther than 2 ft or or some amount of centimeters I'm trying to be a metric I'm trying to be metric I want to be a metric person but I'm not um so uh you could remove you could you could analyze things it makes it really easy to find a human being in the room because a human being has a certain kind of shape it makes it really easy to do quick and dirty 3D scanning there's lots and lots of possibilities of what you can do once you have access to the depth now there was this third little eye here and this by the way is just an RGB camera so one of the things the connect can also do is just see the colors in the room so in addition to having this infrared camera it has an RGB camera now there's a bit of a problem here which is that notice how both of these things are not in the same place so the infrared camera sees the depth of a given pixel at a different place that the RGB camera sees that color so this is an alignment problem a calibration problem where the the color pixels don't necessarily line up exactly with the depth pixels and there are lots of strategies for solving this problem uh and lots of Frameworks and libraries in particular the official Microsoft SDK which has um things baked into it that do this for you but one of the nice things that we'll see once we get to the connect V version two is it has something called a registered image which is an image that aligns the depth pixels with the color pixels okay so this is what the connect does and I really described here what the connect version one does there was also a model 1473 that came out I don't know a year or two later um this one has some problems in particular there's a little bit of a bug uh with currently with running it with the processing Library although it does work kind of only will work every other time can't figure it out for the life of me um so but both of these will work with the library what you need to look for in the library is the version one examples so that's now in between here there was like this connect for Windows and I think this was like a version of The Connect that the Microsoft made to plug into like Windows computers originally this was designed for use with the Xbox for a game for games that you would play by you know dancing I'm kicking my leg by the way if you can't see that um and uh um but you know then Microsoft realized there's I don't know what mic what's in Microsoft has but I'm speculating here but that to make a version that's designed to work with just regular old laptops and computers um I'm not sure if this one works with the processing library but more recently and I I I have this one plugged in and like mounted on the wall over there so I can't hold it up and show it to you the connect version two is a newer and quite significant upgrade from the first connect um and it actually uses a completely different technique it's uses infrared light but it uses a technique called time of flight so it sends the infrared light out measures how long it takes for it to bounce back and that how long that takes uh lets the sensor know how far away things are kind of like a bat maybe does stuff with sound to see I don't know you dolphins do stuff like that but all with sound so with light bouncing it back and forth um the new connect does that and I suppose it's a bit more accurate it's faster uh and uh the RGB camera is also in the new connect is higher resolution okay so that's the basics overview and if I come back over here you can see now now I'm running an example have the connect right over here you can't see it I could I could maybe like turn like kind of like if I hold it up over here can there you go there it is this is the new one I'm G to put it back that felt like a little scary like everything was going to fall over um and you can see now that uh what you're seeing in this particular image is an example of a processing sketch which is rendering all of the pieces of what the library what the connect offers now oh I but I have something more to mention about this but I'll get to that in a second so up top you can see that's just the RGB image so it's like I have a webcam over here I have a webcam over here hi webcam hey that sort of thing right so that's the webcam uh that's that's the RGB camera and it's actually I believe I didn't actually check but it's a it's pretty high resolution image um down below this is the Raw Feed of what the infrared camera is seeing so this is what the infrared camera is seeing and it uses that to extrapolate depth so mostly it just looks like this creepy thing but you can make use of that you can get that image as well um up top up the top right this is what's known as the depth image so the what the connect is measuring is in millimeters it's measuring uh a value between 0 and 4500 how far is the thing away from the camera and then often a depth image is used to visualize that data so in this case you can see as I start to go further and further back I get brighter as I start to come closer and closer I get darker so it's mapping the uh theor color of every pixel to how far away it is and you can see just from a standpoint now how much easier that might be to pick out my hand right because my hand is the only thing that has this very very dark color uh as opposed to other things now there is something funny in the back what's up there above oh that's a window I like what's that Black square up there that's a window that's the door you can seeing all sorts of things inside inside this room that you may not have seen before and then down in the bottom right this is the registered image so this is not part of if you use the version one connect with the open connect Library this is not part of that however uh with version two this is the image that aligns all of the RGB values from the webcam with the depth values so if you wanted to hopefully something I might be able to demonstrate at some video is just do background removal where you see only me and I take I get rid of all the pixels that are behind me um that might be something that I could do here with with that particular image oh did the oh the laptop went to sleep come back or wake up okay so uh couple more things so what I want to show you now is how do you get this library to run this like this particular example so a couple things one is here's the I'll put all this in the in the description of the video this is the URL the the uh library is at github.com shiftman open connect for processing you don't need to go to that URL but that's where the source code is there's a little bit of documentation there I want to make give a big thank you to Thomas sanche as lenling I I might not have pronounced his last name correctly he wrote all the code for making this Library work with the connect version two so I worked on the version one a number of years ago and sort of floundered and Thomas came back and revived this and really helped uh over the summer um and there is also I have a little a page that has some additional documentation it's shiffman Donnet p5c connect and you know this is some text that kind of goes through uh the different versions uh and some of these examples as well that I'm going to cover in the videos now in order to get the actual Library itself what you need to do is go to uh one you know first you need to download processing if you don't have that already that's at processing.org then what you'll need to do is once you have processing uh it might look just like this to you something empty you're going to go to sketch import Library add library now you can see that I have already you know I have three libraries here I already have that library but I'm going to pretend that I don't for a second I'm going to go to add Library which opens up up this contributions manager I can type in Connect right here and this is something really quite important now to bring up so there are several different libraries there is by the way something called Simple openni which is an older library openni was an open source platform open source framework for doing skeleton tracking meaning finding the human form where the hands are where the head is which is very very powerful and things that you can do with the connect I'm starting with just the raw depth data um but open and I think was purchased by Apple and then kind of like shut down as an open thing but there are some efforts to revive it and so uh you could Google around and that's something that you could possibly use I'll try to include some links but you can see that it's currently this simple open eye it's no longer compatible with processing three that's why it's gray out connect V2 for processing this is a library that makes use of the Microsoft official SDK and I'm going to demonstrate that using a PC in a later video um this is a key uh this is a really a great thing to use if you want to get all of the magic that Microsoft has spent all this time developing so what the connect just gives you is raw depth data raw RGB data but what the Microsoft SDK does is it pulls that data in and on and it analyzes it and finds where's the human being like what kind of muscle are they making like where is their head like is their hand open or closed and it's so much a sort of a layer of analysis on the raw def data that will give you a ton of information so but for that you do need to use a Windows machine of course there are some strategies for like sending the data from a Windows machine to another machine through like a websocket what's a websocket all sorts of stuff but we'll come to that in a later video um and uh so those would be the two libraries that but the library I'm using today which you know is already installed you can see by the green check mark you would just need to click it and uh click this install button and it would download and install um that this is the library I'm using today it uses opensource drivers it only looks at the raw depth data so this is good for a bunch of different kind of creative applications that I hope to show you in the next set of videos so this was a long rambling 16minute explanation about the connect that you may or may not have found useful or interesting but I imagine you already turned it off if you didn't and in the next video what I will demonstrate is is just how to write a program that gets that depth image and once it uh I bring that back oh it's not running here get gets that depth image and maybe visualizes that depth image in some way so that's where we'll start and then I'll look at a couple other scenarios along the way as well okay and so thanks for being here and watching and talk to you soon okay everybody uh uh all right did that could people hear me through all that and that worked and everything I don't know what's going I feel like a little lost here um all right I'm looking to see if there are any questions uh um some people are asking things from various place I would like to sing a coding Rainbow theme okay uh uh the white line on his shirt there's a there's a is there something transparent on my shirt oh there's a green it's not white this is a I wore this because this is a shirt that I have that has a rainbow on it and this this line right here is green so it's transparent because the it's picking up the green screen behind me okay um glad that was helpful okay so now what I'm going to do I think maybe what I'm going to do right now you guys is I'm going to try building a little example uh and like the practice and then I'm going to do the video where I build the example again so I'm going to do it now with a little less like personality whatever that means um and you can it's uh ask any questions if you want um so I think the first thing to do would be to actually just look at the depth image and then like take each pixel and map its Z location according to its depth so let me go and grab um ex uh open recent uh this one and I'm going to say um depth dep depth image viz so I'm going to make a sketch that's 640 by 480 uh I'm I'm going to just do this uh so I'm just looking at the depth and I'm going to say p image so I'm I'm I'm going to explain all this when I make the video but I'm just sort of trying out to make see if this this example makes any sense uh and then I'm going to say 4 int xals z x is less than image. width uh x++ for in y = z y is less than image. height y ++ I have a syntax error here uh and then can you guys read this font size okay should I make it bigger uh and then going to take out all this stuff uh and then I'm going to um say int off uh index = x + y * image. width and um color or like uh depth equals uh the brightness of image. pixels at index maybe I'm going to turn off the code completion oh no I want that oh I don't know I'll leave it it's fine uh and um then I'm going to uh I'm going to have a variable called like w is 10 uh oh maybe I call this Skip and that's kind of useful skip uh plus equals Skip and then I'm going to draw I'm just going to draw a rectangle at X comma y uh Skip Skip and I'm going to say fill D and uh I just want to see if this works whoa I'm missing a semicolon uh so I just want I'm just trying to like make it a grid here um what did I miss ah image. load pixels image. load pixels oops I have a capital I there uh oh I totally someone's asking a really good question I totally should have mentioned that in the video you do not need to install any extra drivers or anything it just works um the idea is the library just works um right out of the box yeah so most of the time when you're working with the connect you got to install all this other stuff maybe I'll like I don't know I'll have to put that in an annotation in the video because that was like kind of a big thing that I missed there I should just remake that one but it was too long okay what did I miss here array index bounds array oh X Plus y times width okay okay so you can see great so this is the first thing that I wanted to do which was just and why oh you know what it isn't 640 by 480 what is it uh I forget what's the connect version two with I guess uh it's actually a little bit lower resolution it's uh um uh I forget what it is somebody might know image. width image. height uh come on Console how come I'm not seeing anything in the console don't I have a print line there oh yeah 512 by 424 I forgot about that 512 424 so this is working you can see I'm getting so I just wanted to do something first really quick where I kind of make this grid like lower resolution grid because then what I can do is translate each one of those into 3D based on the brightness and I I'm pretty confident that I can do that in the video so um I think what I'm going to do dare I just delete all this code because I'm going to write it again from scratch in the particular video all right that's what I'm going to do delete okay so I'm going to just make a simp simple video where I look at looping through all the depth pixels and doing something with them uh any questions 512 by 400 thank you thank you for um for pointing out the errors uh wow I've got good I've got a great number of live people today that's wonderful okay so um and then I'll do one where I look at the raw depth data I think so I want to look at the difference between the color data and the Raw depth data um but I think I'll just I'm going to try to do these small little chunks okay here we go um I'm ready let me let me cycle these cameras and um I'm going to erase this diagram I'm over here right now by the way people um erase this cuz I probably need to do a quick pixel diagram uh for this video especially if people haven't worked with pixel processing before and um and now I'm ready okay uh here we go uh got my weird seethrough tshirt I can see the G like like that's like hole in my body it's disturbing okay um the okay so the same exact Library will work with the connect version one as well and the techniques would be the same I just happen to be demonstrating it with the connect version two thinking that that would be a little bit more current okay so um U stop here I I wish there was um okay that's fine and uh okay so I think I can make this a little bit smaller I can minimize the browser here sorry I'm just getting my window all set up uh this one I can close and I'm going to close this and then go open ah come on uh this one great and U make the console a little bit bigger there we go I think we're good what about the font size I feel like it needs to be a little bit bigger it's looking a little smaller to me that's a little bit better right okay um here we go ah the sun is coming sunlight is here today excellent hello in this video I'm going to look at how you can get the depth image from the connect in processing and what you might do with that so this is a very very very first step I have a completely blank sort of like set of code here I just filled a little bit in there in advance but I'm going to write this program from scratch in this video so uh if you didn't watch the prev hello in this video I'm going to look at how you get access to the depth image from the Microsoft Connect in processing and how you write some code to do some stuff with those pixels with that depth image so if you missed the previous video that's where I talked about the connect in general about um how you install the processing Library one thing I did miss which I think is important to mention is that you do not need to install anything else if you're on Mac OS X um so uh the library just uh works it comes with all the libf free neck stuff sort of packaged inside of it uh I believe on Windows there might be one other thing you have to install uh well I should really look this up right now ah crap I'm going to make this I don't want to get this wrong in the video Let's look this up uh here uh connect V2 uh for Windows 8 you have to install some uh this driver um which I'll mention for the V2 okay going do this one more time uh okay here we go hello in this video I'm going to look at how you can uh work with the depth image from the Microsoft Connect in processing I'm going to I need my prop I need my prop I swear this is the last time I'm doing this I just feel like having the prop will be good it's stuck underneath the table help it's funny how I've left my phone on Periscope is still like streaming an index card I don't know if there's anybody there okay uh okay I swear this is the last time I'm making this video now come come some hello I have a prop in this video I'm going to look at how do you use this I'm going to actually look at the code for using this Microsoft Connect in processing using the open connect for processing library now uh one thing I want to mention it that I did not mention in the previous videoos that is if you install the open connect for processing Library you need nothing else whatsoever it just works with the connect there is one exception on Windows 8 with the connect version two you do need to install an extra dri libus I will put that in the description below um but so this is the connect version one model 1414 it would work with this example but I'm going to show you instead I have the connect version two over here and you can see the only code that I filled in so far is having a variable called connect 2 so if you're using the connect version one the only thing you would change this code would work mostly identically um is just say connect uh instead of connect two so it's not connect one and connect two it's just connect and connect two I'm pretty sure about that if I get that wrong somebody will correct me um okay so uh let's look at how you get started so I filled in a little bit of code but the only things that you need really to get started are an import statement at the top that import statement is saying hey I'm here to use this Library uh you need to declare a variable that's variable is going to like hold all the information about this connect that you are using so it's the thing that you're going to create and I create it by saying new connect to this now there is a way to use multiple connects to use a version one and a version two to specify which connect you want to use that's beyond the scope of what I'm doing here in this video I'm only going to look at you just have one connect connected to one connect connected to your computer it's the default one all you need to do is say equals new connect to this so once you've got that going what is the next step well you need to decide what it is you want to do and in this example all I want to do is use the depth image so I'm going to say init depth so the connect uh the connect doesn't the library doesn't start all of the feeds automatically it's not going to start getting the infrared image the raw depth the depth image the video image it's only going to start using what you ask for so in this case I want to say init depth and then I also want to say uh init device which will kind of get things going and by the way this is where if I had multiple devices I could put an argument in there say init device zero one or two that type of thing so once I have that I'm ready to go and I can run this program and we will see nothing nothing on the screen so but a lot of stuff like spit out here which is kind of promising device firmware serial the library is going to like put a lot of stuff in the console which is um some basic information that you can see if it's working it will say like no nothing connected uh if you if you if you don't have it um connected I realized some other things I forgot in the first video but that's okay okay so uh what's the next thing that you want to do so let's just make sure things are working one of the things the connect gives you is that depth image because I said and it depth so in nit depth there are two ways I can look at the depth I can look at the raw depth values with the connect version two these are numbers between 0 and 4500 with the connect version one these are numbers between 0 and 248 U these relate to millimeter measurements um but what I want is get depth image and you can see I what I'm you doing here is I'm asking the connect to give me this depth image and store it in a variable called image and now what I can do is just draw that image on the screen to make sure things are working so we can see here and there it is so there is the depth image you can see I've got it and now it's on the screen so this is the goal of the library it's pretty easy to work with in terms of just getting the data so let's think about what you might want to do so I think most almost all of the uh almost everything that you would do where you're working with the raw depth data or with the depth image involves iterating over all the pixels you want to look at all the pixels and see which ones are the ones that are closest you want to look at all the pixels and see what's the highest point of the closest thing or you want to look at all the pixels and say what's the sort of topology of the entire thing so all of those statements I said involved look at all the pixels so before I get to doing anything here let's talk about what it means to look look at all look at all the pixels so this is something that I've covered in some other videos a whole set of videos about just image processing um from you know jpegs pngs webcams that sort of thing you could refer back to those I'll I'll make sure I link to those at this moment in the video um but just to remind you if you have an image whether it's a depth image or an RGB image that image is a grid of pixels and we typically as human beings look at this as a thing that's twodimensional and it has a bunch of columns and it has a bunch of rows and usually we think of the columns as the X values and the rows as the Y values so you might think of this as like the columns numbered like there's five columns numbered 0 through four and there's uh four columns numbered 0 through three and so if I were over here this is pixel 3 comma one so this is how uh I think of pixels and images and this is the this image over here this depth image is a big grid of pixels columns and rows the thing that you have to remember when working with stuff like this is that the computer is actually storing all of those depth values all of those brightness depth values in this singular onedimensional array 0 1 2 3 4 5 6 7 8 9 Etc and those numbers correspond like this the counting goes across comes down here uh comes down here comes down here so you can see I've got 20 pixels because I've got a five 5 by 4 grid 5 * 4 is 20 the pixels are numbers 0 through 19 so what we need is a methodology for if we're thinking of the XY how do I convert that to the location that's in this onedimensional array the index into that onedimensional array and the formula for doing that is x + y * width and you can see how that works because if I look at this column index two over here 2 + 5 is 7 7 + 5 is 12 12 + 5 is 17 so the width to finds those numbers as they go sort of down row by row by row so if I say 3 + 1 * 5 that's 3 + 5 which is 8 and you can see that's eight right here so this is the formula that you're going to have to get used to because what I'm going to add is Loops I'm going to say Loop through every column and loop through every row row to look at every spot in this depth array so if I come back over here we can now add that to our code so for example I can say right here for every X from zero to and I'm going to say image. width uh not I and I'm going to say four every Y and again if this this idea of a nested Loop is confusing to you I would refer back to some previous videos about image processing but what we can see what I would like you to see here is how this is the loop to say I want to look at every single depth pixel so it could be I want to search for the closest one or I want to search for the for the the furthest away one right or I want to just visualize every pixel in threedimensional space so for every X from zero to the width for every y from zero to the height and now what I could do is say what is that index how to apply that formula now x + y * image. width and then the color is is the color that's in that pixel even though it's a depth value it's turned into a grayscale color is the image. pixels at that index so this is now a loop that you will see in just about all the examples I intend to make today where I'm looking at every single Pixel and finding its index into the depth the the into that depth image and pulling out the color that's there so what might I do with that I could make a point in threedimensional space Let's do let's okay let's do something thing here let's turn what we're seeing on the screen let me run this let's turn this into a lower resolution grid so let's look what I'm going to change this program to do right now is just look at every 10 pixels or every 20 pixels and draw a rectangle with that particular uh color there so let's do that real quick and I'm going to say so what one thing I'm going to do is I'm going to change this to uh brightness I'm just going to look at the um I'm going to look at the brightness of that pixel which is just a single value between 0 and 255 and I want to draw a rectangle at XY now I'm going up by one pixel so what I want to do and you'll see this in some of my examples is I want to introduce a variable called Skip and I'll say skip equals 20 because that's how many pixels I'm going to skip instead of looking at every single Pixel right now I'm going to look at every 20 pixels um and EV then I'm going to draw a rectangle at every 20 pixels and I'm going to fill that rectangle with that particular color so if we run this we should see exactly what I had before but just it's much lower resolution so that you can see I'm still looking at all of the pixels finding its color uh uh from the from the pixel array and then drawing a rectangle of some size arbitary size 20 at that spot so you can see as I move around in front of the connect you can see my hands here and you can start to see like ah this is the kind of thing that computer visionwise it might be easy to pick out my hands as the sort of singular blobs the rectangle but by through a translation because ultimately I want to translate along the threedimensional axis so I use push Matrix and pop Matrix to save and restore um that transformation State these might be Concepts that are unfamiliar to you I will refer you to a different video about Transformations but you can see I have the same exact thing here so instead of drawing the rectangle at XY I've now translated to XY and drawn the rectangle at 0 why am I doing this because now I could add something I could add a z here so the first thing I might try is just say okay well what is this Z let's make this Z equal to brightness and you can see here what do we got we've got as I uh it's kind of hard to see but you can see some uh some rectangles are further in front than other ones that are further away so the brighter ones are closer and the darker ones are further back this isn't really this isn't really doing me any good because actually I think what might make more sense is to have the Clos closer ones be more forward and the further ones way be more behind so I want to essentially position all these rectangles about where they actually are in physical space and so to do that I might do the map use the map function right because we know the brightness has a range between 0 and 255 but what I want is to now have a z value this zv value that's coming out of the screen I want things that are dark to appear close and things that are bright to appear far away so maybe I'll have the things that are looking at their brightness value and mapping it now the truth of the matter is if if I was really doing this what I probably would want to do is actually just look at that raw depth data if I'm trying to visualize the data in 3D this is not exactly the quote unquote correct way of doing it so that's what I'm going to show you in the next video how instead of using the depth image how you might make use of the raw depth data those numbers which are between zero and 4500 okay thanks for watching and I'll maybe see you in the next video okay uh okay um um so is the is it in the in Connect I'm seeing some in the chat I wonder if with the connect version one it's not in it device which is something that I'm learning right now let's go let me open up one of the examples for The Connect version one uh yeah I don't think you actually need the init device for The Connect version one I'm looking at the example right now the the init depth and init video stuff just turns it on um so I think you don't need that function um let me open that uh I'm looking in the chat to see if there are any more the depth range is different I believe between the two models I believe the second version has like a longer depth range um yeah uh okay so that wasn't my best work uh okay so I'm trying to think I'm going to trying to think of what would be most useful to do next um I said I was going to look at the raw depth data um so I think will and then maybe with the raw depth data I'm going to do a thresholding thing where I'm going to uh only show you pixels between certain distances and in that sense I'm going to get just the human form I wonder if I should do that in um Advance who's coming to get me Victor um okay uh I'm trying to think of what else I might be missing um uh uh yeah okay um all right um okay sorry everybody I'm I'm spaced out for a second everybody doing okay Sirens oh yes the sirens are coming to get me thank you uh okay so let's go on to the next topic what I'm going to do is open recent so I think I'm just gonna not going to build this one from scratch this one I have ready in advance which is just doing the point Cloud why did this break had this working a second ago um oh something's already running that's why um um yeah so this is a more accurate way of doing the um the the thing that I did in the previous one um so I think I will show this example which uses the raw depth data and then I'm going to use that to um to do some sort of thresholding as well so I will change this into something else uh okay I think my live stream is like way behind me um like 10 minutes behind um but who knows okay I better get on to the next topic uh so let me close this one okay um okay Point Cloud uh uh sorry everybody I'm just getting this ready that's funny because the X and the Y okay hold on I'm doing something here okay okay this is going to do and I'm going to have that go a lot slower okay sorry I'm ready for the next video let me cycle the cameras and drink a little water my phone battery must have died by now let me see where the okay here we go everybody um s over I need a little I need a little energy boost here should have gotten more coffee this morning okay hello in this video I want to look at look I want to hello in this video but that hello was like a little bit creepy hello in this video I plan and hope and I'm excited to look at the raw depth data meaning not the depth image not the depth values um converted to a grayscale image but actually the raw depth data that's coming out of the connect itself so again with the version two connect you're getting numbers between 0 and 4500 with the version one connect you're getting numbers between 0 and 2 48 and to demonstrate this what I have over here is a simple processing sketch that's drawing a whole lot of dots on a plane in threedimensional space and that plane is rotating rather slowly so what I want to do is and this is what's known as a point Cloud I want to take every point on this plane and give it its actual physical reals space no wait wait wait let me say that again okay the connect is seeing all these points I am all these points in a room and the connect is seeing me and I want to move these points around but this is like the weirdest thing I've ever had to explain and it's like the it's like totally simple and it would just make sense if I just showed it to you yet I insist on trying to explain it in this weird way but I want to take all the points that the connects are seeing in this physical threedimensional space where I am and I want to move these virtual dots which are on the screen in this virtual 3D space and that's known as a point Cloud this is how you might start to build a 3D model of what the connect is seeing in the space so the the the the key difference here uh so one thing that I had before in the previous video is we were looking at this pixelbased image right this idea of each image each pixel of the depth image has a value between 0 and 255 and it's a brightness value based on how far or close it is now the information is stored in exactly the same way inside of this a big array um but uh instead the numbers are between 0 and 4500 so how do we work with these numbers so let's come over here and uh going to do a couple things in this video but this first point Cloud example I mostly have the code already so you can see here that what I'm doing is looping through the connects width and height again I'm skipping because I don't need to do every single point I don't need to do all the points just to visually get this effect um and then I'm finding the offset off set into that array so x + y * connect to.wi so that's how I'm going to look up into that big array of all those depth values now what is that array that array is called is I get that array by saying connect 2 dot get raw depth so when I said get depth image that gives me a p image object with pixel values all in it now I just get a big integer array again those integers are between zero and 4500 so they're in that array and I can say the depth is uh I already use the depth is the offset into that array now there's something else going on now in this function what it's doing is there's a function here called depth to point Cloud position xyd X is the pixel X Y is the pixel y d is the depth that the connect is seeing there's sort of there's a strange thing that's happening which is that the pixel we we look at all these these uh pixels in a grid and we get this raw depth value but the connect itself um there's some math involved in how that can actually converted to real measurements in physical space like where is the actual X where's the actual y based on like how the camera is seeing it so in order to do that this particular example has just this function which essentially you want to download these examples and copy this verbatim um but this function is using all of these kind of uh par parameters that are built into the hardware itself so these are like a whole set of numbers and values that are just part of the connect calibration and you kind of multiply and divide by these numbers and you get the actual value of where it is in space sort of an interesting problem I would love to like go through it at some point but right now I'm sort of inclined to sort of skip it and say the interesting thing is what you're getting is if you give the raw depth value the pixel X and the pixel Y and use that function you're going to get the X Y and depth values in millimeters back of where those things are in physical space so I don't want to in fact draw the this is what you're seeing in this particular visualization right now is just all of these pixels at their exact XY and XY value with a zero depth so what I want to do is change this program to say this actual physical point this P Vector the P Vector is an object that has an x a y and a z i want to draw the vertex at point dox point doy and now point point doz and in order to make this a little bit better I'm going to skip fewer pixels I'm going to skip only four and I'm going to run this again and now you'll see here I am this is the point Cloud this is me in threedimensional space so if I zoom in on this you can start to see like what's going on this over here by the way is the wall it's funny how I can like put my hands on the wall it's almost as if I'm distorting the wall but really what I'm doing is I'm casting a shadow um so it's a little bit strange to see this view of me and my connect I could like no I would give myself a hug that's a little bit weird too I was like punching is weird hugging anything that you do I don't know just scratch all that but you can see here this is now a visualization in threedimensional space you could connect these points with lines you could color them there's a way of actually getting the RGB values and so you could see like the colors that are on my shirt on these points as well this is a road you could go down and I find this road to be particularly interesting but what uh and uh you can see that I'm I'm using just a simple y rotation so now I'm kind of like spinning around this image which is now gone off screen um but if I zoom back in you can sort of see it's over there um so this is kind of the start of sort of thinking of like what can you do with these raw depth values I think what would be a useful demonstration now is to look at how might I actually pick out just me so you can visually see just me but there's a sort of Nest there's like all this stuff over here there's this over here um there's actually like this pole over here that's being picked up by the connect so what I you know what if I just wanted to like even only get my hand right here what I want to do is try to calibrate a threshold so what if I want the connect only to see the connect's over here remember so it's it's to the left of me I don't know what what side that is you're viewing but what if I want to say only look at the pixels in between here and here and that would conceivably get my hand right how would I do that how would I look only look at the pixels between a certain minimum and a certain maximum let's look at that so one thing I'm going to do is I'm going to save this as um I know what to call this min max threshold um and I'm going to get rid of all this 3D stuff for right now uh because I'm not going to do this with you could do this with visualizing the point Cloud still but I'm going to do this with just uh and I'm going to look at all the pixels so I want to do x++ and Y ++ and somebody remind me what's the size 4 512 484 is that right I don't know if that's right um and so hopefully that's right and then what I want to do is I don't need end shape I don't need I don't need begin shape I don't need any of this stuff what I want to do again and I don't need this depth to point Cloud thing I'm taking all of that out because what I want to do right now is just go through this double nested Loop and look at every depth value 0 and 4500 but I only want to like count the ones that are between 200 and 400 or between 500 and 800 what is that what's that minimum and what's that maximum threshold okay let's make this happen so the first thing that I should do probably is uh I would like to make myself just to be able to see this I'm going to make myself an image and I'm going to create a blank image which is the same as the width and height of the connect uh and it's an RGB image so this is a function in processing create image that just makes a blank image and then uh whoops and then what I'm going to do right now is I am going to in here I'm going to right here I'm going to say image. load pixels because I want to operate I need to operate on the pixels of that image I'm going to set pixels in that image based on the raw depth and the end I'm going to need to say image. update pixels and I'm also then going to want to draw that image so just to make sure that things are working what I'm going to do is right here inside sorry this is where all of the important code needs to happen right now it needs to happen right here inside this double Loop right for every X for every y I want to set a pixel in the image image. pixels index offset equals and I'm I'm just going to set it to be you know some color right now some purplish color and run this and we should see that that's working U okay so you can see this purplish color I clearly got the size of the window wrong let me just let me just get that for you guys really quick so if I go back and look at my RGB depth test um ah this isn't telling me Oh actually you know what let's just be smart about this um I want to just know what those values are I'm going to print out I'm going to print out the the the depth width and the depth height really quickly uh we can look in the console 512 424 I knew I had some was close so let me just get that right now and I I don't need this much of the console here and I can get back to the important part of the code we can run this we can see okay purple so I have now filled every pixel on the screen with purple but what I want to do is fill every pixel on the screen based on the depth so for example what if I were to just say if d is greater than 300 and D is less than 1500 image. pixels offset uh is that otherwise image. pixels offset is black so what I'm doing is I'm saying only if the only if the distance is between 300 and 1500 let me see a purple color otherwise let me see a black color and when I run this we should see oh my God I can't believe what I guessed I'm like a genius here I somehow guessed a pretty reasonable uh threshold so you can see here that now what I've done and now you see like all computer vision problems Melt Away in a way like uh what I could do now is like it's so easy to find the I mean not easy but it's much easier now to find the Contours I have this problem of this wall over here so how do I get rid of this wall well first of all the real way that I get rid of that wall is by not doing my connect stuff right next to a wall so unfortunately this is like a bad I need a better setup I think for doing these videos which someday maybe I will find but what I want to do let's at least see if I can get the hands so one thing you'll notice here is that the hands go away once you're about a foot and a half from the connect so what I really want is between about I don't know between zero and maybe like 500 so there's probably a better way for me to calibrate this than just randomly picking numbers but let's give this a try you can see nothing nothing nothing nothing nothing nothing nothing nothing nothing oh that didn't do much any good so so let's uh uh so I you know I whoops that's not going to do me any good either uh let's do between like 200 and a th000 nothing you can see uh like right but if I come in theit so you can see here how like I'm able to pick out only my hand uh again I've got this problem with the wall so I'm going to do something about that in a second uh to maybe try to like just like not look at the pixels on this side of the window I guess um but you can see how you I'm starting to find this idea of a minimum and a maximum threshold and really I should make these variables so I'm going to say A Min thresh is 200 and Max thresh is 1,000 and you know I might as well make these floats because what could be also useful I think the way to I could calibrate this right here's a great way I could calibrate this so in between the minimum threshold and the maximum threshold what I might do is up here I might say Min threshold equals map the mouse's x value which goes between zero and width to between 0 and 4500 uh and the maximum threshold I'm going to do Y which between 0 and height 0 and 4500 and then I'm just going to print out those values I could draw them on the screen which would probably be let's draw them on the screen so then down here I'm going to just fill 255 text size uh 32 two uh text Min thresh plus oh I got to use um double quotes Max thresh you know 10 comma 64 so here we should see on the screen these values so now what I need to do is figure out like what's a good uh whoops wait X is going between I'm doing I'm lost what I'm doing something is wrong here uh Mouse X between oh this is Max thresh yeah that's a problem uh okay so now you can see I'm able to like calibrate the minimum threshold and let's calibrate the maximum threshold like how far back am I seeing but the minimum needs to be higher and then I don't want to see too far back so there we go so this I feel like is good if I'm getting my hand right now it's between about 480 and 827 so let's like only if I'm standing right here of course but you know you could design an interactive exhibit where you put some footprints on the floor and the person has to stand there so I'm now going to keep my hand boy this is a long video I'm at 15 minutes I'm going to keep my hand around here I'm going to make the minimum and maximum 480 and 830 so now I can comment these lines of code out and I'm going to say uh 480 and 830 and I'm going to run this again and we can see I'm kind of I'm getting my hand like really I'm getting a pretty good tracking of my hand so one thing that I'm going to do now of course which I think would be useful is try to get rid of this wall over here so you know the wall is a bit of a problem but I can kind of uh do a little bit of a cheat here I think which is also to say if and and X is greater than I don't know what how many pixels do you think that was that was probably about uh 75 pixels so uh maybe it's a little bit more so I'm just like not allowing me to measure anything that's like 100 pixels over so you can see I kind of got rid of that wall and now I have my hand so this is great you can see like this really nice clean outline of my hand because this is my other hand coming in it's not inside until it gets there right it's outside of that maximum threshold and now it's inside of that minimum threshold it's funny how it like oh no my arm is coming in so of course if my whole body comes in now you can see my whole body is here which is another thing that I want to look at so um you can see how this minimum and maximum threshold is working pretty well so I think this is this wraps up this video I'm going to continue this exact example you could try this on your own as an exercise before you get to the next video how would I actually just find the center of my hand so I could control a processing sketch Now by moving my hand around or moving this hand around or what if I do both hands so how would I do that this is I feel like I'm like I'm some sort of like magic person here um so that's what I'm going to look at in the next video how do I find the center of my hand and control something else like a little like snake that's moving around the screen or make a particle system come out of my hand we'll look at that in the next video and another thing I want to look at is how would I find the top of my head so if I'm the human being here how do I know if I'm bending down or standing up okay so we'll look at that in the next video thanks for sticking with me here I think this is actually starting to come together okay all right chat is anybody there um okay how is the hand Edge drawn in black um okay 424 you guys are telling me in the chat you're so nice uh boy the the live stream is like way behind me I think oh no I've DVR I'm I'm like I'm behind okay I don't need to sorry I'm how's everybody doing uh I got to refresh this page that's my problem oh no I just need to be here ah no wonder I'm in the wrong place uh sorry everybody um I gotta close this come back here there is 23 people watching um uh hi Sean uh welcome everyone I'm about to do in the next video I'm going to demonstrate how to find the center of my hand so and then I'll make a particle system come out of it which I think will be loads of fun for every all the family it's a family holiday family edition of the coding rainbow today and Thanksgiving uh I'm going to drink a little water here um I got to cycle the cameras okay um so I'm just about ready I'm seeing if there's um somebody asked when do you think you can upload the videos uh I will most likely upload the videos uh by the end of the day today tonight um or certainly tomorrow morning guess I'm going to do it as soon as I can uh and if they're not there you can always twe but this will always be there um this will automatically be archived and on YouTube this like a long thing but the so far I've made two three videos they're each about 15 minutes those will be uploaded tonight I don't so many Sean's asking if anyone ordered me pizza yet first of all I don't eat dairy so don't order me a pizza a little like you know vegan tofu quinoa salad things is like more in my speed um but don't order me any food I'm fine I ate a big breakfast I'm feeling good I got to probably this Thanksgiving thing is going to happen tomorrow and I'm going to have to eat this like giant meal uh so don't worry about me I'm fine uh um okay uh what was I going to say I don't remember I think I'm ready for the next video okay so in this next one what I'm going to do is look at how to find the center of my hand right we did this thresholding here and now I'm going to find the center of my hand and let me get a particle system example open it's probably overkill for me to bring that in but it's uh I'm let's let's do it it's totally worth it uh so I'm g go under topics simulate a simple particle system I'm going to change something here really quick about this particular example um uh I really wish I didn't make the example the way that I made it uh uh yeah what did I oh add particle H shf man okay let's see if this works okay so I'm going to make this these particles come out of my hand as I move that's going to be fantastic okay that's going to be the next example yeah yeah read only read only shme only okay so I'm going to go back to minmax threshold and here we go I'm going to hit run here uh and I'm ready to do this video uh thanks for sticking around both XP goodbye Cardiff England uh Wales which is part of the UK and whatever I my geography is off sorry okay here we go ready uh did I cycle the cameras did any remember if I did that I don't remember so I'm going to do that uh let's see oh I'm running low on battery for the microphones but I think I've got a full bar and I've got three bars on the one in my pocket so it should be okay try to keep an eye on that and over here if I stand about here that's where the hands are okay great okay here we go in three I'm going to close this in three I have to press the button there's nobody here to press the button but me hello um in this video I'm going to demonstrate some really basic basic hand tracking with the with the connect and I'm going to make a particle system come out of my hand that's what we're going to look at in this particular video so in the previous video what I did is create this sketch where I calibrated a minimum threshold and a maximum threshold so I'm only looking at depth pixels between those values so if I stand exactly here and move my hand around I can you can kind of see a pretty clean outline of my hand of course this breaks down if I stand too close or if I stand too far away but you know and so I should mention that ultimately this type of of hand tracking might be better suited for the official Microsoft SDK and I'll get to that eventually using a PC and different uh uh processing connect library but I think it's still nice to see these examples of how you can do this stuff with the raw depth okay so let's look at how you might do this so this is where we are we're looking for all pixels that are in between a minimum threshold and a maximum threshold so how might I find the center of all of those pixels right here in the center of my hand well the way that you find the center of something off sometimes called the centroid if you want to sound like you're from the future let's look at the centroid um is by finding the average location so let's say we have a collection of pixels you know that are Loosely this is some strange like threefingered hand right these are all the pixels we care about we can plainly see that this is the scent about around the center but how would I find out the average well let's say you just had these X values this is the x value zero three uh you know 4 8 12 to find the average of some numbers add them all together and then divide by the total 0 + 3 + 4+ 8 + 12 divided by 1 2 3 4 five divid five is the average so if we add up all add all x's and we add all y's and we divide by total pixel not the total pixels in the entire image just the pixels that we've picked out that are in between this minimum and maximum threshold then we'll find the center of that area of pixels so let's look at that how do we inside that Loop add up all the X's add up all the Y's divide by the total number of pixels it's actually a pretty simple thing to do this might be the shortest video I've ever made um I'm going to start I need some value to keep track of the the sum of all the X pixels so I'll add that in then I need another variable to keep track of uh summing up all the Y pixels so I'll add that in then what I also need is a just a total pixels zero now I'm making all these floats because I think it's going to be a bit more accurate to use floating Point math doesn't really matter they're they're technically the they're integers there's no like pixel 3.21 but it's a little simpler to work with floats so this value is where I'm going to add up all the X's this value is we're going to add up all the Y's this is going to be the total number of pixels remember that's not a fixed number like depending on where my hand is how many pixels is it picking up that's um that's going to be the total once I have that I can divide some X by total some y by total and that's going to be average X and average y so let's look at that so right here these are the pixels that count right these pixels right here are the ones that are pink those are the ones that are between the minimum maximum threshold that X is greater than 100 was just to get rid of the wall that's over here because the wall is 100 pixels and over um so in order to do that now I'm going to say right in here I'm going to say sum X Plus equal x sum y plus equal y like I'm literally just adding up all the X's adding up all the Y's and then total pixels plus plus so for every single Pixel just add one I need to add up the X values for the X the Y values for the Y and then figure out how many pixels are there and then at the end what do I got I've I don't need to um draw this text on the screen anymore what do I need to say I need to say the average X right the average X is the sum x divided by the total pixels the average Y is some y divided by total pixels and then now why don't I just draw let's make this a different color why don't I draw an ellipse at average X average Y and 100 um I don't know what what size should that ellipse be 64 by 64 so let's run this con that says add particle Mouse X Mouse y right so it's just as easy now as bringing all this particle system code over and saying instead of adding the particles at Mouse X Mouse y add them at average X average y so uh let's see if we can make that happen I'm going to bring I'm going to do a quick little I should have probably do like the cooking show thing where I have an now coming out of the oven I already premade this but I'm just going to copy paste everything over real quickly I'm going to bring the particle system object I'm going to put this in my setup over here and I'm going to put this stuff in draw and at the end here and then what do I need I need all this particle code so I don't actually need this camera prams tab for this example uh oh hold on uh uh hand tracking sort of particles I don't know what to call this uh I'm going to get rid of this uh tab C camera prams uh and then I'm going to add a new tab I really shouldn't be doing this in the video I think I crashed processing hold on no everything's fine I'm gonna add a new tab called this was not this was not good you fast forward fast forward a minute I'm gonna move the particle system over that was the particle class and I'm GNA duke it doesn't matter I'm to move the particle over just imagine that I did that correctly I'm going to run this which we can see right the particles the the circle is following my hand the particles are following the mouse how do I make those do the same exact thing now all I need to do is say make the particles not at the mouse but at average X average Y and you know what let's let's actually add about 10 particles per frame to make it kind of make more particles and let's run this and we can see now as I put my hand here I can like control where the particle I can make this like fiery thing come out of my it's not fiery but come out of my hand so you can see I'm now using my hand to control particles coming out I can do my dance and it you know works with anything like I can I can have part like this stuff like emanating from my it's like alien and like bursting out or something I don't this is all getting a little bit weird but you can see I can I can strike this pose and uh it's running kind of slow because I'm drawing like so many circles on the screen um it was a little bit unnecessary to like do that much but you can see anyway so I can make the particles move faster you can you can get where this is going here so this is one example of what you can do by having a kind of specific setup knowing where all the pixels are thresholding them finding the center of something um this is what you can do now let me say a couple more things before I go into the next scenario number one uh um and let's um let's turn the particles off for a second number one is we have this issue of one hand two hands the thing in the center on the one hand this is kind of cool I'm like I am a magician levitating a ball around I I forgot that I was making a video for a second on one hand that's sort of an effect on its own feature not a bug type thing on the other hand you might actually want to have a circle for each hand and in that sense you need to employ a more sophisticated blob detection mechanism for example you don't want just the average of all of the pixels you want the average of a bunch of pixels but don't include pixels that are over a certain distance threshold from other ones so this is something that I could potentially demonstrate in a future video in this series I'd be happy to add one in but also in this case one thing you can do if you have this very clean image you can pass it to a library that might do that type of edge detection blob detection Contour detection for you and there's two libraries I'll try to link to them in the description that I might recommend one is called blob detection does kind of what you're thinking another library is called open CV which has a lot of computer vision functionality built to it but one of the things in it is blob detection so maybe I'll try to like show that at a certain point but you can see the basic idea here is still just working even without uh an extra sophisticated layer of looking for separate chunks um okay thanks for watching this I think in the next video I have two more that I intended to do today although it is 1210 I wanted to see if I could look at for the top like how do you find the highest pixel um or Theo you know closest pixel is something you could also find but I think highest might be interesting because uh somebody here at ITP has a project that she's working on which is uh having somebody move up and down so I think that's a useful demonstration and then also maybe looking back at that grid again um but averaging all of the depth points within cells of a grid okay that's what I intend to make next I'm G to hit stop on the record button uh come on wake up okay everyone uh all right everyone yeah I see some are chatting about me in the Stream it is true actually I didn't actually code start programming until 2001 I was 27 years old 2001 you can figure out how old I am now I did take some programming classes in middle school middle uh Assembly Language and basic uh I also took an evening C++ Course once because I thought it might be interesting in programming and I was like this didn't like it uh but then I think being in a creative environment like ITP I got kind of obsessed with it so that is true uh um okay so uh I forgot when my I have to check when my office hours are because I have to go soon unfortunately I have to grab something to eat before let me just I'm looking this up right now uh they start at uh shiffman shiffman shiffman where's shiffman uh at one I I'm not going to give the time okay yeah 120 I need to take a break obviously to eat something between them so so I think I could manage a little bit more because I want to do I think I could try to do these two examples real quick um so let's look at the um yeah there's a problem where I need to file the open CV is not showing up in processing 3 but it actually works in processing 3 it probably just needs a few little fixes um uh I I would love to I uh Greg Borstein who did a tremendous amount of work creating this Library um I should look at it and see if I can uh just put a pull request quickly on GitHub to or to make sure that it shows up uh in processing 3 because it does work in processing 3 there's probably just a few little things that need to be fixed um okay I'm going to I'm going to get a little more water I'm going out into the hallway and I'll be right back okay are you watching this from here okay you were sorry thanks Sean okay okay I'm back everybody uh I'm going to just get a little cool air in here for a second um I'm going to turn off and on the cameras Oh I have to go around this side okay uh let's see here I'm over here I'm going to erase so the next video that I'm going to make here oh wow there's quite a glare from the sunshine over here wonder if I write over here if you can't see it yeah you can't see that very well so I'll just be conscientious of that I I just can't bear to like black out the window in this room it's I did that last year and it's like miserable to be in here so much rather have the sun infecting me uh let's see okay this is pretty good um okay so in this next video the next thing that I'm going to do is look for the closest point or the top of someone's head uh the highest point that type of thing um which is a kind of common algorithm in computer vision that you need uh uh oh yeah right there was a hot mic again uh and um okay and I'm going to um um here we go I got to close the window I'm going to try to I'm going to try to do this by the way for 15 more minutes I don't know if I can get through both of these topics in 15 more minutes um and then I have to go uh I guess I've been doing this for 1 hour and 36 minutes so far okay here we go uh water's here and getting myself ready I I cycled the cameras didn't I just do that right I can't remember do it again I'm going to check the battery is at one bar still so my mic shouldn't go out in the middle of this okay hello um in this video I'm going to look at how you might using the connect fine the closest thing in the room or the highest thing in the room um this type of algorithm is kind of common in a lot of computer vision applications I think which involves similar hi um in this video I want to look at an algorithm that lets you do the kinds of things like find the closest thing in the room or find I'm doing all sorts of like Vogue poses find the highest thing in the room I don't know why I need to do that for the highest thing but whatever um or uh and this is a similar type of algorithm if you've ever looked at like a color tracking algorithm find the brightest thing or find the most red thing in the room I like to refer to this as like the world record algorithm which means like I've got to look at every single Pixel and keep track of which pixel is the record holder and hold on to that record holder the closest thing the highest thing the most red thing and when I get to the end have that XY coordinate that I can use for something else so a lot of things that you might do with the raw depth data of the connect could involve this like if you know the person is always standing like this in a fencing pose what is where is their hand because their hand is always the closest thing or if you want to determine if a person is moving up and down how do you find the top of their head what's the highest thing within a given threshold so let me uh go over to the Whiteboard for a second to just talk in generally speaking about how this kind of algorithm works and then we'll go and implement it in a couple different scenarios okay so as with just about everything that involves IM and pixels or depth points you've got this grid right and the grid has a bunch of x's and a bunch of y's and there's always this Loop all the examples have this for every X for every I look at every pixel now I've got some glare here so hopefully you're going to be able to see what I'm writing but I was to to say shout at me just shout at your computer screen or wherever you're watching this and I will hopefully hear you someday um if you can't read what I'm about to write but uh but so the way that this works is you need to find the record holder so what let's say we wanted to find the um uh the closest thing so remember the depth values are between 0 and 4500 so we could start by saying the initial record right the world record for the closest thing would be 4500 because that's the furthest back so any pixel that beats 4500 is the is by definition the new record holder so we have to say something like if I have the current depth in a variable I need to say if that depth is less than the record then the record is now that depth so this is the core algorithm for every pixel is the first one beating the record it is that's the record holder is the next one beating that record no is the next one beating that record no is the next one beating that record yes okay that's the record holder and while we're doing this we could also keep track of you know the record X and the record y so if we went every time we get that new record we store that X and Y so that by the time we get to the end of this Loop in those variables are the X and Y that win this record so let's look at how we might do that um and I will come over here and let's look at let's do um okay let me save this I kind of want to do the closest thing this what we talked about but you'll see that it's not going to work in the most perfect way but let me save this as uh a closest uh thing and I'm going to um I just want to delete the particle system tabs which are no longer relevant uh oops don't delete that tab ah I think I made a mistake earlier and I'm going to get rid of all this particle system stuff sorry I should have done this before I started recording this but it's too late now um we can get rid of all this particle system stuff and and I'm going to get rid of the average thing that was interesting that we were doing in the previous video um and even such I'm going to keep this I'm going to keep this thresholding in here because I think that's maybe a little bit useful um to kind of keep at the moment actually you know what I'm going to take that thresholding out but I'm going to keep this x is greater than 100 and uh what I would like to do is H too much too much going on that I didn't think to do in advance it's okay everything's fine just you know Talk Amongst yourselves for a minute or fast forward like 30 seconds in this video and I will be at the point so I just want to take out all this stuff let's keep the um uh and uh yeah this is fine uh what I ah I know what I need to do everything's fine uh I'm going to draw I don't need this image anymore uh right what I'm going to do is what I want to have access to to look at sorry everybody is the um the raw depth image I'm not sorry the depth image as well so I'm going to call this the D image equals connect to.get depth uh image so that way I can draw that image on the screen and so let's just make sure this is now working so you can see okay I've got the depth image on the screen so what I want to do now is look look for the pixel that is the closest okay and we've got a bit of a problem here because some of these there's a window back there and it's going to give me some weird zero values so I think this this might not work oh and I should have kept the thresholding crap I should really you know what I'm GNA I'm going to hit stop on the recorder for a second and I'm going to just uh Stitch these Stitch This Together from when I move from over here over here ah crap I I wasn't thinking straight there okay I'm pausing for a second uh all right um so let let me let me figure this out here closest let's just see how this works I'm going to build this I'm going to pause the video I don't I I should have checked this in advance I'm going to close this so what I'm doing now I'm going to come back and record again in a second what I'm doing here is and I can delete all this stuff I'm need that threshold again in a second what I'm doing here is um looking for okay okay so I need the uh record is 4500 and the record X is zero and the record y uh record Y is zero and I'm going to say uh if D is less than record then record equals D Record xal X record yal Y and I need to close curly bracket and then at the end of all this looping I can say uh draw an ellipse at record X record y that is some size that's kind of big uh and let's see how this goes okay so you can see the problem is that it's always in the top left U it's a good thing so what I should probably okay so one thing that I was going to do right is Skip uh skip these pixels uh let's try this and let's see can I get it to be something problem is there's too much glare and reflection back there so I should do the top I should just do oh I I as I got over here something became closer than what's back there my head oh yeah I'm kind of able to get this to work if I come really close but not it doesn't work so great because I really should be there we go why is it if I move I must have messed something up record yals y record xals x no that's right um what I probably I probably should do the top of the head thing why is it not it's interesting how so I think this is a bad demonstration I um which is a mostly because of the setup I have here like if I had if I had the connect over here and had this flat wall behind me it would work pretty well um I could look for the thing that's closest within a minimum Max maximum threshold which is probably I should have kept that um but I think what I might do is put the threshold back in and look for the I should put the threshold back in so let me bring that back uh I still have that here so I want to say if uh so let's bring the threshold back in if so I only want to consider stuff that's if D is greater than Min thresh and D is less than Max thresh and um X is greater than 100 I think is what I had then then I can look for the record uh thresh so this should right now this is working you can see how much it jumps around but you can see it works with anything that's within that threshold that's closest which right now if I bend down is also my head but course as I move out of the threshold so you can see how like unstable this is but I think that could sort of do the demonstration I actually want now also to have that image back now uh which is that I should say um uh what I should be doing is uh I think this would be hold on I you're kind all to stay uh set the initial record to the highest possible didn't I do that um so what I want to do is put that that um the uh image back in too so uh image that load pixels so I'm going to say um uh image dot here let me turn off I'm going to turn off the code completion uh else else uh image. pixels uh offset equals D image. pixels offset and I'm going to here say uh image. pixels offset equals uh color uh 2550 150 and then uh this should be a different color uh so I oh and then I need to draw that image also let's see up whoa hello connect that is the weirdest thing I've ever seen what just happened there whoa what is going on oh some other imag is there whoa what is going on oh I didn't say image. update pixels must be why there we go so I should see like when the stuff is within the threshold I'm finding the closest thing within the threshold um which might be like my elbow uh that sort of thing maybe that minimum threshold should be actually like lower anyway um okay so sorry okay I'm gonna I'm going to I'm gonna start this over and I'm going to start it I'm going to take this out and I'm going to take this out this is the stuff that I'm going to add in and I'm going to take this out so now what it should be I've just got something where it's showing the only the threshold of pixels but also all the rest of them and then I I really want to do the top of the head thing because I think that might actually work much more accurately um to find the highest pixel that's within the threshold but I'll do the closest and then the top why not right okay um so I now have to pretend where was I I was over here and I was talking about this stuff and then I finished and went over to the computer to talk about something else so I'm going to do that again shoot this is going to be this is definitely going to be uh whoops this is definitely going to be um come back come back this is definitely going to be it for today once I get through these two examples because I really I'm I'm like sort of late now we have 45 minutes till my first appointment I need to eat something in between so but I I want to I want to get through this so to have this done okay so here we go I think I can do this now um with this particular example uh so I'm gonna have to like cut this somehow I I I hate it when I do editing this is I'm not really going to do editing I'm just going to splice these things together and I'm going to uh pretend okay so I'm going to walk into the scene over here I'm afraid am I recording this I am yes okay okay so to demonstrate this example now what I have is I've I've adjusted this example a little bit and what it's doing now is it's showing you both the depth image as well as coloring particular pixels of that depth image this pink color that are within this threshold so now I need to figure out what pixel in that threshold is perhaps a record holder of some sort of record so we'll look at the closest thing and also the highest thing and I'm pretty sure the closest thing is going to not work that well but the highest thing I'm hoping is going to work pretty well so let's do the thing that's not going to work as well first um and let's just look at a little bit of what's changed in the code just to to show you so first of all I'm looking at the depth image as well and then what I'm doing is if the pixel if this um depth value is in the the threshold I'm setting that particular color to this pink value if or purple value I don't know what color it is I can't tell uh if it's not um then I'm just pulling the color value from the depth image itself then updating the pixels and drawing the depth image so that is why you are seeing this particular result it's essentially what I had earlier in the previous examples with just also adding in those depth pixels instead of black so now we need to figure out this way of a getting a record holder so the first thing we need to do is say what at the beginning what's the record distance I'm looking for the thing that's closest so the thing that's closest the record to start would be something really really high so the record would be 4500 that's as far as it as something is possible to be from the connect then I need the record X which will be at zero and the record Y which will be at zero so I want to test every pixel X and Y if it beats the record if it does beat the record set RX to that new X and set r y to New Y and then draw a circle at that record value at the end so right here I'm going to check only inside the threshold you know in a different scenario where I had the connect in like an open space and a and a sort of flat wall and people just came into the middle I don't wouldn't really need to do this thresholding thing because I but there's so much stuff in this room there's a desk there's a computer there's a wall that it's not so I think using the threshold here helps it be a little bit more accurate so I can say if that distance is less than the record then the new record is that particular distance right for every single Pixel does that pixel beat the record if it does I've got a new record and if it beats the record then I need to save that particular X and Y in RX and r y so all we need to do this kind of record algorithm is a starting record a starting RX and r y and then every time we beat that record save those two values and then at the end I can draw a circle at RX and r y and I'll just make that Circle uh White uh so it kind of we pick it up and we can see now okay now first of all you can see that circle is just jumping around that's because first of all there's very little there's like stray pixels that are that are making it in the threshold so now you can see that it's kind of working now you can see that white circle is following my hand now notice this is much less accurate than what I did before with a sort of average section of pixels um mostly because anytime you're looking for a single Pixel it's not such a great thing I kind of want to find a group of pixels that are like beating that record but that aside you can see the basic idea is working but it's really like if I come and stand in here like there's a lot of me that's in the threshold but my head as I'm bending over is closer so you can see if I move my hands out they're a little bit closer if my shoulder comes in my shoulder is the closest thing so you can see it's jumping around a lot but it's always finding the particular pixel that is closest it's just sort of demonstrating the idea but let's change it now let's have it find I'm going to stand here to I've beaten that record so record equals that y value save this save the X and the Y and then draw it so the same exact idea I'm just changing what the test is like the height is the yv value if it's less than that record so now we'll run this and we can see it's picking up a lot of noise but if I come in and bend down so there's too many pixels up top you can see that it's flickering there's too many pixels up top that are pulling up some sort of value so I'm going to try to do like a little bit of a hack here again we're going to say and I'm say let's skip uh let's skip the first like 50 pixels I'm only going to look and let's see if this helps there we go so now you can see I'm getting the top of my head pretty accurately if I move my hand up here I'm getting the top of my hand so if I had a particular uh project that wanted to have something move based on whether I'm moving up and down this is good I'm going do some X squats here um you can see that this works so you know I had to sort of like Cal and do some goofy things but you can see this is a very simple way of just finding the top so like people always get obsessed with like finger tracking like let me find the finger but you can see how accurate this is I'm just getting like the tip of my finger now there's no finger tracking here just like if I go like this it's getting the top of my elbow but if you tell people to stand like this and wave their finger you can see how like kind of super accurate that tracking is just from looking this is like the simplest thing ever I'm just looking for the top pixel inside this threshold so hopefully this shows you a few types of things you can can do uh we've seen a range of things of just sort of visualizing the 3D data from like looking for thresholding it in between for tracking the the height of something the average location um this is where I'm finishing this video set today um but there will be some more ones I guess who knows when you're watching this the more ones might already exist the more ones and you'll see them in the next video okay so thanks for watching uh this how oh yeah right uh and I will uh talk to you soon okay goodbye all right everybody um so that's it for today um and uh so if you have any questions I can take questions for like maybe five minutes it's 1236 and I'm going to go in about five minutes um and uh I can take questions and um then I'll go sorry my brain is like totally fried this has been an hour and 58 minutes that I've been on this live stream um so I'll give it a minute to see if anybody wants to ask anything uh uh whoops um see if anybody is um okay uh any important info here um uh okay let's see if anybody ask any questions uh any tips on using more than one connect uh what you want to do if you want to use more than one connect is uh go look at the examples uh in the examples I'm going to come back up here under contributed exam uh oh oh no no contributed libraries under open connect um so this one here multiconnect version this one is showing you actually how to use more than one connect and even a connect version one and a connect version two in the same sketch and here under connect one multiconnect and here in Connect for multiconnect 2 so for example if I just come to multiconnect 2 you can see here um that you can create uh two different connect objects and then init them as init device zero and init device one which will make them separate so you can actually everything works exactly the same way it's pretty simple to be able to do that yeah uh what is the update rate of connect depth data I'm pretty sure it's 60 frames per second but kind of I don't actually know uh I bet you if you Google that there'll be an answer on stack Overflow or something I would love to know the answer to that for sure I I I seem to remember hearing 60 frames per second I don't know that the first version one connect was that but I think the new one is um okay oh yes sorry so okay great so I this is technically how you could have more than one connect hooked up to your computer but you do have certain issues with like you point them at each other the infrared light starts to interfere with each other so trial and error is your best friend here sometimes it just seems to work anyway sometimes it can be a problem if you have a lot of the sunlight it can interfere you can't put a mirror in the room because the mirror is can to reflect all the light so there's a lot of issues around that but um you know for the most part you can have two connects you know if they're pointed in different directions and the infrared stuff doesn't cross they'll definitely work if they do cross I feel like with the new version too they seem to like operate on different frequencies or something and it kind of still works anyway but i'm to be honest I I haven't you know done a lot of stuff with the connect I'm kind of just trying to teach it from like making examples but I haven't with the new connect I haven't really like made a lot of projects with it um okay 2 hours is generally my limit uh I hope next week I've got a real schedule problem but I hope to be back to do at least one day next week but it might not happen but I'm going to be doing these uh in January I might even do these live streams twice a week I'm hoping and then in February I'm going to be doing them a lot is my plan so um so but uh keep in touch ask questions over Twitter put uh comments and questions the YouTube videos is super helpful especially if I mention something that I forgot to put in the description or I could put an annotation in that corrects something that's great so please keep in touch let me know hope this is helpful and I will see you guys soon I'm going to hit stop on this stream
