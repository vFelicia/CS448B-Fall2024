With timestamps:

00:00 - hello welcome to a coding challenge in
00:04 - this coding challenge I am going to it's
00:05 - gonna sound really weird solve X or with
00:08 - a neural network now why would anyone
00:11 - want to do this why would I want to do
00:12 - this well what this is actually this is
00:15 - a video in which I am going to test a
00:17 - neural network library I've been
00:19 - building in JavaScript and in fact if
00:22 - you want to follow along with that
00:24 - process of building it there is a giant
00:27 - playlist here starting with 10.1
00:30 - introduction to neural networks and I
00:31 - start building that library actually
00:33 - around play the video around 10.4 so
00:38 - this video is a standalone video where
00:41 - I'm going to make use of that library in
00:43 - a coding challenge you don't have to
00:46 - have watched all those but if you want
00:48 - the background with a bit more to go
00:49 - deeper in how the internal mechanics of
00:51 - this neural network that I'm going to
00:52 - use works I would refer you to those
00:54 - videos now what is this crazy weird
00:56 - visualization going on over here
00:58 - so let's I'm going to come back to in a
01:01 - second but let's come over to the
01:02 - whiteboard so this is an example a very
01:05 - beginning basic rather trivial example
01:07 - of machine learning and what do I mean
01:09 - by that I mean I'm going to draw a
01:12 - circle here
01:12 - and I'm going to write ml short for
01:15 - machine learning you can think of this
01:17 - as a place where there exists some
01:20 - machine learning recipe some algorithm
01:22 - you might have heard of K nearest
01:24 - neighbor or neural network
01:26 - fill-in-the-blank support vector
01:28 - machines so fill in the blank with your
01:29 - machine learning algorithm there with a
01:32 - machine learning algorithm something
01:33 - goes into it data how you collect your
01:38 - data how you're thoughtful about that
01:40 - what the data is how you call them quote
01:42 - normalize your data there's so many
01:44 - questions
01:45 - ethical questions scientific questions
01:47 - that go into this piece I am not
01:49 - covering that B's in this video but
01:51 - there needs to be some data something
01:53 - that I want to analyze or learn with
01:56 - that's the data portion then that data
02:00 - goes into the magical machine learning
02:02 - recipe and out comes some output now
02:08 - what that output could be it could be a
02:10 - piece of music that I've generated it
02:12 - could be a classification
02:13 - of an image it could be the price of a
02:16 - house that I'm trying to predict based
02:18 - on some data so there's so much
02:19 - possibility here and this output doesn't
02:22 - have to be a single thing but can be
02:24 - multiple things the input obviously the
02:26 - data can be multiple things this is the
02:29 - idea of machine learning now
02:31 - I spent all this time building what is
02:33 - mostly like a toy neural network library
02:36 - it's written JavaScript there's nothing
02:37 - about it that's optimized but just to
02:39 - kind of understand the pieces of how it
02:40 - works so what I want to do is have my
02:42 - recipe be in there be a neural network
02:44 - and I want to create some scenario where
02:50 - I have some training Dana
02:52 - so what I'm going to do this is going to
02:54 - be a demonstration also of the machine
02:55 - learning process called supervised
02:57 - learning supervised learning meaning I
03:03 - am the supervisor and I am going to
03:05 - teach this machine learning recipe to
03:07 - produce output that appropriate output
03:11 - for a given inputs now what well if I
03:15 - just know all the answers why would I
03:17 - even do this well likely there's a
03:19 - scenario machine learning is gonna be
03:22 - used with a scenario where I have a lot
03:23 - of labeled data I have a known data set
03:26 - that I can use to train this system so
03:28 - that if I give it some unknown data it
03:31 - will give me out cut to give me an
03:33 - output a relevant output the classic
03:35 - example of this of course is I have a
03:36 - whole bunch of images here's a bunch of
03:38 - cats here's a bunch of dogs now here's a
03:41 - new image which one is it and along with
03:45 - this process we will typically have
03:47 - training data this is labeled data for
03:51 - which we know the answer we will have
03:54 - testing data this is data that we know
03:58 - the labels for but we aren't using in
04:00 - the training set so that we can see is
04:02 - it working this does it actually give us
04:04 - good we're good outcomes with unknown
04:06 - data and then of course we have the
04:08 - actual unknown new data that we want to
04:11 - use okay so what's the scenario that I'm
04:14 - going to use the trivial realms rather
04:16 - ridiculous example that I'm going to use
04:19 - in this video is the X or a
04:23 - or stands for exclusive or it's a
04:26 - boolean operation that resolves to true
04:28 - only if so you can think of true and if
04:32 - true X or true is actually false I
04:37 - didn't finish my sentence it resolves to
04:39 - true only if one of the two boolean
04:47 - expressions value is true so false X or
04:52 - false also is false and if you go back
04:55 - to my video that's linked here about the
04:58 - perceptron the lib you'll see that this
05:01 - is this is a special problem because a
05:04 - single simple perceptron a single neuron
05:07 - machine learning system cannot solve
05:09 - this problem it is not linearly
05:11 - separable the solution space is not a
05:14 - space where you can just draw a line and
05:16 - see all the categories of one on one
05:18 - side and all the categories of the other
05:20 - on the other side so you can dive into
05:21 - that deeper but this is where a neural
05:24 - network that involves a hidden layer can
05:26 - be used as the machine learning recipe
05:29 - so what I mean by this is I need my
05:32 - training set my training set is going to
05:35 - be 0 0 0 1 1 0 1 1 I'll have 4 elements
05:47 - in my training set and each one of these
05:48 - is labeled this is labeled with a 0 this
05:52 - is labeled with a 1 this is labeled with
05:56 - a 1 and this is labeled with a 0 this is
05:59 - the known data right again this is a
06:02 - sort of trivial you know I could build
06:04 - you could build a circuit right imagine
06:06 - what it would take to build a circuit
06:09 - with two switches and the led only
06:11 - lights up if one switches on they're
06:13 - both on it doesn't light up if they're
06:14 - both off it doesn't light up think about
06:16 - how you might build that that's
06:17 - essentially going that that diagram of
06:20 - that circuit is essentially what we want
06:22 - the neural network to look like so the
06:24 - way that it's going to look and let me
06:27 - erase this here is we can see here in my
06:33 - labeled data set that there are two
06:36 - inputs and one output so the neural
06:40 - network structure has to have two inputs
06:42 - and one output I'm going to send in X 1
06:45 - and X 2 these are true and true true and
06:49 - false false or true and somehow out of
06:51 - this I should get a y I should get a
06:53 - true or false so how you architect and
06:58 - structural a neural network system this
07:00 - is something that I've gone into much
07:01 - more depth in the other videos but the
07:03 - key to this problem is having what's
07:05 - known as a hidden layer so the inputs
07:07 - come in here I want to look at the
07:08 - output here but these neurons are going
07:11 - to exist in between so everything this
07:14 - is also it's known as a fully connected
07:16 - Network so as the inputs come here they
07:20 - both go into this hidden layer some math
07:22 - happens this is the math that I go over
07:24 - in a previous video it has to do with
07:25 - multiplying by weights these are all
07:28 - weighted connections then the then those
07:31 - go into this output layer and we get the
07:33 - answer and then there is a training
07:35 - process we say try it with this so what
07:38 - internally in the training process what
07:39 - it does is if I give it zero zero with a
07:42 - zero and it outputs a 1 it's like I tell
07:44 - it hey you got that wrong adjust all
07:46 - those weights to try to see if you could
07:48 - get it more correct so we're gonna do is
07:51 - over and over again to Train it to see
07:53 - if we can then later we don't have a
07:55 - separate training and testing set in
07:57 - this scenario we're just going to say
07:58 - I'm gonna train it and see if you can
08:00 - start producing the correct answers for
08:02 - all of these numbers okay that's the
08:04 - background for XOR now I'm actually
08:06 - going to go and write the code to do all
08:08 - of this it works ok so you might recall
08:13 - that I started the video I had this
08:14 - thing up here so this is actually an
08:17 - example that I made in the processing
08:18 - Java based programming environment I
08:20 - probably like almost eight years ago at
08:23 - this point so it's not using the same
08:24 - code base but it's actually solved the
08:27 - XOR problem and what's interesting about
08:29 - this and I'm gonna I'm gonna come back
08:31 - to the white board just for one more
08:32 - moment here we find some room here if I
08:35 - draw a plane and I consider this to be 0
08:39 - 0 and this to be 1 1 so this is 1 comma
08:43 - 0 and this is 0 comma 1 right notice
08:48 - that if I take this idea of
08:50 - ex-or and map it to here I've got false
08:53 - here false here true here and true here
08:57 - and by the way that what I read r1 there
08:59 - to here and true here this by the way is
09:02 - why it's not linearly separable you
09:04 - can't draw a line I can draw two lines
09:06 - like this or I can draw two lines like
09:08 - this and you're gonna see that result
09:10 - happen actually as I start to program
09:12 - this I hope if it works but what this
09:15 - this idea of a plane this is a plane
09:17 - that's describing the whole solution
09:19 - space for the problem and if you come
09:21 - back over here you'll see look at that
09:23 - those corners if I bring this over
09:25 - closer to me I can try to point to it
09:27 - these corners are the true corners
09:30 - anymore practice and these corners are
09:32 - the false corners and this plane is all
09:36 - the other solutions now this is a 3d
09:38 - rendering it soon some fancy stuff I'm
09:39 - gonna create a simpler version of this
09:41 - so let's just actually start doing that
09:45 - so what you're going to need first of
09:48 - all is if you're writing this code along
09:50 - with me you're going to need to have the
09:52 - toy neural network j/s library it has
09:55 - really just two files that you need it
09:57 - has neural network J s and n n dot J's
10:00 - and matrix such as you could ignore this
10:02 - this is for testing that's something I
10:04 - cover in some other videos that you
10:05 - could probably find and you'll see that
10:09 - in my index of HTML file
10:12 - I am referencing those two JavaScript
10:14 - files I've got like a weird path thing
10:15 - going on but when I published the code
10:18 - I'll publish that all as one one thing
10:20 - okay so now I need to go over to sketch
10:23 - KS let's do some stuff here let's write
10:27 - a setup function let's write a draw
10:29 - function let's say let I'm gonna have a
10:34 - neural network variable I'm going to say
10:36 - create canvas 400 400 let's draw a
10:40 - background of 0 and let's let's go to
10:43 - the browser and see there we go there it
10:46 - is
10:47 - step 1 now what I want to do is create a
10:51 - neural network and I've written out how
10:54 - I want to create it I want two inputs
10:57 - two hidden neurons and one output so the
11:01 - neural network library the toy library
11:03 - that I've built
11:04 - expects those as arguments to the
11:06 - constructor so I guess a neural network
11:08 - equals a new neural network with two
11:12 - inputs two hidden neurons and one output
11:15 - neuron now I should mention that modern
11:18 - so-called deep learning systems often
11:20 - have many many many hidden layers
11:22 - hundreds of hidden nodes big massive
11:26 - networks this is a very small simple one
11:28 - the library only supports networks with
11:31 - these two layers the input did well if
11:33 - you consider the input you could say
11:34 - three but really these were the layers
11:36 - the hidden in the output plus the inputs
11:38 - three things okay now what do I do I
11:43 - need my training data so I'm gonna say
11:45 - let training equal and I want to have it
11:48 - be in an array and each element of the
11:51 - array I want it to be an object and it's
11:53 - gonna have the inputs which would be
11:57 - like this and the outputs now even
11:58 - though I only have one output right one
12:00 - output outputs can be an array they're
12:03 - also referred to as a vector so a list
12:05 - of numbers but in this case 0 0 gives me
12:08 - just a single up or I'd have single
12:10 - outputs when I put the array the library
12:12 - expects an array so I have that inputs
12:14 - out 0 0 I have 0 1 and 0 0 gives me a 0
12:18 - not a one I have 0 1 which gives me a 1
12:22 - I have 1 0 which gives me a 1 and then I
12:25 - also have what's the last one 1 1 which
12:30 - should give me a 0 so this is my
12:34 - training data now ordinarily this data
12:36 - might be in a spreadsheet it might come
12:37 - from an API it might be in a JSON file
12:40 - but I'm just hard coding the training
12:42 - data directly into my program just to
12:45 - demonstrate the idea now what do I want
12:49 - to do well in the draw function what I
12:52 - want to do is and now if you're look at
12:56 - how machine learning algorithms work
12:57 - typically you'll see something called
12:59 - you'll have a batch training process
13:01 - where you give it a large batch of data
13:03 - and then you adjust then you adjust the
13:05 - weights and do the training and then
13:07 - another batch I'm gonna do everything
13:08 - just one at a time and the way I'm going
13:10 - to do that is with a function called
13:12 - train that's in
13:13 - the in the neural network library so if
13:16 - I say neural network trained this
13:20 - expects two arguments what it expects to
13:24 - say train the neural network with this
13:26 - input and this expected output and so
13:29 - the easy thing here that I could do is I
13:31 - could what it what it should look like
13:33 - is something like this train it with 0 0
13:35 - and with 1 oh right so this is what I'm
13:41 - saying these inputs should produce this
13:43 - output train yourself on that but I have
13:46 - so I have that all stored in an array
13:47 - what I'm gonna do is I'm going to say
13:50 - data equals random training and what did
13:54 - I call that up here I called it training
13:57 - I just called the training let's call it
13:58 - training underscore data training
14:03 - underscore data so the random function
14:05 - in p5 will pull a random element from
14:08 - that array and it will put it here in
14:10 - data so then I could just say train it
14:14 - with these inputs and expect these
14:19 - outputs it's only one output but outputs
14:22 - so this is the process this is the
14:23 - training process of course all of the
14:26 - work to adjust the weights of the neural
14:27 - network it's in the library and you can
14:29 - go head stop saying this refer to those
14:31 - videos that go through that process
14:33 - ok we've got that now I am going to
14:36 - let's just run this and see if I get any
14:38 - errors ah syntax error
14:41 - sketch dodge ass line for oh I have
14:44 - semicolons here these should be commas
14:46 - my syntax is completely wrong if you're
14:50 - watching this you are probably screaming
14:52 - at me or saying very nicely and sweetly
14:54 - to the computer ok there we go now let's
15:00 - run again all right it's running its
15:03 - training so what I can do is right here
15:06 - in the console just to test it I can
15:08 - type and and dot and there's a function
15:10 - called predict and what predict expects
15:13 - in the neural network library is the
15:15 - input data with no output because it's
15:17 - not labeled training data
15:19 - it's just input data so let's see if we
15:21 - can get results that makes sense and
15:23 - hasn't trained for very long
15:26 - and I don't know but let's see let's
15:28 - just write predict 0-0 0.45 that's not
15:31 - right so I should be seeing 0.1 right
15:33 - it's changing 0.43 so my guess here is
15:36 - that we really needed to just train a
15:38 - lot more what I'm going to do is just
15:42 - for right now is I'm gonna say I in the
15:44 - draw loop itself I'm gonna say I equals
15:48 - 0 I is less than a thousand I'm gonna
15:50 - have it do every time through draw a
15:52 - thousand a thousand of these training
15:55 - points so this will hopefully get us
15:58 - there a little faster and I can look at
16:01 - this now we can see aah whoo now that's
16:04 - wrong right
16:05 - oh no that's correct oh no I should be
16:08 - getting I should be getting false yeah
16:09 - so that's right I'd it got it backwards
16:11 - for a second it shouldn't be getting
16:12 - true I should be getting a false zero
16:13 - zero so let's try one zero and I've got
16:16 - something that's close to one so you can
16:18 - see that this work okay so the library
16:20 - is working but let's say I want to
16:22 - visualize it okay I want to visualize it
16:26 - I want to see it working I want to see
16:27 - it animating as it works so one way I
16:29 - could do that is I could basically let's
16:32 - create some variables like resolution
16:34 - I'm gonna make a grid of 10 by 10 pixels
16:39 - so the columns is the width of the
16:43 - canvas divided by the resolution and the
16:47 - rows is the the height of the canvas
16:51 - divided by the resolution then I am
16:54 - going to say x equals 0 X or unnies I I
16:57 - equals 0 I is less than the number of
17:00 - columns I plus plus and I'm gonna say J
17:05 - equals 0 it's less than the number of
17:07 - rows I'm gonna do a nice little nested
17:09 - loop here just to now I'm gonna say fill
17:14 - random 255 and I'm gonna say rectangle I
17:19 - times resolution J times resolution
17:23 - resolution I shoulda picked a less long
17:26 - variable name resolution so with this
17:29 - should do is this is a nice little
17:31 - nested loop to just draw a grid of
17:33 - rectangles ten by ten and a little
17:36 - warning this will be kind of flashy so
17:38 - you can see all these
17:39 - all of these elements are flashing out
17:41 - with a random color but I don't want a
17:43 - random color what I want to do is I want
17:45 - to create some inputs so I'm going to
17:48 - say let x1 equal I divided by columns
17:52 - right from 0 to 1 let x2 equals J
17:58 - divided by rose and the inputs then is
18:01 - an array x1 x2 so what I want to do is I
18:05 - want to create a scenario let me just
18:07 - say no loop here so this stops I want to
18:09 - create a scenario where I am inputting
18:12 - in 0 0 here and at this corner 1 0 and 1
18:18 - 1 and 0 1 down here and all the numbers
18:21 - in between right so now and then I what
18:27 - I can do is I can say let y equal neural
18:31 - network predict and this should be an
18:33 - equals here it's this particular predict
18:35 - those inputs and then fill Y times 255
18:39 - so I should get a brightness value out
18:42 - that's between I should get a Y value
18:44 - that's between 0 and 1 and I should get
18:46 - that a brightness value I can broke my
18:47 - I'm at 255 to get a brightness value
18:49 - okay
18:49 - let's run this boom so we can see now
18:54 - and let's let's let's be a little more
18:58 - thoughtful about this and say no stroke
19:01 - then I'm gonna refresh it and very
19:04 - quickly now ah so this I'm so glad this
19:06 - happened
19:07 - so here's a thing it works for me a
19:08 - bunch of times but actually here you can
19:10 - see it's totally getting stuck let's
19:13 - refresh it again and I got stuck in a
19:16 - slightly different way I hit refresh
19:17 - again whoa it's just like going around
19:20 - the Horde and getting stuck in every
19:21 - possible way now how it worked so here's
19:24 - the thing remember how I said a neural
19:27 - network is an interconnected set of
19:30 - nodes which each connection being a
19:32 - weight so there's a couple important
19:34 - factors here what is those weights are
19:36 - initialized randomly and it there are
19:39 - thoughtful ways that you could
19:40 - initialize those weights but I kind of
19:42 - like initialize them in a certain way
19:43 - the problem is there's multiple
19:45 - solutions here so there's one solution
19:48 - here where there's white all the way
19:50 - along this way and if i refresh
19:52 - bunch of times you'll see there's
19:54 - another solution where there's black all
19:55 - the way down through the middle because
19:57 - honestly the only thing that's correct
19:58 - is the core is what's in the corners so
20:01 - I've run this a bunch of times
20:02 - isn't this the opposite of what we got
20:03 - before I can't remember so there's a
20:05 - bunch of different solutions here and it
20:07 - sometimes can get stuck in that middle
20:08 - so I might one thing I might be able to
20:10 - do is play with something called the
20:11 - learning rate so there is a variable in
20:14 - the the library called learning rate and
20:19 - I could say neural network learning rate
20:22 - equals so I forgot the library actually
20:26 - has a function called set learning rate
20:29 - and so what I can do is I can set this
20:32 - to some value now what should that
20:34 - learning rate be the learning rate is
20:36 - like how big are these steps how big are
20:38 - these adjustments and so maybe what I'll
20:40 - do here is I will create a LR slider for
20:45 - learning rate slider and I'm going to
20:47 - say LR slider
20:48 - equals create slider and so I'm gonna
20:51 - have learning rates that go between 0
20:52 - and 0.5 that's probably a ridiculous
20:56 - range with an incremental step of oh it
20:59 - will start at 0.1 and an incremental
21:02 - step of 0.01 so this is a p5 Dom
21:05 - function create slider that creates an
21:06 - html5 slider puts it on the page and so
21:10 - now I could just say LR LR underscore
21:14 - slider dot value so this should if I'm
21:19 - right always set the learning rate
21:22 - according to this so let's see if I put
21:25 - it up here and I say neural network
21:26 - learning rate it's 0.5 and if I go down
21:30 - to here it is zero now I shouldn't let
21:34 - it be 0 right so the lowest the learning
21:36 - rate should be is probably 0.01 so let's
21:40 - see if we can get it stuck now of course
21:43 - it well I'm gonna hit refresh a bunch ok
21:44 - it's stuck let's see if just like
21:46 - allowing you to take bigger steps one
21:48 - way or the other will sort of fix the
21:49 - problem that didn't really seem to fix
21:53 - it's really stuck here so one thing I
21:55 - could do is I could just like start it
21:57 - over like new neural network 2 to 1 and
22:02 - now I've just started it over and it's
22:05 - still stuck
22:07 - let's try it again let's leave it at
22:10 - like point one so I could write this as
22:12 - an in a function to like if to like
22:13 - restart it a bunch of times and just get
22:15 - lucky with the first weights another
22:17 - thing I could try though just to see if
22:19 - this really helps the thing is I point I
22:22 - probably need to do is be more
22:24 - thoughtful about how the weights are
22:25 - initialized which is something I would
22:26 - need to probably want to build into the
22:28 - neural network library but just out of
22:29 - curiosity let's add four hidden nodes so
22:32 - do we make the network smarter by giving
22:36 - it more things to learn about right so
22:38 - I'm adding in all of these whoops this
22:42 - goes to here right there are more
22:44 - connections more connections more
22:46 - possible things for it to learn about
22:50 - let's see what happens
22:53 - ooh look at this look at that it's nice
23:00 - and curvy it's sort of like learned it
23:02 - and slightly every way and I suspect
23:04 - that I'm gonna have a lot harder time
23:06 - having it get stuck now you can see that
23:10 - there's multiple quote unquote correct
23:12 - solutions to how the space looks but
23:14 - it's really able to figure it out now
23:18 - that's really the end of this video the
23:21 - point of this mostly was just to test
23:23 - the neural network library so it works I
23:27 - can use it I can give it data to learn I
23:30 - can try it with other day and I can
23:33 - visualize its result now so here's the
23:35 - thing you're watching this video what
23:36 - should you do next well first of all I'm
23:38 - gonna new another challenge which is the
23:39 - kind of classic hello world neural
23:43 - network machine learning example which
23:45 - is to recognize handwritten digits and
23:47 - they're so well known test set called M
23:49 - nest that I will use okay kind of don't
23:52 - want to but I think it's worth me just
23:54 - doing that just to do it but and that
23:57 - will be a think more interesting problem
23:58 - and then we can even make it so that if
24:00 - I draw a digit can the neural network
24:02 - detect what digit it is so anyway so
24:04 - that's coming but could you on one come
24:07 - up with your own data set trying to
24:09 - train the neural network with your own
24:11 - data set and then how does it perform
24:13 - you also might think about visualizing
24:16 - this output using color in some way you
24:20 - know you
24:20 - could use 3d as I showed you with this
24:23 - process example which is no longer open
24:24 - so you could try a variety of different
24:28 - ways of visualizing this and maybe or
24:30 - animating it or changing the way you
24:32 - would build an interface to it there's
24:34 - so many possibilities so I encourage you
24:36 - to explore it I encourage you to dig in
24:38 - also to the neural network library code
24:40 - if you want to see how that works and
24:42 - check out those other videos as well
24:44 - so thanks for watching this coding
24:46 - challenge I think that's it that's it
24:48 - that's it I'm done
24:55 - [Music]

Cleaned transcript:

hello welcome to a coding challenge in this coding challenge I am going to it's gonna sound really weird solve X or with a neural network now why would anyone want to do this why would I want to do this well what this is actually this is a video in which I am going to test a neural network library I've been building in JavaScript and in fact if you want to follow along with that process of building it there is a giant playlist here starting with 10.1 introduction to neural networks and I start building that library actually around play the video around 10.4 so this video is a standalone video where I'm going to make use of that library in a coding challenge you don't have to have watched all those but if you want the background with a bit more to go deeper in how the internal mechanics of this neural network that I'm going to use works I would refer you to those videos now what is this crazy weird visualization going on over here so let's I'm going to come back to in a second but let's come over to the whiteboard so this is an example a very beginning basic rather trivial example of machine learning and what do I mean by that I mean I'm going to draw a circle here and I'm going to write ml short for machine learning you can think of this as a place where there exists some machine learning recipe some algorithm you might have heard of K nearest neighbor or neural network fillintheblank support vector machines so fill in the blank with your machine learning algorithm there with a machine learning algorithm something goes into it data how you collect your data how you're thoughtful about that what the data is how you call them quote normalize your data there's so many questions ethical questions scientific questions that go into this piece I am not covering that B's in this video but there needs to be some data something that I want to analyze or learn with that's the data portion then that data goes into the magical machine learning recipe and out comes some output now what that output could be it could be a piece of music that I've generated it could be a classification of an image it could be the price of a house that I'm trying to predict based on some data so there's so much possibility here and this output doesn't have to be a single thing but can be multiple things the input obviously the data can be multiple things this is the idea of machine learning now I spent all this time building what is mostly like a toy neural network library it's written JavaScript there's nothing about it that's optimized but just to kind of understand the pieces of how it works so what I want to do is have my recipe be in there be a neural network and I want to create some scenario where I have some training Dana so what I'm going to do this is going to be a demonstration also of the machine learning process called supervised learning supervised learning meaning I am the supervisor and I am going to teach this machine learning recipe to produce output that appropriate output for a given inputs now what well if I just know all the answers why would I even do this well likely there's a scenario machine learning is gonna be used with a scenario where I have a lot of labeled data I have a known data set that I can use to train this system so that if I give it some unknown data it will give me out cut to give me an output a relevant output the classic example of this of course is I have a whole bunch of images here's a bunch of cats here's a bunch of dogs now here's a new image which one is it and along with this process we will typically have training data this is labeled data for which we know the answer we will have testing data this is data that we know the labels for but we aren't using in the training set so that we can see is it working this does it actually give us good we're good outcomes with unknown data and then of course we have the actual unknown new data that we want to use okay so what's the scenario that I'm going to use the trivial realms rather ridiculous example that I'm going to use in this video is the X or a or stands for exclusive or it's a boolean operation that resolves to true only if so you can think of true and if true X or true is actually false I didn't finish my sentence it resolves to true only if one of the two boolean expressions value is true so false X or false also is false and if you go back to my video that's linked here about the perceptron the lib you'll see that this is this is a special problem because a single simple perceptron a single neuron machine learning system cannot solve this problem it is not linearly separable the solution space is not a space where you can just draw a line and see all the categories of one on one side and all the categories of the other on the other side so you can dive into that deeper but this is where a neural network that involves a hidden layer can be used as the machine learning recipe so what I mean by this is I need my training set my training set is going to be 0 0 0 1 1 0 1 1 I'll have 4 elements in my training set and each one of these is labeled this is labeled with a 0 this is labeled with a 1 this is labeled with a 1 and this is labeled with a 0 this is the known data right again this is a sort of trivial you know I could build you could build a circuit right imagine what it would take to build a circuit with two switches and the led only lights up if one switches on they're both on it doesn't light up if they're both off it doesn't light up think about how you might build that that's essentially going that that diagram of that circuit is essentially what we want the neural network to look like so the way that it's going to look and let me erase this here is we can see here in my labeled data set that there are two inputs and one output so the neural network structure has to have two inputs and one output I'm going to send in X 1 and X 2 these are true and true true and false false or true and somehow out of this I should get a y I should get a true or false so how you architect and structural a neural network system this is something that I've gone into much more depth in the other videos but the key to this problem is having what's known as a hidden layer so the inputs come in here I want to look at the output here but these neurons are going to exist in between so everything this is also it's known as a fully connected Network so as the inputs come here they both go into this hidden layer some math happens this is the math that I go over in a previous video it has to do with multiplying by weights these are all weighted connections then the then those go into this output layer and we get the answer and then there is a training process we say try it with this so what internally in the training process what it does is if I give it zero zero with a zero and it outputs a 1 it's like I tell it hey you got that wrong adjust all those weights to try to see if you could get it more correct so we're gonna do is over and over again to Train it to see if we can then later we don't have a separate training and testing set in this scenario we're just going to say I'm gonna train it and see if you can start producing the correct answers for all of these numbers okay that's the background for XOR now I'm actually going to go and write the code to do all of this it works ok so you might recall that I started the video I had this thing up here so this is actually an example that I made in the processing Java based programming environment I probably like almost eight years ago at this point so it's not using the same code base but it's actually solved the XOR problem and what's interesting about this and I'm gonna I'm gonna come back to the white board just for one more moment here we find some room here if I draw a plane and I consider this to be 0 0 and this to be 1 1 so this is 1 comma 0 and this is 0 comma 1 right notice that if I take this idea of exor and map it to here I've got false here false here true here and true here and by the way that what I read r1 there to here and true here this by the way is why it's not linearly separable you can't draw a line I can draw two lines like this or I can draw two lines like this and you're gonna see that result happen actually as I start to program this I hope if it works but what this this idea of a plane this is a plane that's describing the whole solution space for the problem and if you come back over here you'll see look at that those corners if I bring this over closer to me I can try to point to it these corners are the true corners anymore practice and these corners are the false corners and this plane is all the other solutions now this is a 3d rendering it soon some fancy stuff I'm gonna create a simpler version of this so let's just actually start doing that so what you're going to need first of all is if you're writing this code along with me you're going to need to have the toy neural network j/s library it has really just two files that you need it has neural network J s and n n dot J's and matrix such as you could ignore this this is for testing that's something I cover in some other videos that you could probably find and you'll see that in my index of HTML file I am referencing those two JavaScript files I've got like a weird path thing going on but when I published the code I'll publish that all as one one thing okay so now I need to go over to sketch KS let's do some stuff here let's write a setup function let's write a draw function let's say let I'm gonna have a neural network variable I'm going to say create canvas 400 400 let's draw a background of 0 and let's let's go to the browser and see there we go there it is step 1 now what I want to do is create a neural network and I've written out how I want to create it I want two inputs two hidden neurons and one output so the neural network library the toy library that I've built expects those as arguments to the constructor so I guess a neural network equals a new neural network with two inputs two hidden neurons and one output neuron now I should mention that modern socalled deep learning systems often have many many many hidden layers hundreds of hidden nodes big massive networks this is a very small simple one the library only supports networks with these two layers the input did well if you consider the input you could say three but really these were the layers the hidden in the output plus the inputs three things okay now what do I do I need my training data so I'm gonna say let training equal and I want to have it be in an array and each element of the array I want it to be an object and it's gonna have the inputs which would be like this and the outputs now even though I only have one output right one output outputs can be an array they're also referred to as a vector so a list of numbers but in this case 0 0 gives me just a single up or I'd have single outputs when I put the array the library expects an array so I have that inputs out 0 0 I have 0 1 and 0 0 gives me a 0 not a one I have 0 1 which gives me a 1 I have 1 0 which gives me a 1 and then I also have what's the last one 1 1 which should give me a 0 so this is my training data now ordinarily this data might be in a spreadsheet it might come from an API it might be in a JSON file but I'm just hard coding the training data directly into my program just to demonstrate the idea now what do I want to do well in the draw function what I want to do is and now if you're look at how machine learning algorithms work typically you'll see something called you'll have a batch training process where you give it a large batch of data and then you adjust then you adjust the weights and do the training and then another batch I'm gonna do everything just one at a time and the way I'm going to do that is with a function called train that's in the in the neural network library so if I say neural network trained this expects two arguments what it expects to say train the neural network with this input and this expected output and so the easy thing here that I could do is I could what it what it should look like is something like this train it with 0 0 and with 1 oh right so this is what I'm saying these inputs should produce this output train yourself on that but I have so I have that all stored in an array what I'm gonna do is I'm going to say data equals random training and what did I call that up here I called it training I just called the training let's call it training underscore data training underscore data so the random function in p5 will pull a random element from that array and it will put it here in data so then I could just say train it with these inputs and expect these outputs it's only one output but outputs so this is the process this is the training process of course all of the work to adjust the weights of the neural network it's in the library and you can go head stop saying this refer to those videos that go through that process ok we've got that now I am going to let's just run this and see if I get any errors ah syntax error sketch dodge ass line for oh I have semicolons here these should be commas my syntax is completely wrong if you're watching this you are probably screaming at me or saying very nicely and sweetly to the computer ok there we go now let's run again all right it's running its training so what I can do is right here in the console just to test it I can type and and dot and there's a function called predict and what predict expects in the neural network library is the input data with no output because it's not labeled training data it's just input data so let's see if we can get results that makes sense and hasn't trained for very long and I don't know but let's see let's just write predict 00 0.45 that's not right so I should be seeing 0.1 right it's changing 0.43 so my guess here is that we really needed to just train a lot more what I'm going to do is just for right now is I'm gonna say I in the draw loop itself I'm gonna say I equals 0 I is less than a thousand I'm gonna have it do every time through draw a thousand a thousand of these training points so this will hopefully get us there a little faster and I can look at this now we can see aah whoo now that's wrong right oh no that's correct oh no I should be getting I should be getting false yeah so that's right I'd it got it backwards for a second it shouldn't be getting true I should be getting a false zero zero so let's try one zero and I've got something that's close to one so you can see that this work okay so the library is working but let's say I want to visualize it okay I want to visualize it I want to see it working I want to see it animating as it works so one way I could do that is I could basically let's create some variables like resolution I'm gonna make a grid of 10 by 10 pixels so the columns is the width of the canvas divided by the resolution and the rows is the the height of the canvas divided by the resolution then I am going to say x equals 0 X or unnies I I equals 0 I is less than the number of columns I plus plus and I'm gonna say J equals 0 it's less than the number of rows I'm gonna do a nice little nested loop here just to now I'm gonna say fill random 255 and I'm gonna say rectangle I times resolution J times resolution resolution I shoulda picked a less long variable name resolution so with this should do is this is a nice little nested loop to just draw a grid of rectangles ten by ten and a little warning this will be kind of flashy so you can see all these all of these elements are flashing out with a random color but I don't want a random color what I want to do is I want to create some inputs so I'm going to say let x1 equal I divided by columns right from 0 to 1 let x2 equals J divided by rose and the inputs then is an array x1 x2 so what I want to do is I want to create a scenario let me just say no loop here so this stops I want to create a scenario where I am inputting in 0 0 here and at this corner 1 0 and 1 1 and 0 1 down here and all the numbers in between right so now and then I what I can do is I can say let y equal neural network predict and this should be an equals here it's this particular predict those inputs and then fill Y times 255 so I should get a brightness value out that's between I should get a Y value that's between 0 and 1 and I should get that a brightness value I can broke my I'm at 255 to get a brightness value okay let's run this boom so we can see now and let's let's let's be a little more thoughtful about this and say no stroke then I'm gonna refresh it and very quickly now ah so this I'm so glad this happened so here's a thing it works for me a bunch of times but actually here you can see it's totally getting stuck let's refresh it again and I got stuck in a slightly different way I hit refresh again whoa it's just like going around the Horde and getting stuck in every possible way now how it worked so here's the thing remember how I said a neural network is an interconnected set of nodes which each connection being a weight so there's a couple important factors here what is those weights are initialized randomly and it there are thoughtful ways that you could initialize those weights but I kind of like initialize them in a certain way the problem is there's multiple solutions here so there's one solution here where there's white all the way along this way and if i refresh bunch of times you'll see there's another solution where there's black all the way down through the middle because honestly the only thing that's correct is the core is what's in the corners so I've run this a bunch of times isn't this the opposite of what we got before I can't remember so there's a bunch of different solutions here and it sometimes can get stuck in that middle so I might one thing I might be able to do is play with something called the learning rate so there is a variable in the the library called learning rate and I could say neural network learning rate equals so I forgot the library actually has a function called set learning rate and so what I can do is I can set this to some value now what should that learning rate be the learning rate is like how big are these steps how big are these adjustments and so maybe what I'll do here is I will create a LR slider for learning rate slider and I'm going to say LR slider equals create slider and so I'm gonna have learning rates that go between 0 and 0.5 that's probably a ridiculous range with an incremental step of oh it will start at 0.1 and an incremental step of 0.01 so this is a p5 Dom function create slider that creates an html5 slider puts it on the page and so now I could just say LR LR underscore slider dot value so this should if I'm right always set the learning rate according to this so let's see if I put it up here and I say neural network learning rate it's 0.5 and if I go down to here it is zero now I shouldn't let it be 0 right so the lowest the learning rate should be is probably 0.01 so let's see if we can get it stuck now of course it well I'm gonna hit refresh a bunch ok it's stuck let's see if just like allowing you to take bigger steps one way or the other will sort of fix the problem that didn't really seem to fix it's really stuck here so one thing I could do is I could just like start it over like new neural network 2 to 1 and now I've just started it over and it's still stuck let's try it again let's leave it at like point one so I could write this as an in a function to like if to like restart it a bunch of times and just get lucky with the first weights another thing I could try though just to see if this really helps the thing is I point I probably need to do is be more thoughtful about how the weights are initialized which is something I would need to probably want to build into the neural network library but just out of curiosity let's add four hidden nodes so do we make the network smarter by giving it more things to learn about right so I'm adding in all of these whoops this goes to here right there are more connections more connections more possible things for it to learn about let's see what happens ooh look at this look at that it's nice and curvy it's sort of like learned it and slightly every way and I suspect that I'm gonna have a lot harder time having it get stuck now you can see that there's multiple quote unquote correct solutions to how the space looks but it's really able to figure it out now that's really the end of this video the point of this mostly was just to test the neural network library so it works I can use it I can give it data to learn I can try it with other day and I can visualize its result now so here's the thing you're watching this video what should you do next well first of all I'm gonna new another challenge which is the kind of classic hello world neural network machine learning example which is to recognize handwritten digits and they're so well known test set called M nest that I will use okay kind of don't want to but I think it's worth me just doing that just to do it but and that will be a think more interesting problem and then we can even make it so that if I draw a digit can the neural network detect what digit it is so anyway so that's coming but could you on one come up with your own data set trying to train the neural network with your own data set and then how does it perform you also might think about visualizing this output using color in some way you know you could use 3d as I showed you with this process example which is no longer open so you could try a variety of different ways of visualizing this and maybe or animating it or changing the way you would build an interface to it there's so many possibilities so I encourage you to explore it I encourage you to dig in also to the neural network library code if you want to see how that works and check out those other videos as well so thanks for watching this coding challenge I think that's it that's it that's it I'm done
