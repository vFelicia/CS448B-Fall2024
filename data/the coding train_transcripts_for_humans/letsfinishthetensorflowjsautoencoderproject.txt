With timestamps:

00:00 - [Music]
00:09 - [Music]
00:16 - [Music]
00:21 - do
00:23 - [Music]
00:31 - so
00:33 - [Music]
00:42 - [Music]
00:55 - [Music]
01:04 - [Music]
01:11 - [Music]
01:24 - [Music]
01:38 - [Music]
01:49 - [Music]
01:54 - [Music]
01:59 - [Music]
02:06 - [Music]
02:15 - do
02:18 - [Music]
02:36 - [Music]
02:53 - [Music]
03:11 - do
03:31 - [Music]
03:42 - [Music]
03:56 - [Music]
04:09 - do
04:11 - [Music]
04:19 - [Music]
04:25 - check one two hello this is my voice i'm
04:28 - about to get started in approximately
04:31 - two minutes
04:33 - uh if you could if you're in the chat
04:35 - you could let me know that the volume of
04:37 - my voice
04:38 - is coming through and if there's any
04:40 - static or any other issues i should be
04:42 - aware of thank you very much and see you
04:44 - in just a minute or two
04:48 - [Music]
05:23 - [Music]
05:57 - [Music]
06:15 - ugh
06:20 - hello my buttons aren't working properly
06:23 - that's usually the first thing i like to
06:25 - say here on uh
06:27 - when i start a coding trade session good
06:28 - morning
06:30 - happy sunday
06:32 - oh i was all ready to speak and then i
06:34 - pressed the button to bring me live and
06:36 - then i did not show up live and i got
06:39 - completely flustered
06:40 - but
06:41 - i realized actually now that i look at
06:43 - this i was just pressing the wrong
06:44 - button
06:46 - none of this matters let's just give
06:48 - this another try can we please okay
06:51 - going back to here
06:53 - putting the music back on
06:56 - take two everybody
07:01 - [Music]
07:07 - hello good morning happy sunday welcome
07:09 - to the coding train my name is dan i
07:12 - will be your conductor for today's
07:14 - journey
07:16 - and um this train has been going for a
07:19 - very long time it was paused it was
07:21 - stopped in the station for at least a
07:23 - week now
07:24 - uh it but we're we're we're put
07:26 - shoveling the maybe this is this an
07:28 - electric train we had solar panels on
07:30 - the roof i don't know yet
07:32 - um
07:33 - but i'm getting it going again today and
07:35 - i'm going to be returning to this
07:37 - project that i've been building which is
07:39 - uh an auto encoder now if that term auto
07:42 - encoder means nothing to you don't worry
07:44 - i will give a brief kind of
07:47 - five-minute sort of catch-up summary
07:48 - over what i've done in the last couple
07:50 - sessions before before i dive right into
07:52 - the code um but before i even get to the
07:56 - project that i'm going to be building
07:57 - today let me just say hi are you a new
07:59 - viewer i see that i have a new member
08:01 - who just joined this is very exciting
08:03 - this hasn't necessarily happened in a
08:04 - little while it's michael
08:07 - michael
08:09 - thank you for joining
08:11 - the coding train membership program
08:14 - for your membership you will receive uh
08:17 - thanks for me at this very moment
08:19 - because i'm just speaking and i saw your
08:20 - name and i'm talking about your name
08:22 - that's probably not why you joined it
08:23 - shouldn't be why you joined
08:24 - access to some member discord channels
08:27 - for support on your code we'll send you
08:28 - some stickers in the mail all of those
08:30 - things ah but before before
08:34 - i go too far
08:35 - uh we must um dedicate these random
08:38 - numbers that i'm about to read
08:40 - we're just going to start this project
08:41 - over everybody
08:43 - it's been a rough year it's been a rough
08:45 - two years it's been a rough
08:48 - 48-ish years
08:50 - for me actually hasn't been that rough i
08:52 - i i things i i have i have it very good
08:54 - i i can i i cannot complain
08:57 - um
08:58 - but um i have been uh my i'm on a quest
09:02 - uh many quests one of which is to read
09:04 - this entire book a million random digits
09:06 - with 100 000 normal deviates probably if
09:10 - i had just like started doing this when
09:12 - i started making videos i'd be done by
09:14 - now
09:15 - but no i've tried and then i like do a
09:17 - different system then i change the
09:18 - system again we're going to just
09:20 - 2022 it's all twos with a zero
09:24 - it's a new year
09:26 - i
09:28 - we're going to start this book over but
09:29 - for right now
09:31 - we're going to say thank you to michael
09:33 - and reed
09:35 - from page 113
09:38 - row
09:39 - 5620 i'm going to read these digits
09:43 - 51940.44169.83459.8888
09:48 - oh my goodness that's crazy i gotta show
09:51 - this to you this entire book of random
09:53 - numbers
09:54 - it's not an anomaly let's see can i uh
09:56 - there's no light over near to the camera
09:58 - but i'm trying to i don't even remember
10:00 - where it is now here it is look at this
10:01 - look at that sequence
10:03 - is it gonna autofocus on it it's a
10:04 - little dark eight eight eight eight
10:06 - eight eight that's amazing
10:08 - um
10:10 - zero seven seven five two two three two
10:12 - one one two six two six zero zero eight
10:14 - six nine three two nine three six eight
10:17 - nine nine nine five six and uh michael
10:19 - your random number for you your personal
10:21 - number is 995-99956
10:25 - that's page 113 the end of row 5620
10:29 - uh if we can if i can continue to get my
10:32 - act together some of you have received
10:33 - these
10:34 - um many of you have are waiting but um
10:38 - for the members uh your own very own
10:40 - custom uh train whistle with the coding
10:43 - train laser etched on one side and then
10:45 - a random walk pattern generated with the
10:48 - random numbers in this book uh from your
10:51 - own personal position and number uh is
10:54 - um
10:55 - is what i'm offering we're gonna we're
10:56 - gonna be making a lot more of these
10:57 - starting in january
10:59 - and please join the discord everyone you
11:02 - can find out more all of that stuff
11:04 - there
11:05 - and yeah so um
11:12 - what's next
11:16 - ah let me thank today's sponsor
11:18 - brilliant do you like learning do you
11:21 - like interactivity
11:23 - do you like the holiday season
11:26 - and not know what to get somebody uh you
11:29 - could get them a subscription to
11:31 - brilliant so brilliant i'll come back i
11:32 - have a whole bunch of courses in math
11:34 - and science and interactive lessons and
11:36 - computer science so many things that are
11:38 - just in like
11:39 - complete alignment it's like there's
11:40 - another train that's got the words
11:42 - brilliant on it that's just chugging
11:44 - along alongside a parallel track to the
11:46 - coding train
11:48 - so i'll come back i'd like to do
11:50 - i like you know huge thank you to
11:51 - brilliant for sponsoring the coding
11:53 - train and what's wonderful about it is i
11:55 - get to open up brilliant around the
11:56 - middle of the live stream or taking a
11:58 - break and go through a challenge or a
12:00 - lesson in a course i will do that later
12:02 - but you can sign up for free at
12:03 - brilliant.org codingtrain lets them know
12:06 - that you found brilliant from me the
12:08 - coding train i'm not the code am i the
12:10 - coding i don't know
12:11 - that's another discussion for another
12:13 - time no need for the sort of like
12:15 - metaphysical philosophical quandary that
12:17 - we are am i a train am i a human who
12:19 - knows
12:20 - do i have legs
12:22 - yes a little bit stiff today um
12:28 - uh
12:29 - and um yeah oh oh if you want to unlock
12:32 - all the premium stuff and all the
12:33 - courses uh or or you can give it as a
12:35 - gift
12:36 - you will get 20 off
12:38 - the first 200 people to do so from this
12:40 - link all right now
12:43 - what is happening today first of all my
12:45 - glasses are very dirty
12:46 - and i'm going to uh
12:48 - untuck my t-shirt here
12:50 - and clean them off
12:56 - i wore some special clothes for all of
12:57 - you today on a sunday morning i was like
12:59 - let me find my shirt with flowers and my
13:02 - uh cardigan is this a cardigan is that
13:04 - what you call it nice sweater it's cold
13:06 - but i've been running the heat all
13:07 - morning in this garage
13:09 - uh you notice that if you're hearing me
13:11 - and seeing me without interruption the
13:12 - internet is hopefully working here in
13:14 - the garage it is not yet solar-powered
13:18 - um within the next two to six months i
13:21 - will be uh installing i'm not doing this
13:24 - personally but uh solar panels are being
13:26 - installed all on top of this garage
13:28 - where i am hopefully powering all the
13:30 - lights and the computers in here um so
13:33 - i'm excited to
13:34 - sort of see where that leads and talk
13:36 - about that as i go my my um desire to
13:39 - have the coding train you know to the
13:41 - extent of the things that i can control
13:43 - that are in here powered by solar energy
13:46 - uh um and kratos says it has been a
13:48 - while since the last time i've seen his
13:50 - video i think it was before he got his
13:52 - news to new york well
13:54 - boy do i have news for you
13:56 - uh hopefully this is gonna stabilize and
13:58 - i'll be uh broadcasting from here
14:01 - for at least the next
14:03 - year plus probably two years
14:05 - but i am in a new location yet again and
14:08 - mostly i have things going this is what
14:11 - i really want to work on this oh and
14:12 - it's out of focus this um i like to do a
14:15 - lot of diagramming and things in my
14:17 - videos and live streams let's see if i
14:19 - can focus this
14:20 - uh that's hopefully better um but i'm
14:23 - still sort of working on what whiteboard
14:24 - do i want to have how do i want to do
14:26 - diagramming and all of that stuff so
14:28 - coming back over here um
14:32 - all right so let's get going um
14:35 - actually actually before i go into the
14:38 - auto encoder project i i have a bone to
14:41 - pick with you audience
14:44 - i mean it's probably my fault
14:46 - so it's really not on you it's on me
14:49 - but i want to come over here and i want
14:50 - to talk about the fact that i have this
14:53 - video slit scan time displacement effect
14:55 - challenge
14:57 - i believe if you i don't know what
14:59 - happened to the code here on this page
15:01 - uh maybe that's why
15:04 - oh i have a bone to pick with me
15:07 - i've caused my own uh problem here no
15:10 - wonder
15:11 - oh why didn't anybody say anything to me
15:12 - let me let me just do this for a second
15:15 - yeah all right i messed something up
15:17 - here so let's let's see if we can remedy
15:19 - this right now
15:21 - um
15:22 - i think i um i don't know what the issue
15:24 - is and maybe somebody who's watching can
15:26 - do a pull request but let me at least
15:28 - remedy it for you for the year so this
15:29 - my bone that i was going to pick what is
15:32 - where did that expression come from i
15:33 - don't know it sounds kind of i i need a
15:36 - different one
15:37 - i don't like it anymore i want to pick
15:38 - anyone's bones i don't want my bones
15:40 - picked
15:41 - no picking no bones picking please
15:45 - but this is what i wanted to discuss
15:48 - this video came out and i know i'm slow
15:50 - and there hasn't been as much content
15:52 - recently and maybe there's not as many
15:54 - things for you to riff off of but i felt
15:57 - like this slit scan time displacement
15:59 - challenge coding challenge exact set of
16:01 - examples was ripe
16:03 - for creative twisting by you the
16:05 - beautiful passengers of the coding train
16:08 - to make your own special version of it
16:10 - and share back with me this is what this
16:12 - is what i'm here for what i most enjoy
16:15 - about doing the coding train but it
16:16 - seems like there haven't been made any
16:19 - variations first of all i i gotta really
16:21 - work on my language here on the website
16:24 - coming soon based on this coding
16:25 - challenge by the community yet
16:27 - be the first you could be the first and
16:29 - add your own there's a link there that
16:31 - will
16:32 - show you where to add it if you don't
16:33 - know how there's a guide there's a video
16:35 - with me talking about how to do it and
16:37 - even better coming in 2022 there will be
16:39 - a form on the website that you can use
16:41 - probably to just submit um i want to
16:44 - still encourage people to use github and
16:46 - github pull requests as their first
16:47 - foray through the coding train um and to
16:50 - get into that world but um
16:53 - working on some improvements for how um
16:55 - but i i'm realizing now that the code
16:58 - should be on this page
17:00 - and amir hussain says i've just done
17:02 - double pendulum did you submit it please
17:04 - submit it submit it let's see if there's
17:06 - let's see what the most recent
17:08 - community and i uh
17:11 - community contribution time
17:14 - let's see what you the audience have
17:16 - made most recently based on the videos
17:19 - that i have produced here on the coding
17:21 - trade
17:22 - so and then let's find where that code
17:24 - is for that video
17:25 - [Music]
17:28 - i'm gonna go to github.com codingtrain
17:31 - website
17:32 - um oh look pull requests
17:35 - there's some things here
17:37 - a lot old stuff not oh okay i'll have to
17:40 - come look at this but
17:41 - let's look at closed
17:44 - [Music]
17:49 - yeah nothing nothing 14 days ago
17:53 - the last contribution here we go the
17:55 - last contribution from david beale to
17:59 - the diffusion limit again this is on me
18:01 - i just have not been as present
18:04 - and uh
18:06 - in the sort of like
18:08 - ecosystem of the coding train
18:10 - um
18:12 - so that's you know i'm just kind of like
18:14 - make it through this year and and start
18:16 - a new in 2022 but that is my new year's
18:18 - resolution you heard it here first
18:21 - figure out ways
18:22 - to get more people contributing their
18:26 - own versions um you know um
18:28 - is it raphael who does the like creative
18:30 - coding weekly challenge that seems to be
18:32 - very successful i'm sure there's some
18:34 - things i can learn
18:35 - uh
18:36 - there
18:37 - but let's take a look at this one
18:39 - from david
18:40 - beale so um we can just see it here but
18:44 - i um just so you want to if you want to
18:45 - know where it shows up
18:48 - [Music]
18:52 - if i go
18:54 - to here
18:57 - and
18:58 - there it is 3d dla by david beal okay
19:04 - fade out this music let's take a look at
19:06 - this thank you for your submission
19:10 - whoa
19:10 - oh and i love that this is a youtube
19:12 - video
19:13 - cool let's make it full screen wow what
19:16 - did you make this in i would like to
19:18 - know
19:19 - wow that is so cool
19:22 - i love it so um the diffusion limited
19:25 - aggregation uh coding challenge
19:28 - is
19:29 - a simulation of a kind of random motion
19:32 - a brownian motion if you will
19:34 - where which is created by particles
19:37 - entering from outside of a space
19:40 - coming in and when they intersect
19:41 - another particle they're stopped so if
19:44 - you know i i don't know if we can just
19:46 - go back to the beginning of this video
19:47 - to sort of see the big that starting
19:49 - process but you can see it's happening
19:51 - very very fast so each one of these
19:54 - particles it's almost like these
19:55 - branches are coming out and has a very
19:58 - organic
19:59 - um it can have a tree it can create like
20:01 - a tree branching like um pattern but in
20:03 - here i don't know how to characterize
20:05 - this it's very it's almost like um
20:09 - molecular uh in its look so uh thank you
20:12 - for this this is wonderful to see this
20:14 - in 3d there's also something kind of
20:16 - lovely going on color wise here that i
20:18 - can't put my finger on but it seems like
20:20 - there are started as red particles and
20:22 - they're getting more and more blue
20:24 - um
20:25 - you know oh you know i tempted to be
20:27 - like you know
20:28 - just like i just want to make my own
20:30 - version of this i mean i guess i did in
20:32 - some manner but the version i made the
20:34 - example is just 2d
20:36 - and doesn't have this sort of 3d quality
20:39 - to it so wonderful work
20:41 - thank you for this community
20:42 - contribution so i'm hoping um
20:45 - i can kick-start getting more ways for
20:48 - people to share their versions and more
20:50 - ways for me to share them back
20:51 - and i look forward to thinking about
20:53 - ways to do that better in 2022. all
20:57 - right thank you okay i'm going to scan
20:58 - through this just to see where it goes
21:01 - uh
21:03 - whoa oh yeah so it's like zooming out
21:05 - maybe as uh as unchanged colors again
21:08 - this is wild
21:10 - that is a really quite an impressive
21:12 - looking structure
21:14 - um
21:16 - okay
21:17 - um now let's uh close this
21:21 - um
21:22 - just to sort of close the loop on this
21:24 - um
21:25 - if i go here uh you will see this is the
21:28 - actual code from the video
21:30 - and one of the things that i'm doing in
21:32 - this particular example that you didn't
21:34 - see in david's contribution is i'm
21:36 - animating the process of the particles
21:38 - entering and moving randomly and then
21:40 - getting stuck now i'm doing it
21:42 - really fast sped up because
21:45 - uh
21:46 - you know
21:47 - if i were to actually like animate each
21:50 - particle moving like one or two pixels
21:52 - per frame it would take a very long time
21:54 - to build the actual structure oh and i
21:56 - guess i also have some color scheme
21:59 - going on here i say i don't remember
22:00 - what i do in these coding challenges but
22:02 - now i see that color screen scheme is
22:05 - mirrored in the 3d version of it
22:07 - um
22:09 - wonderful i'm just curious here oh it's
22:12 - the iterations probably the iterations
22:15 - is the variable that kind of can i
22:17 - should log in
22:19 - um
22:22 - the iterations is the variable that
22:24 - controls like how many iterations of
22:27 - these particles moving am i skipping
22:30 - so if i went to just like for example
22:33 - one
22:35 - you would see like this is kind of i
22:37 - mean this would be like amazing to watch
22:39 - over an incredibly long period of time
22:41 - but i can only
22:43 - i'm going to talk for a tremendous
22:45 - amount of time and probably not one
22:46 - particle is going to stop and get stuck
22:49 - if i put it at 50
22:52 - we can see things are kind of moving a
22:54 - little bit faster now maybe we would get
22:56 - there but it was i think i had it at a
22:58 - thousand so you know if i
23:01 - if i did it at 100 000 for example oh
23:03 - that's just going to make things now
23:05 - that now i've lost the sort of frame
23:07 - rate of the sketch itself but you can
23:09 - see okay so that's under anyway you get
23:11 - the idea um
23:14 - i'm i'm
23:16 - lost on this tangent let's try ten
23:18 - thousand there we go um and i presumably
23:21 - i think what i would want to do in this
23:22 - case is actually not draw there's not
23:25 - really once i've have this iteration
23:27 - number up so high there's not a
23:29 - tremendous amount of value in drawing
23:31 - the particles moving themselves because
23:34 - ultimately what we're really just seeing
23:36 - is
23:37 - um
23:39 - the um
23:40 - the pattern that's emerging so just out
23:42 - of curiosity if i wanted to change that
23:45 - those are the walkers
23:47 - we could
23:48 - comment this out
23:50 - and i would see
23:52 - now i'm seeing just the sort of
23:54 - diffusion limited aggregation pattern
23:56 - emerging so there's a lot of parameters
23:58 - to play with here
24:00 - i don't want to save this actually
24:01 - because i've kind of messed it i should
24:02 - or i can maybe just do undo all the way
24:04 - back to where it was
24:07 - and hit save but what the thing that i'm
24:09 - just going to hit leave the thing that
24:11 - i'm curious about here is to take a look
24:13 - at source code now
24:14 - my assumption
24:16 - is what david shared here is a video
24:20 - rendering of it so one that's a
24:22 - beautiful way to share documentation of
24:24 - a project because it's very accessible
24:26 - like
24:27 - yes if you have a p5.js sketch that can
24:29 - run in the browser that's just about as
24:31 - accessible in terms of anyone being who
24:33 - happens to have a phone or a computer
24:37 - with a web browser um can just click
24:39 - that link and see it um
24:41 - but i'm assuming here that this is not
24:44 - done with p5.js because then presumably
24:47 - we could see it just running in the
24:48 - browser rather than have a video render
24:50 - of it although it's possible that it's
24:52 - a slow process that rendering it makes
24:54 - more sense anyway let's go i'm assuming
24:56 - this is going to be processing but i'm
24:57 - excited to find out
25:01 - oh no no oh this is i'm so wrong
25:05 - look at this
25:06 - they're just running in the browser
25:08 - so we got all the possibilities oh and
25:10 - and
25:10 - oh and i can control the camera with my
25:12 - mouse okay okay and i can see that it's
25:15 - running at 30 frames per second down
25:16 - here
25:17 - this is amazing uh so now i have to
25:19 - guess that this is i mean this could be
25:21 - the webgl renderer of p5 it looks like
25:23 - there's a lot going on here
25:25 - so and i don't know why the chat is not
25:27 - scrolling for me or maybe just nobody is
25:29 - making any messages in the chat
25:32 - the last message i see is ro doc saying
25:35 - hi
25:36 - um
25:38 - and like discord member chad is
25:40 - completely also dead am i just talking
25:43 - to myself here hopefully people are
25:44 - there
25:45 - so what did i uh sunday maybe sunday
25:47 - morning is not the best time for me to
25:49 - be live streaming but it worked out for
25:50 - me so here i am maybe you're watching
25:51 - this uh as a playback
25:54 - um i'm going to guess that there's
25:56 - something 3js going on here let's look
25:58 - at a view
26:01 - there's a lot of ways i could do this
26:02 - but i'm just going to go to view source
26:03 - here
26:04 - um
26:06 - and
26:09 - logo
26:10 - manifest
26:13 - drop
26:14 - [Music]
26:15 - this is an awkward way okay this is not
26:17 - helping me
26:18 - uh
26:20 - let's do um inspect
26:22 - this is going to be an easier way to
26:24 - look at it
26:26 - and we can see here
26:28 - there are some javascript so this is
26:30 - probably built
26:32 - um let's see let's look here
26:35 - this is probably a sort of built version
26:37 - of this project i'm assuming
26:40 - that this is using
26:43 - 3gs and maybe it's kind of embedded in
26:45 - one of these javascript files here but
26:47 - i don't need to get lost into this right
26:49 - now
26:51 - i can investigate this more later
26:53 - somebody can tell me
26:54 - um i don't know if this is what library
26:57 - this is uh or or what
26:59 - and i could probably click on this and
27:00 - maybe
27:02 - see something more but i assume these
27:03 - are all sort of built in minified files
27:05 - so it's going to be hard to sort of
27:06 - parse through and and find and then i
27:08 - see people saying uh
27:10 - saying hi now in the chat
27:12 - and and minnie jimmy has the same uh
27:15 - reaction that i have by saying sorry i
27:17 - am in awe of the patterns all right
27:21 - all right i've got to get moving here
27:22 - because
27:24 - uh if you've watched any coding train
27:26 - before
27:27 - you'll know that what tends to happen is
27:29 - i it's just a lot of sort of digressions
27:31 - and tangents and sort of
27:34 - going off in arbitrary directions
27:39 - and what i've the thing that i've been
27:40 - enjoying that i've been trying recently
27:42 - just over the last few weeks is picking
27:45 - one project that
27:47 - really requires a a lot of time to sort
27:50 - of dig into and dig through and try to
27:52 - build and debug and iterate and adjust
27:55 - and so on my list for a very long time
27:58 - has been to investigate
28:01 - programming my own auto encoder now not
28:04 - all the way from scratch in the sense
28:05 - that i'm like writing all the neural
28:07 - network code myself but just
28:10 - using a machine learning library like
28:12 - tensorflow.js and i've been doing that
28:14 - over the course of the last live two
28:16 - live streams so i just want to first
28:17 - summarize where i am
28:19 - so far in the project and where i want
28:21 - to go and i also want to address
28:24 - um
28:25 - this pull request that i haven't been
28:26 - able to merge yet i don't know if the
28:28 - chief who submitted this pull request is
28:30 - in the audience right now
28:32 - if you are say hi in the chat um
28:35 - and then also i want to look at this
28:38 - pull request which i did merge
28:40 - and we're going over this so an avaroop
28:42 - question what did you do last time
28:44 - is exactly where i want to be so
28:46 - um let me walk over
28:49 - and i won't be able to see the chat
28:50 - while i'm over there i'm looking to
28:52 - remedy that let me just have a look that
28:54 - looks like the focus is reasonable on
28:56 - there
29:00 - traverse i saw your question about
29:01 - coding challenges i'll try to address
29:03 - that later
29:05 - so
29:06 - the project that i've been building is
29:08 - in some ways like an ancient technology
29:10 - at this point in terms of
29:13 - what is it uh in terms of how
29:15 - synthetic media generative images i just
29:18 - want to see that there's green bars for
29:19 - my audio which there are
29:20 - are created through machine learning now
29:23 - you might have heard of things like
29:24 - again a generative adversarial network
29:27 - you might have heard of style gan or
29:28 - style gan 2 or style game 3 you might
29:31 - have seen this face this person does not
29:32 - exist and this explosion of
29:36 - synthetic
29:38 - cats and dogs and people and cars and
29:41 - all sorts of things that ai models are
29:44 - generating based on a set of training
29:46 - data of real world imagery
29:49 - and there's all sorts of ways they can
29:50 - be fantastical and look very dreamy and
29:53 - artists are making use of this stuff so
29:54 - for me where does learning about how
29:57 - those things work begin well it begins
29:59 - probably in the basics of you know what
30:02 - is a neural network um i do have videos
30:05 - on that but for me in terms of like if
30:08 - if we've got if i'm making this
30:09 - assumption as having sort of gotten
30:11 - through some of the fundamental aspects
30:13 - of the sort of core pieces of
30:15 - neural network-based machine learning
30:18 - the auto-encoder a particular
30:20 - architecture for a neural network is a
30:22 - wonderful starting point to learn about
30:25 - the process by which a model can
30:27 - generate an image and how
30:30 - you you as the sort of artist or the
30:33 - creator or the programmer can manipulate
30:35 - that model to generate images in certain
30:37 - ways um so uh reference most important
30:41 - reference probably for you to watch
30:43 - there's no post production here so i
30:44 - can't just fly this in right now to show
30:46 - you a preview would be the auto encoder
30:48 - video from the youtube channel two
30:50 - minute papers so that's a good two three
30:52 - minute video just you know explaining
30:54 - anything that i'm about to try to do
30:56 - right now in a much better fashion
30:58 - um but the neural network and again my
31:01 - previous sessions i went through this in
31:03 - much more detail i even did a recap of
31:06 - this part in the
31:08 - last session but just to quickly do that
31:10 - again
31:11 - the idea of an auto encoder the starting
31:13 - point of how you think of it as a
31:14 - copying machine an image is the input
31:17 - and we want that same image to come out
31:19 - as the output the trick here is that of
31:21 - course that's a very easy thing to do
31:23 - because we can copy an image i have this
31:25 - many pixels we make a new image and take
31:27 - each pixel and copy it over but what
31:29 - happens if as you're copying the image
31:33 - you're on you're constrained to work
31:35 - with less and less data so in a way
31:37 - you're compressing the image and then
31:39 - decompressing it or encoding it and
31:42 - decoding it what happens is through that
31:45 - process
31:46 - if the neural network
31:48 - learns all these weights
31:50 - the weights are sort of like the make
31:51 - the core sort of like settings the
31:53 - parameters of the neural network itself
31:55 - it learns the weights to copy an image
31:58 - then we could take out the part where
32:00 - the image comes in as input and just ask
32:03 - the neural network to make to make
32:05 - outputs based on what is essentially
32:08 - random inputs
32:10 - or noisy inputs then we're going to
32:12 - generate new images in the style of what
32:14 - we started with that's the idea of an
32:16 - auto encoder and that will lead to ideas
32:18 - like a variational auto encoder and all
32:20 - sorts of other kinds of generative
32:21 - models
32:22 - so
32:26 - where am i i've built this already
32:29 - i think this is where i should go back
32:31 - to my code i have done everything that
32:34 - is in this diagram
32:36 - except for that last part
32:37 - of take off the sort of first half and
32:40 - start to just generate new images that's
32:42 - what i hope
32:43 - and again it's it's not like i've been
32:45 - working on this like i haven't thought
32:47 - about this
32:48 - once when i have thought about it i
32:49 - haven't done anything on this project
32:51 - since the last live stream so i don't
32:53 - know how this is going to go you could
32:56 - go do something else with your sunday
32:57 - and come back and then like watch it on
32:59 - 2x or speed through and just look at the
33:01 - end so that might be advisable but
33:03 - if you're here
33:05 - thank you i appreciate you
33:07 - i'm going to go i'm going to go forward
33:08 - so let's look at the code pieces that
33:10 - exist already
33:13 - um and raj just asks sorry to be alone
33:18 - in a desert first of all
33:20 - nobody i hope nobody watching the coding
33:22 - train the thing that they're coming away
33:23 - from is a feeling of being alone in the
33:25 - desert
33:26 - although i actually have this i've never
33:28 - been to joshua tree and i was looking
33:29 - i'm just i don't know i know why this
33:31 - came up but i was looking at places to
33:33 - go visit joshua tree that's a desert
33:35 - that i could conceivably get to
33:37 - uh i mean i'd have to take an airplane i
33:39 - don't know what we're talking about here
33:40 - i got off track don't feel alone um the
33:43 - the the vibe here
33:46 - the working assumption is that this
33:49 - place is for people who don't know what
33:51 - the thing i'm talking about is and a lot
33:53 - of times i'm just figuring it out myself
33:55 - you should ask of course you know the
33:56 - reality of the situation is i can't
33:58 - every session go back to the very
34:00 - beginning of like what's a variable
34:02 - but you should feel welcome here
34:04 - wherever you are in that journey and
34:06 - there if i've done my job if this is a
34:08 - job correctly i can point you towards
34:10 - resources to find all of the
34:13 - um
34:14 - you know the prerequisites if you will
34:16 - to what i'm working on today so
34:18 - hopefully that explanation helped you a
34:19 - little bit and moby dick is asking would
34:22 - a reverse autoencoder work where you
34:24 - give it more information in the middle
34:26 - so it learns to opposite
34:28 - i don't i don't know i don't know if i
34:30 - fully understand that question if i'm
34:31 - being honest i have to think about this
34:33 - one more it's a fascinating idea and
34:35 - this is this is one of the things that
34:37 - i'm particularly invested and interested
34:38 - in what are the ways that
34:41 - machine learning models that are maybe
34:43 - trained to do a particular kind of task
34:46 - for a real world application can be
34:49 - uh tweaked broken uh
34:52 - done in the sort of like uh turned
34:54 - upside down for creative um and maybe um
34:58 - outputs and hopefully to be sort of
35:00 - critical and investigate um what are
35:02 - some of the sort of
35:04 - issues that the world has and i'm you
35:07 - know being kind of
35:08 - trite about this but uh with the fact
35:10 - that these machine learning models are
35:12 - playing such a sort of fundamental role
35:14 - in our daily lives um
35:17 - odjabi asks do i need to know how
35:20 - tensorflow to follow um it you know so
35:23 - no because my i'm i'm here welcoming you
35:26 - in whether or not you know anything
35:28 - about tensorflow um uh you know
35:31 - and i at least the stuff that i'm gonna
35:32 - do today like a lot of the tensorflow
35:34 - stuff is done already so it won't be the
35:36 - focus so it is
35:38 - um it is a sort of core essential part
35:40 - of what i'm doing right now but i will
35:42 - try to explain things as i go
35:44 - okay um
35:47 - all right lars is asking about
35:49 - generalized ai i don't have uh i don't
35:51 - have an answer for that question around
35:53 - the corner i would say no if i'm
35:55 - guessing but
35:57 - what do i know
36:00 - i'm just here in my garage
36:02 - on a sunny day
36:04 - with a computer trying to make some
36:07 - squares appear out of
36:09 - random numbers
36:11 - all right
36:12 - if you're wondering why i constantly
36:14 - look over here it's because that's where
36:15 - the chat is that's where my monitor is i
36:17 - mean i have it positioned here because
36:18 - then i can sort of
36:20 - gesture at what i'm doing but i feel
36:22 - like sometimes i'm spending too much
36:23 - time live streaming and looking over in
36:24 - this direction
36:26 - okay so um let's look at the pieces of
36:28 - what i have so far and i had the heat
36:31 - running in here all morning to like try
36:33 - to warm it up it is very noisy so i
36:35 - don't run it while i'm streaming but i
36:36 - already feel like it's getting a little
36:37 - bit cold in here so when i take a break
36:39 - i'll crank it up again
36:41 - um
36:43 - it's oil-based heat right now in this
36:44 - garage with like a very old boiler
36:47 - um but i would like to figure out once i
36:50 - have solar panels if i can do some type
36:52 - of like heat pump maybe that'll be
36:54 - quieter i don't know
36:57 - all right so
36:58 - first things first
37:00 - uh i need training data so if we're
37:03 - looking back to this uh this
37:06 - diagram images have to come in right
37:08 - images have to come in what are the
37:09 - what's the training data um it's very
37:11 - sort of
37:12 - rudimentary training data right now it's
37:14 - i have a processing sketch that just
37:16 - draws random squares so i'm going to run
37:18 - it
37:19 - the images it's saving are actually just
37:21 - 28 by 28 pixels because i'm working with
37:23 - very low resolution right now just to
37:25 - have things run fast and sort of work
37:27 - and be easy to deal with um i would like
37:30 - to today start having this generate
37:32 - different kinds of shapes like triangles
37:34 - and circles and squares because i think
37:36 - the sort of ending animation that i'm
37:38 - imagining of sort of like these shapes
37:40 - morphing around in the latent space i'll
37:42 - talk about what that is um would be more
37:44 - interesting so that exists then the next
37:48 - thing that i have which i haven't even
37:50 - opened yet is a node project
37:54 - and the node project is
37:57 - all the code for it is essentially here
37:59 - in index.js
38:01 - and the node project i'm going to talk
38:03 - you through it now i mean if you want to
38:04 - watch like four or five hours of me live
38:06 - streaming building all this you can
38:09 - um
38:11 - the node project is uh architecting this
38:14 - particular uh whoops wrong button this
38:17 - particular um
38:19 - uh neural network architecture
38:21 - i'm sorry to use the same word multiple
38:23 - times uh
38:24 - importing in the training images running
38:27 - the training and then
38:29 - producing output images as well and i i
38:31 - went around in circles with this because
38:33 - i was um you know ultimately i think
38:35 - moving this into the browser will make
38:36 - more sense
38:38 - um
38:40 - but um
38:41 - uh so you can see some things are
38:43 - commenting so i was trying to use like
38:44 - node canvas and different things but i
38:45 - ultimately just using this library
38:47 - called jimp which you can see up here
38:50 - jimp is a library for manipulating
38:53 - images in node
38:54 - so these are the steps we can say i have
38:56 - this like main function
38:58 - where i call build model build model and
39:02 - we'll look at the code in a second
39:03 - creates all of these layers
39:05 - that are in the diagram then i need to
39:07 - load all 550 images i have 500 training
39:11 - images and 50 test images i made a huge
39:13 - mistake which i haven't watched i need
39:15 - to address so this code i'm going to
39:18 - pull in the new code from the pull
39:19 - request in a second so there's a big
39:20 - mistake here
39:22 - but so this code is like slightly wrong
39:25 - but the idea here is the first 500
39:27 - images are the training images and then
39:29 - the next 50 images are the test images
39:32 - so i can train the model and then
39:34 - generate outputs by running the test
39:36 - images through and see how well the
39:38 - model does copying them essentially and
39:41 - so uh i did
39:43 - i forgot that i did this this is great
39:44 - there's some like refactoring there's
39:46 - basically build model load images train
39:48 - test
39:49 - so if we wanted to look at any of these
39:51 - functions i think looking at build model
39:53 - might be interesting to see
39:55 - this is this is the part that i forgot
39:57 - who just asked this like do i need to
39:58 - know tensorflow no but this is going to
40:00 - look kind of a little bit scary to you
40:02 - it looks scary to me and i i sort of
40:04 - know i know ish tensorflow so the idea
40:07 - is i'm making a sequential model
40:10 - a sequential model this is called
40:11 - sequential because the data flows
40:14 - through all these layers in a sequence
40:16 - feed forward left to right and we could
40:18 - draw it any way we want that's arbitrary
40:20 - but it is sequential
40:22 - and then um
40:25 - uh now i need to add the layers so the
40:27 - first layer receives 784 inputs because
40:30 - the images are 28 by 28 that's 784
40:34 - pixels
40:36 - the next layer
40:37 - and basically it takes those pixels and
40:40 - sends the data into 256 nodes and then
40:43 - those 256 nodes send their data into 128
40:47 - that's the encoder so i could actually
40:49 - add a comment here which would be like
40:51 - encoder oh my hands are so cold
40:55 - i'm gonna have to turn the heat on
40:57 - and then decoder
40:59 - what's the temperature outside let me
41:00 - just tell everybody what the temperature
41:02 - outside is where i am
41:04 - uh
41:04 - it's only 40 degrees
41:08 - um and sunny high of 43 today low of 28.
41:11 - this is in fahrenheit of course not of
41:13 - course but
41:15 - of course because i'm an american here
41:17 - who
41:18 - living in the dark ages of
41:21 - measurement systems uh then the decoder
41:24 - is we go back from 128 to 256 and then
41:27 - back to 784 and there's these activation
41:30 - functions and there's the optimizer and
41:32 - the law all these things these are
41:34 - things i've kind of addressed a little
41:35 - bit but you know again this is the
41:37 - territory of other videos i have about
41:41 - um the pieces of the neural network
41:42 - themselves but and then we call this
41:45 - train function where this is interesting
41:47 - normally you're pairing some like if i
41:49 - were training an image classifier i
41:51 - would have the images and the labels so
41:54 - i'd have the training data and the
41:56 - targets
41:57 - but i don't have that because the target
42:00 - of the training data is the training
42:01 - data itself that's the sort of
42:04 - twist here with an auto encoder i'm
42:06 - trying to have data flow in compress it
42:08 - down and the same exact stuff come out
42:10 - so that's really this weird thing it
42:12 - looks like a mistake to me because it
42:13 - should be like x train and y train or x
42:16 - train and y targets
42:18 - but number of epochs is how many times
42:19 - through all the data batch sizes how
42:22 - many data points do i do before i start
42:24 - adjusting some weights et cetera
42:27 - and
42:28 - yeah and there's some stuff about
42:29 - loading the images and i'm using this
42:31 - jimp library so again i don't want to
42:33 - run through all of this but that's the
42:35 - idea so let's try running this right now
42:37 - and see what happens
42:39 - so first thing first oh no let's correct
42:42 - the error so first thing i'm going to do
42:43 - is going to say kit get pull origin main
42:46 - so i've already merged a pull request
42:48 - that came in
42:49 - um
42:51 - and so i merged it on the github website
42:54 - and now this is the command that i can
42:55 - type to receive that image here that
42:57 - that change locally
43:00 - oh i don't know why
43:01 - i'm getting this weird message and i'm
43:03 - also i
43:04 - all right so we have to deal with this
43:07 - two things have gone wrong here one is
43:10 - i guess the way my git is set up on this
43:12 - computer i haven't specified a sort of
43:14 - default way to reconcile so what if
43:17 - you've made changes in more than one
43:19 - place
43:20 - how are those changes reconciled with
43:22 - each other um there are different ways
43:25 - of doing it and i'm not going to get
43:26 - into that right now but i'm going to
43:28 - just i want the default one to just be
43:31 - the one that i'm going to do so i'm
43:32 - going to take this command
43:34 - and type it in
43:36 - now let's call pull origin mean again
43:39 - we're gonna have another issue
43:41 - so it's saying like aha you've made
43:43 - local changes to the following file
43:46 - that would be overwritten because i'm
43:48 - trying to pull in some changes that were
43:50 - made on the github website server itself
43:54 - but i also was messing around with it
43:55 - here so the only change i actually made
43:58 - was just and i can actually see it if i
43:59 - do i think git
44:01 - diff will show me
44:03 - it's just adding these two comments
44:05 - encoder and decoder so i could undo
44:07 - those but
44:11 - what i'm going to do is i'm going to say
44:12 - git
44:13 - add
44:15 - dot
44:16 - git commit
44:17 - i'm going to put a message in i'm
44:20 - adding
44:21 - encoder and
44:23 - decoder comments
44:26 - there we go and then now i should be
44:28 - able to
44:29 - pull the fix
44:32 - no problem it's merging it
44:35 - i'm not going to type in any more
44:36 - information about that and there we go
44:38 - so now that's coming now what was that
44:40 - change
44:41 - let's go take a look
44:45 - uh how does this 40 minutes in this live
44:47 - stream and i've barely gotten anywhere
44:49 - yet i guess that's the hopefully i've
44:51 - been talking a lot in ways that help you
44:52 - understand the world at least
44:55 - focused in on machine learning and
44:57 - javascript and that sort of stuff
44:59 - um
45:00 - and curvers is talking about reducing
45:02 - the latent dimension to something lower
45:04 - from someone yes yes yes my goal
45:06 - actually by the way is to have a browser
45:10 - page with sliders on it where you could
45:11 - manipulate each dimension individually i
45:14 - i i it does not seem realistic but i'm
45:16 - going to get that today i don't think
45:17 - there should be like four parts i really
45:19 - thought i could finish this but that's
45:20 - my goal so having it less so let's look
45:22 - at fixing number one
45:24 - so
45:25 - um and actually we could just look at
45:26 - the issue which maybe um described it
45:28 - better
45:30 - so you're using the same images for
45:32 - training your network and testing it
45:34 - this is due to
45:36 - array.prototype.slicestart returning a
45:37 - copy of the array from the index start
45:39 - to the end and not zero to the start so
45:42 - i had if you what what is this what's
45:44 - happening here i had
45:47 - um this is what i had
45:51 - and i did not realize that slice 500
45:54 - slices out the array from 500 to the end
45:57 - not 0 to 500 which is what i wanted
46:02 - and then
46:03 - now if i just put 500
46:06 - it'll take i don't have to put the end
46:08 - number because it'll take that to the
46:09 - end so that is a huge mistake that i had
46:12 - in the end i don't know to what extent
46:14 - it's going to make that much of a
46:16 - difference because everything i'm doing
46:17 - here is is utterly simplistic and
46:18 - somewhat trivial so so what that i use
46:20 - those 50 images but
46:24 - let's try
46:25 - um running it and i think if you were if
46:28 - you were here last time i was talking
46:30 - about how an auto encoder could be used
46:31 - to de-noise an image and i wasn't
46:33 - getting that to work this is that's
46:35 - probably why i'm not going to go back to
46:36 - that right now because i think that'll
46:37 - send me down
46:38 - you know at least a half an hour of
46:40 - investigation but let's run this again
46:44 - and it's training the model hopefully
46:46 - now off of 500 images not 50
46:50 - and it's going to do a 250 epochs we're
46:52 - seeing the loss go down which the loss
46:55 - is sort of a summary of the error like
46:57 - how well is it currently copying the
46:59 - images
47:07 - uh hi omar i'm reading your message and
47:09 - thank you tom i don't know what the
47:10 - penguins are for but i love penguins
47:13 - i we i had not gotten a loss below 0.1
47:16 - you can see it's really
47:18 - settled so clearly one of the things
47:20 - this we can learn from this is that if
47:23 - the loss is sort of like frozen uh you
47:25 - know it went down to 0.105 but you can
47:28 - see it's not really changing very much
47:31 - at like whatever number of epochs i'm at
47:33 - um so probably training the model
47:36 - for 250 epochs is quite unnecessary but
47:40 - let's let it finish that so after it
47:42 - trains it for those 250 epochs it's then
47:46 - going to
47:47 - generate 50 new images
47:49 - okay great so
47:51 - just let's go look at the directory that
47:54 - i'm in
47:58 - and
48:00 - we can see whoops
48:02 - wait a second
48:04 - where did it load the images from
48:06 - i'm confused well let's just see what's
48:08 - in the output
48:09 - it worked
48:11 - i'm i i'm a little bit confused because
48:15 - where did it load that i don't see the
48:17 - training data actually in the so hold on
48:19 - load
48:22 - data square
48:25 - but there's nothing in this
48:27 - oh no it's there i just don't know why
48:29 - oh yeah it's just the
48:31 - mac os was activated so this is the
48:33 - sorry about that
48:34 - ignore the last minute i was just
48:35 - confused um so this is
48:39 - these are the training images right
48:41 - these are 28 by 28 pixel squares that i
48:44 - generated in processing
48:48 - um
48:49 - and then
48:52 - and i'm getting all sorts of interesting
48:53 - um
48:56 - commentary in the chat so thank you for
48:57 - that i can't it's not possible for me to
48:59 - address all of it as i'm going but i
49:00 - appreciate it and i often do go back and
49:02 - read it afterwards
49:05 - so
49:06 - all right so now what i want to look at
49:07 - just to make sure things are working the
49:09 - way i intended them to is look at the
49:11 - output
49:12 - so these are
49:13 - the generated images now i cannot even
49:16 - discern the difference
49:18 - um in my assumption would be
49:21 - that these are slightly fuzzier like
49:25 - generally speaking my experience with
49:27 - working with an auto encoder is uh the
49:30 - output images are going to have a sort
49:32 - of fuzzier less precise quality to them
49:35 - than the input images but in this case
49:37 - i'm working with such
49:39 - like fixed kinds of images squares
49:42 - um
49:43 - that have of just black and white pixels
49:45 - at such low resolution i'm not sure how
49:47 - we're going to discern the difference so
49:49 - i want to see if i can get this stuff
49:52 - into a place where i can manipulate it
49:55 - so that's what i want to work on i do
49:56 - need to take a break so i wonder if
49:58 - actually that makes sense usually i just
50:00 - keep going and going but maybe i should
50:02 - just take a short break right now if you
50:04 - generate the images as 28 by 28 instead
50:07 - of reducing them the images are sharper
50:10 - i'm not sure what that means mini jimmy
50:14 - um and i'm of the wrong
50:16 - so let's let's let's go let me go a
50:18 - little bit further sort of think about
50:19 - what i'm doing here
50:24 - well
50:28 - um
50:29 - so is there a way
50:32 - this is what i don't know how to do
50:35 - my idea here is that
50:37 - uh and i and i do want to make this
50:41 - like let's actually try this let's let's
50:43 - do a little bit of this
50:45 - let's do it i don't know why i'm let's
50:47 - have the auto encoder go down to
50:51 - 64. i don't know how many layers it
50:53 - makes sense to do what if i just like
50:54 - went to 16 like i want to have 16.
50:57 - that's my goal
50:59 - um
51:01 - could i possibly
51:03 - just go from 128 to 16 is that like a
51:06 - terrible like silly thing to do
51:10 - and then this would go back to 128.
51:12 - should i put more in between i don't
51:14 - know but let's just see what happens if
51:15 - i go down to a really small number
51:18 - and
51:20 - um
51:22 - and then also the number of epochs
51:27 - where is that
51:32 - oh train model that's a parameter i pass
51:35 - in
51:36 - um train model
51:39 - 250 let's just do 100. let me run this
51:42 - again
51:43 - and that while i'm running while it's
51:45 - running i'm going to talk about what it
51:46 - is i don't know how to do
51:49 - so what i'm hoping i can figure out to
51:52 - do
51:55 - is
51:58 - how do i take
52:00 - this neural network architecture
52:03 - and basically
52:05 - make
52:07 - where is it
52:09 - this
52:11 - the input
52:13 - so how do i delete all this and actually
52:15 - add tr add data to produ from predict
52:18 - insert it into here
52:22 - and yes
52:23 - blue tj says i suspect it gets even
52:25 - fuzzier this is what i'm trying to test
52:27 - right now
52:28 - so we got around the same like loss and
52:31 - i could look 1049 these are new images
52:34 - but
52:35 - honestly
52:36 - we can see with 16 no problem i mean
52:38 - it's sort of hard for me to believe that
52:41 - did i like not save the code or
52:42 - something
52:45 - like like like if i change this to two
52:47 - like it really shouldn't work right so
52:49 - let's just make sure that this doesn't
52:52 - work let's change that to two
52:55 - because otherwise maybe something is
52:57 - wrong
53:03 - okay this is good news the loss is not
53:05 - going down
53:12 - i have a lot to say yeah i'm kind of
53:13 - picking the activation functions very
53:15 - arbitrarily i've talked about activation
53:18 - functions in other videos there's relu
53:20 - which is not how you say it but that's
53:22 - how i say it and sigmoid and um
53:26 - so i'm hoping the images that come out
53:28 - are no good here let's see
53:36 - ah they're not so bad they're just
53:42 - uh they're all basically the same
53:45 - it's just like a much bigger fuzzier
53:46 - square it's like only knows how to do
53:48 - one thing so that's great to see
53:50 - um
53:52 - let's try i want to see like what is the
53:53 - minimum can i get it down to eight
53:55 - again i wanted to have more complex
53:58 - imagery so i don't know what the point
54:00 - of getting it down to eight is with this
54:01 - but let's see
54:09 - i recall the loss being at 1.05
54:21 - all right so this looks pretty good with
54:22 - eight there's
54:27 - yeah and blue tj writes exactly what i
54:28 - was thinking there's leaky relu leaky
54:31 - relu and many rectified linear unit is
54:34 - what that stands for i don't know how
54:35 - much that explains anything to anybody
54:37 - but and many others it's quite hard to
54:39 - find the right one and know which one
54:40 - fits in your use case yeah so to be
54:42 - clear my motivation here is exploration
54:46 - and explanation
54:47 - not
54:48 - optimization not speed not efficiency
54:50 - not even producing a meaningful result i
54:54 - want to understand how these systems
54:55 - work and i want to be able to feel like
54:57 - i have some agency in manipulating how
55:00 - they work in and i feel like i do simply
55:03 - by the fact that i can change the total
55:05 - number of neurons at that middle layer
55:08 - the sort of smallest layer and see a
55:10 - very different result means things are
55:12 - working as expected
55:14 - that match the way that i understand how
55:15 - these systems work
55:17 - so you've got to fix the sigmoid
55:20 - um all right let me let me just see here
55:24 - i what i wanted was
55:26 - i know i want sigmoid as the last
55:31 - activation function because i want my
55:33 - values to be to be between zero and one
55:37 - but i don't know if the suggestion here
55:38 - is that i should just try relu all the
55:40 - way through or even don't worry about it
55:43 - just have it i'm just going to leave it
55:44 - as is
55:46 - right now
55:47 - but um i would love to
55:53 - um
55:55 - and kervers is saying that they got an
55:56 - auto encoder to work fine with just two
55:59 - latent dimensions i have two sigmoids i
56:02 - have three sigmoids i don't know i don't
56:04 - understand the comment okay i'm gonna
56:06 - come back to that i the thing that i
56:08 - want to do now
56:10 - is
56:11 - figure out how do i
56:14 - um how do i start
56:17 - from here
56:19 - once the model i is here
56:22 - so maybe what i should do is first save
56:25 - the save and load the model
56:28 - so hopefully this is as easy as
56:33 - let's look on the tfjs documentation
56:36 - i'll take my break after saving and
56:38 - loading
56:42 - layers model safe sequential model is
56:44 - what i'm using
56:46 - well there's no save function here but
56:48 - is this ultimately a layers model
56:49 - because sequential like extends that or
56:51 - something
56:53 - save model dot save i know a local
56:55 - storage is interesting oh but i'm not in
56:57 - the browser so that i do not want to do
57:00 - i mean i could just move this to the
57:02 - browser it's a little bit silly to be
57:03 - honest that i'm doing this in node
57:07 - but let's try this
57:12 - so what happens if i
57:14 - let's forget about testing the model for
57:16 - a moment
57:18 - oops
57:20 - now let's just try
57:24 - save and what if i do
57:26 - like if i give it a directory we'll put
57:28 - it all in there
57:30 - let's just see and let's
57:31 - let's do this for just like 10 epochs
57:34 - just to sort of see
57:35 - so i'm going to try
57:38 - i'll just call it model
57:41 - let's just see if this will save the
57:44 - model in a directory called model
57:53 - i'm just doing 10 epochs
57:55 - okay
57:56 - model is not defined oh my goodness oh
57:58 - my goodness what is wrong with me it is
58:00 - called autoencoder
58:08 - oh i forgot to address the other pull
58:10 - request
58:11 - um could not find any url well so
58:15 - i don't want it to be a url do i just
58:17 - need to have a folder called model
58:20 - will that do it
58:24 - let's see
58:28 - no
58:29 - no
58:30 - this did not work okay
58:32 - um
58:35 - indexeddb
58:37 - downloads my server
58:41 - what about a file
58:45 - does it really not
58:47 - work just to give it a direct
58:57 - talents okay
58:59 - uh
59:01 - all right let's look at the so let's
59:02 - address the pull request which maybe has
59:04 - a solution for it in it
59:06 - so um
59:10 - where where am i going to auto um
59:17 - yeah here we go all right so let's look
59:19 - at this pull request and actually let's
59:20 - just go to this issue
59:23 - so this is incredible what uh the chief
59:26 - has submitted here um
59:29 - i'm just going to read here want to make
59:30 - the code a bit more readable and
59:32 - organize everything in its own class and
59:34 - file
59:35 - yes
59:36 - yes yes so do i
59:38 - i opened a pull request number three for
59:39 - it i added a data source class which can
59:41 - provide training and testing data and
59:42 - there's an interface for it so
59:45 - more data like random mnist arbitrary
59:48 - images blah blah blah
59:50 - more layers divided into an encoder and
59:53 - decoder it can save its state so you
59:54 - don't have to train it every time the
59:56 - image transformer takes an array of
59:58 - normalized pixel images and saves it to
60:00 - disk so there's so much more
60:03 - here in terms of organizing refactoring
60:05 - the code so i didn't feel like i can
60:07 - merge this
60:09 - because
60:10 - um it's too it's like too too good it's
60:14 - like too much of a radical improvement
60:16 - over what i had before that i won't be
60:18 - able to easily continue this process
60:20 - this explanatory process i have so the
60:22 - chief if you're watching
60:25 - i don't know the best
60:27 - one i don't know what to do here with
60:28 - this one is i could wait and eventually
60:30 - merge this in later once the project is
60:32 - totally finished but i would like to
60:34 - have a version that kind of i'd either
60:36 - or maybe i can draw inspiration from
60:38 - this like implement some of these pieces
60:40 - during a live session but i think what
60:42 - might make sense is for this to live
60:45 - um in uh you know in as documented in
60:48 - the readme for this repo linking out and
60:50 - explaining these improvements so that
60:52 - somebody could sort of see the code that
60:54 - i've written in the live streams follow
60:55 - that along and then see how there is a
60:58 - version of it that's just much more
61:00 - thoughtful in terms of how it is
61:01 - organized
61:02 - so let's think about that the thing that
61:04 - i would really like is
61:06 - an excellent readme documenting all of
61:08 - these pieces
61:10 - um expects a file extension maybe
61:13 - a branch would work but um so a pull
61:16 - request with a nice readme that links to
61:18 - the different live streams and kind of
61:19 - like the um
61:21 - the two minute papers video and it kind
61:23 - of has some sample images in it i mean i
61:25 - should be doing that i just haven't had
61:26 - time so if somebody wants to really
61:27 - think about how this whole process could
61:29 - be documented in readme linking to the
61:31 - chief's work and all of that that would
61:32 - be amazing
61:34 - but let's take a look
61:36 - at the actual pull request
61:40 - because maybe we can get some hints for
61:42 - how
61:43 - to save and load the model from the disk
61:46 - because i'm not seeing it obviously in
61:48 - the tensorflow js documentation so let
61:51 - me just look for save
61:54 - this is for saving the images
61:58 - saving the images auto encoder oh
62:01 - so literally i'm doing it right but i
62:03 - just need to put
62:05 - oh and it's
62:07 - oh and it's divided into an encoder and
62:10 - a decoder so that's also
62:13 - a probably a clue to what i actually
62:16 - want to do
62:17 - i have to understand so let's first just
62:19 - get it to save
62:23 - so
62:24 - is it just this
62:28 - file colon slash model
62:32 - with another slash let's try this
62:38 - a little tiny box here
62:40 - yeah
62:41 - i think this might have worked
62:49 - so one thing we can do is we can look at
62:51 - oh i've got it here what am i doing
62:53 - we can see the model files we can see
62:55 - this um
62:58 - the json which is basically a
63:01 - configuration file describing the
63:04 - architecture of the model it's a
63:06 - sequential model here's all the here's
63:08 - all the layers the kind of layer it is
63:10 - the activation function the number of
63:11 - units etc etc so that's great so then
63:16 - let's save a model trained to a hundred
63:18 - epochs
63:22 - and
63:23 - where do i want to do that
63:26 - so go back to 100
63:50 - all right almost 200 we got down to .108
63:53 - of a loss
63:54 - 107.
63:56 - can we get to a six show me a six show
63:58 - me a six before you finish i want to see
64:00 - that six
64:02 - that's fine we got
64:04 - zero point one zero seven
64:07 - now this should be live just to be sure
64:09 - 1101 am yep that's a new model overwrote
64:11 - the previous model by the way this
64:13 - weights.bin file is all of the trained
64:17 - weights
64:18 - so in theory every time i'm saving the
64:19 - model
64:20 - this is not changing at all model.json
64:23 - the weights are what i'm changing so i
64:25 - could have different weights file if i
64:26 - wanted to try different configurations
64:28 - and swap them in and out
64:30 - what are the weights just for any of you
64:31 - who might be kind of just joining right
64:33 - now it is the value the sort of weight
64:37 - of every single connection between any
64:39 - given node in the system and another
64:41 - node uh well the layers are connected
64:44 - sequentially so
64:46 - um
64:47 - you know the first first layers aren't
64:48 - connected to the last layer they're
64:50 - connected through
64:51 - each other all right um all right now
64:55 - in theory then
64:57 - there shouldn't be
64:59 - i should be able to
65:02 - um and it's this is very awkward what
65:04 - i'm doing here
65:07 - but i'm just going to let me just do it
65:09 - this way
65:12 - let me comment out all of this one more
65:15 - time
65:16 - and then
65:18 - let's get test back
65:21 - oh i do have to load the images sorry
65:29 - and let's see can i do
65:32 - auto const auto encoder
65:35 - equals
65:36 - await
65:38 - how do i call load
65:44 - let's just look in our cheat sheet
65:48 - this is terrible i should look in the
65:50 - documentation model.load
65:53 - huh
65:57 - i'm confused all right i'm going to look
65:58 - at let's look at the documentation
66:01 - so where is load
66:03 - save
66:05 - load sync i don't need to load sync
66:13 - load layers model
66:17 - okay that should be it tf
66:19 - load layers model okay
66:25 - and then i should be using the same path
66:29 - but maybe i say
66:30 - model.json
66:32 - here
66:35 - so
66:38 - let's see if this works
66:40 - i'm going to just to be 100 sure i'm
66:42 - going to delete all these outputs that i
66:44 - had previously
66:46 - and now
66:47 - instead of
66:49 - building the model and training the mile
66:51 - i'm just loading the train model from a
66:53 - particular file this is how i'm going to
66:55 - be i'll just move right into the browser
66:57 - because i can um i'll do
66:59 - yeah i mean once i have a saved i'm
67:01 - going to use node just for training the
67:02 - model and then i'll once i've saved it
67:04 - the files will just bring it right into
67:05 - the browser i think i think that makes
67:07 - the most sense to do
67:09 - yeah i was thinking like oh i could set
67:10 - up like a web server and have the
67:12 - browser send like get requests and the
67:14 - the server like generate the images and
67:16 - send it back but that's like a whole lot
67:17 - of unnecessary trouble right now
67:21 - so let's run this
67:24 - okay ah i think this might have worked
67:30 - output
67:31 - yeah 1104 okay we did it
67:35 - yes all right we're in really good shape
67:37 - here
67:38 - um so i'm going to take a short break
67:40 - just so i could turn the heat back on
67:42 - and
67:43 - check out brilliant as a sponsor for a
67:45 - moment but let me just see i saw
67:46 - somebody ask
67:48 - in order to recover the information of
67:49 - the squares you should use relu in the
67:51 - decoder part as activation functions
67:53 - because they are inverse functions the
67:55 - last layer is okay as sigmoid okay that
67:58 - sounds very reasonable to me
68:00 - thank you and k asks what exactly does
68:02 - an auto encoder do um unfortunately so
68:05 - an autoencoder just as like a one sense
68:07 - is a copying machine it's taking inputs
68:09 - and generally trying to generate the
68:11 - same output while compressing the data
68:13 - inside of a neural network there's a lot
68:15 - more to say about that the two-minute
68:17 - papers video on autoencoder and my
68:19 - earlier explanation in today's live
68:20 - stream should give you much more detail
68:23 - but just for anybody who just happened
68:24 - to tune in right now so what's coming
68:27 - next i hope everybody can stick around
68:29 - please stick around
68:30 - i'm going to just take a short break but
68:33 - what's coming next is
68:35 - i'm going to take this trained model and
68:38 - move it into the browser so that i can
68:40 - see
68:41 - the images appear in the browser and
68:44 - animate them which will be very exciting
68:47 - so before i do that i want to thank
68:51 - today's sponsor of the coding train
68:54 - brilliant
68:56 - um
68:57 - i can't emphasize
68:59 - how important it is when you're learning
69:01 - a new concept to be able to try it
69:03 - yourself so me demonstrating stuff in
69:06 - this video i hope is entertaining for
69:07 - you i hope it's turning the wheels in
69:10 - your brain maybe you're even doing it
69:12 - along with me or you're trying it later
69:14 - that's the way to learn but brilliant is
69:17 - all about trying it yourself in spades
69:20 - topics in math in science and computer
69:23 - science anything you can think of there
69:25 - are lessons and challenges and courses
69:28 - and puzzles and all of them are
69:29 - interactive that allows you to try it
69:31 - yourself
69:32 - so um i'm gonna switch back over to the
69:36 - brilliant website itself
69:38 - um you just before i do though that's
69:40 - the url you can actually sign up for
69:42 - free there's a ton of stuff you can do
69:43 - on brilliant for free if you use that
69:45 - link it lets them know you found out
69:46 - about brilliant through the coding train
69:48 - thank you
69:49 - and also that link will give you the
69:52 - opportunity to have a 20 discount on the
69:54 - premium subscription but even better
69:56 - than buying it for yourself let me just
69:59 - quickly mention
70:01 - that uh you'll notice this button up
70:03 - here because i already have them logged
70:04 - in with a premium account this gift
70:07 - premium it is gift giving season and uh
70:10 - it's hard to
70:11 - find things to buy for people it's also
70:13 - i don't know you know this is plastic
70:15 - and packaging and so gifting a premium
70:17 - subscription to brilliant for somebody
70:19 - who loves learning i mean that's what
70:21 - i'm going to be doing for people um uh
70:24 - um you can do that you'll get this
70:26 - through the same link you'll get the 20
70:28 - uh discount that link there so um i
70:31 - can't recommend that enough
70:33 - let's look at this i i was kind of going
70:36 - to go to the logic there's a bunch of
70:37 - courses so i can show you just really
70:39 - quickly like these are what the
70:40 - interactive lessons look like their
70:41 - logic course has been totally redone
70:44 - with lots of new interactivity so you
70:46 - can see like there's a lot of
70:47 - explanation and then interactive things
70:49 - you can do we're talking about neural
70:50 - networks like all these things i'm
70:51 - talking about about weights
70:53 - we can see there's a whole course all
70:55 - about neural networks that you can
70:57 - browse through um it's a great
70:59 - complement
71:00 - um
71:01 - oh and i'm speaking of which daniel
71:03 - montegrano said can you try loss equals
71:05 - mean squared error
71:07 - and if you want to know what mean
71:09 - squared error is and all that stuff i
71:10 - have a feeling that the brilliant course
71:12 - explains that stuff really really well
71:14 - uh so thanks for that chat message so i
71:16 - think what i want to do today
71:19 - is uh i'm kind of again like i didn't
71:22 - have a plan for this so um if i go to
71:24 - courses you can see these are two
71:26 - courses that i would certainly recommend
71:28 - beautiful geometry is personally my
71:29 - favorite right now and then also the
71:31 - logic course we can scroll through and
71:33 - see all of these popular ones
71:35 - recommended for parents and teachers
71:37 - learning paths you know you can you use
71:39 - if you're watching these probably all
71:41 - appeal to you
71:42 - so um
71:44 - but i think today for fun let's try this
71:47 - nine nine plus challenge that i have not
71:49 - looked at
71:52 - sometimes the best way to solve a
71:53 - problem is by just doing something with
71:56 - it uh-huh that's what i've been talking
71:57 - about then slow down and think about
71:59 - what you're doing for example think
72:00 - about what you need to do to solve just
72:01 - one part of the problem here's a warm-up
72:03 - challenge try it yourself
72:05 - drag the tiled numbers up into the plus
72:14 - note that the sum of all the available
72:15 - tiles is zero yet the goal is to make
72:17 - the row sum and columns both positive oh
72:20 - i did not know that
72:22 - uh oh i did
72:24 - wait no oh no no no i didn't because
72:26 - that's negative 1. so i didn't do it
72:27 - right
72:33 - when i first see somebody refused to
72:34 - even try to solve it they glance at it
72:35 - and claim it it's impossible
72:38 - yeah it's impossible
72:39 - i can't do it
72:41 - oh i can put this in the middle
72:43 - well hello
72:52 - no this goes here and this goes here i
72:55 - did it
72:56 - yes
72:57 - [Laughter]
72:59 - if you start by filling the rows sum to
73:01 - one how many different ways are they
73:02 - okay three dwell a little bit so
73:04 - so now it's going to explain
73:06 - 2 goes in the middle
73:09 - yeah this is basically what i did thank
73:11 - you very much
73:13 - your solution might look a little
73:14 - different as long as the 0 and negative
73:15 - 1 are together in the same row or column
73:17 - and the one and negative two are
73:18 - together in the other both sums will be
73:20 - correct
73:21 - so we've shown that it's definitely
73:23 - possible to arrange negative two
73:25 - negative one zero one and two into a
73:26 - plus that's a positive let's take that
73:28 - one step further is it true that if you
73:30 - arrange any five number tiles in a plus
73:32 - and put a positive value in the center
73:35 - the row sum plus the column sum will be
73:37 - larger than the sum of the five tiles
73:40 - can you prove why this is true well that
73:41 - totally makes sense intuitively because
73:43 - you're using the
73:45 - the center tile twice
73:48 - and you're using all the other tiles
73:49 - once
73:51 - so
73:52 - no matter what
73:54 - it's going to be more because you're
73:56 - adding more numbers essentially
73:58 - okay wrap things up here's a bonus
74:00 - challenge that's fair bit more complex
74:02 - than the plus arrangement however it can
74:04 - be solved using the same algebraic
74:05 - strategies to make the puzzle above and
74:06 - today's challenge solvable
74:09 - oh i have to get five five five
74:11 - everywhere well should i try this or
74:13 - should i just let me just move on to the
74:14 - challenge or though maybe i should try
74:15 - this
74:18 - uh
74:20 - i mean
74:23 - if the zero my my intuition is that the
74:26 - zeros and ones should just be in the
74:27 - corner
74:30 - oh but that's going to be
74:34 - the zeros
74:35 - i don't have enough zeros to put in the
74:37 - corner
74:39 - but if i did that
74:42 - right that's five that's five
74:45 - this won't be five
74:48 - oh but now i can do this
74:50 - oh but that's only four
74:53 - all right what am i missing here people
74:58 - we've got everything but this one
75:03 - can i what if i move this
75:05 - here and this what if i put a 2 in the
75:07 - corner
75:11 - oh now i'm confused what number should
75:12 - go in the corner
75:15 - okay hold on again
75:19 - if i put the two here
75:23 - the threes can't be together
75:28 - so the threes always have to be in the
75:36 - how many threes are there just three
75:39 - look at the chat no nobody's solving
75:41 - this for me in the chat
75:44 - oh i have to fit him with the
75:45 - awkwardness of not being able to figure
75:47 - it out
75:48 - okay
75:50 - um what am i missing i should have read
75:51 - all the explanation
75:53 - so
75:58 - so the ways to to make five out of these
76:01 - numbers and only have four numbers are
76:05 - one one one two
76:09 - two two one
76:12 - three two zero zero three two zero zero
76:19 - so
76:21 - is is three in the corner gonna help me
76:25 - or is two in the corner gonna one in the
76:27 - corner are gonna help me more what if i
76:29 - put all the ones in the corners
76:33 - there's only three of each other i'm
76:35 - confused yeah there's hold on reset
76:38 - yeah there's three of each i see
76:41 - definitely want high number in the
76:42 - corner to be used twice yeah
76:46 - okay three
76:48 - hello come on three
76:51 - so if that three is there
76:57 - uh let's put this three here
77:00 - let's think about this
77:02 - then now if where could a two go
77:11 - um with the only other place to put it
77:13 - through i could put a three here
77:15 - all right so let's think about this
77:17 - if the 3 is here
77:19 - if i put 2's here
77:25 - oh i can't put
77:27 - everything has to be a 0.
77:29 - what if i did that
77:34 - oh it can't there's not four zeros so
77:36 - one of these has to be a one
77:42 - then one of these can these can be zeros
77:50 - and then
77:53 - three
77:54 - ah no no no no no so close but no
77:58 - because the 1 is going to mess
77:59 - everything up here
78:04 - you have a total of 18 you want to make
78:06 - it add up to 20. so the tile you need to
78:07 - reuse has to add up to 2.
78:10 - well that's interesting so maybe the
78:12 - ones
78:13 - are what needs to be reused
78:16 - just one one
78:17 - oh hey let's think about this this is
78:19 - the strategy oh this is great
78:22 - 3 times 3 is 9.
78:26 - plus 6 is 15
78:28 - plus 3 is 18
78:30 - but i need to have a total of 20. so a 1
78:34 - being reused is one extra and another
78:37 - one being reused is another extra
78:40 - okay this makes sense this makes sense
78:42 - as a way of following it now then these
78:44 - have to be 0.
78:46 - so then a 3 and a 2 can go here
78:52 - 3 can go here a 3 can go here
78:58 - and then a 1
79:00 - no
79:02 - oh a 3 can go here
79:04 - and a
79:06 - 0. then a one oh i think i did it and a
79:10 - two
79:11 - and a two
79:15 - thank you forever that so that was the
79:17 - logic that was being explained that i
79:18 - like scanned over
79:21 - from first of all by the way these are
79:23 - so fun like if i what i really would
79:25 - like to do is make a p5.js sketch where
79:27 - you can make these puzzles i mean that's
79:30 - um
79:32 - all right
79:33 - oh and uh
79:35 - so i maybe i could have also done this
79:37 - mike on the box says all the corners are
79:39 - zero but one is a two maybe it would
79:41 - also work that way so i i'd love to
79:43 - decide are there two solutions all right
79:46 - so now here's the actual challenge
79:48 - is it possible to arrange five square
79:50 - tiles numbered one two three four five
79:52 - into a plus so the sum of the three tile
79:55 - column and sum of three tile row so we
79:57 - need to add up to 18
80:00 - and these numbers add up to 9
80:03 - 12
80:04 - 14 15. so i need three more no it's not
80:08 - possible i was gonna put this as a poll
80:10 - but i think it's not possible because
80:13 - there's no number i could put in here
80:14 - twice
80:16 - to give me three extra
80:19 - because one gives me one extra two gives
80:21 - me two extra three gives me oh no three
80:23 - gives me three extra yes
80:26 - [Music]
80:28 - three has to go in the center that's
80:30 - totally wrong i don't know what i was
80:32 - thinking there i was thinking three
80:33 - doesn't divide into two like so i can't
80:35 - put a one and a half in the center but
80:37 - no i just need three more did i do that
80:39 - right
80:40 - let's see
80:41 - uh nine i i i you know i usually like to
80:44 - do these with a poll in the chat
80:46 - but there's uh so i could do let's let's
80:49 - just make the poll
80:51 - it possible or not possible while i'm
80:53 - figuring this out i mean i think i
80:54 - hopefully i was right so i'm gonna make
80:56 - the poll possible
80:58 - or not
80:59 - yes or no
81:01 - no no no add another option
81:04 - how do i delete that now
81:08 - no
81:09 - delete okay
81:10 - so there should be a poll that went up
81:12 - into the chat just now
81:14 - it might take a minute to post where you
81:16 - can just give me is it possible or not
81:18 - and i'm going to work it out
81:19 - so we need to add them up to nine
81:22 - wait what
81:30 - i'm so confused eighteen
81:34 - nine
81:38 - how do i do oh no no four okay okay okay
81:41 - the five and the four can't be together
81:43 - obviously
81:44 - that's eight yeah nine okay this one's
81:47 - two
81:48 - why was the other one so much harder for
81:49 - me
81:51 - there we go i've made them hit submit
81:55 - and now we can see the solution
81:58 - which is that 3 the sum of the row and
82:00 - column is 18. the sum of all the tiles
82:03 - is 15. the middle tile is counted twice
82:05 - so the middle tile must be 18 minus 15
82:07 - or 3.
82:09 - and then of course
82:11 - now we just need the desired sum in the
82:12 - row and then the desired sum in the
82:14 - column okay
82:16 - 93 of you said yes you got it right
82:20 - uh um and so uh thank you i've been like
82:24 - is this not fun like this is what i want
82:26 - to do later today with my free time are
82:28 - you like that
82:30 - and i just want to emphasize like um if
82:33 - you like a lot of the algorithmic art
82:35 - stuff or generative art stuff that i do
82:36 - on the channel the beautiful geometry
82:38 - course is really the one for you so
82:40 - thank you brilliant for sponsoring the
82:41 - coding train if you're watching and have
82:43 - a minute right now i turn the heat on
82:46 - uh to sign up at brilliant.org cutting
82:48 - train you could do that for free if
82:49 - you'd like to buy the premium
82:50 - subscription for yourself or gift it to
82:52 - a friend or loved one or anyone um
82:55 - you'll get the first 200 people to do
82:57 - though will get 20 off okay i'm gonna be
82:59 - back in about
83:01 - uh two or three minutes to see if we can
83:04 - get the auto encoder running in the
83:06 - browser so don't go anywhere
83:09 - come back stay with me i'll be back i'm
83:11 - gonna turn the heat on for two or three
83:12 - minutes warm up my hands and i'll be
83:14 - right back
83:16 - [Music]
83:23 - so
83:25 - [Music]
83:34 - [Music]
83:41 - [Music]
83:46 - oh
83:48 - [Music]
84:07 - [Music]
84:20 - [Music]
84:29 - [Music]
84:36 - [Music]
84:49 - [Music]
85:03 - [Music]
85:14 - [Music]
85:19 - [Music]
85:25 - [Music]
85:31 - do
85:35 - [Music]
85:43 - [Music]
86:02 - do
86:18 - [Music]
86:28 - all right i am back just out of
86:30 - curiosity how loud
86:33 - is that hum in the background right now
86:35 - which is the heater going so i'm gonna
86:38 - if it's tolerable i think i'll leave it
86:40 - running for a little bit longer
86:45 - all right everyone
86:47 - so
86:49 - the next thing that i need to do
86:53 - um and i'm keeping an eye on the chat in
86:55 - terms of the volume is i want to just
86:56 - really quickly create a
87:00 - webpage that loads the model and draws
87:03 - the output
87:06 - to a canvas so i'm going to use p5 and
87:09 - tensorflow.js and i believe that at some
87:11 - point there's no reason why i couldn't
87:13 - use ml5 which i would like to but i'm
87:16 - right now i'm not sure if ml5 supports
87:19 - all of the sort of things that i'm doing
87:21 - with tensorflow.js you might be asking
87:23 - like what's ml5 so ml5 is a javascript
87:26 - library
87:27 - that i
87:29 - helped to work on with a lot of
87:30 - wonderful collaborators and people
87:33 - that is a sort of helper layer on top of
87:36 - tensorflow.js to use a lot of
87:37 - pre-trained models and do a lot of stuff
87:39 - and if you want to learn more about ml5
87:42 - if you go to thecodingtrain.com under
87:44 - learning uh ml this the this video
87:47 - series
87:48 - um has just a ton more stuff so at some
87:52 - point
87:53 - my hope would be
87:55 - um
87:58 - it's oddly cut i love all the comments
88:00 - about the sound it's oddly soothing
88:02 - tolerable i love me some calming white
88:04 - noise it's audible but we want you to
88:06 - stay warm so it's all right sounds like
88:08 - a vacuum cleaner all right i'll leave it
88:10 - running for a little bit here
88:11 - one of the reasons why i don't want to
88:13 - run it and let me just vamp for a little
88:15 - bit is that
88:17 - i have this idea
88:19 - that one of the things i want to do with
88:21 - the coding terrain in the new year
88:23 - is make some more kind of
88:26 - video essay like video essay like videos
88:30 - about things like an auto encoder and
88:32 - narrate the process using clips from
88:35 - these live streams so that you could get
88:38 - maybe the sense of how to build the
88:40 - whole project in a 10 to 20 minute video
88:43 - and then if you wanted to of course you
88:45 - could go back and watch all the
88:46 - development during the live streams so
88:48 - i'd have to script that
88:50 - edit that have some animations and
88:52 - things i love your feedback i'm trying
88:53 - to think of like you know
88:55 - i'm on sabbatical for my job at nyu
88:57 - starting in the new year so i'm going to
88:59 - be focusing not full time on the coding
89:01 - train of a lot of other projects and
89:03 - things to work on personally and for
89:06 - creative coding community but
89:08 - i do want to ramp up and at least be
89:10 - doubling my time or tripling my time
89:12 - that i'm currently spending on the
89:13 - coding trade which is very very little
89:15 - so thank you by the way to everyone i
89:17 - don't know how many of you are watching
89:18 - but thank you to all of you who continue
89:20 - to support me through all the ways that
89:21 - you do even when i feel like i'm not
89:24 - doing it enough for good enough so i
89:27 - really appreciate that um
89:30 - okay mike on the box is asking about the
89:32 - cabana i've moved the cabana may come
89:34 - back
89:35 - but right now i'm i'm in a garage which
89:38 - is much bigger than the cabana so
89:41 - uh yeah
89:42 - um okay
89:44 - uh okay so
89:47 - let's go back here okay so what i'm
89:49 - gonna do is
89:52 - let's just go into
89:54 - this project
89:56 - and create a new folder
89:59 - i'm going to call it i'll call i mean at
90:01 - some point i could have this be a full
90:03 - stack web application where the you can
90:06 - send a message to the server to like
90:07 - retrain the model so i'm going to like
90:09 - sort of build it in the way that i might
90:11 - do that so i'm going to call this public
90:13 - and in public i'm going to create
90:15 - index.html
90:18 - and
90:19 - another new file
90:21 - called oops
90:22 - ah what am i doing here
90:25 - don't save
90:27 - don't save so index.html
90:30 - and then i want to create another new
90:32 - file
90:37 - called sketch.js it's in the wrong place
90:42 - i'm sorry you can't see what i'm doing
90:45 - oh my goodness
90:46 - i totally forgot to be recording this
90:48 - whole session
90:50 - so much for that whole speech on what
90:52 - i'm trying to do
90:57 - oh my god i'm the worst
91:00 - i'm the worst
91:02 - well i'm going to start recording it now
91:04 - now i'm recording it so that whole
91:07 - i mean they could still use clips
91:08 - obviously it's being recorded in the
91:09 - sense that when i'm broadcasting it's
91:10 - being recorded but
91:12 - ah
91:17 - okay so much for my grand plan there
91:19 - well still still possible
91:26 - okay
91:27 - um
91:30 - the quickest way for me to
91:32 - let me just get let me just go to the p5
91:34 - web editor
91:36 - this is my html file
91:40 - uh
91:41 - oh whoops that's in the wrong place
91:44 - public yes move
91:48 - and then my sketch file is
91:52 - it's very hard to type when your hands
91:54 - are cold
91:56 - function draw
91:59 - uh
92:07 - what
92:08 - i've got some crazy autofill stuff going
92:10 - on here
92:22 - and
92:23 - um
92:26 - let's just do okay let's move the model
92:29 - into public as well
92:33 - and then when i run the node script
92:36 - to train a model
92:38 - we want this to go into
92:44 - file public but
92:46 - i'm not doing that right now
92:49 - what i'm doing here is
92:52 - i don't need the sound library
92:56 - let's go back to
92:59 - the tensorflow.js documentation
93:07 - no not overview
93:09 - api reference
93:14 - okay maybe overview
93:19 - get started
93:23 - no there's still a nice link there's a
93:24 - nice link to ml5 here that's so lovely
93:28 - um
93:34 - i'm just looking for like the um guide
93:36 - maybe
93:39 - i just want to know what where the
93:41 - script tags i need
93:46 - install
93:50 - but i want tensorflow.js to install ah
93:53 - this is why are things so hard to find
93:56 - is it just me
93:57 - is it me
94:00 - setup
94:02 - there we go i found it it was in an
94:04 - obvious place can i use tfjs 2.0 i hope
94:07 - so
94:09 - why not so let's try this
94:15 - okay so i've got tfjs
94:18 - now
94:20 - what i'm going to do is i'm going to
94:22 - open
94:23 - a separate
94:27 - web server
94:29 - so ultimately again like where i might
94:31 - go with this project is have it all be
94:33 - one application where there is a server
94:36 - that you can like send messages to to
94:38 - like train them retrain the model and do
94:40 - different things and then there's a
94:41 - client that can load the model and do
94:44 - stuff but right now i'm just treating
94:45 - those as separate projects
94:47 - so this is
94:48 - the client
94:50 - and you can see that my
94:54 - p5.js sketch
94:56 - is loading oh style.css i don't need to
94:58 - worry about that
95:00 - so let's
95:04 - i don't know what how this got over here
95:09 - let's get rid of that
95:14 - great
95:15 - so now i have so the goal that i have is
95:17 - to see an output image in that canvas
95:22 - uh
95:24 - yeah sorry everybody about the sound
95:27 - of course now i'm finally recording now
95:30 - is when i have the bad sound and i
95:31 - wasn't recording the whole time when i
95:33 - had the good sound but i just got to get
95:35 - it to warm up a little bit more in here
95:37 - um i don't know
95:39 - this is not something that i really
95:40 - thought about
95:42 - how to
95:44 - once i once i
95:46 - once i solar power this place maybe some
95:48 - electric heaters i can do that i'll be
95:50 - quieter we'll see
95:52 - um
95:56 - okay so now i should be able to
96:01 - have a
96:04 - variable called like auto encoder
96:08 - uh auto encoder equals
96:12 - tf
96:14 - so this should be the same exact code
96:16 - that i'm doing on the server
96:21 - the difference being
96:26 - i shouldn't need the file path anymore
96:29 - and this has to then be an async
96:30 - function
96:33 - and let's do console log
96:36 - auto encoder so let's see if this works
96:41 - well that's a good sign
96:43 - this looks good
96:46 - i feel like it loaded it i got no error
96:48 - and i see an object that looks like a
96:49 - model
96:51 - so now
96:52 - if i go back to the server code
96:55 - and do generate
97:04 - okay
97:05 - x test
97:07 - so now what i want to do
97:09 - is in the draw loop i'm going to just
97:12 - feed at some noise
97:14 - um
97:16 - i'm going to say no loop oh where am i
97:18 - i'm in the web header i don't want to be
97:19 - in the web editor i could be in the web
97:21 - editor but i'm not doing it there
97:23 - um
97:24 - i'm going to say no loop is the font
97:26 - size okay for everybody it's a little
97:28 - smaller than what i usually work with
97:32 - output is auto now x test has to be a
97:35 - tensor
97:37 - so again at some point
97:40 - um
97:43 - where did i make x test
97:45 - images slice so let's think about this
97:48 - what is one image
97:52 - oh i could draw an image
97:56 - okay
97:58 - uh
97:59 - like what if i just make the image a
98:01 - blank array
98:03 - and i know there's a higher order
98:05 - function like that i could use fill
98:08 - and so 784 pixels
98:14 - and if i make that just like a random
98:15 - number i'm just going to feed noise in
98:17 - right now because i'm not sure what else
98:18 - to do
98:20 - um
98:21 - and then
98:23 - uh
98:26 - this would be
98:32 - turn that into a two that image into a
98:34 - 2d tensor
98:37 - and like i only have one
98:39 - so it's just that one image in an array
98:41 - is this
98:43 - right where
98:46 - like
98:50 - images like tensor2d imageslice500 yeah
98:53 - and then
98:55 - and then i should be able to just call
98:56 - predict
99:10 - and then this is an a if this is an
99:12 - async function
99:16 - i get the new image
99:22 - all right let's just try console logging
99:23 - this
99:27 - call this output image
99:34 - so it should just be one and so i'm just
99:36 - doing one image i'm creating a random
99:38 - array of noise
99:40 - i'm turning it into a tensor i'm sending
99:42 - it into the auto encoder i'm getting
99:44 - something back out and just logging it
99:46 - to the console let's see if this works
99:51 - okay good sign
99:53 - why did i do it twice
99:57 - why did i do it three times
99:59 - because i have no loop i wonder if
100:02 - something weird about the async and the
100:03 - no loop let's get rid of draw for a
100:05 - second here
100:08 - and just do this once
100:12 - and let's not log the autoencoder
100:14 - anymore let's run it again
100:17 - okay great once
100:18 - so i got my image now i should be able
100:21 - to and this is very silly what i'm going
100:23 - to do but it's and can i just do this
100:26 - will that work with or do i have to do i
100:28 - probably have to put parentheses around
100:29 - the await
100:33 - so that's the output image okay now what
100:37 - i could do is say load pixels
100:42 - update pixels
100:45 - oh no no no i want to draw it bigger so
100:48 - i'm going to do this this is a little
100:49 - crazy but i'm just going to draw it as a
100:52 - again sorry for all the noise in the
100:53 - background
100:57 - but it's making it possible for me to do
100:59 - this right now
101:03 - um
101:07 - oh i know i need another bracket
101:09 - and then i'm going to say
101:10 - rectangle i
101:13 - i got to fix my vs settings i times 10
101:17 - j times 10
101:19 - 10
101:20 - really square is what i want
101:23 - i'm going to say fill
101:27 - out
101:29 - output
101:30 - image
101:33 - i plus and this should be a j
101:38 - i plus j
101:44 - times the width which is 28. and again
101:48 - i'm hardcod i'm just i'm hardcoding all
101:50 - sorts of stuff
101:56 - um
101:58 - i'm looking at the uh all right
102:00 - everybody let's be nice to each other
102:02 - let's be nice to the fact that i need to
102:03 - run a heater let's be nice to the fact
102:05 - that we're all asking questions and not
102:06 - sure what's going on i'm very confused
102:08 - i'm not explaining everything let's be
102:10 - nice to each other in the chat please um
102:13 - so i'm looking for the pixel that
102:15 - corresponds with the square that i'm
102:17 - going to render which is the x plus the
102:18 - y times the width
102:20 - and then multiply this times 255 now
102:23 - this should probably just be noisiness
102:26 - but let's see
102:30 - uh
102:31 - oh what what import uh
102:34 - just trying to auto import stuff
102:41 - i've never seen so excited to see a
102:43 - square in my life
102:44 - that is insanity
102:48 - oh my goodness
102:54 - i didn't even that's funny
102:56 - i could like basically have the latent
102:58 - space be the beginning
103:00 - wow this is crazy
103:04 - i
103:05 - i weirdly i don't know why
103:08 - but i weirdly want to do this
103:12 - just because i like seeing the full
103:13 - square
103:17 - but also that's silly
103:20 - what i could do let's do this
103:23 - this is so this is like the silliest
103:24 - thing i've ever done in my life that
103:26 - this is what i'm focusing on right now
103:32 - how do you do this
103:36 - is that correct css
103:40 - yeah that's what i i just wanted to do
103:41 - that okay
103:43 - right how did it produce the script
103:45 - monothon asks everything that i'm i'm
103:48 - asking right now in my head how did it
103:50 - produce a square if the input wasn't a
103:52 - square that's cool right so i think the
103:56 - denoising should work now all right
104:01 - you would think right
104:04 - can this model
104:07 - let's do the following
104:08 - let's do an a real input square and a
104:11 - real output
104:13 - so um 280 times two
104:17 - 560 right
104:20 - and then
104:29 - i'm going to do this create graphics or
104:31 - create image
104:34 - uh 28 by 28.
104:37 - um
104:38 - oh no i need to do create graphics
104:41 - oh no this is fine
104:43 - i'm drawing it a square i can it's fine
104:45 - i don't need to put it on a separate
104:55 - background 255 now
104:59 - okay so what i want to do now is have
105:02 - the filter invert 100
105:05 - what i want to do is have an input image
105:07 - and see the output image so let's draw
105:10 - the output image
105:14 - on the other side
105:17 - and now i want to see the input image on
105:19 - this side so the input is so this would
105:23 - be this can be a function
105:27 - a
105:28 - function render
105:31 - sum
105:33 - array
105:34 - image array
105:37 - at some
105:38 - x and y
105:41 - so this would be x
105:43 - x plus
105:44 - that and this is the image array
105:48 - and the width and height i've still got
105:50 - hard coded here in this like scale 10
105:53 - that should be fixed at some point but
105:55 - now what i should be able to do is
105:56 - render
105:59 - output image
106:00 - at 280 comma zero
106:06 - still getting the same thing a little
106:08 - i'm a little bit suspicious of the fact
106:10 - that the
106:11 - square never changes its size
106:16 - oh no no it's different it's different
106:18 - each time just very subtly so okay
106:21 - now
106:22 - there's no reason why i can't say render
106:25 - image zero zero
106:31 - oh this is insane
106:33 - so i could make this like so
106:36 - i want to get to the browsing the latent
106:38 - space part
106:40 - but weirdly i could just turn this into
106:42 - like
106:44 - a pearl and noise field
106:46 - that's like subtly changing over time
106:49 - and see what happens to my output image
106:53 - like i'm not even like the whole point
106:55 - of this is so i can get down to that
106:56 - reduced dimensionality but i can
106:58 - actually play with this input because
106:59 - it's just 784 values
107:02 - this is this is so i'm so excited by
107:05 - this i can't i mean this is like the
107:07 - most basic of the basic of the basic but
107:09 - i'm uh this is just like
107:12 - really unlocking for me um
107:15 - this like sometimes it just feels like
107:17 - total matte and this feels this even
107:19 - feels like magic but it when you see
107:20 - like these really sophisticated
107:22 - generative models but really being able
107:24 - to like all the pieces of everything
107:25 - going on here we have coded and designed
107:28 - yes the actual machine learning math is
107:30 - coming from the underlying tensorflow.js
107:32 - but how we're manipulating this what
107:34 - data we use of total control over
107:37 - so
107:38 - um
107:40 - what i would like to do now is i would
107:42 - like to put this into the draw loop
107:45 - let's just see what happens here
107:48 - if i just put this
107:50 - async function draw
107:54 - like what if i how
107:57 - okay nope
107:59 - what did i mess up
108:04 - oh the auto no
108:08 - can i read properties of undefined
108:10 - reading predict oh this has to be a wait
108:12 - no
108:19 - what am i doing wrong here
108:25 - wait output array render
108:30 - as if oh no now i didn't get an error
108:34 - but i'm not seeing the
108:37 - i think that a i think a sinking draw
108:41 - is a real problem here
108:44 - so let's not async draw
108:47 - let's let draw
108:49 - go
108:51 - ah this is why i don't like doing this
108:55 - in the browser
108:58 - it's got to be the fact that i'm
108:59 - asyncing draw right
109:02 - so what if i just do
109:06 - like my own
109:08 - loop
109:10 - so let's call this
109:12 - input image
109:15 - oh shoot
109:23 - so this will be an async function
109:28 - this in
109:30 - return
109:32 - output image
109:34 - this isn't really no because
109:39 - all right let's make these glo this is a
109:40 - bad idea but let's just make these
109:42 - global
109:47 - so this is
109:50 - uh
109:55 - and then when you get the next image
109:58 - we make a new one
110:15 - hold on
110:20 - what if i do this
110:22 - let's just let's just initialize them
110:26 - this is sort of i don't i don't like
110:27 - what i'm doing but i just want to make
110:29 - sure it works
110:42 - and then let's just
110:46 - i'm just going to fill them randomly
110:53 - and then
110:54 - this just renders both of them okay
111:02 - oh input image index i
111:05 - i i should see just two random images
111:08 - great so i got two random images
111:12 - um
111:15 - yeah that cr what chris is suggesting
111:17 - you could have draw a whatever is latest
111:19 - finished and your asic function called
111:21 - itself recursively is what i'm going to
111:23 - do there also is an array sync function
111:25 - i think where i can make that conversion
111:28 - to data so mike on the box is asking why
111:30 - do i need a weight so the
111:32 - the three the thing with using
111:34 - tensorflow.js is it's doing all the
111:37 - machine learning math on the gpu
111:40 - and there is
111:42 - uh com there i mean i'm using so little
111:44 - data that this is so unnecessary i
111:46 - should send the back set the back end to
111:48 - cpu but
111:49 - you need to uh have any time that you
111:53 - are taking the data out and turning it
111:55 - in and off of the gpu so that i can
111:57 - manipulate it in my code that needs to
111:59 - be an asynchronous function so this
112:02 - return is unnecessary
112:05 - so what i'm going to do
112:09 - is call
112:12 - await next
112:13 - image
112:14 - so
112:16 - let's just see if i can get one new
112:19 - image
112:20 - no image is not defined
112:25 - where am i still using image
112:27 - uh here
112:32 - okay great so i've got one
112:35 - and now
112:37 - i should be able to just call next image
112:39 - now sometimes this will lock up the
112:42 - browser if i don't like give this a
112:44 - little bit of like daylight here like
112:46 - with a set timeout but let's just see
112:50 - okay great no no problem so this is now
112:53 - working i'm just always drawing the
112:55 - latest thing
112:57 - so now again i want to make this a
112:59 - proper latent space but i cannot resist
113:05 - pearl and noising this
113:07 - so we're going to create x
113:10 - off no i'm going to need to use
113:14 - no this will be z off
113:18 - and then
113:19 - the next image is
113:26 - x offset equals zero
113:30 - no let's do this properly
113:34 - let i equal zero i is less than 28. i
113:37 - hate that i have this hard-coded in here
113:38 - i've got to fix that up
113:50 - so we're going to have
113:52 - j is the y offset
113:56 - gonna have an x offset now you might be
113:58 - like what are you even doing right now
114:01 - so i would assume that let's say 2d purl
114:04 - in noise
114:07 - there we go
114:08 - thank you google for referring to me but
114:11 - um
114:12 - so what i'm doing is i'm taking this
114:14 - concept of having two dimensional purlin
114:16 - noise which you can learn more about in
114:18 - this video from
114:20 - five years ago
114:22 - how long have i been at this oh my god
114:26 - and using that as a way of manipulating
114:28 - the input
114:30 - i really should do the denoising
114:32 - but
114:33 - i can't resist this
114:35 - so you may not understand fully but i'm
114:37 - going to say let value equal noise x off
114:41 - y off z off
114:44 - so every j
114:46 - the y off should go up by some
114:48 - incrementation
114:52 - no stop autofilling things for me
114:55 - the
114:57 - x off
115:00 - should also go up by some incrementation
115:02 - value
115:04 - and then also
115:07 - wait i'm missing a curly bracket right
115:10 - next image curly bracket
115:13 - for
115:15 - what did i do wrong here
115:23 - i just
115:32 - oh
115:33 - oh no that's the end there
115:36 - what just happened
115:38 - ah i forgot that this function has more
115:41 - to it okay
115:42 - we're okay
115:45 - there we go
115:46 - and then z off
115:49 - goes up by that incrementation as well
115:54 - we're going to make it a slow increment
115:55 - let's try this for right now
115:59 - and then
116:01 - the input
116:03 - image
116:04 - in
116:05 - i plus j times 28
116:08 - equals that value
116:12 - all right so let's see what happens here
116:18 - oh we've got some weird extra imports
116:20 - again
116:24 - uh syntax error in line 26.
116:28 - that should be an equals
116:33 - so here i am i mean yeah
116:36 - so this uh the z offset incrementation
116:39 - is kind of wildly
116:41 - too high
116:46 - oh wait no why did i oh that's x off
116:51 - i guess i should have a different
116:58 - yeah
116:59 - so this is this sort of like cloudy
117:01 - pearl and noise field that is changing
117:04 - and slowly over time we're seeing late
117:06 - so again
117:08 - i'm gonna really need oh it's 11 54. i
117:10 - have to wrap up uh this is definitely
117:12 - needs
117:13 - uh
117:16 - right michael kempt is pointing out a
117:18 - very good point which is just because
117:19 - pearl and noise only moves slightly does
117:21 - not mean the output squares will follow
117:23 - so i got a little sidetrack whereas i
117:25 - really should just be working with just
117:26 - the decoder
117:28 - but
117:29 - i think i can i i've got to go
117:31 - unfortunately about five minutes because
117:33 - let me just check
117:34 - um
117:36 - okay because my um
117:39 - i gotta get back to my kids
117:40 - for her i could give you all the details
117:42 - about that but that's the that's the
117:44 - summary but um
117:47 - and that's why you're excited for the
117:48 - actual latent space it's more likely to
117:49 - be a smooth but i think i can get
117:51 - something a little bit more exciting
117:53 - here
117:54 - um so what i would like to do
117:56 - well first i would like to test the
117:58 - denoising
118:04 - that's going to send me i really want to
118:05 - test the denoising but
118:08 - the two things i wanted one would be
118:09 - testing the denoising i'm pretty sure
118:11 - the denoising is going to work though
118:13 - because even just like random noise
118:14 - gives me a square so you would think
118:17 - that random noise with a sort of
118:19 - darker
118:20 - high square embedded inside of it would
118:22 - really give me the square but i think
118:24 - what might be more interesting is for me
118:26 - to have an output with much more variety
118:31 - so should i stick i also kind of am
118:33 - tempted to bump up the resolution i
118:35 - think i'll stick with 28 by 28 though
118:38 - and what i'm going to do is this is my
118:42 - data generation
118:44 - so i am going to say first of all i want
118:46 - the
118:48 - size of the images to be
118:50 - have much more variety so let's allow it
118:52 - to go all the way down to 25
118:55 - then let's also say if random
119:01 - is less let's flip a coin
119:03 - and have it either be a square
119:06 - or a circle
119:13 - let's also i mean i think 500 images
119:16 - should i double the number of images
119:19 - just because
119:22 - um
119:24 - just because now i'm doing squares and
119:26 - circles
119:29 - let's see let's so let's try this
119:33 - so now my images are both squares and
119:36 - circles i'd love to introduce triangles
119:38 - in there but i think this will give us
119:40 - something more interesting just to start
119:42 - with
119:43 - because what i want to see with the
119:44 - latent space is the morphing between
119:46 - squares and circles
119:49 - and i i unfortunately the latent space
119:50 - is gonna have to wait till next time
119:52 - although i am planning to live stream
119:53 - this coming friday
119:54 - i could do it tomorrow
119:56 - probably not though tempted to come back
119:58 - tomorrow we'll see
120:02 - so now if i take this data
120:06 - right which should be
120:09 - squares and circles so this is now the
120:12 - new training data
120:15 - and
120:19 - let me just have is the code loading
120:20 - directly from that now i'm going to go
120:22 - back to my training code
120:30 - i could um
120:33 - let's generate whoops ah
120:37 - let's put the training back in
120:46 - ah sorry everybody what is going on i'm
120:48 - so
120:49 - having trouble i'm just going to
120:50 - manually do this
120:58 - so i want to load now 1100 images
121:02 - i want to train
121:04 - train the first 1000
121:07 - and then the rest will be the tests
121:10 - um image loading where are the images
121:13 - being pulled from when i load all images
121:16 - uh so i think i might liked it to go
121:19 - directly into
121:21 - whatever processing has outputted most
121:23 - recently
121:25 - by the way i'm going to turn since i'm
121:26 - wrapping up i'm going to turn the heat
121:28 - off
121:33 - all right
121:35 - it's plenty warm in here and i'm going
121:36 - to be wrapping up soon so i've turned
121:38 - off the heat
121:39 - um
121:40 - so i'm going to grab this
121:42 - i'm sorry to be rushing a little bit
121:44 - here
121:44 - oh and they're all called square that
121:46 - doesn't matter
121:48 - and there's a thousand of them
121:51 - so oops no but that's fine the last one
121:52 - would be 999.
121:55 - wait a sec
121:57 - like i want to get rid of this
122:00 - and
122:03 - what
122:05 - oh i need four i need uh no no it worked
122:08 - no but let me
122:11 - so this should have a four here
122:16 - let me run that again
122:19 - oh actually ah no stop
122:22 - sorry everybody
122:25 - data is a thing okay
122:28 - delete all this
122:32 - the chat has gone quiet again
122:37 - so what i'm learning by the way is which
122:38 - is totally fine is the those of you who
122:40 - are here
122:41 - thank you it's a small audience for this
122:43 - on sunday morning
122:45 - let's generate the data again
122:49 - 1100
122:51 - is that right
122:52 - yeah okay so now
122:54 - and then what i wanted to do is have
122:56 - yeah the images come from oh and
122:59 - this is so silly but it's fine i'm going
123:01 - to leave it as saying square that i do
123:03 - need to change because they're not all
123:05 - squares so i should probably use a more
123:06 - generic term
123:08 - but oh oh oh and then now
123:10 - i should be able to put that in there
123:13 - is there another place where i'm numeral
123:15 - formatting things
123:23 - i don't know what this is
123:25 - is this right this is writing the output
123:26 - but that's fine
123:30 - and so
123:32 - this should go to
123:34 - the actual data from processing so let's
123:36 - see what happens and then
123:40 - we want a thousand and then the 100 for
123:44 - the tests okay
123:46 - so now i should be able to train the new
123:47 - model
123:52 - oops line 21.
123:55 - oh
123:56 - i'm not loading anymore
124:05 - oh this is going to take a while for 100
124:07 - epochs there's a lot more data
124:09 - let's see how the loss goes
124:20 - all right so q who just joined kyu
124:24 - what i'm doing is i have trained an auto
124:27 - encoder
124:30 - to
124:34 - which is a machine learning model
124:36 - to try to reproduce generic images of
124:39 - squares and circles
124:41 - so right now i'm training that model and
124:43 - once it's done i'm going to load a
124:44 - webpage which shows the results of what
124:48 - the model generates when random noise is
124:50 - fed into it
124:51 - there's a lot more pieces to this that
124:53 - i'm
124:55 - sort of missing here
124:57 - at 6 00 p.m
124:59 - yeah
125:01 - um
125:02 - okay we got to 100 okay so now
125:07 - so first of all we have a little we have
125:09 - some test things that i generated just
125:10 - to see
125:12 - so the output
125:14 - folder
125:16 - should now have new oh um i have to look
125:18 - at the noon ones
125:20 - yeah it's like a circle square squirkle
125:23 - is that the term
125:25 - okay great so we're seeing stuff so now
125:27 - in theory
125:28 - if i refresh this page
125:32 - [Laughter]
125:36 - this is so cool
125:38 - you can see this sort of like it's like
125:39 - a latent space browsing
125:42 - but i'm not really doing that yet
125:45 - now
125:47 - could i expand
125:50 - the universe of the inputs
125:53 - like purlin noise is very sort of like
125:55 - limited around the
125:57 - like i'm just curious
125:59 - so this is where i'm going to wrap up
126:00 - today i'm very happy with this result
126:02 - even though clearly i need a part four i
126:05 - need a part four
126:07 - um
126:09 - i would love to like just swap in open
126:11 - simplex noise but one thing i can do
126:14 - very quickly is i can do two times i
126:16 - mean i shouldn't do this
126:22 - but
126:24 - like i'm feeding in like weird negative
126:26 - numbers and stuff that it doesn't know
126:27 - about
126:28 - so just to sort of see
126:34 - this isn't wild
126:38 - um all right let me just go back to
126:40 - i'm not doing this weird thing that i
126:42 - just did here
126:46 - so ah all right
126:48 - oh 1204 okay okay just give me like five
126:50 - more minutes because i just want to see
126:53 - like i want to have a sense of
126:56 - am i capable of doing this at
126:59 - uh double the resolution right now
127:03 - so now unfortunately i've hard coded
127:05 - everything
127:07 - so let's just look for a second in
127:10 - it's like what if i were to
127:15 - uh i don't know about this oh yeah
127:17 - resize everything to
127:21 - so let me just do a little cleanup
127:24 - here just to leave this
127:28 - because i want to leave this in a place
127:29 - where people can play with it so i'm
127:30 - going to delete all the output
127:35 - i'm going to
127:36 - [Music]
127:38 - the model can stay there
127:40 - i'm going to delete the training data
127:45 - i want to just go through and then
127:52 - so let's do 28 times 2
127:54 - which is 56
127:57 - 20 20 plus 20 is 40. 8 plus 8 is 16 56.
128:03 - so let's just try it double
128:07 - um so that's so i'm going to make this
128:08 - training data it's going to be a little
128:10 - bit higher resolution
128:12 - then when i go into
128:14 - [Music]
128:15 - the
128:17 - auto encoder
128:20 - do i have it hard-coded anywhere like
128:22 - 700 yes
128:23 - so now that is that the only place where
128:25 - that's hard-coded there's two places
128:28 - and then is 28 anywhere
128:31 - no
128:32 - okay so i need in this
128:34 - oh here it is so
128:37 - i need to have a constant w equals 56
128:44 - and so this should be
128:45 - w times w
128:51 - this should be w times w
128:54 - and then this should be
128:56 - w times
128:58 - w
128:59 - is there any 28 anywhere
129:01 - w this is w this is w
129:07 - that's just 128
129:09 - and is there any 784 hardcoded anywhere
129:12 - no then i should be able to go back to
129:14 - the sketch
129:15 - and also have i not really
129:20 - this
129:22 - so this should be
129:24 - uh w times w
129:30 - and this is w times w
129:33 - this is w
129:34 - this is w
129:37 - w
129:41 - this is
129:42 - all right so this i have to think about
129:43 - now
129:47 - so
129:48 - then i also have like little w
129:52 - which equals i'm just going to say
129:54 - height
129:55 - divided by
129:57 - the big
129:58 - w because then
130:02 - that is
130:05 - w times w
130:07 - right
130:09 - is how far over
130:11 - this is w
130:12 - w and then this is
130:14 - little w
130:15 - little w
130:18 - little w i think i did this correct so
130:21 - now all i need to do is
130:24 - like if i want to use a higher
130:26 - resolution image this is like whatever
130:27 - that is i just have to change it in two
130:29 - places here well three places the
130:31 - processing sketch the p5 sketch and the
130:34 - node server
130:36 - so i did it already here
130:39 - i didn't actually make it a variable
130:41 - here
130:42 - just to be consistent
130:45 - let's do that again there's there would
130:48 - be
130:48 - you know tying all these together would
130:50 - be better but now i should be able to
130:52 - train the model it's going to take much
130:54 - longer now i don't know how long
130:57 - like that's one epoch
131:00 - so one epoch was a few seconds there so
131:02 - this is going to take a while line 49
131:08 - um so i don't know what line 49 was
131:11 - referring to
131:13 - um
131:15 - i think i got it already i'm assuming
131:18 - if it was in here
131:20 - if it wasn't here
131:24 - thank you missed one
131:27 - thank you for that
131:28 - yeah those variable names ouch yeah this
131:30 - is terrible so pull requests that i'm
131:32 - looking for
131:34 - are cleaning up the variable names love
131:36 - that making a nice readme that sort of
131:39 - explains everything and links to these
131:41 - live streams
131:42 - i would love pull request contributions
131:44 - for that i mean in january i'll get to
131:47 - it myself
131:50 - but
131:51 - i'm at epoch 31 oh boy this is going to
131:53 - take a while
131:56 - but this is
131:58 - this is um this is going to be the end
132:00 - for today i i did not the things that i
132:02 - didn't get to
132:03 - is
132:04 - just lopping off the input so the two
132:08 - the three the things that i wanted to
132:09 - try and this could go into the readme if
132:10 - anyone wants
132:11 - who's keeping notes on any of this
132:13 - nobody my mental notes are i want to see
132:15 - if the denoising works
132:18 - and then
132:19 - then i want to
132:22 - uh also
132:23 - actually work with the proper latent
132:25 - space by feeding the input like i just
132:28 - have eight
132:29 - dimensions and creating sliders to
132:31 - manipulate those
132:34 - that's next on the agenda
132:36 - um
132:38 - and
132:39 - [Music]
132:40 - you know then also trying training like
132:42 - rgb color could i do
132:44 - how high of a resolution can i push it
132:46 - we can see how long this is taking
132:47 - already
132:48 - just for um
132:51 - a hundred epochs but i'm halfway through
132:53 - i don't know this probably doesn't need
132:55 - to train much longer the loss is still
132:57 - going down
133:03 - um thank you for all these chat messages
133:06 - uh
133:06 - um
133:09 - is my discord even working there's
133:11 - nobody nobody putting messages into the
133:13 - discord but um i've got a supporter
133:15 - channel and discord that i keep open
133:16 - during the live streams
133:18 - okay we're at 80 we're getting there
133:20 - this could use some music right
133:26 - all right 82
133:28 - 83 84
133:31 - 55
133:33 - 86
133:35 - 7
133:37 - 88
133:39 - 89
133:41 - 98
133:42 - 51.
133:47 - [Music]
133:54 - seven
133:56 - eight
133:57 - [Music]
133:59 - 100
134:02 - the loss is still going down i could let
134:04 - it train longer
134:06 - okay so now
134:08 - i mean in theory i should just refresh
134:11 - this page and it'll be working at the
134:12 - higher resolution with the new model
134:14 - because everything's pulling from the
134:15 - same
134:16 - directories but how is that how is that
134:18 - possibly going to be true
134:21 - okay
134:23 - yeah
134:24 - working
134:26 - this is wild
134:28 - all right let's move the late let's move
134:30 - oh this is so
134:32 - let's have the numbers move faster
134:38 - so actually let's just do this let's
134:40 - change the incrementation just globally
134:43 - here
134:45 - there we go
134:50 - so i
134:52 - it seems to be just kind of oscillating
134:54 - between a small circle and a big circle
134:57 - um but i think i really need to play oh
134:59 - there we're getting like a square but
135:01 - the purlin noise space is not giving me
135:04 - a tremendous amount of variety actually
135:07 - oh yeah look at that whoa that's cool
135:10 - this is like
135:13 - this is amazing i mean i'm like
135:16 - i you know i'm living like way in the
135:18 - past in terms of like where
135:21 - the current state of machine learning
135:22 - generative models is today
135:24 - but
135:25 - i don't know
135:26 - i just i'm just in love with this
135:28 - weird sort of thing that i've made
135:31 - but um
135:33 - i uh
135:34 - i want to make this go even faster i'm
135:36 - just curious to like
135:39 - let's let's keep pushing this
135:42 - speed of change here
135:45 - yeah what's interesting is how it goes
135:46 - from like small to big through a fade as
135:49 - opposed to actually like having to grow
135:52 - but and then every once in a while it
135:54 - like turns into a square shape
135:57 - um but anyway yeah where are the squares
136:00 - i'm i'm with you michael michael where
136:02 - are the squares
136:04 - um
136:07 - you know one thing that i would do here
136:09 - just out of curiosity
136:11 - is to change from pearl and noise to
136:13 - just randomness again
136:16 - um and sort of see
136:19 - what that gives us
136:22 - ooh whoops oh i'm missing the
136:25 - w times w
136:30 - it really does seem to be
136:32 - that
136:35 - so much more heavily
136:37 - circle making and it's kind of like it's
136:39 - going but i this isn't a proper test
136:43 - because
136:44 - and i'll go gonna go back this isn't a
136:46 - proper test
136:47 - because i'm not actually
136:52 - working with this in a logical way
136:54 - the two things i should be doing are
136:56 - number one
136:57 - if i am actually wanting to see what it
137:00 - does with full in the full input image i
137:03 - should be drawing
137:05 - strange shapes over here and seeing how
137:07 - they match up
137:11 - then i should be actually controlling
137:13 - the latent variables with sliders
137:15 - because i bet you we could find the
137:17 - circle to square
137:20 - that this dimension
137:21 - so this is what unfortunately i mean two
137:23 - hours and 15 minutes is all i can do for
137:26 - today so part four
137:28 - is coming on friday where i want to
137:32 - examine um actually putting in some
137:34 - input images to see if denoising like
137:36 - let's make also some triangles let's
137:38 - make this more sophisticated maybe rgb
137:40 - color could even be added
137:43 - and then working with only the decoder
137:46 - and creating sliders to allow me to
137:48 - manipulate it since you have more input
137:51 - variety you should train longer to
137:53 - recover the shapes properly yeah i also
137:55 - just needed to train this model longer
137:57 - but the initial results are amazing
137:58 - thank you so before i go any further
138:03 - well before i wrap up
138:08 - so what have i changed
138:10 - there's now the public directory that
138:12 - has the model in it and the the p5
138:14 - sketch
138:15 - i've updated the um the node server to
138:18 - train a new model each time
138:20 - and
138:21 - uh the
138:22 - processing sketch um yes hand drawn
138:26 - circle as an input the output would be a
138:27 - perfect circle
138:29 - oh
138:30 - from perlin oh these are such good ideas
138:33 - file them as issues
138:35 - i mean or pull requests to read me but
138:37 - if these ideas i love these ideas i will
138:39 - not remember them
138:41 - so the purlin noise generate landscapes
138:43 - is a really interesting idea the um
138:45 - drawing and then seeing um seeing if we
138:48 - could make a machine learning model take
138:50 - your squiggly circle that you draw and
138:52 - make it a perfect circle i love all
138:54 - these ideas um
138:56 - so um yes
138:58 - let's do all that add them as issues
139:00 - into the github repo
139:02 - um so let me just do git
139:04 - i did that already git add
139:07 - git commit
139:09 - new
139:11 - this is like code for p5 sketch and
139:14 - training
139:16 - and
139:18 - saving slash loading model that's really
139:20 - what i did today
139:23 - git push origin main and you can see
139:25 - that model is you can actually work just
139:27 - with the p5.js sketch now because
139:32 - the model files i r m committing to the
139:34 - repository
139:36 - so uh if i go here autoencoder demo
139:42 - it's very painful to me that there's no
139:44 - readme here
139:45 - but
139:46 - um this is just the p5.js sketch this is
139:49 - the model that i trained most recently
139:51 - i'm just curious how big is this file
139:53 - 6.4 megabytes very reasonable
139:57 - so
139:58 - everyone can play with this to their
140:00 - heart's content
140:01 - those ideas that you have of things i
140:03 - could try next please file them as
140:06 - issues mini jimmy looks like so if you
140:08 - are taking your own
140:10 - you're making your own version of this
140:12 - um
140:14 - and you add things like colors and do
140:16 - like real expanses of the feature set
140:17 - don't pull request that but either file
140:20 - an issue or pull request a link
140:22 - in a readme to your version with um
140:25 - sample images but what i would love pull
140:27 - requests are documentation
140:30 - of what i have so far
140:32 - um any like small
140:34 - any like real bugs or like significant
140:36 - mistakes that are in the code or small
140:39 - clean up things where like the variable
140:40 - names are changed to be a little bit
140:42 - better i would welcome that but anything
140:44 - that's really significantly changing
140:46 - what i have so far i can't merge because
140:48 - i want to have a record of everything in
140:50 - the live streams but you can i could
140:52 - link to it and review it and incorporate
140:55 - those ideas
140:57 - okay thank you everybody
140:59 - uh thank you to brilliant for being the
141:01 - sponsor of today's live stream check out
141:03 - brilliant brilliant.org codingtrain um
141:06 - and uh i will see you all
141:09 - um whoops maybe on well definitely well
141:12 - hopefully
141:13 - hopefully on friday i'm going to
141:14 - continue this i feel like just
141:18 - leaving this here
141:21 - um i wanted to produce some squares
141:26 - no you don't see this this is like uh
141:29 - i was gonna like usually i'm just gonna
141:30 - leave this here
141:32 - as i play all the outro music and see
141:35 - you
141:36 - on uh the next the next live stream uh
141:39 - this auto encoder project has really
141:40 - been uh fascinating to do
141:43 - i have to think about what how do you
141:44 - think about what to do with this next
141:46 - like i could make proper video tutorials
141:48 - of coding the whole thing that are
141:49 - edited through i could make one video
141:51 - that summarizes it i would love your
141:53 - feedback on that like you're maybe the
141:55 - wrong person to be asking because you're
141:56 - watching this right now but a lot of you
141:58 - just are probably tuned in the last 15
142:00 - minutes so what would you want
142:03 - if you weren't able to tune into all the
142:05 - live streams or if you wanted to go back
142:07 - and review parts of the live streams
142:09 - what would you want as
142:11 - something that comes out of this as a
142:13 - video
142:14 - i don't know uh i'm gonna be working on
142:16 - that in january okay um see you all
142:20 - do i have just the laptop button
142:24 - no i don't have a button for that here
142:26 - does this work yeah all right so i've
142:28 - removed myself i'm muting myself
142:32 - and i will see you all next time on the
142:36 - coding train
142:37 - um
142:44 - [Applause]
142:46 - as always i always forget that this dot
142:48 - this
142:59 - [Music]
143:02 - this dot
143:03 - [Music]
143:10 - this dot
147:15 - i'm realizing something
147:16 - so while i'm playing that music i'm
147:18 - realizing that if i had the latent
147:21 - variables like tied to like frequency
147:23 - levels in the music or something then
147:25 - this output would go along with the
147:28 - music so as like the beat goes the
147:31 - circles would like change as the music
147:33 - slo you know like quiets down it would
147:35 - become more static this is also
147:36 - something for me to try for any of you
147:38 - who are adding issues to the repo for
147:40 - things for me to remember next time
147:42 - having the latent variables tied to
147:44 - input sound would be an awesome thing to
147:46 - do
147:49 - that was the invalid syntax i forgot uh
147:52 - there was one other thing here that i
147:54 - think is important that i will use
147:56 - continuously over and over again
147:59 - all sorts of text generation analysis
148:01 - things
148:03 - that i will use continuously over and
148:05 - over again
148:06 - first thing i need to do is yes
148:14 - [Music]
148:20 - kittens and kittens and kittens and
148:21 - kittens kittens and kittens and kittens
148:23 - and kittens kittens and kittens
148:30 - next time
148:36 - bye

Cleaned transcript:

do so do do do check one two hello this is my voice i'm about to get started in approximately two minutes uh if you could if you're in the chat you could let me know that the volume of my voice is coming through and if there's any static or any other issues i should be aware of thank you very much and see you in just a minute or two ugh hello my buttons aren't working properly that's usually the first thing i like to say here on uh when i start a coding trade session good morning happy sunday oh i was all ready to speak and then i pressed the button to bring me live and then i did not show up live and i got completely flustered but i realized actually now that i look at this i was just pressing the wrong button none of this matters let's just give this another try can we please okay going back to here putting the music back on take two everybody hello good morning happy sunday welcome to the coding train my name is dan i will be your conductor for today's journey and um this train has been going for a very long time it was paused it was stopped in the station for at least a week now uh it but we're we're we're put shoveling the maybe this is this an electric train we had solar panels on the roof i don't know yet um but i'm getting it going again today and i'm going to be returning to this project that i've been building which is uh an auto encoder now if that term auto encoder means nothing to you don't worry i will give a brief kind of fiveminute sort of catchup summary over what i've done in the last couple sessions before before i dive right into the code um but before i even get to the project that i'm going to be building today let me just say hi are you a new viewer i see that i have a new member who just joined this is very exciting this hasn't necessarily happened in a little while it's michael michael thank you for joining the coding train membership program for your membership you will receive uh thanks for me at this very moment because i'm just speaking and i saw your name and i'm talking about your name that's probably not why you joined it shouldn't be why you joined access to some member discord channels for support on your code we'll send you some stickers in the mail all of those things ah but before before i go too far uh we must um dedicate these random numbers that i'm about to read we're just going to start this project over everybody it's been a rough year it's been a rough two years it's been a rough 48ish years for me actually hasn't been that rough i i i things i i have i have it very good i i can i i cannot complain um but um i have been uh my i'm on a quest uh many quests one of which is to read this entire book a million random digits with 100 000 normal deviates probably if i had just like started doing this when i started making videos i'd be done by now but no i've tried and then i like do a different system then i change the system again we're going to just 2022 it's all twos with a zero it's a new year i we're going to start this book over but for right now we're going to say thank you to michael and reed from page 113 row 5620 i'm going to read these digits 51940.44169.83459.8888 oh my goodness that's crazy i gotta show this to you this entire book of random numbers it's not an anomaly let's see can i uh there's no light over near to the camera but i'm trying to i don't even remember where it is now here it is look at this look at that sequence is it gonna autofocus on it it's a little dark eight eight eight eight eight eight that's amazing um zero seven seven five two two three two one one two six two six zero zero eight six nine three two nine three six eight nine nine nine five six and uh michael your random number for you your personal number is 99599956 that's page 113 the end of row 5620 uh if we can if i can continue to get my act together some of you have received these um many of you have are waiting but um for the members uh your own very own custom uh train whistle with the coding train laser etched on one side and then a random walk pattern generated with the random numbers in this book uh from your own personal position and number uh is um is what i'm offering we're gonna we're gonna be making a lot more of these starting in january and please join the discord everyone you can find out more all of that stuff there and yeah so um what's next ah let me thank today's sponsor brilliant do you like learning do you like interactivity do you like the holiday season and not know what to get somebody uh you could get them a subscription to brilliant so brilliant i'll come back i have a whole bunch of courses in math and science and interactive lessons and computer science so many things that are just in like complete alignment it's like there's another train that's got the words brilliant on it that's just chugging along alongside a parallel track to the coding train so i'll come back i'd like to do i like you know huge thank you to brilliant for sponsoring the coding train and what's wonderful about it is i get to open up brilliant around the middle of the live stream or taking a break and go through a challenge or a lesson in a course i will do that later but you can sign up for free at brilliant.org codingtrain lets them know that you found brilliant from me the coding train i'm not the code am i the coding i don't know that's another discussion for another time no need for the sort of like metaphysical philosophical quandary that we are am i a train am i a human who knows do i have legs yes a little bit stiff today um uh and um yeah oh oh if you want to unlock all the premium stuff and all the courses uh or or you can give it as a gift you will get 20 off the first 200 people to do so from this link all right now what is happening today first of all my glasses are very dirty and i'm going to uh untuck my tshirt here and clean them off i wore some special clothes for all of you today on a sunday morning i was like let me find my shirt with flowers and my uh cardigan is this a cardigan is that what you call it nice sweater it's cold but i've been running the heat all morning in this garage uh you notice that if you're hearing me and seeing me without interruption the internet is hopefully working here in the garage it is not yet solarpowered um within the next two to six months i will be uh installing i'm not doing this personally but uh solar panels are being installed all on top of this garage where i am hopefully powering all the lights and the computers in here um so i'm excited to sort of see where that leads and talk about that as i go my my um desire to have the coding train you know to the extent of the things that i can control that are in here powered by solar energy uh um and kratos says it has been a while since the last time i've seen his video i think it was before he got his news to new york well boy do i have news for you uh hopefully this is gonna stabilize and i'll be uh broadcasting from here for at least the next year plus probably two years but i am in a new location yet again and mostly i have things going this is what i really want to work on this oh and it's out of focus this um i like to do a lot of diagramming and things in my videos and live streams let's see if i can focus this uh that's hopefully better um but i'm still sort of working on what whiteboard do i want to have how do i want to do diagramming and all of that stuff so coming back over here um all right so let's get going um actually actually before i go into the auto encoder project i i have a bone to pick with you audience i mean it's probably my fault so it's really not on you it's on me but i want to come over here and i want to talk about the fact that i have this video slit scan time displacement effect challenge i believe if you i don't know what happened to the code here on this page uh maybe that's why oh i have a bone to pick with me i've caused my own uh problem here no wonder oh why didn't anybody say anything to me let me let me just do this for a second yeah all right i messed something up here so let's let's see if we can remedy this right now um i think i um i don't know what the issue is and maybe somebody who's watching can do a pull request but let me at least remedy it for you for the year so this my bone that i was going to pick what is where did that expression come from i don't know it sounds kind of i i need a different one i don't like it anymore i want to pick anyone's bones i don't want my bones picked no picking no bones picking please but this is what i wanted to discuss this video came out and i know i'm slow and there hasn't been as much content recently and maybe there's not as many things for you to riff off of but i felt like this slit scan time displacement challenge coding challenge exact set of examples was ripe for creative twisting by you the beautiful passengers of the coding train to make your own special version of it and share back with me this is what this is what i'm here for what i most enjoy about doing the coding train but it seems like there haven't been made any variations first of all i i gotta really work on my language here on the website coming soon based on this coding challenge by the community yet be the first you could be the first and add your own there's a link there that will show you where to add it if you don't know how there's a guide there's a video with me talking about how to do it and even better coming in 2022 there will be a form on the website that you can use probably to just submit um i want to still encourage people to use github and github pull requests as their first foray through the coding train um and to get into that world but um working on some improvements for how um but i i'm realizing now that the code should be on this page and amir hussain says i've just done double pendulum did you submit it please submit it submit it let's see if there's let's see what the most recent community and i uh community contribution time let's see what you the audience have made most recently based on the videos that i have produced here on the coding trade so and then let's find where that code is for that video i'm gonna go to github.com codingtrain website um oh look pull requests there's some things here a lot old stuff not oh okay i'll have to come look at this but let's look at closed yeah nothing nothing 14 days ago the last contribution here we go the last contribution from david beale to the diffusion limit again this is on me i just have not been as present and uh in the sort of like ecosystem of the coding train um so that's you know i'm just kind of like make it through this year and and start a new in 2022 but that is my new year's resolution you heard it here first figure out ways to get more people contributing their own versions um you know um is it raphael who does the like creative coding weekly challenge that seems to be very successful i'm sure there's some things i can learn uh there but let's take a look at this one from david beale so um we can just see it here but i um just so you want to if you want to know where it shows up if i go to here and there it is 3d dla by david beal okay fade out this music let's take a look at this thank you for your submission whoa oh and i love that this is a youtube video cool let's make it full screen wow what did you make this in i would like to know wow that is so cool i love it so um the diffusion limited aggregation uh coding challenge is a simulation of a kind of random motion a brownian motion if you will where which is created by particles entering from outside of a space coming in and when they intersect another particle they're stopped so if you know i i don't know if we can just go back to the beginning of this video to sort of see the big that starting process but you can see it's happening very very fast so each one of these particles it's almost like these branches are coming out and has a very organic um it can have a tree it can create like a tree branching like um pattern but in here i don't know how to characterize this it's very it's almost like um molecular uh in its look so uh thank you for this this is wonderful to see this in 3d there's also something kind of lovely going on color wise here that i can't put my finger on but it seems like there are started as red particles and they're getting more and more blue um you know oh you know i tempted to be like you know just like i just want to make my own version of this i mean i guess i did in some manner but the version i made the example is just 2d and doesn't have this sort of 3d quality to it so wonderful work thank you for this community contribution so i'm hoping um i can kickstart getting more ways for people to share their versions and more ways for me to share them back and i look forward to thinking about ways to do that better in 2022. all right thank you okay i'm going to scan through this just to see where it goes uh whoa oh yeah so it's like zooming out maybe as uh as unchanged colors again this is wild that is a really quite an impressive looking structure um okay um now let's uh close this um just to sort of close the loop on this um if i go here uh you will see this is the actual code from the video and one of the things that i'm doing in this particular example that you didn't see in david's contribution is i'm animating the process of the particles entering and moving randomly and then getting stuck now i'm doing it really fast sped up because uh you know if i were to actually like animate each particle moving like one or two pixels per frame it would take a very long time to build the actual structure oh and i guess i also have some color scheme going on here i say i don't remember what i do in these coding challenges but now i see that color screen scheme is mirrored in the 3d version of it um wonderful i'm just curious here oh it's the iterations probably the iterations is the variable that kind of can i should log in um the iterations is the variable that controls like how many iterations of these particles moving am i skipping so if i went to just like for example one you would see like this is kind of i mean this would be like amazing to watch over an incredibly long period of time but i can only i'm going to talk for a tremendous amount of time and probably not one particle is going to stop and get stuck if i put it at 50 we can see things are kind of moving a little bit faster now maybe we would get there but it was i think i had it at a thousand so you know if i if i did it at 100 000 for example oh that's just going to make things now that now i've lost the sort of frame rate of the sketch itself but you can see okay so that's under anyway you get the idea um i'm i'm lost on this tangent let's try ten thousand there we go um and i presumably i think what i would want to do in this case is actually not draw there's not really once i've have this iteration number up so high there's not a tremendous amount of value in drawing the particles moving themselves because ultimately what we're really just seeing is um the um the pattern that's emerging so just out of curiosity if i wanted to change that those are the walkers we could comment this out and i would see now i'm seeing just the sort of diffusion limited aggregation pattern emerging so there's a lot of parameters to play with here i don't want to save this actually because i've kind of messed it i should or i can maybe just do undo all the way back to where it was and hit save but what the thing that i'm just going to hit leave the thing that i'm curious about here is to take a look at source code now my assumption is what david shared here is a video rendering of it so one that's a beautiful way to share documentation of a project because it's very accessible like yes if you have a p5.js sketch that can run in the browser that's just about as accessible in terms of anyone being who happens to have a phone or a computer with a web browser um can just click that link and see it um but i'm assuming here that this is not done with p5.js because then presumably we could see it just running in the browser rather than have a video render of it although it's possible that it's a slow process that rendering it makes more sense anyway let's go i'm assuming this is going to be processing but i'm excited to find out oh no no oh this is i'm so wrong look at this they're just running in the browser so we got all the possibilities oh and and oh and i can control the camera with my mouse okay okay and i can see that it's running at 30 frames per second down here this is amazing uh so now i have to guess that this is i mean this could be the webgl renderer of p5 it looks like there's a lot going on here so and i don't know why the chat is not scrolling for me or maybe just nobody is making any messages in the chat the last message i see is ro doc saying hi um and like discord member chad is completely also dead am i just talking to myself here hopefully people are there so what did i uh sunday maybe sunday morning is not the best time for me to be live streaming but it worked out for me so here i am maybe you're watching this uh as a playback um i'm going to guess that there's something 3js going on here let's look at a view there's a lot of ways i could do this but i'm just going to go to view source here um and logo manifest drop this is an awkward way okay this is not helping me uh let's do um inspect this is going to be an easier way to look at it and we can see here there are some javascript so this is probably built um let's see let's look here this is probably a sort of built version of this project i'm assuming that this is using 3gs and maybe it's kind of embedded in one of these javascript files here but i don't need to get lost into this right now i can investigate this more later somebody can tell me um i don't know if this is what library this is uh or or what and i could probably click on this and maybe see something more but i assume these are all sort of built in minified files so it's going to be hard to sort of parse through and and find and then i see people saying uh saying hi now in the chat and and minnie jimmy has the same uh reaction that i have by saying sorry i am in awe of the patterns all right all right i've got to get moving here because uh if you've watched any coding train before you'll know that what tends to happen is i it's just a lot of sort of digressions and tangents and sort of going off in arbitrary directions and what i've the thing that i've been enjoying that i've been trying recently just over the last few weeks is picking one project that really requires a a lot of time to sort of dig into and dig through and try to build and debug and iterate and adjust and so on my list for a very long time has been to investigate programming my own auto encoder now not all the way from scratch in the sense that i'm like writing all the neural network code myself but just using a machine learning library like tensorflow.js and i've been doing that over the course of the last live two live streams so i just want to first summarize where i am so far in the project and where i want to go and i also want to address um this pull request that i haven't been able to merge yet i don't know if the chief who submitted this pull request is in the audience right now if you are say hi in the chat um and then also i want to look at this pull request which i did merge and we're going over this so an avaroop question what did you do last time is exactly where i want to be so um let me walk over and i won't be able to see the chat while i'm over there i'm looking to remedy that let me just have a look that looks like the focus is reasonable on there traverse i saw your question about coding challenges i'll try to address that later so the project that i've been building is in some ways like an ancient technology at this point in terms of what is it uh in terms of how synthetic media generative images i just want to see that there's green bars for my audio which there are are created through machine learning now you might have heard of things like again a generative adversarial network you might have heard of style gan or style gan 2 or style game 3 you might have seen this face this person does not exist and this explosion of synthetic cats and dogs and people and cars and all sorts of things that ai models are generating based on a set of training data of real world imagery and there's all sorts of ways they can be fantastical and look very dreamy and artists are making use of this stuff so for me where does learning about how those things work begin well it begins probably in the basics of you know what is a neural network um i do have videos on that but for me in terms of like if if we've got if i'm making this assumption as having sort of gotten through some of the fundamental aspects of the sort of core pieces of neural networkbased machine learning the autoencoder a particular architecture for a neural network is a wonderful starting point to learn about the process by which a model can generate an image and how you you as the sort of artist or the creator or the programmer can manipulate that model to generate images in certain ways um so uh reference most important reference probably for you to watch there's no post production here so i can't just fly this in right now to show you a preview would be the auto encoder video from the youtube channel two minute papers so that's a good two three minute video just you know explaining anything that i'm about to try to do right now in a much better fashion um but the neural network and again my previous sessions i went through this in much more detail i even did a recap of this part in the last session but just to quickly do that again the idea of an auto encoder the starting point of how you think of it as a copying machine an image is the input and we want that same image to come out as the output the trick here is that of course that's a very easy thing to do because we can copy an image i have this many pixels we make a new image and take each pixel and copy it over but what happens if as you're copying the image you're on you're constrained to work with less and less data so in a way you're compressing the image and then decompressing it or encoding it and decoding it what happens is through that process if the neural network learns all these weights the weights are sort of like the make the core sort of like settings the parameters of the neural network itself it learns the weights to copy an image then we could take out the part where the image comes in as input and just ask the neural network to make to make outputs based on what is essentially random inputs or noisy inputs then we're going to generate new images in the style of what we started with that's the idea of an auto encoder and that will lead to ideas like a variational auto encoder and all sorts of other kinds of generative models so where am i i've built this already i think this is where i should go back to my code i have done everything that is in this diagram except for that last part of take off the sort of first half and start to just generate new images that's what i hope and again it's it's not like i've been working on this like i haven't thought about this once when i have thought about it i haven't done anything on this project since the last live stream so i don't know how this is going to go you could go do something else with your sunday and come back and then like watch it on 2x or speed through and just look at the end so that might be advisable but if you're here thank you i appreciate you i'm going to go i'm going to go forward so let's look at the code pieces that exist already um and raj just asks sorry to be alone in a desert first of all nobody i hope nobody watching the coding train the thing that they're coming away from is a feeling of being alone in the desert although i actually have this i've never been to joshua tree and i was looking i'm just i don't know i know why this came up but i was looking at places to go visit joshua tree that's a desert that i could conceivably get to uh i mean i'd have to take an airplane i don't know what we're talking about here i got off track don't feel alone um the the the vibe here the working assumption is that this place is for people who don't know what the thing i'm talking about is and a lot of times i'm just figuring it out myself you should ask of course you know the reality of the situation is i can't every session go back to the very beginning of like what's a variable but you should feel welcome here wherever you are in that journey and there if i've done my job if this is a job correctly i can point you towards resources to find all of the um you know the prerequisites if you will to what i'm working on today so hopefully that explanation helped you a little bit and moby dick is asking would a reverse autoencoder work where you give it more information in the middle so it learns to opposite i don't i don't know i don't know if i fully understand that question if i'm being honest i have to think about this one more it's a fascinating idea and this is this is one of the things that i'm particularly invested and interested in what are the ways that machine learning models that are maybe trained to do a particular kind of task for a real world application can be uh tweaked broken uh done in the sort of like uh turned upside down for creative um and maybe um outputs and hopefully to be sort of critical and investigate um what are some of the sort of issues that the world has and i'm you know being kind of trite about this but uh with the fact that these machine learning models are playing such a sort of fundamental role in our daily lives um odjabi asks do i need to know how tensorflow to follow um it you know so no because my i'm i'm here welcoming you in whether or not you know anything about tensorflow um uh you know and i at least the stuff that i'm gonna do today like a lot of the tensorflow stuff is done already so it won't be the focus so it is um it is a sort of core essential part of what i'm doing right now but i will try to explain things as i go okay um all right lars is asking about generalized ai i don't have uh i don't have an answer for that question around the corner i would say no if i'm guessing but what do i know i'm just here in my garage on a sunny day with a computer trying to make some squares appear out of random numbers all right if you're wondering why i constantly look over here it's because that's where the chat is that's where my monitor is i mean i have it positioned here because then i can sort of gesture at what i'm doing but i feel like sometimes i'm spending too much time live streaming and looking over in this direction okay so um let's look at the pieces of what i have so far and i had the heat running in here all morning to like try to warm it up it is very noisy so i don't run it while i'm streaming but i already feel like it's getting a little bit cold in here so when i take a break i'll crank it up again um it's oilbased heat right now in this garage with like a very old boiler um but i would like to figure out once i have solar panels if i can do some type of like heat pump maybe that'll be quieter i don't know all right so first things first uh i need training data so if we're looking back to this uh this diagram images have to come in right images have to come in what are the what's the training data um it's very sort of rudimentary training data right now it's i have a processing sketch that just draws random squares so i'm going to run it the images it's saving are actually just 28 by 28 pixels because i'm working with very low resolution right now just to have things run fast and sort of work and be easy to deal with um i would like to today start having this generate different kinds of shapes like triangles and circles and squares because i think the sort of ending animation that i'm imagining of sort of like these shapes morphing around in the latent space i'll talk about what that is um would be more interesting so that exists then the next thing that i have which i haven't even opened yet is a node project and the node project is all the code for it is essentially here in index.js and the node project i'm going to talk you through it now i mean if you want to watch like four or five hours of me live streaming building all this you can um the node project is uh architecting this particular uh whoops wrong button this particular um uh neural network architecture i'm sorry to use the same word multiple times uh importing in the training images running the training and then producing output images as well and i i went around in circles with this because i was um you know ultimately i think moving this into the browser will make more sense um but um uh so you can see some things are commenting so i was trying to use like node canvas and different things but i ultimately just using this library called jimp which you can see up here jimp is a library for manipulating images in node so these are the steps we can say i have this like main function where i call build model build model and we'll look at the code in a second creates all of these layers that are in the diagram then i need to load all 550 images i have 500 training images and 50 test images i made a huge mistake which i haven't watched i need to address so this code i'm going to pull in the new code from the pull request in a second so there's a big mistake here but so this code is like slightly wrong but the idea here is the first 500 images are the training images and then the next 50 images are the test images so i can train the model and then generate outputs by running the test images through and see how well the model does copying them essentially and so uh i did i forgot that i did this this is great there's some like refactoring there's basically build model load images train test so if we wanted to look at any of these functions i think looking at build model might be interesting to see this is this is the part that i forgot who just asked this like do i need to know tensorflow no but this is going to look kind of a little bit scary to you it looks scary to me and i i sort of know i know ish tensorflow so the idea is i'm making a sequential model a sequential model this is called sequential because the data flows through all these layers in a sequence feed forward left to right and we could draw it any way we want that's arbitrary but it is sequential and then um uh now i need to add the layers so the first layer receives 784 inputs because the images are 28 by 28 that's 784 pixels the next layer and basically it takes those pixels and sends the data into 256 nodes and then those 256 nodes send their data into 128 that's the encoder so i could actually add a comment here which would be like encoder oh my hands are so cold i'm gonna have to turn the heat on and then decoder what's the temperature outside let me just tell everybody what the temperature outside is where i am uh it's only 40 degrees um and sunny high of 43 today low of 28. this is in fahrenheit of course not of course but of course because i'm an american here who living in the dark ages of measurement systems uh then the decoder is we go back from 128 to 256 and then back to 784 and there's these activation functions and there's the optimizer and the law all these things these are things i've kind of addressed a little bit but you know again this is the territory of other videos i have about um the pieces of the neural network themselves but and then we call this train function where this is interesting normally you're pairing some like if i were training an image classifier i would have the images and the labels so i'd have the training data and the targets but i don't have that because the target of the training data is the training data itself that's the sort of twist here with an auto encoder i'm trying to have data flow in compress it down and the same exact stuff come out so that's really this weird thing it looks like a mistake to me because it should be like x train and y train or x train and y targets but number of epochs is how many times through all the data batch sizes how many data points do i do before i start adjusting some weights et cetera and yeah and there's some stuff about loading the images and i'm using this jimp library so again i don't want to run through all of this but that's the idea so let's try running this right now and see what happens so first thing first oh no let's correct the error so first thing i'm going to do is going to say kit get pull origin main so i've already merged a pull request that came in um and so i merged it on the github website and now this is the command that i can type to receive that image here that that change locally oh i don't know why i'm getting this weird message and i'm also i all right so we have to deal with this two things have gone wrong here one is i guess the way my git is set up on this computer i haven't specified a sort of default way to reconcile so what if you've made changes in more than one place how are those changes reconciled with each other um there are different ways of doing it and i'm not going to get into that right now but i'm going to just i want the default one to just be the one that i'm going to do so i'm going to take this command and type it in now let's call pull origin mean again we're gonna have another issue so it's saying like aha you've made local changes to the following file that would be overwritten because i'm trying to pull in some changes that were made on the github website server itself but i also was messing around with it here so the only change i actually made was just and i can actually see it if i do i think git diff will show me it's just adding these two comments encoder and decoder so i could undo those but what i'm going to do is i'm going to say git add dot git commit i'm going to put a message in i'm adding encoder and decoder comments there we go and then now i should be able to pull the fix no problem it's merging it i'm not going to type in any more information about that and there we go so now that's coming now what was that change let's go take a look uh how does this 40 minutes in this live stream and i've barely gotten anywhere yet i guess that's the hopefully i've been talking a lot in ways that help you understand the world at least focused in on machine learning and javascript and that sort of stuff um and curvers is talking about reducing the latent dimension to something lower from someone yes yes yes my goal actually by the way is to have a browser page with sliders on it where you could manipulate each dimension individually i i i it does not seem realistic but i'm going to get that today i don't think there should be like four parts i really thought i could finish this but that's my goal so having it less so let's look at fixing number one so um and actually we could just look at the issue which maybe um described it better so you're using the same images for training your network and testing it this is due to array.prototype.slicestart returning a copy of the array from the index start to the end and not zero to the start so i had if you what what is this what's happening here i had um this is what i had and i did not realize that slice 500 slices out the array from 500 to the end not 0 to 500 which is what i wanted and then now if i just put 500 it'll take i don't have to put the end number because it'll take that to the end so that is a huge mistake that i had in the end i don't know to what extent it's going to make that much of a difference because everything i'm doing here is is utterly simplistic and somewhat trivial so so what that i use those 50 images but let's try um running it and i think if you were if you were here last time i was talking about how an auto encoder could be used to denoise an image and i wasn't getting that to work this is that's probably why i'm not going to go back to that right now because i think that'll send me down you know at least a half an hour of investigation but let's run this again and it's training the model hopefully now off of 500 images not 50 and it's going to do a 250 epochs we're seeing the loss go down which the loss is sort of a summary of the error like how well is it currently copying the images uh hi omar i'm reading your message and thank you tom i don't know what the penguins are for but i love penguins i we i had not gotten a loss below 0.1 you can see it's really settled so clearly one of the things this we can learn from this is that if the loss is sort of like frozen uh you know it went down to 0.105 but you can see it's not really changing very much at like whatever number of epochs i'm at um so probably training the model for 250 epochs is quite unnecessary but let's let it finish that so after it trains it for those 250 epochs it's then going to generate 50 new images okay great so just let's go look at the directory that i'm in and we can see whoops wait a second where did it load the images from i'm confused well let's just see what's in the output it worked i'm i i'm a little bit confused because where did it load that i don't see the training data actually in the so hold on load data square but there's nothing in this oh no it's there i just don't know why oh yeah it's just the mac os was activated so this is the sorry about that ignore the last minute i was just confused um so this is these are the training images right these are 28 by 28 pixel squares that i generated in processing um and then and i'm getting all sorts of interesting um commentary in the chat so thank you for that i can't it's not possible for me to address all of it as i'm going but i appreciate it and i often do go back and read it afterwards so all right so now what i want to look at just to make sure things are working the way i intended them to is look at the output so these are the generated images now i cannot even discern the difference um in my assumption would be that these are slightly fuzzier like generally speaking my experience with working with an auto encoder is uh the output images are going to have a sort of fuzzier less precise quality to them than the input images but in this case i'm working with such like fixed kinds of images squares um that have of just black and white pixels at such low resolution i'm not sure how we're going to discern the difference so i want to see if i can get this stuff into a place where i can manipulate it so that's what i want to work on i do need to take a break so i wonder if actually that makes sense usually i just keep going and going but maybe i should just take a short break right now if you generate the images as 28 by 28 instead of reducing them the images are sharper i'm not sure what that means mini jimmy um and i'm of the wrong so let's let's let's go let me go a little bit further sort of think about what i'm doing here well um so is there a way this is what i don't know how to do my idea here is that uh and i and i do want to make this like let's actually try this let's let's do a little bit of this let's do it i don't know why i'm let's have the auto encoder go down to 64. i don't know how many layers it makes sense to do what if i just like went to 16 like i want to have 16. that's my goal um could i possibly just go from 128 to 16 is that like a terrible like silly thing to do and then this would go back to 128. should i put more in between i don't know but let's just see what happens if i go down to a really small number and um and then also the number of epochs where is that oh train model that's a parameter i pass in um train model 250 let's just do 100. let me run this again and that while i'm running while it's running i'm going to talk about what it is i don't know how to do so what i'm hoping i can figure out to do is how do i take this neural network architecture and basically make where is it this the input so how do i delete all this and actually add tr add data to produ from predict insert it into here and yes blue tj says i suspect it gets even fuzzier this is what i'm trying to test right now so we got around the same like loss and i could look 1049 these are new images but honestly we can see with 16 no problem i mean it's sort of hard for me to believe that did i like not save the code or something like like like if i change this to two like it really shouldn't work right so let's just make sure that this doesn't work let's change that to two because otherwise maybe something is wrong okay this is good news the loss is not going down i have a lot to say yeah i'm kind of picking the activation functions very arbitrarily i've talked about activation functions in other videos there's relu which is not how you say it but that's how i say it and sigmoid and um so i'm hoping the images that come out are no good here let's see ah they're not so bad they're just uh they're all basically the same it's just like a much bigger fuzzier square it's like only knows how to do one thing so that's great to see um let's try i want to see like what is the minimum can i get it down to eight again i wanted to have more complex imagery so i don't know what the point of getting it down to eight is with this but let's see i recall the loss being at 1.05 all right so this looks pretty good with eight there's yeah and blue tj writes exactly what i was thinking there's leaky relu leaky relu and many rectified linear unit is what that stands for i don't know how much that explains anything to anybody but and many others it's quite hard to find the right one and know which one fits in your use case yeah so to be clear my motivation here is exploration and explanation not optimization not speed not efficiency not even producing a meaningful result i want to understand how these systems work and i want to be able to feel like i have some agency in manipulating how they work in and i feel like i do simply by the fact that i can change the total number of neurons at that middle layer the sort of smallest layer and see a very different result means things are working as expected that match the way that i understand how these systems work so you've got to fix the sigmoid um all right let me let me just see here i what i wanted was i know i want sigmoid as the last activation function because i want my values to be to be between zero and one but i don't know if the suggestion here is that i should just try relu all the way through or even don't worry about it just have it i'm just going to leave it as is right now but um i would love to um and kervers is saying that they got an auto encoder to work fine with just two latent dimensions i have two sigmoids i have three sigmoids i don't know i don't understand the comment okay i'm gonna come back to that i the thing that i want to do now is figure out how do i um how do i start from here once the model i is here so maybe what i should do is first save the save and load the model so hopefully this is as easy as let's look on the tfjs documentation i'll take my break after saving and loading layers model safe sequential model is what i'm using well there's no save function here but is this ultimately a layers model because sequential like extends that or something save model dot save i know a local storage is interesting oh but i'm not in the browser so that i do not want to do i mean i could just move this to the browser it's a little bit silly to be honest that i'm doing this in node but let's try this so what happens if i let's forget about testing the model for a moment oops now let's just try save and what if i do like if i give it a directory we'll put it all in there let's just see and let's let's do this for just like 10 epochs just to sort of see so i'm going to try i'll just call it model let's just see if this will save the model in a directory called model i'm just doing 10 epochs okay model is not defined oh my goodness oh my goodness what is wrong with me it is called autoencoder oh i forgot to address the other pull request um could not find any url well so i don't want it to be a url do i just need to have a folder called model will that do it let's see no no this did not work okay um indexeddb downloads my server what about a file does it really not work just to give it a direct talents okay uh all right let's look at the so let's address the pull request which maybe has a solution for it in it so um where where am i going to auto um yeah here we go all right so let's look at this pull request and actually let's just go to this issue so this is incredible what uh the chief has submitted here um i'm just going to read here want to make the code a bit more readable and organize everything in its own class and file yes yes yes so do i i opened a pull request number three for it i added a data source class which can provide training and testing data and there's an interface for it so more data like random mnist arbitrary images blah blah blah more layers divided into an encoder and decoder it can save its state so you don't have to train it every time the image transformer takes an array of normalized pixel images and saves it to disk so there's so much more here in terms of organizing refactoring the code so i didn't feel like i can merge this because um it's too it's like too too good it's like too much of a radical improvement over what i had before that i won't be able to easily continue this process this explanatory process i have so the chief if you're watching i don't know the best one i don't know what to do here with this one is i could wait and eventually merge this in later once the project is totally finished but i would like to have a version that kind of i'd either or maybe i can draw inspiration from this like implement some of these pieces during a live session but i think what might make sense is for this to live um in uh you know in as documented in the readme for this repo linking out and explaining these improvements so that somebody could sort of see the code that i've written in the live streams follow that along and then see how there is a version of it that's just much more thoughtful in terms of how it is organized so let's think about that the thing that i would really like is an excellent readme documenting all of these pieces um expects a file extension maybe a branch would work but um so a pull request with a nice readme that links to the different live streams and kind of like the um the two minute papers video and it kind of has some sample images in it i mean i should be doing that i just haven't had time so if somebody wants to really think about how this whole process could be documented in readme linking to the chief's work and all of that that would be amazing but let's take a look at the actual pull request because maybe we can get some hints for how to save and load the model from the disk because i'm not seeing it obviously in the tensorflow js documentation so let me just look for save this is for saving the images saving the images auto encoder oh so literally i'm doing it right but i just need to put oh and it's oh and it's divided into an encoder and a decoder so that's also a probably a clue to what i actually want to do i have to understand so let's first just get it to save so is it just this file colon slash model with another slash let's try this a little tiny box here yeah i think this might have worked so one thing we can do is we can look at oh i've got it here what am i doing we can see the model files we can see this um the json which is basically a configuration file describing the architecture of the model it's a sequential model here's all the here's all the layers the kind of layer it is the activation function the number of units etc etc so that's great so then let's save a model trained to a hundred epochs and where do i want to do that so go back to 100 all right almost 200 we got down to .108 of a loss 107. can we get to a six show me a six show me a six before you finish i want to see that six that's fine we got zero point one zero seven now this should be live just to be sure 1101 am yep that's a new model overwrote the previous model by the way this weights.bin file is all of the trained weights so in theory every time i'm saving the model this is not changing at all model.json the weights are what i'm changing so i could have different weights file if i wanted to try different configurations and swap them in and out what are the weights just for any of you who might be kind of just joining right now it is the value the sort of weight of every single connection between any given node in the system and another node uh well the layers are connected sequentially so um you know the first first layers aren't connected to the last layer they're connected through each other all right um all right now in theory then there shouldn't be i should be able to um and it's this is very awkward what i'm doing here but i'm just going to let me just do it this way let me comment out all of this one more time and then let's get test back oh i do have to load the images sorry and let's see can i do auto const auto encoder equals await how do i call load let's just look in our cheat sheet this is terrible i should look in the documentation model.load huh i'm confused all right i'm going to look at let's look at the documentation so where is load save load sync i don't need to load sync load layers model okay that should be it tf load layers model okay and then i should be using the same path but maybe i say model.json here so let's see if this works i'm going to just to be 100 sure i'm going to delete all these outputs that i had previously and now instead of building the model and training the mile i'm just loading the train model from a particular file this is how i'm going to be i'll just move right into the browser because i can um i'll do yeah i mean once i have a saved i'm going to use node just for training the model and then i'll once i've saved it the files will just bring it right into the browser i think i think that makes the most sense to do yeah i was thinking like oh i could set up like a web server and have the browser send like get requests and the the server like generate the images and send it back but that's like a whole lot of unnecessary trouble right now so let's run this okay ah i think this might have worked output yeah 1104 okay we did it yes all right we're in really good shape here um so i'm going to take a short break just so i could turn the heat back on and check out brilliant as a sponsor for a moment but let me just see i saw somebody ask in order to recover the information of the squares you should use relu in the decoder part as activation functions because they are inverse functions the last layer is okay as sigmoid okay that sounds very reasonable to me thank you and k asks what exactly does an auto encoder do um unfortunately so an autoencoder just as like a one sense is a copying machine it's taking inputs and generally trying to generate the same output while compressing the data inside of a neural network there's a lot more to say about that the twominute papers video on autoencoder and my earlier explanation in today's live stream should give you much more detail but just for anybody who just happened to tune in right now so what's coming next i hope everybody can stick around please stick around i'm going to just take a short break but what's coming next is i'm going to take this trained model and move it into the browser so that i can see the images appear in the browser and animate them which will be very exciting so before i do that i want to thank today's sponsor of the coding train brilliant um i can't emphasize how important it is when you're learning a new concept to be able to try it yourself so me demonstrating stuff in this video i hope is entertaining for you i hope it's turning the wheels in your brain maybe you're even doing it along with me or you're trying it later that's the way to learn but brilliant is all about trying it yourself in spades topics in math in science and computer science anything you can think of there are lessons and challenges and courses and puzzles and all of them are interactive that allows you to try it yourself so um i'm gonna switch back over to the brilliant website itself um you just before i do though that's the url you can actually sign up for free there's a ton of stuff you can do on brilliant for free if you use that link it lets them know you found out about brilliant through the coding train thank you and also that link will give you the opportunity to have a 20 discount on the premium subscription but even better than buying it for yourself let me just quickly mention that uh you'll notice this button up here because i already have them logged in with a premium account this gift premium it is gift giving season and uh it's hard to find things to buy for people it's also i don't know you know this is plastic and packaging and so gifting a premium subscription to brilliant for somebody who loves learning i mean that's what i'm going to be doing for people um uh um you can do that you'll get this through the same link you'll get the 20 uh discount that link there so um i can't recommend that enough let's look at this i i was kind of going to go to the logic there's a bunch of courses so i can show you just really quickly like these are what the interactive lessons look like their logic course has been totally redone with lots of new interactivity so you can see like there's a lot of explanation and then interactive things you can do we're talking about neural networks like all these things i'm talking about about weights we can see there's a whole course all about neural networks that you can browse through um it's a great complement um oh and i'm speaking of which daniel montegrano said can you try loss equals mean squared error and if you want to know what mean squared error is and all that stuff i have a feeling that the brilliant course explains that stuff really really well uh so thanks for that chat message so i think what i want to do today is uh i'm kind of again like i didn't have a plan for this so um if i go to courses you can see these are two courses that i would certainly recommend beautiful geometry is personally my favorite right now and then also the logic course we can scroll through and see all of these popular ones recommended for parents and teachers learning paths you know you can you use if you're watching these probably all appeal to you so um but i think today for fun let's try this nine nine plus challenge that i have not looked at sometimes the best way to solve a problem is by just doing something with it uhhuh that's what i've been talking about then slow down and think about what you're doing for example think about what you need to do to solve just one part of the problem here's a warmup challenge try it yourself drag the tiled numbers up into the plus note that the sum of all the available tiles is zero yet the goal is to make the row sum and columns both positive oh i did not know that uh oh i did wait no oh no no no i didn't because that's negative 1. so i didn't do it right when i first see somebody refused to even try to solve it they glance at it and claim it it's impossible yeah it's impossible i can't do it oh i can put this in the middle well hello no this goes here and this goes here i did it yes [Laughter] if you start by filling the rows sum to one how many different ways are they okay three dwell a little bit so so now it's going to explain 2 goes in the middle yeah this is basically what i did thank you very much your solution might look a little different as long as the 0 and negative 1 are together in the same row or column and the one and negative two are together in the other both sums will be correct so we've shown that it's definitely possible to arrange negative two negative one zero one and two into a plus that's a positive let's take that one step further is it true that if you arrange any five number tiles in a plus and put a positive value in the center the row sum plus the column sum will be larger than the sum of the five tiles can you prove why this is true well that totally makes sense intuitively because you're using the the center tile twice and you're using all the other tiles once so no matter what it's going to be more because you're adding more numbers essentially okay wrap things up here's a bonus challenge that's fair bit more complex than the plus arrangement however it can be solved using the same algebraic strategies to make the puzzle above and today's challenge solvable oh i have to get five five five everywhere well should i try this or should i just let me just move on to the challenge or though maybe i should try this uh i mean if the zero my my intuition is that the zeros and ones should just be in the corner oh but that's going to be the zeros i don't have enough zeros to put in the corner but if i did that right that's five that's five this won't be five oh but now i can do this oh but that's only four all right what am i missing here people we've got everything but this one can i what if i move this here and this what if i put a 2 in the corner oh now i'm confused what number should go in the corner okay hold on again if i put the two here the threes can't be together so the threes always have to be in the how many threes are there just three look at the chat no nobody's solving this for me in the chat oh i have to fit him with the awkwardness of not being able to figure it out okay um what am i missing i should have read all the explanation so so the ways to to make five out of these numbers and only have four numbers are one one one two two two one three two zero zero three two zero zero so is is three in the corner gonna help me or is two in the corner gonna one in the corner are gonna help me more what if i put all the ones in the corners there's only three of each other i'm confused yeah there's hold on reset yeah there's three of each i see definitely want high number in the corner to be used twice yeah okay three hello come on three so if that three is there uh let's put this three here let's think about this then now if where could a two go um with the only other place to put it through i could put a three here all right so let's think about this if the 3 is here if i put 2's here oh i can't put everything has to be a 0. what if i did that oh it can't there's not four zeros so one of these has to be a one then one of these can these can be zeros and then three ah no no no no no so close but no because the 1 is going to mess everything up here you have a total of 18 you want to make it add up to 20. so the tile you need to reuse has to add up to 2. well that's interesting so maybe the ones are what needs to be reused just one one oh hey let's think about this this is the strategy oh this is great 3 times 3 is 9. plus 6 is 15 plus 3 is 18 but i need to have a total of 20. so a 1 being reused is one extra and another one being reused is another extra okay this makes sense this makes sense as a way of following it now then these have to be 0. so then a 3 and a 2 can go here 3 can go here a 3 can go here and then a 1 no oh a 3 can go here and a 0. then a one oh i think i did it and a two and a two thank you forever that so that was the logic that was being explained that i like scanned over from first of all by the way these are so fun like if i what i really would like to do is make a p5.js sketch where you can make these puzzles i mean that's um all right oh and uh so i maybe i could have also done this mike on the box says all the corners are zero but one is a two maybe it would also work that way so i i'd love to decide are there two solutions all right so now here's the actual challenge is it possible to arrange five square tiles numbered one two three four five into a plus so the sum of the three tile column and sum of three tile row so we need to add up to 18 and these numbers add up to 9 12 14 15. so i need three more no it's not possible i was gonna put this as a poll but i think it's not possible because there's no number i could put in here twice to give me three extra because one gives me one extra two gives me two extra three gives me oh no three gives me three extra yes three has to go in the center that's totally wrong i don't know what i was thinking there i was thinking three doesn't divide into two like so i can't put a one and a half in the center but no i just need three more did i do that right let's see uh nine i i i you know i usually like to do these with a poll in the chat but there's uh so i could do let's let's just make the poll it possible or not possible while i'm figuring this out i mean i think i hopefully i was right so i'm gonna make the poll possible or not yes or no no no no add another option how do i delete that now no delete okay so there should be a poll that went up into the chat just now it might take a minute to post where you can just give me is it possible or not and i'm going to work it out so we need to add them up to nine wait what i'm so confused eighteen nine how do i do oh no no four okay okay okay the five and the four can't be together obviously that's eight yeah nine okay this one's two why was the other one so much harder for me there we go i've made them hit submit and now we can see the solution which is that 3 the sum of the row and column is 18. the sum of all the tiles is 15. the middle tile is counted twice so the middle tile must be 18 minus 15 or 3. and then of course now we just need the desired sum in the row and then the desired sum in the column okay 93 of you said yes you got it right uh um and so uh thank you i've been like is this not fun like this is what i want to do later today with my free time are you like that and i just want to emphasize like um if you like a lot of the algorithmic art stuff or generative art stuff that i do on the channel the beautiful geometry course is really the one for you so thank you brilliant for sponsoring the coding train if you're watching and have a minute right now i turn the heat on uh to sign up at brilliant.org cutting train you could do that for free if you'd like to buy the premium subscription for yourself or gift it to a friend or loved one or anyone um you'll get the first 200 people to do though will get 20 off okay i'm gonna be back in about uh two or three minutes to see if we can get the auto encoder running in the browser so don't go anywhere come back stay with me i'll be back i'm gonna turn the heat on for two or three minutes warm up my hands and i'll be right back so oh do do all right i am back just out of curiosity how loud is that hum in the background right now which is the heater going so i'm gonna if it's tolerable i think i'll leave it running for a little bit longer all right everyone so the next thing that i need to do um and i'm keeping an eye on the chat in terms of the volume is i want to just really quickly create a webpage that loads the model and draws the output to a canvas so i'm going to use p5 and tensorflow.js and i believe that at some point there's no reason why i couldn't use ml5 which i would like to but i'm right now i'm not sure if ml5 supports all of the sort of things that i'm doing with tensorflow.js you might be asking like what's ml5 so ml5 is a javascript library that i helped to work on with a lot of wonderful collaborators and people that is a sort of helper layer on top of tensorflow.js to use a lot of pretrained models and do a lot of stuff and if you want to learn more about ml5 if you go to thecodingtrain.com under learning uh ml this the this video series um has just a ton more stuff so at some point my hope would be um it's oddly cut i love all the comments about the sound it's oddly soothing tolerable i love me some calming white noise it's audible but we want you to stay warm so it's all right sounds like a vacuum cleaner all right i'll leave it running for a little bit here one of the reasons why i don't want to run it and let me just vamp for a little bit is that i have this idea that one of the things i want to do with the coding terrain in the new year is make some more kind of video essay like video essay like videos about things like an auto encoder and narrate the process using clips from these live streams so that you could get maybe the sense of how to build the whole project in a 10 to 20 minute video and then if you wanted to of course you could go back and watch all the development during the live streams so i'd have to script that edit that have some animations and things i love your feedback i'm trying to think of like you know i'm on sabbatical for my job at nyu starting in the new year so i'm going to be focusing not full time on the coding train of a lot of other projects and things to work on personally and for creative coding community but i do want to ramp up and at least be doubling my time or tripling my time that i'm currently spending on the coding trade which is very very little so thank you by the way to everyone i don't know how many of you are watching but thank you to all of you who continue to support me through all the ways that you do even when i feel like i'm not doing it enough for good enough so i really appreciate that um okay mike on the box is asking about the cabana i've moved the cabana may come back but right now i'm i'm in a garage which is much bigger than the cabana so uh yeah um okay uh okay so let's go back here okay so what i'm gonna do is let's just go into this project and create a new folder i'm going to call it i'll call i mean at some point i could have this be a full stack web application where the you can send a message to the server to like retrain the model so i'm going to like sort of build it in the way that i might do that so i'm going to call this public and in public i'm going to create index.html and another new file called oops ah what am i doing here don't save don't save so index.html and then i want to create another new file called sketch.js it's in the wrong place i'm sorry you can't see what i'm doing oh my goodness i totally forgot to be recording this whole session so much for that whole speech on what i'm trying to do oh my god i'm the worst i'm the worst well i'm going to start recording it now now i'm recording it so that whole i mean they could still use clips obviously it's being recorded in the sense that when i'm broadcasting it's being recorded but ah okay so much for my grand plan there well still still possible okay um the quickest way for me to let me just get let me just go to the p5 web editor this is my html file uh oh whoops that's in the wrong place public yes move and then my sketch file is it's very hard to type when your hands are cold function draw uh what i've got some crazy autofill stuff going on here and um let's just do okay let's move the model into public as well and then when i run the node script to train a model we want this to go into file public but i'm not doing that right now what i'm doing here is i don't need the sound library let's go back to the tensorflow.js documentation no not overview api reference okay maybe overview get started no there's still a nice link there's a nice link to ml5 here that's so lovely um i'm just looking for like the um guide maybe i just want to know what where the script tags i need install but i want tensorflow.js to install ah this is why are things so hard to find is it just me is it me setup there we go i found it it was in an obvious place can i use tfjs 2.0 i hope so why not so let's try this okay so i've got tfjs now what i'm going to do is i'm going to open a separate web server so ultimately again like where i might go with this project is have it all be one application where there is a server that you can like send messages to to like train them retrain the model and do different things and then there's a client that can load the model and do stuff but right now i'm just treating those as separate projects so this is the client and you can see that my p5.js sketch is loading oh style.css i don't need to worry about that so let's i don't know what how this got over here let's get rid of that great so now i have so the goal that i have is to see an output image in that canvas uh yeah sorry everybody about the sound of course now i'm finally recording now is when i have the bad sound and i wasn't recording the whole time when i had the good sound but i just got to get it to warm up a little bit more in here um i don't know this is not something that i really thought about how to once i once i once i solar power this place maybe some electric heaters i can do that i'll be quieter we'll see um okay so now i should be able to have a variable called like auto encoder uh auto encoder equals tf so this should be the same exact code that i'm doing on the server the difference being i shouldn't need the file path anymore and this has to then be an async function and let's do console log auto encoder so let's see if this works well that's a good sign this looks good i feel like it loaded it i got no error and i see an object that looks like a model so now if i go back to the server code and do generate okay x test so now what i want to do is in the draw loop i'm going to just feed at some noise um i'm going to say no loop oh where am i i'm in the web header i don't want to be in the web editor i could be in the web editor but i'm not doing it there um i'm going to say no loop is the font size okay for everybody it's a little smaller than what i usually work with output is auto now x test has to be a tensor so again at some point um where did i make x test images slice so let's think about this what is one image oh i could draw an image okay uh like what if i just make the image a blank array and i know there's a higher order function like that i could use fill and so 784 pixels and if i make that just like a random number i'm just going to feed noise in right now because i'm not sure what else to do um and then uh this would be turn that into a two that image into a 2d tensor and like i only have one so it's just that one image in an array is this right where like images like tensor2d imageslice500 yeah and then and then i should be able to just call predict and then this is an a if this is an async function i get the new image all right let's just try console logging this call this output image so it should just be one and so i'm just doing one image i'm creating a random array of noise i'm turning it into a tensor i'm sending it into the auto encoder i'm getting something back out and just logging it to the console let's see if this works okay good sign why did i do it twice why did i do it three times because i have no loop i wonder if something weird about the async and the no loop let's get rid of draw for a second here and just do this once and let's not log the autoencoder anymore let's run it again okay great once so i got my image now i should be able to and this is very silly what i'm going to do but it's and can i just do this will that work with or do i have to do i probably have to put parentheses around the await so that's the output image okay now what i could do is say load pixels update pixels oh no no no i want to draw it bigger so i'm going to do this this is a little crazy but i'm just going to draw it as a again sorry for all the noise in the background but it's making it possible for me to do this right now um oh i know i need another bracket and then i'm going to say rectangle i i got to fix my vs settings i times 10 j times 10 10 really square is what i want i'm going to say fill out output image i plus and this should be a j i plus j times the width which is 28. and again i'm hardcod i'm just i'm hardcoding all sorts of stuff um i'm looking at the uh all right everybody let's be nice to each other let's be nice to the fact that i need to run a heater let's be nice to the fact that we're all asking questions and not sure what's going on i'm very confused i'm not explaining everything let's be nice to each other in the chat please um so i'm looking for the pixel that corresponds with the square that i'm going to render which is the x plus the y times the width and then multiply this times 255 now this should probably just be noisiness but let's see uh oh what what import uh just trying to auto import stuff i've never seen so excited to see a square in my life that is insanity oh my goodness i didn't even that's funny i could like basically have the latent space be the beginning wow this is crazy i i weirdly i don't know why but i weirdly want to do this just because i like seeing the full square but also that's silly what i could do let's do this this is so this is like the silliest thing i've ever done in my life that this is what i'm focusing on right now how do you do this is that correct css yeah that's what i i just wanted to do that okay right how did it produce the script monothon asks everything that i'm i'm asking right now in my head how did it produce a square if the input wasn't a square that's cool right so i think the denoising should work now all right you would think right can this model let's do the following let's do an a real input square and a real output so um 280 times two 560 right and then i'm going to do this create graphics or create image uh 28 by 28. um oh no i need to do create graphics oh no this is fine i'm drawing it a square i can it's fine i don't need to put it on a separate background 255 now okay so what i want to do now is have the filter invert 100 what i want to do is have an input image and see the output image so let's draw the output image on the other side and now i want to see the input image on this side so the input is so this would be this can be a function a function render sum array image array at some x and y so this would be x x plus that and this is the image array and the width and height i've still got hard coded here in this like scale 10 that should be fixed at some point but now what i should be able to do is render output image at 280 comma zero still getting the same thing a little i'm a little bit suspicious of the fact that the square never changes its size oh no no it's different it's different each time just very subtly so okay now there's no reason why i can't say render image zero zero oh this is insane so i could make this like so i want to get to the browsing the latent space part but weirdly i could just turn this into like a pearl and noise field that's like subtly changing over time and see what happens to my output image like i'm not even like the whole point of this is so i can get down to that reduced dimensionality but i can actually play with this input because it's just 784 values this is this is so i'm so excited by this i can't i mean this is like the most basic of the basic of the basic but i'm uh this is just like really unlocking for me um this like sometimes it just feels like total matte and this feels this even feels like magic but it when you see like these really sophisticated generative models but really being able to like all the pieces of everything going on here we have coded and designed yes the actual machine learning math is coming from the underlying tensorflow.js but how we're manipulating this what data we use of total control over so um what i would like to do now is i would like to put this into the draw loop let's just see what happens here if i just put this async function draw like what if i how okay nope what did i mess up oh the auto no can i read properties of undefined reading predict oh this has to be a wait no what am i doing wrong here wait output array render as if oh no now i didn't get an error but i'm not seeing the i think that a i think a sinking draw is a real problem here so let's not async draw let's let draw go ah this is why i don't like doing this in the browser it's got to be the fact that i'm asyncing draw right so what if i just do like my own loop so let's call this input image oh shoot so this will be an async function this in return output image this isn't really no because all right let's make these glo this is a bad idea but let's just make these global so this is uh and then when you get the next image we make a new one hold on what if i do this let's just let's just initialize them this is sort of i don't i don't like what i'm doing but i just want to make sure it works and then let's just i'm just going to fill them randomly and then this just renders both of them okay oh input image index i i i should see just two random images great so i got two random images um yeah that cr what chris is suggesting you could have draw a whatever is latest finished and your asic function called itself recursively is what i'm going to do there also is an array sync function i think where i can make that conversion to data so mike on the box is asking why do i need a weight so the the three the thing with using tensorflow.js is it's doing all the machine learning math on the gpu and there is uh com there i mean i'm using so little data that this is so unnecessary i should send the back set the back end to cpu but you need to uh have any time that you are taking the data out and turning it in and off of the gpu so that i can manipulate it in my code that needs to be an asynchronous function so this return is unnecessary so what i'm going to do is call await next image so let's just see if i can get one new image no image is not defined where am i still using image uh here okay great so i've got one and now i should be able to just call next image now sometimes this will lock up the browser if i don't like give this a little bit of like daylight here like with a set timeout but let's just see okay great no no problem so this is now working i'm just always drawing the latest thing so now again i want to make this a proper latent space but i cannot resist pearl and noising this so we're going to create x off no i'm going to need to use no this will be z off and then the next image is x offset equals zero no let's do this properly let i equal zero i is less than 28. i hate that i have this hardcoded in here i've got to fix that up so we're going to have j is the y offset gonna have an x offset now you might be like what are you even doing right now so i would assume that let's say 2d purl in noise there we go thank you google for referring to me but um so what i'm doing is i'm taking this concept of having two dimensional purlin noise which you can learn more about in this video from five years ago how long have i been at this oh my god and using that as a way of manipulating the input i really should do the denoising but i can't resist this so you may not understand fully but i'm going to say let value equal noise x off y off z off so every j the y off should go up by some incrementation no stop autofilling things for me the x off should also go up by some incrementation value and then also wait i'm missing a curly bracket right next image curly bracket for what did i do wrong here i just oh oh no that's the end there what just happened ah i forgot that this function has more to it okay we're okay there we go and then z off goes up by that incrementation as well we're going to make it a slow increment let's try this for right now and then the input image in i plus j times 28 equals that value all right so let's see what happens here oh we've got some weird extra imports again uh syntax error in line 26. that should be an equals so here i am i mean yeah so this uh the z offset incrementation is kind of wildly too high oh wait no why did i oh that's x off i guess i should have a different yeah so this is this sort of like cloudy pearl and noise field that is changing and slowly over time we're seeing late so again i'm gonna really need oh it's 11 54. i have to wrap up uh this is definitely needs uh right michael kempt is pointing out a very good point which is just because pearl and noise only moves slightly does not mean the output squares will follow so i got a little sidetrack whereas i really should just be working with just the decoder but i think i can i i've got to go unfortunately about five minutes because let me just check um okay because my um i gotta get back to my kids for her i could give you all the details about that but that's the that's the summary but um and that's why you're excited for the actual latent space it's more likely to be a smooth but i think i can get something a little bit more exciting here um so what i would like to do well first i would like to test the denoising that's going to send me i really want to test the denoising but the two things i wanted one would be testing the denoising i'm pretty sure the denoising is going to work though because even just like random noise gives me a square so you would think that random noise with a sort of darker high square embedded inside of it would really give me the square but i think what might be more interesting is for me to have an output with much more variety so should i stick i also kind of am tempted to bump up the resolution i think i'll stick with 28 by 28 though and what i'm going to do is this is my data generation so i am going to say first of all i want the size of the images to be have much more variety so let's allow it to go all the way down to 25 then let's also say if random is less let's flip a coin and have it either be a square or a circle let's also i mean i think 500 images should i double the number of images just because um just because now i'm doing squares and circles let's see let's so let's try this so now my images are both squares and circles i'd love to introduce triangles in there but i think this will give us something more interesting just to start with because what i want to see with the latent space is the morphing between squares and circles and i i unfortunately the latent space is gonna have to wait till next time although i am planning to live stream this coming friday i could do it tomorrow probably not though tempted to come back tomorrow we'll see so now if i take this data right which should be squares and circles so this is now the new training data and let me just have is the code loading directly from that now i'm going to go back to my training code i could um let's generate whoops ah let's put the training back in ah sorry everybody what is going on i'm so having trouble i'm just going to manually do this so i want to load now 1100 images i want to train train the first 1000 and then the rest will be the tests um image loading where are the images being pulled from when i load all images uh so i think i might liked it to go directly into whatever processing has outputted most recently by the way i'm going to turn since i'm wrapping up i'm going to turn the heat off all right it's plenty warm in here and i'm going to be wrapping up soon so i've turned off the heat um so i'm going to grab this i'm sorry to be rushing a little bit here oh and they're all called square that doesn't matter and there's a thousand of them so oops no but that's fine the last one would be 999. wait a sec like i want to get rid of this and what oh i need four i need uh no no it worked no but let me so this should have a four here let me run that again oh actually ah no stop sorry everybody data is a thing okay delete all this the chat has gone quiet again so what i'm learning by the way is which is totally fine is the those of you who are here thank you it's a small audience for this on sunday morning let's generate the data again 1100 is that right yeah okay so now and then what i wanted to do is have yeah the images come from oh and this is so silly but it's fine i'm going to leave it as saying square that i do need to change because they're not all squares so i should probably use a more generic term but oh oh oh and then now i should be able to put that in there is there another place where i'm numeral formatting things i don't know what this is is this right this is writing the output but that's fine and so this should go to the actual data from processing so let's see what happens and then we want a thousand and then the 100 for the tests okay so now i should be able to train the new model oops line 21. oh i'm not loading anymore oh this is going to take a while for 100 epochs there's a lot more data let's see how the loss goes all right so q who just joined kyu what i'm doing is i have trained an auto encoder to which is a machine learning model to try to reproduce generic images of squares and circles so right now i'm training that model and once it's done i'm going to load a webpage which shows the results of what the model generates when random noise is fed into it there's a lot more pieces to this that i'm sort of missing here at 6 00 p.m yeah um okay we got to 100 okay so now so first of all we have a little we have some test things that i generated just to see so the output folder should now have new oh um i have to look at the noon ones yeah it's like a circle square squirkle is that the term okay great so we're seeing stuff so now in theory if i refresh this page [Laughter] this is so cool you can see this sort of like it's like a latent space browsing but i'm not really doing that yet now could i expand the universe of the inputs like purlin noise is very sort of like limited around the like i'm just curious so this is where i'm going to wrap up today i'm very happy with this result even though clearly i need a part four i need a part four um i would love to like just swap in open simplex noise but one thing i can do very quickly is i can do two times i mean i shouldn't do this but like i'm feeding in like weird negative numbers and stuff that it doesn't know about so just to sort of see this isn't wild um all right let me just go back to i'm not doing this weird thing that i just did here so ah all right oh 1204 okay okay just give me like five more minutes because i just want to see like i want to have a sense of am i capable of doing this at uh double the resolution right now so now unfortunately i've hard coded everything so let's just look for a second in it's like what if i were to uh i don't know about this oh yeah resize everything to so let me just do a little cleanup here just to leave this because i want to leave this in a place where people can play with it so i'm going to delete all the output i'm going to the model can stay there i'm going to delete the training data i want to just go through and then so let's do 28 times 2 which is 56 20 20 plus 20 is 40. 8 plus 8 is 16 56. so let's just try it double um so that's so i'm going to make this training data it's going to be a little bit higher resolution then when i go into the auto encoder do i have it hardcoded anywhere like 700 yes so now that is that the only place where that's hardcoded there's two places and then is 28 anywhere no okay so i need in this oh here it is so i need to have a constant w equals 56 and so this should be w times w this should be w times w and then this should be w times w is there any 28 anywhere w this is w this is w that's just 128 and is there any 784 hardcoded anywhere no then i should be able to go back to the sketch and also have i not really this so this should be uh w times w and this is w times w this is w this is w w this is all right so this i have to think about now so then i also have like little w which equals i'm just going to say height divided by the big w because then that is w times w right is how far over this is w w and then this is little w little w little w i think i did this correct so now all i need to do is like if i want to use a higher resolution image this is like whatever that is i just have to change it in two places here well three places the processing sketch the p5 sketch and the node server so i did it already here i didn't actually make it a variable here just to be consistent let's do that again there's there would be you know tying all these together would be better but now i should be able to train the model it's going to take much longer now i don't know how long like that's one epoch so one epoch was a few seconds there so this is going to take a while line 49 um so i don't know what line 49 was referring to um i think i got it already i'm assuming if it was in here if it wasn't here thank you missed one thank you for that yeah those variable names ouch yeah this is terrible so pull requests that i'm looking for are cleaning up the variable names love that making a nice readme that sort of explains everything and links to these live streams i would love pull request contributions for that i mean in january i'll get to it myself but i'm at epoch 31 oh boy this is going to take a while but this is this is um this is going to be the end for today i i did not the things that i didn't get to is just lopping off the input so the two the three the things that i wanted to try and this could go into the readme if anyone wants who's keeping notes on any of this nobody my mental notes are i want to see if the denoising works and then then i want to uh also actually work with the proper latent space by feeding the input like i just have eight dimensions and creating sliders to manipulate those that's next on the agenda um and you know then also trying training like rgb color could i do how high of a resolution can i push it we can see how long this is taking already just for um a hundred epochs but i'm halfway through i don't know this probably doesn't need to train much longer the loss is still going down um thank you for all these chat messages uh um is my discord even working there's nobody nobody putting messages into the discord but um i've got a supporter channel and discord that i keep open during the live streams okay we're at 80 we're getting there this could use some music right all right 82 83 84 55 86 7 88 89 98 51. seven eight 100 the loss is still going down i could let it train longer okay so now i mean in theory i should just refresh this page and it'll be working at the higher resolution with the new model because everything's pulling from the same directories but how is that how is that possibly going to be true okay yeah working this is wild all right let's move the late let's move oh this is so let's have the numbers move faster so actually let's just do this let's change the incrementation just globally here there we go so i it seems to be just kind of oscillating between a small circle and a big circle um but i think i really need to play oh there we're getting like a square but the purlin noise space is not giving me a tremendous amount of variety actually oh yeah look at that whoa that's cool this is like this is amazing i mean i'm like i you know i'm living like way in the past in terms of like where the current state of machine learning generative models is today but i don't know i just i'm just in love with this weird sort of thing that i've made but um i uh i want to make this go even faster i'm just curious to like let's let's keep pushing this speed of change here yeah what's interesting is how it goes from like small to big through a fade as opposed to actually like having to grow but and then every once in a while it like turns into a square shape um but anyway yeah where are the squares i'm i'm with you michael michael where are the squares um you know one thing that i would do here just out of curiosity is to change from pearl and noise to just randomness again um and sort of see what that gives us ooh whoops oh i'm missing the w times w it really does seem to be that so much more heavily circle making and it's kind of like it's going but i this isn't a proper test because and i'll go gonna go back this isn't a proper test because i'm not actually working with this in a logical way the two things i should be doing are number one if i am actually wanting to see what it does with full in the full input image i should be drawing strange shapes over here and seeing how they match up then i should be actually controlling the latent variables with sliders because i bet you we could find the circle to square that this dimension so this is what unfortunately i mean two hours and 15 minutes is all i can do for today so part four is coming on friday where i want to examine um actually putting in some input images to see if denoising like let's make also some triangles let's make this more sophisticated maybe rgb color could even be added and then working with only the decoder and creating sliders to allow me to manipulate it since you have more input variety you should train longer to recover the shapes properly yeah i also just needed to train this model longer but the initial results are amazing thank you so before i go any further well before i wrap up so what have i changed there's now the public directory that has the model in it and the the p5 sketch i've updated the um the node server to train a new model each time and uh the processing sketch um yes hand drawn circle as an input the output would be a perfect circle oh from perlin oh these are such good ideas file them as issues i mean or pull requests to read me but if these ideas i love these ideas i will not remember them so the purlin noise generate landscapes is a really interesting idea the um drawing and then seeing um seeing if we could make a machine learning model take your squiggly circle that you draw and make it a perfect circle i love all these ideas um so um yes let's do all that add them as issues into the github repo um so let me just do git i did that already git add git commit new this is like code for p5 sketch and training and saving slash loading model that's really what i did today git push origin main and you can see that model is you can actually work just with the p5.js sketch now because the model files i r m committing to the repository so uh if i go here autoencoder demo it's very painful to me that there's no readme here but um this is just the p5.js sketch this is the model that i trained most recently i'm just curious how big is this file 6.4 megabytes very reasonable so everyone can play with this to their heart's content those ideas that you have of things i could try next please file them as issues mini jimmy looks like so if you are taking your own you're making your own version of this um and you add things like colors and do like real expanses of the feature set don't pull request that but either file an issue or pull request a link in a readme to your version with um sample images but what i would love pull requests are documentation of what i have so far um any like small any like real bugs or like significant mistakes that are in the code or small clean up things where like the variable names are changed to be a little bit better i would welcome that but anything that's really significantly changing what i have so far i can't merge because i want to have a record of everything in the live streams but you can i could link to it and review it and incorporate those ideas okay thank you everybody uh thank you to brilliant for being the sponsor of today's live stream check out brilliant brilliant.org codingtrain um and uh i will see you all um whoops maybe on well definitely well hopefully hopefully on friday i'm going to continue this i feel like just leaving this here um i wanted to produce some squares no you don't see this this is like uh i was gonna like usually i'm just gonna leave this here as i play all the outro music and see you on uh the next the next live stream uh this auto encoder project has really been uh fascinating to do i have to think about what how do you think about what to do with this next like i could make proper video tutorials of coding the whole thing that are edited through i could make one video that summarizes it i would love your feedback on that like you're maybe the wrong person to be asking because you're watching this right now but a lot of you just are probably tuned in the last 15 minutes so what would you want if you weren't able to tune into all the live streams or if you wanted to go back and review parts of the live streams what would you want as something that comes out of this as a video i don't know uh i'm gonna be working on that in january okay um see you all do i have just the laptop button no i don't have a button for that here does this work yeah all right so i've removed myself i'm muting myself and i will see you all next time on the coding train um as always i always forget that this dot this this dot this dot i'm realizing something so while i'm playing that music i'm realizing that if i had the latent variables like tied to like frequency levels in the music or something then this output would go along with the music so as like the beat goes the circles would like change as the music slo you know like quiets down it would become more static this is also something for me to try for any of you who are adding issues to the repo for things for me to remember next time having the latent variables tied to input sound would be an awesome thing to do that was the invalid syntax i forgot uh there was one other thing here that i think is important that i will use continuously over and over again all sorts of text generation analysis things that i will use continuously over and over again first thing i need to do is yes kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens next time bye
