With timestamps:

00:03 - [Music]
01:27 - [Applause]
01:28 - n
01:34 - [Music]
01:44 - [Music]
01:45 - [Applause]
01:47 - [Music]
01:58 - a
02:10 - [Music]
02:11 - [Applause]
02:13 - [Music]
02:21 - [Applause]
02:29 - [Music]
02:58 - n
03:00 - [Music]
04:34 - check one two hello it is me last
04:40 - name to test my
04:43 - audio I
04:45 - [Music]
04:50 - have oh I got 23
04:54 - seconds I won't be ready in
04:57 - time but close I'll be close
04:59 - [Music]
05:28 - a
05:31 - [Music]
05:32 - all right I I heard you all loud and
05:34 - clear that my mic is quite quiet
05:36 - compared to the
05:38 - music I'm gonna leave my mic where it
05:43 - is I'm just turn the music down actually
05:46 - let me turn it up a tiny bit here I have
05:49 - to figure out that'll boost the volume a
05:52 - bit uh so hopefully this is better for
05:55 - you all
05:57 - now um
06:02 - yeah all right here I come the train is
06:05 - departing kind of almost
06:08 - maybe get my notebook
06:12 - out uh I'll turn the camera on
06:15 - me so many things here I'm not prepared
06:18 - for this at all but I'm doing my best
06:21 - everybody good morning good evening good
06:24 - afternoon hello to all of the coding
06:26 - train passengers all around the world it
06:29 - is is me hello to Julian from the UK
06:31 - your
06:32 - host
06:34 - Daniel
06:36 - schifman and I'm here live on a Sunday
06:40 - ah I forgot to turn the heater off I'm
06:42 - in a very cold garage but I have this
06:45 - electric kind of hanging garage heater
06:49 - which uh I am now walking over to to
06:51 - turn off it makes kind of a loud noise
06:54 - uh later I may have to turn it on again
06:56 - if I get kind of cold that didn't work
07:00 - different switch here there we go I'm
07:03 - coming back I'm coming back to view
07:05 - don't
07:06 - worry here I am I'm moving a little
07:08 - slowly it's a Thanksgiving holiday
07:10 - weekend here in the US and I went to
07:13 - visit some
07:14 - family and I slept on a very small twin
07:18 - bed for one night and like half of my
07:20 - back the muscle is all like contorted
07:23 - and twisted so a the my whole rest of
07:25 - the afternoon today I think gonna be
07:26 - doing some stretching I'm an old man on
07:29 - you for you for I mean I'm not you know
07:32 - in in many ways I'm very young to be
07:34 - like I'm I have no interest and and and
07:36 - not qualified to be president of the
07:37 - United States why am I even talking
07:39 - about this but for YouTube for doing
07:42 - this thing that I've been doing for well
07:45 - over 10 years 20 years got something
07:47 - stuck in my teeth I was quickly having a
07:49 - little toast and peanut butter to have
07:51 - some energy
07:53 - here it's been a while I know I know I
07:56 - don't know what happened to 2023 um
08:00 - uh it's almost over I I I was feeling a
08:02 - little bit better uh now I have this
08:07 - um uh a a list of goals and plans that I
08:10 - made at the beginning of the year and
08:12 - there surprisingly are some things
08:13 - checked off here so I feel like uh all
08:17 - is not lost but it has not been the most
08:20 - I mean it's been a very productive year
08:22 - for me and I will talk about the nature
08:24 - of code book which has been my focus for
08:27 - this year um which has really reduced
08:30 - the sort of productivity the content if
08:33 - you will because what else do I do here
08:36 - on the coding train but make content I
08:38 - mean that's what we're all here we're
08:40 - just engines of content to make content
08:43 - to consume content it's all content
08:45 - content content I haven't made very much
08:49 - I would like to say
08:50 - educational possibly slightly
08:52 - entertaining tutorials um but I'm here
08:55 - I'm trying to get at least uh two more
08:58 - live streams in before the end of the
09:00 - year maybe well start thinking about
09:02 - goals for 2024 I do believe in my heart
09:07 - that 2024 will be more coding train
09:10 - focused because there's a fly that's
09:14 - really interested in my light over there
09:17 - so hopefully this won't be too
09:18 - distracting but uh with the nature of
09:21 - code book wrapping up um I think that I
09:25 - would like to turn back towards videoing
09:28 - as opposed to writing uh after all I can
09:31 - just have some language model take care
09:33 - of all my writing for me in 2024 but
09:36 - maybe my humanness still uh comes
09:39 - through the camera somehow although I am
09:42 - working actually let's not mention this
09:44 - just yet but uh coming soon coming soon
09:49 - something interesting for all of you uh
09:52 - where when can we buy the book so let me
09:54 - not talk about the nature of code book
09:56 - just yet because I do have an actual a
09:59 - sponsor of today's live stream uh you
10:02 - really should thank the sponsor greatly
10:05 - because sometimes you know I don't take
10:07 - a lot of sponsors I'm really excited
10:09 - about this one um it is a company called
10:12 - upper story and as soon as I saw and
10:14 - you're not seeing this right now as soon
10:16 - as I saw this game called the Turing
10:18 - tumble named for Allan Turing don't get
10:20 - confused there's a lot of turning going
10:22 - on but this is a game named for Allan
10:25 - Turing um I was really excited I
10:27 - desperately wanted one of these to play
10:29 - with it to try it with my children um in
10:31 - AIT bit I'm going let's see if I can get
10:33 - this camera to work I'm going to show
10:34 - you it live in action I've got it over
10:36 - there uh on a little extra table um so
10:41 - uh you know it's it's holiday time if
10:44 - you're looking for a holiday gift if you
10:46 - want if you if you know some children
10:47 - some adults who want to get into
10:50 - computers want to learn how computers
10:52 - work how to logic gates work all that
10:54 - stuff uh but maybe you need to take a
10:57 - break from your screens uh this is an
10:59 - entire mechanical this is this is a
11:02 - turing complete
11:05 - computer uh sitting there on the table
11:08 - um so uh I'm gonna I'm gonna I'm gonna
11:11 - talk a little bit more about it but if
11:12 - you're interested in learning more uh
11:15 - right now uh there's this website that
11:18 - you can see upper story.com Turing
11:20 - tumble but better yet there a link in
11:22 - the video description I don't know if
11:24 - there's any moderators around I'll have
11:26 - to do this myself at some point but I'll
11:27 - put a link into the chat and maybe even
11:30 - pin it as well
11:34 - um uh so am I ever gonna be it's a gonna
11:38 - be the most techsavvy Grandpa you know
11:40 - first of all I'm not that far I mean I'm
11:44 - I'm hopefully very far but
11:46 - but who knows will ever be a grandpa
11:49 - there's a
11:50 - possibility uh I don't think I don't
11:51 - even think I'm I think I'm like not very
11:53 - techsavvy right now I mean my ability to
11:56 - do things on the computer in any kind of
11:59 - Cutting
12:00 - Edge uh intelligent way you know pales
12:04 - in comparison to what the youths the
12:06 - youths the two youths that no that's
12:08 - another reference the youths are doing
12:10 - these days on YouTube boy there are a
12:12 - lot of incredible people making a
12:14 - technology coding educational content on
12:16 - YouTube anyway check out upper story
12:18 - link in the description let me set the
12:21 - table for what I want to do today uh
12:23 - usually I do the little sponsor segments
12:26 - in the middle but I think I'm actually
12:27 - do it right at the top because it's kind
12:29 - of fun it'll be a fun game for us to
12:31 - play as a little Icebreaker and I've got
12:33 - it set up over there on the table and
12:34 - that way I can then uh move the table
12:36 - out of the way and get back to some
12:37 - whiteboarding if I need to so um I don't
12:41 - have my uh systems up and running fully
12:46 - for all of the different ways I like to
12:48 - look at the
12:49 - chat I keep looking over here but I
12:52 - don't see any chat I just see my
12:56 - soundboard
12:57 - welcome on today's episode of the coding
13:02 - train I'm gonna be here without knowing
13:06 - what I'm gonna say
13:08 - next there's a camera over here that's
13:10 - exciting got some stuff going on Vince
13:12 - asks do your kids code yes they do I
13:17 - think they're a little like enough with
13:19 - the coding already oh my goodness coding
13:22 - this coding that blah blah blah blah
13:23 - blah blah but they're they're interested
13:25 - they do kids these days they've got
13:27 - their coding education in their K
13:29 - through 12 schools at least here um
13:32 - which is very different than my
13:33 - experience um all right so um let's
13:37 - let's think about things let's come back
13:39 - to here so one thing that I am curious
13:42 - about I really would like to do some
13:44 - coding today so I'm gonna talk about I'm
13:46 - gonna we're gonna look at the Turing
13:47 - tumble game step one let's make a list
13:50 - okay uh I'm glad you like the background
13:53 - thank you to Stephen wol in the chat I
13:58 - don't have my whistle I I I don't have
13:59 - any of my props oh I got this
14:03 - one
14:05 - okay okay so uh we're going to start
14:07 - with churing tumble today's sponsor
14:10 - thank you to Upper story uh we are going
14:13 - to move from there and maybe look at nbb
14:17 - is asking what is the plan for today
14:19 - we're figuring it out together I'm going
14:20 - to be here till approximately 1 pm
14:23 - Eastern I um so that's um kind of a bit
14:26 - of a hard out for me so that's an hour
14:28 - 45 minutes like to take a little five
14:30 - minute break somewhere in there if
14:31 - possible if you'll be so kind to allow
14:34 - that um I would like to look at the
14:37 - passenger
14:40 - showcase uh we'll look at some recent
14:42 - additions to the passenger showcase
14:44 - thank you to all of you who have been
14:45 - submitting your
14:46 - projects um I would like to give you an
14:49 - update on the nature of code
14:53 - book and you know
14:56 - usually you would think it makes sense
14:58 - to make my agenda before I start
15:00 - streaming but I spend a very long time
15:03 - getting
15:05 - the audio routing properly so that I
15:08 - could have the soothing tones of some
15:12 - royaltyfree music thank you to epidemic
15:14 - sound which I think is this track is
15:16 - from that I subscribe to uh Nicole says
15:20 - I really need to submit to the passenger
15:22 - showcase sometime and yes yes you do in
15:25 - fact maybe you want to do that today
15:28 - make that your little Sunday activity
15:30 - although it's a Sunday any day you know
15:34 - maybe maybe after if you're watching
15:36 - this maybe after this is over you would
15:37 - close your
15:38 - computer spend some time with your
15:40 - thoughts with nature with a book
15:44 - good book you can just curl up in that
15:48 - fly is coming to get me everybody see if
15:51 - I make it through this okay uh do Tetris
15:54 - ah uh wait oh Stefan Wolfram that's
15:58 - actually your name I'm so sorry I just
16:01 - assumed that was somebody with their
16:03 - YouTube name as like a play off of
16:05 - Steven Wolfram but we actually have the
16:08 - real life honest to goodness Stefan wolf
16:11 - from in the chat today which is kind of
16:14 - great because the thing that I was
16:17 - planning to code today because I really
16:18 - I know my recent live streams have been
16:20 - a bit more just chit chatty um but I
16:24 - would like to
16:27 - um the the two things I'm thinking of
16:29 - coding today one is the
16:32 - Wolfram the uh as an homage to our
16:34 - friend Stefan wolf from the wolf from 1D
16:41 - CA and then the other thing I'm thinking
16:43 - of doing is looking at uh a JavaScript
16:46 - library called Transformers
16:50 - JS and doing some uh uh experiments with
16:55 - uh embeddings and
16:57 - text well this is a really long track
16:59 - that I just put on arbitrarily behind
17:02 - me
17:08 - um I love Dustin's comment there uh this
17:11 - is the adult version which by the way
17:13 - got me a little scared at first I was
17:14 - like oh my God am I an adult version
17:18 - sometimes means something else to me now
17:19 - I'm already getting like incredibly
17:21 - embarrassed just uh of everything I
17:23 - loved and enjoyed from PBS learning
17:24 - shows as a kid I appreciate that uh okay
17:29 - um so I got I got to shut this music off
17:31 - okay I just realized that most of my
17:34 - props uh are in a tote bag
17:38 - uh through several doors away in from
17:42 - this garage where I am because I had
17:44 - packed them all up for this thing that
17:45 - I'm working on and I forgot to bring
17:47 - them back so my random number book all
17:50 - those things so one thing I'm curious
17:52 - about
17:54 - um well also we've got um let's look at
17:57 - this so let's just look at this this
17:58 - list and see if there's anything here so
18:01 - let's let's have a little recap what was
18:04 - accomplished um in and by the way the
18:06 - reason I keep looking over this way is
18:07 - that's where I have my monitor at the
18:09 - YouTube chat and when I turn this muscle
18:12 - in my back gets a
18:14 - little poked oh I forgot
18:16 - to will I be doing a Showcase of the
18:19 - hober submissions uh lost sorsor what an
18:22 - awesome idea so let me I forgot about
18:24 - that
18:27 - yes
18:30 - um all right and by the way I do also
18:32 - have out of the corner of my eye the
18:35 - Discord member chat so if there are any
18:39 - important or like comments or questions
18:41 - or something going on if any of the
18:43 - Discord members who are in the live chat
18:47 - supporter Channel want to put a message
18:50 - there let me know I'm not going to be uh
18:52 - seeing it so maybe reduce the uh we'll
18:55 - figure it out as we go but I just saw
18:57 - that uh fish posted hi so I didn't see
19:00 - that uh and I see that we have someone
19:02 - from Morocco
19:03 - today um welcome I'm the one one of the
19:07 - things that I say this a lot that
19:09 - Thrills me to know end are the
19:11 - international uh Global viewers of the
19:14 - coding I mean I appreciate you if you're
19:15 - like watching this from you know queens
19:17 - or something that's awesome
19:19 - too wait
19:24 - what
19:26 - oh I'm like what does that sound
19:29 - I'm like my computer is about to explode
19:32 - do you hear
19:33 - it so I'm using
19:37 - um this software that I love called
19:40 - loopback uh which is an audio routing
19:43 - software and the way that that works is
19:45 - I have a iPad over here with sound music
19:48 - and sound effects and it kind of routes
19:50 - around through this audio interface into
19:52 - this laptop and then I route it out into
19:54 - this PC streaming computer and it comes
19:56 - into open broadcast studio
19:58 - wow Carl is very cold here in in uh in
20:01 - New York so um but I forgot that
20:07 - um uh I just like this is a new Compu
20:10 - new computer that I haven't streamed
20:12 - with before and I just like quickly
20:13 - installed the trial of loop back and uh
20:16 - I I've bought loop back software so I
20:18 - need to find my license code so I don't
20:22 - know if I'm going to do this right now
20:23 - let's see uh okay so let me come back to
20:26 - here and I might have to dig into my
20:27 - email email where would I have purchased
20:31 - it which email address would I have used
20:34 - we're about to find out okay
20:38 - let's oh boy will you all indulge me for
20:42 - a second you know what I'm gonna
20:45 - um like M okay my email is like on the
20:48 - screen this is terrifying uh let's just
20:51 - see if it's really obviously fast Rogue
20:55 - ah lose B license key yes
20:58 - uh could this possibly be 2016 is that
21:01 - going to actually work did I Daniel
21:04 - schifman my code unlock ah older license
21:09 - key but no I've definitely purchased a
21:12 - newer one because I remember doing this
21:15 - recovered license information in 2019
21:18 - maybe this is
21:21 - it this is like uh um where wherever
21:25 - there is somewhere on the internet best
21:27 - practices for life streaming uh whatever
21:29 - I'm doing is not it oh that's the same
21:32 - all right all right hello at Rogue
21:33 - amoeba maybe I actually just need to
21:35 - purchase a new
21:36 - one loop
21:39 - back receipt 2019 okay
21:43 - receipt uh okay hold on I did purchase
21:46 - ah I've got a new license code okay I've
21:49 - got it I've got it we've got it
21:51 - everybody
21:53 - unlock
21:57 - yes
22:01 - oh wh wrong wrong button success
22:04 - everybody loopb back has been unlocked
22:07 - thank you look at this I get a whole
22:08 - certificate and everything I feel very
22:10 - proud of myself and I'm in honor of this
22:13 - moment going to
22:17 - play oh wow you can't hear that at all I
22:21 - made that very
22:23 - quiet um
22:26 - okay uh
22:31 - um let's see um okay so what were we
22:36 - that was an adventure yeah coding
22:38 - challenge idea thought thought planner
22:40 - okay oh that's interesting uh Nick is
22:42 - writing from
22:44 - Toronto yes uh happy belated Canadian
22:48 - Thanksgiving ah MV lab ask will you be
22:50 - doing the January challenge this year
22:52 - let's let's address this and then I
22:54 - gotta we got to get moving on this list
22:55 - of things if I'm going to get to
22:56 - anything wow wow and we've got J from
23:00 - Algeria watching that is
23:03 - amazing um I don't know if I pronounced
23:05 - your name correctly jog uh feel free to
23:07 - spell it phonetically for me in the chat
23:09 - even if I miss it maybe I'll try to go
23:11 - back and read the chat later um all
23:14 - right
23:15 - so I got we got to get moving here ah
23:17 - yes January so if you're not familiar
23:20 - with January let's take a look it's
23:23 - coming up January is uh um a month
23:29 - January is a month that has its days in
23:31 - it and every day there is a new
23:33 - generative art prompt uh it's uh one
23:37 - I've been trying to participate in some
23:38 - way two years ago um I actually did
23:41 - something every single day last year I
23:43 - didn't do anything any of the days but
23:45 - the end of the month I did a January
23:47 - speedrun as a live stream that was
23:49 - really fun so at a minimum I absolutely
23:52 - want to do a January speed run again but
23:57 - I had this idea I um I don't know if you
24:00 - know this but there is a coding train
24:02 - Tick Tock account also YouTube has
24:05 - shorts I don't really use them I'm not
24:08 - really I haven't figured out a way to
24:11 - use them or to make short form content
24:13 - in any way that's fun and useful but I
24:15 - thought maybe as an experiment in
24:18 - January for January I would make a short
24:22 - video every day based on the prompt um
24:25 - and I would do them completely on my own
24:28 - like all any editing production
24:31 - capturing I would have to do it on my
24:33 - own just as a way to learn um to learn
24:37 - oh and we have a new
24:45 - member hello to
24:48 - mooner welcome you have just joined the
24:52 - conductors of the coding train welcome
24:56 - aboard for your membership ah you will
24:59 - receive a little packet of stickers
25:00 - guess what we do the sticker mailing
25:03 - once a year and uh if any of you have
25:07 - received your stickers because we've
25:08 - been sending them out the last few weeks
25:11 - please uh say so in the chat would love
25:13 - to hear that you got them if you like
25:15 - them but um the the mailing happens once
25:17 - a year but you're just under the wire uh
25:21 - muner if you look into the YouTube
25:23 - Community posts now that you have the
25:25 - members one you will find one where you
25:27 - you can
25:29 - um uh sign this form with your
25:32 - information and we will send you
25:34 - stickers so um yes and welcome to
25:37 - Muhammad in the chat and Yash and AI
25:41 - guest I'm so glad that AI is here all
25:44 - right so let's get started and let's
25:46 - start off uh with the first segment of
25:49 - today's live stream this is a sponsor in
25:52 - case you weren't clear about that but
25:55 - it's something that I would 100%
25:57 - legitimately cover on my own it's I mean
26:00 - honestly like I just wanted to buy one
26:02 - so when they were like okay we going to
26:03 - sponsor we'll send you one I mean
26:04 - nothing could have been a better
26:07 - alignment of things so I want to um show
26:09 - you uh a little bit about what this is
26:12 - um it's whoops I'm I'm I'm having
26:14 - trouble I'm gonna walk over here I'm
26:16 - like a little game show host here um so
26:20 - this is the Turing tumble uh again Nam
26:22 - for Allan Turing so uh I don't know how
26:25 - many of you are familiar with Alan
26:26 - Turing I actually have had the uh chance
26:29 - to uh visit a place in the UK called
26:32 - Bletchley Park and it is where Alan
26:35 - Turing uh cracked the Enigma machine um
26:39 - or uh is the enig yeah the Enigma
26:42 - machine is the German code thing that
26:45 - they broke in World War II there's a
26:47 - whole movie about it the imitation game
26:49 - it's called Alan Turing quite famous for
26:52 - the thought experiment of you know Ken
26:54 - machines think and this so-called Turing
26:57 - test which certainly is quite relevant
26:58 - today in today's world of language
27:00 - models and new AI Technologies but uh I
27:04 - think it was in the 30s probably
27:05 - 1939 that Alan Turing came up with the
27:08 - idea of completeness so a turing
27:11 - complete computer is one that and this
27:15 - is you know think about this we're
27:16 - talking about the 1930s I think that
27:17 - paper is maybe 39 I got to go fact check
27:20 - this someone can fact check me in the
27:21 - chat but think about this how did Turing
27:25 - think about the idea of a turing
27:26 - complete computer before there were even
27:28 - really
27:30 - computers that
27:32 - fly is really coming to get me no I will
27:36 - not the sanctity of the Turing tumble
27:39 - board is is quite oh and I I also
27:42 - realized okay I'm gonna talk to you
27:43 - about Alan Turing while I do some uh
27:46 - busy work here uh of just like um
27:48 - setting up something that I oop I'm very
27:51 - clumsy oh boy I'm going to definitely be
27:53 - fired uh uh from my upper story
27:58 - this okay um so all right so a turing
28:01 - complete computer the idea is uh with
28:06 - infinite time uh with with you know
28:09 - without finite time and resources
28:11 - essentially you think about like a tape
28:14 - a MAG a tape that you could process
28:16 - through and essentially uh uh you know
28:20 - perform computations with it any
28:24 - is it's very hard for me to talk and
28:26 - concentrate what I'm doing but the idea
28:28 - of a tur complete computer is one that
28:31 - given an infinite amount of time and
28:33 - resources or memory you might think of
28:35 - it as could uh perform any computation
28:38 - uh at all and amazingly this toy uh you
28:43 - know board Contraption mechanical
28:45 - Contraption which I had a lot of fun
28:47 - putting together by the way just
28:48 - assembling this thing was quite the
28:50 - challenge for me is a turing complete
28:53 - computer and um one of the things about
28:56 - it what what I love about this game uh
28:59 - so first of all let me come over here
29:00 - and just explain to you how this works
29:01 - let's see if this will
29:03 - work
29:05 - uh ah great perfect so I have over here
29:09 - um the the board itself comes with this
29:11 - book uh the Turing tumble puzzle oh it's
29:14 - upside down okay let's fix that that's
29:18 - one
29:19 - button uh come on alive there we go the
29:23 - Turing tomble puzzle book um 1936 says
29:27 - Dustin was when Turing published the
29:29 - paper on the hypothetical machine uh
29:32 - 1936 okay so uh are you hearing lots of
29:35 - audio pops and snags people are telling
29:38 - me um so let's see I could get a little
29:42 - bit of info if people are having audio
29:44 - issues and I will try to fix those
29:47 - hopefully it is at least you can
29:49 - understand what I'm saying um but I love
29:51 - to know so one of thing what I love
29:53 - about this is first of all so the book
29:56 - comes with a diagram now there's all
29:58 - these different elements I'm not going
29:59 - to be able to go through and do
30:01 - everything plus I wouldn't want to spoil
30:03 - it for you frankly to be perfectly
30:04 - honest so I barely want I want to show
30:06 - this to you because it's so cool um but
30:09 - I don't want to show you too much so
30:10 - this I had a lot of fun putting this
30:11 - together um there is a whole story
30:15 - graphic novel essentially that you can
30:17 - read um this is but I've been doing this
30:19 - with my son who is
30:22 - um
30:24 - 15 yeah and he just he turned 15
30:26 - recently why I had to pause there for to
30:28 - remember we're having a lot of fun
30:30 - putting this together um looking through
30:32 - the story and then as integrated in the
30:34 - story you start to learn about this
30:36 - machine um and how to play and there are
30:39 - a whole set of puzzles and you know
30:43 - immediately when looking on this I
30:45 - realized like oh this is just like a
30:48 - computer and one of my favorite uh Parts
30:51 - is this uh is the um I forgot what it's
30:54 - called it is the um it's going to
30:56 - introduce a new part here new part so
30:59 - this new part is the bit so I have it uh
31:02 - here I'm going to show it to
31:03 - you um oops wrong button I'm getting
31:08 - back in used to this uh no audio problem
31:11 - somebody told me okay that's good um so
31:13 - this uh part right here is a bit and it
31:16 - can be in one of two states and as you
31:19 - see as soon as I get this thing going
31:21 - these marbles will fall and when they
31:24 - hit this bit it switches to another
31:26 - state so
31:27 - essentially uh if you've ever studied uh
31:31 - a and you don't the whole point of this
31:32 - is you don't need to but I'm connecting
31:34 - it to the audience here if any of you I
31:36 - know a lot of you are maybe current
31:37 - students or are maybe studied computer
31:39 - science or took a Computing course uh if
31:41 - you ever studied Assembly Language or
31:44 - lower level computer you might have
31:47 - computation you might have learned about
31:48 - how what what is a logic gate what is a
31:51 - bit what is a register how do computers
31:55 - store information
31:58 - one of the puzzles in this uses these
32:00 - bit pieces to count right because if
32:03 - they're all zeros and ones you can count
32:05 - in binary and you could essentially
32:08 - program by moving these other parts
32:10 - there are gears there are all these
32:11 - different parts so let's just give you
32:13 - an I've already solved one of the
32:14 - puzzles let's look this is puzzle can't
32:17 - remember it's one of the early ones
32:18 - where basically the input are blue and
32:21 - red marbles and what uh what your goal
32:25 - is is to have a particular output that
32:27 - will land here on the bottom and for
32:29 - this particular puzzle the desired
32:32 - output is uh red blue oh no blue red
32:36 - blue red alternating colors so I think
32:40 - I've set this up correctly I it's
32:43 - definitely which position this in is
32:44 - very important I believe uh if I have it
32:47 - in this position the blue Marble's going
32:49 - to fall down this side and Trigger
32:51 - another Blue Marble which would give me
32:52 - two in a row which I don't want so I've
32:55 - got to flip the bit this way I'm going
32:56 - to click this to start
32:59 - it and here comes the Blue Marble it's
33:02 - going to click this which will send a
33:03 - red one ah and the red gets sent to the
33:05 - other side I did it oh so first of all
33:08 - this to me is like the most satisfying
33:11 - sound
33:12 - ever and I'm going to let this play
33:14 - while I go and look to to see if there's
33:16 - some other things I want to tell you
33:17 - about this
33:18 - machine um right so uh I had some notes
33:22 - here so this is a computer it's turning
33:25 - complete so any process that you could
33:28 - do on your computer on your phone you
33:29 - could actually program on this I mean
33:31 - the limit here is the fact that this
33:33 - space is very finite so I only have this
33:36 - much to work with but what's really
33:38 - exciting about this is just how that
33:40 - like explodes your mind to realize that
33:42 - if I if if we had an infinite amount of
33:44 - space for this contraption um we could
33:47 - really program anything all you know you
33:48 - could have a chat GPT could run on this
33:51 - basically uh um let's see so the other
33:55 - thing is there is something called the
33:56 - Turing Trust which was started by Alan
33:58 - turing's family uh strives for a world
34:01 - of equal opportunity with technology
34:02 - enabled education for all um and a
34:05 - portion of each purchase goes to support
34:08 - the Turing trust I wanted to um remember
34:11 - this so upper stories model makes this
34:13 - game is endless curiosity they have
34:15 - other games there's one called
34:17 - spintronics um but really like for me
34:20 - what is really exciting about this is
34:22 - just the one is the pure satisfaction
34:25 - and joy I have from like watching the uh
34:29 - the mechanical nature of this play out
34:33 - um you know I I if I I really want to
34:34 - just put all the marbles back and look
34:36 - we got red blue red blue red blue but
34:38 - the other thing here I think for if you
34:41 - if you if you work in education if you
34:42 - just want to learn yourself if you know
34:44 - a uh a young person or who is just
34:47 - getting started in Computing wants to
34:49 - learn more about how computers work how
34:51 - does counting in binary work how do like
34:53 - the lower levels what do those
34:54 - transistors really do in a computer this
34:57 - and it's you know holiday time this is
34:58 - the perfect gift I would say so um uh if
35:02 - you're interested uh there is a link in
35:03 - the video description um if you use the
35:06 - code coding train all caps one word uh
35:09 - that will get you 10% off uh purchase of
35:12 - the Turing tumble uh certainly if you do
35:14 - end up getting one and enjoy it I'd love
35:16 - to hear from you hear about what your
35:17 - experience is um let's say I thought
35:19 - maybe we would do one one puzzle um the
35:22 - one that I thought might be kind of
35:24 - interesting to try uh let's see here
35:27 - while we have a little
35:29 - time um the Arya ask you for the link
35:31 - it's in the video
35:33 - description um I I should uh post it
35:38 - right and and Kathy writes reminds me of
35:40 - The Game of Life as a computer which I
35:43 - also think is a really apt uh analogy
35:46 - and it's in many ways it's like perfect
35:47 - that what I want to do is the wolf from
35:49 - s automata today maybe as a coding
35:51 - example because you know I was thinking
35:53 - like oh this is just like the wolf from
35:56 - CA which is this system of uh cells that
36:00 - have a state zero or one and the the
36:02 - cell state is basically determined by
36:04 - its neighbors which is in many ways
36:06 - what's playing out there okay uh Dustin
36:09 - says I like the graphic novel style of
36:10 - the manual I do as well um so let's see
36:13 - so let's look the one that I uh
36:15 - pinpointed I thought might be
36:16 - interesting to do would be challenge
36:19 - 18
36:21 - um I've done all the way through um
36:25 - can't remember where I got to I didn't
36:26 - get up to challenge 18 yet but this is
36:28 - one the reason why I thought so I'll
36:30 - just read you challenge 18 entanglement
36:32 - if the top bit and the bottom bit start
36:35 - pointed to the right put a marble in
36:37 - Interceptor T otherwise put a marble in
36:40 - Interceptor F so this is like
36:42 - programming and if statement essentially
36:45 - so the way that I need to do this um so
36:48 - um I'm let me put this back over here
36:51 - and I'm just going to bring the book
36:53 - with
36:54 - me uh and
36:57 - um uh just in case I need a reference uh
37:00 - here so I'm going to take ah I'm very
37:04 - clumsy I'm going to take all these
37:06 - off how much is my bald spot
37:11 - showing very
37:14 - self-conscious uh let's see uh okay oh
37:18 - my back oh okay I'm okay everybody all
37:20 - right um now uh looking at this oh these
37:23 - are not supposed to be there so what I
37:27 - need are the setup is I need two
37:30 - bits I need another one of these where
37:33 - are my
37:34 - bits oh here they
37:37 - are
37:39 - and so I need another one uh direct two
37:42 - below goes here uh this is what I'm
37:46 - looking at as my reference for the
37:48 - puzzle and then um I need a true and a
37:53 - false these uh these are called the
37:56 - inter receptors I believe so they will
37:59 - stop the marble from reaching the bottom
38:02 - that's one thing that's too bad about
38:03 - this puzzle but the first one really
38:04 - showed it is the whole thing just goes
38:06 - so this one goes now
38:10 - here and this one
38:13 - goes
38:15 - here okay I think that's right yep so
38:19 - now I need to figure out if and
38:24 - um you know I don't I I don't I I can
38:26 - just put a few up
38:29 - here so what I want
38:34 - is if the top bit and the bottom bit
38:37 - start pointed to the right put a marble
38:40 - in
38:42 - true so this with this starting point
38:45 - the marble should land here which I
38:48 - first assume I need to catch it like to
38:51 - for it to come
38:55 - down
38:57 - so this would catch it coming down then
39:00 - it would click here go like this so I
39:02 - think I can just catch it coming this
39:06 - way you can try to play along with me
39:09 - here and then it should oh wait a sec no
39:12 - no no I think I have to do this for it
39:14 - to then come down and drop is that oh
39:17 - wait is that
39:19 - enough oh no because I want to drop it
39:22 - in ah they're both pointed to the right
39:25 - so I want to drop it here comes in here
39:28 - then I catch it
39:30 - here and it
39:32 - should then fall in there let's see if
39:34 - this is right so now them both pointed
39:37 - to the
39:39 - right yes okay so I got a true now am I
39:44 - doing and or or we'll see now uh now
39:50 - if if they're to the left if this one's
39:53 - to the
39:54 - right now it should go into
40:01 - false anything else is false so
40:03 - basically I'm doing an and operation
40:06 - this is like programming an and
40:07 - operation because if both of these are
40:09 - to the right it should fall in here if
40:12 - if either one or both is to the sorry
40:14 - pointed to the left which is like on I
40:17 - would say they're both on I should get
40:19 - true if either one is false or they're
40:21 - both false they should go here so
40:22 - certainly if it's pointed to oh wait no
40:25 - no no I did it wrong again no point it
40:27 - to the left yeah yeah yeah yeah so this
40:30 - is going to get it this way so now how
40:32 - do I this gets it point it to the right
40:35 - pointed to the right is on and they go
40:37 - into the true so now if this one's
40:40 - pointed to the left I can easily just
40:42 - take it this
40:44 - way
40:47 - uh uh no I wouldn't want this to happen
40:50 - so I need to take it this way I
40:53 - think it'll go there and then this will
40:55 - fall this way way can I then just catch
40:59 - it here and then catch it here will this
41:03 - work okay so now let's Point them both
41:07 - this way and let's
41:11 - see okay so I got it there but now what
41:15 - if one is pointed to the
41:18 - right well this
41:22 - work yes okay so uh and then what if
41:26 - this one is pointed to the right but
41:27 - this one's pointed this way what's going
41:29 - to happen that should be fine because it
41:31 - won't it won't activate this so I think
41:32 - I did it correctly let's put a few
41:35 - more basically let's just prove uh let's
41:39 - prove that this is a and
41:43 - operation okay so I just how many
41:45 - possibilities are there four true true
41:48 - true false false true false false so
41:51 - let's do all of those and see if it
41:52 - works so this is true true
41:58 - correct this is now false true wait no
42:02 - no no true false true
42:05 - false correct this is now true so this
42:10 - is now false
42:13 - true correct and then false
42:19 - false would be
42:23 - this beautiful all right I did it so
42:26 - this is what I mean I mean I don't know
42:28 - maybe this is not that much fun for you
42:30 - to watch but I can tell you with genuine
42:33 - excitement and enthusiasm that this is
42:36 - really fun uh to do so um so again I
42:40 - will I'll wrap this up here um check the
42:43 - descript check the video description
42:46 - there is a uh link there it's uh you
42:49 - know upper story.com Turing Turing for
42:52 - Allan Turing I got to find my photos of
42:55 - when I went to Bletchley Park that was
42:57 - in 2015 I went there twice so I was in
42:59 - London for like a uh for like six months
43:02 - basically and I went to Bletchley Park
43:04 - and I was like I'm going back here again
43:06 - I just like everybody who came to visit
43:07 - me i' like I'm taking you to Bley Park
43:08 - is really there's a computer Museum
43:10 - there it's fantastic um but you know if
43:12 - you can't go to Bley Park this Turing
43:14 - tumble will get you get you that a
43:16 - little bit of that feeling of like what
43:17 - it is to work with a you know analog
43:19 - mechanical computer um so go to uh upper
43:23 - story.com Turing tumble you can use the
43:26 - code uh coupon code coding train for 10%
43:29 - off and I'll check the link in the
43:31 - description okay um the audio is usable
43:35 - the pops are really annoying yeah audio
43:37 - pops okay there is some audio issues
43:41 - okay so um I am going to now see what I
43:44 - can do to fix my audio issues one thing
43:49 - I will
43:51 - do is uh mute myself
43:55 - first
44:11 - all right let's see if that resolved
44:15 - it uh okay so one thing I I did a few
44:18 - things and one thing is I have muted the
44:22 - uh audio that comes from my um
44:27 - uh the the like music and sound effect
44:29 - stuff because maybe the audio pop pops
44:31 - is coming from there and they're very
44:33 - rare uh the desktop is fine so all right
44:36 - so um hopefully that is
44:39 - resolved and we can move on let's look
44:42 - at so actually before I move on uh it's
44:47 - 11:45 am I still I'm I'm not muted
44:50 - anymore okay um so what I would like to
44:53 - do is put a pole can I do a poll from
44:55 - here
44:57 - here start a
44:59 - poll okay which what should I
45:04 - code wolf
45:07 - from
45:09 - 1dca or uh
45:13 - transformers. JS uh embeddings
45:18 - cluster
45:21 - uh this is
45:24 - AI
45:27 - example do it this
45:31 - way all right all right so I put a
45:34 - little pole it's coming from the lapel
45:37 - mic someone says still hear them well
45:41 - other thing I could
45:43 - do is
45:47 - just
45:49 - uh clip this to a different
45:54 - spot let's try this now and see if that
45:57 - fixes it oh sweater rub okay so my I
46:01 - clipped it to a different spot and
46:03 - actually let's get it even further away
46:05 - from the
46:07 - sweater which maybe unzip this a little
46:10 - more all right let's see if that fixes
46:12 - it I'm moving a little bit slow okay uh
46:16 - well that means I can turn my uh music
46:18 - thing back on just in case uh all right
46:20 - so we're going to see um what's
46:23 - happening with the pole I'll let that
46:25 - run but while I do that I would love to
46:28 - show you let's look at some things that
46:30 - were have been posted recently from uh
46:35 - passengers of the coding train so I'm
46:37 - going to go to GitHub
46:40 - um uh coding train and we're going to
46:43 - look for the
46:48 - um uh coding train
46:51 - logo uh and so this uh if you um oh and
46:56 - you're not seeing it so let me come back
46:58 - here
47:00 - um so uh this is a particular GitHub
47:04 - repo that has a P5 sketch that renders
47:08 - the newest coding train logo this little
47:10 - like asy art like simple drawing of a
47:14 - train um and if I click here uh and run
47:19 - the sketch in uh P5 you can see that the
47:22 - logo is there so this was something that
47:24 - I set up for hober Fest as a way for
47:26 - people to make their First open- Source
47:29 - contribution to this uh repository but
47:32 - uh uh certainly this is still open for
47:35 - contributions and um there's more
47:37 - information here that you can read about
47:39 - and how to submit but I'll just show you
47:41 - a few of the things that people made so
47:43 - this is the uh an animated logo uh made
47:46 - by deom basically took that P5 sketch
47:49 - and animated the paths of the different
47:52 - you know parts of the train uh this is a
47:56 - 3D printable coin which was created by
47:59 - Dan The Lost sorcerer so uh I don't know
48:02 - is this actually 3D printable does this
48:04 - thing exist uh um this is a repo about
48:08 - it yeah looks like there's a a model
48:10 - file uh there's some like code here
48:13 - which looks like it's written in some
48:15 - other like language that I don't know
48:17 - for doing a 3D modeling and Extrusion uh
48:21 - so this is really one I I didn't see
48:23 - that this was like fully documented in
48:24 - such a wonderful way um and you can see
48:26 - this here so I don't know if anybody
48:28 - actually 3D prints this I would love to
48:30 - see a photo of it wow we're really uh
48:33 - we're really at 5050 per here this is
48:35 - not this poll I might just have to
48:36 - decide myself f i famously I like to do
48:39 - whatever the opposite of whatever the
48:40 - poll
48:42 - says um okay and then we have this
48:46 - moving with smoke from Kathy so this is
48:49 - animating the uh coding train I would
48:51 - say this is probably using the particle
48:53 - well I don't know if it's using it but
48:55 - certainly has the same visual behavioral
48:57 - quality as the uh particle system
49:00 - example uh Kathy also made a 3D uh logo
49:04 - this is using P5 geometry so if you if
49:06 - you've been paying attention uh there's
49:08 - p5js version 1.8 is now out and P5 J
49:13 - version 1.8 has a lot of new features
49:16 - particularly around 3D uh P5 geometer
49:19 - I'd love to do some tutorials and videos
49:20 - around P5
49:24 - geometry and then are also a bunch of
49:26 - ports uh a Java port to processing and a
49:29 - python Port um and did I miss anybody's
49:33 - uh there's a couple issues here let's
49:35 - see just talking about the port the
49:37 - brainstorming list I don't see any poll
49:38 - requests so if I miss anybody's please
49:41 - let me know um in the chat oh lost
49:44 - sorcerer is here in the chat haven't
49:47 - printed it yet but will soon so lost
49:49 - sorcerer when you do print it uh please
49:52 - let me know I don't know share share it
49:55 - as a pastor showcase project a photo in
49:57 - this repo on social media wherever
49:59 - wherever things can be shared these
50:02 - days okay let's go now to the coding
50:06 - train.com whoops and let's talk about
50:08 - what's new there so but um and then I'll
50:11 - take a short break and we'll do some
50:12 - coding for a full hour in the second
50:16 - half of this live stream okay so first
50:19 - of all uh coding Train website if you
50:21 - have not uh had a chance to visit it uh
50:24 - what are you waiting for uh this is
50:26 - where you can find um all of the coding
50:29 - challenges actually I just realized
50:32 - thank you to Kathy who does a lot of
50:35 - work uh helping to maintain the website
50:38 - and I
50:39 - realized that um Kathy had updated the
50:44 - featured uh passenger showcase projects
50:47 - uh and challenges so let's merge this
50:50 - right now so that will appear live on
50:53 - the site momentarily uh um and I can
50:56 - talk through what is on the website so
50:59 - you can see the the pro you know the the
51:02 - most watched
51:04 - consumed content is anybody a Patrick
51:06 - Williams fan here we got any Patrick
51:08 - Williams coding train crossover going on
51:10 - Patrick made an amazing uh video about
51:13 - the word content and so I'm constantly
51:15 - thinking about it and finding myself
51:17 - saying content and like having this like
51:19 - sickening feeling inside um but uh in
51:23 - terms of the videos and material that I
51:25 - made these coding challenges have been
51:27 - the sort of long-standing heart the
51:29 - Beating Heart of the coding train and it
51:31 - used to be the thing that I had like a
51:33 - new one every week sometimes two per
51:35 - week but I I kind of just I don't know
51:38 - some someday I'll get back into the
51:39 - rhythm of these again but there's only
51:41 - been uh three in
51:44 - 2023 um hopefully we'll get in at least
51:46 - one more uh last 2022 I was really
51:49 - focused on doing some apple basic stuff
51:51 - but if if if you're new to the coding
51:53 - train hopefully these videos can still
51:55 - if you had had a chance to watch them
51:57 - you can find project ideas and
51:59 - inspiration and for any of them like if
52:01 - you decided you want to for example look
52:03 - at the colot conjecture video um you can
52:07 - find the uh code for it uh any reference
52:10 - materials here and then the passenger
52:13 - showcase so for example spectral piano
52:18 - made a colat
52:20 - BB in 3D so look at it it's like a Col
52:23 - because it looks like a chicken or an
52:24 - eagle that's really cool it's made in 3D
52:27 - so this is where people will share their
52:30 - projects and if you're on the website
52:32 - and you go under the guides um there is
52:35 - a guide here for uh the passenger
52:38 - showcase and a form that you can fill
52:39 - out and submit but did I let's see now
52:42 - if I go to um and if I go to the
52:45 - Showcase page itself this is just like
52:47 - all of the passenger showcase projects
52:49 - and you can page through all of them
52:51 - would be now I think is the time the
52:53 - website settled in a bit would be nice
52:55 - to be able to sort these by other uh
52:58 - means but currently they're sorted by
53:00 - time or you know I could go to any
53:02 - particular U I was looking to see if
53:04 - lost sorcerer uh is not on here but I
53:06 - know that um you know Cathy's page is
53:09 - usually the one I go to as an example
53:12 - you can kind of collect all of your
53:13 - showcase pages in essence like it's not
53:16 - this is not the intended behavior of the
53:17 - website but it's a little portfolio page
53:20 - uh for you okay so let's go to the
53:22 - homepage and we'll see here uh
53:26 - if you uh happen to be watching right
53:28 - now and you've never programmed before
53:30 - and you want to learn the
53:32 - basics um or if you more shaders web gel
53:35 - content yes Nicole um I would like to
53:39 - that's a great goal for 2024 um and you
53:42 - would like to learn to code or maybe you
53:45 - know someone in your life that you want
53:47 - to share your love of coding with um
53:50 - these right now on the home these
53:51 - featured tracks are the two beginners
53:53 - ones uh code Cod programming with p5js
53:56 - are all of my beginner tutorials of
53:58 - programming in JavaScript with P5 and I
54:01 - more recently made a video uh about um
54:05 - learning to code with processing um and
54:07 - this is actually instead of being a
54:08 - sequence of videos It's actually just
54:10 - one five hour full course um that you
54:13 - can watch so those there's there uh
54:15 - featured challenges uh here and then
54:17 - let's look at some passenger showcase
54:19 - projects that have come in recently are
54:22 - curated by uh Cathy so I don't know if
54:24 - these are the new ones yet we'll find
54:26 - out maybe we'll get to look at it so
54:27 - let's look at this bouncing ball from
54:29 - Mauricio
54:32 - Fernandez look at this okay so first of
54:35 - all uh Space Monkey if who you maybe go
54:38 - by Mauricio fantastic work so this is
54:41 - one of the challenges I give in the
54:44 - beginner course so I'm guessing that
54:46 - maybe Mauricio just learned a program we
54:48 - should all give Mauricio a huge round
54:52 - of applause good job for learning to
54:55 - code and one of the first things in my
54:57 - video courses that you learn is how to
55:00 - make a circle bounce around a canvas uh
55:03 - a changing direction each time it hits
55:05 - the edge and it looks like Mauricio here
55:07 - added a wonderful new feature uh which
55:10 - is for it to change its color every time
55:12 - and we can take a quick do a quick code
55:14 - review here we can see that Mauricio has
55:17 - some Global variables I should really be
55:18 - logged in let's log in here as the
55:21 - coding train I usually like to go into
55:23 - the high contrast mode
55:25 - um and make the code a little bit
55:30 - bigger um we can see here that uh look I
55:34 - I just to me also like nothing makes me
55:36 - happier than seeing code comments in
55:38 - another language so that is really
55:39 - wonderful uh I love that you're using
55:41 - your native language also for variable
55:43 - names um and you can see here that uh
55:48 - based on the bouncing a new random color
55:50 - is picked and that random color is used
55:53 - to draw the circle okay here here's my
55:55 - quibble here's my it's not I wouldn't
55:57 - call it a criticism it's an opportunity
55:59 - this is my uh um um I uh uh this is my
56:03 - pet peeve you know I'm having trouble
56:05 - reading this code because of some of the
56:07 - indentation so you can see how the if
56:09 - starts here then the what's happening in
56:11 - the if block is indented over here but
56:13 - then this this curly bracket it just
56:15 - wants to be it wants to be right here so
56:17 - badly we just want to like pluck it move
56:19 - it pluck it move it can't can't do it
56:23 - but guess what oh thank you P5 web
56:26 - editor edit tidy code edit tidy oh no
56:31 - what's going on wait what's going on
56:34 - here why is it not tidying the code oh
56:38 - it did it now I must not I don't know
56:39 - what just happened some temporary glitch
56:41 - but now it tidied the code and we can
56:43 - see to me I know I know I'm being silly
56:46 - and it seems silly but these are the
56:48 - kinds of things that over time uh help
56:52 - me to add a glance under understand how
56:55 - code is structured and what it's doing
56:57 - so even if it doesn't really matter for
56:59 - the end result uh developing a habit of
57:03 - uh of you know a style that you conform
57:07 - to whether you prefer the spaces or the
57:09 - tabs or the two or the four all of that
57:11 - is welcome here we are a tabs and spaces
57:15 - inclusive community here on the coding
57:17 - train but I do think it's helpful to
57:19 - conform to some of these standards to
57:21 - help readability but I would really
57:23 - commend you on putting comments into
57:24 - your code
57:25 - on the way you named your variables and
57:27 - just getting this to work um great job
57:31 - Mauricio
57:33 - okay let's take a look at this um one of
57:37 - my favorite algorithms is the flowfield
57:39 - algorithm and we can see here that uh
57:42 - Ador coding which is a great GitHub name
57:45 - uh oh look at that that is wild so this
57:49 - is using a flow
57:51 - field as well as maybe the Direction I I
57:55 - definitely have said this these words to
57:57 - my students in class of like what if you
58:00 - took a flow field and had the direction
58:02 - of the vectors be related to the pixels
58:05 - of an image and uh perhaps even a video
58:07 - here and you can really see that uh
58:09 - happening in this incredible project I I
58:12 - guess is it actually taking this image
58:13 - of the Mona Lisa or is this a live video
58:16 - I'm not sure um but this is really F and
58:19 - by the way excellent documentation to
58:21 - have a readme that sort of explains
58:23 - what's going on has an image in it this
58:25 - is really really fantastic work I'm
58:26 - wondering what the sine wave is I guess
58:29 - it just maybe the flow field follows
58:30 - something of a sine wave uh when it is
58:35 - um not part of the the some pixels that
58:39 - are part of a mask or something like
58:40 - that we could dig into this more but I
58:42 - think just looking at it as an
58:43 - inspiration is wonderful great work to
58:46 - Ethan from ador's
58:49 - [Applause]
58:51 - coding this is really hard got to get my
58:54 - regular train okay terrain generator
58:56 - with open Simplex noise open Simplex
58:59 - noise another one of my favorite
59:00 - algorithms ah I've been seeing a lot of
59:02 - these so this
59:03 - um uh uh this um this is uh I've been
59:08 - seeing a lot of these like people making
59:10 - little uh renders their generative art
59:12 - sketches their P5 sketches and posting
59:14 - them as YouTube shorts so this is what I
59:16 - was thinking of doing for the January
59:18 - month um but you can see here I love
59:21 - this idea so open Simplex noise is a
59:24 - particular
59:25 - noise algorithm with smooth Randomness
59:27 - and it can exist in different dimensions
59:30 - and to me what this looks like is it is
59:32 - two-dimensional noise but the noise
59:34 - values are being used to extrude the
59:37 - height of a 3D in a sort of 3D terrain
59:41 - um and so this is quite similar to if
59:43 - you wanted to if you wanted to learn how
59:44 - to do something like this where do you
59:46 - get started with this um if I went to
59:48 - the coding train.com under uh challenges
59:52 - maybe search for terrain I can see it
59:54 - updated now the new feature challenge is
59:56 - updated under terrain generation this is
59:59 - my coding challenge video with uh
60:01 - building a oh look at that look at that
60:03 - young man
60:05 - there no back problems
60:09 - uh I mean I don't know I think the
60:11 - silver is quite nice fetching did I just
60:13 - did I use the word fetching to describe
60:15 - myself that was that was not a good idea
60:18 - um I'm getting a little I'm getting a
60:19 - little woozy the talking straight for an
60:21 - hour it's time for my break and time to
60:22 - do some coding how's that poll going oh
60:24 - wow 51% on the wolf R so we're going to
60:27 - have to see I might I might go with the
60:29 - Transformers JS honestly if there's not
60:30 - a huge uh uh um you know movement
60:35 - towards the wolfrom stuff okay so thank
60:37 - you for sharing that to uh Al ala LZ and
60:41 - I apologies if I'm not pronouncing by
60:44 - the way I say I often pronounce the name
60:46 - then I say apologies and I genuinely
60:48 - mean for if I am saying your name uh
60:51 - whether whether I got it right or wrong
60:53 - I would love to hear from you either to
60:54 - say like yeah you pronounced it
60:55 - correctly thank you or um you know this
60:58 - is how you pronounce it you can send me
61:00 - an audio file a link that way as I get
61:02 - to know more names I'll I'll get better
61:04 - at it okay uh let's see what do we got
61:07 - here let's refresh this page and we have
61:09 - three more see that was the lucky lucky
61:13 - uh thing about not um not merging that
61:16 - polar across before I started let's look
61:17 - at three more reaction I'm going to go
61:19 - through these kind of quickly uh so we
61:20 - can get to taking a break and doing some
61:22 - coding reaction diffusion heart shape so
61:24 - one of my favorite algorithms is
61:26 - reaction diffusion also a coding
61:28 - challenge Challen challenge coding
61:30 - challenge challenge and looks like this
61:33 - is using the heart the Contours of a
61:36 - heart as the initial values a reaction
61:39 - diffusion algorithm you can think of it
61:41 - as like this almost like petri dish that
61:43 - I'm like pouring a chemical into one
61:45 - spot and it propagates around that petri
61:48 - dish really this works like a sou
61:50 - automata each pixel has a state and its
61:53 - state changes based on its name
61:54 - neighbors and we can see what emerges
61:56 - from a heart uh thank you enor this is
61:59 - wonderful I think I already commented
62:01 - here so I was going to comment on it
62:03 - again but everybody give give uncore oh
62:05 - look at this I thought like maybe the
62:07 - heart will be lost but we're really
62:08 - getting the heart back here uh okay uh
62:11 - pretty interactive double pendulum from
62:14 - Haron let's take a look at this wow so
62:18 - this is a whole like interactive web
62:19 - page and I can I can change the mass of
62:24 - the different um Bobs I can alter their
62:28 - length and I can play with the gravity
62:31 - let's make gravity really strong and oh
62:33 - we got to have the trail the whole point
62:34 - of the double pendulum is to have the
62:36 - trail so maybe I need to make these
62:38 - later how can I get it to swing much
62:40 - faster can I grab it this is really
62:44 - awesome so let's refresh it and let's
62:47 - turn the trail on and yeah so this uh so
62:51 - one of the double pendulum is one of
62:53 - these incredible chaotic systems uh that
62:56 - you know I have a video which goes
62:58 - through the sort of motion formulas to
62:59 - model it um you can also kind of create
63:02 - one with a physics engine like MJS maybe
63:04 - P5 play um but the trails that it makes
63:08 - are just I find them to be quite
63:11 - beautiful and surprising um Etc all
63:14 - right um two questions I'll answer here
63:17 - that I see in the chat Viking the dude
63:18 - says is Daniel on
63:20 - Twitch primarily streaming on primarily
63:22 - not doing very much these days to be
63:23 - perfectly hon thank you to all of you
63:25 - who support the coding train even in
63:27 - this uh like reduced amount of content
63:29 - if you will um I do have a Twitch
63:32 - account I was using it for a while I was
63:33 - going back and forth I probably haven't
63:35 - streamed on Twitch in well over a year
63:36 - if not longer so Never Say Never but not
63:39 - using twitch too much and then uh sadra
63:42 - is asking about MD and thank you to Lost
63:45 - sorcerer who is answering it it is a
63:46 - markdown file a particular kind of
63:49 - format for uh creating a document um and
63:53 - it's it's it's a standard across a lot
63:55 - of different um systems and GitHub uh
63:58 - GitHub uh uh readme files text files
64:01 - documentation files usually use that
64:03 - markdown format um okay so um I'm gonna
64:08 - take a break now short
64:12 - break I will remind you actually what I
64:15 - should do is I should take a break well
64:18 - it's like we can use the uh Turing
64:20 - tumble as like oh this is the wrong oh
64:23 - look this is the top of my uh coffee
64:26 - um I can't this is me with the green
64:29 - screen I think my lights might be a
64:30 - little bit bright today I don't know I I
64:33 - can't ah there we go t no wrong screen
64:35 - again whiteboard there it is um just
64:39 - remind you of why taking a break if you
64:40 - want to take a look at the uh upper
64:42 - story.com churing tumble uh thank you to
64:44 - the sponsor of today's episode Link in
64:46 - the description uh the coding train code
64:48 - will get you 10% off if you missed my
64:51 - segment earlier in the Stream you can go
64:52 - back and watch it after the stream is is
64:54 - over uh to see me playing around with
64:56 - and enjoying the Turing tumble so I am
64:58 - going to go to my intermission screen um
65:03 - uh nor Muhammad shigar asks for a neural
65:06 - network series there is one it's
65:08 - recorded quite a while ago but if you
65:10 - want to just learn the basics of A Sort
65:11 - of vanilla neural network it's all there
65:13 - for you you can find it maybe somebody
65:16 - in the chat can help uh uh I I think
65:18 - it's even on the coding train.com under
65:20 - a track um but let me put on a little
65:23 - bit of music to take a short break
65:27 - and when I come
65:30 - back uh in less than five minutes I will
65:35 - program I think I'd like to look at
65:37 - transformers. JS so um I think that's
65:41 - that's what I'm planning to do right now
65:43 - all right I'll be right and we're going
65:45 - to make some we're going to make a
65:46 - clustering
65:48 - example um okay I'll be right back
65:53 - short
65:59 - [Music]
66:32 - [Music]
66:38 - [Music]
66:48 - [Music]
66:53 - e
66:54 - [Music]
67:09 - [Music]
67:25 - [Music]
67:54 - [Music]
68:24 - [Music]
69:04 - [Music]
69:12 - all right I am back I turned the heater
69:14 - back on I noticed it's getting quite
69:17 - cold in
69:19 - here um
69:22 - and uh it is 1210 so um it feels very
69:27 - the heater feels very loud to me but I
69:29 - have a feeling it barely comes through
69:31 - for you so let me know if there are any
69:35 - audio issues you have in terms of
69:37 - hearing me I also haven't heard from
69:39 - anyone that the popping or rubbing sound
69:41 - that I think was happening because of
69:43 - the way the lapel mic uh the LA M was
69:46 - rubbing against this sweater um was
69:50 - occurring so that seems to have gone
69:52 - away but let me know I'm I'm I'm
69:55 - also been a little weary I think the
69:58 - cold I didn't realize how like cold it
69:59 - was getting in here so my energy is like
70:02 - I took that break my energy is a little
70:03 - bit low but uh hopefully um things will
70:07 - warm up in here and I am excited to talk
70:10 - to you about um some new stuff that I
70:13 - have been exploring with my teaching
70:15 - this fall and I would really like to I
70:19 - just it just hasn't happened but in an
70:22 - Ideal World I would been making video
70:25 - tutorials all alongside in parallel to
70:27 - the teaching I was doing at NYU which is
70:30 - what I have done in past years but the
70:32 - nature of code book I that's been like
70:35 - I'm like teaching my new material at NYU
70:37 - and then the time that I'm not teaching
70:39 - that I'm working on the nature of code
70:41 - book so in past years I'd be teaching my
70:43 - new material at NYU and in the time when
70:45 - I'm not teaching it I'd be making videos
70:47 - on that same topic and that seemed to
70:49 - work well it just it isn't happening but
70:52 - um we'll see
70:54 - the truth of the matter is this the
70:56 - landscape of what's possible with a lot
70:58 - of the new uh uh techniques and
71:00 - Technologies for generative text which
71:04 - is what I'm exploring in my class this
71:06 - semester is all changing so rapidly that
71:08 - you know I don't know to what extent
71:10 - making a lot of videos would be that
71:11 - useful anyway but um I might as well
71:15 - give you a little peek into that during
71:17 - this live stream and if there is
71:19 - interest uh I would love to come back
71:23 - and do more uh content about it so where
71:29 - to get
71:30 - started
71:35 - um so um there is a GitHub organization
71:40 - called programming from A to Z it's not
71:41 - an actual organization that's just what
71:43 - the thing is called on GitHub and um
71:46 - that's where everything is for the class
71:49 - that I'm currently teaching and um you
71:52 - know the syllabus from for that class is
71:54 - under here um and I can just kind of
71:57 - like uh look at it an overview of it um
72:01 - and if you were to go all the way up to
72:04 - uh week eight this is all and I I
72:07 - realize my desk is really is it higher
72:09 - than it usually is I'll just bring it
72:11 - down a little bit although that might
72:13 - cause me other sorts of issues but
72:16 - um uh if you go through all the way down
72:18 - through week eight these are things that
72:20 - I've actually already made a lot of
72:22 - videos on uh all the way back to like
72:24 - 2015 or 2016 I think when I did a lot of
72:26 - these videos uh if there is two weeks
72:29 - here that I spent in my class where we
72:31 - looked at different social media
72:33 - platforms that you can use their apis to
72:35 - create a bot and in particular I focused
72:38 - quite a bit of time on Discord Bots and
72:42 - uh in case you happen to miss that and
72:44 - you're interested in um learning how to
72:48 - make a Discord
72:50 - bot um the most recent new video that I
72:53 - made which was just in the last month um
72:56 - which are here are uh well one is coding
73:00 - coding a Discord bot so if you if you've
73:03 - ever wanted to make a Discord bot you
73:04 - know a little bit of JavaScript a little
73:06 - bit of programming this video will give
73:08 - you all of the basics to get your first
73:10 - bot up in running if you've never oh and
73:12 - Thomas P thank
73:15 - you Thomas P I am going to uh tell you
73:21 - about videos that I
73:23 - [Music]
73:25 - um uh but if you've never used node
73:28 - before then this video will also uh go
73:31 - over how to set up node project and one
73:33 - of the things that I did in that video
73:34 - that I haven't covered anywhere else is
73:36 - looking at es Imports so if you've never
73:39 - used import statements in node that is
73:41 - helpful for you and then a little bit of
73:43 - an update I can't my arm won't extend
73:45 - all the way over there about some of the
73:47 - workflow tools that I'm using terminal
73:49 - shell vs code Etc um I mention these
73:52 - mostly because I you know not that I pay
73:54 - too much attention to this this my um
73:57 - but
73:59 - uh um the uh law sorcerer sorry let me
74:03 - get to your question if you tag me in
74:05 - Discord and I can answer it there there
74:07 - there I yes yes is the answer but um I
74:10 - have to dig it up it's like a a a PO Box
74:13 - type thing um these videos were very uh
74:16 - barely watched which is very
74:19 - understandable because they're meant to
74:20 - be resources that you know at any moment
74:22 - in time you might need like who's waking
74:24 - up in the morning to be like what am I
74:26 - going to watch while I'm eating my
74:27 - breakfast I don't know how about coding
74:28 - a Discord bot but I do mention in case
74:31 - people didn't see them and are
74:32 - interested and want to kind of like Mark
74:34 - them for watch later or go back and look
74:36 - at them uh feel free to okay so it the
74:40 - thing thing about the heat is even
74:43 - though you're not hearing it it's very
74:45 - loud in my ears and it's causing me to
74:47 - talk very loud which is I think putting
74:50 - a strain on my voice but I'm gonna just
74:52 - try to uh be more mindful of that um so
74:58 - so I do see a little bit about uh uh
75:01 - mentioning that there might be some
75:02 - issues with the audio so if if other
75:05 - people are having audio issues please
75:07 - let me know okay so back to this now the
75:10 - new
75:12 - stuff the new work that I've been doing
75:15 - just in the last few weeks is making a
75:17 - set of examples and content related to
75:21 - working with Transformer models so what
75:23 - is a Transformer model let's just talk
75:25 - about that a little
75:29 - bit okay
75:36 - so for me predictive text all starts
75:41 - with this idea of a marov
75:44 - chain it's going to take me a while to
75:46 - get to where I'm going but I feel like
75:48 - this background is
75:49 - important so this idea of a marov chain
75:52 - uh is not related to text a Markov chain
75:55 - refers to any a a sequence of
75:59 - States weather could be a Markov chain
76:01 - raining Raining sunny sunny sunny
76:04 - raining sunny sunny Raining Raining
76:06 - snowing raining raining right that is a
76:08 - Markov chain and the idea of a Markov
76:11 - chain is given a history of states or
76:16 - just the previous state could you make a
76:19 - probabilistic prediction of what the
76:21 - next state would be if it's been raining
76:23 - for four days in a row is it more likely
76:25 - to be raining the fifth day or more
76:27 - likely to be sunny and if we wanted to
76:30 - we could do an
76:32 - analysis but if we wanted to use a
76:34 - previous analysis to
76:37 - generate uh fictional weather uh we
76:40 - could basically analyze historical
76:42 - weather look at the probabilities of how
76:45 - things happen in sequence and then
76:47 - generate new weather sequences based on
76:50 - those probabilities and that's what's
76:51 - happening with a Markov chain with text
76:54 - so if I were and if I were to an like
76:56 - think of each word as a
76:59 - state or maybe the previous four words
77:04 - as the
77:07 - state I might say
77:10 - uh you know
77:13 - what would come next well maybe there is
77:16 - an % chance that the word hat would come
77:21 - next maybe there is a
77:23 - 20% chance that the I don't know I was G
77:26 - to say litter box but that's two words
77:29 - so I'll just say litter I don't know
77:31 - where is the cat in the lit hiding under
77:33 - the washing machine I don't know what
77:34 - would come next but you could imagine if
77:36 - I were to analyze a huge Corpus of
77:42 - text that was so large that the cat in
77:46 - the that sequence appeared hundreds
77:49 - thousands maybe even millions of times
77:52 - and then I just counted let's say it
77:54 - appeared a 100 times and 80 time it
77:58 - appeared 100 times in the Corpus and 80
78:00 - of those times hat was next and 20 of
78:02 - those times the litter was next then I
78:06 - could use a Markov chain to generate TT
78:08 - now if I could like magically make post-
78:10 - production things appear I would now put
78:12 - up my marov chain coding challenge video
78:15 - where I go through and program this
78:16 - whole thing the that video I actually
78:18 - treat each the state as a sequence of
78:20 - characters not words but you could have
78:23 - you know Word level character level now
78:25 - so why am I talking about this because I
78:28 - want to for a
78:31 - moment it's a very large leap like I
78:35 - want to go from this idea of a Markov
78:37 - chain all the way over to this idea of a
78:39 - transformer model so Transformer model
78:42 - is the Deep learning neural network
78:45 - architecture behind systems like chat
78:48 - GPT uh the Llama model and many many
78:51 - many many more examp examples I'm just
78:53 - picking like two that you might have
78:55 - heard
78:56 - of the reason why I like to make this
78:59 - connection is with a marov model right
79:03 - we would essentially create a giant
79:05 - table a spreadsheet of every possibility
79:09 - and then we could be using all of those
79:11 - probabilities to generate new
79:14 - text a deep learning model is so big
79:18 - essentially the data like we couldn't
79:20 - realistically build a Markov chain out
79:22 - of
79:23 - the entire text on the internet now
79:26 - first of all we should really be asking
79:27 - the question just because we can should
79:30 - we build Transformer models that are
79:32 - essentially trained with you know 10
79:34 - years of chewed up internet and it's not
79:36 - as simple as that and there's lots of
79:38 - thoughtful people doing a lot of work uh
79:41 - that I'm um I don't mean to trivialize
79:44 - um but I do think this is an important
79:46 - question of you know just because we can
79:49 - H make these sort of ideas bigger are
79:52 - they necessary neily better what is the
79:54 - social impact what are the harms all
79:55 - these are important
79:57 - questions but for I do think it's
80:00 - relevant these things are out there for
80:02 - you the person on the internet to
80:05 - understand a little bit about how this
80:06 - stuff works and what it's doing so how
80:09 - do I make this connection I drew that
80:11 - line I want to try to make this
80:12 - connection I'm also like sort of keeping
80:13 - an eye on the chat over there to make
80:15 - sure there's no like messages put some
80:17 - siren emojis not don't put them in there
80:20 - put them in there if there's something
80:21 - wrong don't don't troll me I I know you
80:23 - internet audience I'm only looking at
80:25 - the Discord chat okay so first of all
80:29 - the Transformer model and I'll point you
80:31 - to some resources that do probably a
80:33 - much better job of explaining this than
80:34 - I will and I'm going to just handwave
80:35 - most of it
80:39 - anyway the input if I had the Cat in the
80:45 - Hat what a Transformer model does it
80:49 - it's it this is the input and the same
80:51 - the output I'm oh no
80:53 - hat the same thing like eventually
80:55 - somewhere I want to get this idea of the
80:57 - predicting the next and Transformer
81:00 - models don't actually use words or
81:03 - characters they use as the individual
81:05 - chunks they use something called a token
81:08 - and you can read a lot about how is text
81:12 - tokenized um and you know probably like
81:15 - in and the are full tokens but if I had
81:18 - the word uh computer maybe computer is
81:23 - three tokens or two tokens comp uter or
81:26 - computer
81:28 - or comp UD compot I anyway you can
81:32 - imagine it's not exactly like syllables
81:34 - it's uh there's there's different
81:35 - techniques for tokenizing text but for
81:37 - the sake of argument let's just imagine
81:39 - that these were the
81:42 - tokens now the idea of a deep learning
81:45 - model and this goes across the board for
81:47 - most neural network-based models is they
81:50 - exist because the the the spa the
81:54 - solution space the probability space the
81:56 - space of the data is much too large to
81:59 - encode all of the information like with
82:01 - a markof chain I might literally have a
82:02 - spreadsheet again that has all the
82:04 - possible sequences and all the possible
82:06 - out you know inputs and outputs a deep
82:08 - learning model basically takes an input
82:10 - and then estimates an
82:13 - output and you know you could go back
82:14 - and look at my videos on neural networks
82:16 - and all sorts of other material but the
82:18 - idea here is each one of these the
82:20 - reason why I'm getting to this is each
82:22 - one of these
82:23 - tokens uh well there's multiple steps
82:26 - that are encoded uh first but let's just
82:29 - uh skip up some steps here and sort of
82:32 - think about them as an
82:34 - embedding so and let me come back to the
82:37 - computer for a second I'm kind of
82:38 - jumping around here and I don't even
82:40 - know if uh I don't know what people are
82:43 - talking about in the chat but
82:46 - um so um one of the a video that I made
82:51 - many years ago
82:53 - let's see if we can find
82:56 - it uh this two 2018 I talked about
83:00 - something called word Tove and word to
83:03 - VC is an embeddings model essentially
83:05 - where every word is tie to a list of
83:09 - numbers and embedding is a fancy word
83:11 - essentially for a list of numbers and
83:14 - there's a terrific resource from Allison
83:16 - Parish um that I believe I linked to
83:19 - here on my syllabus week about
83:21 - embeddings
83:23 - um along with those uh which is all
83:26 - about understanding word vectors and
83:28 - thinking about like this is a really
83:30 - nice example of okay what does this mean
83:33 - well what if how do we turn words into
83:35 - numbers well what if we created we
83:38 - measured every animal based on acuteness
83:40 - and a size scale and then a lobster is
83:44 - essentially the embedding 2 comma 15 and
83:46 - a mosquito is one comma one like very
83:49 - small not very cute and very very small
83:52 - color is another really practical
83:55 - example of how words the color red can
83:58 - be associated with numbers 255 Z and I
84:02 - could do if numbers I could do
84:04 - mathematical operations with that means
84:06 - I could say red plus BL blue red plus Bo
84:09 - red plus Buu I said it again red plus
84:13 - blue 25500 plus 255 that equals purple
84:19 - so I could actually do things like
84:21 - dolphin plus crocodile equals 65 comma
84:26 - 95 and that's kind of like an elephant
84:28 - 65 comma 90 dolphin plus crocodile it's
84:31 - kind of like an elephant we learned
84:33 - something new today so this is the
84:35 - idea um and uh
84:41 - so neural
84:43 - networks basically the idea is that if
84:46 - all of these each one of these words can
84:47 - be turned into an embedding then those
84:50 - embeddings can use like positional
84:52 - encode and some other kind of like stuff
84:54 - to be made into like a single embedding
84:56 - and I'm totally like uh skipping a lot
84:59 - of steps and
85:01 - oversimplifying these can go into deep
85:04 - learning layers numbers are the inputs
85:08 - into a neural network and the there's
85:10 - this whole thing about an intention
85:13 - layer uh and then just a regular old
85:16 - fashion feed forward uh uh a neural
85:20 - network layer um so and there's multiple
85:23 - of these but ultimately this ends up
85:27 - predicting and embedding which is that
85:30 - next word uh which is tied to what that
85:33 - next word that should be in sequence so
85:35 - again I I should probably pull up like a
85:37 - a more thoughtfully done internet
85:38 - diagram of this but I wanted to briefly
85:41 - leaving myself some time to do some
85:42 - coding kind of establish this connection
85:45 - so to me I'm interested in Transformer
85:48 - models for a variety of different
85:50 - reasons but a primary reason is this
85:53 - idea of associating text sentences words
85:58 - paragraphs with numbers so if you've
86:00 - ever heard for example of this technique
86:03 - called retrieval augmented generation a
86:06 - rag if you will it's kind of unfortunate
86:08 - terrible name this is something that
86:10 - I've been experimenting with the nature
86:11 - of code
86:12 - book what if I could take a
86:15 - question what is a fractal turn that
86:18 - into an embedding a bunch of numbers
86:20 - search through all the sentences in my
86:23 - book and find all the sentences that
86:25 - have similar
86:27 - numbers I could
86:29 - cluster a DAT a cluster text based data
86:32 - I could search for answers I could do
86:35 - like a question answer search so there's
86:37 - all sorts of outcomes that could come
86:39 - from that and I would like to make
86:40 - videos where I maybe slowly talk about
86:42 - this stuff some more and go step by step
86:44 - through
86:45 - it I don't know maybe it'll take a
86:47 - minute to see if there's some questions
86:48 - in the chat that I could address but
86:51 - ultimately um
86:53 - what I want to focus on right now is not
86:56 - the use of Transformer models to
86:59 - generate and predict text um but the
87:02 - concept that's inside of Transformer
87:04 - models that's very critical there are
87:05 - other models that are trained just to
87:07 - associate embeddings with text um what
87:10 - can I do with
87:11 - that
87:16 - okay dolphin plus crocodile equals shark
87:19 - says Zachary okay so I'm coming back
87:22 - over here um and we're going to I swear
87:25 - we're going to do some coding I'm going
87:26 - to turn the heater off because the noise
87:28 - is bothering me even though it's not
87:30 - bothering
87:35 - you
87:37 - there it won't get too cold in the next
87:40 - half an
87:41 - hour
87:43 - okay so I am going to uh so I have a
87:48 - whole bunch of examples that I've been
87:49 - working on let's go to my Transformers
87:52 - .js examples I don't know if uh this is
87:56 - up to
87:59 - date uh okay it
88:02 - was no I don't know what's in
88:08 - here I have passphrase here I'm not sure
88:11 - why okay so
88:16 - um I am going to uh I'm gonna make
88:20 - something new but I just wanted to um
88:23 - kind of like have this available
88:27 - okay um so what I would like to
88:30 - do actually let me just run this example
88:32 - for you
88:37 - because and the reason I'm not doing
88:39 - these in the P5 web editor is they
88:41 - require some larger data files and some
88:44 - other things that are kind of tricky to
88:46 - do in the the P5 web editor but let's
88:48 - just see if this
88:49 - works it's going to take a minute
88:52 - because it's got to load the embeddings
88:53 - model from the
89:00 - internet okay so what this example is
89:04 - doing and I I might want to like try to
89:05 - build this a little
89:07 - bit but what this example is doing is it
89:11 - has these uh five six sentences what
89:15 - colors the sky what an apple the sky is
89:17 - blue what does the fox say an apple is a
89:19 - fruit I have no idea and so what I'm
89:22 - doing with each in this example is I'm
89:24 - taking each one of these senses and
89:26 - turning it into an
89:28 - embedding and then I am calculating
89:32 - essentially a similarity score and we
89:34 - can talk about the what algorithms you
89:36 - can use for these similarity scores but
89:38 - basically I'm looking for how similar
89:41 - are each one of these sentences to each
89:43 - other and if I look at in the browser
89:46 - one of the things you can see here is
89:48 - all along this is a table all along the
89:51 - diagonal I see a white square because
89:55 - what is an apple which is and I I
89:57 - realize you can't see the bottom
90:00 - here um so let's make this uh like this
90:03 - I'll try to step aside so you can see it
90:06 - better I can move this over even
90:10 - um um here I'm comparing I'm comparing
90:15 - what is an apple to what is an Apple so
90:17 - the similarity score should be one now
90:20 - I'm comparing what is an apple to the
90:22 - sky is blue and the similarity score is
90:27 - 0.078 but what is this one here ah
90:30 - comparing an apple as a fruit to what is
90:33 - an apple I don't get one they're not
90:35 - equal but I get a fairly high score so
90:38 - this is why I'm interested in embeddings
90:41 - it is a mechanism that I could use with
90:45 - my own data so I'm generally trying to
90:48 - lean towards lean into f focus on
90:52 - projects on the coding train that
90:54 - involve bespoke custom you know I'm
90:58 - trying to do a lot of things with nature
90:59 - of codebook transcripts to my videos
91:02 - working with data sets that I have
91:05 - ownership of or a knowledge of uh rather
91:09 - than just kind of
91:10 - arbitrarily uh play around
91:13 - with you know these giant data uh you
91:17 - know piles of text on the on the
91:19 - internet so um even though those piles
91:21 - of we used to train the embeddings model
91:23 - I'm interested in what those embedding
91:25 - models can do for us okay anyway
91:27 - so let's think so what I would like to
91:31 - do now and I probably should have done
91:34 - this other automotic because I don't
91:35 - really have a plan for this is I would
91:37 - like to create a basic example where I
91:41 - have a bunch of these instead of doing
91:44 - this a matrix what I would like to do is
91:46 - try clustering these in other words I
91:48 - want to create a visual world of these
91:51 - sentences where the similar ones appear
91:53 - near to each other there's a lot of
91:57 - steps in between from where I am right
91:58 - now and how I'm going to get there in
92:00 - the next half an hour but let's see what
92:02 - happens okay so I'm going to create a
92:06 - new uh folder called I'm gonna call it
92:08 - clustering and the reason why I'm doing
92:10 - this honestly is this is what I want to
92:11 - teach about in my class at NYU this week
92:14 - so if I could get a little this work
92:16 - done and experiment with this idea
92:20 - um
92:22 - um then uh uh I will do so I see Kathy
92:26 - you're giving me some good notes about
92:28 - some things that I've sort of missed
92:29 - explaining so maybe we could I'm G maybe
92:31 - I'll come back to those as I start to
92:32 - build a code example which will force me
92:34 - to go through things a little bit step
92:36 - by step more slowly okay so let's get uh
92:40 - an HTML
92:41 - file um and I'm just G to borrow this
92:44 - one from here which has P5 built into it
92:48 - um and then let's make a
92:50 - sketch.jpg and I'm going to pull what I
92:52 - need from here so here is a kind of uh
92:57 - an unfortunate truth which will either
92:59 - make you happy or sad depending on who
93:02 - you
93:03 - are so in my life programming and making
93:08 - things in JavaScript in p5js the popping
93:12 - was really
93:14 - loud I don't know what to do about
93:18 - that okay I'm going to try triy moving
93:21 - the m
93:22 - M let me make sure it's the mic and not
93:26 - the laptop I'll mute that it's the only
93:29 - other audio Source going out
93:32 - OBS sorry about the audio
93:36 - everybody
93:40 - um
93:43 - I'm but you know maybe it's the
93:46 - cold I don't know what it is uh maybe
93:49 - it's just that I've been doing this now
93:50 - for an hour and a half and my energy is
93:52 - in but I'm I'm having some uh brain
93:55 - energy issues so let's shake it off
94:00 - everybody as my good friend uh Taylor
94:03 - likes to say shake it off
94:05 - okay now uh so uh what I was getting at
94:09 - is I'm used to importing JavaScript
94:11 - libraries through a script tag in
94:13 - HTML um this particular JavaScript
94:16 - library which is called Transformers JS
94:19 - is only available as a module
94:22 - which means in my code instead of
94:24 - actually putting it in
94:26 - index.html uh I am putting it up here as
94:29 - an import statement import pipeline from
94:35 - the the CDN the content delivery Network
94:38 - where this library is stored so this is
94:40 - the equivalent of you know uh putting
94:43 - like the P5 Library here the difference
94:45 - is instead of putting it in HTML a
94:47 - script tag I need to put it in my actual
94:49 - Javascript file with an import
94:52 - um and if you've never used Imports
94:54 - Before I Do cover these in the video
94:56 - that I just referenced about making your
94:58 - first node project okay now the first
95:03 - thing that I want to do is load a model
95:06 - and I want an embeddings model so and
95:08 - again I'm just pulling code from an
95:10 - example that I made already so the way
95:12 - oh no not the summarizer
95:15 - sorry the way that you load a model uh
95:19 - with um
95:22 - with transformers. JS is by uh through
95:26 - this pipeline function so that's the
95:28 - pipeline function I'm importing from the
95:30 - Transformers JS library and uh you know
95:33 - I could call I'm calling this an
95:35 - extractor so uh an embedding you can
95:37 - think of that as a fe features is
95:40 - another is another related word to
95:42 - embeddings so essentially uh turning
95:45 - text into array of numbers is kind of
95:48 - getting at what are the features of that
95:49 - text numerically speaking and so if I
95:52 - want to extract the features that is
95:55 - what an embeding model does so
95:57 - transformers. has a lot of different
95:59 - pipelines and this is a particular uh
96:02 - open- Source embeddings model called
96:04 - mini LM mini language model um and it
96:07 - performs feature extraction now because
96:10 - this uses a sync and a weit promises oh
96:13 - boy is that something you've never heard
96:15 - of do I have another set of videos here
96:17 - to I mean I don't have to sell them to
96:19 - you because you can just watch them on
96:20 - YouTube but a whole set of videos about
96:22 - async and await and promises but what
96:24 - this essentially means is this needs to
96:26 - be I'm going to put this in a
96:28 - function I'm going to call it
96:32 - go you could call it
96:34 - Main and that function uh needs to be uh
96:39 - modified with the keyword async because
96:41 - it's going to have asynchronous code in
96:43 - it like awaiting loading this model it's
96:46 - going to I couldn't download the model
96:48 - files but the transform. JS will go and
96:51 - plck the model from the cloud I'll show
96:52 - you where the list of models are in a
96:54 - second and now I have that model in the
96:57 - extractor
96:58 - variable just to know that this works
97:01 - the next thing I want to do is I want to
97:04 - say uh let's just have a
97:07 - sentence we're going to say the coding
97:11 - train says Choo
97:14 - Cho and I'm going to say the embeddings
97:18 - are uh await extract
97:24 - VOR
97:26 - dot I'm I'm hoping it's going to
97:28 - autocomplete it for me but it's not so
97:31 - I'll go back and look at the example I
97:32 - made before uh which is oh I just I call
97:36 - sorry let me grab this so I totally did
97:39 - this wrong we'll go back to our example
97:42 - that I'm
97:43 - making uh so the output is um I await
97:48 - the extractor I give it my sentence
97:50 - these these are some uh modifications
97:53 - that have to do with how the embeddings
97:55 - are computed normaliz being true I think
97:58 - gives me all the values in the embedding
98:01 - itself uh normalized between a
98:03 - particular range either zero and one or
98:05 - negative one and one and let's just take
98:07 - a look now at that particular output so
98:11 - this is a very basic hello world the
98:14 - pops happen when I move check the mic
98:16 - Kate
98:17 - little yeah I don't I unfortunately I
98:22 - don't really know what to do about this
98:23 - now and I'm so close to being kind of
98:26 - done that I think it is
98:29 - just it's just part of today's stream
98:31 - and I apologize for
98:34 - that but I've tried unplugging and
98:37 - replugging in the cable and doing
98:38 - different things so unless somebody has
98:41 - an idea another idea not sure what to do
98:45 - uncharge no the mic is
98:49 - fully well
98:52 - the mic is the battery is
98:55 - full uh let me try just putting this on
98:57 - the
98:58 - table and letting this
99:03 - not be like underneath my
99:08 - clothes let's see if that does anything
99:10 - so the mic is just here
99:13 - um maybe I'll even just put it over here
99:17 - I don't know this this might be worse
99:19 - but okay let's see if we can get this to
99:27 - run so clustering is what I'm attempting
99:30 - to build here and oh it would be nice
99:33 - for me to call the function go to have
99:36 - it
99:38 - happen you sure you're not just hearing
99:40 - that fly buzzing
99:44 - around let me make sure whoops let me
99:47 - make sure I have a particular
99:50 - setting
99:52 - ah so this is an important setting that
99:54 - uh I that I um didn't notice that that
99:58 - needs to be check which is to disable
100:00 - the cach while The Debs are open so any
100:02 - changes in my code whoops uh
100:06 - reload where am I
100:12 - here
100:13 - yeah uh
100:17 - clustering let's add some console log so
100:21 - we know this is going loading
100:27 - model
100:29 - model
100:31 - loaded let's see what we
100:34 - get
100:36 - okay so now um we can see here in the so
100:42 - okay great so this worked the model
100:44 - loaded and what I got is the embedding
100:48 - the embedding is in data it's an array
100:50 - of 384 four numbers so now I can say
100:54 - output.
100:57 - data let's just take a look at this and
100:59 - there that's the
101:01 - embedding so let's do another
101:04 - sentence we're getting somewhere folks
101:07 - so first of all Let's do let's call this
101:11 - function load model and let's make the
101:13 - extractor a global variable so I can use
101:17 - it around in other
101:19 - places and then I'm going to say uh
101:25 - go is an a eggs sync function that's
101:28 - going to first load the
101:30 - model and then we're going to say um I
101:35 - don't know what to call we'll call it
101:36 - await uh
101:39 - embedding of a given
101:42 - sentence so let's let's make this um I'm
101:46 - I'm going to make something visual here
101:46 - that you're going to be able to play
101:47 - with uh hopefully before before the in
101:50 - the next 20 minutes so this will get a
101:51 - little bit more interesting um and then
101:54 - what the uh
102:00 - embedding function will
102:02 - do call it
102:04 - embedding and it receives any given
102:08 - sentence and it uh
102:12 - returns output. dat so basically I'm
102:16 - going to say the uh embedding one equals
102:21 - await embedding sentence
102:26 - one and uh sentence two will be the
102:31 - coding train says
102:35 - whoops it's getting cold in here again
102:39 - uh and I'm going to get embedding two
102:43 - and then let's look at
102:48 - them in the console all right right so
102:51 - let's see if this works I'm now all I've
102:53 - done is I've loaded the Transformers JS
102:56 - embedding
102:57 - model I have an asynchronous function
103:00 - that sorry I've loaded the Transformers
103:03 - JS library now I'm loading the
103:05 - particular model by the way is the is
103:09 - the ah is the mic static from the
103:15 - sweater I'm only going to be colder
103:19 - now I don't know we I don't want to
103:21 - throw the ground is a little dirty in
103:22 - here I'm going to put this on a shelf
103:24 - here
103:26 - okay yes we're rolling up our sleeves
103:29 - everybody we're gonna make I have
103:31 - sentence one in the second one thank
103:36 - you all right
103:39 - importing fly importing Transformers
103:46 - JS uh loading a particular model the
103:50 - mini LM model which is an embeddings
103:53 - model asking for the embeddings for two
103:57 - different sentences and console logging
104:00 - them let's see what we've
104:03 - got okay so great now uh so just looking
104:07 - let's just look the first
104:09 - number negative
104:13 - 0.05 and the second number negative 0.03
104:16 - huh maybe these are kind of similarish
104:19 - but here's the thing so how do I know
104:22 - whether these
104:24 - two sentences are similar or not so I'm
104:28 - going to have to put this into my pocket
104:30 - because I walk back over to the
104:32 - Whiteboard to talk about how we
104:34 - calculate similarity between two
104:37 - sentences popping is still
104:40 - there I don't know I don't know what to
104:42 - do I'm so sorry
104:44 - everybody
104:48 - okay
104:49 - so
104:56 - oh my weary bones in the cold in the
105:03 - garage it's whiteboard I need a new
105:06 - studio I don't
105:11 - know
105:13 - okay
105:17 - so let's think for a moment about
105:28 - color let's think about color as a
105:31 - threedimensional
105:33 - embedding so maybe red is the number
105:39 - 255 that's the embedding for red maybe
105:42 - uh Rose uh and I'm going to get this
105:45 - wrong because I'm not good at colors has
105:47 - the embedding associated with it of to
105:52 - um
105:54 - 52 comma uh 10 no let's make that let's
105:58 - take the green zero and has like a
106:00 - little bit of blue in it I don't know if
106:02 - that's I don't know I a semicolon there
106:04 - so think about color as three values
106:09 - well that exists then in
106:11 - threedimensional space I could consider
106:14 - what would normally be the x axis to be
106:16 - the red axis what would normally be the
106:20 - Z axis to be the green axis and would
106:23 - normally be the blue axis sorry the y
106:26 - axis to be the blue axis and so the
106:29 - color red 255 would literally be plotted
106:33 - right there so that's red and then the
106:35 - color rose maybe is
106:38 - here so in this three-dimensional world
106:42 - that I establishing their similarity
106:44 - could be the literal distance ukian
106:47 - distance between those two points
106:51 - so ukian distance being the square like
106:56 - in know is the same in two Dimensions
106:58 - would be you know a triangle C equals
107:02 - the square root of a^2 +
107:04 - B2 that is the distance between these
107:07 - two points uh has to do with the
107:10 - difference between their X values the yv
107:12 - values squared and the square root
107:14 - because of the Pythagorean theorem so
107:16 - ukian distance is one way to calculate a
107:19 - similarity score let's go do
107:24 - that so I I say this because sometimes
107:27 - you're like oh what what crazy math
107:30 - Vector Library do I now need to do what
107:33 - I want to do you don't need anything
107:35 - because I am going to say uh let's get
107:40 - the sum of
107:44 - squares is zero let's go
107:48 - through the entire in
107:53 - embedding and the difference is
107:56 - embedding one minus embedding zero oop
108:00 - sorry embedding one index I minus
108:04 - embedding two index I obviously you know
108:07 - we'd want to be in a larger system we'd
108:09 - want to do this a bit more thoughtfully
108:11 - and then the sum of the squares plus
108:15 - equal difference time difference and
108:17 - then the ukian distance is is the square
108:21 - root of the sum of the
108:27 - squares so now let's look at and let's
108:31 - look at the similar a similarity score
108:35 - between those two
108:38 - sentences people are still talking about
108:40 - the pop I'm so sorry I can put my
108:43 - sweater back on well I'm I'm I'm running
108:47 - out of time I want to get to the I want
108:49 - to get to the grand finale here so okay
108:51 - so we're we're getting somewhere with
108:53 - this idea of
108:55 - embeddings okay what did I square root
108:57 - is not Define because I I'm just kind of
108:59 - imagining using P5 so let's do math.
109:02 - square
109:04 - root okay so look at that I got a
109:07 - similarity score a distance of 62
109:10 - remember that those two sentences were
109:14 - 062 units away in 384 dimensional space
109:19 - because this particular model returns an
109:22 - embedding of 384 numbers okay just to
109:26 - prove the point
109:28 - here what if I change the sentence so
109:31 - the coding train says Choo Cho and uh I
109:36 - love oatmeal for
109:39 - breakfast I'm assuming that these two
109:42 - sentences are going to be further apart
109:45 - than 62 we're about to find out I have
109:47 - not tried this but let's see you know
109:50 - know in my mind those two sentences are
109:51 - now more different than the previous two
109:54 - but let's see so remember I got 62 for
109:57 - uh the previous one let's let's
109:59 - see yeah 1.33 they're further away so
110:03 - even just this basic and this is
110:05 - happening just just in case you're
110:07 - wondering my there's no Cloud stuff
110:10 - happen I mean I am loading the model
110:11 - from the cloud but that model is running
110:14 - on device in JavaScript in the browser
110:17 - so I've done a lot of videos on uh
110:19 - tensor ljs and um ml5 JS I'm really
110:24 - interested in tutorials and educational
110:27 - material around on device uh machine
110:32 - learning where you're uh where there is
110:35 - no required uh cost to like so you
110:38 - watching this I could be doing a similar
110:40 - demonstration with the open AI API where
110:44 - you would send your sentence to their
110:46 - API and you would get embedding back it
110:48 - might be more powerful in certain ways I
110:51 - mean it certainly is in many ways but it
110:53 - would require you one to send your data
110:56 - away whatever those sentences are as
110:58 - well as pay you know a cent two cents
111:01 - three cents for that now again I'm not
111:03 - some like pure soul I mean I'm using all
111:05 - these apis and cloud services all the
111:08 - time but I do think this is why I'm
111:10 - choosing right now to work with
111:12 - Transformers yes it just runs right here
111:14 - on this laptop in the browser um and oh
111:17 - thank you Fatima for you I see that
111:18 - people are giving me some super chots
111:20 - which is very kind uh unnecessary but
111:22 - very kind um okay so I now have I'm
111:28 - showing you a distance now the truth of
111:31 - the matter is ukian distance is not
111:34 - typically used for high dimensional
111:36 - spaces and let's talk about briefly why
111:40 - let's see if this paper towel Works a
111:42 - little bit better I don't know what what
111:45 - I've got here let me wet it oh I have
111:48 - like little wipes okay let's try this
111:50 - um okay so
111:52 - why are why is ukian distance often not
111:57 - used well think about 384
112:02 - Dimensions what
112:04 - if out of all of those de oh and I
112:06 - didn't press whiteboard don't worry
112:08 - everybody I know you're going to tell me
112:10 - this in a minute what
112:13 - if in that high dimensional space that
112:16 - 384 dimensional space all of the values
112:20 - all like 383 values were really really
112:22 - similar but then that 384th value was
112:26 - wildly different well ukian
112:28 - distance-wise you could end up getting a
112:30 - very big number for their ukian distance
112:32 - just because they're very far apart
112:34 - along one dimension But ultimately we
112:37 - want to consider those things to be very
112:38 - very similar so another way that you can
112:42 - compute distance is referred to as
112:45 - cosine similarity and there are many uh
112:48 - wonderful tutorials and videos online
112:50 - about that algorithm in particular I
112:52 - don't have a lot of time here so I'm
112:53 - going to give you like a sort of quick
112:55 - overview of what cosine similarity is so
112:58 - let's uh let's just look in a
113:00 - two-dimensional space um and I'm going
113:03 - to uh have these
113:06 - points right so you can see like ukian
113:10 - distance
113:11 - wise um and and obviously two Dimensions
113:15 - like ukian distance might be better than
113:17 - cosign similarity but you can see like
113:19 - this point is kind of same distance from
113:20 - this but let's let's think about uh if I
113:24 - were to basically take from the origin a
113:27 - ray or a line segment out to all of
113:30 - these
113:32 - points another way that we could
113:35 - evaluate the points is by looking at the
113:37 - angle in between these vectors
113:40 - essentially let's connect Back To Nature
113:42 - of code right so look at these these two
113:46 - points even though they're kind of far
113:48 - away have a very similar angle
113:51 - these this point and this point that
113:53 - angle is quite large and think about
113:57 - this what is cosine
114:00 - of0 cosine of 0 is one so if the angle
114:04 - were literally the same they would have
114:07 - a distance a cosine similarity of one
114:10 - being equal essentially if that angle is
114:12 - very large the similarity score is as it
114:15 - goes to you know 90 deges is going to
114:16 - approach down to zero so 180 degrees
114:21 - yeah so you so that's the idea of cosine
114:24 - similarity and in high-dimensional
114:25 - spaces you know again our brains can at
114:28 - least mind can't think Beyond really
114:30 - three dimensions but in a high
114:33 - dimensional space if you're looking at
114:34 - that angle that cosine similarity
114:36 - essentially that you know analog of this
114:39 - two-dimensional angle in that high
114:40 - dimensional space that's going to be
114:43 - generally a a a fairly good way of
114:46 - knowing if two embeddings are similar to
114:48 - each other
114:50 - okay so how do you do cosine
114:55 - similarity uh let's come back to here I
114:58 - have one more thing I I'm gonna be going
115:00 - a little bit over probably because I do
115:01 - want to finish this example um so uh all
115:05 - right so first of all I forgot to tell
115:07 - you about the nature of code
115:10 - book uh the new edition it's going to be
115:13 - at the regular nature of code website
115:15 - soon enough but the new addition that
115:17 - I've been working on for you know I
115:19 - would say over 10 years but really in
115:20 - Earnest the last six six months to a
115:23 - year
115:24 - um is uh here and actually it's so
115:27 - happens that in chapter
115:31 - five uh under
115:33 - the path following uh segment I have a
115:37 - whole section in the book on something
115:40 - called The Dot
115:41 - product and the dot product is related
115:43 - to cosine and is actually a way that you
115:48 - can calculate the Ang angle between two
115:50 - vectors so you can see I'm doing that in
115:53 - this
115:54 - particular um example that's in the
115:57 - nature of code and so this idea of
116:00 - getting the angle between two vectors uh
116:03 - and then taking the cosine of that angle
116:06 - extrapolates to higher dimensions and
116:09 - because I'm kind of short on time right
116:11 - now and I want to get to the clustering
116:13 - that I want to do what I'm going to do
116:16 - is just go and grab the formulas so
116:18 - these are the formulas that I made for a
116:21 - previous example and I'll put them here
116:23 - into this example that I want to do with
116:26 - clustering so you can see here that
116:28 - essentially I'm using higher order
116:30 - functions but the magnitude also sums up
116:34 - all the magnitudes I use the dot product
116:36 - which I cover in that nature of code
116:38 - chapter you can go and read and then
116:40 - cosine similarity is the dot product of
116:42 - the two vectors uh divided by the you
116:45 - know magnitudes of the two vectors
116:47 - multiplied by each other and that's
116:48 - going to give us the cosine similarity
116:51 - so I could instead I could look at uh
116:55 - let uh similar I'll just call it
116:59 - similarity
117:02 - equal cosine
117:04 - similarity of embedding one and
117:10 - embedding two and let's
117:14 - compare let's see what we get now
117:17 - remember it's going to be inverted like
117:19 - the smaller the ukian distance the more
117:21 - similar the higher the cosine similarity
117:24 - the more similar because the cosine
117:26 - similarity between zero and then one um
117:29 - okay and so uh similarity let's just
117:32 - look at that and see what we
117:37 - get oh what did I
117:41 - similarity
117:44 - similarity know what I'm writing
117:46 - similarity oops my fingers are are
117:49 - getting
117:50 - cold okay here we go okay great so those
117:54 - sentences aren't very similar I got a
117:56 - score of 0.1 what if I go back
118:00 - to
118:02 - uh the
118:04 - coding train says whoops and really
118:08 - these are the you maybe come up with
118:10 - better examples but we should get a
118:13 - lower ukian distance and a higher cosine
118:16 - similarity and that we did yay okay so
118:21 - this was
118:22 - me talking
118:25 - about what is an embedding how can I
118:28 - have an on device machine learning model
118:31 - give me an embedding for any arbitrary
118:33 - amount of text and then how can I
118:35 - compare two different arbitrary amounts
118:38 - of text so what I'm saying to you is
118:40 - what can you make with this could you
118:43 - something that I would say like that you
118:45 - could build now is you could make a
118:48 - chatbot which has like 100 different
118:50 - possible
118:51 - answers and when somebody asks a
118:53 - question you look you take at the
118:55 - embedding of their question and you find
118:58 - out of those 100 answers which one is
119:00 - most similar to that qu question and you
119:03 - give that one back so that could just be
119:05 - something that could be like a hello
119:07 - world demo that you could do just to
119:09 - kind of get this
119:11 - idea um I also think that I should
119:14 - mention uh I kind of glossed over this
119:16 - but uh if I go back to transformers. JX
119:19 - yes there's a lot more um you know
119:22 - tutorials and information here about how
119:24 - you can use this particular JavaScript
119:26 - library and then this is
119:30 - um uh you know the tasks are really what
119:33 - um I'm kind of interested in and um the
119:38 - model that I am using where is it is it
119:40 - I'm looking for what
119:42 - feature or yeah feature extraction so
119:46 - I'm looking for a model that can do
119:48 - feature extraction but there are models
119:50 - in Transformers JS that can you know
119:53 - convert to caption an image can do
119:56 - object detection all sorts of other
119:58 - kinds of things so you might sentence
120:00 - similarity is is basically doing what
120:02 - I'm doing here but it's doing it for you
120:04 - without the uh you know having to
120:06 - compute the the the distance score and
120:08 - all of that so there's a lot of other
120:10 - stuff that you can do and what you can
120:12 - see basically is that you create a
120:15 - pipeline like if you want to do sentence
120:17 - anal sentiment analysis you you have to
120:19 - specify the task and the model you want
120:22 - and so uh and then if I know that I want
120:25 - to do like I have an example that does
120:26 - summarization that I want to do
120:28 - summarization if I click on this I think
120:31 - this will give me the models that I can
120:33 - use that are compatible with um with
120:36 - that so anyway I'm not this is not an
120:38 - overview of everything that hugging face
120:39 - has to offer and how it works but I just
120:41 - wanted to show you the landscape of
120:42 - where you can find the Transformer JS
120:45 - compatible models and kind of link that
120:47 - up to what I'm doing here in my my
120:51 - code um okay
120:54 - so how's the audio going how bad is
121:00 - it because I'm G to do something out of
121:03 - time but I want to do something High
121:05 - degree of difficulty that I definitely
121:07 - do not have time
121:10 - for but let's see what we can get all
121:14 - right we do this in a really crude
121:18 - way problem
121:21 - is you know what's really gonna what's
121:23 - really going to cause me a problem
121:26 - is oh I don't have time to go through
121:29 - all of this today I'm trying to think of
121:30 - maybe I
121:32 - should maybe I should do the question
121:35 - let me show you what I was going to do I
121:37 - can't get I'm gon have to work on this
121:39 - on my own uh join the coding train
121:41 - Discord and I maybe come back make some
121:43 - videos about this because I wanted to do
121:45 - clustering what I've been experimenting
121:48 - with
121:49 - is this incredible um JavaScript library
121:54 - called umap JS okay let's come back to
121:57 - this is where I'm going with this next
121:58 - so I gave you a little lesson in
122:00 - embeddings and using Transformers JS and
122:02 - you could make this project I'm going to
122:04 - be working on this because I got to
122:05 - demonstrate it in class this week on
122:07 - like Wednesday so this example will
122:08 - exist at some point soon all right but I
122:12 - I realistically can't build it now
122:13 - without being here for another hour or
122:15 - two so first of all this is a wonderful
122:18 - article called understanding umap
122:20 - written by uh Andy Conan and Adam Pierce
122:22 - from Google pair which is people in AI
122:25 - research and so one of the things right
122:29 - I I have to walk over to the Whiteboard
122:31 - to just talk about
122:32 - it I've been talking a lot about high
122:36 - dimensional space I have all of these
122:37 - words all these sentences that exist in
122:40 - high dimensional space you can do this
122:42 - with images too by the way you can
122:43 - extract features from images and plot
122:46 - images in high dimensional space and
122:47 - look at their similarities Etc all sorts
122:49 - of possibilities there but every time I
122:52 - come to the Whiteboard to do a diagram I
122:54 - draw it in two Dimensions because that's
122:56 - the way it's easiest for me to see so
123:00 - what if just for just imagine for a
123:03 - moment that I had a list of words or
123:08 - sentences and each one of these and I'll
123:11 - just call them A B C D E
123:14 - FG was associated with an embedding of
123:17 - 384 numbers
123:21 - these this is where I was going with the
123:23 - example I make these sentences exist in
123:26 - 384 dimensional space and if I could
123:28 - just see them in that space I could see
123:30 - the ones that are near or far I don't
123:33 - know maybe my mind would open to all
123:34 - sorts of new possibilities that I
123:36 - couldn't imagine just would be interest
123:38 - wouldn't it be
123:39 - amazing I can't I can't see them in 384
123:42 - dimensional space how could I plot them
123:45 - maybe in two dimensional space even
123:47 - though it wouldn't be true precisely I
123:49 - would get some type of you know
123:52 - visualization of how that data
123:55 - looks so what I need to do is a process
123:58 - known as
124:03 - dimensionality
124:06 - reduction I need to somehow take these
124:10 - 384 dimensions and summarize them into
124:13 - two Dimensions this is not
124:16 - easy okay so there's one way I could do
124:18 - it I could just say why don't I just
124:20 - arbitrarily pick the first two numbers
124:22 - of each of these and we could actually
124:23 - do that we could plot it and we could
124:25 - see and we might get lucky and that
124:27 - might kind of reveal something and be or
124:29 - maybe I pick the seventh value and the
124:31 - 20th value maybe I plot them in 3D space
124:33 - so at least I get to pick three
124:35 - dimensions um could I average a whole
124:38 - bunch of Dimensions together like
124:40 - there's 384 so could I average like half
124:43 - of them into one number in the second
124:44 - half what would that give me well these
124:47 - would be starting points that's like
124:49 - where my mind would go but there uh
124:51 - researchers and other people have
124:52 - developed um lots of other algorithms
124:55 - like PCA which I think it's principal
124:57 - component analysis is
125:00 - one tne which sounds like a sneeze but
125:03 - it's not uh is another I I forget like
125:07 - which letters are capitalized this is
125:08 - another algorithm
125:11 - uh a more recent algorithm is called
125:16 - umap umap is an algorithm that can take
125:19 - all of these high dimensional data and
125:22 - reduce it down into two Dimensions So in
125:25 - theory I could see clusters of the like
125:28 - data within two
125:31 - Dimensions there is a
125:34 - wonderful uh project uh made by also
125:38 - researchers at Google called the
125:39 - embedding
125:42 - projector and this does uh this does
125:45 - precisely that so this is basically
125:48 - taking a word to VC like a list of
125:51 - 10,000 words all that are I don't know
125:54 - what the dimensions are and essentially
125:57 - um mapping them into reducing the
126:00 - dimensions into 3D space and so if I
126:03 - were to zoom in and start to look at
126:05 - words that are near each other um you
126:07 - know I might find things that are
126:10 - similar it's a little hard maybe to see
126:12 - this a different data set that might be
126:15 - um uh better to look at is mnist so this
126:18 - is doing this with images these are low
126:21 - resolution images with 784 pixels so you
126:24 - can think of 784 dimensional space and
126:27 - using it's using PCA to plot them in
126:32 - three dimensions but I could switch to
126:35 - umap and now this is what the umap
126:37 - algorithm is going to
126:39 - do it is now
126:42 - uh taking these 10,000 data points in
126:44 - 780 diens 84 dimensional space you can
126:47 - see that listed up here at 10,000 points
126:50 - 784 dimensional space and uh it's you
126:54 - know taking a little while but now you
126:56 - can see it's clustered them so we can
126:59 - see here the sixes are kind of all in a
127:02 - cluster up here here's the fives and
127:04 - threes are kinded together the eights so
127:06 - this is the stuff that I'm really
127:08 - interested in making my own versions of
127:11 - these I'm sorry that the mic is still a
127:15 - problem I'm going to have to um
127:18 - investigate this okay there I could I
127:22 - could switch this to 2D which could be
127:23 - kind of interesting to see it um there
127:26 - are different parameters in terms of how
127:28 - the algorithm works and clicking right
127:31 - here
127:33 - um takes me to a page that explains more
127:37 - about the umap algorithm that you I'd be
127:40 - you know thrilled for any of you to look
127:42 - at and understand and try to um uh find
127:45 - ways to uh help explain the umap
127:48 - algorithm in Friendly and accessible and
127:50 - approachable terms um I do find that
127:53 - this particular article which has a lot
127:56 - of visual demonstrations this is looking
127:58 - at um another data set it's called
128:00 - fashion mnist it's a whole bunch of uh
128:02 - images of shirts and shoes and things
128:05 - and this is what uh umap um and this is
128:08 - the tne algorithm and it goes through a
128:11 - little bit about the theory uh about how
128:14 - it's looking at you know nearest
128:15 - Neighbors in uh in higher dimensions and
128:18 - then synthesizing that down into uh
128:21 - lower Dimensions
128:25 - so uh I'm G to show you very
128:29 - quickly uh an example I've been working
128:38 - on let's see I don't know which one is
128:41 - the one that I want to look
128:46 - at is it this one one no no no no
128:51 - sorry it's not that
128:53 - one yes
128:55 - so I have been uh experimenting this is
128:59 - a particular data set
129:04 - from oh uh let's see from I've I've
129:07 - referenced this in videos before a
129:09 - GitHub repository called uh
129:12 - corpora and it's just a collection of a
129:14 - lot of interesting data files a lot more
129:16 - to say about it but and under colors
129:19 - there's a few different um data files
129:22 - there's like a data file of Crayola
129:24 - colors so these are this is a nice like
129:28 - way of demonstrating things with
129:29 - embeddings like I have words that are
129:32 - associated with uh embedding of you know
129:34 - three RGB values written as hex codes
129:36 - here and so I think Delux Delux is a
129:40 - paint company and this is a particular
129:44 - uh data set has many many many it's like
129:46 - four thousands of colors um and each
129:48 - with their RGB
129:51 - values so what I've done with this
129:54 - particular example is I'm using this uh
129:57 - umap JS
130:00 - library and I'll have to come back and
130:02 - maybe do some more videos about this or
130:04 - come back and continue this on a live
130:06 - stream if people are interested is I'm
130:08 - using this umap JS library to
130:11 - essentially uh um I I can essentially
130:15 - just call like this function called fit
130:18 - so data can be a giant array of
130:21 - embeddings and then I can just call fit
130:24 - and what it then gives me is TR uh di
130:27 - that data uh reduced by Dimensions so
130:30 - let's go look at my actual code and I'll
130:32 - talk you through let me just run it we
130:33 - see we'll first see what it
130:37 - does so what this is doing and again
130:40 - this is like a a known we don't really
130:43 - need um for this because this is just
130:45 - three-dimensional data but what this is
130:48 - doing doing is it's taking that
130:50 - three-dimensional uh RGB data and
130:52 - flattening it and clustering it in
130:54 - two-dimensional space so we can see that
130:57 - look at these colors that are these
130:58 - colors that are all kind of cluster over
131:00 - here these sort of dark green blues and
131:02 - these kind of light pastel colors and
131:05 - these here um I can run it again it's
131:07 - stochastic meaning it uses a r random
131:10 - seats so it's going to be a different
131:12 - each
131:13 - time but uh but we'll get some very
131:16 - similar results so this is what's
131:18 - happening what it's doing is it's
131:21 - loading that Json file it's putting all
131:23 - the RGB values into a big array so if I
131:28 - look at the
131:30 - array which is console log
131:33 - data this is my big array of
131:38 - embeddings it is
131:41 - 4,224 three-dimensional embeddings and
131:45 - then uh I initialize the umap algorithm
131:50 - these parameters I I wanted to go down
131:51 - into two Dimensions uh the minimum
131:54 - distance and the number of neighbors
131:55 - affect the quality of what it considers
131:57 - sort of similar and not similar and how
131:59 - it places them um I initialize that and
132:02 - then step does one cycle of the
132:05 - algorithm so I can kind of watch it
132:06 - animate because it take quite some time
132:09 - and then out of that I get the embed the
132:13 - 2D embeddings which now I can just plot
132:16 - x's and y's X's wise and so that's where
132:20 - and I'm taking the original colors and
132:22 - filling them so my idea what I'm not
132:24 - going to build right now but what I'm
132:26 - hoping to do next um uh as an example
132:31 - and if anybody wants to try this and
132:33 - compare notes come and say hello in the
132:35 - coding train Discord is I would like to
132:38 - go take this my goal is to have maybe a
132:44 - some like maybe like a 100
132:46 - sentences and then I would like to use
132:49 - Transformers JS to make the embeddings
132:51 - for those sentences and then I would
132:52 - like to use umap to graph them to
132:55 - Cluster them and then maybe I could have
132:58 - like a little interface where you type
132:59 - in a new sentence and it red does the
133:01 - umap and finds its place I don't know
133:04 - what kind of creative what kind of
133:05 - generative poetry could you make by
133:07 - doing a random walk through this
133:09 - two-dimensional uh two-dimensional
133:11 - clusters of sentences so that's kind of
133:13 - where I'm going with this so I kind of
133:15 - showed you the pieces here uh I will try
133:18 - to after this wraps up document all of
133:21 - these pieces and put links in the video
133:23 - description definitely come if you want
133:25 - to help with this or want to ask
133:26 - questions uh the coding train.com
133:28 - Discord would be the place for you to do
133:32 - so um so I wonder I don't you know I
133:36 - don't hopefully this was somewhat
133:37 - interesting for people you've getting a
133:39 - little bit of sense um again if you want
133:41 - to follow more closely a lot of what I'm
133:44 - working on right now which I would love
133:46 - to turn into some video tutorials and
133:47 - just haven't had the time um you can uh
133:50 - you can definitely check out the um
133:54 - programming from a to z a syllabus there
133:56 - are a lot the Transformers JS examples
133:58 - are in repo here um I have some other
134:01 - things that I'm working on with other uh
134:04 - uh different models um and and um API
134:07 - services for accessing these models um
134:11 - that you can find and poke around in
134:13 - here as well all
134:16 - right
134:18 - let's look before I
134:21 - go let's look at
134:23 - my
134:27 - um let's look at my um list of things
134:31 - that I wanted to do in 2023 and let's
134:33 - see what's real I got a month left I'm
134:35 - leaving to do some holiday
134:39 - traveling honestly like the last time
134:42 - I'll be here in this studio is kind of
134:44 - mid December so I've just got a couple
134:46 - weeks left of either live streaming or
134:49 - recording some stuff I would really like
134:51 - to do I think I should do the Wolfram
134:53 - Elementary CA as a coding challenge
134:56 - because that will go nicely with u
134:59 - nature of code so that's probably what
135:00 - I'll do
135:02 - next I didn't get to any of this
135:05 - stuff I did this I kind of did this but
135:08 - I should I don't know I I was planning
135:10 - to do more Discord bot tutorials and
135:12 - then kind of like nobody watched that
135:13 - video and like ah maybe I will maybe I
135:17 - won't but I would encourage I want to do
135:20 - more with
135:21 - ml5 yeah so I'm looking at this I don't
135:24 - know you let me know what you
135:26 - think
135:28 - um use Project Gutenberg and rewrite a
135:31 - classic based on similarity that is a
135:33 - great idea so loading a public domain
135:36 - text from Project Gutenberg and oh I
135:38 - could take like a text chop it up into
135:40 - sentences and then like cluster them all
135:43 - so that could be kind of interesting
135:44 - that would be a great project that
135:45 - somebody could try to do um um yeah so
135:49 - let's talk about nature of code book for
135:51 - a second um so this is the uh finished
135:56 - pretty much finished um new version of
135:59 - nature of code book um it is all
136:02 - available online P5 GS examples all the
136:05 - text is there I would say um yeah well
136:10 - right now I can't I'm this is going to
136:12 - be a living document but it is somewhat
136:14 - Frozen in the sense that I there's going
136:16 - to be a finished version that will go to
136:18 - print so if you would like to support
136:20 - this project um there are two ways you
136:23 - can do that um you could actually you
136:25 - know buy the nature of code book this
136:28 - won't come out till the summer though it
136:29 - says may 2024 I'll be thrilled if it's
136:31 - out May 2024 um so this you can
136:34 - pre-order from no starch I think it's on
136:36 - all the other kind of book websites um
136:39 - or you can um the the GitHub repost have
136:41 - like a skub sponsorship associated with
136:43 - them but I don't I don't get to it but I
136:44 - just want to let you know that's there
136:46 - um and uh the P
136:49 - controller yeah I wanted to do that
136:52 - too chac just watched the word TC video
136:55 - that's interesting so I really like to
136:57 - continue that that was my intention like
136:59 - to continue that with some of these
137:00 - modern uh embeddings models but I never
137:03 - got around to that so let me just thank
137:05 - again um upper story uh for being the
137:10 - sponsor of
137:11 - today's uh coding train uh live stream
137:16 - again if you missed it you go back all
137:17 - the way the beginning of this stream
137:18 - after I'm done I did a demonstration of
137:22 - this uh game called the Turing tumble uh
137:25 - it's a wonderful if you're looking for
137:26 - to find a gift for somebody who loves
137:28 - computers and wants to learn more about
137:30 - how computers work and especially if
137:32 - they want to have an opportunity to do
137:34 - that away from the screen away from
137:36 - digital technology and actually you know
137:39 - get their hands in the mechanics of how
137:41 - computers work to learn a little about
137:42 - the history of computing Allan Turing um
137:45 - check out the Turing tumble and upper
137:47 - story uh the link is in the video's
137:50 - description upper
137:52 - story.com tumble and then coupon code
137:55 - allc caps coding train um that's all
137:57 - I've got uh I will take any other
138:00 - questions as
138:03 - I say goodbye here um I uh hope to
138:09 - continue to see you all sub projects in
138:12 - the passenger showcase to joining the
138:14 - coding training Discord to sharing your
138:17 - work with me watching old CL challenges
138:21 - if you like I don't know 2024 I hope
138:24 - that's a good year for making lots of
138:34 - content I actually went through
138:36 - everything on this list except for the
138:38 - wolfrun thing uh oh uh Kathy asked how
138:42 - does umap compare to fastest nearest
138:44 - neighbors I don't
138:45 - know that's a great question and we
138:47 - should
138:48 - investigate uh
138:51 - that my understanding is umap does a
138:54 - particularly good job of clustering
138:57 - things and doing it very fast and
139:01 - efficiently uh thank you mini Jimmy for
139:03 - your kind comment I'm just awkwardly
139:06 - standing here for another minute and 45
139:09 - seconds because that's what I do let the
139:12 - let the timer run out just see if
139:13 - anybody else has anything to say in the
139:15 - chat before I
139:16 - go
139:18 - [Music]
139:23 - uh I'll put my sweater back
139:27 - on I hope people enjoyed today's live
139:30 - [Music]
139:33 - stream I think I should one one idea
139:36 - that sometimes I think about is what if
139:38 - I just forgot about like making edited
139:41 - videos again and just like live streamed
139:43 - once a
139:44 - week just worked on projects
139:50 - GIF Auto says I got stuck in full screen
139:53 - mode on Apple 2 and can't
139:57 - escape I don't know what to do for you
139:59 - thank you Nicole thank you uh hope uh
140:02 - thank you well oh is there another
140:04 - fundraiser I think there will be another
140:06 - processing Foundation fundraiser check
140:08 - with the foundation website about that
140:11 - lost sorcerer you're welcome I was glad
140:13 - to be able to show that uh give Auto can
140:17 - you get to the Discord I don't know if
140:18 - this is a joke or serious because you're
140:21 - somehow typing into the chat so you
140:23 - can't totally be stuck in full screen
140:25 - but I don't know force quit uh make an
140:27 - ml video editor that's I think beyond
140:30 - the scope of what I can possibly do but
140:32 - I like that idea live stream once a week
140:36 - yeah I'd love to get back into doing
140:37 - that my my teaching schedule is
140:39 - less busy in the spring semester so
140:42 - hopefully I'll get back to oh oh my song
140:44 - is running out goodbye everybody I will
140:46 - see you
140:47 - I mean hopefully I'm going to see you
140:48 - again in 2023 thank you for watching the
140:51 - coding train I don't know if I'm doing
140:54 - this the way I should be doing this
140:55 - anymore but boy am iik trying and doing
140:57 - my best I will see you all soon goodbye
141:00 - as always I always forget
141:16 - this
141:46 - do
141:49 - [Music]
141:58 - doget do I'm going to do the this this
142:02 - do this do this do the this Dot Song
142:04 - never forget the this dot somebody
142:06 - composed that song for
142:16 - me
142:20 - I'm
142:22 - again
142:46 - sing
142:51 - autotune and the internet will fix that
142:54 - for
143:16 - me
143:25 - unicorns and rainbows and cupcakes what
143:28 - else is
143:30 - there yes kittens thank you very much
143:33 - kittens and rainbows and cupcakes notice
143:35 - that look what I get I'm really losing
143:38 - my
143:38 - mind okay let's do
143:41 - [Music]
143:43 - it Kitt kittens and kittens and kittens
143:46 - and kittens kittens and kittens Kitt and
143:48 - Kitt kittens and kittens and Kitt and
143:50 - Kitt Kitt and Kitt Kitt and Kitt kittens
143:52 - and Kitt and Kitt and Kitt Kitt and Kitt
143:56 - kittens and kittens and kittens and
143:57 - kittens kittens and kittens and kittens
143:59 - and kittens kittens and kittens and
144:00 - kittens and kittens kittens and kittens
144:02 - and kittens and kittens kittens and
144:04 - kittens and kittens and kittens kittens
144:05 - and kittens and kittens and kittens
144:07 - kittens and kittens and kittens and
144:08 - kittens kittens and kittens and kittens
144:10 - and kittens kittens and kittens and
144:11 - kittens and kittens kittens and kittens
144:13 - and kittens and kittens kittens and
144:15 - kittens and kittens and kittens kittens
144:16 - and kittens and kittens and kittens
144:18 - kittens and kittens and kittens and
144:19 - kittens kittens and kittens and kittens
144:21 - and kittens kittens and kittens and
144:23 - kittens and kittens kittens and kittens
144:24 - and kittens and
144:33 - [Music]
144:45 - kittens
144:47 - [Music]
144:55 - I feel just sort of like a nice feeling
144:58 - of relaxation everything's going to be
145:01 - okay today dream is not broken it has
145:03 - not frozen this is a this is a wonderful
145:06 - thing okay we're going to do it I'm
145:08 - really getting to something I need my
145:10 - sound
145:14 - [Music]
145:15 - effect
145:16 - [Music]
145:18 - unicorns and rainbows and
145:22 - cupcakes what else is there unicorns and
145:28 - rainbows and
145:30 - cupcakes that was invalid syntax I
145:32 - forgot uh there was one other thing here
145:35 - that I think is important that I will
145:37 - use continuously over and over again in
145:40 - all sorts of text generation analysis
145:43 - things that I will use continuously over
145:46 - and over again first thing I need to do
145:49 - is yes kittens kittens kittens I really
145:52 - losed my mind okay we're going to do it
145:55 - kittens and kittens and kittens and
145:57 - kittens kittens and kittens and kittens
145:59 - and kittens kittens and kittens and
146:00 - kittens and kittens kittens and kittens
146:02 - and kittens and kittens kittens and
146:04 - kittens and kittens and kittens kittens
146:05 - and kittens and kittens and kittens
146:07 - kittens and kittens and kittens and
146:10 - [Music]
146:12 - doia

Cleaned transcript:

n a n check one two hello it is me last name to test my audio I have oh I got 23 seconds I won't be ready in time but close I'll be close a all right I I heard you all loud and clear that my mic is quite quiet compared to the music I'm gonna leave my mic where it is I'm just turn the music down actually let me turn it up a tiny bit here I have to figure out that'll boost the volume a bit uh so hopefully this is better for you all now um yeah all right here I come the train is departing kind of almost maybe get my notebook out uh I'll turn the camera on me so many things here I'm not prepared for this at all but I'm doing my best everybody good morning good evening good afternoon hello to all of the coding train passengers all around the world it is is me hello to Julian from the UK your host Daniel schifman and I'm here live on a Sunday ah I forgot to turn the heater off I'm in a very cold garage but I have this electric kind of hanging garage heater which uh I am now walking over to to turn off it makes kind of a loud noise uh later I may have to turn it on again if I get kind of cold that didn't work different switch here there we go I'm coming back I'm coming back to view don't worry here I am I'm moving a little slowly it's a Thanksgiving holiday weekend here in the US and I went to visit some family and I slept on a very small twin bed for one night and like half of my back the muscle is all like contorted and twisted so a the my whole rest of the afternoon today I think gonna be doing some stretching I'm an old man on you for you for I mean I'm not you know in in many ways I'm very young to be like I'm I have no interest and and and not qualified to be president of the United States why am I even talking about this but for YouTube for doing this thing that I've been doing for well over 10 years 20 years got something stuck in my teeth I was quickly having a little toast and peanut butter to have some energy here it's been a while I know I know I don't know what happened to 2023 um uh it's almost over I I I was feeling a little bit better uh now I have this um uh a a list of goals and plans that I made at the beginning of the year and there surprisingly are some things checked off here so I feel like uh all is not lost but it has not been the most I mean it's been a very productive year for me and I will talk about the nature of code book which has been my focus for this year um which has really reduced the sort of productivity the content if you will because what else do I do here on the coding train but make content I mean that's what we're all here we're just engines of content to make content to consume content it's all content content content I haven't made very much I would like to say educational possibly slightly entertaining tutorials um but I'm here I'm trying to get at least uh two more live streams in before the end of the year maybe well start thinking about goals for 2024 I do believe in my heart that 2024 will be more coding train focused because there's a fly that's really interested in my light over there so hopefully this won't be too distracting but uh with the nature of code book wrapping up um I think that I would like to turn back towards videoing as opposed to writing uh after all I can just have some language model take care of all my writing for me in 2024 but maybe my humanness still uh comes through the camera somehow although I am working actually let's not mention this just yet but uh coming soon coming soon something interesting for all of you uh where when can we buy the book so let me not talk about the nature of code book just yet because I do have an actual a sponsor of today's live stream uh you really should thank the sponsor greatly because sometimes you know I don't take a lot of sponsors I'm really excited about this one um it is a company called upper story and as soon as I saw and you're not seeing this right now as soon as I saw this game called the Turing tumble named for Allan Turing don't get confused there's a lot of turning going on but this is a game named for Allan Turing um I was really excited I desperately wanted one of these to play with it to try it with my children um in AIT bit I'm going let's see if I can get this camera to work I'm going to show you it live in action I've got it over there uh on a little extra table um so uh you know it's it's holiday time if you're looking for a holiday gift if you want if you if you know some children some adults who want to get into computers want to learn how computers work how to logic gates work all that stuff uh but maybe you need to take a break from your screens uh this is an entire mechanical this is this is a turing complete computer uh sitting there on the table um so uh I'm gonna I'm gonna I'm gonna talk a little bit more about it but if you're interested in learning more uh right now uh there's this website that you can see upper story.com Turing tumble but better yet there a link in the video description I don't know if there's any moderators around I'll have to do this myself at some point but I'll put a link into the chat and maybe even pin it as well um uh so am I ever gonna be it's a gonna be the most techsavvy Grandpa you know first of all I'm not that far I mean I'm I'm hopefully very far but but who knows will ever be a grandpa there's a possibility uh I don't think I don't even think I'm I think I'm like not very techsavvy right now I mean my ability to do things on the computer in any kind of Cutting Edge uh intelligent way you know pales in comparison to what the youths the youths the two youths that no that's another reference the youths are doing these days on YouTube boy there are a lot of incredible people making a technology coding educational content on YouTube anyway check out upper story link in the description let me set the table for what I want to do today uh usually I do the little sponsor segments in the middle but I think I'm actually do it right at the top because it's kind of fun it'll be a fun game for us to play as a little Icebreaker and I've got it set up over there on the table and that way I can then uh move the table out of the way and get back to some whiteboarding if I need to so um I don't have my uh systems up and running fully for all of the different ways I like to look at the chat I keep looking over here but I don't see any chat I just see my soundboard welcome on today's episode of the coding train I'm gonna be here without knowing what I'm gonna say next there's a camera over here that's exciting got some stuff going on Vince asks do your kids code yes they do I think they're a little like enough with the coding already oh my goodness coding this coding that blah blah blah blah blah blah but they're they're interested they do kids these days they've got their coding education in their K through 12 schools at least here um which is very different than my experience um all right so um let's let's think about things let's come back to here so one thing that I am curious about I really would like to do some coding today so I'm gonna talk about I'm gonna we're gonna look at the Turing tumble game step one let's make a list okay uh I'm glad you like the background thank you to Stephen wol in the chat I don't have my whistle I I I don't have any of my props oh I got this one okay okay so uh we're going to start with churing tumble today's sponsor thank you to Upper story uh we are going to move from there and maybe look at nbb is asking what is the plan for today we're figuring it out together I'm going to be here till approximately 1 pm Eastern I um so that's um kind of a bit of a hard out for me so that's an hour 45 minutes like to take a little five minute break somewhere in there if possible if you'll be so kind to allow that um I would like to look at the passenger showcase uh we'll look at some recent additions to the passenger showcase thank you to all of you who have been submitting your projects um I would like to give you an update on the nature of code book and you know usually you would think it makes sense to make my agenda before I start streaming but I spend a very long time getting the audio routing properly so that I could have the soothing tones of some royaltyfree music thank you to epidemic sound which I think is this track is from that I subscribe to uh Nicole says I really need to submit to the passenger showcase sometime and yes yes you do in fact maybe you want to do that today make that your little Sunday activity although it's a Sunday any day you know maybe maybe after if you're watching this maybe after this is over you would close your computer spend some time with your thoughts with nature with a book good book you can just curl up in that fly is coming to get me everybody see if I make it through this okay uh do Tetris ah uh wait oh Stefan Wolfram that's actually your name I'm so sorry I just assumed that was somebody with their YouTube name as like a play off of Steven Wolfram but we actually have the real life honest to goodness Stefan wolf from in the chat today which is kind of great because the thing that I was planning to code today because I really I know my recent live streams have been a bit more just chit chatty um but I would like to um the the two things I'm thinking of coding today one is the Wolfram the uh as an homage to our friend Stefan wolf from the wolf from 1D CA and then the other thing I'm thinking of doing is looking at uh a JavaScript library called Transformers JS and doing some uh uh experiments with uh embeddings and text well this is a really long track that I just put on arbitrarily behind me um I love Dustin's comment there uh this is the adult version which by the way got me a little scared at first I was like oh my God am I an adult version sometimes means something else to me now I'm already getting like incredibly embarrassed just uh of everything I loved and enjoyed from PBS learning shows as a kid I appreciate that uh okay um so I got I got to shut this music off okay I just realized that most of my props uh are in a tote bag uh through several doors away in from this garage where I am because I had packed them all up for this thing that I'm working on and I forgot to bring them back so my random number book all those things so one thing I'm curious about um well also we've got um let's look at this so let's just look at this this list and see if there's anything here so let's let's have a little recap what was accomplished um in and by the way the reason I keep looking over this way is that's where I have my monitor at the YouTube chat and when I turn this muscle in my back gets a little poked oh I forgot to will I be doing a Showcase of the hober submissions uh lost sorsor what an awesome idea so let me I forgot about that yes um all right and by the way I do also have out of the corner of my eye the Discord member chat so if there are any important or like comments or questions or something going on if any of the Discord members who are in the live chat supporter Channel want to put a message there let me know I'm not going to be uh seeing it so maybe reduce the uh we'll figure it out as we go but I just saw that uh fish posted hi so I didn't see that uh and I see that we have someone from Morocco today um welcome I'm the one one of the things that I say this a lot that Thrills me to know end are the international uh Global viewers of the coding I mean I appreciate you if you're like watching this from you know queens or something that's awesome too wait what oh I'm like what does that sound I'm like my computer is about to explode do you hear it so I'm using um this software that I love called loopback uh which is an audio routing software and the way that that works is I have a iPad over here with sound music and sound effects and it kind of routes around through this audio interface into this laptop and then I route it out into this PC streaming computer and it comes into open broadcast studio wow Carl is very cold here in in uh in New York so um but I forgot that um uh I just like this is a new Compu new computer that I haven't streamed with before and I just like quickly installed the trial of loop back and uh I I've bought loop back software so I need to find my license code so I don't know if I'm going to do this right now let's see uh okay so let me come back to here and I might have to dig into my email email where would I have purchased it which email address would I have used we're about to find out okay let's oh boy will you all indulge me for a second you know what I'm gonna um like M okay my email is like on the screen this is terrifying uh let's just see if it's really obviously fast Rogue ah lose B license key yes uh could this possibly be 2016 is that going to actually work did I Daniel schifman my code unlock ah older license key but no I've definitely purchased a newer one because I remember doing this recovered license information in 2019 maybe this is it this is like uh um where wherever there is somewhere on the internet best practices for life streaming uh whatever I'm doing is not it oh that's the same all right all right hello at Rogue amoeba maybe I actually just need to purchase a new one loop back receipt 2019 okay receipt uh okay hold on I did purchase ah I've got a new license code okay I've got it I've got it we've got it everybody unlock yes oh wh wrong wrong button success everybody loopb back has been unlocked thank you look at this I get a whole certificate and everything I feel very proud of myself and I'm in honor of this moment going to play oh wow you can't hear that at all I made that very quiet um okay uh um let's see um okay so what were we that was an adventure yeah coding challenge idea thought thought planner okay oh that's interesting uh Nick is writing from Toronto yes uh happy belated Canadian Thanksgiving ah MV lab ask will you be doing the January challenge this year let's let's address this and then I gotta we got to get moving on this list of things if I'm going to get to anything wow wow and we've got J from Algeria watching that is amazing um I don't know if I pronounced your name correctly jog uh feel free to spell it phonetically for me in the chat even if I miss it maybe I'll try to go back and read the chat later um all right so I got we got to get moving here ah yes January so if you're not familiar with January let's take a look it's coming up January is uh um a month January is a month that has its days in it and every day there is a new generative art prompt uh it's uh one I've been trying to participate in some way two years ago um I actually did something every single day last year I didn't do anything any of the days but the end of the month I did a January speedrun as a live stream that was really fun so at a minimum I absolutely want to do a January speed run again but I had this idea I um I don't know if you know this but there is a coding train Tick Tock account also YouTube has shorts I don't really use them I'm not really I haven't figured out a way to use them or to make short form content in any way that's fun and useful but I thought maybe as an experiment in January for January I would make a short video every day based on the prompt um and I would do them completely on my own like all any editing production capturing I would have to do it on my own just as a way to learn um to learn oh and we have a new member hello to mooner welcome you have just joined the conductors of the coding train welcome aboard for your membership ah you will receive a little packet of stickers guess what we do the sticker mailing once a year and uh if any of you have received your stickers because we've been sending them out the last few weeks please uh say so in the chat would love to hear that you got them if you like them but um the the mailing happens once a year but you're just under the wire uh muner if you look into the YouTube Community posts now that you have the members one you will find one where you you can um uh sign this form with your information and we will send you stickers so um yes and welcome to Muhammad in the chat and Yash and AI guest I'm so glad that AI is here all right so let's get started and let's start off uh with the first segment of today's live stream this is a sponsor in case you weren't clear about that but it's something that I would 100% legitimately cover on my own it's I mean honestly like I just wanted to buy one so when they were like okay we going to sponsor we'll send you one I mean nothing could have been a better alignment of things so I want to um show you uh a little bit about what this is um it's whoops I'm I'm I'm having trouble I'm gonna walk over here I'm like a little game show host here um so this is the Turing tumble uh again Nam for Allan Turing so uh I don't know how many of you are familiar with Alan Turing I actually have had the uh chance to uh visit a place in the UK called Bletchley Park and it is where Alan Turing uh cracked the Enigma machine um or uh is the enig yeah the Enigma machine is the German code thing that they broke in World War II there's a whole movie about it the imitation game it's called Alan Turing quite famous for the thought experiment of you know Ken machines think and this socalled Turing test which certainly is quite relevant today in today's world of language models and new AI Technologies but uh I think it was in the 30s probably 1939 that Alan Turing came up with the idea of completeness so a turing complete computer is one that and this is you know think about this we're talking about the 1930s I think that paper is maybe 39 I got to go fact check this someone can fact check me in the chat but think about this how did Turing think about the idea of a turing complete computer before there were even really computers that fly is really coming to get me no I will not the sanctity of the Turing tumble board is is quite oh and I I also realized okay I'm gonna talk to you about Alan Turing while I do some uh busy work here uh of just like um setting up something that I oop I'm very clumsy oh boy I'm going to definitely be fired uh uh from my upper story this okay um so all right so a turing complete computer the idea is uh with infinite time uh with with you know without finite time and resources essentially you think about like a tape a MAG a tape that you could process through and essentially uh uh you know perform computations with it any is it's very hard for me to talk and concentrate what I'm doing but the idea of a tur complete computer is one that given an infinite amount of time and resources or memory you might think of it as could uh perform any computation uh at all and amazingly this toy uh you know board Contraption mechanical Contraption which I had a lot of fun putting together by the way just assembling this thing was quite the challenge for me is a turing complete computer and um one of the things about it what what I love about this game uh so first of all let me come over here and just explain to you how this works let's see if this will work uh ah great perfect so I have over here um the the board itself comes with this book uh the Turing tumble puzzle oh it's upside down okay let's fix that that's one button uh come on alive there we go the Turing tomble puzzle book um 1936 says Dustin was when Turing published the paper on the hypothetical machine uh 1936 okay so uh are you hearing lots of audio pops and snags people are telling me um so let's see I could get a little bit of info if people are having audio issues and I will try to fix those hopefully it is at least you can understand what I'm saying um but I love to know so one of thing what I love about this is first of all so the book comes with a diagram now there's all these different elements I'm not going to be able to go through and do everything plus I wouldn't want to spoil it for you frankly to be perfectly honest so I barely want I want to show this to you because it's so cool um but I don't want to show you too much so this I had a lot of fun putting this together um there is a whole story graphic novel essentially that you can read um this is but I've been doing this with my son who is um 15 yeah and he just he turned 15 recently why I had to pause there for to remember we're having a lot of fun putting this together um looking through the story and then as integrated in the story you start to learn about this machine um and how to play and there are a whole set of puzzles and you know immediately when looking on this I realized like oh this is just like a computer and one of my favorite uh Parts is this uh is the um I forgot what it's called it is the um it's going to introduce a new part here new part so this new part is the bit so I have it uh here I'm going to show it to you um oops wrong button I'm getting back in used to this uh no audio problem somebody told me okay that's good um so this uh part right here is a bit and it can be in one of two states and as you see as soon as I get this thing going these marbles will fall and when they hit this bit it switches to another state so essentially uh if you've ever studied uh a and you don't the whole point of this is you don't need to but I'm connecting it to the audience here if any of you I know a lot of you are maybe current students or are maybe studied computer science or took a Computing course uh if you ever studied Assembly Language or lower level computer you might have computation you might have learned about how what what is a logic gate what is a bit what is a register how do computers store information one of the puzzles in this uses these bit pieces to count right because if they're all zeros and ones you can count in binary and you could essentially program by moving these other parts there are gears there are all these different parts so let's just give you an I've already solved one of the puzzles let's look this is puzzle can't remember it's one of the early ones where basically the input are blue and red marbles and what uh what your goal is is to have a particular output that will land here on the bottom and for this particular puzzle the desired output is uh red blue oh no blue red blue red alternating colors so I think I've set this up correctly I it's definitely which position this in is very important I believe uh if I have it in this position the blue Marble's going to fall down this side and Trigger another Blue Marble which would give me two in a row which I don't want so I've got to flip the bit this way I'm going to click this to start it and here comes the Blue Marble it's going to click this which will send a red one ah and the red gets sent to the other side I did it oh so first of all this to me is like the most satisfying sound ever and I'm going to let this play while I go and look to to see if there's some other things I want to tell you about this machine um right so uh I had some notes here so this is a computer it's turning complete so any process that you could do on your computer on your phone you could actually program on this I mean the limit here is the fact that this space is very finite so I only have this much to work with but what's really exciting about this is just how that like explodes your mind to realize that if I if if we had an infinite amount of space for this contraption um we could really program anything all you know you could have a chat GPT could run on this basically uh um let's see so the other thing is there is something called the Turing Trust which was started by Alan turing's family uh strives for a world of equal opportunity with technology enabled education for all um and a portion of each purchase goes to support the Turing trust I wanted to um remember this so upper stories model makes this game is endless curiosity they have other games there's one called spintronics um but really like for me what is really exciting about this is just the one is the pure satisfaction and joy I have from like watching the uh the mechanical nature of this play out um you know I I if I I really want to just put all the marbles back and look we got red blue red blue red blue but the other thing here I think for if you if you if you work in education if you just want to learn yourself if you know a uh a young person or who is just getting started in Computing wants to learn more about how computers work how does counting in binary work how do like the lower levels what do those transistors really do in a computer this and it's you know holiday time this is the perfect gift I would say so um uh if you're interested uh there is a link in the video description um if you use the code coding train all caps one word uh that will get you 10% off uh purchase of the Turing tumble uh certainly if you do end up getting one and enjoy it I'd love to hear from you hear about what your experience is um let's say I thought maybe we would do one one puzzle um the one that I thought might be kind of interesting to try uh let's see here while we have a little time um the Arya ask you for the link it's in the video description um I I should uh post it right and and Kathy writes reminds me of The Game of Life as a computer which I also think is a really apt uh analogy and it's in many ways it's like perfect that what I want to do is the wolf from s automata today maybe as a coding example because you know I was thinking like oh this is just like the wolf from CA which is this system of uh cells that have a state zero or one and the the cell state is basically determined by its neighbors which is in many ways what's playing out there okay uh Dustin says I like the graphic novel style of the manual I do as well um so let's see so let's look the one that I uh pinpointed I thought might be interesting to do would be challenge 18 um I've done all the way through um can't remember where I got to I didn't get up to challenge 18 yet but this is one the reason why I thought so I'll just read you challenge 18 entanglement if the top bit and the bottom bit start pointed to the right put a marble in Interceptor T otherwise put a marble in Interceptor F so this is like programming and if statement essentially so the way that I need to do this um so um I'm let me put this back over here and I'm just going to bring the book with me uh and um uh just in case I need a reference uh here so I'm going to take ah I'm very clumsy I'm going to take all these off how much is my bald spot showing very selfconscious uh let's see uh okay oh my back oh okay I'm okay everybody all right um now uh looking at this oh these are not supposed to be there so what I need are the setup is I need two bits I need another one of these where are my bits oh here they are and so I need another one uh direct two below goes here uh this is what I'm looking at as my reference for the puzzle and then um I need a true and a false these uh these are called the inter receptors I believe so they will stop the marble from reaching the bottom that's one thing that's too bad about this puzzle but the first one really showed it is the whole thing just goes so this one goes now here and this one goes here okay I think that's right yep so now I need to figure out if and um you know I don't I I don't I I can just put a few up here so what I want is if the top bit and the bottom bit start pointed to the right put a marble in true so this with this starting point the marble should land here which I first assume I need to catch it like to for it to come down so this would catch it coming down then it would click here go like this so I think I can just catch it coming this way you can try to play along with me here and then it should oh wait a sec no no no I think I have to do this for it to then come down and drop is that oh wait is that enough oh no because I want to drop it in ah they're both pointed to the right so I want to drop it here comes in here then I catch it here and it should then fall in there let's see if this is right so now them both pointed to the right yes okay so I got a true now am I doing and or or we'll see now uh now if if they're to the left if this one's to the right now it should go into false anything else is false so basically I'm doing an and operation this is like programming an and operation because if both of these are to the right it should fall in here if if either one or both is to the sorry pointed to the left which is like on I would say they're both on I should get true if either one is false or they're both false they should go here so certainly if it's pointed to oh wait no no no I did it wrong again no point it to the left yeah yeah yeah yeah so this is going to get it this way so now how do I this gets it point it to the right pointed to the right is on and they go into the true so now if this one's pointed to the left I can easily just take it this way uh uh no I wouldn't want this to happen so I need to take it this way I think it'll go there and then this will fall this way way can I then just catch it here and then catch it here will this work okay so now let's Point them both this way and let's see okay so I got it there but now what if one is pointed to the right well this work yes okay so uh and then what if this one is pointed to the right but this one's pointed this way what's going to happen that should be fine because it won't it won't activate this so I think I did it correctly let's put a few more basically let's just prove uh let's prove that this is a and operation okay so I just how many possibilities are there four true true true false false true false false so let's do all of those and see if it works so this is true true correct this is now false true wait no no no true false true false correct this is now true so this is now false true correct and then false false would be this beautiful all right I did it so this is what I mean I mean I don't know maybe this is not that much fun for you to watch but I can tell you with genuine excitement and enthusiasm that this is really fun uh to do so um so again I will I'll wrap this up here um check the descript check the video description there is a uh link there it's uh you know upper story.com Turing Turing for Allan Turing I got to find my photos of when I went to Bletchley Park that was in 2015 I went there twice so I was in London for like a uh for like six months basically and I went to Bletchley Park and I was like I'm going back here again I just like everybody who came to visit me i' like I'm taking you to Bley Park is really there's a computer Museum there it's fantastic um but you know if you can't go to Bley Park this Turing tumble will get you get you that a little bit of that feeling of like what it is to work with a you know analog mechanical computer um so go to uh upper story.com Turing tumble you can use the code uh coupon code coding train for 10% off and I'll check the link in the description okay um the audio is usable the pops are really annoying yeah audio pops okay there is some audio issues okay so um I am going to now see what I can do to fix my audio issues one thing I will do is uh mute myself first all right let's see if that resolved it uh okay so one thing I I did a few things and one thing is I have muted the uh audio that comes from my um uh the the like music and sound effect stuff because maybe the audio pop pops is coming from there and they're very rare uh the desktop is fine so all right so um hopefully that is resolved and we can move on let's look at so actually before I move on uh it's 1145 am I still I'm I'm not muted anymore okay um so what I would like to do is put a pole can I do a poll from here here start a poll okay which what should I code wolf from 1dca or uh transformers. JS uh embeddings cluster uh this is AI example do it this way all right all right so I put a little pole it's coming from the lapel mic someone says still hear them well other thing I could do is just uh clip this to a different spot let's try this now and see if that fixes it oh sweater rub okay so my I clipped it to a different spot and actually let's get it even further away from the sweater which maybe unzip this a little more all right let's see if that fixes it I'm moving a little bit slow okay uh well that means I can turn my uh music thing back on just in case uh all right so we're going to see um what's happening with the pole I'll let that run but while I do that I would love to show you let's look at some things that were have been posted recently from uh passengers of the coding train so I'm going to go to GitHub um uh coding train and we're going to look for the um uh coding train logo uh and so this uh if you um oh and you're not seeing it so let me come back here um so uh this is a particular GitHub repo that has a P5 sketch that renders the newest coding train logo this little like asy art like simple drawing of a train um and if I click here uh and run the sketch in uh P5 you can see that the logo is there so this was something that I set up for hober Fest as a way for people to make their First open Source contribution to this uh repository but uh uh certainly this is still open for contributions and um there's more information here that you can read about and how to submit but I'll just show you a few of the things that people made so this is the uh an animated logo uh made by deom basically took that P5 sketch and animated the paths of the different you know parts of the train uh this is a 3D printable coin which was created by Dan The Lost sorcerer so uh I don't know is this actually 3D printable does this thing exist uh um this is a repo about it yeah looks like there's a a model file uh there's some like code here which looks like it's written in some other like language that I don't know for doing a 3D modeling and Extrusion uh so this is really one I I didn't see that this was like fully documented in such a wonderful way um and you can see this here so I don't know if anybody actually 3D prints this I would love to see a photo of it wow we're really uh we're really at 5050 per here this is not this poll I might just have to decide myself f i famously I like to do whatever the opposite of whatever the poll says um okay and then we have this moving with smoke from Kathy so this is animating the uh coding train I would say this is probably using the particle well I don't know if it's using it but certainly has the same visual behavioral quality as the uh particle system example uh Kathy also made a 3D uh logo this is using P5 geometry so if you if you've been paying attention uh there's p5js version 1.8 is now out and P5 J version 1.8 has a lot of new features particularly around 3D uh P5 geometer I'd love to do some tutorials and videos around P5 geometry and then are also a bunch of ports uh a Java port to processing and a python Port um and did I miss anybody's uh there's a couple issues here let's see just talking about the port the brainstorming list I don't see any poll requests so if I miss anybody's please let me know um in the chat oh lost sorcerer is here in the chat haven't printed it yet but will soon so lost sorcerer when you do print it uh please let me know I don't know share share it as a pastor showcase project a photo in this repo on social media wherever wherever things can be shared these days okay let's go now to the coding train.com whoops and let's talk about what's new there so but um and then I'll take a short break and we'll do some coding for a full hour in the second half of this live stream okay so first of all uh coding Train website if you have not uh had a chance to visit it uh what are you waiting for uh this is where you can find um all of the coding challenges actually I just realized thank you to Kathy who does a lot of work uh helping to maintain the website and I realized that um Kathy had updated the featured uh passenger showcase projects uh and challenges so let's merge this right now so that will appear live on the site momentarily uh um and I can talk through what is on the website so you can see the the pro you know the the most watched consumed content is anybody a Patrick Williams fan here we got any Patrick Williams coding train crossover going on Patrick made an amazing uh video about the word content and so I'm constantly thinking about it and finding myself saying content and like having this like sickening feeling inside um but uh in terms of the videos and material that I made these coding challenges have been the sort of longstanding heart the Beating Heart of the coding train and it used to be the thing that I had like a new one every week sometimes two per week but I I kind of just I don't know some someday I'll get back into the rhythm of these again but there's only been uh three in 2023 um hopefully we'll get in at least one more uh last 2022 I was really focused on doing some apple basic stuff but if if if you're new to the coding train hopefully these videos can still if you had had a chance to watch them you can find project ideas and inspiration and for any of them like if you decided you want to for example look at the colot conjecture video um you can find the uh code for it uh any reference materials here and then the passenger showcase so for example spectral piano made a colat BB in 3D so look at it it's like a Col because it looks like a chicken or an eagle that's really cool it's made in 3D so this is where people will share their projects and if you're on the website and you go under the guides um there is a guide here for uh the passenger showcase and a form that you can fill out and submit but did I let's see now if I go to um and if I go to the Showcase page itself this is just like all of the passenger showcase projects and you can page through all of them would be now I think is the time the website settled in a bit would be nice to be able to sort these by other uh means but currently they're sorted by time or you know I could go to any particular U I was looking to see if lost sorcerer uh is not on here but I know that um you know Cathy's page is usually the one I go to as an example you can kind of collect all of your showcase pages in essence like it's not this is not the intended behavior of the website but it's a little portfolio page uh for you okay so let's go to the homepage and we'll see here uh if you uh happen to be watching right now and you've never programmed before and you want to learn the basics um or if you more shaders web gel content yes Nicole um I would like to that's a great goal for 2024 um and you would like to learn to code or maybe you know someone in your life that you want to share your love of coding with um these right now on the home these featured tracks are the two beginners ones uh code Cod programming with p5js are all of my beginner tutorials of programming in JavaScript with P5 and I more recently made a video uh about um learning to code with processing um and this is actually instead of being a sequence of videos It's actually just one five hour full course um that you can watch so those there's there uh featured challenges uh here and then let's look at some passenger showcase projects that have come in recently are curated by uh Cathy so I don't know if these are the new ones yet we'll find out maybe we'll get to look at it so let's look at this bouncing ball from Mauricio Fernandez look at this okay so first of all uh Space Monkey if who you maybe go by Mauricio fantastic work so this is one of the challenges I give in the beginner course so I'm guessing that maybe Mauricio just learned a program we should all give Mauricio a huge round of applause good job for learning to code and one of the first things in my video courses that you learn is how to make a circle bounce around a canvas uh a changing direction each time it hits the edge and it looks like Mauricio here added a wonderful new feature uh which is for it to change its color every time and we can take a quick do a quick code review here we can see that Mauricio has some Global variables I should really be logged in let's log in here as the coding train I usually like to go into the high contrast mode um and make the code a little bit bigger um we can see here that uh look I I just to me also like nothing makes me happier than seeing code comments in another language so that is really wonderful uh I love that you're using your native language also for variable names um and you can see here that uh based on the bouncing a new random color is picked and that random color is used to draw the circle okay here here's my quibble here's my it's not I wouldn't call it a criticism it's an opportunity this is my uh um um I uh uh this is my pet peeve you know I'm having trouble reading this code because of some of the indentation so you can see how the if starts here then the what's happening in the if block is indented over here but then this this curly bracket it just wants to be it wants to be right here so badly we just want to like pluck it move it pluck it move it can't can't do it but guess what oh thank you P5 web editor edit tidy code edit tidy oh no what's going on wait what's going on here why is it not tidying the code oh it did it now I must not I don't know what just happened some temporary glitch but now it tidied the code and we can see to me I know I know I'm being silly and it seems silly but these are the kinds of things that over time uh help me to add a glance under understand how code is structured and what it's doing so even if it doesn't really matter for the end result uh developing a habit of uh of you know a style that you conform to whether you prefer the spaces or the tabs or the two or the four all of that is welcome here we are a tabs and spaces inclusive community here on the coding train but I do think it's helpful to conform to some of these standards to help readability but I would really commend you on putting comments into your code on the way you named your variables and just getting this to work um great job Mauricio okay let's take a look at this um one of my favorite algorithms is the flowfield algorithm and we can see here that uh Ador coding which is a great GitHub name uh oh look at that that is wild so this is using a flow field as well as maybe the Direction I I definitely have said this these words to my students in class of like what if you took a flow field and had the direction of the vectors be related to the pixels of an image and uh perhaps even a video here and you can really see that uh happening in this incredible project I I guess is it actually taking this image of the Mona Lisa or is this a live video I'm not sure um but this is really F and by the way excellent documentation to have a readme that sort of explains what's going on has an image in it this is really really fantastic work I'm wondering what the sine wave is I guess it just maybe the flow field follows something of a sine wave uh when it is um not part of the the some pixels that are part of a mask or something like that we could dig into this more but I think just looking at it as an inspiration is wonderful great work to Ethan from ador's coding this is really hard got to get my regular train okay terrain generator with open Simplex noise open Simplex noise another one of my favorite algorithms ah I've been seeing a lot of these so this um uh uh this um this is uh I've been seeing a lot of these like people making little uh renders their generative art sketches their P5 sketches and posting them as YouTube shorts so this is what I was thinking of doing for the January month um but you can see here I love this idea so open Simplex noise is a particular noise algorithm with smooth Randomness and it can exist in different dimensions and to me what this looks like is it is twodimensional noise but the noise values are being used to extrude the height of a 3D in a sort of 3D terrain um and so this is quite similar to if you wanted to if you wanted to learn how to do something like this where do you get started with this um if I went to the coding train.com under uh challenges maybe search for terrain I can see it updated now the new feature challenge is updated under terrain generation this is my coding challenge video with uh building a oh look at that look at that young man there no back problems uh I mean I don't know I think the silver is quite nice fetching did I just did I use the word fetching to describe myself that was that was not a good idea um I'm getting a little I'm getting a little woozy the talking straight for an hour it's time for my break and time to do some coding how's that poll going oh wow 51% on the wolf R so we're going to have to see I might I might go with the Transformers JS honestly if there's not a huge uh uh um you know movement towards the wolfrom stuff okay so thank you for sharing that to uh Al ala LZ and I apologies if I'm not pronouncing by the way I say I often pronounce the name then I say apologies and I genuinely mean for if I am saying your name uh whether whether I got it right or wrong I would love to hear from you either to say like yeah you pronounced it correctly thank you or um you know this is how you pronounce it you can send me an audio file a link that way as I get to know more names I'll I'll get better at it okay uh let's see what do we got here let's refresh this page and we have three more see that was the lucky lucky uh thing about not um not merging that polar across before I started let's look at three more reaction I'm going to go through these kind of quickly uh so we can get to taking a break and doing some coding reaction diffusion heart shape so one of my favorite algorithms is reaction diffusion also a coding challenge Challen challenge coding challenge challenge and looks like this is using the heart the Contours of a heart as the initial values a reaction diffusion algorithm you can think of it as like this almost like petri dish that I'm like pouring a chemical into one spot and it propagates around that petri dish really this works like a sou automata each pixel has a state and its state changes based on its name neighbors and we can see what emerges from a heart uh thank you enor this is wonderful I think I already commented here so I was going to comment on it again but everybody give give uncore oh look at this I thought like maybe the heart will be lost but we're really getting the heart back here uh okay uh pretty interactive double pendulum from Haron let's take a look at this wow so this is a whole like interactive web page and I can I can change the mass of the different um Bobs I can alter their length and I can play with the gravity let's make gravity really strong and oh we got to have the trail the whole point of the double pendulum is to have the trail so maybe I need to make these later how can I get it to swing much faster can I grab it this is really awesome so let's refresh it and let's turn the trail on and yeah so this uh so one of the double pendulum is one of these incredible chaotic systems uh that you know I have a video which goes through the sort of motion formulas to model it um you can also kind of create one with a physics engine like MJS maybe P5 play um but the trails that it makes are just I find them to be quite beautiful and surprising um Etc all right um two questions I'll answer here that I see in the chat Viking the dude says is Daniel on Twitch primarily streaming on primarily not doing very much these days to be perfectly hon thank you to all of you who support the coding train even in this uh like reduced amount of content if you will um I do have a Twitch account I was using it for a while I was going back and forth I probably haven't streamed on Twitch in well over a year if not longer so Never Say Never but not using twitch too much and then uh sadra is asking about MD and thank you to Lost sorcerer who is answering it it is a markdown file a particular kind of format for uh creating a document um and it's it's it's a standard across a lot of different um systems and GitHub uh GitHub uh uh readme files text files documentation files usually use that markdown format um okay so um I'm gonna take a break now short break I will remind you actually what I should do is I should take a break well it's like we can use the uh Turing tumble as like oh this is the wrong oh look this is the top of my uh coffee um I can't this is me with the green screen I think my lights might be a little bit bright today I don't know I I can't ah there we go t no wrong screen again whiteboard there it is um just remind you of why taking a break if you want to take a look at the uh upper story.com churing tumble uh thank you to the sponsor of today's episode Link in the description uh the coding train code will get you 10% off if you missed my segment earlier in the Stream you can go back and watch it after the stream is is over uh to see me playing around with and enjoying the Turing tumble so I am going to go to my intermission screen um uh nor Muhammad shigar asks for a neural network series there is one it's recorded quite a while ago but if you want to just learn the basics of A Sort of vanilla neural network it's all there for you you can find it maybe somebody in the chat can help uh uh I I think it's even on the coding train.com under a track um but let me put on a little bit of music to take a short break and when I come back uh in less than five minutes I will program I think I'd like to look at transformers. JS so um I think that's that's what I'm planning to do right now all right I'll be right and we're going to make some we're going to make a clustering example um okay I'll be right back short e all right I am back I turned the heater back on I noticed it's getting quite cold in here um and uh it is 1210 so um it feels very the heater feels very loud to me but I have a feeling it barely comes through for you so let me know if there are any audio issues you have in terms of hearing me I also haven't heard from anyone that the popping or rubbing sound that I think was happening because of the way the lapel mic uh the LA M was rubbing against this sweater um was occurring so that seems to have gone away but let me know I'm I'm I'm also been a little weary I think the cold I didn't realize how like cold it was getting in here so my energy is like I took that break my energy is a little bit low but uh hopefully um things will warm up in here and I am excited to talk to you about um some new stuff that I have been exploring with my teaching this fall and I would really like to I just it just hasn't happened but in an Ideal World I would been making video tutorials all alongside in parallel to the teaching I was doing at NYU which is what I have done in past years but the nature of code book I that's been like I'm like teaching my new material at NYU and then the time that I'm not teaching that I'm working on the nature of code book so in past years I'd be teaching my new material at NYU and in the time when I'm not teaching it I'd be making videos on that same topic and that seemed to work well it just it isn't happening but um we'll see the truth of the matter is this the landscape of what's possible with a lot of the new uh uh techniques and Technologies for generative text which is what I'm exploring in my class this semester is all changing so rapidly that you know I don't know to what extent making a lot of videos would be that useful anyway but um I might as well give you a little peek into that during this live stream and if there is interest uh I would love to come back and do more uh content about it so where to get started um so um there is a GitHub organization called programming from A to Z it's not an actual organization that's just what the thing is called on GitHub and um that's where everything is for the class that I'm currently teaching and um you know the syllabus from for that class is under here um and I can just kind of like uh look at it an overview of it um and if you were to go all the way up to uh week eight this is all and I I realize my desk is really is it higher than it usually is I'll just bring it down a little bit although that might cause me other sorts of issues but um uh if you go through all the way down through week eight these are things that I've actually already made a lot of videos on uh all the way back to like 2015 or 2016 I think when I did a lot of these videos uh if there is two weeks here that I spent in my class where we looked at different social media platforms that you can use their apis to create a bot and in particular I focused quite a bit of time on Discord Bots and uh in case you happen to miss that and you're interested in um learning how to make a Discord bot um the most recent new video that I made which was just in the last month um which are here are uh well one is coding coding a Discord bot so if you if you've ever wanted to make a Discord bot you know a little bit of JavaScript a little bit of programming this video will give you all of the basics to get your first bot up in running if you've never oh and Thomas P thank you Thomas P I am going to uh tell you about videos that I um uh but if you've never used node before then this video will also uh go over how to set up node project and one of the things that I did in that video that I haven't covered anywhere else is looking at es Imports so if you've never used import statements in node that is helpful for you and then a little bit of an update I can't my arm won't extend all the way over there about some of the workflow tools that I'm using terminal shell vs code Etc um I mention these mostly because I you know not that I pay too much attention to this this my um but uh um the uh law sorcerer sorry let me get to your question if you tag me in Discord and I can answer it there there there I yes yes is the answer but um I have to dig it up it's like a a a PO Box type thing um these videos were very uh barely watched which is very understandable because they're meant to be resources that you know at any moment in time you might need like who's waking up in the morning to be like what am I going to watch while I'm eating my breakfast I don't know how about coding a Discord bot but I do mention in case people didn't see them and are interested and want to kind of like Mark them for watch later or go back and look at them uh feel free to okay so it the thing thing about the heat is even though you're not hearing it it's very loud in my ears and it's causing me to talk very loud which is I think putting a strain on my voice but I'm gonna just try to uh be more mindful of that um so so I do see a little bit about uh uh mentioning that there might be some issues with the audio so if if other people are having audio issues please let me know okay so back to this now the new stuff the new work that I've been doing just in the last few weeks is making a set of examples and content related to working with Transformer models so what is a Transformer model let's just talk about that a little bit okay so for me predictive text all starts with this idea of a marov chain it's going to take me a while to get to where I'm going but I feel like this background is important so this idea of a marov chain uh is not related to text a Markov chain refers to any a a sequence of States weather could be a Markov chain raining Raining sunny sunny sunny raining sunny sunny Raining Raining snowing raining raining right that is a Markov chain and the idea of a Markov chain is given a history of states or just the previous state could you make a probabilistic prediction of what the next state would be if it's been raining for four days in a row is it more likely to be raining the fifth day or more likely to be sunny and if we wanted to we could do an analysis but if we wanted to use a previous analysis to generate uh fictional weather uh we could basically analyze historical weather look at the probabilities of how things happen in sequence and then generate new weather sequences based on those probabilities and that's what's happening with a Markov chain with text so if I were and if I were to an like think of each word as a state or maybe the previous four words as the state I might say uh you know what would come next well maybe there is an % chance that the word hat would come next maybe there is a 20% chance that the I don't know I was G to say litter box but that's two words so I'll just say litter I don't know where is the cat in the lit hiding under the washing machine I don't know what would come next but you could imagine if I were to analyze a huge Corpus of text that was so large that the cat in the that sequence appeared hundreds thousands maybe even millions of times and then I just counted let's say it appeared a 100 times and 80 time it appeared 100 times in the Corpus and 80 of those times hat was next and 20 of those times the litter was next then I could use a Markov chain to generate TT now if I could like magically make post production things appear I would now put up my marov chain coding challenge video where I go through and program this whole thing the that video I actually treat each the state as a sequence of characters not words but you could have you know Word level character level now so why am I talking about this because I want to for a moment it's a very large leap like I want to go from this idea of a Markov chain all the way over to this idea of a transformer model so Transformer model is the Deep learning neural network architecture behind systems like chat GPT uh the Llama model and many many many many more examp examples I'm just picking like two that you might have heard of the reason why I like to make this connection is with a marov model right we would essentially create a giant table a spreadsheet of every possibility and then we could be using all of those probabilities to generate new text a deep learning model is so big essentially the data like we couldn't realistically build a Markov chain out of the entire text on the internet now first of all we should really be asking the question just because we can should we build Transformer models that are essentially trained with you know 10 years of chewed up internet and it's not as simple as that and there's lots of thoughtful people doing a lot of work uh that I'm um I don't mean to trivialize um but I do think this is an important question of you know just because we can H make these sort of ideas bigger are they necessary neily better what is the social impact what are the harms all these are important questions but for I do think it's relevant these things are out there for you the person on the internet to understand a little bit about how this stuff works and what it's doing so how do I make this connection I drew that line I want to try to make this connection I'm also like sort of keeping an eye on the chat over there to make sure there's no like messages put some siren emojis not don't put them in there put them in there if there's something wrong don't don't troll me I I know you internet audience I'm only looking at the Discord chat okay so first of all the Transformer model and I'll point you to some resources that do probably a much better job of explaining this than I will and I'm going to just handwave most of it anyway the input if I had the Cat in the Hat what a Transformer model does it it's it this is the input and the same the output I'm oh no hat the same thing like eventually somewhere I want to get this idea of the predicting the next and Transformer models don't actually use words or characters they use as the individual chunks they use something called a token and you can read a lot about how is text tokenized um and you know probably like in and the are full tokens but if I had the word uh computer maybe computer is three tokens or two tokens comp uter or computer or comp UD compot I anyway you can imagine it's not exactly like syllables it's uh there's there's different techniques for tokenizing text but for the sake of argument let's just imagine that these were the tokens now the idea of a deep learning model and this goes across the board for most neural networkbased models is they exist because the the the spa the solution space the probability space the space of the data is much too large to encode all of the information like with a markof chain I might literally have a spreadsheet again that has all the possible sequences and all the possible out you know inputs and outputs a deep learning model basically takes an input and then estimates an output and you know you could go back and look at my videos on neural networks and all sorts of other material but the idea here is each one of these the reason why I'm getting to this is each one of these tokens uh well there's multiple steps that are encoded uh first but let's just uh skip up some steps here and sort of think about them as an embedding so and let me come back to the computer for a second I'm kind of jumping around here and I don't even know if uh I don't know what people are talking about in the chat but um so um one of the a video that I made many years ago let's see if we can find it uh this two 2018 I talked about something called word Tove and word to VC is an embeddings model essentially where every word is tie to a list of numbers and embedding is a fancy word essentially for a list of numbers and there's a terrific resource from Allison Parish um that I believe I linked to here on my syllabus week about embeddings um along with those uh which is all about understanding word vectors and thinking about like this is a really nice example of okay what does this mean well what if how do we turn words into numbers well what if we created we measured every animal based on acuteness and a size scale and then a lobster is essentially the embedding 2 comma 15 and a mosquito is one comma one like very small not very cute and very very small color is another really practical example of how words the color red can be associated with numbers 255 Z and I could do if numbers I could do mathematical operations with that means I could say red plus BL blue red plus Bo red plus Buu I said it again red plus blue 25500 plus 255 that equals purple so I could actually do things like dolphin plus crocodile equals 65 comma 95 and that's kind of like an elephant 65 comma 90 dolphin plus crocodile it's kind of like an elephant we learned something new today so this is the idea um and uh so neural networks basically the idea is that if all of these each one of these words can be turned into an embedding then those embeddings can use like positional encode and some other kind of like stuff to be made into like a single embedding and I'm totally like uh skipping a lot of steps and oversimplifying these can go into deep learning layers numbers are the inputs into a neural network and the there's this whole thing about an intention layer uh and then just a regular old fashion feed forward uh uh a neural network layer um so and there's multiple of these but ultimately this ends up predicting and embedding which is that next word uh which is tied to what that next word that should be in sequence so again I I should probably pull up like a a more thoughtfully done internet diagram of this but I wanted to briefly leaving myself some time to do some coding kind of establish this connection so to me I'm interested in Transformer models for a variety of different reasons but a primary reason is this idea of associating text sentences words paragraphs with numbers so if you've ever heard for example of this technique called retrieval augmented generation a rag if you will it's kind of unfortunate terrible name this is something that I've been experimenting with the nature of code book what if I could take a question what is a fractal turn that into an embedding a bunch of numbers search through all the sentences in my book and find all the sentences that have similar numbers I could cluster a DAT a cluster text based data I could search for answers I could do like a question answer search so there's all sorts of outcomes that could come from that and I would like to make videos where I maybe slowly talk about this stuff some more and go step by step through it I don't know maybe it'll take a minute to see if there's some questions in the chat that I could address but ultimately um what I want to focus on right now is not the use of Transformer models to generate and predict text um but the concept that's inside of Transformer models that's very critical there are other models that are trained just to associate embeddings with text um what can I do with that okay dolphin plus crocodile equals shark says Zachary okay so I'm coming back over here um and we're going to I swear we're going to do some coding I'm going to turn the heater off because the noise is bothering me even though it's not bothering you there it won't get too cold in the next half an hour okay so I am going to uh so I have a whole bunch of examples that I've been working on let's go to my Transformers .js examples I don't know if uh this is up to date uh okay it was no I don't know what's in here I have passphrase here I'm not sure why okay so um I am going to uh I'm gonna make something new but I just wanted to um kind of like have this available okay um so what I would like to do actually let me just run this example for you because and the reason I'm not doing these in the P5 web editor is they require some larger data files and some other things that are kind of tricky to do in the the P5 web editor but let's just see if this works it's going to take a minute because it's got to load the embeddings model from the internet okay so what this example is doing and I I might want to like try to build this a little bit but what this example is doing is it has these uh five six sentences what colors the sky what an apple the sky is blue what does the fox say an apple is a fruit I have no idea and so what I'm doing with each in this example is I'm taking each one of these senses and turning it into an embedding and then I am calculating essentially a similarity score and we can talk about the what algorithms you can use for these similarity scores but basically I'm looking for how similar are each one of these sentences to each other and if I look at in the browser one of the things you can see here is all along this is a table all along the diagonal I see a white square because what is an apple which is and I I realize you can't see the bottom here um so let's make this uh like this I'll try to step aside so you can see it better I can move this over even um um here I'm comparing I'm comparing what is an apple to what is an Apple so the similarity score should be one now I'm comparing what is an apple to the sky is blue and the similarity score is 0.078 but what is this one here ah comparing an apple as a fruit to what is an apple I don't get one they're not equal but I get a fairly high score so this is why I'm interested in embeddings it is a mechanism that I could use with my own data so I'm generally trying to lean towards lean into f focus on projects on the coding train that involve bespoke custom you know I'm trying to do a lot of things with nature of codebook transcripts to my videos working with data sets that I have ownership of or a knowledge of uh rather than just kind of arbitrarily uh play around with you know these giant data uh you know piles of text on the on the internet so um even though those piles of we used to train the embeddings model I'm interested in what those embedding models can do for us okay anyway so let's think so what I would like to do now and I probably should have done this other automotic because I don't really have a plan for this is I would like to create a basic example where I have a bunch of these instead of doing this a matrix what I would like to do is try clustering these in other words I want to create a visual world of these sentences where the similar ones appear near to each other there's a lot of steps in between from where I am right now and how I'm going to get there in the next half an hour but let's see what happens okay so I'm going to create a new uh folder called I'm gonna call it clustering and the reason why I'm doing this honestly is this is what I want to teach about in my class at NYU this week so if I could get a little this work done and experiment with this idea um um then uh uh I will do so I see Kathy you're giving me some good notes about some things that I've sort of missed explaining so maybe we could I'm G maybe I'll come back to those as I start to build a code example which will force me to go through things a little bit step by step more slowly okay so let's get uh an HTML file um and I'm just G to borrow this one from here which has P5 built into it um and then let's make a sketch.jpg and I'm going to pull what I need from here so here is a kind of uh an unfortunate truth which will either make you happy or sad depending on who you are so in my life programming and making things in JavaScript in p5js the popping was really loud I don't know what to do about that okay I'm going to try triy moving the m M let me make sure it's the mic and not the laptop I'll mute that it's the only other audio Source going out OBS sorry about the audio everybody um I'm but you know maybe it's the cold I don't know what it is uh maybe it's just that I've been doing this now for an hour and a half and my energy is in but I'm I'm having some uh brain energy issues so let's shake it off everybody as my good friend uh Taylor likes to say shake it off okay now uh so uh what I was getting at is I'm used to importing JavaScript libraries through a script tag in HTML um this particular JavaScript library which is called Transformers JS is only available as a module which means in my code instead of actually putting it in index.html uh I am putting it up here as an import statement import pipeline from the the CDN the content delivery Network where this library is stored so this is the equivalent of you know uh putting like the P5 Library here the difference is instead of putting it in HTML a script tag I need to put it in my actual Javascript file with an import um and if you've never used Imports Before I Do cover these in the video that I just referenced about making your first node project okay now the first thing that I want to do is load a model and I want an embeddings model so and again I'm just pulling code from an example that I made already so the way oh no not the summarizer sorry the way that you load a model uh with um with transformers. JS is by uh through this pipeline function so that's the pipeline function I'm importing from the Transformers JS library and uh you know I could call I'm calling this an extractor so uh an embedding you can think of that as a fe features is another is another related word to embeddings so essentially uh turning text into array of numbers is kind of getting at what are the features of that text numerically speaking and so if I want to extract the features that is what an embeding model does so transformers. has a lot of different pipelines and this is a particular uh open Source embeddings model called mini LM mini language model um and it performs feature extraction now because this uses a sync and a weit promises oh boy is that something you've never heard of do I have another set of videos here to I mean I don't have to sell them to you because you can just watch them on YouTube but a whole set of videos about async and await and promises but what this essentially means is this needs to be I'm going to put this in a function I'm going to call it go you could call it Main and that function uh needs to be uh modified with the keyword async because it's going to have asynchronous code in it like awaiting loading this model it's going to I couldn't download the model files but the transform. JS will go and plck the model from the cloud I'll show you where the list of models are in a second and now I have that model in the extractor variable just to know that this works the next thing I want to do is I want to say uh let's just have a sentence we're going to say the coding train says Choo Cho and I'm going to say the embeddings are uh await extract VOR dot I'm I'm hoping it's going to autocomplete it for me but it's not so I'll go back and look at the example I made before uh which is oh I just I call sorry let me grab this so I totally did this wrong we'll go back to our example that I'm making uh so the output is um I await the extractor I give it my sentence these these are some uh modifications that have to do with how the embeddings are computed normaliz being true I think gives me all the values in the embedding itself uh normalized between a particular range either zero and one or negative one and one and let's just take a look now at that particular output so this is a very basic hello world the pops happen when I move check the mic Kate little yeah I don't I unfortunately I don't really know what to do about this now and I'm so close to being kind of done that I think it is just it's just part of today's stream and I apologize for that but I've tried unplugging and replugging in the cable and doing different things so unless somebody has an idea another idea not sure what to do uncharge no the mic is fully well the mic is the battery is full uh let me try just putting this on the table and letting this not be like underneath my clothes let's see if that does anything so the mic is just here um maybe I'll even just put it over here I don't know this this might be worse but okay let's see if we can get this to run so clustering is what I'm attempting to build here and oh it would be nice for me to call the function go to have it happen you sure you're not just hearing that fly buzzing around let me make sure whoops let me make sure I have a particular setting ah so this is an important setting that uh I that I um didn't notice that that needs to be check which is to disable the cach while The Debs are open so any changes in my code whoops uh reload where am I here yeah uh clustering let's add some console log so we know this is going loading model model loaded let's see what we get okay so now um we can see here in the so okay great so this worked the model loaded and what I got is the embedding the embedding is in data it's an array of 384 four numbers so now I can say output. data let's just take a look at this and there that's the embedding so let's do another sentence we're getting somewhere folks so first of all Let's do let's call this function load model and let's make the extractor a global variable so I can use it around in other places and then I'm going to say uh go is an a eggs sync function that's going to first load the model and then we're going to say um I don't know what to call we'll call it await uh embedding of a given sentence so let's let's make this um I'm I'm going to make something visual here that you're going to be able to play with uh hopefully before before the in the next 20 minutes so this will get a little bit more interesting um and then what the uh embedding function will do call it embedding and it receives any given sentence and it uh returns output. dat so basically I'm going to say the uh embedding one equals await embedding sentence one and uh sentence two will be the coding train says whoops it's getting cold in here again uh and I'm going to get embedding two and then let's look at them in the console all right right so let's see if this works I'm now all I've done is I've loaded the Transformers JS embedding model I have an asynchronous function that sorry I've loaded the Transformers JS library now I'm loading the particular model by the way is the is the ah is the mic static from the sweater I'm only going to be colder now I don't know we I don't want to throw the ground is a little dirty in here I'm going to put this on a shelf here okay yes we're rolling up our sleeves everybody we're gonna make I have sentence one in the second one thank you all right importing fly importing Transformers JS uh loading a particular model the mini LM model which is an embeddings model asking for the embeddings for two different sentences and console logging them let's see what we've got okay so great now uh so just looking let's just look the first number negative 0.05 and the second number negative 0.03 huh maybe these are kind of similarish but here's the thing so how do I know whether these two sentences are similar or not so I'm going to have to put this into my pocket because I walk back over to the Whiteboard to talk about how we calculate similarity between two sentences popping is still there I don't know I don't know what to do I'm so sorry everybody okay so oh my weary bones in the cold in the garage it's whiteboard I need a new studio I don't know okay so let's think for a moment about color let's think about color as a threedimensional embedding so maybe red is the number 255 that's the embedding for red maybe uh Rose uh and I'm going to get this wrong because I'm not good at colors has the embedding associated with it of to um 52 comma uh 10 no let's make that let's take the green zero and has like a little bit of blue in it I don't know if that's I don't know I a semicolon there so think about color as three values well that exists then in threedimensional space I could consider what would normally be the x axis to be the red axis what would normally be the Z axis to be the green axis and would normally be the blue axis sorry the y axis to be the blue axis and so the color red 255 would literally be plotted right there so that's red and then the color rose maybe is here so in this threedimensional world that I establishing their similarity could be the literal distance ukian distance between those two points so ukian distance being the square like in know is the same in two Dimensions would be you know a triangle C equals the square root of a^2 + B2 that is the distance between these two points uh has to do with the difference between their X values the yv values squared and the square root because of the Pythagorean theorem so ukian distance is one way to calculate a similarity score let's go do that so I I say this because sometimes you're like oh what what crazy math Vector Library do I now need to do what I want to do you don't need anything because I am going to say uh let's get the sum of squares is zero let's go through the entire in embedding and the difference is embedding one minus embedding zero oop sorry embedding one index I minus embedding two index I obviously you know we'd want to be in a larger system we'd want to do this a bit more thoughtfully and then the sum of the squares plus equal difference time difference and then the ukian distance is is the square root of the sum of the squares so now let's look at and let's look at the similar a similarity score between those two sentences people are still talking about the pop I'm so sorry I can put my sweater back on well I'm I'm I'm running out of time I want to get to the I want to get to the grand finale here so okay so we're we're getting somewhere with this idea of embeddings okay what did I square root is not Define because I I'm just kind of imagining using P5 so let's do math. square root okay so look at that I got a similarity score a distance of 62 remember that those two sentences were 062 units away in 384 dimensional space because this particular model returns an embedding of 384 numbers okay just to prove the point here what if I change the sentence so the coding train says Choo Cho and uh I love oatmeal for breakfast I'm assuming that these two sentences are going to be further apart than 62 we're about to find out I have not tried this but let's see you know know in my mind those two sentences are now more different than the previous two but let's see so remember I got 62 for uh the previous one let's let's see yeah 1.33 they're further away so even just this basic and this is happening just just in case you're wondering my there's no Cloud stuff happen I mean I am loading the model from the cloud but that model is running on device in JavaScript in the browser so I've done a lot of videos on uh tensor ljs and um ml5 JS I'm really interested in tutorials and educational material around on device uh machine learning where you're uh where there is no required uh cost to like so you watching this I could be doing a similar demonstration with the open AI API where you would send your sentence to their API and you would get embedding back it might be more powerful in certain ways I mean it certainly is in many ways but it would require you one to send your data away whatever those sentences are as well as pay you know a cent two cents three cents for that now again I'm not some like pure soul I mean I'm using all these apis and cloud services all the time but I do think this is why I'm choosing right now to work with Transformers yes it just runs right here on this laptop in the browser um and oh thank you Fatima for you I see that people are giving me some super chots which is very kind uh unnecessary but very kind um okay so I now have I'm showing you a distance now the truth of the matter is ukian distance is not typically used for high dimensional spaces and let's talk about briefly why let's see if this paper towel Works a little bit better I don't know what what I've got here let me wet it oh I have like little wipes okay let's try this um okay so why are why is ukian distance often not used well think about 384 Dimensions what if out of all of those de oh and I didn't press whiteboard don't worry everybody I know you're going to tell me this in a minute what if in that high dimensional space that 384 dimensional space all of the values all like 383 values were really really similar but then that 384th value was wildly different well ukian distancewise you could end up getting a very big number for their ukian distance just because they're very far apart along one dimension But ultimately we want to consider those things to be very very similar so another way that you can compute distance is referred to as cosine similarity and there are many uh wonderful tutorials and videos online about that algorithm in particular I don't have a lot of time here so I'm going to give you like a sort of quick overview of what cosine similarity is so let's uh let's just look in a twodimensional space um and I'm going to uh have these points right so you can see like ukian distance wise um and and obviously two Dimensions like ukian distance might be better than cosign similarity but you can see like this point is kind of same distance from this but let's let's think about uh if I were to basically take from the origin a ray or a line segment out to all of these points another way that we could evaluate the points is by looking at the angle in between these vectors essentially let's connect Back To Nature of code right so look at these these two points even though they're kind of far away have a very similar angle these this point and this point that angle is quite large and think about this what is cosine of0 cosine of 0 is one so if the angle were literally the same they would have a distance a cosine similarity of one being equal essentially if that angle is very large the similarity score is as it goes to you know 90 deges is going to approach down to zero so 180 degrees yeah so you so that's the idea of cosine similarity and in highdimensional spaces you know again our brains can at least mind can't think Beyond really three dimensions but in a high dimensional space if you're looking at that angle that cosine similarity essentially that you know analog of this twodimensional angle in that high dimensional space that's going to be generally a a a fairly good way of knowing if two embeddings are similar to each other okay so how do you do cosine similarity uh let's come back to here I have one more thing I I'm gonna be going a little bit over probably because I do want to finish this example um so uh all right so first of all I forgot to tell you about the nature of code book uh the new edition it's going to be at the regular nature of code website soon enough but the new addition that I've been working on for you know I would say over 10 years but really in Earnest the last six six months to a year um is uh here and actually it's so happens that in chapter five uh under the path following uh segment I have a whole section in the book on something called The Dot product and the dot product is related to cosine and is actually a way that you can calculate the Ang angle between two vectors so you can see I'm doing that in this particular um example that's in the nature of code and so this idea of getting the angle between two vectors uh and then taking the cosine of that angle extrapolates to higher dimensions and because I'm kind of short on time right now and I want to get to the clustering that I want to do what I'm going to do is just go and grab the formulas so these are the formulas that I made for a previous example and I'll put them here into this example that I want to do with clustering so you can see here that essentially I'm using higher order functions but the magnitude also sums up all the magnitudes I use the dot product which I cover in that nature of code chapter you can go and read and then cosine similarity is the dot product of the two vectors uh divided by the you know magnitudes of the two vectors multiplied by each other and that's going to give us the cosine similarity so I could instead I could look at uh let uh similar I'll just call it similarity equal cosine similarity of embedding one and embedding two and let's compare let's see what we get now remember it's going to be inverted like the smaller the ukian distance the more similar the higher the cosine similarity the more similar because the cosine similarity between zero and then one um okay and so uh similarity let's just look at that and see what we get oh what did I similarity similarity know what I'm writing similarity oops my fingers are are getting cold okay here we go okay great so those sentences aren't very similar I got a score of 0.1 what if I go back to uh the coding train says whoops and really these are the you maybe come up with better examples but we should get a lower ukian distance and a higher cosine similarity and that we did yay okay so this was me talking about what is an embedding how can I have an on device machine learning model give me an embedding for any arbitrary amount of text and then how can I compare two different arbitrary amounts of text so what I'm saying to you is what can you make with this could you something that I would say like that you could build now is you could make a chatbot which has like 100 different possible answers and when somebody asks a question you look you take at the embedding of their question and you find out of those 100 answers which one is most similar to that qu question and you give that one back so that could just be something that could be like a hello world demo that you could do just to kind of get this idea um I also think that I should mention uh I kind of glossed over this but uh if I go back to transformers. JX yes there's a lot more um you know tutorials and information here about how you can use this particular JavaScript library and then this is um uh you know the tasks are really what um I'm kind of interested in and um the model that I am using where is it is it I'm looking for what feature or yeah feature extraction so I'm looking for a model that can do feature extraction but there are models in Transformers JS that can you know convert to caption an image can do object detection all sorts of other kinds of things so you might sentence similarity is is basically doing what I'm doing here but it's doing it for you without the uh you know having to compute the the the distance score and all of that so there's a lot of other stuff that you can do and what you can see basically is that you create a pipeline like if you want to do sentence anal sentiment analysis you you have to specify the task and the model you want and so uh and then if I know that I want to do like I have an example that does summarization that I want to do summarization if I click on this I think this will give me the models that I can use that are compatible with um with that so anyway I'm not this is not an overview of everything that hugging face has to offer and how it works but I just wanted to show you the landscape of where you can find the Transformer JS compatible models and kind of link that up to what I'm doing here in my my code um okay so how's the audio going how bad is it because I'm G to do something out of time but I want to do something High degree of difficulty that I definitely do not have time for but let's see what we can get all right we do this in a really crude way problem is you know what's really gonna what's really going to cause me a problem is oh I don't have time to go through all of this today I'm trying to think of maybe I should maybe I should do the question let me show you what I was going to do I can't get I'm gon have to work on this on my own uh join the coding train Discord and I maybe come back make some videos about this because I wanted to do clustering what I've been experimenting with is this incredible um JavaScript library called umap JS okay let's come back to this is where I'm going with this next so I gave you a little lesson in embeddings and using Transformers JS and you could make this project I'm going to be working on this because I got to demonstrate it in class this week on like Wednesday so this example will exist at some point soon all right but I I realistically can't build it now without being here for another hour or two so first of all this is a wonderful article called understanding umap written by uh Andy Conan and Adam Pierce from Google pair which is people in AI research and so one of the things right I I have to walk over to the Whiteboard to just talk about it I've been talking a lot about high dimensional space I have all of these words all these sentences that exist in high dimensional space you can do this with images too by the way you can extract features from images and plot images in high dimensional space and look at their similarities Etc all sorts of possibilities there but every time I come to the Whiteboard to do a diagram I draw it in two Dimensions because that's the way it's easiest for me to see so what if just for just imagine for a moment that I had a list of words or sentences and each one of these and I'll just call them A B C D E FG was associated with an embedding of 384 numbers these this is where I was going with the example I make these sentences exist in 384 dimensional space and if I could just see them in that space I could see the ones that are near or far I don't know maybe my mind would open to all sorts of new possibilities that I couldn't imagine just would be interest wouldn't it be amazing I can't I can't see them in 384 dimensional space how could I plot them maybe in two dimensional space even though it wouldn't be true precisely I would get some type of you know visualization of how that data looks so what I need to do is a process known as dimensionality reduction I need to somehow take these 384 dimensions and summarize them into two Dimensions this is not easy okay so there's one way I could do it I could just say why don't I just arbitrarily pick the first two numbers of each of these and we could actually do that we could plot it and we could see and we might get lucky and that might kind of reveal something and be or maybe I pick the seventh value and the 20th value maybe I plot them in 3D space so at least I get to pick three dimensions um could I average a whole bunch of Dimensions together like there's 384 so could I average like half of them into one number in the second half what would that give me well these would be starting points that's like where my mind would go but there uh researchers and other people have developed um lots of other algorithms like PCA which I think it's principal component analysis is one tne which sounds like a sneeze but it's not uh is another I I forget like which letters are capitalized this is another algorithm uh a more recent algorithm is called umap umap is an algorithm that can take all of these high dimensional data and reduce it down into two Dimensions So in theory I could see clusters of the like data within two Dimensions there is a wonderful uh project uh made by also researchers at Google called the embedding projector and this does uh this does precisely that so this is basically taking a word to VC like a list of 10,000 words all that are I don't know what the dimensions are and essentially um mapping them into reducing the dimensions into 3D space and so if I were to zoom in and start to look at words that are near each other um you know I might find things that are similar it's a little hard maybe to see this a different data set that might be um uh better to look at is mnist so this is doing this with images these are low resolution images with 784 pixels so you can think of 784 dimensional space and using it's using PCA to plot them in three dimensions but I could switch to umap and now this is what the umap algorithm is going to do it is now uh taking these 10,000 data points in 780 diens 84 dimensional space you can see that listed up here at 10,000 points 784 dimensional space and uh it's you know taking a little while but now you can see it's clustered them so we can see here the sixes are kind of all in a cluster up here here's the fives and threes are kinded together the eights so this is the stuff that I'm really interested in making my own versions of these I'm sorry that the mic is still a problem I'm going to have to um investigate this okay there I could I could switch this to 2D which could be kind of interesting to see it um there are different parameters in terms of how the algorithm works and clicking right here um takes me to a page that explains more about the umap algorithm that you I'd be you know thrilled for any of you to look at and understand and try to um uh find ways to uh help explain the umap algorithm in Friendly and accessible and approachable terms um I do find that this particular article which has a lot of visual demonstrations this is looking at um another data set it's called fashion mnist it's a whole bunch of uh images of shirts and shoes and things and this is what uh umap um and this is the tne algorithm and it goes through a little bit about the theory uh about how it's looking at you know nearest Neighbors in uh in higher dimensions and then synthesizing that down into uh lower Dimensions so uh I'm G to show you very quickly uh an example I've been working on let's see I don't know which one is the one that I want to look at is it this one one no no no no sorry it's not that one yes so I have been uh experimenting this is a particular data set from oh uh let's see from I've I've referenced this in videos before a GitHub repository called uh corpora and it's just a collection of a lot of interesting data files a lot more to say about it but and under colors there's a few different um data files there's like a data file of Crayola colors so these are this is a nice like way of demonstrating things with embeddings like I have words that are associated with uh embedding of you know three RGB values written as hex codes here and so I think Delux Delux is a paint company and this is a particular uh data set has many many many it's like four thousands of colors um and each with their RGB values so what I've done with this particular example is I'm using this uh umap JS library and I'll have to come back and maybe do some more videos about this or come back and continue this on a live stream if people are interested is I'm using this umap JS library to essentially uh um I I can essentially just call like this function called fit so data can be a giant array of embeddings and then I can just call fit and what it then gives me is TR uh di that data uh reduced by Dimensions so let's go look at my actual code and I'll talk you through let me just run it we see we'll first see what it does so what this is doing and again this is like a a known we don't really need um for this because this is just threedimensional data but what this is doing doing is it's taking that threedimensional uh RGB data and flattening it and clustering it in twodimensional space so we can see that look at these colors that are these colors that are all kind of cluster over here these sort of dark green blues and these kind of light pastel colors and these here um I can run it again it's stochastic meaning it uses a r random seats so it's going to be a different each time but uh but we'll get some very similar results so this is what's happening what it's doing is it's loading that Json file it's putting all the RGB values into a big array so if I look at the array which is console log data this is my big array of embeddings it is 4,224 threedimensional embeddings and then uh I initialize the umap algorithm these parameters I I wanted to go down into two Dimensions uh the minimum distance and the number of neighbors affect the quality of what it considers sort of similar and not similar and how it places them um I initialize that and then step does one cycle of the algorithm so I can kind of watch it animate because it take quite some time and then out of that I get the embed the 2D embeddings which now I can just plot x's and y's X's wise and so that's where and I'm taking the original colors and filling them so my idea what I'm not going to build right now but what I'm hoping to do next um uh as an example and if anybody wants to try this and compare notes come and say hello in the coding train Discord is I would like to go take this my goal is to have maybe a some like maybe like a 100 sentences and then I would like to use Transformers JS to make the embeddings for those sentences and then I would like to use umap to graph them to Cluster them and then maybe I could have like a little interface where you type in a new sentence and it red does the umap and finds its place I don't know what kind of creative what kind of generative poetry could you make by doing a random walk through this twodimensional uh twodimensional clusters of sentences so that's kind of where I'm going with this so I kind of showed you the pieces here uh I will try to after this wraps up document all of these pieces and put links in the video description definitely come if you want to help with this or want to ask questions uh the coding train.com Discord would be the place for you to do so um so I wonder I don't you know I don't hopefully this was somewhat interesting for people you've getting a little bit of sense um again if you want to follow more closely a lot of what I'm working on right now which I would love to turn into some video tutorials and just haven't had the time um you can uh you can definitely check out the um programming from a to z a syllabus there are a lot the Transformers JS examples are in repo here um I have some other things that I'm working on with other uh uh different models um and and um API services for accessing these models um that you can find and poke around in here as well all right let's look before I go let's look at my um let's look at my um list of things that I wanted to do in 2023 and let's see what's real I got a month left I'm leaving to do some holiday traveling honestly like the last time I'll be here in this studio is kind of mid December so I've just got a couple weeks left of either live streaming or recording some stuff I would really like to do I think I should do the Wolfram Elementary CA as a coding challenge because that will go nicely with u nature of code so that's probably what I'll do next I didn't get to any of this stuff I did this I kind of did this but I should I don't know I I was planning to do more Discord bot tutorials and then kind of like nobody watched that video and like ah maybe I will maybe I won't but I would encourage I want to do more with ml5 yeah so I'm looking at this I don't know you let me know what you think um use Project Gutenberg and rewrite a classic based on similarity that is a great idea so loading a public domain text from Project Gutenberg and oh I could take like a text chop it up into sentences and then like cluster them all so that could be kind of interesting that would be a great project that somebody could try to do um um yeah so let's talk about nature of code book for a second um so this is the uh finished pretty much finished um new version of nature of code book um it is all available online P5 GS examples all the text is there I would say um yeah well right now I can't I'm this is going to be a living document but it is somewhat Frozen in the sense that I there's going to be a finished version that will go to print so if you would like to support this project um there are two ways you can do that um you could actually you know buy the nature of code book this won't come out till the summer though it says may 2024 I'll be thrilled if it's out May 2024 um so this you can preorder from no starch I think it's on all the other kind of book websites um or you can um the the GitHub repost have like a skub sponsorship associated with them but I don't I don't get to it but I just want to let you know that's there um and uh the P controller yeah I wanted to do that too chac just watched the word TC video that's interesting so I really like to continue that that was my intention like to continue that with some of these modern uh embeddings models but I never got around to that so let me just thank again um upper story uh for being the sponsor of today's uh coding train uh live stream again if you missed it you go back all the way the beginning of this stream after I'm done I did a demonstration of this uh game called the Turing tumble uh it's a wonderful if you're looking for to find a gift for somebody who loves computers and wants to learn more about how computers work and especially if they want to have an opportunity to do that away from the screen away from digital technology and actually you know get their hands in the mechanics of how computers work to learn a little about the history of computing Allan Turing um check out the Turing tumble and upper story uh the link is in the video's description upper story.com tumble and then coupon code allc caps coding train um that's all I've got uh I will take any other questions as I say goodbye here um I uh hope to continue to see you all sub projects in the passenger showcase to joining the coding training Discord to sharing your work with me watching old CL challenges if you like I don't know 2024 I hope that's a good year for making lots of content I actually went through everything on this list except for the wolfrun thing uh oh uh Kathy asked how does umap compare to fastest nearest neighbors I don't know that's a great question and we should investigate uh that my understanding is umap does a particularly good job of clustering things and doing it very fast and efficiently uh thank you mini Jimmy for your kind comment I'm just awkwardly standing here for another minute and 45 seconds because that's what I do let the let the timer run out just see if anybody else has anything to say in the chat before I go uh I'll put my sweater back on I hope people enjoyed today's live stream I think I should one one idea that sometimes I think about is what if I just forgot about like making edited videos again and just like live streamed once a week just worked on projects GIF Auto says I got stuck in full screen mode on Apple 2 and can't escape I don't know what to do for you thank you Nicole thank you uh hope uh thank you well oh is there another fundraiser I think there will be another processing Foundation fundraiser check with the foundation website about that lost sorcerer you're welcome I was glad to be able to show that uh give Auto can you get to the Discord I don't know if this is a joke or serious because you're somehow typing into the chat so you can't totally be stuck in full screen but I don't know force quit uh make an ml video editor that's I think beyond the scope of what I can possibly do but I like that idea live stream once a week yeah I'd love to get back into doing that my my teaching schedule is less busy in the spring semester so hopefully I'll get back to oh oh my song is running out goodbye everybody I will see you I mean hopefully I'm going to see you again in 2023 thank you for watching the coding train I don't know if I'm doing this the way I should be doing this anymore but boy am iik trying and doing my best I will see you all soon goodbye as always I always forget this do doget do I'm going to do the this this do this do this do the this Dot Song never forget the this dot somebody composed that song for me I'm again sing autotune and the internet will fix that for me unicorns and rainbows and cupcakes what else is there yes kittens thank you very much kittens and rainbows and cupcakes notice that look what I get I'm really losing my mind okay let's do it Kitt kittens and kittens and kittens and kittens kittens and kittens Kitt and Kitt kittens and kittens and Kitt and Kitt Kitt and Kitt Kitt and Kitt kittens and Kitt and Kitt and Kitt Kitt and Kitt kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens I feel just sort of like a nice feeling of relaxation everything's going to be okay today dream is not broken it has not frozen this is a this is a wonderful thing okay we're going to do it I'm really getting to something I need my sound effect unicorns and rainbows and cupcakes what else is there unicorns and rainbows and cupcakes that was invalid syntax I forgot uh there was one other thing here that I think is important that I will use continuously over and over again in all sorts of text generation analysis things that I will use continuously over and over again first thing I need to do is yes kittens kittens kittens I really losed my mind okay we're going to do it kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and doia
