With timestamps:

00:00 - welcome to a video coding challenge
00:03 - where I am going to implement in
00:04 - JavaScript an algorithm known as tf-idf
00:08 - what does tf-idf stand for it stands for
00:11 - term frequency inverse document
00:14 - frequency well what okay let's think
00:16 - about what's term frequency well I just
00:18 - did a previous coding challenge where I
00:21 - look red in a text and I counted how
00:24 - many times each word appeared let's take
00:26 - a look at that even though it says
00:27 - tf-idf the top ignore that this is my
00:30 - previous example running the happen up
00:32 - occurred in this text 16 times a 8 times
00:35 - of 7 this by the way excuse me is term
00:40 - frequency how frequent was the term in
00:42 - that document so what's this IDF part
00:45 - and why do we need it
00:46 - well let's think about it this is all of
00:50 - the word frequencies of all the words in
00:53 - the Wikipedia article about rainbows
00:56 - it's an edited a shorter version of that
00:57 - article you can see the word counts
00:58 - aren't very high what if what I wanted
01:01 - to do was extract or automatically
01:04 - through some algorithm determined
01:06 - keywords associated with this article
01:08 - well the first way I could think to do
01:09 - that would be hmm the words that appear
01:12 - most frequent frequently those must be
01:15 - important words for this article so I
01:17 - know what the keywords are there the a
01:19 - of in and an o and PI you can see why
01:23 - this is a problem those are sort of
01:25 - meaningless words now they're quite
01:26 - meaningful in text analysis if you look
01:28 - at James petit Baker's research check
01:30 - this description for a link to book
01:31 - secret life of pronouns that's another
01:32 - topic come back to that another time but
01:34 - in for what I'm doing trying to get
01:36 - keyword extraction those are not
01:38 - meaningful words rainbow however is a
01:40 - meaningful word now if you think about
01:42 - it if I were to look at you know unicorn
01:46 - is probably a bad example but if I were
01:47 - looked to look at the Wikipedia page for
01:49 - mango or for blueberry I probably
01:52 - wouldn't find the word rainbow in it
01:54 - that often so while I would find the
01:57 - words the a of it in so words that might
02:00 - appear frequently in one document but
02:02 - not frequently amongst a corpus of other
02:05 - documents might be unique or important
02:08 - to that particular document and that's
02:10 - what IDF is its inverse document
02:13 - frequency meaning term frequency inverse
02:19 - document frequency meaning a words score
02:22 - equals the term frequency let's say it
02:26 - appears 100 times x inverse document
02:30 - frequency meaning the more frequent it
02:33 - is in other documents the lower the
02:35 - score should be so how do we calculate
02:38 - that well I could say let's say it
02:40 - appears in 10 documents I could just say
02:43 - 1 divided by 10 instead of 10 so 1
02:47 - divided by the number of documents it
02:49 - appears it and you can see if it's only
02:51 - in one document right I'm going to get a
02:57 - score of 100 or I'm going to get a score
03:00 - of 10 so actually in the technical
03:04 - definition of tf-idf the number 1
03:07 - doesn't go here but actually the total
03:09 - number of documents so let's say we're
03:11 - actually examining the corpus is 50
03:16 - documents and then you could see here
03:20 - that you know we're kind of going to get
03:22 - similar if this this is mostly
03:24 - equivalent to score relative but this is
03:26 - the technical definition so 100 times
03:30 - the number of documents divided by the
03:32 - number of documents that appeared in so
03:34 - this now I would get a score of 500 and
03:38 - here I would get a score of 5,000 now
03:42 - this is also not exactly if you look up
03:46 - if you keep reading that Wikipedia page
03:47 - the technical definition of the score of
03:51 - tf-idf there's one step board here which
03:54 - is that this is perhaps weighting it way
03:56 - too strongly in order to reduce the
03:59 - effect that the document count has on
04:02 - the score logarithmic scale is applied
04:05 - so the log function is applied so you
04:07 - could play around with this formula be
04:09 - creative and come up with your own twist
04:10 - on what you're actually looking for but
04:12 - under the technical definition under
04:14 - wicked Wikipedia you'll see that the the
04:16 - log function is applied now why is that
04:19 - applied so how'd and how does
04:20 - logarithmic scale work I'm going to in
04:23 - this video in the description link you
04:24 - to a really great conic
04:26 - a video that describes logarithmic scale
04:28 - in detail or maybe I'll come back and
04:30 - make my own video about that but I'm
04:31 - going to move on and just have you
04:32 - understand it as a way of changing the
04:34 - of reducing the effect that the document
04:37 - frequency has and which can overwhelm
04:39 - the score if you don't apply this
04:42 - logarithmic scale okay so this is the
04:45 - idea of term frequency inverse document
04:47 - frequency instead of now what I want to
04:50 - do is have a program that doesn't just
04:51 - show me the counts of each word but
04:54 - shows me this TF idea score so the
04:58 - question for you is like well what do
05:00 - you why are you using this and what's
05:01 - your corpus so you might think about
05:02 - well let me look at you know every
05:04 - single newspaper up pick a newspaper and
05:06 - every soval these paper articles or a
05:09 - Wikipedia article and all Wikipedia
05:11 - articles you kind of you want a big data
05:13 - set to be able to have this produce
05:15 - meaningful values I'm going to
05:16 - demonstrate this to you with a small
05:18 - data set look at something that works
05:20 - but obviously it'll be a you know a
05:22 - little bit flawed based on the small
05:23 - data set let me just show you the data
05:25 - set really quickly so I'm this is the
05:27 - previous word counting example running
05:30 - verbatim but I'm going to alter the code
05:32 - and instead what I'm going to use is
05:34 - here under files I'm going to use these
05:37 - particular these these text files and
05:40 - these are just text files that are a
05:43 - short paragraphs from Wikipedia like the
05:45 - fish a fish article faith key I don't
05:50 - know where I got this rainbow txt sports
05:53 - txt test and treat txt so I'm just going
05:57 - to pick I'm just going to use tree
05:59 - sports rainbow and fish okay so what I
06:02 - want to add in my sorry what I want to
06:06 - add in this particular example I'm going
06:09 - to go back to the code is I want to
06:11 - create an array of files Eclipse txt
06:17 - fish fish txt rainbow txt and and
06:27 - actually I'm going to do this in sort of
06:28 - a silly way I know I'm going to know
06:29 - rainbow dot exe I'm gonna do that and
06:33 - what was one of the other ones
06:35 - let's try sports dot txt
06:38 - I don't know why I picked these some one
06:40 - point I picked these okay so so these
06:45 - are the files that I'm going to use so I
06:48 - can't just load only these files I need
06:53 - to load all of them so how do I do that
06:56 - oh I want this to be an array
07:00 - I want that raw text to be an array and
07:03 - I'm going to preload all of them so I'm
07:06 - going to say for VAR i equals 0 I is
07:08 - less than files length I plus plus I'm
07:13 - going to say text index I equals load
07:16 - strings files and then plus the files
07:23 - index whoops plus no quotes their files
07:26 - index I so this is me now loading all of
07:29 - those files into an array and then what
07:33 - I want to do here is again all words I
07:36 - need all words not to be a single
07:39 - document I'm loading a bunch of
07:41 - documents and I'm by the way I'm doing
07:42 - this in quick and dirty fashion to
07:44 - demonstrate tf-idf if I were really
07:46 - building this out and I'll show you a
07:48 - different example after to be a bit more
07:49 - thoughtful about how I'm loading all
07:51 - these files and maybe thinking of a more
07:53 - sophisticated data structure to keep
07:55 - track of all this data but this will
07:56 - work for now so I want to this is a good
08:00 - first pass I think so I want to loop
08:02 - through all of the things I loaded and I
08:07 - want to create on all words array and
08:11 - say all words index I join okay so
08:17 - that's good enough for right now because
08:20 - what I want to do is I want to pick what
08:23 - I'm going to do arbitrarily is I'm going
08:25 - to say and let's let's use rainbow and
08:27 - put rainbow first I'm just going to do
08:29 - the tf-idf score for the first article
08:34 - as compared to all the articles again
08:36 - you would want a much larger data set
08:39 - you probably want to have many articles
08:40 - with longer text in them and you might
08:43 - want to build something which allows you
08:44 - to click on different articles and
08:45 - compare that one to all of them but I'm
08:47 - going to make a simple introduction this
08:48 - idea by comparing the first article
08:51 - to all the other articles so now let's
08:53 - just make sure my term frequency is
08:55 - working so instead of splitting all
08:58 - words I want to split all words index
09:00 - zero and I want to still count and count
09:04 - all of those and and visualize that
09:07 - count so everything should work now
09:10 - where I whoa something went a little
09:14 - goofy here because why did I get such
09:17 - higher yeah I mean I'm getting words
09:20 - from others so let's see what did I miss
09:22 - here ah there we go I see the problem
09:25 - this should say txt index high right I
09:29 - don't want I joined all the words from
09:31 - all the articles which I don't want to
09:33 - do I need to still have some way of
09:35 - distinguishing between articles if I was
09:37 - just doing a concordance across all of
09:39 - them that would be fine but I need to
09:40 - keep that just that distinction so let
09:44 - me make sure let me just make this a
09:46 - global variable for make debugging a
09:48 - little bit easier even though I don't
09:49 - necessarily need to and that's so that I
09:55 - can make this an array and get rid of
09:58 - this here so let me run this again we
10:02 - can see here's the raw data from the
10:04 - files and here is that array now we can
10:08 - see yep we can see a hold on all all
10:16 - words I still think I might have a
10:18 - mistake in here dot length no four we're
10:21 - fine all words index zero is rainbow all
10:25 - words index one is Eclipse okay so
10:28 - because either short so this is good I
10:29 - now have all those articles in an array
10:32 - of strings and you can see here they are
10:35 - the counts for the rainbow article again
10:36 - these numbers are really small so my
10:38 - results aren't going to be so great but
10:39 - let's see how it goes so here's the big
10:42 - difference this is an incredibly
10:44 - important point here in my previous
10:48 - videos about word counting we created an
10:52 - associative array each here and was
10:56 - using a JavaScript object the JavaScript
10:59 - object would have a word like rainbow
11:03 - associated with a count like 10 this is
11:07 - no longer going to be good enough
11:09 - because what I want to have now
11:11 - associated with rainbow is to values the
11:14 - terms frequency and the document
11:17 - frequency
11:17 - I need the term frequency and the
11:20 - document frequency so how do I do that
11:23 - if a javascript object has a word
11:28 - associated with a value how can I have a
11:32 - word so a string associated with two
11:34 - values well this is actually quite
11:36 - native to how JavaScript works there's a
11:38 - bunch of ways I could do this for
11:40 - example I could have the key be rainbow
11:43 - and the value be an array with two
11:47 - numbers in it this might be actually a
11:48 - nice way of doing it I'm going to do it
11:50 - in a little bit of a goofier way which I
11:52 - think we'll build later I want to do
11:54 - Bayesian text analysis bayesian text
11:56 - classification and we're going to need
11:58 - to be a bit more thoughtful about this
11:59 - because we're need a lot of numbers with
12:01 - each word so what I'm going to do
12:04 - actually is associate an entire other
12:07 - object with each word so rainbow is the
12:10 - key and the value is term frequency 100
12:16 - and document frequency you know 1 so I'm
12:20 - going to have the key be a reference to
12:23 - an object itself with two values in it
12:27 - so this is going to be really useful for
12:28 - later text analysis operations where you
12:32 - might want to have a lot of metadata I
12:34 - mean what if I want to have rainbows
12:35 - definition or a you know a link to the
12:37 - word Nick page that so that you have a
12:40 - lot of metadata associated with each
12:42 - word if I were to build out this object
12:44 - okay so here we come back so I want to
12:48 - modify the way that this works right
12:50 - whenever I encounter a new word I want
12:55 - to actually not just set the value to
12:57 - one but I want to create an object with
13:01 - a term frequency a term frequency of 1
13:06 - and a document frequency of well let's
13:09 - not do the document frequency yet I
13:11 - think so I want to put it in it I want
13:14 - to document frequencies
13:15 - to go in there but I want to make an
13:17 - object with term frequency of one okay
13:20 - so this program now that's what now this
13:22 - will fail because it that the count is
13:26 - no longer in there you can see there's
13:28 - this object here so what I need to do if
13:30 - I want to visualize this again is say
13:31 - counts index key dot TF because those
13:35 - numbers are now in the object associated
13:37 - with that word in the variable TF Oh
13:39 - undefined interesting oh why is that
13:42 - well here we go because I need to
13:44 - increase the term frequency here right
13:48 - not just increase the value by one okay
13:53 - so now now we're back to where we
13:55 - started ah sorting is also broken
13:58 - because I'm comparing the term
14:01 - frequencies and you can see now we're
14:05 - back to where we started so now I have
14:06 - an object and what I can actually do is
14:09 - figure out document frequency now okay
14:12 - so let's add that in so what I want to
14:16 - do and let's actually let's count it you
14:21 - know what um there's a good bunch of
14:23 - different ways we could do this so I'll
14:24 - try to think what makes the most sense
14:25 - I'm gonna leave it as is and what I'm
14:28 - going to do now is say okay once I'm
14:30 - done with the term frequency I need to
14:32 - look at every single word and count how
14:34 - many times appears in other documents
14:36 - okay let's figure this out oh this is
14:39 - going to be we could do this wow this is
14:40 - hard this is hard so I know that I need
14:43 - to loop through all the keys so let's
14:46 - first loop through all the keys right
14:49 - all right let's I don't need to worry
14:51 - about sorting I'm going to loop through
14:53 - all the keys so my word is keys index I
14:57 - so now what I need to do is loop through
15:00 - all of the files who all I'm going to
15:08 - say all txt equals all words length
15:12 - whoops ah I J a J equals 0 J is less
15:17 - than all words dot length right all
15:19 - words is the array I need to for every
15:23 - word I need to look at all the other
15:25 - documents and see if it's in there so I
15:26 - just need to I didn't do the counts I
15:28 - just need to know does it even a
15:29 - in that document I could do the counts
15:32 - for like how often does it appear in
15:33 - those other documents but I'm going to
15:35 - do it in a simpler way okay so for each
15:38 - one of those what do I need to do I want
15:41 - to check actually you know what mm-hmm
15:45 - let's do this a different way no this
15:49 - will work okay this will work so I need
15:53 - to do like a mini little concordance
15:54 - right here for all of those so I'm going
15:57 - to just say a temp temp counts equals an
16:06 - empty object okay then I want to split
16:10 - up and how did I split before what
16:13 - regular expression do I use this all
16:16 - words index I I want to split it up into
16:20 - tokens oh my god do I really have
16:23 - another loop here VAR k equals 0
16:27 - I'm sure there's like a way to simplify
16:31 - this that is unnecessary I don't think
16:38 - yeah there's a I'm going to be able to
16:40 - make this more efficient but I'm going
16:41 - to keep going with this I don't think I
16:42 - need the outer loop I'm thinking about
16:44 - this but let's keep going k is less than
16:47 - tokens dot length okay I want to go
16:53 - through all of the tokens and if temp
16:58 - counts tokens index I is undefined
17:15 - yeah I just wanted to there's a better
17:17 - way to do this I can already think of it
17:19 - ah I'm running out of space here why is
17:21 - it word wrapping me I don't like that if
17:26 - ten counts tokens I is undefined then I
17:32 - want to just give it a value of one like
17:39 - it exists it's in that document so I
17:42 - want to get a unique list of all the
17:44 - words in that document and once I've
17:47 - done that I can just say if temp counts
17:52 - word exists equals one then word dot
17:59 - document frequency plus plus and by the
18:04 - way here I should give it a document
18:06 - frequency of zero so I'm not going to
18:07 - count this particular instance as a dot
18:11 - document frequency because I happen to
18:13 - be checking the same document again
18:14 - let's let's be let's be better about
18:17 - this let's start this as one so I give
18:20 - it a it's in this document and then I'm
18:22 - going to only go through I'm going to
18:23 - skip that first one in the array so
18:25 - there's less computation here so then I
18:28 - can and let's let's make a word a
18:36 - variable tokens index I because this
18:38 - will make the code more readable and
18:45 - that way okay so and I this is wrong
18:50 - this would be counts in index word D F
18:54 - plus plus whoa okay I kind of wrote all
18:57 - this out I'm probably made some mistakes
18:59 - I think I could I should just doing the
19:01 - concordance every single time for every
19:02 - word which is ridiculous I should do the
19:04 - concordance for the other documents once
19:06 - and then check all the words but I'm
19:08 - going to fix that in a moment but let's
19:10 - even just see if this works this is what
19:12 - happens when you program you're kind of
19:13 - a mess and it's just sort of like you're
19:15 - trying to figure it out so let's just
19:16 - read this through again for every single
19:19 - word in the article that I'm trying to
19:21 - find the keywords for I want to look at
19:24 - all the other articles and quickly do a
19:27 - quick concordance
19:28 - by looking at all those words and then
19:31 - once I've done that quick concordance I
19:33 - want to see if it's in there if it was
19:34 - in there I would increase its document
19:36 - frequency by one and once I'm done with
19:40 - that let's run this program okay I have
19:47 - it error sketched out J s line 35 oh no
19:52 - wonder I equals zero I is less than keys
19:57 - dot length okay look this is taking a
20:01 - very long time I probably have an
20:05 - infinite loop somewhere in this code I
20:06 - probably have locked up the browser
20:08 - right can i scroll can I select anything
20:11 - no so I need to kill this page I'm going
20:16 - to close this page and go back and look
20:18 - so let's let's debug this together ah
20:23 - this should be K by the way because I'm
20:29 - looking at all the tokens and where
20:32 - could the loop have gone wrong ah here
20:35 - we go that should be that used to be a
20:37 - less than I had equals I had an infinite
20:39 - loop stuck in there I'm gonna kill this
20:41 - page okay let's come back run this again
20:44 - but still got a problem let's look at
20:49 - this some more infinite loop anywhere
20:51 - okay I'm back I think there was actually
20:53 - a caching issue when I had that infinite
20:55 - loop so I now I just restarted the the
20:59 - webserver that I'm running and so I now
21:01 - have this running again but I still
21:03 - don't know if I fix the problem
21:06 - okay can I tree property split of
21:09 - undefined line forty why don't I have
21:12 - undef' is uh why is that
21:17 - Oh J this should be J that's really
21:19 - important that has to be J it's part of
21:21 - that loop cough hat okay things are
21:24 - still good and now this is where I'm
21:26 - doing the quick little concordance
21:30 - things are still working I don't know
21:33 - what went wrong there but I think I just
21:34 - had the infinite loop and the infinite
21:36 - loop the browser couldn't like not get
21:39 - out of the cache of that or whatever so
21:41 - let me look at counting
21:42 - now and we can see look at this a is in
21:46 - one document with a term frequency of 8
21:48 - above is in one document the term
21:50 - frequency of 1 now this doesn't really
21:51 - seem right to me
21:52 - I expect that I should have some
21:54 - document frequencies of more than one
21:56 - okay so let's see if we can figure out
21:58 - if the document frequency isn't working
22:00 - properly so one thing is I should
22:03 - definitely add this to lowercase thing
22:06 - let's see if that helps and I'm going to
22:10 - say counts again and you know a we
22:13 - should definitely a should be in more
22:15 - than one document and just to be sure
22:18 - about that let's go to the files eclipse
22:23 - and I'm going to add a a a just to be
22:27 - sure about that I'm going to add a
22:28 - couple instances of a just in case it it
22:32 - wasn't and now I'm going to refresh this
22:34 - and look at the counts and then we go to
22:38 - a and the document frequency is still 1
22:40 - so there is a mistake here let's see if
22:42 - we can figure out what I did wrong
22:43 - in the actual code so now I'm going back
22:46 - to sketch J s so let's look at let's
22:51 - look at all these temp counts so as I
22:56 - run this let's look at all these little
22:57 - mini hash tables I created for each
22:59 - other document 1 true - true 1 true - so
23:05 - this this looks right a is true so I'm
23:08 - definitely getting why I put the value
23:11 - is true oh I said true and then I
23:14 - checked if it's equal to 1 so that has
23:19 - to match of course I want to know why I
23:22 - put true to keep track of it's in the
23:24 - document and so I could just check if
23:25 - that evaluates to true or false so that
23:28 - that's clear the problem and I can I can
23:31 - take out this console dot log and I can
23:35 - look at the counts again and I can now
23:37 - say a document frequency is still 1 okay
23:41 - so that doesn't seem like it makes sense
23:43 - oh boy I see the problem it's very
23:49 - obvious which is that I used word to
23:53 - keep track of the word that I'm
23:54 - currently
23:55 - trying to determine the document
23:57 - frequency and then later in the inner
23:58 - loop I kind of like I made a different
24:00 - word variable and in JavaScript you
24:02 - can't really have these like local
24:03 - variables they clash everything and this
24:06 - is this is a total mess I can't have
24:08 - declare a new variable in a sort of like
24:10 - local or more local scope than the then
24:13 - another variable with the same name so
24:14 - actually I think I just want to get rid
24:16 - of the use of I'm just going to I'm
24:19 - going to call this W that'll solve this
24:23 - problem so I'm just going to use W down
24:25 - here so that when I'm down here I'm
24:27 - referring to the correct word now come
24:30 - on everybody
24:31 - are you with me let's look at the counts
24:33 - and let's look at a and we've got a
24:37 - document frequency is four this is
24:40 - excellent news so now we have term
24:44 - frequency being calculated and document
24:47 - frequency being calculated now let's
24:48 - let's make an improvement here this is
24:52 - really I hate to make this video any
24:54 - longer than it is but this is really
24:56 - bothering me that I have I'm redoing the
24:59 - concordance of all those documents for
25:01 - every word which is pretty much
25:03 - ridiculous if I don't say so myself so
25:06 - I'm going to take this out this this
25:12 - loop out and do it once in advance right
25:15 - I want to look through all the other
25:18 - files I'm going to say other Phi other
25:22 - counts is an array right of all the
25:27 - other counts I'm going to create this
25:30 - temporary counts dictionary and then
25:33 - when I'm done creating that temporary
25:35 - counts dictionary I'm going to put it in
25:37 - other counts okay so now I've done it
25:43 - just once I have a nice array of all of
25:46 - the all of the dictionaries all the
25:48 - unique words in the other documents so
25:51 - now when I go through this list of keys
25:54 - I don't have to realize still have to
25:57 - look at all the other concordance --is
26:03 - the other counts length but I don't have
26:07 - to redo each one which was kind of
26:10 - absurd and I can say now and I hope I
26:16 - can say now temp counts equals other
26:21 - counts index J so now for every word I
26:26 - can see if it's in the other one so I'm
26:28 - just doing all of these concordance as
26:29 - once and then checking them here so
26:33 - hopefully that fixes this still works up
26:35 - I got a line 77 syntax error which is Oh
26:39 - an extra I'm out of I did too many
26:42 - brackets yeah I Clos into too many
26:44 - brackets and now let's look at counts
26:47 - and let's hope that I'm still seeing the
26:49 - right yes so I just made this enormous
26:51 - ly more efficient which is a really good
26:53 - thing thankfully okay now we can
26:55 - actually now I can actually do the the
26:59 - tf-idf score so the next thing I can do
27:01 - is once again look at all the keys and I
27:07 - can calculate the score so how do I do
27:09 - that I can say for I can say give me my
27:16 - I can say give me the TF the the word
27:22 - object and trying to think of giv I'm
27:23 - just gonna say value is a counts and
27:28 - this should really be TF i should change
27:30 - this variable name from counts counts
27:31 - word actually I'm just gonna write oh
27:38 - this is so hard to think of good
27:40 - variable names on the fly but Val is
27:42 - like the worst right so I'm just going
27:44 - to say word up word data that's not much
27:48 - better but the word date is all this
27:49 - stuff the term frequency term frequency
27:52 - and document frequency that's what's in
27:54 - there right now
27:55 - so now term frequency inverse document
27:58 - frequency equals term frequency document
28:03 - frequency TF right I want the term
28:05 - frequency from that object times I need
28:10 - to make it inverse so what are the total
28:12 - number of files I want to say files dot
28:15 - length divided
28:17 - by term the document frequency now by
28:21 - definition I this would be a problem if
28:24 - I could have a document frequency of
28:25 - zero but I started all document
28:26 - frequencies at one so I this shouldn't
28:28 - be a problem so I can put this in
28:31 - parenthesis and then take the logarithm
28:33 - of that and I've done the formula and
28:35 - then I can say why is my text wrapping I
28:39 - don't like that and then I can say T fdf
28:43 - tf-idf equals that score and really what
28:49 - I want to do is just this I want to put
28:52 - the score in that object and I don't
28:56 - like the name of this variable I'm just
28:58 - going to call it word object because it
29:00 - stores all the stuff even though it
29:05 - makes me lose my wraps that line again
29:08 - so here we go I want it at tf-idf score
29:12 - the tf-idf score is the term frequency
29:15 - times the logarithm of the total files
29:17 - divided by the work that the document
29:19 - frequency and now what do I need to do I
29:23 - can just go back down here and say hey
29:26 - guess what remember when I sorted that
29:29 - array I don't want to sort by the term
29:31 - frequency I want to sort by that inverse
29:33 - document frequency score and I want to
29:36 - display that tf-idf score and let's see
29:40 - what happens with a rainbow's txt if I
29:43 - run this you can see look at this
29:45 - perfect arc rainbow light cause so we're
29:48 - getting higher numbers for words that
29:50 - are associated with rainbow and a little
29:53 - hack that I can do just to test
29:54 - something else is I can you know let's
29:56 - try sports txt instead if whatever I put
29:59 - first in this array will be checked or
30:01 - conduct unsportsmanlike games such so
30:04 - again I'm not getting or is a bit of an
30:07 - anomaly here because I have such a small
30:09 - data set so or appears very frequently
30:11 - here but if I had a larger data set I
30:13 - would get more accurate results okay so
30:15 - what can you do with this this is a bit
30:18 - of a mess of a video but I have now
30:20 - working code awfully you learn something
30:21 - or you got something out of it couple
30:23 - things I'll mention one is I have a more
30:25 - thoughtfully designed example which
30:27 - again I'll link to in this video but you
30:29 - can find on the A to Z website
30:31 - where if I go here I can actually drag a
30:35 - whole bunch of files in drag and drop
30:37 - them and it'll do tf-idf for all of them
30:39 - you can see what it does it actually
30:41 - makes a bunch of clickable links so you
30:44 - know I could click on let's say if I
30:46 - click on Fish txt I can see now I'm
30:48 - getting I think it's like I don't know
30:51 - what the weird let's look at test at txt
30:54 - or rainbow txt we got we getting the
30:57 - same results us I did something
30:59 - different with the math formula of the
31:01 - exam and that but you can see I'm
31:04 - getting basically the same result so you
31:06 - can look at this example if you want a
31:07 - more thoughtfully put together example
31:09 - that allows you to try a bunch of
31:11 - different files and drag and drop them
31:13 - but ultimately I would say to you is
31:14 - number one
31:15 - what's your corpus of text what's a
31:18 - unique and interesting corpus of text
31:19 - that's meaningful to you that you might
31:20 - want to try and number two is how might
31:23 - you present these results in a more
31:25 - creative fashion you know what happens
31:27 - if you did this to all of your emails
31:29 - certain emails one email versus all of
31:31 - your other emails that's a corpus or and
31:33 - how might you visualize that information
31:35 - with color with shapes with drawing or
31:37 - simply in some interactive way to allow
31:40 - a user to play around this idea so if
31:41 - you make anything try anything let me
31:43 - know and I would love love to love to
31:46 - see it so write in the comments or share
31:48 - with me on Twitter at Schiffman and see
31:51 - you soon
32:00 - you

Cleaned transcript:

welcome to a video coding challenge where I am going to implement in JavaScript an algorithm known as tfidf what does tfidf stand for it stands for term frequency inverse document frequency well what okay let's think about what's term frequency well I just did a previous coding challenge where I look red in a text and I counted how many times each word appeared let's take a look at that even though it says tfidf the top ignore that this is my previous example running the happen up occurred in this text 16 times a 8 times of 7 this by the way excuse me is term frequency how frequent was the term in that document so what's this IDF part and why do we need it well let's think about it this is all of the word frequencies of all the words in the Wikipedia article about rainbows it's an edited a shorter version of that article you can see the word counts aren't very high what if what I wanted to do was extract or automatically through some algorithm determined keywords associated with this article well the first way I could think to do that would be hmm the words that appear most frequent frequently those must be important words for this article so I know what the keywords are there the a of in and an o and PI you can see why this is a problem those are sort of meaningless words now they're quite meaningful in text analysis if you look at James petit Baker's research check this description for a link to book secret life of pronouns that's another topic come back to that another time but in for what I'm doing trying to get keyword extraction those are not meaningful words rainbow however is a meaningful word now if you think about it if I were to look at you know unicorn is probably a bad example but if I were looked to look at the Wikipedia page for mango or for blueberry I probably wouldn't find the word rainbow in it that often so while I would find the words the a of it in so words that might appear frequently in one document but not frequently amongst a corpus of other documents might be unique or important to that particular document and that's what IDF is its inverse document frequency meaning term frequency inverse document frequency meaning a words score equals the term frequency let's say it appears 100 times x inverse document frequency meaning the more frequent it is in other documents the lower the score should be so how do we calculate that well I could say let's say it appears in 10 documents I could just say 1 divided by 10 instead of 10 so 1 divided by the number of documents it appears it and you can see if it's only in one document right I'm going to get a score of 100 or I'm going to get a score of 10 so actually in the technical definition of tfidf the number 1 doesn't go here but actually the total number of documents so let's say we're actually examining the corpus is 50 documents and then you could see here that you know we're kind of going to get similar if this this is mostly equivalent to score relative but this is the technical definition so 100 times the number of documents divided by the number of documents that appeared in so this now I would get a score of 500 and here I would get a score of 5,000 now this is also not exactly if you look up if you keep reading that Wikipedia page the technical definition of the score of tfidf there's one step board here which is that this is perhaps weighting it way too strongly in order to reduce the effect that the document count has on the score logarithmic scale is applied so the log function is applied so you could play around with this formula be creative and come up with your own twist on what you're actually looking for but under the technical definition under wicked Wikipedia you'll see that the the log function is applied now why is that applied so how'd and how does logarithmic scale work I'm going to in this video in the description link you to a really great conic a video that describes logarithmic scale in detail or maybe I'll come back and make my own video about that but I'm going to move on and just have you understand it as a way of changing the of reducing the effect that the document frequency has and which can overwhelm the score if you don't apply this logarithmic scale okay so this is the idea of term frequency inverse document frequency instead of now what I want to do is have a program that doesn't just show me the counts of each word but shows me this TF idea score so the question for you is like well what do you why are you using this and what's your corpus so you might think about well let me look at you know every single newspaper up pick a newspaper and every soval these paper articles or a Wikipedia article and all Wikipedia articles you kind of you want a big data set to be able to have this produce meaningful values I'm going to demonstrate this to you with a small data set look at something that works but obviously it'll be a you know a little bit flawed based on the small data set let me just show you the data set really quickly so I'm this is the previous word counting example running verbatim but I'm going to alter the code and instead what I'm going to use is here under files I'm going to use these particular these these text files and these are just text files that are a short paragraphs from Wikipedia like the fish a fish article faith key I don't know where I got this rainbow txt sports txt test and treat txt so I'm just going to pick I'm just going to use tree sports rainbow and fish okay so what I want to add in my sorry what I want to add in this particular example I'm going to go back to the code is I want to create an array of files Eclipse txt fish fish txt rainbow txt and and actually I'm going to do this in sort of a silly way I know I'm going to know rainbow dot exe I'm gonna do that and what was one of the other ones let's try sports dot txt I don't know why I picked these some one point I picked these okay so so these are the files that I'm going to use so I can't just load only these files I need to load all of them so how do I do that oh I want this to be an array I want that raw text to be an array and I'm going to preload all of them so I'm going to say for VAR i equals 0 I is less than files length I plus plus I'm going to say text index I equals load strings files and then plus the files index whoops plus no quotes their files index I so this is me now loading all of those files into an array and then what I want to do here is again all words I need all words not to be a single document I'm loading a bunch of documents and I'm by the way I'm doing this in quick and dirty fashion to demonstrate tfidf if I were really building this out and I'll show you a different example after to be a bit more thoughtful about how I'm loading all these files and maybe thinking of a more sophisticated data structure to keep track of all this data but this will work for now so I want to this is a good first pass I think so I want to loop through all of the things I loaded and I want to create on all words array and say all words index I join okay so that's good enough for right now because what I want to do is I want to pick what I'm going to do arbitrarily is I'm going to say and let's let's use rainbow and put rainbow first I'm just going to do the tfidf score for the first article as compared to all the articles again you would want a much larger data set you probably want to have many articles with longer text in them and you might want to build something which allows you to click on different articles and compare that one to all of them but I'm going to make a simple introduction this idea by comparing the first article to all the other articles so now let's just make sure my term frequency is working so instead of splitting all words I want to split all words index zero and I want to still count and count all of those and and visualize that count so everything should work now where I whoa something went a little goofy here because why did I get such higher yeah I mean I'm getting words from others so let's see what did I miss here ah there we go I see the problem this should say txt index high right I don't want I joined all the words from all the articles which I don't want to do I need to still have some way of distinguishing between articles if I was just doing a concordance across all of them that would be fine but I need to keep that just that distinction so let me make sure let me just make this a global variable for make debugging a little bit easier even though I don't necessarily need to and that's so that I can make this an array and get rid of this here so let me run this again we can see here's the raw data from the files and here is that array now we can see yep we can see a hold on all all words I still think I might have a mistake in here dot length no four we're fine all words index zero is rainbow all words index one is Eclipse okay so because either short so this is good I now have all those articles in an array of strings and you can see here they are the counts for the rainbow article again these numbers are really small so my results aren't going to be so great but let's see how it goes so here's the big difference this is an incredibly important point here in my previous videos about word counting we created an associative array each here and was using a JavaScript object the JavaScript object would have a word like rainbow associated with a count like 10 this is no longer going to be good enough because what I want to have now associated with rainbow is to values the terms frequency and the document frequency I need the term frequency and the document frequency so how do I do that if a javascript object has a word associated with a value how can I have a word so a string associated with two values well this is actually quite native to how JavaScript works there's a bunch of ways I could do this for example I could have the key be rainbow and the value be an array with two numbers in it this might be actually a nice way of doing it I'm going to do it in a little bit of a goofier way which I think we'll build later I want to do Bayesian text analysis bayesian text classification and we're going to need to be a bit more thoughtful about this because we're need a lot of numbers with each word so what I'm going to do actually is associate an entire other object with each word so rainbow is the key and the value is term frequency 100 and document frequency you know 1 so I'm going to have the key be a reference to an object itself with two values in it so this is going to be really useful for later text analysis operations where you might want to have a lot of metadata I mean what if I want to have rainbows definition or a you know a link to the word Nick page that so that you have a lot of metadata associated with each word if I were to build out this object okay so here we come back so I want to modify the way that this works right whenever I encounter a new word I want to actually not just set the value to one but I want to create an object with a term frequency a term frequency of 1 and a document frequency of well let's not do the document frequency yet I think so I want to put it in it I want to document frequencies to go in there but I want to make an object with term frequency of one okay so this program now that's what now this will fail because it that the count is no longer in there you can see there's this object here so what I need to do if I want to visualize this again is say counts index key dot TF because those numbers are now in the object associated with that word in the variable TF Oh undefined interesting oh why is that well here we go because I need to increase the term frequency here right not just increase the value by one okay so now now we're back to where we started ah sorting is also broken because I'm comparing the term frequencies and you can see now we're back to where we started so now I have an object and what I can actually do is figure out document frequency now okay so let's add that in so what I want to do and let's actually let's count it you know what um there's a good bunch of different ways we could do this so I'll try to think what makes the most sense I'm gonna leave it as is and what I'm going to do now is say okay once I'm done with the term frequency I need to look at every single word and count how many times appears in other documents okay let's figure this out oh this is going to be we could do this wow this is hard this is hard so I know that I need to loop through all the keys so let's first loop through all the keys right all right let's I don't need to worry about sorting I'm going to loop through all the keys so my word is keys index I so now what I need to do is loop through all of the files who all I'm going to say all txt equals all words length whoops ah I J a J equals 0 J is less than all words dot length right all words is the array I need to for every word I need to look at all the other documents and see if it's in there so I just need to I didn't do the counts I just need to know does it even a in that document I could do the counts for like how often does it appear in those other documents but I'm going to do it in a simpler way okay so for each one of those what do I need to do I want to check actually you know what mmhmm let's do this a different way no this will work okay this will work so I need to do like a mini little concordance right here for all of those so I'm going to just say a temp temp counts equals an empty object okay then I want to split up and how did I split before what regular expression do I use this all words index I I want to split it up into tokens oh my god do I really have another loop here VAR k equals 0 I'm sure there's like a way to simplify this that is unnecessary I don't think yeah there's a I'm going to be able to make this more efficient but I'm going to keep going with this I don't think I need the outer loop I'm thinking about this but let's keep going k is less than tokens dot length okay I want to go through all of the tokens and if temp counts tokens index I is undefined yeah I just wanted to there's a better way to do this I can already think of it ah I'm running out of space here why is it word wrapping me I don't like that if ten counts tokens I is undefined then I want to just give it a value of one like it exists it's in that document so I want to get a unique list of all the words in that document and once I've done that I can just say if temp counts word exists equals one then word dot document frequency plus plus and by the way here I should give it a document frequency of zero so I'm not going to count this particular instance as a dot document frequency because I happen to be checking the same document again let's let's be let's be better about this let's start this as one so I give it a it's in this document and then I'm going to only go through I'm going to skip that first one in the array so there's less computation here so then I can and let's let's make a word a variable tokens index I because this will make the code more readable and that way okay so and I this is wrong this would be counts in index word D F plus plus whoa okay I kind of wrote all this out I'm probably made some mistakes I think I could I should just doing the concordance every single time for every word which is ridiculous I should do the concordance for the other documents once and then check all the words but I'm going to fix that in a moment but let's even just see if this works this is what happens when you program you're kind of a mess and it's just sort of like you're trying to figure it out so let's just read this through again for every single word in the article that I'm trying to find the keywords for I want to look at all the other articles and quickly do a quick concordance by looking at all those words and then once I've done that quick concordance I want to see if it's in there if it was in there I would increase its document frequency by one and once I'm done with that let's run this program okay I have it error sketched out J s line 35 oh no wonder I equals zero I is less than keys dot length okay look this is taking a very long time I probably have an infinite loop somewhere in this code I probably have locked up the browser right can i scroll can I select anything no so I need to kill this page I'm going to close this page and go back and look so let's let's debug this together ah this should be K by the way because I'm looking at all the tokens and where could the loop have gone wrong ah here we go that should be that used to be a less than I had equals I had an infinite loop stuck in there I'm gonna kill this page okay let's come back run this again but still got a problem let's look at this some more infinite loop anywhere okay I'm back I think there was actually a caching issue when I had that infinite loop so I now I just restarted the the webserver that I'm running and so I now have this running again but I still don't know if I fix the problem okay can I tree property split of undefined line forty why don't I have undef' is uh why is that Oh J this should be J that's really important that has to be J it's part of that loop cough hat okay things are still good and now this is where I'm doing the quick little concordance things are still working I don't know what went wrong there but I think I just had the infinite loop and the infinite loop the browser couldn't like not get out of the cache of that or whatever so let me look at counting now and we can see look at this a is in one document with a term frequency of 8 above is in one document the term frequency of 1 now this doesn't really seem right to me I expect that I should have some document frequencies of more than one okay so let's see if we can figure out if the document frequency isn't working properly so one thing is I should definitely add this to lowercase thing let's see if that helps and I'm going to say counts again and you know a we should definitely a should be in more than one document and just to be sure about that let's go to the files eclipse and I'm going to add a a a just to be sure about that I'm going to add a couple instances of a just in case it it wasn't and now I'm going to refresh this and look at the counts and then we go to a and the document frequency is still 1 so there is a mistake here let's see if we can figure out what I did wrong in the actual code so now I'm going back to sketch J s so let's look at let's look at all these temp counts so as I run this let's look at all these little mini hash tables I created for each other document 1 true true 1 true so this this looks right a is true so I'm definitely getting why I put the value is true oh I said true and then I checked if it's equal to 1 so that has to match of course I want to know why I put true to keep track of it's in the document and so I could just check if that evaluates to true or false so that that's clear the problem and I can I can take out this console dot log and I can look at the counts again and I can now say a document frequency is still 1 okay so that doesn't seem like it makes sense oh boy I see the problem it's very obvious which is that I used word to keep track of the word that I'm currently trying to determine the document frequency and then later in the inner loop I kind of like I made a different word variable and in JavaScript you can't really have these like local variables they clash everything and this is this is a total mess I can't have declare a new variable in a sort of like local or more local scope than the then another variable with the same name so actually I think I just want to get rid of the use of I'm just going to I'm going to call this W that'll solve this problem so I'm just going to use W down here so that when I'm down here I'm referring to the correct word now come on everybody are you with me let's look at the counts and let's look at a and we've got a document frequency is four this is excellent news so now we have term frequency being calculated and document frequency being calculated now let's let's make an improvement here this is really I hate to make this video any longer than it is but this is really bothering me that I have I'm redoing the concordance of all those documents for every word which is pretty much ridiculous if I don't say so myself so I'm going to take this out this this loop out and do it once in advance right I want to look through all the other files I'm going to say other Phi other counts is an array right of all the other counts I'm going to create this temporary counts dictionary and then when I'm done creating that temporary counts dictionary I'm going to put it in other counts okay so now I've done it just once I have a nice array of all of the all of the dictionaries all the unique words in the other documents so now when I go through this list of keys I don't have to realize still have to look at all the other concordance is the other counts length but I don't have to redo each one which was kind of absurd and I can say now and I hope I can say now temp counts equals other counts index J so now for every word I can see if it's in the other one so I'm just doing all of these concordance as once and then checking them here so hopefully that fixes this still works up I got a line 77 syntax error which is Oh an extra I'm out of I did too many brackets yeah I Clos into too many brackets and now let's look at counts and let's hope that I'm still seeing the right yes so I just made this enormous ly more efficient which is a really good thing thankfully okay now we can actually now I can actually do the the tfidf score so the next thing I can do is once again look at all the keys and I can calculate the score so how do I do that I can say for I can say give me my I can say give me the TF the the word object and trying to think of giv I'm just gonna say value is a counts and this should really be TF i should change this variable name from counts counts word actually I'm just gonna write oh this is so hard to think of good variable names on the fly but Val is like the worst right so I'm just going to say word up word data that's not much better but the word date is all this stuff the term frequency term frequency and document frequency that's what's in there right now so now term frequency inverse document frequency equals term frequency document frequency TF right I want the term frequency from that object times I need to make it inverse so what are the total number of files I want to say files dot length divided by term the document frequency now by definition I this would be a problem if I could have a document frequency of zero but I started all document frequencies at one so I this shouldn't be a problem so I can put this in parenthesis and then take the logarithm of that and I've done the formula and then I can say why is my text wrapping I don't like that and then I can say T fdf tfidf equals that score and really what I want to do is just this I want to put the score in that object and I don't like the name of this variable I'm just going to call it word object because it stores all the stuff even though it makes me lose my wraps that line again so here we go I want it at tfidf score the tfidf score is the term frequency times the logarithm of the total files divided by the work that the document frequency and now what do I need to do I can just go back down here and say hey guess what remember when I sorted that array I don't want to sort by the term frequency I want to sort by that inverse document frequency score and I want to display that tfidf score and let's see what happens with a rainbow's txt if I run this you can see look at this perfect arc rainbow light cause so we're getting higher numbers for words that are associated with rainbow and a little hack that I can do just to test something else is I can you know let's try sports txt instead if whatever I put first in this array will be checked or conduct unsportsmanlike games such so again I'm not getting or is a bit of an anomaly here because I have such a small data set so or appears very frequently here but if I had a larger data set I would get more accurate results okay so what can you do with this this is a bit of a mess of a video but I have now working code awfully you learn something or you got something out of it couple things I'll mention one is I have a more thoughtfully designed example which again I'll link to in this video but you can find on the A to Z website where if I go here I can actually drag a whole bunch of files in drag and drop them and it'll do tfidf for all of them you can see what it does it actually makes a bunch of clickable links so you know I could click on let's say if I click on Fish txt I can see now I'm getting I think it's like I don't know what the weird let's look at test at txt or rainbow txt we got we getting the same results us I did something different with the math formula of the exam and that but you can see I'm getting basically the same result so you can look at this example if you want a more thoughtfully put together example that allows you to try a bunch of different files and drag and drop them but ultimately I would say to you is number one what's your corpus of text what's a unique and interesting corpus of text that's meaningful to you that you might want to try and number two is how might you present these results in a more creative fashion you know what happens if you did this to all of your emails certain emails one email versus all of your other emails that's a corpus or and how might you visualize that information with color with shapes with drawing or simply in some interactive way to allow a user to play around this idea so if you make anything try anything let me know and I would love love to love to see it so write in the comments or share with me on Twitter at Schiffman and see you soon you
