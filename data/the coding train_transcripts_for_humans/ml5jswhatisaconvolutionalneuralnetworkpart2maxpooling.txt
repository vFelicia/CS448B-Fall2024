With timestamps:

00:00 - [TRAIN WHISTLE]
00:00 - Hi.
00:01 - So if you're here,
this video is really
00:03 - dependent on the previous one.
00:04 - So if you just watched
and you took a break,
00:06 - and talked to your
plants, then welcome back.
00:10 - And I'm here.
00:11 - I'm going to continue
the discussion
00:13 - of convolutional neural
networks building off
00:15 - of what I did before with
the filtering function
00:17 - and take the next
step into max pooling.
00:20 - So I don't want to
keep talking about it
00:22 - because that's exactly what the
video is going to talk about.
00:24 - And I'll see you in the
future because there
00:26 - will be even more of
these after this one, OK?
00:29 - See you soon.
00:29 - Now that I've wrapped up
talking about the convolutions,
00:33 - there's many other
aspects of this diagram
00:36 - but there's one other
really important operation
00:39 - that happens in a convolutional
neural network that's
00:42 - described in this
diagram as sub-sampling
00:45 - that I want to add to my diagram
and my code demonstration.
00:51 - And that is-- and I'm not
going to call it sub-sampling.
00:55 - The common term for this
now is called pooling.
00:58 - And in particular, the
operation that I want to add
01:00 - is max pooling.
01:01 - So there are different
kinds of pooling you can do.
01:03 - But max pooling is the
standard pooling operation
01:07 - for a convolutional
neural network.
01:09 - So max pooling-- I mean,
it's another layer.
01:11 - It can happen at
any given point.
01:14 - So we could max pool before
we apply the convolution.
01:17 - But typically speaking,
the convolutional filters
01:20 - are applied.
01:21 - And then after
those are applied,
01:23 - we get new images out of those.
01:25 - And those go through
a max pooling layer.
01:30 - So I think to
describe it, I think
01:32 - I need to race this
whole diagram so
01:35 - that I can look at max pooling.
01:36 - And then we could kind
of come back to this
01:38 - when we look at the
full architecture.
01:40 - So let's begin with
our 28 by 28 image.
01:47 - Then let's assume I have one
filter just to simplify things.
01:50 - I had one filter
that was 3 by 3.
01:53 - One thing I didn't discuss--
01:55 - and it's going to be more
relevant with the max
01:57 - pooling layer because
I'm going to do something
01:59 - specific with it-- is there's a
term you'll see called stride.
02:04 - And stride refers to--
remember, this filter--
02:08 - I'm not to actually
do this 28 by 28.
02:10 - But this filter is applied
to each and every pixel.
02:15 - We take this filter,
apply it to this pixel.
02:18 - And this gives us a new image.
02:23 - Pixel, apply filter, take
the result into a new pixel.
02:26 - Pixel, apply filter,
take the result,
02:28 - put it into the new pixel.
02:29 - Here's the thing.
02:31 - This is 28 by 28.
02:33 - This is a 3 by 3 filter.
02:36 - I had to start with
this pixel right here
02:38 - because the edges don't
have neighbors on all sides.
02:41 - So ultimately,
this-- sorry, stride
02:46 - refers to how far I
pass the filter along
02:49 - as I'm going through the image.
02:51 - I don't really have
enough spots here.
02:54 - But I could take the
filter and jump over pixels
02:59 - as I'm applying it to reduce
the resolution of the image.
03:03 - In this case, in my code that
I wrote, the stride was one.
03:07 - I just slid over by one.
03:08 - And we can actually see
where the stride would go.
03:11 - This ultimately, right there--
03:13 - the x++, y++--
that's the stride.
03:16 - So I could say x+ equals
stride, y+ equal stride.
03:26 - And set the stride equal to one.
03:28 - So that's what was
happening here.
03:30 - But even with the
stride of one, if I'm
03:32 - skipping the edge pixels,
my new image is 27 by 27.
03:37 - So one thing that's
really key to how
03:41 - a convolutional
neural network works
03:43 - is that the image over
time, as it goes from layer
03:46 - to layer to layer--
03:47 - so this is the convolutional
layer with the filters.
03:52 - And now I'm going to talk
about the pooling layer.
03:56 - The resolution is reduced.
03:58 - And this has a
number of benefits.
04:00 - One is images are high
resolution with millions
04:02 - of pixels.
04:04 - So this learning space
of a neural network,
04:08 - to learn all of the parameters
of every pixel connected
04:10 - to every filter throughout
multiple layers,
04:12 - it would just be much
too big to realistically
04:15 - be computationally
realistic to do.
04:18 - So this process of reducing
the image down, and down,
04:21 - and down as the layers
is effective in keeping
04:24 - things manageable.
04:25 - But it also has
another benefit, which
04:27 - is we're trying to boil
the essence of the image
04:29 - down into something
that will highlight
04:32 - key features in that image.
04:34 - And so this is really
what max pooling does.
04:39 - One thing it does is it really
reduces the resolution, which
04:42 - I'll show you in a second.
04:43 - But it also picks and
chooses the pixels
04:46 - that have the highest
values to emphasize those,
04:49 - what is really being activated.
04:51 - So pooling comes with
a matrix as well.
04:55 - It's not really a filter
but it's a matrix.
04:57 - And a standard matrix
might be 2 by 2.
05:01 - And so let's take the case--
05:03 - and actually, let me
erase all this just
05:06 - to zero in on pooling.
05:08 - To describe this, I'm going
to start with an 8 by 8 image.
05:11 - And I'm going to do
max pooling with a 2
05:15 - by 2 max pooling
with a stride of 2.
05:20 - So there are no weights.
05:22 - This is not a filter.
05:24 - 2 by 2 is just describing,
how many pixels am
05:28 - I looking at at one given time?
05:31 - If I'm looking at a
2 by 2 area of pixels
05:33 - for each iteration of this
algorithm, and then my stride
05:37 - is 2 the next set of pixels.
05:39 - I'll look at is here.
05:40 - The next one is here.
05:42 - The next one is here.
05:43 - So for the columns, I
end up looking at 4.
05:47 - And for the rows, it's the same.
05:49 - It's 8 by 8, 4.
05:50 - So actually, the result
after max pooling is 4 by 4.
05:59 - Now, how does the
algorithm work?
06:01 - This sounds like
some fancy thing.
06:02 - This is actually the
simplest thing ever.
06:04 - Basically, for each one of
these areas of 2 by 2 pixels,
06:08 - take the largest value,
the brightest color,
06:12 - and put it in there.
06:14 - So I'm going to fill in
some arbitrary values here.
06:19 - So I'm not going to fill
this whole thing out.
06:21 - But you see-- I don't know
how well you can see this
06:23 - but I have the
numbers 4, 8, -1, 2.
06:25 - The highest one is 8.
06:27 - It goes here.
06:28 - I have the numbers 3, 3, 1, 9.
06:30 - The highest one is 9.
06:31 - The highest one is 1.
06:34 - The highest one is 10.
06:35 - And so the max pooling
algorithm takes
06:38 - these little neighborhoods,
2 by 2 max pooling, skips,
06:42 - goes from one to the
other with a stride of 2.
06:44 - I could have just moved
these neighborhoods just
06:48 - by one or by even
a larger amount.
06:51 - But this is pretty typical.
06:52 - This has the benefit of
sub-sampling the image,
06:55 - reducing it but not just--
06:57 - we could do average pooling.
06:58 - So you could do average
pooling, average all of these.
07:00 - But it turns out that
convolutional neural networks
07:03 - perform better with max pooling
over average pooling-- maybe
07:06 - not in all cases, but in
sort of the standard image
07:09 - misclassification case.
07:10 - And this is because
what we're looking
07:12 - for are features in the image
that we want to highlight.
07:16 - And so by looking at an area of
pixels and seeing which pixels
07:21 - activated the most and
keeping that one, that's
07:24 - going to really
emphasize and help
07:26 - boil the essence of the
image down into something
07:28 - lower resolution.
07:30 - I should add, just to be
really accurate here--
07:32 - and the chat is offering some
different opinions about this--
07:35 - that while max pooling is the
most common historical example
07:38 - of pooling in a
convolutional neural network,
07:41 - there are other researches
showing promising results
07:44 - from things like
dilated pooling, which
07:46 - is a new concept to me that I
just looked up and read about.
07:49 - You can also do a combination
of max pooling and average
07:51 - pooling.
07:52 - So there is, I think, some
discussion and research
07:54 - happening there.
07:54 - And I'm not here
to tell you what
07:56 - is the optimal way to architect
your convolutional neural
08:00 - network.
08:00 - I just want to talk about
it, and explain the process,
08:02 - and look at an example
of it, which is
08:04 - very common like max pooling.
08:06 - So I'm going to write another
function much like convolution
08:08 - but call it pooling.
08:10 - The same thing happens here.
08:12 - I want to receive an image.
08:14 - I want to give an x, y.
08:15 - I want to return
some RGB value that
08:20 - is the highest RGB values
within that neighborhood.
08:25 - Now, there's an
interesting question here.
08:26 - Do I take the RGB values
from the brightest pixel,
08:30 - whatever they might be?
08:31 - Or do I just take them
the highest R, the highest
08:34 - G, and the highest
B independently
08:35 - and they could be
from different pixels?
08:37 - I don't know the answer
to that right now.
08:39 - Let me just go with actually
picking the brightest
08:40 - R, the brightest G,
and the brightest B
08:42 - separately, independently.
08:47 - So I'm going to start with
the brightest R, G, and B.
08:49 - And I could start with zero.
08:50 - But just to be really,
really safe, absolutely
08:52 - in the convolutional process--
08:55 - the idea of pixels has gone.
08:56 - I'm really just dealing
with numeric data.
08:58 - So I really should, if I'm going
to try to find the brightest,
09:01 - start with negative
infinity because that's
09:04 - the lowest possible number--
09:05 - in JavaScript, that is.
09:07 - Then I want to look
at this 2 by 2 area.
09:16 - And the same thing that I did
before in the convolution,
09:18 - I want to look at the given
pixel and its neighbors.
09:24 - And then I can get the R,
G, and B from that pixel.
09:29 - And now I just want the maximum.
09:31 - I want-- if this R
is greater than what
09:34 - is being stored as
the brightest R,
09:36 - then that R should be
the brightest R, which I
09:38 - can do with the max operation.
09:41 - Bright R is the biggest
between bright R and R.
09:48 - And the same for G and B.
Oh, and it has to be 1 and 2.
09:53 - This is actually all
that I need to do.
09:55 - This is max pooling right here.
09:57 - But now I just need to
return bright R, bright G,
10:00 - and bright B.
10:05 - Next, I'm going to
create yet another image.
10:08 - I'm going to call it pooled.
10:12 - And pooled is also
a blank image.
10:16 - However, if you recall, I'm
going to use a stride of 2
10:21 - so the resolution of that image
is reduced further by half.
10:27 - So I'm actually going to take
out the stride from here.
10:32 - And I'm going to create a
global variable for stride.
10:37 - But this stride
is only referring
10:39 - to the pooling
process because then I
10:42 - can say, create image
dim divided by stride,
10:46 - dimensions divided by stride.
10:49 - Just to add some
comments for a moment,
10:52 - this is convolutional layer.
10:54 - I mean, I'm stimulating the
idea of a convolutional layer.
10:57 - I'm not actually-- there's
no neural network here.
11:00 - There's no machine
learning here.
11:01 - I'm just going through
these particular algorithms
11:04 - without matrix
operations, I should add.
11:08 - Then let's add the
pooling operation.
11:14 - So, same thing here--
11:16 - I'm going to go through
all of the pixels.
11:18 - In this case, I
can start at zero.
11:21 - But I still need to only
go to dimensions minus 1
11:26 - because I'm going to
skip every two pixels.
11:32 - And I don't want to end up here.
11:35 - So this is plus equal stride.
11:37 - And this is plus equal stride.
11:41 - I can do the same exact thing.
11:42 - I can create a
variable called RGB,
11:44 - which equals, now, pooling.
11:46 - I want to pool-- what
were my arguments?
11:48 - The image and the x, y.
11:49 - And I should probably call
this max pooling, but whatever.
11:52 - Oh, no, I'm not pooling the cat.
11:55 - The cat was filtered
with convolution.
11:58 - And then the filtered
image is pooled.
12:00 - So I'm pooling filtered
at this given x, y.
12:05 - Then I need to figure out, where
am I putting the resulting RGB
12:10 - values?
12:11 - And putting them in
the image called pooled
12:13 - but that image has the
dimensions of half.
12:15 - So the pooled x is x
divided by the stride.
12:20 - The pooled y is y
divided by the stride.
12:23 - And then the index is--
12:25 - so this is why this
function really
12:28 - needs the image passed with it.
12:30 - I should not have used
the global variable.
12:33 - It was a terrible idea
because I want to reuse it
12:35 - but I have a different
resolution of image.
12:37 - I'm going to go back
to making this image.
12:40 - And then where did I call it?
12:42 - Here it's image.width.
12:45 - I need it here-- image.
12:49 - Anywhere else?
12:50 - Oh, here-- image.
12:52 - So now I can say index of pixel
x, pixel y in the pooled image.
12:59 - Because I want to
say pooled.pixels,
13:03 - pix plus 0 equals RBG.R.
13:09 - And I need to add the load
pixels and update pixels.
13:15 - And now this should be
the max pooling operation.
13:18 - Go over the filtered
image by the stride.
13:22 - For every 2 by 2 area, find
the highest RGB values.
13:27 - And then add those to
the corresponding pixel
13:31 - in the lower-resolution
pooled image.
13:34 - Let me make the height
of my canvas times 2
13:37 - so I can put the pooled
image at the bottom right.
13:41 - So the filtered image
went off to the right.
13:44 - And now the pooled image should
go also off to the right.
13:51 - And let's give this a try.
13:55 - I don't see the pooled image!
13:57 - This should be a G. I forgot
to add the alpha in again.
14:02 - I always forget this.
14:05 - So I need to give it the alpha.
14:12 - There we go.
14:16 - So let's go back
to a known filter
14:18 - instead of having
random filters.
14:23 - So that was my edge detection.
14:24 - And you can see this is just--
14:26 - I mean, visually what
I'm seeing right now
14:28 - is kind of like a
lower-resolution version
14:30 - of what you have above.
14:31 - But if I were to rewrite this
with, say, average pooling,
14:35 - I think you would
see it different.
14:37 - It wouldn't come--
those features,
14:39 - these edge features that in
a neural network would be
14:42 - discovering-- here I'm
telling it to look for those--
14:45 - are highlighted
even more than they
14:47 - would be with just
average pooling itself.
14:49 - So now that I've shown you
the code for both applying
14:52 - a convolution filter to an image
and then a pooling algorithm
14:56 - to that image with
a variable stride,
14:59 - I think that I can now go
back and look at the larger
15:03 - diagram of the full story of
a convolutional neural network
15:08 - that has these components in it.
15:11 - And again, our reference
point is this diagram
15:14 - from the 1998 paper
Gradient-Based Learning Applied
15:18 - to Document Recognition.
15:19 - I also want to highlight
for you a blog post that
15:21 - was really helpful
for me when I was
15:23 - reading up, and
researching, and trying
15:24 - to learn about convolutional
neural networks.
15:26 - It's this blog post right here--
15:28 - An Intuitive Explanation Of
Convolutional Neural Networks
15:31 - from 2016.
15:34 - This diagram is super helpful.
15:35 - It is exactly what I want
to talk through, basically.
15:38 - And there are a lot of nice
visual diagrams and animations
15:41 - of the convolution process,
convolutional filters,
15:45 - as well as the max
pooling algorithm itself.
15:49 - Here's my best attempt,
now, at the full story
15:53 - of the convolutional
neural network.
15:55 - We start with an image.
15:58 - The first layer is a
convolutional layer.
16:01 - And I'm writing 2D because a lot
of times in a machine learning
16:04 - library, you can
have convolutions
16:07 - in different dimensions.
16:08 - And we're working with a
two-dimensional convolution
16:10 - here.
16:11 - The convolutional layer
has a number of filters.
16:16 - The image is sent to every
one of those filters.
16:20 - And these filters are applied.
16:23 - I should say that the values
that come out of the filters
16:26 - aren't just the raw values
from the convolution process.
16:30 - They're also then passed
through an activation function,
16:33 - the same kind of
activation function
16:34 - that's in a standard
layer or a dense layer.
16:39 - So typically, this would be
rectified linear unit, RELU.
16:45 - The next step is max pooling.
16:48 - I'll represent that
with little squares.
16:52 - So the image that comes
out of the convolution
16:55 - and the activation function
is then max pooled.
17:01 - And then the output
there is another image.
17:07 - So we take this
first image, pass it
17:09 - through a bunch of filters,
max pool them and a whole bunch
17:12 - of other images that, if
I'm using a stride of 2,
17:14 - now have half the resolution
as the original image.
17:17 - So the question becomes
what to do next.
17:20 - Well, we could be done and pass
this to what is the last layer.
17:24 - And if we're doing
that, at some point
17:27 - the data does have
to be flattened.
17:29 - So everything I did
in my previous video
17:32 - about ML5 neural network
with an image that just gets
17:36 - flattened and passed in, that is
what happens in the last layer.
17:41 - The last dense layer
takes these images
17:44 - and has a hidden
layer of neurons.
17:48 - And each image is flattened
and sent into all of those,
17:53 - and then sent to
the output layer,
17:55 - and passed through the
soft max activation
17:57 - function that I've
described, which gives it
17:59 - a probability for a
classification if this
18:01 - were a classification problem.
18:03 - But what's interesting
is in most cases,
18:06 - if you look at a lot
of these diagrams--
18:07 - for example, this diagram on
the blog post I referred to
18:11 - or this particular
diagram here--
18:14 - you'll see convolutions,
sub-sampling, convolutions,
18:18 - sub-sampling.
18:19 - Let me redraw this to give
myself a little bit of room.
18:21 - I'm running out of room and I
want to diagram the full story.
18:24 - I used so much space
here for this image.
18:33 - So here's the same diagram
but squashed a little bit
18:35 - to the left because I want to
add another convolutional layer
18:39 - and another max pooling layer.
18:41 - So I'm going to add
some more filters here.
18:46 - But something interesting
is going to happen here.
18:48 - So let me actually do fewer
filters in this next layer.
18:53 - And I'm going to really
just only use two.
18:56 - And there's only
two filters here.
18:58 - Well, these images that result
from the first convolutional
19:02 - max pooling process, they need
to be sent to both filters.
19:08 - So this image goes here.
19:09 - This image goes here.
19:12 - So in essence, we have 1,
2, 3, 4 times 2 filters.
19:24 - And I'm not really
drawing this well
19:26 - because I have eight in total.
19:29 - So we get eight new outputs out
of this convolutional layer.
19:34 - And each one of those
needs to be max pooled.
19:39 - So now I have eight images.
19:44 - And remember, let's
say this was 28 by 28.
19:47 - These are all 14 by 14.
19:52 - Then after this convolution
process and this max pooling,
19:54 - these are all now 7 by 7.
19:58 - So we get these progressively
lower and lower resolution
20:03 - feature maps of
the original image
20:06 - with lots of different
filters applied
20:07 - in lots of different ways.
20:09 - And then the final result is
essentially everything that I
20:13 - did in my non-convolutional
neural network with an image,
20:17 - just that one hidden layer--
it's called a fully connected
20:20 - or dense layer--
20:21 - and one output layer.
20:23 - All of that gets put right here.
20:26 - But instead of some original
image being flattened and sent
20:30 - to it, this whole
process has happened.
20:33 - And we're sending the data from
these 7 by 7 images through
20:36 - the one dense layer and one--
and I've totally run out
20:41 - of room here, so I'm just
going to put O here--
20:43 - output layer.
20:44 - And this is where we would
finally see, is it a cat
20:48 - or is it a dog?
20:49 - We would see probability
values for the particular
20:53 - classification task.
20:54 - 1, 2, 3, 4, 5, 6, 7--
20:56 - whoops.
20:58 - I'm missing one here.
21:00 - Even though this is a bit
of a mess, let me go back
21:03 - and refer to and
thank the author
21:05 - of this blog post for this much
more thoughtful and precise
21:10 - diagram showing these different
layers, how the images become
21:15 - lower and lower resolution,
become these final feature
21:18 - maps, and then get passed
through what here is actually
21:21 - two fully connected layers.
21:22 - So there are a
lot of reasons why
21:25 - you might have different
numbers of convolutional layers,
21:29 - different numbers of
fully connected layers,
21:31 - different strides,
different filter sizes.
21:34 - Oh, by the way, another
word for filter is kernal.
21:36 - So really, all I wanted to do in
this video is talk through all
21:40 - of the pieces as
well as show you
21:43 - some code that actually
runs through and does
21:46 - those processes to an
image itself, which I think
21:49 - opens up a lot of interesting
possibilities for you
21:52 - if you wanted to create a
project around visualizing
21:55 - the process of a
convolutional neural network
21:58 - as it's learning.
21:59 - Now, this would be a
much bigger endeavor
22:01 - than what I've done
here because you'd
22:02 - need to create these visuals
out of all of the pieces
22:06 - as the training
process is happening.
22:09 - But ultimately, what
I want to do next
22:11 - is to two slash three things.
22:14 - And it might take a while
for me to get to them.
22:16 - But they will be
eventually, hopefully,
22:17 - in subsequent videos.
22:18 - One is I want to just create
this exact architecture
22:22 - with ML5.
22:23 - So I want to show
you how with ML5 I
22:25 - can make an ML5 neural network
with a convolutional layer,
22:28 - maybe two convolutional
layers, and then a dense layer,
22:31 - and an output layer.
22:32 - Then I can take that and apply
it to the previous example
22:35 - where I didn't use
convoluted layers
22:36 - and just see how that looks.
22:38 - I would also like to
look at something that we
22:41 - could call a doodle classifier.
22:43 - So using the quick-draw
data set that I've
22:45 - referred to in a number
of different videos,
22:47 - could I train a classifier to
recognize particular drawings?
22:52 - And in fact, ML5
has built into it
22:55 - a pre-trained doodle
classification
22:58 - model that's pretty robust.
23:00 - So I might try to train a sort
of smaller version of that,
23:04 - write all the code
for that with ML5,
23:06 - but ultimately then show you
how to use the pre-trained model
23:08 - that's in ML5 as well.
23:10 - But that uses
convolution layers.
23:13 - OK.
23:14 - So thank you so much if you
somehow made it all the way
23:17 - to the end of this rather
long explanation and kind
23:20 - of tinkering around with
code demonstration of what
23:24 - the process of
convolution and pooling
23:27 - is in a convolutional
neural network.
23:29 - I hope to see you in a
future coding training video.
23:31 - I mean, I don't
really see you but I
23:33 - feel your presence somehow.
23:35 - And sometimes you write a
nice comment that brings me
23:37 - a little happiness to my day.
23:38 - So I will see you in that
virtual way in a future video.
23:42 - And thanks for watching
and have a great day that's
23:46 - not convoluted at all!
23:48 - [TRAIN WHISTLE]
23:48 - Goodbye!
23:49 - [MUSIC PLAYING]

Cleaned transcript:

[TRAIN WHISTLE] Hi. So if you're here, this video is really dependent on the previous one. So if you just watched and you took a break, and talked to your plants, then welcome back. And I'm here. I'm going to continue the discussion of convolutional neural networks building off of what I did before with the filtering function and take the next step into max pooling. So I don't want to keep talking about it because that's exactly what the video is going to talk about. And I'll see you in the future because there will be even more of these after this one, OK? See you soon. Now that I've wrapped up talking about the convolutions, there's many other aspects of this diagram but there's one other really important operation that happens in a convolutional neural network that's described in this diagram as subsampling that I want to add to my diagram and my code demonstration. And that is and I'm not going to call it subsampling. The common term for this now is called pooling. And in particular, the operation that I want to add is max pooling. So there are different kinds of pooling you can do. But max pooling is the standard pooling operation for a convolutional neural network. So max pooling I mean, it's another layer. It can happen at any given point. So we could max pool before we apply the convolution. But typically speaking, the convolutional filters are applied. And then after those are applied, we get new images out of those. And those go through a max pooling layer. So I think to describe it, I think I need to race this whole diagram so that I can look at max pooling. And then we could kind of come back to this when we look at the full architecture. So let's begin with our 28 by 28 image. Then let's assume I have one filter just to simplify things. I had one filter that was 3 by 3. One thing I didn't discuss and it's going to be more relevant with the max pooling layer because I'm going to do something specific with it is there's a term you'll see called stride. And stride refers to remember, this filter I'm not to actually do this 28 by 28. But this filter is applied to each and every pixel. We take this filter, apply it to this pixel. And this gives us a new image. Pixel, apply filter, take the result into a new pixel. Pixel, apply filter, take the result, put it into the new pixel. Here's the thing. This is 28 by 28. This is a 3 by 3 filter. I had to start with this pixel right here because the edges don't have neighbors on all sides. So ultimately, this sorry, stride refers to how far I pass the filter along as I'm going through the image. I don't really have enough spots here. But I could take the filter and jump over pixels as I'm applying it to reduce the resolution of the image. In this case, in my code that I wrote, the stride was one. I just slid over by one. And we can actually see where the stride would go. This ultimately, right there the x++, y++ that's the stride. So I could say x+ equals stride, y+ equal stride. And set the stride equal to one. So that's what was happening here. But even with the stride of one, if I'm skipping the edge pixels, my new image is 27 by 27. So one thing that's really key to how a convolutional neural network works is that the image over time, as it goes from layer to layer to layer so this is the convolutional layer with the filters. And now I'm going to talk about the pooling layer. The resolution is reduced. And this has a number of benefits. One is images are high resolution with millions of pixels. So this learning space of a neural network, to learn all of the parameters of every pixel connected to every filter throughout multiple layers, it would just be much too big to realistically be computationally realistic to do. So this process of reducing the image down, and down, and down as the layers is effective in keeping things manageable. But it also has another benefit, which is we're trying to boil the essence of the image down into something that will highlight key features in that image. And so this is really what max pooling does. One thing it does is it really reduces the resolution, which I'll show you in a second. But it also picks and chooses the pixels that have the highest values to emphasize those, what is really being activated. So pooling comes with a matrix as well. It's not really a filter but it's a matrix. And a standard matrix might be 2 by 2. And so let's take the case and actually, let me erase all this just to zero in on pooling. To describe this, I'm going to start with an 8 by 8 image. And I'm going to do max pooling with a 2 by 2 max pooling with a stride of 2. So there are no weights. This is not a filter. 2 by 2 is just describing, how many pixels am I looking at at one given time? If I'm looking at a 2 by 2 area of pixels for each iteration of this algorithm, and then my stride is 2 the next set of pixels. I'll look at is here. The next one is here. The next one is here. So for the columns, I end up looking at 4. And for the rows, it's the same. It's 8 by 8, 4. So actually, the result after max pooling is 4 by 4. Now, how does the algorithm work? This sounds like some fancy thing. This is actually the simplest thing ever. Basically, for each one of these areas of 2 by 2 pixels, take the largest value, the brightest color, and put it in there. So I'm going to fill in some arbitrary values here. So I'm not going to fill this whole thing out. But you see I don't know how well you can see this but I have the numbers 4, 8, 1, 2. The highest one is 8. It goes here. I have the numbers 3, 3, 1, 9. The highest one is 9. The highest one is 1. The highest one is 10. And so the max pooling algorithm takes these little neighborhoods, 2 by 2 max pooling, skips, goes from one to the other with a stride of 2. I could have just moved these neighborhoods just by one or by even a larger amount. But this is pretty typical. This has the benefit of subsampling the image, reducing it but not just we could do average pooling. So you could do average pooling, average all of these. But it turns out that convolutional neural networks perform better with max pooling over average pooling maybe not in all cases, but in sort of the standard image misclassification case. And this is because what we're looking for are features in the image that we want to highlight. And so by looking at an area of pixels and seeing which pixels activated the most and keeping that one, that's going to really emphasize and help boil the essence of the image down into something lower resolution. I should add, just to be really accurate here and the chat is offering some different opinions about this that while max pooling is the most common historical example of pooling in a convolutional neural network, there are other researches showing promising results from things like dilated pooling, which is a new concept to me that I just looked up and read about. You can also do a combination of max pooling and average pooling. So there is, I think, some discussion and research happening there. And I'm not here to tell you what is the optimal way to architect your convolutional neural network. I just want to talk about it, and explain the process, and look at an example of it, which is very common like max pooling. So I'm going to write another function much like convolution but call it pooling. The same thing happens here. I want to receive an image. I want to give an x, y. I want to return some RGB value that is the highest RGB values within that neighborhood. Now, there's an interesting question here. Do I take the RGB values from the brightest pixel, whatever they might be? Or do I just take them the highest R, the highest G, and the highest B independently and they could be from different pixels? I don't know the answer to that right now. Let me just go with actually picking the brightest R, the brightest G, and the brightest B separately, independently. So I'm going to start with the brightest R, G, and B. And I could start with zero. But just to be really, really safe, absolutely in the convolutional process the idea of pixels has gone. I'm really just dealing with numeric data. So I really should, if I'm going to try to find the brightest, start with negative infinity because that's the lowest possible number in JavaScript, that is. Then I want to look at this 2 by 2 area. And the same thing that I did before in the convolution, I want to look at the given pixel and its neighbors. And then I can get the R, G, and B from that pixel. And now I just want the maximum. I want if this R is greater than what is being stored as the brightest R, then that R should be the brightest R, which I can do with the max operation. Bright R is the biggest between bright R and R. And the same for G and B. Oh, and it has to be 1 and 2. This is actually all that I need to do. This is max pooling right here. But now I just need to return bright R, bright G, and bright B. Next, I'm going to create yet another image. I'm going to call it pooled. And pooled is also a blank image. However, if you recall, I'm going to use a stride of 2 so the resolution of that image is reduced further by half. So I'm actually going to take out the stride from here. And I'm going to create a global variable for stride. But this stride is only referring to the pooling process because then I can say, create image dim divided by stride, dimensions divided by stride. Just to add some comments for a moment, this is convolutional layer. I mean, I'm stimulating the idea of a convolutional layer. I'm not actually there's no neural network here. There's no machine learning here. I'm just going through these particular algorithms without matrix operations, I should add. Then let's add the pooling operation. So, same thing here I'm going to go through all of the pixels. In this case, I can start at zero. But I still need to only go to dimensions minus 1 because I'm going to skip every two pixels. And I don't want to end up here. So this is plus equal stride. And this is plus equal stride. I can do the same exact thing. I can create a variable called RGB, which equals, now, pooling. I want to pool what were my arguments? The image and the x, y. And I should probably call this max pooling, but whatever. Oh, no, I'm not pooling the cat. The cat was filtered with convolution. And then the filtered image is pooled. So I'm pooling filtered at this given x, y. Then I need to figure out, where am I putting the resulting RGB values? And putting them in the image called pooled but that image has the dimensions of half. So the pooled x is x divided by the stride. The pooled y is y divided by the stride. And then the index is so this is why this function really needs the image passed with it. I should not have used the global variable. It was a terrible idea because I want to reuse it but I have a different resolution of image. I'm going to go back to making this image. And then where did I call it? Here it's image.width. I need it here image. Anywhere else? Oh, here image. So now I can say index of pixel x, pixel y in the pooled image. Because I want to say pooled.pixels, pix plus 0 equals RBG.R. And I need to add the load pixels and update pixels. And now this should be the max pooling operation. Go over the filtered image by the stride. For every 2 by 2 area, find the highest RGB values. And then add those to the corresponding pixel in the lowerresolution pooled image. Let me make the height of my canvas times 2 so I can put the pooled image at the bottom right. So the filtered image went off to the right. And now the pooled image should go also off to the right. And let's give this a try. I don't see the pooled image! This should be a G. I forgot to add the alpha in again. I always forget this. So I need to give it the alpha. There we go. So let's go back to a known filter instead of having random filters. So that was my edge detection. And you can see this is just I mean, visually what I'm seeing right now is kind of like a lowerresolution version of what you have above. But if I were to rewrite this with, say, average pooling, I think you would see it different. It wouldn't come those features, these edge features that in a neural network would be discovering here I'm telling it to look for those are highlighted even more than they would be with just average pooling itself. So now that I've shown you the code for both applying a convolution filter to an image and then a pooling algorithm to that image with a variable stride, I think that I can now go back and look at the larger diagram of the full story of a convolutional neural network that has these components in it. And again, our reference point is this diagram from the 1998 paper GradientBased Learning Applied to Document Recognition. I also want to highlight for you a blog post that was really helpful for me when I was reading up, and researching, and trying to learn about convolutional neural networks. It's this blog post right here An Intuitive Explanation Of Convolutional Neural Networks from 2016. This diagram is super helpful. It is exactly what I want to talk through, basically. And there are a lot of nice visual diagrams and animations of the convolution process, convolutional filters, as well as the max pooling algorithm itself. Here's my best attempt, now, at the full story of the convolutional neural network. We start with an image. The first layer is a convolutional layer. And I'm writing 2D because a lot of times in a machine learning library, you can have convolutions in different dimensions. And we're working with a twodimensional convolution here. The convolutional layer has a number of filters. The image is sent to every one of those filters. And these filters are applied. I should say that the values that come out of the filters aren't just the raw values from the convolution process. They're also then passed through an activation function, the same kind of activation function that's in a standard layer or a dense layer. So typically, this would be rectified linear unit, RELU. The next step is max pooling. I'll represent that with little squares. So the image that comes out of the convolution and the activation function is then max pooled. And then the output there is another image. So we take this first image, pass it through a bunch of filters, max pool them and a whole bunch of other images that, if I'm using a stride of 2, now have half the resolution as the original image. So the question becomes what to do next. Well, we could be done and pass this to what is the last layer. And if we're doing that, at some point the data does have to be flattened. So everything I did in my previous video about ML5 neural network with an image that just gets flattened and passed in, that is what happens in the last layer. The last dense layer takes these images and has a hidden layer of neurons. And each image is flattened and sent into all of those, and then sent to the output layer, and passed through the soft max activation function that I've described, which gives it a probability for a classification if this were a classification problem. But what's interesting is in most cases, if you look at a lot of these diagrams for example, this diagram on the blog post I referred to or this particular diagram here you'll see convolutions, subsampling, convolutions, subsampling. Let me redraw this to give myself a little bit of room. I'm running out of room and I want to diagram the full story. I used so much space here for this image. So here's the same diagram but squashed a little bit to the left because I want to add another convolutional layer and another max pooling layer. So I'm going to add some more filters here. But something interesting is going to happen here. So let me actually do fewer filters in this next layer. And I'm going to really just only use two. And there's only two filters here. Well, these images that result from the first convolutional max pooling process, they need to be sent to both filters. So this image goes here. This image goes here. So in essence, we have 1, 2, 3, 4 times 2 filters. And I'm not really drawing this well because I have eight in total. So we get eight new outputs out of this convolutional layer. And each one of those needs to be max pooled. So now I have eight images. And remember, let's say this was 28 by 28. These are all 14 by 14. Then after this convolution process and this max pooling, these are all now 7 by 7. So we get these progressively lower and lower resolution feature maps of the original image with lots of different filters applied in lots of different ways. And then the final result is essentially everything that I did in my nonconvolutional neural network with an image, just that one hidden layer it's called a fully connected or dense layer and one output layer. All of that gets put right here. But instead of some original image being flattened and sent to it, this whole process has happened. And we're sending the data from these 7 by 7 images through the one dense layer and one and I've totally run out of room here, so I'm just going to put O here output layer. And this is where we would finally see, is it a cat or is it a dog? We would see probability values for the particular classification task. 1, 2, 3, 4, 5, 6, 7 whoops. I'm missing one here. Even though this is a bit of a mess, let me go back and refer to and thank the author of this blog post for this much more thoughtful and precise diagram showing these different layers, how the images become lower and lower resolution, become these final feature maps, and then get passed through what here is actually two fully connected layers. So there are a lot of reasons why you might have different numbers of convolutional layers, different numbers of fully connected layers, different strides, different filter sizes. Oh, by the way, another word for filter is kernal. So really, all I wanted to do in this video is talk through all of the pieces as well as show you some code that actually runs through and does those processes to an image itself, which I think opens up a lot of interesting possibilities for you if you wanted to create a project around visualizing the process of a convolutional neural network as it's learning. Now, this would be a much bigger endeavor than what I've done here because you'd need to create these visuals out of all of the pieces as the training process is happening. But ultimately, what I want to do next is to two slash three things. And it might take a while for me to get to them. But they will be eventually, hopefully, in subsequent videos. One is I want to just create this exact architecture with ML5. So I want to show you how with ML5 I can make an ML5 neural network with a convolutional layer, maybe two convolutional layers, and then a dense layer, and an output layer. Then I can take that and apply it to the previous example where I didn't use convoluted layers and just see how that looks. I would also like to look at something that we could call a doodle classifier. So using the quickdraw data set that I've referred to in a number of different videos, could I train a classifier to recognize particular drawings? And in fact, ML5 has built into it a pretrained doodle classification model that's pretty robust. So I might try to train a sort of smaller version of that, write all the code for that with ML5, but ultimately then show you how to use the pretrained model that's in ML5 as well. But that uses convolution layers. OK. So thank you so much if you somehow made it all the way to the end of this rather long explanation and kind of tinkering around with code demonstration of what the process of convolution and pooling is in a convolutional neural network. I hope to see you in a future coding training video. I mean, I don't really see you but I feel your presence somehow. And sometimes you write a nice comment that brings me a little happiness to my day. So I will see you in that virtual way in a future video. And thanks for watching and have a great day that's not convoluted at all! [TRAIN WHISTLE] Goodbye! [MUSIC PLAYING]
