With timestamps:

00:05 - [Music]
00:30 - [Music]
01:28 - a
01:30 - [Music]
01:46 - [Music]
02:13 - [Applause]
02:14 - [Music]
02:28 - the
02:31 - [Music]
02:59 - good boy morning everyone uh well it
03:01 - might not be morning to where you are
03:03 - but it is for me I know the music might
03:05 - be a little bit loud right now uh I will
03:07 - adjust that balance in a
03:09 - moment uh but um let me know if you can
03:12 - hear me okay I'll be getting started in
03:14 - just a minute uh you might hear more of
03:18 - an echo than usual because um the audio
03:23 - filtering that I typically use is not on
03:25 - right now all right just let me know if
03:26 - the this my quick audio check I'll be
03:28 - starting in about a minute and
03:30 - [Music]
03:58 - yeah
04:02 - [Music]
04:58 - n
05:01 - [Music]
05:28 - n
05:32 - [Music]
05:58 - a
06:01 - [Music]
06:05 - hello everyone let's see here here we go
06:11 - uh let's turn this down just a tiny
06:14 - [Music]
06:17 - bit uh welcome everyone to a Monday
06:20 - morning coding train live stream
06:23 - probably not the most optimal time for
06:27 - me to have a live session but it's the
06:29 - time that works for me uh and so here I
06:32 - am I'm attempting to get another uh
06:35 - screen over here with the chat that I
06:37 - might be able to take a look at it but
06:38 - right now I can see the chat over here
06:40 - and I see people
06:43 - um
06:44 - greeting me from San Antonio Texas and
06:48 - chil rainy England it is chilly Sunny
06:53 - New York right now all right so I'm
06:54 - going to try to get right into it today
06:57 - today there's not going to be a lot of
06:58 - the usual coding train uh wasting of
07:02 - time because I have an agenda so let's
07:06 - Jump Right In uh I'm G to open up my web
07:10 - browser
07:11 - here um and see if I can get to this
07:16 - particular page bear with me for a
07:20 - moment and oh the other thing I'm going
07:23 - to do is I'm gonna hit start I'm
07:25 - recording this to
07:27 - dis uh on the off chance I want to try
07:32 - to do something more with it so we'll
07:35 - see unlikely this will just be available
07:38 - as an archive of a live stream but just
07:39 - in case all right so I um first of all
07:42 - hello welcome my name is Dan schiffman
07:44 - you watching the coding
07:47 - drain this is a YouTube channel where I
07:50 - try to do a wide range of things uh but
07:54 - mostly focusing on Creative coding
07:57 - making art with code graphics and
08:00 - animation with code for the beginner and
08:04 - um try uh yeah that's I think that's a
08:07 - good summation of what it is this
08:09 - channel is I
08:11 - also uh this extra screen thing is not
08:14 - going to work for me I don't think well
08:16 - maybe I'll worry about that later um I
08:19 - also happen to have this uh full-time
08:22 - job which keeps me very busy uh teaching
08:25 - at a program called ITP uh and IMA at TI
08:29 - the Arts New York University and this
08:31 - semester I happen to be teaching a class
08:33 - called programming from A to Z now I
08:36 - think apologies for all this
08:40 - uh e you know what's the word for when
08:44 - I'm taking a really long time to set
08:45 - something up I don't remember yes so U
08:48 - let let me address something quickly in
08:50 - the chat AZ ad says no Pops in the mic
08:52 - today so I did some debugging over the
08:55 - weekend about what was causing the pops
08:57 - in the mic and strangely enough I cannot
08:59 - believe this uh it was Nvidia broadcast
09:03 - the software I use that runs the audio
09:05 - through the graphics card and has
09:07 - various features for audio processing
09:09 - and so this room that I'm in this garage
09:12 - is actually quite large if I'm being
09:13 - perfectly honest for a recording there
09:15 - more space than I need and it is not
09:17 - sound treated and it is very empty and
09:20 - it is very echoey so I've just been
09:23 - using the Reverb uh the echo reduction
09:26 - that's in in video broadcast it works so
09:27 - well that I never bothered to
09:29 - uh sound treat the room but so uh you
09:32 - might be hearing a little bit more of an
09:33 - echo today which is also why I'm
09:35 - recording this to disk in theory if I
09:37 - wanted to uh edit this down to a shorter
09:40 - video tutorial um I could do some audio
09:44 - processing and post all
09:52 - right I did not ask for that I don't
09:55 - know if you could you hear that through
09:56 - the mic this is this uh old uh iPad I
10:00 - found that I was like let me set up to
10:02 - have another screen where I could look
10:03 - at the chat because right now although I
10:05 - see there's one message there oh and
10:07 - Simon got their stickers in the mail
10:09 - that's amazing ah it just says enjoy the
10:11 - Stream So I've got um uh a slight and
10:15 - like what's going on over here this is
10:17 - the yeah this is a little bookshelf here
10:20 - it's kind of like cut off there I'm just
10:22 - not going to worry about all there's a
10:23 - lot of flaws today in my setup we're
10:26 - just gonna move along all right so uh
10:29 - let's see programming with text no yeah
10:33 - introduction yeah let's see if this will
10:35 - get me somewhere UHD is okay okay okay
10:40 - okay you're really gonna show me an ad
10:42 - right now thank you very much okay um so
10:45 - this is a particular
10:47 - um this course that I've been teaching
10:50 - at NYU for quite a long time with this
10:53 - as evidenced by this very old thumbnail
10:55 - design that really should be updated um
10:58 - is about different algorithms that you
11:01 - can use to uh analyze and generate text
11:05 - so I look at things like just how do in
11:09 - JavaScript how do you work with the
11:11 - JavaScript string object loading text
11:13 - from a file looking at regular
11:15 - Expressions uh some word counting stuff
11:17 - some text analysis stuff some node stuff
11:20 - some database stuff some speech stuff oh
11:23 - I used to do Chrome extension in this
11:25 - class so this is kind of what the class
11:28 - was was uh six years ago and the current
11:32 - syllabus uh for the class is here and
11:35 - you can kind of see um all of the weeks
11:37 - right now so um a lot of the video a lot
11:42 - of the uh weeks one through four those
11:44 - old videos pretty much still apply weeks
11:47 - five and six uh I have some um I
11:50 - recently recorded and if you go to the
11:53 - coding train Channel right now you would
11:55 - see and just click on videos the most
11:58 - recent videos that came out were um
12:02 - what what I see on my laptop is what you
12:05 - see over
12:07 - here uh most recent videos that came out
12:10 - are oh okay I need to do this um were
12:12 - for uh working on
12:15 - Bots then I've got some videos on Markov
12:17 - chains and context fre grammar that are
12:19 - coding challenges but the material that
12:22 - has been entirely new this semester I
12:26 - don't know if you
12:27 - noticed it actually just had its oneye
12:30 - uh birthday I believe but uh the world
12:33 - of language models and ways that people
12:37 - interact with text-based interfaces in
12:41 - our daily life now has just
12:44 - changed in extraordinary ways uh that is
12:48 - very complicated and I have lots of
12:51 - complicated feelings about that um so
12:56 - regardless of my own
12:59 - uh confusion and wondering about how I
13:03 - might may or may not want to include
13:05 - some of these new tools and Technologies
13:07 - in my own kinds of work and educational
13:11 - materials I do see it as part of my and
13:14 - riser you asks what is clustering sense
13:16 - edings I'm getting there I do see it as
13:20 - um part of my
13:23 - mission uh n mission's too strong of a
13:25 - word but I at least interested in doing
13:28 - some teach ing around how to
13:31 - explore and um learn about more about
13:35 - language models and in particular I'm
13:37 - very interested in this topic of using
13:40 - embeddings for search and retrieval and
13:43 - other kinds of analysis of data so uh
13:46 - protham says are you checking the
13:47 - YouTube chat or the Discord chat by the
13:49 - fact that I'm reading your message here
13:51 - I would say the YouTube chat I have a
13:53 - slight eye over there in the corner of
13:55 - any like I'll see one message in the
13:57 - Discord chat
13:59 - so any urgent things that need to flag
14:02 - my attention put them there um and uh
14:06 - not a sponsor but this is a um Danielle
14:08 - is mentioning my thermos and it's I
14:11 - really love it it's uh I mean I welcome
14:14 - a sponsorship from a fellow I think it's
14:17 - called fellow I own so many of these
14:19 - yeah it says it on the inside and I have
14:20 - some
14:22 - uh very hot coffee in there that was
14:26 - much too hot okay so um
14:29 - the what I've been having a hard time um
14:33 - figuring out how to find the balance
14:34 - between all the different things I'm
14:35 - working on so coding train it's not like
14:37 - on Hiatus but it's a little bit hit or
14:40 - miss these days so I always like to say
14:42 - at the top thank you for those of you
14:43 - who are engaging and supporting the work
14:45 - that I'm doing even when I'm producing
14:47 - much less as usual most of that uh you
14:50 - I'm not going to go too far into this is
14:52 - because of my obsessive work on this
14:54 - nature of code book uh which will be
14:56 - coming out in the summer but you can
14:57 - read it all online lots more to come
14:59 - about that come
15:02 - 2024 um but uh one of the things uh that
15:07 - happened was actually kind of funny
15:08 - because there was a fire drill I was in
15:10 - the middle of talking about uh
15:14 - embeddings uh and and I don't worry I'll
15:16 - get to what that is as best I can uh and
15:19 - I didn't get to finish some stuff that I
15:20 - wanted to do in class um and I have a
15:23 - bunch of examples here um around working
15:26 - with uh Transformers Js
15:29 - where's this going to go by the way um
15:31 - around uh this thing called umap um so I
15:35 - thought I would come and do a live
15:36 - session around it
15:38 - because I can uh because I I'd like to
15:40 - share this with my students who are in
15:42 - the class but also uh share it with all
15:44 - of you uh any of which might be a
15:47 - student in my class but
15:48 - unlikely they're very busy they don't
15:50 - want to watch me on YouTube so tired of
15:53 - me I would assume by this point um I am
15:55 - in my garage in my home so the other
15:58 - reason why I've been a little slow to do
16:01 - stuff uh just a little behind the scenes
16:04 - here uh is that I set up this whole
16:07 - recording studio that's a little bit
16:09 - strong I set up some equipment in my
16:12 - garage and this semester my teaching
16:14 - schedule is much busier than usual so
16:17 - when I used to record videos at NYU I
16:19 - was just there all the time when I was
16:21 - teaching recording whatever now I've
16:22 - kind of separated that a little bit
16:23 - which I think is a good thing in the
16:25 - long run um but I'm actually at NYU like
16:29 - these last couple weeks of the semester
16:30 - Tuesday through Friday so today is my
16:33 - only day working from home and I have uh
16:36 - uh I mean honestly I have a lot to do I
16:38 - probably shouldn't be doing this right
16:39 - now but at least this is for my class so
16:42 - I I it makes sense got to keep this
16:44 - muscle can't like totally lose the live
16:47 - streaming muscle and
16:50 - um yeah so as long as I get out of here
16:53 - by like noon 12:30 at the absolute
16:55 - latest I'll be able to do all my other
16:57 - meetings and office hours and different
16:58 - things this afternoon go in for the rest
17:01 - of my work week and yeah but really here
17:04 - I what I'm excited about so even though
17:06 - so just to set the stage a little
17:10 - bit um so many wonderful questions in
17:14 - the chat I'm sorry I'm not really going
17:15 - to be able to answer them this is this
17:17 - is not intended this is a w I would call
17:19 - this a wintry hoodie sweater hoodie uh
17:22 - it's not intented to be a hoodie related
17:25 - to a very specific holiday that happens
17:27 - around this time of year that I do not
17:29 - celebrate even though my family insists
17:31 - on somehow kind of partially at least
17:33 - mostly celebrating oh they'll get you
17:36 - there those those
17:38 - rascally kids
17:41 - um it's winry themed it's very it's it's
17:44 - actually it's pretty good it's not that
17:45 - cold here in the garage I was running
17:46 - the heater all morning and I turned it
17:48 - off now for sound and it's sunny so I'm
17:50 - getting some sun in here um all right
17:55 - so uh yeah so here's the thing um I
17:59 - think I can just open up this
18:02 - example um and I'm going to log in as
18:04 - the coding train I'm gonna just show you
18:07 - the very end of this I'm going to build
18:09 - the whole thing during this stream let
18:11 - me show you what's coming at the
18:14 - end it'll be slightly different because
18:16 - maybe I want to use a different data set
18:18 - it's it in here no that's not it wait
18:21 - where is
18:22 - it oh I know it is I messed up I
18:25 - overwrote another example and maybe I
18:27 - should fix that uh H hold on it's
18:31 - actually linked in a very weird
18:33 - place which would
18:37 - be here yeah this is it's like I messed
18:40 - some things up but oh no wait this is
18:43 - the right one oh no this is what the
18:44 - slide oh my God I
18:48 - what what everything is
18:52 - wrong okay it's okay I'm gonna find it I
18:55 - know how to find I this is by the way
18:58 - what actually happens in my class I you
19:00 - I feel like I'm so prepared then I can't
19:02 - I messed up a link and I can't find the
19:04 - right thing then nothing
19:06 - works it's very hard it's very hard no
19:09 - no no don't go here okay don't worry I'm
19:11 - gonna get you this example I know
19:13 - exactly where it is it's it's right here
19:17 - okay let's run this I'm going to do
19:19 - share I'm gonna go to
19:22 - full all right I'm sorry for the very
19:25 - flast fast flickering here I'm not doing
19:28 - anything fancy to animate this in any
19:31 - way uh frogo I am streaming from New
19:34 - York
19:35 - State uh that is about I guess the
19:38 - amount of information that I'm going to
19:39 - give here so what you have just
19:42 - witnessed is and I'll have to zoom in
19:44 - here for you to see a little bit more
19:46 - closely is every function from the p5js
19:50 - reference
19:52 - clustered uh according to a similarity
19:55 - metric so I am look uh basically I have
19:58 - taken a lot you can see all of the
20:00 - loading functions are here there's like
20:03 - some uh some key related stuff here some
20:08 - touch related stuff here uh blend mode
20:11 - and texture is here I'm not saying this
20:14 - is perfect or accurate to how it really
20:17 - should be clustered what I have done
20:19 - just to be the whole story is I have
20:22 - taken a data
20:23 - file
20:27 - and uh let me let me get to that as
20:32 - well I'm again I want to build all these
20:35 - examples but I already did them so I
20:37 - might as well kind of show you the
20:38 - pieces first and then I'll step through
20:39 - building it piece by piece um but I not
20:43 - completely prepared here so let me find
20:46 - this other repo that I need to
20:49 - find um which is called save embeddings
20:52 - Json and again you if you don't know
20:55 - what an embedding is you're in the right
20:57 - place I I kind of don't really either I
20:59 - mean maybe I if you don't at all then I
21:02 - probably know like a little bit more
21:03 - than you so I'll be helpful but I'm not
21:05 - claiming to be some e I'm learning this
21:07 - stuff along with all of you I'm old when
21:11 - I learned a code we didn't
21:14 - have you know CH gbt that's not even
21:18 - that's like barely the that's like the
21:21 - you know 1% of what I didn't have Okay
21:25 - [Music]
21:27 - um
21:30 - don't think I had this
21:35 - repo why do I have a pass key pass
21:37 - phrase here
21:39 - okay
21:41 - uh just bear with me all right I have
21:46 - this text file that I made manually
21:48 - nothing fancy I just put everything from
21:51 - the P5 reference it's about 400 things
21:54 - into this text file so first of all if
21:57 - you have an idea by okay so first of all
22:00 - I'm as every once a while I'll answer a
22:01 - question in the chat uh wait why why why
22:05 - does this iPad just out of nowhere
22:07 - decide to talk to
22:09 - me I'm I'm
22:10 - gonna yeah I'm not I'm not talking to
22:13 - you Siri oh no wait don't say don't say
22:17 - it uh amirali asks you make a 3D so yes
22:22 - one of my prompts to you will be I'm
22:25 - going to show you how to do it in 3D but
22:27 - I'm I'm not here my overall goal here
22:29 - and I realize I'm jumping around a lot
22:31 - now uh which is why I shouldn't look at
22:32 - the chat probably is to give you a very
22:35 - base level without a design point of
22:37 - view example of how to do this and my
22:40 - hope then is that many of you will find
22:43 - an interesting data set and visualize it
22:45 - in your own way um and I'll show you
22:47 - some other examples the embedding
22:49 - projector from um researchers at Google
22:52 - is a is a really good example of this
22:54 - that I will get to uh all right so this
22:57 - is a tech text file that has everything
23:00 - from the P5 reference and what I have
23:03 - done is I have taken each one of those
23:07 - terms and uh used uh what is called an
23:10 - embedding model to create this embedding
23:12 - which is a list of numbers and then that
23:15 - is being uh brought in to a P5 sketch if
23:20 - I could find
23:22 - it where here um and I'm using a
23:25 - particular
23:26 - algorithm uh uh which is called umap
23:31 - to uh
23:33 - to do dimensionality reduction and what
23:37 - I mean by that is all of those
23:38 - embeddings are long list of numbers in a
23:41 - very high-dimensional space and I want
23:43 - to see all those things plotted in a
23:45 - two-dimensional space and umap is a
23:48 - particular algorithm that does that so
23:50 - that is the full story from start to
23:53 - finish the fly is back um of this
23:58 - example project that I want to build
24:01 - without a lot of the details filled in
24:03 - so if you will give me a minute here I
24:08 - am going to you can ask a few questions
24:10 - in the
24:12 - chat um and I could maybe answer them
24:16 - but I'm going to just get myself set up
24:18 - here with then I'll put on a little
24:20 - [Music]
24:26 - music
24:28 - [Music]
24:46 - [Music]
25:01 - [Music]
25:18 - [Music]
25:26 - n
25:31 - [Music]
26:01 - [Music]
26:26 - e
26:28 - [Applause]
26:30 - [Music]
26:36 - all right I am back so let me uh take a
26:40 - look at the chat see if there's any
26:43 - questions um so let me just answer a few
26:45 - of these questions real quick any reason
26:47 - to use umap in instead of tne uh the
26:50 - reason I'm using umap instead of tne is
26:52 - twofold one I heard it's the newer one
26:55 - it's better I mean that probably is not
26:58 - actually true and there is a lovely uh
27:01 - JavaScript implementation of umap that
27:03 - runs beautifully in the browser and so
27:05 - since that's available that's what I'm
27:07 - using um any chance you'll be doing the
27:10 - Advent of code I'm interested in doing
27:12 - it I this is my busiest time of year
27:14 - teaching so um I wish I think I'm more
27:18 - likely to participate in January which
27:20 - is coming in January but I would love to
27:22 - do at least one Advent of code maybe I
27:24 - can do like solve one and try to do it
27:25 - as like a YouTube short
27:28 - um uh is there a way to Cluster similar
27:30 - things
27:31 - together oh okay that's Raj is just
27:34 - explaining what's going on but yes to be
27:36 - clear my P5 functions is just an example
27:41 - data set and I can use any data set of
27:45 - text and the as long as the text is
27:48 - chunked into individual elements I can
27:51 - do what I'm going to do in this video so
27:54 - for example I could do lines from a
27:56 - Shakespeare play I could do do the list
27:58 - of P5 functions I could do I could do uh
28:02 - uh captions from one of my coding train
28:04 - videos um there are lots of things I
28:06 - could do if you have an idea the reason
28:08 - why I am uh using singular words just as
28:13 - an example is because it's a little
28:15 - easier for me to visualize I can just
28:17 - put the words on the screen if I'm
28:19 - clustering larger blocks paragraphs of
28:21 - text uh maybe I could represent those as
28:23 - dots and you hover over them and then
28:25 - you see the paragraph so I could do that
28:26 - too but if you have an idea for a data
28:30 - set that might make sense for me to do
28:33 - today in this video uh you could drop it
28:36 - into the chat I'll probably miss it I
28:39 - don't know if we have any moderators
28:41 - here today because this was one is I'm
28:43 - disorganized and uh uh I'm trying to uh
28:46 - reorganize for 2024 a new uh group of
28:49 - moderators so if you're interested come
28:51 - join the Discord um but um you could
28:56 - like if if anybody sees an interesting
28:57 - data set and I miss it uh feel free to
29:00 - um I don't know try to highlight it for
29:02 - me certainly in the Discord uh member
29:04 - chat is where I would see it
29:08 - okay so oddly enough you're probably not
29:12 - aware of this but um I did recently uh
29:16 - uh cover a little bit of this in a live
29:17 - stream previously and what I talked
29:20 - about in that live stream was just the
29:23 - idea of I I kind of talked about how I
29:26 - wanted to do this and I hadn't done it
29:28 - yet um so I feel like I just want to
29:31 - like uh kind of recap I'm trying to
29:33 - think of where to start let's start with
29:36 - I just need an
29:39 - eraser let's start with what is an
29:43 - embedding
29:51 - o one of these work have some wipes
29:56 - here just give me a second this
29:59 - is this is why I'm recording to disc cuz
30:06 - maybe uh all
30:21 - right come
30:23 - on
30:25 - little doohickey I guess I should have
30:28 - done this before I
30:30 - started I'll get
30:37 - there
30:42 - uh by the way and I apologies to uh I
30:47 - forget the name of the company who
30:49 - reached out to me and I was in contact
30:50 - with about mounting a whiteboard on this
30:52 - wall anybody's got like a recommendation
30:55 - for like the best whiteboard could ever
30:57 - possibly buy to do diagramming on for
31:00 - videos that I could easily light I've
31:03 - looked into digital ones but don't think
31:06 - that's really going to work for me but
31:08 - this one this one I bought um from like
31:11 - a office supply store and I put it
31:13 - together myself and it's a little one is
31:16 - I did a terrible job putting it together
31:18 - myself it's a little bit
31:20 - clunky uh okay so I'll leave um a bit of
31:25 - what was on this whiteboard from before
31:27 - for um what I'm doing today is very much
31:31 - connected to large language models like
31:34 - chat GPT like the Llama model like uh
31:39 - Claude Claude um in that those models
31:44 - use a particular deep learning
31:46 - architecture called
31:48 - Transformers uh you know you I talked
31:51 - about this a bit in my last live stream
31:53 - there's the famous you know ancient
31:55 - paper now 2018 uh attention is all you
31:59 - need so I'm not going to in this
32:01 - particular session talk through uh what
32:05 - the architecture of a transformer model
32:08 - is how they're trained how they work
32:11 - that's part of the materials of my class
32:13 - and if you poke around in the syllabus
32:15 - you you're be welcome to find that stuff
32:17 - but it is highly connected because the
32:20 - same model architecture that is present
32:23 - in a Transformer a large language model
32:26 - is present in what is called an
32:29 - embedding model and I'm probably going
32:31 - to get this slightly wrong but in
32:34 - essence you don't an embedding mod in my
32:37 - mind and again I'm I'm G to Pro
32:39 - oversimplify this and I'd be curious to
32:41 - hear from the chat or anyone later
32:42 - watching this in the comments how
32:44 - accurate this is
32:46 - but well let's actually so I I'm watch
32:49 - the time have a tendy to over
32:51 - overexplained but let's talk about it in
32:53 - this way this is the way that I think
32:55 - about it and maybe it will be helpful so
32:57 - I've made a lot of videos about transfer
33:00 - learning and again this is I'm going off
33:02 - on a little side to come back to this
33:04 - and with teachable machine for example
33:07 - maybe you've watched some of those uh
33:09 - feature extraction so if I have an image
33:13 - classifier and that image has a cat in
33:16 - it well I let's say I don't have an
33:18 - image classifier yet I have an image of
33:20 - a cat and I'm going to send it into an
33:23 - image classifier that image classifier
33:26 - is presumably going to be a
33:28 - convolutional neural network and it's
33:30 - going to have a bunch of layers and at
33:33 - the very end it's going to produce a
33:36 - layer that's often referred to as
33:39 - logits uh we could call those
33:42 - features and then those will have an
33:45 - algorithm applied to it uh uh usually
33:47 - something called Soft Max which then
33:51 - turns it into a set of probabilities
33:55 - tied to each particular tied to a
33:57 - particular label so the the the the
33:59 - mobilet model which is what I use in a
34:02 - lot of my ml5 Js and other image
34:05 - classification tutorials has 1,000 uh
34:09 - you know 1,000 logits for 1,000 labels
34:13 - and presumably here at the end this cat
34:18 - label after softmax is applied would
34:21 - probably have a very high probability
34:23 - and we get that aha there is a cat in
34:27 - this image so again lots of details
34:28 - skipped here you can find a lot of this
34:30 - in my other you know beginner's guide to
34:32 - machine learning etc etc I'm just KCK me
34:34 - an eye on the chat uh to make sure
34:36 - there's no oh and Nik is in the chat hi
34:40 - Nik oh good well nikil by the way when I
34:43 - get everything
34:45 - wrong nille will correct it you don't
34:48 - have to say n but and I'm going to show
34:51 - the embeddings projector in a little bit
34:52 - which is uh uh thank you for joining
34:54 - nille nille is one of the creators of
34:57 - and if I've gotten that wrong you can
34:58 - correct me in the chat okay so one of
35:02 - the things that happens in a transfer
35:04 - learning process is uh um that a model
35:10 - can be basically retrained to associate
35:15 - different labels with the Logics the
35:19 - features of a particular image so in a
35:22 - transfer learning scenario in a feature
35:24 - extraction scenario the prob abilities
35:27 - and their Associated labels are no
35:29 - longer relevant and instead you just
35:31 - keep this list of Logics which is like a
35:34 - list of 1,000
35:37 - numbers and guess what in my mind these
35:42 - 1000 numbers are an embedding for this
35:46 - image basically let's say this image is
35:50 - I'm not going to be able to do this math
35:52 - 640 by 480 that's a lot of pixels so
35:57 - what is the data if I wanted to have a
36:00 - numeric signature for this image well I
36:02 - I do I have all of the pixels and every
36:05 - pixel has an r a g and a b and it's a
36:07 - lot of information it's not really it's
36:10 - too much it's not that useful I want to
36:13 - in a machine learning context boil the
36:16 - essence of this image down into
36:18 - something
36:20 - smaller like a list of 1,000 imag 10,00
36:24 - numbers so
36:27 - that is the idea now with an image it
36:30 - almost you could sort of think of it as
36:32 - like compression it's not exactly right
36:34 - because we started with numbers and now
36:36 - we have fewer numbers but what if I have
36:38 - you know the Cat in the
36:42 - Hat it's sort of like well I guess like
36:44 - these are asky characters but the asy
36:47 - characters aren't really associated with
36:48 - the meaning so there's this whole
36:50 - process in a Transformer model where
36:54 - first these are chopped up into tokens
36:57 - the the tokenization process is perhaps
37:00 - is more nuanced than this but you could
37:02 - think of it as like oh every word is a
37:04 - token or every syllable is a token but
37:06 - the you know the the developers and
37:08 - researchers that make these models have
37:09 - their own ways of tokenizing text and
37:11 - then each one of those tokens has like
37:13 - an embedding associated with it which is
37:15 - like a list of numbers and that's what
37:17 - becomes the input and then there's all
37:19 - these layers of attention and blah blah
37:21 - blah blah blah we're predicting the next
37:22 - token so this is what I kind of talked
37:23 - about previously and it's the thing that
37:25 - I'm not talking about today
37:27 - which is that if I feed the cat in the
37:31 - as a input to a language model I'm going
37:33 - to get um you know a set of pro of of
37:37 - outputs associated with probabilities
37:38 - but in the same way in my mind in the
37:41 - same way that I removed the end the
37:43 - actual predicted label from this image
37:46 - classifier in a Transformer model I
37:48 - could
37:50 - remove predicting the next tokens and
37:52 - just look at a lot of the internal
37:54 - numbers in the hidden layers and
37:58 - somewhere in there might be the meaning
38:00 - of the the the like have a
38:03 - numeric uh representation of the
38:06 - semantic meaning of what I'm passing
38:09 - in
38:10 - so that in my mind is like an embedding
38:13 - so I want to get an embedding for this
38:15 - piece of text now this is such a useful
38:18 - thing to do and you'll see why in a
38:20 - minute with some of the different things
38:22 - I might do a retrieval augmented
38:24 - generation is another topic related to
38:26 - this this is such a useful thing to do
38:29 - that there are models that are
38:31 - specifically trained and built and
38:33 - designed just for this purpose and
38:35 - they're called uh embedding
38:38 - models they're also sometimes especially
38:41 - when I look at transformers. JS uh it's
38:44 - actually called like feature a feature
38:46 - EXT
38:48 - extraction you know feature a feature
38:50 - being a word to describe a uh a property
38:55 - uh I mean that's a very common word in
38:57 - machine learning I think of it as like
38:59 - oh my facial features but we're doing an
39:01 - act there right if I have a if I have my
39:03 - actual face whether it's a 3D model or a
39:05 - photo of it I'm kind of saying like wow
39:07 - look at my nose it's kind of got this uh
39:10 - kind of shape to it or you know boy that
39:12 - tooth of mine is crooked those are my
39:14 - features so machine learning
39:16 - extrapolates features from things and
39:19 - and those features are Quantified into
39:20 - numbers through the you know all the
39:22 - different processes that are involved
39:24 - okay so I'm going to wander back over so
39:27 - that that's loose loose loose
39:30 - explanation I'm going show you a couple
39:31 - other things that might give you a
39:32 - little bit more information wander back
39:34 - over take a quick peek at the chat and
39:37 - move on to now showing you how to use
39:40 - transformers. JS to feed in any sentence
39:44 - of arbitrary length and get back in
39:46 - embedding okay how does everybody feel
39:48 - about that you can't respond to me you
39:50 - can in the chat I
39:54 - guess okay uh
39:57 - um all right
40:00 - um so I'm going to try to answer some of
40:03 - these questions here for a bit uh Ari
40:07 - Sean asks are these logits tied directly
40:10 - to the model oh sorry I didn't change my
40:12 - view here which I can are these logits
40:15 - tied directly to the model for example
40:17 - if you change the weight of the model so
40:19 - I um so this is a great question and I
40:22 - think I want to rephrase it because I
40:24 - think some of the terminologies maybe
40:26 - getting a little mixed up
40:28 - there um so um so I think the the short
40:33 - the short answer though I think is yes
40:36 - in that and and again I don't really
40:37 - have a diagram here but let's just let's
40:39 - think about
40:41 - this so um this is Mo like this is
40:45 - mobilet here this whole thing I should
40:47 - this mobile Net's not here this is the
40:49 - image input this is the
40:52 - model so the Logics that will come out
40:56 - from feeding this image in are the
40:59 - numbers that you get because of the the
41:01 - weights that are in the mobile net model
41:03 - it's been trained if you were to change
41:05 - the weights of the model you'd get
41:06 - different
41:07 - logits so yes if you had two feature
41:12 - extraction models for images maybe they
41:15 - would give kind of like similar Logics
41:17 - in some way because the you if you fed
41:19 - the same image into them because you
41:22 - know lots of models probably look at
41:23 - images in similar ways but uh not you
41:26 - would not be a you know if you wanted to
41:28 - do a similarity search across uh
41:33 - embeddings that were generate with
41:34 - different models you're going to run
41:36 - into issues because in uh I would think
41:39 - because the embeddings you're getting
41:41 - are tied to the way a particular model
41:44 - was trained and that's very important
41:45 - this is not magic none of this is Magic
41:48 - um and it's easy it's a little bit
41:50 - easier to recognize like if the language
41:52 - model is going to predict the word cat
41:54 - after the cat in the it's because of a
41:58 - you know shared it's because of the
42:00 - training data you know there are many me
42:03 - there's many many examples in whatever
42:06 - you know training data set was used of
42:09 - The Cat in the Hat so it's learned the
42:12 - high probability of hat appearing along
42:14 - with those uh that that particular
42:16 - sequence of tokens so with there you can
42:20 - it's easier to sort of then take the
42:21 - next step and realize like oh there's a
42:23 - real danger of cultural bias and
42:26 - problematic Behavior based on how that
42:29 - training data is collected and curated
42:31 - there's all sorts of questions around
42:33 - copyright and authorship so this is a
42:36 - really important big discussion that I
42:39 - am very interested in it's a little
42:41 - sometimes harder to remember that that
42:43 - discussion still exists for the
42:44 - embeddings because even though all we're
42:46 - getting is the numbers associated with
42:48 - it the fact that the Cat in the Hat is
42:50 - similar to maybe some other sentence is
42:52 - because of all the same questions around
42:54 - bias and data collection in whatever
42:57 - whatever data was used to train that
42:58 - model so if two models with the same
43:03 - architecture were trained with the same
43:04 - data set then if I used and I might get
43:09 - kind of like the same results twice
43:11 - would be slightly different but yes I in
43:13 - the end I think that to answer that
43:15 - question I think um if I'm answering it
43:17 - correctly these Logics are calculated
43:20 - you know at through the process of
43:22 - sending the pixels through the different
43:23 - layers of the convolutional neural
43:25 - network and all of the weights and
43:27 - activation functions and all that stuff
43:29 - okay and I realize not everybody knows
43:31 - all of this and that's fine stay with me
43:34 - here um okay uh so I don't see any uh
43:39 - obvious I see I see people answering
43:41 - other people's questions in the chat
43:42 - which I'm thrilled for um okay so let's
43:45 - just come back to this for a second I'm
43:46 - going to show you this particular
43:48 - example so what this example is showing
43:51 - you just as just as as a as another note
43:54 - of what you can do with this so one of
43:56 - the things that um embeddings can be
44:00 - used for uh
44:02 - is um and I might get some of these
44:04 - terms slightly wrong but like a semantic
44:05 - search or a similarity score between two
44:09 - uh uh blocks of text and so one here's a
44:12 - scenario I'll give you um to let's say
44:15 - you're programming a chatbot and your
44:17 - chatbot knows 10
44:19 - answers and you basically want to like
44:22 - whatever somebody asks you want to give
44:23 - them one of those 10 answers maybe an
44:26 - answer is like I don't know um so let's
44:29 - say the uh question that's asked is what
44:33 - color is the sky and one of your answers
44:37 - that you have is the sky is blue and I
44:40 - think if I go up here so uh or I can oh
44:43 - yeah here is what I'm so what this uh
44:47 - particular example is doing and let's
44:49 - see if I can um do I have it
44:54 - open and this is not what what I'm going
44:56 - to code today even though I'm like and
44:58 - I'm wow I'm at 11:15 already um but I
45:02 - think it's good background for this and
45:03 - it is one of the examples you could look
45:05 - at I think it's here no that's just like
45:09 - a test um is uh this so and I'm conf I'm
45:15 - conflating the idea of questions and
45:16 - answers I just put everything into one
45:18 - array but imagine I had an array of
45:20 - questions and an array of answers
45:22 - basically if I can create an embedding
45:26 - if I can turn every one of these
45:27 - sentences into a list of numbers then I
45:30 - can start to do math with those numbers
45:32 - and whatever results I get from that
45:33 - math I can tie it back to the original
45:35 - text so for example I could look and say
45:38 - like which one of these if I if I take
45:41 - what color is the sky which one of these
45:44 - other one two 3 four five sentences has
45:47 - the most similar numbers to what color
45:50 - is the sky now we got to talk about what
45:51 - does it mean to look at whether the two
45:53 - sets of numbers are similar but just
45:55 - from that you can imagine like if if I
45:58 - just had one number like well this one
46:00 - is six and that one is 5.7 those numbers
46:02 - are kind of similar so that's I can
46:04 - match that distance that difference
46:06 - between the numbers so this what this is
46:09 - showing you I think someone said in the
46:10 - chat is like a comparison Matrix uh
46:13 - which basically you can see I'm mapping
46:14 - the similarity of two sentences to a
46:16 - color so all down the diagonal of course
46:19 - it's I'm getting 100% my mug is in the
46:23 - way there a similarity score of one
46:26 - because they're exactly the same 100%
46:27 - the same and here I'm getting a
46:30 - similarity score of
46:32 - 0.07 because the sky is blue and what is
46:34 - an apple aren't very similar in terms of
46:37 - meaning and structure whatever uh other
46:40 - qualities that we might attribute to how
46:42 - the embeddings were created but the sky
46:44 - is blue and what color in the sky that
46:46 - has a 10 times higher similarity score
46:49 - so another thing that I could build
46:51 - right now is like that chatbot question
46:53 - and answer thing um
46:56 - and I'll also just briefly mention I
46:58 - think I talked about this previously if
47:01 - you look up the concept of and there's a
47:04 - great uh replicate by the way is a a
47:06 - hosting service for models that I've
47:08 - been using a lot of uh not not also not
47:10 - a sponsor but uh has generously given me
47:13 - a lot of credits to use because these
47:15 - things cost money although what I'm
47:16 - going to show you with transform
47:17 - transformers. JS runs on device so it
47:19 - does not cost money um but they have a
47:21 - nice um uh rag tutorial
47:26 - uh how to use retrieval augmented
47:28 - generation uh that explains this idea of
47:31 - retrieval augmented generation so what
47:33 - that means and I have some examp I I'm
47:35 - watching the time I want to show you my
47:36 - retrieval augmented generation example
47:39 - that I built in node uh but I'll come
47:41 - back to that if I have time so that's
47:43 - another place where you could use it let
47:44 - me just tell you what I mean and
47:46 - actually Nik was in the chat ah do I
47:49 - have this um I think I have it uh let me
47:52 - just I'm going to open up nille is one
47:55 - of the founders of a startup called
47:59 - lilac um and I think if
48:06 - I um I think this is it here yeah
48:10 - restart this space um I'm restarting
48:13 - lilac uh Nelle helped me build a uh rag
48:17 - for the nature of code book let's see if
48:19 - it uh wakes up here I should disclose
48:21 - that I do have a business relationship
48:23 - with uh lilac but you should Ely check
48:26 - out the work that they're
48:28 - doing um let's see if this can wake
48:34 - up so retrieve what retrieval augmented
48:37 - generation is is this idea of let's say
48:42 - I want to ask a question and I want the
48:45 - answer to not come from a large language
48:49 - models prior knowledge if you will to
48:52 - use that term but instead to actually
48:54 - come from the nature of code
48:56 - book I could do a similarity search
49:00 - across the entire book it's a question
49:02 - of how do I chunk up the book but let's
49:04 - just say I chunked up the book in
49:06 - paragraphs so I could ask a question
49:09 - like how do you code a
49:11 - fractal and then and I have I maybe I'll
49:15 - run my own example of this while we're
49:17 - waiting I'll just show
49:20 - you don't tell me it's not in here uh
49:23 - example rag replicate
49:26 - let's see
49:28 - uh See if this runs um so if I could
49:34 - write a question this is going to take a
49:35 - little while because this is using a
49:37 - replicate platform um and so that they
49:39 - might have to like boot up the model but
49:41 - I'll ask here like how how do you
49:45 - program the canor
49:47 - set I know that's the example in the
49:49 - Lilac oh wow that went really
49:53 - fast oh did I change I think I changed
49:57 - the data I forgot I was messing with
50:00 - this
50:01 - example and I changed the
50:06 - data uh this is now actually not my
50:08 - nature of code book but a
50:11 - transcript a transcript of um my uh
50:16 - processing tutorial I'll show you how I
50:18 - know this for sure um I'm G ask who is
50:22 - Daniel
50:23 - schiffman or let's say who is I'm just
50:25 - going to say who is shiftman because oh
50:28 - no it's fine it's fine let's do
50:31 - that uh right so you can see it's
50:33 - searching for
50:37 - um it's searching for in my video
50:39 - transcript things that are related to
50:42 - that question and you could see I'm
50:43 - about to get started but I want to talk
50:44 - to you a little more about just sort of
50:46 - me and my background and also a little
50:47 - bit about if you'll indulge me the
50:49 - history of processing itself so I could
50:50 - say like uh what is RGB color so this is
50:55 - not searching through the nature of code
50:56 - book it's searching through a transcript
50:59 - of everything I said in a particular
51:01 - video and what R so that's the retrieval
51:04 - the augmented generation is I could say
51:06 - hey take all of this and give it to a
51:09 - language model and say could you answer
51:11 - this question here's the knowledge you
51:13 - need to answer the question don't use
51:15 - your other knowledge and that's the idea
51:17 - of retrieval augmented generation and
51:18 - this uh example does do all of that but
51:21 - I I was mucking around with whatever
51:23 - version the version on GitHub does all
51:24 - of that let's just see uh and and maybe
51:27 - this will come back all right so that's
51:28 - a little bit of um some background so
51:33 - now
51:34 - finally I'm actually getting to what I
51:37 - wanted to do which is let's start
51:40 - getting embeddings now masimo oh oh
51:42 - masimo has a great comment too about
51:44 - llama 2 but bogo's question is really
51:47 - important there are many different
51:50 - models for embeddings uh there are very
51:52 - there are many fewer models for
51:54 - embeddings that work uh on device so one
51:59 - model that works on device is all mini
52:01 - lm- L6 dv2 I'm going to use BGE small
52:06 - 1.5 I think today um most all of these
52:11 - models are embeddings for the English
52:13 - language and I my apologies in advance
52:16 - for not being as knowledgeable about
52:18 - what is out there and available for
52:20 - other languages I think it's a bit of a
52:23 - problem that a lot of the research in
52:26 - language and AI is very English language
52:29 - focused and centered and I would love to
52:32 - hear more about initiatives and work
52:34 - that I can support and participate in
52:37 - that is uh expanding the technology to
52:40 - other languages and cultures there's uh
52:43 - so many reasons why that is important um
52:46 - so I haven't done a deep dive into this
52:48 - country name data set that's pretty
52:50 - interesting uh says Yousef that's a
52:52 - great suggestion but so let's look for
52:55 - for the model that I'm going to use uh
52:57 - and um Let Me Close oh I closed that
53:00 - it's fine I'll come back to it um so the
53:03 - model let's go here so first of all so
53:07 - my understanding of the sort of current
53:12 - and I guess I why is
53:14 - my if you're having trouble seeing
53:16 - anything on the screen please let me
53:18 - know um I just lowered the desk because
53:22 - I think it's blocking quite a bit my
53:25 - understanding is that the current latest
53:27 - and greatest model for English uh
53:31 - embeddings and I believe this particular
53:33 - research group also did a version of
53:36 - with the same technique for the for
53:38 - Chinese um is BGE large so we could
53:41 - click over here oh this is uh replicate
53:45 - examples but I think I'm looking for is
53:47 - the paper yeah so this is the paper for
53:51 - um the research group that has worked on
53:53 - these particular models it's from the
53:55 - Beijing Academy of artificial
53:56 - intelligence a lot of these models are
53:58 - published on hugging face which is
53:59 - another uh platform for hosting models
54:03 - and I could see right here I wonder if
54:04 - it's actually going to let me do this
54:05 - without even um logging in I could say
54:10 - you know the Cat in the Hat and I could
54:14 - uh run it and this is going to run on
54:17 - replicate server and give me an
54:20 - embedding right there so uh personally
54:23 - if you look at the GitHub repo that
54:28 - um I will that is accompanying this
54:31 - video under uh save embeddings D Json
54:35 - there are two scripts uh one is uh
54:39 - embeddings replicate JS and this one
54:42 - uses uh the BGE large 1.5 model hosted
54:46 - on replicate but to use this you'll need
54:48 - to sign up for a replicate API token and
54:50 - there's a small cost per query uh to
54:55 - replicate um uh the one that I'm going
54:58 - to use today in this video is using uh
55:01 - transformers. JS and this particular
55:05 - you'll see it here feature extraction
55:07 - model uh runs on device meaning it's
55:10 - actually running just on my it actually
55:12 - can run in the browser but I'm going to
55:14 - run it through node because uh I'll get
55:16 - to why it's a little bit tricky it's not
55:18 - tricky for regular JavaScript people to
55:20 - run in the browser but it's a little bit
55:22 - tricky to get it to work with P5 so I'll
55:24 - get to that when I get to that
55:27 - okay and Kathy's pointing out there are
55:29 - lots of data sets on hugging face as
55:32 - well and that include different
55:33 - languages okay so let's get right to it
55:37 - so this is the particular model I need
55:40 - to raise this up I'm sorry so please let
55:42 - me know I'm going to try to be mindful
55:45 - here about not blocking I guess I could
55:47 - just move myself down and still have my
55:50 - desk higher this is probably a bad idea
55:52 - but I'm going to just do this right now
55:54 - uh
55:55 - uh uh where where am I keyed me okay
55:59 - unlock
56:01 - myself there I'm lower
56:03 - now uh so my desk is still at the same
56:07 - height but it is blocking less of the
56:09 - screen okay oh and thank you munzer for
56:11 - gifting a coding train
56:14 - membership somebody will receive that
56:16 - MBL lab received it wonderful
56:21 - um okay now some more
56:26 - background if you have uh followed me at
56:31 - all you have probably followed the fact
56:34 - that I use a particular Library called
56:36 - ml5.js to do a lot of machine learning
56:40 - examples in JavaScript and boy do I have
56:42 - a lot that I hope to do soon all about
56:44 - this Library coming
56:46 - soon um ml5.js is built on top of
56:51 - tensorflow.js I don't I don't think
56:53 - nil's here anymore but uh looked like
56:55 - nikelle one of the creators of
56:57 - tensorflow.js was in the chat briefly um
57:00 - so tensorflow.js is kind of the OG the
57:03 - original JavaScript library for machine
57:05 - learning and JavaScript there is another
57:07 - one that uh seems to be gaining a lot of
57:09 - popularity particularly in the language
57:11 - model space these days comes out of
57:13 - Microsoft called Onyx
57:16 - JS so
57:19 - uh um what I what you're seeing here is
57:22 - that this particular model uh has been
57:26 - released with Onyx waits to be
57:29 - compatible with transformers. JS oh Nila
57:32 - is still there okay so
57:35 - uh um so what's going on
57:40 - here Transformer the Transformers
57:43 - library is hugging face again this AI uh
57:48 - hosting company platform that I um uh uh
57:51 - find to be quite useful in addition
57:54 - addition all the other ones that I find
57:55 - useful um is uh uh has a python package
58:00 - called Transformers they have recently
58:02 - released a JavaScript version called uh
58:04 - transformers. JS uh it is built on top
58:07 - of Onyx which is the other thing so just
58:10 - like ml5 is built on top of
58:12 - tensorflow.js transformers. JS is built
58:15 - on top of onyx. JS that's probably where
58:17 - the similarity uh stops um but so just
58:21 - want to give you that background and
58:22 - understanding so uh one of the things
58:24 - I'm actually personally investigating is
58:27 - uh if I if if we were as the group who
58:30 - works on ml5 to add language model
58:32 - capabilities to ml5 uh an embeddings
58:35 - model for example could we also include
58:37 - the Onyx backend in addition to the
58:39 - tensorflow back end for that library but
58:42 - all that I want to do here is actually
58:45 - use transformers. JS so that I could get
58:48 - access cths beddings model so let's look
58:50 - at how we can do that now first of all
58:52 - not to overdo it here but um I'm about
58:56 - to wade into the territory of working
58:57 - with node and uh if you are unfamiliar
59:02 - with that you won't you
59:03 - know I guess you could stop watching
59:05 - right now and go look at these but later
59:07 - um I made a couple videos that's about
59:09 - sort of like the tools that I'm using
59:10 - and setting up a node project so I'm not
59:12 - going to do all that detail now but that
59:14 - reference material is there
59:16 - okay so let's go to uh here so this is a
59:22 - new um and I got to just be mindful of
59:24 - where I am so I'm not blocking things
59:26 - too much this is a new empty directory
59:30 - on my Mac I'm going to say npm init Dy
59:34 - just to create an empty node project um
59:37 - then I'm going to open this up in Visual
59:39 - Studio code and I'm going to create a
59:41 - file and I'm going to call it a save
59:44 - embeddings uh doj .js so uh usually the
59:48 - sort of default file for a node project
59:51 - might be index.js or server.js most of
59:54 - the things things I do are making a web
59:55 - server with node but this is just kind
59:57 - of like I just want to write a script
59:59 - that I can just kind of run as a process
60:01 - so I'm like the weirdo who uses node in
60:04 - the way that everybody else might use
60:06 - python or other kinds of command line
60:08 - tools because I'm heavily invested in
60:11 - the JavaScript ecosystem for my teaching
60:13 - and other things that I'm doing so um
60:16 - and so hey there's plenty of other
60:17 - people doing all amazing uh much more
60:19 - sophisticated and highly intelligent uh
60:23 - tutorials and educational materials on
60:24 - machine learning in Python so go find
60:27 - that but I'm here I am just digging into
60:30 - JavaScript again okay
60:34 - so um what am I doing here let's so the
60:37 - first thing I need to do is I need to
60:39 - import transformers. JS if you haven't
60:42 - seen es import statements before I also
60:44 - covered that in those videos but
60:46 - essentially all I need to do and I
60:48 - actually don't is this so I'm just going
60:51 - to uh put this right in here
60:53 - so I want to import this particular node
60:57 - package presumably to use this node
60:59 - package I need to also say um npmi for
61:04 - install I'm going going write install
61:06 - and uh install the Transformers JS node
61:10 - package it'll just take a minute
61:18 - here wow this takes longer than it
61:20 - usually does for me okay now if I go
61:23 - back to uh terminal I mean Visual Studio
61:26 - code you will see here under
61:28 - package.json that I now have this
61:31 - particular dependency uh Transformers uh
61:35 - JS uh from uh version 2.9.0 I should
61:39 - also say that because I'm going to use
61:40 - Imports I need to add to my package.json
61:42 - uh type
61:49 - module um okay and by the way in case
61:51 - anyone is wondering I do use co-pilot uh
61:54 - been experimenting with it a lot more
61:55 - recently but I've turned it off for the
61:57 - purpose of this live session because I
61:59 - thought it might muck things up too much
62:01 - um so we're we're just writing our own
62:03 - artisanal handcrafted code here in this
62:06 - uh coding train session so I'm going to
62:08 - go back to the documentation and this is
62:11 - what I
62:12 - want I want
62:14 - to uh so the way that transformers. JS
62:18 - works is everything every model is
62:21 - called a pipeline and there is a task
62:24 - and then the particular model you want
62:26 - to use for that task so for example if I
62:29 - go to just the main transformers. JS
62:31 - page and scroll down a bit you'll see
62:34 - like oh I could do a sentiment analysis
62:37 - pipeline or uh these are I could do a uh
62:41 - question answering or sentence
62:42 - similarity or summation or text
62:43 - classification there's all these
62:45 - different there's Vision ones so there's
62:47 - a ton of stuff you can do and for every
62:50 - single one of these like if I just pick
62:52 - I'm going to do um uh image
62:54 - classification if I click here you'll
62:56 - see well there's a video and some other
63:00 - U and it's actually see this is the
63:01 - thing it's showing me quickly it takes
63:04 - me to the python code let's see if
63:06 - there's a JS version so sometimes you
63:07 - have to do a little extra digging
63:09 - because that didn't work I didn't end up
63:11 - on the um maybe if I
63:13 - click here under models or
63:17 - docs yeah this took me to the
63:20 - Transformers JS docs and you can see
63:23 - here and I apologies that my I should
63:25 - make this a little wider now you can see
63:27 - like oh look if I want to do uh image
63:29 - classification I just load this
63:32 - particular model now you might be asking
63:33 - like where is it loading the model all I
63:36 - did was give it the name so this is very
63:38 - common ml5 works the same way I think
63:41 - some uh tfjs models work the same way
63:44 - these libraries have built into
63:45 - themselves the URLs for the cloud
63:47 - hosting P platforms where the actual
63:49 - model files are stored so you could load
63:52 - you could download the model files and
63:53 - load it locally
63:54 - but what I'm doing here is as long as I
63:56 - give it the name trans the Transformers
63:59 - uh JavaScript library knows where to go
64:01 - out into the cloud if you will and
64:03 - retrieve that model now this won't work
64:06 - because it's got the keyword await in it
64:09 - so for me to await the result of loading
64:13 - this model I need to put this in a
64:15 - function that uh is modified with the
64:18 - async keyword and uh if you're not
64:21 - familiar with asynchronous events and
64:23 - async and A8
64:24 - I won't go to my channel to find them
64:26 - whole set of videos about that as well
64:28 - but I'm just going to write a function
64:29 - called load model who I don't know what
64:31 - that autofill was async function load
64:35 - model and uh I could then write a main
64:39 - function I'm just going to call it Go
64:42 - async function go and I put everything
64:44 - in this F in this function and I'll just
64:46 - like call it I know I should probably
64:48 - put that below and I'm going to say
64:50 - await load model so the first step here
64:53 - is is for me just to load this model
64:58 - and I don't I don't
65:03 - insist for no reason at
65:05 - all
65:08 - okay brain yeah I get it I get
65:14 - it where are we TimeWise 11:35
65:18 - okay uh I don't believe that no JS lets
65:21 - you await in the global context if I'm
65:23 - wrong about that that then my whole life
65:25 - is about to change um let's
65:29 - Also let's also do
65:34 - this and I can say uh uh what do I call
65:38 - this um um I'll just call this the
65:40 - embeddings model or I'll call this like
65:42 - BGE
65:44 - small I'm just like making this up as I
65:46 - go BGE model equals a weight load model
65:50 - okay so now uh let's take a look at this
65:54 - let's make sure this
65:56 - works and again if anybody's having
65:58 - trouble seeing the code or anything
66:00 - please let me know okay so let's run
66:04 - save
66:05 - embeddings and it's going to take a bit
66:07 - right it's got a it's a it's a the small
66:10 - model but it's going to take a little
66:11 - while so while that is
66:15 - going let's go back and so what do I
66:17 - want to do
66:19 - next what I want to do next is get an
66:23 - embedding
66:24 - so uh we can see here I'm just going to
66:28 - copy paste the example this is different
66:31 - than no this is right
66:36 - um um let's just copy this example here
66:40 - and look at what happens and I'm going
66:42 - to just uh have it be I'm just curious
66:45 - can I do it I mean it makes sense to do
66:47 - it with more than one but I thought I
66:50 - could just give it a single string I'm
66:51 - just curious about that because I think
66:53 - that'll be a little bit simpler right
66:57 - now did it load that model
67:02 - yet thanks for my nice typo here we
67:05 - didn't
67:06 - see so uh let's try running this again
67:09 - and see what
67:12 - happens okay uh oh and I need to say
67:15 - await run the BGE model through that
67:18 - Source okay so first of all we see like
67:22 - uh it it's console loged huge uh uh
67:25 - JavaScript object which you can see a
67:27 - lot of the properties and information
67:28 - about the model something that's really
67:30 - important here is this number
67:32 - 384 so that's going to be the length of
67:35 - a particular
67:37 - embedding um all right AR is telling me
67:41 - what about a node version 18.18 which I
67:43 - think is the version I'm
67:47 - using can you really that's insane if I
67:50 - can do that I don't believe you okay
67:53 - good let's try
67:58 - this are you kidding
68:02 - me oh yeah it this is going to
68:07 - work since
68:09 - when what what since when could you do
68:14 - this oh my
68:16 - goodness I did not know that oh wow I
68:20 - got go change all my examples it's going
68:21 - to make my life so much easier
68:24 - we do not need this
68:27 - function
68:29 - okay
68:31 - wow I I didn't think I could love node
68:34 - anymore and I really do love it now all
68:35 - right let's just keep it called as
68:36 - extractor that's fine all right so
68:39 - what's happening
68:40 - here what's Happening Here is I am
68:42 - loading this particular model it's task
68:46 - as feature extraction and the model I'm
68:48 - loading is BGE small English version 1.5
68:51 - uh there are other models that are
68:53 - compatible with transformers. JS
68:55 - presumably you could train your own
68:56 - embeddings model uh but that's the one
68:59 - that I'm using for here I'm giving a
69:01 - source text hello world I'm uh and you
69:05 - know I this is not me this is not a
69:08 - coding train example if I don't instead
69:10 - put like Choo Cho and then I am passing
69:13 - that text to the model and then these
69:15 - two properties pooling is just modifying
69:19 - a particular aspect of what's Happening
69:22 - inside of the feature extraction process
69:24 - I probably relates to like actually
69:27 - don't know somebody can tell me in the
69:29 - chat probably I'm assuming it relates to
69:31 - like I think of Max pooling with like
69:33 - convolutional neuron networks um but
69:35 - obviously there's some aspect somewhere
69:37 - where it has to imagine has I'm guessing
69:39 - there's like multiple embeddings and
69:41 - maybe mean is saying just average them
69:42 - when you have multiple ones and you need
69:44 - when you to pull a bunch of embeddings
69:46 - together to just get one normalize means
69:48 - it's going to give me the values I'm
69:51 - assuming uh we'll check this the
69:53 - embedding numbers that come out will be
69:55 - between some normalized range maybe
69:57 - between negative 1 and one or between
69:58 - zero and one um so let's run this again
70:01 - uh it's definitely between negative 1
70:03 - and one based on
70:05 - these okay so we got a uh an embedding
70:11 - uh its dimensions are 1 by 384 because
70:14 - it only ask for one sentence the type is
70:17 - floating point and then the data the
70:19 - actual numeric values are in this
70:22 - particular property called data all
70:25 - right so for example I could say
70:27 - embeddings do dat
70:30 - index0 and that's that first value so
70:34 - for
70:36 - example that fly well all right so let's
70:39 - let's let's go a little further let's
70:42 - just make up a bunch this is where I
70:44 - wish I had um co-pilot on co-pilot is
70:47 - the funniest thing if you're like trying
70:49 - to create a fake data set of sentences
70:51 - just starts making up sentences for you
70:53 - it's kind of kind of amazing anyone's
70:54 - experienced that
70:57 - um yeah I can't I still can't believe
70:59 - this thing about me not needing the
71:01 - asynchronous I could just do await in
71:03 - the global spacing node like this is
71:05 - really this changes everything Q like
71:10 - Hollywood you know music or record
71:13 - scratch I don't know what the sound
71:14 - effect that goes with that is all
71:16 - right now we need to decide what is our
71:19 - data set going to
71:21 - be so um
71:24 - oh here I know a place I could look I'm
71:27 - gonna go to corpora on GitHub so this is
71:30 - a GitHub repo that I turn to very often
71:33 - when I'm looking for just like a fun
71:35 - list of things so maybe let's go to film
71:38 - and
71:39 - TV uh Game of Thrones houses popular
71:42 - movies let's try
71:45 - that uh how how long is this this is
71:47 - pretty good has the
71:50 - date U I'm just looking at TV shows
71:54 - how long is this maybe let's do TV shows
71:56 - it's a little it's longer um let's do TV
71:59 - shows so I'm going to do something kind
72:01 - of ridiculous here I mean this is Json
72:03 - so I should load it as Json I kind of
72:06 - want to just load it as plain text
72:07 - because that'll be more common to what
72:10 - you
72:11 - find um but let's grab
72:14 - this oh oh here let's just grab this
72:17 - whole thing
72:19 - raw and let's go uh make a file called
72:23 - tv.
72:25 - txt I'm going paste it in here um and
72:28 - now I'm going to do some fancy regular
72:30 - expression
72:32 - searching uh let's look for a
72:36 - quote the beginning of
72:39 - a beginning of a line and
72:42 - quote and so this is I'm by so uh I got
72:46 - a whole set of videos about regular
72:48 - Expressions so I'm just quickly
72:49 - reformatting this document and then I'm
72:52 - going to search for quote
72:55 - comma quote comma end of line I realize
72:59 - this is kind of a ridiculous way that
73:00 - I'm doing this I'm going to get rid of
73:02 - this let's just now search through did I
73:05 - get
73:09 - everything um actually the reason why I
73:11 - kind of well it's
73:13 - fine let's see if there's anything that
73:15 - was weirdly
73:21 - formatted good enough okay
73:24 - how many TV shows we got here I guess
73:25 - it's 1,000 it said 1,000 didn't it okay
73:28 - all right so let me get rid of
73:29 - this and get rid of that okay great um I
73:33 - don't yeah okay so now I have a list
73:38 - of 1,000 TV shows in a text file called
73:42 - tv.
73:43 - txt
73:45 - okay so now what I would like to do is
73:49 - let's bring in the file system module
73:51 - from node import
73:54 - uh FS from FS I think that should do it
73:58 - and I'm going to say the raw text equals
74:01 - a wait
74:03 - fs. um read file does it just I forget
74:09 - how to use promises I guess I could just
74:10 - use read file sync somebody will tell me
74:13 - I'm just going to use read file sync uh
74:15 - the tv.
74:17 - txt uh with uh the file format is utf8
74:21 - so now I have the raw t text and just to
74:24 - be sure about this let's console log it
74:27 - to see I'm going to get rid of all this
74:29 - embedding
74:33 - stuff right so there's all of the text
74:37 - files and this I maybe need to like move
74:39 - this in a little bit so it's easier to
74:41 - see so now I want to split it up so
74:44 - shows equals raw dosit by um any number
74:50 - of line
74:51 - breaks and let's look at that
74:57 - array great so now I have an array of
75:00 - all of the TV shows so
75:03 - presumably I
75:05 - could load this
75:08 - model oh I already did I loaded the
75:10 - model here I can now say for let show of
75:16 - shows uh and get now again it would be
75:21 - smart to do some kind of batch process
75:23 - processing where I do like 10 at a time
75:25 - and that certainly makes a lot more
75:26 - sense especially if you're using a model
75:28 - in the cloud but for the sake of
75:30 - Simplicity I'm just going to do it one
75:31 - at a time so I'm going to get an
75:36 - embedding uh for every single
75:40 - show and then I also want to
75:45 - have I'm going to say output Json is an
75:52 - object and and uh and that object is
75:55 - going to have an array maybe called
75:57 - embeddings in
75:59 - it so essentially I want to get the
76:03 - embedding which is in embeddings do dat
76:06 - and for each one I want to say
76:10 - output json. eddings do push and then
76:15 - I'm putting an object in it which is got
76:18 - the show and the embedding which is is
76:24 - embeddings do
76:26 - data and I guess that should be it's a
76:29 - single embedding so I think this makes
76:31 - more sense so let's just see uh you can
76:34 - you can you can all kind of check check
76:36 - on me here if this makes sense so I'm
76:38 - kind of thinking ahead here because I
76:39 - have made this example before uh show
76:43 - can be a const says super crafter that's
76:45 - a good point so could output Json not
76:49 - super in the habit of be that good as
76:50 - using const so what this should do is as
76:55 - I look at and let's let's do console
76:58 - log uh G
77:02 - um uh extracting
77:06 - embedding
77:08 - for uh show I'll put that in as a
77:12 - console log so if I get the embedding
77:15 - then what I want to do and this might
77:17 - make more sense is to say something like
77:20 - let well I'll just leave it it's fine B
77:23 - basically I want to oh this is no
77:25 - semicolon here I want to make a big Json
77:28 - array of the show names with their
77:31 - embeddings because what I'm doing here
77:33 - is creating what you might refer to as
77:35 - an embeddings database now there's no
77:37 - reason why I couldn't bring so you know
77:40 - later I'm going to load this database
77:42 - and do clustering with it there's no
77:44 - reason why that couldn't be in the same
77:46 - app but if it's for in my mind if my
77:50 - goal is to do a visualization of a fixed
77:53 - data set that is not changing it doesn't
77:55 - make sense to rerun the model every
77:57 - single time so I'm going to do these as
77:59 - two separate steps and I'll talk to you
78:01 - about how you could do it as one okay um
78:05 - so here we go let's run this see what
78:10 - happens so doing extracting all of these
78:13 - things it finished so I didn't do
78:15 - anything with the output Jon so I don't
78:17 - know if it
78:19 - worked but let's let's at least console
78:22 - log the output Json let's write it to a
78:24 - file uh let's just write it to a file so
78:27 - FS WR file sync should go to um the file
78:35 - name so let's call it TV
78:37 - embeddings and then I need to give it
78:41 - the uh and I'll do I'm going to do uh
78:43 - const output equals Json
78:46 - stringify and the what is it called
78:50 - output
78:51 - Json
78:56 - so uh what I'm trying to do and I'll
78:58 - I'll add in
79:00 - null comma 2 so these arguments just
79:02 - format it so for me to write this out to
79:06 - a file it's a JavaScript object I need
79:09 - to turn it into a string into raw text
79:11 - so I can write it to the file so this
79:13 - should now you know this isn't a lot of
79:15 - code very simple I'm loading the
79:18 - Transformers JS model I'm loading a data
79:21 - set from with raw text I'm chopping it
79:23 - up I'm feeding every element into the
79:27 - model I'm getting an embedding I'm
79:29 - packaging all that up in a Json object
79:32 - JavaScript object and writing it to a
79:34 - file let's just see could is it possible
79:37 - that I didn't make a mistake here we'll
79:39 - find
79:43 - out okay see how fast that was by the
79:45 - way that's what I like about using an on
79:47 - device
79:48 - model okay this looks pretty
79:51 - good uh
79:57 - why is it is this h no no no no no no no
79:59 - no no no no why did it do
80:03 - that and maybe it's going to be fine in
80:06 - the end but this should be
80:09 - this all right I have to debug this
80:12 - right this I don't want an
80:14 - object with
80:16 - every index being a
80:20 - number uh why did it do that I don't
80:24 - recall this happening in my other
80:26 - experiments but let's
80:29 - see um so let's just do
80:32 - one show here for a second is it
80:35 - something in the way that I did this
80:37 - okay conso log I know I could just type
80:42 - what do I type CL you were saying to
80:45 - me
80:51 - CG
80:53 - I got some Visual Studio code settings I
80:55 - need to figure out um embedding let's
81:00 - just look at this and then let's say
81:02 - break so I'm just going to look at the
81:04 - first
81:07 - one okay so I definitely got a nice
81:10 - plain actual array of
81:20 - numbers all right still just a nice
81:23 - plain array of
81:27 - numbers
81:34 - uh well let's do
81:39 - this console
81:44 - log output
81:46 - Json let's see what happens
81:50 - here oh whoops
81:54 - oh the break the break is before okay
81:56 - sorry about
81:58 - that so let's take this out also just
82:04 - to ah yeah look there it
82:08 - is I wonder if this stringify did so
82:11 - stringify clearly did
82:13 - something uh let's see what's in here
82:15 - now yeah
82:18 - okay uh what if I take this out just
82:31 - huh it isn't an array object oh okay so
82:36 - I have to because it's this special kind
82:38 - of float 32 array thing it's not
82:40 - actually an array you know actually I
82:41 - think Transformers JS has this
82:44 - list I was looking at the documentation
82:47 - I think I saw a list
82:51 - function oh yeah two two
82:53 - list so I wonder if I'm supposed to use
82:56 - two list let's see what that
82:59 - does
83:04 - um so this is this is useful for me to
83:12 - know is it uh two what was it two
83:17 - list oh without the underscore okay
83:19 - let's try
83:21 - this
83:24 - not too L does it does it go
83:27 - here this is how yeah ah okay ah oh it
83:31 - gives it to me okay so this is good so
83:33 - maybe that's what I want so I
83:37 - want uh
83:41 - this embedding to list index zero
83:46 - because I I'm just getting one I think
83:48 - this is will now
83:50 - work let's see what we've got
83:55 - um and see here oh let me put this back
83:58 - I mean I don't need the formatting well
84:00 - I think my visual studio code will
84:02 - format it yeah okay great that fixed it
84:05 - that's what I want I want to actually
84:06 - just see the array of numbers okay so
84:09 - the formatting is very much unnecessary
84:12 - but it it's helpful for me to be able to
84:14 - see it so I'm going to put that back in
84:17 - uh null comma 2 and then I'm going to
84:19 - take out this break and I don't need
84:22 - console log here this should get me and
84:26 - again this is because I'm not batching
84:29 - them so I'm just doing one at a time
84:31 - which is probably not best practice but
84:33 - it'll get us uh it'll get us to the
84:36 - finish line here okay here we
84:39 - go extracting all the
84:43 - embeddings all right we've got all the
84:45 - embeddings now and there there it is now
84:48 - usually in Visual Studio code it lets me
84:50 - like fold these up but doesn't really
84:52 - matter you can sort of
84:56 - see
84:57 - um whoops I I hit save and it did
85:00 - something so you can see that this file
85:02 - is not really human readable uh and
85:04 - actually one thing I'm very curious
85:05 - about is how big is it reveal INF
85:09 - finder 9.5 megabytes so one small
85:14 - problem here is that the I wanted to
85:17 - show you how to do this in the P5 web
85:19 - editor which I think is useful the p5b
85:22 - web editor is
85:25 - um uh can you can only upload files up
85:28 - to 5 megabytes so I have a couple
85:31 - options one is I could do this with
85:34 - fewer TV shows another is I could uh
85:38 - just Host this file in a CDN somewhere
85:40 - if anybody has any
85:46 - suggestions all right I'm going to let's
85:49 - let's go let's go move to the next topic
85:51 - so I'm going to come back back to that
85:53 - so I have my embeddings so you could
85:55 - imagine now there's a lot of things I
85:57 - could do for example I could do make a
85:59 - chat bot where I where I asked the
86:02 - question please suggest a a TV show for
86:05 - me to watch I love TV shows about Farms
86:10 - now
86:11 - again because the embeddings are just
86:13 - associated with the titles of the show
86:15 - this won't work very well but I could
86:17 - now turn my question into an embedding
86:20 - and then do a similarity search across
86:21 - all the TV show
86:22 - and return a
86:24 - suggestion more likely if I really
86:26 - wanted to do this in a more robust way I
86:29 - would want to do like embeddings based
86:30 - on like the description of the shows and
86:32 - all sorts of other more have much more
86:35 - information and data and I would love to
86:37 - see people uh experiment with that I got
86:39 - to come back and do some more of these
86:41 - like search and retrieval things and the
86:43 - secret to it which I had a diagram up on
86:45 - the board is looking at something called
86:46 - cosign similarity okay host on the cloud
86:49 - would be nice on gith yeah I could just
86:51 - host it on GitHub actually so let's
86:53 - let's actually for the sake of argument
86:55 - just so you have access to it's not that
86:56 - different than what I already have but
86:58 - let me just go on GitHub and make a new
87:01 - repo for this live
87:04 - stream
87:07 - um embedding I'll just call it em we can
87:10 - change the name of this
87:12 - later uh make it
87:14 - public uh create the
87:18 - repository um
87:20 - and uh let me just get this here and
87:24 - then I'm going to say get init wait
87:27 - actually let's add a get ignore
87:31 - first there's no environment variables
87:33 - but let's just put that in there just in
87:35 - case I forget later um maybe I don't
87:39 - want to
87:43 - um right now let's not upload the um
87:47 - data
87:48 - files so I'm going to ignore those as
87:51 - well
88:03 - oops code from live
88:06 - stream and then add the remote oh wait
88:11 - the whole point was for me to host it on
88:12 - the CDN okay fine I forgot what I was
88:16 - doing here so I do need to include these
88:21 - things
88:23 - yeah oh and that took out the
88:25 - package.json file too I made so many
88:28 - mistakes there uh I don't know if I need
88:32 - that but I'm just it's a reflex at this
88:39 - point
88:43 - okay so now uh here we go the repo is
88:47 - there there's no uh read me I I don't
88:49 - know like so one I'm a little I'm a
88:51 - little a little bit hesitant about this
88:53 - because I have this whole repo that I
88:56 - already made called save embeddings Json
88:59 - so this makes more s it's like
89:01 - documented and I have like you know in
89:04 - instructions and things so I'm not sure
89:06 - you know I'm not sure if I should
89:07 - deprecate this later and combine them
89:09 - but for right now it'll work because
89:12 - what I want is to be able to uh load
89:16 - this file um you can use a JS deliver
89:19 - link but um I think this will actually
89:21 - work just load the these embeddings from
89:23 - this raw file okay so let's
89:28 - now go to the P5 web
89:31 - editor and let's see if we make the font
89:36 - a little bit
89:37 - bigger so I want to move towards uh
89:41 - clustering and umap where where am I
89:44 - time wise oh I'm at noon I said I was
89:47 - going to be done at noon but we're going
89:49 - to keep going because I want to finish
89:50 - this by golly
89:52 - oh just the TV shows on a gist well that
89:55 - makes more sense okay I should have done
89:57 - that so uh paste bin yeah the gist would
90:01 - have made more sense too
90:06 - late it's too late for me I've done this
90:08 - already okay I'm trying to think so
90:11 - there's there's two steps here one is
90:15 - how to load that embeddings database
90:17 - into P5 that's actually not going to be
90:18 - too hard I'm just going to use load Json
90:20 - so let me skip that for now now the
90:22 - other more complex question is around
90:26 - how am I going to take that data and
90:30 - draw a clustering map of all of those TV
90:33 - shows and for that I am going to
90:38 - use a particular algorithm called umap
90:42 - now let's go
90:43 - to uh the uh embedding
90:49 - projector um this is a research search
90:52 - Project from the uh group at Google uh I
90:56 - you know I've name checked nikelle a
90:58 - bunch of times uh nikil is one of the uh
91:01 - creators of this along with Daniel smov
91:03 - and I'm probably missing lots of other
91:04 - people who worked on this um so
91:07 - apologies to that um this is a
91:11 - visualization of high-dimensional data
91:14 - um that has a very thoughtful uh
91:17 - interface and demonstrates various
91:19 - different algorithms you can use to
91:20 - visualize that data so first let's talk
91:23 - about what's here so the demon the the
91:27 - data that is being used to
91:30 - demonstrate uh first when you load the
91:32 - embedding projector is word to VC what
91:34 - is word to VC so you might think this
91:37 - whole idea of embeddings wow large
91:39 - language models AI we're living in the
91:41 - dawn of you know putting words with
91:44 - numbers this is not a new idea and in
91:48 - fact if you go to back to my my syllabus
91:52 - under the embeddings week and I scroll
91:55 - down uh stay at the top here you will
91:58 - see that I even made a couple videos
92:00 - that I never finished so I really should
92:02 - get back to and somebody just gifted
92:04 - like azillion
92:06 - memberships wow okay I've never seen
92:10 - this happen but thank you
92:14 - to uh generate Collective that is uh
92:17 - unbelievably generous and kind of you um
92:21 - so
92:23 - uh uh so I made these videos what is
92:26 - word to VC color vectors that
92:28 - understanding word vectors article is by
92:29 - Allison Parish it's absolutely fantastic
92:33 - I would really recommend reading it um
92:35 - and the original paper around word
92:38 - representation in Vector space is from
92:40 - 2013 so that's like 10 years ago so
92:42 - there have been uh many instances and
92:46 - examples of looking at how to vectorize
92:51 - uh text text um and uh word Tove being a
92:55 - particular model and uh embeddings
92:58 - database that has been used in lots of
92:59 - different projects uh Universal sentence
93:02 - encoder is a tensorflow.js model from
93:04 - 2018 that turn sentences into embedding
93:07 - so this is not new territory I recommend
93:10 - this background reading for you um by
93:13 - the way I've got some other links here
93:15 - to other reading material around
93:16 - embeddings that would also I think it's
93:18 - good background material so what this
93:21 - particular visualization is showing me
93:23 - is 10,000 words um each of those words
93:28 - has an embedding of 200 numbers and yet
93:31 - I'm seeing them in three-dimensional
93:34 - space so what does this mean let's go
93:36 - back to the Whiteboard for a brief
93:41 - minute if you'll indulge me a little bit
93:46 - here okay hold on I'm breaking out the
93:49 - Windex everybody
93:52 - I don't like to use this if I don't have
93:54 - to but it's
93:56 - gonna water would be better but you know
93:59 - time is of the essence here the Windex
94:01 - just does the trick now I'm breathing in
94:04 - the fumes
94:06 - hopefully I don't
94:08 - know
94:14 - okay
94:15 - let's just get all of this out of the
94:19 - way get one of these nice
94:22 - cloth all right dry it
94:29 - off
94:34 - okay so let's just say for the sake of
94:40 - argument that I have a
94:45 - word um boy
94:50 - this
95:06 - that I have a word uh like uh
95:12 - rainbow and it's associated with an
95:15 - embedding which is uh 200 numbers and I
95:19 - have a word uh
95:23 - Cy which is associated with an
95:27 - edting and it has 200 numbers now let's
95:31 - think about a different
95:33 - example let's say I have the word
95:37 - red and it's associated with an
95:39 - embedding of just three
95:42 - numbers and I have the word uh
95:45 - blue and it's associated with an
95:48 - embedding oops damn it
95:59 - which is just three
96:01 - numbers I meant to do this the other way
96:04 - around and I I have
96:07 - pink and it's associated with I don't
96:10 - know three numbers I I don't know if
96:13 - that's pink whatever
96:15 - so if I wanted to
96:18 - visualize these three words according to
96:21 - their embeddings well I have a number of
96:23 - ways I could do it I could do it with
96:24 - actual colors but let's say I wanted to
96:27 - plot them in a three dimensional
96:30 - space well I could consider the first
96:33 - number to be the xaxis the second number
96:36 - to be I kind of want to make the second
96:37 - one the z-axis so that I can I make I do
96:40 - that no that's fine the Y
96:43 - AIS and the third number the z-axis and
96:47 - then you could start to think like okay
96:50 - so red R would be like over here because
96:53 - it's at 255 along the x axis and maybe
96:57 - blue would be over here because it's uh
97:01 - so this is blue and this is red and then
97:05 - maybe pink would be kind of like you
97:09 - know somewhere like here this would be
97:12 - where pink is and you could start
97:13 - imagining plotting all these
97:16 - colors because each word is associated
97:19 - with three numbers it Maps easily to
97:21 - three dimensions if I wanted to plot
97:24 - them in two Dimensions I could just do
97:26 - something like well let me just get rid
97:27 - of the Y Dimension you know I'll still
97:29 - just plot them if some of them have a
97:31 - lot of green in it I'm going to lose
97:33 - that information but I'd still kind of
97:34 - have a a basic visualization of the
97:37 - color space what do I do if I have 200
97:41 - numbers well in an Ideal World I'd be
97:44 - some kind of like alien super being like
97:47 - you know I don't know think of those
97:49 - things in the movie arrival or something
97:51 - but I could just like
97:52 - see 200 I could just like let me draw
97:56 - you uh a 200 dimensional space and
98:00 - you're GNA just my my brain I don't know
98:02 - about you my brain does not work like
98:04 - that I can't even in my mind visualize a
98:06 - four dimensional space I can barely do a
98:08 - threedimensional space if I'm being
98:09 - perfectly honest here so there's not an
98:12 - easy way to visualize these numbers in a
98:16 - high dimensional space that's the
98:19 - information though is in that high
98:20 - dimensional space
98:21 - so what I need is some algorithm for
98:24 - dimensionality reduction if I could
98:26 - figure out a way to take that and just
98:29 - reduce it down to three numbers still
98:33 - retaining the essence of all of the
98:35 - numbers then I could plot that and maybe
98:39 - G glean something about the data I could
98:41 - start to Cluster them I could do K near
98:43 - you know there's all sorts of things I
98:44 - could do uh like in the embedding
98:46 - projector which I'll show in a second so
98:50 - the question is how do I do that well
98:53 - like with I said here like ah why don't
98:56 - I just pick I want to do in 2D or 3D
98:58 - I'll just pick the first three numbers
99:00 - sure I'm losing 197 other numbers but
99:02 - let's try that you could actually do
99:04 - that it's not a big try it go for it I
99:08 - could maybe even do something like well
99:10 - uh what if I want to do it in two
99:11 - Dimensions let me take the first 100
99:13 - numbers and average them and the second
99:15 - 100 numbers and average them again it's
99:18 - probably not going to do I'm going to
99:19 - lose way too much information it's not
99:21 - going to retain the actual geometric
99:25 - structure and positioning of the 200
99:28 - dimensional space but that would work
99:30 - that's a dimensionality reduction
99:32 - algorithm
99:33 - so there are this is but this is the
99:36 - task that I need to do my data does not
99:38 - is not originally in two-dimensional or
99:41 - three-dimensional space but I want to
99:43 - see it visualize it in that space how do
99:45 - I reduce these vectors down to a lower
99:48 - Dimension and still yet retain Ain uh as
99:53 - much of the information I want things
99:55 - that would be near each other in two
99:57 - dimensional space to still be near each
99:59 - other in two-dimensional
100:00 - space so that's the problem at
100:04 - hand um I'm thank you fun Planet who
100:07 - seems to be doing a heroic job of
100:09 - moderating the chat I appreciate that um
100:14 - so this is the Energy Savers oh wait
100:17 - what the I'm plugged in let me try
100:22 - we've got a slight minor emergency here
100:25 - which is that my battery apparently I
100:27 - have not been plugged in and the battery
100:29 - is very low I'm plug let me check is
100:31 - this not plugged in there is a plug
100:35 - that's plugged into an outlet is this
100:37 - I'm afraid to turn anything off it's got
100:39 - some cobwebs on it let's try plugging
100:42 - this
100:46 - in wow what is going on here oh okay
100:50 - hold hold on
100:53 - uh I'm going to unplug from the screen
100:56 - for a second just to plug this in
100:58 - directly to this one port that I know
101:00 - works okay something is wrong with my
101:03 - power supply give me a second I have a
101:05 - backup
101:07 - one I have a backup power
101:10 - supply um coming back I mean I could
101:12 - also but people are just
101:14 - like I've never seen this all these
101:16 - gifting of memberships I didn't even I
101:18 - like forgot that I had that turned on
101:20 - this is very kind of
101:22 - you okay I guess I should do these live
101:24 - streams more often
101:27 - um okay uh hold on I'm just getting
101:29 - another plug hopefully you can still
101:31 - hear me let's try this
101:41 - one I cannot have my laptop die before I
101:47 - finish this now this is very dangerous
101:48 - what I'm about to do I'm going to try to
101:50 - plug it in from a different place it's a
101:53 - tripping Hazard where I'm plugging it in
101:57 - so somebody remind me not to trip if I
102:00 - start trying to go to the
102:02 - Whiteboard
102:05 - okay we are saved everybody so I don't
102:09 - know what's wrong with this
102:10 - plug let me let me just make let me put
102:13 - it now that I know it works here I'll
102:17 - put it out of the way where I won't
102:19 - trip cuz as fun as that might be for all
102:22 - of
102:24 - you it won't be good nothing good will
102:27 - come out of
102:28 - me all right yeah so there's something
102:30 - wrong with that other power supply so uh
102:34 - okay did okay hold on we're I'm going to
102:37 - be back to the tutorial in a second I am
102:40 - recording this whole thing to dis so it
102:43 - is possible if there's interest I would
102:46 - be glad to make an editing
102:49 - version of this and editing an edited
102:53 - version that's just the like tutorial
102:55 - part which might make it easier for
102:56 - people to rewatch
102:59 - later um but we'll see okay
103:03 - um all right so I was talking about so I
103:06 - want to make a version the so I was a
103:07 - little bit background around word to V
103:09 - right and so we can see here that if I
103:12 - were to zoom into this I um you know
103:15 - presumably uh words that are near each
103:18 - other are going to have sort of similar
103:22 - uh similar meanings uh because this uh
103:26 - the 200 dimensional space of all of
103:28 - these words has been uh reduced down to
103:30 - three dimensions
103:33 - now how was this done was it done by
103:36 - just taking the first three numbers was
103:38 - it done by averaging no it was done with
103:42 - a particular algorithm called whoops PCA
103:46 - principal component analysis let's take
103:49 - a look at it with a different algorithm
103:51 - called tne which I have no I forgot what
103:54 - that stands for at one point I
103:56 - knew uh so do uh
104:01 - um this will definitely be there this
104:03 - will 100% be available to watch later I
104:06 - just um was wondering if it might be
104:08 - helpful to have a shorter version of it
104:10 - without all of the like me finding my
104:12 - plug and stuff in it now I this doesn't
104:15 - usually run so slow to me I think it has
104:16 - something to do with the fact that I'm
104:18 - plugged into the streaming system but
104:20 - you can see now the tne algorithm is uh
104:25 - moving the dots around uh reducing the
104:28 - 10,000 points to 200 dimensions and at
104:31 - some point it will finish and we could
104:34 - start to explore
104:35 - it um I could even change it to 2D and
104:38 - there's some oh you can't see this down
104:40 - here but there's even some like various
104:43 - parameters and things that you could
104:45 - change but um so uh PCA I you know this
104:49 - is my loose understanding is principal
104:51 - component analysis was one of the uh
104:53 - first algorithms to do this
104:54 - dimensionality reduction tne was all the
104:56 - rage a number of years ago and more
104:58 - recently uh umap is a new algorithm uh
105:03 - that uh uh along some set of metrics uh
105:08 - retains
105:10 - the uh relative similarity position I'm
105:14 - trying to think of like what's the best
105:15 - way to describe this I should really
105:17 - just point you to this article which
105:18 - will explain it uh much better
105:21 - data's Global structure that's the word
105:22 - I'm using umap is a technique that
105:25 - offers advantages over tne most notably
105:28 - increased speed and better preservation
105:30 - of the data's Global structure so this
105:32 - is a wonderful article from Andy Conan
105:35 - and Adam Pierce from Google pair uh
105:37 - people in AI research
105:40 - um that describe I believe these are the
105:43 - same authors as the umap JS library that
105:47 - I'm about to use you can see Canon ey
105:50 - here which I assume is uh the the same
105:53 - name U might be getting some of these
105:55 - details slightly wrong uh we're still
105:57 - going there but so this article does a
105:59 - wonderful job of giving you a high level
106:02 - understanding of umap so first of all
106:05 - this is now what we're seeing here which
106:07 - is nice is the clustering of images so
106:10 - if I were to make a again I'm way over
106:12 - time already here but I would love to do
106:14 - an example of this with images I'm going
106:16 - to do it with text right now but you can
106:18 - see the difference this is this is using
106:20 - a particular data set called fashion
106:22 - mnist which is basically lots of little
106:24 - low resolution images of a whole lot of
106:26 - shirts whole lot of shoes a whole lot of
106:27 - pants and so if we look at this you can
106:30 - see like uh zooming in here you can see
106:32 - like a lot of the shirts and pants uh so
106:34 - sorry coats and pullovers and shirts are
106:36 - here all the shoes sneakers sandals are
106:39 - down here umap has done this amazing job
106:41 - of organizing all of the data according
106:45 - to its similarity it's not matching
106:47 - shirts with shirts it's matching
106:49 - embedded ings with similar embeddings
106:52 - and it just so happens that those
106:53 - embeddings are coming from images um and
106:57 - these are low resolution enough that I'm
106:58 - assuming this is actually just done with
107:00 - the raw pixel data as opposed to what I
107:01 - was talking about earlier with like
107:03 - feature extraction through through some
107:05 - image model um so you can read more
107:08 - there's a wonderful there's there's a
107:09 - couple different properties of umap that
107:11 - we'll see that you can change and you
107:13 - can kind of uh play around with these
107:15 - different visual interfaces to kind of
107:17 - understand like well what does it
107:19 - consider how many neighbors that are
107:21 - near it in high dimensional space is it
107:23 - looking for to kind of map down to to
107:26 - lower dimensional space how far is too
107:29 - far how close is close um and there's a
107:32 - bunch of different demos this is one
107:34 - that was super interesting to me so this
107:36 - is actually taking a three 3D data like
107:40 - from a 3D model and doing umap
107:44 - projection you could also call this
107:45 - dimensionality reduction projection it's
107:47 - no different than how you might do uh
107:50 - projection in a 3D renderer because
107:52 - you've got to take 3D data and create
107:54 - the illusion of seeing it in
107:56 - two-dimensional space that is
107:57 - dimensionality reduction as well so but
108:00 - umap dimensionality reduction is doing
108:02 - like you can sort of see how it works
108:04 - here and you can see what these
108:05 - parameters do like if I take uh minimum
108:08 - neighbors all the way down to three and
108:10 - minimum distance down to zero this is
108:13 - how it's arranged this data into two
108:15 - Dimensions versus increasing the number
108:18 - of neighbors and increasing that minimum
108:21 - distance you can see like look at this
108:23 - strange like crazy version of this
108:26 - Mammoth now in 2D so this is ultimately
108:29 - what's happening um and there's a lot
108:32 - more examples and demonstrations and
108:34 - explanations in this article so
108:38 - um I uh you know one is I've read this
108:42 - through it really helped me I cannot you
108:45 - know regurgitate it in an eloquent way
108:47 - right now I'm going to just uh sort of
108:51 - recommend that if you want to learn more
108:52 - about how umap works that this would be
108:55 - your starting point
108:56 - resource for us however what I would
108:59 - like to do is just go to um app.js and
109:03 - there's probably a more elegant way to
109:05 - integrate this into your code oh you can
109:07 - install it through npm but I'm just
109:09 - going to for the sake of using it in the
109:11 - P5 web editor I'm just going to go under
109:13 - lib I'm going to go to umap js. JS and
109:17 - I'm going to just download this file so
109:20 - I downloaded that file and in the P5 web
109:23 - editor I'm going to upload
109:27 - it and where is it under downloads here
109:31 - it is let's upload
109:33 - it and now in my uh
109:38 - index.html I am going to include I don't
109:41 - need this is the sound library right
109:42 - away so I'm just going to get rid of
109:45 - that and instead include uh umap Js s
109:51 - .js so and this is my umap clustering
109:58 - example
110:00 - okay it runs we've got a sketch okay so
110:05 - now what I need to do is two things one
110:09 - is I need to figure out how to run the
110:13 - umap clustering algorithm and in fact
110:16 - let's just do that right now with random
110:18 - data to start and then I'll load in my
110:20 - Json uh embeddings so let's make a
110:25 - uh array called
110:28 - data and let's make 100 random data
110:37 - points and have each one
110:41 - be an embedding uh I don't I'm making
110:45 - this up as I go
110:47 - uh uh a record I don't know what to this
110:49 - is like maybe I'll call this embeddings
110:52 - and I'll call this like data uh let's
110:55 - just make an array with three random
110:57 - numbers in
110:59 - it
111:03 - um and then let's push
111:08 - that into the
111:13 - embeddings so what I have here and U
111:16 - okay I got to keep an eye let me open
111:17 - this which will help make sure that I'm
111:19 - not standing in front of the code okay
111:21 - so this is I'm creating three I'm
111:24 - basically doing um where's the
111:27 - Whiteboard I'm basically starting with
111:29 - this so I'm going to start with this
111:31 - which is just embeddings with three
111:33 - numbers and I'm going to try to do
111:36 - dimensionality reduction down to two
111:37 - Dimensions if I can get that to work
111:40 - then I can load my higher dimensional
111:42 - sentence
111:46 - embeddings okay so now uh I don't know
111:50 - the umap library off the top of my head
111:52 - so we'll follow the
111:58 - documentation um so I don't need to
112:00 - import it because I've just loaded it
112:03 - from the file itself so I'm going to uh
112:07 - just create a new umap
112:09 - object let me close out let me just
112:13 - close out some other things
112:16 - running make my screen a little brighter
112:18 - so I'm going to do map and I'm just
112:21 - going to use let you don't need to tell
112:22 - me cuz I'm in the P5 world now my
112:25 - friendly let place and I'm going to say
112:28 - uh umap equals umap and then literally
112:32 - all I need to do is say um map I'm going
112:34 - to show you how to animate it later but
112:36 - fit uh
112:39 - embeddings so that should do it let's
112:41 - just let's just see if I do it do I get
112:44 - an error or anything oh it's slow wow
112:47 - wait wait
112:48 - wait
112:53 - 100 things just calling fit should not
112:56 - freeze I probably should have paid more
112:58 - attention
113:02 - to to uh what I was doing here because I
113:06 - might not have the data in the right
113:10 - format um I can look at any of my
113:14 - examples oh you know what I think is an
113:17 - issue here is I'm not um setting the uh
113:22 - all right let me look at one I I made
113:24 - this example already and I'm a little
113:26 - bit pressed for time here so let's just
113:28 - go and look at
113:31 - it uh oh right and it's in my a
113:33 - [Music]
113:35 - toz uh sketches it would be
113:40 - uh that's interesting this is a
113:42 - different
113:43 - one I'm looking for I thought I made a
113:46 - hello world one but let's just look at
113:47 - this yeah so
113:50 - so
113:52 - let's oh yeah I think I I sort of didn't
113:55 - I sort of forgot about like the
113:56 - important part okay so I got to um kill
114:00 - this
114:01 - page uh let's see if we can get it back
114:08 - okay
114:11 - okay I missed some important things here
114:14 - which is
114:16 - that um and let's just see did I get
114:18 - that right yeah
114:27 - I would like these to be on different
114:28 - lines because okay it's not going to do
114:30 - that that's fine okay so what did I
114:32 - forget so one thing that I forgot that
114:34 - really important is I need to uh give it
114:37 - some initial properties and as that
114:39 - article demonstrated these properties
114:42 - and neighbors minimum distance those are
114:46 - parameters that affect the cluster ing I
114:50 - shouldn't say clustering because
114:51 - clustering to me is really like actually
114:53 - putting them it it affects the structure
114:56 - of the dimensionality reduction how many
114:59 - other elements is it looking to get near
115:02 - uh what is a distance threshold those
115:04 - are really important parameters you can
115:05 - play with this is the what I want to
115:07 - really focus on it is um the dimensions
115:12 - that you want to end up with so I
115:14 - started with three-dimensional data I
115:16 - want to end up with two-dimensional data
115:18 - now I might have done
115:20 - maybe this like is a problem let me just
115:24 - put in the let me just do
115:26 - this that's kind of not what I wanted to
115:28 - do but just to make
115:31 - sure let's just see if this now will
115:35 - finish and not
115:40 - freeze look at this for a second let's
115:42 - look at what the format of the data is
115:46 - in this one that was
115:48 - working
115:59 - sure okay so this one
116:02 - worked and it's just
116:04 - 120 and I maybe and it is actually using
116:07 - just actual RGB values so maybe I should
116:10 - just try that this one's still
116:14 - frozen oh fix line
116:17 - eight oh
116:20 - oh that's the
116:25 - problem I'm sorry
116:27 - everybody I'm sorry everybody
116:31 - okay see my naming is
116:34 - terrible this is data and also by the
116:38 - way just for fun times now I
116:41 - realize I can make these
116:46 - 255 okay all right everybody
116:50 - we're moving on here with life okay
116:53 - great okay it's working so so all that
116:56 - was wrong in case you weren't following
116:58 - that is I was being a lunatic and trying
117:01 - to put my array into my array and I had
117:03 - an empty array full of itself recurent
117:06 - and then I was trying to you map that
117:08 - definitely not going to work so let's
117:10 - just look at what is the data what does
117:12 - the data look like what are the data is
117:15 - probably the what I should say uh oh no
117:17 - so what are the embeddings
117:20 - umap is
117:22 - expecting a array of arrays so I have
117:26 - 103 dimensional embeddings they're just
117:29 - color
117:31 - values then let's look at what do I get
117:37 - out let's look at
117:39 - umap
117:42 - and maybe I'm supposed to uh if I call
117:45 - fit what well let's look at the
117:48 - documentation
117:55 - uh maybe it's just in there maybe I'm
117:58 - just being um stubborn here so learning
118:02 - rate there's other things I could change
118:05 - random categorical distance function
118:07 - optimization
118:09 - state I'm I'm being so stubborn and not
118:12 - looking at my
118:14 - example like refusing to look at my
118:16 - example where do I get the
118:18 - results
118:23 - I random spread that's giving me my
118:26 - properties I mean I did
118:29 - it I'm just refusing to look at the
118:31 - example I'm gonna look at the
118:35 - example fine you got
118:41 - me
118:43 - uh you map results oh oh
118:48 - you
118:50 - yeah no wait you map
118:52 - results oh that's the array okay hold on
118:54 - what am I do oh I
118:57 - see all right fine everybody it was I'm
119:00 - just being silly okay so how does this
119:03 - work and I kind of hate what's going on
119:05 - here I have so little room on my screen
119:07 - for the code and I really want it to
119:10 - like I'm just going to make it a little
119:14 - smaller you tell me friends if uh you
119:18 - can no longer read this on your giant
119:21 - your tiny little phones that you're
119:22 - watching this stream on okay um wow
119:26 - that's way smaller that's too small I
119:28 - can't even read that now I get 28
119:32 - okay
119:33 - um
119:35 - so uh I umap is the object that is going
119:40 - to uh execute the algorithm and hold all
119:42 - the parameters the
119:45 - results are return from the fit function
119:49 - now what I would like to look at are
119:51 - those
119:54 - results and here I now see uh I have all
119:59 - that data mapped to two Dimensions now
120:02 - you have to I have to ask the question
120:03 - of what is the range that I'm
120:07 - getting good
120:11 - question I don't know ask the people who
120:13 - wrote that umap JavaScript library um
120:17 - okay hopefully you can um
120:20 - so what what I'm going to do now I think
120:23 - so so it didn't retain like the umap
120:26 - space that it projected it into is kind
120:28 - of an
120:29 - arbitrary space and this is actually a
120:32 - stochastic function meaning it uses
120:34 - random numbers and you're going to get a
120:35 - different result each time there is a
120:38 - way to pass a a seated random function
120:40 - into it so you get the same result each
120:42 - time but that's beyond what I'm doing
120:43 - here basically let's look at the
120:46 - following just really quickly let's go
120:48 - and
120:49 - say for and let's make the background uh
120:53 - black for let I equal 0 I is less than
120:57 - umap results. length
121:01 - i++ and I'm going to say uh I'll call it
121:04 - data point equals umap results index I
121:09 - and then I used the con there even
121:11 - though I said I wouldn't let's say let
121:14 - x equal data point uh index zero
121:19 - and let y equal data point index one
121:25 - maybe I want to
121:26 - translate to the middle of the
121:30 - screen and then just say fill
121:34 - 255 and draw a circle at XY that's you
121:38 - know like eight pixels let's see what we
121:40 - got uh and I'm going to say no
121:44 - stroke so you can see that's all of
121:48 - those points but that's because the
121:50 - range I haven't thought about mapping
121:52 - that range to my pixel space so one way
121:55 - that I could do it is I could say hey
121:57 - let's map it's got a range between
121:59 - negative 1 and one to between uh you
122:01 - know negative 100 and
122:04 - 100 uh
122:06 - and um maybe let's take the Y and do the
122:10 - same
122:14 - thing uh what's going on here so in in
122:19 - other words this isn't a great way to do
122:20 - it because I'm just kind of grasping at
122:22 - straws so what I actually would like to
122:24 - do and I I know I could use like some
122:27 - fancy higher order array functions to do
122:30 - this let's look for the smallest value
122:34 - oh that actually is not so bad let's
122:36 - look for the smallest value and the
122:37 - biggest
122:39 - value so I'm going
122:42 - to uh say x is data
122:46 - point index zero
122:49 - and
122:50 - Y is data
122:54 - point index one let's get rid of the
122:56 - translate I'll just do the mapping
122:58 - through what I'm going to do and then
123:00 - I'm going to have some numbers like the
123:04 - minimum X should be negative negative
123:10 - Infinity Max X is positive
123:15 - Infinity Max X and let's do that for the
123:18 - Y
123:21 - and then uh I don't need these temporary
123:25 - ones I'm going say the minimum X is
123:27 - whichever is
123:31 - lower the minimum between wait do I say
123:35 - the
123:36 - max no the minimum X is infinity the
123:39 - maximum X is negative right because I
123:41 - need to start with the opposite of what
123:43 - I want to get right I want to find the
123:45 - minimum value so first I'm going to
123:47 - check is it less than infinity yeah so I
123:50 - just had that wrong so is the minimum
123:52 - between the actual value and what it
123:55 - thinks the current minimum is uh and
123:57 - same thing for minimum
124:00 - y uh is this for y and now I can do that
124:05 - for the max values
124:12 - whoops and just change this to
124:16 - Max I look forward to all of you
124:18 - suggesting much fancier nicer ways of
124:20 - writing
124:23 - this and then now I can map
124:27 - from minimum X to maximum X maximum X to
124:33 - Zero to
124:35 - width and then minimum y maximum
124:43 - y
124:44 - zero to
124:47 - height
124:50 - and because I my random data is
124:54 - color um let's look
124:57 - at the fill as embeddings index I index
125:02 - zero so I'm going to just use the
125:04 - original embedding values to set the
125:13 - color and this is very clunky because of
125:16 - the 2D array stuff now look at that
125:18 - woohoo okay let's let's make it more
125:20 - Colors Let's do like 500
125:23 - now there we go see what's happening
125:25 - here look look umap took those and
125:29 - clustered them look at all the greens in
125:31 - their house now these are Rand so let's
125:34 - do random seed just so um I'm just going
125:37 - to show you this so I could say random
125:39 - seed so I get the same random color data
125:42 - set every
125:44 - time but I'm getting a different umap
125:48 - arrangement every time it's
125:50 - because uh umap is uh is a stochastic
125:55 - process and it uses random it tries
125:56 - things randomly and starts moving things
125:58 - around uh based on the random tries
126:01 - that's probably not a super accurate
126:03 - technical way to explain it um okay so
126:06 - we're gonna get to the sentence we're
126:07 - gonna get to the TV shows we're almost
126:09 - there to the end 12:36 oh boy okay I
126:12 - gotta I hope I'm not missing a meeting I
126:14 - don't think I am all right so just for
126:16 - the sake of argument though I just want
126:17 - to show you that I could actually give
126:19 - it let's let's um let's put this into
126:23 - like an options object because I think
126:25 - it's a little bit more
126:30 - clear and I can say um I can give it the
126:35 - P5 God I hate how I don't have space
126:39 - here um I can give it the random
126:41 - function in from P5 there we go thank
126:44 - you Auto format um so now because I
126:48 - seeded the random function I'm telling
126:50 - umap to use the P5 random function it's
126:53 - the same orientation every time so that
126:55 - could be that could be important um in
126:58 - different cases okay so this is pretty
127:02 - good and I could move right now to just
127:04 - using the embeddings but let's let me
127:06 - show you one more thing I'm going to
127:08 - duplicate this I'm going to say umap
127:11 - clustering two and what I'm going to
127:14 - change it to now is because especially
127:16 - with a large data set you it can run
127:19 - very slow and so you might be waiting a
127:22 - long time for the final clustering plus
127:24 - it's kind of fun to watch it so I can
127:27 - say uh let's see if it's here fit async
127:31 - looking for a
127:33 - step doesn't seem to be documented here
127:35 - I don't know where I figured this stuff
127:36 - out I must have been looking at an
127:38 - example but uh I can just say initial I
127:41 - think I know how to do this so I'm going
127:43 - to say
127:45 - initialize fit I think that's the right
127:48 - function
127:49 - name and I'm also going to say umap is
127:56 - running or just going to say like yeah
127:58 - let like umap running is
128:03 - false and then I think I say I should
128:07 - just look at the example this is very
128:09 - silly so I thought it would be in the
128:11 - documentation but and there's probably a
128:12 - different documentation that I could
128:13 - look at um but I forgotten what it is
128:20 - uh this one will have it um you step I
128:26 - should have known
128:27 - that and then get embedding okay that's
128:30 - all it is okay so then I'm going to say
128:35 - um umap running at the beginning of draw
128:39 - I want to do one cycle of the algorithm
128:42 - every time through draw I'm going to say
128:44 - umap running is umap Step so step
128:48 - through one cycle of the
128:50 - algorithm and then the uh umap results
128:54 - basically which I
128:57 - guess I can make that a local variable
129:00 - oh so I think I just only need I can
129:02 - just call initialize fit umap results
129:07 - equals
129:09 - umap
129:11 - get
129:13 - embeddings or maybe hold on let me just
129:15 - check
129:17 - this
129:20 - yeah
129:21 - step umap get embedding or result yeah
129:24 - okay then I'm gonna say umap get
129:29 - embeddings okay so what did I miss get
129:33 - embedding there we go ah so now you can
129:36 - see it's doing uh one cycle of the
129:39 - algorithm every time through draw now
129:41 - it's never going to stop but actually it
129:44 - will get to a point when it's finished I
129:46 - just need to tell it to stop stepping
129:49 - so I think that I say if you map
129:53 - running then uh I want to call
129:58 - step because I I still want to oh no if
130:02 - it's not running whoa
130:06 - wait oh but I maybe I need to be running
130:09 - at the
130:10 - start
130:12 - no
130:17 - okay uh
130:22 - wait what did I do
130:24 - wrong hold on
130:33 - let's
130:35 - okay oh it's telling me how
130:39 - many so that's giving it me it's
130:41 - actually giving me a count and is it
130:44 - going to go to like zero or
130:47 - something
130:49 - you can see it getting
130:52 - close
130:54 - huh so this is not what I
130:58 - expected again I've got to look at my
131:02 - example which I keep closing because I
131:04 - really don't want to look at
131:08 - it
131:13 - is yeah that's what I did result my is
131:17 - in the results where
131:20 - else and I started it as
131:22 - true that's interesting okay I mean I
131:26 - guess it doesn't really matter umap
131:27 - running how's this
131:37 - different
131:40 - uh I guess I did the whole thing oh okay
131:43 - I I had the whole thing here in draw so
131:47 - anyway the there's obviously like a so I
131:49 - might not have been doing this correctly
131:51 - but I see that now it's doing it so this
131:54 - is fine I'm going to figure this out
131:59 - so
132:01 - uh I'm going to say
132:04 - if so I know it's going to do
132:07 - it yeah let's just do
132:09 - this umap running is
132:12 - true
132:14 - uh I'm going to say iterations equals
132:18 - map I'm just going to make my own
132:19 - version of
132:21 - this is greater than or greater than or
132:23 - equal to 500 or is less than 500 and
132:27 - maybe there is a way to specify it in
132:28 - the
132:29 - options
132:31 - um umap running equals
132:36 - false and
132:41 - then uh I mean this is silly I I've kind
132:44 - of I will refactor this later as I like
132:47 - to say
133:03 - uh okay uh
133:08 - if I think it makes much more sense for
133:11 - me just to do this
133:14 - okay what did I okay this should work
133:18 - right so basically umap step gives me
133:23 - the number of
133:24 - iterations and um B I want to keep
133:28 - calling step until I get to
133:30 - 500 uh so that should run through 500
133:34 - and then we should see and EPO is the
133:37 - option name so I could do that so that's
133:41 - so let's do that let uh NE
133:45 - EPO equals 500
133:49 - uh and then um I could say n
133:54 - EPO here and then and epox here so this
133:59 - would be a more proper way of doing it
134:00 - okay sorry for that uh now you see this
134:04 - is now the umap algorithm running all of
134:07 - its iterations and it's I you know even
134:09 - though it's a little bit there's you
134:11 - could probably make a much nicer
134:12 - animation of this where you actually
134:14 - kept track of the points over time and
134:16 - like interpolated them but even so I
134:18 - kind of love like like now I could do
134:20 - like 2,000
134:22 - points and it's kind of like this lovely
134:25 - like mash of color uh that slowly over
134:29 - time starts to separate out into its uh
134:32 - positions so even just visually here I
134:34 - think something interesting is going on
134:36 - but let's tie this all together I'm an
134:38 - hour over what I meant to be but that's
134:41 - fine I'm actually doing this stream and
134:43 -  this project some amount of you
134:45 - have stuck with me for quite a long
134:47 - period of time many many of you've been
134:48 - very generous in gifting memberships and
134:51 - things let's bring in that sentence data
134:54 - so save one more
134:58 - duplicate and now I'm going to put in
135:01 - function
135:03 - preload I'm going to have a variable
135:06 - called Json data and my Json data is
135:10 - equal to and let's turn off the auto
135:12 - refresh I need to go back to wherever I
135:17 - uploaded
135:20 - that uh embeddings
135:24 - database which is right
135:28 - here let's go to Raw let's grab this
135:34 - URL and let's do low Json that
135:39 - URL and let's just for the sake of
135:42 - argument put in console log Json data
135:49 - just to make sure it's there okay what
135:50 - did I
135:52 - miss semicolon is in the wrong
135:55 - place because I have so little space for
135:58 - my
136:00 - code okay great so you can see I got 999
136:04 - embeddings so that's good I got 999
136:07 - embeddings and I don't know what what
136:10 - follows that okay so
136:12 - now the
136:15 - data these are the embeddings so
136:18 - uh I have a global variable called
136:20 - embeddings already so now I'm looping
136:22 - through the length of the Json
136:26 - data and I am saying Json data oh it's
136:31 - in a variable called
136:33 - embeddings so embeddings do length and
136:37 - uh I should really think about renaming
136:39 - these variables because I'm using the
136:41 - word embeddings in probably too many
136:42 - places but I can take uh Json data
136:46 - embeddings index I
136:48 - so I'm putting all of those things into
136:51 - that original this is ridiculous I oh no
136:55 - it's not it makes sense I have to umap
137:00 - requires I'm gonna I'm going to change
137:02 - this to like raw embeddings I think
137:04 - that'll maybe make more
137:06 - sense so what I'm doing and we don't
137:09 - really care about the random seating
137:11 - here right now so I'm going to take that
137:13 - out the raw embeddings are what umap
137:16 - needs my embeddings are coming in with
137:19 - these JavaScript objects that are paired
137:21 - with the TV show name which I also want
137:23 - so I'm going to leave the same options
137:27 - we're going to do all the same stuff but
137:29 - now instead of drawing a
137:35 - circle let's
137:39 - try
137:42 - saying we are so close to being done
137:44 - here
137:45 - text Raw
137:49 - embeddings embeddings oh God I I need a
137:52 - no no not the raw embeddings the Json
137:54 - data again I could organize this better
137:57 - Json data. embeddings indexi
138:02 - dot what did I call it
138:06 - show
138:08 - show do show X comma y okay so I think
138:14 - what this should do now is instead of
138:18 - the random color data I've loaded all of
138:21 - the uh again remember I've loaded all of
138:25 - the TV shows that have a name and an
138:29 - embedding I've reformatted it into a raw
138:33 - embeddings array which is what umap
138:35 - needs and this should be raw embeddings
138:39 - here then I'm getting the
138:42 - results visualizing them but instead of
138:45 - circles I'm drawing the actual text
138:47 - let's see what happens okay great I
138:50 - think this is working so I'm going to
138:51 - stop this because it makes much more
138:53 - sense I need a much bigger pixel space
138:55 - for this to be interesting at all so
138:57 - let's do uh window
139:00 - width and window height and I'm going to
139:04 - do let's take out the console log I
139:06 - think this is done I'm going to do
139:08 - share and go to this full screen view
139:12 - and let's see what happens sorry for how
139:14 - flickery this is probably like
139:16 - destroying YouTube compression
139:22 - after 500
139:24 - iterations we should see something not
139:29 - whoa okay
139:31 - wow I
139:34 - guess I was expecting to have something
139:36 - with a bit more structure to
139:40 - it but um I guess these show names are
139:44 - really kind of like wildly different
139:47 - Curb Your Enthusiasm in 21 Jump Street
139:49 - yeah those are basically the same show I
139:52 - mean nine to five let's let's double
139:55 - check the
139:56 - code to make sure I didn't mess anything
140:00 - up number of
140:03 - neighbors umap step yeah I mean I didn't
140:06 - change anything so maybe this data set I
140:08 - mean I could try a different data set
140:09 - real
140:10 - quick uh we could try playing with these
140:14 - values um but uh I also think I might
140:17 - need to stop now and and let you all
140:20 - like try this with your own data and
140:22 - make more beautiful interesting
140:23 - visualizations try 3D be more thoughtful
140:26 - about the design and interaction can you
140:28 - zoom in and out all that kind of stuff
140:31 - I'm a little bit
140:32 - disheartened um let's look at let's look
140:34 - at this um let's see if we can uh look
140:38 - here again and kind of like what happens
140:41 - if I so I get things minimum distance
140:46 - yeah so lower minimum distance let's
140:49 - just try using some crazier
140:52 - parameters like let's lower the minimum
140:55 - distance and let's like increase the
140:57 - number of neighbors I was going to put
140:59 - in 50 here and hit
141:02 - save and then hit refresh oh also maybe
141:06 - I hadn't actually hit save before I went
141:09 - to the full screen but let's see what we
141:14 - get so fun Planet says isn't raw in
141:17 - edings the same as embeddings no because
141:20 - the embeddings file is written in this
141:24 - way where the actual embeddings are
141:26 - inside these little Java object objects
141:28 - with show and embedding and umap JS is
141:30 - just looking for a 2d array so that's
141:33 - mean just reinfor re re re um
141:36 - reformatting it okay let's wait for 500
141:45 - iterations it you know the P5 uh
141:48 - functions worked so well that I just
141:50 - assumed any data set would kind of work
141:52 - but I'm not getting
141:55 - um uh really great results here but I
141:58 - mean it did do something like maybe if
142:01 - we did similarity scores between these
142:03 - we'd see that this actually this
142:04 - Arrangement like really makes a lot of
142:05 - sense but also this data set is kind of
142:08 - silly
142:10 - um Boardwalk Empire and aliens in
142:13 - America are You Smarter Than A Fifth
142:15 - Grader Cupcake Wars that kind of makes
142:18 - sense that those are near Name That Tune
142:20 - yeah Murder She Wrote also like this is
142:24 - like the worst visualization ever uh so
142:27 - A Pup Named Scooby
142:29 - too um so it's sort of hard to evaluate
142:33 - because uh my data I picked a poor data
142:35 - set um I'm missing are you sure am I
142:39 - missing
142:42 - something
142:44 - oh I'm missing yet another
142:49 - I think fun planet in the chat caught
142:52 - something really
142:55 - crucial I think so let's
142:59 - let's let's look at my mistake
143:02 - here so this is my naming problem of
143:05 - calling everything embedding everywhere
143:06 - in my
143:07 - code um look at
143:12 - this yeah this array has objects in it
143:15 - that has the show and that so it is the
143:17 - same so I did I made a huge mistake here
143:20 - this needs to be the the whole point of
143:22 - this was to only put the arrays in
143:28 - it yeah look at that now I have a raise
143:31 - of
143:32 - 384 okay hold on we're going back stop
143:36 - save think we're going to get something
143:40 - now I mean we'll see we still who knows
143:43 - how you know it's going to work other
143:45 - people caught it before fun Planet I
143:47 - just noticed you fun Planet because you
143:48 - have the
143:49 - wrench so thank you everybody yeah
143:52 - William Clark I see says
143:54 - it um yeah now who's it's definitely
143:59 - different um you can see it's quite
144:01 - different and um Easy Street East Street
144:04 - Flamingo Road 21 Jump Street yeah yeah
144:07 - yeah so the embeddings are you know
144:09 - obviously this we're just doing it by
144:10 - show titles you can see this little
144:12 - cluster here the Restless years the
144:14 - light you know Living Color love of life
144:16 - okay now we're getting results again my
144:19 - visualization lacks a leaves a lot to be
144:22 - desired um I am curious I really I think
144:26 - I'm an hour Beyond where I meant to be
144:28 - let's just try I'm just
144:30 - curious um I I would love to do this now
144:33 - in
144:33 - 3D um but you know I got to move on with
144:37 - my day but I just want to try changing
144:38 - those parameters a little bit just to
144:39 - see if we get more
144:43 - structure so you could imagine uh so one
144:46 - thing I give you a lot of prompts here
144:48 - one try doing this with a different data
144:49 - set smaller data set even try doing it
144:52 - in 3D think about if you can make this a
144:54 - navigable space like how could I zoom
144:57 - around move in and out maybe I could
144:59 - hover over one and it would like link
145:01 - all the ones with a certain similarity
145:03 - score could I use like a force directed
145:05 - graph like maybe these things are
145:06 - connected with spring forces and the
145:09 - spring force is related to uh its
145:11 - similarity score there's so many
145:13 - possibilities here I would love I mean
145:17 - maybe I mean there are some of you
145:19 - somehow still watching this um what I'm
145:22 - going to do is I'm going to turn all
145:23 - this off right now and I am going to
145:26 - it'll take might even be till tomorrow
145:28 - although I I I I welcome help with this
145:32 - I will link from the video description
145:35 - to all of the code all of the Articles
145:37 - all of the stuff that I explained in
145:39 - this uh if you think it would be
145:42 - valuable for me to work with Mata who
145:45 - does video editing for the coding
145:46 - training to try to create this was now
145:49 - a 2 and a half hour 10:30 11 2 and a
145:52 - half hour live stream I think this could
145:54 - probably get cut down to like an hour um
145:58 - um right a bigger uh right we could try
146:01 - this with I didn't get to start show you
146:03 - how this would look with the replicate
146:05 - embeddings model I mean that the the BGE
146:07 - large so there's so much more to this
146:10 - but I hope that you learned
146:13 - something this open your eyes to some
146:15 - possibilities maybe you're in ired to
146:17 - make your own version of something I
146:19 - kind of would like to do this with
146:20 - YouTube channels actually um so I have
146:22 - to stop I I have too many my my my brain
146:24 - is melted from building this whole
146:25 - example but um so if you want to engage
146:28 - with this more go to the
146:40 - codtracker if it's not there the video
146:42 - description for this live stream should
146:44 - be annotated with all of the links and
146:47 - code that you would need to reproduce
146:49 - this on your own okay uh thank you
146:52 - everybody I'm G to just put on the
146:54 - goodbye stuff and kind of I will put on
146:58 - um this little song here just to see if
147:01 - there's I'll take like one or two last
147:04 - questions um and let me just look at my
147:08 - [Music]
147:10 - message
147:11 - [Music]
147:15 - okay uh
147:16 - [Music]
147:21 - uh sorry I'm I'm like I'm like looking
147:24 - at
147:25 - uh my text messages which I don't need
147:28 - to be I'm just an IP oh Jesus Christ um
147:33 - okay uh I love embeddings the meaningful
147:35 - data thanks Dan uh is there a neural
147:38 - network from hugging face that knows the
147:40 - semantics of your words yes this is the
147:42 - idea of the embeddings models now I
147:44 - think we have to be very cautious
147:47 - about how much intelligence or uh we
147:52 - ascribe and how much we really believe
147:55 - that these models are perfectly
147:58 - encapsulating the semantics of our words
148:02 - they're you know all of the same kinds
148:04 - of cultural biases and issues that
148:07 - language models might have and how they
148:09 - predict and generate text all of those
148:11 - same considerations exist in the
148:14 - embeddings models however I do think it
148:16 - is is quite a tool a powerful tool to be
148:19 - able to work with data sets to create
148:22 - art with data sets to understand your
148:25 - data better um and there's lots of
148:27 - possibilities there for
148:35 - sure this song is much too long because
148:37 - no uh um but let me let me this let me
148:40 - just close out these windows to make
148:41 - sure everything's
148:42 - [Music]
148:45 - saved
148:52 - I'm going to hit stop recording on my
148:54 - recording to
148:56 - dis uh
149:00 - hopefully audio quality oh oh you know
149:04 - [Music]
149:06 - what okay oh no oh no okay hold
149:11 - on I think it's not a problem because
149:16 - yeah I
149:17 - the recording to dis
149:20 - audio was being passed through NV video
149:24 - broadcast so it probably has all that
149:27 - like popping and stuff in it but I do
149:29 - have the I could archive the audio from
149:30 - the stream and put it together so oops
149:33 - so that might that might make it a
149:35 - little more challenging but
149:38 - um okay all right goodbye everybody I
149:41 - will see you uh I don't know when
149:43 - sometime again I I I like doing this if
149:45 - you like just the live stream where I
149:46 - build a project like this and this is
149:48 - useful to you I'll be curious to see if
149:50 - this video has any life to it after this
149:53 - stream that's why I used to like anyway
149:56 - I don't need to go into all that right
149:58 - now just thanks for watching come come
150:00 - say hello in the coding train Discord
150:02 - and
150:04 - um yeah that's
150:08 - it as always I always forget that this
150:11 - this going to do this this to do this
150:15 - this this this
150:25 - [Music]
150:32 - do dot doet do dot dot do do do dot do
150:40 - do dot dot going to do do to do do dot
150:45 - I'm going to do
150:50 - [Music]
150:55 - do dot s this dot dot dot never forget
151:00 - this
151:01 - [Music]
151:04 - do this dot this dot this do never
151:08 - forget this do I'm going to do the this
151:10 - this dot this dot this dot the this Dot
151:13 - Song never forget the this dot somebody
151:15 - composed that song for
151:19 - me

Cleaned transcript:

a the good boy morning everyone uh well it might not be morning to where you are but it is for me I know the music might be a little bit loud right now uh I will adjust that balance in a moment uh but um let me know if you can hear me okay I'll be getting started in just a minute uh you might hear more of an echo than usual because um the audio filtering that I typically use is not on right now all right just let me know if the this my quick audio check I'll be starting in about a minute and yeah n n a hello everyone let's see here here we go uh let's turn this down just a tiny bit uh welcome everyone to a Monday morning coding train live stream probably not the most optimal time for me to have a live session but it's the time that works for me uh and so here I am I'm attempting to get another uh screen over here with the chat that I might be able to take a look at it but right now I can see the chat over here and I see people um greeting me from San Antonio Texas and chil rainy England it is chilly Sunny New York right now all right so I'm going to try to get right into it today today there's not going to be a lot of the usual coding train uh wasting of time because I have an agenda so let's Jump Right In uh I'm G to open up my web browser here um and see if I can get to this particular page bear with me for a moment and oh the other thing I'm going to do is I'm gonna hit start I'm recording this to dis uh on the off chance I want to try to do something more with it so we'll see unlikely this will just be available as an archive of a live stream but just in case all right so I um first of all hello welcome my name is Dan schiffman you watching the coding drain this is a YouTube channel where I try to do a wide range of things uh but mostly focusing on Creative coding making art with code graphics and animation with code for the beginner and um try uh yeah that's I think that's a good summation of what it is this channel is I also uh this extra screen thing is not going to work for me I don't think well maybe I'll worry about that later um I also happen to have this uh fulltime job which keeps me very busy uh teaching at a program called ITP uh and IMA at TI the Arts New York University and this semester I happen to be teaching a class called programming from A to Z now I think apologies for all this uh e you know what's the word for when I'm taking a really long time to set something up I don't remember yes so U let let me address something quickly in the chat AZ ad says no Pops in the mic today so I did some debugging over the weekend about what was causing the pops in the mic and strangely enough I cannot believe this uh it was Nvidia broadcast the software I use that runs the audio through the graphics card and has various features for audio processing and so this room that I'm in this garage is actually quite large if I'm being perfectly honest for a recording there more space than I need and it is not sound treated and it is very empty and it is very echoey so I've just been using the Reverb uh the echo reduction that's in in video broadcast it works so well that I never bothered to uh sound treat the room but so uh you might be hearing a little bit more of an echo today which is also why I'm recording this to disk in theory if I wanted to uh edit this down to a shorter video tutorial um I could do some audio processing and post all right I did not ask for that I don't know if you could you hear that through the mic this is this uh old uh iPad I found that I was like let me set up to have another screen where I could look at the chat because right now although I see there's one message there oh and Simon got their stickers in the mail that's amazing ah it just says enjoy the Stream So I've got um uh a slight and like what's going on over here this is the yeah this is a little bookshelf here it's kind of like cut off there I'm just not going to worry about all there's a lot of flaws today in my setup we're just gonna move along all right so uh let's see programming with text no yeah introduction yeah let's see if this will get me somewhere UHD is okay okay okay okay you're really gonna show me an ad right now thank you very much okay um so this is a particular um this course that I've been teaching at NYU for quite a long time with this as evidenced by this very old thumbnail design that really should be updated um is about different algorithms that you can use to uh analyze and generate text so I look at things like just how do in JavaScript how do you work with the JavaScript string object loading text from a file looking at regular Expressions uh some word counting stuff some text analysis stuff some node stuff some database stuff some speech stuff oh I used to do Chrome extension in this class so this is kind of what the class was was uh six years ago and the current syllabus uh for the class is here and you can kind of see um all of the weeks right now so um a lot of the video a lot of the uh weeks one through four those old videos pretty much still apply weeks five and six uh I have some um I recently recorded and if you go to the coding train Channel right now you would see and just click on videos the most recent videos that came out were um what what I see on my laptop is what you see over here uh most recent videos that came out are oh okay I need to do this um were for uh working on Bots then I've got some videos on Markov chains and context fre grammar that are coding challenges but the material that has been entirely new this semester I don't know if you noticed it actually just had its oneye uh birthday I believe but uh the world of language models and ways that people interact with textbased interfaces in our daily life now has just changed in extraordinary ways uh that is very complicated and I have lots of complicated feelings about that um so regardless of my own uh confusion and wondering about how I might may or may not want to include some of these new tools and Technologies in my own kinds of work and educational materials I do see it as part of my and riser you asks what is clustering sense edings I'm getting there I do see it as um part of my mission uh n mission's too strong of a word but I at least interested in doing some teach ing around how to explore and um learn about more about language models and in particular I'm very interested in this topic of using embeddings for search and retrieval and other kinds of analysis of data so uh protham says are you checking the YouTube chat or the Discord chat by the fact that I'm reading your message here I would say the YouTube chat I have a slight eye over there in the corner of any like I'll see one message in the Discord chat so any urgent things that need to flag my attention put them there um and uh not a sponsor but this is a um Danielle is mentioning my thermos and it's I really love it it's uh I mean I welcome a sponsorship from a fellow I think it's called fellow I own so many of these yeah it says it on the inside and I have some uh very hot coffee in there that was much too hot okay so um the what I've been having a hard time um figuring out how to find the balance between all the different things I'm working on so coding train it's not like on Hiatus but it's a little bit hit or miss these days so I always like to say at the top thank you for those of you who are engaging and supporting the work that I'm doing even when I'm producing much less as usual most of that uh you I'm not going to go too far into this is because of my obsessive work on this nature of code book uh which will be coming out in the summer but you can read it all online lots more to come about that come 2024 um but uh one of the things uh that happened was actually kind of funny because there was a fire drill I was in the middle of talking about uh embeddings uh and and I don't worry I'll get to what that is as best I can uh and I didn't get to finish some stuff that I wanted to do in class um and I have a bunch of examples here um around working with uh Transformers Js where's this going to go by the way um around uh this thing called umap um so I thought I would come and do a live session around it because I can uh because I I'd like to share this with my students who are in the class but also uh share it with all of you uh any of which might be a student in my class but unlikely they're very busy they don't want to watch me on YouTube so tired of me I would assume by this point um I am in my garage in my home so the other reason why I've been a little slow to do stuff uh just a little behind the scenes here uh is that I set up this whole recording studio that's a little bit strong I set up some equipment in my garage and this semester my teaching schedule is much busier than usual so when I used to record videos at NYU I was just there all the time when I was teaching recording whatever now I've kind of separated that a little bit which I think is a good thing in the long run um but I'm actually at NYU like these last couple weeks of the semester Tuesday through Friday so today is my only day working from home and I have uh uh I mean honestly I have a lot to do I probably shouldn't be doing this right now but at least this is for my class so I I it makes sense got to keep this muscle can't like totally lose the live streaming muscle and um yeah so as long as I get out of here by like noon 1230 at the absolute latest I'll be able to do all my other meetings and office hours and different things this afternoon go in for the rest of my work week and yeah but really here I what I'm excited about so even though so just to set the stage a little bit um so many wonderful questions in the chat I'm sorry I'm not really going to be able to answer them this is this is not intended this is a w I would call this a wintry hoodie sweater hoodie uh it's not intented to be a hoodie related to a very specific holiday that happens around this time of year that I do not celebrate even though my family insists on somehow kind of partially at least mostly celebrating oh they'll get you there those those rascally kids um it's winry themed it's very it's it's actually it's pretty good it's not that cold here in the garage I was running the heater all morning and I turned it off now for sound and it's sunny so I'm getting some sun in here um all right so uh yeah so here's the thing um I think I can just open up this example um and I'm going to log in as the coding train I'm gonna just show you the very end of this I'm going to build the whole thing during this stream let me show you what's coming at the end it'll be slightly different because maybe I want to use a different data set it's it in here no that's not it wait where is it oh I know it is I messed up I overwrote another example and maybe I should fix that uh H hold on it's actually linked in a very weird place which would be here yeah this is it's like I messed some things up but oh no wait this is the right one oh no this is what the slide oh my God I what what everything is wrong okay it's okay I'm gonna find it I know how to find I this is by the way what actually happens in my class I you I feel like I'm so prepared then I can't I messed up a link and I can't find the right thing then nothing works it's very hard it's very hard no no no don't go here okay don't worry I'm gonna get you this example I know exactly where it is it's it's right here okay let's run this I'm going to do share I'm gonna go to full all right I'm sorry for the very flast fast flickering here I'm not doing anything fancy to animate this in any way uh frogo I am streaming from New York State uh that is about I guess the amount of information that I'm going to give here so what you have just witnessed is and I'll have to zoom in here for you to see a little bit more closely is every function from the p5js reference clustered uh according to a similarity metric so I am look uh basically I have taken a lot you can see all of the loading functions are here there's like some uh some key related stuff here some touch related stuff here uh blend mode and texture is here I'm not saying this is perfect or accurate to how it really should be clustered what I have done just to be the whole story is I have taken a data file and uh let me let me get to that as well I'm again I want to build all these examples but I already did them so I might as well kind of show you the pieces first and then I'll step through building it piece by piece um but I not completely prepared here so let me find this other repo that I need to find um which is called save embeddings Json and again you if you don't know what an embedding is you're in the right place I I kind of don't really either I mean maybe I if you don't at all then I probably know like a little bit more than you so I'll be helpful but I'm not claiming to be some e I'm learning this stuff along with all of you I'm old when I learned a code we didn't have you know CH gbt that's not even that's like barely the that's like the you know 1% of what I didn't have Okay um don't think I had this repo why do I have a pass key pass phrase here okay uh just bear with me all right I have this text file that I made manually nothing fancy I just put everything from the P5 reference it's about 400 things into this text file so first of all if you have an idea by okay so first of all I'm as every once a while I'll answer a question in the chat uh wait why why why does this iPad just out of nowhere decide to talk to me I'm I'm gonna yeah I'm not I'm not talking to you Siri oh no wait don't say don't say it uh amirali asks you make a 3D so yes one of my prompts to you will be I'm going to show you how to do it in 3D but I'm I'm not here my overall goal here and I realize I'm jumping around a lot now uh which is why I shouldn't look at the chat probably is to give you a very base level without a design point of view example of how to do this and my hope then is that many of you will find an interesting data set and visualize it in your own way um and I'll show you some other examples the embedding projector from um researchers at Google is a is a really good example of this that I will get to uh all right so this is a tech text file that has everything from the P5 reference and what I have done is I have taken each one of those terms and uh used uh what is called an embedding model to create this embedding which is a list of numbers and then that is being uh brought in to a P5 sketch if I could find it where here um and I'm using a particular algorithm uh uh which is called umap to uh to do dimensionality reduction and what I mean by that is all of those embeddings are long list of numbers in a very highdimensional space and I want to see all those things plotted in a twodimensional space and umap is a particular algorithm that does that so that is the full story from start to finish the fly is back um of this example project that I want to build without a lot of the details filled in so if you will give me a minute here I am going to you can ask a few questions in the chat um and I could maybe answer them but I'm going to just get myself set up here with then I'll put on a little music n e all right I am back so let me uh take a look at the chat see if there's any questions um so let me just answer a few of these questions real quick any reason to use umap in instead of tne uh the reason I'm using umap instead of tne is twofold one I heard it's the newer one it's better I mean that probably is not actually true and there is a lovely uh JavaScript implementation of umap that runs beautifully in the browser and so since that's available that's what I'm using um any chance you'll be doing the Advent of code I'm interested in doing it I this is my busiest time of year teaching so um I wish I think I'm more likely to participate in January which is coming in January but I would love to do at least one Advent of code maybe I can do like solve one and try to do it as like a YouTube short um uh is there a way to Cluster similar things together oh okay that's Raj is just explaining what's going on but yes to be clear my P5 functions is just an example data set and I can use any data set of text and the as long as the text is chunked into individual elements I can do what I'm going to do in this video so for example I could do lines from a Shakespeare play I could do do the list of P5 functions I could do I could do uh uh captions from one of my coding train videos um there are lots of things I could do if you have an idea the reason why I am uh using singular words just as an example is because it's a little easier for me to visualize I can just put the words on the screen if I'm clustering larger blocks paragraphs of text uh maybe I could represent those as dots and you hover over them and then you see the paragraph so I could do that too but if you have an idea for a data set that might make sense for me to do today in this video uh you could drop it into the chat I'll probably miss it I don't know if we have any moderators here today because this was one is I'm disorganized and uh uh I'm trying to uh reorganize for 2024 a new uh group of moderators so if you're interested come join the Discord um but um you could like if if anybody sees an interesting data set and I miss it uh feel free to um I don't know try to highlight it for me certainly in the Discord uh member chat is where I would see it okay so oddly enough you're probably not aware of this but um I did recently uh uh cover a little bit of this in a live stream previously and what I talked about in that live stream was just the idea of I I kind of talked about how I wanted to do this and I hadn't done it yet um so I feel like I just want to like uh kind of recap I'm trying to think of where to start let's start with I just need an eraser let's start with what is an embedding o one of these work have some wipes here just give me a second this is this is why I'm recording to disc cuz maybe uh all right come on little doohickey I guess I should have done this before I started I'll get there uh by the way and I apologies to uh I forget the name of the company who reached out to me and I was in contact with about mounting a whiteboard on this wall anybody's got like a recommendation for like the best whiteboard could ever possibly buy to do diagramming on for videos that I could easily light I've looked into digital ones but don't think that's really going to work for me but this one this one I bought um from like a office supply store and I put it together myself and it's a little one is I did a terrible job putting it together myself it's a little bit clunky uh okay so I'll leave um a bit of what was on this whiteboard from before for um what I'm doing today is very much connected to large language models like chat GPT like the Llama model like uh Claude Claude um in that those models use a particular deep learning architecture called Transformers uh you know you I talked about this a bit in my last live stream there's the famous you know ancient paper now 2018 uh attention is all you need so I'm not going to in this particular session talk through uh what the architecture of a transformer model is how they're trained how they work that's part of the materials of my class and if you poke around in the syllabus you you're be welcome to find that stuff but it is highly connected because the same model architecture that is present in a Transformer a large language model is present in what is called an embedding model and I'm probably going to get this slightly wrong but in essence you don't an embedding mod in my mind and again I'm I'm G to Pro oversimplify this and I'd be curious to hear from the chat or anyone later watching this in the comments how accurate this is but well let's actually so I I'm watch the time have a tendy to over overexplained but let's talk about it in this way this is the way that I think about it and maybe it will be helpful so I've made a lot of videos about transfer learning and again this is I'm going off on a little side to come back to this and with teachable machine for example maybe you've watched some of those uh feature extraction so if I have an image classifier and that image has a cat in it well I let's say I don't have an image classifier yet I have an image of a cat and I'm going to send it into an image classifier that image classifier is presumably going to be a convolutional neural network and it's going to have a bunch of layers and at the very end it's going to produce a layer that's often referred to as logits uh we could call those features and then those will have an algorithm applied to it uh uh usually something called Soft Max which then turns it into a set of probabilities tied to each particular tied to a particular label so the the the the mobilet model which is what I use in a lot of my ml5 Js and other image classification tutorials has 1,000 uh you know 1,000 logits for 1,000 labels and presumably here at the end this cat label after softmax is applied would probably have a very high probability and we get that aha there is a cat in this image so again lots of details skipped here you can find a lot of this in my other you know beginner's guide to machine learning etc etc I'm just KCK me an eye on the chat uh to make sure there's no oh and Nik is in the chat hi Nik oh good well nikil by the way when I get everything wrong nille will correct it you don't have to say n but and I'm going to show the embeddings projector in a little bit which is uh uh thank you for joining nille nille is one of the creators of and if I've gotten that wrong you can correct me in the chat okay so one of the things that happens in a transfer learning process is uh um that a model can be basically retrained to associate different labels with the Logics the features of a particular image so in a transfer learning scenario in a feature extraction scenario the prob abilities and their Associated labels are no longer relevant and instead you just keep this list of Logics which is like a list of 1,000 numbers and guess what in my mind these 1000 numbers are an embedding for this image basically let's say this image is I'm not going to be able to do this math 640 by 480 that's a lot of pixels so what is the data if I wanted to have a numeric signature for this image well I I do I have all of the pixels and every pixel has an r a g and a b and it's a lot of information it's not really it's too much it's not that useful I want to in a machine learning context boil the essence of this image down into something smaller like a list of 1,000 imag 10,00 numbers so that is the idea now with an image it almost you could sort of think of it as like compression it's not exactly right because we started with numbers and now we have fewer numbers but what if I have you know the Cat in the Hat it's sort of like well I guess like these are asky characters but the asy characters aren't really associated with the meaning so there's this whole process in a Transformer model where first these are chopped up into tokens the the tokenization process is perhaps is more nuanced than this but you could think of it as like oh every word is a token or every syllable is a token but the you know the the developers and researchers that make these models have their own ways of tokenizing text and then each one of those tokens has like an embedding associated with it which is like a list of numbers and that's what becomes the input and then there's all these layers of attention and blah blah blah blah blah we're predicting the next token so this is what I kind of talked about previously and it's the thing that I'm not talking about today which is that if I feed the cat in the as a input to a language model I'm going to get um you know a set of pro of of outputs associated with probabilities but in the same way in my mind in the same way that I removed the end the actual predicted label from this image classifier in a Transformer model I could remove predicting the next tokens and just look at a lot of the internal numbers in the hidden layers and somewhere in there might be the meaning of the the the like have a numeric uh representation of the semantic meaning of what I'm passing in so that in my mind is like an embedding so I want to get an embedding for this piece of text now this is such a useful thing to do and you'll see why in a minute with some of the different things I might do a retrieval augmented generation is another topic related to this this is such a useful thing to do that there are models that are specifically trained and built and designed just for this purpose and they're called uh embedding models they're also sometimes especially when I look at transformers. JS uh it's actually called like feature a feature EXT extraction you know feature a feature being a word to describe a uh a property uh I mean that's a very common word in machine learning I think of it as like oh my facial features but we're doing an act there right if I have a if I have my actual face whether it's a 3D model or a photo of it I'm kind of saying like wow look at my nose it's kind of got this uh kind of shape to it or you know boy that tooth of mine is crooked those are my features so machine learning extrapolates features from things and and those features are Quantified into numbers through the you know all the different processes that are involved okay so I'm going to wander back over so that that's loose loose loose explanation I'm going show you a couple other things that might give you a little bit more information wander back over take a quick peek at the chat and move on to now showing you how to use transformers. JS to feed in any sentence of arbitrary length and get back in embedding okay how does everybody feel about that you can't respond to me you can in the chat I guess okay uh um all right um so I'm going to try to answer some of these questions here for a bit uh Ari Sean asks are these logits tied directly to the model oh sorry I didn't change my view here which I can are these logits tied directly to the model for example if you change the weight of the model so I um so this is a great question and I think I want to rephrase it because I think some of the terminologies maybe getting a little mixed up there um so um so I think the the short the short answer though I think is yes in that and and again I don't really have a diagram here but let's just let's think about this so um this is Mo like this is mobilet here this whole thing I should this mobile Net's not here this is the image input this is the model so the Logics that will come out from feeding this image in are the numbers that you get because of the the weights that are in the mobile net model it's been trained if you were to change the weights of the model you'd get different logits so yes if you had two feature extraction models for images maybe they would give kind of like similar Logics in some way because the you if you fed the same image into them because you know lots of models probably look at images in similar ways but uh not you would not be a you know if you wanted to do a similarity search across uh embeddings that were generate with different models you're going to run into issues because in uh I would think because the embeddings you're getting are tied to the way a particular model was trained and that's very important this is not magic none of this is Magic um and it's easy it's a little bit easier to recognize like if the language model is going to predict the word cat after the cat in the it's because of a you know shared it's because of the training data you know there are many me there's many many examples in whatever you know training data set was used of The Cat in the Hat so it's learned the high probability of hat appearing along with those uh that that particular sequence of tokens so with there you can it's easier to sort of then take the next step and realize like oh there's a real danger of cultural bias and problematic Behavior based on how that training data is collected and curated there's all sorts of questions around copyright and authorship so this is a really important big discussion that I am very interested in it's a little sometimes harder to remember that that discussion still exists for the embeddings because even though all we're getting is the numbers associated with it the fact that the Cat in the Hat is similar to maybe some other sentence is because of all the same questions around bias and data collection in whatever whatever data was used to train that model so if two models with the same architecture were trained with the same data set then if I used and I might get kind of like the same results twice would be slightly different but yes I in the end I think that to answer that question I think um if I'm answering it correctly these Logics are calculated you know at through the process of sending the pixels through the different layers of the convolutional neural network and all of the weights and activation functions and all that stuff okay and I realize not everybody knows all of this and that's fine stay with me here um okay uh so I don't see any uh obvious I see I see people answering other people's questions in the chat which I'm thrilled for um okay so let's just come back to this for a second I'm going to show you this particular example so what this example is showing you just as just as as a as another note of what you can do with this so one of the things that um embeddings can be used for uh is um and I might get some of these terms slightly wrong but like a semantic search or a similarity score between two uh uh blocks of text and so one here's a scenario I'll give you um to let's say you're programming a chatbot and your chatbot knows 10 answers and you basically want to like whatever somebody asks you want to give them one of those 10 answers maybe an answer is like I don't know um so let's say the uh question that's asked is what color is the sky and one of your answers that you have is the sky is blue and I think if I go up here so uh or I can oh yeah here is what I'm so what this uh particular example is doing and let's see if I can um do I have it open and this is not what what I'm going to code today even though I'm like and I'm wow I'm at 1115 already um but I think it's good background for this and it is one of the examples you could look at I think it's here no that's just like a test um is uh this so and I'm conf I'm conflating the idea of questions and answers I just put everything into one array but imagine I had an array of questions and an array of answers basically if I can create an embedding if I can turn every one of these sentences into a list of numbers then I can start to do math with those numbers and whatever results I get from that math I can tie it back to the original text so for example I could look and say like which one of these if I if I take what color is the sky which one of these other one two 3 four five sentences has the most similar numbers to what color is the sky now we got to talk about what does it mean to look at whether the two sets of numbers are similar but just from that you can imagine like if if I just had one number like well this one is six and that one is 5.7 those numbers are kind of similar so that's I can match that distance that difference between the numbers so this what this is showing you I think someone said in the chat is like a comparison Matrix uh which basically you can see I'm mapping the similarity of two sentences to a color so all down the diagonal of course it's I'm getting 100% my mug is in the way there a similarity score of one because they're exactly the same 100% the same and here I'm getting a similarity score of 0.07 because the sky is blue and what is an apple aren't very similar in terms of meaning and structure whatever uh other qualities that we might attribute to how the embeddings were created but the sky is blue and what color in the sky that has a 10 times higher similarity score so another thing that I could build right now is like that chatbot question and answer thing um and I'll also just briefly mention I think I talked about this previously if you look up the concept of and there's a great uh replicate by the way is a a hosting service for models that I've been using a lot of uh not not also not a sponsor but uh has generously given me a lot of credits to use because these things cost money although what I'm going to show you with transform transformers. JS runs on device so it does not cost money um but they have a nice um uh rag tutorial uh how to use retrieval augmented generation uh that explains this idea of retrieval augmented generation so what that means and I have some examp I I'm watching the time I want to show you my retrieval augmented generation example that I built in node uh but I'll come back to that if I have time so that's another place where you could use it let me just tell you what I mean and actually Nik was in the chat ah do I have this um I think I have it uh let me just I'm going to open up nille is one of the founders of a startup called lilac um and I think if I um I think this is it here yeah restart this space um I'm restarting lilac uh Nelle helped me build a uh rag for the nature of code book let's see if it uh wakes up here I should disclose that I do have a business relationship with uh lilac but you should Ely check out the work that they're doing um let's see if this can wake up so retrieve what retrieval augmented generation is is this idea of let's say I want to ask a question and I want the answer to not come from a large language models prior knowledge if you will to use that term but instead to actually come from the nature of code book I could do a similarity search across the entire book it's a question of how do I chunk up the book but let's just say I chunked up the book in paragraphs so I could ask a question like how do you code a fractal and then and I have I maybe I'll run my own example of this while we're waiting I'll just show you don't tell me it's not in here uh example rag replicate let's see uh See if this runs um so if I could write a question this is going to take a little while because this is using a replicate platform um and so that they might have to like boot up the model but I'll ask here like how how do you program the canor set I know that's the example in the Lilac oh wow that went really fast oh did I change I think I changed the data I forgot I was messing with this example and I changed the data uh this is now actually not my nature of code book but a transcript a transcript of um my uh processing tutorial I'll show you how I know this for sure um I'm G ask who is Daniel schiffman or let's say who is I'm just going to say who is shiftman because oh no it's fine it's fine let's do that uh right so you can see it's searching for um it's searching for in my video transcript things that are related to that question and you could see I'm about to get started but I want to talk to you a little more about just sort of me and my background and also a little bit about if you'll indulge me the history of processing itself so I could say like uh what is RGB color so this is not searching through the nature of code book it's searching through a transcript of everything I said in a particular video and what R so that's the retrieval the augmented generation is I could say hey take all of this and give it to a language model and say could you answer this question here's the knowledge you need to answer the question don't use your other knowledge and that's the idea of retrieval augmented generation and this uh example does do all of that but I I was mucking around with whatever version the version on GitHub does all of that let's just see uh and and maybe this will come back all right so that's a little bit of um some background so now finally I'm actually getting to what I wanted to do which is let's start getting embeddings now masimo oh oh masimo has a great comment too about llama 2 but bogo's question is really important there are many different models for embeddings uh there are very there are many fewer models for embeddings that work uh on device so one model that works on device is all mini lm L6 dv2 I'm going to use BGE small 1.5 I think today um most all of these models are embeddings for the English language and I my apologies in advance for not being as knowledgeable about what is out there and available for other languages I think it's a bit of a problem that a lot of the research in language and AI is very English language focused and centered and I would love to hear more about initiatives and work that I can support and participate in that is uh expanding the technology to other languages and cultures there's uh so many reasons why that is important um so I haven't done a deep dive into this country name data set that's pretty interesting uh says Yousef that's a great suggestion but so let's look for for the model that I'm going to use uh and um Let Me Close oh I closed that it's fine I'll come back to it um so the model let's go here so first of all so my understanding of the sort of current and I guess I why is my if you're having trouble seeing anything on the screen please let me know um I just lowered the desk because I think it's blocking quite a bit my understanding is that the current latest and greatest model for English uh embeddings and I believe this particular research group also did a version of with the same technique for the for Chinese um is BGE large so we could click over here oh this is uh replicate examples but I think I'm looking for is the paper yeah so this is the paper for um the research group that has worked on these particular models it's from the Beijing Academy of artificial intelligence a lot of these models are published on hugging face which is another uh platform for hosting models and I could see right here I wonder if it's actually going to let me do this without even um logging in I could say you know the Cat in the Hat and I could uh run it and this is going to run on replicate server and give me an embedding right there so uh personally if you look at the GitHub repo that um I will that is accompanying this video under uh save embeddings D Json there are two scripts uh one is uh embeddings replicate JS and this one uses uh the BGE large 1.5 model hosted on replicate but to use this you'll need to sign up for a replicate API token and there's a small cost per query uh to replicate um uh the one that I'm going to use today in this video is using uh transformers. JS and this particular you'll see it here feature extraction model uh runs on device meaning it's actually running just on my it actually can run in the browser but I'm going to run it through node because uh I'll get to why it's a little bit tricky it's not tricky for regular JavaScript people to run in the browser but it's a little bit tricky to get it to work with P5 so I'll get to that when I get to that okay and Kathy's pointing out there are lots of data sets on hugging face as well and that include different languages okay so let's get right to it so this is the particular model I need to raise this up I'm sorry so please let me know I'm going to try to be mindful here about not blocking I guess I could just move myself down and still have my desk higher this is probably a bad idea but I'm going to just do this right now uh uh uh where where am I keyed me okay unlock myself there I'm lower now uh so my desk is still at the same height but it is blocking less of the screen okay oh and thank you munzer for gifting a coding train membership somebody will receive that MBL lab received it wonderful um okay now some more background if you have uh followed me at all you have probably followed the fact that I use a particular Library called ml5.js to do a lot of machine learning examples in JavaScript and boy do I have a lot that I hope to do soon all about this Library coming soon um ml5.js is built on top of tensorflow.js I don't I don't think nil's here anymore but uh looked like nikelle one of the creators of tensorflow.js was in the chat briefly um so tensorflow.js is kind of the OG the original JavaScript library for machine learning and JavaScript there is another one that uh seems to be gaining a lot of popularity particularly in the language model space these days comes out of Microsoft called Onyx JS so uh um what I what you're seeing here is that this particular model uh has been released with Onyx waits to be compatible with transformers. JS oh Nila is still there okay so uh um so what's going on here Transformer the Transformers library is hugging face again this AI uh hosting company platform that I um uh uh find to be quite useful in addition addition all the other ones that I find useful um is uh uh has a python package called Transformers they have recently released a JavaScript version called uh transformers. JS uh it is built on top of Onyx which is the other thing so just like ml5 is built on top of tensorflow.js transformers. JS is built on top of onyx. JS that's probably where the similarity uh stops um but so just want to give you that background and understanding so uh one of the things I'm actually personally investigating is uh if I if if we were as the group who works on ml5 to add language model capabilities to ml5 uh an embeddings model for example could we also include the Onyx backend in addition to the tensorflow back end for that library but all that I want to do here is actually use transformers. JS so that I could get access cths beddings model so let's look at how we can do that now first of all not to overdo it here but um I'm about to wade into the territory of working with node and uh if you are unfamiliar with that you won't you know I guess you could stop watching right now and go look at these but later um I made a couple videos that's about sort of like the tools that I'm using and setting up a node project so I'm not going to do all that detail now but that reference material is there okay so let's go to uh here so this is a new um and I got to just be mindful of where I am so I'm not blocking things too much this is a new empty directory on my Mac I'm going to say npm init Dy just to create an empty node project um then I'm going to open this up in Visual Studio code and I'm going to create a file and I'm going to call it a save embeddings uh doj .js so uh usually the sort of default file for a node project might be index.js or server.js most of the things things I do are making a web server with node but this is just kind of like I just want to write a script that I can just kind of run as a process so I'm like the weirdo who uses node in the way that everybody else might use python or other kinds of command line tools because I'm heavily invested in the JavaScript ecosystem for my teaching and other things that I'm doing so um and so hey there's plenty of other people doing all amazing uh much more sophisticated and highly intelligent uh tutorials and educational materials on machine learning in Python so go find that but I'm here I am just digging into JavaScript again okay so um what am I doing here let's so the first thing I need to do is I need to import transformers. JS if you haven't seen es import statements before I also covered that in those videos but essentially all I need to do and I actually don't is this so I'm just going to uh put this right in here so I want to import this particular node package presumably to use this node package I need to also say um npmi for install I'm going going write install and uh install the Transformers JS node package it'll just take a minute here wow this takes longer than it usually does for me okay now if I go back to uh terminal I mean Visual Studio code you will see here under package.json that I now have this particular dependency uh Transformers uh JS uh from uh version 2.9.0 I should also say that because I'm going to use Imports I need to add to my package.json uh type module um okay and by the way in case anyone is wondering I do use copilot uh been experimenting with it a lot more recently but I've turned it off for the purpose of this live session because I thought it might muck things up too much um so we're we're just writing our own artisanal handcrafted code here in this uh coding train session so I'm going to go back to the documentation and this is what I want I want to uh so the way that transformers. JS works is everything every model is called a pipeline and there is a task and then the particular model you want to use for that task so for example if I go to just the main transformers. JS page and scroll down a bit you'll see like oh I could do a sentiment analysis pipeline or uh these are I could do a uh question answering or sentence similarity or summation or text classification there's all these different there's Vision ones so there's a ton of stuff you can do and for every single one of these like if I just pick I'm going to do um uh image classification if I click here you'll see well there's a video and some other U and it's actually see this is the thing it's showing me quickly it takes me to the python code let's see if there's a JS version so sometimes you have to do a little extra digging because that didn't work I didn't end up on the um maybe if I click here under models or docs yeah this took me to the Transformers JS docs and you can see here and I apologies that my I should make this a little wider now you can see like oh look if I want to do uh image classification I just load this particular model now you might be asking like where is it loading the model all I did was give it the name so this is very common ml5 works the same way I think some uh tfjs models work the same way these libraries have built into themselves the URLs for the cloud hosting P platforms where the actual model files are stored so you could load you could download the model files and load it locally but what I'm doing here is as long as I give it the name trans the Transformers uh JavaScript library knows where to go out into the cloud if you will and retrieve that model now this won't work because it's got the keyword await in it so for me to await the result of loading this model I need to put this in a function that uh is modified with the async keyword and uh if you're not familiar with asynchronous events and async and A8 I won't go to my channel to find them whole set of videos about that as well but I'm just going to write a function called load model who I don't know what that autofill was async function load model and uh I could then write a main function I'm just going to call it Go async function go and I put everything in this F in this function and I'll just like call it I know I should probably put that below and I'm going to say await load model so the first step here is is for me just to load this model and I don't I don't insist for no reason at all okay brain yeah I get it I get it where are we TimeWise 1135 okay uh I don't believe that no JS lets you await in the global context if I'm wrong about that that then my whole life is about to change um let's Also let's also do this and I can say uh uh what do I call this um um I'll just call this the embeddings model or I'll call this like BGE small I'm just like making this up as I go BGE model equals a weight load model okay so now uh let's take a look at this let's make sure this works and again if anybody's having trouble seeing the code or anything please let me know okay so let's run save embeddings and it's going to take a bit right it's got a it's a it's a the small model but it's going to take a little while so while that is going let's go back and so what do I want to do next what I want to do next is get an embedding so uh we can see here I'm just going to copy paste the example this is different than no this is right um um let's just copy this example here and look at what happens and I'm going to just uh have it be I'm just curious can I do it I mean it makes sense to do it with more than one but I thought I could just give it a single string I'm just curious about that because I think that'll be a little bit simpler right now did it load that model yet thanks for my nice typo here we didn't see so uh let's try running this again and see what happens okay uh oh and I need to say await run the BGE model through that Source okay so first of all we see like uh it it's console loged huge uh uh JavaScript object which you can see a lot of the properties and information about the model something that's really important here is this number 384 so that's going to be the length of a particular embedding um all right AR is telling me what about a node version 18.18 which I think is the version I'm using can you really that's insane if I can do that I don't believe you okay good let's try this are you kidding me oh yeah it this is going to work since when what what since when could you do this oh my goodness I did not know that oh wow I got go change all my examples it's going to make my life so much easier we do not need this function okay wow I I didn't think I could love node anymore and I really do love it now all right let's just keep it called as extractor that's fine all right so what's happening here what's Happening Here is I am loading this particular model it's task as feature extraction and the model I'm loading is BGE small English version 1.5 uh there are other models that are compatible with transformers. JS presumably you could train your own embeddings model uh but that's the one that I'm using for here I'm giving a source text hello world I'm uh and you know I this is not me this is not a coding train example if I don't instead put like Choo Cho and then I am passing that text to the model and then these two properties pooling is just modifying a particular aspect of what's Happening inside of the feature extraction process I probably relates to like actually don't know somebody can tell me in the chat probably I'm assuming it relates to like I think of Max pooling with like convolutional neuron networks um but obviously there's some aspect somewhere where it has to imagine has I'm guessing there's like multiple embeddings and maybe mean is saying just average them when you have multiple ones and you need when you to pull a bunch of embeddings together to just get one normalize means it's going to give me the values I'm assuming uh we'll check this the embedding numbers that come out will be between some normalized range maybe between negative 1 and one or between zero and one um so let's run this again uh it's definitely between negative 1 and one based on these okay so we got a uh an embedding uh its dimensions are 1 by 384 because it only ask for one sentence the type is floating point and then the data the actual numeric values are in this particular property called data all right so for example I could say embeddings do dat index0 and that's that first value so for example that fly well all right so let's let's let's go a little further let's just make up a bunch this is where I wish I had um copilot on copilot is the funniest thing if you're like trying to create a fake data set of sentences just starts making up sentences for you it's kind of kind of amazing anyone's experienced that um yeah I can't I still can't believe this thing about me not needing the asynchronous I could just do await in the global spacing node like this is really this changes everything Q like Hollywood you know music or record scratch I don't know what the sound effect that goes with that is all right now we need to decide what is our data set going to be so um oh here I know a place I could look I'm gonna go to corpora on GitHub so this is a GitHub repo that I turn to very often when I'm looking for just like a fun list of things so maybe let's go to film and TV uh Game of Thrones houses popular movies let's try that uh how how long is this this is pretty good has the date U I'm just looking at TV shows how long is this maybe let's do TV shows it's a little it's longer um let's do TV shows so I'm going to do something kind of ridiculous here I mean this is Json so I should load it as Json I kind of want to just load it as plain text because that'll be more common to what you find um but let's grab this oh oh here let's just grab this whole thing raw and let's go uh make a file called tv. txt I'm going paste it in here um and now I'm going to do some fancy regular expression searching uh let's look for a quote the beginning of a beginning of a line and quote and so this is I'm by so uh I got a whole set of videos about regular Expressions so I'm just quickly reformatting this document and then I'm going to search for quote comma quote comma end of line I realize this is kind of a ridiculous way that I'm doing this I'm going to get rid of this let's just now search through did I get everything um actually the reason why I kind of well it's fine let's see if there's anything that was weirdly formatted good enough okay how many TV shows we got here I guess it's 1,000 it said 1,000 didn't it okay all right so let me get rid of this and get rid of that okay great um I don't yeah okay so now I have a list of 1,000 TV shows in a text file called tv. txt okay so now what I would like to do is let's bring in the file system module from node import uh FS from FS I think that should do it and I'm going to say the raw text equals a wait fs. um read file does it just I forget how to use promises I guess I could just use read file sync somebody will tell me I'm just going to use read file sync uh the tv. txt uh with uh the file format is utf8 so now I have the raw t text and just to be sure about this let's console log it to see I'm going to get rid of all this embedding stuff right so there's all of the text files and this I maybe need to like move this in a little bit so it's easier to see so now I want to split it up so shows equals raw dosit by um any number of line breaks and let's look at that array great so now I have an array of all of the TV shows so presumably I could load this model oh I already did I loaded the model here I can now say for let show of shows uh and get now again it would be smart to do some kind of batch process processing where I do like 10 at a time and that certainly makes a lot more sense especially if you're using a model in the cloud but for the sake of Simplicity I'm just going to do it one at a time so I'm going to get an embedding uh for every single show and then I also want to have I'm going to say output Json is an object and and uh and that object is going to have an array maybe called embeddings in it so essentially I want to get the embedding which is in embeddings do dat and for each one I want to say output json. eddings do push and then I'm putting an object in it which is got the show and the embedding which is is embeddings do data and I guess that should be it's a single embedding so I think this makes more sense so let's just see uh you can you can you can all kind of check check on me here if this makes sense so I'm kind of thinking ahead here because I have made this example before uh show can be a const says super crafter that's a good point so could output Json not super in the habit of be that good as using const so what this should do is as I look at and let's let's do console log uh G um uh extracting embedding for uh show I'll put that in as a console log so if I get the embedding then what I want to do and this might make more sense is to say something like let well I'll just leave it it's fine B basically I want to oh this is no semicolon here I want to make a big Json array of the show names with their embeddings because what I'm doing here is creating what you might refer to as an embeddings database now there's no reason why I couldn't bring so you know later I'm going to load this database and do clustering with it there's no reason why that couldn't be in the same app but if it's for in my mind if my goal is to do a visualization of a fixed data set that is not changing it doesn't make sense to rerun the model every single time so I'm going to do these as two separate steps and I'll talk to you about how you could do it as one okay um so here we go let's run this see what happens so doing extracting all of these things it finished so I didn't do anything with the output Jon so I don't know if it worked but let's let's at least console log the output Json let's write it to a file uh let's just write it to a file so FS WR file sync should go to um the file name so let's call it TV embeddings and then I need to give it the uh and I'll do I'm going to do uh const output equals Json stringify and the what is it called output Json so uh what I'm trying to do and I'll I'll add in null comma 2 so these arguments just format it so for me to write this out to a file it's a JavaScript object I need to turn it into a string into raw text so I can write it to the file so this should now you know this isn't a lot of code very simple I'm loading the Transformers JS model I'm loading a data set from with raw text I'm chopping it up I'm feeding every element into the model I'm getting an embedding I'm packaging all that up in a Json object JavaScript object and writing it to a file let's just see could is it possible that I didn't make a mistake here we'll find out okay see how fast that was by the way that's what I like about using an on device model okay this looks pretty good uh why is it is this h no no no no no no no no no no no why did it do that and maybe it's going to be fine in the end but this should be this all right I have to debug this right this I don't want an object with every index being a number uh why did it do that I don't recall this happening in my other experiments but let's see um so let's just do one show here for a second is it something in the way that I did this okay conso log I know I could just type what do I type CL you were saying to me CG I got some Visual Studio code settings I need to figure out um embedding let's just look at this and then let's say break so I'm just going to look at the first one okay so I definitely got a nice plain actual array of numbers all right still just a nice plain array of numbers uh well let's do this console log output Json let's see what happens here oh whoops oh the break the break is before okay sorry about that so let's take this out also just to ah yeah look there it is I wonder if this stringify did so stringify clearly did something uh let's see what's in here now yeah okay uh what if I take this out just huh it isn't an array object oh okay so I have to because it's this special kind of float 32 array thing it's not actually an array you know actually I think Transformers JS has this list I was looking at the documentation I think I saw a list function oh yeah two two list so I wonder if I'm supposed to use two list let's see what that does um so this is this is useful for me to know is it uh two what was it two list oh without the underscore okay let's try this not too L does it does it go here this is how yeah ah okay ah oh it gives it to me okay so this is good so maybe that's what I want so I want uh this embedding to list index zero because I I'm just getting one I think this is will now work let's see what we've got um and see here oh let me put this back I mean I don't need the formatting well I think my visual studio code will format it yeah okay great that fixed it that's what I want I want to actually just see the array of numbers okay so the formatting is very much unnecessary but it it's helpful for me to be able to see it so I'm going to put that back in uh null comma 2 and then I'm going to take out this break and I don't need console log here this should get me and again this is because I'm not batching them so I'm just doing one at a time which is probably not best practice but it'll get us uh it'll get us to the finish line here okay here we go extracting all the embeddings all right we've got all the embeddings now and there there it is now usually in Visual Studio code it lets me like fold these up but doesn't really matter you can sort of see um whoops I I hit save and it did something so you can see that this file is not really human readable uh and actually one thing I'm very curious about is how big is it reveal INF finder 9.5 megabytes so one small problem here is that the I wanted to show you how to do this in the P5 web editor which I think is useful the p5b web editor is um uh can you can only upload files up to 5 megabytes so I have a couple options one is I could do this with fewer TV shows another is I could uh just Host this file in a CDN somewhere if anybody has any suggestions all right I'm going to let's let's go let's go move to the next topic so I'm going to come back back to that so I have my embeddings so you could imagine now there's a lot of things I could do for example I could do make a chat bot where I where I asked the question please suggest a a TV show for me to watch I love TV shows about Farms now again because the embeddings are just associated with the titles of the show this won't work very well but I could now turn my question into an embedding and then do a similarity search across all the TV show and return a suggestion more likely if I really wanted to do this in a more robust way I would want to do like embeddings based on like the description of the shows and all sorts of other more have much more information and data and I would love to see people uh experiment with that I got to come back and do some more of these like search and retrieval things and the secret to it which I had a diagram up on the board is looking at something called cosign similarity okay host on the cloud would be nice on gith yeah I could just host it on GitHub actually so let's let's actually for the sake of argument just so you have access to it's not that different than what I already have but let me just go on GitHub and make a new repo for this live stream um embedding I'll just call it em we can change the name of this later uh make it public uh create the repository um and uh let me just get this here and then I'm going to say get init wait actually let's add a get ignore first there's no environment variables but let's just put that in there just in case I forget later um maybe I don't want to um right now let's not upload the um data files so I'm going to ignore those as well oops code from live stream and then add the remote oh wait the whole point was for me to host it on the CDN okay fine I forgot what I was doing here so I do need to include these things yeah oh and that took out the package.json file too I made so many mistakes there uh I don't know if I need that but I'm just it's a reflex at this point okay so now uh here we go the repo is there there's no uh read me I I don't know like so one I'm a little I'm a little a little bit hesitant about this because I have this whole repo that I already made called save embeddings Json so this makes more s it's like documented and I have like you know in instructions and things so I'm not sure you know I'm not sure if I should deprecate this later and combine them but for right now it'll work because what I want is to be able to uh load this file um you can use a JS deliver link but um I think this will actually work just load the these embeddings from this raw file okay so let's now go to the P5 web editor and let's see if we make the font a little bit bigger so I want to move towards uh clustering and umap where where am I time wise oh I'm at noon I said I was going to be done at noon but we're going to keep going because I want to finish this by golly oh just the TV shows on a gist well that makes more sense okay I should have done that so uh paste bin yeah the gist would have made more sense too late it's too late for me I've done this already okay I'm trying to think so there's there's two steps here one is how to load that embeddings database into P5 that's actually not going to be too hard I'm just going to use load Json so let me skip that for now now the other more complex question is around how am I going to take that data and draw a clustering map of all of those TV shows and for that I am going to use a particular algorithm called umap now let's go to uh the uh embedding projector um this is a research search Project from the uh group at Google uh I you know I've name checked nikelle a bunch of times uh nikil is one of the uh creators of this along with Daniel smov and I'm probably missing lots of other people who worked on this um so apologies to that um this is a visualization of highdimensional data um that has a very thoughtful uh interface and demonstrates various different algorithms you can use to visualize that data so first let's talk about what's here so the demon the the data that is being used to demonstrate uh first when you load the embedding projector is word to VC what is word to VC so you might think this whole idea of embeddings wow large language models AI we're living in the dawn of you know putting words with numbers this is not a new idea and in fact if you go to back to my my syllabus under the embeddings week and I scroll down uh stay at the top here you will see that I even made a couple videos that I never finished so I really should get back to and somebody just gifted like azillion memberships wow okay I've never seen this happen but thank you to uh generate Collective that is uh unbelievably generous and kind of you um so uh uh so I made these videos what is word to VC color vectors that understanding word vectors article is by Allison Parish it's absolutely fantastic I would really recommend reading it um and the original paper around word representation in Vector space is from 2013 so that's like 10 years ago so there have been uh many instances and examples of looking at how to vectorize uh text text um and uh word Tove being a particular model and uh embeddings database that has been used in lots of different projects uh Universal sentence encoder is a tensorflow.js model from 2018 that turn sentences into embedding so this is not new territory I recommend this background reading for you um by the way I've got some other links here to other reading material around embeddings that would also I think it's good background material so what this particular visualization is showing me is 10,000 words um each of those words has an embedding of 200 numbers and yet I'm seeing them in threedimensional space so what does this mean let's go back to the Whiteboard for a brief minute if you'll indulge me a little bit here okay hold on I'm breaking out the Windex everybody I don't like to use this if I don't have to but it's gonna water would be better but you know time is of the essence here the Windex just does the trick now I'm breathing in the fumes hopefully I don't know okay let's just get all of this out of the way get one of these nice cloth all right dry it off okay so let's just say for the sake of argument that I have a word um boy this that I have a word uh like uh rainbow and it's associated with an embedding which is uh 200 numbers and I have a word uh Cy which is associated with an edting and it has 200 numbers now let's think about a different example let's say I have the word red and it's associated with an embedding of just three numbers and I have the word uh blue and it's associated with an embedding oops damn it which is just three numbers I meant to do this the other way around and I I have pink and it's associated with I don't know three numbers I I don't know if that's pink whatever so if I wanted to visualize these three words according to their embeddings well I have a number of ways I could do it I could do it with actual colors but let's say I wanted to plot them in a three dimensional space well I could consider the first number to be the xaxis the second number to be I kind of want to make the second one the zaxis so that I can I make I do that no that's fine the Y AIS and the third number the zaxis and then you could start to think like okay so red R would be like over here because it's at 255 along the x axis and maybe blue would be over here because it's uh so this is blue and this is red and then maybe pink would be kind of like you know somewhere like here this would be where pink is and you could start imagining plotting all these colors because each word is associated with three numbers it Maps easily to three dimensions if I wanted to plot them in two Dimensions I could just do something like well let me just get rid of the Y Dimension you know I'll still just plot them if some of them have a lot of green in it I'm going to lose that information but I'd still kind of have a a basic visualization of the color space what do I do if I have 200 numbers well in an Ideal World I'd be some kind of like alien super being like you know I don't know think of those things in the movie arrival or something but I could just like see 200 I could just like let me draw you uh a 200 dimensional space and you're GNA just my my brain I don't know about you my brain does not work like that I can't even in my mind visualize a four dimensional space I can barely do a threedimensional space if I'm being perfectly honest here so there's not an easy way to visualize these numbers in a high dimensional space that's the information though is in that high dimensional space so what I need is some algorithm for dimensionality reduction if I could figure out a way to take that and just reduce it down to three numbers still retaining the essence of all of the numbers then I could plot that and maybe G glean something about the data I could start to Cluster them I could do K near you know there's all sorts of things I could do uh like in the embedding projector which I'll show in a second so the question is how do I do that well like with I said here like ah why don't I just pick I want to do in 2D or 3D I'll just pick the first three numbers sure I'm losing 197 other numbers but let's try that you could actually do that it's not a big try it go for it I could maybe even do something like well uh what if I want to do it in two Dimensions let me take the first 100 numbers and average them and the second 100 numbers and average them again it's probably not going to do I'm going to lose way too much information it's not going to retain the actual geometric structure and positioning of the 200 dimensional space but that would work that's a dimensionality reduction algorithm so there are this is but this is the task that I need to do my data does not is not originally in twodimensional or threedimensional space but I want to see it visualize it in that space how do I reduce these vectors down to a lower Dimension and still yet retain Ain uh as much of the information I want things that would be near each other in two dimensional space to still be near each other in twodimensional space so that's the problem at hand um I'm thank you fun Planet who seems to be doing a heroic job of moderating the chat I appreciate that um so this is the Energy Savers oh wait what the I'm plugged in let me try we've got a slight minor emergency here which is that my battery apparently I have not been plugged in and the battery is very low I'm plug let me check is this not plugged in there is a plug that's plugged into an outlet is this I'm afraid to turn anything off it's got some cobwebs on it let's try plugging this in wow what is going on here oh okay hold hold on uh I'm going to unplug from the screen for a second just to plug this in directly to this one port that I know works okay something is wrong with my power supply give me a second I have a backup one I have a backup power supply um coming back I mean I could also but people are just like I've never seen this all these gifting of memberships I didn't even I like forgot that I had that turned on this is very kind of you okay I guess I should do these live streams more often um okay uh hold on I'm just getting another plug hopefully you can still hear me let's try this one I cannot have my laptop die before I finish this now this is very dangerous what I'm about to do I'm going to try to plug it in from a different place it's a tripping Hazard where I'm plugging it in so somebody remind me not to trip if I start trying to go to the Whiteboard okay we are saved everybody so I don't know what's wrong with this plug let me let me just make let me put it now that I know it works here I'll put it out of the way where I won't trip cuz as fun as that might be for all of you it won't be good nothing good will come out of me all right yeah so there's something wrong with that other power supply so uh okay did okay hold on we're I'm going to be back to the tutorial in a second I am recording this whole thing to dis so it is possible if there's interest I would be glad to make an editing version of this and editing an edited version that's just the like tutorial part which might make it easier for people to rewatch later um but we'll see okay um all right so I was talking about so I want to make a version the so I was a little bit background around word to V right and so we can see here that if I were to zoom into this I um you know presumably uh words that are near each other are going to have sort of similar uh similar meanings uh because this uh the 200 dimensional space of all of these words has been uh reduced down to three dimensions now how was this done was it done by just taking the first three numbers was it done by averaging no it was done with a particular algorithm called whoops PCA principal component analysis let's take a look at it with a different algorithm called tne which I have no I forgot what that stands for at one point I knew uh so do uh um this will definitely be there this will 100% be available to watch later I just um was wondering if it might be helpful to have a shorter version of it without all of the like me finding my plug and stuff in it now I this doesn't usually run so slow to me I think it has something to do with the fact that I'm plugged into the streaming system but you can see now the tne algorithm is uh moving the dots around uh reducing the 10,000 points to 200 dimensions and at some point it will finish and we could start to explore it um I could even change it to 2D and there's some oh you can't see this down here but there's even some like various parameters and things that you could change but um so uh PCA I you know this is my loose understanding is principal component analysis was one of the uh first algorithms to do this dimensionality reduction tne was all the rage a number of years ago and more recently uh umap is a new algorithm uh that uh uh along some set of metrics uh retains the uh relative similarity position I'm trying to think of like what's the best way to describe this I should really just point you to this article which will explain it uh much better data's Global structure that's the word I'm using umap is a technique that offers advantages over tne most notably increased speed and better preservation of the data's Global structure so this is a wonderful article from Andy Conan and Adam Pierce from Google pair uh people in AI research um that describe I believe these are the same authors as the umap JS library that I'm about to use you can see Canon ey here which I assume is uh the the same name U might be getting some of these details slightly wrong uh we're still going there but so this article does a wonderful job of giving you a high level understanding of umap so first of all this is now what we're seeing here which is nice is the clustering of images so if I were to make a again I'm way over time already here but I would love to do an example of this with images I'm going to do it with text right now but you can see the difference this is this is using a particular data set called fashion mnist which is basically lots of little low resolution images of a whole lot of shirts whole lot of shoes a whole lot of pants and so if we look at this you can see like uh zooming in here you can see like a lot of the shirts and pants uh so sorry coats and pullovers and shirts are here all the shoes sneakers sandals are down here umap has done this amazing job of organizing all of the data according to its similarity it's not matching shirts with shirts it's matching embedded ings with similar embeddings and it just so happens that those embeddings are coming from images um and these are low resolution enough that I'm assuming this is actually just done with the raw pixel data as opposed to what I was talking about earlier with like feature extraction through through some image model um so you can read more there's a wonderful there's there's a couple different properties of umap that we'll see that you can change and you can kind of uh play around with these different visual interfaces to kind of understand like well what does it consider how many neighbors that are near it in high dimensional space is it looking for to kind of map down to to lower dimensional space how far is too far how close is close um and there's a bunch of different demos this is one that was super interesting to me so this is actually taking a three 3D data like from a 3D model and doing umap projection you could also call this dimensionality reduction projection it's no different than how you might do uh projection in a 3D renderer because you've got to take 3D data and create the illusion of seeing it in twodimensional space that is dimensionality reduction as well so but umap dimensionality reduction is doing like you can sort of see how it works here and you can see what these parameters do like if I take uh minimum neighbors all the way down to three and minimum distance down to zero this is how it's arranged this data into two Dimensions versus increasing the number of neighbors and increasing that minimum distance you can see like look at this strange like crazy version of this Mammoth now in 2D so this is ultimately what's happening um and there's a lot more examples and demonstrations and explanations in this article so um I uh you know one is I've read this through it really helped me I cannot you know regurgitate it in an eloquent way right now I'm going to just uh sort of recommend that if you want to learn more about how umap works that this would be your starting point resource for us however what I would like to do is just go to um app.js and there's probably a more elegant way to integrate this into your code oh you can install it through npm but I'm just going to for the sake of using it in the P5 web editor I'm just going to go under lib I'm going to go to umap js. JS and I'm going to just download this file so I downloaded that file and in the P5 web editor I'm going to upload it and where is it under downloads here it is let's upload it and now in my uh index.html I am going to include I don't need this is the sound library right away so I'm just going to get rid of that and instead include uh umap Js s .js so and this is my umap clustering example okay it runs we've got a sketch okay so now what I need to do is two things one is I need to figure out how to run the umap clustering algorithm and in fact let's just do that right now with random data to start and then I'll load in my Json uh embeddings so let's make a uh array called data and let's make 100 random data points and have each one be an embedding uh I don't I'm making this up as I go uh uh a record I don't know what to this is like maybe I'll call this embeddings and I'll call this like data uh let's just make an array with three random numbers in it um and then let's push that into the embeddings so what I have here and U okay I got to keep an eye let me open this which will help make sure that I'm not standing in front of the code okay so this is I'm creating three I'm basically doing um where's the Whiteboard I'm basically starting with this so I'm going to start with this which is just embeddings with three numbers and I'm going to try to do dimensionality reduction down to two Dimensions if I can get that to work then I can load my higher dimensional sentence embeddings okay so now uh I don't know the umap library off the top of my head so we'll follow the documentation um so I don't need to import it because I've just loaded it from the file itself so I'm going to uh just create a new umap object let me close out let me just close out some other things running make my screen a little brighter so I'm going to do map and I'm just going to use let you don't need to tell me cuz I'm in the P5 world now my friendly let place and I'm going to say uh umap equals umap and then literally all I need to do is say um map I'm going to show you how to animate it later but fit uh embeddings so that should do it let's just let's just see if I do it do I get an error or anything oh it's slow wow wait wait wait 100 things just calling fit should not freeze I probably should have paid more attention to to uh what I was doing here because I might not have the data in the right format um I can look at any of my examples oh you know what I think is an issue here is I'm not um setting the uh all right let me look at one I I made this example already and I'm a little bit pressed for time here so let's just go and look at it uh oh right and it's in my a toz uh sketches it would be uh that's interesting this is a different one I'm looking for I thought I made a hello world one but let's just look at this yeah so so let's oh yeah I think I I sort of didn't I sort of forgot about like the important part okay so I got to um kill this page uh let's see if we can get it back okay okay I missed some important things here which is that um and let's just see did I get that right yeah I would like these to be on different lines because okay it's not going to do that that's fine okay so what did I forget so one thing that I forgot that really important is I need to uh give it some initial properties and as that article demonstrated these properties and neighbors minimum distance those are parameters that affect the cluster ing I shouldn't say clustering because clustering to me is really like actually putting them it it affects the structure of the dimensionality reduction how many other elements is it looking to get near uh what is a distance threshold those are really important parameters you can play with this is the what I want to really focus on it is um the dimensions that you want to end up with so I started with threedimensional data I want to end up with twodimensional data now I might have done maybe this like is a problem let me just put in the let me just do this that's kind of not what I wanted to do but just to make sure let's just see if this now will finish and not freeze look at this for a second let's look at what the format of the data is in this one that was working sure okay so this one worked and it's just 120 and I maybe and it is actually using just actual RGB values so maybe I should just try that this one's still frozen oh fix line eight oh oh that's the problem I'm sorry everybody I'm sorry everybody okay see my naming is terrible this is data and also by the way just for fun times now I realize I can make these 255 okay all right everybody we're moving on here with life okay great okay it's working so so all that was wrong in case you weren't following that is I was being a lunatic and trying to put my array into my array and I had an empty array full of itself recurent and then I was trying to you map that definitely not going to work so let's just look at what is the data what does the data look like what are the data is probably the what I should say uh oh no so what are the embeddings umap is expecting a array of arrays so I have 103 dimensional embeddings they're just color values then let's look at what do I get out let's look at umap and maybe I'm supposed to uh if I call fit what well let's look at the documentation uh maybe it's just in there maybe I'm just being um stubborn here so learning rate there's other things I could change random categorical distance function optimization state I'm I'm being so stubborn and not looking at my example like refusing to look at my example where do I get the results I random spread that's giving me my properties I mean I did it I'm just refusing to look at the example I'm gonna look at the example fine you got me uh you map results oh oh you yeah no wait you map results oh that's the array okay hold on what am I do oh I see all right fine everybody it was I'm just being silly okay so how does this work and I kind of hate what's going on here I have so little room on my screen for the code and I really want it to like I'm just going to make it a little smaller you tell me friends if uh you can no longer read this on your giant your tiny little phones that you're watching this stream on okay um wow that's way smaller that's too small I can't even read that now I get 28 okay um so uh I umap is the object that is going to uh execute the algorithm and hold all the parameters the results are return from the fit function now what I would like to look at are those results and here I now see uh I have all that data mapped to two Dimensions now you have to I have to ask the question of what is the range that I'm getting good question I don't know ask the people who wrote that umap JavaScript library um okay hopefully you can um so what what I'm going to do now I think so so it didn't retain like the umap space that it projected it into is kind of an arbitrary space and this is actually a stochastic function meaning it uses random numbers and you're going to get a different result each time there is a way to pass a a seated random function into it so you get the same result each time but that's beyond what I'm doing here basically let's look at the following just really quickly let's go and say for and let's make the background uh black for let I equal 0 I is less than umap results. length i++ and I'm going to say uh I'll call it data point equals umap results index I and then I used the con there even though I said I wouldn't let's say let x equal data point uh index zero and let y equal data point index one maybe I want to translate to the middle of the screen and then just say fill 255 and draw a circle at XY that's you know like eight pixels let's see what we got uh and I'm going to say no stroke so you can see that's all of those points but that's because the range I haven't thought about mapping that range to my pixel space so one way that I could do it is I could say hey let's map it's got a range between negative 1 and one to between uh you know negative 100 and 100 uh and um maybe let's take the Y and do the same thing uh what's going on here so in in other words this isn't a great way to do it because I'm just kind of grasping at straws so what I actually would like to do and I I know I could use like some fancy higher order array functions to do this let's look for the smallest value oh that actually is not so bad let's look for the smallest value and the biggest value so I'm going to uh say x is data point index zero and Y is data point index one let's get rid of the translate I'll just do the mapping through what I'm going to do and then I'm going to have some numbers like the minimum X should be negative negative Infinity Max X is positive Infinity Max X and let's do that for the Y and then uh I don't need these temporary ones I'm going say the minimum X is whichever is lower the minimum between wait do I say the max no the minimum X is infinity the maximum X is negative right because I need to start with the opposite of what I want to get right I want to find the minimum value so first I'm going to check is it less than infinity yeah so I just had that wrong so is the minimum between the actual value and what it thinks the current minimum is uh and same thing for minimum y uh is this for y and now I can do that for the max values whoops and just change this to Max I look forward to all of you suggesting much fancier nicer ways of writing this and then now I can map from minimum X to maximum X maximum X to Zero to width and then minimum y maximum y zero to height and because I my random data is color um let's look at the fill as embeddings index I index zero so I'm going to just use the original embedding values to set the color and this is very clunky because of the 2D array stuff now look at that woohoo okay let's let's make it more Colors Let's do like 500 now there we go see what's happening here look look umap took those and clustered them look at all the greens in their house now these are Rand so let's do random seed just so um I'm just going to show you this so I could say random seed so I get the same random color data set every time but I'm getting a different umap arrangement every time it's because uh umap is uh is a stochastic process and it uses random it tries things randomly and starts moving things around uh based on the random tries that's probably not a super accurate technical way to explain it um okay so we're gonna get to the sentence we're gonna get to the TV shows we're almost there to the end 1236 oh boy okay I gotta I hope I'm not missing a meeting I don't think I am all right so just for the sake of argument though I just want to show you that I could actually give it let's let's um let's put this into like an options object because I think it's a little bit more clear and I can say um I can give it the P5 God I hate how I don't have space here um I can give it the random function in from P5 there we go thank you Auto format um so now because I seeded the random function I'm telling umap to use the P5 random function it's the same orientation every time so that could be that could be important um in different cases okay so this is pretty good and I could move right now to just using the embeddings but let's let me show you one more thing I'm going to duplicate this I'm going to say umap clustering two and what I'm going to change it to now is because especially with a large data set you it can run very slow and so you might be waiting a long time for the final clustering plus it's kind of fun to watch it so I can say uh let's see if it's here fit async looking for a step doesn't seem to be documented here I don't know where I figured this stuff out I must have been looking at an example but uh I can just say initial I think I know how to do this so I'm going to say initialize fit I think that's the right function name and I'm also going to say umap is running or just going to say like yeah let like umap running is false and then I think I say I should just look at the example this is very silly so I thought it would be in the documentation but and there's probably a different documentation that I could look at um but I forgotten what it is uh this one will have it um you step I should have known that and then get embedding okay that's all it is okay so then I'm going to say um umap running at the beginning of draw I want to do one cycle of the algorithm every time through draw I'm going to say umap running is umap Step so step through one cycle of the algorithm and then the uh umap results basically which I guess I can make that a local variable oh so I think I just only need I can just call initialize fit umap results equals umap get embeddings or maybe hold on let me just check this yeah step umap get embedding or result yeah okay then I'm gonna say umap get embeddings okay so what did I miss get embedding there we go ah so now you can see it's doing uh one cycle of the algorithm every time through draw now it's never going to stop but actually it will get to a point when it's finished I just need to tell it to stop stepping so I think that I say if you map running then uh I want to call step because I I still want to oh no if it's not running whoa wait oh but I maybe I need to be running at the start no okay uh wait what did I do wrong hold on let's okay oh it's telling me how many so that's giving it me it's actually giving me a count and is it going to go to like zero or something you can see it getting close huh so this is not what I expected again I've got to look at my example which I keep closing because I really don't want to look at it is yeah that's what I did result my is in the results where else and I started it as true that's interesting okay I mean I guess it doesn't really matter umap running how's this different uh I guess I did the whole thing oh okay I I had the whole thing here in draw so anyway the there's obviously like a so I might not have been doing this correctly but I see that now it's doing it so this is fine I'm going to figure this out so uh I'm going to say if so I know it's going to do it yeah let's just do this umap running is true uh I'm going to say iterations equals map I'm just going to make my own version of this is greater than or greater than or equal to 500 or is less than 500 and maybe there is a way to specify it in the options um umap running equals false and then uh I mean this is silly I I've kind of I will refactor this later as I like to say uh okay uh if I think it makes much more sense for me just to do this okay what did I okay this should work right so basically umap step gives me the number of iterations and um B I want to keep calling step until I get to 500 uh so that should run through 500 and then we should see and EPO is the option name so I could do that so that's so let's do that let uh NE EPO equals 500 uh and then um I could say n EPO here and then and epox here so this would be a more proper way of doing it okay sorry for that uh now you see this is now the umap algorithm running all of its iterations and it's I you know even though it's a little bit there's you could probably make a much nicer animation of this where you actually kept track of the points over time and like interpolated them but even so I kind of love like like now I could do like 2,000 points and it's kind of like this lovely like mash of color uh that slowly over time starts to separate out into its uh positions so even just visually here I think something interesting is going on but let's tie this all together I'm an hour over what I meant to be but that's fine I'm actually doing this stream and this project some amount of you have stuck with me for quite a long period of time many many of you've been very generous in gifting memberships and things let's bring in that sentence data so save one more duplicate and now I'm going to put in function preload I'm going to have a variable called Json data and my Json data is equal to and let's turn off the auto refresh I need to go back to wherever I uploaded that uh embeddings database which is right here let's go to Raw let's grab this URL and let's do low Json that URL and let's just for the sake of argument put in console log Json data just to make sure it's there okay what did I miss semicolon is in the wrong place because I have so little space for my code okay great so you can see I got 999 embeddings so that's good I got 999 embeddings and I don't know what what follows that okay so now the data these are the embeddings so uh I have a global variable called embeddings already so now I'm looping through the length of the Json data and I am saying Json data oh it's in a variable called embeddings so embeddings do length and uh I should really think about renaming these variables because I'm using the word embeddings in probably too many places but I can take uh Json data embeddings index I so I'm putting all of those things into that original this is ridiculous I oh no it's not it makes sense I have to umap requires I'm gonna I'm going to change this to like raw embeddings I think that'll maybe make more sense so what I'm doing and we don't really care about the random seating here right now so I'm going to take that out the raw embeddings are what umap needs my embeddings are coming in with these JavaScript objects that are paired with the TV show name which I also want so I'm going to leave the same options we're going to do all the same stuff but now instead of drawing a circle let's try saying we are so close to being done here text Raw embeddings embeddings oh God I I need a no no not the raw embeddings the Json data again I could organize this better Json data. embeddings indexi dot what did I call it show show do show X comma y okay so I think what this should do now is instead of the random color data I've loaded all of the uh again remember I've loaded all of the TV shows that have a name and an embedding I've reformatted it into a raw embeddings array which is what umap needs and this should be raw embeddings here then I'm getting the results visualizing them but instead of circles I'm drawing the actual text let's see what happens okay great I think this is working so I'm going to stop this because it makes much more sense I need a much bigger pixel space for this to be interesting at all so let's do uh window width and window height and I'm going to do let's take out the console log I think this is done I'm going to do share and go to this full screen view and let's see what happens sorry for how flickery this is probably like destroying YouTube compression after 500 iterations we should see something not whoa okay wow I guess I was expecting to have something with a bit more structure to it but um I guess these show names are really kind of like wildly different Curb Your Enthusiasm in 21 Jump Street yeah those are basically the same show I mean nine to five let's let's double check the code to make sure I didn't mess anything up number of neighbors umap step yeah I mean I didn't change anything so maybe this data set I mean I could try a different data set real quick uh we could try playing with these values um but uh I also think I might need to stop now and and let you all like try this with your own data and make more beautiful interesting visualizations try 3D be more thoughtful about the design and interaction can you zoom in and out all that kind of stuff I'm a little bit disheartened um let's look at let's look at this um let's see if we can uh look here again and kind of like what happens if I so I get things minimum distance yeah so lower minimum distance let's just try using some crazier parameters like let's lower the minimum distance and let's like increase the number of neighbors I was going to put in 50 here and hit save and then hit refresh oh also maybe I hadn't actually hit save before I went to the full screen but let's see what we get so fun Planet says isn't raw in edings the same as embeddings no because the embeddings file is written in this way where the actual embeddings are inside these little Java object objects with show and embedding and umap JS is just looking for a 2d array so that's mean just reinfor re re re um reformatting it okay let's wait for 500 iterations it you know the P5 uh functions worked so well that I just assumed any data set would kind of work but I'm not getting um uh really great results here but I mean it did do something like maybe if we did similarity scores between these we'd see that this actually this Arrangement like really makes a lot of sense but also this data set is kind of silly um Boardwalk Empire and aliens in America are You Smarter Than A Fifth Grader Cupcake Wars that kind of makes sense that those are near Name That Tune yeah Murder She Wrote also like this is like the worst visualization ever uh so A Pup Named Scooby too um so it's sort of hard to evaluate because uh my data I picked a poor data set um I'm missing are you sure am I missing something oh I'm missing yet another I think fun planet in the chat caught something really crucial I think so let's let's let's look at my mistake here so this is my naming problem of calling everything embedding everywhere in my code um look at this yeah this array has objects in it that has the show and that so it is the same so I did I made a huge mistake here this needs to be the the whole point of this was to only put the arrays in it yeah look at that now I have a raise of 384 okay hold on we're going back stop save think we're going to get something now I mean we'll see we still who knows how you know it's going to work other people caught it before fun Planet I just noticed you fun Planet because you have the wrench so thank you everybody yeah William Clark I see says it um yeah now who's it's definitely different um you can see it's quite different and um Easy Street East Street Flamingo Road 21 Jump Street yeah yeah yeah so the embeddings are you know obviously this we're just doing it by show titles you can see this little cluster here the Restless years the light you know Living Color love of life okay now we're getting results again my visualization lacks a leaves a lot to be desired um I am curious I really I think I'm an hour Beyond where I meant to be let's just try I'm just curious um I I would love to do this now in 3D um but you know I got to move on with my day but I just want to try changing those parameters a little bit just to see if we get more structure so you could imagine uh so one thing I give you a lot of prompts here one try doing this with a different data set smaller data set even try doing it in 3D think about if you can make this a navigable space like how could I zoom around move in and out maybe I could hover over one and it would like link all the ones with a certain similarity score could I use like a force directed graph like maybe these things are connected with spring forces and the spring force is related to uh its similarity score there's so many possibilities here I would love I mean maybe I mean there are some of you somehow still watching this um what I'm going to do is I'm going to turn all this off right now and I am going to it'll take might even be till tomorrow although I I I I welcome help with this I will link from the video description to all of the code all of the Articles all of the stuff that I explained in this uh if you think it would be valuable for me to work with Mata who does video editing for the coding training to try to create this was now a 2 and a half hour 1030 11 2 and a half hour live stream I think this could probably get cut down to like an hour um um right a bigger uh right we could try this with I didn't get to start show you how this would look with the replicate embeddings model I mean that the the BGE large so there's so much more to this but I hope that you learned something this open your eyes to some possibilities maybe you're in ired to make your own version of something I kind of would like to do this with YouTube channels actually um so I have to stop I I have too many my my my brain is melted from building this whole example but um so if you want to engage with this more go to the codtracker if it's not there the video description for this live stream should be annotated with all of the links and code that you would need to reproduce this on your own okay uh thank you everybody I'm G to just put on the goodbye stuff and kind of I will put on um this little song here just to see if there's I'll take like one or two last questions um and let me just look at my message okay uh uh sorry I'm I'm like I'm like looking at uh my text messages which I don't need to be I'm just an IP oh Jesus Christ um okay uh I love embeddings the meaningful data thanks Dan uh is there a neural network from hugging face that knows the semantics of your words yes this is the idea of the embeddings models now I think we have to be very cautious about how much intelligence or uh we ascribe and how much we really believe that these models are perfectly encapsulating the semantics of our words they're you know all of the same kinds of cultural biases and issues that language models might have and how they predict and generate text all of those same considerations exist in the embeddings models however I do think it is is quite a tool a powerful tool to be able to work with data sets to create art with data sets to understand your data better um and there's lots of possibilities there for sure this song is much too long because no uh um but let me let me this let me just close out these windows to make sure everything's saved I'm going to hit stop recording on my recording to dis uh hopefully audio quality oh oh you know what okay oh no oh no okay hold on I think it's not a problem because yeah I the recording to dis audio was being passed through NV video broadcast so it probably has all that like popping and stuff in it but I do have the I could archive the audio from the stream and put it together so oops so that might that might make it a little more challenging but um okay all right goodbye everybody I will see you uh I don't know when sometime again I I I like doing this if you like just the live stream where I build a project like this and this is useful to you I'll be curious to see if this video has any life to it after this stream that's why I used to like anyway I don't need to go into all that right now just thanks for watching come come say hello in the coding train Discord and um yeah that's it as always I always forget that this this going to do this this to do this this this this do dot doet do dot dot do do do dot do do dot dot going to do do to do do dot I'm going to do do dot s this dot dot dot never forget this do this dot this dot this do never forget this do I'm going to do the this this dot this dot this dot the this Dot Song never forget the this dot somebody composed that song for me
