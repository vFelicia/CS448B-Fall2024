With timestamps:

00:00 - hello this is the first video in a
00:03 - series of videos I'm making about the
00:05 - Microsoft Kinect this thing so what is
00:09 - this thing how does it work and how do
00:10 - you write your own software that makes
00:12 - use of this thing how can you do all
00:13 - sorts of creative coding projects now
00:15 - there's a lot of different programming
00:17 - languages environments and frameworks
00:18 - and libraries for how you might make use
00:20 - the Kinect I'm going to use this thing
00:23 - called processing processing 3 the third
00:25 - edition version of processing which is a
00:29 - Java based programming environment open
00:30 - source environment that there is a
00:33 - connect several different connect
00:34 - libraries for eventually I will hope to
00:37 - make a video where I look at p5.js which
00:39 - is a JavaScript framework for doing
00:42 - creative coding in the browser and how
00:43 - might you get the stuff from the Kinect
00:47 - what is this thing called the Kinect in
00:49 - the browser itself which I think will be
00:51 - an exciting thing to see as well but in
00:53 - this first video what I want to do when
00:56 - I get into the code really in the next
00:57 - video and what I want to do in this
00:58 - video is give you an overview so what
01:01 - are the different editions of the Kinect
01:04 - there's a bunch of different ones that
01:05 - you could buy what are the pieces that
01:06 - you need how do you get the library to
01:09 - make use of the Kinect that sort of
01:10 - stuff and you can see I have a basic
01:12 - example that's running behind me with
01:14 - the Kinect version 2 and I will talk
01:16 - through the pieces of this code so first
01:19 - let's think about the different versions
01:21 - of the Kinect so this is this one here
01:23 - Refik glasses I'm gonna this one is the
01:26 - 14 model 14 14 this one is the and I'm
01:30 - going to I'm going to come over here and
01:32 - try not to trip over to myself and I got
01:36 - to grab this eraser for a second so
01:40 - let's make a list here so the two key
01:43 - pieces of information for you or you
01:45 - need to decide are you using the Kinect
01:48 - version one or the Kinect version two
01:53 - I'm probably gonna get lots of stuff
01:55 - wrong here that you can write in the
01:57 - continent so I'll put little annotations
01:59 - on the YouTube video that fix them but
02:00 - hopefully I'll get things loosely right
02:02 - so the original Kinect version one model
02:05 - 1414 is the one that came out I think I
02:07 - was new
02:08 - number 2011-12 somewhere around there I
02:12 - remember the weekend it came out people
02:13 - people were quote-unquote hacking it but
02:15 - really just making but about hacking at
02:17 - I need making open-source drivers to to
02:19 - read the data driver being a thing that
02:22 - your computer runs to talk to the
02:23 - hardware device and so when that came
02:27 - out a library I worked on the library
02:30 - called open connect for processing and
02:34 - the reason why it's called open connect
02:38 - is because it's making use of the open
02:40 - connect an open connect an open source a
02:43 - driver for for connecting to the connect
02:46 - which is also known as a Lib free net so
02:52 - this is sort of the genesis of all of
02:55 - this the thing that I built for
02:57 - processing is just a thin layer on top
02:59 - of work that lots of lots of other
03:01 - people did which allows you to get the
03:03 - data from the connect now let's come
03:05 - back to the connect like what is it's
03:07 - over here and then I'll get to the other
03:09 - editions in a second like what is this
03:11 - thing so this is the original connect
03:13 - and you can see here that there are
03:15 - three little circles on here it's like a
03:17 - little nice little friend with three
03:19 - eyeballs and what do each of these
03:21 - eyeballs do so one of them if we a
03:25 - camera oh oh
03:26 - Schiffman you i suck at making these
03:28 - videos okay I'm just going to go anyway
03:31 - okay so this is the connect uh and it
03:35 - has three little eyeballs one of which
03:38 - is an infrared projector so this is this
03:44 - is what the 14:14 does and I'll talk a
03:46 - little bit about any a different marker
03:48 - here what happens once you get to the
03:50 - connect version to how that works
03:52 - differently it has an infrared projector
03:55 - which sends out infrared light into the
03:57 - room then it has what I would call you
04:01 - know could call it a sensor or a camera
04:02 - but it has an infrared camera to read
04:05 - the infrared light Pacific in the room
04:08 - what is infrared light it's you know
04:10 - light that's all around us but is it
04:11 - visible somebody with a physics degree
04:13 - could explain that better but this is
04:15 - blasting out infrared light this
04:17 - infrared camera is reading it so what
04:20 - what is the value of doing this so that
04:22 - interesting
04:22 - is the kind of light that it's passing
04:24 - out is actually a whole lot of infrared
04:27 - dots it's projecting a lot of infrared
04:29 - dots into the room it looks like this
04:31 - and it's a very specific pattern of dots
04:34 - and the Kinect itself it knows what that
04:37 - pattern of dots is supposed to look like
04:38 - so it's that pattern of dots if I have
04:41 - the Kinect here it's blasting infrared
04:43 - light lands on a flat surface the
04:46 - infrared camera that's reading where
04:48 - those dots landed that's seeing those
04:49 - dots reflecting back is going to see
04:52 - like oh it matches exactly the pattern
04:54 - of dots that I know that's a flat
04:56 - surface but if this surface was curved
04:58 - those dots will appear distorted by
05:00 - analyzing that distortion the Kinect can
05:03 - recognize what things are closer and
05:05 - what things are further away so the
05:08 - value of this is it is often referred to
05:11 - you can think of it as a depth camera or
05:13 - a depth sensor this is what this
05:15 - infrared projector and infrared camera
05:16 - are doing they're measuring the depth in
05:19 - of each pixel in the room so while a
05:22 - regular web camera says here's a 640 by
05:25 - 480 image each pixel has a red green and
05:27 - blue value and it's beautiful isn't it
05:30 - the colors of the rainbow or the hair in
05:32 - this image the Kinect is saying I see I
05:36 - don't see RGB what I see is I see a
05:39 - pixel and instead of telling you what
05:40 - color that pixel is I'm going to tell
05:42 - you how far is that pixel away from the
05:45 - sensor and this is incredibly valuable
05:47 - in computer vision you know one of the
05:48 - classic computer vision problems that
05:51 - people try to solve is background
05:52 - removal you know that's why I have this
05:54 - green screen okay I have to go
05:56 - underneath this here okay I have the
05:59 - obstacle course in my office I'm going
06:00 - underneath this to turn this camera back
06:02 - on and I'm coming back underneath I have
06:05 - this hello I have this I have this green
06:08 - screen here behind me you can see and so
06:10 - the camera is saying every green pixel
06:13 - remove it and put the stuff from the
06:15 - computer behind it but if I had a Kinect
06:17 - I don't have to say look for the green
06:19 - pixels behind me I can just say look for
06:21 - any pixel that's farther than two feet
06:24 - or something out of centimeters I'm
06:28 - trying to be a metric I'm trying to be
06:29 - metric I want to be a metric person but
06:31 - I'm not so you could remove you could
06:34 - you can analyze things
06:35 - makes it really easy to find a human
06:37 - being in the room because the human
06:39 - being has a certain kind of shape it
06:41 - makes it really easy to do quick and
06:42 - dirty 3d scanning there's lots and lots
06:45 - of possibilities of what you can do once
06:46 - you have access to the depth now there
06:49 - was this third little eye here and this
06:51 - by the way is just an RGB camera so one
06:55 - of the things the Kinect can also do is
06:57 - just see the colors in the room so in
07:00 - addition to having this infrared camera
07:01 - it has an RGB camera now there's a bit
07:03 - of a problem here which is that notice
07:07 - how both of these things are not in the
07:10 - same place so the infrared camera sees
07:14 - the depth of a given pixel at a
07:16 - different place that the RGB camera sees
07:18 - that color so this is an alignment
07:20 - problem a calibration problem where the
07:23 - the color pixels don't necessarily line
07:25 - up exactly with the depth pixels and
07:27 - there are lots of strategies for solving
07:30 - this problem and lots of frameworks and
07:33 - libraries in particular the official
07:35 - Microsoft SDK which has on things baked
07:38 - into it that do this for you but one of
07:40 - the nice things that we'll see once we
07:42 - get to the Kinect Veet version 2 is it
07:44 - has something called a registered image
07:46 - which is an image that aligns the depth
07:50 - pixels with the color pixels okay so
07:52 - this is what the Kinect does and I
07:55 - really described here what the Kinect
07:57 - version 1 does there was also a model
08:00 - 1473 that came out I don't know a year
08:03 - or two later um this one has some
08:05 - problems in particular there's a little
08:07 - bit of a bug with currently with running
08:09 - it with the processing library although
08:10 - it does work kind of only will work
08:12 - every other time can't figure it out for
08:14 - the life of me so but both of these will
08:17 - work with the library what you need to
08:19 - look for the library is the version 1
08:21 - examples so that's that now in between
08:25 - here there was like this Kinect for
08:27 - Windows and I think this was like a
08:30 - version of the Kinect that the Microsoft
08:31 - made to plug into like Windows computers
08:34 - originally this was designed for use
08:35 - with the Xbox for a game for games that
08:38 - you would play by you know dancing I'm
08:41 - kicking my leg by the way if you can't
08:42 - see that and but then Microsoft realized
08:47 - there's I don't know what my
08:48 - what's in Microsoft's cases but I've
08:50 - speculating here but that to make a
08:52 - version that's designed to work with
08:53 - just regular old laptops and computers
08:56 - I'm not sure if this one works with the
08:58 - processing library but more recently and
09:01 - I have this one plugged in and like
09:03 - mounted on the wall over there so I
09:04 - can't hold it up and show it to you the
09:06 - Kinect version 2 is a newer and quite
09:09 - significant upgrade from the first
09:11 - Kinect and it actually uses a completely
09:14 - different technique it uses infrared
09:17 - light but it uses a technique called
09:18 - time-of-flight so it sends the infrared
09:20 - light out measures how long it takes for
09:22 - it to bounce back and that how long that
09:25 - takes
09:25 - let's the sensor know how far away
09:27 - things are kind of like a bat maybe does
09:29 - stuff with sound to see I don't know
09:31 - yeah dolphins do stuff like that but all
09:33 - the sound so with light bouncing it back
09:35 - and forth the new Kinect does that and I
09:38 - suppose it's a bit more accurate it's
09:41 - faster and the RGB camera is also in the
09:45 - new Kinect is higher resolution okay so
09:47 - that's the basics overview and if I come
09:50 - back over here you can see now now I'm
09:53 - running an example I have the Kinect
09:54 - right over here you can't see it I could
09:56 - I could maybe like turn like kind of
09:59 - like if I hold it up over here can there
10:00 - you go there it is this is the new one
10:03 - I'm gonna put it back that felt like a
10:05 - little scary like everything was going
10:06 - to fall over and you can see now that
10:09 - what you're seeing in this particular
10:12 - image is an example of a processing
10:14 - sketch which is rendering all of the
10:17 - pieces of what the library what the
10:19 - Kinect offers now oh but I have
10:21 - something more to mention about this but
10:23 - I'll get to that in a second so up top
10:25 - you can see that's just the RGB image so
10:28 - it's like I have a webcam over here I
10:29 - have a webcam over here high webcam that
10:33 - sort of thing right so that's the webcam
10:34 - that's the RGB camera and it's actually
10:37 - I believe I didn't actually check but
10:39 - it's a pretty high resolution image down
10:42 - below this is the raw feed of what the
10:44 - infrared camera is seeing so this is
10:46 - what the infrared camera is seeing and
10:48 - it uses that to extrapolate depth so
10:50 - mostly just looks like this creepy thing
10:52 - but you can make use of that you can get
10:54 - that image as well up top at the top
10:57 - right this is what's known as the depth
10:59 - image so the what the Kinect is
11:01 - measuring
11:02 - is in millimeters it's measuring a value
11:05 - between 0 and 4500 how far is the thing
11:08 - away from the camera and then often a
11:10 - depth image is used to visualize that
11:13 - data so in this case you can see as I
11:15 - start to go further and further back I
11:17 - get brighter as I start to come closer
11:19 - and closer I get darker so it's mapping
11:21 - the the color of every pixel to how far
11:25 - away it is and you can see just from a
11:27 - standpoint now how much easier that
11:29 - might be to pick out my hand right
11:31 - because my hand is the only thing that
11:32 - has this very very dark color as opposed
11:35 - to other things now there is something
11:37 - funny in the back what's up there up oh
11:40 - that's a window I was like what about
11:42 - black square up there that's how window
11:44 - that's the door you can see in all sorts
11:46 - of things inside inside this room that
11:48 - you may not have seen before
11:49 - and then down in the bottom right this
11:51 - is the registered image so this is not
11:54 - part of you use the version one connect
11:58 - with the open connected library this is
12:00 - not part of that however it with version
12:03 - 2 this is the image that aligns all of
12:06 - the RGB values from the webcam with the
12:09 - depth value so if you wanted to
12:11 - hopefully it's something I might be able
12:12 - to demonstrate it in some video is just
12:14 - do background removal where you see only
12:15 - me and I take I get rid of all the
12:17 - pixels that are behind me um that might
12:20 - be something that I could do here with
12:21 - that particular image oh did the oh the
12:23 - laptop went to sleep come back wake up
12:25 - okay so a couple more things so what I
12:30 - want to show you now is how do you get
12:31 - this library to run this like this
12:33 - particular example so a couple things
12:35 - one is here's the I put all this in the
12:38 - description of the video this is the URL
12:39 - the the library is at github.com slash
12:43 - Schiffman open connect for processing
12:45 - you don't need to go to that URL but
12:46 - that's where the source code is there's
12:48 - a little bit of documentation there I
12:50 - want to make give a big THANK YOU to
12:52 - Tomas Sanchez lending I might not have
12:55 - pronounced his last name correctly he
12:57 - wrote all the code for making this
12:58 - library work with the connect version
13:00 - two so I worked on to the version one
13:02 - number of years ago and sort of
13:04 - floundered and Thomas came back and
13:05 - revived this and really helped over the
13:07 - summer and there is also I have a little
13:10 - page that has some additional
13:12 - documentation it's Schiffman dotnet
13:14 - slash P 5
13:15 - / connect and you know this is some text
13:18 - that kind of goes through the different
13:20 - versions and some of these examples as
13:22 - well that I'm going to cover in the
13:24 - videos now in order to get the actual
13:26 - library itself what you need to do is go
13:29 - to one first you need to download
13:31 - processing if you don't have that
13:32 - already that's at processing org then
13:35 - what you'll need to do is once you have
13:36 - processing it might look just like this
13:39 - to you something empty you're going to
13:41 - go to sketch import library add library
13:45 - now you can see that I have already
13:46 - knife three libraries here I already
13:48 - have that library but I'm going to
13:50 - pretend that I don't for a second I'm
13:51 - going to go to add library which opens
13:53 - up this contributions manager I can type
13:56 - in connect right here and this is
13:57 - something really quite important now to
13:59 - bring up so there are several different
14:03 - libraries there is by the way something
14:05 - called simple open and I which is an
14:07 - older library open and I was an open
14:09 - source platform open source framework
14:11 - for doing skeleton tracking meaning
14:14 - finding of human form where the hands
14:16 - are where the head is which is very very
14:18 - powerful and things that you can do with
14:19 - the Kinect I'm starting with just the
14:21 - raw depth data but open and I think was
14:24 - purchased by Apple have been kind of
14:25 - like shut down as an open thing but
14:27 - there are some efforts to revive it and
14:29 - so you could Google around and that's
14:31 - something that you could possibly use
14:32 - I'll try to include some links but you
14:33 - can see that it's currently this simple
14:35 - open eye it's no longer compatible with
14:37 - processing 3 that's why it's grayed out
14:39 - Connect v2 for processing this is a
14:42 - library that makes use of the Microsoft
14:44 - official SDK and I'm going to
14:46 - demonstrate that using a PC in a later
14:48 - video this is a key this is a really
14:53 - great thing to use if you want to get
14:55 - all of the magic that Microsoft has
14:57 - spent all this time developing so what
15:00 - the Kinect just gives you is raw depth
15:02 - theta raw RGB data but what the
15:04 - Microsoft SDK does is it pulls that data
15:07 - in and on and it analyzes it and finds
15:10 - where's the human being like what kind
15:11 - of muscle are they making like where's
15:13 - their head like is their hand open or
15:16 - closed and it's so much through a layer
15:18 - of analysis on the raw def data that
15:20 - will give you a ton of information so
15:22 - but for that you do need to use a
15:24 - Windows machine
15:24 - of course there are some strategies for
15:25 - like sending the data from windows
15:27 - chained to another machine to like a
15:28 - WebSocket what's a WebSocket all sorts
15:31 - of stuff but we'll come to that in a
15:33 - later video and so those would be the
15:36 - two libraries that but the library I'm
15:38 - using today which you know is already
15:40 - installed you can see by the green
15:41 - checkmark you would just need to click
15:43 - it and click this install button and it
15:46 - would download and install that this is
15:49 - the library I'm using today it uses open
15:51 - source drivers it only looks at the raw
15:54 - depth data so this is good for a bunch
15:56 - of different kind of creative
15:57 - applications that I hope to show you in
15:59 - the next set of videos so this was a
16:02 - long rambling 16 minute explanation
16:04 - about the connect that you may or may
16:06 - not have found useful or interesting but
16:08 - I imagine you've already turned it off
16:10 - if you didn't and in the next video what
16:12 - I will demonstrate is is just how to
16:14 - write a program that gets that depth
16:16 - image and once it I mean bring that back
16:19 - oh it's not running here get gets that
16:21 - depth image and maybe visualizes that
16:23 - depth image in some way so that's where
16:25 - we'll start I'm going to look at a
16:26 - couple other scenarios along the way as
16:27 - well okay and so thanks for being here
16:30 - and watching and talk to you soon

Cleaned transcript:

hello this is the first video in a series of videos I'm making about the Microsoft Kinect this thing so what is this thing how does it work and how do you write your own software that makes use of this thing how can you do all sorts of creative coding projects now there's a lot of different programming languages environments and frameworks and libraries for how you might make use the Kinect I'm going to use this thing called processing processing 3 the third edition version of processing which is a Java based programming environment open source environment that there is a connect several different connect libraries for eventually I will hope to make a video where I look at p5.js which is a JavaScript framework for doing creative coding in the browser and how might you get the stuff from the Kinect what is this thing called the Kinect in the browser itself which I think will be an exciting thing to see as well but in this first video what I want to do when I get into the code really in the next video and what I want to do in this video is give you an overview so what are the different editions of the Kinect there's a bunch of different ones that you could buy what are the pieces that you need how do you get the library to make use of the Kinect that sort of stuff and you can see I have a basic example that's running behind me with the Kinect version 2 and I will talk through the pieces of this code so first let's think about the different versions of the Kinect so this is this one here Refik glasses I'm gonna this one is the 14 model 14 14 this one is the and I'm going to I'm going to come over here and try not to trip over to myself and I got to grab this eraser for a second so let's make a list here so the two key pieces of information for you or you need to decide are you using the Kinect version one or the Kinect version two I'm probably gonna get lots of stuff wrong here that you can write in the continent so I'll put little annotations on the YouTube video that fix them but hopefully I'll get things loosely right so the original Kinect version one model 1414 is the one that came out I think I was new number 201112 somewhere around there I remember the weekend it came out people people were quoteunquote hacking it but really just making but about hacking at I need making opensource drivers to to read the data driver being a thing that your computer runs to talk to the hardware device and so when that came out a library I worked on the library called open connect for processing and the reason why it's called open connect is because it's making use of the open connect an open connect an open source a driver for for connecting to the connect which is also known as a Lib free net so this is sort of the genesis of all of this the thing that I built for processing is just a thin layer on top of work that lots of lots of other people did which allows you to get the data from the connect now let's come back to the connect like what is it's over here and then I'll get to the other editions in a second like what is this thing so this is the original connect and you can see here that there are three little circles on here it's like a little nice little friend with three eyeballs and what do each of these eyeballs do so one of them if we a camera oh oh Schiffman you i suck at making these videos okay I'm just going to go anyway okay so this is the connect uh and it has three little eyeballs one of which is an infrared projector so this is this is what the 1414 does and I'll talk a little bit about any a different marker here what happens once you get to the connect version to how that works differently it has an infrared projector which sends out infrared light into the room then it has what I would call you know could call it a sensor or a camera but it has an infrared camera to read the infrared light Pacific in the room what is infrared light it's you know light that's all around us but is it visible somebody with a physics degree could explain that better but this is blasting out infrared light this infrared camera is reading it so what what is the value of doing this so that interesting is the kind of light that it's passing out is actually a whole lot of infrared dots it's projecting a lot of infrared dots into the room it looks like this and it's a very specific pattern of dots and the Kinect itself it knows what that pattern of dots is supposed to look like so it's that pattern of dots if I have the Kinect here it's blasting infrared light lands on a flat surface the infrared camera that's reading where those dots landed that's seeing those dots reflecting back is going to see like oh it matches exactly the pattern of dots that I know that's a flat surface but if this surface was curved those dots will appear distorted by analyzing that distortion the Kinect can recognize what things are closer and what things are further away so the value of this is it is often referred to you can think of it as a depth camera or a depth sensor this is what this infrared projector and infrared camera are doing they're measuring the depth in of each pixel in the room so while a regular web camera says here's a 640 by 480 image each pixel has a red green and blue value and it's beautiful isn't it the colors of the rainbow or the hair in this image the Kinect is saying I see I don't see RGB what I see is I see a pixel and instead of telling you what color that pixel is I'm going to tell you how far is that pixel away from the sensor and this is incredibly valuable in computer vision you know one of the classic computer vision problems that people try to solve is background removal you know that's why I have this green screen okay I have to go underneath this here okay I have the obstacle course in my office I'm going underneath this to turn this camera back on and I'm coming back underneath I have this hello I have this I have this green screen here behind me you can see and so the camera is saying every green pixel remove it and put the stuff from the computer behind it but if I had a Kinect I don't have to say look for the green pixels behind me I can just say look for any pixel that's farther than two feet or something out of centimeters I'm trying to be a metric I'm trying to be metric I want to be a metric person but I'm not so you could remove you could you can analyze things makes it really easy to find a human being in the room because the human being has a certain kind of shape it makes it really easy to do quick and dirty 3d scanning there's lots and lots of possibilities of what you can do once you have access to the depth now there was this third little eye here and this by the way is just an RGB camera so one of the things the Kinect can also do is just see the colors in the room so in addition to having this infrared camera it has an RGB camera now there's a bit of a problem here which is that notice how both of these things are not in the same place so the infrared camera sees the depth of a given pixel at a different place that the RGB camera sees that color so this is an alignment problem a calibration problem where the the color pixels don't necessarily line up exactly with the depth pixels and there are lots of strategies for solving this problem and lots of frameworks and libraries in particular the official Microsoft SDK which has on things baked into it that do this for you but one of the nice things that we'll see once we get to the Kinect Veet version 2 is it has something called a registered image which is an image that aligns the depth pixels with the color pixels okay so this is what the Kinect does and I really described here what the Kinect version 1 does there was also a model 1473 that came out I don't know a year or two later um this one has some problems in particular there's a little bit of a bug with currently with running it with the processing library although it does work kind of only will work every other time can't figure it out for the life of me so but both of these will work with the library what you need to look for the library is the version 1 examples so that's that now in between here there was like this Kinect for Windows and I think this was like a version of the Kinect that the Microsoft made to plug into like Windows computers originally this was designed for use with the Xbox for a game for games that you would play by you know dancing I'm kicking my leg by the way if you can't see that and but then Microsoft realized there's I don't know what my what's in Microsoft's cases but I've speculating here but that to make a version that's designed to work with just regular old laptops and computers I'm not sure if this one works with the processing library but more recently and I have this one plugged in and like mounted on the wall over there so I can't hold it up and show it to you the Kinect version 2 is a newer and quite significant upgrade from the first Kinect and it actually uses a completely different technique it uses infrared light but it uses a technique called timeofflight so it sends the infrared light out measures how long it takes for it to bounce back and that how long that takes let's the sensor know how far away things are kind of like a bat maybe does stuff with sound to see I don't know yeah dolphins do stuff like that but all the sound so with light bouncing it back and forth the new Kinect does that and I suppose it's a bit more accurate it's faster and the RGB camera is also in the new Kinect is higher resolution okay so that's the basics overview and if I come back over here you can see now now I'm running an example I have the Kinect right over here you can't see it I could I could maybe like turn like kind of like if I hold it up over here can there you go there it is this is the new one I'm gonna put it back that felt like a little scary like everything was going to fall over and you can see now that what you're seeing in this particular image is an example of a processing sketch which is rendering all of the pieces of what the library what the Kinect offers now oh but I have something more to mention about this but I'll get to that in a second so up top you can see that's just the RGB image so it's like I have a webcam over here I have a webcam over here high webcam that sort of thing right so that's the webcam that's the RGB camera and it's actually I believe I didn't actually check but it's a pretty high resolution image down below this is the raw feed of what the infrared camera is seeing so this is what the infrared camera is seeing and it uses that to extrapolate depth so mostly just looks like this creepy thing but you can make use of that you can get that image as well up top at the top right this is what's known as the depth image so the what the Kinect is measuring is in millimeters it's measuring a value between 0 and 4500 how far is the thing away from the camera and then often a depth image is used to visualize that data so in this case you can see as I start to go further and further back I get brighter as I start to come closer and closer I get darker so it's mapping the the color of every pixel to how far away it is and you can see just from a standpoint now how much easier that might be to pick out my hand right because my hand is the only thing that has this very very dark color as opposed to other things now there is something funny in the back what's up there up oh that's a window I was like what about black square up there that's how window that's the door you can see in all sorts of things inside inside this room that you may not have seen before and then down in the bottom right this is the registered image so this is not part of you use the version one connect with the open connected library this is not part of that however it with version 2 this is the image that aligns all of the RGB values from the webcam with the depth value so if you wanted to hopefully it's something I might be able to demonstrate it in some video is just do background removal where you see only me and I take I get rid of all the pixels that are behind me um that might be something that I could do here with that particular image oh did the oh the laptop went to sleep come back wake up okay so a couple more things so what I want to show you now is how do you get this library to run this like this particular example so a couple things one is here's the I put all this in the description of the video this is the URL the the library is at github.com slash Schiffman open connect for processing you don't need to go to that URL but that's where the source code is there's a little bit of documentation there I want to make give a big THANK YOU to Tomas Sanchez lending I might not have pronounced his last name correctly he wrote all the code for making this library work with the connect version two so I worked on to the version one number of years ago and sort of floundered and Thomas came back and revived this and really helped over the summer and there is also I have a little page that has some additional documentation it's Schiffman dotnet slash P 5 / connect and you know this is some text that kind of goes through the different versions and some of these examples as well that I'm going to cover in the videos now in order to get the actual library itself what you need to do is go to one first you need to download processing if you don't have that already that's at processing org then what you'll need to do is once you have processing it might look just like this to you something empty you're going to go to sketch import library add library now you can see that I have already knife three libraries here I already have that library but I'm going to pretend that I don't for a second I'm going to go to add library which opens up this contributions manager I can type in connect right here and this is something really quite important now to bring up so there are several different libraries there is by the way something called simple open and I which is an older library open and I was an open source platform open source framework for doing skeleton tracking meaning finding of human form where the hands are where the head is which is very very powerful and things that you can do with the Kinect I'm starting with just the raw depth data but open and I think was purchased by Apple have been kind of like shut down as an open thing but there are some efforts to revive it and so you could Google around and that's something that you could possibly use I'll try to include some links but you can see that it's currently this simple open eye it's no longer compatible with processing 3 that's why it's grayed out Connect v2 for processing this is a library that makes use of the Microsoft official SDK and I'm going to demonstrate that using a PC in a later video this is a key this is a really great thing to use if you want to get all of the magic that Microsoft has spent all this time developing so what the Kinect just gives you is raw depth theta raw RGB data but what the Microsoft SDK does is it pulls that data in and on and it analyzes it and finds where's the human being like what kind of muscle are they making like where's their head like is their hand open or closed and it's so much through a layer of analysis on the raw def data that will give you a ton of information so but for that you do need to use a Windows machine of course there are some strategies for like sending the data from windows chained to another machine to like a WebSocket what's a WebSocket all sorts of stuff but we'll come to that in a later video and so those would be the two libraries that but the library I'm using today which you know is already installed you can see by the green checkmark you would just need to click it and click this install button and it would download and install that this is the library I'm using today it uses open source drivers it only looks at the raw depth data so this is good for a bunch of different kind of creative applications that I hope to show you in the next set of videos so this was a long rambling 16 minute explanation about the connect that you may or may not have found useful or interesting but I imagine you've already turned it off if you didn't and in the next video what I will demonstrate is is just how to write a program that gets that depth image and once it I mean bring that back oh it's not running here get gets that depth image and maybe visualizes that depth image in some way so that's where we'll start I'm going to look at a couple other scenarios along the way as well okay and so thanks for being here and watching and talk to you soon
