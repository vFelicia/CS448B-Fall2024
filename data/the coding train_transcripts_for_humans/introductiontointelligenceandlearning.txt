With timestamps:

00:00 - hello welcome to the first video in a
00:05 - new course on a series set of videos
00:09 - that I am here me dan Shipman presenting
00:14 - to you on my youtube channel decoding
00:16 - dreams okay so what is it you might be
00:19 - aware remember me from such videos as
00:22 - the nature of code I have a playlist of
00:26 - videos most these videos were recorded
00:27 - probably several years ago and they
00:30 - cover I'm going to zoom in here all of
00:34 - these topics one through eight and I
00:37 - have a book which covers all these
00:39 - topics one through eight and I've been
00:41 - teaching a class at about this stuff for
00:45 - a bunch of years many years almost like
00:47 - seven or eight years in fact and so this
00:49 - year I am trying something new with this
00:52 - course and therefore also on the few
00:54 - Tube channel now what is this new things
00:55 - on try what always happens when I teach
00:58 - this course is if it's a full semester
01:00 - course that I like kind of universally
01:02 - like plates there are here in my class
01:05 - over here there are these ten tops so
01:07 - you can't see the bottom let's see I'm
01:10 - not zoomed properly okay there we go
01:12 - there are these ten topics and what
01:14 - happens is you know this here the first
01:17 - half of it is really about physics
01:20 - simulation animation moving things on
01:22 - the screen and all the kind of stuff you
01:25 - could do with that and by the time we
01:28 - get to this people are on their way and
01:30 - they've been overloaded they're trying
01:31 - to learn all this stuff that what's here
01:34 - in nine and ten chapters nine and ten
01:36 - gets lost so what I'm doing this year is
01:40 - and starting right now is I would like
01:42 - to take what's in this book here nine
01:46 - and ten chapters 9 and 10 and expand the
01:49 - material out which is something that
01:51 - would be several you know many sessions
01:54 - about seven five or six or seven or
01:56 - eight I have no idea some amount of
01:58 - sessions of content where I take a
02:00 - closer look at topics related to and
02:03 - here's the title of this course
02:04 - intelligence and learning I'm going to
02:07 - come over here and I'm going to write
02:09 - that down this is like what people who
02:10 - are teachers I've been watching some
02:12 - like
02:12 - OpenCourseWare you have a big chalkboard
02:16 - and then you just like make a point and
02:17 - you write it down so I'm going to do
02:18 - that intelligent and learning now I am
02:26 - specific first of all well as I'm
02:28 - specifically not calling this a course
02:31 - like artificial intelligence nor am i
02:36 - calling this a course like introduction
02:41 - to machine learning nor am i saying it's
02:46 - a course called say introduction to deep
02:49 - learning so what's one reason why I'm
02:53 - not calling it that well first of all
02:54 - I'm afraid of all these things so I feel
02:56 - like if I call it this is a course on
02:58 - artificial intelligence or machine
02:59 - learning that's a little bit scary to me
03:02 - so the other reason why I want to call
03:03 - it intelligence and learning is I want
03:05 - to take the broadest approach possible
03:06 - so you watching this course whether if
03:09 - you implement the latest and greatest
03:11 - perfect machine learning neural network
03:13 - convolutional recurrent magical system
03:15 - thing that does something you read about
03:17 - in some academic paper or you make some
03:19 - crazy projects where it seems like the
03:21 - computer is playing this goofy game with
03:23 - you in it and how could it possibly be
03:24 - doing that so there's a lot of space in
03:27 - between and for me I want to just really
03:28 - take a broad approach to this not just
03:31 - look at only you know neural networks
03:33 - and machine learning and not just look
03:35 - at only these topics in artificial
03:36 - intelligence and okay so first of all
03:38 - listen I'm kind of blending all these
03:40 - terms let's try to at least define them
03:42 - so let's I saw the chart in the book
03:47 - somewhere I'm going to recreate it so
03:49 - artificial intelligence of the topic
03:51 - those the white has artificial
03:53 - intelligence well I actually just
03:54 - recently watched a lecture by professor
03:58 - at MIT Patrick Langston Patrick Winston
04:00 - I think it says that the opening of the
04:02 - lecture models so it'll correct me if
04:05 - I'm wrong for thinking perception and
04:11 - action so this is a very broad term so
04:18 - let's think about this for a second let
04:19 - me go back to some of my other examples
04:21 - to come over here and I'm going to open
04:24 - it where if we were
04:26 - falling along with the third piece if we
04:28 - stop here at week six or session six or
04:30 - chapter six for everyone to call it and
04:32 - I ran this flocking simulation I could
04:38 - ask the question is this artificial
04:41 - intelligence we nobody can answer the
04:46 - question I want to hear from you so I
04:49 - want to asking this question like but
04:52 - what's interesting whether or not you
04:53 - want to say yes or no I'm going to go
04:56 - back to here for a second
04:57 - models for thinking perception and
04:59 - action so one thing if you remember if
05:02 - you look at steering behaviors and
05:04 - steering behaviors pioneered by Craig
05:05 - Reynolds what is it a action steering
05:16 - locomotion so I've really been focusing
05:21 - on steering how do you calculate a
05:24 - steering force how do you do the physics
05:25 - for that and how do you actually make
05:26 - that triangle move for one pixel to
05:28 - another and steering and locomotion kind
05:32 - of cover all those pieces actions this
05:36 - is a place where well what is the action
05:38 - what are the goals and the flocking
05:39 - system the goals are stay with your
05:42 - neighbors but don't crash into your
05:43 - neighbors and also states in proximity
05:46 - your neighbors also move in the same
05:47 - direction as your neighbors but don't
05:48 - crash into your neighbors and other kind
05:50 - of action things you might selectively
05:52 - follow this thing or chase this thing or
05:55 - run away from this thing or try to get
05:57 - through this doorway the fastest as you
05:58 - can so what's interesting here is seeing
06:01 - this link is what our models for
06:04 - thinking in perception that might lead
06:06 - to action to govern the types of
06:07 - animated systems that you might create
06:09 - so this to me is the link here whether
06:12 - it's enough to say I am going to kind of
06:14 - define the rules of almost doing a zone
06:17 - like a rule-based system feature
06:19 - engineering so to speak like I don't
06:21 - need a learning-based system I'm going
06:23 - to define the rules of how all these
06:24 - things should behave but they're going
06:26 - to appear intelligence versus something
06:28 - like a learning system which has to
06:29 - learn over time so machine learning
06:31 - being something that crosses over with
06:35 - artificial intelligence you know I think
06:37 - of machine learning
06:39 - something that you have data and you
06:42 - make meaning from that data so how do
06:45 - you how do you and the you know -
06:48 - there's more to it than this but you
06:50 - know one of the most classic
06:51 - applications of a machine learning
06:53 - system is classifying data
06:56 - classification so here's a bunch of
06:59 - pictures which ones are cats and which
07:02 - ones are dogs and there's more you know
07:04 - the other type of system that you
07:06 - classic application machine learning is
07:09 - regression which instead of categorizing
07:12 - into a discrete set of labels you know
07:15 - cats or dogs you might say you know
07:17 - here's all of these you want to arrive
07:21 - at a more continuous result so here's
07:23 - all these properties of a house how many
07:24 - bedrooms where's it located how many
07:26 - bathrooms and kendama can the system
07:30 - take that data and determine predictive
07:32 - price so these are two classic tasks and
07:36 - machine learning now what's in the news
07:39 - and what's all the rage what's everybody
07:42 - working with these days our neural
07:45 - networks so you know a popular and
07:48 - powerful and exciting so much new
07:50 - research in this right now recently of
07:52 - creating machine learning systems to do
07:54 - these tasks with neural networks however
07:56 - in this course I want to look at other
07:59 - systems that do the same thing that are
08:01 - simpler that might not be as powerful
08:04 - but might have opportunities for
08:05 - creative possibilities but also if you
08:07 - can use the simpler system for the same
08:09 - result it's going to make it a little
08:11 - easier to perhaps dive into what my mind
08:14 - might be the most difficult
08:15 - I like cancel this part actually last
08:18 - time I mentioned machine learning a fire
08:19 - alarm went off which saved me nothing
08:21 - happened this time but so so we'll see
08:25 - so now so these are inner areas where I
08:29 - want to just look at and cover in this
08:31 - course now what's this thing down here
08:34 - under DL this is deep learning and you
08:36 - know what I'm going to put deep learning
08:37 - in here so as I just mentioned a one
08:43 - technique for performing these machine
08:45 - learning tasks is using something called
08:48 - an artificial neural network so in the
08:51 - case of an
08:52 - artificial neural network that data that
08:56 - you're trying to classify enters as
09:01 - input to something called a neuron and
09:07 - then passes through a network of neurons
09:11 - to have some sort of output and I
09:15 - spelled that wrong
09:16 - close enough CatDog price of a price of
09:19 - a house that sort of thing now an
09:23 - artificial neural network is a system
09:25 - and I'm going to get more into this in
09:26 - another video just specifically just
09:27 - about this so I kind of want to just
09:28 - actually kind of move ahead and skip
09:30 - over this but the reason why I was
09:32 - mentioning this is there's a point if
09:34 - there's a long history of this and the
09:36 - very first discovery of an artificial
09:38 - neural network I'm going to build one of
09:40 - these in a future current Cody Jones
09:41 - it's called a perceptron which is a
09:43 - nervous is a Welliver on called a
09:46 - network because it's a single neuron so
09:48 - a model for a single neuron an
09:50 - artificial neural network being a model
09:52 - for many interconnected neurons maybe
09:54 - it's a fully connected Network and B
09:56 - it's like a partially connected network
09:58 - but the reason why so much rip that
10:02 - there has been a revolution in research
10:05 - and application neural networks when
10:08 - they were first discovered this idea of
10:10 - a perceptron couldn't solve very simple
10:12 - problems so there's a famous paper the
10:14 - perceptron paper McCullough Pitts
10:17 - I believe I'm getting that right
10:18 - probably the chat will confirm I'll try
10:21 - to link to that information in this
10:22 - video's description and there were
10:24 - various steps along the way but there
10:26 - was a long time before anyone was really
10:28 - able to do a lot of work with neural
10:31 - networks and so deep learning refers to
10:34 - the idea of a neural network which has a
10:38 - lot of depth to it so in between the
10:40 - inputs and the output output and these
10:43 - could be both be plural or singular
10:45 - there are many many many layers it is
10:48 - deep very deep so you know you could
10:53 - imagine all of these connections and so
10:56 - the idea here and you know the training
10:58 - systems and how it works now the
10:59 - learning system huh we got to get into
11:01 - all that but that's not for this video
11:02 - right here I got all the help of this
11:04 - tangent
11:05 - about neural networks so this is these
11:08 - are the different aspects of the pieces
11:10 - of this course that I would like to look
11:11 - at now let me come back over here okay
11:15 - so let me take a look at the list of
11:17 - topics I'm going to skip week one for a
11:19 - second so this is the course if you want
11:21 - this URL will be in the video's
11:23 - description this is the the syllabus for
11:27 - the course it's kind of my working
11:29 - document boy do I accept any and all
11:31 - contributions and help so feel free to
11:34 - file github issues and pull requests and
11:37 - things and if I come down here to the oh
11:40 - and I'm kind of in a place where you
11:41 - can't really see it I'm going to skip
11:43 - them a skip over week one and so here
11:45 - are my topics so I'm going to go through
11:47 - these kind of quickly again this is very
11:49 - survey oriented and boy and I'm missing
11:51 - a ton of stuff you know so this is just
11:54 - a selection but it's also still figuring
11:55 - this out so next week I'm going to talk
11:58 - about genetic algorithms which is an
12:00 - evolutionary based approach to solving
12:03 - problems with which is a way of solving
12:04 - problems in software taking inspiration
12:06 - from evolutionary processes in nature so
12:09 - I already have a bunch of videos on that
12:11 - and I'll do some more content about that
12:12 - as well and that will be in next week
12:14 - this should say classification and
12:16 - regression and recently I learned that
12:20 - the term regression comes from
12:21 - regression to the mean and this is like
12:23 - a 19th century concept but anyway I'll
12:26 - talk about where I'm getting all my I
12:27 - just read a bunch of books last week I
12:29 - have to thank all these people that I'm
12:31 - you're probably messing up all the stuff
12:33 - that I read but I want to get interested
12:37 - in those I want to get started with
12:38 - those tasks without using neural network
12:41 - based models so something called K
12:43 - nearest neighbor one of the things I
12:45 - would like to do is build a simple movie
12:47 - recommendation system with K nearest
12:49 - neighbors an idea if you have an idea
12:50 - for a data set or an interesting
12:52 - creative application for K nearest
12:53 - neighbor that's very simple with a
12:55 - simple data set that I can work with
12:56 - we love that suggestion and also linear
12:59 - regression so I want to do I want to do
13:02 - an example of the simplest form of
13:04 - regression and we can think of that in
13:07 - too with an input and
13:10 - having an output that's a continuous
13:12 - floating-point value so I want to look
13:14 - at that and we'll do that we're going to
13:16 - get all this stuff like oh there's a
13:17 - learning rate what's this gradient
13:19 - descent thing and all this stuff so
13:22 - hopefully kind of defining some of those
13:23 - terminology and understanding those
13:25 - pieces as we look at K X K nearest
13:27 - neighbor and linear regression will will
13:30 - give us a leg up for the next week when
13:32 - we look at neural networks so I would
13:35 - like to build some simple neural network
13:38 - examples from scratch and when I all of
13:41 - this stuff I'm going to do so far
13:42 - probably in processing or JavaScript
13:44 - using the p5.js library some combination
13:46 - of those things so if we want to build a
13:48 - perceptron you know if I'm feeling
13:50 - ambitious we might look at what happens
13:51 - if instead of a perceptron we have a
13:53 - multi-layered network and in all of this
13:56 - you can think of the neural network is
13:57 - like you're tuning all of these knobs so
13:59 - that the output gives you something
14:01 - that's correct you know you there's a
14:03 - whole training process that we're going
14:05 - to have to discuss called supervised
14:06 - learning supervised learning
14:08 - unsupervised learning reinforcement
14:09 - learning interesting topics that I'm
14:12 - going to get into but with one of the
14:15 - most complex aspects of neural networks
14:18 - is what do you do how do you train all
14:22 - that stuff that's in the middle and so
14:23 - there's a concept known as back back
14:25 - propagation that I that's like almost
14:29 - almost like quaternions for me but I'm
14:30 - not running out of the room just yet and
14:33 - once I get to there I want to
14:34 - investigate some other platform so I
14:37 - might if I always I like but my plan and
14:41 - hope is to look a bit at it once we've
14:44 - built some simple examples from scratch
14:46 - to look at other tools for some more
14:49 - sophisticated applications like tensor
14:51 - flow and then be able to get into
14:54 - certain specific kinds of neural
14:56 - networks that could do different kinds
14:58 - of tasks what is a convolution network
15:00 - what is a recurrent Network and what is
15:02 - reinforcement learning so those are some
15:05 - aspects of things then you know I don't
15:07 - plan on building those larger more
15:10 - sophisticated systems from scratch but
15:12 - if we can build some basic ones
15:13 - understand how everything works then my
15:15 - thinking is then we all have a leg up to
15:17 - using frameworks and tools to do some of
15:20 - the other stuff again all this is
15:22 - subject to change one of the
15:23 - things I mentioned this last week that
15:24 - I'm hoping to do because even though I
15:26 - might move to something like tensorflow
15:28 - and Python to demonstrate some examples
15:31 - in some of these other areas I would
15:33 - love to work on a simple web server that
15:35 - runs tensorflow in the background that
15:37 - processing or p5 could talk to there are
15:40 - also examples of some of these written
15:41 - in JavaScript well-known examples by
15:44 - Andrey Carpathia the recurrent RNN Jas
15:47 - and Condon s cons cons vinet and redress
15:50 - SJS so people are totally time's up I
15:54 - told people end up doing it live but you
15:56 - might be watching this an archive that I
15:57 - wanted to keep this in 20 minutes ok so
15:59 - that's my introduction you know here's
16:02 - the thing I'm learning this done so if
16:05 - you're going to watch of course from
16:07 - somebody who really knows this stuff I
16:08 - will link to lots of resources and
16:10 - that's what I meant to what I wanted to
16:12 - I wanted to mention some resources that
16:15 - I'm using very important that I will
16:16 - include in this video's description
16:18 - and I think here under the wiki under
16:21 - related projects and resources here are
16:25 - here are some resources that I want to
16:27 - specifically mention so one is the
16:29 - website called machine learning for
16:31 - artists it's got videos a video tutorial
16:35 - video lectures examples written
16:37 - descriptions lots of wonderful thing by
16:39 - artist and researcher named Jean Cogan
16:41 - absolute expert wonderful in this field
16:43 - I watched a lot of Rebecca feed drinks
16:45 - machine learning for musicians and
16:47 - artists videos Rebecca fie brink has
16:49 - made something absolutely wonderful
16:50 - called weka nadir which is a tool that
16:52 - allows you to send data itself machine
16:54 - learning stuff and it sends it back out
16:55 - all with something called OSD open sound
16:57 - control I would love to do some video
16:59 - tutorials on that or have some guest
17:01 - tutorials from Rebecca C brink on
17:03 - there's also a cadenza course on a
17:06 - creative applications with tensor flow
17:08 - that I tend to look at and get some
17:10 - resources from I also want to mention
17:13 - the let's see what else ah Andrew
17:17 - Gloucester is writing a book about
17:19 - machine learning and deep learning and
17:21 - it's not out yet but he was generous
17:23 - enough to let me look at some preview
17:24 - drafts so thank you very much follow at
17:27 - Andrews laughter on Twitter if you want
17:30 - to find out about his upcoming book
17:32 - coming out it's been really helpful to
17:34 - read and I'm sure there are also
17:39 - grokking deep learning is a book from
17:41 - Manning and rocking algorithms these are
17:43 - books that I've mentioned that I have
17:44 - kind of been looking as well as a make
17:46 - your own neural network which is a book
17:48 - that walks you through programming your
17:49 - own neural network in Python people in
17:51 - the chat are giving me lots of
17:53 - suggestions for other deep learning and
17:56 - machine learning and AI books I don't
17:58 - have my props I have the old textbooks
18:01 - bring those another time on artificial
18:03 - intelligence that are great but the
18:05 - other thing I would recommend is these
18:08 - are three compilations of resources so
18:11 - this is one that's put together by this
18:13 - community this is an awesome machine
18:15 - learning there's a lot of awesome blank
18:17 - lists that are put together let me let
18:20 - me see who puts this together just
18:21 - because I forgot from Joseph Smith CT on
18:25 - github and also this is a list of
18:29 - resources from memo Hawkins okay so
18:31 - please I'm accepting all suggestions and
18:35 - help and examples and ideas I look
18:37 - forward to all of these hopefully not so
18:40 - angry letters I will receive as I screw
18:42 - everything up
18:43 - over the next six or seven weeks we're
18:44 - gonna you know I have I guess what I
18:47 - didn't really say is I have you know to
18:49 - wrap up here what I have is these two
18:52 - chapters in nature code which deal with
18:54 - genetic algorithms and the basics of
18:56 - neural networks that's where I kind of
18:57 - left my knowledge behind and I'm
18:59 - embarking on this journey here YouTube
19:01 - to try to expand past what's in there
19:04 - and we will see how it goes so thanks
19:06 - for joining me and I look forward to
19:08 - seeing you in some future videos oh I'm
19:10 - back I do this a lot I'm back because I
19:13 - forgot that I had this page of notes and
19:15 - said I just rambled and you know it's
19:17 - got a few more links about thinking
19:19 - about the definition of artificial
19:20 - intelligence and machine learning I'm
19:21 - still working on stuff you'll find this
19:23 - also linked but you know something
19:24 - really important here that I wanted to
19:26 - just mention was you know it's it's very
19:30 - important when studying and I'm really
19:32 - gets going to be looking at the
19:33 - algorithms and making stuff and trying
19:35 - to be creative and wackadoodle in my way
19:37 - through this if that's a verb but it is
19:40 - really important for you the world of
19:42 - people who are going to be using these
19:43 - tools using these algorithms make
19:46 - project working for companies to be
19:47 - critical and think about what you're
19:49 - doing whether it's a good idea and is it
19:51 - hurting anybody is it helping anybody
19:53 - and so there's some you know some one
19:57 - thing I'll just mention here is there's
19:59 - an organization called AI now which has
20:01 - just learned about recently I thought I
20:03 - just clicked on them yep over here which
20:05 - is a initiative to research the social
20:07 - impacts of artificial intelligence to
20:09 - ensure a more equitable future so I
20:11 - encourage you to check out there's going
20:13 - to be a symposium in July checked about
20:15 - about this I also just love this quote
20:17 - from hard Maru on Twitter which is makes
20:23 - a david ha from google makes a lot of
20:24 - wonderful i recurrent neural there's a
20:26 - wonderful recurrent neural network can
20:28 - writing with p5.js example that you
20:33 - could find i'll try to link to that as
20:34 - well but you know whatever happened to
20:37 - making the world a better place so you
20:39 - know when you talk about what is your
20:40 - goal with building an AI systems with
20:43 - using machine learning why are you doing
20:46 - it and so i'll leave you with that are
20:47 - you making the world a better place
20:49 - i hope that you are and come along i'll
20:52 - see you in the next video
20:58 - [Music]

Cleaned transcript:

hello welcome to the first video in a new course on a series set of videos that I am here me dan Shipman presenting to you on my youtube channel decoding dreams okay so what is it you might be aware remember me from such videos as the nature of code I have a playlist of videos most these videos were recorded probably several years ago and they cover I'm going to zoom in here all of these topics one through eight and I have a book which covers all these topics one through eight and I've been teaching a class at about this stuff for a bunch of years many years almost like seven or eight years in fact and so this year I am trying something new with this course and therefore also on the few Tube channel now what is this new things on try what always happens when I teach this course is if it's a full semester course that I like kind of universally like plates there are here in my class over here there are these ten tops so you can't see the bottom let's see I'm not zoomed properly okay there we go there are these ten topics and what happens is you know this here the first half of it is really about physics simulation animation moving things on the screen and all the kind of stuff you could do with that and by the time we get to this people are on their way and they've been overloaded they're trying to learn all this stuff that what's here in nine and ten chapters nine and ten gets lost so what I'm doing this year is and starting right now is I would like to take what's in this book here nine and ten chapters 9 and 10 and expand the material out which is something that would be several you know many sessions about seven five or six or seven or eight I have no idea some amount of sessions of content where I take a closer look at topics related to and here's the title of this course intelligence and learning I'm going to come over here and I'm going to write that down this is like what people who are teachers I've been watching some like OpenCourseWare you have a big chalkboard and then you just like make a point and you write it down so I'm going to do that intelligent and learning now I am specific first of all well as I'm specifically not calling this a course like artificial intelligence nor am i calling this a course like introduction to machine learning nor am i saying it's a course called say introduction to deep learning so what's one reason why I'm not calling it that well first of all I'm afraid of all these things so I feel like if I call it this is a course on artificial intelligence or machine learning that's a little bit scary to me so the other reason why I want to call it intelligence and learning is I want to take the broadest approach possible so you watching this course whether if you implement the latest and greatest perfect machine learning neural network convolutional recurrent magical system thing that does something you read about in some academic paper or you make some crazy projects where it seems like the computer is playing this goofy game with you in it and how could it possibly be doing that so there's a lot of space in between and for me I want to just really take a broad approach to this not just look at only you know neural networks and machine learning and not just look at only these topics in artificial intelligence and okay so first of all listen I'm kind of blending all these terms let's try to at least define them so let's I saw the chart in the book somewhere I'm going to recreate it so artificial intelligence of the topic those the white has artificial intelligence well I actually just recently watched a lecture by professor at MIT Patrick Langston Patrick Winston I think it says that the opening of the lecture models so it'll correct me if I'm wrong for thinking perception and action so this is a very broad term so let's think about this for a second let me go back to some of my other examples to come over here and I'm going to open it where if we were falling along with the third piece if we stop here at week six or session six or chapter six for everyone to call it and I ran this flocking simulation I could ask the question is this artificial intelligence we nobody can answer the question I want to hear from you so I want to asking this question like but what's interesting whether or not you want to say yes or no I'm going to go back to here for a second models for thinking perception and action so one thing if you remember if you look at steering behaviors and steering behaviors pioneered by Craig Reynolds what is it a action steering locomotion so I've really been focusing on steering how do you calculate a steering force how do you do the physics for that and how do you actually make that triangle move for one pixel to another and steering and locomotion kind of cover all those pieces actions this is a place where well what is the action what are the goals and the flocking system the goals are stay with your neighbors but don't crash into your neighbors and also states in proximity your neighbors also move in the same direction as your neighbors but don't crash into your neighbors and other kind of action things you might selectively follow this thing or chase this thing or run away from this thing or try to get through this doorway the fastest as you can so what's interesting here is seeing this link is what our models for thinking in perception that might lead to action to govern the types of animated systems that you might create so this to me is the link here whether it's enough to say I am going to kind of define the rules of almost doing a zone like a rulebased system feature engineering so to speak like I don't need a learningbased system I'm going to define the rules of how all these things should behave but they're going to appear intelligence versus something like a learning system which has to learn over time so machine learning being something that crosses over with artificial intelligence you know I think of machine learning something that you have data and you make meaning from that data so how do you how do you and the you know there's more to it than this but you know one of the most classic applications of a machine learning system is classifying data classification so here's a bunch of pictures which ones are cats and which ones are dogs and there's more you know the other type of system that you classic application machine learning is regression which instead of categorizing into a discrete set of labels you know cats or dogs you might say you know here's all of these you want to arrive at a more continuous result so here's all these properties of a house how many bedrooms where's it located how many bathrooms and kendama can the system take that data and determine predictive price so these are two classic tasks and machine learning now what's in the news and what's all the rage what's everybody working with these days our neural networks so you know a popular and powerful and exciting so much new research in this right now recently of creating machine learning systems to do these tasks with neural networks however in this course I want to look at other systems that do the same thing that are simpler that might not be as powerful but might have opportunities for creative possibilities but also if you can use the simpler system for the same result it's going to make it a little easier to perhaps dive into what my mind might be the most difficult I like cancel this part actually last time I mentioned machine learning a fire alarm went off which saved me nothing happened this time but so so we'll see so now so these are inner areas where I want to just look at and cover in this course now what's this thing down here under DL this is deep learning and you know what I'm going to put deep learning in here so as I just mentioned a one technique for performing these machine learning tasks is using something called an artificial neural network so in the case of an artificial neural network that data that you're trying to classify enters as input to something called a neuron and then passes through a network of neurons to have some sort of output and I spelled that wrong close enough CatDog price of a price of a house that sort of thing now an artificial neural network is a system and I'm going to get more into this in another video just specifically just about this so I kind of want to just actually kind of move ahead and skip over this but the reason why I was mentioning this is there's a point if there's a long history of this and the very first discovery of an artificial neural network I'm going to build one of these in a future current Cody Jones it's called a perceptron which is a nervous is a Welliver on called a network because it's a single neuron so a model for a single neuron an artificial neural network being a model for many interconnected neurons maybe it's a fully connected Network and B it's like a partially connected network but the reason why so much rip that there has been a revolution in research and application neural networks when they were first discovered this idea of a perceptron couldn't solve very simple problems so there's a famous paper the perceptron paper McCullough Pitts I believe I'm getting that right probably the chat will confirm I'll try to link to that information in this video's description and there were various steps along the way but there was a long time before anyone was really able to do a lot of work with neural networks and so deep learning refers to the idea of a neural network which has a lot of depth to it so in between the inputs and the output output and these could be both be plural or singular there are many many many layers it is deep very deep so you know you could imagine all of these connections and so the idea here and you know the training systems and how it works now the learning system huh we got to get into all that but that's not for this video right here I got all the help of this tangent about neural networks so this is these are the different aspects of the pieces of this course that I would like to look at now let me come back over here okay so let me take a look at the list of topics I'm going to skip week one for a second so this is the course if you want this URL will be in the video's description this is the the syllabus for the course it's kind of my working document boy do I accept any and all contributions and help so feel free to file github issues and pull requests and things and if I come down here to the oh and I'm kind of in a place where you can't really see it I'm going to skip them a skip over week one and so here are my topics so I'm going to go through these kind of quickly again this is very survey oriented and boy and I'm missing a ton of stuff you know so this is just a selection but it's also still figuring this out so next week I'm going to talk about genetic algorithms which is an evolutionary based approach to solving problems with which is a way of solving problems in software taking inspiration from evolutionary processes in nature so I already have a bunch of videos on that and I'll do some more content about that as well and that will be in next week this should say classification and regression and recently I learned that the term regression comes from regression to the mean and this is like a 19th century concept but anyway I'll talk about where I'm getting all my I just read a bunch of books last week I have to thank all these people that I'm you're probably messing up all the stuff that I read but I want to get interested in those I want to get started with those tasks without using neural network based models so something called K nearest neighbor one of the things I would like to do is build a simple movie recommendation system with K nearest neighbors an idea if you have an idea for a data set or an interesting creative application for K nearest neighbor that's very simple with a simple data set that I can work with we love that suggestion and also linear regression so I want to do I want to do an example of the simplest form of regression and we can think of that in too with an input and having an output that's a continuous floatingpoint value so I want to look at that and we'll do that we're going to get all this stuff like oh there's a learning rate what's this gradient descent thing and all this stuff so hopefully kind of defining some of those terminology and understanding those pieces as we look at K X K nearest neighbor and linear regression will will give us a leg up for the next week when we look at neural networks so I would like to build some simple neural network examples from scratch and when I all of this stuff I'm going to do so far probably in processing or JavaScript using the p5.js library some combination of those things so if we want to build a perceptron you know if I'm feeling ambitious we might look at what happens if instead of a perceptron we have a multilayered network and in all of this you can think of the neural network is like you're tuning all of these knobs so that the output gives you something that's correct you know you there's a whole training process that we're going to have to discuss called supervised learning supervised learning unsupervised learning reinforcement learning interesting topics that I'm going to get into but with one of the most complex aspects of neural networks is what do you do how do you train all that stuff that's in the middle and so there's a concept known as back back propagation that I that's like almost almost like quaternions for me but I'm not running out of the room just yet and once I get to there I want to investigate some other platform so I might if I always I like but my plan and hope is to look a bit at it once we've built some simple examples from scratch to look at other tools for some more sophisticated applications like tensor flow and then be able to get into certain specific kinds of neural networks that could do different kinds of tasks what is a convolution network what is a recurrent Network and what is reinforcement learning so those are some aspects of things then you know I don't plan on building those larger more sophisticated systems from scratch but if we can build some basic ones understand how everything works then my thinking is then we all have a leg up to using frameworks and tools to do some of the other stuff again all this is subject to change one of the things I mentioned this last week that I'm hoping to do because even though I might move to something like tensorflow and Python to demonstrate some examples in some of these other areas I would love to work on a simple web server that runs tensorflow in the background that processing or p5 could talk to there are also examples of some of these written in JavaScript wellknown examples by Andrey Carpathia the recurrent RNN Jas and Condon s cons cons vinet and redress SJS so people are totally time's up I told people end up doing it live but you might be watching this an archive that I wanted to keep this in 20 minutes ok so that's my introduction you know here's the thing I'm learning this done so if you're going to watch of course from somebody who really knows this stuff I will link to lots of resources and that's what I meant to what I wanted to I wanted to mention some resources that I'm using very important that I will include in this video's description and I think here under the wiki under related projects and resources here are here are some resources that I want to specifically mention so one is the website called machine learning for artists it's got videos a video tutorial video lectures examples written descriptions lots of wonderful thing by artist and researcher named Jean Cogan absolute expert wonderful in this field I watched a lot of Rebecca feed drinks machine learning for musicians and artists videos Rebecca fie brink has made something absolutely wonderful called weka nadir which is a tool that allows you to send data itself machine learning stuff and it sends it back out all with something called OSD open sound control I would love to do some video tutorials on that or have some guest tutorials from Rebecca C brink on there's also a cadenza course on a creative applications with tensor flow that I tend to look at and get some resources from I also want to mention the let's see what else ah Andrew Gloucester is writing a book about machine learning and deep learning and it's not out yet but he was generous enough to let me look at some preview drafts so thank you very much follow at Andrews laughter on Twitter if you want to find out about his upcoming book coming out it's been really helpful to read and I'm sure there are also grokking deep learning is a book from Manning and rocking algorithms these are books that I've mentioned that I have kind of been looking as well as a make your own neural network which is a book that walks you through programming your own neural network in Python people in the chat are giving me lots of suggestions for other deep learning and machine learning and AI books I don't have my props I have the old textbooks bring those another time on artificial intelligence that are great but the other thing I would recommend is these are three compilations of resources so this is one that's put together by this community this is an awesome machine learning there's a lot of awesome blank lists that are put together let me let me see who puts this together just because I forgot from Joseph Smith CT on github and also this is a list of resources from memo Hawkins okay so please I'm accepting all suggestions and help and examples and ideas I look forward to all of these hopefully not so angry letters I will receive as I screw everything up over the next six or seven weeks we're gonna you know I have I guess what I didn't really say is I have you know to wrap up here what I have is these two chapters in nature code which deal with genetic algorithms and the basics of neural networks that's where I kind of left my knowledge behind and I'm embarking on this journey here YouTube to try to expand past what's in there and we will see how it goes so thanks for joining me and I look forward to seeing you in some future videos oh I'm back I do this a lot I'm back because I forgot that I had this page of notes and said I just rambled and you know it's got a few more links about thinking about the definition of artificial intelligence and machine learning I'm still working on stuff you'll find this also linked but you know something really important here that I wanted to just mention was you know it's it's very important when studying and I'm really gets going to be looking at the algorithms and making stuff and trying to be creative and wackadoodle in my way through this if that's a verb but it is really important for you the world of people who are going to be using these tools using these algorithms make project working for companies to be critical and think about what you're doing whether it's a good idea and is it hurting anybody is it helping anybody and so there's some you know some one thing I'll just mention here is there's an organization called AI now which has just learned about recently I thought I just clicked on them yep over here which is a initiative to research the social impacts of artificial intelligence to ensure a more equitable future so I encourage you to check out there's going to be a symposium in July checked about about this I also just love this quote from hard Maru on Twitter which is makes a david ha from google makes a lot of wonderful i recurrent neural there's a wonderful recurrent neural network can writing with p5.js example that you could find i'll try to link to that as well but you know whatever happened to making the world a better place so you know when you talk about what is your goal with building an AI systems with using machine learning why are you doing it and so i'll leave you with that are you making the world a better place i hope that you are and come along i'll see you in the next video
