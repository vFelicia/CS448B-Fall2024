With timestamps:

00:02 - okay my glasses on hi uh fixing my hair
00:06 - okay edit that part out uh welcome to
00:09 - another video in the nature of code
00:10 - video series and today I don't have
00:12 - anything in my I I'm missing my pen here
00:15 - it is I have to hold it I feel more
00:16 - comfortable this way today we are making
00:18 - a huge leap forward so if if you
00:21 - actually watched every single video or
00:23 - at least most of them up until now you
00:25 - would have found that all of the
00:26 - simulations there's a circle on the
00:28 - screen a square on the screen some shape
00:30 - on the screen it's really an inanimate
00:31 - object it has no decision-making ability
00:33 - it has no life it has no hopes and
00:35 - dreams and fears it's just sitting there
00:37 - and forces in the environment push or
00:38 - pull it around what we want to do in
00:41 - this very moment in this very spot
00:43 - together today is say we want to begin
00:45 - to build simulations where the objects
00:48 - make a decision I think earlier in
00:50 - probably the first video I think I might
00:51 - have talked about a a ball sitting on a
00:53 - table that falls off the table versus a
00:55 - little creature sitting at the end of
00:57 - the table that chooses to jump off that
00:59 - table today we want to be that creature
01:01 - that jumps off the table that that is
01:03 - able to perceive its environment and
01:04 - make a decision as to where it should go
01:06 - now we have we want to do this just for
01:08 - its own sake because this is going to be
01:09 - interesting and allow us to build um
01:12 - different types of motion behaviors that
01:14 - we haven't been able to do so far but we
01:16 - also have another goal in mind so I want
01:18 - to um come over here for a second and
01:20 - look so this is um without the mouse in
01:21 - the center oh I I don't this does not
01:24 - control that Mouse this is this mouse
01:26 - anyway that's irrelevant what we have
01:27 - here is an example that you'll find in
01:29 - processing
01:30 - it's the flocking simulation we're going
01:32 - to get to this example probably at the
01:34 - end of this set of chapter 6 videos but
01:37 - the reason why I want to look at it is
01:39 - this is an example of a complex system
01:42 - what is a complex system complex system
01:44 - is often thought of a system that's more
01:45 - than the sum of its parts well what is
01:48 - the part here the part is this little
01:49 - triangle that's moving around the screen
01:51 - that operates with these really three
01:52 - Simple Rules don't run into my neighbor
01:55 - stay with the group try to go in the
01:56 - direction of the group we're going to
01:58 - look at those rules later more formally
02:00 - but but that simple those Simple Rules
02:02 - we can understand each one of these
02:04 - individual triangles very easily but
02:06 - globally then we get this kind of
02:07 - unpredictable highly intelligent ordered
02:10 - yet chaotic um Behavior it's really
02:13 - quite amazing and and you know there's
02:15 - tons of examples of this in nature ant
02:17 - colonies termites lightning earthquakes
02:20 - the weather uh think about the stock
02:22 - market there we could go on and on and
02:24 - on and come come up with tons of
02:25 - examples of systems of these simple
02:28 - agents that when you put them all
02:29 - together you get this Global
02:30 - intelligence I mean an ant can't be that
02:32 - sophisticated but how does an ant colony
02:34 - build an elaborate set of tunnels and
02:36 - collect lots of food and I don't know
02:38 - protect the queen disclaimer I have no
02:40 - idea what ants actually do but you know
02:42 - something like that I watched I don't
02:44 - know bugs life or be movie or I don't
02:47 - know there's a bunch of them anyway so
02:48 - this is where we want to go if we but
02:50 - but before we get to stuff like this
02:52 - we're going to look at these simple
02:54 - agents now um so I'm going to get to all
02:58 - the details of this I guess this video
03:00 - is kind of like a little bit of an
03:01 - introductory landscape of this topic and
03:03 - I wanted to just point out to you um a
03:05 - couple things that I think um are useful
03:08 - for you to think about so
03:11 - um okay let's take a moment to Define
03:15 - what we mean
03:17 - by
03:19 - autonomous agent so what are the what
03:23 - are the sort of principles that we're
03:24 - going to think about as we start to
03:26 - build these simulations that involve
03:28 - entities that can that can that are more
03:32 - alive okay so one principle is that an
03:35 - anonomous agent has an ability and
03:37 - there's a sort of key word here a
03:38 - limited
03:40 - ability to
03:42 - perceive its
03:46 - environment now this may seem like a
03:48 - trivial detail to you but this will
03:50 - become quite an important factor in in
03:52 - what we end up programming right is are
03:55 - the things on the screen able to see
03:57 - anything within um 25 pixels of
04:01 - itself or perhaps is this object on the
04:04 - screen only able to see things that are
04:06 - in front of it at a certain distance
04:08 - right so what is that limited ability
04:10 - what can it actually see on the screen
04:12 - or smell or sense right we want to build
04:16 - start building entities these objects
04:18 - that have sensors on them you know
04:20 - virtual software sensors so okay the
04:23 - other thing that we want to do is once
04:24 - it's perceiving its environment it it's
04:27 - going to kind of process that
04:29 - environment so let's process the
04:34 - environment and
04:36 - calculate an
04:38 - action so the key thing here is
04:41 - calculate that action so I'm I'm an
04:44 - entity and I'm us I got to get a better
04:47 - word than entity but I'm a thing and I
04:49 - see that there's a bunch of things in
04:50 - front of me and those things look scary
04:52 - so I'm going to calculate my action
04:54 - which is to run away in the opposite
04:55 - direction right what is that calculation
04:58 - going to result in it's going to result
05:00 - in a
05:01 - force so what's really um what what's
05:05 - really important about what we're doing
05:06 - here is we're not we're not really doing
05:08 - anything new we're just thinking about
05:10 - things differently and coming up with
05:12 - some interesting formulas and logic and
05:14 - rules by which we send forces into our
05:17 - objects so even though we're thinking
05:19 - wildly different conceptually this thing
05:21 - is alive this thing is not alive um wind
05:24 - is something that just affects it you
05:26 - know external Force like wind versus an
05:28 - internal Force like fear
05:30 - um in the end they're all just going to
05:32 - be forces and um the last thing I want
05:34 - to put on this list here is that is that
05:37 - there is no Global plan or leader now
05:41 - this isn't some hard and fast rule you
05:44 - know from everything you ever build now
05:45 - in processing you better not have a
05:47 - leader in that program you know we're
05:48 - not say I'm not saying that by any
05:49 - stretch of the imagination but one thing
05:52 - that's important to realize is um we as
05:55 - a kind of exercise here are building
05:57 - entities that just respond to whatever
05:59 - they can perceive around themselves and
06:01 - and and and make a decision and and and
06:03 - and and calculate an action based on
06:05 - that there isn't some Global leader
06:07 - telling them what to do now you may want
06:09 - to build simulations with global plans
06:11 - and leaders in them and that's fine but
06:13 - a true autonomous agent wouldn't have
06:15 - that it really is making its decisions
06:16 - only based on its own perception of the
06:18 - environment so these are the kind of key
06:21 - principles that we're going to see in
06:22 - the programs we're going to build now
06:26 - what are these examples we're going to
06:28 - make and where do they come from so
06:29 - there's a lot of places there's a lot of
06:31 - things we could come up with and think
06:32 - of um ultimately we're going to build
06:34 - our examples off of the work of uh Craig
06:36 - Reynolds and his um uh all based on this
06:41 - paper he wrote called steering behaviors
06:42 - for autonomous characters um which I'm
06:44 - going to get to in a second but before
06:46 - we do that let's just look um at some
06:48 - kind of nice examples of this so I uh I
06:50 - have this video on a loop here which I'm
06:52 - going to try to have no idea where it's
06:53 - going to be in the video but um so this
06:55 - is from Casey Reese's process compendium
06:57 - which I will link to below and you can
06:59 - see here here there's an element with a
07:01 - bunch of rules if you I I highly suggest
07:03 - you go pause this video go watch his
07:05 - video and you can see here are all of
07:07 - these elements that are operating with
07:09 - these very simple rules they perceive
07:11 - their environment what are they near if
07:13 - they hit something if they're if they
07:14 - intersect something turn if they don't
07:16 - intersect something goes straight and
07:18 - all of his work these beautiful artworks
07:20 - are created out of these incredibly
07:22 - simple rules and I can kind of um um
07:25 - scan through this and you can see I'm
07:27 - going to go back to the beginning we can
07:29 - see it as maybe this this di this this
07:31 - this simulation is perhaps a slightly
07:32 - better um representation of that so one
07:34 - of the the reasons why I wanted to just
07:36 - quickly reference um uh Casey Reese's
07:39 - work is because a lot of his inspiration
07:41 - comes from am I still here yes it comes
07:43 - from this book I have a prop now it's a
07:45 - book it is paper oh it's like a Fanning
07:48 - me okay this book called Vehicles by um
07:51 - Valentino brenberg so um Valentine
07:53 - brenberg is a neuroscientist uh and I
07:55 - think if I go here and this is just the
07:57 - page of the book on um Google book and
08:00 - you can see what what's nice about this
08:02 - book is it's kind of exercise in science
08:04 - fiction in a way and creating these
08:06 - ideas of these little robots with
08:08 - sensors that see light and this one is
08:10 - afraid of the light and this one is
08:11 - attracted to the light and um and and
08:14 - brenberg really thinks of um these
08:17 - vehicles as almost like you know pets or
08:19 - little creatures and they respond to
08:21 - fear or love or aggression or foresight
08:24 - and and so I think this is an important
08:26 - place to really think about a a really
08:29 - nice set of inspiration for how you
08:31 - might want to think about and build
08:32 - autonomous characters so I will also
08:34 - link to some material on brenberg
08:36 - vehicles below which you can look at as
08:38 - a kind of source of inspiration for you
08:40 - but the reason why I bring this up is
08:43 - brenberg Vehicles were a main source of
08:45 - inspiration for Craig Reynolds steering
08:48 - behaviors so what we're ultimately going
08:50 - to look at um and build a set of cring
08:54 - examples which are just pure
08:56 - implementations of Reynold steering
08:58 - behaviors for autonomous characters so
09:00 - this is a paper that was uh written in
09:03 - 99 um I I encourage you to take a look
09:06 - at it I'm going to kind of go through a
09:07 - lot of it in a less formal less depth
09:11 - processing speak and so you might want
09:13 - the kind of true uh guts of this by
09:15 - taking a look through this paper
09:16 - yourself but what Reynolds has done is
09:19 - has said okay we don't really care
09:23 - exactly about how things really truly
09:25 - work in the real world what we want to
09:27 - create is the appearance we want to
09:29 - create lifelike and improvisational
09:31 - characters that move about the screen
09:33 - and I one of my favorite examples
09:35 - there's a whole set of behaviors
09:37 - wandering and seeking pursuing a Target
09:40 - uh following a path one of the ones that
09:42 - I think is a great illustration of this
09:44 - is queuing at a doorway and we can see
09:46 - here in this um simulation we have a lot
09:49 - of elements that are all trying to get
09:51 - through this doorway but as they come
09:53 - together they have to slow down and stop
09:55 - so how what is its perception of this
09:57 - environment how does it know where the
09:58 - door is how is it trying to get there
10:00 - how does it see the things around it why
10:02 - does it choose to slow down when it gets
10:03 - near something these are all the types
10:05 - of things that we want to step through
10:08 - so we're going to look at the um this
10:11 - idea of a steering Force how do we
10:13 - calculate a steering force and what are
10:15 - a lot of
10:16 - scenarios whereby we need these steering
10:18 - forces what kind of steering Force do we
10:20 - want when an object wants to catch some
10:22 - you know catch its prey um versus escape
10:25 - from a crowded room because it feels
10:27 - very claustrophobic in that room room
10:30 - strange scenario there's a great I I
10:32 - should link to it below there's a great
10:33 - um uh paper and Sim online simulation
10:36 - that came out recently of simulating a
10:37 - MH pit um so what is what do a mher in a
10:42 - MH pit desire to do and what types of
10:44 - decisions does it make based on how
10:46 - other Mosers are moshing around them
10:48 - right you could ask yourself that
10:49 - question you could come up with a set of
10:51 - rules and then you could simulate that
10:52 - and I encourage you to take a look at
10:53 - that simulation which I will link to
10:55 - below I don't have it prepared here
10:57 - because I don't prepare for any of this
10:59 - just blabbing on and on I will get
11:01 - better at This I Swear okay so um let's
11:04 - talk so we we're this is just a lot of
11:06 - Flowery language and kind of walking
11:08 - through a bunch of things here which
11:10 - which I'm almost done with but what I
11:12 - want to do is kind of talk through how
11:14 - Reynolds thinks of
11:17 - um um what his Vehicles
11:20 - do
11:22 - so Reynolds thinks of his Vehicles as
11:27 - operating with three steps
11:30 - action
11:37 - selection
11:41 - steering and
11:44 - Locomotion so our objects that we're
11:46 - going to build in processing are going
11:48 - to follow these three steps action
11:51 - selection is looking at the environment
11:53 - and choosing an action oh I've got to
11:56 - get that food oh I've got to run away
11:58 - for that Predator oh I really want to
11:59 - get through that doorway oh that path
12:01 - looks lovely it's the yellow bck Road
12:02 - let me follow it right so we have to
12:04 - choose a desire and here this word
12:08 - desire is really really key all of our
12:11 - objects that we're going to build are
12:12 - going to have a desired velocity the
12:14 - velocity the direction and speed at
12:16 - which they really want to go at the
12:18 - moment once they have that desired
12:20 - velocity we're going to calculate a
12:22 - steering Force based on it that steering
12:25 - Force I just want to write the word is a
12:27 - force
12:29 - it's just a vector so just the way we
12:31 - calculated an attraction Force we
12:33 - calculated a friction Force we are now
12:35 - calculating steering forces we're going
12:37 - to have a very specific formula for it
12:39 - which is so simple and elegant and but
12:42 - powerful and that's really the
12:43 - Innovation that that Reynolds came up
12:44 - with with this framework so we're going
12:46 - to look at how we calculate steering
12:47 - forces and the good news here once we
12:49 - have that steering Force we need to
12:51 - apply it to the object's Locomotion it
12:52 - needs to move what are some options for
12:55 - Locomotion well we could have Oiler
12:58 - integration location velocity and
13:01 - acceleration we could use box 2D we
13:04 - could use toxic Libs right the third
13:07 - step is the physics simulation so all
13:10 - we're doing here is we're saying we have
13:11 - an existing physics simulation and now
13:13 - we're going to layer on top of it this
13:15 - methodology for choosing behaviors and
13:18 - applying forces to those objects so th
13:21 - this so everything that we've done
13:23 - all videos long is all building up to
13:28 - this point where we now have this
13:29 - physics engine we could use any one of
13:30 - these we're going to use our own we're
13:32 - just going to use P vector and our own
13:33 - location velocity and acceleration and
13:35 - now starting to apply steering forces to
13:37 - it so um I'm going to stop this video
13:40 - here that's kind of an introduction to
13:42 - the landscape of all of this stuff I
13:43 - think I have this list of things that I
13:45 - covered and in the next video we're
13:46 - going to all we're going to really look
13:48 - at is this very simple calculation for
13:50 - how we calculate a steering force and
13:53 - the first behavior that we're going to
13:54 - look at is Seeking a Target so like ah
13:56 - over there is something I want to get
13:58 - there I'm going to how do I steer in
13:59 - that direction which is very similar to
14:00 - gravitational attraction but I want to
14:02 - look also at like how this model differs
14:04 - from that and how it's in many ways more
14:06 - powerful or at least a better model for
14:09 - entities that might be alive or kind of
14:11 - providing their own set of um uh you
14:15 - moving themselves about a space as
14:16 - opposed to just experiencing a force
14:19 - okay
14:20 - um thank you and uh I'm say good night
14:24 - but it's the afternoon I I'm over here
14:26 - now okay goodbye

Cleaned transcript:

okay my glasses on hi uh fixing my hair okay edit that part out uh welcome to another video in the nature of code video series and today I don't have anything in my I I'm missing my pen here it is I have to hold it I feel more comfortable this way today we are making a huge leap forward so if if you actually watched every single video or at least most of them up until now you would have found that all of the simulations there's a circle on the screen a square on the screen some shape on the screen it's really an inanimate object it has no decisionmaking ability it has no life it has no hopes and dreams and fears it's just sitting there and forces in the environment push or pull it around what we want to do in this very moment in this very spot together today is say we want to begin to build simulations where the objects make a decision I think earlier in probably the first video I think I might have talked about a a ball sitting on a table that falls off the table versus a little creature sitting at the end of the table that chooses to jump off that table today we want to be that creature that jumps off the table that that is able to perceive its environment and make a decision as to where it should go now we have we want to do this just for its own sake because this is going to be interesting and allow us to build um different types of motion behaviors that we haven't been able to do so far but we also have another goal in mind so I want to um come over here for a second and look so this is um without the mouse in the center oh I I don't this does not control that Mouse this is this mouse anyway that's irrelevant what we have here is an example that you'll find in processing it's the flocking simulation we're going to get to this example probably at the end of this set of chapter 6 videos but the reason why I want to look at it is this is an example of a complex system what is a complex system complex system is often thought of a system that's more than the sum of its parts well what is the part here the part is this little triangle that's moving around the screen that operates with these really three Simple Rules don't run into my neighbor stay with the group try to go in the direction of the group we're going to look at those rules later more formally but but that simple those Simple Rules we can understand each one of these individual triangles very easily but globally then we get this kind of unpredictable highly intelligent ordered yet chaotic um Behavior it's really quite amazing and and you know there's tons of examples of this in nature ant colonies termites lightning earthquakes the weather uh think about the stock market there we could go on and on and on and come come up with tons of examples of systems of these simple agents that when you put them all together you get this Global intelligence I mean an ant can't be that sophisticated but how does an ant colony build an elaborate set of tunnels and collect lots of food and I don't know protect the queen disclaimer I have no idea what ants actually do but you know something like that I watched I don't know bugs life or be movie or I don't know there's a bunch of them anyway so this is where we want to go if we but but before we get to stuff like this we're going to look at these simple agents now um so I'm going to get to all the details of this I guess this video is kind of like a little bit of an introductory landscape of this topic and I wanted to just point out to you um a couple things that I think um are useful for you to think about so um okay let's take a moment to Define what we mean by autonomous agent so what are the what are the sort of principles that we're going to think about as we start to build these simulations that involve entities that can that can that are more alive okay so one principle is that an anonomous agent has an ability and there's a sort of key word here a limited ability to perceive its environment now this may seem like a trivial detail to you but this will become quite an important factor in in what we end up programming right is are the things on the screen able to see anything within um 25 pixels of itself or perhaps is this object on the screen only able to see things that are in front of it at a certain distance right so what is that limited ability what can it actually see on the screen or smell or sense right we want to build start building entities these objects that have sensors on them you know virtual software sensors so okay the other thing that we want to do is once it's perceiving its environment it it's going to kind of process that environment so let's process the environment and calculate an action so the key thing here is calculate that action so I'm I'm an entity and I'm us I got to get a better word than entity but I'm a thing and I see that there's a bunch of things in front of me and those things look scary so I'm going to calculate my action which is to run away in the opposite direction right what is that calculation going to result in it's going to result in a force so what's really um what what's really important about what we're doing here is we're not we're not really doing anything new we're just thinking about things differently and coming up with some interesting formulas and logic and rules by which we send forces into our objects so even though we're thinking wildly different conceptually this thing is alive this thing is not alive um wind is something that just affects it you know external Force like wind versus an internal Force like fear um in the end they're all just going to be forces and um the last thing I want to put on this list here is that is that there is no Global plan or leader now this isn't some hard and fast rule you know from everything you ever build now in processing you better not have a leader in that program you know we're not say I'm not saying that by any stretch of the imagination but one thing that's important to realize is um we as a kind of exercise here are building entities that just respond to whatever they can perceive around themselves and and and and make a decision and and and and and calculate an action based on that there isn't some Global leader telling them what to do now you may want to build simulations with global plans and leaders in them and that's fine but a true autonomous agent wouldn't have that it really is making its decisions only based on its own perception of the environment so these are the kind of key principles that we're going to see in the programs we're going to build now what are these examples we're going to make and where do they come from so there's a lot of places there's a lot of things we could come up with and think of um ultimately we're going to build our examples off of the work of uh Craig Reynolds and his um uh all based on this paper he wrote called steering behaviors for autonomous characters um which I'm going to get to in a second but before we do that let's just look um at some kind of nice examples of this so I uh I have this video on a loop here which I'm going to try to have no idea where it's going to be in the video but um so this is from Casey Reese's process compendium which I will link to below and you can see here here there's an element with a bunch of rules if you I I highly suggest you go pause this video go watch his video and you can see here are all of these elements that are operating with these very simple rules they perceive their environment what are they near if they hit something if they're if they intersect something turn if they don't intersect something goes straight and all of his work these beautiful artworks are created out of these incredibly simple rules and I can kind of um um scan through this and you can see I'm going to go back to the beginning we can see it as maybe this this di this this this simulation is perhaps a slightly better um representation of that so one of the the reasons why I wanted to just quickly reference um uh Casey Reese's work is because a lot of his inspiration comes from am I still here yes it comes from this book I have a prop now it's a book it is paper oh it's like a Fanning me okay this book called Vehicles by um Valentino brenberg so um Valentine brenberg is a neuroscientist uh and I think if I go here and this is just the page of the book on um Google book and you can see what what's nice about this book is it's kind of exercise in science fiction in a way and creating these ideas of these little robots with sensors that see light and this one is afraid of the light and this one is attracted to the light and um and and brenberg really thinks of um these vehicles as almost like you know pets or little creatures and they respond to fear or love or aggression or foresight and and so I think this is an important place to really think about a a really nice set of inspiration for how you might want to think about and build autonomous characters so I will also link to some material on brenberg vehicles below which you can look at as a kind of source of inspiration for you but the reason why I bring this up is brenberg Vehicles were a main source of inspiration for Craig Reynolds steering behaviors so what we're ultimately going to look at um and build a set of cring examples which are just pure implementations of Reynold steering behaviors for autonomous characters so this is a paper that was uh written in 99 um I I encourage you to take a look at it I'm going to kind of go through a lot of it in a less formal less depth processing speak and so you might want the kind of true uh guts of this by taking a look through this paper yourself but what Reynolds has done is has said okay we don't really care exactly about how things really truly work in the real world what we want to create is the appearance we want to create lifelike and improvisational characters that move about the screen and I one of my favorite examples there's a whole set of behaviors wandering and seeking pursuing a Target uh following a path one of the ones that I think is a great illustration of this is queuing at a doorway and we can see here in this um simulation we have a lot of elements that are all trying to get through this doorway but as they come together they have to slow down and stop so how what is its perception of this environment how does it know where the door is how is it trying to get there how does it see the things around it why does it choose to slow down when it gets near something these are all the types of things that we want to step through so we're going to look at the um this idea of a steering Force how do we calculate a steering force and what are a lot of scenarios whereby we need these steering forces what kind of steering Force do we want when an object wants to catch some you know catch its prey um versus escape from a crowded room because it feels very claustrophobic in that room room strange scenario there's a great I I should link to it below there's a great um uh paper and Sim online simulation that came out recently of simulating a MH pit um so what is what do a mher in a MH pit desire to do and what types of decisions does it make based on how other Mosers are moshing around them right you could ask yourself that question you could come up with a set of rules and then you could simulate that and I encourage you to take a look at that simulation which I will link to below I don't have it prepared here because I don't prepare for any of this just blabbing on and on I will get better at This I Swear okay so um let's talk so we we're this is just a lot of Flowery language and kind of walking through a bunch of things here which which I'm almost done with but what I want to do is kind of talk through how Reynolds thinks of um um what his Vehicles do so Reynolds thinks of his Vehicles as operating with three steps action selection steering and Locomotion so our objects that we're going to build in processing are going to follow these three steps action selection is looking at the environment and choosing an action oh I've got to get that food oh I've got to run away for that Predator oh I really want to get through that doorway oh that path looks lovely it's the yellow bck Road let me follow it right so we have to choose a desire and here this word desire is really really key all of our objects that we're going to build are going to have a desired velocity the velocity the direction and speed at which they really want to go at the moment once they have that desired velocity we're going to calculate a steering Force based on it that steering Force I just want to write the word is a force it's just a vector so just the way we calculated an attraction Force we calculated a friction Force we are now calculating steering forces we're going to have a very specific formula for it which is so simple and elegant and but powerful and that's really the Innovation that that Reynolds came up with with this framework so we're going to look at how we calculate steering forces and the good news here once we have that steering Force we need to apply it to the object's Locomotion it needs to move what are some options for Locomotion well we could have Oiler integration location velocity and acceleration we could use box 2D we could use toxic Libs right the third step is the physics simulation so all we're doing here is we're saying we have an existing physics simulation and now we're going to layer on top of it this methodology for choosing behaviors and applying forces to those objects so th this so everything that we've done all videos long is all building up to this point where we now have this physics engine we could use any one of these we're going to use our own we're just going to use P vector and our own location velocity and acceleration and now starting to apply steering forces to it so um I'm going to stop this video here that's kind of an introduction to the landscape of all of this stuff I think I have this list of things that I covered and in the next video we're going to all we're going to really look at is this very simple calculation for how we calculate a steering force and the first behavior that we're going to look at is Seeking a Target so like ah over there is something I want to get there I'm going to how do I steer in that direction which is very similar to gravitational attraction but I want to look also at like how this model differs from that and how it's in many ways more powerful or at least a better model for entities that might be alive or kind of providing their own set of um uh you moving themselves about a space as opposed to just experiencing a force okay um thank you and uh I'm say good night but it's the afternoon I I'm over here now okay goodbye
