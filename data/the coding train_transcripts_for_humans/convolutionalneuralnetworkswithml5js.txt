With timestamps:

00:00 - [Music]
00:05 - [Music]
00:12 - [Music]
00:19 - [Music]
00:52 - [Music]
01:00 - [Music]
01:07 - [Music]
01:20 - [Music]
01:34 - [Music]
01:45 - [Music]
01:56 - [Music]
02:02 - [Music]
02:14 - [Music]
02:31 - [Music]
02:44 - [Music]
02:52 - [Music]
03:15 - [Music]
03:27 - [Music]
03:53 - [Music]
04:03 - [Music]
04:13 - [Music]
04:37 - [Music]
05:14 - [Music]
05:57 - [Music]
06:40 - [Music]
07:13 - [Music]
07:30 - good morning and welcome to the coding
07:35 - train with me your host coding train
07:39 - person I do have a name it's Dan and we
07:44 - begin as we always begin with the
07:47 - ceremonial reading of today's random
07:50 - numbers coding training today is brought
07:53 - to you by the random numbers fifty nine
07:55 - thousand one hundred ninety four nine
07:58 - thousand and twenty seven ninety five
08:00 - thousand nine hundred twenty two fifty
08:02 - five thousand four hundred and sixteen
08:04 - twenty four thousand two hundred and
08:07 - forty-one maybe thousand this is what I
08:11 - look at the chat oh wait I'm in the
08:14 - wrong chat channel to see if like
08:17 - there's anything terribly wrong going on
08:19 - let me switch
08:23 - [Music]
08:29 - there we go
08:31 - brand el Mac says hello everyone by the
08:33 - way I'm looking at the discord chat
08:35 - which is for disc members of the coding
08:38 - train but I also seen the YouTube chat
08:40 - where I see ninety four thousand nine
08:41 - hundred thirty from our naav are now
08:44 - sends another random number seventy
08:45 - thousand nine hundred forty eight I
08:47 - wonder if we had you know a random
08:54 - number for every person if every person
08:56 - watching thought of a random number
09:01 - between 0 and 90 9999 inclusive of that
09:06 - what the distribution would be and
09:09 - whether we would have a a good random
09:15 - number pseudo-random number generator a
09:17 - random number generator or not
09:18 - interesting question interesting theory
09:20 - I could loot my out-of-focus I thought I
09:23 - was on focus everything is definitely on
09:25 - fire the roof the roof it's up there
09:34 - bunch of floors up I guess if the roof
09:36 - is only technically the top of the
09:38 - building I mean there's a ceiling that's
09:39 - not really a roof no says Oliver once
09:44 - again I will remind everybody watching
09:47 - that when you say yes or no is if you
09:48 - were replying to me I have no idea what
09:51 - you're talking about because it happens
09:52 - about 30 seconds later and my memory
09:54 - apparently my short-term memory is not
09:56 - nearly that long I forgot to wash my
09:59 - glasses it's very important that I wash
10:01 - my glasses before I livestream these
10:03 - very bright lights which reflect in them
10:05 - which is a problem I need to get some
10:06 - anti reflective lenses but also as soon
10:10 - as those lights come on if there's like
10:11 - a little bit of dirt it's much better
10:16 - refocus yeah why is that alright so
10:18 - let's try using the random digits book I
10:21 - thought I focused and this book possibly
10:25 - prop itself up oh by the way this is a
10:28 - YouTube show livestream thingamabob
10:32 - where I code stuff and talk about things
10:34 - and I'm still on a little machine
10:35 - learning kick so that's what's happening
10:37 - today let me see if I can fix this
10:39 - focus because I cannot be in two places
10:42 - at once one of these days maybe I'll get
10:45 - a like a robot assistant to be in here
10:47 - and to focus the camera for me so weird
10:51 - I think this random number book is not
10:55 - very good for helping me focus in more
10:59 - ways than one better
11:05 - I can't tell let's go with mine oh wait
11:11 - wait wait
11:11 - let's try my other special focus device
11:15 - oh good it's transit all right I'm just
11:19 - gonna have to go with my usual Elgato
11:24 - streamed box not a sponsor today's
11:26 - sponsor by the way is audible if you go
11:29 - to audible.com slash coding trade or
11:31 - text coding drain - 500 - 500 you can
11:35 - get a free audio book you can listen to
11:38 - a free audiobook and I listening to one
11:40 - right now which is called your a thing I
11:43 - love you bye Jenelle Shane I'm gonna
11:44 - talk about that book it's a amazing AI
11:46 - book or you can also text coding train -
11:49 - 500 500
11:50 - I love audible it's so wonderful to
11:52 - listen to books when I'm on the subway
11:53 - and jogging and all that stuff so I will
11:55 - come back and talk about that
11:56 - I do also love stream deck although they
11:58 - are not a sponsor so I don't have a link
12:00 - for you but I do have a link for you
12:01 - audible.com slash Kodi drain all right
12:03 - let me see if I could focus the camera
12:05 - now on this you would think I did this I
12:10 - do I have my list of things to do before
12:12 - I start focusing the camera is one of
12:16 - them it looks good I also want to take a
12:22 - if I think this is better now I feel
12:28 - like I look out of focus tell me if I'm
12:30 - okay I mean I'm not okay this is clear
12:35 - I've got lots of issues many many many
12:38 - many issues okay
12:40 - don't worry about me I'm fine I'm okay
12:42 - my life is fine
12:47 - but I am very much out of focus in so
12:51 - many ways literally and figuratively
12:55 - but hopefully I've literally in focus
12:57 - right now if somebody in the member
12:59 - channel under live chat in the discord
13:01 - could let me know that would be super
13:03 - helpful if I'm not I will fix it I might
13:06 - like want to take just a short break to
13:08 - go clean my glasses all right I think we
13:13 - have a new member who just joined Scott
13:17 - Bauer related baby - Jack Bauer no
13:22 - that's like a label you probably an
13:23 - unmet you should definitely just like
13:25 - cancel your membership that I made some
13:27 - sort of like lame ridiculous joke I'm
13:30 - going to talk about what I'm gonna do
13:32 - today which is examine something called
13:34 - convolutional neural networks david says
13:37 - I'm good that reminds me I'm gonna show
13:40 - a community contribution from David
13:42 - which should be a fun little experiment
13:43 - it's okay but not perfect let me mention
13:48 - the discord just because I'm gonna take
13:52 - like a second here so this is the new
13:56 - coding train discord this is the all
13:59 - aboard channel so if you join the coding
14:01 - train discord you are required to read
14:05 - this will be welcome map message and the
14:07 - code of conduct which is here I'll also
14:11 - note like I get a ton of questions on
14:13 - the videos which I appreciate the
14:15 - comments and I do scan through all them
14:17 - and I try to reply here and there when I
14:19 - can
14:19 - but if you're looking for coding help to
14:22 - places for you one is the that I'll
14:24 - mention first is the processing
14:27 - discourse so if you go to the processing
14:33 - foundation forum which is a discourse
14:36 - dot processing org if you have a
14:38 - processing or p5 specific question a
14:40 - search this forum it's probably been
14:42 - asked and answered but you can also ask
14:44 - it here this is a great place but if
14:45 - you're something if you want to if
14:47 - you're interested in discord or
14:48 - something more coding trained specific
14:50 - this is a great place to get help and
14:53 - you can see the different channels here
14:55 - we have um HTML CSS p5 processing Oh if
14:58 - these
14:59 - you bike okay node for a server-side
15:09 - stuff of machine learning Python which
15:11 - is not my area of expertise get not not
15:14 - that any of this is really my area of
15:16 - expertise
15:16 - maybe processing I had one area of
15:19 - expertise that I might actually claim it
15:22 - would be processing so if someone could
15:24 - post is anybody a moderator currently in
15:26 - the chat who can post the discord link
15:28 - if not oh wait I can I can I'm gonna do
15:32 - that right now I should get up I have a
15:34 - button actually right here which
15:36 - whenever I press it it posts you to the
15:39 - chat I should have that post like the
15:42 - discord lake or I could make another but
15:44 - let's see if I can get that to work so I
15:47 - am going to go over here to useful links
15:50 - so this is where I'm I'm gonna I'm
15:53 - actually gonna show you where I'm going
15:54 - but I'm doing it on a different computer
15:56 - useful links here which these are all
15:58 - the various coding train links that you
16:00 - might be interested in I'm gonna grab
16:01 - this discord link I'm gonna hit copy and
16:06 - paste it into the chat just so it's
16:08 - there then I am going to go to my where
16:17 - am I going to my stream deck and I'm
16:20 - going to go down to YouTube YouTube but
16:24 - YouTube and put in chat message just
16:28 - call it discord I have so many keyboards
16:30 - and buttons then I'm going to paste the
16:34 - link here to the discord and I think now
16:41 - if I just hit save anytime I want
16:46 - I am I don't know I'm afraid to say this
16:52 - name cuz I feel like there might be
16:55 - something hidden in there that I'm not
16:56 - aware of cuz I'm not really thinking he
16:59 - is going to code in the next few minutes
17:00 - and you would be right you are the
17:04 - winner of a
17:07 - trip for two on the cutting train
17:11 - choo-choo
17:12 - [Music]
17:23 - and you'll also get with your trip for
17:26 - two on the Kotick train random numbers
17:32 - and what was I doing
17:36 - Oh welcome Japs thanks Jeff for joining
17:41 - the coding train on the cookie speaking
17:48 - did you take like an improv class or
17:50 - something cuz I'm absolutely terrible at
17:52 - this
17:54 - [Music]
17:58 - with your coding trade membership you
18:01 - will receive in the mail stickers much
18:14 - love from Tanzania Africa thanks Scott
18:20 - welcome aboard to the kodi train with
18:24 - your super chat message you'll now
18:29 - receive a reading from the kodi train
18:33 - [Music]
18:42 - okay I was doing something I'm testing
18:52 - this button did it work
18:55 - I pressed the button I to post a link to
18:57 - this chord so let me just quickly
18:59 - mention a couple other things in here
19:02 - under store oh no wrong wrong link wrong
19:09 - link discord you failed me I guess I
19:11 - should edit that this is the new so
19:13 - that's the old store I mean actually
19:15 - still exist I might take it down I don't
19:16 - know but this is the new store I just
19:19 - wanted to mention that there are coding
19:22 - train hoodies available I would really
19:24 - liked one of these so this is my pitch
19:27 - to you these are expensive to make I'm
19:31 - not using a print on demand service
19:34 - anymore standard TV helped me design and
19:36 - produce this merchandise which I'm told
19:38 - this high quality and so this they're
19:41 - gonna do actually a print run of these I
19:44 - don't know what the process is but so
19:47 - it's only taking three orders so if
19:49 - people don't order them they won't get
19:50 - made I've already ordered a whole bunch
19:52 - for myself maybe I've ordered enough
19:54 - that it'll get made but that's my pitch
19:57 - to you if you want me to see me wearing
20:00 - one of these but I would like to I'm
20:01 - wearing my ITP camp hoodie right now
20:03 - then other people need to order them and
20:05 - there's other stuff here if you're
20:07 - interested standard TV I don't
20:08 - a button to post on the chat okay so I
20:12 - am you know I'm sure I want to get
20:14 - started sooner than later or not I mean
20:16 - all of this is goofing off on some level
20:18 - but not waste not I want to get started
20:22 - with the content because a little bit
20:23 - behind all the things I want to do it
20:24 - next week is nature of Code times so I
20:28 - need to move on from some of the machine
20:30 - learning stuff although it will circle
20:32 - back to it because some of the stuff in
20:33 - nature of code towards the end uses AI
20:37 - but so I'm gonna do as much as I can
20:40 - today on some of the ml 5 stuff that
20:42 - I've been doing and see where I get
20:43 - thank you Oliver for posting the store
20:46 - link in the chat and that's that so if
20:50 - you will bear with me Oh watch my
20:56 - glasses it should just take a minute and
20:58 - I'm gonna put on intermission animation
21:01 - this is not actually the intermission
21:03 - though there will be an intermission
21:04 - about an hour to an hour and a half in
21:08 - is so loud
21:15 - [Music]
21:24 - [Music]
21:31 - [Music]
21:38 - [Music]
22:04 - all right I'm back sorry about that
22:07 - I just thinking I might be the first
22:08 - person in the history of universe in the
22:10 - universe to say watch watch watches
22:16 - their class yes I went down to the lake
22:18 - with my washing board all right so one
22:40 - more thing I wanted to attempt to do
22:43 - which is I always like to show community
22:45 - contributions I'm going to go to coding
22:49 - challenges gar IO a new one came in from
22:53 - David which is here so tic-tac-toe with
22:58 - friends so I would like to return to
23:03 - doing more some more content and
23:10 - examples with WebSockets which is a way
23:13 - of having a way of having a continuous
23:18 - real-time network connection from the
23:22 - browser from JavaScript and I did a
23:25 - shared whiteboard and I look out of
23:29 - focus I'm gonna I'm gonna examine that
23:31 - again I did a shared whiteboard I did
23:33 - this sort of agario Agora IO and how to
23:36 - say it example and let's look at this
23:38 - and then I did tic-tac-toe challenge I
23:40 - didn't do that let's take a look so my
23:41 - name is a coding train and then I don't
23:45 - know if this matters but I'm gonna just
23:47 - not show you the secret code I'm going
23:49 - to put in to join the game in case that
23:52 - makes it like sort of hackable in some
23:54 - way so now I put pacing in that code I'm
23:57 - hitting join game join game oh I don't
24:05 - see where oh there is no open game did I
24:07 - already join it hello Oh
24:13 - oh wait I'm in it I'm in it okay laptop
24:15 - come back
24:16 - alright I'm now in the game uh-oh X's
24:20 - turn I'm oh uh oh it's gone again we
24:25 - found a bug I failed I failed
24:35 - he had the focus is up is it just like
24:38 - drifting the focus let's try it one more
24:41 - time
24:41 - where'd I put my focus device it's weird
24:47 - I could put it on to autofocus I thought
24:51 - that that's going to cause more problems
24:52 - than oh and I'm oh okay yes I'm so not
25:16 - yeah I can see that it's out of focus
25:27 - that's better
25:37 - all right I don't know I don't know I
25:43 - don't know all right sorry David I
25:55 - messed up in the discord thank you okay
26:04 - we'll try again later but you should
26:07 - make your commute let's see I don't
26:09 - think the to the latest video I released
26:11 - by the way is under the ml5 beginner's
26:14 - guide playlist and it should be down
26:18 - here ml5 pose regression I don't think
26:22 - there any oh there are oh you know it
26:24 - this is a mistake actually here's a bug
26:26 - bug report I'm not sure why this
26:29 - happened but this particular video ml5
26:34 - pose regression and this pose classifier
26:38 - one oh no no no no oh no yes yes they're
26:43 - showing the same community contributions
26:45 - so there is a way for that that's
26:48 - supposed to happen and and actually so
26:54 - is this one maybe that's okay actually
26:55 - so maybe that's the point
26:57 - so maybe the all of the pose videos
27:00 - should have the same community
27:02 - contributions that's a nope - now I
27:04 - don't know if that's a bug report that's
27:05 - an open question focus or not I have to
27:12 - resolve this you know where is the focus
27:18 - does this look more in focus am I
27:22 - getting more or less in focus as I come
27:25 - forward from like this is back middle
27:31 - forward middle back where is the focus
27:35 - the best worst or am I just like way all
27:38 - too much in my head and I'm fine
27:53 - [Music]
28:02 - [Music]
28:09 - [Music]
28:16 - [Music]
28:38 - oh it's really going well today I'm
29:23 - trying to give myself a reference point
29:31 - [Music]
29:34 - I was expecting some messages about the
30:01 - focus but I didn't get any
30:04 - that's loves like let me go through the
30:06 - whiteboard for a minute
30:07 - you got blurred I be not I saw like a
30:15 - math blank was typing and sarcasm as a
30:18 - service was typing but then no messages
30:21 - appeared I'm gonna give this one more
30:30 - shot this can I focus on have an idea
30:41 - have an idea
30:46 - we try the train whistle I really need
30:51 - to figure out tricks I need to figure
30:53 - out how to zoom the camera in used like
31:00 - I don't know what button will do that
31:01 - for me on this camera so I'm like
31:03 - looking really closely at the screen
31:05 - that's way out of focus I used to be
31:17 - able to zoom the camera way way way way
31:19 - way in and then on the confidence
31:21 - monitor I could really see it it's just
31:26 - better
31:48 - and that's out of focus I'm gonna get
31:54 - this I mean a soft focus might be good
31:58 - for me I think that's a little bit
32:03 - better can come over here no that's like
32:09 - totally blurry so weird what is going on
32:14 - I'm losing my mind this always happens
32:25 - to me
32:37 - it's weird with the camera today I think
32:40 - some settings changed on this camera I
32:44 - wonder if somebody people have been
32:46 - using this room and maybe settings got
32:53 - changed hold on let's see is it auto
32:57 - focusing oh it's on auto focus so the
33:02 - camera gotcha somebody changed to semi
33:05 - it's on auto focus I oh maybe I'm not
33:10 - oh I'm not scrolled all the way down on
33:11 - discord oh I'm not scrolled all the way
33:15 - down oh no wonder
33:28 - I'm nods good all right so I've
33:30 - determined the problem this this room
33:34 - has been used and the camera settings
33:37 - were changed ah right
33:49 - I'm not crazy it's on a foot is it Auto
33:51 - focusing on me
34:10 - yeah I know everybody's saying you want
34:13 - me coding but I I have a problem and I
34:16 - have to address it
34:21 - yeah it's autofocusing right so how do I
34:26 - change it back to manual I can't see the
34:30 - back of the camera I don't know what to
34:34 - do about this is
34:40 - alright I'm caution to the wind
34:43 - everybody a little I'm just gonna go I
34:45 - just got to go for it go
34:51 - behind-the-scenes action here so I can
34:56 - see the camera settings and also really
35:02 - test this autofocus theory oh yes yeah
35:14 - all right I'm gonna switch it to manual
35:17 - focus menu
35:21 - [Music]
35:41 - it says manual focus
35:52 - that was wrong about that oh this is
35:59 - autofocus this is what autofocus looks
36:02 - like maybe I should try it on auto focus
36:20 - it was not an autofocus I'm really
36:23 - interesting I think I need to go to the
36:29 - eye doctor that's the worst let's
36:33 - actually just try it on auto focus for a
36:35 - second not gonna tighten it in place
36:37 - this is this is now how to focus does it
36:45 - do a good job of finding me in autofocus
36:47 - so let's just pretend I'm coding for a
36:49 - little bit like I'm walking around and
36:52 - I'm tukya I'm talking about the coding
36:55 - I'm type type type in the coding type
36:59 - type type in the coding hey it's on
37:01 - autofocus is that actually like sort of
37:04 - staying in focus as I move around and
37:06 - talk talk talk about the code stuff I
37:16 - feel like actually the autofocus looks
37:18 - pretty sure auto focus or the wind I'm
37:23 - gonna wait for the
37:33 - so it's been brand Lmax Simon does not
37:37 - like the autofocus
37:51 - no it's blurry as hell so the autofocus
37:58 - was not good it seems to be good when
38:02 - I'm up here
38:17 - people I really do I really I realize
38:19 - everyone's having fun I really need help
38:20 - with this because I can't both stream
38:24 - and see and I haven't had this issue
38:26 - before and I can I have to change the
38:29 - settings on the camera I have to pull it
38:30 - all the way out from the wall which is
38:32 - not a great setup Oh brand Lmax saying
38:35 - it was good okay
38:36 - I mean the cameras in the wrong place so
38:41 - the moving is not in issues because the
38:44 - moving is it's because I didn't tighten
38:49 - it so that I'm not worried about it is a
38:55 - little bit and let me I need to get the
39:10 - level
39:24 - okay only if you're not in screen it
39:26 - jumps around so on autofocus right now
39:28 - which is what I think I'm gonna do I
39:30 - mean so let me just level the camera
39:42 - that's just not level right now which
39:49 - way is level
39:58 - that's level loosen it actually again so
40:06 - I can actually that's actually better
40:10 - for it to be pointed up because I can
40:14 - raise the desk
40:15 - thank you all for bearing with me I'm
40:23 - tightening it in place
40:39 - okay
40:47 - okay I think I have to get started I'm
40:53 - sorry everybody
40:53 - oh we were having fun till I ruined
40:58 - everything
41:15 - I saw an autofocus now
41:27 - I can't believe someone just joy
41:31 - interesting it does seem to asking me
41:42 - too
42:03 - well oh my god what just happened okay
42:14 - I have it locked what did it just do oh
42:18 - I'm so in focus right now I'm losing my
42:21 - mind
42:25 - I'm very very in focus and if I move
42:34 - over here I'm still in fact alright this
42:37 - is good I think if I'm still and which I
42:39 - am for most of the time it focuses
42:41 - better alright I have to give up on the
42:45 - focus and this is just gonna be good
42:46 - enough am I about the same size as I
42:50 - usually have just randomly changed a
42:52 - little it doesn't really matter because
42:56 - yeah I do see the laptop moving around I
42:59 - think though if I stay mostly I mean I
43:02 - do move around a lot but I don't move
43:07 - around a lot I don't know what just
43:08 - changed but it's like totally in focus
43:10 - now interestingly I do think that maybe
43:18 - some of the settings on the camera did
43:20 - change and I will investigate that at
43:23 - some point all right oh we mentioned I'm
43:28 - gonna get started I apologize to
43:31 - everyone it's ty can't believe this
43:32 - 10:15 I do have two hours left so it
43:36 - should be time for me to do some stuff I
43:39 - do want to mention one thing which is
43:41 - that I did make another coating in the
43:45 - Cabana video about the hilbert curve so
43:48 - if you were waiting for that stay tuned
43:51 - I programmed this particular continuous
43:54 - space-filling curve it makes a lovely
43:57 - example I also did something where I
43:59 - used Pross the alpha version of
44:03 - processing for there's a you're a little
44:06 - too high there's a purple line at the
44:09 - bottom okay yeah yeah thank you that's
44:13 - that's easy to fix
44:15 - position
44:16 - why's that
44:19 - Oh weird I'm less concerned with that
44:24 - stuff because Matthew when we edit we
44:28 - can fix that but I think I have now
44:33 - fixed it okay
44:44 - all right putting everything to side I
44:48 - am now going to talk about
44:51 - conflation of neural networks Oh my
44:54 - brain was sucked in the headspace for
44:56 - this and I've lost it a little bit okay
45:45 - looking here okay yeah these are the
45:49 - these are the links I'm interested in
45:55 - and these are slides and this is the
46:08 - example I made before and then I'm
46:16 - looking for us this particular post it's
46:19 - a really excellent one oh this was the
46:24 - diagram yeah
46:25 - yeah okay
46:34 - okay
47:01 - Wow focus is life's better than it's
47:04 - ever been
47:05 - I'm so focused I am focused on the task
47:08 - at hand
47:09 - [Music]
47:23 - I always get this thing where people say
47:30 - and an Ashwin just said it that I look
47:32 - like a character from the show called
47:34 - money heist which I've never watched
47:35 - maybe I need to watch that or maybe I
47:37 - just act like that character I don't
47:39 - know hello and welcome to hello welcome
47:54 - to another beginner's guide to machine
47:56 - learning with ml5 jazz video and in this
47:58 - video I am going to talk about something
48:00 - called a convolutional neural network
48:03 - what is a convolutional neural network
48:05 - what are the new operations in a
48:07 - convolutional neural network that are
48:09 - different from the kinds of neural
48:11 - networks we've looked at and I've talked
48:12 - about before and how can this particular
48:16 - example which I made in a previous video
48:18 - that just takes the pixels of an image
48:21 - feeds them into a plane neural network
48:24 - so to speak I'm not a convolutional
48:26 - neural network what would happen if I
48:28 - changed it to a convolutional neural
48:30 - network would it perform better what
48:31 - would what what what are the outcomes
48:35 - that's the point of this video that I'm
48:38 - making let me start by looking at let me
48:48 - start by diagramming the kinds of neural
48:51 - networks let me start by diagramming the
48:55 - neural networks that I've used before
48:59 - let me start by diagramming the neural
49:02 - networks that I've used in some of my
49:11 - let me start by diagramming what the
49:14 - neural networks looked like with ml5
49:17 - neural network to date and all in the
49:19 - videos that I've made so there's been
49:21 - two layers a hidden layer and an output
49:26 - layer and then also there's some data
49:29 - coming into the neural network and in
49:31 - this case in the previous example it was
49:35 - an image
49:36 - which was flattened so I use the example
49:40 - of 10 by 10 pixels each with an R a G
49:45 - and a B so that made an array of of 300
49:50 - inputs all these all these pixel values
49:53 - those are the inputs and those go into
49:56 - the hidden layer but just for the sake
50:09 - of argument let me simplify this diagram
50:12 - and I'm just going to consider an
50:14 - example with 4 inputs I'm going to
50:18 - consider that example as having 5 hidden
50:20 - nodes hidden units and then it's let's
50:25 - say it's a classification problem and
50:27 - there's three possible categories a
50:31 - vanilla no sorry us the ml 5 neural
50:35 - network by default creates so this has 4
50:42 - inputs 3 outputs and 5 I don't know if I
50:48 - need that so when I call the function ml
50:57 - 5 neural network it creates this
51:04 - architecture behind the scenes and
51:06 - connects every single input to every
51:09 - hidden unit and every hidden unit to
51:12 - each output
51:34 - twit hi
51:53 - so this is what the neural network looks
51:55 - like each one of these connections has a
52:00 - weight associated with it each neuron
52:03 - receives the sum of all of the previous
52:07 - inputs to it in the previous sir each
52:10 - each unit receives the sum of all of the
52:15 - inputs times the weights passed through
52:17 - an activation function which then
52:19 - becomes the output which then all of
52:21 - those with those weights are summed into
52:24 - the next layer and so on and so forth so
52:31 - this is what I have worked with before
52:41 - the whiteboard camera is skewed no no
52:44 - it's fine it's fine it's fine I can't be
52:52 - bothered to like fix the cameras anymore
52:55 - let me use my level did you have a level
52:57 - here and let's just see it's pretty it's
53:02 - not so bad oh it is skewed I can I can I
53:05 - can turn it a tiny bit that's gonna make
53:09 - it a little bit better okay yeah that's
53:14 - better all right
53:34 - while in the previous example I was able
53:37 - to get this kind of architecture to work
53:40 - with image input and get results that
53:44 - that produced something if the output
53:47 - this can be improved upon and the reason
53:50 - why this can be approved upon is there
53:52 - is an aspect to this data that's coming
53:55 - in that that is lost there is there is
54:00 - there is information in this data that's
54:03 - coming in that is lost when it is
54:05 - flattened to just a single flat array
54:11 - and the information that's lost is the
54:16 - relative spatial orientation of the
54:19 - pixels it's meaningful that these colors
54:21 - are near other colors something in what
54:24 - we're seeing in the image has to do with
54:26 - the spatial arrangement of the pixels
54:28 - themselves in two dimensions at so
54:33 - there's um in order to address that we
54:39 - want to add into this architecture I
54:42 - really spent a lot of time drawing this
54:43 - diagram which I've now good at mostly a
54:45 - race which is also a hidden layer
54:50 - anything in between the inputs and
54:52 - outputs is a hidden layer but we want to
54:54 - add something called a convolutional
54:56 - layer so in this video I want to explain
54:59 - what are the elements there are units
55:02 - nodes neurons so to speak in a
55:06 - convolutional layer but what are they
55:09 - and one of the word that's typically
55:11 - used is actually called a filter which
55:13 - makes a lot of sense now convolutional
55:15 - neural networks can be applied to lots
55:17 - of scenarios besides images and there's
55:20 - a lot of research into different ways
55:22 - that they can be used effectively but
55:23 - I'm gonna stick with the context of
55:26 - working with images because the word
55:28 - filter really fits with that we're
55:30 - filtering an image how is this layer
55:32 - filtering an image
55:43 - there's another step here called Knoll
55:46 - implement I'll come back to it all right
56:04 - pretty sure that
56:13 - so much your fact-check for this for me
56:15 - but this is
56:29 - now the idea of a convolutional layer is
56:32 - not a new concept it dates back to the
56:37 - it predates this deep learning boom so
56:41 - to speak boom this other so the idea of
56:46 - a convolutional layer is not a new
56:47 - concept and it predates this era that
56:51 - we're in now a so called deep learning
56:52 - and in fact if you want to like go back
56:54 - and find the and if you want to go back
56:57 - and find the and if you want to go back
57:03 - and look at the origins of convolutional
57:07 - neural networks you can find them in
57:08 - this paper called gradient based
57:10 - learning applied to document recognition
57:12 - from 1998 section two convolutional
57:21 - neural networks for isolated character
57:23 - recognition convolutional networks and
57:27 - here we can see this diagram which is
57:32 - I'm attempting to kind of talk through
57:34 - and create my own version of over here
57:37 - on the whiteboard itself I think
57:44 - someone's at the door hi looking for
57:50 - something
57:50 - ah okay this is a recording studio
57:58 - that's actually live live broadcasting
58:01 - yeah no problem okay
58:10 - I probably should have muted my
58:14 - microphone before I answer the door
58:32 - this is also the original paper
58:34 - associated with the EM mist dataset a
58:38 - dataset of handwritten digits that's
58:40 - been choose umpteen amounts of times in
58:44 - research papers over the years related
58:46 - to machine learning
59:01 - this is another yeah okay so this is
59:07 - what I want to talk about next which I'm
59:09 - going to come back to okay
59:33 - okay
59:36 - let's go back let's I know I'm going
59:42 - back and forth a lot here but let's go
59:43 - back to thinking of the input as a
59:45 - two-dimensional image itself so this
59:47 - two-dimensional image and let's not say
59:51 - it's ten by ten let's use what the Emnes
59:53 - data set is which is a 28 by 28 pixel
59:56 - image and of course now much higher
59:58 - resolution images are used and this is
60:01 - what is coming in to the first
60:03 - convolutional layer this image is being
60:06 - sent to every single one of these
60:08 - filters the filter is a the filter is a
60:16 - matrix of numbers and it can be the
60:24 - matrix is the fill a filter is a matrix
60:26 - of numbers and let's just for example
60:29 - let's have a three by three matrix so
60:31 - each one of these filters represents
60:37 - [Music]
60:40 - each one of these filters represents
60:42 - nine numbers a matrix that's three by
60:45 - three you could have a five by five
60:46 - filter or and so on and so forth but is
60:50 - sort of standard size or a nice example
60:52 - size for us to start with is three by
60:54 - three each one of these filters is then
60:59 - applied to the image each one of these
61:08 - filters is then applied to the image
61:10 - through a convolutional process this by
61:16 - the way is not this by the way is not a
61:21 - concept exclusive to machine learning
61:23 - this idea of a convolutional filter to
61:26 - an image has been part of image
61:28 - processing in computer science and
61:30 - computer vision algorithms for a very
61:32 - long time to demonstrate this let me
61:35 - actually open up I can't believe I'm
61:36 - gonna do this but I'm gonna open up
61:38 - Photoshop
61:51 - sign in oh I have a creative cloud
61:56 - account hold on a second I didn't think
61:58 - I'd have to sign in to legit you're
62:07 - gonna watch apex legends videos now when
62:10 - I'm here talking about convolutional
62:12 - neural networks okay um Adobe oh no
62:25 - that's the wrong or oh I have to like
62:29 - login wait I wonder if I log in it's
62:33 - through my NYU account just give me a
62:35 - second here let me try to login
62:40 - [Music]
62:47 - I just want to show you this this is
63:21 - such a fail I do have an Adobe Creative
63:23 - Cloud account
63:24 - I very lucky to have that through New
63:26 - York University I logged it to by NYU
63:30 - account
63:35 - let's just do that figure out how to log
63:56 - in properly so what I want to do is
64:04 - let's get an image
64:15 - this is how I it's way too vain - all
64:21 - right whatever let's let's get an image
64:23 - of a kitten and more settings where's
64:30 - that thing - usage rights labeled for
64:36 - reuse with modification
64:46 - actually I should get the quick-draw I
64:49 - should
64:57 - maybe I should I thought let's use the
65:01 - kitten okay what you can't go wrong with
65:04 - a kitten
65:11 - didn't I just download this kitten
65:17 - let's do this doesn't hurt to have the
65:21 - high-resolution one for Photoshop save
65:28 - image
65:51 - oh my god I never never been so
65:55 - difficult to open a kitten image I don't
65:58 - need to uh I mean I do need to learn
65:59 - Photoshop all right
66:13 - now in Photoshop you might notice
66:15 - there's a filter menu why because all of
66:18 - many now in Photoshop so here I have in
66:23 - Photoshop and I've opened this image of
66:24 - a kitten and there's a menu option
66:26 - called filter this word is not filter by
66:28 - accident it's not called filter by
66:31 - accident over here either there's a
66:34 - connection so all of these types of
66:36 - operations that you might do for example
66:37 - like blur an image these are filters
66:41 - convolutions applied to the image I'm
66:44 - gonna go down here under other and
66:46 - select custom all of a sudden you're
66:50 - going to see here I have this matrix of
66:54 - numbers this matrix of numbers in
66:56 - Photoshop is exactly the same thing as
67:01 - this matrix of numbers I'm drawing right
67:04 - here each one of these filters in the
67:08 - convolutional layer represents a matrix
67:12 - of numbers that will be applied to the
67:13 - image so let me actually just put some
67:15 - numbers in here
67:45 - I know how easy that is to see if I I
67:48 - mean this shouldn't if I do this does it
67:52 - actually make it yeah
68:25 - I'm looking at the chat
68:44 - this particular set of numbers happens
68:47 - to be a filter for finding edges in an
68:50 - image and you can think of it as these
68:53 - are all weights for a given pixel so for
68:56 - any given pixel I want to subtract
68:58 - colors that are to the left of it and
69:00 - emphasize colors that are at that pixel
69:03 - and above and below this draws out areas
69:07 - of the image where the neighboring
69:09 - pixels are very very different
69:11 - interestingly enough I could switch
69:13 - these to 0 and these to negative 5
69:23 - can you see the difference let me do it
69:25 - top let me do actually I think would
69:27 - actually be better for me to show you
69:28 - like like do one above
69:40 - whoa
69:44 - yeah
69:49 - switching the convolution to have the
69:52 - negative numbers on the top sorry
69:54 - switching the filter to have the
69:55 - negative numbers on the top you can see
69:57 - now I'm still detecting edges but I'm
69:59 - detecting horizontal edges if you go
70:02 - back and look at the cat that I had
70:04 - previously versus this one you can see
70:05 - vertical edges versus horizontal edges
70:07 - so there are known filters which draw
70:10 - out certain features of an image and
70:16 - that's exactly what each one of these
70:19 - filters does if all of the nodes of a
70:22 - neural network can draw out and
70:24 - highlight different aspects of an image
70:27 - those can be weighted to indicate and
70:30 - classify the image in certain ways the
70:35 - big difference here the big difference
70:37 - between a convolutional layer in a
70:39 - neural network and what I'm doing here
70:43 - by hard coding into known filters is a
70:47 - neural network is going is that the
70:49 - neural network is not going to have
70:51 - filters hard-coded into them it's going
70:53 - to learn filters that do a good job of
70:57 - identifying features in an image so this
71:07 - relates to the idea of weights I think
71:09 - so if I if I go back to my previous
71:11 - diagram
71:19 - where every single input is connected to
71:22 - each hidden note where every single
71:26 - input is connected to each hidden neuron
71:28 - with a weight now the input image is
71:32 - connected to every single one of these
71:34 - filters and the weights are are the in a
71:40 - way there are now nine weights for every
71:43 - single one instead of learning goal
71:45 - weight it's going to learn a set of
71:47 - weights for an area of pixels to
71:49 - identify a feature in the image all of
71:57 - those all of these filters will start
71:59 - with random numbers all of these filters
72:04 - will start with random values and then
72:07 - the same gradient descent process the
72:11 - error back propagated through the
72:13 - network adjusting all the dials
72:14 - adjusting all the weights in these
72:16 - matrices and all of these filters works
72:18 - in exactly the same way exactly works in
72:22 - the same way so in the ml five series I
72:30 - haven't really gone through and looked
72:32 - at the gradient descent learning
72:33 - algorithm to adjust all the weights in
72:35 - detail I do have another set of videos
72:37 - that do that if you're interested but
72:39 - the same gradient descent algorithm that
72:41 - is applied to these weights is applied
72:43 - to all of the different values in each
72:45 - of one of these filters
72:55 - okay anybody watching this one add one a
73:02 - show Gaussian blur filter yeah me
73:06 - actually that's actually kind of a
73:07 - useful one to do I'm not going to show a
73:10 - Gaussian blur one one one one one one
73:15 - one one one oh it doesn't do I do this
73:21 - uh yeah okay this is like dividing by so
73:27 - how do i oh yeah
73:41 - oh yeah no I see it down there
73:47 - incidentally just to show a very common
73:50 - convolution album to album incidentally
73:54 - just to show a very common convolution
73:56 - operation to blur an image blurring an
73:59 - image is taking the average of a given
74:02 - pixel and all of its neighbors so here
74:04 - you can see if I give the same weight to
74:06 - a 5x5 matrix of pixels around a center
74:09 - pixel and then divide that scale is
74:11 - divided by 25 because there's 25 that's
74:13 - averaging all the colors if I click on
74:16 - preview blurred not blurred blurred not
74:19 - blur of course there are other more
74:21 - sophisticated convolutions like a
74:24 - Gaussian blur you can take a look at
74:26 - Gaussian blur and some ways to pronounce
74:27 - it you could take a look and research
74:29 - what that is but again I'm not going
74:32 - down the road to look at common image
74:34 - processing convolutions instead talking
74:36 - about that concept of a convolution as
74:38 - applied to an image in the process of a
74:41 - convolutional neural network middle one
74:48 - should be - it doesn't need to be George
74:52 - it could be if I wanted it to have a
74:54 - higher weight but it doesn't mean
74:57 - there's no right or wrong answers to
74:59 - this as far as I'm concerned kittens and
75:01 - kittens are getting to get into Guinness
75:03 - alright so here's the thing I want to
75:05 - take a small digression here and program
75:08 - the convolution algorithm sort of
75:10 - outside of a neural network you can't
75:12 - tell the difference I can tell the
75:18 - difference there maybe maybe you need to
75:22 - like look at it at super high much
75:24 - higher resolution was that not an
75:29 - effective demonstration let me say this
75:32 - I wish it would like up it's always
75:37 - previewing it here
75:43 - zoom in on a little bit more yeah just
75:46 - to serve that zoomed in a little more I
75:49 - mean Matt sure can do his own zooming
75:53 - when we edit it but if this is helpful
75:55 - to record this okay if you're watching
76:00 - it on your phone I can't help you yeah
76:02 - okay
76:05 - it is a subtle blur all right let me go
76:13 - out of here and let me get let me get
76:24 - something here
76:29 - where's this example
76:39 - okay so like how these are
76:56 - through the second one
77:06 - save in the save cat oh no stop stop I
77:16 - put it in draw sorry about that just
77:19 - want one cat image this one so let me go
77:27 - back to here duplicate this convolution
77:34 - I don't know why I started with this
77:40 - example but
77:45 - oh it's no P image
78:02 - you
78:21 - I actually don't need the ml5 library
78:24 - for this I'm like a little bit a little
78:29 - bit silly would I why do plants
78:44 - let's do with this okay
78:52 - I'm going I'm just setting up the base
78:56 - coat I'm going to start with cat equals
78:59 - load image cat dot PNG and now let's
79:07 - draw
79:20 - and
79:27 - okay
79:30 - okay
79:37 - where are we 10:50 all right so today
79:40 - I'm gonna do this convolution example
79:42 - and then take a short break I'm out of
79:48 - my copier so our knob is asking why 280
79:52 - times 2 because the example I'm going to
79:54 - make is going to show the image and then
79:56 - the convolution applied to it okay
80:14 - just to take this Oh
80:16 - just to take this a little bit further
80:18 - going on my hair they seem like a weird
80:22 - like line see it over here this in my
80:26 - anyway just to take this a little bit
80:31 - further I'm going to demonstrate how to
80:34 - code the convolution algorithm in p5.js
80:37 - in truth ml 5 and tensorflow GS are
80:40 - going to handle all of the convolution
80:42 - operations for us and creating all the
80:44 - filters we're just going to configure a
80:45 - convolutional layer from a high level
80:47 - but I think it's interesting to look at
80:49 - how you might code an image processing
80:51 - algorithm in p5 I have some videos that
80:53 - do things like this previously but let's
80:55 - look at it in this context so I took a
80:58 - very low resolution 28 by 28 image of a
81:01 - cat this comes from the quick-draw
81:03 - dataset which I've made videos about
81:05 - before and I will also use to see if we
81:07 - can create a doodle classifier as part
81:09 - of this series and all I want to do is
81:13 - apply a convolution to that image so
81:18 - first I'm going to create a variable and
81:20 - I'm going to call it filter so this is
81:22 - going to be our filter and I'm going to
81:24 - make it a two dimensional array so let
81:28 - me just put all zeros in it to start
81:41 - you
81:44 - so this is the filter and let's go with
81:47 - that one that looks for edges
82:09 - let me make a separate image that is the
82:12 - same resolution as the cat image but oh
82:16 - you know what's interesting here I just
82:18 - realized something weird that's going on
82:20 - I'm not actually blowing up the 28 by 28
82:22 - you created it to 80 by 280 image with
82:25 - like big blocks in it it's a little bit
82:29 - weird let me let me fix that I think if
82:37 - I do adjust I think it's gonna be more I
82:42 - don't let me just change this to 28 by
82:45 - 28 hit save and that's really the
82:50 - drawing of the cat then let me delete
82:55 - this one add file re-upload it so now if
83:05 - I do this again we're gonna see just the
83:07 - little cat up there which is what I want
83:09 - but I want to draw it at
83:19 - all right that's a little blurry hmm
83:22 - now I have to start this whole thing
83:24 - over why did it because it's trying to
83:27 - smooth it there we go okay this looks so
83:39 - the code is gonna kind of like change a
83:43 - teeny bit in the middle of this video
83:44 - but that's fine
83:55 - the cat image itself is just 28 by 28
83:58 - pixels I'm using a very low resolution
84:00 - version of that drawing but I'm drawing
84:02 - it I'm drawing it 10 times the size the
84:12 - cat image is actually quite low
84:13 - resolution just 28 by 28 pixels but I'm
84:15 - drawing it at twice the size I want to
84:17 - write the code to apply this filter to
84:19 - the image and draw the filtered image to
84:22 - the right
84:36 - I'm gonna create a variable called dim
84:38 - for dimensions and just call this 28
84:55 - Oh and then I that I'm all out of order
84:59 - here but and then I want another
85:00 - variable to store the filtered image and
85:07 - in setup I can create that image
85:17 - so this creates a blank image at the
85:20 - same this creates a blank image of the
85:22 - same dimensions as the original cat
85:24 - drawing then I can write a loop
85:47 - and this loop is going to look at every
85:51 - single pixel from for all the columns X
85:54 - and all of the rows why I wrote int
85:56 - there because I am half the time
85:57 - programming in Java but one thing that's
86:04 - important here if we're going to take
86:06 - this 3 by 3 matrix and apply it to every
86:10 - single pixel of the original image if
86:12 - we're applying it to that first pixel 0
86:14 - 0
86:14 - there's no pixel to the left and no
86:16 - pixel above it it doesn't have all of
86:18 - its neighbors so there's various ways
86:20 - around this but I'm just going to start
86:22 - with I'm gonna I'm just gonna ignore all
86:26 - the edge pixels so this loop will go
86:36 - from so the loop will go from 1 to
86:40 - dimensions minus 1
86:48 - and stop using this autoformat okay
86:58 - now there's a lot more work to be done
87:01 - here just to apply this filter to any
87:04 - given pixel crime thing
87:27 - I think a way that might make sense to
87:30 - do this is to actually have a new
87:32 - function I would call the function
87:37 - filter let's just call it convolution
87:39 - I'm gonna write a function called
87:41 - convolution it receives an image an X
87:47 - and a Y and a filter and it returns a RG
88:00 - it returns a new color so the idea of
88:03 - this function is it receives ooh why did
88:08 - that shut off
88:18 - I'm turning that fan on is that it
88:28 - receives all the things that needs it
88:30 - receives the original image the filter
88:32 - to apply to it which particular pixel we
88:34 - want to process and then we'll return
88:36 - back to new RGB value after that after
88:39 - that pixel is processed and the reason
88:46 - why I'm doing that in a separate
88:47 - function is I need another nested loop
88:49 - to go over the filter so I need to go
88:52 - from I need to go to eat I need to go
89:00 - from 0 to 3 0 1 2 columns in the filter
89:04 - 0 1 2 rows in the filter and we're
89:08 - beginning to be quite a lot had 4 nested
89:11 - loops right in here now I probably
89:17 - shouldn't have some of this hard-coded
89:18 - in here the number 3 and that sort of
89:20 - thing but you can imagine how you might
89:22 - need to use variables if the filter size
89:24 - is flexible
89:34 - the Auto formatting of the editors
89:36 - driving me crazy okay
89:59 - there should be this yeah
90:03 - I'll leave I'll fix that later this is
90:06 - wrong there are 500 people watching no
90:16 - now now we have it really sort of like
90:22 - sad fact which is true about most cases
90:26 - where you're doing image processing with
90:29 - some framework and in this case our
90:31 - framework is JavaScript in canvas and
90:33 - p5.js and the sad fact is though even
90:36 - though all of this is built up all this
90:40 - discussion is built upon the fact that
90:41 - we are retaining the spatial orientation
90:44 - of the pixels we're thinking of it as a
90:46 - 2-dimensional matrix of numbers the
90:49 - actual data is stored in one array and
90:52 - so I've gone over this in probably
90:54 - countless videos but there's a simple
90:56 - formula to look at if I have a given X Y
90:59 - position in a two dimensional in a two
91:04 - dimensional array in a two dimensional
91:09 - matrix how do I find the one dimensional
91:12 - look up into that matrix assuming that
91:15 - the pixels were counted wrote by rows 0
91:18 - 1 2 3 4 5 6 7 8 about next row you know
91:20 - twenty eight twenty nine 20 31 and that
91:24 - formula is let index well I need to do
91:29 - that before this nested loop because I'm
91:31 - looking at that right now I just want
91:32 - the center pixel that XY let index equal
91:36 - X plus y times image dot with so this is
91:42 - the foreman you think about it makes
91:43 - sense right because it's all the X's and
91:45 - then the offset along the Y's is how
91:48 - many rows times the width of the image
91:50 - but there's another problem which is
91:53 - that in JavaScript in canvas for every
91:57 - single pixel in this image there are
91:59 - actually four numbers being stored an R
92:01 - a G a B and an alpha the red green and
92:04 - blue channels and the alpha channels
92:07 - channel singular so each pixel takes up
92:11 - four spots so this index actually needs
92:14 - to say times for it so guess what
92:17 - you know what's gonna make a lot of
92:18 - sense I'm gonna need this operation a
92:19 - lot let's write a function for it index
92:23 - I'll just call it index and it receives
92:25 - an X Y and a width and it returns you
92:31 - know what the width is never gonna
92:33 - change in my sketch so I don't want to
92:36 - be so crazy as to have to pass it around
92:38 - everywhere so let's just gonna pull it
92:41 - from a global variable return X plus y
92:45 - times image dot width and that's not
92:47 - image it's cat dot with okay so once
92:50 - again this is terrible what I'm doing
92:51 - but I'm just saving myself a little bit
92:53 - of heartache here and there so this
92:55 - index ooh mmm let's call this this pixel
92:59 - is okay this should be x for this pixel
93:07 - is that function index XY ah
93:14 - I keep auto formatting and it does this
93:16 - thing that's fine I'll leave that there
93:17 - it's it's gonna be what its gonna be
93:22 - somebody must have shared this live
93:24 - stream because the viewership did just
93:25 - jump up really high and I wonder why
93:31 - okay
93:42 - now I have something I could do to
93:45 - simplify this but I might as well write
93:47 - the code for if this were a full RGB
93:49 - image this is a grayscale image but it
93:51 - has all the channels in it so what I
93:53 - need to do to perform this convolution
93:55 - operation if you go back and think about
93:57 - the Photoshop example that I showed is I
93:59 - need to add up all of the pixel values
94:03 - of the thing that I need to do to
94:06 - perform this convolution operation is to
94:09 - take all of the weights the numbers that
94:13 - are in the filter matrix and I need to
94:15 - multiply each one times the pixel value
94:19 - of all of the neighbors and their
94:20 - corresponding locations add them all up
94:22 - together and maybe divide by something
94:25 - if I'm if I want to sort of like average
94:26 - it out but in this case I actually don't
94:29 - want to divide by anything I'm just
94:30 - gonna leave the weights or the weights
94:31 - or the weights are their weights
94:41 - and actually this right here is
94:43 - irrelevant I don't know I need to do
94:45 - this inside the loop you'll see in a
94:46 - second I think it's gonna make sense so
94:48 - I need some I'm gonna make a sum of all
94:50 - the R values a sum of all the green
94:54 - values and a sum of all the blue values
95:00 - then I need to get the R so now I need
95:03 - to get the pixel which is this is not 0
95:07 - to 3 oh yes it is I'm looking up in the
95:10 - filter oh yeah all right wait a sec wait
95:14 - a sec wait a sec let's actually I think
95:16 - this is gonna be make more sets look go
95:18 - from negative 1 to 2 you'll see why let
95:21 - me - I'll explain why and negative 1 to
95:23 - 2 let's do that instead and maybe it's
95:25 - more clear to say less than or equal to
95:27 - 1 less than or equal to 1 because and
95:35 - let me draw this diagram once again if
95:39 - this is pixel 0 0 this is pixel negative
95:43 - 1 negative 1 this is 1 comma 1 this is 1
95:47 - comma 0 this is a 1 comma negative 1 I
95:51 - guess I'll do them all
96:01 - right so you can see that the
96:04 - neighboring pixels are offset by
96:06 - negative one and one and negative one
96:08 - and one so the pixel X value is X plus I
96:22 - the pixel y value is y plus J and then
96:29 - the pixel index is call the index
96:33 - function X which returns the actual
96:36 - index into that array for pixel X and
96:39 - pixel Y and actually maybe it makes more
96:41 - sense for me to just say that I don't
96:43 - necessarily need separate variables it
96:45 - might actually be just as clear just to
96:48 - put this right in here okay
96:59 - am I missing chat messages no okay
97:06 - so ombre is asking can't you load grace
97:09 - that images that's grayscale for
97:11 - simplicity I could I absolutely could
97:14 - but I'm gonna just go with this because
97:16 - then me I could also demonstrate this
97:18 - with an RGB image a little bit
97:19 - extrapolate better but yes I absolutely
97:21 - could
97:38 - so now I just need to add the red green
97:41 - and blue values at this particular pixel
97:43 - to the sum so some are plus equal image
97:48 - dot pixels at that pixel index and then
97:53 - G and B G is the next one and B and B
98:02 - blue is the next one and let's add a
98:04 - plus zero here just to be consistent
98:16 - so ultimately what I'm actually
98:18 - returning here is our is some our G is
98:22 - some B and B is some good some of us are
98:27 - G is some g and b sm b so this is the
98:35 - process now of adding up all the pixels
98:38 - I've gone through every single pixel in
98:40 - a 3x3 neighboring area and added up all
98:42 - the reds greens and blues and returning
98:44 - those back guess what though I'm missing
98:47 - the aah why is this camera going off
98:50 - it's not the coding train if the cameras
98:53 - don't just go off every once in a while
98:55 - or all the time
99:04 - but I'm missing the crucial component
99:06 - which is as I'm adding all the pixels up
99:09 - in that area I need to multiply each one
99:11 - by the value in the filter itself
99:22 - incidentally I should also mention that
99:24 - this what I'm the operation that this
99:26 - really is is the dot product and in an
99:29 - actual machine learning system all this
99:31 - would be done with matrix math but I'm
99:33 - doing it sort of like longhand just to
99:36 - sort of see the process and look at it
99:37 - so what's what should I call this in the
99:45 - filter like the factor now I need to
99:49 - look up in the filter I comma I J only
99:53 - here's the thing because I decided to go
99:56 - from negative 1 to 1 negative 1 to 1 the
100:00 - filter doesn't have those index values
100:02 - it goes 0 1 2 0 1 2 so this has to be I
100:05 - plus 1 J plus 1 so it's all six of one
100:10 - half-dozen to the other whether I go
100:11 - from 0 to 2 there and do the offset in
100:13 - the pixels but the point is the pixel
100:15 - array I'm looking actually to the
100:16 - negative and positive to the left and
100:18 - right but the filter is just a three by
100:21 - three array starting with 0 0 in the top
100:23 - left so now I should be able to multiply
100:25 - by factor
100:42 - can I fit this all in one little spot
100:45 - yep
100:53 - and there we go I have the full
100:56 - convolution operation I might have made
100:59 - a mistake here I think this is right
101:00 - when I run it we'll find out if I made a
101:02 - mistake I'm take I'm summing up a 3 by 3
101:06 - neighborhood of pixels all multiplied by
101:10 - weights that are in a 3 by 3 filter oh
101:14 - but I actually have to call that
101:16 - function here now which should be
101:17 - relatively easy because all the work was
101:20 - in there so if I say let I'm just going
101:24 - to call this RGB equal convolution the
101:29 - cap at a given X and y with the filter
101:36 - then the new image which is called
101:40 - filter oh I have to look up it's okay no
101:45 - problem the pixel is index XY and then
101:53 - filter and so I have to look up the one
101:56 - dimensional location in the new image
101:59 - and then at dot pixels at that pixel is
102:07 - the RGB the red value that came back
102:12 - plus zero
102:18 - plus zero plus one plus two green and
102:23 - blue and then if all goes according to
102:30 - plan
102:31 - I should be able to draw the filtered
102:32 - image at offset to the right with the
102:39 - same size I did miss something kind of
102:45 - important which is that if I am working
102:48 - with pixels of an image in p5 I need to
102:51 - call load pixels so cat dot load pixels
102:55 - filter dot load pixels and thence I
102:59 - haven't changed the pixels of the
103:01 - original cat image but since I changed
103:03 - the pixels of the filtered image
103:04 - afterwards then you just call update
103:06 - pixels and now is the moment of truth
103:11 - never never good when I pressed the
103:15 - snare drum button to run the sketch
103:20 - all right well I've already got an error
103:26 - cannot read properly load pixels of Oh
103:33 - filter filter filtered that should be
103:36 - filtered also this isn't right create
103:38 - canvas the size of the canvas is times
103:40 - ten times two times ten remember the
103:44 - image is just 28 by 28 let's try this
103:46 - again a little bit better didn't get any
103:57 - errors I'll see in image where did I go
104:08 - wrong
104:16 - do I need to give it a hard-coded
104:19 - transparency of 255 yes
104:23 - oops so uh it was fully transparent so
104:27 - I'm not pulling the transparency over I
104:29 - could pull it over but I just know I
104:31 - don't want to be transferred
104:31 - look at that look at how it found the oh
104:36 - oh look at this
104:40 - that doesn't look like it's finding the
104:43 - vertical edges pixels that are different
104:47 - to the left looks like it's finding
104:48 - horizontal edges and you know Oh Simon
104:58 - saying do you know that 10 times 2 is 20
105:00 - I know I know
105:03 - Suraj is really asking me to say their
105:06 - name so I guess I have just to get that
105:08 - to stop please don't post things like
105:09 - that I mean I appreciate your kind
105:11 - thoughts but it does fill up the chat
105:13 - but let's say the name Sir Roger schwa
105:16 - so that we can move on okay thank you
105:19 - for all of your support and for watching
105:21 - the channel now the wreath the reason
105:25 - why this is detecting horizontal edges
105:28 - and not vertical ones is because of the
105:30 - way that I'm doing my loop
105:40 - I is first in the loop I don't know why
105:45 - is that I mean if I think of why yeah
105:53 - because if I is the x-value oh it's the
105:59 - yeah yeah yeah the reason why it's
106:06 - finding the horizontal filters rather
106:08 - than the vertical filters is even though
106:09 - I wrote it out this way
106:11 - the inner loop down here is looking at
106:18 - right is yeah but shouldn't it match up
106:32 - I'm like I'm like I my brain is a little
106:34 - fuzzy here no I know I know how to fix
106:37 - it I'm just trying to get the words to
106:38 - explain this why is it doing not doing
106:42 - it because x+ I mean if I is changing
106:45 - cuz I corresponds to the outer the outer
106:51 - array okay yeah so even though I've
106:59 - written it this way so visually these
107:01 - negative ones appear as if they're like
107:03 - a vertical column the inner loop is
107:06 - actually iterating over the the the
107:14 - smaller arrays inside the inner loop is
107:17 - actually entering over for these smaller
107:19 - arrays inside the larger array so I not
107:25 - the inner loop no no one more time with
107:30 - feeling even though even though I've
107:37 - typed this out in a way that visually
107:40 - these negative ones appear in a column
107:42 - it's actually those correspond not to
107:46 - the J index but to the I index so I
107:52 - think one way to fix that would just be
107:55 - to swap it here and and maybe I just
107:59 - like a more elegant way of doing this
108:00 - but this now if I run it this way you'll
108:02 - see ah look at those horizontal edges
108:18 - no need to apologize Suraj I appreciate
108:21 - your interest so now we see how this
108:27 - convolution is applied to the image
108:31 - what's actually happening is to go back
108:34 - for a moment to this neural network
108:36 - process is we don't know what filter is
108:39 - going to produce a meaningful output to
108:41 - recognize what's in the image oh this
108:45 - camera must be overheating I don't know
108:52 - why I'm it's not that hot today 77
108:54 - degrees in this room but we don't know
108:59 - what filter is going to produce a
109:02 - meaningful output in order to recognize
109:05 - or highlight something that's in the
109:07 - image and sometimes we might need
109:08 - multiple filters to highlight different
109:10 - things all right I've got a fan for this
109:20 - in case of emergency so let me blow this
109:24 - fan I think the camera is overheating
109:29 - which usually doesn't happen with this
109:33 - amount of like so hold on I'm just you
109:43 - know just to blow the air around here
109:44 - for a bit it's a little bit loud but I
109:47 - don't want it to you can always process
109:51 - the audio later the difference in the
109:56 - neural network here the convolutional
109:58 - neural network is we're not hard coding
110:01 - in specific filters that we know
110:02 - highlight things in an image the neural
110:05 - network is going to learn what values
110:07 - for the filters highlight important
110:09 - aspects of the image to help the machine
110:12 - learning tasks at hand such as
110:13 - classification so it might draw out you
110:16 - know cats tend to have you know ears
110:20 - that appeared a certain way and this
110:21 - kind of filter like brings that out and
110:23 - then leads to the final way
110:26 - final layer of the network activating
110:28 - with a high value for that particular
110:30 - classification so just to keep my
110:33 - example simulating the neural network
110:34 - process a bit more let's just every time
110:37 - I run it give it a random filter because
110:40 - that's what the layer would begin with
110:41 - just like a neural network begins with
110:42 - random weights and learn to the right
110:44 - weights the filters begin with random
110:46 - values and it learns optimal values so
110:54 - right here and setup sorry right here so
110:59 - right here and setup I'll write a nested
111:02 - loop
111:28 - and give it a random value between
111:31 - negative and one now in truth
111:33 - convolutional neural network but in
111:36 - truth there are other mechanisms and
111:38 - strategies for starting for the initial
111:41 - weights of a convolutional neural
111:43 - network but picking random numbers will
111:45 - work for for us right now just to see so
111:49 - every time I run it you can see we get a
111:52 - different result image that is filtering
111:55 - the image in a different way
112:04 - okay so I'm it's 11:20 I have an hour in
112:11 - 15 minutes left the next thing that I'm
112:15 - going to do is talk about one more
112:19 - operation called a max pooling that's
112:22 - another the operation that happens after
112:24 - this filtering process then I will zoom
112:26 - back out and look at the the full
112:30 - architecture of a convolutional neural
112:32 - network and that will finish this first
112:33 - tutorial if I have time I'll then
112:36 - actually show how do we nem l5 add a
112:40 - convolutional layer to a neural network
112:43 - so let butBut I want to take a short
112:47 - break and I want to take this time to
112:50 - thank whoops the sponsor of today's
112:54 - coding training episode oh look
112:56 - everybody left only thank you short
112:59 - breaking I want to take this time to
113:00 - thank the sponsor of the coding train
113:02 - today which is audible.com so I happen
113:06 - to be already I'm so excited about this
113:08 - because I happen to already be a
113:10 - audiobook listener I do try to read
113:13 - books as well I mean that's a thing but
113:14 - I do I spent a lot of time on the subway
113:17 - I spent a lot of time jogging exercising
113:19 - I don't spend as much time as I would
113:20 - like and I find that listening to
113:23 - something music is the thing to listen
113:25 - to but for me listening to audiobooks is
113:28 - a way to a have a chance to to to learn
113:36 - something that I don't have the time to
113:37 - read the physical book and it's just it
113:40 - keeps it's energizing I really love it
113:43 - and I am so excited cuz I didn't know
113:45 - this I listen to a lot of different
113:47 - kinds of audiobooks I listen to you know
113:50 - detective novels and strange non and
113:52 - historical nonfiction and different
113:54 - kinds of things but I hadn't really
113:55 - looked into whether there were machine
113:58 - learning audiobooks and so the exciting
114:00 - thing that I'm gonna tell you is that if
114:01 - you go to audible.com slash coding train
114:03 - or text coding training to 500 500 you
114:06 - will get a free audio book a 30-day free
114:09 - trial of the audio audible subscription
114:12 - which every month you get a free
114:14 - audiobook and two audible originals
114:16 - which are original content for
114:17 - by audible but there's a book that I
114:20 - want to recommend which I'm going to see
114:22 - if I'd bookmark yet before I started
114:24 - which is called you look like a thing
114:26 - and I love you which is how artificial
114:29 - intelligence works and why it's making
114:31 - the world a weirder place by gianelle
114:32 - shame I started listening to this
114:34 - yesterday and verso books so a wonderful
114:37 - about this book is a lot of the work of
114:39 - Janelle Shane is generating text with AI
114:42 - and she's going through in the book how
114:45 - a lot of like how a lot of times she
114:46 - gets nonsense and the audiobook narrator
114:49 - she's say I don't know it pronounced
114:51 - sexy sands performs all this like
114:54 - nonsense speak and it's kind of
114:55 - hysterical and wonderful and delightful
114:57 - so this book both has a wonderful set I
115:00 - mean it's a really great companion to
115:01 - the stuff that I'm teaching about
115:02 - because it goes through the concepts but
115:04 - it also looks at in the context of
115:06 - creative arts and sort of making weird
115:08 - stuff so I couldn't couldn't recommend
115:10 - it enough for you to listen to let me
115:14 - see here if I'm missing anything else
115:17 - that I want to tell you about audible so
115:20 - audible members can choose three titles
115:22 - every month a one audio book like this
115:24 - two exclusive audible originals that you
115:26 - can't hear anywhere else and you also
115:28 - marble gnomes also get access to
115:30 - exclusive guided fitness programs so
115:32 - just start to start the new year off
115:33 - it's still it's not February yet you can
115:36 - still start the new year off of the news
115:37 - resolution to listen to an audio book to
115:39 - listen to an audiobook once per month so
115:42 - you can start listening with a thirty
115:44 - dre 30-day audible trial choose one
115:46 - audiobook and two audible originals
115:48 - absolutely free at audible.com slash
115:51 - coding trade or text coding train to 500
115:55 - 500 okay so I'm gonna take a short break
115:59 - to refill my bug of I don't know what
116:02 - I'm gonna put in it water tea coffee who
116:05 - waits to be seen what I'm gonna find in
116:07 - the kitchen over there if you have a
116:09 - chance and to give audible a try while
116:11 - if you're still hanging around for the
116:13 - second half of this live stream you can
116:15 - take your time to do this in this break
116:17 - and I will be back in just about five
116:19 - minutes to continue this convolutional
116:22 - neural network example
116:36 - [Music]
116:44 - [Music]
116:52 - [Music]
116:58 - [Music]
117:31 - [Music]
117:39 - [Music]
117:47 - [Music]
117:59 - [Music]
118:14 - [Music]
118:24 - [Music]
118:35 - [Music]
118:42 - [Music]
118:53 - [Music]
119:10 - [Music]
119:24 - [Music]
119:32 - [Music]
119:54 - [Music]
120:06 - [Music]
120:21 - hi everybody it's gonna just be three or
120:26 - four minutes more so I'm just this song
120:29 - heads in about 30 seconds so I'm just
120:31 - gonna scrub it back in the beginning
120:33 - I'll be back in just about three or four
120:36 - minutes moving as quickly as I can
120:43 - [Music]
120:51 - [Music]
120:59 - [Music]
121:05 - [Music]
121:38 - [Music]
121:46 - [Music]
121:54 - [Music]
122:06 - [Music]
122:21 - [Music]
122:31 - [Music]
122:49 - [Music]
123:00 - [Music]
123:17 - [Music]
123:30 - [Music]
123:39 - [Music]
124:01 - [Music]
124:13 - [Music]
124:39 - [Music]
124:50 - okay thank you for your patience I am
124:57 - back so again thank you to audible.com
125:02 - you can get a free trial at audible.com
125:04 - slash coding trained and I look this
125:06 - book is so wonderful I actually ordered
125:07 - I'm listening to the audiobook right now
125:09 - and I also ordered the hard copy but it
125:11 - hasn't come yet
125:12 - otherwise I'd wave it in front of you
125:14 - okay close this and we are back here so
125:24 - I'm going to save this as is and now I'm
125:28 - going to say duplicate convolution max
125:34 - pooling okay oh and this I can remove
125:45 - maternal coder says the viewer instant
125:48 - rise happen twice what if someone is
125:50 - viewbotting that seems kind of unlikely
125:54 - that someone is viewbotting I mean why
125:56 - would anybody do that I mean it did that
125:59 - the fact that I've been twice in it was
126:00 - very consistent with the numbers a
126:02 - little bit odd usually when this happens
126:04 - it's because just somebody happens to
126:05 - share something on social media or
126:07 - YouTube is doing like weird stuff with
126:09 - its recommendations and all of a sudden
126:11 - it sends a whole bunch of people who all
126:13 - like calm and then instantly leave when
126:14 - they realize it's not what they're
126:15 - looking for so who knows hip chocolate
126:22 - chip hope your midterms went well and
126:31 - marshmallow is asking can I post two
126:33 - links of a project so I don't know maybe
126:35 - you're asking about posting links to the
126:37 - YouTube chat I will mention that what am
126:43 - I saying
126:43 - ah so if you want to share stuff
126:45 - the two ways to do it or there's lots of
126:47 - ways to share stuff but in terms of
126:49 - coding training community is the discord
126:51 - so I will post the discord link I have a
126:54 - button that does that now so that
126:55 - discord link should appear in the chat
126:57 - but it's actually going to appear before
126:59 - I say this chat is a real-time but
127:03 - there's a 30 second lag from what I say
127:05 - and when it reaches your ears and then
127:07 - also at the coding train comm there are
127:10 - ways of adding links to projects that
127:11 - relate to particular videos or
127:13 - challenges okay everyone wants to know
127:20 - what's in the cup so this is why I took
127:21 - a little bit longer I was like I feel
127:23 - like I need some coffee
127:24 - and I was like no coffee I was like I
127:27 - you know what I don't you drink coffee
127:28 - I just need water I filled up with water
127:30 - at a nice full mug full of water but I
127:38 - really love this bug so much I'm waiting
127:40 - for it to be a sponsor so kind of three
127:43 - hit me up fellow mug I think it's called
127:48 - so I figure what the company is anyway
127:49 - audible.com slash Cody great um mostly
127:54 - saying ah but then I was like I need a
127:56 - couple more minutes I need to make a
127:57 - quick little bit of coffee so I made a
127:59 - little coffee sort of coffee
128:04 - hello to or and prom and other people in
128:09 - the chat
128:16 - 2:32 and the chat is asking can you give
128:18 - temporary permission I could but it's is
128:21 - I can't manage that while I'm
128:23 - live-streaming so I prefer people to
128:24 - share links I just keep the YouTube
128:26 - protective settings on and that's the
128:30 - way it is and welcome to Brian's heart
128:34 - all aboard on the kodi train with your
128:37 - kodi train membership you have received
128:40 - a random number sixty five thousand and
128:56 - seventy six oh thanks for watching the
129:09 - promises videos says or appreciate it
129:12 - alright now what am i doing so just so
129:19 - you know I have look kind of like a hard
129:20 - stop at 12:30 and there's a there's a
129:24 - workshop happening in this space I'm
129:26 - starting at 1:00 so I need to get out of
129:27 - here and kind of clean up plus I need to
129:30 - move on my day and eat lunch and do
129:31 - other things as much as I would like to
129:33 - livestream my voice is starting to hurt
129:35 - I might talk for a lot but I'm good
129:38 - thing for you is hopefully maybe even as
129:40 - soon as next week a video that's not
129:43 - edited out of a live stream will be
129:44 - coming live on the channel a coating in
129:47 - the Cabana video it's very cold during
129:50 - that video it's snowed so stay tuned for
129:53 - that all right what am I looking for max
129:58 - pooling
130:03 - back to this paper or there's this
130:15 - yeah
130:20 - okay
130:24 - okay
130:31 - oh by the way this is just from
130:34 - Wikipedia but this is you can see just a
130:37 - lot of additional these are a lot of
130:39 - sort of common convolution filters for
130:45 - certain kinds of operations okay so I
130:55 - this is sort of my notes I hesitate to
130:58 - use a lot of these diagrams and images
131:01 - in the edited version of the video
131:03 - that's coming out I mean certainly I
131:04 - would credit them but they're not ones
131:05 - that I've made and I want to be
131:07 - thoughtful about you know I want to
131:11 - feature the work of others but I also
131:12 - want to be thoughtful about having
131:16 - permission to use theirs other's work
131:18 - but I think this paper where did the
131:21 - paper go
131:29 - where is the alright I just want to see
131:34 - I like a kind of like using the the yawn
131:39 - Laocoon paper with other authors there
131:41 - are as well where's the oh here we go
131:53 - I just want to see if max pooling us in
131:55 - here sub Oh is subsampling is sub
132:02 - sampling the same as the max pooling
132:06 - operation cuz it doesn't say in this oh
132:13 - no I have to do this every time
132:15 - now welcome loonies pouch to the cutting
132:20 - trees aboard the cody train cheers you
132:27 - have entered the cafe cars where I will
132:29 - be drinking my coffee say hello to you
132:34 - [Music]
132:45 - Kate week Mon writes I think so I'm
132:49 - pretty sure that he's referring to my
132:50 - question I'm so happy that King week -
132:53 - joins Minh is watching because it's it
133:01 - really helps me to stay sane and know
133:05 - that what I'm saying is not completely
133:06 - crazy is this actually oh this is I can
133:09 - search this PDF pooling pooling does not
133:13 - show up my guess is it's the subsampling
133:20 - if anybody knows this for sure I would
133:22 - appreciate okay
133:36 - all right so okay I was indeed all right
133:46 - okay now that I've wrapped up talking
133:53 - about the convolutions there's one other
133:56 - there's many other aspects to this
133:58 - diagram but there's one other really
133:59 - important operation that happens in a
134:02 - convolutional neural network that's
134:04 - described in this diagram it's
134:06 - subsampling
134:07 - that I want to add to my diagram and my
134:12 - code demonstration and that is and I'm
134:15 - not going to call it sub sampling I'm
134:16 - the common term for this now is called
134:20 - pooling and in particular the operation
134:22 - that I want to add is max pooling so
134:24 - there are different kinds of pooling you
134:25 - could do but max pooling is the standard
134:28 - pooling operation for a convolutional
134:30 - neural network so max pooling I mean
134:32 - it's another layer it can happen at any
134:34 - given point so we could max pool before
134:37 - we apply the convolution but I've
134:39 - typically speaking the convolutional
134:42 - filters are applied and then after those
134:45 - are applied we get new images out of
134:47 - those and those go through a max pooling
134:50 - layer so I think to describe I think I
134:54 - need to erase this whole diagram so that
134:57 - I can look at max pooling and then we
134:59 - could kind of come back to this when we
135:00 - look at the full architecture
135:29 - so let's begin with our 28 by 28 image
135:36 - then let's assume I have one filter just
135:39 - to simplify things I had one filter that
135:42 - was three by three one thing I didn't
135:44 - discuss and it's gonna be more relevant
135:46 - with the max pooling layer because I'm
135:48 - gonna do something specific with it is
135:50 - there's a term you'll see called stride
135:52 - and stride refers to remember this
135:56 - filter you know I'm not gonna actually
135:58 - do this 28 by 28
136:00 - but this filter is applied to each and
136:03 - every pixel we take we take this filter
136:06 - apply it to this pixel and this gives us
136:08 - a new image pixel apply filter take the
136:17 - result into a new pixel pixel apply
136:19 - filter take the result put it into the
136:20 - new pixel here's the thing this is 28 by
136:24 - 28 this is a 3 by 3 filter I had to
136:28 - start with this pixel right here right
136:30 - because the edges don't have neighbors
136:32 - on all sides so ultimately this and
136:36 - stride sorry stride refers to how far I
136:39 - pass the filter along as I'm going
136:42 - through the image I don't really have
136:44 - enough spots here but you know I could I
136:47 - could take the filter and jump over
136:50 - pixels as I'm applying it to reduce the
136:53 - resolution of the image in this case I
136:55 - had a stride of 1 in my code that I
136:58 - wrote the stride was 1 I just slid over
137:00 - by 1 and we can actually see where the
137:01 - stride would go if I go back to my
137:05 - example
137:14 - this ultimately right there the X plus
137:17 - plus y plus plus that's the stride so I
137:19 - could say X plus equals stride y plus
137:24 - equals stride and set the stride equal
137:30 - to one so that's what was happening here
137:33 - but even with a stride of one if I'm
137:35 - skipping the edge pixels my new image is
137:38 - 27 by 27 so one thing that's really key
137:42 - to how a convolutional neural network
137:45 - works is that the image over time as it
137:48 - goes from layer to layer to layer so
137:51 - this is the convolutional layer with the
137:54 - filters and now I'm going to talk about
137:56 - the pooling layer the resolution is
138:00 - reduced and this has a number of
138:02 - benefits one is images are high
138:04 - resolution with millions of pixels so
138:07 - this the this learning space of a neural
138:10 - network to learn all the parameters of
138:12 - every pixel connected to every filter
138:14 - throughout multiple layers
138:15 - it would just be much too big to
138:17 - realistically be computationally
138:19 - realistic to do so this process of
138:23 - reducing the image down and down and
138:24 - down as the layers is effective in
138:27 - keeping things manageable but it also
138:29 - has another benefit which is we're
138:30 - trying to boil the essence of the image
138:32 - down into something that will highlight
138:35 - key features in that image and so this
138:38 - is really what the what pooling does
138:40 - what max pooling does a 1:1 thing it
138:43 - does is it really reduces the resolution
138:45 - which I'll show you in a second but it
138:47 - also picks and chooses the pixels that
138:49 - have the highest values to emphasize
138:51 - those what is really being activated so
138:55 - pooling comes with a matrix as well it's
138:58 - not really a filter but it's a matrix
139:00 - and a standard matrix might be two by
139:03 - two and so let's take the case and
139:07 - actually let me erase all this just to
139:09 - zero in on pooling
139:22 - I'm gonna try to let's come up with a
139:24 - simple scenario what if I did 8 by 8
139:31 - terrible 1 2 3 4 5 6
139:37 - oh I'm the worst
139:46 - one two three four five six seven oh so
139:50 - close
139:52 - eight one two three four five six seven
140:02 - eight
140:07 - so describe this I'm going to start with
140:09 - an 8x8 image and I'm gonna do max
140:12 - pooling with a two two by two max
140:15 - pooling with a stride of two so there
140:21 - are no weights this is not a filter it's
140:23 - two by two is just describing how much
140:26 - of the how many pixels am I looking at
140:28 - at one given time so if if I'm looking
140:37 - at a 2x2 area of pixels for each
140:40 - iteration of this algorithm and then my
140:42 - stride is to the next set of pixels on
140:45 - look at us here the next one is here the
140:47 - next one is here so for for the for the
140:51 - columns I end up looking at four and for
140:53 - the rows it's the same it's eight by
140:55 - eight four so actually the result I just
140:57 - want to point out that after max pooling
140:59 - and actually I don't know I don't need
141:01 - to draw it that far over the result
141:07 - after max pooling is four by four four
141:14 - by four
141:18 - now how does the algorithm works but
141:20 - this sounds like some fancy thing this
141:22 - is actually the simplest thing ever
141:24 - basically for each one of these areas of
141:26 - two by two pixels take the largest value
141:29 - the brightest color and put it in there
141:35 - so so I'm gonna fill in some arbitrary
141:39 - values here I don't know how easy this
141:41 - will be to see but let me just write
141:42 - some values
141:53 - so I'm not gonna fill this whole thing
141:55 - out but you see I don't know how well
141:57 - you can see this but I have the numbers
141:58 - for 8 negative 1 to the highest one is 8
142:01 - it goes here I have the numbers 3 3 1 9
142:05 - the highest one is 9 the highest one is
142:07 - 1 the highest one is 10 and so the max
142:11 - pooling algorithm takes these little
142:14 - neighborhoods 2 by 2 max pooling skips
142:17 - goes from one to the other with a stride
142:19 - of two I could have just moved these
142:22 - neighborhoods just by one or by even a
142:24 - larger amount but this is pretty typical
142:26 - and then takes it down this has to be
142:30 - this has the benefit of sub sampling the
142:33 - image reducing it but not just we can do
142:36 - average pooling so you could do average
142:38 - pooling averages all of these but it
142:39 - turns out convolutional neural networks
142:42 - perform better with max pooling over
142:44 - average playing maybe not in all cases
142:46 - but in sort of like the standard image
142:48 - classification case and this is because
142:50 - what we're looking for our features in
142:52 - the image that we want to highlight and
142:54 - so by looking at an area of pixels and
142:58 - seeing which pixels were have activated
143:00 - the most and keeping that one that's
143:02 - going to really emphasize then help boil
143:05 - the essence of the image down into
143:07 - something lower resolution oh just no
143:14 - one use max pooling anymore am I so like
143:19 - out of date
143:26 - me I am so me I will I will do it really
143:30 - likes my member joining bit which I very
143:32 - much appreciate the spontaneous thing I
143:34 - thought of today I will happily when if
143:36 - I have some time so just to be accurate
143:43 - in my video here should I add a little
143:46 - sentence about what is now more commonly
143:49 - used in max pooling truth teller says me
143:51 - tells me truth teller is name is truth
143:54 - teller
143:54 - so truth teller I know because when I
143:57 - see something on the internet I
143:58 - definitely read it without being
144:00 - critical or thinking about whether it
144:01 - could be accurate at all right
144:03 - no but I you know I have no reason to
144:05 - doubt truth teller K weak bonds
144:09 - confirmation could really help me though
144:11 - I don't wanna put too much pressure on K
144:14 - weak mine max pool plus average pool is
144:17 - better dilated is dilated pooling the
144:34 - same thing dilated pooling
144:49 - whoa max pooling dilated pooling all
144:56 - right
145:04 - max pull is most common all right
145:07 - I should add just to be really accurate
145:15 - here and the chat is tell this is
145:17 - offering some different opinions about
145:18 - this that while max pooling is the most
145:20 - sort of like common historical example
145:22 - of while max pulling is the most common
145:27 - historical example of pooling in a
145:28 - convolutional neural network there are
145:30 - other other researches showing promising
145:33 - results from things like dilated pooling
145:35 - which is a new concept to me that I just
145:36 - looked up and read about some
145:38 - combination you can also do a
145:39 - combination of max pooling and average
145:41 - pooling so there is I think some
145:42 - discussion and research happening there
145:44 - and I'm not here to tell you what is the
145:46 - optimal way to architect your
145:48 - convolutional neural network I just want
145:50 - to talk about and explain the process
145:51 - and look at an example of it which is
145:54 - very common like max pooling in
146:00 - particular okay I think that's enough
146:05 - that's enough for me to say an ADD so
146:15 - now so let's add max pooling okay I'm
146:30 - trying to think of how to do this
146:46 - would IMAX pull the our G's and be is
146:50 - separately I think I would write or
146:52 - would I take the pixel value that is the
146:58 - would I take the pixel value from
147:01 - whatever from the one that has the
147:04 - highest like brightness like the average
147:06 - RGB like could I take different ARS and
147:08 - G's and beats from different pixels in
147:11 - the neighborhood or do I have to take
147:12 - the full RGB from one that happens to
147:14 - have the highest brightness I don't know
147:18 - can someone answer that for me before I
147:22 - move on and I have about a half an hour
147:23 - left this might be the last thing that I
147:30 - do today
147:39 - I'll wait terrible thing for you to do
147:46 - just like have a question and not bother
147:48 - trying to research it or think about it
147:50 - just like ask it wait to the National
147:55 - for me in the past I guess I'll start
148:06 - writing this code
148:33 - maybe take RGB separately so maybe I'll
148:39 - just ask this question as I make the
148:40 - video and I'll just pick one way of
148:41 - doing it since there doesn't seem to be
148:43 - a consensus in the last few seconds so
148:48 - I'm gonna write another function much
148:50 - like convolution but call it pooling
149:00 - and the same thing it goes here I want
149:03 - to receive an image I want to find a
149:06 - certain XY
149:15 - I want to same thing happens here I want
149:17 - to receive an image I want to give an X
149:20 - Y I want to return some RGB value that
149:25 - is the highest RGB values within that
149:29 - neighborhood now there's an interesting
149:39 - question here do I take the RGB values
149:41 - from the brightest pixel whatever they
149:44 - might be or do I just take the the
149:45 - highest are the highest gee and the
149:47 - highest be independently and they could
149:49 - be from different pixels I don't know
149:51 - the answer to that right now let me take
149:53 - the RGB from the brightest pixel
150:07 - no that's gonna be more work let me just
150:09 - go with actually picking the brightest
150:11 - are the brightest G and the brightest B
150:12 - separately independently
150:26 - so I'm gonna start with the brightest RG
150:29 - and B and I could start with zero but
150:30 - just to be really really safe you
150:32 - absolutely absolutely absolutely in the
150:34 - convolutional process there's the the
150:37 - idea of pixels is gone really just
150:38 - dealing with numeric data and so I
150:40 - really should if I'm gonna try to find
150:42 - the brightest a start with in negative
150:44 - infinity because that's the lowest
150:46 - possible number you know in JavaScript
150:48 - that is
150:55 - then I want to look at this 2x2 area
151:26 - and the same thing that I did before in
151:30 - convolution I and the same thing that I
151:38 - did before in the convolution I want to
151:39 - look at the given pixel and its
151:41 - neighbors
151:59 - yes starting with the color II which
152:01 - definitely made life difficult for
152:02 - myself it's silly cuz the image itself
152:04 - it's great scale but whatever
152:06 - at the end I'll load my color image to
152:09 - see that this actually works with color
152:20 - and then I could get the RG and B from
152:22 - that pixel
152:37 - and now I just want the maximum I want
152:41 - if this R is greater than that print
152:43 - that what is being stored as the
152:44 - brightest are then that are should be
152:47 - the brightest are which I can do with
152:48 - the max operation right R is the biggest
152:52 - between bright R and R and the same for
153:00 - G and B oh and the same for G and B oh
153:06 - and that has to be 1 & 2
153:18 - so this is actually all that I need to
153:20 - do this is max pooling right here but
153:22 - now I just need to return bright are
153:24 - bright G and bright B
154:04 - all right
154:14 - next I'm going to create yet another
154:17 - image I'm going to call it pooled
154:26 - and pooled is also a blank image however
154:31 - if you recall I'm going to use a stride
154:35 - of two so the resolution of that image
154:38 - is reduced further by half
154:51 - so I'm actually going to take out the
154:53 - stride from here and I'm going to create
155:00 - a global variable for stride but this
155:06 - stride is only referring to the pooling
155:08 - process because then I can say create
155:12 - image dim / stride dimensions / stride
155:22 - sorry I'm lost here
155:30 - so just to add some comments for a
155:33 - moment this is convolutional layer i
155:37 - mean i'm simulating the idea of a
155:38 - convolutional layer i'm not actually
155:40 - there's a neural network here there's no
155:42 - machine learning here I'm just going
155:44 - through these particular algorithms
155:45 - without matrix operations I should add
155:52 - then let's add the pooling operation so
155:59 - same thing here I'm going to go through
156:02 - all of the pixels
156:17 - in this case I can start at zero but I
156:21 - still need to only go to dimensions - 1
156:26 - because maze I'm going to skip every 2
156:30 - pixels and I don't want to end up here
156:43 - so this is plus equal stride and this is
156:47 - plus equal stride
156:55 - I can do the same exact thing I can
156:57 - create a variable called RGB which
156:59 - equals now pooling I want to pool what
157:02 - were my arguments the image and the XY Y
157:06 - is there oh and I should probably call
157:08 - this like max pooling but whatever oh no
157:17 - no I'm not pulling the cat the cat was
157:20 - filtered with convolution and then the
157:22 - filtered image is pooled so I'm pulling
157:24 - filtered at this given X Y then I need
157:32 - to figure out where am I putting the
157:35 - resulting RGB values I'm putting them in
157:38 - the I'm putting them in the image called
157:43 - pooled but that image has the dimensions
157:45 - of half so the pooled X is X divided by
157:51 - the stride the pooled Y is y divided by
157:55 - the stride and then the index is and
158:08 - yeah so this is why this function really
158:12 - needs the image passed with it i I
158:14 - should not have used the global variable
158:16 - it was terrible idea because I want to
158:18 - reuse it but I have a different
158:19 - resolution of image so I'm gonna go back
158:22 - to making this image and then where did
158:25 - I call it here it's image dot with
158:36 - here it's cat oh I don't need to do the
158:39 - dot dot with it's just the the
158:41 - particular image that I'm calling the
158:43 - operation with I needed here image
158:53 - anywhere else
158:55 - oh here image
159:03 - so now I could say index of pixel X
159:07 - pixel Y in the pooled image because I
159:15 - want to say pooled dot pixels pix plus 0
159:22 - equals RGB are
159:33 - and I need to add the load pixels and
159:35 - update pixels
159:51 - and now this should be the max pooling
159:53 - operation go over the filtered image by
159:59 - the stride for every 2x2 area find the
160:03 - highest RGB values and then add those to
160:07 - the pixel the corresponding pixel in the
160:09 - lower resolution pooled image
160:23 - let me make the height of my canvas
160:25 - times two so I can put the pooled image
160:27 - at the bottom right so the filtered
160:33 - image went off to the right and now the
160:36 - pooled image should go also off to the
160:41 - right and let's give this a try I don't
160:46 - see the pooled image lines think of the
160:51 - chat zombie line 61 is an error this
160:59 - should be a G
161:08 - what did I miss
161:15 - oh I forgot to add the Alpha again I
161:20 - always forget this so I need to give it
161:25 - the Alpha there we go so let's go back
161:37 - to a known filter instead of having
161:39 - random filters so that was my edge
161:44 - detection and you can see this is just I
161:47 - mean visually what I'm seeing right now
161:48 - is kind of like a lower resolution
161:50 - version of what you have above but if I
161:53 - were to rewrite this with say average
161:55 - pooling I think you would see it
161:57 - different it wouldn't come at the most
161:59 - features these edge features that it's
162:01 - you know in a neural network would be
162:03 - discovering here I'm telling it to look
162:05 - for those are highlighted even more than
162:07 - they would be with just average pooling
162:09 - itself
162:21 - right so now that I've shown you the
162:25 - code for both applying a convolution
162:27 - filter to an image and then a pooling
162:30 - algorithm to that image with a variable
162:32 - stride I think that I can now go back
162:35 - and look at the larger rket the larger
162:38 - diagram of the full story of a
162:40 - convolutional neural network that has
162:43 - these components in it and again our
162:46 - reference point is this diagram from the
162:49 - 1998 paper which is called the 99 1998
162:57 - paper gradient based learning applied to
162:59 - document recognition but Matt Joe when
163:02 - we edit this we can just leave this
163:05 - there I've just needed to read what the
163:07 - paper was gone
163:22 - and then so what where was I okay
163:34 - just want to also
163:52 - I also just want to highlight for you a
163:54 - blog post that was super helpful for me
163:56 - in like figuring out what to do and talk
163:58 - about in or was it I also want to
164:01 - highlight for you a blog post that was
164:02 - really helpful for me when I was reading
164:04 - up and researching and trying to learn
164:05 - about convolutional neural networks it's
164:07 - this blog post right here an intuitive
164:09 - explanation of convolutional neural Oaks
164:11 - from night from 2016 this diagram is
164:16 - super helpful this is exactly what I
164:17 - want to talk through basically and there
164:19 - are a lot of nice visual diagrams and
164:21 - animations of the convolution process
164:24 - convolutional filters as well as the max
164:32 - pulling algorithm itself as well
164:59 - okay
165:23 - forget that that research as it worked
165:25 - very well
165:34 - let's look at the here's my best attempt
165:38 - now at the full story of the
165:40 - convolutional neural network we start
165:47 - with an image the first layer is a
165:55 - convolutional layer and I'm writing 2d
165:57 - because a lot of times in a machine
165:59 - learning library you can have
166:00 - convolutions in different dimensions and
166:03 - we're working with a two dimensional
166:04 - convolution here the convolutional layer
166:10 - has a number of filters the image is
166:17 - sent to every one of those filters and
166:20 - the these filters are applied I should
166:24 - say that the pixel the values that come
166:26 - out of the filters aren't just the raw
166:28 - values from the convolution process
166:30 - they're also then passed through an
166:32 - activation function the same kind of
166:34 - activation function that is in a
166:36 - standard neural network our standard
166:39 - dense layer the let's just assume the
166:44 - same kind of the same kind of activation
166:46 - function that's in a standard layer or a
166:50 - dense layer so typically this would be
166:56 - rectified linear unit or raloo typically
167:01 - this would be rectified linear unit or e
167:05 - Lu
167:12 - then the next step is max pooling
167:26 - I'll represent that with little squares
167:32 - so the image that comes out of the
167:35 - convolution and the activation function
167:37 - is then max pooled and then the output
167:43 - there is another image so we take this
167:54 - first image pass it through a bunch of
167:56 - filters max pool then and then we have a
167:58 - whole bunch of new images that aren't
168:00 - most likely if I'm using the stride if
168:02 - the a whole bunch of other image that if
168:05 - I'm using a stride of two now have half
168:07 - the resolution as the original image so
168:09 - the question becomes what to do next
168:11 - well we could be done and pass this to
168:14 - what I what is the last layer and if
168:17 - we're doing that at some point the Dana
168:20 - does have to be flattened so everything
168:22 - I did in my previous video about ml5
168:25 - neural network with an image that just
168:27 - gets flattened and passed in that is
168:30 - what happens in the last layer the last
168:33 - dense layer takes these images and makes
168:36 - and has a hidden a hidden layer of
168:41 - neurons and each image is flattened and
168:47 - sent into all of those and then sent to
168:51 - the output layer yeah and then sent to
168:58 - the output layer and pass through the
169:00 - softmax activation function that I've
169:02 - described which gives it a probability
169:04 - for a classification if this were a
169:06 - classification problem but what's
169:08 - interesting is in most cases if you look
169:10 - at a lot of these diagrams for example
169:13 - this diagram on the blogpost I referred
169:16 - to or this particular diagram here
169:23 - you'll see convolutions subsampling
169:25 - convolutions subsampling
169:36 - so it's actually quite common in a
169:40 - convolutional neural network I really
169:42 - didn't give myself enough space here
169:59 - if we have another convolutional layer
170:02 - let's say there's just three
170:03 - convolutions filters this image goes
170:06 - into all of them I'm confused
170:10 - somebody help me out here for a second
170:13 - so let's say we have another set of
170:16 - filters this many filters this these
170:24 - images that come in there's one image
170:25 - that goes into all these initiatives
170:28 - initial filters then that gets max
170:31 - pooled and and we get a new set of
170:33 - images each one of these images would go
170:35 - into all of the filters but does that
170:40 - mean does that mean then I'm actually
170:44 - producing I now have one two three four
170:50 - five times four 20 images that get max
170:52 - pulled that must be right
171:03 - yeah we can see that happening here
171:05 - because there's this many images that
171:09 - get subsampled and then the convolutions
171:13 - are excellent name is saying they're
171:19 - stacked into a 3d image but ultimately
171:20 - that's the same idea filters must be 3d
171:26 - but here in this diagram it's showing it
171:29 - expand out right
171:50 - oops
171:56 - yup says Isaac let me redraw this to
172:01 - give myself a little bit room I'm
172:02 - running out of room and I want to
172:04 - diagram the full story I used so much
172:06 - space here for this image
173:01 - okay so here's the same diagram but
173:04 - squashed a little bit to the left here
173:06 - because what I want to do now is add
173:08 - another convolutional layer and another
173:11 - max pooling layer actually so here's the
173:20 - same diagram but squashed a little bit
173:22 - to the left because I want to add
173:23 - another convolutional layer and another
173:26 - max pooling layer so I'm gonna add some
173:28 - more filters here but something
173:33 - interesting is gonna happen here so let
173:34 - me actually do fewer filters in this
173:38 - next layer and I'm gonna be really I'm
173:41 - gonna just do only use - there's only
173:43 - two filters here well these images that
173:47 - result from the first convolutional max
173:49 - pooling process they need to be tested
173:52 - are not tested they need to be sent to
173:54 - both filters so this image goes here
173:56 - this image goes here so in essence we
174:02 - have 1 2 3 4 times 2 times 2 filters and
174:17 - I'm not really drawing this well to have
174:19 - 8 in total so we get 8 new outputs out
174:25 - of this convolutional layer and each one
174:28 - of those needs to be max pooled so now
174:38 - I have eight images and remember let's
174:41 - say this was 28 by 28 these are all
174:45 - seven by I'm sorry 14 by 14 then after
174:49 - this convolution process and this max
174:50 - pooling these are all now seven by seven
174:54 - so we get these progressively lower and
174:58 - lower resolution feature maps of the
175:01 - original image with lots of different
175:03 - filters applied in lots of different
175:05 - ways
175:32 - finally and this is exactly and then the
175:39 - final result is essentially everything
175:41 - that I did in my non convolutional
175:45 - neural network with an image just that
175:48 - one hidden layer it's called a fully
175:50 - connected or dense layer and one output
175:52 - layer all of that gets put right here
175:55 - but instead of some original image being
175:58 - flattened and sent to it this whole
176:01 - process has happened and we're sending
176:03 - the data from these 7x7 images through
176:06 - the one dense layer and one and I've
176:10 - totally run out of room here so I'm just
176:11 - gonna put oh here output layer and this
176:15 - is where we would finally see is it a
176:17 - cat or is it a dog we would see
176:20 - probability values for the particular
176:23 - classification task and again if I come
176:25 - back to this diagram I just want to
176:27 - thank the author of this blog post
176:30 - because this is a much nicer more sort
176:33 - of like elegant way of drawing this and
176:36 - you can see actually this has two fully
176:39 - connected layers which is also a things
176:40 - so there are different ways you could
176:42 - architect this only drew seven
176:44 - somebody's saying one two three four
176:49 - five six seven eight one two three four
176:51 - five six seven
176:52 - oops I'm missing one here
177:01 - okay
177:12 - even though this is a bit of a mess let
177:15 - me go back and refer to the and thank
177:17 - the author of this blog post for this
177:19 - much more thoughtful and precise diagram
177:23 - showing these different layers how the
177:26 - images become lower and lower resolution
177:29 - become these final feature maps and then
177:32 - get passed through what's here is
177:33 - actually two fully connected layers so
177:35 - there are a lot of reasons why you might
177:38 - have different numbers of convolutional
177:41 - layers different numbers of fully
177:43 - connected layers different strides
177:45 - different filter sizes that another word
177:47 - for filter is kernel so this is it I
177:50 - really all I want to do this video was
177:52 - talk through all the pieces as well as
177:54 - show you some code that actually runs
177:58 - through and does those processes to an
178:00 - image itself which I think opens up a
178:02 - lot of interesting possibilities for you
178:05 - if you wanted to create a project around
178:07 - visualizing the process of a
178:09 - convolutional neural network as it's
178:11 - learning now this would be a much bigger
178:13 - endeavor than what I've done here
178:15 - because you need to create these visuals
178:16 - out of all of the pieces as the training
178:20 - process is happening but ultimately what
178:23 - I want to do next is 2/3 things and it
178:27 - might take a while for me to get to them
178:28 - but they will be eventually hopefully in
178:30 - subsequent videos one is I want to just
178:32 - create this exact architecture with ml5
178:36 - I want to show you how the ml5 I can
178:38 - make ml5 neural network with a
178:40 - convolutional layer maybe two
178:41 - convolutional layers and then a dense
178:43 - layer and an output layer then I can
178:46 - take that and apply it to the previous
178:47 - example where I didn't use convolutional
178:48 - layers and just see how that looks I
178:50 - also would like to look at creating
178:53 - something called that I'll call I also
178:56 - like to look at something that we could
178:58 - call a doodle classifier so using the
179:01 - quick-draw dataset that I've referred to
179:03 - in a number of different videos could I
179:04 - train a classifier to recognize
179:08 - particular drawings and in fact ml five
179:11 - has built into it a doodle app retrain
179:14 - dual classification model that's pretty
179:17 - robust
179:17 - so you know I might try to train a sort
179:19 - of like smaller version of that write
179:21 - all the code for that with ml five but
179:23 - ultimately then show you how to use the
179:25 - pre trained
179:26 - that's in ml5 as well but that uses
179:28 - convolutional layers okay
179:31 - Soho thank you so much if you somehow
179:33 - made it all the way to the end of this
179:35 - rather long explanation and kind of
179:37 - tinkering around with code demonstration
179:40 - of what the process of convolution and
179:44 - pooling is in a convolutional neural
179:46 - network I hope to see you in a future
179:48 - coding training video I mean I don't
179:49 - really see you but I I feel your
179:51 - presence somehow and as long as you
179:52 - write a nice comment it brings me a
179:54 - little happiness to my day so I will see
179:57 - you in that virtual way in a future
179:58 - video and thanks for watching and have a
180:01 - great day that's not convoluted at all
180:04 - Oh Jean Cogan's what neural networks see
180:11 - ah let me reference that I meant to
180:15 - thank you yeah this is what I meant to
180:25 - reference yeah this is maybe we could
180:33 - fly in a little clip of this what I'm
180:37 - describing actually is really what I'm
180:40 - describing really has been implemented
180:42 - with gene Kogan's us video and lecture
180:46 - series called what convolutional neural
180:47 - networks see and you can see over here a
180:50 - visualization of all the filters being
180:52 - applied to genes a webcam image in real
180:55 - time so I've maybe given you the pieces
180:57 - now of what it would take to actually
180:59 - create a project like that yourself
181:04 - okay truth-teller escape is spouting
181:09 - some total truth online to be fair
181:13 - that's a better cat than the cats in the
181:15 - cat's movie all right Simon Tiger points
181:24 - out for 32 by 32 images you can bring it
181:27 - down to a 1 by 1 pixel image in only 5
181:30 - convolutional layer blocks which is a
181:33 - term ok
181:34 - it's a peek into the black box yeah
181:37 - yeah okay
181:43 - okay everyone thank you for tuning in
181:45 - I've got to go I didn't get so listen up
181:49 - listen if I go now - let's just go to
181:54 - hear this I had a little guide here of
181:58 - what I think it's like under missing
182:00 - videos let's see a sort by recently
182:11 - updated missing visitor oh so oh oh my
182:16 - god so many things to do
182:20 - yeah let's revise this oh boy edit what
182:27 - are CNN's that was done
182:56 - well I was hoping to check off whoops
183:01 - that was I was hoping to check off more
183:07 - boxes but clearly I just I added more
183:13 - boxes and checked off one so I've
183:15 - actually gone back in time like they
183:16 - have Lord to do that what I had to do
183:19 - before I started today here's the thing
183:21 - I'm unfortunately gonna leave this stuff
183:24 - aside I would like to over the course of
183:27 - this semester fill in gaps here but next
183:30 - week with like when I'm back next week
183:32 - for a live stream which hopefully be
183:33 - next Friday although I am planning to
183:34 - switch to Thursdays but I think next
183:35 - week is actually gonna be Friday's I am
183:39 - going to start looking at it's gonna be
183:43 - a fairly beginner hopefully fairly
183:44 - beginner friendly a session on create
183:47 - vector and vectors in p5.js so all this
183:50 - stuff at least I have this list to keep
183:52 - track of stuff but and I will try to
183:55 - return to it hopefully I would over the
183:58 - course of this semester we'll see how
184:01 - that goes
184:01 - whoo thank you for tuning in let me put
184:05 - on this little song remind you that you
184:08 - can sign up for the discord and I have
184:13 - just posted the discord link in the chat
184:15 - also once again remind you to thank
184:18 - I mean I'm thanking and remind you that
184:20 - you could get a free 30-day trial of
184:22 - audible a premium audible subscription
184:25 - at audible.com slash coding train and
184:28 - that gives you a free audiobook and two
184:30 - audible originals I highly recommend you
184:33 - now
184:35 - book that I talked about your a thing I
184:37 - love you what else do I want to mention
184:42 - any questions in the YouTube chat or the
184:46 - discord member chat I will gladly
184:49 - address in the next minute or two I'm
184:50 - not five minutes over so I really do
184:52 - need to stop gosh I hope the recording
184:55 - is fine from today to find out I didn't
184:59 - check it in the middle which I will sure
185:03 - [Music]
185:15 - [Music]
185:25 - [Music]
185:27 - did I mention the store standard TV /
185:32 - coding training
185:34 - [Music]
185:38 - I really you know I only want people to
185:40 - get stuff if they would enjoy it but I
185:42 - do have a vested interest and people
185:44 - buying the hoodie because they'll only
185:46 - make them if enough people buy them and
185:47 - I want one guess I could figure out a
185:50 - way to make my own today
185:58 - strange usually I can't keep up with the
186:01 - questions now there's just no questions
186:03 - well thank you very much
186:06 - and I am going to sign off in about 48
186:09 - seconds
186:11 - [Music]
186:15 - I'm tired three hours is a long time
186:18 - live streaming pieces in four hours but
186:20 - we nice if I had another hour to keep
186:22 - going you try to get a little further
186:23 - but I think my brain is a little bit
186:25 - dead anyway
186:27 - time to do some gross stuff alright
186:29 - thank you everybody I will see you next
186:30 - week be on the lookout for edited
186:32 - versions of these livestream sessions as
186:34 - well as hopefully soon in the Cabana
186:37 - video see you in the discord
186:45 - [Music]
187:08 - [Music]
187:33 - [Music]
187:41 - [Music]
187:51 - I'm gonna do this this stock this start
187:54 - the starter this start song never forget
187:56 - the Vista
188:06 - [Music]
188:19 - [Music]
188:35 - [Music]
188:41 - auto-tuned and the internet will fix
188:43 - that for me
188:52 - coordinates
188:55 - [Music]
189:11 - [Music]
189:13 - so this is random this is noise Perley
189:17 - noise that is in the core random
189:19 - algorithm the actual random algorithm
189:21 - itself those numbers aren't related at
189:24 - all you pick like I'm picking random
189:26 - numbers between zero and ten nine two
189:28 - seven six one nine four eight nine to
189:33 - one thirty I think nine why apparently
189:35 - but with curly noise I might pick
189:36 - numbers like this two three four three
189:39 - four five six five four five six seven
189:43 - five six seven five six seven eight nine
189:46 - eight seven six well this is like pearly
189:49 - noise performance part
189:51 - [Music]
190:02 - these like girls and boys performances
190:10 - but with curly noise I might pick
190:13 - numbers like this
190:20 - by purling noise that is Hurley noise
190:23 - this is Hurley noise that is Hurley no
190:25 - this is this is Hurley noise that is
190:26 - Hurley no so this is Hurley noise that
190:28 - is her pearling know her Perlin noise
190:29 - that is Hurley noise this is Hurley
190:31 - noise that is Hurley noise so this is
190:51 - but with curly noise I might pick
190:54 - numbers like this this is like Perlin
191:12 - noise performance part unicorns and
191:15 - rainbows and cupcakes what else is there
191:19 - yes kids thank you very much kittens and
191:22 - rainbows and cupcakes
191:23 - notice that look what I get
191:26 - really losing my mind
191:27 - [Music]
191:43 - [Music]
191:54 - [Music]
192:09 - [Music]
192:36 - [Music]
192:43 - I feel just sort of like a nice feeling
192:47 - of relaxation everything's gonna be okay
192:50 - today dream is not broken it has not
192:52 - frozen this isn't this is a wonderful
192:54 - thing okay we're gonna do it I'm really
192:57 - getting to something I need my sound
193:02 - [Music]
193:24 - I will use it over and over again all
193:29 - sorts of text generation analysis states
193:32 - that I will use continuously over and
193:35 - over again
193:39 - [Music]
193:53 - [Music]

Cleaned transcript:

good morning and welcome to the coding train with me your host coding train person I do have a name it's Dan and we begin as we always begin with the ceremonial reading of today's random numbers coding training today is brought to you by the random numbers fifty nine thousand one hundred ninety four nine thousand and twenty seven ninety five thousand nine hundred twenty two fifty five thousand four hundred and sixteen twenty four thousand two hundred and fortyone maybe thousand this is what I look at the chat oh wait I'm in the wrong chat channel to see if like there's anything terribly wrong going on let me switch there we go brand el Mac says hello everyone by the way I'm looking at the discord chat which is for disc members of the coding train but I also seen the YouTube chat where I see ninety four thousand nine hundred thirty from our naav are now sends another random number seventy thousand nine hundred forty eight I wonder if we had you know a random number for every person if every person watching thought of a random number between 0 and 90 9999 inclusive of that what the distribution would be and whether we would have a a good random number pseudorandom number generator a random number generator or not interesting question interesting theory I could loot my outoffocus I thought I was on focus everything is definitely on fire the roof the roof it's up there bunch of floors up I guess if the roof is only technically the top of the building I mean there's a ceiling that's not really a roof no says Oliver once again I will remind everybody watching that when you say yes or no is if you were replying to me I have no idea what you're talking about because it happens about 30 seconds later and my memory apparently my shortterm memory is not nearly that long I forgot to wash my glasses it's very important that I wash my glasses before I livestream these very bright lights which reflect in them which is a problem I need to get some anti reflective lenses but also as soon as those lights come on if there's like a little bit of dirt it's much better refocus yeah why is that alright so let's try using the random digits book I thought I focused and this book possibly prop itself up oh by the way this is a YouTube show livestream thingamabob where I code stuff and talk about things and I'm still on a little machine learning kick so that's what's happening today let me see if I can fix this focus because I cannot be in two places at once one of these days maybe I'll get a like a robot assistant to be in here and to focus the camera for me so weird I think this random number book is not very good for helping me focus in more ways than one better I can't tell let's go with mine oh wait wait wait let's try my other special focus device oh good it's transit all right I'm just gonna have to go with my usual Elgato streamed box not a sponsor today's sponsor by the way is audible if you go to audible.com slash coding trade or text coding drain 500 500 you can get a free audio book you can listen to a free audiobook and I listening to one right now which is called your a thing I love you bye Jenelle Shane I'm gonna talk about that book it's a amazing AI book or you can also text coding train 500 500 I love audible it's so wonderful to listen to books when I'm on the subway and jogging and all that stuff so I will come back and talk about that I do also love stream deck although they are not a sponsor so I don't have a link for you but I do have a link for you audible.com slash Kodi drain all right let me see if I could focus the camera now on this you would think I did this I do I have my list of things to do before I start focusing the camera is one of them it looks good I also want to take a if I think this is better now I feel like I look out of focus tell me if I'm okay I mean I'm not okay this is clear I've got lots of issues many many many many issues okay don't worry about me I'm fine I'm okay my life is fine but I am very much out of focus in so many ways literally and figuratively but hopefully I've literally in focus right now if somebody in the member channel under live chat in the discord could let me know that would be super helpful if I'm not I will fix it I might like want to take just a short break to go clean my glasses all right I think we have a new member who just joined Scott Bauer related baby Jack Bauer no that's like a label you probably an unmet you should definitely just like cancel your membership that I made some sort of like lame ridiculous joke I'm going to talk about what I'm gonna do today which is examine something called convolutional neural networks david says I'm good that reminds me I'm gonna show a community contribution from David which should be a fun little experiment it's okay but not perfect let me mention the discord just because I'm gonna take like a second here so this is the new coding train discord this is the all aboard channel so if you join the coding train discord you are required to read this will be welcome map message and the code of conduct which is here I'll also note like I get a ton of questions on the videos which I appreciate the comments and I do scan through all them and I try to reply here and there when I can but if you're looking for coding help to places for you one is the that I'll mention first is the processing discourse so if you go to the processing foundation forum which is a discourse dot processing org if you have a processing or p5 specific question a search this forum it's probably been asked and answered but you can also ask it here this is a great place but if you're something if you want to if you're interested in discord or something more coding trained specific this is a great place to get help and you can see the different channels here we have um HTML CSS p5 processing Oh if these you bike okay node for a serverside stuff of machine learning Python which is not my area of expertise get not not that any of this is really my area of expertise maybe processing I had one area of expertise that I might actually claim it would be processing so if someone could post is anybody a moderator currently in the chat who can post the discord link if not oh wait I can I can I'm gonna do that right now I should get up I have a button actually right here which whenever I press it it posts you to the chat I should have that post like the discord lake or I could make another but let's see if I can get that to work so I am going to go over here to useful links so this is where I'm I'm gonna I'm actually gonna show you where I'm going but I'm doing it on a different computer useful links here which these are all the various coding train links that you might be interested in I'm gonna grab this discord link I'm gonna hit copy and paste it into the chat just so it's there then I am going to go to my where am I going to my stream deck and I'm going to go down to YouTube YouTube but YouTube and put in chat message just call it discord I have so many keyboards and buttons then I'm going to paste the link here to the discord and I think now if I just hit save anytime I want I am I don't know I'm afraid to say this name cuz I feel like there might be something hidden in there that I'm not aware of cuz I'm not really thinking he is going to code in the next few minutes and you would be right you are the winner of a trip for two on the cutting train choochoo and you'll also get with your trip for two on the Kotick train random numbers and what was I doing Oh welcome Japs thanks Jeff for joining the coding train on the cookie speaking did you take like an improv class or something cuz I'm absolutely terrible at this with your coding trade membership you will receive in the mail stickers much love from Tanzania Africa thanks Scott welcome aboard to the kodi train with your super chat message you'll now receive a reading from the kodi train okay I was doing something I'm testing this button did it work I pressed the button I to post a link to this chord so let me just quickly mention a couple other things in here under store oh no wrong wrong link wrong link discord you failed me I guess I should edit that this is the new so that's the old store I mean actually still exist I might take it down I don't know but this is the new store I just wanted to mention that there are coding train hoodies available I would really liked one of these so this is my pitch to you these are expensive to make I'm not using a print on demand service anymore standard TV helped me design and produce this merchandise which I'm told this high quality and so this they're gonna do actually a print run of these I don't know what the process is but so it's only taking three orders so if people don't order them they won't get made I've already ordered a whole bunch for myself maybe I've ordered enough that it'll get made but that's my pitch to you if you want me to see me wearing one of these but I would like to I'm wearing my ITP camp hoodie right now then other people need to order them and there's other stuff here if you're interested standard TV I don't a button to post on the chat okay so I am you know I'm sure I want to get started sooner than later or not I mean all of this is goofing off on some level but not waste not I want to get started with the content because a little bit behind all the things I want to do it next week is nature of Code times so I need to move on from some of the machine learning stuff although it will circle back to it because some of the stuff in nature of code towards the end uses AI but so I'm gonna do as much as I can today on some of the ml 5 stuff that I've been doing and see where I get thank you Oliver for posting the store link in the chat and that's that so if you will bear with me Oh watch my glasses it should just take a minute and I'm gonna put on intermission animation this is not actually the intermission though there will be an intermission about an hour to an hour and a half in is so loud all right I'm back sorry about that I just thinking I might be the first person in the history of universe in the universe to say watch watch watches their class yes I went down to the lake with my washing board all right so one more thing I wanted to attempt to do which is I always like to show community contributions I'm going to go to coding challenges gar IO a new one came in from David which is here so tictactoe with friends so I would like to return to doing more some more content and examples with WebSockets which is a way of having a way of having a continuous realtime network connection from the browser from JavaScript and I did a shared whiteboard and I look out of focus I'm gonna I'm gonna examine that again I did a shared whiteboard I did this sort of agario Agora IO and how to say it example and let's look at this and then I did tictactoe challenge I didn't do that let's take a look so my name is a coding train and then I don't know if this matters but I'm gonna just not show you the secret code I'm going to put in to join the game in case that makes it like sort of hackable in some way so now I put pacing in that code I'm hitting join game join game oh I don't see where oh there is no open game did I already join it hello Oh oh wait I'm in it I'm in it okay laptop come back alright I'm now in the game uhoh X's turn I'm oh uh oh it's gone again we found a bug I failed I failed he had the focus is up is it just like drifting the focus let's try it one more time where'd I put my focus device it's weird I could put it on to autofocus I thought that that's going to cause more problems than oh and I'm oh okay yes I'm so not yeah I can see that it's out of focus that's better all right I don't know I don't know I don't know all right sorry David I messed up in the discord thank you okay we'll try again later but you should make your commute let's see I don't think the to the latest video I released by the way is under the ml5 beginner's guide playlist and it should be down here ml5 pose regression I don't think there any oh there are oh you know it this is a mistake actually here's a bug bug report I'm not sure why this happened but this particular video ml5 pose regression and this pose classifier one oh no no no no oh no yes yes they're showing the same community contributions so there is a way for that that's supposed to happen and and actually so is this one maybe that's okay actually so maybe that's the point so maybe the all of the pose videos should have the same community contributions that's a nope now I don't know if that's a bug report that's an open question focus or not I have to resolve this you know where is the focus does this look more in focus am I getting more or less in focus as I come forward from like this is back middle forward middle back where is the focus the best worst or am I just like way all too much in my head and I'm fine oh it's really going well today I'm trying to give myself a reference point I was expecting some messages about the focus but I didn't get any that's loves like let me go through the whiteboard for a minute you got blurred I be not I saw like a math blank was typing and sarcasm as a service was typing but then no messages appeared I'm gonna give this one more shot this can I focus on have an idea have an idea we try the train whistle I really need to figure out tricks I need to figure out how to zoom the camera in used like I don't know what button will do that for me on this camera so I'm like looking really closely at the screen that's way out of focus I used to be able to zoom the camera way way way way way in and then on the confidence monitor I could really see it it's just better and that's out of focus I'm gonna get this I mean a soft focus might be good for me I think that's a little bit better can come over here no that's like totally blurry so weird what is going on I'm losing my mind this always happens to me it's weird with the camera today I think some settings changed on this camera I wonder if somebody people have been using this room and maybe settings got changed hold on let's see is it auto focusing oh it's on auto focus so the camera gotcha somebody changed to semi it's on auto focus I oh maybe I'm not oh I'm not scrolled all the way down on discord oh I'm not scrolled all the way down oh no wonder I'm nods good all right so I've determined the problem this this room has been used and the camera settings were changed ah right I'm not crazy it's on a foot is it Auto focusing on me yeah I know everybody's saying you want me coding but I I have a problem and I have to address it yeah it's autofocusing right so how do I change it back to manual I can't see the back of the camera I don't know what to do about this is alright I'm caution to the wind everybody a little I'm just gonna go I just got to go for it go behindthescenes action here so I can see the camera settings and also really test this autofocus theory oh yes yeah all right I'm gonna switch it to manual focus menu it says manual focus that was wrong about that oh this is autofocus this is what autofocus looks like maybe I should try it on auto focus it was not an autofocus I'm really interesting I think I need to go to the eye doctor that's the worst let's actually just try it on auto focus for a second not gonna tighten it in place this is this is now how to focus does it do a good job of finding me in autofocus so let's just pretend I'm coding for a little bit like I'm walking around and I'm tukya I'm talking about the coding I'm type type type in the coding type type type in the coding hey it's on autofocus is that actually like sort of staying in focus as I move around and talk talk talk about the code stuff I feel like actually the autofocus looks pretty sure auto focus or the wind I'm gonna wait for the so it's been brand Lmax Simon does not like the autofocus no it's blurry as hell so the autofocus was not good it seems to be good when I'm up here people I really do I really I realize everyone's having fun I really need help with this because I can't both stream and see and I haven't had this issue before and I can I have to change the settings on the camera I have to pull it all the way out from the wall which is not a great setup Oh brand Lmax saying it was good okay I mean the cameras in the wrong place so the moving is not in issues because the moving is it's because I didn't tighten it so that I'm not worried about it is a little bit and let me I need to get the level okay only if you're not in screen it jumps around so on autofocus right now which is what I think I'm gonna do I mean so let me just level the camera that's just not level right now which way is level that's level loosen it actually again so I can actually that's actually better for it to be pointed up because I can raise the desk thank you all for bearing with me I'm tightening it in place okay okay I think I have to get started I'm sorry everybody oh we were having fun till I ruined everything I saw an autofocus now I can't believe someone just joy interesting it does seem to asking me too well oh my god what just happened okay I have it locked what did it just do oh I'm so in focus right now I'm losing my mind I'm very very in focus and if I move over here I'm still in fact alright this is good I think if I'm still and which I am for most of the time it focuses better alright I have to give up on the focus and this is just gonna be good enough am I about the same size as I usually have just randomly changed a little it doesn't really matter because yeah I do see the laptop moving around I think though if I stay mostly I mean I do move around a lot but I don't move around a lot I don't know what just changed but it's like totally in focus now interestingly I do think that maybe some of the settings on the camera did change and I will investigate that at some point all right oh we mentioned I'm gonna get started I apologize to everyone it's ty can't believe this 1015 I do have two hours left so it should be time for me to do some stuff I do want to mention one thing which is that I did make another coating in the Cabana video about the hilbert curve so if you were waiting for that stay tuned I programmed this particular continuous spacefilling curve it makes a lovely example I also did something where I used Pross the alpha version of processing for there's a you're a little too high there's a purple line at the bottom okay yeah yeah thank you that's that's easy to fix position why's that Oh weird I'm less concerned with that stuff because Matthew when we edit we can fix that but I think I have now fixed it okay all right putting everything to side I am now going to talk about conflation of neural networks Oh my brain was sucked in the headspace for this and I've lost it a little bit okay looking here okay yeah these are the these are the links I'm interested in and these are slides and this is the example I made before and then I'm looking for us this particular post it's a really excellent one oh this was the diagram yeah yeah okay okay Wow focus is life's better than it's ever been I'm so focused I am focused on the task at hand I always get this thing where people say and an Ashwin just said it that I look like a character from the show called money heist which I've never watched maybe I need to watch that or maybe I just act like that character I don't know hello and welcome to hello welcome to another beginner's guide to machine learning with ml5 jazz video and in this video I am going to talk about something called a convolutional neural network what is a convolutional neural network what are the new operations in a convolutional neural network that are different from the kinds of neural networks we've looked at and I've talked about before and how can this particular example which I made in a previous video that just takes the pixels of an image feeds them into a plane neural network so to speak I'm not a convolutional neural network what would happen if I changed it to a convolutional neural network would it perform better what would what what what are the outcomes that's the point of this video that I'm making let me start by looking at let me start by diagramming the kinds of neural networks let me start by diagramming the neural networks that I've used before let me start by diagramming the neural networks that I've used in some of my let me start by diagramming what the neural networks looked like with ml5 neural network to date and all in the videos that I've made so there's been two layers a hidden layer and an output layer and then also there's some data coming into the neural network and in this case in the previous example it was an image which was flattened so I use the example of 10 by 10 pixels each with an R a G and a B so that made an array of of 300 inputs all these all these pixel values those are the inputs and those go into the hidden layer but just for the sake of argument let me simplify this diagram and I'm just going to consider an example with 4 inputs I'm going to consider that example as having 5 hidden nodes hidden units and then it's let's say it's a classification problem and there's three possible categories a vanilla no sorry us the ml 5 neural network by default creates so this has 4 inputs 3 outputs and 5 I don't know if I need that so when I call the function ml 5 neural network it creates this architecture behind the scenes and connects every single input to every hidden unit and every hidden unit to each output twit hi so this is what the neural network looks like each one of these connections has a weight associated with it each neuron receives the sum of all of the previous inputs to it in the previous sir each each unit receives the sum of all of the inputs times the weights passed through an activation function which then becomes the output which then all of those with those weights are summed into the next layer and so on and so forth so this is what I have worked with before the whiteboard camera is skewed no no it's fine it's fine it's fine I can't be bothered to like fix the cameras anymore let me use my level did you have a level here and let's just see it's pretty it's not so bad oh it is skewed I can I can I can turn it a tiny bit that's gonna make it a little bit better okay yeah that's better all right while in the previous example I was able to get this kind of architecture to work with image input and get results that that produced something if the output this can be improved upon and the reason why this can be approved upon is there is an aspect to this data that's coming in that that is lost there is there is there is information in this data that's coming in that is lost when it is flattened to just a single flat array and the information that's lost is the relative spatial orientation of the pixels it's meaningful that these colors are near other colors something in what we're seeing in the image has to do with the spatial arrangement of the pixels themselves in two dimensions at so there's um in order to address that we want to add into this architecture I really spent a lot of time drawing this diagram which I've now good at mostly a race which is also a hidden layer anything in between the inputs and outputs is a hidden layer but we want to add something called a convolutional layer so in this video I want to explain what are the elements there are units nodes neurons so to speak in a convolutional layer but what are they and one of the word that's typically used is actually called a filter which makes a lot of sense now convolutional neural networks can be applied to lots of scenarios besides images and there's a lot of research into different ways that they can be used effectively but I'm gonna stick with the context of working with images because the word filter really fits with that we're filtering an image how is this layer filtering an image there's another step here called Knoll implement I'll come back to it all right pretty sure that so much your factcheck for this for me but this is now the idea of a convolutional layer is not a new concept it dates back to the it predates this deep learning boom so to speak boom this other so the idea of a convolutional layer is not a new concept and it predates this era that we're in now a so called deep learning and in fact if you want to like go back and find the and if you want to go back and find the and if you want to go back and look at the origins of convolutional neural networks you can find them in this paper called gradient based learning applied to document recognition from 1998 section two convolutional neural networks for isolated character recognition convolutional networks and here we can see this diagram which is I'm attempting to kind of talk through and create my own version of over here on the whiteboard itself I think someone's at the door hi looking for something ah okay this is a recording studio that's actually live live broadcasting yeah no problem okay I probably should have muted my microphone before I answer the door this is also the original paper associated with the EM mist dataset a dataset of handwritten digits that's been choose umpteen amounts of times in research papers over the years related to machine learning this is another yeah okay so this is what I want to talk about next which I'm going to come back to okay okay let's go back let's I know I'm going back and forth a lot here but let's go back to thinking of the input as a twodimensional image itself so this twodimensional image and let's not say it's ten by ten let's use what the Emnes data set is which is a 28 by 28 pixel image and of course now much higher resolution images are used and this is what is coming in to the first convolutional layer this image is being sent to every single one of these filters the filter is a the filter is a matrix of numbers and it can be the matrix is the fill a filter is a matrix of numbers and let's just for example let's have a three by three matrix so each one of these filters represents each one of these filters represents nine numbers a matrix that's three by three you could have a five by five filter or and so on and so forth but is sort of standard size or a nice example size for us to start with is three by three each one of these filters is then applied to the image each one of these filters is then applied to the image through a convolutional process this by the way is not this by the way is not a concept exclusive to machine learning this idea of a convolutional filter to an image has been part of image processing in computer science and computer vision algorithms for a very long time to demonstrate this let me actually open up I can't believe I'm gonna do this but I'm gonna open up Photoshop sign in oh I have a creative cloud account hold on a second I didn't think I'd have to sign in to legit you're gonna watch apex legends videos now when I'm here talking about convolutional neural networks okay um Adobe oh no that's the wrong or oh I have to like login wait I wonder if I log in it's through my NYU account just give me a second here let me try to login I just want to show you this this is such a fail I do have an Adobe Creative Cloud account I very lucky to have that through New York University I logged it to by NYU account let's just do that figure out how to log in properly so what I want to do is let's get an image this is how I it's way too vain all right whatever let's let's get an image of a kitten and more settings where's that thing usage rights labeled for reuse with modification actually I should get the quickdraw I should maybe I should I thought let's use the kitten okay what you can't go wrong with a kitten didn't I just download this kitten let's do this doesn't hurt to have the highresolution one for Photoshop save image oh my god I never never been so difficult to open a kitten image I don't need to uh I mean I do need to learn Photoshop all right now in Photoshop you might notice there's a filter menu why because all of many now in Photoshop so here I have in Photoshop and I've opened this image of a kitten and there's a menu option called filter this word is not filter by accident it's not called filter by accident over here either there's a connection so all of these types of operations that you might do for example like blur an image these are filters convolutions applied to the image I'm gonna go down here under other and select custom all of a sudden you're going to see here I have this matrix of numbers this matrix of numbers in Photoshop is exactly the same thing as this matrix of numbers I'm drawing right here each one of these filters in the convolutional layer represents a matrix of numbers that will be applied to the image so let me actually just put some numbers in here I know how easy that is to see if I I mean this shouldn't if I do this does it actually make it yeah I'm looking at the chat this particular set of numbers happens to be a filter for finding edges in an image and you can think of it as these are all weights for a given pixel so for any given pixel I want to subtract colors that are to the left of it and emphasize colors that are at that pixel and above and below this draws out areas of the image where the neighboring pixels are very very different interestingly enough I could switch these to 0 and these to negative 5 can you see the difference let me do it top let me do actually I think would actually be better for me to show you like like do one above whoa yeah switching the convolution to have the negative numbers on the top sorry switching the filter to have the negative numbers on the top you can see now I'm still detecting edges but I'm detecting horizontal edges if you go back and look at the cat that I had previously versus this one you can see vertical edges versus horizontal edges so there are known filters which draw out certain features of an image and that's exactly what each one of these filters does if all of the nodes of a neural network can draw out and highlight different aspects of an image those can be weighted to indicate and classify the image in certain ways the big difference here the big difference between a convolutional layer in a neural network and what I'm doing here by hard coding into known filters is a neural network is going is that the neural network is not going to have filters hardcoded into them it's going to learn filters that do a good job of identifying features in an image so this relates to the idea of weights I think so if I if I go back to my previous diagram where every single input is connected to each hidden note where every single input is connected to each hidden neuron with a weight now the input image is connected to every single one of these filters and the weights are are the in a way there are now nine weights for every single one instead of learning goal weight it's going to learn a set of weights for an area of pixels to identify a feature in the image all of those all of these filters will start with random numbers all of these filters will start with random values and then the same gradient descent process the error back propagated through the network adjusting all the dials adjusting all the weights in these matrices and all of these filters works in exactly the same way exactly works in the same way so in the ml five series I haven't really gone through and looked at the gradient descent learning algorithm to adjust all the weights in detail I do have another set of videos that do that if you're interested but the same gradient descent algorithm that is applied to these weights is applied to all of the different values in each of one of these filters okay anybody watching this one add one a show Gaussian blur filter yeah me actually that's actually kind of a useful one to do I'm not going to show a Gaussian blur one one one one one one one one one oh it doesn't do I do this uh yeah okay this is like dividing by so how do i oh yeah oh yeah no I see it down there incidentally just to show a very common convolution album to album incidentally just to show a very common convolution operation to blur an image blurring an image is taking the average of a given pixel and all of its neighbors so here you can see if I give the same weight to a 5x5 matrix of pixels around a center pixel and then divide that scale is divided by 25 because there's 25 that's averaging all the colors if I click on preview blurred not blurred blurred not blur of course there are other more sophisticated convolutions like a Gaussian blur you can take a look at Gaussian blur and some ways to pronounce it you could take a look and research what that is but again I'm not going down the road to look at common image processing convolutions instead talking about that concept of a convolution as applied to an image in the process of a convolutional neural network middle one should be it doesn't need to be George it could be if I wanted it to have a higher weight but it doesn't mean there's no right or wrong answers to this as far as I'm concerned kittens and kittens are getting to get into Guinness alright so here's the thing I want to take a small digression here and program the convolution algorithm sort of outside of a neural network you can't tell the difference I can tell the difference there maybe maybe you need to like look at it at super high much higher resolution was that not an effective demonstration let me say this I wish it would like up it's always previewing it here zoom in on a little bit more yeah just to serve that zoomed in a little more I mean Matt sure can do his own zooming when we edit it but if this is helpful to record this okay if you're watching it on your phone I can't help you yeah okay it is a subtle blur all right let me go out of here and let me get let me get something here where's this example okay so like how these are through the second one save in the save cat oh no stop stop I put it in draw sorry about that just want one cat image this one so let me go back to here duplicate this convolution I don't know why I started with this example but oh it's no P image you I actually don't need the ml5 library for this I'm like a little bit a little bit silly would I why do plants let's do with this okay I'm going I'm just setting up the base coat I'm going to start with cat equals load image cat dot PNG and now let's draw and okay okay where are we 1050 all right so today I'm gonna do this convolution example and then take a short break I'm out of my copier so our knob is asking why 280 times 2 because the example I'm going to make is going to show the image and then the convolution applied to it okay just to take this Oh just to take this a little bit further going on my hair they seem like a weird like line see it over here this in my anyway just to take this a little bit further I'm going to demonstrate how to code the convolution algorithm in p5.js in truth ml 5 and tensorflow GS are going to handle all of the convolution operations for us and creating all the filters we're just going to configure a convolutional layer from a high level but I think it's interesting to look at how you might code an image processing algorithm in p5 I have some videos that do things like this previously but let's look at it in this context so I took a very low resolution 28 by 28 image of a cat this comes from the quickdraw dataset which I've made videos about before and I will also use to see if we can create a doodle classifier as part of this series and all I want to do is apply a convolution to that image so first I'm going to create a variable and I'm going to call it filter so this is going to be our filter and I'm going to make it a two dimensional array so let me just put all zeros in it to start you so this is the filter and let's go with that one that looks for edges let me make a separate image that is the same resolution as the cat image but oh you know what's interesting here I just realized something weird that's going on I'm not actually blowing up the 28 by 28 you created it to 80 by 280 image with like big blocks in it it's a little bit weird let me let me fix that I think if I do adjust I think it's gonna be more I don't let me just change this to 28 by 28 hit save and that's really the drawing of the cat then let me delete this one add file reupload it so now if I do this again we're gonna see just the little cat up there which is what I want but I want to draw it at all right that's a little blurry hmm now I have to start this whole thing over why did it because it's trying to smooth it there we go okay this looks so the code is gonna kind of like change a teeny bit in the middle of this video but that's fine the cat image itself is just 28 by 28 pixels I'm using a very low resolution version of that drawing but I'm drawing it I'm drawing it 10 times the size the cat image is actually quite low resolution just 28 by 28 pixels but I'm drawing it at twice the size I want to write the code to apply this filter to the image and draw the filtered image to the right I'm gonna create a variable called dim for dimensions and just call this 28 Oh and then I that I'm all out of order here but and then I want another variable to store the filtered image and in setup I can create that image so this creates a blank image at the same this creates a blank image of the same dimensions as the original cat drawing then I can write a loop and this loop is going to look at every single pixel from for all the columns X and all of the rows why I wrote int there because I am half the time programming in Java but one thing that's important here if we're going to take this 3 by 3 matrix and apply it to every single pixel of the original image if we're applying it to that first pixel 0 0 there's no pixel to the left and no pixel above it it doesn't have all of its neighbors so there's various ways around this but I'm just going to start with I'm gonna I'm just gonna ignore all the edge pixels so this loop will go from so the loop will go from 1 to dimensions minus 1 and stop using this autoformat okay now there's a lot more work to be done here just to apply this filter to any given pixel crime thing I think a way that might make sense to do this is to actually have a new function I would call the function filter let's just call it convolution I'm gonna write a function called convolution it receives an image an X and a Y and a filter and it returns a RG it returns a new color so the idea of this function is it receives ooh why did that shut off I'm turning that fan on is that it receives all the things that needs it receives the original image the filter to apply to it which particular pixel we want to process and then we'll return back to new RGB value after that after that pixel is processed and the reason why I'm doing that in a separate function is I need another nested loop to go over the filter so I need to go from I need to go to eat I need to go from 0 to 3 0 1 2 columns in the filter 0 1 2 rows in the filter and we're beginning to be quite a lot had 4 nested loops right in here now I probably shouldn't have some of this hardcoded in here the number 3 and that sort of thing but you can imagine how you might need to use variables if the filter size is flexible the Auto formatting of the editors driving me crazy okay there should be this yeah I'll leave I'll fix that later this is wrong there are 500 people watching no now now we have it really sort of like sad fact which is true about most cases where you're doing image processing with some framework and in this case our framework is JavaScript in canvas and p5.js and the sad fact is though even though all of this is built up all this discussion is built upon the fact that we are retaining the spatial orientation of the pixels we're thinking of it as a 2dimensional matrix of numbers the actual data is stored in one array and so I've gone over this in probably countless videos but there's a simple formula to look at if I have a given X Y position in a two dimensional in a two dimensional array in a two dimensional matrix how do I find the one dimensional look up into that matrix assuming that the pixels were counted wrote by rows 0 1 2 3 4 5 6 7 8 about next row you know twenty eight twenty nine 20 31 and that formula is let index well I need to do that before this nested loop because I'm looking at that right now I just want the center pixel that XY let index equal X plus y times image dot with so this is the foreman you think about it makes sense right because it's all the X's and then the offset along the Y's is how many rows times the width of the image but there's another problem which is that in JavaScript in canvas for every single pixel in this image there are actually four numbers being stored an R a G a B and an alpha the red green and blue channels and the alpha channels channel singular so each pixel takes up four spots so this index actually needs to say times for it so guess what you know what's gonna make a lot of sense I'm gonna need this operation a lot let's write a function for it index I'll just call it index and it receives an X Y and a width and it returns you know what the width is never gonna change in my sketch so I don't want to be so crazy as to have to pass it around everywhere so let's just gonna pull it from a global variable return X plus y times image dot width and that's not image it's cat dot with okay so once again this is terrible what I'm doing but I'm just saving myself a little bit of heartache here and there so this index ooh mmm let's call this this pixel is okay this should be x for this pixel is that function index XY ah I keep auto formatting and it does this thing that's fine I'll leave that there it's it's gonna be what its gonna be somebody must have shared this live stream because the viewership did just jump up really high and I wonder why okay now I have something I could do to simplify this but I might as well write the code for if this were a full RGB image this is a grayscale image but it has all the channels in it so what I need to do to perform this convolution operation if you go back and think about the Photoshop example that I showed is I need to add up all of the pixel values of the thing that I need to do to perform this convolution operation is to take all of the weights the numbers that are in the filter matrix and I need to multiply each one times the pixel value of all of the neighbors and their corresponding locations add them all up together and maybe divide by something if I'm if I want to sort of like average it out but in this case I actually don't want to divide by anything I'm just gonna leave the weights or the weights or the weights are their weights and actually this right here is irrelevant I don't know I need to do this inside the loop you'll see in a second I think it's gonna make sense so I need some I'm gonna make a sum of all the R values a sum of all the green values and a sum of all the blue values then I need to get the R so now I need to get the pixel which is this is not 0 to 3 oh yes it is I'm looking up in the filter oh yeah all right wait a sec wait a sec wait a sec let's actually I think this is gonna be make more sets look go from negative 1 to 2 you'll see why let me I'll explain why and negative 1 to 2 let's do that instead and maybe it's more clear to say less than or equal to 1 less than or equal to 1 because and let me draw this diagram once again if this is pixel 0 0 this is pixel negative 1 negative 1 this is 1 comma 1 this is 1 comma 0 this is a 1 comma negative 1 I guess I'll do them all right so you can see that the neighboring pixels are offset by negative one and one and negative one and one so the pixel X value is X plus I the pixel y value is y plus J and then the pixel index is call the index function X which returns the actual index into that array for pixel X and pixel Y and actually maybe it makes more sense for me to just say that I don't necessarily need separate variables it might actually be just as clear just to put this right in here okay am I missing chat messages no okay so ombre is asking can't you load grace that images that's grayscale for simplicity I could I absolutely could but I'm gonna just go with this because then me I could also demonstrate this with an RGB image a little bit extrapolate better but yes I absolutely could so now I just need to add the red green and blue values at this particular pixel to the sum so some are plus equal image dot pixels at that pixel index and then G and B G is the next one and B and B blue is the next one and let's add a plus zero here just to be consistent so ultimately what I'm actually returning here is our is some our G is some B and B is some good some of us are G is some g and b sm b so this is the process now of adding up all the pixels I've gone through every single pixel in a 3x3 neighboring area and added up all the reds greens and blues and returning those back guess what though I'm missing the aah why is this camera going off it's not the coding train if the cameras don't just go off every once in a while or all the time but I'm missing the crucial component which is as I'm adding all the pixels up in that area I need to multiply each one by the value in the filter itself incidentally I should also mention that this what I'm the operation that this really is is the dot product and in an actual machine learning system all this would be done with matrix math but I'm doing it sort of like longhand just to sort of see the process and look at it so what's what should I call this in the filter like the factor now I need to look up in the filter I comma I J only here's the thing because I decided to go from negative 1 to 1 negative 1 to 1 the filter doesn't have those index values it goes 0 1 2 0 1 2 so this has to be I plus 1 J plus 1 so it's all six of one halfdozen to the other whether I go from 0 to 2 there and do the offset in the pixels but the point is the pixel array I'm looking actually to the negative and positive to the left and right but the filter is just a three by three array starting with 0 0 in the top left so now I should be able to multiply by factor can I fit this all in one little spot yep and there we go I have the full convolution operation I might have made a mistake here I think this is right when I run it we'll find out if I made a mistake I'm take I'm summing up a 3 by 3 neighborhood of pixels all multiplied by weights that are in a 3 by 3 filter oh but I actually have to call that function here now which should be relatively easy because all the work was in there so if I say let I'm just going to call this RGB equal convolution the cap at a given X and y with the filter then the new image which is called filter oh I have to look up it's okay no problem the pixel is index XY and then filter and so I have to look up the one dimensional location in the new image and then at dot pixels at that pixel is the RGB the red value that came back plus zero plus zero plus one plus two green and blue and then if all goes according to plan I should be able to draw the filtered image at offset to the right with the same size I did miss something kind of important which is that if I am working with pixels of an image in p5 I need to call load pixels so cat dot load pixels filter dot load pixels and thence I haven't changed the pixels of the original cat image but since I changed the pixels of the filtered image afterwards then you just call update pixels and now is the moment of truth never never good when I pressed the snare drum button to run the sketch all right well I've already got an error cannot read properly load pixels of Oh filter filter filtered that should be filtered also this isn't right create canvas the size of the canvas is times ten times two times ten remember the image is just 28 by 28 let's try this again a little bit better didn't get any errors I'll see in image where did I go wrong do I need to give it a hardcoded transparency of 255 yes oops so uh it was fully transparent so I'm not pulling the transparency over I could pull it over but I just know I don't want to be transferred look at that look at how it found the oh oh look at this that doesn't look like it's finding the vertical edges pixels that are different to the left looks like it's finding horizontal edges and you know Oh Simon saying do you know that 10 times 2 is 20 I know I know Suraj is really asking me to say their name so I guess I have just to get that to stop please don't post things like that I mean I appreciate your kind thoughts but it does fill up the chat but let's say the name Sir Roger schwa so that we can move on okay thank you for all of your support and for watching the channel now the wreath the reason why this is detecting horizontal edges and not vertical ones is because of the way that I'm doing my loop I is first in the loop I don't know why is that I mean if I think of why yeah because if I is the xvalue oh it's the yeah yeah yeah the reason why it's finding the horizontal filters rather than the vertical filters is even though I wrote it out this way the inner loop down here is looking at right is yeah but shouldn't it match up I'm like I'm like I my brain is a little fuzzy here no I know I know how to fix it I'm just trying to get the words to explain this why is it doing not doing it because x+ I mean if I is changing cuz I corresponds to the outer the outer array okay yeah so even though I've written it this way so visually these negative ones appear as if they're like a vertical column the inner loop is actually iterating over the the the smaller arrays inside the inner loop is actually entering over for these smaller arrays inside the larger array so I not the inner loop no no one more time with feeling even though even though I've typed this out in a way that visually these negative ones appear in a column it's actually those correspond not to the J index but to the I index so I think one way to fix that would just be to swap it here and and maybe I just like a more elegant way of doing this but this now if I run it this way you'll see ah look at those horizontal edges no need to apologize Suraj I appreciate your interest so now we see how this convolution is applied to the image what's actually happening is to go back for a moment to this neural network process is we don't know what filter is going to produce a meaningful output to recognize what's in the image oh this camera must be overheating I don't know why I'm it's not that hot today 77 degrees in this room but we don't know what filter is going to produce a meaningful output in order to recognize or highlight something that's in the image and sometimes we might need multiple filters to highlight different things all right I've got a fan for this in case of emergency so let me blow this fan I think the camera is overheating which usually doesn't happen with this amount of like so hold on I'm just you know just to blow the air around here for a bit it's a little bit loud but I don't want it to you can always process the audio later the difference in the neural network here the convolutional neural network is we're not hard coding in specific filters that we know highlight things in an image the neural network is going to learn what values for the filters highlight important aspects of the image to help the machine learning tasks at hand such as classification so it might draw out you know cats tend to have you know ears that appeared a certain way and this kind of filter like brings that out and then leads to the final way final layer of the network activating with a high value for that particular classification so just to keep my example simulating the neural network process a bit more let's just every time I run it give it a random filter because that's what the layer would begin with just like a neural network begins with random weights and learn to the right weights the filters begin with random values and it learns optimal values so right here and setup sorry right here so right here and setup I'll write a nested loop and give it a random value between negative and one now in truth convolutional neural network but in truth there are other mechanisms and strategies for starting for the initial weights of a convolutional neural network but picking random numbers will work for for us right now just to see so every time I run it you can see we get a different result image that is filtering the image in a different way okay so I'm it's 1120 I have an hour in 15 minutes left the next thing that I'm going to do is talk about one more operation called a max pooling that's another the operation that happens after this filtering process then I will zoom back out and look at the the full architecture of a convolutional neural network and that will finish this first tutorial if I have time I'll then actually show how do we nem l5 add a convolutional layer to a neural network so let butBut I want to take a short break and I want to take this time to thank whoops the sponsor of today's coding training episode oh look everybody left only thank you short breaking I want to take this time to thank the sponsor of the coding train today which is audible.com so I happen to be already I'm so excited about this because I happen to already be a audiobook listener I do try to read books as well I mean that's a thing but I do I spent a lot of time on the subway I spent a lot of time jogging exercising I don't spend as much time as I would like and I find that listening to something music is the thing to listen to but for me listening to audiobooks is a way to a have a chance to to to learn something that I don't have the time to read the physical book and it's just it keeps it's energizing I really love it and I am so excited cuz I didn't know this I listen to a lot of different kinds of audiobooks I listen to you know detective novels and strange non and historical nonfiction and different kinds of things but I hadn't really looked into whether there were machine learning audiobooks and so the exciting thing that I'm gonna tell you is that if you go to audible.com slash coding train or text coding training to 500 500 you will get a free audio book a 30day free trial of the audio audible subscription which every month you get a free audiobook and two audible originals which are original content for by audible but there's a book that I want to recommend which I'm going to see if I'd bookmark yet before I started which is called you look like a thing and I love you which is how artificial intelligence works and why it's making the world a weirder place by gianelle shame I started listening to this yesterday and verso books so a wonderful about this book is a lot of the work of Janelle Shane is generating text with AI and she's going through in the book how a lot of like how a lot of times she gets nonsense and the audiobook narrator she's say I don't know it pronounced sexy sands performs all this like nonsense speak and it's kind of hysterical and wonderful and delightful so this book both has a wonderful set I mean it's a really great companion to the stuff that I'm teaching about because it goes through the concepts but it also looks at in the context of creative arts and sort of making weird stuff so I couldn't couldn't recommend it enough for you to listen to let me see here if I'm missing anything else that I want to tell you about audible so audible members can choose three titles every month a one audio book like this two exclusive audible originals that you can't hear anywhere else and you also marble gnomes also get access to exclusive guided fitness programs so just start to start the new year off it's still it's not February yet you can still start the new year off of the news resolution to listen to an audio book to listen to an audiobook once per month so you can start listening with a thirty dre 30day audible trial choose one audiobook and two audible originals absolutely free at audible.com slash coding trade or text coding train to 500 500 okay so I'm gonna take a short break to refill my bug of I don't know what I'm gonna put in it water tea coffee who waits to be seen what I'm gonna find in the kitchen over there if you have a chance and to give audible a try while if you're still hanging around for the second half of this live stream you can take your time to do this in this break and I will be back in just about five minutes to continue this convolutional neural network example hi everybody it's gonna just be three or four minutes more so I'm just this song heads in about 30 seconds so I'm just gonna scrub it back in the beginning I'll be back in just about three or four minutes moving as quickly as I can okay thank you for your patience I am back so again thank you to audible.com you can get a free trial at audible.com slash coding trained and I look this book is so wonderful I actually ordered I'm listening to the audiobook right now and I also ordered the hard copy but it hasn't come yet otherwise I'd wave it in front of you okay close this and we are back here so I'm going to save this as is and now I'm going to say duplicate convolution max pooling okay oh and this I can remove maternal coder says the viewer instant rise happen twice what if someone is viewbotting that seems kind of unlikely that someone is viewbotting I mean why would anybody do that I mean it did that the fact that I've been twice in it was very consistent with the numbers a little bit odd usually when this happens it's because just somebody happens to share something on social media or YouTube is doing like weird stuff with its recommendations and all of a sudden it sends a whole bunch of people who all like calm and then instantly leave when they realize it's not what they're looking for so who knows hip chocolate chip hope your midterms went well and marshmallow is asking can I post two links of a project so I don't know maybe you're asking about posting links to the YouTube chat I will mention that what am I saying ah so if you want to share stuff the two ways to do it or there's lots of ways to share stuff but in terms of coding training community is the discord so I will post the discord link I have a button that does that now so that discord link should appear in the chat but it's actually going to appear before I say this chat is a realtime but there's a 30 second lag from what I say and when it reaches your ears and then also at the coding train comm there are ways of adding links to projects that relate to particular videos or challenges okay everyone wants to know what's in the cup so this is why I took a little bit longer I was like I feel like I need some coffee and I was like no coffee I was like I you know what I don't you drink coffee I just need water I filled up with water at a nice full mug full of water but I really love this bug so much I'm waiting for it to be a sponsor so kind of three hit me up fellow mug I think it's called so I figure what the company is anyway audible.com slash Cody great um mostly saying ah but then I was like I need a couple more minutes I need to make a quick little bit of coffee so I made a little coffee sort of coffee hello to or and prom and other people in the chat 232 and the chat is asking can you give temporary permission I could but it's is I can't manage that while I'm livestreaming so I prefer people to share links I just keep the YouTube protective settings on and that's the way it is and welcome to Brian's heart all aboard on the kodi train with your kodi train membership you have received a random number sixty five thousand and seventy six oh thanks for watching the promises videos says or appreciate it alright now what am i doing so just so you know I have look kind of like a hard stop at 1230 and there's a there's a workshop happening in this space I'm starting at 100 so I need to get out of here and kind of clean up plus I need to move on my day and eat lunch and do other things as much as I would like to livestream my voice is starting to hurt I might talk for a lot but I'm good thing for you is hopefully maybe even as soon as next week a video that's not edited out of a live stream will be coming live on the channel a coating in the Cabana video it's very cold during that video it's snowed so stay tuned for that all right what am I looking for max pooling back to this paper or there's this yeah okay okay oh by the way this is just from Wikipedia but this is you can see just a lot of additional these are a lot of sort of common convolution filters for certain kinds of operations okay so I this is sort of my notes I hesitate to use a lot of these diagrams and images in the edited version of the video that's coming out I mean certainly I would credit them but they're not ones that I've made and I want to be thoughtful about you know I want to feature the work of others but I also want to be thoughtful about having permission to use theirs other's work but I think this paper where did the paper go where is the alright I just want to see I like a kind of like using the the yawn Laocoon paper with other authors there are as well where's the oh here we go I just want to see if max pooling us in here sub Oh is subsampling is sub sampling the same as the max pooling operation cuz it doesn't say in this oh no I have to do this every time now welcome loonies pouch to the cutting trees aboard the cody train cheers you have entered the cafe cars where I will be drinking my coffee say hello to you Kate week Mon writes I think so I'm pretty sure that he's referring to my question I'm so happy that King week joins Minh is watching because it's it really helps me to stay sane and know that what I'm saying is not completely crazy is this actually oh this is I can search this PDF pooling pooling does not show up my guess is it's the subsampling if anybody knows this for sure I would appreciate okay all right so okay I was indeed all right okay now that I've wrapped up talking about the convolutions there's one other there's many other aspects to this diagram but there's one other really important operation that happens in a convolutional neural network that's described in this diagram it's subsampling that I want to add to my diagram and my code demonstration and that is and I'm not going to call it sub sampling I'm the common term for this now is called pooling and in particular the operation that I want to add is max pooling so there are different kinds of pooling you could do but max pooling is the standard pooling operation for a convolutional neural network so max pooling I mean it's another layer it can happen at any given point so we could max pool before we apply the convolution but I've typically speaking the convolutional filters are applied and then after those are applied we get new images out of those and those go through a max pooling layer so I think to describe I think I need to erase this whole diagram so that I can look at max pooling and then we could kind of come back to this when we look at the full architecture so let's begin with our 28 by 28 image then let's assume I have one filter just to simplify things I had one filter that was three by three one thing I didn't discuss and it's gonna be more relevant with the max pooling layer because I'm gonna do something specific with it is there's a term you'll see called stride and stride refers to remember this filter you know I'm not gonna actually do this 28 by 28 but this filter is applied to each and every pixel we take we take this filter apply it to this pixel and this gives us a new image pixel apply filter take the result into a new pixel pixel apply filter take the result put it into the new pixel here's the thing this is 28 by 28 this is a 3 by 3 filter I had to start with this pixel right here right because the edges don't have neighbors on all sides so ultimately this and stride sorry stride refers to how far I pass the filter along as I'm going through the image I don't really have enough spots here but you know I could I could take the filter and jump over pixels as I'm applying it to reduce the resolution of the image in this case I had a stride of 1 in my code that I wrote the stride was 1 I just slid over by 1 and we can actually see where the stride would go if I go back to my example this ultimately right there the X plus plus y plus plus that's the stride so I could say X plus equals stride y plus equals stride and set the stride equal to one so that's what was happening here but even with a stride of one if I'm skipping the edge pixels my new image is 27 by 27 so one thing that's really key to how a convolutional neural network works is that the image over time as it goes from layer to layer to layer so this is the convolutional layer with the filters and now I'm going to talk about the pooling layer the resolution is reduced and this has a number of benefits one is images are high resolution with millions of pixels so this the this learning space of a neural network to learn all the parameters of every pixel connected to every filter throughout multiple layers it would just be much too big to realistically be computationally realistic to do so this process of reducing the image down and down and down as the layers is effective in keeping things manageable but it also has another benefit which is we're trying to boil the essence of the image down into something that will highlight key features in that image and so this is really what the what pooling does what max pooling does a 11 thing it does is it really reduces the resolution which I'll show you in a second but it also picks and chooses the pixels that have the highest values to emphasize those what is really being activated so pooling comes with a matrix as well it's not really a filter but it's a matrix and a standard matrix might be two by two and so let's take the case and actually let me erase all this just to zero in on pooling I'm gonna try to let's come up with a simple scenario what if I did 8 by 8 terrible 1 2 3 4 5 6 oh I'm the worst one two three four five six seven oh so close eight one two three four five six seven eight so describe this I'm going to start with an 8x8 image and I'm gonna do max pooling with a two two by two max pooling with a stride of two so there are no weights this is not a filter it's two by two is just describing how much of the how many pixels am I looking at at one given time so if if I'm looking at a 2x2 area of pixels for each iteration of this algorithm and then my stride is to the next set of pixels on look at us here the next one is here the next one is here so for for the for the columns I end up looking at four and for the rows it's the same it's eight by eight four so actually the result I just want to point out that after max pooling and actually I don't know I don't need to draw it that far over the result after max pooling is four by four four by four now how does the algorithm works but this sounds like some fancy thing this is actually the simplest thing ever basically for each one of these areas of two by two pixels take the largest value the brightest color and put it in there so so I'm gonna fill in some arbitrary values here I don't know how easy this will be to see but let me just write some values so I'm not gonna fill this whole thing out but you see I don't know how well you can see this but I have the numbers for 8 negative 1 to the highest one is 8 it goes here I have the numbers 3 3 1 9 the highest one is 9 the highest one is 1 the highest one is 10 and so the max pooling algorithm takes these little neighborhoods 2 by 2 max pooling skips goes from one to the other with a stride of two I could have just moved these neighborhoods just by one or by even a larger amount but this is pretty typical and then takes it down this has to be this has the benefit of sub sampling the image reducing it but not just we can do average pooling so you could do average pooling averages all of these but it turns out convolutional neural networks perform better with max pooling over average playing maybe not in all cases but in sort of like the standard image classification case and this is because what we're looking for our features in the image that we want to highlight and so by looking at an area of pixels and seeing which pixels were have activated the most and keeping that one that's going to really emphasize then help boil the essence of the image down into something lower resolution oh just no one use max pooling anymore am I so like out of date me I am so me I will I will do it really likes my member joining bit which I very much appreciate the spontaneous thing I thought of today I will happily when if I have some time so just to be accurate in my video here should I add a little sentence about what is now more commonly used in max pooling truth teller says me tells me truth teller is name is truth teller so truth teller I know because when I see something on the internet I definitely read it without being critical or thinking about whether it could be accurate at all right no but I you know I have no reason to doubt truth teller K weak bonds confirmation could really help me though I don't wanna put too much pressure on K weak mine max pool plus average pool is better dilated is dilated pooling the same thing dilated pooling whoa max pooling dilated pooling all right max pull is most common all right I should add just to be really accurate here and the chat is tell this is offering some different opinions about this that while max pooling is the most sort of like common historical example of while max pulling is the most common historical example of pooling in a convolutional neural network there are other other researches showing promising results from things like dilated pooling which is a new concept to me that I just looked up and read about some combination you can also do a combination of max pooling and average pooling so there is I think some discussion and research happening there and I'm not here to tell you what is the optimal way to architect your convolutional neural network I just want to talk about and explain the process and look at an example of it which is very common like max pooling in particular okay I think that's enough that's enough for me to say an ADD so now so let's add max pooling okay I'm trying to think of how to do this would IMAX pull the our G's and be is separately I think I would write or would I take the pixel value that is the would I take the pixel value from whatever from the one that has the highest like brightness like the average RGB like could I take different ARS and G's and beats from different pixels in the neighborhood or do I have to take the full RGB from one that happens to have the highest brightness I don't know can someone answer that for me before I move on and I have about a half an hour left this might be the last thing that I do today I'll wait terrible thing for you to do just like have a question and not bother trying to research it or think about it just like ask it wait to the National for me in the past I guess I'll start writing this code maybe take RGB separately so maybe I'll just ask this question as I make the video and I'll just pick one way of doing it since there doesn't seem to be a consensus in the last few seconds so I'm gonna write another function much like convolution but call it pooling and the same thing it goes here I want to receive an image I want to find a certain XY I want to same thing happens here I want to receive an image I want to give an X Y I want to return some RGB value that is the highest RGB values within that neighborhood now there's an interesting question here do I take the RGB values from the brightest pixel whatever they might be or do I just take the the highest are the highest gee and the highest be independently and they could be from different pixels I don't know the answer to that right now let me take the RGB from the brightest pixel no that's gonna be more work let me just go with actually picking the brightest are the brightest G and the brightest B separately independently so I'm gonna start with the brightest RG and B and I could start with zero but just to be really really safe you absolutely absolutely absolutely in the convolutional process there's the the idea of pixels is gone really just dealing with numeric data and so I really should if I'm gonna try to find the brightest a start with in negative infinity because that's the lowest possible number you know in JavaScript that is then I want to look at this 2x2 area and the same thing that I did before in convolution I and the same thing that I did before in the convolution I want to look at the given pixel and its neighbors yes starting with the color II which definitely made life difficult for myself it's silly cuz the image itself it's great scale but whatever at the end I'll load my color image to see that this actually works with color and then I could get the RG and B from that pixel and now I just want the maximum I want if this R is greater than that print that what is being stored as the brightest are then that are should be the brightest are which I can do with the max operation right R is the biggest between bright R and R and the same for G and B oh and the same for G and B oh and that has to be 1 & 2 so this is actually all that I need to do this is max pooling right here but now I just need to return bright are bright G and bright B all right next I'm going to create yet another image I'm going to call it pooled and pooled is also a blank image however if you recall I'm going to use a stride of two so the resolution of that image is reduced further by half so I'm actually going to take out the stride from here and I'm going to create a global variable for stride but this stride is only referring to the pooling process because then I can say create image dim / stride dimensions / stride sorry I'm lost here so just to add some comments for a moment this is convolutional layer i mean i'm simulating the idea of a convolutional layer i'm not actually there's a neural network here there's no machine learning here I'm just going through these particular algorithms without matrix operations I should add then let's add the pooling operation so same thing here I'm going to go through all of the pixels in this case I can start at zero but I still need to only go to dimensions 1 because maze I'm going to skip every 2 pixels and I don't want to end up here so this is plus equal stride and this is plus equal stride I can do the same exact thing I can create a variable called RGB which equals now pooling I want to pool what were my arguments the image and the XY Y is there oh and I should probably call this like max pooling but whatever oh no no I'm not pulling the cat the cat was filtered with convolution and then the filtered image is pooled so I'm pulling filtered at this given X Y then I need to figure out where am I putting the resulting RGB values I'm putting them in the I'm putting them in the image called pooled but that image has the dimensions of half so the pooled X is X divided by the stride the pooled Y is y divided by the stride and then the index is and yeah so this is why this function really needs the image passed with it i I should not have used the global variable it was terrible idea because I want to reuse it but I have a different resolution of image so I'm gonna go back to making this image and then where did I call it here it's image dot with here it's cat oh I don't need to do the dot dot with it's just the the particular image that I'm calling the operation with I needed here image anywhere else oh here image so now I could say index of pixel X pixel Y in the pooled image because I want to say pooled dot pixels pix plus 0 equals RGB are and I need to add the load pixels and update pixels and now this should be the max pooling operation go over the filtered image by the stride for every 2x2 area find the highest RGB values and then add those to the pixel the corresponding pixel in the lower resolution pooled image let me make the height of my canvas times two so I can put the pooled image at the bottom right so the filtered image went off to the right and now the pooled image should go also off to the right and let's give this a try I don't see the pooled image lines think of the chat zombie line 61 is an error this should be a G what did I miss oh I forgot to add the Alpha again I always forget this so I need to give it the Alpha there we go so let's go back to a known filter instead of having random filters so that was my edge detection and you can see this is just I mean visually what I'm seeing right now is kind of like a lower resolution version of what you have above but if I were to rewrite this with say average pooling I think you would see it different it wouldn't come at the most features these edge features that it's you know in a neural network would be discovering here I'm telling it to look for those are highlighted even more than they would be with just average pooling itself right so now that I've shown you the code for both applying a convolution filter to an image and then a pooling algorithm to that image with a variable stride I think that I can now go back and look at the larger rket the larger diagram of the full story of a convolutional neural network that has these components in it and again our reference point is this diagram from the 1998 paper which is called the 99 1998 paper gradient based learning applied to document recognition but Matt Joe when we edit this we can just leave this there I've just needed to read what the paper was gone and then so what where was I okay just want to also I also just want to highlight for you a blog post that was super helpful for me in like figuring out what to do and talk about in or was it I also want to highlight for you a blog post that was really helpful for me when I was reading up and researching and trying to learn about convolutional neural networks it's this blog post right here an intuitive explanation of convolutional neural Oaks from night from 2016 this diagram is super helpful this is exactly what I want to talk through basically and there are a lot of nice visual diagrams and animations of the convolution process convolutional filters as well as the max pulling algorithm itself as well okay forget that that research as it worked very well let's look at the here's my best attempt now at the full story of the convolutional neural network we start with an image the first layer is a convolutional layer and I'm writing 2d because a lot of times in a machine learning library you can have convolutions in different dimensions and we're working with a two dimensional convolution here the convolutional layer has a number of filters the image is sent to every one of those filters and the these filters are applied I should say that the pixel the values that come out of the filters aren't just the raw values from the convolution process they're also then passed through an activation function the same kind of activation function that is in a standard neural network our standard dense layer the let's just assume the same kind of the same kind of activation function that's in a standard layer or a dense layer so typically this would be rectified linear unit or raloo typically this would be rectified linear unit or e Lu then the next step is max pooling I'll represent that with little squares so the image that comes out of the convolution and the activation function is then max pooled and then the output there is another image so we take this first image pass it through a bunch of filters max pool then and then we have a whole bunch of new images that aren't most likely if I'm using the stride if the a whole bunch of other image that if I'm using a stride of two now have half the resolution as the original image so the question becomes what to do next well we could be done and pass this to what I what is the last layer and if we're doing that at some point the Dana does have to be flattened so everything I did in my previous video about ml5 neural network with an image that just gets flattened and passed in that is what happens in the last layer the last dense layer takes these images and makes and has a hidden a hidden layer of neurons and each image is flattened and sent into all of those and then sent to the output layer yeah and then sent to the output layer and pass through the softmax activation function that I've described which gives it a probability for a classification if this were a classification problem but what's interesting is in most cases if you look at a lot of these diagrams for example this diagram on the blogpost I referred to or this particular diagram here you'll see convolutions subsampling convolutions subsampling so it's actually quite common in a convolutional neural network I really didn't give myself enough space here if we have another convolutional layer let's say there's just three convolutions filters this image goes into all of them I'm confused somebody help me out here for a second so let's say we have another set of filters this many filters this these images that come in there's one image that goes into all these initiatives initial filters then that gets max pooled and and we get a new set of images each one of these images would go into all of the filters but does that mean does that mean then I'm actually producing I now have one two three four five times four 20 images that get max pulled that must be right yeah we can see that happening here because there's this many images that get subsampled and then the convolutions are excellent name is saying they're stacked into a 3d image but ultimately that's the same idea filters must be 3d but here in this diagram it's showing it expand out right oops yup says Isaac let me redraw this to give myself a little bit room I'm running out of room and I want to diagram the full story I used so much space here for this image okay so here's the same diagram but squashed a little bit to the left here because what I want to do now is add another convolutional layer and another max pooling layer actually so here's the same diagram but squashed a little bit to the left because I want to add another convolutional layer and another max pooling layer so I'm gonna add some more filters here but something interesting is gonna happen here so let me actually do fewer filters in this next layer and I'm gonna be really I'm gonna just do only use there's only two filters here well these images that result from the first convolutional max pooling process they need to be tested are not tested they need to be sent to both filters so this image goes here this image goes here so in essence we have 1 2 3 4 times 2 times 2 filters and I'm not really drawing this well to have 8 in total so we get 8 new outputs out of this convolutional layer and each one of those needs to be max pooled so now I have eight images and remember let's say this was 28 by 28 these are all seven by I'm sorry 14 by 14 then after this convolution process and this max pooling these are all now seven by seven so we get these progressively lower and lower resolution feature maps of the original image with lots of different filters applied in lots of different ways finally and this is exactly and then the final result is essentially everything that I did in my non convolutional neural network with an image just that one hidden layer it's called a fully connected or dense layer and one output layer all of that gets put right here but instead of some original image being flattened and sent to it this whole process has happened and we're sending the data from these 7x7 images through the one dense layer and one and I've totally run out of room here so I'm just gonna put oh here output layer and this is where we would finally see is it a cat or is it a dog we would see probability values for the particular classification task and again if I come back to this diagram I just want to thank the author of this blog post because this is a much nicer more sort of like elegant way of drawing this and you can see actually this has two fully connected layers which is also a things so there are different ways you could architect this only drew seven somebody's saying one two three four five six seven eight one two three four five six seven oops I'm missing one here okay even though this is a bit of a mess let me go back and refer to the and thank the author of this blog post for this much more thoughtful and precise diagram showing these different layers how the images become lower and lower resolution become these final feature maps and then get passed through what's here is actually two fully connected layers so there are a lot of reasons why you might have different numbers of convolutional layers different numbers of fully connected layers different strides different filter sizes that another word for filter is kernel so this is it I really all I want to do this video was talk through all the pieces as well as show you some code that actually runs through and does those processes to an image itself which I think opens up a lot of interesting possibilities for you if you wanted to create a project around visualizing the process of a convolutional neural network as it's learning now this would be a much bigger endeavor than what I've done here because you need to create these visuals out of all of the pieces as the training process is happening but ultimately what I want to do next is 2/3 things and it might take a while for me to get to them but they will be eventually hopefully in subsequent videos one is I want to just create this exact architecture with ml5 I want to show you how the ml5 I can make ml5 neural network with a convolutional layer maybe two convolutional layers and then a dense layer and an output layer then I can take that and apply it to the previous example where I didn't use convolutional layers and just see how that looks I also would like to look at creating something called that I'll call I also like to look at something that we could call a doodle classifier so using the quickdraw dataset that I've referred to in a number of different videos could I train a classifier to recognize particular drawings and in fact ml five has built into it a doodle app retrain dual classification model that's pretty robust so you know I might try to train a sort of like smaller version of that write all the code for that with ml five but ultimately then show you how to use the pre trained that's in ml5 as well but that uses convolutional layers okay Soho thank you so much if you somehow made it all the way to the end of this rather long explanation and kind of tinkering around with code demonstration of what the process of convolution and pooling is in a convolutional neural network I hope to see you in a future coding training video I mean I don't really see you but I I feel your presence somehow and as long as you write a nice comment it brings me a little happiness to my day so I will see you in that virtual way in a future video and thanks for watching and have a great day that's not convoluted at all Oh Jean Cogan's what neural networks see ah let me reference that I meant to thank you yeah this is what I meant to reference yeah this is maybe we could fly in a little clip of this what I'm describing actually is really what I'm describing really has been implemented with gene Kogan's us video and lecture series called what convolutional neural networks see and you can see over here a visualization of all the filters being applied to genes a webcam image in real time so I've maybe given you the pieces now of what it would take to actually create a project like that yourself okay truthteller escape is spouting some total truth online to be fair that's a better cat than the cats in the cat's movie all right Simon Tiger points out for 32 by 32 images you can bring it down to a 1 by 1 pixel image in only 5 convolutional layer blocks which is a term ok it's a peek into the black box yeah yeah okay okay everyone thank you for tuning in I've got to go I didn't get so listen up listen if I go now let's just go to hear this I had a little guide here of what I think it's like under missing videos let's see a sort by recently updated missing visitor oh so oh oh my god so many things to do yeah let's revise this oh boy edit what are CNN's that was done well I was hoping to check off whoops that was I was hoping to check off more boxes but clearly I just I added more boxes and checked off one so I've actually gone back in time like they have Lord to do that what I had to do before I started today here's the thing I'm unfortunately gonna leave this stuff aside I would like to over the course of this semester fill in gaps here but next week with like when I'm back next week for a live stream which hopefully be next Friday although I am planning to switch to Thursdays but I think next week is actually gonna be Friday's I am going to start looking at it's gonna be a fairly beginner hopefully fairly beginner friendly a session on create vector and vectors in p5.js so all this stuff at least I have this list to keep track of stuff but and I will try to return to it hopefully I would over the course of this semester we'll see how that goes whoo thank you for tuning in let me put on this little song remind you that you can sign up for the discord and I have just posted the discord link in the chat also once again remind you to thank I mean I'm thanking and remind you that you could get a free 30day trial of audible a premium audible subscription at audible.com slash coding train and that gives you a free audiobook and two audible originals I highly recommend you now book that I talked about your a thing I love you what else do I want to mention any questions in the YouTube chat or the discord member chat I will gladly address in the next minute or two I'm not five minutes over so I really do need to stop gosh I hope the recording is fine from today to find out I didn't check it in the middle which I will sure did I mention the store standard TV / coding training I really you know I only want people to get stuff if they would enjoy it but I do have a vested interest and people buying the hoodie because they'll only make them if enough people buy them and I want one guess I could figure out a way to make my own today strange usually I can't keep up with the questions now there's just no questions well thank you very much and I am going to sign off in about 48 seconds I'm tired three hours is a long time live streaming pieces in four hours but we nice if I had another hour to keep going you try to get a little further but I think my brain is a little bit dead anyway time to do some gross stuff alright thank you everybody I will see you next week be on the lookout for edited versions of these livestream sessions as well as hopefully soon in the Cabana video see you in the discord I'm gonna do this this stock this start the starter this start song never forget the Vista autotuned and the internet will fix that for me coordinates so this is random this is noise Perley noise that is in the core random algorithm the actual random algorithm itself those numbers aren't related at all you pick like I'm picking random numbers between zero and ten nine two seven six one nine four eight nine to one thirty I think nine why apparently but with curly noise I might pick numbers like this two three four three four five six five four five six seven five six seven five six seven eight nine eight seven six well this is like pearly noise performance part these like girls and boys performances but with curly noise I might pick numbers like this by purling noise that is Hurley noise this is Hurley noise that is Hurley no this is this is Hurley noise that is Hurley no so this is Hurley noise that is her pearling know her Perlin noise that is Hurley noise this is Hurley noise that is Hurley noise so this is but with curly noise I might pick numbers like this this is like Perlin noise performance part unicorns and rainbows and cupcakes what else is there yes kids thank you very much kittens and rainbows and cupcakes notice that look what I get really losing my mind I feel just sort of like a nice feeling of relaxation everything's gonna be okay today dream is not broken it has not frozen this isn't this is a wonderful thing okay we're gonna do it I'm really getting to something I need my sound I will use it over and over again all sorts of text generation analysis states that I will use continuously over and over again
