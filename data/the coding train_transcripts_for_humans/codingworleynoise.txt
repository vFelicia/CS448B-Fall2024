With timestamps:

00:00 - [MUSIC PLAYING]
00:18 - Good morning.
00:20 - Welcome to Coding in the Cabana.
00:23 - I'm here with my
co-host, Gloria Pickle.
00:26 - And today the topic
is Worley noise.
00:33 - Now I'm particularly
excited about this topic.
00:35 - I'm here, quarantined at
home, like many of you
00:38 - are who might be watching
this all around the world.
00:41 - And I did a live stream where
I implemented Worley noise.
00:44 - So I've done this before, but I
had some technical difficulties
00:46 - and so I wanted to come back and
make a really short video where
00:49 - I just coded the algorithm,
explained it, and put up a web
00:52 - page so that you could
share your own versions
00:55 - of this kind of noise.
00:56 - The noise is nothing
new on this channel.
00:58 - I have covered all
sorts of kind of noise.
01:01 - Perlin noise being the most--
01:03 - the noise algorithm that
I use the most, probably.
01:05 - Now anytime I'm doing
a noise algorithm,
01:07 - we've got to talk about
how am I visualizing.
01:09 - I want to visualize
this algorithm,
01:10 - and I want to look at the noise
in a two-dimensional space.
01:13 - So I'm going to start
with a Processing window,
01:16 - and I just want to set every
single pixel color to a noise
01:19 - value.
01:21 - Now just plain old
noise is randomness.
01:23 - So let's set up, and let's
just do plain old noise first.
01:25 - In order to set every
single pixel of this window
01:28 - to a given color, I
need a nested loop
01:31 - to look at every single
x and every single y.
01:36 - Now the pixels are stored in
an array, and I can access it.
01:39 - It's just a global
variable in processing
01:40 - that's built in with
just the keyword pixels.
01:42 - But I don't know where
exactly I need to look at.
01:45 - I'll get to that in a second.
01:46 - So I want to set every
sing one of these pixels
01:48 - to a given color.
01:49 - Let's make it, just to start
with, some kind of pink color.
01:53 - So what goes in here?
01:55 - So if I have a two-dimensional
window, that's, let's say,
01:57 - it's 400 by 400.
01:59 - And let's scale
that down to 4 by 4.
02:03 - Every single pixel has an index.
02:05 - There's a number
associated with it.
02:07 - 0, 1, 2, 3, 4, 5, 6, 7.
02:12 - There's 16 pixels total.
02:13 - 4 times 4 is 16, and their
index values go from 0 to 15.
02:19 - You'll notice that 2 plus 4
is 6 plus 4 is 10, or 0 plus 4
02:24 - is 4 plus 4 is 8.
02:25 - So this width, four is the
offset between the index values
02:29 - in any given row.
02:31 - So there's a really nice
formula that I can use,
02:33 - which is actually just
take which row am I on,
02:36 - multiply it by 4, and
add that to the column.
02:39 - So if I'm on row 0, 1, 2 times
4 is 8 plus the column 1.
02:44 - 1 plus 8 is 9.
02:45 - Or in other words,
putting this in code,
02:48 - int index equals x
plus y times width.
02:51 - That's the formula.
02:52 - Look at the index.
02:53 - So this would set the
entire window to pink.
02:55 - Now if I run this,
it's going to tell me,
02:57 - I have no idea what
you're talking about.
02:59 - Because Pickle,
what did I forget?
03:01 - Exactly.
03:02 - That's right.
03:03 - Pickle knows, and one more step.
03:06 - I've got to tell
it I'm done with it
03:07 - so it can render those pixels.
03:09 - Birds are really chirping today.
03:11 - What a lovely day it is.
03:12 - There we go.
03:13 - There's my nice little pink
beautiful window that I love.
03:16 - So let's change this
to a noise algorithm,
03:19 - and pure noise is randomness.
03:21 - We've got this old-timey--
the television has no signal,
03:24 - and I know that
you watching this
03:26 - are watching this on your
tubular, old-timey television.
03:30 - Worley noise is a kind
of cellular noise,
03:32 - and the algorithm was
proposed by Steven Worley
03:34 - in a paper published in 1996.
03:37 - There's a really
basic, two-step process
03:39 - for generating the noise.
03:41 - First step is randomly
distribute feature points
03:44 - in space.
03:44 - So what do I mean by that?
03:46 - I have my two-dimensional space.
03:48 - I'm actually going to make it
three-dimensional in a moment,
03:50 - but let's start with
just two dimensions.
03:51 - And I need to randomly
distribute a bunch of points.
03:54 - So how many points
did I put here?
03:55 - Seven.
03:56 - Let's start with seven points.
03:58 - Easiest way for me to
create seven points
04:00 - is just make an array
of p vector objects
04:04 - and give it seven total spots.
04:09 - And then initialize every
single one of those points
04:12 - with a random place
in the canvas.
04:18 - Now one of the
things that you could
04:20 - do if you're making
your own version of this
04:21 - is think about, well, how do you
actually generate those points?
04:24 - Maybe they're the
points along the path
04:26 - of some other kind of design
or have some other algorithm
04:28 - to distribute them.
04:29 - But I'm just going to let
them be totally random.
04:31 - Let's take a look
at those points
04:32 - by writing another
loop down here.
04:36 - This is a special kind of loop
that looks at every object v
04:38 - inside of the array points.
04:40 - And I'm just going to actually
literally draw it as a point.
04:43 - Let's give it a stroke.
04:45 - Let's make it green so I can
really see it and give it
04:48 - a kind of larger stroke weight.
04:51 - And there we go.
04:52 - So now we see every
time I run this,
04:54 - I'm going to get a
new set of points.
04:57 - So step 1 is done.
04:58 - Randomly distribute
feature points in space.
05:00 - Step 2 is really where the noise
algorithm starts to kick in.
05:04 - f of n of x.
05:07 - So x being the given pixel, xy.
05:11 - So for every given
pixel xy, I need
05:14 - to calculate a noise value.
05:15 - And it is equal to the distance
to the nth closest point,
05:24 - meaning let's start
with n equals 1.
05:28 - So if these are
all my seed points,
05:33 - and then I happen to be
looking at a given pixel,
05:36 - for example, this pixel, which
point is the nth closest?
05:41 - The n being 1,
the first closest.
05:43 - That's this one.
05:44 - If I were looking at,
let's say, n equals 2,
05:49 - well, let's say this
is the second closest.
05:51 - Now you might start to think,
wait, this kind of reminds me
05:54 - of something.
05:55 - Let's just look at three points.
05:57 - I can kind of create this
tiling where all the points here
06:01 - are all closest to this one.
06:03 - And all of the points here
are all closest to this one.
06:07 - This is known as a
Voronoi tessellation.
06:09 - And this is a--
06:11 - Worley noise and the
Voronoi tessellation
06:13 - are completely interrelated.
06:14 - I'm actually in many ways
doing the same algorithm.
06:17 - Worley noise is going to veer
off into a different direction,
06:20 - but this is something I
should come back and revisit.
06:22 - How can I look at this
particular problem
06:24 - from a computational
geometry perspective?
06:26 - In the case of
Worley noise, we're
06:28 - just going to look at every
single pixel and its distance
06:31 - to the closest feature point.
06:34 - Every single point,
and calculate
06:38 - the distance between the
xy and that point's xy.
06:45 - And let's put all those into
an array of distance values.
06:51 - The reason why I want to
look at all the distances
06:53 - is because I want to
vary this n value.
06:55 - Sometimes I want to look
at the first closest,
06:57 - second closest, third closest.
06:58 - Maybe I don't need them
all, but let's just
07:00 - keep them all right now, store
them all into this array,
07:04 - and then after that,
I can sort the array.
07:09 - That's an array also.
07:11 - So I could write my own
algorithm for sorting an array,
07:13 - but processing has it built in.
07:15 - If it's just an
array of numbers,
07:17 - processing will sort it for me,
just with the sort function.
07:19 - And let's ask the question
of what n do I want to use,
07:22 - if I want to use n equals 1.
07:24 - Then the color-- it's not
going to be a random value--
07:29 - that noise value is
front distances n of 1.
07:33 - And actually, so n
should be 0, because 0 is
07:35 - the first element of the array.
07:37 - And I'm going to
set it to a color.
07:39 - Ah, not the distances.
07:41 - I want the sorted ones.
07:43 - The distances were sorted,
so the closest one is always
07:45 - at the beginning of the array.
07:46 - There we go.
07:47 - We can start to see this
Voronoi-like tessellation.
07:51 - Let's do a little
bit of a mapping.
07:54 - Let's say the distances
range between 0
07:58 - and width divided by 2.
08:00 - And when it's really close,
when the distance is 0,
08:02 - I want it to be very bright.
08:04 - And when it's far away,
I want it to be dark.
08:07 - There we go.
08:08 - This looks more like
what I would expect.
08:10 - And interestingly enough,
we can do some fun things,
08:12 - like we can have these
points move around.
08:18 - Them shaking like this perhaps
isn't the most interesting
08:20 - movement, and maybe having them
be bouncing balls bouncing off
08:23 - the edges or flocking together
or moving in spiral patterns
08:26 - or with Perlin noise,
I'll let you explore that.
08:29 - Maybe I'll come
back to it later.
08:30 - But you can see that
these points can actually
08:32 - move around to create an
animation out of the noise.
08:35 - Let's look at what happens
when I have a lot more points.
08:37 - So instead of 7, let's try 25.
08:40 - And there.
08:41 - We see the same sort of thing.
08:42 - We see the same
pattern, but the cells,
08:44 - the cellular texture
of it, their cells
08:47 - are getting smaller and smaller.
08:48 - 100.
08:50 - Because there are
so many points now,
08:53 - it's not having an easy time
calculating the distance
08:56 - to all those points.
08:56 - And it's running quite slow.
08:58 - So this is where I want--
08:58 - I would want to add some
kind of optimization to it,
09:01 - but I'm not going to worry
about that right now.
09:03 - I just want to
compute static noise,
09:04 - and doesn't matter if
it takes a long time.
09:06 - So I'm going to get rid of
this idea of an animation.
09:09 - I'm actually, in
fact, let's just
09:10 - comment out drawing
the points entirely,
09:12 - and let's write no loop here.
09:16 - So there we go.
09:17 - So I can see here is a very
basic visualization of Worley
09:21 - noise.
09:21 - It looks quite like the example
here on the Wikipedia page.
09:25 - Obviously, that page
has it darker closer.
09:28 - So if I changed it
to this, and I'm not
09:30 - getting that full brightness,
because the points
09:34 - are also close.
09:34 - Let's just manually come
up with a range here.
09:37 - There we go.
09:38 - I have now created
basically exactly what
09:40 - is on this Wikipedia
page right here.
09:42 - Now remember, the
idea of Worley noise
09:46 - is that I have this
additional variable n,
09:49 - so I don't just have
to map the noise
09:52 - to the distance of the closest
point, which will give me
09:55 - the Voronoi-like pattern.
09:56 - I could also calculate
the noise value
09:58 - based on the distance to
the second-closest point,
10:01 - in which case an n of 1.
10:04 - And look at this.
10:05 - I have this almost more like
crystal-like structure to it.
10:08 - What happens if I
change it to n of 2?
10:12 - n of 3?
10:14 - Change the mapping to allow
for a larger range of distance.
10:18 - So you can see, there's lots
of different kinds of textures
10:20 - that you could
generate, based on how
10:22 - you manipulate that mapping, how
many seed points do you pick,
10:26 - as well as which value
of n you're using.
10:28 - But I have missed something.
10:30 - So Worley noise,
even though we're
10:32 - looking at this sort of
two-dimensional visualization
10:34 - of it, those feature
points could actually
10:36 - exist in three dimensions.
10:39 - So I could think of a
cube in three dimensions,
10:42 - pick a whole set of
initial feature points,
10:44 - and then look at a slice
inside of that cube.
10:47 - To do that, let's add a
z value to the p vectors.
10:51 - I'm keeping everything
in square dimensions,
10:53 - because I think it makes things
a little bit simpler here.
10:56 - So it really actually
doesn't matter
10:57 - that I have a width and height.
10:58 - Everything is 400.
10:59 - So let's keep the z values
also between 0 and 400.
11:04 - I'll just use width
arbitrarily there.
11:06 - This distance is no longer
between an x and y and an x
11:08 - and y.
11:09 - It's between an x,
y, z, and an x, y, z.
11:13 - And just to make this
read a little bit easier,
11:18 - Let's put the particular
point that I'm
11:20 - looking at in a variable
v. And let's also add a z.
11:26 - So now I'm looking at the
distance between two points
11:29 - in three-dimensional space.
11:30 - I have my feature points, the
x, y, and z of the given feature
11:33 - point, and then the x, y, z of
the given pixel I'm looking at.
11:36 - But again, I'm
looking at a slice.
11:38 - So z is constant.
11:39 - So I'm going to
make up a z value.
11:41 - Let's just look at the center
slice, width divided by 2.
11:44 - And let's change n back to 0.
11:45 - So I look at the closest point
and see what this looks like.
11:48 - Not too different, right?
11:50 - Can I quickly see
the difference?
11:53 - I'm going to just say if
mouse pressed d equals--
11:58 - let's just look at
that 2D distance.
12:00 - Let's allow it to animate.
12:03 - So you can see here,
when I click the mouse,
12:05 - there's a lot more cells.
12:06 - Let's see if I use
fewer feature points,
12:08 - if this is maybe a
bit more obvious.
12:10 - So that, the 3D--
12:11 - that's with the feature points
in 3D, and this is within 2D.
12:15 - So we can see there's a bit more
of a spherical kind of quality
12:18 - to them.
12:18 - It's a bit smoother,
the noise texture.
12:21 - Let's go back to
about 50 points.
12:23 - Let's stick with 3D.
12:26 - Let's look at n equals 1.
12:30 - n equals 3.
12:32 - Now something that I could
try that's pretty interesting
12:34 - here is I could vary the z.
12:38 - So for example, I
could look through
12:41 - what does the noise space
look like at any given
12:43 - different slice?
12:45 - So what if I had z just be
frame count modulus width.
12:51 - So at every frame
of animation, I'm
12:53 - looking at a different slice.
12:55 - When it gets to the top slice,
it goes all the way back down.
12:58 - Let's set n at back to 0.
13:00 - You can see it slowly animating.
13:01 - It's as if I'm scanning into
this three-dimensional space.
13:05 - One thing I could try here,
just to add a little more flair
13:07 - to this, is I could use a
different n for an RGB color.
13:12 - So I could have the
red value be tied
13:14 - to n equals 0, the green to
n equals 1, and the blue to n
13:17 - equals 2.
13:17 - Let's see what happens there.
13:19 - So let's actually call
this r is sorted 0.
13:22 - g is sorted 1 map.
13:25 - And b is sorted 2.
13:28 - And then the color is RGB.
13:32 - I could also play around
with varying the ranges,
13:35 - and I could have this
go to 55 down to 0.
13:39 - And maybe the blue value,
change this to 200.
13:44 - A lot of possible kinds
of colors and textures
13:47 - I could create just
from varying the
13:49 - how I map the ranges,
which distance I use.
13:53 - But here we go.
13:54 - We can see this is basically
the foundation upon which
13:56 - you could create
your own animation
13:58 - or texture with Worley noise.
14:01 - So what might you
want to try with this?
14:03 - A couple things.
14:03 - One is this is
running pretty slow.
14:07 - I'm able to get this.
14:08 - It's a reasonable frame
rate of 400 by 400,
14:11 - but this would really
merit some optimization.
14:13 - One optimization
would be to improve
14:15 - on how many points you need to
look at for every given pixel.
14:18 - So you don't need to actually
look at all the feature
14:20 - points for every given pixel.
14:21 - We can register the points into
given cells into the window
14:24 - and only look at a
few of them, and I've
14:26 - covered this topic extensively
in my quadtree videos.
14:29 - But you could even
use a sort simpler,
14:31 - just like spatial subdivision
without the quadtree whole
14:34 - thing itself.
14:35 - Otherwise, just the
rendering is quite slow,
14:37 - having to do this calculation
for every single pixel.
14:39 - There's a really nice resource
called The Book of Shaders,
14:41 - and it has a tutorial write-up
about how to compute Worley
14:45 - noise with a web GL shader.
14:46 - It's called The Book of Shaders.
14:48 - So I'll link to that in the
video description as well.
14:50 - So I look forward to your
own versions of Worley noise.
14:53 - I'm going to leave
you with a rendering
14:55 - that I made during
the Livestream.
14:56 - When I first coded the
Worley noise algorithm,
14:58 - it didn't-- this run
originally in real time.
15:01 - It's 1920 by 1080.
15:03 - Computing the noise space in
that with that resolution,
15:06 - but using saveFrame
in processing
15:08 - was pretty easy to render
out every single frame
15:10 - and just let it run, save
it, and export it to a movie.
15:13 - So I'll link to the time
code in the video description
15:16 - where I created this.
15:16 - I hope you enjoyed this
delightful day of coding
15:19 - Worley noise in the cabana.
15:20 - I'm going to go outside play
with Pickle a little bit
15:22 - and water the plants.
15:23 - Come on, Pickle.
15:24 - [MUSIC PLAYING]

Cleaned transcript:

[MUSIC PLAYING] Good morning. Welcome to Coding in the Cabana. I'm here with my cohost, Gloria Pickle. And today the topic is Worley noise. Now I'm particularly excited about this topic. I'm here, quarantined at home, like many of you are who might be watching this all around the world. And I did a live stream where I implemented Worley noise. So I've done this before, but I had some technical difficulties and so I wanted to come back and make a really short video where I just coded the algorithm, explained it, and put up a web page so that you could share your own versions of this kind of noise. The noise is nothing new on this channel. I have covered all sorts of kind of noise. Perlin noise being the most the noise algorithm that I use the most, probably. Now anytime I'm doing a noise algorithm, we've got to talk about how am I visualizing. I want to visualize this algorithm, and I want to look at the noise in a twodimensional space. So I'm going to start with a Processing window, and I just want to set every single pixel color to a noise value. Now just plain old noise is randomness. So let's set up, and let's just do plain old noise first. In order to set every single pixel of this window to a given color, I need a nested loop to look at every single x and every single y. Now the pixels are stored in an array, and I can access it. It's just a global variable in processing that's built in with just the keyword pixels. But I don't know where exactly I need to look at. I'll get to that in a second. So I want to set every sing one of these pixels to a given color. Let's make it, just to start with, some kind of pink color. So what goes in here? So if I have a twodimensional window, that's, let's say, it's 400 by 400. And let's scale that down to 4 by 4. Every single pixel has an index. There's a number associated with it. 0, 1, 2, 3, 4, 5, 6, 7. There's 16 pixels total. 4 times 4 is 16, and their index values go from 0 to 15. You'll notice that 2 plus 4 is 6 plus 4 is 10, or 0 plus 4 is 4 plus 4 is 8. So this width, four is the offset between the index values in any given row. So there's a really nice formula that I can use, which is actually just take which row am I on, multiply it by 4, and add that to the column. So if I'm on row 0, 1, 2 times 4 is 8 plus the column 1. 1 plus 8 is 9. Or in other words, putting this in code, int index equals x plus y times width. That's the formula. Look at the index. So this would set the entire window to pink. Now if I run this, it's going to tell me, I have no idea what you're talking about. Because Pickle, what did I forget? Exactly. That's right. Pickle knows, and one more step. I've got to tell it I'm done with it so it can render those pixels. Birds are really chirping today. What a lovely day it is. There we go. There's my nice little pink beautiful window that I love. So let's change this to a noise algorithm, and pure noise is randomness. We've got this oldtimey the television has no signal, and I know that you watching this are watching this on your tubular, oldtimey television. Worley noise is a kind of cellular noise, and the algorithm was proposed by Steven Worley in a paper published in 1996. There's a really basic, twostep process for generating the noise. First step is randomly distribute feature points in space. So what do I mean by that? I have my twodimensional space. I'm actually going to make it threedimensional in a moment, but let's start with just two dimensions. And I need to randomly distribute a bunch of points. So how many points did I put here? Seven. Let's start with seven points. Easiest way for me to create seven points is just make an array of p vector objects and give it seven total spots. And then initialize every single one of those points with a random place in the canvas. Now one of the things that you could do if you're making your own version of this is think about, well, how do you actually generate those points? Maybe they're the points along the path of some other kind of design or have some other algorithm to distribute them. But I'm just going to let them be totally random. Let's take a look at those points by writing another loop down here. This is a special kind of loop that looks at every object v inside of the array points. And I'm just going to actually literally draw it as a point. Let's give it a stroke. Let's make it green so I can really see it and give it a kind of larger stroke weight. And there we go. So now we see every time I run this, I'm going to get a new set of points. So step 1 is done. Randomly distribute feature points in space. Step 2 is really where the noise algorithm starts to kick in. f of n of x. So x being the given pixel, xy. So for every given pixel xy, I need to calculate a noise value. And it is equal to the distance to the nth closest point, meaning let's start with n equals 1. So if these are all my seed points, and then I happen to be looking at a given pixel, for example, this pixel, which point is the nth closest? The n being 1, the first closest. That's this one. If I were looking at, let's say, n equals 2, well, let's say this is the second closest. Now you might start to think, wait, this kind of reminds me of something. Let's just look at three points. I can kind of create this tiling where all the points here are all closest to this one. And all of the points here are all closest to this one. This is known as a Voronoi tessellation. And this is a Worley noise and the Voronoi tessellation are completely interrelated. I'm actually in many ways doing the same algorithm. Worley noise is going to veer off into a different direction, but this is something I should come back and revisit. How can I look at this particular problem from a computational geometry perspective? In the case of Worley noise, we're just going to look at every single pixel and its distance to the closest feature point. Every single point, and calculate the distance between the xy and that point's xy. And let's put all those into an array of distance values. The reason why I want to look at all the distances is because I want to vary this n value. Sometimes I want to look at the first closest, second closest, third closest. Maybe I don't need them all, but let's just keep them all right now, store them all into this array, and then after that, I can sort the array. That's an array also. So I could write my own algorithm for sorting an array, but processing has it built in. If it's just an array of numbers, processing will sort it for me, just with the sort function. And let's ask the question of what n do I want to use, if I want to use n equals 1. Then the color it's not going to be a random value that noise value is front distances n of 1. And actually, so n should be 0, because 0 is the first element of the array. And I'm going to set it to a color. Ah, not the distances. I want the sorted ones. The distances were sorted, so the closest one is always at the beginning of the array. There we go. We can start to see this Voronoilike tessellation. Let's do a little bit of a mapping. Let's say the distances range between 0 and width divided by 2. And when it's really close, when the distance is 0, I want it to be very bright. And when it's far away, I want it to be dark. There we go. This looks more like what I would expect. And interestingly enough, we can do some fun things, like we can have these points move around. Them shaking like this perhaps isn't the most interesting movement, and maybe having them be bouncing balls bouncing off the edges or flocking together or moving in spiral patterns or with Perlin noise, I'll let you explore that. Maybe I'll come back to it later. But you can see that these points can actually move around to create an animation out of the noise. Let's look at what happens when I have a lot more points. So instead of 7, let's try 25. And there. We see the same sort of thing. We see the same pattern, but the cells, the cellular texture of it, their cells are getting smaller and smaller. 100. Because there are so many points now, it's not having an easy time calculating the distance to all those points. And it's running quite slow. So this is where I want I would want to add some kind of optimization to it, but I'm not going to worry about that right now. I just want to compute static noise, and doesn't matter if it takes a long time. So I'm going to get rid of this idea of an animation. I'm actually, in fact, let's just comment out drawing the points entirely, and let's write no loop here. So there we go. So I can see here is a very basic visualization of Worley noise. It looks quite like the example here on the Wikipedia page. Obviously, that page has it darker closer. So if I changed it to this, and I'm not getting that full brightness, because the points are also close. Let's just manually come up with a range here. There we go. I have now created basically exactly what is on this Wikipedia page right here. Now remember, the idea of Worley noise is that I have this additional variable n, so I don't just have to map the noise to the distance of the closest point, which will give me the Voronoilike pattern. I could also calculate the noise value based on the distance to the secondclosest point, in which case an n of 1. And look at this. I have this almost more like crystallike structure to it. What happens if I change it to n of 2? n of 3? Change the mapping to allow for a larger range of distance. So you can see, there's lots of different kinds of textures that you could generate, based on how you manipulate that mapping, how many seed points do you pick, as well as which value of n you're using. But I have missed something. So Worley noise, even though we're looking at this sort of twodimensional visualization of it, those feature points could actually exist in three dimensions. So I could think of a cube in three dimensions, pick a whole set of initial feature points, and then look at a slice inside of that cube. To do that, let's add a z value to the p vectors. I'm keeping everything in square dimensions, because I think it makes things a little bit simpler here. So it really actually doesn't matter that I have a width and height. Everything is 400. So let's keep the z values also between 0 and 400. I'll just use width arbitrarily there. This distance is no longer between an x and y and an x and y. It's between an x, y, z, and an x, y, z. And just to make this read a little bit easier, Let's put the particular point that I'm looking at in a variable v. And let's also add a z. So now I'm looking at the distance between two points in threedimensional space. I have my feature points, the x, y, and z of the given feature point, and then the x, y, z of the given pixel I'm looking at. But again, I'm looking at a slice. So z is constant. So I'm going to make up a z value. Let's just look at the center slice, width divided by 2. And let's change n back to 0. So I look at the closest point and see what this looks like. Not too different, right? Can I quickly see the difference? I'm going to just say if mouse pressed d equals let's just look at that 2D distance. Let's allow it to animate. So you can see here, when I click the mouse, there's a lot more cells. Let's see if I use fewer feature points, if this is maybe a bit more obvious. So that, the 3D that's with the feature points in 3D, and this is within 2D. So we can see there's a bit more of a spherical kind of quality to them. It's a bit smoother, the noise texture. Let's go back to about 50 points. Let's stick with 3D. Let's look at n equals 1. n equals 3. Now something that I could try that's pretty interesting here is I could vary the z. So for example, I could look through what does the noise space look like at any given different slice? So what if I had z just be frame count modulus width. So at every frame of animation, I'm looking at a different slice. When it gets to the top slice, it goes all the way back down. Let's set n at back to 0. You can see it slowly animating. It's as if I'm scanning into this threedimensional space. One thing I could try here, just to add a little more flair to this, is I could use a different n for an RGB color. So I could have the red value be tied to n equals 0, the green to n equals 1, and the blue to n equals 2. Let's see what happens there. So let's actually call this r is sorted 0. g is sorted 1 map. And b is sorted 2. And then the color is RGB. I could also play around with varying the ranges, and I could have this go to 55 down to 0. And maybe the blue value, change this to 200. A lot of possible kinds of colors and textures I could create just from varying the how I map the ranges, which distance I use. But here we go. We can see this is basically the foundation upon which you could create your own animation or texture with Worley noise. So what might you want to try with this? A couple things. One is this is running pretty slow. I'm able to get this. It's a reasonable frame rate of 400 by 400, but this would really merit some optimization. One optimization would be to improve on how many points you need to look at for every given pixel. So you don't need to actually look at all the feature points for every given pixel. We can register the points into given cells into the window and only look at a few of them, and I've covered this topic extensively in my quadtree videos. But you could even use a sort simpler, just like spatial subdivision without the quadtree whole thing itself. Otherwise, just the rendering is quite slow, having to do this calculation for every single pixel. There's a really nice resource called The Book of Shaders, and it has a tutorial writeup about how to compute Worley noise with a web GL shader. It's called The Book of Shaders. So I'll link to that in the video description as well. So I look forward to your own versions of Worley noise. I'm going to leave you with a rendering that I made during the Livestream. When I first coded the Worley noise algorithm, it didn't this run originally in real time. It's 1920 by 1080. Computing the noise space in that with that resolution, but using saveFrame in processing was pretty easy to render out every single frame and just let it run, save it, and export it to a movie. So I'll link to the time code in the video description where I created this. I hope you enjoyed this delightful day of coding Worley noise in the cabana. I'm going to go outside play with Pickle a little bit and water the plants. Come on, Pickle. [MUSIC PLAYING]
