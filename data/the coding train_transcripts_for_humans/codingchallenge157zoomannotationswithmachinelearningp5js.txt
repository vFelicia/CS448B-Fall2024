With timestamps:

00:00 - Hello, everyone, and welcome
to a Coding Challenge.
00:02 - The first one since
March of 2020,
00:05 - and what I am going
to attempt to do today
00:07 - is make my own version
of this project.
00:10 - This is not my idea.
00:12 - This came across my
Twitter desk the other day
00:15 - from Cameron Hunter, who
created a video lens that
00:19 - uses hand gestures to show comic
book style messages instead
00:23 - in a video call.
00:25 - I don't know if you noticed in
this year of 2020 lots of stuff
00:29 - is happening.
00:30 - Many of us, including myself,
are spending a large amount
00:33 - of time in video
calls, and I want
00:35 - to see if I can
figure out a way using
00:37 - the tools of p5.js,
ml5.js, teachable machine,
00:42 - and open broadcast studio, and
Zoom as the video conference
00:46 - software of choice,
not a sponsor.
00:48 - You could use anyone
that you want,
00:50 - but I'm going to attempt
to use Zoom and see
00:52 - if I can create my own
overlays that are controlled
00:54 - to my own gestures.
00:55 - That's what's going
to happen today.
00:56 - I have not attempted
this at any point
00:59 - in the past, present, or future.
01:01 - So here we go.
01:02 - To be honest,
there's probably not
01:03 - going to be a ton
of coding in this.
01:05 - But I will be writing
code, and mostly I'm
01:08 - going to be plugging in
this piece of software,
01:10 - to this piece of software,
and this piece of software.
01:12 - Lots of connectors, and tubes,
and cables, and things, but all
01:15 - happening on the
computer, because I'm
01:17 - too afraid to use that
stuff in real physical life.
01:19 - So let me talk through
what the components are.
01:21 - What I'm going to
have ultimately
01:23 - is a video feed where, for
example, when I raise my hand.
01:27 - And apparently I can't draw.
01:28 - That's me raising my hand.
01:30 - I might have a pop-up
that says, question.
01:33 - A big pop-up so that the
other people in the room
01:35 - can see that I'm raising my
hand, and I have a question.
01:38 - So to do this, I'm going to use
p5.js to connect to my camera
01:43 - and show my camera feed.
01:45 - Then I'm going to use
a teachable machine
01:47 - to train a machine
learning model to recognize
01:51 - my particular gestures.
01:53 - So just to point
out you should be
01:55 - able to do this yourself
at the end of this video,
01:57 - and you won't even have to
write any of your own code.
01:59 - You could reuse my code,
but almost certainly, well
02:02 - definitely, you will need
to train your own model.
02:04 - So I'll talk about
how to do that.
02:06 - So once I have
that, and then I'm
02:08 - going to talk to the teachable
machine model with ml5.js.
02:12 - So all of these components will
be running in a web browser.
02:18 - This is all inside
the web browser.
02:19 - Then I'm going to use a
piece of software called
02:23 - OBS, or Open Broadcast Studio.
02:26 - It is the software I'm using
right now to live stream
02:30 - to record to disk.
02:31 - It is software that I use
for making YouTube videos.
02:35 - But what I can do with OBS--
one of the things I can do--
02:38 - is I can capture everything
that's in the browser.
02:41 - So the browser is going
to be sent into OBS,
02:44 - and then this picture-- boy,
this diagram is terrible--
02:47 - you will see in OBS.
02:49 - Then from OBS I'm going
to start something
02:52 - called a virtual camera.
02:56 - So I'm going to
trick the computer
02:59 - into thinking that the
open broadcast studio
03:01 - software is my webcam.
03:04 - So when I log into
a Zoom meeting,
03:09 - and there is a grid of people.
03:11 - And this is me here.
03:14 - I will select the OBS virtual
cam as my video input.
03:20 - So instead of
picking the default--
03:21 - if I'm on a Mac it's going
to say FaceTime camera--
03:23 - I'm going to switch
to OBS virtual camera.
03:26 - This is not the
only way to do this.
03:28 - As you can see in the
project, I reference
03:31 - where I got this idea from.
03:32 - It's using something like
Snap Lens studio something.
03:35 - I'm sure there are
countless other ways
03:37 - you could approach this.
03:38 - I am hoping this
is going to work.
03:40 - Again, I haven't tried this yet.
03:41 - So remains to be seen.
03:43 - All right let's do the
first part, train the model.
03:47 - So I'm going to go to the
teachable machine website.
03:49 - If you want to learn more
about teachable machine,
03:51 - I have three videos
that I've already
03:53 - made about how to create a
model and use it with p5.
03:56 - And you can do stuff with audio.
03:57 - There's lots of stuff there.
03:58 - Google has a lot of resources.
04:00 - It's made by folks at
the Google creative lab.
04:02 - I'm just going to click
on to get started.
04:05 - I want to do an image
project, because I
04:06 - want to train a model on me.
04:09 - I'm just going to do background.
04:11 - Background being me not doing
anything, just me just kind
04:14 - of sitting in the
meeting like this.
04:17 - Trying to make eye contact
with people over a computer,
04:20 - or through a web.
04:20 - Have you ever tried?
04:21 - It doesn't work.
04:22 - How do you make the eye contact?
04:23 - And then the next category
will be questioned.
04:26 - So I want to quick webcam.
04:28 - You can see I've already
installed, by the way,
04:30 - OBS virtual camera
on this computer.
04:32 - So you can see it's
already available,
04:34 - but that's not what
I want right now.
04:35 - I want the FaceTime
camera, and I just
04:37 - want to record myself here.
04:39 - [MUSIC PLAYING]
04:41 - So that's probably good enough.
04:44 - And then I want to
do the question.
04:45 - [MUSIC PLAYING]
04:48 - And I try to get about the same
amount of samples, like 238.
04:52 - OK, and I'm going
to train this model.
04:55 - I get to take a
little break here.
04:57 - [MUSIC PLAYING]
05:00 - Remember the don't
switch tabs song?
05:02 - (SINGING) Don't switch the tabs.
05:04 - Don't switch the tabs.
05:07 - Oh, it trained.
05:08 - OK, so let's see
if it's working.
05:10 - Background, question,
background, question.
05:17 - So this is perfect.
05:18 - So now I have a model train.
05:19 - It's very important.
05:20 - I mean even though
I've talk about all
05:21 - of this in the teachable
machine videos,
05:23 - and I'm trying not
to do this now.
05:25 - It's important for
me to emphasize
05:26 - this is not doing any kind
of gesture recognition.
05:29 - This is pure image
classification.
05:31 - So it's not going to work
if I gave this model to you,
05:34 - and you're wearing a different
shirt, you have different hair,
05:36 - you're not wearing glasses,
your background is different.
05:39 - So this is the kind of
thing that every person
05:41 - would have to customize,
which I think is nice,
05:43 - because you can make up your own
gestures and different things.
05:45 - And everybody moves
in different ways,
05:46 - and does different
types of things.
05:48 - So now export model.
05:50 - So I'm going to
upload the model.
05:54 - Now I have URL right here,
which I'm going to click Copy.
05:58 - Then I'm going to go over
to the ml5 code example.
06:02 - So let's call this
Zoom annotations.
06:05 - I don't know if
that makes sense,
06:07 - just want to simplify
this example.
06:09 - It actually has some extra
stuff in it that I don't need,
06:13 - and let's run it.
06:14 - So this is the example
that comes with ml5,
06:17 - and actually it's
a pre-trained model
06:21 - has two categories,
daytime or nighttime.
06:25 - So it's hard to make a model
that people can universally
06:28 - test and use, but this is one.
06:30 - So now in theory if I were
to go and paste the URL.
06:34 - Remember, where did
I get that from?
06:36 - Right from here.
06:38 - This sharable link of the model,
I'm going to pasted in here.
06:43 - I've pasted it in, and I'm
going to run the example again.
06:48 - So this will hopefully
be fixed by the time
06:50 - you watch this video.
06:51 - I actually updated the examples.
06:53 - It needs to also
have added the--
06:56 - to the end of the URL I
need to add plusmodel.json.
06:58 - That's what ml5 is looking
for that particular JSON
07:01 - file that holds the
information about the model.
07:04 - Background, question,
background, question.
07:08 - All right, let's get at least a
quick pop up of a question mark
07:12 - to appear when I say
I have a question.
07:16 - Before I do that, let me make
a couple of quick changes.
07:18 - I want to just make this
a little bit bigger,
07:23 - and then I'm always going
to have the video size match
07:29 - the canvas size.
07:30 - And then I actually don't
want to draw the text label.
07:33 - That's not something I'm doing.
07:35 - So let me just make
sure this works still,
07:37 - and we see it a
little bit bigger.
07:39 - So I should be able to say
now, if label equals question,
07:45 - draw something else.
07:46 - And I happen to have a
thank you to Jason Haglund,
07:49 - who is that coding-trained
illustrator,
07:51 - makes all of the characters.
07:52 - Let's try using this one.
07:55 - So I should be able to upload
a file, and drag it here.
08:01 - It's kind of a weird name.
08:02 - Let me just rename this.
08:04 - I'm just going to call
it a question.png.
08:06 - And then in the sketch
I want to say question,
08:12 - and I'll preload that image.
08:14 - Preload a question.png.
08:17 - Then let us try to say
image question 0, 0.
08:23 - So I'm not really being
thoughtful about this.
08:25 - Let's just see if it appears.
08:27 - Whoops, what happened?
08:29 - Preload!
08:31 - No, the function
name is Load Image.
08:33 - This is me trying to do
stuff way too quickly
08:34 - and making weird mistakes.
08:40 - Guess what, folks?
08:42 - I named my labels
with a capital Q.
08:45 - [MUSIC PLAYING]
08:48 - Capital first letter.
08:51 - OK.
08:58 - So one thing I really want to do
which I feel like is important
09:01 - here is to kind of
bounce this a little bit.
09:03 - So I feel like if
it's going to appear,
09:05 - I don't want it to
disappear immediately.
09:10 - I don't want it to flicker.
09:11 - So I'm just going to
always have it fade out.
09:13 - So let me just--
09:14 - I think I can use--
09:15 - I mean I should make an object.
09:17 - There's all sorts of ways
I could engineer this
09:18 - in a really thoughtful way.
09:20 - I'm going to make a variable
called fade out equal to 255.
09:25 - And then whenever I
detect a particular label
09:28 - I'll say fade out equals to 255.
09:30 - Bare with me.
09:31 - I going to have to
think about how to do
09:32 - that with multiple things.
09:33 - But let me just get
this to work right now.
09:35 - Fade out minus equals 5.
09:37 - Let's make minus equal 10.
09:40 - If fade out greater than
zero, image question.
09:45 - And actually fade
out should be zero.
09:48 - So you know what,
this is why I need
09:50 - to wrap these two
things together
09:51 - into an object or something.
09:53 - But let's just have
question fade be at zero.
09:56 - And what I'm really doing is
I'm setting question fade to 255
10:01 - whenever I get that label.
10:03 - And then I'm always
fading it out,
10:04 - and I'm only drawing it if I
have a value greater than zero.
10:09 - And just for
efficiency's sake, I'll
10:12 - also just fade it out when
that's greater than zero.
10:14 - So it shouldn't flicker.
10:21 - Oh, sorry.
10:23 - That's actually like
just leaving it there.
10:25 - I was actually going to fade it.
10:27 - So I was going to say
tint, question, fade,
10:31 - which I realized I debounced
it just by not even having
10:35 - it fade but--
10:38 - Oh, Hello.
10:40 - That tint applies to everything.
10:46 - Well, that was weird.
10:50 - Maybe I need to do this.
10:52 - So I'm definitely fading.
10:53 - Oh, I'm just fading
the brightness.
10:56 - There we go.
10:57 - That's why I was looking to do.
10:59 - So I want the brightness
to always be a 255,
11:02 - but I want to fade the alpha.
11:04 - OK, so now let's see if we can
get this into a Zoom meeting.
11:08 - Now obviously of course,
we could spend hours
11:10 - making little animations and
training different gestures.
11:13 - And after I get
it all working, I
11:15 - want to spend a
little time making
11:16 - a version of this
with some animations
11:18 - and different things.
11:19 - But I just want to see if
I can at least get this
11:21 - into a Zoom meeting.
11:23 - So the first thing
I need to do is
11:25 - open up Open Broadcast Studio.
11:26 - So this is the website
for OBS studio.
11:28 - It's open source.
11:29 - And so I already have
that on my computer.
11:31 - I'm going to open it up.
11:33 - When you open it up, it should
look blank just like this.
11:36 - It's an empty window.
11:37 - So I have a scene.
11:39 - That's what's down here.
11:40 - I can make multiple
scenes, but I just
11:42 - want to use the default scene.
11:43 - Now I need a source.
11:44 - Ultimately, what I
probably want to do--
11:46 - and I'll see if I can
get this working later--
11:48 - is select a video
capture device.
11:52 - I'm going to call this webcam,
and I'm going to pick my webcam
11:59 - and have that be the main
element of the scene.
12:04 - And then the other stuff
would be an overlay over it,
12:07 - which I think I have
an idea of how to do.
12:08 - But right now, I'm just going
to try to get the raw browser
12:11 - window into this.
12:14 - So it won't be pixel
perfect in terms
12:16 - of resolution and everything,
but it will be a start.
12:18 - I'm going to take
that out, and I'm
12:21 - going to say I think
it's window capture.
12:25 - And I want to capture
p5 web editor,
12:33 - and I think the best way for me
to do this is to go to a share.
12:40 - Let's take the present
mode and open a new window.
12:45 - Paste it in there.
12:47 - Let's see if it's working.
12:49 - Great.
12:49 - OK, so now in OBS I want
to take the one that
12:54 - says Google Chrome webcam
image classification.
12:57 - So I want to take that.
12:58 - Then I'm going to use the
Option key to just crop
13:02 - around the part that I want.
13:03 - Again, this is silly.
13:04 - There's some better ways that
I could do this probably.
13:07 - But I'm just going to crop
around the part that I want,
13:10 - and then I will stretch it out.
13:14 - And now I've got it in OBS.
13:17 - And whenever I raise my
hand, it's happening.
13:21 - You can see the frame
rate is really low.
13:23 - I'm going to work on
a way to fix this.
13:26 - The next thing that
I want to do is
13:27 - start the OBS virtual camera.
13:30 - That's an option
I have over here
13:31 - under tools, start
virtual camera.
13:33 - That is not come by
default with OBS studio.
13:37 - It's Dan from the future coming
in to let some breaking news.
13:40 - [MUSIC PLAYING]
Monitoring breaking news.
13:43 - In the latest version of
Open Broadcast Studio,
13:45 - version 26, on Windows only.
13:49 - The virtual camera is built in.
13:50 - It looks like this.
13:52 - There's a button that you can
press, start virtual camera.
13:55 - But this won't be
available on Mac.
13:56 - Although, probably
by the time you're
13:58 - watching this in the future,
your future, it might be.
14:01 - The rest of this
video will show you
14:03 - how to get the plugin
extensions that you
14:05 - need to run a virtual
camera, but if you're
14:07 - on Windows running OBS
26 you're good to go.
14:11 - Back to the past.
14:12 - And for Mac, there's this
particular OBS virtual cam
14:17 - that you could just download and
run the installer right here.
14:19 - And I'll include links to both
of these for Mac and Windows
14:22 - in the video's description.
14:24 - And somebody's the
chat telling me there's
14:26 - a way to use z4l2sink on Linux.
14:28 - I've started the virtual
camera, and now I
14:30 - need to go into a Zoom meeting.
14:32 - Go into the meeting.
14:33 - So normally if I
start my video, this
14:36 - is just me in the Zoom
meeting with this video.
14:42 - That's the webcam.
14:43 - And now I should be able
to go over here and change
14:45 - to OBS virtual camera.
14:47 - Shoot, I forgot that
I opened it up here.
14:52 - There we go.
14:53 - Here we go.
14:54 - I'm in the Zoom meeting.
14:56 - Hi, everybody.
14:57 - Oh well this is such a great
discussion class thingy.
15:02 - Oh, it's reversed.
15:07 - So because it's
flipped, because Zoom
15:09 - is trying to make it a
nice experience for me,
15:10 - I'm going to uncheck
this mirror my video.
15:13 - And I've already mirrored
it in my own software.
15:15 - And now, hi, I'm a question.
15:21 - So I want to think about
ways to improve this.
15:23 - This is what I'm going to do.
15:25 - I want to make a
1280 by 720 canvas.
15:29 - I'm going to make the
video as small as possible.
15:33 - So let's see, even if I
do it like 160 by 120,
15:37 - and I'm going to hide it.
15:39 - I'm not going to hide it.
15:40 - I want to see that
video separately,
15:42 - and then I don't want
to draw the video.
15:45 - Instead, I just want to
see the image pop up.
15:48 - So let's see if this works.
15:50 - So I've got my
video at the bottom,
15:52 - and I'm able to get the
question mark to pop up.
15:56 - Great.
15:57 - So now I'm going to go to
the present to view again.
16:03 - I move the camera
around, which I think
16:05 - is causing a bit of a problem.
16:06 - I'm going to have to retrain
the model, which I'll do.
16:09 - Let me go back to here.
16:10 - This is working pretty well.
16:11 - And I want to change the
background to a pure green,
16:16 - and you'll see why in a second.
16:18 - Now, this should
run much faster.
16:20 - I don't need a high resolution
video to do the classification,
16:23 - and I'm also not drawing it.
16:25 - So it's much less work for me
not to actually draw the video.
16:27 - Just draw this, because now
what I can do in open broadcast
16:30 - studio is I can actually just
add my camera source directly.
16:35 - So I want to add
the FaceTime camera.
16:39 - I'm going to stretch it
out to take up the full,
16:42 - and you can see the frame
rate is very fluid here.
16:45 - Then I'm going to add as
another scene a window capture,
16:51 - and I'm going to
get the browser.
16:54 - I want to grab
this, which is here.
16:57 - I hit OK.
17:00 - I'm going to stretch
this out, but I'm going
17:02 - to crop it around the Canvas.
17:08 - I'm going to fill the
window basically with it.
17:12 - Then I'm going to
add a filter in OBS.
17:16 - I'm going to go to Filters.
17:17 - I'm going to add
an effect filter.
17:20 - I'm going to go to chroma key.
17:24 - And I want to chroma
key the green out.
17:27 - The default is going
to work really well.
17:29 - Have a perfect
chroma key, because I
17:30 - drew the green itself.
17:32 - And now there we go, and I
have no frame rate issues.
17:39 - Pops right up.
17:41 - It's time for my Zoom meeting.
17:43 - I'm so excited.
17:44 - It's time to be on Zoom for
the 15th hour of the day.
17:48 - OBS I need to make sure I am
running my virtual camera.
17:53 - I want to join my test meeting.
17:56 - Now I'm in the meeting.
17:58 - I turn on my video.
17:59 - Hello, friends.
18:01 - Welcome to class today on Zoom.
18:03 - If you have a question,
please raise your hand.
18:09 - All right.
18:11 - This works.
18:11 - I'm so glad.
18:12 - This actually works quite well.
18:14 - Let's have a little
bit more fun.
18:16 - Here are all the steps you
need to do one at a time.
18:19 - First, collect
images for any label
18:21 - that you want to define
in teachable machine.
18:23 - I'm using question, yes,
no, love, and funny,
18:26 - but obviously you
can make up your own.
18:27 - And I'm also using
one called background
18:29 - for a neutral position when
I'm not doing anything,
18:31 - and I don't want to
show any annotation.
18:34 - Train the model.
18:38 - Then upload the model.
18:41 - Copy paste the model
URL into your code.
18:44 - You can find the
code in the link
18:45 - in this video's description.
18:47 - Upload any images
and animations you
18:49 - want to use to
your p5.js sketch.
18:54 - Add an if statement
for each label
18:56 - to either draw one of
those images or any code
18:58 - that you want to write really.
19:00 - Once you're done coding, run
your p5 sketch in present view.
19:05 - Now you can move on over
to broadcast studio.
19:08 - Create a scene in OBS.
19:10 - Add a video capture device
and select your camera.
19:15 - Then add window
capture, and select
19:18 - the browser window that's
running your p5.js sketch.
19:21 - Crop and resize, accordingly.
19:23 - If necessary, add a
chroma key filter.
19:32 - Start the open broadcast
studio virtual camera.
19:36 - Then move on over to Zoom, and
select as your video source
19:39 - OBS virtual camera.
19:42 - Then fame and fortune await you
as you entertain your friends
19:45 - and teachers in Zoom.
19:48 - All right.
19:48 - I hope you were able
to follow those steps.
19:51 - I cannot wait to see if anybody
actually takes this methodology
19:55 - and applies it to a
real, live Zoom meeting.
19:58 - I, in fact, did just that.
20:00 - After I recorded
this tutorial, I
20:02 - had a quick Zoom call with some
friends of the coding training
20:04 - that I sent the steps.
20:06 - I'm going to show
that to you right now,
20:08 - and you can sort of see what it
looks like in real, live Zoom.
20:12 - During this meeting I thought,
Of all these new ideas
20:16 - of things that I could try
beyond just loading an image
20:19 - and displaying the image.
20:20 - The first thing I
thought of is, OK.
20:23 - I'm programming in p5.js.
20:25 - There's lots of things I could
do beyond just load an image
20:27 - and display it.
20:28 - I have the full range
of possible things
20:30 - I can encode in p5.
20:32 - One of the things that I
think is really fun to try
20:34 - is just any coding challenge
I made with any generative art
20:37 - visualization, I can
use as an overlay.
20:39 - So I could strike poses to set
off heart-shaped fireworks.
20:46 - What if every time I wear my
party rock glasses, I also
20:49 - get a party rock hat,
which follows my head
20:53 - using Poe's net?
20:55 - If you're watching
this, I really
20:57 - hope you have your own
creative idea for something
20:59 - you want to try, something
you've already made in p5
21:01 - that you want to
have running live
21:03 - in real time in a Zoom meeting.
21:05 - Maybe you're visualizing data,
it's just some sort of art,
21:07 - it's augmenting your
body or your poses.
21:10 - You don't even need to
show your video at all.
21:12 - You could just be showing
other stuff in your Zoom.
21:14 - Anything you could do in
p5.js with Open Broadcast
21:17 - Studio and a virtual camera,
you can show in a video call.
21:21 - If you make something, I really
want you to share it with me.
21:23 - Probably the easiest way for
you to do it is on Twitter,
21:25 - @shiffman, but also if you go
to the website page for this
21:28 - video-- it's a kind of
a more permanent place--
21:30 - you can submit a link
to any documentation
21:32 - of what you've done.
21:33 - One important thing to
note, and hopefully you're
21:36 - thinking about this
already, is that if you're
21:37 - capturing a Zoom meeting.
21:38 - So for one, maybe just capture
it with just you in it,
21:41 - and that's what
you share with me.
21:42 - But if there are
other participants,
21:44 - make sure you have
their consent.
21:45 - You've asked for
their permission
21:46 - before you share any images or
snapshots of that Zoom meeting
21:49 - online.
21:50 - All right.
21:50 - That's all I've got for today.
21:52 - Thanks for watching
this coding challenge.
21:54 - Go and bring some delight
to somebody's day.
21:56 - I know you're going to be
in a lot of video calls,
21:58 - but if you could take
a break from that
22:00 - and safely get some fresh air.
22:02 - I highly recommend that too.
22:03 - And I will see you in a
future coding challenge.
22:05 - Goodbye.
22:05 - [MUSIC PLAYING]

Cleaned transcript:

Hello, everyone, and welcome to a Coding Challenge. The first one since March of 2020, and what I am going to attempt to do today is make my own version of this project. This is not my idea. This came across my Twitter desk the other day from Cameron Hunter, who created a video lens that uses hand gestures to show comic book style messages instead in a video call. I don't know if you noticed in this year of 2020 lots of stuff is happening. Many of us, including myself, are spending a large amount of time in video calls, and I want to see if I can figure out a way using the tools of p5.js, ml5.js, teachable machine, and open broadcast studio, and Zoom as the video conference software of choice, not a sponsor. You could use anyone that you want, but I'm going to attempt to use Zoom and see if I can create my own overlays that are controlled to my own gestures. That's what's going to happen today. I have not attempted this at any point in the past, present, or future. So here we go. To be honest, there's probably not going to be a ton of coding in this. But I will be writing code, and mostly I'm going to be plugging in this piece of software, to this piece of software, and this piece of software. Lots of connectors, and tubes, and cables, and things, but all happening on the computer, because I'm too afraid to use that stuff in real physical life. So let me talk through what the components are. What I'm going to have ultimately is a video feed where, for example, when I raise my hand. And apparently I can't draw. That's me raising my hand. I might have a popup that says, question. A big popup so that the other people in the room can see that I'm raising my hand, and I have a question. So to do this, I'm going to use p5.js to connect to my camera and show my camera feed. Then I'm going to use a teachable machine to train a machine learning model to recognize my particular gestures. So just to point out you should be able to do this yourself at the end of this video, and you won't even have to write any of your own code. You could reuse my code, but almost certainly, well definitely, you will need to train your own model. So I'll talk about how to do that. So once I have that, and then I'm going to talk to the teachable machine model with ml5.js. So all of these components will be running in a web browser. This is all inside the web browser. Then I'm going to use a piece of software called OBS, or Open Broadcast Studio. It is the software I'm using right now to live stream to record to disk. It is software that I use for making YouTube videos. But what I can do with OBS one of the things I can do is I can capture everything that's in the browser. So the browser is going to be sent into OBS, and then this picture boy, this diagram is terrible you will see in OBS. Then from OBS I'm going to start something called a virtual camera. So I'm going to trick the computer into thinking that the open broadcast studio software is my webcam. So when I log into a Zoom meeting, and there is a grid of people. And this is me here. I will select the OBS virtual cam as my video input. So instead of picking the default if I'm on a Mac it's going to say FaceTime camera I'm going to switch to OBS virtual camera. This is not the only way to do this. As you can see in the project, I reference where I got this idea from. It's using something like Snap Lens studio something. I'm sure there are countless other ways you could approach this. I am hoping this is going to work. Again, I haven't tried this yet. So remains to be seen. All right let's do the first part, train the model. So I'm going to go to the teachable machine website. If you want to learn more about teachable machine, I have three videos that I've already made about how to create a model and use it with p5. And you can do stuff with audio. There's lots of stuff there. Google has a lot of resources. It's made by folks at the Google creative lab. I'm just going to click on to get started. I want to do an image project, because I want to train a model on me. I'm just going to do background. Background being me not doing anything, just me just kind of sitting in the meeting like this. Trying to make eye contact with people over a computer, or through a web. Have you ever tried? It doesn't work. How do you make the eye contact? And then the next category will be questioned. So I want to quick webcam. You can see I've already installed, by the way, OBS virtual camera on this computer. So you can see it's already available, but that's not what I want right now. I want the FaceTime camera, and I just want to record myself here. [MUSIC PLAYING] So that's probably good enough. And then I want to do the question. [MUSIC PLAYING] And I try to get about the same amount of samples, like 238. OK, and I'm going to train this model. I get to take a little break here. [MUSIC PLAYING] Remember the don't switch tabs song? (SINGING) Don't switch the tabs. Don't switch the tabs. Oh, it trained. OK, so let's see if it's working. Background, question, background, question. So this is perfect. So now I have a model train. It's very important. I mean even though I've talk about all of this in the teachable machine videos, and I'm trying not to do this now. It's important for me to emphasize this is not doing any kind of gesture recognition. This is pure image classification. So it's not going to work if I gave this model to you, and you're wearing a different shirt, you have different hair, you're not wearing glasses, your background is different. So this is the kind of thing that every person would have to customize, which I think is nice, because you can make up your own gestures and different things. And everybody moves in different ways, and does different types of things. So now export model. So I'm going to upload the model. Now I have URL right here, which I'm going to click Copy. Then I'm going to go over to the ml5 code example. So let's call this Zoom annotations. I don't know if that makes sense, just want to simplify this example. It actually has some extra stuff in it that I don't need, and let's run it. So this is the example that comes with ml5, and actually it's a pretrained model has two categories, daytime or nighttime. So it's hard to make a model that people can universally test and use, but this is one. So now in theory if I were to go and paste the URL. Remember, where did I get that from? Right from here. This sharable link of the model, I'm going to pasted in here. I've pasted it in, and I'm going to run the example again. So this will hopefully be fixed by the time you watch this video. I actually updated the examples. It needs to also have added the to the end of the URL I need to add plusmodel.json. That's what ml5 is looking for that particular JSON file that holds the information about the model. Background, question, background, question. All right, let's get at least a quick pop up of a question mark to appear when I say I have a question. Before I do that, let me make a couple of quick changes. I want to just make this a little bit bigger, and then I'm always going to have the video size match the canvas size. And then I actually don't want to draw the text label. That's not something I'm doing. So let me just make sure this works still, and we see it a little bit bigger. So I should be able to say now, if label equals question, draw something else. And I happen to have a thank you to Jason Haglund, who is that codingtrained illustrator, makes all of the characters. Let's try using this one. So I should be able to upload a file, and drag it here. It's kind of a weird name. Let me just rename this. I'm just going to call it a question.png. And then in the sketch I want to say question, and I'll preload that image. Preload a question.png. Then let us try to say image question 0, 0. So I'm not really being thoughtful about this. Let's just see if it appears. Whoops, what happened? Preload! No, the function name is Load Image. This is me trying to do stuff way too quickly and making weird mistakes. Guess what, folks? I named my labels with a capital Q. [MUSIC PLAYING] Capital first letter. OK. So one thing I really want to do which I feel like is important here is to kind of bounce this a little bit. So I feel like if it's going to appear, I don't want it to disappear immediately. I don't want it to flicker. So I'm just going to always have it fade out. So let me just I think I can use I mean I should make an object. There's all sorts of ways I could engineer this in a really thoughtful way. I'm going to make a variable called fade out equal to 255. And then whenever I detect a particular label I'll say fade out equals to 255. Bare with me. I going to have to think about how to do that with multiple things. But let me just get this to work right now. Fade out minus equals 5. Let's make minus equal 10. If fade out greater than zero, image question. And actually fade out should be zero. So you know what, this is why I need to wrap these two things together into an object or something. But let's just have question fade be at zero. And what I'm really doing is I'm setting question fade to 255 whenever I get that label. And then I'm always fading it out, and I'm only drawing it if I have a value greater than zero. And just for efficiency's sake, I'll also just fade it out when that's greater than zero. So it shouldn't flicker. Oh, sorry. That's actually like just leaving it there. I was actually going to fade it. So I was going to say tint, question, fade, which I realized I debounced it just by not even having it fade but Oh, Hello. That tint applies to everything. Well, that was weird. Maybe I need to do this. So I'm definitely fading. Oh, I'm just fading the brightness. There we go. That's why I was looking to do. So I want the brightness to always be a 255, but I want to fade the alpha. OK, so now let's see if we can get this into a Zoom meeting. Now obviously of course, we could spend hours making little animations and training different gestures. And after I get it all working, I want to spend a little time making a version of this with some animations and different things. But I just want to see if I can at least get this into a Zoom meeting. So the first thing I need to do is open up Open Broadcast Studio. So this is the website for OBS studio. It's open source. And so I already have that on my computer. I'm going to open it up. When you open it up, it should look blank just like this. It's an empty window. So I have a scene. That's what's down here. I can make multiple scenes, but I just want to use the default scene. Now I need a source. Ultimately, what I probably want to do and I'll see if I can get this working later is select a video capture device. I'm going to call this webcam, and I'm going to pick my webcam and have that be the main element of the scene. And then the other stuff would be an overlay over it, which I think I have an idea of how to do. But right now, I'm just going to try to get the raw browser window into this. So it won't be pixel perfect in terms of resolution and everything, but it will be a start. I'm going to take that out, and I'm going to say I think it's window capture. And I want to capture p5 web editor, and I think the best way for me to do this is to go to a share. Let's take the present mode and open a new window. Paste it in there. Let's see if it's working. Great. OK, so now in OBS I want to take the one that says Google Chrome webcam image classification. So I want to take that. Then I'm going to use the Option key to just crop around the part that I want. Again, this is silly. There's some better ways that I could do this probably. But I'm just going to crop around the part that I want, and then I will stretch it out. And now I've got it in OBS. And whenever I raise my hand, it's happening. You can see the frame rate is really low. I'm going to work on a way to fix this. The next thing that I want to do is start the OBS virtual camera. That's an option I have over here under tools, start virtual camera. That is not come by default with OBS studio. It's Dan from the future coming in to let some breaking news. [MUSIC PLAYING] Monitoring breaking news. In the latest version of Open Broadcast Studio, version 26, on Windows only. The virtual camera is built in. It looks like this. There's a button that you can press, start virtual camera. But this won't be available on Mac. Although, probably by the time you're watching this in the future, your future, it might be. The rest of this video will show you how to get the plugin extensions that you need to run a virtual camera, but if you're on Windows running OBS 26 you're good to go. Back to the past. And for Mac, there's this particular OBS virtual cam that you could just download and run the installer right here. And I'll include links to both of these for Mac and Windows in the video's description. And somebody's the chat telling me there's a way to use z4l2sink on Linux. I've started the virtual camera, and now I need to go into a Zoom meeting. Go into the meeting. So normally if I start my video, this is just me in the Zoom meeting with this video. That's the webcam. And now I should be able to go over here and change to OBS virtual camera. Shoot, I forgot that I opened it up here. There we go. Here we go. I'm in the Zoom meeting. Hi, everybody. Oh well this is such a great discussion class thingy. Oh, it's reversed. So because it's flipped, because Zoom is trying to make it a nice experience for me, I'm going to uncheck this mirror my video. And I've already mirrored it in my own software. And now, hi, I'm a question. So I want to think about ways to improve this. This is what I'm going to do. I want to make a 1280 by 720 canvas. I'm going to make the video as small as possible. So let's see, even if I do it like 160 by 120, and I'm going to hide it. I'm not going to hide it. I want to see that video separately, and then I don't want to draw the video. Instead, I just want to see the image pop up. So let's see if this works. So I've got my video at the bottom, and I'm able to get the question mark to pop up. Great. So now I'm going to go to the present to view again. I move the camera around, which I think is causing a bit of a problem. I'm going to have to retrain the model, which I'll do. Let me go back to here. This is working pretty well. And I want to change the background to a pure green, and you'll see why in a second. Now, this should run much faster. I don't need a high resolution video to do the classification, and I'm also not drawing it. So it's much less work for me not to actually draw the video. Just draw this, because now what I can do in open broadcast studio is I can actually just add my camera source directly. So I want to add the FaceTime camera. I'm going to stretch it out to take up the full, and you can see the frame rate is very fluid here. Then I'm going to add as another scene a window capture, and I'm going to get the browser. I want to grab this, which is here. I hit OK. I'm going to stretch this out, but I'm going to crop it around the Canvas. I'm going to fill the window basically with it. Then I'm going to add a filter in OBS. I'm going to go to Filters. I'm going to add an effect filter. I'm going to go to chroma key. And I want to chroma key the green out. The default is going to work really well. Have a perfect chroma key, because I drew the green itself. And now there we go, and I have no frame rate issues. Pops right up. It's time for my Zoom meeting. I'm so excited. It's time to be on Zoom for the 15th hour of the day. OBS I need to make sure I am running my virtual camera. I want to join my test meeting. Now I'm in the meeting. I turn on my video. Hello, friends. Welcome to class today on Zoom. If you have a question, please raise your hand. All right. This works. I'm so glad. This actually works quite well. Let's have a little bit more fun. Here are all the steps you need to do one at a time. First, collect images for any label that you want to define in teachable machine. I'm using question, yes, no, love, and funny, but obviously you can make up your own. And I'm also using one called background for a neutral position when I'm not doing anything, and I don't want to show any annotation. Train the model. Then upload the model. Copy paste the model URL into your code. You can find the code in the link in this video's description. Upload any images and animations you want to use to your p5.js sketch. Add an if statement for each label to either draw one of those images or any code that you want to write really. Once you're done coding, run your p5 sketch in present view. Now you can move on over to broadcast studio. Create a scene in OBS. Add a video capture device and select your camera. Then add window capture, and select the browser window that's running your p5.js sketch. Crop and resize, accordingly. If necessary, add a chroma key filter. Start the open broadcast studio virtual camera. Then move on over to Zoom, and select as your video source OBS virtual camera. Then fame and fortune await you as you entertain your friends and teachers in Zoom. All right. I hope you were able to follow those steps. I cannot wait to see if anybody actually takes this methodology and applies it to a real, live Zoom meeting. I, in fact, did just that. After I recorded this tutorial, I had a quick Zoom call with some friends of the coding training that I sent the steps. I'm going to show that to you right now, and you can sort of see what it looks like in real, live Zoom. During this meeting I thought, Of all these new ideas of things that I could try beyond just loading an image and displaying the image. The first thing I thought of is, OK. I'm programming in p5.js. There's lots of things I could do beyond just load an image and display it. I have the full range of possible things I can encode in p5. One of the things that I think is really fun to try is just any coding challenge I made with any generative art visualization, I can use as an overlay. So I could strike poses to set off heartshaped fireworks. What if every time I wear my party rock glasses, I also get a party rock hat, which follows my head using Poe's net? If you're watching this, I really hope you have your own creative idea for something you want to try, something you've already made in p5 that you want to have running live in real time in a Zoom meeting. Maybe you're visualizing data, it's just some sort of art, it's augmenting your body or your poses. You don't even need to show your video at all. You could just be showing other stuff in your Zoom. Anything you could do in p5.js with Open Broadcast Studio and a virtual camera, you can show in a video call. If you make something, I really want you to share it with me. Probably the easiest way for you to do it is on Twitter, @shiffman, but also if you go to the website page for this video it's a kind of a more permanent place you can submit a link to any documentation of what you've done. One important thing to note, and hopefully you're thinking about this already, is that if you're capturing a Zoom meeting. So for one, maybe just capture it with just you in it, and that's what you share with me. But if there are other participants, make sure you have their consent. You've asked for their permission before you share any images or snapshots of that Zoom meeting online. All right. That's all I've got for today. Thanks for watching this coding challenge. Go and bring some delight to somebody's day. I know you're going to be in a lot of video calls, but if you could take a break from that and safely get some fresh air. I highly recommend that too. And I will see you in a future coding challenge. Goodbye. [MUSIC PLAYING]
