With timestamps:

00:00 - [WHISTLE]
00:00 - Hello.
00:01 - And welcome to another video
using Posenet and ML5.js.
00:05 - But in this video,
what I'm going
00:07 - to do is take the output of
the Posenet pre-trained model,
00:12 - and feed that into an ML5
neural network to train,
00:16 - oppose classifier,
to recognize when
00:19 - I'm making certain motions
like a y, and m, a c, and an a.
00:25 - Before I begin coding,
let me quickly mention
00:27 - something I added between
the last video and now.
00:29 - I'm mirroring the image so
that when I raise my left hand,
00:33 - it's mirrored to me what I'm
seeing on the screen in front
00:36 - of me over there.
00:37 - This is important
for interactivity.
00:39 - It makes it feel much more
intuitive and natural to see
00:42 - yourself mirrored.
00:43 - You might recall
that the ML5 has
00:45 - a specific function called Flip
Image that will do it for you.
00:48 - But I actually
found, because I'm
00:50 - drawing all this other stuff,
that it's easier for me
00:52 - to just write the
code for it itself,
00:54 - which involves a
translate and a scale.
00:56 - In other words, typically if
I'm drawing an image, it's 00,
00:59 - I'm drawing it right here, and
the image gets painted across
01:03 - the canvas.
01:04 - But if I call
scale negative 1,1,
01:08 - it sets the x-axis going
in the other direction.
01:10 - So positive pixels go this way.
01:12 - And if I translate over to
here and put 00 here and draw
01:16 - the image this way, it will
appear reversed-- inverted,
01:19 - flipped--
01:20 - to the viewer.
01:21 - So that's what's happening in
these three steps right here.
01:24 - The two videos that I'm
assuming are prerequisites
01:27 - here are the previous
one, where I covered
01:29 - all of the code for this
particular Posenet example
01:32 - that you're seeing running
right here in the web editor,
01:34 - as well as this train your
own neural network set
01:38 - of videos that covered
the basics of how
01:40 - the ML5 neural network
function works to train a model
01:44 - to play musical notes based
on where the user clicks
01:47 - their mouse in a canvas.
01:49 - To get started, I could
really begin with either one
01:51 - of these sketches.
01:52 - For example, I could go
and get my Posenet code
01:54 - and bring it into this
particular sketch.
01:56 - Or I could take the neural
network code from this sketch
01:59 - and bring it into
the Posenet one.
02:01 - I think I want to continue
working from the Posenet sketch
02:04 - itself.
02:05 - And the first thing
that I want to do
02:06 - is create an object to
store the neural network.
02:10 - So I'm going to call that Brain.
02:12 - And then after I initialize
the Posenet model,
02:15 - I'll say Brain is a
new ML5 neural network.
02:20 - And you might
recall that anytime
02:21 - you create a neural
network, you can
02:23 - specify a set of
options for how you
02:25 - configured that neural network.
02:27 - All of the options
for how to configure
02:28 - an ML5 neural network, you
can find on the documentation
02:31 - page for the reference.
02:32 - I'm just starting with these
four basic properties-- inputs,
02:35 - outputs, task, and debug.
02:37 - So let's come over
here to the whiteboard.
02:39 - And let's diagram
out what's going on.
02:42 - Now remember, we're starting
with the Posenet machine
02:45 - learning model.
02:48 - We're sending an image into
that model as the input.
02:52 - The Posenet model
then takes that image
02:55 - and does Pose estimation,
making a guess
02:57 - as to where all the key
points are on the human body
03:01 - that it sees.
03:04 - And all of those points come
in the form of xy pairs,
03:07 - coordinates.
03:09 - Here's my elbow.
03:10 - Here's my shoulder.
03:11 - Here's my ear.
03:11 - It doesn't have an ear--
03:12 - whatever-- nose,
there's 17 of them.
03:15 - All of this data is
what I want to send
03:19 - in as the input to my
ML5 neural network.
03:23 - ML5 neural network will
take all these xy pairs
03:26 - and classify them into a
given pose that has a label.
03:30 - It's a dab pose, or a
Saturday Night Fever pose.
03:33 - I don't know what kind of
poses I'm going to make.
03:35 - I'll do YMCA.
03:36 - Why not?
03:39 - This now tells me how I want
to configure my neural network.
03:44 - I want to send it
17 pairs of numbers.
03:46 - That's 34 inputs.
03:49 - And I want it to
classify those 34 numbers
03:51 - into one of four labels.
03:53 - That is four outputs.
03:55 - 34 inputs, four outputs,
the task is classification.
04:01 - And I do want to see debugging
as I'm training the model.
04:04 - And I have to give those options
to the ML5 neural network
04:06 - itself.
04:07 - This is where things get
kind of complicated because I
04:09 - need to call Brain.AddData.
04:12 - That's the way I add training
data to my neural network.
04:15 - So somewhere I have to have
some kind of interaction.
04:17 - Maybe I press a key.
04:18 - I'll press the key Y and then
it will wait a little bit.
04:22 - And it'll know
after five seconds,
04:24 - for when I come over here,
to start collecting pose data
04:28 - for a certain amount of time.
04:29 - Then it will stop.
04:30 - And then I'll come back over
here, and press a button,
04:32 - and do something else.
04:33 - So this requires a
lot of thoughtfulness
04:35 - in terms of how I might build
the interaction around this.
04:38 - I'm just going to try
to do it in a simple way
04:40 - that I can get it to work right
here right now in this room.
04:43 - For a much nicer example around
interaction and collecting pose
04:47 - data, you can take a look at
Google Creative Lab's Teachable
04:49 - Machines.
04:50 - So I've made video tutorials
about training image models
04:53 - and sound models that can
actually be imported into ML5.
04:56 - At this moment, you cannot
import the pose model into ML5.
05:00 - That's something that
we're working on.
05:02 - And I'm hoping that
this video tutorial
05:03 - will lead the way to that.
05:05 - But essentially,
what I'm building
05:07 - is a pose teachable machine.
05:09 - I just won't do as thoughtful
of an interaction as here
05:13 - in the actual Teachable
Machine project.
05:15 - You can see here in Teachable
Machine, for example,
05:17 - there's a button
that I can press.
05:19 - And it's going to give
me a 10-second countdown.
05:22 - And then when I come over
here, after 10 seconds
05:28 - it's going to start
collecting my poses.
05:33 - So this is a much nicer example.
05:35 - I encourage you to look
at it for inspiration.
05:37 - Of course, that was
terrible training data.
05:38 - But now I'm going to
go back to my code
05:40 - and try to implement
my own version of this.
05:42 - To keep track of the
flow of the sketch,
05:44 - let me add a variable
called State.
05:46 - And I'll just initialize
it to waiting.
05:49 - And then I will add the
key pressed function.
05:53 - And when I press the key, I want
to say state equals collecting.
05:57 - Only, I don't want to start
collecting immediately.
05:59 - I want to wait a
little bit because it's
06:01 - going to take me some time
to walk over there and get
06:03 - into my pose.
06:04 - So I'll use Set Time
Out for a delay.
06:07 - So, Time Out is a built
in function in JavaScript.
06:09 - It's not part of P5 that
will execute a function
06:12 - after a certain amount of time.
06:13 - And maybe I want to execute this
function after a certain amount
06:16 - of milliseconds.
06:17 - So I can put a little
function inside here.
06:20 - I could use the arrow syntax.
06:21 - There's a variety of ways
I could approach this.
06:23 - Let's just say 10 seconds later.
06:25 - Right?
06:25 - So when I press the
key, 10 seconds later,
06:28 - set the state equal
to collecting.
06:30 - Also have a variable
called Target Label.
06:34 - And I'll set the target
label equal to the key that
06:38 - was pressed.
06:42 - All right, so I have
this function going.
06:43 - When I press the key,
whatever key I press
06:45 - is the target label.
06:46 - I want to see that
in the console.
06:48 - And then 10 seconds
later, I want
06:50 - to see it say that it's
starting to collect.
06:51 - Let me make it one
second later so I
06:53 - don't have to wait as long.
06:55 - All right, and I'm going
to press the Y key.
06:59 - Y, collecting-- perfect.
07:01 - So this is the right idea.
07:03 - Once that state
switches to collecting,
07:05 - I want to call the ML5 neural
network Add Data function.
07:10 - Where I want to call
the add data function
07:13 - is right here when
I have a pose.
07:14 - So when I have a pose, I want
to say Brain, Add Data, and then
07:19 - the inputs and the targets.
07:22 - The inputs are all of the xy
locations of the pose itself.
07:26 - There's 34 of them.
07:27 - I mean, I have kind
of an issue where
07:29 - the camera can't see my legs.
07:30 - So I probably should
ignore some of them.
07:32 - But I'm just not going
to worry about that.
07:33 - I could also consider using
the confidence scores.
07:36 - Like maybe the confidence
score, the neural network
07:38 - could learn when it's
a low confidence score
07:40 - to kind of ignore that point.
07:41 - But I'll ask you to try all
that stuff if you're making
07:44 - your own version of this.
07:45 - I'm just going to use
these 17 xy pairs.
07:48 - So I need them to be
in a plain old array.
07:52 - And if you recall, they're
not in a plain old array.
07:55 - They're in this
pose at key points
07:56 - which each has an object,
which is position.x.
07:59 - So I need to flatten the data.
08:01 - Whatever format
the data is in, I
08:03 - want to just put it
into a plain array.
08:06 - So I'm going to grab this loop.
08:10 - I'm going to create an
empty array called Inputs.
08:15 - And I'll just say
inputs.push x, inputs.push y.
08:21 - So this is me going
through the entire pose,
08:24 - getting all the
xy's, putting them
08:26 - in an array, which is the
input to the neural network.
08:28 - And what's the target?
08:31 - It also wants an array.
08:33 - But in this case, it's
one thing, just the label.
08:35 - So I can take the target
label, put it an array.
08:37 - And that's what I'm giving
an Add Data function.
08:40 - You might recall in my previous
neural network examples,
08:42 - I was making objects that I
passed in with named inputs
08:46 - and outputs.
08:47 - So this is just showing you
that you can do it either way.
08:49 - If I want to have names for
all the inputs and outputs,
08:51 - I can build an object
with properties.
08:53 - If I just want a big
array of numbers,
08:54 - I can just make
it a plain array.
08:56 - But there's a new problem.
08:58 - The new problem is once I
start collecting the data,
09:00 - I'm going to strike the pose.
09:02 - And maybe I'll collect the
pose for a little while.
09:04 - I've got to stop
collecting the pose.
09:06 - So let's go back up to where
I started collecting the pose.
09:12 - I'm going to do something awful.
09:15 - This is so painful.
09:16 - I don't want to do it.
09:17 - Let's just do it and then
we'll revisit it later.
09:20 - We will.
09:21 - [MUSIC PLAYING]
09:27 - I'm going to call set Time
Out again right inside here.
09:30 - Because a second later
or 10 seconds later,
09:33 - I want to stop collecting.
09:39 - This might be some of the
worst code I've ever written.
09:41 - It's really awful to look at.
09:43 - It's what's informally
known as callback hell.
09:45 - And there's a variety of ways I
could approach this differently
09:48 - by using promises,
and async, and await.
09:50 - But in this case,
really all I want to do
09:52 - is set the state to
collecting in 10 seconds.
09:56 - Then 10 seconds later,
set it back to waiting.
09:58 - And I think this
will work for me.
10:00 - Let's give it a try.
10:01 - I need to first press Y. One
1,000, two 1,000, three 1,000,
10:08 - four 1,000, five
1,000-- collecting.
10:13 - 10 seconds later it
should say not collecting.
10:15 - All r right.
10:17 - OK, that worked.
10:18 - What I'm doing here,
quite poorly I might add,
10:20 - is implementing a state machine.
10:21 - So it might be nice for me
to, in a separate video which,
10:23 - if I can ever get
around to making it,
10:25 - talk about a more proper way of
implementing a state machine.
10:28 - But this works.
10:29 - I set this state
variable to collecting.
10:32 - 10 seconds later, set it
back to not collecting.
10:34 - And during that time,
I am adding data
10:38 - to the ML5 neural network.
10:40 - [DING]
10:41 - Sorry for a second.
10:42 - I'm coming to you from
almost weeks-- several weeks,
10:45 - a month later, a
really long time,
10:46 - look how much my
beard has grown--
10:48 - to issue a correction.
10:49 - I have made a very significant
error in this video
10:53 - that you're watching.
10:54 - And I don't correct it any
time throughout the course
10:56 - of this video.
10:57 - And the error is that
I forgot to actually
11:00 - include an if statement here.
11:02 - In the Got Poses event,
when I receive a pose,
11:07 - I should only
actually call Add Data
11:09 - when the state is collecting.
11:11 - I was just doing it anyway.
11:12 - Sure, I set the
state to collecting,
11:14 - and waiting, and then to
collecting, and waiting.
11:16 - But I didn't actually
include a conditional.
11:18 - So I had a lot of messy
extra noise in the data.
11:22 - So I just redid
it now in the time
11:25 - that I'm talking
to you right now,
11:26 - and collected the data
again, retrained the model,
11:29 - and performed so much
better than it actually
11:30 - does in the video.
11:32 - And the code that's released
has that small correction in it.
11:34 - Amazingly, it kind of worked
anyway, as you'll see,
11:36 - as we continue watching.
11:37 - But just note that correction
when you go look at the code.
11:40 - It's an important detail.
11:42 - Thanks, and enjoy the
rest of this video.
11:45 - Immediately what I
want to do right now
11:47 - is add a function
to save the data.
11:50 - Because I do not want to do
this many, many, many times.
11:54 - So in key pressed, I'm going
to say if the key is S--
12:01 - Brain, save data.
12:03 - So let me quickly try
collecting that one pose again
12:07 - and make sure it can
save to a JSON file
12:09 - that I can reload later.
12:11 - Press Y, I've got
10 seconds now.
12:17 - Collecting, not collecting.
12:22 - So I can come back over here.
12:23 - I can press S. And I now have
a JSON file that was saved.
12:29 - Let's take a look at that file.
12:31 - And this is what
that file looks like.
12:32 - For every single pose it's
got X's, those are the inputs.
12:37 - There should be 34 of
them, 0 through 33.
12:41 - Then it's got the Y's,
which is one label, Y.
12:44 - So these are all of
my poses saved here
12:48 - in this big JSON file.
12:49 - Great, I can now train them--
12:52 - I can now collect the data
for all four of those poses.
12:55 - Let's see if I can
manage to do that.
12:57 - First, Y. Collecting.
13:06 - Not collecting, OK.
13:08 - Now I'm going to
do M. Collecting.
13:16 - Not collecting, OK.
13:17 - Should I really do all of these?
13:20 - C-- really noisy data.
13:28 - One more, A. OK.
13:34 - Now we save the data.
13:36 - Save.
13:39 - OK, stop.
13:42 - Stop the sketch.
13:44 - I've got the data.
13:47 - Two megabytes-- so that was a
large file but not ridiculous.
13:52 - I'm going to rename it to YMCA.
13:56 - I'm going to now
upload it to my sketch.
14:01 - And then I'm going to comment
out all the data collection
14:04 - stuff.
14:04 - Because I'm just going
to consider myself
14:06 - done with data collection.
14:07 - And I'll actually
duplicate the sketch.
14:09 - And let me call this
one Data Collection.
14:14 - I'll duplicate it and call
this one now Model Training.
14:19 - The next step is
when the sketch runs,
14:21 - to load the existing data.
14:24 - So now I don't need
to collect the data.
14:26 - I could load the data,
collect more data.
14:27 - There's so many ways
you could do this.
14:29 - But I just want to load
what I collected previously
14:32 - and then, when the
data is ready--
14:41 - when the data is ready,
when it's loaded,
14:43 - then I can call
the Train function.
14:45 - There's a lot of options I
could configure Train with.
14:47 - But I just wanted
to go for 10 epochs.
14:49 - That's running through
all of the data 10 times.
14:51 - I might need a lot more.
14:53 - When it is finished, I
want to just console log
14:56 - that it's been trained and
save the model to my Downloads
14:59 - folder so that I have it saved.
15:01 - Let's see if this works.
15:03 - So, I see the graph pop
up that would show me
15:05 - the loss while it's training.
15:07 - But it never went down at all.
15:08 - Let's try giving it 100 epochs.
15:15 - This is not a good sign.
15:18 - [DING]
15:19 - Guess what I forgot to do?
15:21 - Something very important.
15:23 - What is the data
that I'm collecting?
15:26 - These xy values are
on my P5 canvas,
15:32 - which has a roulette
resolution of 640 by 480.
15:35 - So they are large values.
15:36 - They need to be normalized down
to a standard between 0 and 1.
15:40 - So I'm going to let
the ML5 library take
15:42 - care of that for me by just
adding the normalized data
15:44 - function.
15:45 - So right here in data ready
before I train the model,
15:48 - I can call normalized data.
15:52 - Let's run it one more time.
15:54 - Let's just go down to 50 epochs.
16:00 - And there we go.
16:01 - Now I see a loss going down
the way I had hoped it would.
16:06 - And the model is trained
and presumably saved
16:08 - to my Downloads folder.
16:10 - Let's go take a look.
16:11 - Because I was doing
this multiple times,
16:12 - I have a mess of files down
here in the Downloads folder.
16:15 - But the one that was
most recent is number 5.
16:18 - So I'm going to get
rid of everything
16:21 - and just rename these
back to the default names.
16:26 - And now I can upload the
model that I trained back up
16:29 - to the P5 web editor.
16:31 - Lets duplicate the
sketch one more time.
16:34 - I'm going to call
this Posenet Deploy.
16:38 - Let's create a folder,
called it Model.
16:43 - Add the model files.
16:45 - I can see the files over here.
16:49 - And now instead of
loading the data,
16:51 - I can load the trained model.
16:57 - But if you recall from
the previous videos,
16:59 - there are three
files for the model.
17:01 - So I need to create an object
to store all three file names.
17:05 - The format for how
that has to be,
17:07 - I can find on the reference
page for ML5 neural network.
17:10 - Copy this to clipboard.
17:12 - Bring it over here
and put in my path,
17:15 - which is just called Model.
17:22 - Let's run the sketch and see if
I can just get model ready here
17:26 - in the console.
17:28 - Oh, oh, I'm just
missing a quote.
17:32 - Thank goodness.
17:34 - And I'm inconsistently using
single and double quotes.
17:36 - Let's fix that.
17:40 - Oh, it's not neural network.
17:42 - I called it Brain.
17:44 - So close.
17:47 - Posenet ready, Posenet ready.
17:50 - Huh?
17:52 - Oh, I have a
callback for Posenet
17:58 - for when it's ready
called Model Loaded.
18:00 - So this needs to be--
18:03 - I'll call this Brain Loaded.
18:06 - So remember, we're using two
machine learning models here,
18:09 - Posenet, which is doing
the pose estimation.
18:11 - Then the outputs
of that model are
18:13 - going into my own neural network
that I've trained called Brain.
18:16 - Let's try this one more time.
18:20 - Pose classification
ready, Posenet ready.
18:22 - Wonderful.
18:23 - Incidentally, the
classification model
18:25 - was loaded first
because Posenet actually
18:28 - has to reach out to
the cloud and download
18:29 - the model from Google servers.
18:31 - We are so close to
being done with this.
18:33 - Just a couple more steps.
18:35 - Once my brain is loaded, I can
actually ask it to classify.
18:40 - So I can say
Brain.ClassifyInputs.
18:44 - And when you've got a
result, call Got Result.
18:48 - The question is, what
are those inputs?
18:51 - These are those inputs.
18:52 - The same thing I did when I was
collecting the training data--
18:55 - grabbing the xy pairs,
flattening them into an array--
18:57 - I need to do that for
the inputs that I'm
18:59 - sending in when I'm
deploying the model
19:01 - and asking it to guess, asking
it to do that classification.
19:04 - Here's the loop from
the data collection
19:06 - where I flattened it
into a single array.
19:08 - I can grab that and I
can bring that in here.
19:12 - But I'm going to, once I get the
result, want to do this again.
19:16 - So really, I should
take all of this,
19:19 - write a new function
called Classify Pose,
19:24 - make sure there is a
pose in the first place.
19:27 - Then once the brain is loaded,
just call Classify Pose.
19:31 - I need the Got Result callback
which has a two arguments
19:37 - error, results.
19:41 - And I'm just going
to say console log
19:45 - results index zero dot label.
19:48 - Let's console log the
whole results as well.
19:50 - So in theory, the first
pose I get should be--
19:56 - if there is a pose when the
brain is loaded, or there
19:59 - won't be.
19:59 - So I'm going to have to--
20:01 - I'm going to put the
recursive loop call in here
20:04 - and call Classify Pose again.
20:06 - So the idea is when the brain
is loaded, classify a pose.
20:10 - If there's a pose,
call Brain.Classify.
20:13 - But what if there's no pose?
20:15 - I'll never go get a
result. Otherwise, hmm--
20:23 - this is really silly, but
I'm anticipating an issue
20:25 - that I'm going to have.
20:26 - So what I'm going to do is
if it doesn't detect a pose,
20:29 - let's just say hey,
in a little bit--
20:33 - why don't you wait
like 100 milliseconds
20:39 - and call Classify Pose again?
20:42 - So that way it will
continue to check.
20:44 - So at some point eventually,
there will be a pose.
20:47 - It'll call Brain.Classify
when that's done.
20:50 - It will call it again.
20:50 - If there [? ever loses ?]
detecting a pose,
20:53 - it won't stop.
20:54 - It will actually continue and
just every 100 milliseconds,
20:56 - keep trying again.
20:58 - All right, I think--
20:59 - there's no way this is
going to work, right?
21:02 - Let's give it a try.
21:07 - All right, pose ready.
21:11 - Y A, Y--
21:17 - C, C-- A, Y, M. What?
21:26 - This actually worked?
21:28 - Well, let's just throw
caution to the wind
21:30 - and draw the label in big
letters on the canvas.
21:36 - I'm going to set it equal
to Y so that I see it
21:38 - right there at the beginning.
21:40 - And at the end of Draw,
I'm going to say fill 255,
21:44 - 0, 255, no stroke.
21:50 - OK, there's the Y--
21:51 - oh, it's going to be reversed.
21:53 - It's going to be
flipped because of the--
21:55 - so I'm going to
also out push here.
22:00 - It doesn't matter,
Y is symmetrical.
22:01 - Y and the C won't work.
22:03 - And then pop here so that the
Y is always in the center.
22:08 - OK, now when I get a result,
set it equal to that label--
22:17 - I kind of want to
see the confidence.
22:20 - So I'll log the
confidence to the console.
22:23 - Because I want to see
how well it-- how sure
22:26 - it is about that
particular label.
22:28 - All right, here we go.
22:31 - [HUMMING "YMCA"] One,
two, three, four, one.
22:44 - It's fun to stay at the YMCA.
22:49 - It's fun to stay at YMCA.
22:58 - All right, we need these
to be capital letters.
23:03 - [HUMMING "YMCA"] One,
two, three, four, five.
23:18 - [HUMMING "YMCA"]
23:22 - Let's go slower.
23:25 - YMCA.
23:34 - So, thanks for watching this.
23:35 - I'm kind of shocked it works.
23:37 - There's so much more that
could be done with this.
23:40 - First of all, a question
came up, which is you
23:42 - forgot to normalize the data
during this classification
23:47 - process.
23:47 - And ML5, one of the
nice things it does,
23:49 - is it saves the normalization
minimums and maximums
23:52 - from the training process and
then reapplies them later.
23:55 - So I don't have to--
23:56 - I don't have to call
Normalize Data again.
23:58 - That's happening
behind the scenes.
23:59 - Otherwise, you know, what
other kinds of labels,
24:02 - what kinds of other
outputs-- you know, could
24:03 - I play different
drumbeats based on a pose?
24:07 - What other kinds of
things could you classify?
24:09 - If I collected a
much larger data set,
24:11 - if I was more thoughtful about
how I was collecting the data,
24:14 - can I get this to be
much more accurate?
24:16 - Give this a try.
24:17 - Make something.
24:18 - What I definitely
also want to do,
24:20 - which I'll need to make
another video about,
24:22 - is turn this into a regression.
24:24 - So could I take that example
where I play a frequency--
24:27 - [HUMMING] --and
alter that frequency
24:31 - by changing my
motion, my movements?
24:34 - And in fact, I could
actually have the output
24:36 - of that regression be color.
24:37 - That might be
something to explore.
24:39 - I got this idea from a
viewer named Darshawn
24:41 - who submitted a community
contribution where,
24:43 - instead of painting with
sound, you're painting
24:46 - with color with a regression.
24:47 - And that's really
interesting because it
24:48 - requires you to have
three different outputs--
24:51 - an R, a G, and a B. So take
a look at that project.
24:53 - And maybe I'll think
about doing something
24:55 - with poses and color output
in the next video tutorial.
24:59 - [HUMMING 'YMCA"]
25:04 - I have an idea.
25:06 - What if I only update the
label if the confidence is
25:09 - above a given threshold?
25:13 - Let's take 75%.
25:16 - Maybe this will eliminate
some of the noise.
25:19 - [HUMMING "YMCA"]
25:32 - It totally helps, right?
25:33 - Because it's not flickering
as much because it's
25:35 - only altering it if it's
really confident about what
25:38 - the pose is.
25:38 - And I can maybe make that
threshold even higher.
25:41 - [HUMMING "YMCA"]
25:46 - The M and the A are so similar.
25:47 - You're all right about that.
25:49 - It is able to get it though.
25:51 - M is something
slightly different.
25:55 - I'm a little out of breath, but
one more thing I want to say.
25:57 - Again, unlike with my
previous examples where
26:01 - I've trained models that do
something similar based off
26:04 - of images and
pixels, in this case,
26:06 - the pose data is more
generic that I think,
26:09 - if you go to the URL
for this sketch, which
26:11 - is in this video's description,
you can make those poses
26:14 - and hopefully it'll
recognize them.
26:15 - So give that a try.
26:16 - And I can't wait to see you
in a future coding video.
26:21 - Goodbye, have a great day.
26:22 - [WHISTLE]

Cleaned transcript:

[WHISTLE] Hello. And welcome to another video using Posenet and ML5.js. But in this video, what I'm going to do is take the output of the Posenet pretrained model, and feed that into an ML5 neural network to train, oppose classifier, to recognize when I'm making certain motions like a y, and m, a c, and an a. Before I begin coding, let me quickly mention something I added between the last video and now. I'm mirroring the image so that when I raise my left hand, it's mirrored to me what I'm seeing on the screen in front of me over there. This is important for interactivity. It makes it feel much more intuitive and natural to see yourself mirrored. You might recall that the ML5 has a specific function called Flip Image that will do it for you. But I actually found, because I'm drawing all this other stuff, that it's easier for me to just write the code for it itself, which involves a translate and a scale. In other words, typically if I'm drawing an image, it's 00, I'm drawing it right here, and the image gets painted across the canvas. But if I call scale negative 1,1, it sets the xaxis going in the other direction. So positive pixels go this way. And if I translate over to here and put 00 here and draw the image this way, it will appear reversed inverted, flipped to the viewer. So that's what's happening in these three steps right here. The two videos that I'm assuming are prerequisites here are the previous one, where I covered all of the code for this particular Posenet example that you're seeing running right here in the web editor, as well as this train your own neural network set of videos that covered the basics of how the ML5 neural network function works to train a model to play musical notes based on where the user clicks their mouse in a canvas. To get started, I could really begin with either one of these sketches. For example, I could go and get my Posenet code and bring it into this particular sketch. Or I could take the neural network code from this sketch and bring it into the Posenet one. I think I want to continue working from the Posenet sketch itself. And the first thing that I want to do is create an object to store the neural network. So I'm going to call that Brain. And then after I initialize the Posenet model, I'll say Brain is a new ML5 neural network. And you might recall that anytime you create a neural network, you can specify a set of options for how you configured that neural network. All of the options for how to configure an ML5 neural network, you can find on the documentation page for the reference. I'm just starting with these four basic properties inputs, outputs, task, and debug. So let's come over here to the whiteboard. And let's diagram out what's going on. Now remember, we're starting with the Posenet machine learning model. We're sending an image into that model as the input. The Posenet model then takes that image and does Pose estimation, making a guess as to where all the key points are on the human body that it sees. And all of those points come in the form of xy pairs, coordinates. Here's my elbow. Here's my shoulder. Here's my ear. It doesn't have an ear whatever nose, there's 17 of them. All of this data is what I want to send in as the input to my ML5 neural network. ML5 neural network will take all these xy pairs and classify them into a given pose that has a label. It's a dab pose, or a Saturday Night Fever pose. I don't know what kind of poses I'm going to make. I'll do YMCA. Why not? This now tells me how I want to configure my neural network. I want to send it 17 pairs of numbers. That's 34 inputs. And I want it to classify those 34 numbers into one of four labels. That is four outputs. 34 inputs, four outputs, the task is classification. And I do want to see debugging as I'm training the model. And I have to give those options to the ML5 neural network itself. This is where things get kind of complicated because I need to call Brain.AddData. That's the way I add training data to my neural network. So somewhere I have to have some kind of interaction. Maybe I press a key. I'll press the key Y and then it will wait a little bit. And it'll know after five seconds, for when I come over here, to start collecting pose data for a certain amount of time. Then it will stop. And then I'll come back over here, and press a button, and do something else. So this requires a lot of thoughtfulness in terms of how I might build the interaction around this. I'm just going to try to do it in a simple way that I can get it to work right here right now in this room. For a much nicer example around interaction and collecting pose data, you can take a look at Google Creative Lab's Teachable Machines. So I've made video tutorials about training image models and sound models that can actually be imported into ML5. At this moment, you cannot import the pose model into ML5. That's something that we're working on. And I'm hoping that this video tutorial will lead the way to that. But essentially, what I'm building is a pose teachable machine. I just won't do as thoughtful of an interaction as here in the actual Teachable Machine project. You can see here in Teachable Machine, for example, there's a button that I can press. And it's going to give me a 10second countdown. And then when I come over here, after 10 seconds it's going to start collecting my poses. So this is a much nicer example. I encourage you to look at it for inspiration. Of course, that was terrible training data. But now I'm going to go back to my code and try to implement my own version of this. To keep track of the flow of the sketch, let me add a variable called State. And I'll just initialize it to waiting. And then I will add the key pressed function. And when I press the key, I want to say state equals collecting. Only, I don't want to start collecting immediately. I want to wait a little bit because it's going to take me some time to walk over there and get into my pose. So I'll use Set Time Out for a delay. So, Time Out is a built in function in JavaScript. It's not part of P5 that will execute a function after a certain amount of time. And maybe I want to execute this function after a certain amount of milliseconds. So I can put a little function inside here. I could use the arrow syntax. There's a variety of ways I could approach this. Let's just say 10 seconds later. Right? So when I press the key, 10 seconds later, set the state equal to collecting. Also have a variable called Target Label. And I'll set the target label equal to the key that was pressed. All right, so I have this function going. When I press the key, whatever key I press is the target label. I want to see that in the console. And then 10 seconds later, I want to see it say that it's starting to collect. Let me make it one second later so I don't have to wait as long. All right, and I'm going to press the Y key. Y, collecting perfect. So this is the right idea. Once that state switches to collecting, I want to call the ML5 neural network Add Data function. Where I want to call the add data function is right here when I have a pose. So when I have a pose, I want to say Brain, Add Data, and then the inputs and the targets. The inputs are all of the xy locations of the pose itself. There's 34 of them. I mean, I have kind of an issue where the camera can't see my legs. So I probably should ignore some of them. But I'm just not going to worry about that. I could also consider using the confidence scores. Like maybe the confidence score, the neural network could learn when it's a low confidence score to kind of ignore that point. But I'll ask you to try all that stuff if you're making your own version of this. I'm just going to use these 17 xy pairs. So I need them to be in a plain old array. And if you recall, they're not in a plain old array. They're in this pose at key points which each has an object, which is position.x. So I need to flatten the data. Whatever format the data is in, I want to just put it into a plain array. So I'm going to grab this loop. I'm going to create an empty array called Inputs. And I'll just say inputs.push x, inputs.push y. So this is me going through the entire pose, getting all the xy's, putting them in an array, which is the input to the neural network. And what's the target? It also wants an array. But in this case, it's one thing, just the label. So I can take the target label, put it an array. And that's what I'm giving an Add Data function. You might recall in my previous neural network examples, I was making objects that I passed in with named inputs and outputs. So this is just showing you that you can do it either way. If I want to have names for all the inputs and outputs, I can build an object with properties. If I just want a big array of numbers, I can just make it a plain array. But there's a new problem. The new problem is once I start collecting the data, I'm going to strike the pose. And maybe I'll collect the pose for a little while. I've got to stop collecting the pose. So let's go back up to where I started collecting the pose. I'm going to do something awful. This is so painful. I don't want to do it. Let's just do it and then we'll revisit it later. We will. [MUSIC PLAYING] I'm going to call set Time Out again right inside here. Because a second later or 10 seconds later, I want to stop collecting. This might be some of the worst code I've ever written. It's really awful to look at. It's what's informally known as callback hell. And there's a variety of ways I could approach this differently by using promises, and async, and await. But in this case, really all I want to do is set the state to collecting in 10 seconds. Then 10 seconds later, set it back to waiting. And I think this will work for me. Let's give it a try. I need to first press Y. One 1,000, two 1,000, three 1,000, four 1,000, five 1,000 collecting. 10 seconds later it should say not collecting. All r right. OK, that worked. What I'm doing here, quite poorly I might add, is implementing a state machine. So it might be nice for me to, in a separate video which, if I can ever get around to making it, talk about a more proper way of implementing a state machine. But this works. I set this state variable to collecting. 10 seconds later, set it back to not collecting. And during that time, I am adding data to the ML5 neural network. [DING] Sorry for a second. I'm coming to you from almost weeks several weeks, a month later, a really long time, look how much my beard has grown to issue a correction. I have made a very significant error in this video that you're watching. And I don't correct it any time throughout the course of this video. And the error is that I forgot to actually include an if statement here. In the Got Poses event, when I receive a pose, I should only actually call Add Data when the state is collecting. I was just doing it anyway. Sure, I set the state to collecting, and waiting, and then to collecting, and waiting. But I didn't actually include a conditional. So I had a lot of messy extra noise in the data. So I just redid it now in the time that I'm talking to you right now, and collected the data again, retrained the model, and performed so much better than it actually does in the video. And the code that's released has that small correction in it. Amazingly, it kind of worked anyway, as you'll see, as we continue watching. But just note that correction when you go look at the code. It's an important detail. Thanks, and enjoy the rest of this video. Immediately what I want to do right now is add a function to save the data. Because I do not want to do this many, many, many times. So in key pressed, I'm going to say if the key is S Brain, save data. So let me quickly try collecting that one pose again and make sure it can save to a JSON file that I can reload later. Press Y, I've got 10 seconds now. Collecting, not collecting. So I can come back over here. I can press S. And I now have a JSON file that was saved. Let's take a look at that file. And this is what that file looks like. For every single pose it's got X's, those are the inputs. There should be 34 of them, 0 through 33. Then it's got the Y's, which is one label, Y. So these are all of my poses saved here in this big JSON file. Great, I can now train them I can now collect the data for all four of those poses. Let's see if I can manage to do that. First, Y. Collecting. Not collecting, OK. Now I'm going to do M. Collecting. Not collecting, OK. Should I really do all of these? C really noisy data. One more, A. OK. Now we save the data. Save. OK, stop. Stop the sketch. I've got the data. Two megabytes so that was a large file but not ridiculous. I'm going to rename it to YMCA. I'm going to now upload it to my sketch. And then I'm going to comment out all the data collection stuff. Because I'm just going to consider myself done with data collection. And I'll actually duplicate the sketch. And let me call this one Data Collection. I'll duplicate it and call this one now Model Training. The next step is when the sketch runs, to load the existing data. So now I don't need to collect the data. I could load the data, collect more data. There's so many ways you could do this. But I just want to load what I collected previously and then, when the data is ready when the data is ready, when it's loaded, then I can call the Train function. There's a lot of options I could configure Train with. But I just wanted to go for 10 epochs. That's running through all of the data 10 times. I might need a lot more. When it is finished, I want to just console log that it's been trained and save the model to my Downloads folder so that I have it saved. Let's see if this works. So, I see the graph pop up that would show me the loss while it's training. But it never went down at all. Let's try giving it 100 epochs. This is not a good sign. [DING] Guess what I forgot to do? Something very important. What is the data that I'm collecting? These xy values are on my P5 canvas, which has a roulette resolution of 640 by 480. So they are large values. They need to be normalized down to a standard between 0 and 1. So I'm going to let the ML5 library take care of that for me by just adding the normalized data function. So right here in data ready before I train the model, I can call normalized data. Let's run it one more time. Let's just go down to 50 epochs. And there we go. Now I see a loss going down the way I had hoped it would. And the model is trained and presumably saved to my Downloads folder. Let's go take a look. Because I was doing this multiple times, I have a mess of files down here in the Downloads folder. But the one that was most recent is number 5. So I'm going to get rid of everything and just rename these back to the default names. And now I can upload the model that I trained back up to the P5 web editor. Lets duplicate the sketch one more time. I'm going to call this Posenet Deploy. Let's create a folder, called it Model. Add the model files. I can see the files over here. And now instead of loading the data, I can load the trained model. But if you recall from the previous videos, there are three files for the model. So I need to create an object to store all three file names. The format for how that has to be, I can find on the reference page for ML5 neural network. Copy this to clipboard. Bring it over here and put in my path, which is just called Model. Let's run the sketch and see if I can just get model ready here in the console. Oh, oh, I'm just missing a quote. Thank goodness. And I'm inconsistently using single and double quotes. Let's fix that. Oh, it's not neural network. I called it Brain. So close. Posenet ready, Posenet ready. Huh? Oh, I have a callback for Posenet for when it's ready called Model Loaded. So this needs to be I'll call this Brain Loaded. So remember, we're using two machine learning models here, Posenet, which is doing the pose estimation. Then the outputs of that model are going into my own neural network that I've trained called Brain. Let's try this one more time. Pose classification ready, Posenet ready. Wonderful. Incidentally, the classification model was loaded first because Posenet actually has to reach out to the cloud and download the model from Google servers. We are so close to being done with this. Just a couple more steps. Once my brain is loaded, I can actually ask it to classify. So I can say Brain.ClassifyInputs. And when you've got a result, call Got Result. The question is, what are those inputs? These are those inputs. The same thing I did when I was collecting the training data grabbing the xy pairs, flattening them into an array I need to do that for the inputs that I'm sending in when I'm deploying the model and asking it to guess, asking it to do that classification. Here's the loop from the data collection where I flattened it into a single array. I can grab that and I can bring that in here. But I'm going to, once I get the result, want to do this again. So really, I should take all of this, write a new function called Classify Pose, make sure there is a pose in the first place. Then once the brain is loaded, just call Classify Pose. I need the Got Result callback which has a two arguments error, results. And I'm just going to say console log results index zero dot label. Let's console log the whole results as well. So in theory, the first pose I get should be if there is a pose when the brain is loaded, or there won't be. So I'm going to have to I'm going to put the recursive loop call in here and call Classify Pose again. So the idea is when the brain is loaded, classify a pose. If there's a pose, call Brain.Classify. But what if there's no pose? I'll never go get a result. Otherwise, hmm this is really silly, but I'm anticipating an issue that I'm going to have. So what I'm going to do is if it doesn't detect a pose, let's just say hey, in a little bit why don't you wait like 100 milliseconds and call Classify Pose again? So that way it will continue to check. So at some point eventually, there will be a pose. It'll call Brain.Classify when that's done. It will call it again. If there [? ever loses ?] detecting a pose, it won't stop. It will actually continue and just every 100 milliseconds, keep trying again. All right, I think there's no way this is going to work, right? Let's give it a try. All right, pose ready. Y A, Y C, C A, Y, M. What? This actually worked? Well, let's just throw caution to the wind and draw the label in big letters on the canvas. I'm going to set it equal to Y so that I see it right there at the beginning. And at the end of Draw, I'm going to say fill 255, 0, 255, no stroke. OK, there's the Y oh, it's going to be reversed. It's going to be flipped because of the so I'm going to also out push here. It doesn't matter, Y is symmetrical. Y and the C won't work. And then pop here so that the Y is always in the center. OK, now when I get a result, set it equal to that label I kind of want to see the confidence. So I'll log the confidence to the console. Because I want to see how well it how sure it is about that particular label. All right, here we go. [HUMMING "YMCA"] One, two, three, four, one. It's fun to stay at the YMCA. It's fun to stay at YMCA. All right, we need these to be capital letters. [HUMMING "YMCA"] One, two, three, four, five. [HUMMING "YMCA"] Let's go slower. YMCA. So, thanks for watching this. I'm kind of shocked it works. There's so much more that could be done with this. First of all, a question came up, which is you forgot to normalize the data during this classification process. And ML5, one of the nice things it does, is it saves the normalization minimums and maximums from the training process and then reapplies them later. So I don't have to I don't have to call Normalize Data again. That's happening behind the scenes. Otherwise, you know, what other kinds of labels, what kinds of other outputs you know, could I play different drumbeats based on a pose? What other kinds of things could you classify? If I collected a much larger data set, if I was more thoughtful about how I was collecting the data, can I get this to be much more accurate? Give this a try. Make something. What I definitely also want to do, which I'll need to make another video about, is turn this into a regression. So could I take that example where I play a frequency [HUMMING] and alter that frequency by changing my motion, my movements? And in fact, I could actually have the output of that regression be color. That might be something to explore. I got this idea from a viewer named Darshawn who submitted a community contribution where, instead of painting with sound, you're painting with color with a regression. And that's really interesting because it requires you to have three different outputs an R, a G, and a B. So take a look at that project. And maybe I'll think about doing something with poses and color output in the next video tutorial. [HUMMING 'YMCA"] I have an idea. What if I only update the label if the confidence is above a given threshold? Let's take 75%. Maybe this will eliminate some of the noise. [HUMMING "YMCA"] It totally helps, right? Because it's not flickering as much because it's only altering it if it's really confident about what the pose is. And I can maybe make that threshold even higher. [HUMMING "YMCA"] The M and the A are so similar. You're all right about that. It is able to get it though. M is something slightly different. I'm a little out of breath, but one more thing I want to say. Again, unlike with my previous examples where I've trained models that do something similar based off of images and pixels, in this case, the pose data is more generic that I think, if you go to the URL for this sketch, which is in this video's description, you can make those poses and hopefully it'll recognize them. So give that a try. And I can't wait to see you in a future coding video. Goodbye, have a great day. [WHISTLE]
