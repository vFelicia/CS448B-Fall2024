With timestamps:

00:00 - (bell dinging)
00:01 - - Alright, we are here in the
third Spell video thank you
00:05 - to Spell for sponsoring, sign
up at spell.run/codingtrain.
00:09 - Okay so if you watched the
first video, where I explain
00:13 - how to set up Spell then
you watch the second video
00:16 - which you trained your
own style transfer model
00:19 - using transfer flow and
Python running it in the cloud
00:22 - on spell.run, now you're
ready for that last step.
00:26 - Downloading your trained model from Spell,
00:29 - bringing in to the browser,
00:31 - using the ml5.js open source library,
00:34 - P5.JS open source library,
00:36 - ML5 by the way is build
on top of TensorFlow.js.
00:38 - Got to mention all these libraries.
00:39 - All theses libraries come
together and you can then take
00:42 - realtime images from
your web cam and style it
00:44 - with your style transfer model.
00:46 - So follow this tutorial.
00:47 - If you get this working
please please please
00:49 - share it with me.
00:50 - #ThisDotStyle on twitter or
share it in the comments here
00:53 - or anywhere you can find to share it.
00:55 - I would know and see what you all make.
00:57 - Okay, enjoy this video from Yining again.
01:01 - - So far we set up the environment,
01:04 - we download the dataset,
we trained the model
01:09 - with the style Python script,
01:12 - we copied our trained model
back to our local computer
01:18 - and then last step is to convert the model
01:21 - to a format that we can use
in TensorFlow.js and ml5.js.
01:27 - Okay let's do this.
01:30 - Oh, by the way this is the folder...
01:33 - This is the trained model
that we got on the desktop.
01:40 - Okay so...
01:45 - If I go back to my old
directory which is livestream
01:53 - here,
01:57 - We're going to use
02:00 - the scripts
02:01 - that
02:03 - is from fast-style-transfer-deeplearn.js
02:08 - Deeplearn.js is the formal
name for TensorFlow.js
02:12 - This is...
02:14 - This ripple is built by
02:18 - Reiichiro
02:20 - Nakano.
02:22 - His work is amazing,
02:25 - he recently contribute a new model
02:28 - called sketch.rn to ml5.js, too.
02:32 - You guys should definitely
check out his work.
02:35 - But we're going to use
his script to convert
02:39 - the TensorFlow model into a
model that we can use in ml5.js.
02:46 - So,
02:48 - the way that we are going to do it is to
02:52 - clone
02:54 - his GitHub ripple.
03:00 - And then we're going inside
to this GitHub ripple.
03:06 - And we're going to put
03:09 - all those checkpoint files that we got
03:12 - into
03:15 - one of the folders inside of
this GitHub ripple which is...
03:21 - So I'm just going to go to
fast-style-transfer-deeplearn.js
03:25 - Now just copy this folder
to the root directory of
03:30 - this GitHub ripple and I
just did, it's here and then
03:35 - we can run or we're going
to run two Python scripts.
03:38 - The first thing is to
dump the checkpoints,
03:41 - to just to convert the format,
03:44 - so what we're going to do is
03:49 - copy, paste this command and to add
03:52 - this in the code I detailed first.
03:55 - Python script and dump
this script and then
04:00 - the output directory is
04:03 - src/ckpts/our folder name
04:07 - which would be SpellModel
04:11 - and then the checkpoint file
04:14 - is in the grouped directory
of the GitHub ripple.
04:21 - So it's /SpellModel/fns.ckpt.
04:29 - This is the path to our model,
04:33 - which we saw before in
this checkpoint file.
04:39 - This is the path to our checkpoint.
04:43 - That's why we have this name here.
04:46 - Okay, so now I'm just
going to run this script.
04:57 - And then you can see it's done.
04:59 - So, it's actually created one
05:03 - checkpoint file and 49 other files
05:08 - and we can go to,
05:11 - go there to see what is the output.
05:14 - The output lives in source,
05:19 - checkpoints, and this is our model.
05:23 - And you can see that
05:26 - we got the manifest.jxon.
05:29 - This tells us the structure of the graph.
05:35 - And also 49 files
05:39 - that tells us all those values
05:40 - of those variables in each layer
05:44 - and this is the format we can use
05:47 - in ml5.js and TensorFlow.js.
05:51 - Okay.
05:52 - So now I'm just going to copy this
05:55 - model
05:57 - back to my desktop.
06:00 - Okay.
06:01 - Going to rename it and
drag it to my desktop.
06:05 - Okay, so far,
06:08 - we
06:10 - got two models.
06:13 - We have the TensorFlow saved model
06:16 - that can work in TensorFlow, of course.
06:19 - And then we got another model that
06:21 - can work in ml5.js and TensorFlow.js.
06:25 - So this is what we got today.
06:30 - And the next step is to
run this model in ml5.js.
06:36 - Here are two demos on ml5's website
06:40 - and we also
06:42 - have this
06:43 - demo here.
06:46 - That you can slack to different styles.
06:49 - You can upload the image,
06:53 - you can change the style here
and you can upload the image.
06:58 - I'm going to upload
07:00 - a photo,
07:03 - a photo of a cat.
07:05 - And then click this Transfer My Image.
07:08 - This is the transferred cat.
07:12 - You can also play with
different styles too.
07:15 - Oh, I do like this one.
07:20 - And also you can use webcam
07:25 - and then click this button
07:29 - and you can see the
transferred version of the...
07:38 - of the images from the webcam.
07:40 - So you can go there
and check this demo out
07:43 - but next we're just going to run
07:47 - this model in our p5...
07:50 - In our ml5
07:56 - demo.
07:59 - So,
08:04 - we can do this quickly.
08:12 - Here, we're just going to
clone this GitHub ripple.
08:19 - And then go inside to that folder,
08:23 - styleTransfer_spell
08:27 - and we're going to open this
folder in code your editor
08:31 - and in this
08:34 - model's folder there is
already one model there.
08:39 - We're going to add our
08:42 - new models inside of this folder.
08:45 - So what I'm going to do is to
08:48 - find that
08:51 - GitHub ripple
08:53 - and inside of our models
08:55 - I'm going to copy, paste this model in.
09:00 - I'm just going to rename it to,
09:03 - "Lotus,"
09:04 - because the name of the
art is called Lotus.
09:10 - Okay, so now we go back to our code editor
09:14 - We have a new model here
09:17 - and we can take a look at
what's inside of the index.html.
09:24 - So to run this...
09:26 - To build this demo, we need
09:29 - p5.js
09:30 - to mainly to get the video from the webcam
09:35 - and also we need
09:36 - p5.dom library
09:38 - to make it easier to
create dom elements for us
09:42 - and then in the end we
need the ml5 library.
09:47 - And then we have some styles here
09:49 - we can ignore here we
can ignore them for now.
09:51 - And we're also running
the sketch.js script here.
09:56 - And in the body we have header tag,
10:00 - we have
10:02 - P tag
10:04 - and we're linking
10:06 - the source of the image,
10:09 - the art style image
10:12 - and also we are showing the art image,
10:17 - but I'm going to change
this to the lotus image.
10:21 - This is a pre trained model.
10:26 - I'm going to add this
10:29 - image into this image folder.
10:32 - Okay.
10:34 - So here where we can say images/lotus.
10:39 - So we're going to show that image
10:40 - and in the end we have a div
container to contain our canvas
10:46 - and now we can go to...
10:49 - Let's save this index.html
10:52 - and then we're going to go to sketch.js.
10:55 - I'm just going to delete all the code here
10:57 - so we can do it ourselves
one more time together.
11:04 - So to build this demo
we need three things.
11:08 - We need a video that can get
11:12 - the images from our webcam.
11:15 - Right?
11:16 - So we have video, we also
need the style transfer
11:21 - from ml5 library to allow
us to transfer images.
11:26 - So I'm going to have another
variable called style.
11:30 - And in the end, we need a
variable to hold our output image
11:34 - so we're going to do let resultImg.
11:41 - Okay, so this is the
three things that we need.
11:47 - And in p5 there is a setup function,
11:51 - that's where because
once at the beginning.
11:54 - So in this setup function we're going to
11:57 - use p5.js to create a canvas.
12:02 - That is
12:04 - 320
12:06 - wide
12:07 - and 250
12:12 - as it's height
12:13 - and then we're going to use
this p5 dom library to put
12:19 - this canvas element
inside of a div element
12:23 - who's ID is canvasContainer,
12:29 - okay.
12:29 - So we created canvas, that's it and then
12:33 - we're going to create the video.
12:36 - So p5 has this function
called createCapture
12:43 - and if we press the
12:46 - uppercase video in,
12:47 - it will try to get the
video from your webcam.
12:50 - And we're also going to say video to hide,
12:53 - because we don't really
need the original video,
12:55 - we need the transferred video.
12:59 - So we're also going to say
13:03 - video hide
13:10 - And we are also going to
create the result image
13:16 - p5 dom library has this.
13:20 - I just want to make it
a little bit better.
13:26 - We're going to create this result image
13:30 - equals to create Img,
13:33 - press your empty stream there
13:36 - And we are also going to hide this image.
13:41 - We're going to draw
the image on the canvas
13:43 - so we don't really need this image.
13:46 - And in the end we're going to use ml5
13:49 - to get the style transfer model, right?
13:52 - So,
13:53 - style equals to
13:56 - ml5.
13:58 - style
14:00 - Transfer,
14:02 - and we are going to paste
in the path to the model.
14:05 - So it's model...
14:08 - Models not model,
14:10 - models/lotus.
14:16 - Okay and that way we can also tell
14:20 - this style transfer to look
for inputs from our video.
14:24 - So we pass in the video and
also we have a callback function
14:29 - saying oh if you finish
loading this model let me know.
14:33 - So, this is a callback
function called modelLoaded,
14:38 - we are going to define this function now.
14:40 - This is a callback function so
14:45 - we are going to do function modelLoaded.
14:50 - Once the model is loaded we can just
14:52 - ask the style transfer
to transfer something,
14:55 - but at first I want to change the text
14:58 - on this P tagging to model loaded,
15:01 - just to let people know
the model is good to go.
15:05 - So,
15:07 - I'm going to select
15:10 - an element.
15:15 - This is a function from p5 dom library
15:19 - to select a html element from the dom.
15:24 - The ID is status
15:27 - and I want to change it's html to
15:32 - Model Loaded.
15:34 - Okay.
15:35 - And then once the model
is loaded I'm going to ask
15:38 - the style to transfer something.
15:40 - So I'm going to say style.transfer
15:44 - and I'm going to pass in
another function called result.
15:50 - So this is a callback
function, once the model
15:53 - got anything back this
function will be called.
15:56 - So let's make up this
function, function gotResult.
16:01 - It would get two things,
one is if there's any error
16:05 - during this process it would put the error
16:08 - in this error variable and another
16:11 - thing is the output which is image.
16:13 - So in this, once we got
the result we are going to
16:21 - give the result image an attribute
16:26 - to hold the image source.
16:29 - So we're going to say resultImg.attribute.
16:39 - We copy the source of this image
16:42 - .source
16:44 - to our result image.
16:47 - And after we got the
result we want to call this
16:52 - style.transfer again,
16:54 - over and over again to see...
16:57 - To see more result
16:58 - so we are going to do
17:00 - style.transfer gotResult again.
17:03 - And one thing is missing
because we did update
17:07 - the source for result image but
this result image is hidden.
17:11 - So,
17:13 - we cannot see it but p5
has a function called draw.
17:19 - It will run over and over again.
17:22 - In the draw function we are
going to draw this result image.
17:27 - So, I'm just going to say image,
17:30 - it's lowercase I,
17:32 - image
17:33 - result
17:37 - Img
17:38 - from origin zero, zero,
17:40 - and the size is
17:43 - 320
17:44 - to 240.
17:46 - Okay that's it.
17:50 - This is the whole sketch.js.
17:54 - Next,
17:55 - finally we are going to run this
18:01 - code.
18:03 - We can do Pyton minus m
18:06 - SimpleHTTPServer.
18:09 - If you are using Pyton
three you need to do
18:11 - Pyton minus m
18:13 - Simple.HTTP...
18:15 - Simple.HTTP?
18:16 - no, Simple.Server
18:19 - Anyway, it starts the
server at local host 8,000.
18:23 - So now if we go to our local host
18:30 - 8,000.
18:33 - We should be able to see something.
18:41 - So model is loaded, this
is the wrong style source.
18:47 - - [Daniel] I just have to come in and try.
18:49 - (laughing)
18:52 - That is so cool (laughs).
18:55 - - And as you can see this
style has more colors
18:59 - so the result is a little bit better
19:02 - than the previous model
19:05 - and
19:07 - yes, this is the demo that we built today.
19:17 - So this is all the resources that I used.
19:20 - This is the...
19:21 - This is Gatys paper from 2015.
19:25 - This is Gene Kogan's,
"What Neural Networks See."
19:30 - This is the Transferring
Style Tutorial from Spell
19:35 - and also for ml5.js it has
a style transfer tutorial
19:39 - made by Chris and I recommend
you to check that out too.
19:44 - And this is the link to ml5.js and
19:48 - I also want to recommend
this youtube channel because
19:52 - I learned a lot of motion
learning papers from it.
19:56 - And I want to give credit to those two
20:01 - project creators,
20:03 - we used the TensorFlow implementation of
20:06 - the fast style transfer
made by Logan Engstrom
20:10 - and we used the script to convert the
20:12 - TensorFlow swift model to a format
20:16 - that we can use in
TensorFlow.js and ml5.js.
20:20 - It's made by
20:22 - Reiichiro
20:24 - Nakano.
20:27 - And to wrap up today we
trained a style transfer model
20:31 - with Spell and we
20:34 - run this model
20:35 - with ml5
20:37 - in the browser
20:38 - and you can check out the model here
20:41 - and that's it.
20:43 - (bell dinging)
20:44 - - Alright, thank you so
much Yining for being
20:45 - a wonderful guest on the
Coding Train, for showing
20:47 - us how to train our own
style transfer model,
20:50 - how to take that style transfer model
20:51 - and bring it into the browser,
style our beautiful faces
20:55 - with the style of the image,
with the image from the webcam,
20:58 - all that stuff.
20:59 - So, thank you to Yining.
21:00 - Thank you to Spell for sponsoring this.
21:03 - I'm really curious, really
curious if people are able
21:05 - to follow this and I really
want to know like what kind of
21:07 - creative, weird image combinations
can you think of and try.
21:12 - So please make some train
style transfer models,
21:15 - style all sorts of images and
share those with me on twitter
21:18 - at #ThisDotStyle or right
here in the comments as well,
21:22 - but I don't think you can
post an image in the comments,
21:24 - but you can link to it I guess.
21:26 - So anyway thank you, see
you in future videos.
21:30 - Goodbye.
21:31 - (upbeat music)
21:38 - (bell dinging)

Cleaned transcript:

(bell dinging) Alright, we are here in the third Spell video thank you to Spell for sponsoring, sign up at spell.run/codingtrain. Okay so if you watched the first video, where I explain how to set up Spell then you watch the second video which you trained your own style transfer model using transfer flow and Python running it in the cloud on spell.run, now you're ready for that last step. Downloading your trained model from Spell, bringing in to the browser, using the ml5.js open source library, P5.JS open source library, ML5 by the way is build on top of TensorFlow.js. Got to mention all these libraries. All theses libraries come together and you can then take realtime images from your web cam and style it with your style transfer model. So follow this tutorial. If you get this working please please please share it with me. #ThisDotStyle on twitter or share it in the comments here or anywhere you can find to share it. I would know and see what you all make. Okay, enjoy this video from Yining again. So far we set up the environment, we download the dataset, we trained the model with the style Python script, we copied our trained model back to our local computer and then last step is to convert the model to a format that we can use in TensorFlow.js and ml5.js. Okay let's do this. Oh, by the way this is the folder... This is the trained model that we got on the desktop. Okay so... If I go back to my old directory which is livestream here, We're going to use the scripts that is from faststyletransferdeeplearn.js Deeplearn.js is the formal name for TensorFlow.js This is... This ripple is built by Reiichiro Nakano. His work is amazing, he recently contribute a new model called sketch.rn to ml5.js, too. You guys should definitely check out his work. But we're going to use his script to convert the TensorFlow model into a model that we can use in ml5.js. So, the way that we are going to do it is to clone his GitHub ripple. And then we're going inside to this GitHub ripple. And we're going to put all those checkpoint files that we got into one of the folders inside of this GitHub ripple which is... So I'm just going to go to faststyletransferdeeplearn.js Now just copy this folder to the root directory of this GitHub ripple and I just did, it's here and then we can run or we're going to run two Python scripts. The first thing is to dump the checkpoints, to just to convert the format, so what we're going to do is copy, paste this command and to add this in the code I detailed first. Python script and dump this script and then the output directory is src/ckpts/our folder name which would be SpellModel and then the checkpoint file is in the grouped directory of the GitHub ripple. So it's /SpellModel/fns.ckpt. This is the path to our model, which we saw before in this checkpoint file. This is the path to our checkpoint. That's why we have this name here. Okay, so now I'm just going to run this script. And then you can see it's done. So, it's actually created one checkpoint file and 49 other files and we can go to, go there to see what is the output. The output lives in source, checkpoints, and this is our model. And you can see that we got the manifest.jxon. This tells us the structure of the graph. And also 49 files that tells us all those values of those variables in each layer and this is the format we can use in ml5.js and TensorFlow.js. Okay. So now I'm just going to copy this model back to my desktop. Okay. Going to rename it and drag it to my desktop. Okay, so far, we got two models. We have the TensorFlow saved model that can work in TensorFlow, of course. And then we got another model that can work in ml5.js and TensorFlow.js. So this is what we got today. And the next step is to run this model in ml5.js. Here are two demos on ml5's website and we also have this demo here. That you can slack to different styles. You can upload the image, you can change the style here and you can upload the image. I'm going to upload a photo, a photo of a cat. And then click this Transfer My Image. This is the transferred cat. You can also play with different styles too. Oh, I do like this one. And also you can use webcam and then click this button and you can see the transferred version of the... of the images from the webcam. So you can go there and check this demo out but next we're just going to run this model in our p5... In our ml5 demo. So, we can do this quickly. Here, we're just going to clone this GitHub ripple. And then go inside to that folder, styleTransfer_spell and we're going to open this folder in code your editor and in this model's folder there is already one model there. We're going to add our new models inside of this folder. So what I'm going to do is to find that GitHub ripple and inside of our models I'm going to copy, paste this model in. I'm just going to rename it to, "Lotus," because the name of the art is called Lotus. Okay, so now we go back to our code editor We have a new model here and we can take a look at what's inside of the index.html. So to run this... To build this demo, we need p5.js to mainly to get the video from the webcam and also we need p5.dom library to make it easier to create dom elements for us and then in the end we need the ml5 library. And then we have some styles here we can ignore here we can ignore them for now. And we're also running the sketch.js script here. And in the body we have header tag, we have P tag and we're linking the source of the image, the art style image and also we are showing the art image, but I'm going to change this to the lotus image. This is a pre trained model. I'm going to add this image into this image folder. Okay. So here where we can say images/lotus. So we're going to show that image and in the end we have a div container to contain our canvas and now we can go to... Let's save this index.html and then we're going to go to sketch.js. I'm just going to delete all the code here so we can do it ourselves one more time together. So to build this demo we need three things. We need a video that can get the images from our webcam. Right? So we have video, we also need the style transfer from ml5 library to allow us to transfer images. So I'm going to have another variable called style. And in the end, we need a variable to hold our output image so we're going to do let resultImg. Okay, so this is the three things that we need. And in p5 there is a setup function, that's where because once at the beginning. So in this setup function we're going to use p5.js to create a canvas. That is 320 wide and 250 as it's height and then we're going to use this p5 dom library to put this canvas element inside of a div element who's ID is canvasContainer, okay. So we created canvas, that's it and then we're going to create the video. So p5 has this function called createCapture and if we press the uppercase video in, it will try to get the video from your webcam. And we're also going to say video to hide, because we don't really need the original video, we need the transferred video. So we're also going to say video hide And we are also going to create the result image p5 dom library has this. I just want to make it a little bit better. We're going to create this result image equals to create Img, press your empty stream there And we are also going to hide this image. We're going to draw the image on the canvas so we don't really need this image. And in the end we're going to use ml5 to get the style transfer model, right? So, style equals to ml5. style Transfer, and we are going to paste in the path to the model. So it's model... Models not model, models/lotus. Okay and that way we can also tell this style transfer to look for inputs from our video. So we pass in the video and also we have a callback function saying oh if you finish loading this model let me know. So, this is a callback function called modelLoaded, we are going to define this function now. This is a callback function so we are going to do function modelLoaded. Once the model is loaded we can just ask the style transfer to transfer something, but at first I want to change the text on this P tagging to model loaded, just to let people know the model is good to go. So, I'm going to select an element. This is a function from p5 dom library to select a html element from the dom. The ID is status and I want to change it's html to Model Loaded. Okay. And then once the model is loaded I'm going to ask the style to transfer something. So I'm going to say style.transfer and I'm going to pass in another function called result. So this is a callback function, once the model got anything back this function will be called. So let's make up this function, function gotResult. It would get two things, one is if there's any error during this process it would put the error in this error variable and another thing is the output which is image. So in this, once we got the result we are going to give the result image an attribute to hold the image source. So we're going to say resultImg.attribute. We copy the source of this image .source to our result image. And after we got the result we want to call this style.transfer again, over and over again to see... To see more result so we are going to do style.transfer gotResult again. And one thing is missing because we did update the source for result image but this result image is hidden. So, we cannot see it but p5 has a function called draw. It will run over and over again. In the draw function we are going to draw this result image. So, I'm just going to say image, it's lowercase I, image result Img from origin zero, zero, and the size is 320 to 240. Okay that's it. This is the whole sketch.js. Next, finally we are going to run this code. We can do Pyton minus m SimpleHTTPServer. If you are using Pyton three you need to do Pyton minus m Simple.HTTP... Simple.HTTP? no, Simple.Server Anyway, it starts the server at local host 8,000. So now if we go to our local host 8,000. We should be able to see something. So model is loaded, this is the wrong style source. [Daniel] I just have to come in and try. (laughing) That is so cool (laughs). And as you can see this style has more colors so the result is a little bit better than the previous model and yes, this is the demo that we built today. So this is all the resources that I used. This is the... This is Gatys paper from 2015. This is Gene Kogan's, "What Neural Networks See." This is the Transferring Style Tutorial from Spell and also for ml5.js it has a style transfer tutorial made by Chris and I recommend you to check that out too. And this is the link to ml5.js and I also want to recommend this youtube channel because I learned a lot of motion learning papers from it. And I want to give credit to those two project creators, we used the TensorFlow implementation of the fast style transfer made by Logan Engstrom and we used the script to convert the TensorFlow swift model to a format that we can use in TensorFlow.js and ml5.js. It's made by Reiichiro Nakano. And to wrap up today we trained a style transfer model with Spell and we run this model with ml5 in the browser and you can check out the model here and that's it. (bell dinging) Alright, thank you so much Yining for being a wonderful guest on the Coding Train, for showing us how to train our own style transfer model, how to take that style transfer model and bring it into the browser, style our beautiful faces with the style of the image, with the image from the webcam, all that stuff. So, thank you to Yining. Thank you to Spell for sponsoring this. I'm really curious, really curious if people are able to follow this and I really want to know like what kind of creative, weird image combinations can you think of and try. So please make some train style transfer models, style all sorts of images and share those with me on twitter at #ThisDotStyle or right here in the comments as well, but I don't think you can post an image in the comments, but you can link to it I guess. So anyway thank you, see you in future videos. Goodbye. (upbeat music) (bell dinging)
