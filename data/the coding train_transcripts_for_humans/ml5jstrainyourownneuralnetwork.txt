With timestamps:

00:01 - Hello and welcome to
another Beginner's
00:03 - Guide to Machine Learning
video tutorial with ml5.js.
00:07 - Very excited about this one.
00:08 - I'm typically excited about
the video tutorials I make.
00:10 - But this one, I'm particularly
excited about because I'm
00:13 - going to look at something
that has recently
00:15 - arrived in the ml5.js library.
00:17 - So first of all, use version
0.4.2 or a more recent version
00:21 - perhaps.
00:21 - But that's the version I'll
be using in this video.
00:24 - And I want to look
at this functionality
00:26 - in the ml5.js library
called ml5 neural network.
00:29 - It is a function in ml5 that
creates an empty or blank, so
00:34 - to speak, neural network.
00:36 - Most everything that I've
showed you in this video series
00:39 - so far has involved loading
a pre-trained model, so
00:43 - a neural network
architecture that's already
00:46 - been trained with some data.
00:48 - And in this video,
I want to look
00:50 - at making an empty,
a blank slate,
00:53 - configuring your neural network,
collecting data, training
00:57 - the model, and doing inference.
01:00 - And the context that
I want to look at that
01:02 - is with real time
interactive data.
01:04 - So I'm going to come back and
maybe use some more traditional
01:07 - data sets.
01:08 - There's a data set that's on the
ml5 examples with the Titanic
01:12 - survival data set.
01:14 - I have the data set for my
color classifier series.
01:16 - So I'll come back and show you
some examples of those as well.
01:20 - But in this first
video, I just want
01:22 - to do something
very generic, which
01:24 - is create a blank
neural network,
01:26 - use mouse clicks to train it,
and then move the mouse around
01:31 - for it to make guesses
or predictions.
01:33 - And that might sound
like a weird thing to do.
01:36 - Hopefully, it'll
start to make sense
01:37 - as I build the code and step
through all the processes.
01:41 - I also want to highlight for
you the Wekinator project, which
01:44 - is a free open source
piece of software created
01:46 - by Rebecca Fiebrink in 2009
for training machine learning
01:51 - models.
01:52 - And I would especially encourage
you to watch Rebecca Fiebrink's
01:56 - talk from the Eyeo
conference in 2018
01:59 - where she talks about
creativity and inclusion
02:02 - in machine learning, and goes
through some demonstrations
02:05 - with Wekinator and processing
and other pieces of software.
02:08 - So a lot of the work
that I'm doing with ml5
02:12 - is entirely based on recreations
of many of the example
02:18 - demonstrations that Rebecca
Fiebrink made and has
02:22 - done research about
for years and years
02:24 - with the Wekinator project.
02:25 - So in fact, the
examples that I'm
02:27 - going to make in this video
and the next one and the next
02:29 - follow ups are direct
ports, in a way,
02:32 - of some of the original
Wekinator and processing
02:35 - examples.
02:35 - But I'm going to do
it all in JavaScript
02:37 - in the browser with P5
and the ml5.js library.
02:41 - There's also a fairly
lengthy history
02:43 - of creative artists training
machine learning models
02:46 - in real time to control musical
instruments, a performance,
02:50 - a visual art piece.
02:52 - And I would encourage
you to check out
02:53 - some of these projects.
02:54 - Our guide for figuring
out how to write the code
02:57 - is going to be the ml5 website.
02:59 - And there's a page on the ml5
website for the neural network
03:03 - function.
03:03 - But before I start
diving to the code,
03:06 - let's take a minute to talk
about what a neural network is.
03:10 - Now, by no means
in this video am
03:12 - I going to do a
comprehensive deep dive
03:15 - into what a neural
network is and how
03:17 - to code one from scratch.
03:18 - I will refer you to many other
wonderful resources where
03:22 - you could do that
deep dive, starting
03:23 - with the three
3Blue1Brown video, What
03:26 - Is a Neural Network and
some of the subsequent ones.
03:28 - I also I have a 10 to
15-part video series where
03:32 - I build a neural network
from scratch in JavaScript
03:35 - based on a particular
book called Make Your Own
03:37 - Neural Network
that is in Python.
03:39 - I have other videos that are
guides around machine learning
03:43 - concepts where I talk
about different kinds
03:45 - of neural networks.
03:46 - So I will link to all of those
in this video's description.
03:49 - But here, I'm going to
use the whiteboard over
03:52 - here just to give you a very
zoomed out, high level overview
03:56 - of what I'm talking about.
03:58 - So a machine learning system,
in the most basic sense,
04:01 - involves inputs and outputs.
04:07 - So let's say for a moment
that the goal that I have
04:11 - is to train a machine
learning model
04:14 - to use my body as the input.
04:18 - So maybe how I moving my
arms and legs and head,
04:21 - that will be the input.
04:22 - And the output would be
a musical instrument,
04:24 - a note that's being played.
04:26 - So I could somehow
play different notes
04:28 - based on how I move my body.
04:30 - This is an area that's covered
in great detail in Rebecca
04:33 - Fiebrink's course, Machine
Learning for Artists
04:36 - and Musicians.
04:36 - One way that I might
boil this idea down
04:39 - into its very simplest version
is, think about a 2D canvas.
04:44 - And it's very convenient
that I'm using p5.
04:46 - Because that's the thing
that exists in p5.js.
04:48 - And what I'm going
to do is I'm going
04:50 - to say there is a
mouse in that canvas.
04:53 - And the mouse is going to
move around the canvas.
04:55 - And based on where it is, it
will play a particular note.
04:59 - Now of course I could
program the same idea
05:01 - with an if statement.
05:01 - But this is really what it means
to work with machine learning.
05:05 - Instead of programming
the rules explicitly
05:09 - into code, what
I'm going to do is
05:12 - give the code a whole
bunch of examples
05:14 - and have it learn those rules.
05:16 - So I want to demonstrate
that process in a scenario
05:19 - where it's very obvious how
it's working so that then we
05:22 - can build on that into much
more complex scenarios.
05:24 - The steps are, collect data.
05:30 - Two, train model.
05:35 - Then three, I guess we
can call this prediction.
05:40 - So that's also sometimes
referred to as inference.
05:43 - That's really when we're
deploying the model,
05:45 - we're making use of the model.
05:47 - Right here, this is my
representation of the model.
05:51 - So in this case, if I want to
start with a classification
05:54 - problem-- and I will
show you demonstrations
05:56 - of classification
and regression--
05:59 - I'm going to have two inputs--
06:02 - input one and input
two, often referred to
06:05 - as x's in machine
learning context.
06:09 - Those inputs are going to go in
to this machine learning model.
06:13 - The output is going to
be one of, let's say,
06:16 - three different categories.
06:19 - So I'm going to
have three outputs--
06:22 - C, D, and E. So two inputs and,
in this case, three outputs.
06:31 - My diagram looks a
little bit weird.
06:33 - So I'm going to fix
it up for a second.
06:35 - Now all this time, I've just
been putting the letters ML
06:37 - in here for Machine
Learning, or maybe referring
06:40 - to this as a model.
06:41 - Because in truth, other
things, other kinds
06:44 - of algorithms, other types of
ideas beyond a neural network
06:47 - could slot in here.
06:50 - But the ml5 five
generic blank machine
06:53 - learning model that you can
train is a neural network one.
06:57 - So if I were to try to zoom
into this for a moment, what
07:00 - I would actually
see is something
07:02 - that looks something like this.
07:09 - This is my zoomed in diagram of
really what's going on in here.
07:14 - A neural network is
a network of neurons.
07:18 - Technically, this is a
feed-forward multi-layer
07:21 - perception.
07:21 - Because the inputs, which
are represented right here,
07:25 - get fed through
these connections,
07:27 - they're weighted connections,
and get added up altogether
07:30 - and arrive in this layer, which
is known as the hidden layer.
07:35 - And there can be multiple hidden
layers and different kinds
07:37 - of hidden layers.
07:38 - But the data is
summed and processed
07:41 - through a mathematical function
called an activation function,
07:44 - and then fed out
of the hidden layer
07:46 - and into the output layer.
07:49 - And the output layer, after
all of the hidden outputs
07:52 - are summed and passed through
an activation function,
07:55 - we get a set of numbers out.
07:57 - And those numbers
might look like this--
07:59 - 0.2, 0.7, 0.1 meaning a
20% of being category C,
08:06 - a 70% chance of
being category D,
08:09 - or a 10% chance
of being category
08:11 - E. So there's a lot more details
of what's going on in here.
08:15 - And I certainly,
once again, would
08:17 - refer you to the various
things that I'll link
08:19 - in this video's description.
08:20 - The idea here is that a neural
network is a machine learning
08:23 - model that can be trained.
08:25 - It can be shown a lot
of examples of inputs
08:27 - with their correct
corresponding outputs.
08:30 - And it can tune all
of the weights of all
08:32 - these connections so that
when it later gets new data,
08:35 - it can make appropriate
predictions.
08:38 - This is everything
that the ml5 library
08:41 - will take care of for you.
08:43 - And for us, we're
going to really just
08:44 - be working with the
inputs and outputs,
08:47 - collecting our training
data, training the model,
08:50 - and predicting outputs.
08:52 - Now that I've gotten
through that explanation,
08:54 - I really want to
just write some code
08:55 - and show you how this all works.
08:57 - Sorry to interrupt.
08:58 - It is me, from around
four days in the future.
09:01 - I did actually continue this.
09:02 - This was recorded
during a live stream.
09:04 - And I did go all the way
through and make this example.
09:06 - But I made some pretty
significant errors
09:08 - in how I use the ml5 library.
09:10 - So I've come back to
rerecord and try this again.
09:13 - I'm sure I'll make other
mistakes and things will
09:15 - go wrong.
09:16 - But if you want to watch
the original version,
09:18 - I'll link to that
video description.
09:19 - But I'm going to
start over right now.
09:21 - Quickly want to point
out that in addition
09:23 - to the p5 libraries, I've added
a reference to the ml5 library
09:26 - version 0.4.2 in index of HTML.
09:30 - In my blank p5 sketch, I can
add an ml5 neural network.
09:34 - So I need a new variable.
09:35 - I'm going to call that model.
09:39 - And I'm going to set that model
equal to ml5.neuralNetwork.
09:43 - Whenever I create a
neural network object,
09:46 - I need to configure it.
09:47 - I need to give it some
information about what's
09:49 - going inside there.
09:50 - And the guide for doing
this is the ml5 website.
09:53 - So here on the ml5 website,
you can see this quick start
09:56 - which has some sort
of sample code,
09:58 - documentation of the usage of
the neural network function,
10:01 - and a bunch of different ways of
initializing a neural network.
10:04 - And all of these involve
a variable called options.
10:08 - The idea is that I'm
creating an object that's
10:11 - going to store the properties
of the neural network.
10:14 - And then when I call
ml5.neuralNetwork,
10:17 - I pass that object in.
10:19 - So for example, looking
here at my diagram,
10:22 - I can see there are two
inputs and three outputs.
10:26 - That's something that I could
configure in the options.
10:29 - Inputs, two.
10:31 - Outputs, three.
10:33 - At a minimum, this is
all you need to configure
10:35 - an ml5 neural network--
10:37 - how many inputs,
how many outputs.
10:39 - If I scroll through the
ml5 documentation page,
10:41 - you'll see there are a
variety of other ways
10:44 - that I could configure
a neural network.
10:46 - For example, I could
actually give it a data file.
10:48 - So ml5 has functionality
built into it
10:50 - that could take a CSV or Comma
Separated Value file or a JSON
10:54 - data file and configure
inputs and outputs based
10:57 - on what's in that file.
10:58 - So I need to come
back to that and cover
10:59 - that in a separate video.
11:00 - But actually, the way
that I want to do it here
11:03 - is actually this particular way.
11:05 - Instead of specifying
the number of inputs
11:08 - and the number of outputs, it's
much more convenient for me
11:10 - to name them.
11:11 - So here are the inputs,
and x and the y.
11:14 - And here are the
outputs of label.
11:16 - Now this is not something
that the actual mechanics
11:19 - of a neural network uses.
11:21 - Inputs don't have names.
11:22 - Outputs don't have names.
11:23 - These are just numbers
flowing through
11:25 - this feed-forward network.
11:27 - But for us from a
zoomed out view,
11:29 - we can maintain
the neural network
11:30 - and use it more easily
by naming things.
11:33 - Adjusting that in the code,
I'll have an x and a y.
11:37 - These are my inputs.
11:38 - There's two and they
have names, x and y.
11:40 - The really confusing
thing here is
11:42 - what to do about the outputs.
11:44 - So while, technically
speaking, the way
11:46 - I diagram this is correct and
there are three output neurons,
11:51 - each scoring a probability
for all three categories,
11:54 - from the zoomed out
view we can think
11:56 - of it as the neural
network ending up with one
11:59 - singular result--
12:00 - what is the label it's
classified the input data in.
12:04 - So ml5 is going to handle
the number of categories
12:09 - and how to score all
those things for you.
12:11 - So if we're naming stuff,
I can actually just
12:13 - write here, say, label.
12:17 - And as I start to create
the training data,
12:19 - I'm going to come back
to this and explain
12:21 - where that number
three comes back in.
12:23 - There's one more property
to the options that's very
12:26 - important for me to specify.
12:27 - And that is the task that I want
the neural network to perform.
12:31 - And in this case, the
task is classification.
12:33 - The other task that I could've
specified is a regression.
12:36 - And I'll come back
and do other examples
12:38 - that use a neural network
to perform a regression.
12:40 - We'll see what that is and how
that works in future videos.
12:43 - In this case, though,
it's a classification
12:44 - because I want
the neural network
12:46 - to classify the input into one
of three discrete categories.
12:50 - So now, we are ready for the
first step, collect data.
12:54 - And this should really
say, collect training data.
12:57 - Collecting training
data means I need
13:00 - to have a set of inputs and
their correct corresponding
13:04 - outputs.
13:05 - And in this case, I want
to collect that data
13:07 - through user interaction.
13:09 - And I'll do that
with mouse clicks.
13:10 - So I'm going to write a
function called mousePressed.
13:13 - And I'm actually going to
get rid of the draw loop.
13:15 - And just to get started, every
time I click the mouse, let's
13:18 - draw a circle on
the screen, mouseX,
13:20 - mouseY with a radius of 24.
13:25 - And let's also put a letter
in the center of the circle.
13:32 - So now as I click, I'm
collecting data points.
13:35 - I'm collecting x and y's
that go with the category C.
13:38 - But I also want to
collect x and y's that
13:40 - go with different categories.
13:41 - So let me do that
through a key press.
13:44 - I'm going to create a
variable called targetLabel.
13:47 - And I'm just going to give that
a default value of C. The I'm
13:51 - going to add keyPressed.
13:53 - And I'll just set targetLabel
equal to the key that I press.
13:58 - Then I'll draw the
targetLabel instead.
14:01 - So here's a bunch of C's.
14:02 - Now I'm going to press
D. Here's a bunch of d's.
14:05 - Oh, it's lower case.
14:07 - Let me add to uppercase.
14:10 - Let's make sure this works.
14:11 - A bunch of C's, some D's, and E.
14:15 - Now of course, I could
do any letter right now.
14:19 - So I probably would want to
add some kind of error checking
14:21 - or determine what I want to
let be the actual targetLabels.
14:25 - But for now, I'm going to
just let it be a free for all
14:27 - and just restrict
myself to C, D, and E.
14:30 - I didn't actually
collect the data though.
14:32 - I'm just showing you
a very crude user
14:34 - interface for indicating
where I've clicked
14:37 - and letter I've pressed.
14:38 - So let me create a variable
called trainingData.
14:44 - I'm going to make that an array.
14:46 - Then whenever I click the mouse,
I'm going to say my inputs are.
14:50 - And now because I
named the inputs
14:53 - when I configured
the neural network,
14:54 - I can create an object
with an x and a y,
14:57 - and also another
one with a label.
14:59 - You'll see.
15:00 - X is mouseX.
15:02 - Y is mouseY.
15:04 - And then I'm going to
make one called outputs.
15:06 - And really, though,
these are the outputs
15:08 - but this is called a target.
15:10 - That's a word I can use here.
15:11 - Because this is
the target output
15:13 - that I want the neural network
to learn given these inputs.
15:17 - So I'm going to say
target equals label.
15:20 - And the label is
the targetLabel.
15:22 - And actually, I don't need
this training data array.
15:24 - I was thinking I wanted to
use that so I could store all
15:27 - of the data myself in an array.
15:29 - And that could be very
useful in a lot of contexts.
15:32 - Actually, all that
I need to do here
15:34 - is just say model.addData
(inputs, target).
15:40 - So this is a function in
the ml5 neural network
15:43 - class where the model can
accept training data as pairs
15:48 - of inputs and target.
15:49 - And I need to make sure that
the inputs and the target
15:52 - match up with how I
configured the neural network.
15:55 - And they do.
15:56 - Because I have an x
and a y and a label.
15:58 - And now I have an x
and y and a label here.
16:01 - Now rightfully so, you
might be asking yourself,
16:04 - what happened to the fact that
we were restricting ourselves
16:07 - to three possible
categorical outputs.
16:10 - And this is where a higher
level library like ml5 comes in.
16:14 - It's just saying, I know you're
going to do classification.
16:17 - I know I'm going to
give you a label.
16:18 - I know you're going to
give me some training data.
16:20 - So just give me all
the training data.
16:22 - I will count how many
possible outputs there
16:24 - are after you finish giving
me the training data.
16:27 - So as long as I give it a
bunch of examples with a C,
16:29 - a bunch of examples with a
D, and a bunch of examples
16:32 - with an E, it will
configure itself
16:34 - to work with a limit of three
possible labels as the output.
16:38 - Let me quickly test to
see if I get any errors.
16:42 - C, D, E. Seems to be working.
16:47 - Good.
16:47 - I am ready for the next
step, training the model.
16:52 - This is a really
easy one for us.
16:53 - Because the ml5
neural network class
16:55 - has a function called train.
16:58 - So I can just call
that train function.
17:00 - Certainly it would
make sense for me
17:02 - to build some kind of
user interface here.
17:04 - But I'm just going to keep
going with my keyPressed method.
17:06 - And I'm going to check and
say, if the key pressed is T,
17:10 - then call model.train.
17:14 - When I train the
model, I can also
17:15 - give it some options that
set various properties
17:18 - of the training process itself.
17:20 - So I'm going to create
another options object.
17:23 - Information on what
those options are
17:24 - is on the ml5
documentation page.
17:27 - I'm going to just
use one option.
17:28 - I'm going to set
something called an epoch.
17:30 - So I'm going to set the
number of epochs to 100.
17:33 - So what is an epoch?
17:34 - If I look at my training
data, I have 30 data points.
17:38 - And I'm going to feed
all of those things
17:40 - into the neural network.
17:41 - I'm going to say,
hey, neural network.
17:43 - Here's an xy.
17:44 - That goes with the
C. Here's an xy.
17:46 - That goes with the C.
17:47 - Now importantly, one
thing that's important
17:48 - that ml5 does for
you behind the scenes
17:50 - is it shuffles all
those into random order.
17:52 - Because the neural networks not
going to learn so effectively
17:55 - if I send in all the C's,
and all the D's, and then all
17:58 - the E's.
17:58 - I want to send them
in a random order.
18:00 - Sending it all 30 of
those is one epoch.
18:03 - Typically that's not enough
for the neural network
18:06 - to learn the optimal
configuration of weights.
18:09 - So you want to send it in
again, and again, and again.
18:12 - So if I have 30 data points
and I train for 100 epochs,
18:15 - that's sending stuff through
the neural network 3,000 times.
18:19 - Now in truth, there's
more to it than this.
18:20 - There's something
called a batch size
18:22 - because I might consider the
data in smaller batches out
18:25 - of those 30.
18:26 - And that can affect how
I adjust the weights.
18:29 - But we don't need
to worry about that.
18:31 - Setting the number of epochs
is a good starting point for us
18:33 - to start thinking about
the process of training
18:36 - a neural network.
18:37 - So I can pass to the train
function the options.
18:40 - And then the train function
also has two callbacks.
18:43 - One is optional.
18:44 - But I'm going to use them both.
18:45 - There's a whileTraining
callback and then
18:49 - a finishedTraining callback.
18:51 - The idea is that
there's a number
18:52 - of events happening while you're
training the neural network.
18:55 - The whileTraining callback
is executed every epoch.
18:59 - So that'll get
executed 100 times.
19:00 - And the finishedTraining
callback
19:02 - is executed when the
whole thing is finished.
19:04 - So let me write those functions.
19:08 - In finishedTraining, I'm just
going to add a console log.
19:13 - whileTraining actually
receives information
19:16 - about the training process
and receives two things--
19:18 - an epoch and a loss.
19:22 - These callbacks really
work as debugging tools
19:24 - for me to look at how the
training process is going.
19:27 - Oh, that epoch finished.
19:28 - What was the loss?
19:29 - And I need to come back and
talk about what loss is.
19:32 - But I can really look at what's
happened while it's training
19:34 - and then know that the
training has finished.
19:36 - ml5, however, has built into it
a visualization functionality
19:42 - that's part of TensorFlow.js
itself, particularly
19:44 - its library called tf.vis.
19:47 - And I can enable that
by adding one more
19:49 - option to my neural
network configuration.
19:53 - And that is debug true.
19:57 - If I add debug true, I'm
going to get much better tools
20:00 - than what I've got here
with my own callbacks.
20:02 - There's one more thing
that I've missed here.
20:06 - And that has to do with
normalizing the data.
20:10 - What does our training
data look like?
20:13 - Remember, I've got
this p5 canvas.
20:15 - Maybe it's 400 by 400.
20:18 - Any given input is a mouse click
into that canvas, like here.
20:22 - And so this might be the
mouse location 100, 100.
20:26 - So that would mean
the literal number
20:29 - 100 is being fed into
the neural network.
20:32 - But neural networks
are generally tuned
20:35 - to work with data
that's all standardized
20:37 - within a particular range.
20:39 - And there could be
a variety of ways
20:40 - you might want to use
one range versus another.
20:43 - But in many cases, you always
want to squash your input data
20:47 - into a range between 0 and 1.
20:49 - And that process is
called normalization.
20:51 - So that would be really
easy for me to do myself.
20:53 - Because if I know
the width is 400,
20:55 - I could just say 100
divided by 400 is 0.25.
20:59 - So I could apply this
normalization math myself
21:02 - in the code.
21:03 - But ml5 has a
function built into it
21:05 - that you could call right
before you train the data that
21:07 - will look at the minimums and
maximums of all of your input
21:10 - data and normalize it.
21:12 - So coming over here, I can
call that function right
21:14 - before I train the model by
saying model.normalizeData.
21:20 - An now I think I am
ready to actually train
21:24 - the model for the very first
time and complete step two.
21:30 - Let's give it a try.
21:31 - Let's add a console log to know
that the training process is
21:34 - starting.
21:36 - Let's collect a lot of data.
21:42 - Now I'm clustering all my
C's and D's and E's together
21:45 - because I want to
create a scenario that
21:46 - should be easy for the
neural network to learn.
21:48 - Again, I don't need
a neural network
21:50 - to figure out that there's
C's in the top left
21:53 - and D's in the top right
and E's on the bottom.
21:55 - But if the neural network
can learn this scenario,
21:57 - more complex and
interesting ones
22:00 - it could possibly learn as well.
22:01 - So again, if you remember,
my exciting interface
22:04 - was to press the T button.
22:06 - So I'm now going to press it.
22:10 - And this is the debug
view that pops up.
22:12 - This comes up because
I put debug as true.
22:16 - And what you're seeing, you
saw the epochs being console
22:19 - logged here.
22:20 - You see that it says
finishedTraining.
22:21 - But this is showing me
a graph of the loss.
22:25 - The x-axis is the epoch.
22:28 - And the y-axis is the
value of the loss.
22:32 - So what is loss?
22:33 - If this particular
data point that I'm
22:35 - sending into the neural network
is paired with the target of C,
22:41 - when it gets sent in,
the x gets sent in, 0.25.
22:45 - I should make the y
something different.
22:47 - Let's say the y is 200.
22:49 - The y gets sent in as 0.5.
22:51 - The neural network is
going to guess C, D, or E.
22:55 - Then it has to decide
did it get it right
22:57 - or did it get it wrong.
22:58 - Was there an error?
22:59 - So if it happened
to guess C, it's
23:01 - going to have gotten it right.
23:03 - You can think of the error as 0.
23:05 - If it's gotten it wrong,
if it guessed a D,
23:08 - then there is an error.
23:10 - Now what the value of
that error is actually
23:12 - has to do with the
scoring that it's
23:14 - doing based on its confidence
that its one label or another.
23:18 - Maybe it was like
99% sure it was
23:20 - a D. It's going to
have a big error then.
23:23 - But if it was only like 60%
sure it was a D and 40% sure
23:26 - it was a C, then that error
is going to be smaller.
23:29 - But that error, another
word for that error is loss.
23:32 - So as it sends all of
the data over a given
23:35 - epoch through the
neural network,
23:37 - it's going to summarize all of
the errors into a loss value.
23:42 - So as the neural network trains
the model with the training
23:45 - data over and over
again, epoch by epoch,
23:48 - that loss should be going down.
23:50 - It's getting better and making
more correct guesses over time.
23:53 - Based on what the
graph is doing here,
23:55 - this indicates to me
a couple of things.
23:57 - One is it's learning
kind of slowly.
24:00 - So one possibility could be
just give it more epochs.
24:03 - So maybe what I actually want
to do is go back into the code
24:07 - and give it 200
epochs instead of 100.
24:09 - The truth of the matter is
I have a very, very, very
24:11 - small data set here.
24:13 - So with a little bit of data,
I need a lot more epochs
24:15 - and it kind of makes it
feel like it's more data.
24:18 - Another way that I could
tackle this issue is
24:20 - by adding another
property to the options
24:22 - object when I configure
the neural network.
24:24 - And that property is something
called a learning rate.
24:27 - The learning rate refers to
how much these dials should
24:31 - turn based on the
errors that it's
24:33 - seeing as the neural network is
looking at the training data.
24:36 - So it got an error.
24:37 - Should I turn the
dial a lot or should I
24:39 - turn it just a little bit?
24:40 - If I turn it a lot, I might get
closer to the correct result.
24:43 - But I could also overshoot
that correct result.
24:45 - So this kind of
hyperparameter tuning,
24:48 - which is a fancy
word for saying,
24:50 - I want to try this learning
rate on this number of epochs,
24:53 - these are the kinds of things
that you could experiment
24:55 - with by training your
model over and over again
24:57 - with different properties.
24:58 - But for me right now, I'm going
to leave the default learning
25:01 - rate and just experiment
with the number of epochs.
25:03 - And maybe in some
future videos, I'll
25:04 - come back and look at some
of the other parameters
25:06 - and what might happen
as I tune them.
25:08 - Let's try one more time.
25:11 - Collecting data and
training the model.
25:20 - Oh, wacky.
25:25 - So this is really good.
25:26 - I want to see that loss
go all the way down.
25:28 - We can see at the very end
here it gets down to 0.096314.
25:33 - And you could also see that
it's starting to level out.
25:35 - That indicates to me that
if I'd given it more epochs,
25:38 - maybe it would squeeze out
a tiny bit more accuracy.
25:41 - But this is pretty good enough.
25:43 - And that, my friends,
is the end of step two.
25:46 - Guess what.
25:47 - Only one step left.
25:48 - And this one is prediction,
meaning the idea now
25:52 - that I've trained the model is
I want to give it new inputs.
25:55 - I'm not giving you a target.
25:56 - I'm not telling you
what the answer is.
25:58 - Neural network, you've learned.
25:59 - You've thought about this a lot.
26:00 - I've taught you all
I can teach you.
26:02 - Now make some guesses for me.
26:04 - To implement this, I
think something useful
26:06 - could be for me to
create a variable that's
26:08 - like the state of the program.
26:10 - And at the beginning, the
state would be collection.
26:12 - And when the state
is collection,
26:15 - that's where I want
to set the targetLabel
26:17 - and add the data to the model.
26:19 - When I press the T key,
then the state is training.
26:24 - And then when I'm
finished training,
26:26 - I could say the
state is prediction.
26:30 - And ultimately, I
think I just want
26:32 - to draw those circles during
the collection process.
26:37 - Because if the
state is prediction,
26:43 - then I want to ask the model
to classify the inputs.
26:50 - The idea being that
there are no targets.
26:53 - The model is trained.
26:55 - Here are some inputs.
26:56 - Classify them for me.
26:57 - So where do I get
the results back?
26:59 - I need a callback.
27:00 - I can define a function
called gotResults.
27:03 - Just like all the other
ml5 stuff that I've looked
27:05 - at in previous videos, there
can be an error or there could
27:08 - actually be results .
27:10 - If there is an error,
don't do anything.
27:13 - Otherwise, let's take
a look at the results.
27:16 - Let's try this again.
27:18 - I can't believe I have to
collect the data again.
27:20 - Wouldn't it be nice if
I could save the data
27:23 - so that I don't have to collect
it again if I've made changes
27:26 - to my code?
27:27 - In fact, it is.
27:28 - And I will come back
and do a separate video
27:30 - all about how to save the data.
27:31 - And in fact, I could also
save the trained model
27:34 - so I could load that trained
model onto another sketch,
27:36 - or all sorts of possibilities.
27:38 - And I will also
come back and look
27:39 - at saving data and
saving the model
27:41 - and reloading those things.
27:42 - But for right now,
I'm just going to--
27:44 - because I have the
time to do it and I
27:46 - can speed through this
when you're watching it,
27:48 - I'm just going to
constantly recollect
27:50 - the data over and over again.
27:56 - The model is trained.
27:57 - And if I did things
correctly, it'll
27:59 - now show me some results
when I click into the canvas.
28:04 - I'm going to click
over by the C's.
28:07 - This is good.
28:07 - I got an array back,
that results array.
28:10 - And it has three objects in it.
28:11 - What are those objects?
28:12 - The first one is the
label C with a confidence
28:15 - score of 88.5%.
28:18 - That's good.
28:19 - That's what I
should have gotten.
28:20 - The second one is D,
confidence score of 7%.
28:24 - Third one E, confidence
score of around 5%.
28:28 - This is exactly what I expect.
28:30 - These confidence scores are what
the neural network is really
28:34 - producing behind the scenes.
28:35 - But the ml5 library has taken
those confidence scores,
28:39 - associated them
with given labels,
28:41 - and then sorted those labels
in order of confidence.
28:45 - So I will always have in
results(0).label the label it
28:50 - thinks it should be.
28:52 - So what I can do is
grab this drawing code.
28:55 - And I can put it
right down here.
28:58 - Maybe I'll change it
to blue with an alpha.
29:03 - And instead of targetLabel, I'm
looking at results(0).label.
29:08 - Now the truth is, I shouldn't
be using mouseX and mouseY here.
29:11 - I should be actually
saving those inputs maybe
29:13 - in a global variable
or passing them.
29:15 - But I think the
prediction is going
29:16 - to happen fast enough
that I'm not really going
29:17 - to be able to move my mouse.
29:19 - So I think it'll work out OK.
29:20 - Let's give this a try.
29:21 - I've got to collect all the
data again, and train the model.
29:30 - Now I should be able to click
here and see a C. I did.
29:34 - And a D. I did.
29:36 - And an E. Let's move
along here and see.
29:39 - When does it change to C?
29:41 - It changed to C there.
29:42 - That's like a decision
threshold like thingy.
29:45 - You know what would
be interesting to do?
29:47 - We could draw a map of
what all the decisions are
29:50 - across all the pixels.
29:51 - That's a project you should do.
29:53 - I click over here.
29:54 - I should get a D.
See, what's over here?
29:56 - A D, a D, a D, an E.
Oh, this is fascinating.
29:58 - I love that this works.
29:59 - So guess what.
30:01 - This is actually done.
30:02 - But the whole point of
what I wanted to do here
30:06 - was to have it play sound.
30:07 - Because I want this to be
the beginning of an idea
30:10 - that I could maybe play musical
notes by moving my hand around.
30:13 - Imagine, again, the inputs
being instead of the xy of mouse
30:16 - clicks, the xy of some
type of hand tracking.
30:19 - Or I could actually have
more than just two inputs.
30:22 - Because I could take the
xy of this and the xy
30:24 - this and the xy or this, or
whatever kind of other data.
30:27 - Maybe you've hooked up a
whole bunch of sensors.
30:29 - And you've got a bunch
of different force
30:31 - sensors and an Arduino.
30:32 - And those could be the inputs
to your neural network.
30:34 - So many possibilities.
30:35 - But I'm not going explore
all those possibilities
30:37 - right now, at least.
30:38 - But I do want to show you
the output of playing a note.
30:41 - I made a video tutorial that
you could go back and watch
30:44 - if you want about how
to use a sound envelope
30:47 - with a sound oscillator
in p5 to generate a tone.
30:52 - And so I'm just going
to, for now, just grab
30:54 - this code, all of this, the
oscillator and the envelope.
30:58 - I'm going to paste all
that in setup here.
31:01 - And this, by the
way, has changed
31:02 - to the full word,
envelope, since I last
31:04 - made that tutorial.
31:05 - And now whenever
I click the mouse,
31:08 - I should be able to
say envelope play.
31:13 - So if I do this,
[NOTES SOUNDING] when I click,
31:19 - you hear this note play.
31:20 - But I want it to
play C, D, or E.
31:24 - And honestly, I could
make a lot of notes
31:26 - right now since I can have more
than just three categories.
31:28 - But let's just stick
with C, D, and E.
31:31 - What I need to play
a particular note
31:33 - is the frequency of that note.
31:35 - And I can find this
on this Wikipedia page
31:37 - about frequencies
and piano notes.
31:38 - I'll start with C4, D4, and E4.
31:40 - I'll make an object that's a
lookup table for those notes.
31:44 - So I have C, D, and E all
matched with their frequency.
31:47 - I should make sure that
the envelope and the wave
31:50 - are global variables.
31:52 - Because now when
I play the note,
31:57 - I could set the frequency
to notes(targetLabel).
32:03 - This will look up the
numeric frequency associated
32:06 - with that label and set
the sound oscillator
32:08 - to that frequency.
32:09 - [NOTES SOUNDING] C, C,
C. [NOTES SOUNDING] D,
32:13 - D, D. [NOTES SOUNDING] E, E, E.
32:18 - Now if I press F, it's not
going to change because I didn't
32:21 - put F in that lookup table.
32:22 - But you could add more notes.
32:23 - Add more notes, more notes.
32:25 - Then guess what.
32:26 - All I need to do is take
this exact same code.
32:29 - After prediction, instead
of the targetLabel--
32:33 - let me just put this
in another variable
32:35 - so it doesn't look so insane.
32:38 - Results(label), draw the
label, then play the note
32:42 - associated with that label.
32:44 - I think this project is done.
32:46 - Let's try it.
32:47 - I'm going to collect
the data again.
32:49 - I'm really coming
back and showing you
32:51 - how to save the data.
32:59 - Time to train the model.
33:03 - Moment of truth.
33:05 - Time to do prediction.
33:09 - [NOTES SOUNDING]
33:19 - I kind of want to do this as
I just drag the mouse around.
33:22 - Oh, guess what.
33:23 - This has been such a good
demonstration of a regression.
33:25 - So the next video
I should do, I just
33:27 - come back and do this exact same
thing but with a regression.
33:30 - What would that be?
33:31 - Instead of having categorical
output which you could only
33:35 - have a C or D or E, a regression
would have numeric output.
33:39 - You could think
of it as a slider.
33:41 - So maybe if the frequency
of C is around 262
33:46 - and the frequency of D is
around 330, maybe in between
33:51 - I'd play a note.
33:52 - I'd play like C sharp,
that's in between C and D
33:55 - right over here.
33:56 - That would be a regression.
33:57 - But I'll come back.
33:58 - I'll explain all of that and
do that in a separate video
34:00 - tutorial.
34:01 - So there's too many directions
you could go in just
34:03 - from watching this.
34:04 - At a minimum, if you're
watching this video
34:06 - and you want to try it, see if
you can recreate this process.
34:09 - You're going to find it quite
frustrating to have to collect
34:11 - the data over and over again.
34:13 - So you might want
to skip ahead if I
34:15 - have those videos ready
to see how to save
34:17 - the data you've collected.
34:18 - But certainly doing
this with more notes
34:22 - and thinking about the input
in a very different way
34:24 - would be a good starting
point for you to try.
34:27 - So thanks so much for watching.
34:29 - Many more tutorials about
the ml5 neural network
34:32 - functionality to come.
34:33 - And I'll see you in those,
where we train more models.

Cleaned transcript:

Hello and welcome to another Beginner's Guide to Machine Learning video tutorial with ml5.js. Very excited about this one. I'm typically excited about the video tutorials I make. But this one, I'm particularly excited about because I'm going to look at something that has recently arrived in the ml5.js library. So first of all, use version 0.4.2 or a more recent version perhaps. But that's the version I'll be using in this video. And I want to look at this functionality in the ml5.js library called ml5 neural network. It is a function in ml5 that creates an empty or blank, so to speak, neural network. Most everything that I've showed you in this video series so far has involved loading a pretrained model, so a neural network architecture that's already been trained with some data. And in this video, I want to look at making an empty, a blank slate, configuring your neural network, collecting data, training the model, and doing inference. And the context that I want to look at that is with real time interactive data. So I'm going to come back and maybe use some more traditional data sets. There's a data set that's on the ml5 examples with the Titanic survival data set. I have the data set for my color classifier series. So I'll come back and show you some examples of those as well. But in this first video, I just want to do something very generic, which is create a blank neural network, use mouse clicks to train it, and then move the mouse around for it to make guesses or predictions. And that might sound like a weird thing to do. Hopefully, it'll start to make sense as I build the code and step through all the processes. I also want to highlight for you the Wekinator project, which is a free open source piece of software created by Rebecca Fiebrink in 2009 for training machine learning models. And I would especially encourage you to watch Rebecca Fiebrink's talk from the Eyeo conference in 2018 where she talks about creativity and inclusion in machine learning, and goes through some demonstrations with Wekinator and processing and other pieces of software. So a lot of the work that I'm doing with ml5 is entirely based on recreations of many of the example demonstrations that Rebecca Fiebrink made and has done research about for years and years with the Wekinator project. So in fact, the examples that I'm going to make in this video and the next one and the next follow ups are direct ports, in a way, of some of the original Wekinator and processing examples. But I'm going to do it all in JavaScript in the browser with P5 and the ml5.js library. There's also a fairly lengthy history of creative artists training machine learning models in real time to control musical instruments, a performance, a visual art piece. And I would encourage you to check out some of these projects. Our guide for figuring out how to write the code is going to be the ml5 website. And there's a page on the ml5 website for the neural network function. But before I start diving to the code, let's take a minute to talk about what a neural network is. Now, by no means in this video am I going to do a comprehensive deep dive into what a neural network is and how to code one from scratch. I will refer you to many other wonderful resources where you could do that deep dive, starting with the three 3Blue1Brown video, What Is a Neural Network and some of the subsequent ones. I also I have a 10 to 15part video series where I build a neural network from scratch in JavaScript based on a particular book called Make Your Own Neural Network that is in Python. I have other videos that are guides around machine learning concepts where I talk about different kinds of neural networks. So I will link to all of those in this video's description. But here, I'm going to use the whiteboard over here just to give you a very zoomed out, high level overview of what I'm talking about. So a machine learning system, in the most basic sense, involves inputs and outputs. So let's say for a moment that the goal that I have is to train a machine learning model to use my body as the input. So maybe how I moving my arms and legs and head, that will be the input. And the output would be a musical instrument, a note that's being played. So I could somehow play different notes based on how I move my body. This is an area that's covered in great detail in Rebecca Fiebrink's course, Machine Learning for Artists and Musicians. One way that I might boil this idea down into its very simplest version is, think about a 2D canvas. And it's very convenient that I'm using p5. Because that's the thing that exists in p5.js. And what I'm going to do is I'm going to say there is a mouse in that canvas. And the mouse is going to move around the canvas. And based on where it is, it will play a particular note. Now of course I could program the same idea with an if statement. But this is really what it means to work with machine learning. Instead of programming the rules explicitly into code, what I'm going to do is give the code a whole bunch of examples and have it learn those rules. So I want to demonstrate that process in a scenario where it's very obvious how it's working so that then we can build on that into much more complex scenarios. The steps are, collect data. Two, train model. Then three, I guess we can call this prediction. So that's also sometimes referred to as inference. That's really when we're deploying the model, we're making use of the model. Right here, this is my representation of the model. So in this case, if I want to start with a classification problem and I will show you demonstrations of classification and regression I'm going to have two inputs input one and input two, often referred to as x's in machine learning context. Those inputs are going to go in to this machine learning model. The output is going to be one of, let's say, three different categories. So I'm going to have three outputs C, D, and E. So two inputs and, in this case, three outputs. My diagram looks a little bit weird. So I'm going to fix it up for a second. Now all this time, I've just been putting the letters ML in here for Machine Learning, or maybe referring to this as a model. Because in truth, other things, other kinds of algorithms, other types of ideas beyond a neural network could slot in here. But the ml5 five generic blank machine learning model that you can train is a neural network one. So if I were to try to zoom into this for a moment, what I would actually see is something that looks something like this. This is my zoomed in diagram of really what's going on in here. A neural network is a network of neurons. Technically, this is a feedforward multilayer perception. Because the inputs, which are represented right here, get fed through these connections, they're weighted connections, and get added up altogether and arrive in this layer, which is known as the hidden layer. And there can be multiple hidden layers and different kinds of hidden layers. But the data is summed and processed through a mathematical function called an activation function, and then fed out of the hidden layer and into the output layer. And the output layer, after all of the hidden outputs are summed and passed through an activation function, we get a set of numbers out. And those numbers might look like this 0.2, 0.7, 0.1 meaning a 20% of being category C, a 70% chance of being category D, or a 10% chance of being category E. So there's a lot more details of what's going on in here. And I certainly, once again, would refer you to the various things that I'll link in this video's description. The idea here is that a neural network is a machine learning model that can be trained. It can be shown a lot of examples of inputs with their correct corresponding outputs. And it can tune all of the weights of all these connections so that when it later gets new data, it can make appropriate predictions. This is everything that the ml5 library will take care of for you. And for us, we're going to really just be working with the inputs and outputs, collecting our training data, training the model, and predicting outputs. Now that I've gotten through that explanation, I really want to just write some code and show you how this all works. Sorry to interrupt. It is me, from around four days in the future. I did actually continue this. This was recorded during a live stream. And I did go all the way through and make this example. But I made some pretty significant errors in how I use the ml5 library. So I've come back to rerecord and try this again. I'm sure I'll make other mistakes and things will go wrong. But if you want to watch the original version, I'll link to that video description. But I'm going to start over right now. Quickly want to point out that in addition to the p5 libraries, I've added a reference to the ml5 library version 0.4.2 in index of HTML. In my blank p5 sketch, I can add an ml5 neural network. So I need a new variable. I'm going to call that model. And I'm going to set that model equal to ml5.neuralNetwork. Whenever I create a neural network object, I need to configure it. I need to give it some information about what's going inside there. And the guide for doing this is the ml5 website. So here on the ml5 website, you can see this quick start which has some sort of sample code, documentation of the usage of the neural network function, and a bunch of different ways of initializing a neural network. And all of these involve a variable called options. The idea is that I'm creating an object that's going to store the properties of the neural network. And then when I call ml5.neuralNetwork, I pass that object in. So for example, looking here at my diagram, I can see there are two inputs and three outputs. That's something that I could configure in the options. Inputs, two. Outputs, three. At a minimum, this is all you need to configure an ml5 neural network how many inputs, how many outputs. If I scroll through the ml5 documentation page, you'll see there are a variety of other ways that I could configure a neural network. For example, I could actually give it a data file. So ml5 has functionality built into it that could take a CSV or Comma Separated Value file or a JSON data file and configure inputs and outputs based on what's in that file. So I need to come back to that and cover that in a separate video. But actually, the way that I want to do it here is actually this particular way. Instead of specifying the number of inputs and the number of outputs, it's much more convenient for me to name them. So here are the inputs, and x and the y. And here are the outputs of label. Now this is not something that the actual mechanics of a neural network uses. Inputs don't have names. Outputs don't have names. These are just numbers flowing through this feedforward network. But for us from a zoomed out view, we can maintain the neural network and use it more easily by naming things. Adjusting that in the code, I'll have an x and a y. These are my inputs. There's two and they have names, x and y. The really confusing thing here is what to do about the outputs. So while, technically speaking, the way I diagram this is correct and there are three output neurons, each scoring a probability for all three categories, from the zoomed out view we can think of it as the neural network ending up with one singular result what is the label it's classified the input data in. So ml5 is going to handle the number of categories and how to score all those things for you. So if we're naming stuff, I can actually just write here, say, label. And as I start to create the training data, I'm going to come back to this and explain where that number three comes back in. There's one more property to the options that's very important for me to specify. And that is the task that I want the neural network to perform. And in this case, the task is classification. The other task that I could've specified is a regression. And I'll come back and do other examples that use a neural network to perform a regression. We'll see what that is and how that works in future videos. In this case, though, it's a classification because I want the neural network to classify the input into one of three discrete categories. So now, we are ready for the first step, collect data. And this should really say, collect training data. Collecting training data means I need to have a set of inputs and their correct corresponding outputs. And in this case, I want to collect that data through user interaction. And I'll do that with mouse clicks. So I'm going to write a function called mousePressed. And I'm actually going to get rid of the draw loop. And just to get started, every time I click the mouse, let's draw a circle on the screen, mouseX, mouseY with a radius of 24. And let's also put a letter in the center of the circle. So now as I click, I'm collecting data points. I'm collecting x and y's that go with the category C. But I also want to collect x and y's that go with different categories. So let me do that through a key press. I'm going to create a variable called targetLabel. And I'm just going to give that a default value of C. The I'm going to add keyPressed. And I'll just set targetLabel equal to the key that I press. Then I'll draw the targetLabel instead. So here's a bunch of C's. Now I'm going to press D. Here's a bunch of d's. Oh, it's lower case. Let me add to uppercase. Let's make sure this works. A bunch of C's, some D's, and E. Now of course, I could do any letter right now. So I probably would want to add some kind of error checking or determine what I want to let be the actual targetLabels. But for now, I'm going to just let it be a free for all and just restrict myself to C, D, and E. I didn't actually collect the data though. I'm just showing you a very crude user interface for indicating where I've clicked and letter I've pressed. So let me create a variable called trainingData. I'm going to make that an array. Then whenever I click the mouse, I'm going to say my inputs are. And now because I named the inputs when I configured the neural network, I can create an object with an x and a y, and also another one with a label. You'll see. X is mouseX. Y is mouseY. And then I'm going to make one called outputs. And really, though, these are the outputs but this is called a target. That's a word I can use here. Because this is the target output that I want the neural network to learn given these inputs. So I'm going to say target equals label. And the label is the targetLabel. And actually, I don't need this training data array. I was thinking I wanted to use that so I could store all of the data myself in an array. And that could be very useful in a lot of contexts. Actually, all that I need to do here is just say model.addData (inputs, target). So this is a function in the ml5 neural network class where the model can accept training data as pairs of inputs and target. And I need to make sure that the inputs and the target match up with how I configured the neural network. And they do. Because I have an x and a y and a label. And now I have an x and y and a label here. Now rightfully so, you might be asking yourself, what happened to the fact that we were restricting ourselves to three possible categorical outputs. And this is where a higher level library like ml5 comes in. It's just saying, I know you're going to do classification. I know I'm going to give you a label. I know you're going to give me some training data. So just give me all the training data. I will count how many possible outputs there are after you finish giving me the training data. So as long as I give it a bunch of examples with a C, a bunch of examples with a D, and a bunch of examples with an E, it will configure itself to work with a limit of three possible labels as the output. Let me quickly test to see if I get any errors. C, D, E. Seems to be working. Good. I am ready for the next step, training the model. This is a really easy one for us. Because the ml5 neural network class has a function called train. So I can just call that train function. Certainly it would make sense for me to build some kind of user interface here. But I'm just going to keep going with my keyPressed method. And I'm going to check and say, if the key pressed is T, then call model.train. When I train the model, I can also give it some options that set various properties of the training process itself. So I'm going to create another options object. Information on what those options are is on the ml5 documentation page. I'm going to just use one option. I'm going to set something called an epoch. So I'm going to set the number of epochs to 100. So what is an epoch? If I look at my training data, I have 30 data points. And I'm going to feed all of those things into the neural network. I'm going to say, hey, neural network. Here's an xy. That goes with the C. Here's an xy. That goes with the C. Now importantly, one thing that's important that ml5 does for you behind the scenes is it shuffles all those into random order. Because the neural networks not going to learn so effectively if I send in all the C's, and all the D's, and then all the E's. I want to send them in a random order. Sending it all 30 of those is one epoch. Typically that's not enough for the neural network to learn the optimal configuration of weights. So you want to send it in again, and again, and again. So if I have 30 data points and I train for 100 epochs, that's sending stuff through the neural network 3,000 times. Now in truth, there's more to it than this. There's something called a batch size because I might consider the data in smaller batches out of those 30. And that can affect how I adjust the weights. But we don't need to worry about that. Setting the number of epochs is a good starting point for us to start thinking about the process of training a neural network. So I can pass to the train function the options. And then the train function also has two callbacks. One is optional. But I'm going to use them both. There's a whileTraining callback and then a finishedTraining callback. The idea is that there's a number of events happening while you're training the neural network. The whileTraining callback is executed every epoch. So that'll get executed 100 times. And the finishedTraining callback is executed when the whole thing is finished. So let me write those functions. In finishedTraining, I'm just going to add a console log. whileTraining actually receives information about the training process and receives two things an epoch and a loss. These callbacks really work as debugging tools for me to look at how the training process is going. Oh, that epoch finished. What was the loss? And I need to come back and talk about what loss is. But I can really look at what's happened while it's training and then know that the training has finished. ml5, however, has built into it a visualization functionality that's part of TensorFlow.js itself, particularly its library called tf.vis. And I can enable that by adding one more option to my neural network configuration. And that is debug true. If I add debug true, I'm going to get much better tools than what I've got here with my own callbacks. There's one more thing that I've missed here. And that has to do with normalizing the data. What does our training data look like? Remember, I've got this p5 canvas. Maybe it's 400 by 400. Any given input is a mouse click into that canvas, like here. And so this might be the mouse location 100, 100. So that would mean the literal number 100 is being fed into the neural network. But neural networks are generally tuned to work with data that's all standardized within a particular range. And there could be a variety of ways you might want to use one range versus another. But in many cases, you always want to squash your input data into a range between 0 and 1. And that process is called normalization. So that would be really easy for me to do myself. Because if I know the width is 400, I could just say 100 divided by 400 is 0.25. So I could apply this normalization math myself in the code. But ml5 has a function built into it that you could call right before you train the data that will look at the minimums and maximums of all of your input data and normalize it. So coming over here, I can call that function right before I train the model by saying model.normalizeData. An now I think I am ready to actually train the model for the very first time and complete step two. Let's give it a try. Let's add a console log to know that the training process is starting. Let's collect a lot of data. Now I'm clustering all my C's and D's and E's together because I want to create a scenario that should be easy for the neural network to learn. Again, I don't need a neural network to figure out that there's C's in the top left and D's in the top right and E's on the bottom. But if the neural network can learn this scenario, more complex and interesting ones it could possibly learn as well. So again, if you remember, my exciting interface was to press the T button. So I'm now going to press it. And this is the debug view that pops up. This comes up because I put debug as true. And what you're seeing, you saw the epochs being console logged here. You see that it says finishedTraining. But this is showing me a graph of the loss. The xaxis is the epoch. And the yaxis is the value of the loss. So what is loss? If this particular data point that I'm sending into the neural network is paired with the target of C, when it gets sent in, the x gets sent in, 0.25. I should make the y something different. Let's say the y is 200. The y gets sent in as 0.5. The neural network is going to guess C, D, or E. Then it has to decide did it get it right or did it get it wrong. Was there an error? So if it happened to guess C, it's going to have gotten it right. You can think of the error as 0. If it's gotten it wrong, if it guessed a D, then there is an error. Now what the value of that error is actually has to do with the scoring that it's doing based on its confidence that its one label or another. Maybe it was like 99% sure it was a D. It's going to have a big error then. But if it was only like 60% sure it was a D and 40% sure it was a C, then that error is going to be smaller. But that error, another word for that error is loss. So as it sends all of the data over a given epoch through the neural network, it's going to summarize all of the errors into a loss value. So as the neural network trains the model with the training data over and over again, epoch by epoch, that loss should be going down. It's getting better and making more correct guesses over time. Based on what the graph is doing here, this indicates to me a couple of things. One is it's learning kind of slowly. So one possibility could be just give it more epochs. So maybe what I actually want to do is go back into the code and give it 200 epochs instead of 100. The truth of the matter is I have a very, very, very small data set here. So with a little bit of data, I need a lot more epochs and it kind of makes it feel like it's more data. Another way that I could tackle this issue is by adding another property to the options object when I configure the neural network. And that property is something called a learning rate. The learning rate refers to how much these dials should turn based on the errors that it's seeing as the neural network is looking at the training data. So it got an error. Should I turn the dial a lot or should I turn it just a little bit? If I turn it a lot, I might get closer to the correct result. But I could also overshoot that correct result. So this kind of hyperparameter tuning, which is a fancy word for saying, I want to try this learning rate on this number of epochs, these are the kinds of things that you could experiment with by training your model over and over again with different properties. But for me right now, I'm going to leave the default learning rate and just experiment with the number of epochs. And maybe in some future videos, I'll come back and look at some of the other parameters and what might happen as I tune them. Let's try one more time. Collecting data and training the model. Oh, wacky. So this is really good. I want to see that loss go all the way down. We can see at the very end here it gets down to 0.096314. And you could also see that it's starting to level out. That indicates to me that if I'd given it more epochs, maybe it would squeeze out a tiny bit more accuracy. But this is pretty good enough. And that, my friends, is the end of step two. Guess what. Only one step left. And this one is prediction, meaning the idea now that I've trained the model is I want to give it new inputs. I'm not giving you a target. I'm not telling you what the answer is. Neural network, you've learned. You've thought about this a lot. I've taught you all I can teach you. Now make some guesses for me. To implement this, I think something useful could be for me to create a variable that's like the state of the program. And at the beginning, the state would be collection. And when the state is collection, that's where I want to set the targetLabel and add the data to the model. When I press the T key, then the state is training. And then when I'm finished training, I could say the state is prediction. And ultimately, I think I just want to draw those circles during the collection process. Because if the state is prediction, then I want to ask the model to classify the inputs. The idea being that there are no targets. The model is trained. Here are some inputs. Classify them for me. So where do I get the results back? I need a callback. I can define a function called gotResults. Just like all the other ml5 stuff that I've looked at in previous videos, there can be an error or there could actually be results . If there is an error, don't do anything. Otherwise, let's take a look at the results. Let's try this again. I can't believe I have to collect the data again. Wouldn't it be nice if I could save the data so that I don't have to collect it again if I've made changes to my code? In fact, it is. And I will come back and do a separate video all about how to save the data. And in fact, I could also save the trained model so I could load that trained model onto another sketch, or all sorts of possibilities. And I will also come back and look at saving data and saving the model and reloading those things. But for right now, I'm just going to because I have the time to do it and I can speed through this when you're watching it, I'm just going to constantly recollect the data over and over again. The model is trained. And if I did things correctly, it'll now show me some results when I click into the canvas. I'm going to click over by the C's. This is good. I got an array back, that results array. And it has three objects in it. What are those objects? The first one is the label C with a confidence score of 88.5%. That's good. That's what I should have gotten. The second one is D, confidence score of 7%. Third one E, confidence score of around 5%. This is exactly what I expect. These confidence scores are what the neural network is really producing behind the scenes. But the ml5 library has taken those confidence scores, associated them with given labels, and then sorted those labels in order of confidence. So I will always have in results(0).label the label it thinks it should be. So what I can do is grab this drawing code. And I can put it right down here. Maybe I'll change it to blue with an alpha. And instead of targetLabel, I'm looking at results(0).label. Now the truth is, I shouldn't be using mouseX and mouseY here. I should be actually saving those inputs maybe in a global variable or passing them. But I think the prediction is going to happen fast enough that I'm not really going to be able to move my mouse. So I think it'll work out OK. Let's give this a try. I've got to collect all the data again, and train the model. Now I should be able to click here and see a C. I did. And a D. I did. And an E. Let's move along here and see. When does it change to C? It changed to C there. That's like a decision threshold like thingy. You know what would be interesting to do? We could draw a map of what all the decisions are across all the pixels. That's a project you should do. I click over here. I should get a D. See, what's over here? A D, a D, a D, an E. Oh, this is fascinating. I love that this works. So guess what. This is actually done. But the whole point of what I wanted to do here was to have it play sound. Because I want this to be the beginning of an idea that I could maybe play musical notes by moving my hand around. Imagine, again, the inputs being instead of the xy of mouse clicks, the xy of some type of hand tracking. Or I could actually have more than just two inputs. Because I could take the xy of this and the xy this and the xy or this, or whatever kind of other data. Maybe you've hooked up a whole bunch of sensors. And you've got a bunch of different force sensors and an Arduino. And those could be the inputs to your neural network. So many possibilities. But I'm not going explore all those possibilities right now, at least. But I do want to show you the output of playing a note. I made a video tutorial that you could go back and watch if you want about how to use a sound envelope with a sound oscillator in p5 to generate a tone. And so I'm just going to, for now, just grab this code, all of this, the oscillator and the envelope. I'm going to paste all that in setup here. And this, by the way, has changed to the full word, envelope, since I last made that tutorial. And now whenever I click the mouse, I should be able to say envelope play. So if I do this, [NOTES SOUNDING] when I click, you hear this note play. But I want it to play C, D, or E. And honestly, I could make a lot of notes right now since I can have more than just three categories. But let's just stick with C, D, and E. What I need to play a particular note is the frequency of that note. And I can find this on this Wikipedia page about frequencies and piano notes. I'll start with C4, D4, and E4. I'll make an object that's a lookup table for those notes. So I have C, D, and E all matched with their frequency. I should make sure that the envelope and the wave are global variables. Because now when I play the note, I could set the frequency to notes(targetLabel). This will look up the numeric frequency associated with that label and set the sound oscillator to that frequency. [NOTES SOUNDING] C, C, C. [NOTES SOUNDING] D, D, D. [NOTES SOUNDING] E, E, E. Now if I press F, it's not going to change because I didn't put F in that lookup table. But you could add more notes. Add more notes, more notes. Then guess what. All I need to do is take this exact same code. After prediction, instead of the targetLabel let me just put this in another variable so it doesn't look so insane. Results(label), draw the label, then play the note associated with that label. I think this project is done. Let's try it. I'm going to collect the data again. I'm really coming back and showing you how to save the data. Time to train the model. Moment of truth. Time to do prediction. [NOTES SOUNDING] I kind of want to do this as I just drag the mouse around. Oh, guess what. This has been such a good demonstration of a regression. So the next video I should do, I just come back and do this exact same thing but with a regression. What would that be? Instead of having categorical output which you could only have a C or D or E, a regression would have numeric output. You could think of it as a slider. So maybe if the frequency of C is around 262 and the frequency of D is around 330, maybe in between I'd play a note. I'd play like C sharp, that's in between C and D right over here. That would be a regression. But I'll come back. I'll explain all of that and do that in a separate video tutorial. So there's too many directions you could go in just from watching this. At a minimum, if you're watching this video and you want to try it, see if you can recreate this process. You're going to find it quite frustrating to have to collect the data over and over again. So you might want to skip ahead if I have those videos ready to see how to save the data you've collected. But certainly doing this with more notes and thinking about the input in a very different way would be a good starting point for you to try. So thanks so much for watching. Many more tutorials about the ml5 neural network functionality to come. And I'll see you in those, where we train more models.
