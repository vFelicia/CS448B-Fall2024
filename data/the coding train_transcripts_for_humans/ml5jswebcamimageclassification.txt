With timestamps:

00:00 - [BELL RINGS]
00:01 - Hello.
00:02 - I'm back.
00:03 - I'm back.
00:04 - I'm here to do another video
using the ml5 JavaScript
00:07 - library, a library--
00:08 - a beginner-friendly library
about machine learning.
00:10 - I'm going to use, again,
the same pre-trained model
00:13 - called MobileNet that I
talked probably way too much
00:15 - about in the previous video.
00:18 - But instead of
attempting to classify
00:21 - this image as a puffin,
which the model failed to it.
00:23 - It thinks it's an
oyster catcher, which
00:25 - is not an unreasonable guess.
00:27 - I am going to
attempt to classify
00:29 - images coming straight in in
real time from the web camera.
00:33 - So this would
actually not take us
00:34 - very long, frankly,
because I've mostly
00:36 - written all the code for it.
00:38 - So the first thing I want
to change in the code
00:41 - to turn it into video
is I want to go and look
00:43 - at where I created the image.
00:45 - So I said, puffin = createImg.
00:47 - I had just this static image.
00:49 - Now what I want to do is I want
to use the P5 function called
00:52 - Create Capture, and
instead of pointing to--
00:57 - I can't spell today.
00:58 - Instead of-- I can't
spell every day--
00:59 - instead of pointing to an
image file, the argument
01:02 - that I give the Create
Capture function is just
01:05 - the constant video.
01:07 - Video means I want to
create a video capture.
01:09 - It's going to default to
the default camera that's
01:13 - connected to the computer.
01:14 - So just to be sure
about this, I'm
01:16 - going to comment
out puffin.hide.
01:18 - I'm going to change this.
01:19 - I'm going to get rid
of this, which has
01:21 - to do with drawing the image.
01:23 - I'm going to get rid of the
predict, comment that out,
01:27 - and I'm going to change
this variable to video.
01:29 - So the only thing that
I should see right now
01:31 - is I should see the video
appearing on the page.
01:38 - So let's run this.
01:39 - Oh, first, it's
asking me permission.
01:41 - It wants to use my camera.
01:43 - I'm going to say Allow,
and then there it is.
01:46 - There's me.
01:47 - Hi, everybody!
01:48 - Look.
01:48 - I'm there and there.
01:49 - I'm here.
01:50 - I'm here.
01:50 - I'm double double
double [? band. ?] OK.
01:54 - So there it is.
01:56 - Now here's the thing.
01:57 - I could just use the video
element there, and it's fine.
02:00 - But I just have this
thing that I obsess over
02:04 - and I feel is important.
02:05 - What I'm going to do is I'm
going to hide the video.
02:07 - This is-- this has nothing to do
with the machine learning image
02:11 - classification
aspect, but I feel
02:12 - like you might have a
chance to express yourself
02:15 - to be more creative, instead
of just using the default dom
02:17 - element.
02:18 - If you actually draw the
video to the canvas itself,
02:21 - this might allow you just to do
things like draw on top of it
02:24 - and other type of stuff.
02:25 - So there we go.
02:26 - Now I have the video
in the actual canvas.
02:28 - Now I need to
figure out now when
02:30 - to call the predict
function, so in theory, I
02:32 - should just call the
predict function right here
02:34 - with the video.
02:35 - But here's one of the
nice things about ml5.
02:37 - Since ml5 knows about
things like, hey, you
02:41 - might want to do this with a
continuously running video,
02:44 - I can actually, when I create
the image class, I'm going to--
02:50 - I'm going to take
this out of here,
02:52 - so I'm going to take video
out of the .predict function.
02:54 - And actually, the
way to do this is
02:56 - when I create this image
classifier, I can actually say,
03:00 - I want the MobileNet model to
act continuously on the video.
03:06 - So I want to hook those
things up together,
03:09 - so I can actually
insert the video,
03:11 - the P5 video element right
there into the image classifier
03:14 - function.
03:15 - And then I can just call
predict without any particular--
03:19 - I mean I could always say,
predict on this specific image,
03:22 - but now the video is just
linked to that image classifier,
03:25 - and I could just call predict.
03:27 - So now if I run this,
I'm going to refresh it.
03:33 - There it goes.
03:33 - And we should see, there I am.
03:35 - I am a poncho or a
cardigan, or I'm often
03:40 - considered chain mail.
03:41 - Once again, we're seeing
the failings of the image--
03:46 - the MobileNet model in
this particular [? way. ?]
03:48 - Now the thing is it
just did it once.
03:51 - It just called predict the
moment the model was ready.
03:55 - But guess what.
03:56 - What if-- how do I
call it continuously?
03:58 - Well, you know what?
03:59 - Once it calls predict,
and it got the results,
04:01 - why not just ask
it to do it again?
04:04 - So if there was a mistake,
maybe I want to not move on.
04:07 - But if it works, I'm going
to rid of the createP stuff
04:10 - here and get rid of the
probability just for right now.
04:13 - I can just do this.
04:16 - So what I'm doing
here is this is like--
04:18 - this is essentially like a loop,
another loop that's happening.
04:22 - When the model is ready, that's
when I can start predicting.
04:25 - Then once I've got
the results, I've
04:27 - got the results, draw them,
and then show me the next one.
04:30 - Oh, but guess what.
04:31 - Hold on.
04:32 - That's weird.
04:33 - It didn't actually show up.
04:34 - So this is actually
a big problem,
04:36 - so I'm going to run this again.
04:38 - Well, hopefully, this will work.
04:39 - It's going to-- so
weirdly, this is working.
04:43 - I don't like that
this is working.
04:45 - Let's see.
04:45 - This is something it generally
tends to get correctly--
04:49 - kneepad.
04:50 - Really?
04:52 - Water bottle.
04:52 - OK.
04:54 - So-- but this worked
by accident, the fact
04:58 - that I'm seeing the text there.
05:00 - I probably shouldn't
draw in multiple places.
05:03 - What would make more
sense for me to do
05:06 - is make a global variable called
Label, and then just-- oh,
05:10 - and then have this and
have that set initially
05:13 - to an empty string.
05:15 - And then this
drawing of the label
05:17 - should actually be right
here in draw itself.
05:22 - So let's try this again.
05:23 - Let's make it a little smaller,
and let's try one more time.
05:28 - And here we go.
05:29 - Let's see what types of
things it can classify.
05:35 - And you know what?
05:36 - I should-- hm, this is--
05:39 - you know, so I'd have to be
more thoughtful about the design
05:42 - here.
05:42 - So let's do this.
05:45 - Let's make the canvas a little
bit taller, and, of course,
05:50 - I could just write it
into an HTML element,
05:52 - but just for simplicity,
let's see here.
06:02 - Let's see if this
does the trick.
06:08 - I just drew-- you know,
that's a little bit better.
06:11 - I meant to--
06:12 - I should make the
canvas a bit taller.
06:17 - I don't know why I
was so stingy there.
06:23 - So what I'm trying to do
is just draw a little area.
06:25 - There we go.
06:26 - OK, so now-- and I
probably should take out
06:32 - this console.log.
06:34 - These console.logs can
really slow things down.
06:38 - And I'm going to do this again.
06:39 - Last time-- here we go.
06:43 - All right, poncho--
oh, let's see.
06:48 - Spatula-- that's pretty good.
06:50 - Spatula.
06:52 - OK, does it recognize a bell?
06:56 - Magnetic compass.
06:58 - What about a train whistle?
07:00 - A matchstick.
07:01 - That's pretty good.
07:02 - Does it recognize a book?
07:05 - Broccoli.
07:06 - What about a marker?
07:10 - I can do this--
07:10 - I could do this all day long.
07:12 - This video is going to
be like 17 hours long.
07:15 - Pill bottle.
07:18 - Kneepad.
07:19 - Water tower.
07:21 - I think that green background
is kind of likely confusing it.
07:24 - What else do I got in this room?
07:28 - Accordion.
07:29 - Piano accordion.
07:30 - So you can see, as long
as it's something that's
07:34 - in there, if it's been trained
on that particular-- if I just
07:38 - happen to have a
chihuahua with me,
07:40 - I probably could get it to
recognize that chihuahua.
07:42 - So this is a fun thing
that you can now play with.
07:44 - You can make your
own project about.
07:47 - Sort of ske-- there's a--
07:51 - Google made a project like
this called an emoji scavenger
07:54 - hunt, where you had to
find certain things,
07:56 - get the image classifier
to recognize it.
07:58 - So there's all sorts--
08:00 - of course, it used
some custom training
08:02 - there to make that work
for particular objects.
08:04 - But so I think there's a lot
of possibilities of things
08:06 - you could explore
here, but now you
08:07 - can really have your hands
in there, play with the code,
08:11 - visualize things,
draw stuff, and really
08:14 - experiment with what
is the MobileNet model?
08:17 - What works well?
08:17 - What doesn't work well?
08:19 - And the net-- one of
the things that I really
08:21 - want to show you
how to do, which
08:23 - I will do in a future
video in this series,
08:25 - is use the MobileNet model
only as a starting point.
08:29 - So the MobileNet model
is a starting point,
08:30 - but I can then retrain
it with some custom
08:34 - images and some new labels.
08:35 - So by golly, I could get that
MobileNet model to recognize
08:38 - puffins if I wanted it to.
08:39 - So thanks for tuning in.
08:44 - Is that a thing you say?
08:45 - Do you tune into videos?
08:46 - I don't know.
08:47 - It's a live stream.
08:48 - If you're watching this
now, thanks for watching.
08:50 - And stay tuned.
08:51 - I'm just going to
keep going through it
08:52 - and show you more features
of the ml5 library.
08:56 - What should I do next?
09:00 - I don't know.
09:01 - I think I might do--
09:04 - I'm not sure yet.
09:06 - Stay tuned.
09:07 - Come back.
09:09 - Goodbye.
09:10 - Thanks for watching.
09:12 - Just look for the description.
09:13 - It'll say Next Video.
09:15 - [WHISTLES]
09:16 - [MUSIC PLAYING]

Cleaned transcript:

[BELL RINGS] Hello. I'm back. I'm back. I'm here to do another video using the ml5 JavaScript library, a library a beginnerfriendly library about machine learning. I'm going to use, again, the same pretrained model called MobileNet that I talked probably way too much about in the previous video. But instead of attempting to classify this image as a puffin, which the model failed to it. It thinks it's an oyster catcher, which is not an unreasonable guess. I am going to attempt to classify images coming straight in in real time from the web camera. So this would actually not take us very long, frankly, because I've mostly written all the code for it. So the first thing I want to change in the code to turn it into video is I want to go and look at where I created the image. So I said, puffin = createImg. I had just this static image. Now what I want to do is I want to use the P5 function called Create Capture, and instead of pointing to I can't spell today. Instead of I can't spell every day instead of pointing to an image file, the argument that I give the Create Capture function is just the constant video. Video means I want to create a video capture. It's going to default to the default camera that's connected to the computer. So just to be sure about this, I'm going to comment out puffin.hide. I'm going to change this. I'm going to get rid of this, which has to do with drawing the image. I'm going to get rid of the predict, comment that out, and I'm going to change this variable to video. So the only thing that I should see right now is I should see the video appearing on the page. So let's run this. Oh, first, it's asking me permission. It wants to use my camera. I'm going to say Allow, and then there it is. There's me. Hi, everybody! Look. I'm there and there. I'm here. I'm here. I'm double double double [? band. ?] OK. So there it is. Now here's the thing. I could just use the video element there, and it's fine. But I just have this thing that I obsess over and I feel is important. What I'm going to do is I'm going to hide the video. This is this has nothing to do with the machine learning image classification aspect, but I feel like you might have a chance to express yourself to be more creative, instead of just using the default dom element. If you actually draw the video to the canvas itself, this might allow you just to do things like draw on top of it and other type of stuff. So there we go. Now I have the video in the actual canvas. Now I need to figure out now when to call the predict function, so in theory, I should just call the predict function right here with the video. But here's one of the nice things about ml5. Since ml5 knows about things like, hey, you might want to do this with a continuously running video, I can actually, when I create the image class, I'm going to I'm going to take this out of here, so I'm going to take video out of the .predict function. And actually, the way to do this is when I create this image classifier, I can actually say, I want the MobileNet model to act continuously on the video. So I want to hook those things up together, so I can actually insert the video, the P5 video element right there into the image classifier function. And then I can just call predict without any particular I mean I could always say, predict on this specific image, but now the video is just linked to that image classifier, and I could just call predict. So now if I run this, I'm going to refresh it. There it goes. And we should see, there I am. I am a poncho or a cardigan, or I'm often considered chain mail. Once again, we're seeing the failings of the image the MobileNet model in this particular [? way. ?] Now the thing is it just did it once. It just called predict the moment the model was ready. But guess what. What if how do I call it continuously? Well, you know what? Once it calls predict, and it got the results, why not just ask it to do it again? So if there was a mistake, maybe I want to not move on. But if it works, I'm going to rid of the createP stuff here and get rid of the probability just for right now. I can just do this. So what I'm doing here is this is like this is essentially like a loop, another loop that's happening. When the model is ready, that's when I can start predicting. Then once I've got the results, I've got the results, draw them, and then show me the next one. Oh, but guess what. Hold on. That's weird. It didn't actually show up. So this is actually a big problem, so I'm going to run this again. Well, hopefully, this will work. It's going to so weirdly, this is working. I don't like that this is working. Let's see. This is something it generally tends to get correctly kneepad. Really? Water bottle. OK. So but this worked by accident, the fact that I'm seeing the text there. I probably shouldn't draw in multiple places. What would make more sense for me to do is make a global variable called Label, and then just oh, and then have this and have that set initially to an empty string. And then this drawing of the label should actually be right here in draw itself. So let's try this again. Let's make it a little smaller, and let's try one more time. And here we go. Let's see what types of things it can classify. And you know what? I should hm, this is you know, so I'd have to be more thoughtful about the design here. So let's do this. Let's make the canvas a little bit taller, and, of course, I could just write it into an HTML element, but just for simplicity, let's see here. Let's see if this does the trick. I just drew you know, that's a little bit better. I meant to I should make the canvas a bit taller. I don't know why I was so stingy there. So what I'm trying to do is just draw a little area. There we go. OK, so now and I probably should take out this console.log. These console.logs can really slow things down. And I'm going to do this again. Last time here we go. All right, poncho oh, let's see. Spatula that's pretty good. Spatula. OK, does it recognize a bell? Magnetic compass. What about a train whistle? A matchstick. That's pretty good. Does it recognize a book? Broccoli. What about a marker? I can do this I could do this all day long. This video is going to be like 17 hours long. Pill bottle. Kneepad. Water tower. I think that green background is kind of likely confusing it. What else do I got in this room? Accordion. Piano accordion. So you can see, as long as it's something that's in there, if it's been trained on that particular if I just happen to have a chihuahua with me, I probably could get it to recognize that chihuahua. So this is a fun thing that you can now play with. You can make your own project about. Sort of ske there's a Google made a project like this called an emoji scavenger hunt, where you had to find certain things, get the image classifier to recognize it. So there's all sorts of course, it used some custom training there to make that work for particular objects. But so I think there's a lot of possibilities of things you could explore here, but now you can really have your hands in there, play with the code, visualize things, draw stuff, and really experiment with what is the MobileNet model? What works well? What doesn't work well? And the net one of the things that I really want to show you how to do, which I will do in a future video in this series, is use the MobileNet model only as a starting point. So the MobileNet model is a starting point, but I can then retrain it with some custom images and some new labels. So by golly, I could get that MobileNet model to recognize puffins if I wanted it to. So thanks for tuning in. Is that a thing you say? Do you tune into videos? I don't know. It's a live stream. If you're watching this now, thanks for watching. And stay tuned. I'm just going to keep going through it and show you more features of the ml5 library. What should I do next? I don't know. I think I might do I'm not sure yet. Stay tuned. Come back. Goodbye. Thanks for watching. Just look for the description. It'll say Next Video. [WHISTLES] [MUSIC PLAYING]
