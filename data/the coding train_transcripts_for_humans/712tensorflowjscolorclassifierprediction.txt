With timestamps:

00:00 - all right oh this is getting tiring but
00:02 - I am back and I have yet another in this
00:08 - building your own custom color
00:09 - classifier with 1000 GS series now the
00:12 - thing that I want to add to this video
00:14 - and by the way this line moving across
00:16 - is pointless I just have it there so
00:18 - that I could see that the draw loop is
00:19 - animating that I haven't blocked it
00:21 - there's two things that I miss that are
00:24 - kind of important from the previous
00:25 - video what is this is actually not the
00:29 - validation data loss I didn't realize
00:32 - this but I'm going to I'm gonna change
00:35 - this here I'm gonna I'm gonna
00:36 - console.log the full logs object so
00:41 - right what I'm putting on to the screen
00:43 - is logs dot loss
00:45 - let me come to console log what's there
00:47 - so again we have to wait a minute for
00:49 - the first epoch to finish apologies for
00:51 - that
00:53 - okay there are actually two lost values
00:56 - there's the loss function can be
00:58 - computed against the training data and
01:01 - there's the loss function computed
01:03 - against the validation data now to do
01:05 - this properly I really should be using
01:07 - the validation loss because that data
01:10 - that hasn't been done with the training
01:12 - that's that's that's that's protecting
01:15 - against overfitting having my model work
01:16 - really well with the training data only
01:18 - the thing is I have a very small data
01:21 - set 5,000 data points
01:23 - I'm just using 10% as the validation
01:25 - data and the weight to the flow digest
01:28 - works it also takes that 10% from the
01:30 - end and I didn't wasn't careful about
01:32 - shuffling the data around so this is
01:34 - something that I should come back to I
01:35 - don't know maybe this series will go on
01:36 - to infinity but if I were doing this
01:40 - properly I would actually want to show
01:42 - the validation loss here like this log
01:47 - stop validation loss maybe I want to
01:49 - show both and maybe I want to be more
01:51 - thoughtful about shuffling the data
01:52 - first in advance but I that's not what I
01:55 - said I was gonna do the next video so
01:57 - I'm again leaving that temporarily as an
01:59 - exercise to the viewer or I'll come back
02:01 - and do it in a future video
02:02 - I don't know yet that's item number one
02:04 - item number two thank you to me I am so
02:07 - me
02:07 - and others in the coding train sponsor
02:09 - patron group I've made this way more
02:12 - complicated than it needs by trying to
02:14 - make this an async function in here
02:16 - actually this does not need to be an
02:18 - async function if I just return TF dot
02:22 - next frame so if I just return TF next
02:24 - frame it's actually returning the
02:27 - promise and unlocking the draw loop so
02:29 - that makes it simpler actually I really
02:31 - want to do it couldn't be this so
02:34 - simpler what am I doing here at the end
02:36 - of every batch I want TF next frame to
02:38 - be executed and so I actually don't need
02:41 - to write a wrapper function to execute
02:43 - TF next frame what I could just do is
02:47 - set that as the callback the callback
02:50 - again if I wanted to do more with on
02:52 - batch and look at the loss and the logs
02:54 - but really what I want is at the end of
02:56 - every batch to draw a new frame of
02:58 - animation I can just put TF knocked next
03:00 - frame as the function which is the
03:02 - callback there okay so let's this is
03:06 - still working that simplifies the code
03:08 - makes it a little nicer to look at I
03:09 - don't even really need this on on begin
03:13 - and on end but I'll leave those in there
03:15 - just so you see them okay so now I'm
03:18 - ready for what is the purpose of this
03:19 - video the purpose of this video is while
03:23 - I'm training the model I couldn't wait
03:24 - till I finished rigging the model but
03:26 - I'm actually it allowed this to happen
03:27 - while I'm training the model I want to
03:29 - be able to specify a color and see what
03:32 - the neural network thinks that color is
03:34 - so very quickly to do this what I'm
03:37 - going to do is I'm going to create our
03:38 - slider G slider B slider I'm going to
03:42 - make three sliders again this could use
03:45 - a lot of improvements and I'm going to
03:47 - use the p5 Dom library create slider
03:50 - function so the slider is a range
03:52 - between 0 and 255 and let's start with
03:55 - like what's this red and green make
03:58 - yellow let's start with a yellow and so
04:05 - the G's the B slider should be on 0 and
04:11 - then I want the background color to and
04:15 - I don't know what that's doing there I
04:17 - don't need this line anymore it's
04:18 - distracting I want to say are
04:21 - Lichter well let's actually let's so I
04:24 - want to say let our equal our slider
04:26 - value so I want to get the values from
04:30 - the sliders I want G and I won't be
04:34 - eventually I'm gonna send these as
04:36 - inputs into the neural network but right
04:38 - now I just want to be able to see that
04:39 - color our G B okay so here we go so now
04:44 - we should see there are three sliders
04:46 - and as I adjust these sliders I can
04:48 - change the color and so what I want
04:51 - whoops what I want is to be able to and
04:54 - I see though what I want is now to see
04:56 - the neural networks prediction down here
04:58 - so how do I do that okay time to use
05:02 - tensorflow touch yes again whoo so I
05:06 - need to make some input data so the
05:09 - input X's are tensor T F dot tensor 2d
05:18 - and an array with RGB in it now in
05:22 - theory I could be running prediction
05:25 - with multiple RG B's right but I'm not
05:29 - so I need an array of arrays in here so
05:34 - this is my input data then what do I
05:37 - want to do I want to say model dot
05:39 - predict with those X's feel like you
05:44 - know what I need to normalize those
05:48 - right because the it expects to have
05:51 - normalized values between 0 and 1 so I
05:53 - need to divide each of those by 255 then
05:55 - I need to call model dot predict and
05:57 - then look at the results and that happen
06:06 - oh what this doesn't actually happen
06:09 - asynchronously it's the because the data
06:15 - is still on the GPU this is a confusing
06:17 - thing I have to pull I'm gonna use that
06:19 - date I have to pull it out but let's
06:20 - just look at the results of pure results
06:22 - so I should then be able to say results
06:26 - dot print okay so I think this is me
06:30 - just creating the inputs getting the
06:33 - prediction and then I should be able to
06:34 - see that in the console
06:37 - syntax error who I have an extra extra
06:41 - curly bracket alright okay so we can see
06:45 - this and this is exactly what I should
06:47 - be getting right it is a probability
06:49 - distribution over nine labels now
06:53 - whether it's giving me correct ones who
06:54 - knows but look at that so now how do I
06:57 - get the label out of there well remember
07:01 - that what I'm looking for is I'm looking
07:04 - for which probability is at them at the
07:07 - highest level is it a ninety percent
07:09 - chance of it being yellowish and point
07:12 - zero one point zero two point zero three
07:13 - you know 1% 2% 3% of being the other
07:16 - ones and there actually is a function
07:18 - intention flow Jas that will pull out
07:21 - the index of the highest probability
07:24 - value that's called Arg max right I
07:27 - could write a little for loop or or some
07:30 - kind of function to do that but if I
07:31 - look for Arg max TF dot Arg max returns
07:35 - the indices of the maximum values along
07:39 - an axis so this is can be quite more
07:41 - complex because I can have
07:42 - multi-dimensional data but I actually
07:44 - get to do this in a really simple way I
07:46 - just want to say let index equal results
07:52 - dot Arg max yep and if there's an access
07:56 - of AXI access of 1 the first there's a 1
07:59 - dimensional here so now let me say index
08:02 - dot print and so let me run this and we
08:08 - can see it's just giving me whom is that
08:11 - right is that a coincidence so I should
08:14 - get some different values yes okay so
08:18 - it's actually changing so that that's
08:20 - giving me that maximum index so as I
08:23 - change so so this is my label here's the
08:26 - thing though that's my label but I need
08:28 - to convert that to one of these so 0
08:33 - means reddish one means greenish two
08:35 - beads blueish 3 means orangish so I have
08:39 - this label list already I should be able
08:42 - to just say let label equal label list
08:49 - index the only thing is I can't do that
08:53 - because this is a tensor
08:55 - that's a tensor and what I want I need
08:58 - to pull that the tensor is the numbers
09:00 - the data that lives on the GPU the WebGL
09:03 - fancy thing that Tetsuo digest is
09:05 - implemented I need to pull that off and
09:07 - normally I would pull that off with an
09:09 - asynchronous function but the thing is
09:11 - here it's such a little tiny bit of data
09:15 - I think I can pull it off synchronously
09:17 - and not slow down my program from
09:20 - running so actually what I want to say
09:22 - here is Data Sync and then which is a
09:26 - dot data would pull it off
09:28 - asynchronously so let's look at and
09:31 - let's let's say I'm a console dot log
09:35 - index let me get rid of my other console
09:37 - logs that I don't really want to look at
09:41 - right now so okay so I got an array with
09:48 - the number in it I pulled it off and so
09:52 - then I just want to say index 0 so I
09:55 - only need that first value index 0 and
10:00 - so there we go
10:01 - that's the label number I now have the
10:03 - label number and so now I can say this
10:06 - and I can say and let's put it out on a
10:10 - paragraph element so let's say let label
10:13 - P let's have that be first and so now I
10:19 - want to say label P equals creepy and
10:24 - then I should say all the way back down
10:27 - here label P HTML label
10:31 - okay ready for this here we go I've
10:34 - started my training oh wait why this is
10:37 - so silly but I want the label to P above
10:39 - it I really should not be changing this
10:42 - right now so let me just put it here
10:48 - okay so here we go it thinks that's
10:52 - greenish right well it hasn't gotten
10:54 - very far with the training I would
10:56 - imagine that once we train further and
10:58 - the law starts going down it's going to
11:00 - recognize that
11:01 - as yellowish so here I'm gonna just wait
11:03 - a little bit and I'll be back in a
11:05 - minute
11:06 - [Music]
11:10 - all right back so he trained over 10 in
11:13 - each box and you can see now it's saying
11:15 - this is yellowish let me tune this down
11:17 - that's greenish turn this up
11:19 - that's bluish we've still got blueish
11:21 - can we get some purple purplish can we
11:25 - get some pink
11:26 - oh it didn't get pink maybe if I add a
11:28 - little more brightness ah now that
11:30 - thinks that's pink so I have now trained
11:33 - the neural network to recognize and
11:35 - let's see if it can get red reddish so
11:38 - we can see I could play with this all
11:39 - day long this is now going to classify
11:42 - the color based on that particular mouse
11:44 - so in a way I'm done I probably want to
11:47 - train it for more epochs what are some
11:50 - things that I want to do so one is I
11:52 - would want to be more thoughtful get
11:54 - more data I would want to be more
11:56 - thoughtful about the validation data and
11:58 - then other thing I would want to start
11:59 - doing is thinking about well does it
12:01 - actually work better what are the hyper
12:03 - parameters that I can play with for
12:05 - example the hidden layer I put 16 units
12:09 - in it well or what happens if I use a
12:12 - different activation function for the
12:13 - hidden layer what happens I use more
12:15 - nodes or less nodes what if I change the
12:17 - learning rate what if I change the
12:19 - optimization function if I use like the
12:21 - atom optimization function so these are
12:25 - things that all these things are things
12:29 - that I could play with and research and
12:31 - think about an experiment with to try to
12:33 - tune the model really well then at some
12:36 - point I also would want to save that
12:38 - model right save it to a JSON file so
12:41 - the trained model somehow so that I
12:43 - could load it back in without having to
12:45 - run through the training process again
12:47 - maybe I'd even want a larger dataset I'd
12:49 - want to Train it over a long time me but
12:50 - I want to port this code to node so I
12:52 - could let it train-like server-side
12:54 - without having to train in the client
12:55 - there's so many possibilities but I have
12:58 - now built a machine learning model with
13:02 - tensor photos I'm gonna cry
13:05 - I don't know how many videos this took
13:07 - that trains a model based on crowdsource
13:10 - color data and if you want if you just a
13:14 - humor me for a second if you remember if
13:17 - I go here this is the system right
13:20 - this system was used to allow people
13:23 - from the internet to click on and say
13:26 - that's like pinkish that's greenish
13:29 - that's blueish tag a whole bunch of
13:32 - colors save all that data in a firebase
13:34 - database retrieve all that data clean
13:37 - that data put it into JSON file load
13:40 - that JSON file here into this sketch
13:44 - build a model train the model with that
13:48 - data and then pulls a new color from a
13:51 - slider oh and I forgotten something
13:53 - memory management oh I knew there was a
13:56 - step that I'm missing estimating what
14:00 - category out of the fixed set of labels
14:02 - this that color is but I did forget
14:05 - something really quite important which
14:08 - is memory management let's look at this
14:10 - num memory om TF memory dot num tensors
14:20 - so again when I create tensors that are
14:24 - allocated to memory on the GPU to store
14:26 - numbers those don't get cleaned up
14:28 - automatically there's no garbage
14:29 - collector like in kind of regular
14:31 - JavaScript programming so 15,000 485
14:35 - tensors that one thing and there's still
14:37 - even more and more and more it's growing
14:40 - this is a memory leak so one place where
14:42 - I didn't clean up any of the tensors is
14:44 - right here and there's a easy way I can
14:46 - clean this up by adding in the TF tidy
14:51 - function so what TF tidy does is it says
14:55 - just put all of this code that's inside
14:58 - of this function passed into TF tidy
15:01 - clean up any tensors that are made there
15:04 - so this will clean up everything for me
15:06 - so now let's run this again and we're
15:11 - gonna take a look at the tensors there's
15:13 - 31 73 it's kind of leaking right well
15:17 - let's let it get all the way through 10
15:19 - a box I'll be back in a minute when that
15:21 - finishes so the training is complete and
15:30 - we can see now ah there we go
15:33 - I am no longer leaking tensors now the
15:36 - thing is do I really did I really need
15:39 - 1628 tensors I don't think that I did I
15:42 - think there is also there is also a leak
15:44 - going on inside of this train function
15:48 - and I think there's an issue with this
15:52 - and so I'm gonna I might have to do a
15:54 - follow-up video about this because at
15:56 - the moment if I go to github.com TF o DT
16:04 - oh hold on let's go from here
16:07 - - I should have had this prepared where
16:11 - do I go github and issues and I'm gonna
16:17 - look for fit memory leak this one so I
16:25 - believe there is at present a memory
16:29 - leak in model dot fit with callbacks and
16:31 - you can see that's exactly what I'm
16:33 - doing right where model dot fits with
16:38 - callbacks so I'm gonna not worry about
16:41 - that particular memory leak right now
16:43 - I'm gonna wait for us to see if that
16:45 - gets corrected by the time you're
16:47 - watching this that might already be
16:48 - corrected and this code might have no
16:50 - more memory leaks in it just by updating
16:52 - the version of tensorflow Tijs or I
16:54 - might still be missing something in here
16:56 - to do a memory leak so you know if you
16:58 - don't want any spoilers and/or the
17:01 - following videos the fallout videos have
17:03 - not been published yet you could kind of
17:05 - kind of like sort that out yourself but
17:06 - I will come back at some point
17:07 - and talk about that okay so thank you
17:10 - for watching I wish you many purplish
17:15 - and pinkish and bluish and greenish days
17:20 - all the colors of the rainbow may they
17:23 - fill your days with joy may you make
17:25 - your own classifier with your own data
17:27 - please
17:28 - with me I don't know has this helped the
17:31 - world this tutorial series I've missed
17:32 - so much about data and data collection
17:35 - of machine learning and bottles and
17:36 - algorithms but hopefully I've got done
17:37 - something this is not the end
17:39 - it's only the beginning ma I'll see you
17:41 - soon in future tutorial videos that up
17:44 - because this playlist probably has about
17:45 - 300 more left ok goodbye
17:53 - [Music]

Cleaned transcript:

all right oh this is getting tiring but I am back and I have yet another in this building your own custom color classifier with 1000 GS series now the thing that I want to add to this video and by the way this line moving across is pointless I just have it there so that I could see that the draw loop is animating that I haven't blocked it there's two things that I miss that are kind of important from the previous video what is this is actually not the validation data loss I didn't realize this but I'm going to I'm gonna change this here I'm gonna I'm gonna console.log the full logs object so right what I'm putting on to the screen is logs dot loss let me come to console log what's there so again we have to wait a minute for the first epoch to finish apologies for that okay there are actually two lost values there's the loss function can be computed against the training data and there's the loss function computed against the validation data now to do this properly I really should be using the validation loss because that data that hasn't been done with the training that's that's that's that's protecting against overfitting having my model work really well with the training data only the thing is I have a very small data set 5,000 data points I'm just using 10% as the validation data and the weight to the flow digest works it also takes that 10% from the end and I didn't wasn't careful about shuffling the data around so this is something that I should come back to I don't know maybe this series will go on to infinity but if I were doing this properly I would actually want to show the validation loss here like this log stop validation loss maybe I want to show both and maybe I want to be more thoughtful about shuffling the data first in advance but I that's not what I said I was gonna do the next video so I'm again leaving that temporarily as an exercise to the viewer or I'll come back and do it in a future video I don't know yet that's item number one item number two thank you to me I am so me and others in the coding train sponsor patron group I've made this way more complicated than it needs by trying to make this an async function in here actually this does not need to be an async function if I just return TF dot next frame so if I just return TF next frame it's actually returning the promise and unlocking the draw loop so that makes it simpler actually I really want to do it couldn't be this so simpler what am I doing here at the end of every batch I want TF next frame to be executed and so I actually don't need to write a wrapper function to execute TF next frame what I could just do is set that as the callback the callback again if I wanted to do more with on batch and look at the loss and the logs but really what I want is at the end of every batch to draw a new frame of animation I can just put TF knocked next frame as the function which is the callback there okay so let's this is still working that simplifies the code makes it a little nicer to look at I don't even really need this on on begin and on end but I'll leave those in there just so you see them okay so now I'm ready for what is the purpose of this video the purpose of this video is while I'm training the model I couldn't wait till I finished rigging the model but I'm actually it allowed this to happen while I'm training the model I want to be able to specify a color and see what the neural network thinks that color is so very quickly to do this what I'm going to do is I'm going to create our slider G slider B slider I'm going to make three sliders again this could use a lot of improvements and I'm going to use the p5 Dom library create slider function so the slider is a range between 0 and 255 and let's start with like what's this red and green make yellow let's start with a yellow and so the G's the B slider should be on 0 and then I want the background color to and I don't know what that's doing there I don't need this line anymore it's distracting I want to say are Lichter well let's actually let's so I want to say let our equal our slider value so I want to get the values from the sliders I want G and I won't be eventually I'm gonna send these as inputs into the neural network but right now I just want to be able to see that color our G B okay so here we go so now we should see there are three sliders and as I adjust these sliders I can change the color and so what I want whoops what I want is to be able to and I see though what I want is now to see the neural networks prediction down here so how do I do that okay time to use tensorflow touch yes again whoo so I need to make some input data so the input X's are tensor T F dot tensor 2d and an array with RGB in it now in theory I could be running prediction with multiple RG B's right but I'm not so I need an array of arrays in here so this is my input data then what do I want to do I want to say model dot predict with those X's feel like you know what I need to normalize those right because the it expects to have normalized values between 0 and 1 so I need to divide each of those by 255 then I need to call model dot predict and then look at the results and that happen oh what this doesn't actually happen asynchronously it's the because the data is still on the GPU this is a confusing thing I have to pull I'm gonna use that date I have to pull it out but let's just look at the results of pure results so I should then be able to say results dot print okay so I think this is me just creating the inputs getting the prediction and then I should be able to see that in the console syntax error who I have an extra extra curly bracket alright okay so we can see this and this is exactly what I should be getting right it is a probability distribution over nine labels now whether it's giving me correct ones who knows but look at that so now how do I get the label out of there well remember that what I'm looking for is I'm looking for which probability is at them at the highest level is it a ninety percent chance of it being yellowish and point zero one point zero two point zero three you know 1% 2% 3% of being the other ones and there actually is a function intention flow Jas that will pull out the index of the highest probability value that's called Arg max right I could write a little for loop or or some kind of function to do that but if I look for Arg max TF dot Arg max returns the indices of the maximum values along an axis so this is can be quite more complex because I can have multidimensional data but I actually get to do this in a really simple way I just want to say let index equal results dot Arg max yep and if there's an access of AXI access of 1 the first there's a 1 dimensional here so now let me say index dot print and so let me run this and we can see it's just giving me whom is that right is that a coincidence so I should get some different values yes okay so it's actually changing so that that's giving me that maximum index so as I change so so this is my label here's the thing though that's my label but I need to convert that to one of these so 0 means reddish one means greenish two beads blueish 3 means orangish so I have this label list already I should be able to just say let label equal label list index the only thing is I can't do that because this is a tensor that's a tensor and what I want I need to pull that the tensor is the numbers the data that lives on the GPU the WebGL fancy thing that Tetsuo digest is implemented I need to pull that off and normally I would pull that off with an asynchronous function but the thing is here it's such a little tiny bit of data I think I can pull it off synchronously and not slow down my program from running so actually what I want to say here is Data Sync and then which is a dot data would pull it off asynchronously so let's look at and let's let's say I'm a console dot log index let me get rid of my other console logs that I don't really want to look at right now so okay so I got an array with the number in it I pulled it off and so then I just want to say index 0 so I only need that first value index 0 and so there we go that's the label number I now have the label number and so now I can say this and I can say and let's put it out on a paragraph element so let's say let label P let's have that be first and so now I want to say label P equals creepy and then I should say all the way back down here label P HTML label okay ready for this here we go I've started my training oh wait why this is so silly but I want the label to P above it I really should not be changing this right now so let me just put it here okay so here we go it thinks that's greenish right well it hasn't gotten very far with the training I would imagine that once we train further and the law starts going down it's going to recognize that as yellowish so here I'm gonna just wait a little bit and I'll be back in a minute all right back so he trained over 10 in each box and you can see now it's saying this is yellowish let me tune this down that's greenish turn this up that's bluish we've still got blueish can we get some purple purplish can we get some pink oh it didn't get pink maybe if I add a little more brightness ah now that thinks that's pink so I have now trained the neural network to recognize and let's see if it can get red reddish so we can see I could play with this all day long this is now going to classify the color based on that particular mouse so in a way I'm done I probably want to train it for more epochs what are some things that I want to do so one is I would want to be more thoughtful get more data I would want to be more thoughtful about the validation data and then other thing I would want to start doing is thinking about well does it actually work better what are the hyper parameters that I can play with for example the hidden layer I put 16 units in it well or what happens if I use a different activation function for the hidden layer what happens I use more nodes or less nodes what if I change the learning rate what if I change the optimization function if I use like the atom optimization function so these are things that all these things are things that I could play with and research and think about an experiment with to try to tune the model really well then at some point I also would want to save that model right save it to a JSON file so the trained model somehow so that I could load it back in without having to run through the training process again maybe I'd even want a larger dataset I'd want to Train it over a long time me but I want to port this code to node so I could let it trainlike serverside without having to train in the client there's so many possibilities but I have now built a machine learning model with tensor photos I'm gonna cry I don't know how many videos this took that trains a model based on crowdsource color data and if you want if you just a humor me for a second if you remember if I go here this is the system right this system was used to allow people from the internet to click on and say that's like pinkish that's greenish that's blueish tag a whole bunch of colors save all that data in a firebase database retrieve all that data clean that data put it into JSON file load that JSON file here into this sketch build a model train the model with that data and then pulls a new color from a slider oh and I forgotten something memory management oh I knew there was a step that I'm missing estimating what category out of the fixed set of labels this that color is but I did forget something really quite important which is memory management let's look at this num memory om TF memory dot num tensors so again when I create tensors that are allocated to memory on the GPU to store numbers those don't get cleaned up automatically there's no garbage collector like in kind of regular JavaScript programming so 15,000 485 tensors that one thing and there's still even more and more and more it's growing this is a memory leak so one place where I didn't clean up any of the tensors is right here and there's a easy way I can clean this up by adding in the TF tidy function so what TF tidy does is it says just put all of this code that's inside of this function passed into TF tidy clean up any tensors that are made there so this will clean up everything for me so now let's run this again and we're gonna take a look at the tensors there's 31 73 it's kind of leaking right well let's let it get all the way through 10 a box I'll be back in a minute when that finishes so the training is complete and we can see now ah there we go I am no longer leaking tensors now the thing is do I really did I really need 1628 tensors I don't think that I did I think there is also there is also a leak going on inside of this train function and I think there's an issue with this and so I'm gonna I might have to do a followup video about this because at the moment if I go to github.com TF o DT oh hold on let's go from here I should have had this prepared where do I go github and issues and I'm gonna look for fit memory leak this one so I believe there is at present a memory leak in model dot fit with callbacks and you can see that's exactly what I'm doing right where model dot fits with callbacks so I'm gonna not worry about that particular memory leak right now I'm gonna wait for us to see if that gets corrected by the time you're watching this that might already be corrected and this code might have no more memory leaks in it just by updating the version of tensorflow Tijs or I might still be missing something in here to do a memory leak so you know if you don't want any spoilers and/or the following videos the fallout videos have not been published yet you could kind of kind of like sort that out yourself but I will come back at some point and talk about that okay so thank you for watching I wish you many purplish and pinkish and bluish and greenish days all the colors of the rainbow may they fill your days with joy may you make your own classifier with your own data please with me I don't know has this helped the world this tutorial series I've missed so much about data and data collection of machine learning and bottles and algorithms but hopefully I've got done something this is not the end it's only the beginning ma I'll see you soon in future tutorial videos that up because this playlist probably has about 300 more left ok goodbye
