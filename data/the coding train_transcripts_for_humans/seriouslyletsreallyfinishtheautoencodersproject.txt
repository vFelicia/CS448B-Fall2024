With timestamps:

00:02 - [Music]
00:21 - do
00:24 - [Music]
00:33 - hello
00:35 - [Music]
01:25 - [Applause]
01:27 - [Music]
01:44 - [Applause]
01:45 - [Music]
01:59 - do
02:08 - [Music]
02:09 - [Applause]
02:12 - [Music]
02:19 - [Applause]
02:24 - [Music]
02:42 - do
02:43 - [Music]
02:56 - do
02:58 - [Music]
03:10 - do
03:13 - [Music]
03:34 - hello good morning or afternoon good
03:37 - evening
03:38 - a little bit of a sound check here quick
03:41 - sound check
03:42 - um there's probably a loud pun because i
03:45 - am currently running the heater in the
03:47 - garage
03:48 - but other than that let me know how my
03:50 - voice is sounding and i'll be getting
03:52 - started in approximately two and a half
03:55 - minutes
03:59 - [Music]
04:07 - [Music]
04:20 - do
04:22 - [Music]
04:35 - do
04:36 - [Music]
05:25 - me
05:28 - [Music]
06:00 - do
06:02 - [Music]
06:13 - do
06:17 - [Music]
06:28 - hello
06:29 - happy monday welcome to another session
06:32 - of the coding train my name is dan i
06:34 - will be your
06:35 - 2 conductor for today's session i'm
06:39 - still setting up a few things here and
06:41 - there
06:42 - last time i forgot to record my session
06:44 - to disc
06:46 - uh so i am going to make sure that i do
06:48 - that this time and i want you to think
06:51 - about
06:52 - today's sponsor of the coding train as i
06:54 - go and set those settings today's
06:56 - sponsor is
06:57 - curiosity stream
07:00 - uh let's see how come that did not open
07:04 - obs 64. oh obs is already running launch
07:08 - anyway yes
07:09 - okay thank you
07:12 - and now i am going to hit
07:14 - um start recording
07:18 - and there we go all right so
07:20 - um
07:21 - [Music]
07:23 - boy boy am i unsure about what's
07:25 - happening in the world of the coding
07:27 - train but i am preparing i don't know
07:29 - where it is maybe this is it
07:31 - this here
07:33 - is a stool a stool actually it's like
07:35 - one of these weird stools that like you
07:37 - sit on and it wobbles it's supposed to
07:38 - be good for your back
07:40 - but i am now
07:41 - hereby
07:43 - proclaiming that this is a reset button
07:46 - it's a giant reset button
07:48 - and very soon it will be 2022
07:52 - and i am going to
07:55 - place my bell
07:57 - on top
07:59 - of the reset button and i can't do it
08:00 - now the ball will drop
08:03 - drop onto the bell
08:05 - we'll make that sound
08:07 - uh and i'm gonna everything's gonna be
08:08 - reset um
08:10 - in the year uh 2022
08:14 - because this boy
08:16 - um and um
08:17 - this has really been quite a difficult
08:20 - uh i know year two years for so many
08:22 - people just for me speaking personally
08:24 - just a really difficult month of
08:26 - december and i haven't been able to sort
08:29 - of keep up with the pace of sort of
08:32 - coding train activities like i would
08:34 - really like to but
08:36 - i'm finishing up a whole bunch of things
08:39 - and have this clear path ahead of me
08:41 - so this is the time by the way if you
08:44 - ever wanted to get in touch with like
08:46 - your suggestion of what you think the
08:48 - coding train should really be
08:50 - should it really just be
08:52 - daily live streams every day
08:55 - should it be more
08:56 - sequenced video tutorials should it be
08:58 - project videos should it have high
09:00 - production value low production value
09:02 - uh should should it have a brand new
09:04 - website that allows you to share all the
09:07 - things you're making based on the coding
09:08 - trade videos back should we be doing
09:10 - more things on social media should
09:11 - coding train have a tick tock
09:15 - i'm thinking about all these things and
09:17 - um ramping up my plans to uh
09:20 - to activate uh all of the all of the
09:24 - cars on the train
09:26 - and the various different engines and
09:28 - the components it's all gonna happen in
09:30 - 2022 but here i am still in 2021 just
09:34 - eeking out one more live stream there's
09:37 - gonna be another one at some point
09:40 - i really would like to do my annual
09:43 - holiday
09:44 - slash new year's processing foundation
09:46 - telethon to support the work of the
09:49 - processing foundation i think
09:51 - this is this is not official yet this is
09:54 - unofficial this is like a little
09:56 - unofficial pre-announcement announcement
09:58 - i think it's going to happen after the
10:00 - christmas holiday but before new year's
10:03 - um this year i don't think i can get it
10:05 - together to do it
10:06 - this week or next so most likely my uh
10:10 - new the holiday livestream which will be
10:11 - a new year new year live stream
10:14 - launching the new year of the coding
10:15 - train will happen
10:18 - it's probably i'm gonna guess uh
10:20 - december 29th or 30th or 31st
10:24 - one of those dates if you want to be the
10:25 - first to know when i've scheduled it you
10:27 - should sign up for the coding train
10:29 - discord
10:32 - i just pressed a button
10:34 - and i don't know if that message is
10:35 - going to go into the chat didn't seem to
10:37 - do it but it's uh
10:39 - codytrain.comcodingtrain.comdiscord
10:43 - discord.gg codytrain somebody will put
10:45 - it in the chat hi peter glad that you're
10:48 - here catching the stream
10:49 - um
10:51 - but uh what am i talking about if you
10:54 - want to be the first to know about when
10:55 - this special end-of-year new year
10:58 - spectacular coding train telethon
11:01 - spectacular will happen maybe i'll even
11:04 - break out my ukulele to sing a new year
11:06 - song would you like to write that song
11:08 - the lyrics of that song get in touch
11:10 - because i got nothing i got
11:12 - nothing if you want to be the first to
11:15 - know sign up for the discord because the
11:16 - discord oh it has this new feature let's
11:18 - see if i can even show it to you
11:21 - um
11:22 - i'm going to open up discord here on my
11:24 - computing machine that you cannot see
11:26 - just yet oh no okay wait wait wait
11:30 - this is fine i have to log in
11:32 - everything's going to be fine it's got
11:34 - this magic qr code thing
11:37 - so
11:37 - this is really what i should be doing on
11:39 - a live stream i should be logging into
11:41 - things
11:42 - start talking
11:44 - um
11:45 - i'm talking already i don't need to
11:47 - start talking discord why you're
11:49 - reminding me
11:52 - if i had a co-host i wouldn't have to
11:54 - just continuously speak the entire time
11:56 - i should be good with the silence or i
11:57 - need more music going on
11:59 - um
12:00 - now let me just do this little special
12:03 - trick thing that i'm going to do
12:05 - then let me go back to ah the coding
12:07 - train oh
12:09 - i'm really doing something very
12:10 - important but you can't see it
12:13 - because otherwise it will reveal all of
12:15 - my
12:16 - coding train oh my god
12:20 - secrets um
12:23 - um we wouldn't want to do that um
12:27 - now okay yes yes yes no no no i got one
12:30 - more button to press boy i really should
12:32 - have prepared this
12:34 - did i tell you about today's sponsor
12:36 - look at that well i'm still doing this
12:40 - hidden
12:41 - option command i
12:44 - uh turn this off
12:47 - oh boy this was boy this was worth the
12:49 - wait everybody oh you have no idea
12:52 - what's coming to you you have no idea
12:54 - the excitement i'm about to
12:57 - show you
13:13 - such a letdown but you'll see here in
13:15 - the coding train discord
13:17 - now has this events feature so whenever
13:20 - i have a live stream event i schedule it
13:23 - in the discord which there's a way for
13:25 - you to get a notification about that you
13:27 - can see the youtube link the details
13:29 - about it multiple it's if it's happening
13:30 - now it have a big happening now button
13:32 - so i fully expect that there are now
13:35 - hundreds of thousands of viewers in real
13:38 - time the kodi trade right now because of
13:40 - this new happening now button
13:42 - thing
13:43 - card tag discord
13:46 - extravaganza all right
13:49 - so um
13:50 - you can also just subscribe to the
13:51 - youtube channel and there's like a bell
13:53 - or something it'll also give you a
13:54 - notification in theory when i schedule
13:57 - the next live stream
13:59 - uh and simon is reminding me um in the
14:02 - member discord remember
14:04 - oh remember when you did advent of code
14:07 - on the stream
14:09 - yeah
14:10 - december is
14:12 - i really want december to be like a
14:14 - really active month of streaming and
14:16 - coding and fun
14:18 - but it's just not happening this year
14:23 - but mark my words
14:25 - streaming and coding and fun and all of
14:27 - that stuff is coming in next year so
14:29 - what are we here to do today
14:32 - if you've enjoyed my last three live
14:35 - streams
14:37 - do i have good news for you
14:39 - i'm gonna be continuing the project this
14:41 - is kind of a new thing that i started
14:44 - which is i'm just going to come back
14:46 - over here for a second
14:48 - which is to work on a larger project
14:51 - over multiple sessions
14:55 - i don't know how effective or
14:58 - entertaining or insightful this is
15:02 - so right now the kinds of things i do in
15:04 - the coding train are divided into
15:06 - sort of different
15:08 - different buckets and actually one thing
15:10 - i might just do right now just to talk
15:12 - about that for a second
15:14 - is to come here to the channel so this
15:16 - is great for anybody who's who's new
15:19 - uh today
15:21 - so i have what the most popular thing
15:24 - that i do which youtube likes to tell me
15:26 - is very popular
15:28 - are these coding challenge videos from
15:30 - at least four or five years ago so
15:32 - apparently the way that i work is i
15:34 - discovered something really popular that
15:36 - people love and want to get more of and
15:38 - then kind of went did something
15:40 - different
15:41 - but so
15:42 - uh these are the coding challenge videos
15:44 - they're sort of standalone one-off
15:46 - videos where i build a project
15:49 - i also have and this is kind of where
15:52 - what i'm kind of very much dedicated to
15:55 - always having at least this feels very
15:57 - primary and fundamental to me
15:59 - um hi christine in leeds england
16:03 - welcome to leeds england lovely to see
16:05 - you here um these are the sort of
16:07 - sequence tutorial videos so first of all
16:10 - if you are new or if you have a friend
16:12 - who's like oh i'd love to learn to code
16:14 - or where should i start or i'm
16:15 - interested in generative art or creative
16:17 - coding or javascript
16:19 - this playlist is for total beginners and
16:23 - one of the things that i have been doing
16:26 - and the reason why i like having it
16:27 - sectioned into different videos is
16:29 - because i can over time replace them so
16:32 - if i look at this right now
16:34 - these were um you can see like these are
16:36 - from three years ago the sort of intro
16:39 - to the series and using the web editor
16:42 - then all of a sudden oh yeah then we
16:43 - still got three years ago then all of a
16:45 - sudden we go and we get some videos from
16:47 - six months ago more gray hair so these
16:50 - were so out of date and old that i
16:52 - started to replace them new thumbnail
16:54 - style i don't know what people think of
16:55 - that um but then we go back and we
16:59 - continue
17:00 - like suddenly then the video goes to six
17:02 - years ago so definitely high on my list
17:05 - is
17:06 - anything that's five plus years old
17:09 - in this sort of tutorial series i want
17:11 - to redo
17:13 - i have been working this is what i'm
17:15 - kind of focusing on today i would like
17:17 - to make a video about auto encoders
17:20 - uh matt is saying i could probably get a
17:22 - co-host in songwriting help from gpt-3
17:25 - great point
17:27 - actually that's been my sort of pet
17:29 - procrastination project is playing
17:31 - around with a lot of the new large
17:32 - language models
17:34 - that are available through open ais
17:35 - gpt-3
17:37 - and
17:38 - also hugging face uh hosts a tremendous
17:41 - amount of different language models with
17:42 - lots of exciting applications although i
17:44 - think it's important to be very cautious
17:47 - and conscientious when using these large
17:48 - language models so there's a lot to say
17:50 - about that um
17:52 - nature of code is a big project for me
17:54 - in the new year i don't know where i'm
17:55 - scrolling
17:56 - so oh so so
17:59 - but
17:59 - what i was talking about which i wanted
18:01 - to just sort of get off my chest here
18:03 - is that
18:04 - standalone project videos like these
18:08 - sequence tutorials and then
18:11 - if i go to
18:16 - live streams i thought there was a place
18:18 - where i could just see like my live
18:19 - stream playlist i'm not seeing it i'm
18:21 - not going to to try to find that now but
18:22 - that's what you're watching right now
18:24 - apparently 166 of you
18:26 - lucky lucky lucky people are here with
18:29 - me
18:30 - um
18:31 - and
18:32 - uh would you redo the game you started
18:35 - says nico writes would you redo the game
18:37 - you started with the triangles moving
18:38 - around the map on their own
18:41 - i'm not sure
18:43 - what the pot redo them but never remove
18:45 - them yes so this is a good point i am i
18:47 - have no plans
18:49 - to ever delete any of the older videos
18:51 - and in fact um another way to browse the
18:54 - videos is through the coding train
18:56 - website and if i go to beginners if you
18:58 - really enjoy the sort of classic coding
19:00 - train style
19:02 - uh you can find these really ancient uh
19:05 - intro to processing
19:07 - tutorials which are
19:09 - even though it says 2015 i'm pretty sure
19:11 - these were recorded in 2012.
19:14 - it's just that i only got around to
19:16 - uploading them to youtube all at once on
19:18 - july 10
19:20 - 2015.
19:23 - ah time flies
19:25 - i'm getting older too what's that song
19:28 - that i'm thinking of you're getting
19:29 - older i'm getting older too i don't know
19:31 - i'm getting older you're not you're you
19:33 - look lovely you look
19:35 - beautiful you look younger than you ever
19:37 - have and actually the irony here is
19:40 - while i'm talking to you the viewer i'm
19:41 - just staring at an image of myself so
19:44 - i'm saying it to me but really i'm
19:45 - saying it to you all right we got to get
19:47 - we got to get moving here
19:49 - i've been alluding to it
19:51 - i want to tell you
19:52 - about the best
19:55 - deal in streaming available
19:58 - today
19:59 - oh anything think of any streaming
20:01 - service with any content i have to tell
20:04 - you about the best deal
20:07 - available better than all of the ones
20:08 - you're thinking of
20:10 - um so how do i get to it if i go to
20:12 - youtube.com
20:14 - the coding train and the community tab i
20:16 - just made a post about it
20:18 - and here it is holidays start early so
20:21 - um you've heard me talk about this
20:23 - before um it is the curiosity stream and
20:26 - nebula bundle it gives you access to all
20:29 - of curiosity's stream tons of
20:31 - educational documentaries nature science
20:34 - math
20:35 - um just
20:37 - nature nature nature nature those are
20:38 - the ones that i love
20:40 - so many amazing documentaries and
20:43 - with it
20:45 - you also get full access to nebula which
20:48 - is a streaming service that my content
20:50 - is on you can even see here this picture
20:52 - so all ad free if there's any all
20:55 - sponsor free
20:56 - um really nice player you've got like a
20:58 - roku app and a fire tv app some new
21:01 - stuff um i think i wrote about it here
21:03 - um picture and picture on ios
21:06 - and
21:07 - like i stole this from renee ritchie who
21:09 - is i'm a big fan of
21:11 - all for less than the cost of a usb
21:13 - dongle so um you can get all of the
21:16 - nebula content all of curiosity stream
21:18 - thousands of documentaries for less than
21:19 - 12 a year this is exclusive only for the
21:21 - holidays it's a 42 discount 11.59
21:25 - uh if you sign up through the link it's
21:27 - pinned in the chat um
21:30 - curiositystream.com codingtrain so if
21:32 - you're wondering like what's a way for
21:33 - you to support the coding train
21:35 - actually going to that link and signing
21:37 - up will uh supports me and supports all
21:39 - these other wonderful creators that are
21:41 - on nebula
21:43 - i'll come back in the middle and just
21:44 - basically say what i just said now again
21:46 - but if you have any requests to poke
21:48 - around and look at anybody's any
21:50 - particular content i can make some
21:51 - recommendations for you all right now
21:53 - coming back
21:56 - i am really excited about this project
22:00 - uh because it is one of these things
22:02 - like uh
22:03 - as simon likes to tell me um
22:07 - wait i'm sorry i'm reading
22:10 - i'm reading the the chats in multiple
22:12 - places uh thank you viveshop vivesvan um
22:18 - simon likes to remind me um i have this
22:22 - habit if i go to the rainbow topics
22:24 - github repository
22:26 - i have this habit of making these like
22:29 - to-do lists
22:30 - fall 2020 spring 2021 summer 2021.
22:34 - notice i didn't make one for fall 2021 i
22:36 - was like forget it i just make the to-do
22:38 - list don't get to anything that's on it
22:40 - i think i would really like to make one
22:41 - for 20 20 20 20 20 20 22
22:45 - and uh really develop a schedule oh
22:47 - something that i'm thinking about tell
22:48 - me what you think about this here's an
22:49 - idea for you uh think about like some
22:52 - cool illustration graphic design twitch
22:54 - tuesdays coding train
22:57 - twitch tuesdays like a little music bump
23:00 - or something
23:03 - um i think you've experimented with
23:04 - streaming on twitch but that's so cheap
23:07 - so a little different vibe try some more
23:09 - interactive features something i'm
23:10 - thinking about
23:11 - um
23:14 - but i believe like if i just go to
23:15 - summer 2021 you can see all these lists
23:18 - of things that i want to do and on the
23:20 - list
23:21 - it's been there so many times auto
23:23 - encoder so vivisvan asks what are you
23:25 - building today
23:28 - auto encoder except i'm not really
23:30 - building it today i am finishing it
23:32 - today i have been building it you have
23:34 - guess what you have about six to seven
23:36 - hours of old content you can go back and
23:38 - watch
23:39 - so i have been working on this auto
23:41 - encoder uh with tensorflow.js and p5.js
23:45 - uh for the last three live streams i
23:47 - don't think i should go past this one
23:50 - and the thing that i'm thinking about
23:51 - doing and i would love to hear from you
23:53 - is then
23:55 - um not on the level of say like two
23:57 - minute papers or some other like three
24:00 - blue one brown
24:01 - is another channel that i love sebastian
24:03 - lag
24:05 - um
24:06 - jordan herron i'm just naming youtubers
24:08 - that i like
24:09 - but um
24:11 - but i am thinking about what would it
24:13 - mean for me to do a scripted i know
24:16 - shocker scripted video about
24:20 - what is an auto encoder and how to build
24:23 - one using tensorflow.js and p5.js
24:27 - and
24:28 - cut and paste that's not the right term
24:31 - for edit together highlights from the
24:34 - live stream sessions
24:36 - with narration and some additional
24:39 - demonstration and that could be maybe in
24:41 - 20 minutes that's kind of a goal that i
24:44 - have the only video that i've done
24:46 - anything remotely close to this
24:49 - is the mouse
24:51 - learning
24:52 - um
24:54 - let's see if this comes up um this this
24:57 - video if you haven't watched it um let
25:00 - me just pull this up for a second
25:02 - um this is a video that i made that had
25:05 - a script
25:06 - and um i love you too do do do venom
25:10 - okay you just made me say doo doo venom
25:12 - that was a trick
25:14 - good job
25:16 - uh and andrew's asked me i've looked at
25:18 - advent of call so uh if you haven't
25:20 - watched this video i would love for you
25:21 - to go check it out and tell me what you
25:22 - like or didn't like about it
25:24 - but the idea here is could i um could i
25:28 - could i pull could i could i
25:31 - kind of have the best of both worlds
25:33 - like
25:34 - one of my mantras one of the things i
25:35 - really try to do is show every every
25:38 - every piece of building a project start
25:40 - to finish and all of the pain and bugs
25:43 - and mess in between at the same time
25:47 - how many of you realistically if you're
25:49 - like i want to learn how to build an
25:50 - auto encoder oh there's seven hours of
25:52 - video i could watch
25:54 - where at the end you get a fuzzy circle
25:58 - um really have the time for that or
26:00 - going you know is that really going to
26:01 - be uh useful for you so i want to try to
26:03 - have the best of both worlds that's
26:04 - something that i'm thinking of planning
26:06 - to do matt says great plan matt gorbay
26:08 - gorge from the french gold
26:12 - no maybe
26:13 - sorry if i'm butchering your name
26:16 - um
26:18 - so
26:19 - um that i
26:22 - am thinking about um
26:24 - um doing so anyway
26:28 - new area of exploration look at all this
26:30 - stuff
26:31 - this this
26:32 - so much stuff that i want to do oh
26:33 - remember how i was going to do these i
26:35 - actually i have some like just videos
26:38 - that i sh recorded and they're kind of
26:40 - like half edited that i never got
26:42 - together to finish
26:43 - uh so much oh
26:45 - plotter i want to buy a plotter so many
26:47 - i want to get a knitting machine
26:50 - so much to do in 2022.
26:52 - i'm a poet and i didn't even know it
26:56 - all right so let's get back to the task
26:58 - at hand before i take up too much time
27:01 - with this introduction to today's
27:03 - session thank you for everybody too for
27:05 - being here let me go to terminal
27:09 - i'm going to walk you through now all
27:11 - the pieces of the project that have
27:13 - already been built
27:16 - so
27:18 - first piece is a processing sketch
27:22 - to uh generate training images for the
27:26 - auto encoder and i realized that if
27:28 - you're totally new and haven't tuned
27:30 - into the last three live streams the
27:32 - question what is an auto encoder might
27:34 - be on your mind
27:36 - i'll come to that at some point i'm sure
27:37 - i won't be able to help myself but just
27:39 - imagine at least for the one sentence
27:41 - version i'm using an auto encoder to
27:44 - create images in the style of an
27:46 - existing data set and this here
27:51 - if i run this sketch this is now
27:52 - generating that existing data set it is
27:55 - just a series of random circles or
27:58 - squares
27:59 - um um i believe i'm making some number
28:02 - of them as we will find out i'm making
28:04 - 1100 of them so at some point it will
28:07 - stop
28:13 - and
28:15 - we can see now in this data folder here
28:17 - are all these images that i generated so
28:20 - i'm hoping by the end of today i can try
28:22 - to work with something more
28:23 - sophisticated should i try to use letter
28:26 - forms
28:27 - color
28:28 - different kinds of shapes i'm not sure
28:30 - yet more abstract patterns again i don't
28:33 - know
28:34 - um but let's leave that oh fractal trees
28:37 - we could try that would be kind of
28:38 - interesting learn blender so sake
28:42 - yeah i kind of into this idea of
28:44 - learning unreal engine and then turning
28:46 - this garage into a like a virtual set i
28:49 - have this huge garage now
28:52 - can i make it into a volume like the
28:54 - mandalorian set and just put like
28:55 - screens over everything instead of a
28:57 - green screen that just actually be
28:59 - this giant screen behind me
29:03 - now i don't have the budget for that i'm
29:04 - going to need a lot of you to sign up
29:06 - for that curiosity stream bundle if i'm
29:08 - going to do that
29:09 - ah and andrea
29:11 - asks are you working on a new version of
29:13 - the nature of code
29:14 - um and stig writes um oh just crack the
29:19 - playback speed to 28x i hope by the way
29:21 - all of you just watch me on 2x i mean
29:23 - obviously you can't right now
29:24 - well maybe good no touch designer i
29:27 - don't think is for me i appreciate the
29:29 - suggestion from rodrigo but probably not
29:33 - for me
29:34 - um
29:34 - wait wait wait i was talking about
29:36 - something
29:39 - generating images we're doing the auto
29:40 - encoder let's talk about the mandalorian
29:42 - set
29:47 - ah nature of code it was andrea's
29:49 - question uh yes so i you know i don't
29:52 - know why i'm dancing around this i am on
29:53 - sabbatical starting it's actually not
29:55 - the you know i still have a lot of admin
29:57 - and other uh nyu related
29:59 - responsibilities that i'll be continuing
30:01 - to do for the first three weeks of
30:02 - january but my sabbatical from my
30:05 - teaching job begins january 24th um i
30:09 - don't i'm not suddenly going to be full
30:11 - time coding train but if i'm at best you
30:14 - know one fifth time right now one eighth
30:17 - time right now coding trade honestly
30:19 - this month
30:20 - um i'm hoping to ramp up to like a
30:22 - quarter time a half time like really
30:24 - spend two or three two to
30:27 - two like at least two full days per week
30:29 - working on coding train um i also i've
30:32 - got a um there's an expression that uses
30:35 - naughty language if you will that i'm
30:37 - not going to say
30:39 - i have to like
30:40 - do something or else get off the other
30:43 - thing
30:45 - i got to do this nature of code book
30:46 - like it's now and forget it like if i
30:48 - don't have a new version of the nature
30:50 - of code book done in 2022 forget it it's
30:53 - never gonna happen you heard it here
30:54 - first mark my words
30:57 - sign me onto the piece of paper
30:59 - everybody record this broadcast it put
31:01 - it out into the universe
31:03 - i'm either going to have a new version
31:05 - of the nature of code book
31:07 - completed that means you can buy it a
31:09 - print version and it will be all online
31:11 - for free as a website both of those
31:13 - things by the end of 2022
31:16 - all with p5.js a new chapter on neural
31:18 - networks
31:19 - if that's not done that's it that
31:21 - project is dead
31:23 - i don't think i'm going to do a
31:24 - kickstarter for it which is what i did
31:26 - for the first book i think i've got
31:28 - enough kind of momentum with the sort of
31:30 - support but so those of you who are
31:32 - supporting the coding train whether it
31:33 - is signing up for a membership
31:34 - supporting the sponsors um all the other
31:36 - kinds of ways just watching
31:39 - tweeting sharing recommending it to your
31:41 - friends all the things that all of you
31:43 - do that i so appreciate um
31:46 - i think that's enough to kind of keep me
31:48 - going in terms of nature of code book um
31:52 - yeah
31:52 - uh
31:53 - [Music]
31:54 - unity and godot would be better
31:56 - alternatives to unreal
31:59 - says uh simon okay i'm gonna take that
32:02 - advice very seriously
32:04 - um
32:05 - and thank you kathy wrote this really
32:08 - uh oh nicole shader expert nicole is in
32:10 - the chat oh shaders i actually really
32:13 - would like i don't know if i'm qualified
32:15 - to do this i got to see uh the great
32:18 - pattucio author of the book of shaders
32:21 - i'm in new york city recently and i said
32:23 - oh thank you thank you thank you thank
32:26 - you thank you thank you i feel like
32:27 - that's what i
32:28 - people sometimes like have that reaction
32:30 - to me and i'm like no no no no please no
32:33 - stop oh no no oh if you insist and then
32:35 - i get out my ukulele and play them a
32:36 - song no okay um
32:40 - christmas
32:41 - gift yes okay um
32:46 - nicole uh thank you for your help when i
32:48 - tried i stumbled through learning
32:49 - shaders thank you of course to eliza and
32:51 - aletheia in the uh curiously minded
32:53 - stream i was thinking i might like to do
32:55 - a little basic introduction to shaders
32:58 - as like similar to my intro to p5.js but
33:01 - i don't know i i to do that i really
33:03 - have to think about how i'm kind of
33:05 - crediting
33:06 - um all of the sources that i'm sort of
33:08 - learned from i mean this is something
33:10 - that i do throughout throughout
33:11 - everything but also like whether
33:13 - i'm really the right person for that i
33:15 - mean in some ways i lo that's the idea
33:17 - of the coding train like i'm a beginner
33:18 - at this too so let's learn together
33:21 - i have to think about how to do that
33:22 - effectively okay um
33:24 - [Music]
33:26 - yeah uh nicole you are an expert
33:29 - relat
33:30 - in my eyes but no one expert is uh just
33:33 - a word that maybe we should just remove
33:35 - from the vocabulary here i mean it's
33:37 - it's nice to be an expert in something
33:39 - but i feel like in the so i don't
33:41 - there's nothing wrong with being an
33:42 - expert people who are experts should be
33:44 - celebrated for their expertise
33:46 - especially in like the sciences and
33:49 - things that we sort of like rely on to
33:50 - keep our
33:52 - world
33:53 - turning and our society moving forward
33:56 - but um in the in creative coding i like
33:59 - to think of all of us as um
34:01 - expert amateurs
34:03 - or amateur experts i'm not no i think
34:05 - it's more like we're expert at being an
34:07 - amateur like that's what i am ah i've
34:08 - decided i am but i'm not i'm not saying
34:11 - i'm good at it but like the thing that i
34:12 - like to do is try to learn the new thing
34:15 - and then help
34:16 - others learn it as well and sometimes i
34:18 - fail sometimes i succeed who knows
34:21 - back to the autoencoder project kendri
34:26 - i'm not prepared for this
34:29 - kendri
34:32 - welcome to your coding train membership
34:36 - [Music]
34:41 - you have just boarded the coding train
34:42 - passengers
34:44 - manifest please make sure you sign up
34:45 - for discord check the community tab for
34:48 - a post where there's a google form that
34:50 - you can fill out make sure you link your
34:52 - youtube discord accounts and you also
34:54 - get
34:56 - a random number
34:58 - 2022 2022 is going to be the year that
35:01 - i'm going to get back to reading this
35:03 - book of random numbers in a logical and
35:05 - organized way
35:08 - but your random number kendri is on page
35:10 - 169 it is row 8420 column
35:15 - one two three four
35:17 - and the number sequence
35:19 - is five six zero two nine
35:22 - again um we've kind of lost a little bit
35:24 - of momentum on this but we'll get it
35:26 - back a bunch of you if you're in the
35:27 - chat you received one of these please
35:29 - let give a shout out but um
35:32 - members uh uh at certain levels will
35:36 - receive this beautiful custom laser
35:38 - etched train whistle with a random
35:40 - number
35:41 - with a random walk
35:43 - according to the sequence of your random
35:44 - number of the random number book oh
35:46 - that's a mouthful okay
35:50 - um
35:50 - [Music]
35:52 - ah so um kd kydz i got to get to the
35:55 - auto encoder um it's 11 35 so i'm i'm
35:58 - going to start that but i do want to
36:00 - address this is an excellent question
36:02 - from kydz
36:04 - how do you see the use of your projects
36:06 - on
36:08 - on
36:09 - websites either following the internet
36:11 - video or changing up code i love the
36:12 - flock animation are you okay with
36:14 - crediting great question so let me
36:15 - rephrase the question
36:18 - let me just create a scenario you're a
36:19 - viewer of the coding train
36:21 - you saw one of the coding challenges
36:25 - maybe uh and i'm gonna just go to them
36:28 - and you're like
36:30 - oh this self-avoiding random walk
36:33 - this pattern is perfect for this design
36:37 - that i've uh that i've been hired to do
36:39 - for a movie poster or for my own
36:40 - personal portfolio website i want it to
36:42 - be running in the background um can i
36:44 - use it
36:46 - so the answer the short answer that
36:48 - question is yes
36:52 - with no other caveats
36:55 - all of my uh
36:57 - example code
36:59 - is released under a very permissive
37:01 - license typically the mit license
37:04 - hopefully
37:06 - um
37:07 - it's here in the website i think it's in
37:09 - the faq uh license here we go
37:12 - mit license so this is a short and
37:15 - simple permissive license conditions
37:17 - only requiring preservation of copyright
37:19 - and license notices
37:20 - license works modifications larger
37:22 - workspaces from under different terms
37:23 - without source code so basically you can
37:25 - you can um use it for anything you want
37:27 - you can modify you can distribute it it
37:29 - can be private you don't have to you
37:30 - don't have to provide credit um so
37:33 - there's not a lot of restrictions in
37:34 - terms of the example code um
37:38 - let me say a few things about that
37:40 - um
37:42 - it's nice if you can give credit i
37:43 - appreciate it
37:45 - i'm saying this less for me
37:47 - i get plenty of credit i don't need any
37:49 - more credit for stuff
37:51 - but
37:53 - we live in this sort of ecosystem of
37:55 - creative coding open source
37:57 - everybody's got different sort of
37:59 - comfort level with things being reused
38:01 - not reused so always check to see if
38:04 - there's a license
38:05 - regardless of what the license is i
38:07 - would provide credit a reference a thank
38:09 - you i would be overly generous i would
38:11 - go above and beyond whatever is required
38:13 - by the license and the thing this
38:15 - doesn't apply to my code examples but
38:17 - you will often find artistic works
38:21 - that are released under an open source
38:23 - license so in theory there's no
38:26 - legal issue
38:28 - with you
38:29 - taking that code and using it say on
38:31 - your own website but i do think there is
38:34 - something different
38:36 - to copying example code and
38:39 - remixing it for your own creative vision
38:42 - and taking somebody else's
38:44 - artistic intent and applying that um
38:49 - to you within your own work without sort
38:51 - of proper reference and credit so it's
38:53 - muddy it's murky um certainly there are
38:56 - sort of like clear scenarios like oh
38:58 - look example code under mit license
39:00 - please go forth and use
39:03 - artistic work without the source code
39:06 - being open source
39:08 - you may not like
39:10 - copy that put it out on your own name
39:12 - sell it you know make prints of it sell
39:14 - it on your local corner store market or
39:16 - whatever kind of digital currency things
39:18 - people are doing these days i don't know
39:19 - what i got to talk about right now
39:22 - so um and i think actually um golan
39:25 - levin has a really excellent guide to
39:27 - this
39:29 - i'm just want to like i know where i can
39:30 - find this
39:32 - so i'm just going to
39:33 - pull it up
39:35 - i'm very
39:36 - actually i think i can probably show you
39:38 - this pretty sure that i keep a note to
39:41 - it in my syllab syllabi
39:43 - i know i do for my my undergrad course
39:45 - that is in nyu's learning management
39:48 - system which i can't pull up
39:50 - but i can go to my public syllabi for my
39:52 - uh programming from a to
39:56 - a z course
40:00 - by the way if you're looking for some of
40:01 - my most recent stuff um
40:07 - pablo is saying open processing now
40:08 - requires to give credit to all you yes
40:10 - so open processing
40:12 - is definitely a site where people are
40:14 - publishing both their code and their
40:16 - sort of creative artistic vision and so
40:19 - if you're helped by the code and you
40:21 - provide credit i think that's very
40:23 - reasonable
40:24 - if you are just you know if you took
40:26 - something on open processing and like
40:27 - turned it in as your homework assignment
40:28 - for my class i think that would there be
40:30 - an issue even if that's like not
40:32 - something that's
40:34 - you know that you know you could be sued
40:36 - for you know according to whatever the
40:38 - laws of wherever you are let me just go
40:40 - here to a to z let's see if i can find
40:42 - the reference to golan levin's
40:45 - um yeah here we go so i adapted this um
40:49 - it's called um a statement use of free
40:51 - and open source code from examples uh
40:53 - this is adapted from i'm sure hopefully
40:55 - goal 11 may have an up more up-to-date
40:57 - one from when i adapted it from fall
41:00 - 2018 but i just thought this um
41:04 - this is a really useful uh section
41:06 - um
41:07 - that is is is uh speaking of giving
41:10 - credit
41:11 - adapted from golan levinson written by
41:13 - golan levin be careful tonight happens
41:15 - that an artist places the entire source
41:17 - code for their sketch or artwork online
41:19 - as a resource from which others can
41:20 - learn
41:22 - assignments given in new media arts
41:23 - courses are often similar you may also
41:25 - discover the work of a student in some
41:27 - other class or school with posted code
41:29 - for a project which responds to a
41:30 - similar assignment or even the
41:32 - assignment for your class that you're
41:34 - taking right now you should probably
41:36 - avoid this code or at the very least be
41:39 - careful about approaching such code for
41:41 - possible reuse if it is necessary to do
41:43 - so it is best to extract the components
41:46 - that solve a specific technical problem
41:48 - giving credit there i would add and um
41:51 - rather than those parts which operates
41:52 - to create a poetic experience again
41:54 - these are tricky things to define in
41:57 - really strict boundaries uh with really
41:59 - exact right or wrong we're all trying
42:02 - our best it's very hard i think
42:04 - transparency and narrating and
42:07 - documenting your process is the most
42:09 - important thing you can do so even if
42:12 - you did something that you felt like
42:14 - yeah make your make it your own even if
42:16 - you did something that you know could be
42:19 - characterized as
42:22 - repurposing the poetic aspects of
42:24 - somebody's project into your own
42:26 - if you've documented through your blog
42:29 - post through code comments through your
42:31 - website your entire process of how and
42:34 - why you did that then at least i think a
42:37 - um
42:38 - a dis good faith discussion around that
42:40 - can happen and can be corrected if their
42:42 - mistakes were made so um
42:46 - so yeah so you can re you know you
42:48 - should you can uh hopefully i don't know
42:49 - if this let's see if this link still
42:50 - even works
42:53 - yeah so this is the original
42:55 - um
42:56 - policies from golan's uh celeb syllabus
42:59 - i assume there's a more recent one in
43:01 - 2018 you can find it under my
43:03 - programming from a to z and other
43:04 - courses if that's helpful to you if you
43:05 - have suggestions about a phrase and
43:07 - write that better boy would i love those
43:10 - because this is a very
43:12 - uh it's like you know talk about faqs
43:14 - for people who are new to teaching
43:16 - people are students new to coding uh i
43:19 - ask this question all the time and get
43:21 - confused myself so
43:23 - okay
43:24 - now auto encoder we're really gonna get
43:27 - this project this is why it takes by the
43:29 - way this is why it takes seven seven
43:32 - hundred
43:32 - three hour live streams because i spend
43:35 - 45 minutes i haven't even started
43:37 - working on the code for this project
43:43 - how about we start now i did
43:45 - i started demonstrating okay generated
43:47 - the training images the next step
43:49 - um and let's check
43:51 - i have a node
43:54 - a piece of node code
43:56 - that
43:58 - runs through a series of steps
44:01 - basically it builds the architecture of
44:03 - this machine learning autoencoder model
44:08 - um and sorry i'm just reading k y d z zs
44:11 - i'm gonna this balancing act of like
44:13 - just having this discussion with the
44:14 - chat going through this code example is
44:16 - quite difficult but
44:18 - um recreating the flock type animation
44:20 - um is yeah and and so
44:23 - again to be clear
44:25 - i am making and releasing my examples
44:27 - for you to use
44:30 - use them and you're not required to give
44:31 - credit
44:32 - which is different than if i had some
44:35 - sort of like artistic
44:37 - project that i was displaying that had
44:40 - some other kinds of intentions behind it
44:42 - for you and how you might reuse that
44:45 - so copying my code
44:47 - exactly and putting it on your website
44:48 - is fine that's what it's there for of
44:50 - course you probably want to make it your
44:52 - own that's the exciting part of all this
44:54 - okay
44:56 - um
44:57 - sgl
44:59 - let me see if hopefully somebody in the
45:00 - chat can post that link otherwise tweet
45:03 - at me or follow up after i can try to
45:04 - put it in the video description
45:06 - later okay so back to the auto encoder
45:09 - the code that i've written so far
45:10 - basically does everything
45:12 - it creates a
45:14 - loads all those 1100 training images
45:17 - it trains the auto encoder with the
45:20 - training images i'm using just the first
45:22 - 1000 images to train the model
45:25 - it then saves
45:27 - the model to a
45:31 - to a local file because i'm going to
45:33 - load that model from a p5 sketch and
45:35 - then it also generates test images just
45:38 - to sort of see
45:39 - um
45:41 - okay
45:42 - so
45:44 - um let's run that
45:48 - let's first look at the directory and um
45:52 - i'm going to delete all of the
45:55 - the output images that i generated last
45:57 - time to make sure this is actually
45:58 - working
46:01 - and i'm going to run
46:04 - the training now
46:06 - it was suggested to me i think over
46:07 - social media after last live stream
46:11 - that
46:12 - i
46:12 - absolutely need a song to play or sing
46:16 - by the way i do have my ukulele here in
46:18 - the studio
46:22 - it's
46:24 - been over a year
46:26 - since you know where's the joy in my
46:29 - life that it's been over well over a
46:31 - year
46:32 - since i actually even unzipped this case
46:37 - i mean there's no way this is going to
46:38 - be in tune
46:40 - even this is the night this is my nice
46:42 - one has a strap
46:46 - it's not in tune at all
46:50 - none of the chords i play will work but
46:52 - we need a training song
46:55 - okay i'm gonna have to deal with this
46:56 - later
46:58 - um
46:59 - but so i'm uh anybody who wants to write
47:02 - me
47:03 - a training song maybe it would go
47:06 - [Music]
47:07 - epoch 34 out of 100 eta 1.1
47:12 - 1771 milliseconds so this is not good
47:16 - this is not good this is not good
47:20 - uh the loss is going down it's at .06
47:27 - this is very embarrassing
47:34 - the voice in the back of my head always
47:35 - when i start to like um the silliness
47:38 - starts to take over a little bit is um
47:40 - people who comment i would have enjoyed
47:42 - your video if you just would stop it
47:43 - with the clown act
47:46 - i can't help it that's my that's my
47:48 - inner that's my inner
47:50 - inner
47:51 - soul
47:52 - is a clown
47:54 - it just
47:55 - wants to break free i never made it to
47:56 - the shock le cox school of mime in paris
47:59 - that was like my childhood dream and i
48:01 - just never made it there and now i
48:03 - reduce to
48:04 - machine learning javascript examples
48:06 - while
48:08 - clowning around
48:14 - [Music]
48:23 - like getting 100 epochs was definitely
48:25 - too long
48:27 - yeah chris sears
48:29 - um
48:30 - it should be in the style of a rocky
48:32 - montage i like
48:37 - um i really don't need to let this go
48:39 - all the way but um
48:41 - especially because i already trained a
48:43 - model but it's it's almost there so i
48:44 - can let this go
48:46 - um
48:49 - uh all right so
48:51 - we're almost there to getting this to
48:53 - train and as i start to iterate and work
48:55 - on this more um i'm going to not
48:58 - you know take
49:00 - the full five minutes or whatever this
49:01 - has been for it to train
49:03 - but we're almost there so once the model
49:04 - is trained
49:08 - um manus asks are you plotting the law
49:10 - so questions would have been good so i
49:12 - am not the loss the loss
49:15 - value which is the result of a loss
49:17 - function is sort of summarizing the
49:19 - overall error of the model how well is
49:22 - it at reproducing those original
49:24 - training images and you can see that
49:26 - it's going down over time although it
49:28 - kind of went up here so one thing that i
49:30 - could do is analyze like when did it
49:31 - really stop like clearly at epoch 34 it
49:35 - was quite higher
49:36 - than at epoch 54. but you can see
49:39 - somewhere around here actually
49:41 - maybe not even until like the 90 around
49:44 - epoch 90 or so
49:45 - um
49:46 - did it sort of stop really going down um
49:50 - kathy asked a great question
49:52 - it is possible to set an acceptable loss
49:54 - or maybe this is a question is it
49:56 - possible to set an acceptable loss
49:57 - before running a stop when it reaches
49:59 - the desired loss that's uh absolutely i
50:01 - could write that into the code i'm not
50:03 - going to do that right now because that
50:04 - would be sort of an additional thing to
50:06 - engineer but i would certainly encourage
50:08 - anyone watching to try to do that and
50:10 - that seems like a really interesting
50:11 - idea yeah so
50:13 - again just to emphasize
50:15 - um
50:16 - hi michael k ah i posted something on
50:19 - twitter and somebody came to join the
50:20 - live stream
50:23 - look at this amazing um so okay so many
50:27 - interesting questions here so let's let
50:29 - me address these questions
50:30 - by the following so first of all this is
50:33 - the output that i have now generated
50:35 - let's take a look at these images
50:38 - and i'm going to just scroll through a
50:39 - bunch of them
50:41 - so you can see i'm getting what i was
50:43 - hoping for which is these kind of like
50:45 - squirkles they're sort of they're mostly
50:47 - circular but you can see the sort of
50:48 - corners of squares and sometimes i got a
50:50 - full square as soon as i have a full
50:52 - circle sometimes i have something
50:54 - somewhere in between
50:56 - now
50:57 - a couple things to mention about this
50:59 - one
51:02 - this is an incredibly trivial example
51:06 - right what i am reproducing with the
51:08 - auto encoder
51:09 - are
51:10 - very low resolution
51:13 - simple shapes that are either only i
51:15 - mean there's really only two variables
51:16 - here there's a switch is it a square or
51:19 - a circle and then there's the radius so
51:21 - you can think about i mean this actually
51:22 - came came to me i mean i think it was
51:25 - based on some of the chat messages but
51:27 - if i go over here to the whiteboard if i
51:28 - were to like come over here and sort of
51:30 - re-explain what an auto encoder is and
51:32 - again
51:33 - uh what is autocoder go and check out
51:36 - the two-minute papers autoencoder video
51:38 - on youtube uh where it describes an
51:40 - autoencoder as a copying machine right
51:42 - it's a neural network that takes an
51:44 - image in as an input and the idea is we
51:46 - want to get that same image out as an
51:48 - output that's a very easy thing to do
51:50 - right we could just cut in terms of
51:52 - without a neural network i just iterate
51:54 - over the pixels and make a new image
51:55 - with all the same pixels however the
51:58 - idea of an auto encoder is the data is
52:00 - being passed layer upon layer upon layer
52:03 - through a neural network being
52:04 - compressed down to from however many
52:07 - pixels to some other layer with a
52:09 - smaller number of nodes and then
52:11 - decompressed back up so if you think
52:13 - about it
52:14 - i technically only need
52:16 - two nodes in this sort of center layer
52:19 - for what i'm doing because one variable
52:22 - right i need to keep track of what is
52:24 - the size of this shape and the other
52:26 - variable is it a square or a circle so
52:28 - in theory if i go to the architecture
52:33 - of this auto encoder
52:37 - and i look at how i've built it right oh
52:40 - i'm sorry i didn't i didn't switch over
52:42 - if i look at how i built it the first
52:44 - layer receives
52:46 - um it has 256 it receives the number of
52:49 - pixels of the actual image and it
52:51 - compresses it down i mean it's not this
52:53 - isn't really compression i'm just using
52:55 - that as kind of a in a sort of
52:57 - metaphorical way to describe the process
52:59 - although i mean it is
53:01 - compressing it essentially the data and
53:03 - 256 to 128 and then down to eight
53:06 - and then back up to 128 back up to 256
53:10 - and then eventually back to a full pixel
53:13 - image
53:15 - um right and we could do a convolutional
53:17 - autoencoder and a variational auto code
53:19 - and then a thank you astro penguin for
53:21 - answering about overfitting
53:23 - um
53:25 - so um so
53:27 - let's we can address that in a bit i
53:29 - feel like
53:30 - i was getting some good suggestions
53:31 - about changing what loss function i'm
53:33 - using but just out of curiosity i hate
53:35 - to do this
53:37 - let's
53:38 - add one more layer
53:42 - and bring it down to two units
53:45 - and then have the decoder also have one
53:48 - more layer
53:53 - with eight
53:54 - units then let's see if i can still get
53:57 - it to work and i know i said i wasn't
53:59 - going to do this again with a hundred
54:00 - epochs
54:03 - but i can't help it
54:06 - so here we go we are training the model
54:09 - again let's see if that loss can go down
54:13 - and see if we can get um
54:15 - a mean squared error loss function for
54:18 - auto encoders yeah
54:20 - um
54:21 - and astral let me just read astro
54:23 - penguin's comment
54:25 - overfitting is when your model doesn't
54:27 - just represent your data but also your
54:29 - noise it is so well trained to your data
54:31 - that works very well on it but poorly on
54:33 - another data set right you can train a
54:35 - model so well
54:37 - that it can
54:38 - re-produce
54:41 - the training data perfectly
54:44 - but because it's just so locked into
54:46 - that training data if the real world
54:48 - data has any kind of variability to it
54:51 - that's just not there in the training
54:53 - data it's going to explode and do a
54:55 - terrible job so there are lots of
54:57 - techniques to reduce overfitting in
54:59 - terms of how you collect your data set
55:02 - using something called dropout which is
55:03 - adding some sort of randomness and
55:05 - disconnecting parts of the neural
55:06 - network as it's learning
55:07 - um
55:08 - this seems to have settled on a loss of
55:10 - 0.23
55:12 - i'm going to just run this again
55:15 - and just give it 30 epochs so we can i
55:18 - think that's faster than waiting for it
55:19 - to get to 100.
55:22 - uh where did i where do i set the number
55:24 - of epochs
55:25 - um
55:26 - train here it is so let's just let's
55:28 - just train it with 30
55:31 - um and let that go
55:39 - um
55:40 - ah yeah um
55:43 - and uh simon's reminding me that i was
55:45 - gonna try to do this with um
55:47 - try to see if i could de-noise some
55:49 - images so i'm i'm getting like sort of
55:50 - scattered here of all the different
55:52 - things i want to try
55:53 - but it's okay it's not even noon yet
55:57 - i've only spent an hour
55:58 - um
56:00 - place the auto encoder song
56:06 - cyber said this is great
56:08 - cyber gus says it's like preparing for a
56:11 - math exam by memorizing the solutions to
56:14 - the problems right so like if you have
56:16 - like a sample test you just memorize all
56:18 - the answers but don't look at how any of
56:20 - the problems work
56:22 - and then you got a new test you could
56:23 - put all those correct answers in but
56:25 - they won't match the actual problems
56:26 - it's kind of a wonderful okay so i think
56:28 - we're at epoch 30. i'm just curious to
56:31 - see oh there's a lot of randomness in
56:33 - how well it does
56:35 - i didn't let you let it go more i didn't
56:37 - realize but let's just see what kind of
56:38 - images we got even from that
56:42 - from that training so they're
56:44 - they look pretty good they're just much
56:46 - fuzzier
56:47 - so this is what it was able to do with
56:48 - just two parameters
56:50 - but also i didn't let it train
56:52 - for as long
56:54 - as i could have
56:56 - nicole wants to know what is in my mug
56:58 - first of all love this mug fellow mug
57:00 - not a sponsor
57:02 - you never know though um it is coffee
57:05 - and oat milk
57:10 - delicious
57:11 - sometimes it is ginger tea depending on
57:13 - how i'm feeling
57:15 - i'm either like a coffee and oat milk or
57:17 - i'm a plain ginger tea
57:19 - kind of fellow that's in my felt with my
57:21 - fellow mug
57:22 - that's me
57:24 - all right
57:27 - moving along
57:28 - um let's go back to um
57:34 - yeah
57:35 - i'm reading simon's commentary and i
57:37 - totally agree
57:38 - let's look at whether or not our auto
57:40 - encoder can
57:42 - effectively denoise a shape this is you
57:46 - know an actual application of auto
57:48 - encoders what do i even mean by denoise
57:51 - hold on
57:52 - so i'm going to put this back to
57:54 - 100 epochs
57:57 - and i'm going to go back and get rid of
57:59 - this like little layer
58:02 - uh the and just leave the the middle
58:05 - layer
58:06 - um as having um eight units
58:10 - um i want to just try it with a
58:13 - different loss function
58:16 - um is it this
58:20 - is this what i should put in here let's
58:22 - just try a little a little risky here to
58:24 - introduce that at the moment
58:26 - but okay
58:28 - let's train i'm just gonna let it train
58:30 - oh look at that
58:34 - huh
58:37 - look at that it like with that loss
58:39 - function it's like
58:42 - not improving after just a few epochs
58:44 - interesting so hold on this will be
58:46 - great
58:47 - if that was
58:48 - that much of an improvement
58:51 - let's have it go
58:54 - just 10 epochs
58:58 - sometimes it's totally unnecessary but i
59:00 - just like to delete
59:01 - the output just to know that i'm getting
59:03 - new output for sure
59:05 - let's run this for 10 epochs
59:10 - and see what we get look at that like
59:12 - basically after two
59:15 - four five
59:17 - oh no it's still improving huh
59:20 - oh it's still it's always why does this
59:22 - happen to me
59:23 - it's still improving so the other time
59:25 - it kind of like was waffling but let's
59:27 - take a look
59:28 - at what i've got after just 10 epochs
59:34 - all right fine
59:36 - torture me so go back to 50.
59:40 - this is one of the problems with this
59:42 - project is just running again takes so
59:44 - long
59:45 - uh mse
59:47 - did i not type the right thing in
59:55 - let's let it go we're gonna let it go
59:56 - for let's let's actually look in the
59:57 - tensorflow documentation
60:00 - um
60:00 - [Music]
60:03 - where is that is this tensorflow.js i
60:05 - don't think so
60:09 - um
60:12 - these are all the tabs i was looking at
60:18 - yeah look at this
60:23 - going way down
60:26 - still going down
60:28 - whoops
60:29 - um
60:36 - this is what i want
60:39 - api
60:41 - um
60:42 - i want the tensorflow.js api
60:46 - uh mean
60:48 - mean squared
60:51 - yeah no i think i got it right
60:54 - mean squared error
60:59 - now do i want the stochastic gradient
61:02 - descent
61:04 - the learning rate was too high
61:06 - um
61:06 - [Music]
61:08 - might be getting stuck in a local
61:09 - minimum the opposite of a t all right um
61:12 - so that's interesting i wonder if i
61:13 - should be also trying this to cast sgd
61:15 - um optimizer instead of atom
61:18 - um but anyway
61:21 - it was still the loss even uh even at
61:24 - that 50th epoch was still going down
61:26 - pretty consistently although it did pop
61:28 - back up there so let's take a look now
61:30 - at the images we generated
61:34 - all right these look really good
61:37 - so what i want to
61:40 - see now if i can get it to do is denoise
61:44 - an image but i'm going to go into the
61:46 - browser to do that that's what we didn't
61:48 - get to do last time okay everybody
61:50 - um okay so
61:53 - the next step of this
61:57 - was
61:58 - um
62:00 - if i run a local web server
62:03 - i have a p5.js sketch
62:05 - which is loading the model
62:13 - that's interesting i
62:14 - i thought i would have to go into like
62:16 - the public
62:18 - oh it's serving it knows to serve dot
62:20 - public that's so funny because i have a
62:22 - directory in there okay so this is now
62:24 - the p5.js sketch which is loading that
62:27 - model and i am feeding it just random
62:30 - noise like a a sort of
62:32 - purlin-esque no perlin noise there's
62:35 - always sort of discussion around whether
62:37 - this is true perlin noise or not or
62:38 - simplex or gradient or whatever but this
62:40 - sort of cloudy noise pattern is what i'm
62:42 - feeding into the model and i'm getting
62:44 - this shape out meaning the model is
62:47 - working and this is kind of like leading
62:50 - the way to what i want to really focus
62:52 - on today which is a latent space walk
62:56 - but before we get to that what i would
62:58 - like to do is draw
63:01 - a um an image of a circle and see how it
63:05 - copies it an image of a square and then
63:07 - add noise and see what happens
63:10 - bear with me
63:11 - or join me for this part so i'm going to
63:13 - go into
63:18 - i'm going to go into
63:23 - the
63:24 - um
63:27 - sorry sketch.js i lost my train of
63:30 - thought here and
63:32 - um
63:33 - [Music]
63:35 - let me just do
63:43 - uh
63:46 - training new model
63:50 - so
63:52 - i am going to
63:54 - i know sorry
63:57 - comment out
64:01 - i think i'm just going to take out the
64:03 - noise thing because we don't really need
64:04 - that
64:06 - so
64:07 - it'll be in the code history do i want
64:09 - to add a tag
64:10 - people going to want to find this
64:13 - well
64:15 - i know where it is
64:17 - so we'll finally i'm going to take out
64:18 - all of the noise stuff
64:22 - and just go back to
64:27 - a random image and saying no loop
64:34 - so if i do this
64:38 - um
64:43 - and then
64:47 - next image sorry i'm forgetting how i'm
64:49 - doing
64:52 - this uh
64:56 - does this work
64:58 - and then put no loop in i just want to
65:00 - know this is silly i don't
65:03 - need to add the no loop but i'm just
65:04 - curious too
65:06 - all right forget it keep the no loop
65:10 - have it be a random image wait sketch
65:12 - sorry hold on
65:14 - what did i do
65:17 - oh i lost this ah
65:21 - okay this is what i want to do so this
65:23 - is what it looks like when i'm feeding
65:24 - random noise into it
65:28 - it's trying to find and and
65:30 - month nonsense
65:32 - we see a machine trying to find shapes
65:34 - in the random noise so
65:36 - what i would like to do instead
65:39 - is and i'm going to create
65:41 - a um
65:43 - i know what to call this the um
65:47 - the i'll call it input canvas
65:51 - and let's say input
65:52 - canvas equals create graphics
66:00 - at
66:04 - um
66:05 - i've done this in sort of like a weird
66:07 - backwards way but
66:10 - bear with me um what is the size oh yeah
66:12 - create graphics w comma w no no we're
66:14 - fine create graphics i have i forgot i
66:17 - had that w value
66:18 - so i'm working with 56 by 56 pixel
66:21 - images
66:22 - um
66:23 - and the input canvas
66:27 - i'm going to say
66:30 - input canvas dot background i'm going to
66:34 - draw a background of white
66:36 - then i'm going to draw i'm going to say
66:38 - a stroke of
66:40 - zero
66:42 - a stroke
66:45 - weight and this i should essentially be
66:46 - matching what i did in processing so i'm
66:49 - going to say a stroke weight of 16
66:51 - 16
66:53 - then i'm going to say um
66:56 - input canvas
66:58 - circle uh
67:00 - w divided by 2 w divided by 2 and just
67:03 - give it um
67:05 - a
67:07 - a radius or diameter of w divided by 3
67:12 - and i'm going to say input canvas
67:16 - no fill
67:18 - then
67:19 - um
67:21 - i'm still this is still going to be
67:22 - random i'm just doing this one the only
67:25 - thing i'm trying to do right now is i
67:27 - want to see a drawn shape drawn with p5
67:30 - on this left part
67:32 - so now i should be able to in draw
67:34 - instead of rendering this input image it
67:37 - should be able to say image
67:39 - input canvas
67:41 - 0 0
67:43 - and resize it up to w times w
67:48 - wait why won't it
67:49 - why won't it do that
67:51 - doesn't my variable names are terrible
67:54 - where was
67:56 - okay
67:57 - and then let's see if this now gives me
68:02 - oh
68:03 - this always happens it's trying to
68:05 - import ah
68:08 - it's trying to import something i really
68:10 - have to work on my vs code settings
68:14 - okay good
68:15 - oh the stroke oh i forgot i was drawing
68:18 - it as a larger image than resizing it
68:20 - down so this stroke weight was you know
68:23 - a bit much
68:24 - uh technically it should be
68:27 - um
68:30 - uh 16 where to
68:33 - this is very silly but i'm just going to
68:34 - do this
68:36 - okay great so now the idea here is that
68:40 - the auto encoder should take this input
68:43 - circle and produce an exact copy of it
68:47 - on the right now however what's
68:48 - important to note is i'm not feeding it
68:50 - into the auto encoder so the next thing
68:52 - i want to do
68:54 - is feed the image into the auto encoder
68:59 - so
68:59 - [Music]
69:00 - that happens here so i'm going to need
69:02 - to do it by looking at the
69:04 - pixels so i need to say
69:09 - input canvas
69:10 - load pixels
69:14 - and then i equal 0 i is less than
69:18 - w times w
69:20 - times four
69:22 - because there's four elements of the
69:24 - pixel array per oh no no no i'm gonna
69:27 - have to do the multiply by four
69:28 - somewhere else
69:29 - same thing because my input image array
69:32 - has w times w spots in it but instead of
69:35 - a random i want to say input canvas
69:38 - pixels i times four
69:41 - okay that should work because i could
69:42 - just take the r channel if it's if it's
69:45 - a full grayscale like black and white
69:47 - image i times 4 if the array is rgb
69:50 - alpha rgb alpha then the r channel is 0
69:54 - 4 8 12. and so if the i is going up 0 1
69:59 - 2 3 i times 4 is 0 4 8 12 et cetera so i
70:02 - believe
70:04 - this should work
70:07 - look at that look at that beautiful auto
70:08 - encoder it copied that shape perfectly
70:11 - now
70:13 - just you wait and see
70:16 - let
70:18 - r equals map mouse x which goes between
70:22 - 0 and width
70:23 - to between 0
70:25 - and width
70:29 - this is the most brilliant code i've
70:30 - ever written in my entire life
70:32 - i'm gonna map this range between zero
70:35 - and width now hold on everybody just
70:36 - hold on a second i'm gonna blow your
70:38 - mind right now to between the minimum of
70:40 - zero and the maximum width but in case i
70:43 - wanted to change that later it's nice to
70:44 - have the map function in there and then
70:46 - this
70:47 - should be r which is really a diameter
70:50 - so let's call it diameter
70:55 - and we should see
70:57 - [Music]
71:00 - i wonder if it never got
71:04 - interesting so this is not working as
71:10 - expected hmm
71:16 - am i
71:20 - i'm definitely redrawing the image
71:23 - redoing the pixels into
71:26 - the auto encoder
71:35 - let's try a square
71:37 - just out of curiosity
71:39 - and also wait wait wait i have an idea
71:41 - the range was 25 to 200.
71:47 - so in theory like only range that it
71:49 - learned
71:50 - is
71:51 - uh between 25 divided by little w
71:55 - and
71:56 - 200 divided by little w
72:00 - um
72:02 - so
72:03 - that might help
72:07 - let me just say input if i'm going to do
72:09 - a square input canvas
72:12 - rectmode center
72:14 - let's see what happens here
72:23 - i'm like suspicious that it's not
72:26 - something is changing all right do i
72:28 - need to train the model
72:29 - i feel like the model picked up the
72:31 - average radius of the circle it does
72:32 - seem that way
72:34 - all right i feel like let me just go
72:37 - back
72:38 - to
72:43 - um what i had originally
72:46 - which was
72:52 - um
72:53 - i just want to make sure i'm using the
72:55 - right model
72:57 - so let's
72:59 - um i'm sure
73:00 - it is but
73:03 - let's go to
73:08 - um
73:14 - where's the model saved
73:16 - oh it's here
73:18 - today at 12th grade
73:21 - it's a little bit silly but let me um
73:29 - i'm going to put this
73:30 - back to what i started with today
73:36 - so i i'm just putting it back to binary
73:39 - cross entropy adam even though it kind
73:40 - of doesn't make any sense
73:42 - and a hundred epochs and i'm gonna once
73:45 - again
73:46 - train this model
73:49 - and let it go the full 100 epochs this
73:52 - time all right everybody
73:54 - the decoded images look like the average
73:56 - of all parameters half circle half
73:58 - square with a medium radius side i know
74:04 - um so i wasn't getting that issue before
74:07 - so i'm just going to let this
74:09 - kind of power through
74:11 - a longer training process and see what
74:13 - we get so this will be a new the way i
74:15 - have this configured is when i train the
74:17 - model it saves the model in the
74:20 - directory of the p5 sketch and the p5
74:22 - sketch should should pull that up
74:29 - all right
74:30 - while this model is training and since
74:32 - i'm halfway through the live stream this
74:34 - is a perfect time
74:35 - for me to do my sponsor segment
74:39 - today's coding train is brought to you
74:41 - by
74:43 - curiosity stream thank you crosstalk
74:46 - stream now i'm just going to repeat what
74:47 - i said at the beginning of the live
74:48 - stream
74:49 - but those of you who i know most of you
74:51 - probably weren't here at the beginning
74:52 - so guess what i have something exciting
74:54 - to tell you about it is the best deal in
74:57 - streaming today so i am going to go up
75:00 - here uh whoops and show you something
75:05 - curiosity stream
75:10 - let's come back over here
75:12 - okay
75:14 - whoops wrong thing
75:20 - curiosity
75:23 - stream
75:31 - um i'm signing in here okay so curiosity
75:33 - stream is a amazing streaming service
75:38 - with thousands literally thousands of
75:40 - documentaries
75:42 - um all in so many um
75:45 - areas related to things that i do here
75:47 - on the coding train in particular my
75:50 - favorite part of kinds of documentaries
75:52 - that are on oh my god i've got to watch
75:54 - this one
75:56 - whale wisdom i love whales are the
75:58 - nature document documentaries um secret
76:02 - lives there's a whole bunch of secret
76:03 - lives of blank um
76:05 - nature documentation these are great for
76:06 - kids um science space and tech um
76:10 - infinite rainbows
76:12 - wait a second here
76:13 - i mean it's worth signing up for
76:14 - curiosity stream just for infinite
76:16 - rainbows alone how did i not know about
76:18 - there's only 22 minutes long
76:20 - in the time span of one single coding
76:22 - train coding challenge you can watch an
76:24 - entire documentary about what exactly
76:26 - are rainbows learn the science of i'm
76:28 - sorry this live stream is over
76:31 - it is done
76:34 - i don't know if the music is playing i'm
76:36 - out of here i'm going to watch this
76:37 - right now um but if curiosity stream
76:41 - isn't enough
76:42 - with this special one-time well it's not
76:44 - exclusive
76:46 - 42 off discount
76:48 - you also
76:50 - get access to uh nebula let me sign in
76:53 - here
76:54 - um
76:55 - nebula is a streaming service uh made
76:58 - created by creators youtube creators
77:00 - hopefully many of you might recognize
77:01 - many of your favorites here uh not not
77:04 - just bikes is new to curiosity stream
77:06 - i'm sorry new to nebula and i've been uh
77:08 - really enjoying not just bikes even
77:10 - though now i live somewhere where i have
77:12 - to drive everywhere
77:14 - so nerdsync is great um all of these
77:17 - wonderful channels um you can watch all
77:19 - of the videos from these youtube
77:21 - channels on nebula with no ads no
77:24 - sponsor segments and many of them have
77:26 - extended versions this is something i'm
77:28 - hoping to get into in 2022 so you could
77:30 - sign up now
77:32 - and so um
77:36 - the other thing about it is there are a
77:37 - ton of originals so if you look at the
77:41 - nebula originals
77:42 - you can see different
77:45 - um kinds of video content that you can't
77:48 - find look at this next officially you're
77:50 - in in gaming next level world building
77:52 - why games are better than movies is a
77:54 - wonderful nebula original series none of
77:56 - these these are only available through
77:57 - nebula and
77:59 - uh i'm going to take this from renee
78:01 - ritchie this is i just bought a dongle
78:04 - yesterday i needed a dongle for one of
78:07 - my laptops
78:08 - it cost more than an entire year it's
78:11 - like less than one dollar a month
78:13 - for both curiosity stream and nebula for
78:15 - the whole year it's 11.59
78:18 - um if you just sign up through this link
78:20 - um it lets them it lets them know you
78:22 - found out about curiosity's stream and
78:24 - the nebula bundle through me helps the
78:25 - coding train out gives you access to all
78:27 - this wonderful content supporting
78:28 - educational content creators so i hope
78:30 - you will consider it um something that
78:33 - you think about doing for your streaming
78:35 - and entertainment and education needs uh
78:37 - for
78:38 - 2022 i don't know what your new year's
78:39 - resolution is but my new year's
78:41 - resolution was to watch more wonderful
78:43 - youtube con educational content creators
78:45 - on nebula all right let's check in uh
78:48 - back to our uh training
78:52 - uh by the way the link is in um a pinned
78:55 - message in the chat if you're looking
78:57 - for it's also in the video description
78:59 - okay
79:01 - so this is presumably
79:04 - the
79:05 - the new model was
79:06 - trained got down to a loss of zero point
79:10 - sorry for all the scrolling 0.644
79:13 - i'm gonna refresh this page
79:17 - weird
79:18 - i'm like suspicious that my code isn't
79:20 - working
79:22 - because
79:24 - did i delete i deleted all of the let's
79:26 - go back to the random noise
79:30 - so first of all
79:31 - let's just check
79:33 - here
79:34 - oh wait a second no public yeah
79:37 - this is the model from 12 16 p.m that's
79:39 - the new model
79:41 - this project i'm not making any progress
79:44 - today at this project which is very
79:45 - distressing
79:49 - i feel like it did something a moment
79:51 - ago like when i switched back in
79:53 - um
79:55 - hold on we're going to debug this
79:58 - where's my next image okay i got to go
80:01 - back to the sketch
80:04 - next image function
80:11 - what if i go back to oh
80:18 - who knows what the problem is i know
80:19 - what the problem is
80:22 - come on come on chat
80:24 - come on you can think about it
80:26 - what's wrong what are the numbers coming
80:29 - out of inputcanvas.pixels
80:32 - if it is a white pixel what value is it
80:35 - 255
80:37 - i didn't normalize the values i didn't
80:39 - normalize the values this needs to be
80:41 - normalized divided by 255 okay
80:49 - all right that didn't seem to change
80:51 - anything
80:52 - ah
80:54 - um
80:55 - okay let's just for the sake of argument
80:58 - put in random noise again
81:05 - so i am getting a
81:07 - variety
81:08 - again ignore the fact
81:10 - this is
81:11 - in the
81:16 - hmm
81:27 - i times 4 that's right right
81:33 - it's pixels
81:41 - should i give it
81:43 - it's not in the draw let's check the
81:45 - input all right
81:47 - but
81:51 - i mean let's just make sure
82:05 - it's continuing to run
82:08 - and make new input
82:17 - whoa no that's right 56 by 56 3136 okay
82:22 - but like
82:24 - a bunch of zeros yeah i mean this looks
82:27 - right
82:30 - all right let's try like why is the
82:32 - model not able to give me a range of
82:34 - sizes it was not having that problem
82:38 - in the version that i made where i was
82:40 - passing pearl and noise into it
82:43 - and look it's like
82:48 - what's it it's doing something
82:52 - okay
82:53 - use the mouse click to switch between
82:54 - square and circle
83:01 - am i getting alpha my
83:03 - i don't think i'm getting the alpha i
83:05 - times 4 should be the r channel
83:09 - all right this is a good idea
83:13 - so
83:14 - if mouse pressed
83:18 - mouse is pressed
83:20 - draw a square
83:26 - otherwise draw a circle
83:37 - okay
83:39 - that's definitely something
83:50 - is the scale wrong the mods that map oh
83:53 - no but it's symmetrical
83:55 - it could be that i'm not reading the
83:57 - pixels in the right order no
83:59 - it's totally symmetrical so i don't
84:01 - think
84:03 - that should matter
84:05 - all right here's the thing that i could
84:07 - try
84:08 - let's go back to our model
84:13 - let's
84:18 - let's look at okay so let's think about
84:20 - the model architecture for a second
84:23 - yeah many jimmy's saying accumulate the
84:25 - rgb and divide by three
84:27 - that shouldn't matter the mouse mapping
84:29 - seems a little wrong yeah i don't
84:30 - understand
84:35 - so hold on let's do this without the
84:36 - mouse mapping just to be
84:38 - more consistent here
84:41 - let me go here and let me say
84:50 - diameter let me make diameter global
84:52 - variable
84:59 - um
85:13 - start at the smallest
85:15 - and then
85:19 - where do i set it yeah and then i'm
85:21 - going to say
85:38 - just have it cycle back so i'm just
85:40 - going to have the diameter cycle
85:43 - automatically
85:54 - it's weird like this to me like the fact
85:56 - that it's not changing at all
85:58 - makes me suspicious
86:01 - that i'm not doing something
86:03 - correctly
86:08 - because
86:10 - in the neural network
86:12 - right like in the output folder in my
86:14 - test images
86:17 - i'm getting
86:20 - really um
86:25 - right
86:28 - this is this is what i'm getting when
86:30 - i'm testing it
86:32 - so like why is p5 not doing this
86:39 - so this is what this is why i'm
86:40 - suspicious because the model
86:43 - otherwise is performing as expected just
86:46 - not when i bring it into p5 so i feel
86:49 - like maybe the way that i'm drawing
86:50 - these images is somehow wrong
86:52 - all right i have another idea
86:58 - just bear with me for a second let me
87:00 - take a training data image
87:08 - oh this is no no let me take
87:12 - let me take 10 images from the training
87:14 - data
87:18 - and let me put those in
87:20 - a folder called data
87:22 - we're going to figure this out
87:24 - okay
87:25 - so now
87:27 - i am going to
87:34 - um
87:37 - joseph asked when you were using noise
87:39 - were you using the noise value or the
87:41 - pixel value
87:42 - oh i was definitely using the um
87:48 - the noise the noise the noise value hold
87:51 - on
87:53 - let me add preload
87:59 - so we're going to call these test images
88:03 - test images index i equals load image
88:08 - data what are these called square
88:13 - i
88:14 - dot
88:18 - dot png
88:23 - and the oh i need to use the back tick
88:27 - and this should be number format
88:31 - four
88:33 - uh and then i need a loop
88:37 - do you have 11 for some reason
88:42 - okay
88:43 - so now
88:48 - um let's just
88:52 - for a second
88:53 - take this out all this out
89:00 - i'm going to draw
89:02 - image
89:05 - test images
89:07 - zero
89:16 - now again i'm not let's let's okay so
89:18 - let's take a look at this
89:22 - oh you know what there's a little bit of
89:23 - an issue here
89:28 - i'm worried that i wasn't refreshing the
89:31 - code hold on don't worry okay so this
89:34 - looks better
89:36 - um let's get rid of this
89:39 - now um
89:43 - function mouse pressed
89:47 - let's have a
89:49 - test
89:50 - index
89:51 - equals zero
89:54 - so this is test index
89:56 - and then test
89:58 - index plus plus
90:04 - okay that's the first image
90:06 - okay see
90:09 - nothing is changing now is nothing
90:11 - changing
90:12 - because
90:14 - i am incorrectly
90:20 - i'm pretty sure that i have the cache
90:23 - disabled but let me just check
90:28 - under network is what i'm looking for
90:31 - yeah i have this setting should
90:34 - should stop me from
90:36 - caching the model file
90:40 - um but why
90:45 - so now i'm going to do this
90:48 - let's actually load the
90:58 - let's load the pixels of this image
91:04 - and this should be no
91:07 - this shouldn't be
91:09 - oh yeah i don't need this input canvas
91:11 - anymore
91:13 - this was silly
91:20 - right i can just draw that test image
91:22 - directly
91:24 - load pixels
91:41 - pixels i times four
91:56 - okay i'm reading the chat because
92:00 - okay
92:01 - ah
92:03 - okay
92:05 - so something about the canvas was wrong
92:10 - okay
92:11 - i knew something was weird
92:15 - well this is much
92:16 - more what i was expecting oh whoa boy
92:19 - did i just go off on a direction forever
92:21 - why what was wrong with the canvas
92:24 - input canvas pixels
92:30 - input canvas draw the image
92:35 - like what's the difference okay put this
92:37 - and just put this back
92:44 - okay so and now
92:46 - why
92:49 - why if i say
92:50 - input why if i do this instead of the
92:53 - test image
93:01 - the load pixel this must be a p5 bug
93:08 - this has got to be a p5 bug
93:10 - oh this is so sad but i guess this is
93:12 - good that i discovered this because
93:13 - maybe it would
93:15 - cause me some problems later
93:17 - why is the canvas can i not seem to get
93:20 - new
93:21 - pixels from it
93:26 - i mean one thing i could try to do
93:28 - is
93:30 - recreate the graphics context each time
93:39 - still not working
93:42 - is this asynchronous or something
93:48 - i commented out the update
93:51 - what am i missing
93:57 - right there's no difference here
94:03 - i mean i i guess to be 100 sure
94:10 - i need to draw the input canvas
94:17 - oh but
94:20 - but that's gonna
94:22 - cause problems
94:25 - if i'm
94:27 - recreating it so i have to put this back
94:29 - into setup
94:34 - yeah why
94:36 - why what
94:45 - i mean
94:50 - okay let's try this
95:07 - what if i were to say test image copy
95:11 - input canvas
95:17 - i mean i'm just like copying the image
95:18 - in extra time
95:27 - so right instead of using the pixels
95:30 - from the actual canvas
95:35 - i am
95:37 - i mean do i need to update the
95:39 - is it as simple as i just didn't update
95:41 - the pixels because i did load pixels
95:43 - that could be it
95:46 - well this works
95:50 - so i like copied the pixel from the
95:52 - canvas
95:54 - into
95:55 - an image but
95:56 - could it have been
95:58 - hold on this does kind of make sense
96:11 - all right this is what doesn't work
96:15 - i mean i have a workaround now
96:19 - so that doesn't work
96:21 - but what if i were to put input canvas
96:24 - update pixels
96:31 - no is that the wrong place for them
96:36 - i don't no what i'm doing
96:39 - no i think it's just broken
96:43 - i think the input canvas is broken so
96:48 - i'm going to go back to this ridiculous
96:51 - solution
96:58 - i don't
97:04 - this is working
97:07 - but now i'm going to go back to
97:10 - this
97:11 - and forget about the test images
97:17 - there we go
97:22 - and now in theory
97:25 - it's interesting how it's having trouble
97:27 - distinguishing the circle in the square
97:29 - but i'm not going to get too bent out of
97:30 - shape about that i kind of like that
97:34 - anyway
97:38 - yeah so i definitely eric is saying what
97:40 - if you train a data set that randomly
97:42 - rotates the square i 100 want to do that
97:44 - so i'm just unfortunately like i'm i'm
97:47 - this this is like the slowest thing i'm
97:49 - ever because i'm running into so many
97:52 - small little bugs but i have this
97:55 - working
97:57 - so
97:58 - what i would like to do
98:00 - is i would like to
98:04 - uh add the noise oh my god
98:08 - so just to finish close the loop on this
98:13 - uh
98:14 - [Music]
98:15 - and i see some comments here
98:17 - um in the discord chat as well so
98:21 - just to close the loop on this what i
98:22 - would like to do is let me add some
98:24 - noise
98:25 - so i'm gonna say
98:26 - i'm just gonna add
98:30 - 10
98:31 - random dots
98:35 - so let's give me a
98:38 - random x
98:40 - and a random y
98:43 - and do a point
98:44 - at x y
98:46 - with the same stroke weight
98:51 - so how come i don't
98:54 - see those
98:56 - oh i don't need this last argument rgb
98:59 - uh point
99:02 - oh input canvas sorry input canvas
99:05 - xy
99:10 - so
99:10 - you can see that the noise is i mean
99:13 - this is like a sort of
99:15 - pretty terrible demonstration of noise
99:18 - um let's do the following
99:21 - um
99:22 - let's give it like a hundred points
99:25 - uh
99:27 - stroke
99:29 - weight
99:30 - um this is so silly that i have this
99:31 - like divided by two at w everywhere but
99:34 - let's just make it stroke weight one
99:37 - um and then
99:40 - also we can do the stroke like a little
99:42 - bit lighter
99:49 - [Music]
99:52 - oh i forgot to do input canvas that's
99:54 - why
99:57 - input canvas input canvas
100:00 - uh can i get away with like 500
100:04 - yeah so this is what i wanted to show
100:06 - you of course we have this weird
100:08 - squirkle thing going on
100:10 - but this is how an auto encoder can
100:13 - denoise
100:15 - and let's try doing
100:16 - 1500
100:20 - right the noise is completely eliminated
100:22 - and yet i am drawing a nice circle or
100:26 - square
100:27 - you can see it's a little bit more
100:28 - squarey as it gets larger
100:31 - a little bit more squarey
100:36 - wizzy says unsure what this is all about
100:38 - i just got here from the quadtree so
100:39 - first of all welcome i hope the quadtree
100:41 - video was helpful to you wizzy what i am
100:44 - doing currently is i am building and
100:46 - this is the diagram of it an auto
100:48 - encoder in uh javascript using both
100:51 - tensorflow.js and p5.js and what i'm now
100:54 - demonstrating
100:59 - is and and monos is saying this isn't
101:01 - really denoising
101:03 - the model wasn't trained on it so the
101:05 - way that i'm approaching denoising here
101:08 - is not giving it noisy images with a
101:11 - target output
101:12 - i'm just having it learn
101:14 - a singular kind of output
101:16 - and then if i give it a noisy image the
101:20 - only thing it knows how to do is make a
101:22 - copy of that input with a certain kind
101:25 - of style output thus removing the noise
101:27 - so that's really how i think of this as
101:29 - denoising um
101:32 - so this is exciting to see
101:34 - the interesting thing would be like what
101:35 - happens if i let the circle
101:37 - be bigger
101:39 - than the range in the training data set
101:41 - i assume it won't be able to reproduce
101:42 - that but that'll be kind of interesting
101:44 - to see
101:45 - so like for example right now
101:47 - um this diameter its
101:50 - range is going up to 200
101:53 - but what if i actually like let it go
101:55 - from zero all the way to the full width
102:03 - so you can see as it gets to 0 it
102:05 - doesn't know what to make of that
102:07 - oh whoops
102:14 - oh sorry up this should be to this sorry
102:20 - so at a certain point it's going to get
102:23 - larger than any training image it ever
102:25 - looked at and it's going to get confused
102:29 - let's see what happens yep there that
102:31 - happened right there so it's like trying
102:34 - to make sense of that but it had no it
102:36 - can't extrapolate beyond what it learned
102:39 - but if i were to retrain the model
102:46 - with images that were
102:48 - the full size
102:53 - i'm giving it a bigger range of images
102:55 - now
103:09 - but if you input an image of mario
103:10 - brothers it will draw a squirkle anyway
103:11 - exactly it's going to draw everything
103:13 - into a squirkle
103:15 - and if i uh retrain the model
103:18 - now i kind of want to
103:21 - just
103:23 - for the sake of argument now now that i
103:25 - understand what wasn't working
103:27 - what the issue was let me go back to the
103:30 - model training code
103:31 - and
103:32 - i'm really determined to finish this
103:34 - project today so i'm obviously going to
103:36 - go past one o'clock
103:40 - but let me just return to this i am
103:42 - curious to
103:44 - [Music]
103:46 - see what happens if i try
103:49 - go back to mean squared error as the
103:51 - loss function
103:53 - and let's just change the optimizer to
103:55 - sgd i don't know
103:57 - if this should be
104:00 - better or not
104:01 - but let's retrain the model
104:05 - you can sing the model training song
104:06 - okay so i don't sgd doesn't seem to be
104:11 - maybe i need a higher learning rate with
104:12 - sgd
104:18 - um
104:19 - so let's go back to um
104:22 - i can't remember if i specify the
104:23 - learning rate anywhere
104:26 - i didn't i didn't i'm using a default
104:28 - learning rate
104:29 - but let's try mean squared error
104:36 - and let's see
104:37 - um
104:39 - let's see how well this does
104:42 - um the inside of the rectangle looks
104:45 - bent in this processing sketch so i
104:47 - think that's just an optical illusion i
104:49 - don't want to run this again although i
104:50 - can without saving the image
104:53 - i think that's just an optical illusion
104:55 - because of the
104:57 - rapid pace of circle and squares
105:00 - if i were to change the frame rate
105:03 - to like five
105:08 - i don't think you would see that
105:14 - traditionally we use noisy inputs while
105:16 - trading model rather than just a test
105:18 - set but this is perhaps the best way to
105:20 - do it given the simple nature of the
105:21 - problem thank you monas that's a very
105:23 - useful commentary all right so what's
105:24 - happening next while this is training
105:27 - um
105:28 - and let me just put this
105:30 - back
105:31 - um
105:33 - i want to go to the github repo for this
105:35 - and this this isn't going to work yet
105:37 - because it's still training the newer
105:38 - model
105:39 - although it seems to have like got stuck
105:42 - on a local minimum like which can happen
105:44 - from time to time i don't know if i
105:46 - should adjust the learning rate does
105:48 - anybody have a suggestion
105:51 - i kind of want to just run it again
105:55 - and see
106:03 - though it's it's stuck in that same spot
106:11 - where do i put the learning rate is that
106:13 - here so let's go to tf.js
106:24 - fit
106:27 - dot fit
106:30 - um
106:32 - call backs validation split
106:35 - sample weight initial epoch yield every
106:37 - where does the learning rate get
106:44 - ah
106:45 - it goes with the optimizer
106:49 - okay
106:51 - so if i wanted to try adjusting the
106:53 - learning rate
107:02 - would go here
107:08 - like this
107:10 - so let's give it like
107:11 - just curious like a super high learning
107:13 - rate
107:14 - oh whoa
107:16 - it found its way past that so it just
107:18 - took a little bit okay whoa okay i'm
107:20 - gonna i'm gonna let it this looks like a
107:22 - much better model with mean squared
107:24 - error now
107:25 - i'm gonna let it keep going and not
107:28 - worry about
107:33 - so i'm just gonna keep this
107:34 - in the back of my pocket if i wanted to
107:39 - i'm going to let this model i'm going to
107:40 - let this model finish training
107:42 - the loss is like
107:44 - very very very lower than anything i've
107:46 - seen to date yet working on this project
107:49 - and now
107:51 - what i want to do is go to the github
107:53 - repo for this
107:56 - and
107:59 - um
108:02 - i didn't
108:03 - i didn't see this one
108:05 - um sorry mini james but i want to look
108:07 - at this one
108:09 - so um this particular
108:12 - github issue was filed
108:14 - um
108:14 - [Music]
108:16 - had us has some really really helpful uh
108:19 - tips in it so first of all
108:21 - um i managed um so thank you so much to
108:24 - java gt who writes
108:28 - so this is how you can you can access
108:30 - the individual layers with
108:31 - autoencoder.layers
108:33 - so i made a little helpful function to
108:35 - split the auto encoder by looking for an
108:37 - increasing number of nodes
108:39 - so this is the way i'm going to be able
108:41 - to do that so
108:43 - but you can't just loop over these
108:44 - layers adding them to another sequence
108:46 - they don't carry the weights
108:48 - so i solve this with another helper
108:49 - function that creates a new dense layer
108:52 - so
108:53 - this is interesting to look at i suppose
108:54 - i can use this methodology
108:57 - um
109:00 - and um there's a lot of other helpful
109:03 - like tips in here
109:05 - about things so that's what i want to do
109:07 - next um also uh generating a gif like
109:10 - all this in the nodes in the node
109:12 - program make sure that decoder is fed
109:15 - with values zero through one
109:18 - um okay
109:20 - so but i'm going to come back to that i
109:21 - want to work on splitting the model next
109:25 - um but where is it
109:27 - um
109:28 - managed to get a 28 by 28 encoder
109:30 - reduced down to a single value
109:33 - couldn't do this at larger sizes which
109:35 - worked well down to four variables one
109:38 - makes sense because there's only one
109:39 - variable changing the the that radius
109:43 - um okay
109:45 - are we done all right we have a new
109:46 - model
109:48 - let's see how this new model looks
109:52 - so this new model should be much better
109:59 - yeah you can see like at the larger size
110:02 - it's really distinguishing the circle
110:03 - versus square
110:05 - and denoising
110:12 - now interestingly at lower at a lower
110:15 - size it's having a lot of trouble
110:18 - um it's having a lot of trouble um
110:21 - distinguishing the um the circle and the
110:24 - square because the bends probably of the
110:26 - circle are obviously much less extreme
110:29 - and harmony is doing a really great
110:31 - suggestion which is what happens when
110:33 - you translate the input image all right
110:36 - so what happens if
110:38 - i'm doing too many things at once here
110:41 - but
110:42 - i'm going to get to the latent space
110:43 - thing in a moment i have to make a new
110:46 - clearly make a new sketch here
110:50 - what happens if i draw that image
110:57 - at
111:07 - um
111:11 - at an x y position
111:13 - of my own
111:15 - design
111:23 - so let's see what happens here
111:29 - so you can see as i move it around
111:36 - it's confused but when it's centered
111:39 - that's kind of cool to see
111:46 - you can see like if i put it over here
111:47 - it thinks it's a it's like that must be
111:49 - a big square because there's dark pixels
111:51 - over there but maybe it's a small one
111:53 - and i don't know why i've lost the
111:56 - oh this one's supposed to be um circle
111:59 - no wonder
112:02 - so a good thing now what would happen if
112:05 - i trained it with in circles and squares
112:08 - that are anywhere in the image oh can i
112:10 - do that
112:12 - but i want to do the latent space
112:14 - thing if you use cosine annealing
112:17 - learning rate you can use a high
112:18 - learning rate the schedule or lower yeah
112:19 - yeah yeah
112:20 - so i don't know that i'm going to get
112:21 - that sophisticated with this but quick
112:23 - summary of the comment from manas is
112:25 - that
112:26 - you can start with a high learning rate
112:28 - and then over time like as it gets
112:30 - closer and closer to the optimal weights
112:32 - you can lower the learning rate so that
112:34 - it can fine tune it better but i cannot
112:37 - resist
112:39 - we must not stop
112:40 - let's try
112:42 - um
112:44 - having this also be
112:54 - let's
112:55 - try having
112:59 - the squares and circles in the training
113:01 - data set
113:03 - be
113:04 - in a random position
113:07 - and this has to be float because i'm not
113:09 - in javascript land anymore
113:14 - uh
113:16 - wait a sec
113:17 - something is wrong oh because i'm doing
113:19 - center
113:20 - no
113:21 - that should still be fine
113:28 - oh i'm resizing it down so this has to
113:31 - actually be these values should be the
113:32 - actual canvas size
113:36 - yeah all right this is going to be
113:37 - really tricky is it really going to be
113:39 - able to learn this
113:40 - convolutional layers would solve this i
113:42 - probably should not be trying to do this
113:46 - this is just asking for trouble
113:49 - but i cannot resist
113:56 - and
113:58 - remember my auto encoder
114:01 - only has
114:04 - eight units in the middle maybe i should
114:06 - give it
114:06 - 16. maybe for this i should give it 16.
114:09 - let's give it 16.
114:14 - uh i kind of want to save that previous
114:16 - model in case i need to go back to it
114:19 - so hold on
114:23 - um
114:26 - model
114:27 - squirkle
114:31 - now
114:31 - and then i think i might need to create
114:34 - the model directory again but it's empty
114:40 - okay
114:44 - so now i am attempting
114:49 - to see uh
114:54 - uh i think somebody might be here that i
114:56 - need to speak with hold on a sec
114:58 - everybody while this is training
115:13 - um sorry i'm just checking something
115:15 - here
115:17 - it might just be a delivery truck but i
115:19 - hear a loud noise
115:28 - oh
115:29 - maybe just retrieving something okay
115:32 - how's this going here oh no this seems
115:33 - kind of stuck
115:38 - i i think
115:43 - with many sizes placements you'll want a
115:44 - larger training set that makes a lot of
115:47 - sense the model size is less important
115:48 - than the data all right so that's a
115:50 - really good point okay i think i need to
115:51 - backtrack
115:53 - because my goal was to demonstrate
115:55 - latent latent variables
115:59 - so let me backtrack and not go down this
116:02 - road right now
116:03 - i think i could have done like
116:05 - if like a rotation maybe would have been
116:10 - so let's go back to
116:16 - um
116:23 - oh no that's wrong
116:30 - so let me put it back
116:32 - i had saved the model but i realized i
116:34 - need to
116:35 - deconstruct the model so
116:37 - um
116:40 - let me quit this let me just start the
116:43 - training again all right let's take a
116:44 - look at what i want to do so ultimately
116:47 - and let's put this back to eight
116:52 - i wonder if i could get it down to four
116:53 - oh let's do eight that's fine
116:57 - let's see if the loss does well with
116:59 - four
117:02 - okay
117:03 - so i'm trying to put it down to four
117:05 - just to see how we do
117:11 - oh i didn't make the new training data
117:16 - i have to make the new training data
117:17 - sorry everybody my brain has melted here
117:20 - uh
117:21 - what is going on
117:30 - okay
117:31 - let us go back to
117:35 - this wonderful
117:40 - let's go back to this wonderful
117:43 - code here
117:45 - so this is taking out the layers
117:48 - creating a new layer
117:51 - setting the weights
117:53 - okay
117:54 - so this makes sense i feel like there
117:56 - must be a way to do it
117:58 - um
118:01 - so i don't i think because it's such a
118:03 - simple amount of
118:06 - layers right now
118:10 - i don't know that i need i'm going to
118:11 - use this as a reference
118:13 - but i think i might be able to
118:15 - just even just save those layers in a
118:17 - variable
118:19 - and do this more simply
118:26 - um okay
118:27 - um let's see how this training is going
118:30 - wait what just happened oh yeah no the
118:32 - images are done okay
118:36 - i didn't take a break that's all kind of
118:38 - a problem
118:39 - um
118:41 - andrea says those sigmoid activations
118:43 - seem strange shouldn't you have only one
118:44 - after the final layer i think that's
118:46 - correct
118:48 - let's do that as well let's have all of
118:51 - them
118:55 - let's be able to expand it out only the
118:58 - last one
118:59 - should be sigmoid
119:03 - let's see how this does for us
119:08 - okay so now just examining
119:13 - just examining the code
119:20 - i know i just want
119:22 - the last three layers so let's look at
119:25 - this
119:31 - so now what i want to write some code is
119:35 - create a new model with
119:37 - just the the the decoder
119:40 - so i think that probably
119:43 - the way that i should be doing this
119:44 - though
119:45 - is rather than extract the layers
119:47 - shouldn't i just save them as i'm going
119:49 - like for example
119:53 - what if i were to say
120:01 - what if i were to create an array
120:08 - sorry for the noise everybody
120:12 - [Music]
120:15 - yeah i could do
120:17 - all right
120:21 - um
120:27 - all right so what if i
120:37 - i'm just gonna do this
120:41 - oh yeah
120:42 - i have an idea sorry
120:47 - couldn't i
120:48 - change do this
120:50 - and then have decoder layers
120:56 - and then basically
120:58 - do exactly this
121:09 - um
121:11 - decoder layers
121:13 - push
121:15 - yeah
121:28 - just the helicopter landing outside
121:29 - don't be alarmed he's picking me up i've
121:31 - gotta g i've gotta get somewhere fast
121:37 - uh
121:41 - all right so
121:45 - i'm gonna add all these decoder layers
121:51 - okay
121:52 - then
121:54 - i'm going to say
121:55 - 4 let i equal 0 i is less than
121:58 - decoder layers dot length i plus plus
122:04 - then i'm going to say add
122:06 - decoder layers index i
122:26 - um okay
122:30 - so
122:34 - now
122:35 - i put the decoder layers in a separate
122:38 - array
122:43 - then i'm adding them to the auto encoder
122:45 - so this should be the same
122:46 - i hate to just constantly retrain the
122:48 - model
122:49 - but let me just make sure this still
122:51 - sort of like looks right
122:56 - yep this seems reasonable so so
122:58 - everything is the same same as it was
123:00 - before
123:01 - now if i go back to this reference i
123:04 - want to create a new model
123:09 - so let's it's nice to put this in a
123:11 - separate function but i'm going to pull
123:13 - this code from java gt
123:15 - and see if i can kind of unpack it but
123:17 - with my
123:18 - methodology
123:22 - so
123:23 - oh i see but
123:27 - so i'm actually going to return
123:30 - both
123:32 - the
123:33 - decoder layers
123:35 - and the auto encoder
123:37 - as like an object because i might want
123:39 - to make use of both of these
123:41 - and then i can say
123:54 - do this
123:55 - so
123:56 - now i'm building the autoencoder but
123:59 - saving the decoder layers in a separate
124:02 - array
124:04 - okay
124:06 - um
124:07 - by the way banning if there's like spam
124:10 - happening in the chat
124:12 - is perfectly thank you nicole for
124:14 - stepping up and doing some moderation
124:17 - um
124:22 - i'm just gonna
124:25 - okay i don't know if it's possible to
124:26 - ban or not
124:28 - okay
124:30 - okay
124:31 - so
124:32 - okay
124:34 - so now i have access to the decoder
124:36 - layers separately so what i want to do
124:38 - here is create the new model with just
124:40 - the decoder
124:43 - create decoder
124:46 - with both the decoder layers and the
124:49 - auto
124:50 - encoder
124:53 - i don't know if this is going to work
124:56 - so now
124:57 - i just want
124:59 - uh
125:00 - create decoder is that what i called it
125:03 - decoder layers
125:05 - and the auto encoder
125:08 - and then i can go and take a look at
125:11 - this
125:12 - and say create the new model the decoder
125:18 - is a sequential model
125:21 - then
125:22 - for every
125:31 - for every decoder layer
125:44 - right this is the sort of i'm kind of
125:46 - doing the same thing so this there might
125:48 - be a lot of redundancy here
125:50 - so we can clean it up later refactor
125:52 - this later but
125:54 - i am creating the decoder
125:56 - creating a new model just by
125:59 - taking the list of decoder layers that i
126:01 - saved
126:02 - to kaya suzuki
126:06 - someday there'll be too many of these
126:07 - and i won't be able to do it it's good
126:12 - tsukaya suzuki
126:16 - welcome to
126:17 - the coding train you are boarding right
126:19 - now
126:21 - slow down train we're pulling into the
126:22 - station and opening the door and letting
126:25 - kaya on board
126:27 - for your coding train membership
126:30 - you win
126:32 - not this ukulele my prize ukulele
126:35 - but your very own random number
126:43 - uh on page 163 line uh row
126:47 - 8125 column one your sequence is
126:51 - get ready zero five three four eight
126:56 - okay
126:57 - um
126:59 - so close here
127:01 - so i'm adding all of the decoder layers
127:04 - to this new decoder model
127:07 - then i need to compile it
127:13 - i'm going to compile the decoder
127:18 - with the same settings that i used for
127:20 - the auto encoder
127:23 - so let me just make a 100
127:26 - sure that i'm doing this correctly by
127:27 - actually copying this up here
127:29 - and just changing this to decoder again
127:31 - any returned in code that i can
127:33 - consolidate and do in a better way i
127:35 - will
127:37 - um but the issue is i believe maybe we
127:40 - don't have the weights
127:44 - so
127:47 - oh it's making a new layer
127:49 - why do i have to make a new layer and
127:51 - copy the
127:52 - weights oh is that really why can i just
127:56 - add the layer with the weights
128:00 - manually copying the weights
128:07 - huh
128:08 - so let's
128:09 - i feel like there's a different way to
128:11 - do this
128:13 - with um tensorflow.js but if this works
128:16 - then awesome so sorry i'm gonna do it
128:19 - i'm gonna i'm gonna follow this way so
128:22 - i'm actually not adding the decoder
128:24 - layer directly i'm creating a new layer
128:31 - with
128:32 - so the old layer
128:36 - is that decoder layer and i'm making a
128:39 - new layer
128:40 - with
128:42 - the same number of units the same
128:44 - activation function and the same input
128:48 - shape in theory i shouldn't have to do
128:51 - that because the input shape should be
128:52 - inferred but
128:54 - and then
128:58 - i'm going to add that
128:59 - new layer
129:03 - but i also need to copy over the weights
129:11 - like this
129:14 - okay
129:16 - and i don't need the auto encoder
129:18 - to be passed in
129:21 - because i thought i was going to need
129:22 - that to pull the weights please use four
129:24 - of loops you know what
129:26 - i would like to do that as well
129:30 - let layer of decoder layers
129:41 - yeah then i don't need this much better
129:45 - so this should be the function
129:48 - that and again i i feel like there's got
129:50 - to be a different way of doing this but
129:52 - i don't i'm fine with it if this works
129:54 - great
129:56 - um in which
129:58 - in where i am
130:01 - [Music]
130:02 - and by the way i shouldn't have to
130:04 - retrain the model now i should be able
130:06 - to just
130:08 - um pull in the auto encoder load it
130:10 - because i have it saved
130:14 - um but where did i save it is the
130:17 - question file public model
130:20 - so i have to do this
130:23 - so
130:25 - oh the last training got kind of stuck
130:29 - at like a not a great loss let's go
130:32 - should i just go back to 16
130:35 - let's go back to 16 units in the center
130:40 - um
130:43 - oh this needs a lot of work 16 units
130:47 - or eight let's go back to eight
130:50 - eight is fine i can do eight
130:52 - we're gonna go back to eight
130:55 - um now i've added the decoder layers
131:04 - all right and then returning them both
131:07 - so now create deco okay so let decoder
131:12 - equals create
131:13 - the decoder
131:17 - and then i want to save decoder
131:23 - save decoder equals public file public
131:26 - model decoder
131:28 - so i'm going to save the decoder to a
131:30 - different directory okay everyone
131:36 - isn't there a model.getlayer method
131:38 - there certainly is marius so i i feel
131:41 - like there's there's probably a much
131:42 - more proper tfjs way of doing this but
131:46 - i think this should work let's see what
131:48 - happens
131:50 - unfortunately i'm gonna have to train
131:51 - the whole model again
131:56 - and hopefully we're gonna start seeing
131:58 - um
132:03 - i wonder if i do need to play with the
132:04 - learning rate
132:10 - or is it just going to break out of this
132:11 - somehow
132:20 - so let's take a look here
132:30 - i could just load the model i had
132:32 - earlier
132:38 - why why why why why why why why why
132:44 - am i just too impatient and i should let
132:46 - it
132:54 - what is the deal with it being
132:55 - completely stuck did i not put the new
132:58 - training data in
133:00 - there hold on
133:03 - let's make sure the new training data is
133:05 - in there
133:07 - yeah that's the new training data
133:43 - what is going on
133:53 - yep this is the new training data
134:01 - i'm not saving the decoder
134:05 - there's a typo in the code oh thank you
134:08 - well that's good that gives me another
134:10 - excuse to run this again
134:22 - i mean i'm tempted to just load the
134:24 - previous model i have that i know is
134:26 - working well and then
134:29 - but what
134:34 - let's just generate a new
134:36 - training data set again just to be sure
134:43 - lower the learning rate
134:47 - okay
134:51 - so to do the learning rate
134:56 - right now i'm just using the default
134:59 - atom
135:07 - so what would be a good learning rate
135:09 - i'm just going to try this point zero
135:11 - one
135:33 - uh
135:35 - now this is weird
135:54 - the loss is not going down
136:08 - hmm
136:12 - did this mess up something it really
136:14 - shouldn't have i just put the layers in
136:16 - here
136:19 - and then i'm putting them in
136:22 - the auto encoder one at a
136:30 - time this is not going well
136:35 - change in the activation function
136:38 - i don't think so i mean i can put these
136:41 - back
137:04 - hmm
137:17 - maybe it's thing with your layers array
137:19 - i know
137:22 - well
137:23 - now now i've now i've got it
137:26 - it seems to have caught
137:32 - so it
137:37 - all right i'm gonna go with this
137:42 - and let this model finish training
137:46 - because now the learning rate is
137:48 - and this by the way is now
137:52 - just with
137:56 - whatever the default learning rate is
138:00 - what is it tensorflow
138:03 - js default learning rate
138:05 - atom
138:12 - point zero zero i don't know if that's
138:13 - from 2018.
138:18 - so this is probably the default learning
138:20 - rate for adam
138:38 - okay
138:40 - we're still going down
138:45 - why is the accuracy zero
138:58 - let's just see how this model does
139:02 - it's so hard
139:03 - oh okay i like this
139:08 - epoch 85.
139:16 - oof
139:21 - what was that why was that one time that
139:23 - i uh
139:25 - got this incredibly low loss
139:33 - oop
139:42 - cannot read
139:47 - oh you know what
139:50 - i forgot to return it
139:55 - hilarious but that's fine let's just see
139:58 - now
140:07 - um let's go back to my p5 sketch
140:10 - why is this model so much worse all of a
140:12 - sudden
140:23 - okay
140:26 - so look at this
140:28 - model
140:31 - i mean it's definitely
140:33 - doing something
140:39 - what just happened i see the chat going
140:41 - a little bit
140:42 - crazy um
140:45 - but if i go here
140:47 - and
140:49 - load model dash squirkle
140:56 - look
140:57 - what what did i do for this model this
140:59 - model is working so well
141:06 - like this is what
141:08 - i train like when i train this model
141:10 - like what what happened
141:16 - i don't remember like what settings were
141:18 - different
141:19 - okay
141:20 - ah
141:27 - this is driving me crazy
141:32 - auto encoder
141:34 - 256 128 8
141:37 - 128 256.
141:40 - and these are the decoder layers
141:42 - that i then add one at a time
141:48 - just make sure for
141:50 - a layer
141:53 - of decoder layers
141:59 - add that layer
142:02 - then compile it mean squared error
142:05 - yeah i don't need this accuracy metric i
142:07 - guess
142:09 - just take that out
142:14 - and
142:18 - let's just be explicit about the
142:20 - learning rate so i can sort of see what
142:22 - it is
142:26 - i wonder if i got lucky with the train
142:28 - let's i could give it more images
142:34 - let's generate another set of training
142:36 - images
142:38 - use i'll give relu another chance okay
142:54 - but i want to use sigmoid for the last
142:56 - one because i want to
142:58 - uh i want to
143:00 - [Music]
143:01 - make sure that i'm bound between zero
143:04 - and one
143:06 - and maybe i shouldn't okay
143:11 - okay here we go everybody wait hold on
143:13 - let's just see here
143:15 - um
143:21 - this is like really awful how i have
143:22 - like this duplicate code
143:25 - but
143:29 - this shouldn't matter actually though
143:30 - because i'm not going to be training
143:32 - this model
143:33 - so i'm not sure why i need this but i'm
143:34 - going to
143:35 - okay
143:36 - okay okay everybody
143:55 - i want to give relu another chance
144:00 - model summary
144:03 - okay
144:05 - i like this
144:06 - idea
144:08 - i can't believe that i'm gonna be
144:09 - another one of these live streams and
144:10 - not gotten to the part that i wanted to
144:12 - go to
144:16 - want to go to save train model
144:21 - okay
144:33 - is this right what you're suggesting
144:37 - oh my uh
144:43 - yeah it's completely
144:46 - stuck learning rate okay
144:48 - like lower learning rate
144:51 - okay
144:57 - i would have thought i need to raise the
144:58 - learning rate but
145:08 - like to me i need to raise
145:11 - yeah i could
145:20 - [Music]
145:31 - lower the rate divide by 10 until it
145:33 - works
145:36 - this does not seem like
145:50 - what if i have a high learning rate
146:02 - eight eight three two is just like
146:09 - where it wants to be
146:16 - what is going on but what
146:19 - what did i do
146:22 - like did i change something in the
146:24 - training data
146:30 - i don't think so training data looks
146:32 - reasonable
146:56 - yeah
146:57 - interesting
147:00 - okay what just happened here
147:03 - no sigmoid
147:05 - no sigmoid a terrible sigmoid okay wait
147:08 - this is good
147:09 - hold on but i was like messing around
147:11 - with the learning rate okay i'll leave
147:13 - that default learning rate okay
147:15 - i think we might be in good shape now
147:16 - people
147:18 - i think maybe
147:20 - i think this
147:22 - sigmoid was not helping me
147:33 - i'm sorry
147:35 - i'm sorry
147:48 - in my head because i'm doing something
147:50 - that's the most sort of like basic
147:52 - simplistic
147:55 - like demonstration
147:58 - that i should go back to the classics
148:00 - like sigmoid
148:03 - but i guess that was really standing in
148:05 - the way of progress here
148:08 - standing in the way of the progress did
148:09 - i tell you about today's sponsor
148:11 - another hour
148:12 - curiositystream.com codingtrain are you
148:15 - asleep
148:17 - do you need to wake up
148:18 - as the coding train board you
148:21 - you could try watching something on
148:22 - curiosity's dream or nebula for less
148:24 - than one dollar a month for the entire
148:26 - year
148:28 - oh my god
148:32 - okay we've stopped
148:34 - no it's still going down little little
148:36 - bits and pieces
148:41 - little bits and pieces
148:46 - what did i do that one time
148:48 - that we got that crazy low loss
148:52 - was it just like luck
148:56 - drop the non-linearity for the last
148:58 - layer
149:04 - ah k weekman is here
149:08 - probably could have saved me like at
149:10 - least two hours of wasted time right the
149:13 - losses definitely seems to be nope still
149:15 - going down i want to see that like
149:17 - scientific notation though then i know
149:20 - i'm really doing something right
149:30 - okay
149:32 - oop
149:33 - hiccup a hiccup
149:35 - the number went up this is very exciting
149:37 - i mean needs really needs some kind of
149:39 - like something
150:03 - all right
150:05 - 256 128 8 128 256
150:09 - 3136 that's right total parameters
150:12 - trainable parameters non-trainable
150:13 - members okay we got the model summary
150:18 - might need more epochs or a higher
150:20 - learning rate well let's just see
150:23 - how this
150:25 - i refresh this should be oh no this is
150:27 - still whoa what
150:32 - okay this is insane i've not seen it do
150:35 - this
150:36 - wait but am i loading the correct model
150:43 - yeah look at look at this crazy model
150:45 - what it's like outputting
150:51 - so funny i was there was a time earlier
150:54 - today where my model trained perfectly
150:57 - and now
150:59 - what is going on
151:02 - uh
151:03 - k weekman this is our current
151:08 - setting
151:10 - um
151:12 - where oh sorry i mean the wrong code the
151:15 - current this is the current setting
151:21 - um
151:23 - yeah where's the noise coming from right
151:26 - yeah let's let's
151:28 - let's remove the noise at least in our
151:31 - input image
151:33 - just to see how well the model is
151:34 - performing otherwise
151:38 - um
151:50 - this is so weird
151:53 - the model was trained and has some like
151:56 - i think this is because of
151:58 - relu in the last no
152:04 - i mean where did that noise come from
152:07 - where are those dots come why are they
152:09 - there
152:16 - correct i know everyone in the chat is
152:18 - like 30 seconds behind me but the left
152:20 - is the input image the right is the
152:22 - output and i'm not sure where this new
152:24 - noise is coming from
152:27 - uh the dots are because of the rayleigh
152:29 - on the last layer negative values
152:30 - becomes zeros
152:32 - oh over 255
152:40 - um okay so maybe
152:45 - maybe it's just an issue with me drawing
152:47 - it i have an idea hold on hold on
152:53 - i think there's an issue just with me
152:54 - drawing it so
152:57 - uh where am i
152:59 - where am i getting the values predict
153:01 - await output array output image
153:05 - render output image
153:07 - fill
153:09 - so um
153:17 - let me
153:18 - get that value and let me constrain it
153:23 - to between 0 and 255.
153:35 - no it's still there it's very consistent
153:39 - relu is in the last layer clip the
153:41 - values i thought that's what i was doing
153:46 - um
153:50 - this shouldn't make any difference
154:02 - all right what if
154:07 - hold on
154:12 - if val is less than okay hold on
154:19 - get rid of the constrain
154:21 - maybe what i don't want to do is
154:22 - constrain
154:25 - if val is
154:29 - less than zero
154:30 - val equals 255.
154:39 - let me just make sure
154:41 - i'm actually editing the right code
154:45 - okay
154:59 - i'm totally lost
155:05 - all right try sigmoid okay we're going
155:07 - back to sigmoid people
155:15 - so i want the last layer to be sigmoid
155:20 - and i want
155:23 - to just say atom here
155:30 - this is what i want i want this
155:32 - simplicity and this worked
155:37 - yeah
155:38 - um
155:41 - i mean
155:43 - do i just need more units i shouldn't
155:58 - why why why why why what's going on
156:06 - this was working two hours ago no
156:08 - problem
156:11 - it was training perfectly and it was
156:13 - reproducing it perfectly
156:17 - oh we can ignore this nonsense
156:29 - i mean maybe i should really be
156:31 - controlling the learning rate
156:48 - i'm reading the comments right now
156:51 - and i'm appreciating them i've got to
156:53 - figure this out
157:09 - shuffle i didn't change anything the
157:12 - only weird thing i did was like adding
157:14 - the layers through this weird other way
157:16 - but i don't understand how that could
157:17 - possibly be different
157:22 - and the model summary makes sense
157:31 - i'm so frustrated oh my god it's 1 40.
157:37 - this
157:38 - i have me i have a meeting i have to go
157:40 - to
157:48 - the input is a 56 by 56 image i had
157:51 - upped the resolution because why not
157:54 - i could certainly lower it back down
157:57 - just to like
158:00 - yeah i mean we could lower it back down
158:02 - until everything will run a lot faster
158:04 - let me try that
158:07 - i'll make a new set of images
158:18 - stroke weight at 8.
158:28 - well there we go
158:33 - there we go
158:34 - so
158:42 - okay
158:44 - so why
158:46 - was 56 by 56
158:49 - freaking it out so much
158:52 - like it's really not that different of a
158:54 - problem to learn
158:57 - i guess it's just the orders of
158:58 - magnitude higher
159:00 - all right well i'm going to go with this
159:04 - just because
159:12 - so this has to change i got to change
159:14 - this to 28
159:16 - which would be the only thing that
159:17 - matters
159:25 - this is done
159:31 - okay
159:32 - i must have some kind of
159:34 - scaling thing off because i changed it
159:37 - to 28
159:38 - somewhere
160:00 - i'm not using these anymore
160:05 - where did i mess up
160:07 - this is not a thing
160:14 - this is not a thing i'm doing
160:40 - what is going on are my output images
160:42 - correct
160:51 - no
160:52 - oh no something is totally messed up
160:56 - when i changed it to 28 by 28 that's
160:59 - weird
161:01 - am i hard coding in
161:07 - oh wait no
161:08 - okay
161:09 - 28 by 28.
161:19 - where
161:37 - huh
161:41 - what have i done
161:47 - why did i destroy everything
161:56 - look at the chat regenerate images all
161:59 - right
162:00 - okay okay did i not regenerate the
162:02 - images
162:05 - i didn't regenerate the images
162:17 - is that really true
162:36 - i thought i did but i guess i didn't
162:45 - oh hi gloria
162:47 - gloria woke up
162:50 - oh but now i'm stuck again oh no i'm not
162:53 - okay
163:04 - [Music]
163:08 - okay okay everybody i forgot to generate
163:12 - them
163:14 - gloria
163:15 - come here come here girl you need to go
163:17 - outside huh
163:18 - come here do you want to say hi
163:23 - okay
163:25 - she does not love to be picked up oh
163:27 - come here oh you're a good doggy
163:30 - but she does let me pick her up
163:33 - okay oh yes
163:39 - look at that loss function
163:41 - that is a good loss function okay would
163:43 - you like to go back down
163:46 - okay
163:47 - go back down gloria okay oh god she is
163:51 - shedding like crazy okay
164:02 - okay
164:03 - all right well
164:04 - at least this is working now
164:08 - let me put the noise back in although i
164:10 - had it working at a higher resolution
164:12 - which was
164:13 - nicer
164:16 - oh i'm good i'm gonna lose my mind here
164:19 - let me put the uh points back in
164:25 - and put some noise back in
164:32 - and we're denoising again
164:37 - and we're denoising so now
164:40 - now i can do the latent variables
164:49 - the smooth version of relu is soft plus
164:52 - okay so simon i see your messages about
164:55 - the activation function
165:00 - um so i but i think i'm gonna have to
165:02 - investigate that for right now what i
165:04 - just want to do is see if i can get the
165:05 - decoder only to work okay everybody
165:09 - and i've got 15 minutes to do this
165:12 - so first of all did
165:17 - did i save
165:23 - the decoder
165:25 - yes
165:26 - so this should be the decoder
165:32 - and it has half the number of parameters
165:34 - so that makes sense that it's half the
165:35 - weights
165:38 - so now
165:39 - let's see if i
165:43 - i'm going to make a separate
165:47 - folder called decoder
165:51 - and then i'm going to take indexed
165:54 - index.html
165:56 - sketch.js
166:01 - put that into here
166:03 - and make a folder called model
166:07 - and that will go into here
166:10 - and then in the code where it is saving
166:13 - the decoder
166:18 - um
166:19 - [Music]
166:22 - so many things here
166:24 - i had so many ambitions of like some
166:26 - things i was going to do with this that
166:28 - i am definitely not getting to
166:30 - um
166:31 - if i am the the it should be public
166:34 - decoder slash model it's where it should
166:36 - be saved
166:39 - i just changed it to that
166:41 - now i should be able to go slash decoder
166:44 - this is going to break
166:46 - right okay this is going to break
166:51 - increase either the layer sizes or the
166:53 - amount of training data yes 100 right
166:57 - more layers and nodes but resolution is
166:58 - a matter of data size thank you so if i
167:01 - create some versions of this after today
167:03 - or anybody helps with this i'm gonna get
167:05 - back to a higher resolution but right
167:08 - now
167:11 - this i'm gonna i'm gonna close things
167:13 - because i don't know where i am
167:15 - this is now the decoder sketch
167:19 - and the decoder sketch
167:23 - does not need an input canvas
167:27 - an input it does need an output image
167:32 - which i'm going to make random and we're
167:34 - going to load
167:36 - model.json this is the decoder
167:42 - get rid of this diameter
167:46 - now next image
167:52 - is
167:54 - the i need to make it it's not an input
167:57 - and image anymore it should just be
168:00 - six
168:01 - the decoder should take
168:04 - uh let like the z vector the latent
168:07 - vector
168:08 - should have
168:10 - how many values in it
168:13 - did i end with 8 or sixteen i think i
168:15 - did eight right
168:18 - so this middle layer
168:22 - oh sixteen i i had sixteen okay i gotta
168:26 - redo this
168:27 - with less i wanted to get it down to
168:28 - four but fine 16. that's why i trained
168:31 - the model i have a trained model that
168:33 - works so let's just find out 16 values
168:39 - z index i equals random one so i'm just
168:42 - going to give it a random vector
168:45 - and then
168:46 - x
168:47 - test it's not really a test isn't really
168:50 - exactly right should be
168:55 - just the one z vector
168:59 - predict await
169:02 - and then everything else should be the
169:04 - same
169:05 - except i am only rendering there's no
169:07 - input image anymore
169:10 - i am just rendering the output image
169:14 - and it should be 280 by 280. so i have
169:16 - no idea if i did this right but let's
169:18 - see
169:20 - uh
169:25 - error due to auto encoder
169:27 - so decoder oh this is decoder
169:33 - square was expecting the number for the
169:35 - third parameter
169:41 - let's get rid of
169:44 - doing it again
169:48 - output
169:49 - print
169:54 - so it got a tensor
169:57 - okay
170:00 - weight output array
170:11 - it got an array of values oh i think
170:14 - maybe
170:15 - no i'm filling it at the beginning
170:19 - so let's let's not call this for a
170:21 - second
170:24 - ah
170:25 - w is 28
170:32 - i'm going to look at the chat
170:37 - okay so what
170:46 - it's getting something
170:48 - it's getting
170:51 - 784 pixels
170:55 - i plus j times w
171:11 - oh wait oh let me no loop please sorry
171:18 - but this worked
171:19 - so where was the error
171:22 - and why isn't it drawing anything
171:26 - square is expecting a number for the
171:27 - third
171:34 - oh does w not
171:38 - oh my goodness
171:41 - so for all this
171:44 - sorry everybody
171:47 - i forgot about it's just that
171:50 - okay boy tiny little mistake there
171:54 - so now
171:59 - we should actually be able to
172:03 - all right
172:04 - so that's
172:06 - one image i got from the model
172:15 - uh
172:23 - oh
172:25 - am i supposed to put a weight here
172:28 - i think i might have killed this
172:35 - let's take out that print
172:45 - oh i still have some other crazy console
172:47 - log
172:56 - so i would have expected
173:01 - this model not to produce such
173:06 - like fuzziness
173:13 - but let's just out of curiosity if i
173:15 - give it like all point five
173:18 - yeah
173:24 - hmm
173:31 - oh but this is the input is like part of
173:39 - could it
173:40 - am i like
173:42 - oops no no no no
173:46 - interesting
173:50 - so the question is did i make a mistake
173:52 - somewhere
173:54 - yeah
173:56 - right okay
173:58 - so i guess i can't really i'm not really
174:01 - going to be able to
174:02 - sit onto saying this generate just as
174:05 - just using the d you have to
174:06 - re-parameterize the latent vector
174:11 - so i was going to just make sliders so
174:13 - my my plan was this follows
174:20 - um so take a look at this
174:30 - um
174:34 - uh sliders
174:42 - push
174:45 - create slider so the range should be
174:47 - between 0 and 1
174:49 - starting value of 0.5
174:51 - and an incrementation value of 0.01
174:56 - and then what i wanted to do was have
174:58 - this do sliders
175:00 - index i value
175:08 - output image not being defined what did
175:10 - i do here
175:26 - oh line 34.
175:29 - what did i mess up
175:34 - oh did i lose that
175:39 - i still lost that by accident
175:41 - no
175:44 - oh
175:44 - let sliders
175:48 - equal an array
175:49 - oh not sliders index i sorry
175:53 - okay
176:11 - so i want to get this down to many fewer
176:13 - than just do like four
176:18 - and then see what i could i can see oh
176:20 - this makes it more square
176:25 - squared a circle
176:27 - this parameter
176:33 - yeah
176:35 - i know i know i need to use a
176:36 - variational auto encoder i just thought
176:39 - maybe
176:40 - the scale of relu is unbounded
176:45 - yeah so do i should i change that to
176:47 - sigmoid also
176:49 - would that help
176:51 - or
176:52 - like
176:53 - should i let them
176:55 - like the other thing i could do is just
176:57 - let the sliders
177:00 - have like a really higher range
177:03 - oops i keep doing this
177:08 - right i can get all sorts of interesting
177:10 - stuff
177:22 - all right so why don't i'm going to try
177:24 - the following
177:26 - and i realize i just
177:28 - i keep running this by accident so i'm
177:29 - going to let this run again
177:32 - and i'm going to go back to my
177:34 - model
177:37 - and i would like
177:43 - this i would like this let me get this
177:45 - down to eight i kind of want to make
177:46 - this four
177:49 - and then this activation should be
177:51 - sigmoid
177:53 - meaning
177:54 - these four units coming into here
177:57 - and i could add more layers
178:00 - but i don't know that i really need to
178:03 - um we'll all will be between zero and
178:05 - one
178:10 - yeah and i could look at some of the
178:12 - compressed images to see some values
178:14 - yeah but let's let's try this
178:26 - okay
178:28 - i'm stuck at a
178:30 - loss
178:32 - uh
178:52 - oh so close so close
178:55 - lower latent space i know would give
178:57 - worse results i just don't want to have
178:59 - so many sliders
179:17 - yeah it is good results so far
179:31 - so i
179:35 - is it going to help at all if i add some
179:38 - more layers
179:53 - increase the training data size oh wait
179:58 - oh oh
180:01 - it
180:02 - i just wasn't patient enough
180:04 - it like was stuck and then it caught
180:06 - okay hold on
180:09 - let me undo that let me undo that last
180:11 - little
180:17 - little extra thing i added
180:19 - okay
180:21 - now
180:23 - um go back to the sketch
180:27 - and it's still 16.
180:30 - it's still 16
180:32 - but i used sigmoid
180:39 - yeah this is much better
180:47 - it's just
180:48 - too many
180:50 - latent there we go
180:55 - so i'm able to control all the different
180:58 - variables
181:00 - and i can kind of try to figure out
181:02 - which ones do which
181:04 - i'm trying to figure out how to make
181:09 - whoa
181:10 - there certainly is some
181:13 - extra weirdness here
181:24 - anyway this is exciting but i i really
181:26 - want it to be like eight
181:30 - so what if
181:33 - let me let me just
181:35 - it's two o'clock so i've got to be done
181:38 - i can't believe how much time i spent
181:40 - doing this
181:41 - um
181:43 - but this will be my last attempt
181:47 - i'm just going to like
181:48 - pump it up a little bit
181:51 - i don't know that this matters
181:57 - i'm going to give it an additional layer
181:59 - with 64.
182:01 - i'm going to keep the 16.
182:04 - i really think i should be able to get
182:05 - it down to 4.
182:08 - then i'm going to put it down to 4 and
182:10 - make that sigmoid
182:14 - then i need to add back in
182:22 - a 16
182:26 - and a 64 right
182:30 - and should i make many more training
182:32 - images is that going to help me
182:35 - like if i make um
182:39 - 2100 i'm going to double the training
182:41 - images
182:46 - i really want i really want it to be
182:49 - all right let's do let's do 50 100
182:51 - images i'm gonna get it down to four and
182:54 - i'm gonna let it train for 200 epochs
182:59 - um
183:02 - 200 image so this has to be
183:05 - 5 000 i know i need to make the images
183:08 - and 5 000. we run this
183:15 - i could also constrain the squares and
183:17 - circles to be less
183:20 - yeah so flubby everybody's telling me
183:22 - this really good suggestion which is to
183:24 - pass images through the encoder and look
183:26 - at latent vectors because that would
183:28 - certainly
183:30 - help give me a sense and that's
183:32 - a very important uh analysis that i
183:34 - could do
183:36 - right two should be enough one for the
183:38 - type of shape and one for the radius
183:54 - this is going to take a while i'm still
183:55 - just generating the training i'm just
183:56 - going to tell you about today's sponsor
183:58 - curiosity stream are you still watching
184:01 - this have you been watching this for
184:03 - three hours
184:05 - i can't believe how much time i'm
184:06 - spending on this auto encoder i hope
184:08 - that this will
184:09 - add to my life in some meaningful way
184:19 - this has got to be the last attempt and
184:21 - now that i have a model for this i can
184:23 - off on my own and you i'm going to push
184:25 - all this to github
184:26 - all of you can try
184:29 - tweaking this in different ways and let
184:30 - me know
184:32 - what configuration architecture of the
184:34 - model
184:35 - how many units you're able to get them
184:37 - to
184:39 - what i'm missing here i will accept pull
184:41 - requests because this is my last live
184:43 - stream one more line needs to be
184:44 - modified from one thousand to five
184:46 - thousand okay where's that
184:49 - i think i got both of them
184:51 - oh is it where i'm loading the images no
184:55 - i think i'm good
184:59 - i think i'm good
185:02 - yeah think of how many eternal rainbows
185:04 - you could all be has anybody
185:07 - signed up for curiosity stream and
185:08 - watched the rainbow documentary you
185:10 - could have watched it like 10 times
185:12 - crossing stream flat coating train
185:20 - okay
185:21 - okay
185:22 - let's try this
185:29 - okay
185:31 - okay
185:32 - patience
185:34 - patience everybody
185:39 - line 17
185:44 - oh
185:45 - thank you
185:47 - [Music]
185:50 - got it
185:51 - [Music]
186:01 - oh this took a long time
186:03 - [Music]
186:09 - come on lower that loss
186:12 - you can do it lower that loss
186:18 - [Music]
186:21 - oh yes
186:23 - [Music]
186:28 - oh i like that i like that oh my god
186:35 - somehow i signed up for 200 epochs of
186:37 - this
186:40 - [Music]
186:42 - yeah so
186:44 - more data
186:45 - was clearly something i needed to do
186:48 - i also added more layers
186:53 - how long is it taking
186:55 - three seconds
186:57 - per epoch
186:59 - so i got like a little bit more so i got
187:01 - like 600 seconds left to go
187:04 - 10 minutes
187:05 - [Music]
187:08 - i mean i'm not going anywhere
187:11 - [Music]
187:14 - oh this is just the last live stream
187:16 - related to this auto encoder decoder
187:19 - project i mean i'll probably come back
187:24 - [Music]
187:30 - yeah i've got a really nice gpu sitting
187:32 - over here on the machine i'm using
187:33 - stream
187:36 - well the point of doing this was just
187:38 - like
187:39 - little bits of data
187:40 - [Music]
187:45 - oh that is a beautiful loss as soon as
187:47 - that scientific notation comes in
187:52 - i definitely do not need 200 epochs
187:55 - but i'm afraid to stop it
187:59 - [Music]
188:01 - oh yeah everybody
188:02 - while this is training
188:04 - you should sign up
188:06 - for the one year
188:08 - curiosity
188:10 - package
188:12 - it's less than it comes out to less than
188:14 - one dollar per month
188:16 - i'm not talking about less than one
188:17 - dollar per day
188:19 - [Music]
188:32 - at the local coffee place it's very
188:34 - expensive
188:36 - two cups of coffee for the entire year
188:38 - there you go two cups of coffee you know
188:42 - i get the oatmeal which costs 50 cents
188:44 - extra and then you can just watch this
188:46 - documentary about rainbows which is 22
188:48 - minutes long
188:50 - over
188:51 - again you can tweet me and say
188:54 - thank you so much i watched the rainbows
188:56 - over and over again
188:59 - mark edward
189:01 - i haven't so my battery died simon
189:03 - [Music]
189:10 - ah pca
189:12 - yes
189:13 - code parade was doing projects like this
189:16 - uh so wait hold on
189:19 - come back
189:20 - see how this is going
189:22 - uh we're at epoch 63.
189:25 - oh why didn't i put in the lower north e
189:26 - box i just i could put in 150 epochs run
189:30 - it again
189:31 - but it's still going down let's get it
189:34 - let's let it
189:35 - look simon says oh
189:37 - sorry this
189:38 - i guess i could try to plug this in
189:40 - do i have a plug for it somewhere
189:45 - code parade was doing some projects like
189:47 - this the music was loud sorry about that
189:50 - i thought i turned it down
189:56 - um it always saves models every 10 ebox
190:00 - i know i don't think i put that in there
190:02 - i don't think i added any code to like
190:04 - save the model every so often
190:06 - and it's not improving anymore oh no
190:08 - there we go huge jump down
190:10 - um but simon is suggesting that i can
190:13 - use
190:14 - basically uh pca or principal component
190:16 - analysis to sort the sliders from most
190:19 - to least
190:21 - important um
190:30 - if you change your clock on your laptop
190:32 - it would already be finished
190:34 - don't think that's how it works
190:36 - hold on i can send some important text
190:38 - messages i'm going to be done in 10
190:40 - minutes
190:42 - okay
191:08 - uh
191:11 - like the nice thing is didn't get very
191:13 - cold in here sunny out
191:16 - um
191:17 - where's gloria hopefully gloria didn't
191:18 - like
191:19 - pee somewhere because it's i've been
191:22 - taking her outside and this whole time
191:23 - i've been live streaming
191:25 - um
191:28 - are we i've lost track of what the loss
191:30 - is doing
191:34 - oh yeah it's going down further because
191:35 - i've got a
191:39 - if anybody could work out the sort of
191:41 - time travel i mean i just have to let it
191:42 - go at this point um i'll answer
191:44 - questions i don't know i could i could
191:45 - do some other work i could tell you more
191:47 - signing up for curiosity stream
191:51 - uh oh okay mark edwards today i just got
191:53 - here can i get a quick recap
191:56 - yes thank you for asking
191:58 - i'm gonna move over here just to have
192:00 - just to like get my legs moving a little
192:02 - bit so i'm building this is now my
192:05 - fourth live stream
192:06 - i'm building an auto encoder project
192:09 - and i'm using the tools of tensorflow.js
192:12 - which is a machine learning library in
192:13 - javascript and p5 which is a creative
192:16 - coding library in javascript that is
192:17 - good for like drawing and animation
192:19 - images
192:20 - i this diagram is completely sort of
192:22 - like not that useful anymore so me
192:25 - standing by it take that for what it is
192:27 - but um an auto encoder a great summary
192:30 - of what an auto encoder is you can find
192:32 - in this two minute papers a youtube
192:33 - channel
192:35 - what is an auto encoder and the idea
192:38 - is for a neural network to learn
192:41 - the um
192:42 - like a sort of like lower dimensional
192:44 - representation of
192:47 - an image
192:48 - that's a terrible way to explain it
192:51 - an autoencoder is a mechanism for taking
192:53 - an input image and copying it to an
192:56 - output image which is a very simple
192:59 - thing to do
193:00 - with just basic image processing
193:03 - algorithms like
193:04 - take every pixel copy every pixel but
193:07 - the hook here is that the auto encoder
193:09 - is not just taking all the pixels and
193:11 - copying them to the output it's sending
193:13 - all the pixels through a neural network
193:15 - that with each layer of that network has
193:18 - less and less and less numbers that it's
193:20 - allowed to work with so it's like an
193:22 - image compression algorithm and then a
193:24 - decompression algorithm can the neural
193:26 - network
193:27 - learn
193:28 - how to
193:30 - um sort of encode the represent encode
193:32 - an image into a smaller number of
193:34 - numbers and right now i'm actually
193:35 - trying to take these images of simple
193:38 - shapes they're squares and circles and
193:39 - encode them down to four numbers and
193:41 - really it should just be two
193:43 - theory we should be able to do two
193:44 - because there's only two variables it's
193:46 - either a square or a circle and it's the
193:48 - other variable is how big is it
193:50 - but i'm going with four
193:52 - so i have that
193:54 - working i've built all the code for it
193:58 - now i am training the model and i i just
194:01 - put in 200 epochs because
194:05 - i wanted to give it enough time to train
194:08 - and then when it's done
194:10 - what i hope to see this was like an
194:12 - earlier version of it is something that
194:15 - produces a much higher quality image
194:17 - than what you're seeing in terms of like
194:20 - it appearing to be a circle or a square
194:22 - and that i only have to play with four
194:24 - sliders to kind of manipulate it that's
194:26 - what i'm going for
194:31 - is there an epoch training dance
194:34 - no i'm so tired and hungry and exhausted
194:38 - and lost
194:40 - that i don't have one but if i could get
194:42 - it back
194:46 - it was only like
194:47 - [Music]
194:50 - this is how i feel this is my epoch
194:53 - training dance
194:58 - 164
195:07 - [Music]
195:12 - 168.
195:17 - yes yes so mikhail is this i love this
195:21 - comment i still don't get how the
195:22 - compression works you've gone from shape
195:24 - and radius to shape and radius and a few
195:26 - hundred kilobytes of weights so to be
195:28 - clear
195:30 - i'm not actually doing anything of any
195:32 - utility whatsoever
195:35 - i'm trying to demonstrate the concept
195:39 - to and to help my understanding of how
195:43 - to architect
195:44 - machine learning models
195:46 - how to experiment with them
195:48 - how to
195:49 - perhaps make creative output with them
195:52 - and in a way like
195:53 - the concepts that i'm demonstrating with
195:56 - this very very basic
195:58 - scenario
195:59 - would hopefully extend how the music is
196:04 - would hopefully extend
196:06 - to
196:07 - use of say something like a more you
196:10 - know a gan or a style gan model sort of
196:13 - like looking at how generative models
196:15 - work thinking about how latent space and
196:17 - latent variables work i'm hoping that
196:19 - this whole process
196:22 - could
196:23 - um
196:24 - could provide something
196:26 - of note there but yes i mean i could
196:28 - write the code to just make the slider
196:31 - to a button and a slider and just
196:33 - manipulate them to get a circle or a
196:35 - square of a variable size
196:38 - um so there is um
196:41 - a coding trained group this is uh sa
196:43 - mckenzie asks i'm sorry if i tell me how
196:45 - to fix my name pronunciation um are you
196:48 - doing advent of code this year not so
196:50 - much personally although maybe now i
196:52 - might have some time to
196:54 - i'm just on my own but i don't think
196:55 - i'll be streaming it
196:58 - but there is a coding train advent of
197:00 - code team
197:01 - or whatever it's called and you can um
197:06 - if you're in the discord somebody please
197:08 - post the discord link
197:10 - you can find out information about
197:11 - joining and having your advent of code
197:13 - contribute to the leaderboard uh kobe
197:15 - who is the discord manager is organizing
197:17 - that so apologies for not knowing too
197:18 - much about it but you can definitely
197:20 - check into that
197:26 - yes so this is the older version with a
197:28 - less a poorly trained model and 16
197:31 - latent variables
197:32 - when this finishes oh it finished oh my
197:35 - god
197:36 - so let's just look at this for a second
197:38 - 256 128 64 16 4. 16 64 122 okay that's
197:44 - right now hopefully
197:47 - oh it's a made-up name essay mcquenzy so
197:50 - it's a made-up name i don't know how
197:51 - it's pronounced great my friend seizure
197:52 - was great okay so now
197:55 - if i come back to my sketch that loads
197:58 - the decoder only
198:00 - i should be able to do this with just
198:02 - four sliders
198:03 - i think that's the only thing i need to
198:05 - change
198:06 - let me just make sure was this
198:09 - a new model from 2 16 p.m all right
198:12 - everybody i really should not do this
198:15 - any time and every time i've ever played
198:17 - this
198:18 - sound effect means it's not going to
198:20 - work
198:21 - but i'm about to hit refresh
198:23 - and hopefully we're going to see a nice
198:25 - squirkle there in the center
198:27 - four sliders that allow me to
198:37 - wait okay
198:39 - reading value undefined hmm
198:43 - at least it was just a syntax error ah i
198:45 - hard coded
198:52 - late in total equals four
198:56 - now that was
198:58 - anticlimactic
199:05 - okay
199:11 - i'm so excited
199:14 - oh let me tell you about today's sponsor
199:15 - oh no sorry sorry sorry okay refresh
199:20 - oh i like it i like it
199:25 - okay circle to square
199:28 - to square okay interesting
199:34 - so
199:34 - how what these variables do
199:36 - your guess is as good as mine
199:39 - maybe i um and i think i would love to
199:41 - do the random walk now
199:46 - but this is really
199:49 - really everything i ever wanted
199:52 - in an auto encoder
199:54 - latent vector exploration
199:57 - p5.js sketch
200:07 - i've only had an hour until i have a
200:08 - meeting in 10 minutes and i was planning
200:11 - to eat lunch in between this live stream
200:13 - and this meeting and answer all my
200:15 - emails and do everything else i needed
200:16 - to do
200:17 - so i can't do the random walk part
200:20 - uh because i would be like oh i have 10
200:21 - more minutes i'll do it
200:23 - i have to just stop
200:26 - but um i will do that on my own let me
200:28 - push the code
200:32 - so the new things i'm adding are
200:35 - adjusted the data generation
200:38 - i guess this uh i added the the node
200:41 - cert the nodes
200:43 - code now trains the model and siphons
200:46 - out the decoder only
200:48 - i've got a new model
200:51 - and a new sketch
200:52 - a new model adjusted the sketch a little
200:54 - bit and then there's the new decoder and
200:57 - then i saved that earlier squirkle model
201:01 - so let me add all this
201:05 - live stream 4.
201:10 - um and if you're wondering oh
201:16 - if you're wondering
201:22 - um oh those models must be big
201:28 - if you're wondering where you can find
201:29 - all this
201:33 - um
201:36 - oh yeah
201:38 - it's here
201:39 - so
201:41 - uh
201:42 - i will accept i'm accepting now um
201:46 - pull requests on this
201:48 - um this was super helpful the way that
201:52 - java gt wrote an issue just to explain
201:54 - some improvements and some ideas
201:57 - i think this project is in a place where
202:02 - i can
202:03 - accept pull requests again i'm not at
202:05 - the moment looking to totally refactor
202:08 - it i i i need to write a message here
202:11 - because i've been i reply to this via in
202:13 - my like live stream many times i want to
202:15 - thank the chief here
202:17 - chief um
202:18 - for this incredible refactoring and
202:21 - contribution but it's too different than
202:23 - what i wrote during the live streams so
202:26 - i would love much rather link out to
202:28 - that but if you can help sort of
202:30 - optimize the sort of like architecture
202:34 - uh the learning rate
202:36 - um so that could get slightly higher
202:37 - resolution
202:39 - i think having four latent variables is
202:41 - good like little design improvements i
202:42 - would gladly take those
202:44 - um
202:45 - but i would very much especially love
202:47 - just documentation so images screenshots
202:50 - gif animations explanations in the
202:52 - readme it's not really your job to do
202:54 - that it's mine
202:55 - but if you're looking to contribute i
202:57 - gladly would take any form of
202:59 - contributions i'm going to put this to
203:00 - bed
203:01 - i think i've only got one more thing on
203:03 - the docket for
203:05 - uh 20
203:07 - 21 and then i'm hopefully relaunching
203:09 - the coding train and new in 2022 it will
203:12 - be the processing foundation end of year
203:14 - fundraiser i think that's going to
203:16 - happen now
203:17 - probably the 20 it's going to happen
203:19 - after christmas before new year's
203:21 - so uh stay tuned sign up for the discord
203:25 - thank you
203:26 - to um
203:28 - sponsor uh please check out i'm you know
203:30 - uh curiositystream.com codingtrain for
203:33 - full access to over a thousand over a
203:36 - thousand documentaries everything that's
203:38 - on nebula all the extra content so many
203:40 - wonderful educational creators for less
203:43 - than one dollar a month for the whole
203:44 - year it's 11.59
203:46 - special 42 off discount check that out
203:49 - and um i really appreciate all of you
203:52 - sticking with me for this
203:54 - and
203:55 - um
203:57 - i will see you
203:59 - on the next live stream and i'm looking
204:01 - forward to all sorts of new content and
204:04 - community initiative now is the time to
204:05 - join the discord if you want to have a
204:07 - voice in the future of the coding train
204:09 - join the discord
204:10 - i would love to see you there
204:12 - um goodbye i gotta go i gotta i gotta
204:15 - have another meeting in like literally
204:16 - seven minutes i'm gonna do it from right
204:17 - here just i gotta sign out of this
204:19 - computer but hopefully i won't still be
204:20 - live streaming by accident it's the zoom
204:22 - call so i gotta i gotta play my outro
204:25 - music and all of that uh thanks
204:27 - everybody goodbye see you soon oh my god
204:31 - i cannot believe i cannot believe this
204:32 - day maybe i'll make the random walk
204:34 - happen uh just really quickly while i'm
204:35 - playing the outdoor music that's a good
204:37 - idea
204:39 - i didn't even find the outdoor music i
204:41 - don't even know what the outdoor music
204:42 - is anymore as always i always forget
204:44 - that this stop this stock this stop this
204:46 - stop i'm gonna do this stop this stop
204:48 - i'm gonna do this this stop this stop
204:50 - this stop i'm gonna do this stop
204:55 - [Music]
205:25 - [Music]
205:32 - this dot
205:33 - [Music]
205:47 - this dot song never forget this dot
205:50 - [Music]
206:02 - i'm gonna say once again here we go sing
206:05 - it with me
206:09 - [Music]
206:15 - it's look forward to cartesian
206:17 - coordination
206:19 - [Music]
206:33 - autotune and the internet will fix that
206:35 - for me
206:40 - take it with me
206:43 - to cartesian
206:44 - [Music]
207:03 - [Music]
207:09 - unicorns and rainbows and cupcakes what
207:11 - else is
207:12 - there
207:14 - yes kittens thank you very much kittens
207:16 - and rainbows and cupcakes notice that
207:19 - look what i get
207:20 - i'm really losing my mind
207:23 - okay let's do it
207:25 - [Music]
207:42 - and kittens the kittens getting some
207:45 - kittens and kittens the kittens the
207:50 - kittens the kittens kittens and kittens
207:54 - and
207:56 - [Music]
208:07 - i just quickly adapted this to move the
208:09 - sliders randomly
208:11 - which is sort of demonstrating
208:13 - a uh oh yes i wanted my stream called
208:16 - three minutes okay goodbye everybody
208:18 - that's hilarious
208:20 - i'm going i'm muting my microphone now
208:21 - i'm gonna let this play for another like
208:23 - few seconds
208:24 - just to the end of this song it's got
208:25 - one minute 30 seconds on the song bye
208:27 - everybody
209:22 - over again
209:24 - all sorts of text generation analysis
209:26 - things
209:27 - that i will use continuously over and
209:30 - over again
209:31 - first thing i need to do is yes
209:37 - okay we're gonna do it
209:39 - kittens the kittens the kittens and
209:41 - kittens kittens and kittens and kittens
209:42 - and kittens kittens the kittens and
209:44 - kittens and kittens kittens and kittens
209:46 - and kittens and kittens kittens and
209:47 - kittens and kittens and kittens kittens
209:49 - and kittens and kittens and kittens
209:50 - kittens the kittens the kittens have
209:52 - dusted
209:54 - [Music]
210:09 - you

Cleaned transcript:

do hello do do do do hello good morning or afternoon good evening a little bit of a sound check here quick sound check um there's probably a loud pun because i am currently running the heater in the garage but other than that let me know how my voice is sounding and i'll be getting started in approximately two and a half minutes do do me do do hello happy monday welcome to another session of the coding train my name is dan i will be your 2 conductor for today's session i'm still setting up a few things here and there last time i forgot to record my session to disc uh so i am going to make sure that i do that this time and i want you to think about today's sponsor of the coding train as i go and set those settings today's sponsor is curiosity stream uh let's see how come that did not open obs 64. oh obs is already running launch anyway yes okay thank you and now i am going to hit um start recording and there we go all right so um boy boy am i unsure about what's happening in the world of the coding train but i am preparing i don't know where it is maybe this is it this here is a stool a stool actually it's like one of these weird stools that like you sit on and it wobbles it's supposed to be good for your back but i am now hereby proclaiming that this is a reset button it's a giant reset button and very soon it will be 2022 and i am going to place my bell on top of the reset button and i can't do it now the ball will drop drop onto the bell we'll make that sound uh and i'm gonna everything's gonna be reset um in the year uh 2022 because this boy um and um this has really been quite a difficult uh i know year two years for so many people just for me speaking personally just a really difficult month of december and i haven't been able to sort of keep up with the pace of sort of coding train activities like i would really like to but i'm finishing up a whole bunch of things and have this clear path ahead of me so this is the time by the way if you ever wanted to get in touch with like your suggestion of what you think the coding train should really be should it really just be daily live streams every day should it be more sequenced video tutorials should it be project videos should it have high production value low production value uh should should it have a brand new website that allows you to share all the things you're making based on the coding trade videos back should we be doing more things on social media should coding train have a tick tock i'm thinking about all these things and um ramping up my plans to uh to activate uh all of the all of the cars on the train and the various different engines and the components it's all gonna happen in 2022 but here i am still in 2021 just eeking out one more live stream there's gonna be another one at some point i really would like to do my annual holiday slash new year's processing foundation telethon to support the work of the processing foundation i think this is this is not official yet this is unofficial this is like a little unofficial preannouncement announcement i think it's going to happen after the christmas holiday but before new year's um this year i don't think i can get it together to do it this week or next so most likely my uh new the holiday livestream which will be a new year new year live stream launching the new year of the coding train will happen it's probably i'm gonna guess uh december 29th or 30th or 31st one of those dates if you want to be the first to know when i've scheduled it you should sign up for the coding train discord i just pressed a button and i don't know if that message is going to go into the chat didn't seem to do it but it's uh codytrain.comcodingtrain.comdiscord discord.gg codytrain somebody will put it in the chat hi peter glad that you're here catching the stream um but uh what am i talking about if you want to be the first to know about when this special endofyear new year spectacular coding train telethon spectacular will happen maybe i'll even break out my ukulele to sing a new year song would you like to write that song the lyrics of that song get in touch because i got nothing i got nothing if you want to be the first to know sign up for the discord because the discord oh it has this new feature let's see if i can even show it to you um i'm going to open up discord here on my computing machine that you cannot see just yet oh no okay wait wait wait this is fine i have to log in everything's going to be fine it's got this magic qr code thing so this is really what i should be doing on a live stream i should be logging into things start talking um i'm talking already i don't need to start talking discord why you're reminding me if i had a cohost i wouldn't have to just continuously speak the entire time i should be good with the silence or i need more music going on um now let me just do this little special trick thing that i'm going to do then let me go back to ah the coding train oh i'm really doing something very important but you can't see it because otherwise it will reveal all of my coding train oh my god secrets um um we wouldn't want to do that um now okay yes yes yes no no no i got one more button to press boy i really should have prepared this did i tell you about today's sponsor look at that well i'm still doing this hidden option command i uh turn this off oh boy this was boy this was worth the wait everybody oh you have no idea what's coming to you you have no idea the excitement i'm about to show you such a letdown but you'll see here in the coding train discord now has this events feature so whenever i have a live stream event i schedule it in the discord which there's a way for you to get a notification about that you can see the youtube link the details about it multiple it's if it's happening now it have a big happening now button so i fully expect that there are now hundreds of thousands of viewers in real time the kodi trade right now because of this new happening now button thing card tag discord extravaganza all right so um you can also just subscribe to the youtube channel and there's like a bell or something it'll also give you a notification in theory when i schedule the next live stream uh and simon is reminding me um in the member discord remember oh remember when you did advent of code on the stream yeah december is i really want december to be like a really active month of streaming and coding and fun but it's just not happening this year but mark my words streaming and coding and fun and all of that stuff is coming in next year so what are we here to do today if you've enjoyed my last three live streams do i have good news for you i'm gonna be continuing the project this is kind of a new thing that i started which is i'm just going to come back over here for a second which is to work on a larger project over multiple sessions i don't know how effective or entertaining or insightful this is so right now the kinds of things i do in the coding train are divided into sort of different different buckets and actually one thing i might just do right now just to talk about that for a second is to come here to the channel so this is great for anybody who's who's new uh today so i have what the most popular thing that i do which youtube likes to tell me is very popular are these coding challenge videos from at least four or five years ago so apparently the way that i work is i discovered something really popular that people love and want to get more of and then kind of went did something different but so uh these are the coding challenge videos they're sort of standalone oneoff videos where i build a project i also have and this is kind of where what i'm kind of very much dedicated to always having at least this feels very primary and fundamental to me um hi christine in leeds england welcome to leeds england lovely to see you here um these are the sort of sequence tutorial videos so first of all if you are new or if you have a friend who's like oh i'd love to learn to code or where should i start or i'm interested in generative art or creative coding or javascript this playlist is for total beginners and one of the things that i have been doing and the reason why i like having it sectioned into different videos is because i can over time replace them so if i look at this right now these were um you can see like these are from three years ago the sort of intro to the series and using the web editor then all of a sudden oh yeah then we still got three years ago then all of a sudden we go and we get some videos from six months ago more gray hair so these were so out of date and old that i started to replace them new thumbnail style i don't know what people think of that um but then we go back and we continue like suddenly then the video goes to six years ago so definitely high on my list is anything that's five plus years old in this sort of tutorial series i want to redo i have been working this is what i'm kind of focusing on today i would like to make a video about auto encoders uh matt is saying i could probably get a cohost in songwriting help from gpt3 great point actually that's been my sort of pet procrastination project is playing around with a lot of the new large language models that are available through open ais gpt3 and also hugging face uh hosts a tremendous amount of different language models with lots of exciting applications although i think it's important to be very cautious and conscientious when using these large language models so there's a lot to say about that um nature of code is a big project for me in the new year i don't know where i'm scrolling so oh so so but what i was talking about which i wanted to just sort of get off my chest here is that standalone project videos like these sequence tutorials and then if i go to live streams i thought there was a place where i could just see like my live stream playlist i'm not seeing it i'm not going to to try to find that now but that's what you're watching right now apparently 166 of you lucky lucky lucky people are here with me um and uh would you redo the game you started says nico writes would you redo the game you started with the triangles moving around the map on their own i'm not sure what the pot redo them but never remove them yes so this is a good point i am i have no plans to ever delete any of the older videos and in fact um another way to browse the videos is through the coding train website and if i go to beginners if you really enjoy the sort of classic coding train style uh you can find these really ancient uh intro to processing tutorials which are even though it says 2015 i'm pretty sure these were recorded in 2012. it's just that i only got around to uploading them to youtube all at once on july 10 2015. ah time flies i'm getting older too what's that song that i'm thinking of you're getting older i'm getting older too i don't know i'm getting older you're not you're you look lovely you look beautiful you look younger than you ever have and actually the irony here is while i'm talking to you the viewer i'm just staring at an image of myself so i'm saying it to me but really i'm saying it to you all right we got to get we got to get moving here i've been alluding to it i want to tell you about the best deal in streaming available today oh anything think of any streaming service with any content i have to tell you about the best deal available better than all of the ones you're thinking of um so how do i get to it if i go to youtube.com the coding train and the community tab i just made a post about it and here it is holidays start early so um you've heard me talk about this before um it is the curiosity stream and nebula bundle it gives you access to all of curiosity's stream tons of educational documentaries nature science math um just nature nature nature nature those are the ones that i love so many amazing documentaries and with it you also get full access to nebula which is a streaming service that my content is on you can even see here this picture so all ad free if there's any all sponsor free um really nice player you've got like a roku app and a fire tv app some new stuff um i think i wrote about it here um picture and picture on ios and like i stole this from renee ritchie who is i'm a big fan of all for less than the cost of a usb dongle so um you can get all of the nebula content all of curiosity stream thousands of documentaries for less than 12 a year this is exclusive only for the holidays it's a 42 discount 11.59 uh if you sign up through the link it's pinned in the chat um curiositystream.com codingtrain so if you're wondering like what's a way for you to support the coding train actually going to that link and signing up will uh supports me and supports all these other wonderful creators that are on nebula i'll come back in the middle and just basically say what i just said now again but if you have any requests to poke around and look at anybody's any particular content i can make some recommendations for you all right now coming back i am really excited about this project uh because it is one of these things like uh as simon likes to tell me um wait i'm sorry i'm reading i'm reading the the chats in multiple places uh thank you viveshop vivesvan um simon likes to remind me um i have this habit if i go to the rainbow topics github repository i have this habit of making these like todo lists fall 2020 spring 2021 summer 2021. notice i didn't make one for fall 2021 i was like forget it i just make the todo list don't get to anything that's on it i think i would really like to make one for 20 20 20 20 20 20 22 and uh really develop a schedule oh something that i'm thinking about tell me what you think about this here's an idea for you uh think about like some cool illustration graphic design twitch tuesdays coding train twitch tuesdays like a little music bump or something um i think you've experimented with streaming on twitch but that's so cheap so a little different vibe try some more interactive features something i'm thinking about um but i believe like if i just go to summer 2021 you can see all these lists of things that i want to do and on the list it's been there so many times auto encoder so vivisvan asks what are you building today auto encoder except i'm not really building it today i am finishing it today i have been building it you have guess what you have about six to seven hours of old content you can go back and watch so i have been working on this auto encoder uh with tensorflow.js and p5.js uh for the last three live streams i don't think i should go past this one and the thing that i'm thinking about doing and i would love to hear from you is then um not on the level of say like two minute papers or some other like three blue one brown is another channel that i love sebastian lag um jordan herron i'm just naming youtubers that i like but um but i am thinking about what would it mean for me to do a scripted i know shocker scripted video about what is an auto encoder and how to build one using tensorflow.js and p5.js and cut and paste that's not the right term for edit together highlights from the live stream sessions with narration and some additional demonstration and that could be maybe in 20 minutes that's kind of a goal that i have the only video that i've done anything remotely close to this is the mouse learning um let's see if this comes up um this this video if you haven't watched it um let me just pull this up for a second um this is a video that i made that had a script and um i love you too do do do venom okay you just made me say doo doo venom that was a trick good job uh and andrew's asked me i've looked at advent of call so uh if you haven't watched this video i would love for you to go check it out and tell me what you like or didn't like about it but the idea here is could i um could i could i pull could i could i kind of have the best of both worlds like one of my mantras one of the things i really try to do is show every every every piece of building a project start to finish and all of the pain and bugs and mess in between at the same time how many of you realistically if you're like i want to learn how to build an auto encoder oh there's seven hours of video i could watch where at the end you get a fuzzy circle um really have the time for that or going you know is that really going to be uh useful for you so i want to try to have the best of both worlds that's something that i'm thinking of planning to do matt says great plan matt gorbay gorge from the french gold no maybe sorry if i'm butchering your name um so um that i am thinking about um um doing so anyway new area of exploration look at all this stuff this this so much stuff that i want to do oh remember how i was going to do these i actually i have some like just videos that i sh recorded and they're kind of like half edited that i never got together to finish uh so much oh plotter i want to buy a plotter so many i want to get a knitting machine so much to do in 2022. i'm a poet and i didn't even know it all right so let's get back to the task at hand before i take up too much time with this introduction to today's session thank you for everybody too for being here let me go to terminal i'm going to walk you through now all the pieces of the project that have already been built so first piece is a processing sketch to uh generate training images for the auto encoder and i realized that if you're totally new and haven't tuned into the last three live streams the question what is an auto encoder might be on your mind i'll come to that at some point i'm sure i won't be able to help myself but just imagine at least for the one sentence version i'm using an auto encoder to create images in the style of an existing data set and this here if i run this sketch this is now generating that existing data set it is just a series of random circles or squares um um i believe i'm making some number of them as we will find out i'm making 1100 of them so at some point it will stop and we can see now in this data folder here are all these images that i generated so i'm hoping by the end of today i can try to work with something more sophisticated should i try to use letter forms color different kinds of shapes i'm not sure yet more abstract patterns again i don't know um but let's leave that oh fractal trees we could try that would be kind of interesting learn blender so sake yeah i kind of into this idea of learning unreal engine and then turning this garage into a like a virtual set i have this huge garage now can i make it into a volume like the mandalorian set and just put like screens over everything instead of a green screen that just actually be this giant screen behind me now i don't have the budget for that i'm going to need a lot of you to sign up for that curiosity stream bundle if i'm going to do that ah and andrea asks are you working on a new version of the nature of code um and stig writes um oh just crack the playback speed to 28x i hope by the way all of you just watch me on 2x i mean obviously you can't right now well maybe good no touch designer i don't think is for me i appreciate the suggestion from rodrigo but probably not for me um wait wait wait i was talking about something generating images we're doing the auto encoder let's talk about the mandalorian set ah nature of code it was andrea's question uh yes so i you know i don't know why i'm dancing around this i am on sabbatical starting it's actually not the you know i still have a lot of admin and other uh nyu related responsibilities that i'll be continuing to do for the first three weeks of january but my sabbatical from my teaching job begins january 24th um i don't i'm not suddenly going to be full time coding train but if i'm at best you know one fifth time right now one eighth time right now coding trade honestly this month um i'm hoping to ramp up to like a quarter time a half time like really spend two or three two to two like at least two full days per week working on coding train um i also i've got a um there's an expression that uses naughty language if you will that i'm not going to say i have to like do something or else get off the other thing i got to do this nature of code book like it's now and forget it like if i don't have a new version of the nature of code book done in 2022 forget it it's never gonna happen you heard it here first mark my words sign me onto the piece of paper everybody record this broadcast it put it out into the universe i'm either going to have a new version of the nature of code book completed that means you can buy it a print version and it will be all online for free as a website both of those things by the end of 2022 all with p5.js a new chapter on neural networks if that's not done that's it that project is dead i don't think i'm going to do a kickstarter for it which is what i did for the first book i think i've got enough kind of momentum with the sort of support but so those of you who are supporting the coding train whether it is signing up for a membership supporting the sponsors um all the other kinds of ways just watching tweeting sharing recommending it to your friends all the things that all of you do that i so appreciate um i think that's enough to kind of keep me going in terms of nature of code book um yeah uh unity and godot would be better alternatives to unreal says uh simon okay i'm gonna take that advice very seriously um and thank you kathy wrote this really uh oh nicole shader expert nicole is in the chat oh shaders i actually really would like i don't know if i'm qualified to do this i got to see uh the great pattucio author of the book of shaders i'm in new york city recently and i said oh thank you thank you thank you thank you thank you thank you i feel like that's what i people sometimes like have that reaction to me and i'm like no no no no please no stop oh no no oh if you insist and then i get out my ukulele and play them a song no okay um christmas gift yes okay um nicole uh thank you for your help when i tried i stumbled through learning shaders thank you of course to eliza and aletheia in the uh curiously minded stream i was thinking i might like to do a little basic introduction to shaders as like similar to my intro to p5.js but i don't know i i to do that i really have to think about how i'm kind of crediting um all of the sources that i'm sort of learned from i mean this is something that i do throughout throughout everything but also like whether i'm really the right person for that i mean in some ways i lo that's the idea of the coding train like i'm a beginner at this too so let's learn together i have to think about how to do that effectively okay um yeah uh nicole you are an expert relat in my eyes but no one expert is uh just a word that maybe we should just remove from the vocabulary here i mean it's it's nice to be an expert in something but i feel like in the so i don't there's nothing wrong with being an expert people who are experts should be celebrated for their expertise especially in like the sciences and things that we sort of like rely on to keep our world turning and our society moving forward but um in the in creative coding i like to think of all of us as um expert amateurs or amateur experts i'm not no i think it's more like we're expert at being an amateur like that's what i am ah i've decided i am but i'm not i'm not saying i'm good at it but like the thing that i like to do is try to learn the new thing and then help others learn it as well and sometimes i fail sometimes i succeed who knows back to the autoencoder project kendri i'm not prepared for this kendri welcome to your coding train membership you have just boarded the coding train passengers manifest please make sure you sign up for discord check the community tab for a post where there's a google form that you can fill out make sure you link your youtube discord accounts and you also get a random number 2022 2022 is going to be the year that i'm going to get back to reading this book of random numbers in a logical and organized way but your random number kendri is on page 169 it is row 8420 column one two three four and the number sequence is five six zero two nine again um we've kind of lost a little bit of momentum on this but we'll get it back a bunch of you if you're in the chat you received one of these please let give a shout out but um members uh uh at certain levels will receive this beautiful custom laser etched train whistle with a random number with a random walk according to the sequence of your random number of the random number book oh that's a mouthful okay um ah so um kd kydz i got to get to the auto encoder um it's 11 35 so i'm i'm going to start that but i do want to address this is an excellent question from kydz how do you see the use of your projects on on websites either following the internet video or changing up code i love the flock animation are you okay with crediting great question so let me rephrase the question let me just create a scenario you're a viewer of the coding train you saw one of the coding challenges maybe uh and i'm gonna just go to them and you're like oh this selfavoiding random walk this pattern is perfect for this design that i've uh that i've been hired to do for a movie poster or for my own personal portfolio website i want it to be running in the background um can i use it so the answer the short answer that question is yes with no other caveats all of my uh example code is released under a very permissive license typically the mit license hopefully um it's here in the website i think it's in the faq uh license here we go mit license so this is a short and simple permissive license conditions only requiring preservation of copyright and license notices license works modifications larger workspaces from under different terms without source code so basically you can you can um use it for anything you want you can modify you can distribute it it can be private you don't have to you don't have to provide credit um so there's not a lot of restrictions in terms of the example code um let me say a few things about that um it's nice if you can give credit i appreciate it i'm saying this less for me i get plenty of credit i don't need any more credit for stuff but we live in this sort of ecosystem of creative coding open source everybody's got different sort of comfort level with things being reused not reused so always check to see if there's a license regardless of what the license is i would provide credit a reference a thank you i would be overly generous i would go above and beyond whatever is required by the license and the thing this doesn't apply to my code examples but you will often find artistic works that are released under an open source license so in theory there's no legal issue with you taking that code and using it say on your own website but i do think there is something different to copying example code and remixing it for your own creative vision and taking somebody else's artistic intent and applying that um to you within your own work without sort of proper reference and credit so it's muddy it's murky um certainly there are sort of like clear scenarios like oh look example code under mit license please go forth and use artistic work without the source code being open source you may not like copy that put it out on your own name sell it you know make prints of it sell it on your local corner store market or whatever kind of digital currency things people are doing these days i don't know what i got to talk about right now so um and i think actually um golan levin has a really excellent guide to this i'm just want to like i know where i can find this so i'm just going to pull it up i'm very actually i think i can probably show you this pretty sure that i keep a note to it in my syllab syllabi i know i do for my my undergrad course that is in nyu's learning management system which i can't pull up but i can go to my public syllabi for my uh programming from a to a z course by the way if you're looking for some of my most recent stuff um pablo is saying open processing now requires to give credit to all you yes so open processing is definitely a site where people are publishing both their code and their sort of creative artistic vision and so if you're helped by the code and you provide credit i think that's very reasonable if you are just you know if you took something on open processing and like turned it in as your homework assignment for my class i think that would there be an issue even if that's like not something that's you know that you know you could be sued for you know according to whatever the laws of wherever you are let me just go here to a to z let's see if i can find the reference to golan levin's um yeah here we go so i adapted this um it's called um a statement use of free and open source code from examples uh this is adapted from i'm sure hopefully goal 11 may have an up more uptodate one from when i adapted it from fall 2018 but i just thought this um this is a really useful uh section um that is is is uh speaking of giving credit adapted from golan levinson written by golan levin be careful tonight happens that an artist places the entire source code for their sketch or artwork online as a resource from which others can learn assignments given in new media arts courses are often similar you may also discover the work of a student in some other class or school with posted code for a project which responds to a similar assignment or even the assignment for your class that you're taking right now you should probably avoid this code or at the very least be careful about approaching such code for possible reuse if it is necessary to do so it is best to extract the components that solve a specific technical problem giving credit there i would add and um rather than those parts which operates to create a poetic experience again these are tricky things to define in really strict boundaries uh with really exact right or wrong we're all trying our best it's very hard i think transparency and narrating and documenting your process is the most important thing you can do so even if you did something that you felt like yeah make your make it your own even if you did something that you know could be characterized as repurposing the poetic aspects of somebody's project into your own if you've documented through your blog post through code comments through your website your entire process of how and why you did that then at least i think a um a dis good faith discussion around that can happen and can be corrected if their mistakes were made so um so yeah so you can re you know you should you can uh hopefully i don't know if this let's see if this link still even works yeah so this is the original um policies from golan's uh celeb syllabus i assume there's a more recent one in 2018 you can find it under my programming from a to z and other courses if that's helpful to you if you have suggestions about a phrase and write that better boy would i love those because this is a very uh it's like you know talk about faqs for people who are new to teaching people are students new to coding uh i ask this question all the time and get confused myself so okay now auto encoder we're really gonna get this project this is why it takes by the way this is why it takes seven seven hundred three hour live streams because i spend 45 minutes i haven't even started working on the code for this project how about we start now i did i started demonstrating okay generated the training images the next step um and let's check i have a node a piece of node code that runs through a series of steps basically it builds the architecture of this machine learning autoencoder model um and sorry i'm just reading k y d z zs i'm gonna this balancing act of like just having this discussion with the chat going through this code example is quite difficult but um recreating the flock type animation um is yeah and and so again to be clear i am making and releasing my examples for you to use use them and you're not required to give credit which is different than if i had some sort of like artistic project that i was displaying that had some other kinds of intentions behind it for you and how you might reuse that so copying my code exactly and putting it on your website is fine that's what it's there for of course you probably want to make it your own that's the exciting part of all this okay um sgl let me see if hopefully somebody in the chat can post that link otherwise tweet at me or follow up after i can try to put it in the video description later okay so back to the auto encoder the code that i've written so far basically does everything it creates a loads all those 1100 training images it trains the auto encoder with the training images i'm using just the first 1000 images to train the model it then saves the model to a to a local file because i'm going to load that model from a p5 sketch and then it also generates test images just to sort of see um okay so um let's run that let's first look at the directory and um i'm going to delete all of the the output images that i generated last time to make sure this is actually working and i'm going to run the training now it was suggested to me i think over social media after last live stream that i absolutely need a song to play or sing by the way i do have my ukulele here in the studio it's been over a year since you know where's the joy in my life that it's been over well over a year since i actually even unzipped this case i mean there's no way this is going to be in tune even this is the night this is my nice one has a strap it's not in tune at all none of the chords i play will work but we need a training song okay i'm gonna have to deal with this later um but so i'm uh anybody who wants to write me a training song maybe it would go epoch 34 out of 100 eta 1.1 1771 milliseconds so this is not good this is not good this is not good uh the loss is going down it's at .06 this is very embarrassing the voice in the back of my head always when i start to like um the silliness starts to take over a little bit is um people who comment i would have enjoyed your video if you just would stop it with the clown act i can't help it that's my that's my inner that's my inner inner soul is a clown it just wants to break free i never made it to the shock le cox school of mime in paris that was like my childhood dream and i just never made it there and now i reduce to machine learning javascript examples while clowning around like getting 100 epochs was definitely too long yeah chris sears um it should be in the style of a rocky montage i like um i really don't need to let this go all the way but um especially because i already trained a model but it's it's almost there so i can let this go um uh all right so we're almost there to getting this to train and as i start to iterate and work on this more um i'm going to not you know take the full five minutes or whatever this has been for it to train but we're almost there so once the model is trained um manus asks are you plotting the law so questions would have been good so i am not the loss the loss value which is the result of a loss function is sort of summarizing the overall error of the model how well is it at reproducing those original training images and you can see that it's going down over time although it kind of went up here so one thing that i could do is analyze like when did it really stop like clearly at epoch 34 it was quite higher than at epoch 54. but you can see somewhere around here actually maybe not even until like the 90 around epoch 90 or so um did it sort of stop really going down um kathy asked a great question it is possible to set an acceptable loss or maybe this is a question is it possible to set an acceptable loss before running a stop when it reaches the desired loss that's uh absolutely i could write that into the code i'm not going to do that right now because that would be sort of an additional thing to engineer but i would certainly encourage anyone watching to try to do that and that seems like a really interesting idea yeah so again just to emphasize um hi michael k ah i posted something on twitter and somebody came to join the live stream look at this amazing um so okay so many interesting questions here so let's let me address these questions by the following so first of all this is the output that i have now generated let's take a look at these images and i'm going to just scroll through a bunch of them so you can see i'm getting what i was hoping for which is these kind of like squirkles they're sort of they're mostly circular but you can see the sort of corners of squares and sometimes i got a full square as soon as i have a full circle sometimes i have something somewhere in between now a couple things to mention about this one this is an incredibly trivial example right what i am reproducing with the auto encoder are very low resolution simple shapes that are either only i mean there's really only two variables here there's a switch is it a square or a circle and then there's the radius so you can think about i mean this actually came came to me i mean i think it was based on some of the chat messages but if i go over here to the whiteboard if i were to like come over here and sort of reexplain what an auto encoder is and again uh what is autocoder go and check out the twominute papers autoencoder video on youtube uh where it describes an autoencoder as a copying machine right it's a neural network that takes an image in as an input and the idea is we want to get that same image out as an output that's a very easy thing to do right we could just cut in terms of without a neural network i just iterate over the pixels and make a new image with all the same pixels however the idea of an auto encoder is the data is being passed layer upon layer upon layer through a neural network being compressed down to from however many pixels to some other layer with a smaller number of nodes and then decompressed back up so if you think about it i technically only need two nodes in this sort of center layer for what i'm doing because one variable right i need to keep track of what is the size of this shape and the other variable is it a square or a circle so in theory if i go to the architecture of this auto encoder and i look at how i've built it right oh i'm sorry i didn't i didn't switch over if i look at how i built it the first layer receives um it has 256 it receives the number of pixels of the actual image and it compresses it down i mean it's not this isn't really compression i'm just using that as kind of a in a sort of metaphorical way to describe the process although i mean it is compressing it essentially the data and 256 to 128 and then down to eight and then back up to 128 back up to 256 and then eventually back to a full pixel image um right and we could do a convolutional autoencoder and a variational auto code and then a thank you astro penguin for answering about overfitting um so um so let's we can address that in a bit i feel like i was getting some good suggestions about changing what loss function i'm using but just out of curiosity i hate to do this let's add one more layer and bring it down to two units and then have the decoder also have one more layer with eight units then let's see if i can still get it to work and i know i said i wasn't going to do this again with a hundred epochs but i can't help it so here we go we are training the model again let's see if that loss can go down and see if we can get um a mean squared error loss function for auto encoders yeah um and astral let me just read astro penguin's comment overfitting is when your model doesn't just represent your data but also your noise it is so well trained to your data that works very well on it but poorly on another data set right you can train a model so well that it can reproduce the training data perfectly but because it's just so locked into that training data if the real world data has any kind of variability to it that's just not there in the training data it's going to explode and do a terrible job so there are lots of techniques to reduce overfitting in terms of how you collect your data set using something called dropout which is adding some sort of randomness and disconnecting parts of the neural network as it's learning um this seems to have settled on a loss of 0.23 i'm going to just run this again and just give it 30 epochs so we can i think that's faster than waiting for it to get to 100. uh where did i where do i set the number of epochs um train here it is so let's just let's just train it with 30 um and let that go um ah yeah um and uh simon's reminding me that i was gonna try to do this with um try to see if i could denoise some images so i'm i'm getting like sort of scattered here of all the different things i want to try but it's okay it's not even noon yet i've only spent an hour um place the auto encoder song cyber said this is great cyber gus says it's like preparing for a math exam by memorizing the solutions to the problems right so like if you have like a sample test you just memorize all the answers but don't look at how any of the problems work and then you got a new test you could put all those correct answers in but they won't match the actual problems it's kind of a wonderful okay so i think we're at epoch 30. i'm just curious to see oh there's a lot of randomness in how well it does i didn't let you let it go more i didn't realize but let's just see what kind of images we got even from that from that training so they're they look pretty good they're just much fuzzier so this is what it was able to do with just two parameters but also i didn't let it train for as long as i could have nicole wants to know what is in my mug first of all love this mug fellow mug not a sponsor you never know though um it is coffee and oat milk delicious sometimes it is ginger tea depending on how i'm feeling i'm either like a coffee and oat milk or i'm a plain ginger tea kind of fellow that's in my felt with my fellow mug that's me all right moving along um let's go back to um yeah i'm reading simon's commentary and i totally agree let's look at whether or not our auto encoder can effectively denoise a shape this is you know an actual application of auto encoders what do i even mean by denoise hold on so i'm going to put this back to 100 epochs and i'm going to go back and get rid of this like little layer uh the and just leave the the middle layer um as having um eight units um i want to just try it with a different loss function um is it this is this what i should put in here let's just try a little a little risky here to introduce that at the moment but okay let's train i'm just gonna let it train oh look at that huh look at that it like with that loss function it's like not improving after just a few epochs interesting so hold on this will be great if that was that much of an improvement let's have it go just 10 epochs sometimes it's totally unnecessary but i just like to delete the output just to know that i'm getting new output for sure let's run this for 10 epochs and see what we get look at that like basically after two four five oh no it's still improving huh oh it's still it's always why does this happen to me it's still improving so the other time it kind of like was waffling but let's take a look at what i've got after just 10 epochs all right fine torture me so go back to 50. this is one of the problems with this project is just running again takes so long uh mse did i not type the right thing in let's let it go we're gonna let it go for let's let's actually look in the tensorflow documentation um where is that is this tensorflow.js i don't think so um these are all the tabs i was looking at yeah look at this going way down still going down whoops um this is what i want api um i want the tensorflow.js api uh mean mean squared yeah no i think i got it right mean squared error now do i want the stochastic gradient descent the learning rate was too high um might be getting stuck in a local minimum the opposite of a t all right um so that's interesting i wonder if i should be also trying this to cast sgd um optimizer instead of atom um but anyway it was still the loss even uh even at that 50th epoch was still going down pretty consistently although it did pop back up there so let's take a look now at the images we generated all right these look really good so what i want to see now if i can get it to do is denoise an image but i'm going to go into the browser to do that that's what we didn't get to do last time okay everybody um okay so the next step of this was um if i run a local web server i have a p5.js sketch which is loading the model that's interesting i i thought i would have to go into like the public oh it's serving it knows to serve dot public that's so funny because i have a directory in there okay so this is now the p5.js sketch which is loading that model and i am feeding it just random noise like a a sort of purlinesque no perlin noise there's always sort of discussion around whether this is true perlin noise or not or simplex or gradient or whatever but this sort of cloudy noise pattern is what i'm feeding into the model and i'm getting this shape out meaning the model is working and this is kind of like leading the way to what i want to really focus on today which is a latent space walk but before we get to that what i would like to do is draw a um an image of a circle and see how it copies it an image of a square and then add noise and see what happens bear with me or join me for this part so i'm going to go into i'm going to go into the um sorry sketch.js i lost my train of thought here and um let me just do uh training new model so i am going to i know sorry comment out i think i'm just going to take out the noise thing because we don't really need that so it'll be in the code history do i want to add a tag people going to want to find this well i know where it is so we'll finally i'm going to take out all of the noise stuff and just go back to a random image and saying no loop so if i do this um and then next image sorry i'm forgetting how i'm doing this uh does this work and then put no loop in i just want to know this is silly i don't need to add the no loop but i'm just curious too all right forget it keep the no loop have it be a random image wait sketch sorry hold on what did i do oh i lost this ah okay this is what i want to do so this is what it looks like when i'm feeding random noise into it it's trying to find and and month nonsense we see a machine trying to find shapes in the random noise so what i would like to do instead is and i'm going to create a um i know what to call this the um the i'll call it input canvas and let's say input canvas equals create graphics at um i've done this in sort of like a weird backwards way but bear with me um what is the size oh yeah create graphics w comma w no no we're fine create graphics i have i forgot i had that w value so i'm working with 56 by 56 pixel images um and the input canvas i'm going to say input canvas dot background i'm going to draw a background of white then i'm going to draw i'm going to say a stroke of zero a stroke weight and this i should essentially be matching what i did in processing so i'm going to say a stroke weight of 16 16 then i'm going to say um input canvas circle uh w divided by 2 w divided by 2 and just give it um a a radius or diameter of w divided by 3 and i'm going to say input canvas no fill then um i'm still this is still going to be random i'm just doing this one the only thing i'm trying to do right now is i want to see a drawn shape drawn with p5 on this left part so now i should be able to in draw instead of rendering this input image it should be able to say image input canvas 0 0 and resize it up to w times w wait why won't it why won't it do that doesn't my variable names are terrible where was okay and then let's see if this now gives me oh this always happens it's trying to import ah it's trying to import something i really have to work on my vs code settings okay good oh the stroke oh i forgot i was drawing it as a larger image than resizing it down so this stroke weight was you know a bit much uh technically it should be um uh 16 where to this is very silly but i'm just going to do this okay great so now the idea here is that the auto encoder should take this input circle and produce an exact copy of it on the right now however what's important to note is i'm not feeding it into the auto encoder so the next thing i want to do is feed the image into the auto encoder so that happens here so i'm going to need to do it by looking at the pixels so i need to say input canvas load pixels and then i equal 0 i is less than w times w times four because there's four elements of the pixel array per oh no no no i'm gonna have to do the multiply by four somewhere else same thing because my input image array has w times w spots in it but instead of a random i want to say input canvas pixels i times four okay that should work because i could just take the r channel if it's if it's a full grayscale like black and white image i times 4 if the array is rgb alpha rgb alpha then the r channel is 0 4 8 12. and so if the i is going up 0 1 2 3 i times 4 is 0 4 8 12 et cetera so i believe this should work look at that look at that beautiful auto encoder it copied that shape perfectly now just you wait and see let r equals map mouse x which goes between 0 and width to between 0 and width this is the most brilliant code i've ever written in my entire life i'm gonna map this range between zero and width now hold on everybody just hold on a second i'm gonna blow your mind right now to between the minimum of zero and the maximum width but in case i wanted to change that later it's nice to have the map function in there and then this should be r which is really a diameter so let's call it diameter and we should see i wonder if it never got interesting so this is not working as expected hmm am i i'm definitely redrawing the image redoing the pixels into the auto encoder let's try a square just out of curiosity and also wait wait wait i have an idea the range was 25 to 200. so in theory like only range that it learned is uh between 25 divided by little w and 200 divided by little w um so that might help let me just say input if i'm going to do a square input canvas rectmode center let's see what happens here i'm like suspicious that it's not something is changing all right do i need to train the model i feel like the model picked up the average radius of the circle it does seem that way all right i feel like let me just go back to um what i had originally which was um i just want to make sure i'm using the right model so let's um i'm sure it is but let's go to um where's the model saved oh it's here today at 12th grade it's a little bit silly but let me um i'm going to put this back to what i started with today so i i'm just putting it back to binary cross entropy adam even though it kind of doesn't make any sense and a hundred epochs and i'm gonna once again train this model and let it go the full 100 epochs this time all right everybody the decoded images look like the average of all parameters half circle half square with a medium radius side i know um so i wasn't getting that issue before so i'm just going to let this kind of power through a longer training process and see what we get so this will be a new the way i have this configured is when i train the model it saves the model in the directory of the p5 sketch and the p5 sketch should should pull that up all right while this model is training and since i'm halfway through the live stream this is a perfect time for me to do my sponsor segment today's coding train is brought to you by curiosity stream thank you crosstalk stream now i'm just going to repeat what i said at the beginning of the live stream but those of you who i know most of you probably weren't here at the beginning so guess what i have something exciting to tell you about it is the best deal in streaming today so i am going to go up here uh whoops and show you something curiosity stream let's come back over here okay whoops wrong thing curiosity stream um i'm signing in here okay so curiosity stream is a amazing streaming service with thousands literally thousands of documentaries um all in so many um areas related to things that i do here on the coding train in particular my favorite part of kinds of documentaries that are on oh my god i've got to watch this one whale wisdom i love whales are the nature document documentaries um secret lives there's a whole bunch of secret lives of blank um nature documentation these are great for kids um science space and tech um infinite rainbows wait a second here i mean it's worth signing up for curiosity stream just for infinite rainbows alone how did i not know about there's only 22 minutes long in the time span of one single coding train coding challenge you can watch an entire documentary about what exactly are rainbows learn the science of i'm sorry this live stream is over it is done i don't know if the music is playing i'm out of here i'm going to watch this right now um but if curiosity stream isn't enough with this special onetime well it's not exclusive 42 off discount you also get access to uh nebula let me sign in here um nebula is a streaming service uh made created by creators youtube creators hopefully many of you might recognize many of your favorites here uh not not just bikes is new to curiosity stream i'm sorry new to nebula and i've been uh really enjoying not just bikes even though now i live somewhere where i have to drive everywhere so nerdsync is great um all of these wonderful channels um you can watch all of the videos from these youtube channels on nebula with no ads no sponsor segments and many of them have extended versions this is something i'm hoping to get into in 2022 so you could sign up now and so um the other thing about it is there are a ton of originals so if you look at the nebula originals you can see different um kinds of video content that you can't find look at this next officially you're in in gaming next level world building why games are better than movies is a wonderful nebula original series none of these these are only available through nebula and uh i'm going to take this from renee ritchie this is i just bought a dongle yesterday i needed a dongle for one of my laptops it cost more than an entire year it's like less than one dollar a month for both curiosity stream and nebula for the whole year it's 11.59 um if you just sign up through this link um it lets them it lets them know you found out about curiosity's stream and the nebula bundle through me helps the coding train out gives you access to all this wonderful content supporting educational content creators so i hope you will consider it um something that you think about doing for your streaming and entertainment and education needs uh for 2022 i don't know what your new year's resolution is but my new year's resolution was to watch more wonderful youtube con educational content creators on nebula all right let's check in uh back to our uh training uh by the way the link is in um a pinned message in the chat if you're looking for it's also in the video description okay so this is presumably the the new model was trained got down to a loss of zero point sorry for all the scrolling 0.644 i'm gonna refresh this page weird i'm like suspicious that my code isn't working because did i delete i deleted all of the let's go back to the random noise so first of all let's just check here oh wait a second no public yeah this is the model from 12 16 p.m that's the new model this project i'm not making any progress today at this project which is very distressing i feel like it did something a moment ago like when i switched back in um hold on we're going to debug this where's my next image okay i got to go back to the sketch next image function what if i go back to oh who knows what the problem is i know what the problem is come on come on chat come on you can think about it what's wrong what are the numbers coming out of inputcanvas.pixels if it is a white pixel what value is it 255 i didn't normalize the values i didn't normalize the values this needs to be normalized divided by 255 okay all right that didn't seem to change anything ah um okay let's just for the sake of argument put in random noise again so i am getting a variety again ignore the fact this is in the hmm i times 4 that's right right it's pixels should i give it it's not in the draw let's check the input all right but i mean let's just make sure it's continuing to run and make new input whoa no that's right 56 by 56 3136 okay but like a bunch of zeros yeah i mean this looks right all right let's try like why is the model not able to give me a range of sizes it was not having that problem in the version that i made where i was passing pearl and noise into it and look it's like what's it it's doing something okay use the mouse click to switch between square and circle am i getting alpha my i don't think i'm getting the alpha i times 4 should be the r channel all right this is a good idea so if mouse pressed mouse is pressed draw a square otherwise draw a circle okay that's definitely something is the scale wrong the mods that map oh no but it's symmetrical it could be that i'm not reading the pixels in the right order no it's totally symmetrical so i don't think that should matter all right here's the thing that i could try let's go back to our model let's let's look at okay so let's think about the model architecture for a second yeah many jimmy's saying accumulate the rgb and divide by three that shouldn't matter the mouse mapping seems a little wrong yeah i don't understand so hold on let's do this without the mouse mapping just to be more consistent here let me go here and let me say diameter let me make diameter global variable um start at the smallest and then where do i set it yeah and then i'm going to say just have it cycle back so i'm just going to have the diameter cycle automatically it's weird like this to me like the fact that it's not changing at all makes me suspicious that i'm not doing something correctly because in the neural network right like in the output folder in my test images i'm getting really um right this is this is what i'm getting when i'm testing it so like why is p5 not doing this so this is what this is why i'm suspicious because the model otherwise is performing as expected just not when i bring it into p5 so i feel like maybe the way that i'm drawing these images is somehow wrong all right i have another idea just bear with me for a second let me take a training data image oh this is no no let me take let me take 10 images from the training data and let me put those in a folder called data we're going to figure this out okay so now i am going to um joseph asked when you were using noise were you using the noise value or the pixel value oh i was definitely using the um the noise the noise the noise value hold on let me add preload so we're going to call these test images test images index i equals load image data what are these called square i dot dot png and the oh i need to use the back tick and this should be number format four uh and then i need a loop do you have 11 for some reason okay so now um let's just for a second take this out all this out i'm going to draw image test images zero now again i'm not let's let's okay so let's take a look at this oh you know what there's a little bit of an issue here i'm worried that i wasn't refreshing the code hold on don't worry okay so this looks better um let's get rid of this now um function mouse pressed let's have a test index equals zero so this is test index and then test index plus plus okay that's the first image okay see nothing is changing now is nothing changing because i am incorrectly i'm pretty sure that i have the cache disabled but let me just check under network is what i'm looking for yeah i have this setting should should stop me from caching the model file um but why so now i'm going to do this let's actually load the let's load the pixels of this image and this should be no this shouldn't be oh yeah i don't need this input canvas anymore this was silly right i can just draw that test image directly load pixels pixels i times four okay i'm reading the chat because okay ah okay so something about the canvas was wrong okay i knew something was weird well this is much more what i was expecting oh whoa boy did i just go off on a direction forever why what was wrong with the canvas input canvas pixels input canvas draw the image like what's the difference okay put this and just put this back okay so and now why why if i say input why if i do this instead of the test image the load pixel this must be a p5 bug this has got to be a p5 bug oh this is so sad but i guess this is good that i discovered this because maybe it would cause me some problems later why is the canvas can i not seem to get new pixels from it i mean one thing i could try to do is recreate the graphics context each time still not working is this asynchronous or something i commented out the update what am i missing right there's no difference here i mean i i guess to be 100 sure i need to draw the input canvas oh but but that's gonna cause problems if i'm recreating it so i have to put this back into setup yeah why why what i mean okay let's try this what if i were to say test image copy input canvas i mean i'm just like copying the image in extra time so right instead of using the pixels from the actual canvas i am i mean do i need to update the is it as simple as i just didn't update the pixels because i did load pixels that could be it well this works so i like copied the pixel from the canvas into an image but could it have been hold on this does kind of make sense all right this is what doesn't work i mean i have a workaround now so that doesn't work but what if i were to put input canvas update pixels no is that the wrong place for them i don't no what i'm doing no i think it's just broken i think the input canvas is broken so i'm going to go back to this ridiculous solution i don't this is working but now i'm going to go back to this and forget about the test images there we go and now in theory it's interesting how it's having trouble distinguishing the circle in the square but i'm not going to get too bent out of shape about that i kind of like that anyway yeah so i definitely eric is saying what if you train a data set that randomly rotates the square i 100 want to do that so i'm just unfortunately like i'm i'm this this is like the slowest thing i'm ever because i'm running into so many small little bugs but i have this working so what i would like to do is i would like to uh add the noise oh my god so just to finish close the loop on this uh and i see some comments here um in the discord chat as well so just to close the loop on this what i would like to do is let me add some noise so i'm gonna say i'm just gonna add 10 random dots so let's give me a random x and a random y and do a point at x y with the same stroke weight so how come i don't see those oh i don't need this last argument rgb uh point oh input canvas sorry input canvas xy so you can see that the noise is i mean this is like a sort of pretty terrible demonstration of noise um let's do the following um let's give it like a hundred points uh stroke weight um this is so silly that i have this like divided by two at w everywhere but let's just make it stroke weight one um and then also we can do the stroke like a little bit lighter oh i forgot to do input canvas that's why input canvas input canvas uh can i get away with like 500 yeah so this is what i wanted to show you of course we have this weird squirkle thing going on but this is how an auto encoder can denoise and let's try doing 1500 right the noise is completely eliminated and yet i am drawing a nice circle or square you can see it's a little bit more squarey as it gets larger a little bit more squarey wizzy says unsure what this is all about i just got here from the quadtree so first of all welcome i hope the quadtree video was helpful to you wizzy what i am doing currently is i am building and this is the diagram of it an auto encoder in uh javascript using both tensorflow.js and p5.js and what i'm now demonstrating is and and monos is saying this isn't really denoising the model wasn't trained on it so the way that i'm approaching denoising here is not giving it noisy images with a target output i'm just having it learn a singular kind of output and then if i give it a noisy image the only thing it knows how to do is make a copy of that input with a certain kind of style output thus removing the noise so that's really how i think of this as denoising um so this is exciting to see the interesting thing would be like what happens if i let the circle be bigger than the range in the training data set i assume it won't be able to reproduce that but that'll be kind of interesting to see so like for example right now um this diameter its range is going up to 200 but what if i actually like let it go from zero all the way to the full width so you can see as it gets to 0 it doesn't know what to make of that oh whoops oh sorry up this should be to this sorry so at a certain point it's going to get larger than any training image it ever looked at and it's going to get confused let's see what happens yep there that happened right there so it's like trying to make sense of that but it had no it can't extrapolate beyond what it learned but if i were to retrain the model with images that were the full size i'm giving it a bigger range of images now but if you input an image of mario brothers it will draw a squirkle anyway exactly it's going to draw everything into a squirkle and if i uh retrain the model now i kind of want to just for the sake of argument now now that i understand what wasn't working what the issue was let me go back to the model training code and i'm really determined to finish this project today so i'm obviously going to go past one o'clock but let me just return to this i am curious to see what happens if i try go back to mean squared error as the loss function and let's just change the optimizer to sgd i don't know if this should be better or not but let's retrain the model you can sing the model training song okay so i don't sgd doesn't seem to be maybe i need a higher learning rate with sgd um so let's go back to um i can't remember if i specify the learning rate anywhere i didn't i didn't i'm using a default learning rate but let's try mean squared error and let's see um let's see how well this does um the inside of the rectangle looks bent in this processing sketch so i think that's just an optical illusion i don't want to run this again although i can without saving the image i think that's just an optical illusion because of the rapid pace of circle and squares if i were to change the frame rate to like five i don't think you would see that traditionally we use noisy inputs while trading model rather than just a test set but this is perhaps the best way to do it given the simple nature of the problem thank you monas that's a very useful commentary all right so what's happening next while this is training um and let me just put this back um i want to go to the github repo for this and this this isn't going to work yet because it's still training the newer model although it seems to have like got stuck on a local minimum like which can happen from time to time i don't know if i should adjust the learning rate does anybody have a suggestion i kind of want to just run it again and see though it's it's stuck in that same spot where do i put the learning rate is that here so let's go to tf.js fit dot fit um call backs validation split sample weight initial epoch yield every where does the learning rate get ah it goes with the optimizer okay so if i wanted to try adjusting the learning rate would go here like this so let's give it like just curious like a super high learning rate oh whoa it found its way past that so it just took a little bit okay whoa okay i'm gonna i'm gonna let it this looks like a much better model with mean squared error now i'm gonna let it keep going and not worry about so i'm just gonna keep this in the back of my pocket if i wanted to i'm going to let this model i'm going to let this model finish training the loss is like very very very lower than anything i've seen to date yet working on this project and now what i want to do is go to the github repo for this and um i didn't i didn't see this one um sorry mini james but i want to look at this one so um this particular github issue was filed um had us has some really really helpful uh tips in it so first of all um i managed um so thank you so much to java gt who writes so this is how you can you can access the individual layers with autoencoder.layers so i made a little helpful function to split the auto encoder by looking for an increasing number of nodes so this is the way i'm going to be able to do that so but you can't just loop over these layers adding them to another sequence they don't carry the weights so i solve this with another helper function that creates a new dense layer so this is interesting to look at i suppose i can use this methodology um and um there's a lot of other helpful like tips in here about things so that's what i want to do next um also uh generating a gif like all this in the nodes in the node program make sure that decoder is fed with values zero through one um okay so but i'm going to come back to that i want to work on splitting the model next um but where is it um managed to get a 28 by 28 encoder reduced down to a single value couldn't do this at larger sizes which worked well down to four variables one makes sense because there's only one variable changing the the that radius um okay are we done all right we have a new model let's see how this new model looks so this new model should be much better yeah you can see like at the larger size it's really distinguishing the circle versus square and denoising now interestingly at lower at a lower size it's having a lot of trouble um it's having a lot of trouble um distinguishing the um the circle and the square because the bends probably of the circle are obviously much less extreme and harmony is doing a really great suggestion which is what happens when you translate the input image all right so what happens if i'm doing too many things at once here but i'm going to get to the latent space thing in a moment i have to make a new clearly make a new sketch here what happens if i draw that image at um at an x y position of my own design so let's see what happens here so you can see as i move it around it's confused but when it's centered that's kind of cool to see you can see like if i put it over here it thinks it's a it's like that must be a big square because there's dark pixels over there but maybe it's a small one and i don't know why i've lost the oh this one's supposed to be um circle no wonder so a good thing now what would happen if i trained it with in circles and squares that are anywhere in the image oh can i do that but i want to do the latent space thing if you use cosine annealing learning rate you can use a high learning rate the schedule or lower yeah yeah yeah so i don't know that i'm going to get that sophisticated with this but quick summary of the comment from manas is that you can start with a high learning rate and then over time like as it gets closer and closer to the optimal weights you can lower the learning rate so that it can fine tune it better but i cannot resist we must not stop let's try um having this also be let's try having the squares and circles in the training data set be in a random position and this has to be float because i'm not in javascript land anymore uh wait a sec something is wrong oh because i'm doing center no that should still be fine oh i'm resizing it down so this has to actually be these values should be the actual canvas size yeah all right this is going to be really tricky is it really going to be able to learn this convolutional layers would solve this i probably should not be trying to do this this is just asking for trouble but i cannot resist and remember my auto encoder only has eight units in the middle maybe i should give it 16. maybe for this i should give it 16. let's give it 16. uh i kind of want to save that previous model in case i need to go back to it so hold on um model squirkle now and then i think i might need to create the model directory again but it's empty okay so now i am attempting to see uh uh i think somebody might be here that i need to speak with hold on a sec everybody while this is training um sorry i'm just checking something here it might just be a delivery truck but i hear a loud noise oh maybe just retrieving something okay how's this going here oh no this seems kind of stuck i i think with many sizes placements you'll want a larger training set that makes a lot of sense the model size is less important than the data all right so that's a really good point okay i think i need to backtrack because my goal was to demonstrate latent latent variables so let me backtrack and not go down this road right now i think i could have done like if like a rotation maybe would have been so let's go back to um oh no that's wrong so let me put it back i had saved the model but i realized i need to deconstruct the model so um let me quit this let me just start the training again all right let's take a look at what i want to do so ultimately and let's put this back to eight i wonder if i could get it down to four oh let's do eight that's fine let's see if the loss does well with four okay so i'm trying to put it down to four just to see how we do oh i didn't make the new training data i have to make the new training data sorry everybody my brain has melted here uh what is going on okay let us go back to this wonderful let's go back to this wonderful code here so this is taking out the layers creating a new layer setting the weights okay so this makes sense i feel like there must be a way to do it um so i don't i think because it's such a simple amount of layers right now i don't know that i need i'm going to use this as a reference but i think i might be able to just even just save those layers in a variable and do this more simply um okay um let's see how this training is going wait what just happened oh yeah no the images are done okay i didn't take a break that's all kind of a problem um andrea says those sigmoid activations seem strange shouldn't you have only one after the final layer i think that's correct let's do that as well let's have all of them let's be able to expand it out only the last one should be sigmoid let's see how this does for us okay so now just examining just examining the code i know i just want the last three layers so let's look at this so now what i want to write some code is create a new model with just the the the decoder so i think that probably the way that i should be doing this though is rather than extract the layers shouldn't i just save them as i'm going like for example what if i were to say what if i were to create an array sorry for the noise everybody yeah i could do all right um all right so what if i i'm just gonna do this oh yeah i have an idea sorry couldn't i change do this and then have decoder layers and then basically do exactly this um decoder layers push yeah just the helicopter landing outside don't be alarmed he's picking me up i've gotta g i've gotta get somewhere fast uh all right so i'm gonna add all these decoder layers okay then i'm going to say 4 let i equal 0 i is less than decoder layers dot length i plus plus then i'm going to say add decoder layers index i um okay so now i put the decoder layers in a separate array then i'm adding them to the auto encoder so this should be the same i hate to just constantly retrain the model but let me just make sure this still sort of like looks right yep this seems reasonable so so everything is the same same as it was before now if i go back to this reference i want to create a new model so let's it's nice to put this in a separate function but i'm going to pull this code from java gt and see if i can kind of unpack it but with my methodology so oh i see but so i'm actually going to return both the decoder layers and the auto encoder as like an object because i might want to make use of both of these and then i can say do this so now i'm building the autoencoder but saving the decoder layers in a separate array okay um by the way banning if there's like spam happening in the chat is perfectly thank you nicole for stepping up and doing some moderation um i'm just gonna okay i don't know if it's possible to ban or not okay okay so okay so now i have access to the decoder layers separately so what i want to do here is create the new model with just the decoder create decoder with both the decoder layers and the auto encoder i don't know if this is going to work so now i just want uh create decoder is that what i called it decoder layers and the auto encoder and then i can go and take a look at this and say create the new model the decoder is a sequential model then for every for every decoder layer right this is the sort of i'm kind of doing the same thing so this there might be a lot of redundancy here so we can clean it up later refactor this later but i am creating the decoder creating a new model just by taking the list of decoder layers that i saved to kaya suzuki someday there'll be too many of these and i won't be able to do it it's good tsukaya suzuki welcome to the coding train you are boarding right now slow down train we're pulling into the station and opening the door and letting kaya on board for your coding train membership you win not this ukulele my prize ukulele but your very own random number uh on page 163 line uh row 8125 column one your sequence is get ready zero five three four eight okay um so close here so i'm adding all of the decoder layers to this new decoder model then i need to compile it i'm going to compile the decoder with the same settings that i used for the auto encoder so let me just make a 100 sure that i'm doing this correctly by actually copying this up here and just changing this to decoder again any returned in code that i can consolidate and do in a better way i will um but the issue is i believe maybe we don't have the weights so oh it's making a new layer why do i have to make a new layer and copy the weights oh is that really why can i just add the layer with the weights manually copying the weights huh so let's i feel like there's a different way to do this with um tensorflow.js but if this works then awesome so sorry i'm gonna do it i'm gonna i'm gonna follow this way so i'm actually not adding the decoder layer directly i'm creating a new layer with so the old layer is that decoder layer and i'm making a new layer with the same number of units the same activation function and the same input shape in theory i shouldn't have to do that because the input shape should be inferred but and then i'm going to add that new layer but i also need to copy over the weights like this okay and i don't need the auto encoder to be passed in because i thought i was going to need that to pull the weights please use four of loops you know what i would like to do that as well let layer of decoder layers yeah then i don't need this much better so this should be the function that and again i i feel like there's got to be a different way of doing this but i don't i'm fine with it if this works great um in which in where i am and by the way i shouldn't have to retrain the model now i should be able to just um pull in the auto encoder load it because i have it saved um but where did i save it is the question file public model so i have to do this so oh the last training got kind of stuck at like a not a great loss let's go should i just go back to 16 let's go back to 16 units in the center um oh this needs a lot of work 16 units or eight let's go back to eight eight is fine i can do eight we're gonna go back to eight um now i've added the decoder layers all right and then returning them both so now create deco okay so let decoder equals create the decoder and then i want to save decoder save decoder equals public file public model decoder so i'm going to save the decoder to a different directory okay everyone isn't there a model.getlayer method there certainly is marius so i i feel like there's there's probably a much more proper tfjs way of doing this but i think this should work let's see what happens unfortunately i'm gonna have to train the whole model again and hopefully we're gonna start seeing um i wonder if i do need to play with the learning rate or is it just going to break out of this somehow so let's take a look here i could just load the model i had earlier why why why why why why why why why am i just too impatient and i should let it what is the deal with it being completely stuck did i not put the new training data in there hold on let's make sure the new training data is in there yeah that's the new training data what is going on yep this is the new training data i'm not saving the decoder there's a typo in the code oh thank you well that's good that gives me another excuse to run this again i mean i'm tempted to just load the previous model i have that i know is working well and then but what let's just generate a new training data set again just to be sure lower the learning rate okay so to do the learning rate right now i'm just using the default atom so what would be a good learning rate i'm just going to try this point zero one uh now this is weird the loss is not going down hmm did this mess up something it really shouldn't have i just put the layers in here and then i'm putting them in the auto encoder one at a time this is not going well change in the activation function i don't think so i mean i can put these back hmm maybe it's thing with your layers array i know well now now i've now i've got it it seems to have caught so it all right i'm gonna go with this and let this model finish training because now the learning rate is and this by the way is now just with whatever the default learning rate is what is it tensorflow js default learning rate atom point zero zero i don't know if that's from 2018. so this is probably the default learning rate for adam okay we're still going down why is the accuracy zero let's just see how this model does it's so hard oh okay i like this epoch 85. oof what was that why was that one time that i uh got this incredibly low loss oop cannot read oh you know what i forgot to return it hilarious but that's fine let's just see now um let's go back to my p5 sketch why is this model so much worse all of a sudden okay so look at this model i mean it's definitely doing something what just happened i see the chat going a little bit crazy um but if i go here and load model dash squirkle look what what did i do for this model this model is working so well like this is what i train like when i train this model like what what happened i don't remember like what settings were different okay ah this is driving me crazy auto encoder 256 128 8 128 256. and these are the decoder layers that i then add one at a time just make sure for a layer of decoder layers add that layer then compile it mean squared error yeah i don't need this accuracy metric i guess just take that out and let's just be explicit about the learning rate so i can sort of see what it is i wonder if i got lucky with the train let's i could give it more images let's generate another set of training images use i'll give relu another chance okay but i want to use sigmoid for the last one because i want to uh i want to make sure that i'm bound between zero and one and maybe i shouldn't okay okay here we go everybody wait hold on let's just see here um this is like really awful how i have like this duplicate code but this shouldn't matter actually though because i'm not going to be training this model so i'm not sure why i need this but i'm going to okay okay okay everybody i want to give relu another chance model summary okay i like this idea i can't believe that i'm gonna be another one of these live streams and not gotten to the part that i wanted to go to want to go to save train model okay is this right what you're suggesting oh my uh yeah it's completely stuck learning rate okay like lower learning rate okay i would have thought i need to raise the learning rate but like to me i need to raise yeah i could lower the rate divide by 10 until it works this does not seem like what if i have a high learning rate eight eight three two is just like where it wants to be what is going on but what what did i do like did i change something in the training data i don't think so training data looks reasonable yeah interesting okay what just happened here no sigmoid no sigmoid a terrible sigmoid okay wait this is good hold on but i was like messing around with the learning rate okay i'll leave that default learning rate okay i think we might be in good shape now people i think maybe i think this sigmoid was not helping me i'm sorry i'm sorry in my head because i'm doing something that's the most sort of like basic simplistic like demonstration that i should go back to the classics like sigmoid but i guess that was really standing in the way of progress here standing in the way of the progress did i tell you about today's sponsor another hour curiositystream.com codingtrain are you asleep do you need to wake up as the coding train board you you could try watching something on curiosity's dream or nebula for less than one dollar a month for the entire year oh my god okay we've stopped no it's still going down little little bits and pieces little bits and pieces what did i do that one time that we got that crazy low loss was it just like luck drop the nonlinearity for the last layer ah k weekman is here probably could have saved me like at least two hours of wasted time right the losses definitely seems to be nope still going down i want to see that like scientific notation though then i know i'm really doing something right okay oop hiccup a hiccup the number went up this is very exciting i mean needs really needs some kind of like something all right 256 128 8 128 256 3136 that's right total parameters trainable parameters nontrainable members okay we got the model summary might need more epochs or a higher learning rate well let's just see how this i refresh this should be oh no this is still whoa what okay this is insane i've not seen it do this wait but am i loading the correct model yeah look at look at this crazy model what it's like outputting so funny i was there was a time earlier today where my model trained perfectly and now what is going on uh k weekman this is our current setting um where oh sorry i mean the wrong code the current this is the current setting um yeah where's the noise coming from right yeah let's let's let's remove the noise at least in our input image just to see how well the model is performing otherwise um this is so weird the model was trained and has some like i think this is because of relu in the last no i mean where did that noise come from where are those dots come why are they there correct i know everyone in the chat is like 30 seconds behind me but the left is the input image the right is the output and i'm not sure where this new noise is coming from uh the dots are because of the rayleigh on the last layer negative values becomes zeros oh over 255 um okay so maybe maybe it's just an issue with me drawing it i have an idea hold on hold on i think there's an issue just with me drawing it so uh where am i where am i getting the values predict await output array output image render output image fill so um let me get that value and let me constrain it to between 0 and 255. no it's still there it's very consistent relu is in the last layer clip the values i thought that's what i was doing um this shouldn't make any difference all right what if hold on if val is less than okay hold on get rid of the constrain maybe what i don't want to do is constrain if val is less than zero val equals 255. let me just make sure i'm actually editing the right code okay i'm totally lost all right try sigmoid okay we're going back to sigmoid people so i want the last layer to be sigmoid and i want to just say atom here this is what i want i want this simplicity and this worked yeah um i mean do i just need more units i shouldn't why why why why why what's going on this was working two hours ago no problem it was training perfectly and it was reproducing it perfectly oh we can ignore this nonsense i mean maybe i should really be controlling the learning rate i'm reading the comments right now and i'm appreciating them i've got to figure this out shuffle i didn't change anything the only weird thing i did was like adding the layers through this weird other way but i don't understand how that could possibly be different and the model summary makes sense i'm so frustrated oh my god it's 1 40. this i have me i have a meeting i have to go to the input is a 56 by 56 image i had upped the resolution because why not i could certainly lower it back down just to like yeah i mean we could lower it back down until everything will run a lot faster let me try that i'll make a new set of images stroke weight at 8. well there we go there we go so okay so why was 56 by 56 freaking it out so much like it's really not that different of a problem to learn i guess it's just the orders of magnitude higher all right well i'm going to go with this just because so this has to change i got to change this to 28 which would be the only thing that matters this is done okay i must have some kind of scaling thing off because i changed it to 28 somewhere i'm not using these anymore where did i mess up this is not a thing this is not a thing i'm doing what is going on are my output images correct no oh no something is totally messed up when i changed it to 28 by 28 that's weird am i hard coding in oh wait no okay 28 by 28. where huh what have i done why did i destroy everything look at the chat regenerate images all right okay okay did i not regenerate the images i didn't regenerate the images is that really true i thought i did but i guess i didn't oh hi gloria gloria woke up oh but now i'm stuck again oh no i'm not okay okay okay everybody i forgot to generate them gloria come here come here girl you need to go outside huh come here do you want to say hi okay she does not love to be picked up oh come here oh you're a good doggy but she does let me pick her up okay oh yes look at that loss function that is a good loss function okay would you like to go back down okay go back down gloria okay oh god she is shedding like crazy okay okay all right well at least this is working now let me put the noise back in although i had it working at a higher resolution which was nicer oh i'm good i'm gonna lose my mind here let me put the uh points back in and put some noise back in and we're denoising again and we're denoising so now now i can do the latent variables the smooth version of relu is soft plus okay so simon i see your messages about the activation function um so i but i think i'm gonna have to investigate that for right now what i just want to do is see if i can get the decoder only to work okay everybody and i've got 15 minutes to do this so first of all did did i save the decoder yes so this should be the decoder and it has half the number of parameters so that makes sense that it's half the weights so now let's see if i i'm going to make a separate folder called decoder and then i'm going to take indexed index.html sketch.js put that into here and make a folder called model and that will go into here and then in the code where it is saving the decoder um so many things here i had so many ambitions of like some things i was going to do with this that i am definitely not getting to um if i am the the it should be public decoder slash model it's where it should be saved i just changed it to that now i should be able to go slash decoder this is going to break right okay this is going to break increase either the layer sizes or the amount of training data yes 100 right more layers and nodes but resolution is a matter of data size thank you so if i create some versions of this after today or anybody helps with this i'm gonna get back to a higher resolution but right now this i'm gonna i'm gonna close things because i don't know where i am this is now the decoder sketch and the decoder sketch does not need an input canvas an input it does need an output image which i'm going to make random and we're going to load model.json this is the decoder get rid of this diameter now next image is the i need to make it it's not an input and image anymore it should just be six the decoder should take uh let like the z vector the latent vector should have how many values in it did i end with 8 or sixteen i think i did eight right so this middle layer oh sixteen i i had sixteen okay i gotta redo this with less i wanted to get it down to four but fine 16. that's why i trained the model i have a trained model that works so let's just find out 16 values z index i equals random one so i'm just going to give it a random vector and then x test it's not really a test isn't really exactly right should be just the one z vector predict await and then everything else should be the same except i am only rendering there's no input image anymore i am just rendering the output image and it should be 280 by 280. so i have no idea if i did this right but let's see uh error due to auto encoder so decoder oh this is decoder square was expecting the number for the third parameter let's get rid of doing it again output print so it got a tensor okay weight output array it got an array of values oh i think maybe no i'm filling it at the beginning so let's let's not call this for a second ah w is 28 i'm going to look at the chat okay so what it's getting something it's getting 784 pixels i plus j times w oh wait oh let me no loop please sorry but this worked so where was the error and why isn't it drawing anything square is expecting a number for the third oh does w not oh my goodness so for all this sorry everybody i forgot about it's just that okay boy tiny little mistake there so now we should actually be able to all right so that's one image i got from the model uh oh am i supposed to put a weight here i think i might have killed this let's take out that print oh i still have some other crazy console log so i would have expected this model not to produce such like fuzziness but let's just out of curiosity if i give it like all point five yeah hmm oh but this is the input is like part of could it am i like oops no no no no interesting so the question is did i make a mistake somewhere yeah right okay so i guess i can't really i'm not really going to be able to sit onto saying this generate just as just using the d you have to reparameterize the latent vector so i was going to just make sliders so my my plan was this follows um so take a look at this um uh sliders push create slider so the range should be between 0 and 1 starting value of 0.5 and an incrementation value of 0.01 and then what i wanted to do was have this do sliders index i value output image not being defined what did i do here oh line 34. what did i mess up oh did i lose that i still lost that by accident no oh let sliders equal an array oh not sliders index i sorry okay so i want to get this down to many fewer than just do like four and then see what i could i can see oh this makes it more square squared a circle this parameter yeah i know i know i need to use a variational auto encoder i just thought maybe the scale of relu is unbounded yeah so do i should i change that to sigmoid also would that help or like should i let them like the other thing i could do is just let the sliders have like a really higher range oops i keep doing this right i can get all sorts of interesting stuff all right so why don't i'm going to try the following and i realize i just i keep running this by accident so i'm going to let this run again and i'm going to go back to my model and i would like this i would like this let me get this down to eight i kind of want to make this four and then this activation should be sigmoid meaning these four units coming into here and i could add more layers but i don't know that i really need to um we'll all will be between zero and one yeah and i could look at some of the compressed images to see some values yeah but let's let's try this okay i'm stuck at a loss uh oh so close so close lower latent space i know would give worse results i just don't want to have so many sliders yeah it is good results so far so i is it going to help at all if i add some more layers increase the training data size oh wait oh oh it i just wasn't patient enough it like was stuck and then it caught okay hold on let me undo that let me undo that last little little extra thing i added okay now um go back to the sketch and it's still 16. it's still 16 but i used sigmoid yeah this is much better it's just too many latent there we go so i'm able to control all the different variables and i can kind of try to figure out which ones do which i'm trying to figure out how to make whoa there certainly is some extra weirdness here anyway this is exciting but i i really want it to be like eight so what if let me let me just it's two o'clock so i've got to be done i can't believe how much time i spent doing this um but this will be my last attempt i'm just going to like pump it up a little bit i don't know that this matters i'm going to give it an additional layer with 64. i'm going to keep the 16. i really think i should be able to get it down to 4. then i'm going to put it down to 4 and make that sigmoid then i need to add back in a 16 and a 64 right and should i make many more training images is that going to help me like if i make um 2100 i'm going to double the training images i really want i really want it to be all right let's do let's do 50 100 images i'm gonna get it down to four and i'm gonna let it train for 200 epochs um 200 image so this has to be 5 000 i know i need to make the images and 5 000. we run this i could also constrain the squares and circles to be less yeah so flubby everybody's telling me this really good suggestion which is to pass images through the encoder and look at latent vectors because that would certainly help give me a sense and that's a very important uh analysis that i could do right two should be enough one for the type of shape and one for the radius this is going to take a while i'm still just generating the training i'm just going to tell you about today's sponsor curiosity stream are you still watching this have you been watching this for three hours i can't believe how much time i'm spending on this auto encoder i hope that this will add to my life in some meaningful way this has got to be the last attempt and now that i have a model for this i can off on my own and you i'm going to push all this to github all of you can try tweaking this in different ways and let me know what configuration architecture of the model how many units you're able to get them to what i'm missing here i will accept pull requests because this is my last live stream one more line needs to be modified from one thousand to five thousand okay where's that i think i got both of them oh is it where i'm loading the images no i think i'm good i think i'm good yeah think of how many eternal rainbows you could all be has anybody signed up for curiosity stream and watched the rainbow documentary you could have watched it like 10 times crossing stream flat coating train okay okay let's try this okay okay patience patience everybody line 17 oh thank you got it oh this took a long time come on lower that loss you can do it lower that loss oh yes oh i like that i like that oh my god somehow i signed up for 200 epochs of this yeah so more data was clearly something i needed to do i also added more layers how long is it taking three seconds per epoch so i got like a little bit more so i got like 600 seconds left to go 10 minutes i mean i'm not going anywhere oh this is just the last live stream related to this auto encoder decoder project i mean i'll probably come back yeah i've got a really nice gpu sitting over here on the machine i'm using stream well the point of doing this was just like little bits of data oh that is a beautiful loss as soon as that scientific notation comes in i definitely do not need 200 epochs but i'm afraid to stop it oh yeah everybody while this is training you should sign up for the one year curiosity package it's less than it comes out to less than one dollar per month i'm not talking about less than one dollar per day at the local coffee place it's very expensive two cups of coffee for the entire year there you go two cups of coffee you know i get the oatmeal which costs 50 cents extra and then you can just watch this documentary about rainbows which is 22 minutes long over again you can tweet me and say thank you so much i watched the rainbows over and over again mark edward i haven't so my battery died simon ah pca yes code parade was doing projects like this uh so wait hold on come back see how this is going uh we're at epoch 63. oh why didn't i put in the lower north e box i just i could put in 150 epochs run it again but it's still going down let's get it let's let it look simon says oh sorry this i guess i could try to plug this in do i have a plug for it somewhere code parade was doing some projects like this the music was loud sorry about that i thought i turned it down um it always saves models every 10 ebox i know i don't think i put that in there i don't think i added any code to like save the model every so often and it's not improving anymore oh no there we go huge jump down um but simon is suggesting that i can use basically uh pca or principal component analysis to sort the sliders from most to least important um if you change your clock on your laptop it would already be finished don't think that's how it works hold on i can send some important text messages i'm going to be done in 10 minutes okay uh like the nice thing is didn't get very cold in here sunny out um where's gloria hopefully gloria didn't like pee somewhere because it's i've been taking her outside and this whole time i've been live streaming um are we i've lost track of what the loss is doing oh yeah it's going down further because i've got a if anybody could work out the sort of time travel i mean i just have to let it go at this point um i'll answer questions i don't know i could i could do some other work i could tell you more signing up for curiosity stream uh oh okay mark edwards today i just got here can i get a quick recap yes thank you for asking i'm gonna move over here just to have just to like get my legs moving a little bit so i'm building this is now my fourth live stream i'm building an auto encoder project and i'm using the tools of tensorflow.js which is a machine learning library in javascript and p5 which is a creative coding library in javascript that is good for like drawing and animation images i this diagram is completely sort of like not that useful anymore so me standing by it take that for what it is but um an auto encoder a great summary of what an auto encoder is you can find in this two minute papers a youtube channel what is an auto encoder and the idea is for a neural network to learn the um like a sort of like lower dimensional representation of an image that's a terrible way to explain it an autoencoder is a mechanism for taking an input image and copying it to an output image which is a very simple thing to do with just basic image processing algorithms like take every pixel copy every pixel but the hook here is that the auto encoder is not just taking all the pixels and copying them to the output it's sending all the pixels through a neural network that with each layer of that network has less and less and less numbers that it's allowed to work with so it's like an image compression algorithm and then a decompression algorithm can the neural network learn how to um sort of encode the represent encode an image into a smaller number of numbers and right now i'm actually trying to take these images of simple shapes they're squares and circles and encode them down to four numbers and really it should just be two theory we should be able to do two because there's only two variables it's either a square or a circle and it's the other variable is how big is it but i'm going with four so i have that working i've built all the code for it now i am training the model and i i just put in 200 epochs because i wanted to give it enough time to train and then when it's done what i hope to see this was like an earlier version of it is something that produces a much higher quality image than what you're seeing in terms of like it appearing to be a circle or a square and that i only have to play with four sliders to kind of manipulate it that's what i'm going for is there an epoch training dance no i'm so tired and hungry and exhausted and lost that i don't have one but if i could get it back it was only like this is how i feel this is my epoch training dance 164 168. yes yes so mikhail is this i love this comment i still don't get how the compression works you've gone from shape and radius to shape and radius and a few hundred kilobytes of weights so to be clear i'm not actually doing anything of any utility whatsoever i'm trying to demonstrate the concept to and to help my understanding of how to architect machine learning models how to experiment with them how to perhaps make creative output with them and in a way like the concepts that i'm demonstrating with this very very basic scenario would hopefully extend how the music is would hopefully extend to use of say something like a more you know a gan or a style gan model sort of like looking at how generative models work thinking about how latent space and latent variables work i'm hoping that this whole process could um could provide something of note there but yes i mean i could write the code to just make the slider to a button and a slider and just manipulate them to get a circle or a square of a variable size um so there is um a coding trained group this is uh sa mckenzie asks i'm sorry if i tell me how to fix my name pronunciation um are you doing advent of code this year not so much personally although maybe now i might have some time to i'm just on my own but i don't think i'll be streaming it but there is a coding train advent of code team or whatever it's called and you can um if you're in the discord somebody please post the discord link you can find out information about joining and having your advent of code contribute to the leaderboard uh kobe who is the discord manager is organizing that so apologies for not knowing too much about it but you can definitely check into that yes so this is the older version with a less a poorly trained model and 16 latent variables when this finishes oh it finished oh my god so let's just look at this for a second 256 128 64 16 4. 16 64 122 okay that's right now hopefully oh it's a madeup name essay mcquenzy so it's a madeup name i don't know how it's pronounced great my friend seizure was great okay so now if i come back to my sketch that loads the decoder only i should be able to do this with just four sliders i think that's the only thing i need to change let me just make sure was this a new model from 2 16 p.m all right everybody i really should not do this any time and every time i've ever played this sound effect means it's not going to work but i'm about to hit refresh and hopefully we're going to see a nice squirkle there in the center four sliders that allow me to wait okay reading value undefined hmm at least it was just a syntax error ah i hard coded late in total equals four now that was anticlimactic okay i'm so excited oh let me tell you about today's sponsor oh no sorry sorry sorry okay refresh oh i like it i like it okay circle to square to square okay interesting so how what these variables do your guess is as good as mine maybe i um and i think i would love to do the random walk now but this is really really everything i ever wanted in an auto encoder latent vector exploration p5.js sketch i've only had an hour until i have a meeting in 10 minutes and i was planning to eat lunch in between this live stream and this meeting and answer all my emails and do everything else i needed to do so i can't do the random walk part uh because i would be like oh i have 10 more minutes i'll do it i have to just stop but um i will do that on my own let me push the code so the new things i'm adding are adjusted the data generation i guess this uh i added the the node cert the nodes code now trains the model and siphons out the decoder only i've got a new model and a new sketch a new model adjusted the sketch a little bit and then there's the new decoder and then i saved that earlier squirkle model so let me add all this live stream 4. um and if you're wondering oh if you're wondering um oh those models must be big if you're wondering where you can find all this um oh yeah it's here so uh i will accept i'm accepting now um pull requests on this um this was super helpful the way that java gt wrote an issue just to explain some improvements and some ideas i think this project is in a place where i can accept pull requests again i'm not at the moment looking to totally refactor it i i i need to write a message here because i've been i reply to this via in my like live stream many times i want to thank the chief here chief um for this incredible refactoring and contribution but it's too different than what i wrote during the live streams so i would love much rather link out to that but if you can help sort of optimize the sort of like architecture uh the learning rate um so that could get slightly higher resolution i think having four latent variables is good like little design improvements i would gladly take those um but i would very much especially love just documentation so images screenshots gif animations explanations in the readme it's not really your job to do that it's mine but if you're looking to contribute i gladly would take any form of contributions i'm going to put this to bed i think i've only got one more thing on the docket for uh 20 21 and then i'm hopefully relaunching the coding train and new in 2022 it will be the processing foundation end of year fundraiser i think that's going to happen now probably the 20 it's going to happen after christmas before new year's so uh stay tuned sign up for the discord thank you to um sponsor uh please check out i'm you know uh curiositystream.com codingtrain for full access to over a thousand over a thousand documentaries everything that's on nebula all the extra content so many wonderful educational creators for less than one dollar a month for the whole year it's 11.59 special 42 off discount check that out and um i really appreciate all of you sticking with me for this and um i will see you on the next live stream and i'm looking forward to all sorts of new content and community initiative now is the time to join the discord if you want to have a voice in the future of the coding train join the discord i would love to see you there um goodbye i gotta go i gotta i gotta have another meeting in like literally seven minutes i'm gonna do it from right here just i gotta sign out of this computer but hopefully i won't still be live streaming by accident it's the zoom call so i gotta i gotta play my outro music and all of that uh thanks everybody goodbye see you soon oh my god i cannot believe i cannot believe this day maybe i'll make the random walk happen uh just really quickly while i'm playing the outdoor music that's a good idea i didn't even find the outdoor music i don't even know what the outdoor music is anymore as always i always forget that this stop this stock this stop this stop i'm gonna do this stop this stop i'm gonna do this this stop this stop this stop i'm gonna do this stop this dot this dot song never forget this dot i'm gonna say once again here we go sing it with me it's look forward to cartesian coordination autotune and the internet will fix that for me take it with me to cartesian unicorns and rainbows and cupcakes what else is there yes kittens thank you very much kittens and rainbows and cupcakes notice that look what i get i'm really losing my mind okay let's do it and kittens the kittens getting some kittens and kittens the kittens the kittens the kittens kittens and kittens and i just quickly adapted this to move the sliders randomly which is sort of demonstrating a uh oh yes i wanted my stream called three minutes okay goodbye everybody that's hilarious i'm going i'm muting my microphone now i'm gonna let this play for another like few seconds just to the end of this song it's got one minute 30 seconds on the song bye everybody over again all sorts of text generation analysis things that i will use continuously over and over again first thing i need to do is yes okay we're gonna do it kittens the kittens the kittens and kittens kittens and kittens and kittens and kittens kittens the kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens and kittens and kittens and kittens kittens the kittens the kittens have dusted you
