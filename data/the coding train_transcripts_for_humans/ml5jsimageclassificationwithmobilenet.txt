With timestamps:

00:00 - [BELL RINGING]
00:00 - Hello.
00:01 - Welcome to the first code
tutorial that I am ever making.
00:05 - I did make this kind of
long-winded, rambling
00:08 - introduction to what ML5 library
is itself, but in this video,
00:11 - I'm actually going to
make a code example that
00:13 - does image classification.
00:15 - So this is going to be
our "hello world," "hello
00:18 - to machine learning,"
first start.
00:21 - It's one of the easiest
things you can do with the ML5
00:23 - library, and it involves--
00:25 - this is very key--
00:27 - a pre-trained model.
00:28 - So this is not where
everyone starts in tutorials
00:32 - about machine learning.
00:33 - A lot of tutorials
about machine learning
00:34 - start with, like I said
in the previous video,
00:36 - linear regression and the
math and training this.
00:39 - And we're just going to
use a pre-trained model.
00:41 - Somebody else made
a machine learning
00:43 - model that knows how to
recognize the contents
00:46 - of images, and ML5--
00:48 - they open-sourced it,
and ML5 is providing
00:50 - us access to it
within JavaScript
00:52 - to use with the p5 library.
00:54 - So I'm going to write
the code for this
00:55 - and talk about how it works,
but let's first actually--
00:57 - if you just even want to just
play around with this model
01:00 - to start with, you could do
this right here on the ML5 home
01:02 - page.
01:03 - So right here, you can
see this image of a macaw.
01:06 - And guess what?
01:06 - The MobileNet model labeled
this image as a macaw
01:09 - with a confidence of 98.79%.
01:14 - Oh, this must be the best,
smartest machine learning model
01:17 - ever.
01:17 - It's like magic.
01:18 - It just knows everything.
01:19 - And in fact, I can
grab this toucan
01:21 - and I can drag it in
here, and look at this.
01:23 - It's a toucan with a
conference of 99.99%.
01:28 - This is so smart.
01:29 - So smart.
01:29 - I can't believe the
MobileNet model is amazing.
01:31 - Now let's get this
puffin in here.
01:33 - It's got to know
what a puffin is.
01:34 - Look at this.
01:35 - The MobileNet labeled
this as an oystercatcher,
01:39 - and its confidence
is kind of low.
01:41 - Huh.
01:42 - So what's going on here?
01:43 - Why is it not saying puffin?
01:45 - That's clearly a puffin.
01:47 - Well, first of all, guess what?
01:49 - A pre-trained model for
image classification--
01:53 - forget about accuracy-- has
a fixed number of even things
01:58 - in the world it knows about.
02:00 - And one of the things that's
really important if you're
02:02 - working with something
like a pre-trained model
02:04 - is actually to know
what's in that set.
02:06 - Now, it's not the most
easy thing to find.
02:10 - But right here on
the ML5 GitHub,
02:12 - there's actually this
page of JavaScript code
02:15 - that shows all the things that
the MobileNet model happens
02:20 - to know about.
02:20 - In fact, there
are 1,000 classes.
02:23 - And you could see this is crazy.
02:25 - It knows about a beagle and a
bloodhound and a black and--
02:27 - and a English foxhound.
02:29 - It's trained to know
obscure dog breeds.
02:33 - But if I look for puffin,
it's nowhere to be found.
02:38 - Oystercatcher,
however, is in there.
02:40 - And if I were to look-- like,
what does an oystercatcher
02:42 - look like?
02:45 - It kind of makes sense.
02:47 - That's the thing it knows
about that's closest to puffin.
02:50 - So if your project
is all about puffins,
02:54 - you're not out of luck.
02:55 - And I will show you ways to
train with your own data,
02:59 - to retrain a pre-trained model.
03:00 - But right now, we're
at this starting point.
03:02 - So birds aside-- it happens
you know a lot about birds.
03:06 - It happens you know
a lot about dogs.
03:08 - But let's just say, for
the sake of argument,
03:11 - I'm going to now give it
this coding train logo.
03:13 - It thinks that's a wall clock,
and it has a low confidence.
03:16 - And that-- I don't know,
maybe because of what's
03:19 - here, the flat nature of it.
03:22 - I can give it an
image of myself.
03:24 - It thinks I'm a snorkel,
which strangely is probably
03:27 - quite accurate.
03:28 - I'm kind of snorkel-like
in more ways than one.
03:31 - But whatever.
03:32 - Maybe that's too weird.
03:33 - But the point is, it actually
knows nothing about people,
03:37 - and it knows nothing
about a lot of things
03:39 - that exist in our world.
03:41 - Who made these decisions?
03:43 - What's in the pre--
03:44 - why are these classes
written this way?
03:46 - And what was it
even trained with?
03:47 - So first-- so let's
talk about for
03:49 - a second supervised learning.
03:51 - What is supervised learning?
03:52 - So image classification.
03:53 - What's happening with
image classification?
03:55 - So the stage that we're
going to do in our code,
03:58 - we're really just going to
do the prediction stage.
04:02 - So the prediction stage-- we
have this pre-trained MobileNet
04:05 - model.
04:07 - The model expects some input,
and it expects that input
04:12 - to be an image.
04:14 - So that's the
input to the model.
04:16 - Then the model
generates an output,
04:18 - and that output is
a list of labels--
04:21 - cat, dog, puffin, et cetera--
and confidence scores--
04:28 - 98%.
04:31 - Well, I guess the--
04:32 - do the scores all
add up to 100%?
04:34 - I think they should.
04:36 - 90%.
04:37 - 6%.
04:38 - 2%.
04:40 - Et cetera.
04:41 - So this is the stage
that we're doing.
04:43 - But how did we even--
04:45 - how do we get to the point where
we could do this ourselves?
04:48 - So somebody had to do
this with a process known
04:51 - as supervised learning.
04:54 - I'm going to write this down
here-- supervised learning.
04:57 - So supervised learning
involves a data set.
05:03 - And this is often
referred to as a
05:05 - labeled data set,
meaning-- you could
05:07 - think of it as a
spreadsheet, a table,
05:10 - a table of images and labels.
05:16 - Essentially, there's
two columns here.
05:18 - One column is a lot
of examples of inputs,
05:21 - and the other column is a
lot of examples of outputs.
05:24 - So I might have cat.jpeg.
05:27 - Oh, and that's a cat.
05:29 - And then I might
have kitten.jpeg,
05:32 - and that's also a cat.
05:33 - And then I have puffin.jpeg,
and that's a puffin.
05:38 - So the idea here is that there
is this existing training
05:42 - data set.
05:42 - This is a training data set.
05:46 - The data set is used to
train the MobileNet model.
05:50 - It just says over and over
again, here's this image,
05:54 - here's its label.
05:54 - Here's this image.
05:55 - Here's this label.
05:56 - And the process
of how that works
05:58 - involves looking at the error.
06:01 - The model tries to make a guess.
06:03 - Does it get it wrong?
06:04 - Since it knows the
right answer, it
06:05 - can change its
settings to try to get
06:07 - the right answer the next time.
06:08 - This is the process.
06:09 - Once that finishes,
usually the model
06:12 - is tested with some
other images that
06:15 - weren't used in
the training set,
06:16 - and then a paper is written
about it, it's published.
06:19 - Or it might be something
that a company owns and keeps
06:24 - closed down and doesn't
provide access to.
06:26 - It uses it in their own
proprietary software.
06:28 - MobileNet is one that is public.
06:31 - So the important
question for us to ask,
06:33 - if we're going to use
this pre-trained model
06:36 - and we're going to start trying
to understand why it's giving
06:39 - us certain results and
what is it good at,
06:40 - what is it not good
at, is we need to know,
06:42 - what was that training set?
06:44 - In this case, the
training set is a database
06:49 - of images called ImageNet.
06:51 - We can come back
to the computer.
06:54 - Sorry.
06:54 - Whoops.
06:56 - We can look at the
ImageNet website.
07:00 - And look at this.
07:01 - ImageNet is a database of
almost 15 million images.
07:05 - And that seems
pretty good, right?
07:07 - A machine learning
system, for it
07:09 - to do a good job in the
supervised learning process,
07:12 - it needs a lot of data.
07:13 - If we just have 10
images, it's not
07:15 - going to be able
to do very much.
07:16 - There's some tricky things we
can do that I'll show you later
07:19 - with small data sets,
but in general, we
07:21 - need a large data set.
07:22 - So that seems like a good thing.
07:23 - But one thing you
have to realize--
07:25 - what are the motivations
of this data set?
07:26 - Where are the
images coming from?
07:28 - Well, most of the--
07:31 - this data set was really
put together for research
07:35 - into image classification.
07:37 - And in order to
do that, it needs
07:39 - to use, well, images that
are in the public domain,
07:42 - that it can get access to.
07:43 - And frankly, almost all of--
07:46 - it's very likely that if you
do a Google search for any
07:49 - of these-- so any of the--
07:51 - let me just do this
really quickly.
07:52 - So I go back to the labels.
07:53 - Let's look for king penguin.
07:56 - So I'm going to do a
search for king penguin.
07:58 - I'm going to go to Images.
08:00 - I'm going to grab this image.
08:02 - I'm going to do Save Image As.
08:04 - I'm going to save it to
the desktop as Penguin.
08:07 - I mean to go back to ML5.
08:09 - And then I'm going
to go here and say--
08:12 - Look, 100%.
08:13 - Do you know why it's 100%?
08:15 - I am almost sure that
that image is in--
08:18 - I mean, I'm not sure about
this, but go and look.
08:20 - That's probably in ImageNet.
08:22 - So a lot of these things that
come up in the first search
08:25 - result that are in the
public domain for Wikipedia,
08:27 - they're actually in
that image database.
08:30 - So it's going to work
really well with something
08:32 - like that versus the
image of a puffin that's
08:34 - not in the database.
08:35 - Doesn't even know
what a puffin--
08:36 - So maybe if we could find
an image of a penguin that's
08:38 - not in the database,
ImageNet database,
08:41 - it probably would
guess it as a penguin.
08:42 - But we wouldn't necessarily
see that much of a confidence.
08:45 - Maybe if we had a zoomed-out
picture with a lot more
08:48 - background noise--
08:49 - something that you could
try that's super interesting
08:51 - is to just download this image
and draw over it or change
08:54 - a couple of pixels.
08:55 - What happens to the image
classification afterwards?
08:57 - All these things you could try.
08:58 - And better yet, you can try
them by writing your own code.
09:02 - So I think it's time--
09:03 - I've rambled on and
on for long enough
09:06 - about what this model is.
09:07 - The last thing I'll
mention is, if you really
09:09 - want to dive deeply into
the MobileNet model,
09:11 - there is a whole paper
written about it.
09:12 - There's a GitHub repository.
09:13 - I'll link to all that stuff.
09:15 - I encourage you to
research this stuff
09:17 - and to think about it, to ask
questions, and to be critical.
09:20 - What are the motivations
behind the creation of a model?
09:23 - What data was used
in that model?
09:25 - And where might you want
to use it or not use it?
09:30 - So all that aside,
let's actually
09:32 - write some code to
use the model now.
09:35 - We're ready to write the code.
09:36 - Now, what I'm starting
with is one JavaScript file
09:40 - with a little bit of code in it.
09:41 - Again, I mentioned I'm
using the p5 library.
09:43 - The p5 library supports
a setup function
09:46 - which executes when
the web page loads.
09:48 - createCanvas makes a canvas.
09:50 - And now I color the
background with the color 0,
09:53 - which is black.
09:54 - And if I go into
the browser, I am
09:56 - able to see the
results of this code
09:59 - because I also happen to be
running a local server using
10:02 - a node server package.
10:05 - Now, there are so many
ways that you can run a web
10:09 - page that's running JavaScript.
10:10 - And you could use CodePen or
OpenProcessing or something new
10:15 - that's going to be
coming out soon,
10:16 - which is a p5 editor
that you could use online
10:18 - that, when it comes
out, I'll link
10:19 - to it in the video description.
10:21 - But for right now,
I'm going to use
10:23 - my workflow of
having my own text
10:24 - editor on my computer and the p5
libraries imported in the HTML
10:31 - file.
10:32 - So here's the HTML file.
10:33 - The only thing it's doing
right now as it's referencing
10:36 - the p5 library and something
called the p5.dom library
10:39 - which I need for some of
the things I want to do.
10:41 - And then also, of
course, my own sketch.js.
10:44 - I have a video where I go
through my entire workflow
10:48 - in more detailed steps.
10:49 - I will also link to that
this video's description.
10:52 - Now that that's
settled, though, I
10:53 - can actually start to use ML5.
10:55 - So how do I use ML5?
10:57 - So right here, I'm
on the ML5 homepage.
10:58 - The first place I
should go is just
11:00 - click on this big
Get Started button.
11:01 - So I'm going to click on that.
11:03 - And I totally clicked
around to the wrong place.
11:07 - Let's try that again.
11:08 - I'm going to click on
the Get Started button.
11:11 - And I'm going to
go right down here,
11:12 - and I'm going to look at this.
11:13 - This is what I need.
11:15 - Now, I can download the ML5
JavaScript library file itself
11:20 - and include it on my computer.
11:21 - And I might want to do that
if I'm going to work offline.
11:24 - But I prefer to just reference
this particular URL in a script
11:29 - tag.
11:29 - And this is-- at the
time of this recording,
11:32 - this is the current version
of the ML5 library--
11:35 - 0.1.1.
11:36 - Now, by the time you're watching
this, it might be like 7.8.6.
11:40 - And if that's the
case, this video
11:42 - probably means absolutely
nothing whatsoever.
11:45 - But if it's relatively
close to that version,
11:47 - hopefully this video is
still helpful to you.
11:50 - I will not make my
joke about your brain
11:52 - being inside of the
gelatinous thawing machine
11:54 - thing in this video.
11:56 - I've made it too many times.
11:58 - It's not even a--
it's not even funny.
12:00 - So I'm going to
put that in here.
12:02 - I'm just going to go
back to my web page,
12:04 - and I'm going to refresh.
12:05 - It's still working.
12:07 - Good.
12:08 - So now we have the
ML5 library imported.
12:10 - We can start calling
ML5 functions.
12:12 - So one thing I might actually
do is just go back to the ML5
12:16 - website-- oops, sorry--
12:17 - which is here, and
click on Examples.
12:20 - And I could go down to
Image Classification,
12:22 - and then I could start
looking at this code
12:25 - and copy-pasting some stuff.
12:27 - I'm going to type it out.
12:28 - And I have some of
this in my head,
12:29 - so I can just type it out.
12:31 - But more importantly, probably--
12:33 - there are these examples which
you can use to get started,
12:36 - but I might also
suggest just having
12:38 - the web page open
to the reference
12:40 - page for a particular feature.
12:41 - So again, I want
to have videos that
12:43 - go through all of
these features,
12:45 - but let's go through the
Image Classifier one.
12:47 - I'm going to click on that.
12:50 - So now, this is
the documentation.
12:52 - There's a little bit
of an example here,
12:54 - and there's some information
about the syntax.
12:56 - And if I get confused, I
can refer back to that.
12:59 - But since I know some of
this having done this before,
13:02 - I'm going to just start writing
directly into sketch.js itself.
13:07 - So the first thing
that I need to do
13:09 - is I need to create an
image classifier itself.
13:12 - So I'm going to make
a variable, and I'm
13:14 - going to call it classifier.
13:16 - And actually, you know what?
13:17 - I'm going to call it mobilenet
because I want to remind myself
13:20 - that this is not
magic, that this
13:22 - is using a very specific
pre-trained model called
13:24 - MobileNet.
13:25 - So I'm going to call
my variable mobilenet.
13:26 - Then I'm going to say mobilenet
equals ml5.imageClassifer.
13:33 - So this is a function
that generates
13:34 - an image classification object.
13:36 - It's going to be stored in
that variable mobilenet.
13:39 - And now it needs some arguments.
13:41 - So what goes in there?
13:42 - Now, the truth of
the matter is, there
13:46 - might be a variety of
things you can put in there.
13:48 - At the time of this
recording, there's
13:50 - really only one option,
which is the MobileNet model.
13:54 - So I'm telling ML5 that I want
to make an image classifier,
13:57 - and the first
argument I'm giving it
13:59 - as a string with the
name of the model.
14:02 - Now, in theory, as ML5 supports
additional pre-trained model,
14:06 - I might get to type something
in here, like UnicornClassifier.
14:10 - Maybe it classifies all
different kinds of unicorns.
14:14 - MobileNet.
14:14 - And then I need something
else really important.
14:16 - I need a callback.
14:19 - Deep breath, deep breath,
deep breath, deep breath.
14:22 - So I've got to
stop for a second.
14:24 - Oi.
14:26 - The ML5 library
supports callbacks,
14:27 - which is what I'm going to
use in these video tutorials,
14:30 - and something called promises.
14:32 - If you don't know what
a JavaScript promise is,
14:34 - I will refer you to my playlist
about JavaScript promises,
14:37 - and you might look at
some of the documentation.
14:40 - But if you're
someone who already
14:41 - uses JavaScript promises,
it's another way
14:43 - of handling asynchronous
events that's
14:45 - slightly different but
very similar to callbacks.
14:47 - That's something you can
go and do on your own,
14:50 - or I'll make some
videos about that too.
14:52 - But right now, I'm going to
use the callback methodology.
14:54 - So the idea here as I type
in the name of a function.
14:57 - I could also put an
anonymous function
14:59 - in there called model ready.
15:01 - And I'm going to write--
15:02 - I'm just going to
put that function
15:04 - up here in the global
space because that's
15:06 - going to be very simple.
15:08 - And I'm just going to say
console.log, "Model is ready!"
15:15 - So the idea here is I am now
creating an image classifier
15:18 - with a MobileNet model.
15:19 - It's going to take some time
for it to load that model.
15:21 - This is not a small thing.
15:22 - Now, it's called MobileNet
because it's actually
15:24 - a tiny model that can
even run on mobile phones.
15:27 - So this code would work well
even in a mobile browser.
15:31 - But even the tiniest
model is something
15:34 - that's got some size to it.
15:35 - It's going to take a
little while to load.
15:37 - So let's go see how long.
15:39 - I go over here, into here.
15:41 - I'm going to hit Refresh.
15:42 - [WHISTLING]
15:45 - Model is Ready.
15:46 - So I don't know-- that
was a few seconds.
15:48 - You can see-- now, one thing
that's interesting-- where
15:50 - did it load the model from?
15:52 - Does the ML5 library have
a copy of it loaded--
15:55 - actually, no.
15:56 - So one thing that's
important here is a lot
15:59 - of the pre-trained models--
16:00 - this is going to be
different, but a lot
16:02 - of the pre-trained models that
you might make use of in ML5
16:05 - are actually loaded
from the cloud,
16:07 - meaning some underground
bunker of servers
16:10 - where the model file is stored.
16:13 - And I believe it's coming
from a Google server.
16:17 - So if you're not
connected to the internet,
16:20 - this example won't even run.
16:21 - At some point, it would be
nice to support ways of running
16:24 - MobileNet model offline.
16:25 - It is certainly
technically possible.
16:26 - But the ML5 library--
not all of the examples,
16:29 - but this example in particular
requires you to be online.
16:33 - So the model is ready.
16:34 - So now what can I do?
16:36 - I can classify an image.
16:39 - This is fun for me.
16:41 - All right.
16:42 - So let's see.
16:44 - I already have in
this directory a bunch
16:47 - of those images that I
was experimenting with.
16:49 - Let's start by using the
puffin, since that's one
16:51 - that we worked with earlier.
16:53 - Personally, I like
to use in my examples
16:56 - stuff that doesn't work because
it leads you to ask questions.
17:01 - If stuff just
works, it can start
17:03 - to feel like magic and you can--
17:05 - it's important to
think about why stuff
17:07 - and how stuff is working.
17:09 - So what I'm going
to do in setup,
17:11 - I'm going to make a
variable called puffin.
17:14 - Puffing.
17:14 - Puffin.
17:15 - And I'm going to say,
puffin equals createImg.
17:19 - Now, this is a particular
function in the p5 library.
17:23 - This is now-- like createCanvase
is p5, createIMG is p5.
17:27 - This makes a dom element, an
image element on the web page
17:32 - that is that image.
17:34 - So if I were to reload this
page, you're going to see--
17:37 - OK.
17:37 - Ah, it's in the
directory images,
17:40 - so I need to include that there.
17:41 - You're going to see
there it is down there.
17:43 - Now, I can do things, like
if I wanted to have this all
17:45 - happen in my canvas, I
could say puffin.hide,
17:49 - and then I can actually
say image, puffin.
17:52 - And this won't work, but it'll
be interesting to think why
17:55 - for a second.
17:56 - And I want to draw the
puffin into canvas.
17:58 - The reason why it didn't
work is, once again, things
18:02 - don't happen in JavaScript
instantaneously.
18:04 - So it's going to take some
time to create that image.
18:08 - I'm going to-- I could give that
a callback called imageReady.
18:12 - A lot of this stuff is
unnecessary to the example
18:14 - I'm building, but just
to demonstrate the idea.
18:17 - And then, now I'm going to
draw the image into the canvas.
18:21 - Ah, but that image is really a
big size, so I could resize it.
18:25 - Or I could just force it to
be the size of the canvas.
18:28 - And there we go.
18:29 - So I now have a p5 canvas
displaying my puffin image,
18:32 - and the model is ready.
18:34 - So now, once the model
is ready, what can I do?
18:38 - I can classify the image.
18:40 - I can try to ask
MobileNet what's in it.
18:42 - And the way I do that is with
a function called predict.
18:46 - So you'll see different
names for different functions
18:48 - in the ML5 library.
18:49 - Predict will come up often.
18:51 - It might change to classify by
the time you watch this video,
18:54 - but I think it's called predict
right now, this version of ML5.
18:58 - I'm going to say
mobilenet.predict puffin,
19:04 - meaning I want
MobileNet to give me
19:06 - a prediction of what it thinks
the content of the puffin image
19:10 - is.
19:11 - And then, guess what?
19:12 - That takes some time.
19:13 - It doesn't happen
instantaneously.
19:14 - So I need yet again
another callback.
19:17 - And I'm going to give it a
callback called gotResults.
19:19 - And again, I could do
this with a promise
19:21 - if that's something that
you're more comfortable with,
19:23 - but I'm going to
do with a callback.
19:25 - And then I'm going to write
this function called gotResults.
19:28 - And now, if you've
used p5 before,
19:31 - this is very
similar to loadJSON.
19:33 - Oh, I want to load the
data from this JSON file.
19:39 - And then, you usually
have an argument
19:41 - to the callback which
has the stuff in it.
19:43 - The stuff that you want
fills that argument.
19:46 - But here's something.
19:48 - ML5 works with error
first callbacks.
19:50 - This is a JavaScript
pattern where,
19:52 - when you write the
callback, you always
19:55 - must include as
the first argument
19:58 - an error argument,
an error variable,
20:01 - meaning the library is forcing
you to check for errors.
20:04 - So in this case, I might
want to say something like,
20:06 - if (error)--
20:08 - whoops, not a new promise--
20:11 - console-- and by the way,
I could say console.log,
20:13 - but I can actually say
console.error(error).
20:15 - And then otherwise,
console.log(results).
20:19 - So this is a little bit
of extra error handling,
20:21 - if something went wrong
in the prediction process,
20:24 - hopefully I would
see that there.
20:25 - Otherwise, I'm going
to see the results.
20:30 - Let's see if this works.
20:35 - Model is Ready.
20:36 - Model is Ready.
20:38 - And then-- oh, look at this.
20:40 - [MUSIC PLAYING]
20:42 - And here we go.
20:44 - Oystercatcher.
20:45 - And we can see this
probability is--
20:48 - that is crazy.
20:49 - So this is really
interesting to me.
20:51 - This got 75%.
20:53 - Then it also thought
it was albatross
20:55 - and drake, different
probabilities.
20:57 - Now why-- 5%, 11%.
21:00 - Why-- why is this
different than what
21:02 - I got with the oystercatcher
in the home page of ML5JS?
21:07 - I don't know the answer to that.
21:09 - I will have to think about that.
21:11 - It's a different probability.
21:12 - But nonetheless, I'm getting
a pretty similar result.
21:14 - It might have to do with
versions of something,
21:16 - and that the home page is
running a different version
21:18 - of something.
21:19 - But we can see this is the idea.
21:20 - Now what I could what do is
I could go and I could say,
21:24 - all right, let me get
the label is results.
21:29 - This, by the way, is an array
with three objects in it.
21:33 - So I could say, I want to get
the first object, index 0.
21:38 - And I want to get the class
name, object 0 dot classname.
21:43 - That's the label.
21:44 - And then I'm just
going to draw--
21:46 - I'm going to say
fill(0) textSize(100)--
21:51 - no, starts with (64).
21:53 - I don't know.
21:53 - And then I going
to say text(label).
21:58 - And I'll say 10, and like
height minus 50 or something.
22:02 - I don't know.
22:04 - I'm just putting it arbitrarily
somewhere on the page,
22:07 - on the canvas.
22:08 - So let's run this again.
22:09 - We can see Model Loaded.
22:13 - And then it says
oystercatcher right there.
22:15 - How thrilling.
22:16 - We have now run the MobileNet
model, gotten a prediction
22:20 - for our image, and there it is.
22:21 - Of course, I could
also do something
22:23 - like create a dom
element for the label.
22:27 - I could also get the probability
by saying equals results(0).--
22:35 - and what was it called?
22:37 - className probability is
the other probability.
22:42 - And I don't know if
I spelled that right.
22:43 - And I could create two dom
elements using createP.
22:49 - And we could run
this one more time.
22:52 - And now we're going to
see that stuff down here.
22:55 - It's very, very small.
22:56 - Probability is not defined.
22:58 - Probability.
23:01 - Probability.
23:02 - Oh, prob.
23:04 - I named my variable prob
because I got a lot of probs.
23:12 - So we can see here
there's the probability.
23:14 - So this is the basics.
23:16 - Now you see you could
actually just go and use
23:18 - this in a project right now.
23:20 - I have a couple
of ideas for you.
23:22 - Number one is make
a little interface,
23:24 - try different images.
23:25 - Can you make one
where you can actually
23:26 - drag and drop your own image
like it does on the ML5 home
23:28 - page?
23:29 - Could you make something
where you draw on the canvas
23:31 - and it's trying to classify
what you're drawing?
23:34 - Another thing you could try is--
23:35 - can you get it to classify
what the web canvas is seeing?
23:38 - And guess what?
23:39 - That's what I'm going
to do in the next video.
23:41 - So there are so many more
things you could do with this,
23:43 - but this is the basic idea.
23:45 - Try your own version
of this experiment.
23:46 - Play around.
23:47 - Try a lot of different images.
23:48 - But in the next video, I
am going to basically take
23:51 - this exact example but hook
it up to the live webcam feed,
23:55 - and we can see it
classify images
23:56 - from the webcam in real time.
23:58 - All right.
24:01 - I'm doing this as a
Livestream right now.
24:03 - If you're watching this
recorded, it's recorded.
24:05 - But I'm going to check
to see any questions,
24:06 - and I'll answer those also at
the beginning the next video.
24:08 - See you soon.
24:09 - [BELL RINGING]
24:10 - [MUSIC PLAYING]

Cleaned transcript:

[BELL RINGING] Hello. Welcome to the first code tutorial that I am ever making. I did make this kind of longwinded, rambling introduction to what ML5 library is itself, but in this video, I'm actually going to make a code example that does image classification. So this is going to be our "hello world," "hello to machine learning," first start. It's one of the easiest things you can do with the ML5 library, and it involves this is very key a pretrained model. So this is not where everyone starts in tutorials about machine learning. A lot of tutorials about machine learning start with, like I said in the previous video, linear regression and the math and training this. And we're just going to use a pretrained model. Somebody else made a machine learning model that knows how to recognize the contents of images, and ML5 they opensourced it, and ML5 is providing us access to it within JavaScript to use with the p5 library. So I'm going to write the code for this and talk about how it works, but let's first actually if you just even want to just play around with this model to start with, you could do this right here on the ML5 home page. So right here, you can see this image of a macaw. And guess what? The MobileNet model labeled this image as a macaw with a confidence of 98.79%. Oh, this must be the best, smartest machine learning model ever. It's like magic. It just knows everything. And in fact, I can grab this toucan and I can drag it in here, and look at this. It's a toucan with a conference of 99.99%. This is so smart. So smart. I can't believe the MobileNet model is amazing. Now let's get this puffin in here. It's got to know what a puffin is. Look at this. The MobileNet labeled this as an oystercatcher, and its confidence is kind of low. Huh. So what's going on here? Why is it not saying puffin? That's clearly a puffin. Well, first of all, guess what? A pretrained model for image classification forget about accuracy has a fixed number of even things in the world it knows about. And one of the things that's really important if you're working with something like a pretrained model is actually to know what's in that set. Now, it's not the most easy thing to find. But right here on the ML5 GitHub, there's actually this page of JavaScript code that shows all the things that the MobileNet model happens to know about. In fact, there are 1,000 classes. And you could see this is crazy. It knows about a beagle and a bloodhound and a black and and a English foxhound. It's trained to know obscure dog breeds. But if I look for puffin, it's nowhere to be found. Oystercatcher, however, is in there. And if I were to look like, what does an oystercatcher look like? It kind of makes sense. That's the thing it knows about that's closest to puffin. So if your project is all about puffins, you're not out of luck. And I will show you ways to train with your own data, to retrain a pretrained model. But right now, we're at this starting point. So birds aside it happens you know a lot about birds. It happens you know a lot about dogs. But let's just say, for the sake of argument, I'm going to now give it this coding train logo. It thinks that's a wall clock, and it has a low confidence. And that I don't know, maybe because of what's here, the flat nature of it. I can give it an image of myself. It thinks I'm a snorkel, which strangely is probably quite accurate. I'm kind of snorkellike in more ways than one. But whatever. Maybe that's too weird. But the point is, it actually knows nothing about people, and it knows nothing about a lot of things that exist in our world. Who made these decisions? What's in the pre why are these classes written this way? And what was it even trained with? So first so let's talk about for a second supervised learning. What is supervised learning? So image classification. What's happening with image classification? So the stage that we're going to do in our code, we're really just going to do the prediction stage. So the prediction stage we have this pretrained MobileNet model. The model expects some input, and it expects that input to be an image. So that's the input to the model. Then the model generates an output, and that output is a list of labels cat, dog, puffin, et cetera and confidence scores 98%. Well, I guess the do the scores all add up to 100%? I think they should. 90%. 6%. 2%. Et cetera. So this is the stage that we're doing. But how did we even how do we get to the point where we could do this ourselves? So somebody had to do this with a process known as supervised learning. I'm going to write this down here supervised learning. So supervised learning involves a data set. And this is often referred to as a labeled data set, meaning you could think of it as a spreadsheet, a table, a table of images and labels. Essentially, there's two columns here. One column is a lot of examples of inputs, and the other column is a lot of examples of outputs. So I might have cat.jpeg. Oh, and that's a cat. And then I might have kitten.jpeg, and that's also a cat. And then I have puffin.jpeg, and that's a puffin. So the idea here is that there is this existing training data set. This is a training data set. The data set is used to train the MobileNet model. It just says over and over again, here's this image, here's its label. Here's this image. Here's this label. And the process of how that works involves looking at the error. The model tries to make a guess. Does it get it wrong? Since it knows the right answer, it can change its settings to try to get the right answer the next time. This is the process. Once that finishes, usually the model is tested with some other images that weren't used in the training set, and then a paper is written about it, it's published. Or it might be something that a company owns and keeps closed down and doesn't provide access to. It uses it in their own proprietary software. MobileNet is one that is public. So the important question for us to ask, if we're going to use this pretrained model and we're going to start trying to understand why it's giving us certain results and what is it good at, what is it not good at, is we need to know, what was that training set? In this case, the training set is a database of images called ImageNet. We can come back to the computer. Sorry. Whoops. We can look at the ImageNet website. And look at this. ImageNet is a database of almost 15 million images. And that seems pretty good, right? A machine learning system, for it to do a good job in the supervised learning process, it needs a lot of data. If we just have 10 images, it's not going to be able to do very much. There's some tricky things we can do that I'll show you later with small data sets, but in general, we need a large data set. So that seems like a good thing. But one thing you have to realize what are the motivations of this data set? Where are the images coming from? Well, most of the this data set was really put together for research into image classification. And in order to do that, it needs to use, well, images that are in the public domain, that it can get access to. And frankly, almost all of it's very likely that if you do a Google search for any of these so any of the let me just do this really quickly. So I go back to the labels. Let's look for king penguin. So I'm going to do a search for king penguin. I'm going to go to Images. I'm going to grab this image. I'm going to do Save Image As. I'm going to save it to the desktop as Penguin. I mean to go back to ML5. And then I'm going to go here and say Look, 100%. Do you know why it's 100%? I am almost sure that that image is in I mean, I'm not sure about this, but go and look. That's probably in ImageNet. So a lot of these things that come up in the first search result that are in the public domain for Wikipedia, they're actually in that image database. So it's going to work really well with something like that versus the image of a puffin that's not in the database. Doesn't even know what a puffin So maybe if we could find an image of a penguin that's not in the database, ImageNet database, it probably would guess it as a penguin. But we wouldn't necessarily see that much of a confidence. Maybe if we had a zoomedout picture with a lot more background noise something that you could try that's super interesting is to just download this image and draw over it or change a couple of pixels. What happens to the image classification afterwards? All these things you could try. And better yet, you can try them by writing your own code. So I think it's time I've rambled on and on for long enough about what this model is. The last thing I'll mention is, if you really want to dive deeply into the MobileNet model, there is a whole paper written about it. There's a GitHub repository. I'll link to all that stuff. I encourage you to research this stuff and to think about it, to ask questions, and to be critical. What are the motivations behind the creation of a model? What data was used in that model? And where might you want to use it or not use it? So all that aside, let's actually write some code to use the model now. We're ready to write the code. Now, what I'm starting with is one JavaScript file with a little bit of code in it. Again, I mentioned I'm using the p5 library. The p5 library supports a setup function which executes when the web page loads. createCanvas makes a canvas. And now I color the background with the color 0, which is black. And if I go into the browser, I am able to see the results of this code because I also happen to be running a local server using a node server package. Now, there are so many ways that you can run a web page that's running JavaScript. And you could use CodePen or OpenProcessing or something new that's going to be coming out soon, which is a p5 editor that you could use online that, when it comes out, I'll link to it in the video description. But for right now, I'm going to use my workflow of having my own text editor on my computer and the p5 libraries imported in the HTML file. So here's the HTML file. The only thing it's doing right now as it's referencing the p5 library and something called the p5.dom library which I need for some of the things I want to do. And then also, of course, my own sketch.js. I have a video where I go through my entire workflow in more detailed steps. I will also link to that this video's description. Now that that's settled, though, I can actually start to use ML5. So how do I use ML5? So right here, I'm on the ML5 homepage. The first place I should go is just click on this big Get Started button. So I'm going to click on that. And I totally clicked around to the wrong place. Let's try that again. I'm going to click on the Get Started button. And I'm going to go right down here, and I'm going to look at this. This is what I need. Now, I can download the ML5 JavaScript library file itself and include it on my computer. And I might want to do that if I'm going to work offline. But I prefer to just reference this particular URL in a script tag. And this is at the time of this recording, this is the current version of the ML5 library 0.1.1. Now, by the time you're watching this, it might be like 7.8.6. And if that's the case, this video probably means absolutely nothing whatsoever. But if it's relatively close to that version, hopefully this video is still helpful to you. I will not make my joke about your brain being inside of the gelatinous thawing machine thing in this video. I've made it too many times. It's not even a it's not even funny. So I'm going to put that in here. I'm just going to go back to my web page, and I'm going to refresh. It's still working. Good. So now we have the ML5 library imported. We can start calling ML5 functions. So one thing I might actually do is just go back to the ML5 website oops, sorry which is here, and click on Examples. And I could go down to Image Classification, and then I could start looking at this code and copypasting some stuff. I'm going to type it out. And I have some of this in my head, so I can just type it out. But more importantly, probably there are these examples which you can use to get started, but I might also suggest just having the web page open to the reference page for a particular feature. So again, I want to have videos that go through all of these features, but let's go through the Image Classifier one. I'm going to click on that. So now, this is the documentation. There's a little bit of an example here, and there's some information about the syntax. And if I get confused, I can refer back to that. But since I know some of this having done this before, I'm going to just start writing directly into sketch.js itself. So the first thing that I need to do is I need to create an image classifier itself. So I'm going to make a variable, and I'm going to call it classifier. And actually, you know what? I'm going to call it mobilenet because I want to remind myself that this is not magic, that this is using a very specific pretrained model called MobileNet. So I'm going to call my variable mobilenet. Then I'm going to say mobilenet equals ml5.imageClassifer. So this is a function that generates an image classification object. It's going to be stored in that variable mobilenet. And now it needs some arguments. So what goes in there? Now, the truth of the matter is, there might be a variety of things you can put in there. At the time of this recording, there's really only one option, which is the MobileNet model. So I'm telling ML5 that I want to make an image classifier, and the first argument I'm giving it as a string with the name of the model. Now, in theory, as ML5 supports additional pretrained model, I might get to type something in here, like UnicornClassifier. Maybe it classifies all different kinds of unicorns. MobileNet. And then I need something else really important. I need a callback. Deep breath, deep breath, deep breath, deep breath. So I've got to stop for a second. Oi. The ML5 library supports callbacks, which is what I'm going to use in these video tutorials, and something called promises. If you don't know what a JavaScript promise is, I will refer you to my playlist about JavaScript promises, and you might look at some of the documentation. But if you're someone who already uses JavaScript promises, it's another way of handling asynchronous events that's slightly different but very similar to callbacks. That's something you can go and do on your own, or I'll make some videos about that too. But right now, I'm going to use the callback methodology. So the idea here as I type in the name of a function. I could also put an anonymous function in there called model ready. And I'm going to write I'm just going to put that function up here in the global space because that's going to be very simple. And I'm just going to say console.log, "Model is ready!" So the idea here is I am now creating an image classifier with a MobileNet model. It's going to take some time for it to load that model. This is not a small thing. Now, it's called MobileNet because it's actually a tiny model that can even run on mobile phones. So this code would work well even in a mobile browser. But even the tiniest model is something that's got some size to it. It's going to take a little while to load. So let's go see how long. I go over here, into here. I'm going to hit Refresh. [WHISTLING] Model is Ready. So I don't know that was a few seconds. You can see now, one thing that's interesting where did it load the model from? Does the ML5 library have a copy of it loaded actually, no. So one thing that's important here is a lot of the pretrained models this is going to be different, but a lot of the pretrained models that you might make use of in ML5 are actually loaded from the cloud, meaning some underground bunker of servers where the model file is stored. And I believe it's coming from a Google server. So if you're not connected to the internet, this example won't even run. At some point, it would be nice to support ways of running MobileNet model offline. It is certainly technically possible. But the ML5 library not all of the examples, but this example in particular requires you to be online. So the model is ready. So now what can I do? I can classify an image. This is fun for me. All right. So let's see. I already have in this directory a bunch of those images that I was experimenting with. Let's start by using the puffin, since that's one that we worked with earlier. Personally, I like to use in my examples stuff that doesn't work because it leads you to ask questions. If stuff just works, it can start to feel like magic and you can it's important to think about why stuff and how stuff is working. So what I'm going to do in setup, I'm going to make a variable called puffin. Puffing. Puffin. And I'm going to say, puffin equals createImg. Now, this is a particular function in the p5 library. This is now like createCanvase is p5, createIMG is p5. This makes a dom element, an image element on the web page that is that image. So if I were to reload this page, you're going to see OK. Ah, it's in the directory images, so I need to include that there. You're going to see there it is down there. Now, I can do things, like if I wanted to have this all happen in my canvas, I could say puffin.hide, and then I can actually say image, puffin. And this won't work, but it'll be interesting to think why for a second. And I want to draw the puffin into canvas. The reason why it didn't work is, once again, things don't happen in JavaScript instantaneously. So it's going to take some time to create that image. I'm going to I could give that a callback called imageReady. A lot of this stuff is unnecessary to the example I'm building, but just to demonstrate the idea. And then, now I'm going to draw the image into the canvas. Ah, but that image is really a big size, so I could resize it. Or I could just force it to be the size of the canvas. And there we go. So I now have a p5 canvas displaying my puffin image, and the model is ready. So now, once the model is ready, what can I do? I can classify the image. I can try to ask MobileNet what's in it. And the way I do that is with a function called predict. So you'll see different names for different functions in the ML5 library. Predict will come up often. It might change to classify by the time you watch this video, but I think it's called predict right now, this version of ML5. I'm going to say mobilenet.predict puffin, meaning I want MobileNet to give me a prediction of what it thinks the content of the puffin image is. And then, guess what? That takes some time. It doesn't happen instantaneously. So I need yet again another callback. And I'm going to give it a callback called gotResults. And again, I could do this with a promise if that's something that you're more comfortable with, but I'm going to do with a callback. And then I'm going to write this function called gotResults. And now, if you've used p5 before, this is very similar to loadJSON. Oh, I want to load the data from this JSON file. And then, you usually have an argument to the callback which has the stuff in it. The stuff that you want fills that argument. But here's something. ML5 works with error first callbacks. This is a JavaScript pattern where, when you write the callback, you always must include as the first argument an error argument, an error variable, meaning the library is forcing you to check for errors. So in this case, I might want to say something like, if (error) whoops, not a new promise console and by the way, I could say console.log, but I can actually say console.error(error). And then otherwise, console.log(results). So this is a little bit of extra error handling, if something went wrong in the prediction process, hopefully I would see that there. Otherwise, I'm going to see the results. Let's see if this works. Model is Ready. Model is Ready. And then oh, look at this. [MUSIC PLAYING] And here we go. Oystercatcher. And we can see this probability is that is crazy. So this is really interesting to me. This got 75%. Then it also thought it was albatross and drake, different probabilities. Now why 5%, 11%. Why why is this different than what I got with the oystercatcher in the home page of ML5JS? I don't know the answer to that. I will have to think about that. It's a different probability. But nonetheless, I'm getting a pretty similar result. It might have to do with versions of something, and that the home page is running a different version of something. But we can see this is the idea. Now what I could what do is I could go and I could say, all right, let me get the label is results. This, by the way, is an array with three objects in it. So I could say, I want to get the first object, index 0. And I want to get the class name, object 0 dot classname. That's the label. And then I'm just going to draw I'm going to say fill(0) textSize(100) no, starts with (64). I don't know. And then I going to say text(label). And I'll say 10, and like height minus 50 or something. I don't know. I'm just putting it arbitrarily somewhere on the page, on the canvas. So let's run this again. We can see Model Loaded. And then it says oystercatcher right there. How thrilling. We have now run the MobileNet model, gotten a prediction for our image, and there it is. Of course, I could also do something like create a dom element for the label. I could also get the probability by saying equals results(0). and what was it called? className probability is the other probability. And I don't know if I spelled that right. And I could create two dom elements using createP. And we could run this one more time. And now we're going to see that stuff down here. It's very, very small. Probability is not defined. Probability. Probability. Oh, prob. I named my variable prob because I got a lot of probs. So we can see here there's the probability. So this is the basics. Now you see you could actually just go and use this in a project right now. I have a couple of ideas for you. Number one is make a little interface, try different images. Can you make one where you can actually drag and drop your own image like it does on the ML5 home page? Could you make something where you draw on the canvas and it's trying to classify what you're drawing? Another thing you could try is can you get it to classify what the web canvas is seeing? And guess what? That's what I'm going to do in the next video. So there are so many more things you could do with this, but this is the basic idea. Try your own version of this experiment. Play around. Try a lot of different images. But in the next video, I am going to basically take this exact example but hook it up to the live webcam feed, and we can see it classify images from the webcam in real time. All right. I'm doing this as a Livestream right now. If you're watching this recorded, it's recorded. But I'm going to check to see any questions, and I'll answer those also at the beginning the next video. See you soon. [BELL RINGING] [MUSIC PLAYING]
