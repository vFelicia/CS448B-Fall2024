With timestamps:

00:00 - (bell dings)
- Hello, welcome to session three
00:04 - of The Nature of Code: Intelligence and Learning.
00:06 - So this is one of my
opening videos for these sessions.
00:09 - If you are watching this video
as part of that playlist
00:12 - for the Intelligence and Learning course,
00:14 - you will see a lot of videos in front of you
00:16 - with a variety of demonstrations
and different coding challenges.
00:19 - There will also be a video at the end,
00:21 - where I come back and pose some ideas
00:23 - for an exercise or assignment that you could try.
00:26 - But what I want to do
in this particular video is--
00:29 - Now, now is the time--
this course has just started
00:32 - with this little warm-up of thinking
about artificial intelligence,
00:35 - and search algorithms, and graph systems,
00:37 - and then we took this turn
00:39 - and thought about genetic algorithms
and evolutionary systems,
00:42 - but you might be here because you heard
about this term, machine learning,
00:46 - maybe even heard about
this term deep learning,
00:48 - and you want to get a sense
of what does that mean,
00:51 - what are the possibilities with
machine learning and deep learning,
00:54 - how do machine learning systems work,
what are they for,
00:57 - what's the lingo
for this sort of stuff,
00:59 - and now's the time to get into that.
01:01 - Now, session three here,
01:03 - I will not be using any neural network yet.
01:07 - So what I want to do in session three
01:09 - is just talk about what machine learning is,
01:12 - what its applications are.
01:14 - So something that I'm gonna cover here
01:16 - is classification and regression,
what do those terms mean,
01:19 - and what are some classic algorithms
01:22 - for performing classification and regression.
01:25 - And so, I'm going to look at something
called nearest neighbor similarity,
01:29 - K nearest neighbor.
01:30 - And I'm also going to look
at something called linear regression.
01:34 - And so these will be some
sort of classic algorithms
01:36 - that you can play around with
and actually do stuff with.
01:39 - And then in session four,
01:41 - we'll start looking at
what a neural network is
01:43 - and see how we can use that
as part of a machine learning system.
01:47 - Okay, are you with me?
01:48 - By the way, I barely know how to do this stuff,
01:50 - so if you're watching this for an expert,
01:52 - you probably wanna find somebody else on YouTube,
01:54 - but I'm learning this stuff, trying it out,
01:56 - and hopefully you're gonna come along
and join me on the train, right?
02:00 - Oh, I forgot! We're on a train.
(train whistle blows)
02:02 - On this ride on the train in the sky
02:05 - with me as your guide.
02:06 - Do sky and guide rhyme?
02:07 - I think they do.
02:08 - You'll see.
02:09 - I had a point to this, but I digress.
02:11 - Okay, so what is machine learning?
02:14 - So first of all, one thing
that I might suggest for you
02:16 - if you wanna watch some videos
02:17 - about somebody who really knows
what they're talking about,
02:20 - I would suggest Andrew Ng's Coursera course.
02:23 - A lot of my knowledge and inspiration
has come from that course,
02:27 - and Andrew Ng does a good job
02:29 - of giving a nice introduction to machine learning.
02:32 - And two particular references--
02:35 - one is this definition,
this quote from Arthur Samuels,
02:38 - who is a pioneer in the
world of machine learning,
02:41 - defining machine learning
as a field of study
02:44 - that gives computers the ability to learn
without being explicitly programmed.
02:50 - And so here's an interesting
thing we can think about.
02:52 - When we looked at the A* algorithm
in session one for pathfinding,
02:57 - we were designing, us the programmer,
03:00 - writing an algorithm
to specifically perform a task.
03:04 - The computer would follow those
instructions and get to a result.
03:07 - There was an intelligence to that algorithm,
03:10 - there was the disappearance of sort of
the computer solving a problem
03:14 - in thinking about it, but ultimately,
we had written the instructions,
03:18 - the code for the computer to solve,
to arrive at an answer.
03:21 - So what if, instead of us writing the instructions,
03:25 - we would just set up a framework
for the computer to figure out
03:29 - what the instructions might be,
what are the right parameters
03:32 - for some type of model to
perform some sort of task?
03:36 - So this is the idea of machine learning.
03:37 - And I would encourage you to look
at the work of Arthur Samuels.
03:40 - One of the things that he did
03:42 - was train a computer to learn to play checkers
03:44 - by just having it play itself over
and over and over again,
03:47 - thousands of times, to be able
to learn what a good strategy was.
03:51 - But ultimately--
03:53 - So one of the things that I want
to talk about here is--
03:58 - So let me come over the whiteboard here.
04:00 - I have this README that
I'll link to in the description.
04:02 - You can read some of the definitions
04:04 - and information that's on that README.
04:06 - But what I want to look at
is this model for, this--
04:10 - I'm gonna describe to you machine learning
in this particular way.
04:14 - So there is some sort of input.
04:19 - That input is going to go into
some sort of algorithm, some recipe.
04:26 - I think that's a nice way of thinking about it.
04:28 - Some machine learning recipe.
04:31 - And then out of that machine learning recipe,
04:34 - we are going to get an output.
04:38 - The input into the machine learning recipe
04:41 - is typically numeric.
04:46 - So you could think of it as, you know,
04:48 - a classic example that's always given
04:50 - is what if we want to build
a machine learning system
04:54 - that can guess the price
of a house based on some inputs.
04:58 - so maybe we might say something like,
05:00 - "Oh, the house has three bedrooms,
05:03 - "and it has two bathrooms,
05:05 - "and it has 1,000 square feet."
05:08 - And etc., etc.
05:10 - This is the input into the machine learning recipe,
05:13 - and the output might come,
"The house is $1 million."
05:19 - Something like that.
Nice house, apparently.
05:21 - Okay, so this is what machine--
05:24 - So typically speaking,
05:25 - another way of thinking about machine learning
05:27 - is making sense of data.
05:29 - So I have some sort of data
05:31 - and I want to make sense of it.
05:33 - I have some input and some output.
05:35 - So two kinds of output that you'll see
05:39 - in most machine learning
algorithms are classification.
05:44 - Another kind of output is regression.
05:50 - So what you might not have realized here
05:52 - is this example that I gave to you,
05:55 - where the parameters of a house, a data point,
05:58 - goes into the machine learning recipe
and we get this price output,
06:02 - this is actually regression.
06:04 - Regression refers to predicting
some sort of continuous numeric output,
06:10 - whereas classification refers to
taking an input and classifying it
06:16 - into a discrete set of labels.
06:18 - So here might be another scenario.
06:20 - I have an image of a cat.
06:28 - That is the input into
the machine learning recipe.
06:31 - And the output is something like this.
06:37 - Well...
06:39 - I'm getting the--
usually the output comes numeric,
06:42 - so we have to sort of figure out
what this could mean,
06:44 - but I'm speaking in kind of
higher level terms here,
06:48 - so I'm just gonna say
the output is cat.
06:53 - I am labeling it--
and maybe the only possible options
06:56 - are cat versus dog, so what that output
06:59 - actually is is something like 0.9, 0.1.
07:05 - Like there's a 90% chance this is a cat,
07:07 - 10% chance it's a dog.
07:09 - So this is classification,
07:11 - attempting to assign a discrete label
07:15 - to something like an image.
07:16 - We could've done something with
07:18 - the house data using the classification.
07:20 - We could say, you know, fancy house,
07:23 - summer house, winter house.
07:25 - You know, we could classify into one of two categories.
07:27 - That's classification.
07:29 - Regression, getting a continuous numeric output.
07:33 - So how does this work?
07:34 - So number one is we've got to, at some point,
07:37 - start talking about what are some different recipes
07:40 - that could go in here.
07:41 - And I could name you a few.
07:43 - For example, K nearest neighbor.
07:46 - This is a particular algorithm that can work
07:49 - for both classification and regression.
07:51 - I could say something like support vector machine,
07:55 - or I could say artificial neural network.
07:59 - And then there are a variety of flavors, so to speak,
08:02 - of styles and of artificial neural networks,
08:06 - convolutional neural network,
recurrent neural network.
08:09 - So this is something I ultimately intend
08:11 - to spend a lot of time on.
08:13 - What is an artificial neural network?
08:15 - How does it work?
08:16 - And why is it effective to put it in here?
08:19 - But even with all of the amazing innovation
08:21 - that's happening in machine learning
and deep learning right now,
08:24 - there's a lot that you can do
08:26 - without artificial neural networks.
08:29 - A lot of simple, fun exercises and things.
08:32 - So in this particular session, session three,
08:37 - I'm gonna look at the other algorithms
08:39 - that are non-artificial neural network--
08:41 - non-neural network based that
become the machine learning recipe,
08:44 - like K nearest neighbor.
08:46 - But let's take a moment here to talk about
08:49 - how overall this works,
08:51 - because the thing is this doesn't just happen magically.
08:55 - You can't just--
08:57 - The point of doing this is that
08:59 - at some day, we might want to put
an unknown image in here
09:03 - and get a classification label for that image.
09:06 - But how could a machine learning
recipe do that from nothing?
09:09 - And it can't.
09:11 - So one of the things I wanna talk about here
09:13 - is how does this work.
09:14 - So before you can actually use machine learning
09:17 - to make predictions for unknown data,
09:21 - you need to train the system.
09:23 - So the training step involves--
09:26 - So there there are several different strategies
09:29 - for how a machine learning system can learn
09:31 - in order to perform operations like this.
09:33 - One is called supervised learning.
09:38 - And supervised learning is the strategy
09:40 - that I'm going to use in just about everything
09:43 - that I do in this particular course
from session three right now and on.
09:47 - Although, I will come back to
some other techniques as well.
09:51 - Another kind of learning is unsupervised learning.
09:57 - And another kind of learning
09:59 - that I really love, my favorite kind of learning,
10:03 - is reinforcement learning.
10:05 - In fact, I have a whole book
all about reinforcement learning
10:08 - that I'm reading right now.
10:09 - Okay, so what are these different--
10:12 - And, you know, there's something
called semi-supervised learning
10:14 - and there's little variations on this,
10:16 - but these are three core types of learning
10:20 - that can be applied to the machine learning process.
10:23 - Let's start with reinforcement learning for a second.
10:26 - Reinforcement learning is the kind of learning
10:29 - where an agent observes the environment
10:32 - and chooses an action.
10:34 - You can think of a mouse trying to get through a maze.
10:36 - The mouse looks around.
There's a wall here.
10:38 - There's a wall here.
There's a wall here.
10:40 - The mouse decides to go left,
or the mouse decides to go right.
10:43 - And then once the mouse makes that decision,
10:46 - the mouse receives a reward.
10:48 - And that could be a positive or negative reward.
10:50 - And as the mouse receives more positive rewards
10:53 - for certain kinds of actions, it does more
of those actions over the long term
10:56 - and gets better and better at things.
10:58 - So that's reinforcement learning.
10:59 - I'm gonna spend a whole session
looking at this at some point,
11:02 - and we're gonna see some techniques.
11:03 - I have an example that uses a kind of
11:06 - reinforcement-style learning to train--
11:11 - tp autonomously play the game Flappy Bird.
11:13 - Okay, unsupervised learning is a kind of learning
11:17 - that's generally applied to data
that you know nothing about.
11:21 - So I have 100,000 songs,
11:24 - and I just want to kind of learn
11:26 - what patterns are there in the song.
11:28 - So typically, unsupervised learning is applied
11:31 - to problems like clustering.
11:33 - So I have all this data and I want
11:35 - to figure out how can this
data be arranged in groups?
11:38 - Could I have a--
And I don't know anything about it.
11:40 - Could an algorithm figure out,
based on patterns in the data,
11:44 - how to group that data,
how to cluster that data?
11:46 - So I don't know that this is something
that I'm gonna spend any time--
11:49 - It's not on my current trajectory/syllabus,
11:52 - but it is something that I would like to do
11:54 - at some point in the future.
11:56 - I actually have some ideas for some stuff
I want to do about that eventually.
11:59 - Okay, but here we're gonna
give a nice little star, and a heart,
12:03 - and a little smiley face,
and a little rainbow
12:06 - for supervised learning,
12:08 - because this is what I'm going to use
12:10 - in most of most of my examples
over the next several videos.
12:14 - The idea of supervised learning is I have
12:19 - training data.
12:21 - Training data.
12:24 - So number one, I have training data.
12:26 - Number two, I have test data.
12:31 - And number three,
12:32 - I have the rest of the world, a universe of data.
12:36 - So maybe we could call this unknown.
12:39 - Un-- un-- ah!
I can't spell.
12:44 - Unknown data.
12:49 - So how does this work?
12:50 - So first, what we do in supervised learning
12:53 - is we take this training data.
12:55 - We have a huge database of--
12:58 - a spreadsheet of bedrooms, bathrooms,
13:01 - and square footage for houses
13:03 - with their actual price that they sold at.
13:05 - So we have a data set that has the parameters
13:11 - and some sort of target, often called a target.
13:14 - So this would be like the training data
13:16 - with the inputs
and a target.
13:20 - The idea is the inputs go into
the machine learning recipe,
13:24 - they come out the other side,
13:26 - and some sort of guess is made.
13:29 - Maybe the house actually sold for $1.5 million,
13:33 - but the guest was $1 million.
13:35 - Ah, so the machine learning recipe got it wrong.
13:38 - So we turn some knobs here,
and mess around with it
13:42 - to try to get it to have a better result
13:44 - that's towards what that error--
13:46 - So we're gonna talk a lot about
this error and that sort of thing.
13:49 - We're gonna come back to this many, many times.
13:51 - So we do this over and over again
with lots and lots of training data,
13:55 - turning all the knobs,
trying to get it to do a good job.
13:59 - Then what we do is we have test data.
14:01 - Now, test data is just like the training data.
14:04 - It's data that has inputs with a known result,
14:07 - a known result that we should get.
14:09 - But we didn't actually use it while training,
14:11 - because we have this issue--
14:13 - a machine learning recipe might
perform really, really well
14:17 - with the training data,
but not with actual other data.
14:20 - So to see how well it's working,
we've actually got to give it data
14:22 - that we didn't use to train,
and that's called the test data.
14:25 - So we would feed that, see how well it does,
14:28 - evaluate, and evaluate the performance,
14:30 - and say like, "Ah, you know what?
14:31 - "It got all the test data right."
14:33 - It's ready. It's all grown up.
14:35 - Our machine learning recipe is ready to go,
14:38 - and we send it out into the world
to start interacting with unknown data.
14:42 - So this is really the process.
14:44 - This is supervised learning.
14:45 - It's saying, "Hey, I'm the teacher."
14:47 - This is the machine learning system.
14:50 - I'm going to teach the system
with my known data, with known output.
14:54 - I'm gonna test the data with separate
known inputs and known outputs,
14:58 - and then it's gonna be all grown up.
15:00 - It's gonna graduate.
15:01 - I'm gonna send it out into the world,
15:03 - and yadda, yadda, yadda.
15:06 - You know, more--
15:07 - By the way, I plan on doing a lot of
yadda, yadda, yadding neural network stuff.
15:11 - We might get to like, "And then you have to
15:12 - "do this calculus thing, yadda, yadda, yadda." (laughs)
15:16 - So I think that's a good practice
to yadda, yadda, yadda
15:19 - machine learning as much as possible.
15:21 - Okay, so that's a brief introduction
to what machine learning is overall,
15:27 - and what some of the sort of key aspects
of how a machine learning system works.
15:32 - But we're going to get into a lot more
15:35 - about the details here,
and we're gonna look
15:36 - at a variety of different kinds
of recipes that can be put in here,
15:40 - and how they work with different kinds of data,
15:42 - like which recipe do you want to work with images,
15:44 - which recipe would you want for working with text,
15:46 - for this kind of classification,
for this kind of regression.
15:50 - But right now I'm going to move on
and start looking at nearest neighbor.
15:54 - What is this thing called nearest neighbor?
15:56 - How can I look at two different pieces of data?
16:00 - So let me--
16:01 - So I have a bunch of pre-made
examples in some of the--
16:04 - If you follow along with the playlist,
16:05 - you're going to see a bunch of examples
where I code stuff from scratch.
16:08 - But I won't be able to do--
16:10 - I'm not gonna do a video for
every single one of these examples.
16:12 - I mean, maybe I will someday.
16:14 - But the first thing I'm really
gonna start looking at is--
16:17 - and this is an example inspired by--
16:20 - this is an example inspired by Rebecca Fiebrink,
16:23 - who has a wonderful course called, I think,
16:26 - Machine Learning for Musicians and Artists
16:28 - from the company Kadenze--
16:30 - I'll put a link to that in this video's description--
16:32 - where she uses a tool that she built called Wekinator
16:35 - to do classification and regression
and a variety of other things.
16:39 - So she does a lot of stuff
with gestural interfaces
16:41 - and musical output.
16:43 - So one of the things I wanna look at--
16:44 - And I'm gonna hit play here.
16:47 - And what you're gonna see is
16:49 - as I move the mouse
16:52 - near a particular note, the note changes.
16:55 - C, D, E, F.
16:59 - And this is actually a classification--
17:02 - This is an example of classification.
17:04 - What I'm doing is I have two-dimensional data,
17:07 - a Cartesian coordinate system,
17:09 - and I wanna classify every XY point
to a particular note.
17:13 - This is classification.
So the nearest note
17:16 - is the note that I play.
17:19 - I can actually switch this
example to perform regression,
17:23 - and this is an example now of regression.
17:27 - You can hear--
17:28 - I make a prediction based on a weighted distance.
17:32 - So here, I essentially have
an average of C and G.
17:36 - I'm hearing a little G.
17:38 - I'm at a frequency between G and C.
17:40 - You can hear G,
17:43 - C,
17:44 - G, C.
17:45 - So this is-- these are the kind of examples
17:48 - that I wanna build to get you started
with understanding the algorithms
17:51 - and I have some ideas for some
creative possibilities that you can do.
17:55 - And then we're gonna just keep going.
17:57 - So okay, so stay tuned.
17:59 - There'll be a bunch of videos in this playlist
18:01 - where I go through a few
different examples and scenarios.
18:03 - I'll come back with another video
with some homework ideas,
18:06 - and hopefully you'll make
some stuff and share it with me,
18:08 - and live your life in this world/universe/place,
18:12 - and maybe give somebody a hug
or say something nice to somebody,
18:15 - 'cause those are good things to do, too.
18:16 - Okay, see you in a future video.
18:17 - (bell dings)
18:18 - (upbeat music)

Cleaned transcript:

(bell dings) Hello, welcome to session three of The Nature of Code Intelligence and Learning. So this is one of my opening videos for these sessions. If you are watching this video as part of that playlist for the Intelligence and Learning course, you will see a lot of videos in front of you with a variety of demonstrations and different coding challenges. There will also be a video at the end, where I come back and pose some ideas for an exercise or assignment that you could try. But what I want to do in this particular video is Now, now is the time this course has just started with this little warmup of thinking about artificial intelligence, and search algorithms, and graph systems, and then we took this turn and thought about genetic algorithms and evolutionary systems, but you might be here because you heard about this term, machine learning, maybe even heard about this term deep learning, and you want to get a sense of what does that mean, what are the possibilities with machine learning and deep learning, how do machine learning systems work, what are they for, what's the lingo for this sort of stuff, and now's the time to get into that. Now, session three here, I will not be using any neural network yet. So what I want to do in session three is just talk about what machine learning is, what its applications are. So something that I'm gonna cover here is classification and regression, what do those terms mean, and what are some classic algorithms for performing classification and regression. And so, I'm going to look at something called nearest neighbor similarity, K nearest neighbor. And I'm also going to look at something called linear regression. And so these will be some sort of classic algorithms that you can play around with and actually do stuff with. And then in session four, we'll start looking at what a neural network is and see how we can use that as part of a machine learning system. Okay, are you with me? By the way, I barely know how to do this stuff, so if you're watching this for an expert, you probably wanna find somebody else on YouTube, but I'm learning this stuff, trying it out, and hopefully you're gonna come along and join me on the train, right? Oh, I forgot! We're on a train. (train whistle blows) On this ride on the train in the sky with me as your guide. Do sky and guide rhyme? I think they do. You'll see. I had a point to this, but I digress. Okay, so what is machine learning? So first of all, one thing that I might suggest for you if you wanna watch some videos about somebody who really knows what they're talking about, I would suggest Andrew Ng's Coursera course. A lot of my knowledge and inspiration has come from that course, and Andrew Ng does a good job of giving a nice introduction to machine learning. And two particular references one is this definition, this quote from Arthur Samuels, who is a pioneer in the world of machine learning, defining machine learning as a field of study that gives computers the ability to learn without being explicitly programmed. And so here's an interesting thing we can think about. When we looked at the A* algorithm in session one for pathfinding, we were designing, us the programmer, writing an algorithm to specifically perform a task. The computer would follow those instructions and get to a result. There was an intelligence to that algorithm, there was the disappearance of sort of the computer solving a problem in thinking about it, but ultimately, we had written the instructions, the code for the computer to solve, to arrive at an answer. So what if, instead of us writing the instructions, we would just set up a framework for the computer to figure out what the instructions might be, what are the right parameters for some type of model to perform some sort of task? So this is the idea of machine learning. And I would encourage you to look at the work of Arthur Samuels. One of the things that he did was train a computer to learn to play checkers by just having it play itself over and over and over again, thousands of times, to be able to learn what a good strategy was. But ultimately So one of the things that I want to talk about here is So let me come over the whiteboard here. I have this README that I'll link to in the description. You can read some of the definitions and information that's on that README. But what I want to look at is this model for, this I'm gonna describe to you machine learning in this particular way. So there is some sort of input. That input is going to go into some sort of algorithm, some recipe. I think that's a nice way of thinking about it. Some machine learning recipe. And then out of that machine learning recipe, we are going to get an output. The input into the machine learning recipe is typically numeric. So you could think of it as, you know, a classic example that's always given is what if we want to build a machine learning system that can guess the price of a house based on some inputs. so maybe we might say something like, "Oh, the house has three bedrooms, "and it has two bathrooms, "and it has 1,000 square feet." And etc., etc. This is the input into the machine learning recipe, and the output might come, "The house is $1 million." Something like that. Nice house, apparently. Okay, so this is what machine So typically speaking, another way of thinking about machine learning is making sense of data. So I have some sort of data and I want to make sense of it. I have some input and some output. So two kinds of output that you'll see in most machine learning algorithms are classification. Another kind of output is regression. So what you might not have realized here is this example that I gave to you, where the parameters of a house, a data point, goes into the machine learning recipe and we get this price output, this is actually regression. Regression refers to predicting some sort of continuous numeric output, whereas classification refers to taking an input and classifying it into a discrete set of labels. So here might be another scenario. I have an image of a cat. That is the input into the machine learning recipe. And the output is something like this. Well... I'm getting the usually the output comes numeric, so we have to sort of figure out what this could mean, but I'm speaking in kind of higher level terms here, so I'm just gonna say the output is cat. I am labeling it and maybe the only possible options are cat versus dog, so what that output actually is is something like 0.9, 0.1. Like there's a 90% chance this is a cat, 10% chance it's a dog. So this is classification, attempting to assign a discrete label to something like an image. We could've done something with the house data using the classification. We could say, you know, fancy house, summer house, winter house. You know, we could classify into one of two categories. That's classification. Regression, getting a continuous numeric output. So how does this work? So number one is we've got to, at some point, start talking about what are some different recipes that could go in here. And I could name you a few. For example, K nearest neighbor. This is a particular algorithm that can work for both classification and regression. I could say something like support vector machine, or I could say artificial neural network. And then there are a variety of flavors, so to speak, of styles and of artificial neural networks, convolutional neural network, recurrent neural network. So this is something I ultimately intend to spend a lot of time on. What is an artificial neural network? How does it work? And why is it effective to put it in here? But even with all of the amazing innovation that's happening in machine learning and deep learning right now, there's a lot that you can do without artificial neural networks. A lot of simple, fun exercises and things. So in this particular session, session three, I'm gonna look at the other algorithms that are nonartificial neural network nonneural network based that become the machine learning recipe, like K nearest neighbor. But let's take a moment here to talk about how overall this works, because the thing is this doesn't just happen magically. You can't just The point of doing this is that at some day, we might want to put an unknown image in here and get a classification label for that image. But how could a machine learning recipe do that from nothing? And it can't. So one of the things I wanna talk about here is how does this work. So before you can actually use machine learning to make predictions for unknown data, you need to train the system. So the training step involves So there there are several different strategies for how a machine learning system can learn in order to perform operations like this. One is called supervised learning. And supervised learning is the strategy that I'm going to use in just about everything that I do in this particular course from session three right now and on. Although, I will come back to some other techniques as well. Another kind of learning is unsupervised learning. And another kind of learning that I really love, my favorite kind of learning, is reinforcement learning. In fact, I have a whole book all about reinforcement learning that I'm reading right now. Okay, so what are these different And, you know, there's something called semisupervised learning and there's little variations on this, but these are three core types of learning that can be applied to the machine learning process. Let's start with reinforcement learning for a second. Reinforcement learning is the kind of learning where an agent observes the environment and chooses an action. You can think of a mouse trying to get through a maze. The mouse looks around. There's a wall here. There's a wall here. There's a wall here. The mouse decides to go left, or the mouse decides to go right. And then once the mouse makes that decision, the mouse receives a reward. And that could be a positive or negative reward. And as the mouse receives more positive rewards for certain kinds of actions, it does more of those actions over the long term and gets better and better at things. So that's reinforcement learning. I'm gonna spend a whole session looking at this at some point, and we're gonna see some techniques. I have an example that uses a kind of reinforcementstyle learning to train tp autonomously play the game Flappy Bird. Okay, unsupervised learning is a kind of learning that's generally applied to data that you know nothing about. So I have 100,000 songs, and I just want to kind of learn what patterns are there in the song. So typically, unsupervised learning is applied to problems like clustering. So I have all this data and I want to figure out how can this data be arranged in groups? Could I have a And I don't know anything about it. Could an algorithm figure out, based on patterns in the data, how to group that data, how to cluster that data? So I don't know that this is something that I'm gonna spend any time It's not on my current trajectory/syllabus, but it is something that I would like to do at some point in the future. I actually have some ideas for some stuff I want to do about that eventually. Okay, but here we're gonna give a nice little star, and a heart, and a little smiley face, and a little rainbow for supervised learning, because this is what I'm going to use in most of most of my examples over the next several videos. The idea of supervised learning is I have training data. Training data. So number one, I have training data. Number two, I have test data. And number three, I have the rest of the world, a universe of data. So maybe we could call this unknown. Un un ah! I can't spell. Unknown data. So how does this work? So first, what we do in supervised learning is we take this training data. We have a huge database of a spreadsheet of bedrooms, bathrooms, and square footage for houses with their actual price that they sold at. So we have a data set that has the parameters and some sort of target, often called a target. So this would be like the training data with the inputs and a target. The idea is the inputs go into the machine learning recipe, they come out the other side, and some sort of guess is made. Maybe the house actually sold for $1.5 million, but the guest was $1 million. Ah, so the machine learning recipe got it wrong. So we turn some knobs here, and mess around with it to try to get it to have a better result that's towards what that error So we're gonna talk a lot about this error and that sort of thing. We're gonna come back to this many, many times. So we do this over and over again with lots and lots of training data, turning all the knobs, trying to get it to do a good job. Then what we do is we have test data. Now, test data is just like the training data. It's data that has inputs with a known result, a known result that we should get. But we didn't actually use it while training, because we have this issue a machine learning recipe might perform really, really well with the training data, but not with actual other data. So to see how well it's working, we've actually got to give it data that we didn't use to train, and that's called the test data. So we would feed that, see how well it does, evaluate, and evaluate the performance, and say like, "Ah, you know what? "It got all the test data right." It's ready. It's all grown up. Our machine learning recipe is ready to go, and we send it out into the world to start interacting with unknown data. So this is really the process. This is supervised learning. It's saying, "Hey, I'm the teacher." This is the machine learning system. I'm going to teach the system with my known data, with known output. I'm gonna test the data with separate known inputs and known outputs, and then it's gonna be all grown up. It's gonna graduate. I'm gonna send it out into the world, and yadda, yadda, yadda. You know, more By the way, I plan on doing a lot of yadda, yadda, yadding neural network stuff. We might get to like, "And then you have to "do this calculus thing, yadda, yadda, yadda." (laughs) So I think that's a good practice to yadda, yadda, yadda machine learning as much as possible. Okay, so that's a brief introduction to what machine learning is overall, and what some of the sort of key aspects of how a machine learning system works. But we're going to get into a lot more about the details here, and we're gonna look at a variety of different kinds of recipes that can be put in here, and how they work with different kinds of data, like which recipe do you want to work with images, which recipe would you want for working with text, for this kind of classification, for this kind of regression. But right now I'm going to move on and start looking at nearest neighbor. What is this thing called nearest neighbor? How can I look at two different pieces of data? So let me So I have a bunch of premade examples in some of the If you follow along with the playlist, you're going to see a bunch of examples where I code stuff from scratch. But I won't be able to do I'm not gonna do a video for every single one of these examples. I mean, maybe I will someday. But the first thing I'm really gonna start looking at is and this is an example inspired by this is an example inspired by Rebecca Fiebrink, who has a wonderful course called, I think, Machine Learning for Musicians and Artists from the company Kadenze I'll put a link to that in this video's description where she uses a tool that she built called Wekinator to do classification and regression and a variety of other things. So she does a lot of stuff with gestural interfaces and musical output. So one of the things I wanna look at And I'm gonna hit play here. And what you're gonna see is as I move the mouse near a particular note, the note changes. C, D, E, F. And this is actually a classification This is an example of classification. What I'm doing is I have twodimensional data, a Cartesian coordinate system, and I wanna classify every XY point to a particular note. This is classification. So the nearest note is the note that I play. I can actually switch this example to perform regression, and this is an example now of regression. You can hear I make a prediction based on a weighted distance. So here, I essentially have an average of C and G. I'm hearing a little G. I'm at a frequency between G and C. You can hear G, C, G, C. So this is these are the kind of examples that I wanna build to get you started with understanding the algorithms and I have some ideas for some creative possibilities that you can do. And then we're gonna just keep going. So okay, so stay tuned. There'll be a bunch of videos in this playlist where I go through a few different examples and scenarios. I'll come back with another video with some homework ideas, and hopefully you'll make some stuff and share it with me, and live your life in this world/universe/place, and maybe give somebody a hug or say something nice to somebody, 'cause those are good things to do, too. Okay, see you in a future video. (bell dings) (upbeat music)
