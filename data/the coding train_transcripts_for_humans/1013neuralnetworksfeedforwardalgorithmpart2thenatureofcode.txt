With timestamps:

00:00 - hello now if you watch the previous
00:02 - video hey boys
00:04 - thank you well I hope you're not too mad
00:07 - at me and I didn't file too many
00:09 - complaints in the comments there but in
00:11 - the previous video I talked through the
00:12 - feed-forward algorithm they attempted to
00:15 - map it and graph it I attempted to get
00:17 - all the indices right to explain why we
00:19 - use matrix math for it all that sort of
00:21 - stuff now we've got to get to something
00:23 - we got to get to the interesting part
00:24 - which is actually to use the neural
00:26 - networks for something it's taking me a
00:27 - while to get there I will get there but
00:30 - I have something to confess if you
00:33 - thought that was bad
00:33 - I actually uh wilderness Dan over here
00:39 - tried in a live stream previously to go
00:42 - through all this and got all the index
00:43 - values and everything wrong was so bad
00:45 - it couldn't even like get it together to
00:47 - turn it into an actual tutorial video
00:48 - that I'm making in the playlist but it
00:50 - does exist if you're interested I got a
00:52 - haircut seemed to fix a lot of things I
00:53 - look like a much more professional
00:55 - person you can go back and watch that
00:57 - previous those previous attempts so
01:00 - actually done so this is my second try
01:03 - I'm just being honest here all right so
01:05 - what is it that I want to do oops in
01:08 - this particular video we can close all
01:09 - this stuff what I want to do is I have a
01:13 - matrix I have a matrix class that I've
01:16 - developed I have a neural network class
01:20 - that I've developed what I want to do I
01:23 - want to be able to write code like the
01:25 - following I want to be able to go into
01:28 - my p5.js sketch or any JavaScript
01:30 - program and say something like let
01:33 - neural network let n equal a new neural
01:37 - network maybe it has maybe I want to
01:40 - solve X or so I want to have two inputs
01:43 - I just want to have one two hidden nodes
01:48 - and one output so I want to make a
01:51 - neural network object and I want to give
01:52 - it an architecture then I want to do
01:54 - something like I'm going to make an
01:56 - input like I want to send in true false
01:59 - 0 1 comma 0 I want to be able to say let
02:05 - output equal neural network feed-forward
02:08 - that input and then I want to say
02:11 - console.log output so this is the
02:13 - this is what I want to be able to do I
02:15 - want to be able to use the neural
02:16 - network on a kind of higher level and
02:18 - once I can do that then I can have
02:20 - inputs that are all different kinds of
02:21 - things where I'm doing data science or
02:23 - some kind of like learn to play flappy
02:25 - bird or whatever it is that I'm doing
02:28 - okay so let's do this what I have so far
02:35 - here is just I have that feed-forward
02:37 - function it takes an input and returns
02:40 - that guess now there's no code there I
02:42 - need to fill in the code all that matrix
02:44 - math I need to take everything that I
02:46 - have here and I need to put that all
02:50 - into here so how do I do that all right
02:53 - well my neural network needs some more
02:56 - stuff for example all that it has right
02:59 - now is the number of input nodes which
03:00 - is I just sent into the number of hidden
03:02 - nodes I sent into and the number of
03:04 - output nodes I sent in one well what I
03:06 - need is I need to keep track of those
03:08 - weights right I need to have weights and
03:10 - what do I need to have weights between
03:13 - we need to have the weights between
03:15 - input and hidden and the weights between
03:17 - hidden and output so those we've
03:20 - established our matrices weights between
03:22 - input and hidden is a new matrix and now
03:27 - it has a certain number of rows and
03:29 - columns it has a certain number of rows
03:32 - sorry columns based on the number of
03:34 - inputs and rows based on the number of
03:36 - hidden nodes so we're gonna say it has
03:40 - this dot hidden nodes is its number of
03:44 - rows and this dot input nodes is its
03:48 - number of columns so that's one wait
03:50 - mate ryx
03:51 - and another wait matrix is between
03:55 - hidden and output and that's going to
03:57 - have the number of rows which is the
04:00 - number of output nodes and the number of
04:04 - columns is the number of hidden nodes so
04:06 - I've created these weight matrices now
04:08 - oh oh you have an interesting question
04:11 - when we create a neural network how do
04:14 - we pick the weights again the whole
04:17 - point of this is we need to have some
04:19 - interesting wonderful exciting
04:21 - complicated weird algorithm for tuning
04:24 - the weights for finding the optimal
04:26 - weights for whatever
04:27 - type of application we're trying to
04:28 - build but to start we just want to give
04:31 - it random weights and I did the whole
04:33 - fields of research dedicated to figuring
04:36 - out like good ways to see the neural
04:38 - network with good kind of beginning
04:39 - weight so that you can get the optimal
04:40 - weights more easily blah blah blah but
04:42 - for us right now I just want to give it
04:43 - random weights so I can actually just
04:45 - say we've already built a randomized
04:49 - function into the neural the matrix
04:52 - library so I can say randomized so this
04:55 - will randomize the weights and actually
04:58 - though if you recall I was reminded by
05:00 - this in the chat that my randomize
05:02 - function for some of my demonstrations I
05:04 - was actually picking a number between 0
05:05 - and 10 and it would make much more sense
05:07 - to get a random number between maybe
05:12 - negative 1 and 1 to start at the weight
05:14 - so I could take math dot random which is
05:16 - 0 to 1 x 2 subtract 1 and I've got a
05:18 - random value between negative 1 and 1
05:20 - okay so we're doing well what else do I
05:25 - need
05:25 - I should probably I should probably keep
05:29 - track of the bias the hidden bias and
05:31 - the output bias again as we saw when I'm
05:34 - sort of talking about it could put that
05:35 - into the matrices but I'm going to keep
05:36 - track of that separately it's a little
05:38 - easier for me so I'm gonna say this dot
05:41 - bias hidden equals a new matrix that has
05:49 - how many biases do I have I have o based
05:52 - on the number of hidden nodes right that
05:54 - those are the rows and then one column
05:56 - is it yeah because it's one column
05:57 - vector and the bias or the output is
06:00 - based on how many output nodes so for
06:03 - every I need a bias value for every node
06:06 - in every layer so I need to bias values
06:09 - for each hidden node and one bias value
06:11 - for each the single output node but you
06:13 - know again my neural network library
06:15 - allows me to create neural networks with
06:17 - any number of hidden nodes any number of
06:19 - inputs any number outputs it is just has
06:20 - these two layers and the inputs but so
06:23 - at some point it might be worth
06:24 - expanding it so I kind of multiple
06:26 - hidden layers that sort of thing but
06:27 - this is gonna work fine for now okay so
06:32 - what else do I need now ah-ha-ha-ha
06:35 - there's something we're missing so for
06:38 - example let's just what am I
06:42 - what am i feeding in here feed-forward
06:45 - input this is just an array but
06:47 - technically in order for me to be able
06:50 - to do the first stop right the first
06:52 - thing that I want to do is I want to say
06:54 - this dot hidden I'm sorry I'm gonna make
06:57 - this let hidden this will be the output
07:00 - right I want to compute the output of
07:03 - the hidden nodes that's going to be a
07:06 - one dimensional of one column matrix
07:09 - that is going to be that is going to be
07:15 - the matrix product between the input and
07:22 - this and the weights and the weight
07:26 - weight matrix between and actually I
07:28 - have to say the weights first sorry the
07:30 - weights remember the order in matrix
07:32 - multiplication really matters the
07:34 - weights input hidden with that input
07:39 - then I'm going to say hidden dot add
07:45 - this dot bias so I do the matrix product
07:50 - of the inputs and the weights then I add
07:53 - in the bias and then I'm gonna do
07:56 - activation function I won't do that just
07:57 - yet but even this is no good so far this
08:01 - is no good so far because this input
08:04 - what does this matrix multiply function
08:06 - expect matrix multiply in my library
08:10 - expects two matrix objects and this the
08:17 - way I've written my sketches I just made
08:18 - the inputs an array which is an
08:20 - incredibly convenient thing to do I
08:21 - don't want to make my end-users have to
08:24 - like figure out they just want me I'll
08:26 - send the inputs in in a simple array so
08:28 - one thing that I should do here I mean I
08:31 - could test I could check if it's already
08:33 - an instance of a matrix I could skip it
08:35 - but what I want to do is I want to say
08:38 - I'm going to call this input array I
08:40 - want to say inputs equals matrix from
08:46 - array input array and the reason why I'm
08:48 - writing this out is because I've thought
08:50 - of this already
08:51 - I need to be able to make a matrix
08:53 - object from
08:54 - arrey so I want to be able to have a
08:56 - matrix object so that my matrix multiply
08:58 - function will work and I could create a
09:00 - different constructor that takes an
09:02 - array but I think what would make sense
09:03 - is for me to add right up here in the
09:06 - beginning right and a static function
09:08 - that's that's called from array it takes
09:12 - an array and what I want to do here is I
09:15 - want to say let may n equal a new matrix
09:18 - that has just that has a number of rows
09:22 - based on the arrays length and one
09:25 - column right I want to create a matrix
09:28 - that looks like this
09:30 - it has a number of rows based on the
09:32 - arrays length and one column and then
09:36 - all I need to do is say for let I equals
09:40 - 0 I is less than array dot length I plus
09:44 - plus and I'm going to say data oh sorry
09:51 - sorry
09:52 - m dot data index I index 0 equals equals
10:01 - array index I and then return n so this
10:06 - is just again oh I'm sure every lots of
10:09 - you could probably think of some type of
10:11 - array functionality that I could use
10:13 - really easily but this is creating that
10:15 - matrix and then just that matrix and
10:19 - then putting the input into it so just
10:21 - to be sure about this let me let me say
10:24 - m dot print okay let me just make sure
10:28 - this works so I have some errors here oh
10:32 - that actually nicely printed something
10:34 - out for me that I didn't realize it
10:35 - would so what I want to do is I want to
10:37 - say let a array equal a 1 comma 0 comma
10:42 - negative 5 and then I want to say matrix
10:46 - dot from array array and we should see
10:52 - there we go we've got a column a single
10:54 - column matrix 1 0 negative 5 so that
10:57 - function is working the way that I hoped
10:59 - it would so I can take out this
11:02 - debugging and I can keep this in here
11:04 - and now if I go back to this code I can
11:07 - say
11:08 - okay we get an input array we turn that
11:12 - into an input matrix and then this needs
11:15 - an S here we multiply we do the matrix
11:19 - product of the inputs with the weights
11:21 - we add in the bias we one more step left
11:25 - to go we need to do the activation
11:27 - function so we need the sigmoid function
11:29 - well it so happens that there isn't a
11:31 - magical sigmoid function that exists in
11:33 - JavaScript however there is in the math
11:36 - library a function called exp JavaScript
11:40 - math let's find this documentation page
11:43 - this exp Euler's number or also known as
11:47 - Napier's constant does for us e to the X
11:52 - so I can write my own sigmoid function
11:55 - so I can just um and and at some point I
11:58 - probably will allow the neural network
12:01 - library to use different activation
12:03 - functions but right now I'm just
12:04 - globally gonna write a function called
12:06 - sigmoid it's going to take one input X
12:09 - and it is going to return one divided by
12:12 - one plus mass of X somebody fact-check
12:18 - for me but I believe that is the sigmoid
12:20 - function and so the wonderful thing now
12:23 - is once I receive the inputs once I've
12:26 - done the matrix product of the weights
12:28 - and the inputs once I've added in the
12:30 - bias I can generate the outputs with the
12:32 - activation function just by saying
12:35 - hidden dot map sigmoid if you recall I
12:39 - wrote into my matrix library a function
12:42 - called map which just allows me to apply
12:47 - any arbitrary function to every element
12:49 - of that matrix so so there we go now
12:54 - we're done so this is this is all the
12:58 - code for generating the hidden outputs
13:05 - and this is the activation function now
13:07 - where are we in the diagram we've got
13:11 - the inputs we did the matrix product we
13:13 - added in the biases we passed the
13:16 - activation function now those outputs
13:19 - are coming in here
13:20 - what do we need to do now take those
13:22 - hidden outputs and do the matrix product
13:25 - with these weights so we're gonna do
13:29 - exactly that same thing we're going to
13:30 - say let output equal matrix dot multiply
13:35 - this this dot weights now I need the
13:40 - weights between the hidden and the
13:43 - output H oh I need the hidden outputs
13:47 - which is drug just calling hidden then I
13:49 - need to add in those output biases did I
13:55 - call it bias oh yes
13:56 - in each oh and by the way I just
13:58 - realized I never gave these any initial
14:00 - values so it would make sense for me to
14:03 - also randomize these so I'm going to
14:09 - randomize those biases so right so now
14:12 - I've got the weights times they hit the
14:15 - matrix products with the weights and the
14:16 - hidden outputs
14:17 - I'm added in the bias and then output
14:20 - dot map sigmoid and guess what return
14:26 - output that's all I want that's done
14:28 - that's the last piece I want to send in
14:31 - the inputs in my actual code I want to
14:35 - be able to send in the inputs and then
14:37 - read out the output but here's the thing
14:39 - I sent in the inputs as a simple array
14:42 - and then internally converted that into
14:44 - a matrix so I could do all the math
14:45 - properly now before I get the outputs
14:48 - back I don't want you want to send out a
14:49 - matrix it's gonna be simpler if I just
14:51 - send out those outputs as an array so
14:53 - much like I wrote that from array
14:55 - function I am going to create a function
15:00 - called
15:01 - two array and that doesn't need to be
15:03 - static because I'm gonna take any given
15:05 - matrix object and return in the right
15:07 - now there are some way I could probably
15:10 - transpose it and and do some fancy way
15:13 - or use the slice function I'm again I'm
15:15 - gonna do this just in a way that I know
15:16 - will work will catalyze refactor this
15:19 - later in the end I'm gonna refactor all
15:20 - this using somebody else's matrix
15:22 - library anyway so let me think about how
15:24 - I would do this first I want to make an
15:26 - array I'll make it empty and then really
15:28 - all I want to do is I want to loop
15:31 - through every element of the array
15:34 - every element of the matrix and what I
15:36 - want to do is I want to say array dot
15:40 - push every element of the matrix and say
15:44 - return alright so this would actually
15:45 - take any two-dimensional matrix and
15:47 - flatten it to one mention array the
15:49 - question is though one thing we should
15:52 - ask ourselves here is it appropriate to
15:53 - have the columns as the inner loop so if
15:56 - I think about it if I wanted to take I
15:58 - mean obviously doesn't matter if it's
16:00 - this matrix because I just want to take
16:02 - all these and put it into an array but
16:04 - if it's that if I want to take like this
16:06 - array and flatten it do I want to go
16:08 - do-do-do-do-do-do or do I want to go
16:10 - doo-doo-doo-doo doo-doo-doo-doo I think
16:13 - I want to go this way do-do-do-do-do-do
16:17 - I got distracted by my own singing of
16:19 - the iteration song is just doo doo doo
16:21 - doo alright sorry I'll get back to this
16:24 - I apologize I think I want to iterate
16:26 - through the columns on the inner loop
16:27 - which it looks like that's what I'm
16:30 - doing so I'm gonna keep it this way
16:31 - except for yeah okay so I'm gonna keep
16:33 - it this way
16:34 - and I'm gonna say here now in the neural
16:36 - network I can say return output to array
16:41 - okay everyone this is it this is the
16:44 - whole feed-forward algorithm this is
16:47 - receiving the inputs generating the
16:50 - hidden outputs generating the output
16:54 - output and then sending it back to the
17:01 - color alright so this is the whole
17:03 - algorithm layer this is like layer 1 and
17:06 - layer 2 the hidden layer the output
17:08 - layer okay what do we do now let's try
17:13 - running the code I mean it's absurd but
17:15 - because this does nothing but let's
17:17 - actually let's just run this let's just
17:19 - see can I create a neural network give
17:22 - it some are very input and get some
17:24 - output can I get it with no mistakes it
17:27 - seems very unlikely that I'm gonna have
17:28 - no mistakes and this is a reason why I
17:30 - shouldn't use my drum roll effect but
17:32 - I'm gonna do it anyway
17:36 - here we go let's run this code it worked
17:45 - the first time thing it worked is a
17:50 - strange thing to say cuz relay to get
17:52 - any errors and probably one reason
17:53 - getting errors because it's actually my
17:54 - second try of building this out you
17:57 - might be wondering like oh okay so I
17:59 - just watched like two and a half hours
18:02 - of like eight videos in a row about
18:03 - matrices and neural networks and you
18:07 - just went for point five nine three one
18:11 - zero seven the thing is we have none you
18:14 - gotta start testing this we've got to
18:15 - come up with a server we're getting
18:16 - close we're what I want to do probably
18:18 - the first thing I'll do it's not that
18:19 - interesting but at least allow us to
18:21 - test whether this code works is can I
18:24 - train it to learn and and operation or
18:27 - operation or X or exclusive or which is
18:29 - one that I've talked about that can't be
18:31 - solved with a single perceptron so can I
18:33 - feed it in one zero and train it to get
18:35 - the number one out can I feed it in zero
18:37 - one train to get the number one out but
18:39 - if I give it zero zero one one I get the
18:40 - number zero out so I need to attend that
18:43 - but I am missing a lot of functionality
18:47 - from this neural network class I have
18:50 - this feed-forward algorithm function now
18:53 - what I need is to write a function
18:56 - called train and what I'm gonna do with
18:58 - the train function is I'm going to give
19:00 - it some inputs and then I'm gonna give
19:02 - it a known answer so the idea here is
19:04 - like with feed-forward I'm really just
19:07 - saying take these inputs and give me an
19:08 - output with training I'm gonna say take
19:11 - these inputs that I have an owned
19:12 - labeled answer to and do something to
19:15 - yourself based on that and that's where
19:16 - I'll start getting to in the next video
19:18 - I have to talk about back propagation
19:20 - and gradient descent I have talked about
19:21 - this in previous videos will kind of
19:23 - return to that then I need to finish
19:24 - implementing this function and then I'll
19:26 - do a coding challenge where I try to
19:27 - solve XOR and do like a simple digit
19:30 - recognition or something with this
19:31 - particular neural network library okay
19:34 - thanks for watching um just them going
19:37 - through this I'm trying it out and see
19:38 - if I can make this room that would still
19:39 - happen doing a guy's being us Abby -
19:44 - thanks Abby - but all things all things
19:47 - will come eventually so thanks for
19:49 - watching and
19:50 - as always I don't know subscribe like
19:51 - that helps supposedly and because then
19:54 - YouTube's neural network I'm just
19:56 - copying three blue and brown stroke at
19:57 - this point you should watch three blue
19:58 - one Browns videos they're good and I
20:03 - learned so much just from like watching
20:06 - those and I'll be back in the next video
20:07 - it's a boy thank you
20:13 - [Music]

Cleaned transcript:

hello now if you watch the previous video hey boys thank you well I hope you're not too mad at me and I didn't file too many complaints in the comments there but in the previous video I talked through the feedforward algorithm they attempted to map it and graph it I attempted to get all the indices right to explain why we use matrix math for it all that sort of stuff now we've got to get to something we got to get to the interesting part which is actually to use the neural networks for something it's taking me a while to get there I will get there but I have something to confess if you thought that was bad I actually uh wilderness Dan over here tried in a live stream previously to go through all this and got all the index values and everything wrong was so bad it couldn't even like get it together to turn it into an actual tutorial video that I'm making in the playlist but it does exist if you're interested I got a haircut seemed to fix a lot of things I look like a much more professional person you can go back and watch that previous those previous attempts so actually done so this is my second try I'm just being honest here all right so what is it that I want to do oops in this particular video we can close all this stuff what I want to do is I have a matrix I have a matrix class that I've developed I have a neural network class that I've developed what I want to do I want to be able to write code like the following I want to be able to go into my p5.js sketch or any JavaScript program and say something like let neural network let n equal a new neural network maybe it has maybe I want to solve X or so I want to have two inputs I just want to have one two hidden nodes and one output so I want to make a neural network object and I want to give it an architecture then I want to do something like I'm going to make an input like I want to send in true false 0 1 comma 0 I want to be able to say let output equal neural network feedforward that input and then I want to say console.log output so this is the this is what I want to be able to do I want to be able to use the neural network on a kind of higher level and once I can do that then I can have inputs that are all different kinds of things where I'm doing data science or some kind of like learn to play flappy bird or whatever it is that I'm doing okay so let's do this what I have so far here is just I have that feedforward function it takes an input and returns that guess now there's no code there I need to fill in the code all that matrix math I need to take everything that I have here and I need to put that all into here so how do I do that all right well my neural network needs some more stuff for example all that it has right now is the number of input nodes which is I just sent into the number of hidden nodes I sent into and the number of output nodes I sent in one well what I need is I need to keep track of those weights right I need to have weights and what do I need to have weights between we need to have the weights between input and hidden and the weights between hidden and output so those we've established our matrices weights between input and hidden is a new matrix and now it has a certain number of rows and columns it has a certain number of rows sorry columns based on the number of inputs and rows based on the number of hidden nodes so we're gonna say it has this dot hidden nodes is its number of rows and this dot input nodes is its number of columns so that's one wait mate ryx and another wait matrix is between hidden and output and that's going to have the number of rows which is the number of output nodes and the number of columns is the number of hidden nodes so I've created these weight matrices now oh oh you have an interesting question when we create a neural network how do we pick the weights again the whole point of this is we need to have some interesting wonderful exciting complicated weird algorithm for tuning the weights for finding the optimal weights for whatever type of application we're trying to build but to start we just want to give it random weights and I did the whole fields of research dedicated to figuring out like good ways to see the neural network with good kind of beginning weight so that you can get the optimal weights more easily blah blah blah but for us right now I just want to give it random weights so I can actually just say we've already built a randomized function into the neural the matrix library so I can say randomized so this will randomize the weights and actually though if you recall I was reminded by this in the chat that my randomize function for some of my demonstrations I was actually picking a number between 0 and 10 and it would make much more sense to get a random number between maybe negative 1 and 1 to start at the weight so I could take math dot random which is 0 to 1 x 2 subtract 1 and I've got a random value between negative 1 and 1 okay so we're doing well what else do I need I should probably I should probably keep track of the bias the hidden bias and the output bias again as we saw when I'm sort of talking about it could put that into the matrices but I'm going to keep track of that separately it's a little easier for me so I'm gonna say this dot bias hidden equals a new matrix that has how many biases do I have I have o based on the number of hidden nodes right that those are the rows and then one column is it yeah because it's one column vector and the bias or the output is based on how many output nodes so for every I need a bias value for every node in every layer so I need to bias values for each hidden node and one bias value for each the single output node but you know again my neural network library allows me to create neural networks with any number of hidden nodes any number of inputs any number outputs it is just has these two layers and the inputs but so at some point it might be worth expanding it so I kind of multiple hidden layers that sort of thing but this is gonna work fine for now okay so what else do I need now ahhahaha there's something we're missing so for example let's just what am I what am i feeding in here feedforward input this is just an array but technically in order for me to be able to do the first stop right the first thing that I want to do is I want to say this dot hidden I'm sorry I'm gonna make this let hidden this will be the output right I want to compute the output of the hidden nodes that's going to be a one dimensional of one column matrix that is going to be that is going to be the matrix product between the input and this and the weights and the weight weight matrix between and actually I have to say the weights first sorry the weights remember the order in matrix multiplication really matters the weights input hidden with that input then I'm going to say hidden dot add this dot bias so I do the matrix product of the inputs and the weights then I add in the bias and then I'm gonna do activation function I won't do that just yet but even this is no good so far this is no good so far because this input what does this matrix multiply function expect matrix multiply in my library expects two matrix objects and this the way I've written my sketches I just made the inputs an array which is an incredibly convenient thing to do I don't want to make my endusers have to like figure out they just want me I'll send the inputs in in a simple array so one thing that I should do here I mean I could test I could check if it's already an instance of a matrix I could skip it but what I want to do is I want to say I'm going to call this input array I want to say inputs equals matrix from array input array and the reason why I'm writing this out is because I've thought of this already I need to be able to make a matrix object from arrey so I want to be able to have a matrix object so that my matrix multiply function will work and I could create a different constructor that takes an array but I think what would make sense is for me to add right up here in the beginning right and a static function that's that's called from array it takes an array and what I want to do here is I want to say let may n equal a new matrix that has just that has a number of rows based on the arrays length and one column right I want to create a matrix that looks like this it has a number of rows based on the arrays length and one column and then all I need to do is say for let I equals 0 I is less than array dot length I plus plus and I'm going to say data oh sorry sorry m dot data index I index 0 equals equals array index I and then return n so this is just again oh I'm sure every lots of you could probably think of some type of array functionality that I could use really easily but this is creating that matrix and then just that matrix and then putting the input into it so just to be sure about this let me let me say m dot print okay let me just make sure this works so I have some errors here oh that actually nicely printed something out for me that I didn't realize it would so what I want to do is I want to say let a array equal a 1 comma 0 comma negative 5 and then I want to say matrix dot from array array and we should see there we go we've got a column a single column matrix 1 0 negative 5 so that function is working the way that I hoped it would so I can take out this debugging and I can keep this in here and now if I go back to this code I can say okay we get an input array we turn that into an input matrix and then this needs an S here we multiply we do the matrix product of the inputs with the weights we add in the bias we one more step left to go we need to do the activation function so we need the sigmoid function well it so happens that there isn't a magical sigmoid function that exists in JavaScript however there is in the math library a function called exp JavaScript math let's find this documentation page this exp Euler's number or also known as Napier's constant does for us e to the X so I can write my own sigmoid function so I can just um and and at some point I probably will allow the neural network library to use different activation functions but right now I'm just globally gonna write a function called sigmoid it's going to take one input X and it is going to return one divided by one plus mass of X somebody factcheck for me but I believe that is the sigmoid function and so the wonderful thing now is once I receive the inputs once I've done the matrix product of the weights and the inputs once I've added in the bias I can generate the outputs with the activation function just by saying hidden dot map sigmoid if you recall I wrote into my matrix library a function called map which just allows me to apply any arbitrary function to every element of that matrix so so there we go now we're done so this is this is all the code for generating the hidden outputs and this is the activation function now where are we in the diagram we've got the inputs we did the matrix product we added in the biases we passed the activation function now those outputs are coming in here what do we need to do now take those hidden outputs and do the matrix product with these weights so we're gonna do exactly that same thing we're going to say let output equal matrix dot multiply this this dot weights now I need the weights between the hidden and the output H oh I need the hidden outputs which is drug just calling hidden then I need to add in those output biases did I call it bias oh yes in each oh and by the way I just realized I never gave these any initial values so it would make sense for me to also randomize these so I'm going to randomize those biases so right so now I've got the weights times they hit the matrix products with the weights and the hidden outputs I'm added in the bias and then output dot map sigmoid and guess what return output that's all I want that's done that's the last piece I want to send in the inputs in my actual code I want to be able to send in the inputs and then read out the output but here's the thing I sent in the inputs as a simple array and then internally converted that into a matrix so I could do all the math properly now before I get the outputs back I don't want you want to send out a matrix it's gonna be simpler if I just send out those outputs as an array so much like I wrote that from array function I am going to create a function called two array and that doesn't need to be static because I'm gonna take any given matrix object and return in the right now there are some way I could probably transpose it and and do some fancy way or use the slice function I'm again I'm gonna do this just in a way that I know will work will catalyze refactor this later in the end I'm gonna refactor all this using somebody else's matrix library anyway so let me think about how I would do this first I want to make an array I'll make it empty and then really all I want to do is I want to loop through every element of the array every element of the matrix and what I want to do is I want to say array dot push every element of the matrix and say return alright so this would actually take any twodimensional matrix and flatten it to one mention array the question is though one thing we should ask ourselves here is it appropriate to have the columns as the inner loop so if I think about it if I wanted to take I mean obviously doesn't matter if it's this matrix because I just want to take all these and put it into an array but if it's that if I want to take like this array and flatten it do I want to go dodododododo or do I want to go doodoodoodoo doodoodoodoo I think I want to go this way dodododododo I got distracted by my own singing of the iteration song is just doo doo doo doo alright sorry I'll get back to this I apologize I think I want to iterate through the columns on the inner loop which it looks like that's what I'm doing so I'm gonna keep it this way except for yeah okay so I'm gonna keep it this way and I'm gonna say here now in the neural network I can say return output to array okay everyone this is it this is the whole feedforward algorithm this is receiving the inputs generating the hidden outputs generating the output output and then sending it back to the color alright so this is the whole algorithm layer this is like layer 1 and layer 2 the hidden layer the output layer okay what do we do now let's try running the code I mean it's absurd but because this does nothing but let's actually let's just run this let's just see can I create a neural network give it some are very input and get some output can I get it with no mistakes it seems very unlikely that I'm gonna have no mistakes and this is a reason why I shouldn't use my drum roll effect but I'm gonna do it anyway here we go let's run this code it worked the first time thing it worked is a strange thing to say cuz relay to get any errors and probably one reason getting errors because it's actually my second try of building this out you might be wondering like oh okay so I just watched like two and a half hours of like eight videos in a row about matrices and neural networks and you just went for point five nine three one zero seven the thing is we have none you gotta start testing this we've got to come up with a server we're getting close we're what I want to do probably the first thing I'll do it's not that interesting but at least allow us to test whether this code works is can I train it to learn and and operation or operation or X or exclusive or which is one that I've talked about that can't be solved with a single perceptron so can I feed it in one zero and train it to get the number one out can I feed it in zero one train to get the number one out but if I give it zero zero one one I get the number zero out so I need to attend that but I am missing a lot of functionality from this neural network class I have this feedforward algorithm function now what I need is to write a function called train and what I'm gonna do with the train function is I'm going to give it some inputs and then I'm gonna give it a known answer so the idea here is like with feedforward I'm really just saying take these inputs and give me an output with training I'm gonna say take these inputs that I have an owned labeled answer to and do something to yourself based on that and that's where I'll start getting to in the next video I have to talk about back propagation and gradient descent I have talked about this in previous videos will kind of return to that then I need to finish implementing this function and then I'll do a coding challenge where I try to solve XOR and do like a simple digit recognition or something with this particular neural network library okay thanks for watching um just them going through this I'm trying it out and see if I can make this room that would still happen doing a guy's being us Abby thanks Abby but all things all things will come eventually so thanks for watching and as always I don't know subscribe like that helps supposedly and because then YouTube's neural network I'm just copying three blue and brown stroke at this point you should watch three blue one Browns videos they're good and I learned so much just from like watching those and I'll be back in the next video it's a boy thank you
