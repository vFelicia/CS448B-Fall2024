With timestamps:

00:00 - - Hello, welcome to a video tutorial.
00:03 - That's what happens on
this channel, I guess.
00:05 - So this is sponsored by Spell.
00:07 - Thank you so much to
Spell for the sponsorship.
00:10 - What you're about to
watch is an edited version
00:12 - of a livestream that
happened a couple weeks ago.
00:14 - We have a guest educator and artist,
00:17 - Brooklyn based educator
and artist Nabil Hassein.
00:19 - I recommend you check out his website
00:21 - linked in this video's
description and learn more
00:23 - about his background and his current work,
00:25 - and all sorts of wonderful
stuff that he is up to.
00:28 - So what you're going to
see, from beginning to end
00:30 - in this video, is the process
00:33 - for taking a corpus of text,
00:34 - training a machine learning model,
00:36 - this particular model is called LSTM,
00:39 - long short term memory neural network.
00:42 - Nabil will explain that
a bit more in the video
00:43 - and offer you some
resources to learn about it.
00:45 - Train a model to learn about that text.
00:50 - Train it in the cloud, on Spell,
00:52 - you go to spell.run slash coding train
00:55 - if you want to sign up for that service
00:57 - and follow along with the tutorial.
00:59 - And then download the train model,
01:02 - then bring that train
model into the browser,
01:04 - into JavaScript, generate
new text in the style of
01:08 - the original text that
the model was trained on.
01:10 - So you're going to see the
full process for this tutorial.
01:13 - Probably, if you've never watched
01:14 - any of my videos before
you're new to coding,
01:16 - you might want to watch
some of my workflow videos
01:19 - that show you how to
set up your environment
01:21 - you're going to need, you'll
need a Python environment,
01:23 - you're going to need a code editor
01:25 - and know how to run a
webpage in your browser
01:28 - that you're developing
locally on your computer.
01:29 - But I have videos that
show all that stuff.
01:31 - I also have a video that
introduces the Spell platform
01:34 - and gives you some background
about how that works.
01:36 - Alright, so I hope you enjoy this video.
01:38 - If you make something with
this, please share it with me.
01:40 - I would love to see what kind
of crazy, and interesting,
01:42 - and wacky, and original, and
fun, and playful projects
01:44 - you are inspired to make
by learning how to do this.
01:48 - Thank you again to Nabil
for being here to make
01:51 - this tutorial and to
Spell for the sponsorship.
01:53 - Okay, bye bye.
01:55 - - Alright, hello everyone, I'm Nabil,
01:57 - thanks Dan for this great intro
01:59 - and thank Spell for paying me to make
02:01 - this video or to do this livestream.
02:04 - So I have here kind of an outline
02:05 - of what I plan to go through,
02:08 - so I guess I'll start by going ahead
02:09 - and introducing myself.
02:10 - So I already said hi, I'm Nabil,
02:12 - I live in Brooklyn, I'm a freelance
02:14 - technologist, educator,
do some other things.
02:17 - Again, thank you Spell
for sponsoring this video.
02:21 - So this livestream is about how to train
02:24 - an LSTM model using the Spell platform,
02:27 - so on some remote machine somewhere,
02:30 - and then how to use that
model that we've trained
02:32 - using a library called ml5.js,
02:35 - which is a browser based front end library
02:38 - for using machine learning models.
02:42 - So what I'm going to do in this video,
02:43 - I've practiced most of this,
02:45 - I'm going to try to do a few things
02:46 - truly live for you here today.
02:49 - I'm going to kind of
extend a project that I did
02:53 - actually at the School
for Poetic Computation,
02:55 - which Dan mentioned last summer.
02:57 - The way that that project
works is there's a bunch
03:01 - of random, it'll generate random rhymes.
03:04 - Right now, this, what
I have live on the web,
03:07 - what I'm actually showing from my website
03:08 - is based on a Markov model,
03:10 - so it's not really machine learning,
03:11 - it's just probabilistic predicting
03:13 - the next character based
on the previous ones.
03:17 - Then you can click this all day
03:18 - and it'll keep coming up
with more and more rhymes.
03:20 - The video in general, as you know,
03:22 - is about training an
LSTM model using Spell
03:24 - and then using it in the browser
03:26 - via a library called ml5.js.
03:29 - So let's go ahead and get into it.
03:34 - So the next thing, so I'm
not really going to talk
03:37 - to you much in this video about the theory
03:39 - of neural networks or
what is an LSTM really,
03:42 - but I figure I should
probably say something.
03:44 - First of all, LSTM stands
for long short term memory.
03:49 - It's a specific type of
recurrent neural network,
03:52 - and what is useful about
recurrent neural networks
03:56 - or RNNs compared to some other types
03:58 - of neural networks is the way
04:00 - that their architecture includes loops,
04:02 - and that can be useful for kind of
04:04 - keeping data around in the network,
04:06 - so to speak, which is very useful
04:08 - for applications involving
04:11 - natural language, human language,
04:13 - because context matters
so much in language.
04:18 - Predicting the next
character or the next word,
04:21 - you might get a much better prediction
04:24 - if you actually remember what was said
04:26 - even some while ago, maybe like
04:27 - much earlier in a long sentence.
04:30 - I have a few quick references here,
04:34 - which, by now are a little old,
04:35 - but these are what I read to learn
04:39 - a little bit about
recurrent neural networks.
04:41 - So there's this blog post
called The Unreasonable
04:43 - Effective of Recurrent Neural Networks,
04:46 - and there's this other blog post
04:48 - called Understanding LSTMs.
04:51 - So yeah, this gives a
little bit of overview
04:53 - of kind of the same stuff
I was just talking about.
04:54 - Humans don't start their thinking
from scratch every second.
04:58 - You understand each word based on
04:59 - your understanding of previous words,
05:00 - and that's what we want
our network to do as well,
05:03 - which is why we're going
to use this LSTM model.
05:09 - I know that before I had the chance,
05:10 - while preparing for this video,
05:12 - to watch a video that Dan made kind of
05:13 - giving an overview of the Spell platform,
05:16 - so a link that video will also
05:17 - be added to the video description
05:19 - and you can kind of get into a little
05:21 - bit more depth about using Spell.
05:24 - And I'll also mention some things
05:25 - about using Spell as we go through this.
05:29 - Okay, so when you want to
do a project like this,
05:31 - the first thing that you have to do
05:33 - is get your corpus of data.
05:37 - So in this case, since I
was getting song lyrics,
05:40 - I used a site called Genius.com,
05:43 - which you might be familiar with.
05:45 - It's a popular lyrics website,
05:47 - it has some other features too
05:48 - but the main thing I use it for,
05:49 - and I think most people use it for,
05:50 - is reading lyrics.
05:53 - So what I'm going to do,
I'm going to try to do
05:55 - everything kind of from
scratch, so to speak,
05:57 - so that you should be able
to follow along in theory.
06:00 - What I'm going to do, this is a
folder that I used to prepare.
06:06 - What I'm going to do is
just make a new folder
06:08 - called Spell Livestream, and I'm going to
06:12 - do everything from inside of this folder,
06:14 - which just lives somewhere on my computer.
06:16 - So right now this folder is empty.
06:21 - And so the first thing that
I'm going to do is just
06:26 - clone my generative DOOM
repository from GitHub.
06:30 - There's only actually one file in there
06:33 - that I care about so
maybe not actually clone
06:35 - the whole repository, let
me just get that one file.
06:37 - Okay, so I'm just going to
06:43 - where this is, it's in data,
oh but did I push it up?
06:47 - I have so many branches here.
06:48 - Okay, why don't I use the one
that I have on my computer.
06:52 - So I'm just going to copy a file
06:54 - that I have on my
computer into this folder.
06:57 - So where's that, in Spell demo slash
07:00 - generative DOOM slash data.
07:05 - I have a file called
input.txt that I just moved,
07:08 - that I just brought a copy
of into my current directory.
07:11 - We can just check it out really quickly,
07:14 - oops, less input.txt.
07:16 - So you can see this is
just the list of lyrics.
07:20 - Okay, this is my corpus.
07:22 - It's worth noting that the data set
07:25 - I'm actually using for this
example isn't that big.
07:28 - We can check the size
of it with the command
07:30 - line utility du for this usage,
07:32 - past the human readable
flag so that we can actually
07:34 - tell how big this file is.
07:37 - It's about 308 kilobytes,
so it's not huge.
07:40 - Normally when you're training
machine learning models,
07:44 - kind of, the more data the better,
07:47 - but I got all the lyrics I
could find by this artist,
07:48 - this is really the most that I could get.
07:51 - So that's what we're going to use.
07:55 - Cool, so it's also worth noting
07:59 - that you have to clean the
data before you train it,
08:02 - so I can actually go ahead and show
08:07 - the code that I used to get these lyrics.
08:09 - I'm not going to go into
full depth, but again,
08:11 - it's on my GitHub if you
want to check it out.
08:14 - So let's put it over here.
08:20 - So I happen to do my
scripting using Python.
08:23 - You can do this in any language,
08:24 - you can do web scripting using Node.js
08:26 - or Ruby or whatever your
favorite language is.
08:28 - But I happen to have already used before
08:30 - a Python library called BeautifulSoup,
08:32 - which is very useful for web scripting.
08:37 - It so happens that
Genius.com happens to keep
08:40 - their lyrics and their URLs
follow a pattern like this,
08:45 - genius.com slash the name of the artist,
08:47 - which I substituted in here,
08:49 - and the name of the song,
08:51 - which I substituted in here,
08:53 - and then I used another Python library
08:55 - called Requests to just go ahead
08:58 - and fetch all these different things.
09:00 - So this is the basic idea,
09:01 - I'm not going to go into full depth,
09:03 - but I just kind of hard
coded a lot of names
09:05 - of different songs into here,
09:08 - and then I have a main
loop which basically
09:10 - just loops through each artist's name
09:12 - because DOOM has actually recorded
09:14 - under many different
names, so I can't just
09:15 - use the same artist's name all the time.
09:17 - And then the same thing for the albums
09:20 - and then finally the songs in order
09:22 - to go ahead and just
fetch all of this data.
09:27 - The thing is that when you
just go directly to some
09:35 - lyrics website, like when you fetch
09:37 - the data on the page, you end up getting
09:38 - a lot of other data that you don't
09:39 - really care about in the HTML,
09:42 - and so an important step
is to clean the data
09:45 - so that when you're training the model
09:47 - you're only training it on the actual
09:48 - corpus that you care about
09:50 - and you're not training
it on the angle brackets
09:52 - of HTML tags or something like that
09:54 - that you don't actually want.
09:56 - So again, I think I have most of the code
09:58 - that I used to clean it on the GitHub,
10:01 - I think it is there, but if not there are
10:04 - other resources that you can use
10:06 - to learn more about data cleaning.
10:07 - Again this video is really about
10:08 - training machine learning
models using Spell
10:10 - and then using them in the browser.
10:13 - So let's get back to that.
10:15 - I wanted to mention Project Gutenberg
10:17 - is another resource that
has lots of free text
10:20 - that's in the public domain
that you can just use.
10:23 - Web scraping with Node.js
is another resource
10:25 - that I've happened to look at
10:26 - for doing this kind of thing.
10:29 - And so although my script.py
file in my generative
10:32 - DOOM repository doesn't show this,
10:35 - the original version I
kind of kept each file,
10:40 - kept each song, in it's
own file of lyrics.
10:43 - But it so happens that the machine,
10:46 - where I'm going to show you next,
10:49 - works with an input that's
just one big input file,
10:52 - input.txt, so I just did
some boring shell script
10:55 - stuff that just concatenate
all the files together.
10:58 - And I've already noted that
my dataset is kind of small.
11:00 - That's everything that I wanted
to say about getting there.
11:05 - So let's kind of get into the main thing.
11:07 - So I think I already did this part,
11:09 - I created a new directory for all
11:12 - this stuff to live in.
11:16 - Okay.
11:18 - So let's go ahead and
go on to the next step.
11:21 - So it's a good habit, I
think, to use virtualenv.
11:27 - I use it with Python two, I understand
11:28 - things have kind of moved
on a bit with Python three,
11:30 - but I'm still on the Python two,
11:33 - so I'm going to use this virtualenv thing
11:36 - to kind of keep my dependencies isolated.
11:41 - Although I think there
should actually only be one.
11:43 - But let's go ahead and do that anyway.
11:45 - So I have some other
virtualenv active right now,
11:47 - it so happens, I see that from
my command prompts over here.
11:50 - So I just ran this command
deactivate to get rid of that.
11:53 - I'm just going to clear the screen
11:54 - to make it a little less noisy here.
11:56 - And then what did I want to do?
11:57 - I wanted to create a new virtualenv.
12:01 - And what did I want to call it?
12:01 - I want to call it spell video virtualenv.
12:09 - Okay.
12:10 - So it's setting up a
new virtual environment,
12:14 - which lives inside of this folder here.
12:17 - And the way that you use Python virtualenv
12:20 - to get it active is you say, what is it,
12:24 - spell video virtualenv
slash bin slash activate,
12:30 - we'll have to say source at the beginning.
12:31 - Source and then the path
to this activate script.
12:38 - Okay, alright.
12:41 - And now you can see my prompt changed
12:43 - because I happen to have
my terminal preferences
12:46 - set up that way so that I can
12:47 - remember what virtualenv I'm in.
12:51 - Okay, so I did that.
12:54 - Oh yeah, I already went
and got that input file,
12:57 - which I should probably push it up,
12:59 - I haven't actually
pushed up to the GitHub,
13:02 - like the one file version, but you know,
13:06 - life is messy.
13:08 - But what I am going to
get the proper version
13:10 - of from GitHub is this repository
13:13 - called training LSTM and so I'm just
13:16 - going to go ahead and clone that,
13:17 - and let's actually go and take a look
13:19 - at that repository and its read me.
13:21 - Cool, so you can see that this,
13:24 - you can see from the description of this
13:26 - repository training in LSTM network
13:29 - and using the model ml5.js that it's
13:32 - highly relevant to what
we're doing in this video.
13:39 - The directions in this
repository's read me
13:42 - are based on what you would want to do
13:44 - if you were training
13:48 - the machine learning model
locally on your own computer.
13:52 - So if that's what you want to do,
13:53 - you can go ahead and follow this,
13:54 - but since this video is
about how to use Spell,
13:57 - that's what I'm actually going to do,
13:58 - so I'm not going to follow
these directions exactly,
14:01 - but we are going to follow along
14:02 - with certain parts of it.
14:06 - Okay, so I've already
cloned this repository,
14:08 - right, that was the
last command that I ran,
14:10 - so I'm going to go ahead and
enter into that repository.
14:15 - And then what I want to do is create
14:17 - a directory inside of here called data.
14:21 - And then I'm going to
go ahead and move that
14:24 - input.txt file into that data directory.
14:29 - Or a copy, I'd rather.
14:30 - I guess I could've deleted it in
14:32 - the other directory, but whatever.
14:34 - Okay.
14:36 - Okay, great, so this is the setup.
14:40 - We have a repository.
14:42 - We have this repository
locally that is going to
14:44 - help us train an LSTM
network using TensorFlow.
14:49 - And then we're going to,
after we train the model,
14:51 - we can use it in ml5.js.
14:53 - So we're pretty much done with our setup,
14:55 - let's get into actually
training the model.
14:58 - So again, this is the
link that you can use
15:01 - to sign up for Spell
if you haven't already.
15:04 - It so happens that I have already,
15:06 - so I should be logged in here,
15:08 - let me just make sure I
haven't been logged out.
15:10 - I haven't.
15:10 - So I'm in here in Spell.run,
15:13 - and it gives me some information
15:15 - about how to install Spell,
15:17 - how to log-in with Spell,
15:18 - there's a little quick step guide
15:19 - that you can check out
with some of the resources
15:21 - that I used when preparing for this video.
15:24 - So yeah, like I mentioned, that other
15:26 - training LSTM repositories
tells you how to run locally,
15:31 - but for us all we really do
need to install is Spell,
15:36 - so I'm going to go ahead and
do that with pip install Spell.
15:40 - And it's going to go ahead and fetch Spell
15:45 - and whatever things Spell depends on
15:47 - from the Python packing, Py
Py, whatever it's called,
15:52 - it's going to just go ahead and get that.
15:57 - Okay.
15:58 - And then once it's done
installing I'll be able to log in.
16:03 - Alright, I can remember it.
16:04 - So, you see it greeted
me, hello Nabil Hassein,
16:06 - so that's me, so I am logged in as myself.
16:10 - And if you ever forget who you're
16:11 - logged in as for some reason,
16:13 - the Spell command has
a lot of sub commands,
16:15 - like Spell who am I will
tell you who you are.
16:20 - I'm just going to go ahead and get started
16:21 - with training this model,
16:22 - and the first thing that we need to do
16:25 - is to upload the file to Spell, okay.
16:31 - So what I want to run
is this command here.
16:34 - Spell upload the path on my
local computer of the file,
16:39 - and then I want to give it a name
16:41 - of where I'm going to upload it to.
16:44 - Okay, so I just got to place that command.
16:45 - Spell upload my data slash
input.txt to this destination.
16:53 - Oh it's actually going to prompt me
16:54 - for the destination in a minute.
16:56 - It doesn't want that yet but it's
16:57 - going to want that momentarily.
16:59 - So let me just say spell upload
17:01 - the name of the file
that I want to upload.
17:04 - And now it's asking me
for the name of the upload
17:05 - that I was trying to
give a little bit early.
17:07 - And it tells me that the file,
17:10 - this is the path to it
on my local computer
17:12 - that I'm typing on right
now will be accessible
17:14 - at upload slash name slash input.txt.
17:17 - And that's the name, oops, oops,
17:20 - just part of it is the name
17:21 - that I want to put in so I'm just going to
17:23 - delete the part I don't want and put in,
17:25 - what was it, Nabil spell livestream DOOM.
17:34 - Okay.
17:35 - Total upload size, 307k,
same as what we saw,
17:38 - or at least very close to what we saw
17:39 - when we ran the du command earlier.
17:43 - And the upload completed.
17:46 - So that's great.
17:48 - So what we're going to do now,
17:50 - this is kind of the most,
17:52 - probably most complicated command that
17:54 - we're going to run but
it's really the only one.
17:57 - This is really what's saying to go ahead
17:59 - and actually run the Python script
18:02 - that we downloaded from train,
18:05 - that training LSTM git repository.
18:09 - Okay, we're going to run that with Python,
18:11 - this train.py script with
the data dir set too,
18:16 - what I happen to call data,
18:18 - that the name of the folder
where I put that input.txt.
18:22 - And I'm going to run it and
I'm going to mount the data,
18:29 - I'm going to mount the folder that I had
18:31 - just created by uploading
that file as the name data
18:35 - so that it can understand
this data directory.
18:39 - Okay, so I should get, I think,
18:41 - one error when I do this,
and I'll talk about why.
18:45 - Okay, spell run mount
dash dash mount upload
18:50 - slash Nabil Spell DOOM,
ope, I called it livestream,
18:53 - in my notes I didn't quite update
19:00 - from when I practiced so let
me go ahead and fix that.
19:04 - Okay, let's see.
19:06 - Okay, so let's try that.
19:08 - And it tells me that there's some
19:09 - untracked files in this repository
19:11 - and they won't be available on this run.
19:13 - Continue the run anyway?
19:14 - No, that's really the
file that I care about.
19:16 - So Spell encourages us to use the Git
19:21 - version control system to make sure
19:22 - that the data that we're
training on is checked in,
19:25 - and that's very good for reproducibility,
19:26 - if we want to go back later and understand
19:28 - what was going on and what was there,
19:31 - so I'm going to go ahead
and kind of follow this
19:35 - adjusted workflow so I'm going to go ahead
19:38 - and git add dot, or I guess I could
19:41 - git add data, whatever.
19:43 - That's the only thing, same effect
19:44 - in this particular case, and I'm going to
19:46 - say add data dot input.txt
file of DOOM lyrics.
19:54 - Okay.
19:55 - And now, having done that,
19:57 - if I run the same command it won't give me
19:58 - that same warning since the files
20:00 - are now tracked instead
of being untracked.
20:02 - Okay.
20:09 - Let me go ahead and start to do this
20:09 - and then I'll go ahead and
mention that other thing
20:11 - that I said I was going to mention.
20:13 - So I'm just going to press up a few times
20:14 - and just go back to my history
20:16 - to run the same command again.
20:17 - Spell run, I'm mounting that data folder
20:20 - that I uploaded to be called data.
20:25 - Oh I put it in the wrong order.
20:29 - - [Dan] So one thing to mention, I think,
20:30 - is that if you're going
to mount the data file,
20:32 - you don't actually have to commit it.
20:35 - - Oh.
20:36 - 'Cause otherwise if you pull it
20:36 - from there you can do either.
20:38 - - Oh, I see.
20:39 - - [Dan] So if you don't
want to upload it with git,
20:42 - then you can do the mounting thing
20:43 - that you're showing now.
20:43 - - Okay, yeah, oh right, so I'm kind of,
20:46 - so there's more than one
way to work with Spell,
20:48 - and I think I kind of conflated
20:49 - two of them a little bit.
20:52 - So, yeah, I didn't actually need to do
20:53 - the git commit because of the way
20:55 - that I'm doing this because
I uploaded it before,
20:59 - and that will also kind
of give some of the same,
21:01 - reproducibility benefits
because Spell will
21:04 - keep a record of what we uploaded,
21:06 - but it doesn't hurt to
get committed either.
21:10 - Let me just fix that typo.
21:12 - - [Dan] In this case, it's such
21:13 - a small file it doesn't really matter.
21:14 - - Yeah.
21:15 - - [Dan] If you were working with a huge
21:17 - gigabyte file or something,
21:17 - you'd want to upload that separately
21:19 - without having to commit it also.
21:21 - - Right, yeah, because Git isn't always
21:23 - the best for dealing with large files
21:24 - which is why there's tools like Spell
21:27 - and tools like, what is it, Git,
21:30 - whatever, there's a bunch of tools.
21:33 - Cool, so let me just go
ahead and fix that typo.
21:36 - I should fix that on my notes as well.
21:38 - Tells me everything is up to date
21:39 - because I did make, like, a commit,
21:41 - although, like Dan mentioned,
21:42 - I didn't really have to.
21:43 - Tells me it's casting spell number 16,
21:46 - so I happen to have used
Spell about 15 times before.
21:49 - Tells me I can stop viewing the logs
21:51 - with control C, tells me it's requesting
21:53 - a machine and building and mounting,
21:55 - and the run is running.
21:56 - And, so, this is still running,
21:57 - and like it told me before,
22:00 - I can just get out of the logs in my
22:02 - local terminal with control C,
22:04 - but this is running on a remote machine
22:06 - that Spell has provisioned
and set up very nicely
22:08 - for me so I don't have to worry about it.
22:10 - So I'm not actually stopping the run
22:12 - from happening when I control C,
22:13 - I'm just stopping the logs
22:14 - from appearing in my own terminal.
22:16 - If I want to check out those logs,
22:19 - I can say Spell logs 16,
22:22 - and they'll start appearing again.
22:26 - And there's also some other commands
22:28 - that it told me about,
like I could kill it
22:29 - with Spell kill whatever,
but I don't want to,
22:31 - I'm going to let it keep running.
22:33 - And besides checking out the logs locally
22:35 - with Spell logs the number of the run,
22:39 - you could also come over
here to this Spell Web UI,
22:43 - and check out different information
22:44 - about the run in here.
22:46 - But as you may notice from this video,
22:47 - I tend to have a preference
for the command lines,
22:49 - so I'm going to keep doing
things mostly that way.
22:54 - Cool.
22:55 - So let's see.
22:56 - Oh yeah, so one thing I did want to
22:57 - mention was the parameters,
22:59 - or what is sometimes
called the hyperparameters
23:01 - of the network, so let's just go back
23:02 - to this git read me really quick.
23:05 - So yeah, like I said, this gives you more
23:07 - information about how
you would run it locally,
23:10 - including how you can
pass additional flags
23:12 - that I didn't bother passing to control
23:15 - more of the characteristics
of the network,
23:18 - like its size, how many
layers they are built
23:22 - into the sequence, and
various other things
23:25 - that you can read more
about in this repository.
23:29 - They have here some
recommendations for what
23:33 - you might want to select
for your hyperparameters
23:35 - according to the size of
your training dataset.
23:39 - Because my training dataset is so small,
23:42 - I decided the defaults were probably fine.
23:45 - The next thing that I wanted to talk about
23:46 - was the difference between running
23:48 - on CPU versus GPU.
23:51 - So I imagine this might be
review for many viewers,
23:55 - but I am a teacher, so I'm always
23:56 - a fan of just reviewing material.
24:00 - So the CPU is the central processing unit
24:03 - of your computer that has maybe a little
24:06 - bit of parallelism, but for the most part
24:08 - is best at running things
sequentially, very fast.
24:14 - And the model of computation is a little
24:16 - bit different from that of GPU,
24:18 - which at some point stood for graphics
24:21 - processing unit and maybe still does,
24:22 - but maybe that acronym's
been retired by now
24:24 - because GPUs actually have
very many applications
24:28 - other than graphics, including training
24:30 - neural networks on text, for example.
24:34 - GPUs, historically they got, I think,
24:37 - that name because each pixel on a screen
24:42 - for the most part is
independent of each other one
24:45 - and so can be computed independently,
24:47 - and so a GPU is much more highly
24:49 - parallel compared to a CPU.
24:52 - It's not going to be as fast at
24:53 - completing like one single task,
24:57 - but it is very good for displaying things
25:01 - on screens and it also happens to be
25:03 - very good for training neural networks.
25:06 - So in the last command
that I ran over here
25:10 - on the command line to
train the neural network,
25:13 - this is running by a CPU,
25:18 - and what I could do if I wanted to
25:20 - instead run my code on a GPU
25:22 - is just tell it that
that's the type of machine
25:25 - I want by adding this dash
dash machine type flag.
25:30 - And the machine type that
I'm going to use is K80,
25:35 - okay, so where does this K80 come from?
25:37 - Well, if you check out
spell.run slash pricing,
25:43 - you'll see some information about how much
25:46 - Spell charges for different
types of machine types
25:50 - according to your needs
for whether this GPU
25:52 - or that CPU is the best
for your particular task.
25:56 - As you can see there's
a few different ones,
25:57 - CPU, CPU big, you know,
all these things, K80.
26:01 - K80 happens to be one of the
less expensive GPU units,
26:05 - so it's good enough for my purses
26:07 - and that is what I'm going to use.
26:11 - Okay, so I go ahead and run that command.
26:13 - Everything's up to date,
it's casting spell number 17,
26:16 - we see a very similar bit
of output as we did before
26:20 - as it gets ready to
start training the model.
26:27 - Okay, the run is running,
so in a moment we should
26:30 - start seeing the logs, after
it reads the text file.
26:34 - Alright.
26:35 - So now this run is running,
26:37 - and I don't know how obvious this is
26:39 - if you're following
along, but it's actually
26:42 - noticeable at least for me that
26:43 - this is happening a lot faster.
26:45 - This model is being trained a lot
26:46 - faster via the GPU than the CPU one was.
26:51 - So the CPU one got a head start,
26:53 - but I still expect that the GPU one
26:54 - will actually finish substantially faster.
26:57 - We see we're already at
like 413 out of 6,000
27:01 - iterations that it's going
through to train the model.
27:05 - Like if we check in on the previous one,
27:08 - let's see how far it is.
27:09 - Yeah, actually, okay, no, I mean
27:11 - the head start it had was pretty big,
27:14 - but you can see the GPU
one is moving faster.
27:17 - Like, if we actually go in,
27:20 - because like I mentioned before,
27:21 - I've had a few practice runs here before,
27:25 - we can look at a few
ones that I did before.
27:32 - Yeah, these were kind of
my first two practice runs.
27:33 - Using a subtly different
model, you can see here,
27:35 - but this one on CPU took
close to five hours,
27:40 - and on GPU it took only a little
27:42 - bit more than 15 minutes.
27:47 - Yeah, so GPU is faster for
this particular use case.
27:54 - Okay, so just for the sake of time,
27:56 - I'm going to grab a
model that I had already
28:00 - trained before rather than
just waiting for this one
28:02 - to go all the way through,
although we could.
28:05 - We could do that, I
mean we can actually use
28:06 - this model later if people
are interested in that.
28:09 - But so what I want to do to grab the data
28:13 - from Spell is to run this command here,
28:16 - spell cp runs slash the number
of the run slash models.
28:21 - Okay, that's how I'm
going to fetch that data.
28:25 - Okay, so I'm just going to cd up here,
28:28 - now I'm kind of in my home folder of all
28:32 - the different things that I'm kind of
28:33 - grabbing from here, grabbing from there
28:35 - to put together into this demo.
28:38 - I'm going to go ahead and
run spell cp, it was 15,
28:42 - right, let me just look here again.
28:44 - Yeah, yeah, so you can see this is using
28:47 - that same training LSTM
I was talking about,
28:51 - it completed in about five minutes.
28:52 - Actually I guess this one should
28:53 - complete pretty quickly, too.
28:55 - And that was a practice
run that I did just
28:57 - a few minutes before
this livestream started.
29:00 - So I'm going to spell cp
runs slash 15 slash models.
29:08 - And it's copying 10 files
that are from there.
29:13 - My ls, my ls data, it
remembers the same data
29:17 - directory that I passed
in before as the name.
29:21 - And these 10 files
constitute the model, okay,
29:26 - I'm not really going
to go into depth about
29:27 - what are these files and what's in them,
29:30 - but yeah, if you're following along
29:31 - you could poke into them and check it out.
29:35 - Cool, so we've trained the model.
29:38 - We've used Spell to train a LSTM model
29:43 - on a corpus of data that we obtained,
29:47 - and now that we have the model,
29:48 - let's use it for something.
29:51 - So I'm going to borrow and then modify
29:54 - an example from this repository here,
29:58 - on the ml5.js GitHub account they have
30:00 - a repository called ml5 examples.
30:04 - So there's a whole collection of examples,
30:05 - there's a bunch of them.
30:06 - You can find out a little bit about how
30:07 - it's organized and some other
stuff from their read me.
30:10 - I'm going to use one in the p5js folder.
30:13 - We are worried about LSTMs.
30:18 - Yeah, that interactive
one is also interesting.
30:21 - That's more
30:23 - I mean, it's more interactive,
30:24 - I'm not really going to describe it.
30:25 - We're going to use the
non-interactive version, LSTM texts.
30:30 - And we have here just a few files.
30:32 - So they actually have a pre-trained model
30:35 - that I'm going to just ignore and not use
30:36 - because we're going to use our model
30:37 - that we just trained instead,
30:39 - but what I am going to do is just fetch
30:40 - these two files, this HTML
file and sketch.js file.
30:44 - And because this repository's big
30:45 - and I just don't want to wait to clone it,
30:48 - I'm literally just going to fetch
30:49 - these two files and nothing else.
30:51 - Okay.
30:53 - So what I'm going to do is just,
30:58 - we'll create another directory, why not.
31:01 - Ml5 LSTM example,
31:05 - and I will change my current
directory to be in there.
31:09 - Let me just clear my
screen for clarity's sake,
31:13 - and then I'm just going to use the command
31:14 - line program wget, which
will just fetch the raw file,
31:19 - I did have to click raw on GitHub.
31:21 - And we'll fetch it onto my local machine.
31:26 - So I do that,
31:29 - and then I go back and I do
the same thing with sketch.js.
31:32 - I just find this one raw file,
31:35 - copy the URL and I use the program wget
31:38 - to download it locally.
31:41 - Okay, so now if I list what's here,
31:42 - I have these two files,
index.html and sketch.js.
31:46 - So let's take a minute to check out,
31:49 - we'll read the files themselves
31:50 - and we'll also use them.
31:52 - So what I'm going to do is just run
31:54 - a program called http server,
31:56 - which you could install if you want,
31:59 - if you don't already have it with,
32:01 - what is it, mpm install
dash g http dash server.
32:04 - You can use any of it, if you're used
32:05 - to using a different web server,
32:07 - anything that will serve up index.html
32:09 - in your local folder is fine.
32:12 - So it tells me where, tells me
32:14 - the URL I can go to on local host
32:18 - to check this out so
I'm going to go there.
32:21 - Says LSTM Text Generation Example,
32:23 - this example uses a pre-trained model
32:24 - on a corpus of Virginia Wolf,
32:26 - although I'm actually not doing that,
32:27 - so I might change that.
32:29 - So let's actually go ahead
and go into this file
32:31 - and also look at the JavaScript file.
32:35 - So let me, I'm a iMAX user,
32:37 - I'm just going to go
ahead and open up repos
32:40 - and I call it Spell livestream.
32:45 - So these are the two files that I had
32:47 - just downloaded a moment ago.
32:50 - It's index.html and sketch.js,
32:52 - so let me open those up in a way
32:54 - that's going to be a little
bit more readable for you.
33:01 - My notes before were so, I guess
33:03 - let me do it over here then.
33:06 - The folders don't really bother
33:08 - the video as much as this one does.
33:11 - Okay, so we have here an HTML document,
33:14 - which relies on p5
33:18 - and ml5 as the libraries
that are being used
33:22 - and pretty much nothing else.
33:25 - Alright, so this example uses
33:27 - a pre-trained model on
a corpus of MF DOOM.
33:31 - So let's just make this nice and accurate.
33:34 - Okay.
33:35 - It says the meaning of life is,
33:37 - which isn't something
I remember DOOM saying,
33:38 - but whatever, we can leave that
33:39 - as the seed text for now.
33:41 - That's an input field in HTML,
33:42 - so we can just change that anyway.
33:45 - So we have a few sliders for how long
33:47 - we want the output to
be and the temperature,
33:48 - which we'll talk about
more a little later.
33:51 - And what's really interesting
is the sketch.js file,
33:53 - so let's actually take a look there.
33:56 - It says open source software,
33:57 - I can just do whatever I want with it,
33:59 - which is great.
34:01 - Okay, so we declare a few variables here,
34:04 - so again, this video isn't about p5,
34:06 - there's kind of a lot of things
34:07 - that I'm touching on but not getting into,
34:09 - but p5 is a really cool library,
34:10 - I encourage you to check that out
34:12 - if you're not familiar with it already.
34:13 - It's great for a lot of artistic coding,
34:15 - I've used it for some
other projects as well.
34:19 - There's kind of two main functions in,
34:25 - well, yeah, let me not really get into p5.
34:29 - We're going to start
with the set up function.
34:32 - Now I'll just say that p5 will run
34:34 - this set up function
for us at the beginning.
34:36 - And it says create the LSTM generator
34:39 - passing it the model directory.
34:43 - I don't have anything
called model slash wolf
34:45 - 'cause I didn't clone
that whole repository,
34:46 - so what I need to do
is make sure that this,
34:50 - when it's generating,
like when it's creating
34:53 - the LSTM that we're going to use,
34:55 - I need to make sure that this is pointing
34:57 - towards the proper path
where we have our file.
35:00 - So let me go ahead and just
remind myself on the command
35:03 - line of where I am keeping everything.
35:06 - Let me just control C out of the server
35:08 - and I'll start again in a minute.
35:10 - So let's see.
35:11 - Let me ls up here, I have something called
35:14 - data up there, which had
what I wanted, right?
35:17 - Yeah, those are the files from my model.
35:19 - So why don't I just copy that
folder into here, where I am.
35:25 - I have to say, what is it, lower case R
35:27 - or capital R for our cursive copy.
35:30 - I guess lower case worked.
35:31 - So now when I ls here,
besides the two files
35:36 - that I fetch from GitHub using wget,
35:38 - I also have all those data
files that are right here.
35:43 - So what I'm going to do is I'm just
35:45 - going to change this to say data,
35:50 - because that's where my data is, okay.
35:54 - And then here, there's some other code.
35:56 - This is really about the user interaction
35:58 - of like what happens when sliders
36:01 - get moved around and buttons get clicked,
36:04 - so I'm not really going to go over that.
36:08 - What we will just take a minute to look at
36:10 - is this generate function, which again,
36:14 - not going to go all the way through,
36:16 - but it lets you know
it's generating stuff,
36:19 - like just so that the user knows something
36:21 - is happening, grabs the
input from the seed text.
36:30 - It uses these parameters,
temperature and length,
36:33 - and then the ml5.js
library does really all
36:37 - the heavy lifting for us,
36:38 - we just kind of cull this
lstm.generate function
36:43 - with our data and patch up this call back
36:45 - function which will go
ahead and update the dom,
36:49 - kind of update the HTML
page when that function
36:52 - is done running, done generating the text
36:55 - that the model has predicted
based on the input seed.
36:59 - Okay.
37:00 - So you can see this is
a pretty short file.
37:02 - Didn't go through every detail,
37:03 - but it's on GitHub, you can check it out.
37:06 - You saw I really just made
one small change to it.
37:10 - Cool, so let me go back to my notes.
37:12 - I'm pretty sure I know
what I want to do next,
37:13 - but it's always good to be sure.
37:16 - That's the path, yup, I
already told you that.
37:20 - I did that.
37:21 - Alright, so let me actually go ahead
37:23 - and run the server again.
37:27 - Okay, just refresh the page,
37:29 - you can see it's updated with this.
37:31 - Okay, the model's loaded,
we can click generate.
37:37 - And it, I mean, I don't know how many
37:41 - people listen to DOOM, if you don't
37:43 - maybe you can just take my word for it.
37:44 - This sounds a little bit
like something he might say.
37:47 - So we can adjust the
length, make it longer,
37:53 - or make it shorter,
37:56 - and we can use this
temperature thing, like,
37:58 - the temperature is
something like intuitively,
38:02 - it's kind of like the
randomness of the text.
38:05 - The higher the temperature,
the less random it will be,
38:08 - kind of the more derivative it will be
38:10 - of the original text,
and if you turn it up
38:14 - very high it starts to become very likely
38:16 - that you get kind of direct quotes
38:18 - from the original corpus.
38:21 - If it's lower, it is maybe a little
38:24 - bit more chaotic, so to speak.
38:27 - And I think that can generate things
38:29 - that are a little bit more out there
38:31 - and more interesting or original.
38:33 - But if you start to do it maybe too low,
38:37 - you might start to get
kind of just nonsense.
38:40 - It might not really make
very much sense at all.
38:42 - Especially if you get like really low.
38:45 - Oh, it might or it might not.
38:49 - So yeah, I mean, okay, I'll withhold
38:53 - my opinion on these
generated lyrics for now.
38:55 - This is an art critique session.
38:57 - Alright, so yeah, I mean,
that's really the main thing,
39:03 - so I mean if I was going to go ahead
39:04 - and reproduce my original project,
39:08 - what I would do now is pull in another
39:09 - dependency which is the
pronouncing library,
39:12 - and then I would've,
what I should've done,
39:16 - maybe I can do this now, is trained
39:19 - the model backwards, like
if we actually look at
39:28 - this input.txt you can see
39:30 - that these lyrics are forward
39:31 - and so the model does that also,
39:33 - so that's something that I would
39:34 - want to do is just reverse that input
39:37 - and train the model backwards.
39:39 - And then I can use the pronouncing
39:40 - thing to go backwards and so on.
39:43 - But, yeah, I think instead of doing that
39:45 - I think what might make more sense
39:46 - would be for me to take any questions
39:48 - from the people who are on the livestream
39:49 - because that is pretty much, yeah,
39:53 - that's pretty much that.
39:54 - So we've got through what is LSTM,
39:58 - getting data, setting things up,
40:00 - training the model using Spell,
40:01 - and then using the model in ml5.js,
40:05 - so that is what I had
prepared for you today,
40:06 - and I look forward to any questions.
40:10 - - Thank you so much Nabil,
for this wonderful tutorial.
40:13 - Again, thank you to Spell
for the sponsorship.
40:15 - If you make something with this,
40:17 - please share it with me,
40:18 - I would really love to know about it,
40:19 - and I'll see you in future tutorial.
40:21 - Many more machine learning, ml5,
40:23 - Python-y, TensorFlow-y
things to come I hope.
40:26 - Goodbye.
40:27 - (upbeat music)

Cleaned transcript:

Hello, welcome to a video tutorial. That's what happens on this channel, I guess. So this is sponsored by Spell. Thank you so much to Spell for the sponsorship. What you're about to watch is an edited version of a livestream that happened a couple weeks ago. We have a guest educator and artist, Brooklyn based educator and artist Nabil Hassein. I recommend you check out his website linked in this video's description and learn more about his background and his current work, and all sorts of wonderful stuff that he is up to. So what you're going to see, from beginning to end in this video, is the process for taking a corpus of text, training a machine learning model, this particular model is called LSTM, long short term memory neural network. Nabil will explain that a bit more in the video and offer you some resources to learn about it. Train a model to learn about that text. Train it in the cloud, on Spell, you go to spell.run slash coding train if you want to sign up for that service and follow along with the tutorial. And then download the train model, then bring that train model into the browser, into JavaScript, generate new text in the style of the original text that the model was trained on. So you're going to see the full process for this tutorial. Probably, if you've never watched any of my videos before you're new to coding, you might want to watch some of my workflow videos that show you how to set up your environment you're going to need, you'll need a Python environment, you're going to need a code editor and know how to run a webpage in your browser that you're developing locally on your computer. But I have videos that show all that stuff. I also have a video that introduces the Spell platform and gives you some background about how that works. Alright, so I hope you enjoy this video. If you make something with this, please share it with me. I would love to see what kind of crazy, and interesting, and wacky, and original, and fun, and playful projects you are inspired to make by learning how to do this. Thank you again to Nabil for being here to make this tutorial and to Spell for the sponsorship. Okay, bye bye. Alright, hello everyone, I'm Nabil, thanks Dan for this great intro and thank Spell for paying me to make this video or to do this livestream. So I have here kind of an outline of what I plan to go through, so I guess I'll start by going ahead and introducing myself. So I already said hi, I'm Nabil, I live in Brooklyn, I'm a freelance technologist, educator, do some other things. Again, thank you Spell for sponsoring this video. So this livestream is about how to train an LSTM model using the Spell platform, so on some remote machine somewhere, and then how to use that model that we've trained using a library called ml5.js, which is a browser based front end library for using machine learning models. So what I'm going to do in this video, I've practiced most of this, I'm going to try to do a few things truly live for you here today. I'm going to kind of extend a project that I did actually at the School for Poetic Computation, which Dan mentioned last summer. The way that that project works is there's a bunch of random, it'll generate random rhymes. Right now, this, what I have live on the web, what I'm actually showing from my website is based on a Markov model, so it's not really machine learning, it's just probabilistic predicting the next character based on the previous ones. Then you can click this all day and it'll keep coming up with more and more rhymes. The video in general, as you know, is about training an LSTM model using Spell and then using it in the browser via a library called ml5.js. So let's go ahead and get into it. So the next thing, so I'm not really going to talk to you much in this video about the theory of neural networks or what is an LSTM really, but I figure I should probably say something. First of all, LSTM stands for long short term memory. It's a specific type of recurrent neural network, and what is useful about recurrent neural networks or RNNs compared to some other types of neural networks is the way that their architecture includes loops, and that can be useful for kind of keeping data around in the network, so to speak, which is very useful for applications involving natural language, human language, because context matters so much in language. Predicting the next character or the next word, you might get a much better prediction if you actually remember what was said even some while ago, maybe like much earlier in a long sentence. I have a few quick references here, which, by now are a little old, but these are what I read to learn a little bit about recurrent neural networks. So there's this blog post called The Unreasonable Effective of Recurrent Neural Networks, and there's this other blog post called Understanding LSTMs. So yeah, this gives a little bit of overview of kind of the same stuff I was just talking about. Humans don't start their thinking from scratch every second. You understand each word based on your understanding of previous words, and that's what we want our network to do as well, which is why we're going to use this LSTM model. I know that before I had the chance, while preparing for this video, to watch a video that Dan made kind of giving an overview of the Spell platform, so a link that video will also be added to the video description and you can kind of get into a little bit more depth about using Spell. And I'll also mention some things about using Spell as we go through this. Okay, so when you want to do a project like this, the first thing that you have to do is get your corpus of data. So in this case, since I was getting song lyrics, I used a site called Genius.com, which you might be familiar with. It's a popular lyrics website, it has some other features too but the main thing I use it for, and I think most people use it for, is reading lyrics. So what I'm going to do, I'm going to try to do everything kind of from scratch, so to speak, so that you should be able to follow along in theory. What I'm going to do, this is a folder that I used to prepare. What I'm going to do is just make a new folder called Spell Livestream, and I'm going to do everything from inside of this folder, which just lives somewhere on my computer. So right now this folder is empty. And so the first thing that I'm going to do is just clone my generative DOOM repository from GitHub. There's only actually one file in there that I care about so maybe not actually clone the whole repository, let me just get that one file. Okay, so I'm just going to where this is, it's in data, oh but did I push it up? I have so many branches here. Okay, why don't I use the one that I have on my computer. So I'm just going to copy a file that I have on my computer into this folder. So where's that, in Spell demo slash generative DOOM slash data. I have a file called input.txt that I just moved, that I just brought a copy of into my current directory. We can just check it out really quickly, oops, less input.txt. So you can see this is just the list of lyrics. Okay, this is my corpus. It's worth noting that the data set I'm actually using for this example isn't that big. We can check the size of it with the command line utility du for this usage, past the human readable flag so that we can actually tell how big this file is. It's about 308 kilobytes, so it's not huge. Normally when you're training machine learning models, kind of, the more data the better, but I got all the lyrics I could find by this artist, this is really the most that I could get. So that's what we're going to use. Cool, so it's also worth noting that you have to clean the data before you train it, so I can actually go ahead and show the code that I used to get these lyrics. I'm not going to go into full depth, but again, it's on my GitHub if you want to check it out. So let's put it over here. So I happen to do my scripting using Python. You can do this in any language, you can do web scripting using Node.js or Ruby or whatever your favorite language is. But I happen to have already used before a Python library called BeautifulSoup, which is very useful for web scripting. It so happens that Genius.com happens to keep their lyrics and their URLs follow a pattern like this, genius.com slash the name of the artist, which I substituted in here, and the name of the song, which I substituted in here, and then I used another Python library called Requests to just go ahead and fetch all these different things. So this is the basic idea, I'm not going to go into full depth, but I just kind of hard coded a lot of names of different songs into here, and then I have a main loop which basically just loops through each artist's name because DOOM has actually recorded under many different names, so I can't just use the same artist's name all the time. And then the same thing for the albums and then finally the songs in order to go ahead and just fetch all of this data. The thing is that when you just go directly to some lyrics website, like when you fetch the data on the page, you end up getting a lot of other data that you don't really care about in the HTML, and so an important step is to clean the data so that when you're training the model you're only training it on the actual corpus that you care about and you're not training it on the angle brackets of HTML tags or something like that that you don't actually want. So again, I think I have most of the code that I used to clean it on the GitHub, I think it is there, but if not there are other resources that you can use to learn more about data cleaning. Again this video is really about training machine learning models using Spell and then using them in the browser. So let's get back to that. I wanted to mention Project Gutenberg is another resource that has lots of free text that's in the public domain that you can just use. Web scraping with Node.js is another resource that I've happened to look at for doing this kind of thing. And so although my script.py file in my generative DOOM repository doesn't show this, the original version I kind of kept each file, kept each song, in it's own file of lyrics. But it so happens that the machine, where I'm going to show you next, works with an input that's just one big input file, input.txt, so I just did some boring shell script stuff that just concatenate all the files together. And I've already noted that my dataset is kind of small. That's everything that I wanted to say about getting there. So let's kind of get into the main thing. So I think I already did this part, I created a new directory for all this stuff to live in. Okay. So let's go ahead and go on to the next step. So it's a good habit, I think, to use virtualenv. I use it with Python two, I understand things have kind of moved on a bit with Python three, but I'm still on the Python two, so I'm going to use this virtualenv thing to kind of keep my dependencies isolated. Although I think there should actually only be one. But let's go ahead and do that anyway. So I have some other virtualenv active right now, it so happens, I see that from my command prompts over here. So I just ran this command deactivate to get rid of that. I'm just going to clear the screen to make it a little less noisy here. And then what did I want to do? I wanted to create a new virtualenv. And what did I want to call it? I want to call it spell video virtualenv. Okay. So it's setting up a new virtual environment, which lives inside of this folder here. And the way that you use Python virtualenv to get it active is you say, what is it, spell video virtualenv slash bin slash activate, we'll have to say source at the beginning. Source and then the path to this activate script. Okay, alright. And now you can see my prompt changed because I happen to have my terminal preferences set up that way so that I can remember what virtualenv I'm in. Okay, so I did that. Oh yeah, I already went and got that input file, which I should probably push it up, I haven't actually pushed up to the GitHub, like the one file version, but you know, life is messy. But what I am going to get the proper version of from GitHub is this repository called training LSTM and so I'm just going to go ahead and clone that, and let's actually go and take a look at that repository and its read me. Cool, so you can see that this, you can see from the description of this repository training in LSTM network and using the model ml5.js that it's highly relevant to what we're doing in this video. The directions in this repository's read me are based on what you would want to do if you were training the machine learning model locally on your own computer. So if that's what you want to do, you can go ahead and follow this, but since this video is about how to use Spell, that's what I'm actually going to do, so I'm not going to follow these directions exactly, but we are going to follow along with certain parts of it. Okay, so I've already cloned this repository, right, that was the last command that I ran, so I'm going to go ahead and enter into that repository. And then what I want to do is create a directory inside of here called data. And then I'm going to go ahead and move that input.txt file into that data directory. Or a copy, I'd rather. I guess I could've deleted it in the other directory, but whatever. Okay. Okay, great, so this is the setup. We have a repository. We have this repository locally that is going to help us train an LSTM network using TensorFlow. And then we're going to, after we train the model, we can use it in ml5.js. So we're pretty much done with our setup, let's get into actually training the model. So again, this is the link that you can use to sign up for Spell if you haven't already. It so happens that I have already, so I should be logged in here, let me just make sure I haven't been logged out. I haven't. So I'm in here in Spell.run, and it gives me some information about how to install Spell, how to login with Spell, there's a little quick step guide that you can check out with some of the resources that I used when preparing for this video. So yeah, like I mentioned, that other training LSTM repositories tells you how to run locally, but for us all we really do need to install is Spell, so I'm going to go ahead and do that with pip install Spell. And it's going to go ahead and fetch Spell and whatever things Spell depends on from the Python packing, Py Py, whatever it's called, it's going to just go ahead and get that. Okay. And then once it's done installing I'll be able to log in. Alright, I can remember it. So, you see it greeted me, hello Nabil Hassein, so that's me, so I am logged in as myself. And if you ever forget who you're logged in as for some reason, the Spell command has a lot of sub commands, like Spell who am I will tell you who you are. I'm just going to go ahead and get started with training this model, and the first thing that we need to do is to upload the file to Spell, okay. So what I want to run is this command here. Spell upload the path on my local computer of the file, and then I want to give it a name of where I'm going to upload it to. Okay, so I just got to place that command. Spell upload my data slash input.txt to this destination. Oh it's actually going to prompt me for the destination in a minute. It doesn't want that yet but it's going to want that momentarily. So let me just say spell upload the name of the file that I want to upload. And now it's asking me for the name of the upload that I was trying to give a little bit early. And it tells me that the file, this is the path to it on my local computer that I'm typing on right now will be accessible at upload slash name slash input.txt. And that's the name, oops, oops, just part of it is the name that I want to put in so I'm just going to delete the part I don't want and put in, what was it, Nabil spell livestream DOOM. Okay. Total upload size, 307k, same as what we saw, or at least very close to what we saw when we ran the du command earlier. And the upload completed. So that's great. So what we're going to do now, this is kind of the most, probably most complicated command that we're going to run but it's really the only one. This is really what's saying to go ahead and actually run the Python script that we downloaded from train, that training LSTM git repository. Okay, we're going to run that with Python, this train.py script with the data dir set too, what I happen to call data, that the name of the folder where I put that input.txt. And I'm going to run it and I'm going to mount the data, I'm going to mount the folder that I had just created by uploading that file as the name data so that it can understand this data directory. Okay, so I should get, I think, one error when I do this, and I'll talk about why. Okay, spell run mount dash dash mount upload slash Nabil Spell DOOM, ope, I called it livestream, in my notes I didn't quite update from when I practiced so let me go ahead and fix that. Okay, let's see. Okay, so let's try that. And it tells me that there's some untracked files in this repository and they won't be available on this run. Continue the run anyway? No, that's really the file that I care about. So Spell encourages us to use the Git version control system to make sure that the data that we're training on is checked in, and that's very good for reproducibility, if we want to go back later and understand what was going on and what was there, so I'm going to go ahead and kind of follow this adjusted workflow so I'm going to go ahead and git add dot, or I guess I could git add data, whatever. That's the only thing, same effect in this particular case, and I'm going to say add data dot input.txt file of DOOM lyrics. Okay. And now, having done that, if I run the same command it won't give me that same warning since the files are now tracked instead of being untracked. Okay. Let me go ahead and start to do this and then I'll go ahead and mention that other thing that I said I was going to mention. So I'm just going to press up a few times and just go back to my history to run the same command again. Spell run, I'm mounting that data folder that I uploaded to be called data. Oh I put it in the wrong order. [Dan] So one thing to mention, I think, is that if you're going to mount the data file, you don't actually have to commit it. Oh. 'Cause otherwise if you pull it from there you can do either. Oh, I see. [Dan] So if you don't want to upload it with git, then you can do the mounting thing that you're showing now. Okay, yeah, oh right, so I'm kind of, so there's more than one way to work with Spell, and I think I kind of conflated two of them a little bit. So, yeah, I didn't actually need to do the git commit because of the way that I'm doing this because I uploaded it before, and that will also kind of give some of the same, reproducibility benefits because Spell will keep a record of what we uploaded, but it doesn't hurt to get committed either. Let me just fix that typo. [Dan] In this case, it's such a small file it doesn't really matter. Yeah. [Dan] If you were working with a huge gigabyte file or something, you'd want to upload that separately without having to commit it also. Right, yeah, because Git isn't always the best for dealing with large files which is why there's tools like Spell and tools like, what is it, Git, whatever, there's a bunch of tools. Cool, so let me just go ahead and fix that typo. I should fix that on my notes as well. Tells me everything is up to date because I did make, like, a commit, although, like Dan mentioned, I didn't really have to. Tells me it's casting spell number 16, so I happen to have used Spell about 15 times before. Tells me I can stop viewing the logs with control C, tells me it's requesting a machine and building and mounting, and the run is running. And, so, this is still running, and like it told me before, I can just get out of the logs in my local terminal with control C, but this is running on a remote machine that Spell has provisioned and set up very nicely for me so I don't have to worry about it. So I'm not actually stopping the run from happening when I control C, I'm just stopping the logs from appearing in my own terminal. If I want to check out those logs, I can say Spell logs 16, and they'll start appearing again. And there's also some other commands that it told me about, like I could kill it with Spell kill whatever, but I don't want to, I'm going to let it keep running. And besides checking out the logs locally with Spell logs the number of the run, you could also come over here to this Spell Web UI, and check out different information about the run in here. But as you may notice from this video, I tend to have a preference for the command lines, so I'm going to keep doing things mostly that way. Cool. So let's see. Oh yeah, so one thing I did want to mention was the parameters, or what is sometimes called the hyperparameters of the network, so let's just go back to this git read me really quick. So yeah, like I said, this gives you more information about how you would run it locally, including how you can pass additional flags that I didn't bother passing to control more of the characteristics of the network, like its size, how many layers they are built into the sequence, and various other things that you can read more about in this repository. They have here some recommendations for what you might want to select for your hyperparameters according to the size of your training dataset. Because my training dataset is so small, I decided the defaults were probably fine. The next thing that I wanted to talk about was the difference between running on CPU versus GPU. So I imagine this might be review for many viewers, but I am a teacher, so I'm always a fan of just reviewing material. So the CPU is the central processing unit of your computer that has maybe a little bit of parallelism, but for the most part is best at running things sequentially, very fast. And the model of computation is a little bit different from that of GPU, which at some point stood for graphics processing unit and maybe still does, but maybe that acronym's been retired by now because GPUs actually have very many applications other than graphics, including training neural networks on text, for example. GPUs, historically they got, I think, that name because each pixel on a screen for the most part is independent of each other one and so can be computed independently, and so a GPU is much more highly parallel compared to a CPU. It's not going to be as fast at completing like one single task, but it is very good for displaying things on screens and it also happens to be very good for training neural networks. So in the last command that I ran over here on the command line to train the neural network, this is running by a CPU, and what I could do if I wanted to instead run my code on a GPU is just tell it that that's the type of machine I want by adding this dash dash machine type flag. And the machine type that I'm going to use is K80, okay, so where does this K80 come from? Well, if you check out spell.run slash pricing, you'll see some information about how much Spell charges for different types of machine types according to your needs for whether this GPU or that CPU is the best for your particular task. As you can see there's a few different ones, CPU, CPU big, you know, all these things, K80. K80 happens to be one of the less expensive GPU units, so it's good enough for my purses and that is what I'm going to use. Okay, so I go ahead and run that command. Everything's up to date, it's casting spell number 17, we see a very similar bit of output as we did before as it gets ready to start training the model. Okay, the run is running, so in a moment we should start seeing the logs, after it reads the text file. Alright. So now this run is running, and I don't know how obvious this is if you're following along, but it's actually noticeable at least for me that this is happening a lot faster. This model is being trained a lot faster via the GPU than the CPU one was. So the CPU one got a head start, but I still expect that the GPU one will actually finish substantially faster. We see we're already at like 413 out of 6,000 iterations that it's going through to train the model. Like if we check in on the previous one, let's see how far it is. Yeah, actually, okay, no, I mean the head start it had was pretty big, but you can see the GPU one is moving faster. Like, if we actually go in, because like I mentioned before, I've had a few practice runs here before, we can look at a few ones that I did before. Yeah, these were kind of my first two practice runs. Using a subtly different model, you can see here, but this one on CPU took close to five hours, and on GPU it took only a little bit more than 15 minutes. Yeah, so GPU is faster for this particular use case. Okay, so just for the sake of time, I'm going to grab a model that I had already trained before rather than just waiting for this one to go all the way through, although we could. We could do that, I mean we can actually use this model later if people are interested in that. But so what I want to do to grab the data from Spell is to run this command here, spell cp runs slash the number of the run slash models. Okay, that's how I'm going to fetch that data. Okay, so I'm just going to cd up here, now I'm kind of in my home folder of all the different things that I'm kind of grabbing from here, grabbing from there to put together into this demo. I'm going to go ahead and run spell cp, it was 15, right, let me just look here again. Yeah, yeah, so you can see this is using that same training LSTM I was talking about, it completed in about five minutes. Actually I guess this one should complete pretty quickly, too. And that was a practice run that I did just a few minutes before this livestream started. So I'm going to spell cp runs slash 15 slash models. And it's copying 10 files that are from there. My ls, my ls data, it remembers the same data directory that I passed in before as the name. And these 10 files constitute the model, okay, I'm not really going to go into depth about what are these files and what's in them, but yeah, if you're following along you could poke into them and check it out. Cool, so we've trained the model. We've used Spell to train a LSTM model on a corpus of data that we obtained, and now that we have the model, let's use it for something. So I'm going to borrow and then modify an example from this repository here, on the ml5.js GitHub account they have a repository called ml5 examples. So there's a whole collection of examples, there's a bunch of them. You can find out a little bit about how it's organized and some other stuff from their read me. I'm going to use one in the p5js folder. We are worried about LSTMs. Yeah, that interactive one is also interesting. That's more I mean, it's more interactive, I'm not really going to describe it. We're going to use the noninteractive version, LSTM texts. And we have here just a few files. So they actually have a pretrained model that I'm going to just ignore and not use because we're going to use our model that we just trained instead, but what I am going to do is just fetch these two files, this HTML file and sketch.js file. And because this repository's big and I just don't want to wait to clone it, I'm literally just going to fetch these two files and nothing else. Okay. So what I'm going to do is just, we'll create another directory, why not. Ml5 LSTM example, and I will change my current directory to be in there. Let me just clear my screen for clarity's sake, and then I'm just going to use the command line program wget, which will just fetch the raw file, I did have to click raw on GitHub. And we'll fetch it onto my local machine. So I do that, and then I go back and I do the same thing with sketch.js. I just find this one raw file, copy the URL and I use the program wget to download it locally. Okay, so now if I list what's here, I have these two files, index.html and sketch.js. So let's take a minute to check out, we'll read the files themselves and we'll also use them. So what I'm going to do is just run a program called http server, which you could install if you want, if you don't already have it with, what is it, mpm install dash g http dash server. You can use any of it, if you're used to using a different web server, anything that will serve up index.html in your local folder is fine. So it tells me where, tells me the URL I can go to on local host to check this out so I'm going to go there. Says LSTM Text Generation Example, this example uses a pretrained model on a corpus of Virginia Wolf, although I'm actually not doing that, so I might change that. So let's actually go ahead and go into this file and also look at the JavaScript file. So let me, I'm a iMAX user, I'm just going to go ahead and open up repos and I call it Spell livestream. So these are the two files that I had just downloaded a moment ago. It's index.html and sketch.js, so let me open those up in a way that's going to be a little bit more readable for you. My notes before were so, I guess let me do it over here then. The folders don't really bother the video as much as this one does. Okay, so we have here an HTML document, which relies on p5 and ml5 as the libraries that are being used and pretty much nothing else. Alright, so this example uses a pretrained model on a corpus of MF DOOM. So let's just make this nice and accurate. Okay. It says the meaning of life is, which isn't something I remember DOOM saying, but whatever, we can leave that as the seed text for now. That's an input field in HTML, so we can just change that anyway. So we have a few sliders for how long we want the output to be and the temperature, which we'll talk about more a little later. And what's really interesting is the sketch.js file, so let's actually take a look there. It says open source software, I can just do whatever I want with it, which is great. Okay, so we declare a few variables here, so again, this video isn't about p5, there's kind of a lot of things that I'm touching on but not getting into, but p5 is a really cool library, I encourage you to check that out if you're not familiar with it already. It's great for a lot of artistic coding, I've used it for some other projects as well. There's kind of two main functions in, well, yeah, let me not really get into p5. We're going to start with the set up function. Now I'll just say that p5 will run this set up function for us at the beginning. And it says create the LSTM generator passing it the model directory. I don't have anything called model slash wolf 'cause I didn't clone that whole repository, so what I need to do is make sure that this, when it's generating, like when it's creating the LSTM that we're going to use, I need to make sure that this is pointing towards the proper path where we have our file. So let me go ahead and just remind myself on the command line of where I am keeping everything. Let me just control C out of the server and I'll start again in a minute. So let's see. Let me ls up here, I have something called data up there, which had what I wanted, right? Yeah, those are the files from my model. So why don't I just copy that folder into here, where I am. I have to say, what is it, lower case R or capital R for our cursive copy. I guess lower case worked. So now when I ls here, besides the two files that I fetch from GitHub using wget, I also have all those data files that are right here. So what I'm going to do is I'm just going to change this to say data, because that's where my data is, okay. And then here, there's some other code. This is really about the user interaction of like what happens when sliders get moved around and buttons get clicked, so I'm not really going to go over that. What we will just take a minute to look at is this generate function, which again, not going to go all the way through, but it lets you know it's generating stuff, like just so that the user knows something is happening, grabs the input from the seed text. It uses these parameters, temperature and length, and then the ml5.js library does really all the heavy lifting for us, we just kind of cull this lstm.generate function with our data and patch up this call back function which will go ahead and update the dom, kind of update the HTML page when that function is done running, done generating the text that the model has predicted based on the input seed. Okay. So you can see this is a pretty short file. Didn't go through every detail, but it's on GitHub, you can check it out. You saw I really just made one small change to it. Cool, so let me go back to my notes. I'm pretty sure I know what I want to do next, but it's always good to be sure. That's the path, yup, I already told you that. I did that. Alright, so let me actually go ahead and run the server again. Okay, just refresh the page, you can see it's updated with this. Okay, the model's loaded, we can click generate. And it, I mean, I don't know how many people listen to DOOM, if you don't maybe you can just take my word for it. This sounds a little bit like something he might say. So we can adjust the length, make it longer, or make it shorter, and we can use this temperature thing, like, the temperature is something like intuitively, it's kind of like the randomness of the text. The higher the temperature, the less random it will be, kind of the more derivative it will be of the original text, and if you turn it up very high it starts to become very likely that you get kind of direct quotes from the original corpus. If it's lower, it is maybe a little bit more chaotic, so to speak. And I think that can generate things that are a little bit more out there and more interesting or original. But if you start to do it maybe too low, you might start to get kind of just nonsense. It might not really make very much sense at all. Especially if you get like really low. Oh, it might or it might not. So yeah, I mean, okay, I'll withhold my opinion on these generated lyrics for now. This is an art critique session. Alright, so yeah, I mean, that's really the main thing, so I mean if I was going to go ahead and reproduce my original project, what I would do now is pull in another dependency which is the pronouncing library, and then I would've, what I should've done, maybe I can do this now, is trained the model backwards, like if we actually look at this input.txt you can see that these lyrics are forward and so the model does that also, so that's something that I would want to do is just reverse that input and train the model backwards. And then I can use the pronouncing thing to go backwards and so on. But, yeah, I think instead of doing that I think what might make more sense would be for me to take any questions from the people who are on the livestream because that is pretty much, yeah, that's pretty much that. So we've got through what is LSTM, getting data, setting things up, training the model using Spell, and then using the model in ml5.js, so that is what I had prepared for you today, and I look forward to any questions. Thank you so much Nabil, for this wonderful tutorial. Again, thank you to Spell for the sponsorship. If you make something with this, please share it with me, I would really love to know about it, and I'll see you in future tutorial. Many more machine learning, ml5, Pythony, TensorFlowy things to come I hope. Goodbye. (upbeat music)
