hello and welcome I'm your code monkey and yesterday Unity finally announced some proper AI tools the secret to life is to find something you love to do and do it every day a few months ago all they showed was just a vague teaser but now we have info on actual proper tools one is called Muse and one is called sentis and beyond that there's also a new category on the asset store with all these AI tools there are obviously questions about copyright and what data sets they are using the answer is actually pretty vague right now I found a bunch of completely responses I'll mention what I found my research in a little bit but first let's look at the tools what they are starting with unity Muse which is the AI tool to assist you during the creation process this one has two parts text and sketches now on the text part one interesting thing that they mentioned in the blog post is how it uses AI to search through the documentation training resources and support content it is all that in order to get you structured accurate and uptodate information from yinty now I find this part extremely interesting since one big problem with tools like chatgpt is housing Nations which is how it confidently gives you an answer even if it's wrong so I'm definitely very curious about this focus on supposedly accurate results including working code samples like I mentioned in my chatgpt video I would not use it to generate code only for brainstorming design questions which is exactly how I've been using Chachi PT in my own game Thinking guardians but who knows perhaps the code that this produces so good that I won't start using it honestly I really doubt it but I'm very curious to test this claim we can pause the video to see the answers to the question how do I make a match 3 game first it literally shows that it knows what is a metric game so that's a good start I wonder what would happen if you asked in a more obscure genre then it says first you need a game board and suggest unity's tunnel map system which Yip is a good option importantly here is the one which refers to the extra links on the bottom this is really good so people can learn more detail about certain topics next it suggests using physics now personally I wouldn't really use physics on a Mastery game but it's definitely a valid option it correctly tells you to use the 2D physics system with 2D component again with an extra link for extra information then for step 3 it actually goes quite vague it says you need to implement the core mechanics of a match 3 game so you need to make the scripts to handle the matching clearing and scoring then you need to spawn New pieces and move current pieces to fill the gaps actually did a Mastery game from scratch quite a while ago and yep I did have to do all this but I do find it a bit odd how the answer is so vague honestly this feels like that one meme about how to draw an owl how you first draw two circles and then you draw the rest of the owl but one key thing about Tunes like chechi PT is being able to ask followup questions so I do wonder how detailed they would go if you ask for more detail on this third point then it also makes some nice suggestions based on existing Unity tools to have things like mailboxes Cloud save and authentication this is actually a great thing because a lot of people might not know about tons of tools that ENT has I made my entire Unity overview course directly to answer this question so this is a great thing so all in all this is a pretty decent overview of what is a match 3 and how you could build one although again I I wonder if this would be enough info for a complete beginner I guess the answer really comes down to how much detail it would give you if you ask for firm clarification on that third point then we can see the demo it asks another question with some more detail on how to create a Sprite and rotate it so you import an image then it tells you difference between having the editor set up in 2D or 3D which is actually a pretty important thing this is something that can trip a beginner so this is really great then it gives some very beginner friendly instructions once again alongside some helpful links and finally gives a super simple script so this part this textbased tool this doesn't really seem anything too impressive but it's also not necessarily unimpressive it's really just like many other tools that already exist now much more interesting to me are the other parts of this tool how you can just use text to generate animations like for example do a backflip personally I have no skills as an animator so this would be extremely useful to me I always hate having to look at the accessor to find all kinds of Animation packs to try to figure out which one contains whatever specific animation I'm looking for so if I could just type some text and get a quick draft animation that would be wonderful one thing that I do hope this will has is refinement meaning ask a question and then being able to ask followups that is something that is liking to almost kind of like Dolly where everything must be generated from just one prompt and you can really ask follow questions like can we chat GPT so I really hope this won't last for doing that like for example do a backflip okay now do it a bit more intense now jump a bit higher and so on I think that would be great another use case is Sprite texture generation but also extra interesting is how you can draw sketches so you don't don't have to generate the entire image with just one prompt you draw to select the areas you want to generate and then you give the prompt lately I've been using the Photoshop AI beta which has exactly this feature and I have found that extremely useful I find this workflow much better than having to generate the entire image with just one prompt this is great for creating tons of variation where you can just select one part of the image and easily create tons of variation for that although of course you can also generate entire things like entire textures and looking at the demo the generated materials do seem to work quite well at scale with no visible seams or repetition now the terrain does look pretty basic some people on Twitter were pointing out how this rain really looks like a game from the early 2000s but again keep in mind this is just one material if you were to mix multiple materials generated by this and you add a bunch of props then I think this ring will look quite good so this full material generation also seems pretty interesting now on the blog post they also mentioned how this tune will help you both in the editor and on the web so it sounds like that means there won't be some kind of website that you can access it to but then it will also will be accessible directly from inside the editor so that's great oh no from this tool Unity Muse I don't see much use for the generic textbased AI but the other use cases do seem externally useful I would love to be able to easily generate some animations with text and generate some random iterations of different Sprites for my games so I definitely can't wait to try this out and explore all of its limitations now the next signal this one is called DND centers and this is how you can embed an AI model in the UNT runtime which will run on every platform that Unity supports so that includes mobile PC web consoles and so on what this means is really that there's no Cloud hosting or no Server Connection needed at all once your model is trained it just runs locally on the player machines so after you train it there are no costs to you as developer and of course with this being local it also helps with latency which is usually a big problem with things like using AI to generate some NPC response the demo showcases someone talking to a character that is being driven by AI what hairstyles would you choose if you had hair if I had hair I would probably go for a mess people not plumbing through I like how they look on other people and I think they're easy to maintain now they don't specify exactly how AI is used I assume they are using AI for the initial speech to text recognition then probably using it for text to voice generation and perhaps even for the mouth animation however while the selling point on this is being local on device with no latency the video doesn't necessarily show that there are Cuts before every response I have no idea if they cut just because it took a bit too long to reply or really just make the video more interesting with some zooms and also on this specific demo on this specific use case personally this is something that I really have no interest in a while ago Nvidia announced another similar tool where again you could chat with a random NPC you could ask it whatever you want and again my reaction to that was exactly the same personally I have never once played the game where I thought to myself oh I wish I could talk to this random NPC for hours on end about anything that's really just something I have never had a desire to do in any game I just want to talk to the NPC get the info information that whatever designer came up with and then go ahead and keep doing some gameplay but then again that's just because personally I prefer some more mechanically focused games as opposed to things that are very story based so I could see that for a player who enjoys something like Adventure Point and click games for that I can see how it could be a selling point to be able to talk to every NPC for as long as you want now suddenly there's not much more detail on this tune the idea of having an inference engine running on devices potentially quite interesting but my bigger question is how exactly are you training the AI model so how much that does need how do you actually train it is it just by using the regular Unity ml agents package is sent is really just a rebranding or a new name for what they've had for a long time which was Barracuda it's been a long time since I touched them in Legends definitely want to get back to it at some point hopefully there won't be some more details on the specifics of how this tune works and then there's also an update for the SSR now there is a specific category for verified AI Solutions and there's already quite out of them Honestly by now there are hundreds of AI tools all over the place I try to keep up with the pace of AI but there's just way too much stuff here you've got some 3D asset generators some NPC AI dialogue and behavior there's some image generation voice generation liquids and even testing so lots of stuff and if you want to try it out most of these Tunes are free to test and by the way there's even more tools these up top are just the highlights that are actually verified but there's a bunch more that claim to use AI to do all kinds of things like music generation integration with machine learning and a bunch more so if you're interested go browse the SSR and see this category now for a pretty big question what data sets were these two on screened on and what about issues with copyright suddenly I cannot find a definitive answer when I spoke with the unity AI team behind closed doors back at GDC back then they told me it was extremely important for them to actually own the data sets which is excellent however over here when people ask for what data sets are using the answer is extremely vague they just say they license a large language model and FedEx some Unity docs so it sounds like they use something like chechi PT and then finetuned it with DNT knowledge but this part this really says absolutely nothing about the art generation tools however someone asked this question on Twitter and some of you replied who is the SVP of innovation at unity and here it says it's their own data set called Runa I literally cannot find any mention of anything called Runa outside of this Suite so no idea what that refers to is that an art asset or animation no idea another interesting tweet is by Natalie who works at Graphics at weather which is part of unity and again this says in relation to this weird alien creature how it was built on custom data which was ethically sourced and again my question is what data does that refer to is it the math movements is it the backflip animation that we saw is it the voice generation really no idea personally I think it is extremely important to be very clear about where the data sets came from and that there are no copyright issues I think that is absolutely essential before any series devs will risk using these zones in their commercial games so I really hope they clear up all this confusion and give a clear answer about each type of AI generation and which specific data sets they were trained on alright so that's the latest on unti tools if you're interested they are part of their AI better program which you can go sign up to gain access for the upcoming host beta personally I already signed up months ago when they first showed the teaser if I get access to the beta I'll definitely try them out so stay tuned alright hope that's useful check out these videos to learn some more thanks to these awesome patreon supporters for making these videos possible thank you for watching