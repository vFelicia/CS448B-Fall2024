hello and welcome i'm your code monkey and here let's learn one of the more basic tasks related to machine learning let's teach the machine how to drive a car this is a classic example and it's pretty easy to do when working with unity ml agents i cover the complete getting start guide in another video so go watch that if you're not familiar with the toolkit machine learning in unity is actually very simple and easy to use once you understand the basics there's a link in the description for the entire machine learning playlist now here we want to teach the ai to drive a car for that we first need a car controller so here i have a very simple one i can move it with the arrow keys and works pretty much exactly like you would expect just a very basic car controller now how this is implemented isn't important for training the ai all that matters is that we have some way that we can interact with this controller by setting forward and turning amounts in this case i have this symbol function set the inputs where i can set the for the mount and turn them out so the ai won't work on any car controller you want to use doesn't have to be this specific one all it needs is to expose a function where the ai can take these actions in order to get our final ai we're first going to teach to drive it in a simple track just doing some left turns then we're going to teach it on a track where the some right turns and then finally we're going to train it on a much more complex track but before we look at the training let's first think of the big picture of what it is that we need for the ai to drive a car so i've got a car here and the goal is for the car to go all the way around the track so think about what information does the ai need in order to achieve this goal well first it needs to know where the track is so we can tell it that by essentially placing some invisible walls on each side of the track and firing some raycasts so just place a bunch of walls all alongside the track and this way the ai won't be able to tell where there's a wall and where there isn't so it will learn what's around it so it can learn to stay away from the walls and then we also need to tell the ai that it's actually making progress so for that there are some invisible checkpoints placed around the track so i can make them a bit visible and yep there they go all the checkpoints so every time the ai goes through one checkpoint it receives a reward as usual when it comes to machine learning the tricky part isn't really on the code that part is very easy as you saw in the getting started video the tricky part is making a good training environment so this is why before you start writing any code you should stop and think about what does the ai need to know just like we did right now so over here i have a brain that i trained previously as you can see it follows correctly alongside the track and goes through all the checkpoints and goes all the way around it so it works on this one with just left turns it also works on this one with right turns there you go they all keep going at it and it also works on this much more complex strap there you go they start in there they go through they manage to go through that turn through that turn then over here this complex one yep there you go they succeed and they keep going all the way the ai isn't completely perfect there are still some times where they hit the invisible walls but the model is working so the solution to fix all that is simply much more training so that's the setup that i've got i have a simple nice car model that i grabbed from a racing asset pack there's a link if you want to grab it on the car object i have a simple collider a rigid body and a car driver script so these are the components for the car controller to work like i said you can use any car controller you want so don't worry about these specific components so those handle the car and then over here i have all the machine learning components so in here is the car driver agent the behavior parameters and the decision requester so these are the standard machine learning components i cover them in detail in the getting started video the one big difference here is over here on the decision requester i'm requesting a decision on every step rather than default which would be on every five steps i'm requesting it on every single one because the car drives pretty fast so it does need to make a decision quite often now the one new thing here is this component the array perception sensor so this is a default ml agent's component what it does is it automatically handles firing some raycasts and adding them to the observations it also has a nice editor script so we can see it over here in the editor in action so if i move the car yep there you go you can see it happening you can see as it collides so this is the information that the ai won't receive for the parameters here you can play around with how many rays per direction so there you go right here we have three so one two three and one down the center so you can increase as many as you want then you've got the max rate degree so right now the maximum is just 70 degrees in there but if you want you can make it go 360. then the sphere cast radius so that's the size of the sphere so this isn't actually a raycast rather than sphere cast so this is helpful if the object you're trying to detect with raycast is quite tiny so just increase the size of the sphere cast like that then you can also define a length so this is how far the raycast will go so naturally needs to be big enough in order to actually detect the objects in front of it then we also have a start and end vertical offsets so here for example the object the origin is right down there but i don't want it to start firing right from the floor since that i put it on a vertical offset of one so it starts one unit above then you can also have the n vertical offset so for example you could put this one to go down and there you go all the raycasts go down so for example if you want to teach the machine to avoid falling off the map you would simply add this make it start higher and then lower okay so those are the basics then you have the layer mask so this is what layers the rays won't collide against and once again you need to think like a machine like we did a while ago so in order for the ai to learn how to drive it needs to know about the walls as well as the checkpoints so that's exactly what i said here by using this layer mask the rays will only collide with these layers so for example i've got a car here and as you can see this second car is right in front there you go the array goes through it but it doesn't collide with that one since that one is not on the walls or checkpoints layer then we also have the detectable tags so this is how the ai knows what object it hits so they are based on the game object tags right in here so as you can see on the wall they've got the wall tag as well as the one layer and the checkpoint the same thing same thing so with this sensor the ai now knows if it hits something at what distance that object is and what type of object it is so with this the ai has knowledge that there's a wall over here onto this side at this distance and knows that it's a wall and right in front it knows that there's a checkpoint at this distance i mean again the ai really only works with numbers so it doesn't really understand what is a checkpoint and what is a wall but over time it will learn to increase the distance from this object type and decrease distance towards this object type so as you can see the setup is very simple the only new thing compared to what i covered in the getting started video is really just a sensor now let's look at the agent code and by the way if you find the video helpful consider subscribing and hitting the like button it really helps out the channel here it is it's a pretty simple script as you can see it's less than 100 lines long the tricky part is really only on the training setup and not on the code itself so here on start i'm just listening to the track checkpoints so this is the script that handles when the car goes through a checkpoint i cover this checkpoint system in detail in another video then over here it's very simple if it goes through the correct checkpoint gets a positive reward and through the wrong checkpoint gets a negative reward then down here on our episode begin we just place the car on start with a bit of randomness we make it point the same forward as the spawn position we reset the checkpoints and we stop the car driver then over here for the observations as we saw we use the sensor and that one automatically handles most of them over here i just have an extra one for the dot product between the transform forward and the checkpoint forward so with this the i should learn to face the same direction as the checkpoint and then we have the actions and for actions we really just have two of them so just forward and turn and that one is handled by discrete actions so we've got accelerate brake slash reverse and don't move and also turn right turn left and don't turn then after coming up with the tournament for mount i just send that over to the car driver again it doesn't matter what car controller i'm using here it can be anything as long as i can make it work with these two types of inputs then for the heuristics very basic just using the arrow keys and then down here we've got the collisions here on the uncollision enter so when a collision first happens when it first hits a wall i'm giving it a rather large negative reward and then on the collision say which is triggered for every physics update that the collision is happening for that one i give it a small reward so with this i'm trying to encourage the ai to keep off the walls because before i added this the i was essentially just sliding along the wall and that's it there's nothing else so as you can see it's a very simple script the code is all very basic the training setup is really the only tricky part so i just placed all the tracks placed all the checkpoints alongside it as well as all the walls and again the only thing that matters is really just the physics system so here i can easily make the walls invisible and everything still works perfectly then for the checkpoints themselves i'm using the checkpoint system that i covered in detail in another video it handles the logic for ensuring that each car is passing through the correct checkpoint now here it is important not to place them too far apart so they should be relatively evenly spaced and have a bunch more on the turns you have to remember that the ai really only knows it did something good when it gets a reward so adding more rewards on complex turns does make it helpful so for example here i have quite a lot of checkpoints in order to make sure that it learns how to do this really complex turn okay now we can try training it just like this so here it is just using reinforcement learning and it's trying to learn right away you've seen that they actually start going backwards instead of forwards the reason is because i made the breaking speed long's moving forward is pretty fast so if he tries a bunch of random actions then he just ends up going backwards now the one big change that i made since my first attempt at this project was with regards to the walls first i made the ai and lose instantly when they touch the walls that makes logical sense but it also made it so that every episode was very short so it was hard for the ai to actually randomly try moving forward and getting the first reward so i just made the wall solid and disable the ending of the episode as i said the tricky part is really the training setup and your goal is to help your ai learn by any means necessary so you start by teaching it the simplest example possible and then over time you can make the training scenario more difficult so with this it's just doing normal reinforcement training so as you can see even after some time it still hasn't figured out that the obvious thing is to go forward so that's just basic reinforcement training but like i covered in the last video we can use the awesome power of imitation learning if you haven't seen it yet go watch that video it's really a very powerful tool for that i have some demos here that i prepared previously essentially i just went through the track a bunch of times and recorded it so over here got 4 000 steps going through eight episodes with a nice mean reward so i recorded it for the left turn track and the one for the right turn track then on the config file just enable it to use the demos by enabling both gale and behavioral cloning and for starters i want the agent to learn how to behave excel like the demos so leave the strength of both of these close to one and for the extrinsic rewards we can now leave it at just 0.1 so let's see with imitation learning how much faster it learns and for the first attempt for some reason it sounds dry is going backwards but afterwards it does start to learn from the demos and there you go right away it instantly learns to go forwards now obviously it's still getting stuck so it still hasn't learned but in just pretty much just a couple of steps then it already learned quite a lot more than just with reinforcement learning so as you can see imitation and learning is really very powerful in order to enable it it's really very simple you just had a bunch of things over here on the config and there you go they automatically start using it so here you can see a handful of them have already managed to go through the first turn go through there and these ones manage to go and look at that one okay so that's what i did i first used the demo on this track and trained it enough so that they'll learn how to achieve this so trained it using bc gale and reinforcement learning then when it learned this track i set it to training on this second track i used a different demo i lowered the strength on the imitation learning components and increased a bit on the extrinsic rewards and then when it learned how to go through this track then i set it to train on all five tracks and just let it go using only reinforcement learning so here i have a brain that i've trained for about five million steps and right away you can see all of them go so there they go on this track and they also go successfully on this track and then down here on the complex track yep look at that they go through that turn and this come like certain down poor thing got stuck but most of them actually go through they come into that one and they do nice turn and there they go so here you can see just how powerful this is if for example you have a game where you want to support custom player tracks you would just make a handful of pieces all of them with builtin walls and checkpoints and you'll let the player create any track shape you want then the cars would still be able to race through any track custom made by the player you would simply include a trained brain model where you would train it for something like 50 million steps and the agent would perfectly follow any track with any shape alright so there you have it yet another excellent use case for using machine learning and another example of how easy it is to use ml agency in unity check the phone playlist linked in the description where i'm adding all of my machine learning videos as always you can download the project files and utilities from unitycodemonkey.com this video is made possible thanks to these awesome supporters go to patreon.com unitycodemonkey to get some perks and help keep the videos free for everyone if you found this video helpful consider liking and subscribing post any questions have any comments and i'll see you next time you