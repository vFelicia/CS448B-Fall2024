hello and welcome i'm your code monkey so a while ago i made this simple match 3 game it's got the basic design you would expect i even made a video showcasing how i made this in just under 6 hours then i also used this game as an example for how to use game simulation to play your game in the cloud and for that i created the bot using some classic ai to play the game the bot is simple and not very smart but it does work and now here let's implement some ai using machine learning to teach you how to play a match 3 game the one huge benefit of using machine learning as opposed to classic ai is that after implementing it once we can easily modify our game and add extra features without having to change much on the ai if we were to add some special skill like for example an explosion when matching four in a row then we would need to explicitly add that to the classic ai but when using machine learning we just need to run training some more so using machine learning ai is excellent for a game that is constantly updating in the end we will see how easy the ai will learn how to play after adding a new feature and making a super intelligent ai is also great for giving the player a hint when they're stuck you can just ask the ai to make a decision and then you would show that move to the player this video is sponsored by unity so i've already covered the basics for ml agents and machine learning in unity in another video go watch that one to learn how the toolkit works if you know those basics you should be able to follow everything here so we're going to implement machine learning using the official ml agents match 3 extension i'm using the game that i have here as an example but the process for adding it to any match 3 game will be very similar and quite simple thanks to how the extension is set up as long as you have some events and some simple functions in your match 3 class then this will work with any kind of game you really just need to write one script which handles the connection between your custom match 3 scripts any match during the extensions and everything works you can get the official match 3 extension from the ml legends github repo there's a link in the description to install the extensions you can open up the package manager click on the plus icon to add a package from git and then you paste in the link that you see on the documentation okay so in those extensions you have essentially three elements that make it up you have a board a actuator and a sensor the only one that we really need to work with is just the board this is an abstract class that we're going to implement naturally this represents the board or the play area and it contains the number of rows and columns as well as the number of cell types and any special types that your game has then we just have a whole bunch of functions that we're going to need to implement which is how we interact with the board so this is the only class that we're going to need to interact with then we have the sensor and actuator both those have two classes so you have the class that actually implements the logic and then also the components which is what you attach into your game objects which in turn all they do is construct the actual underlying class the sensor is what generates observations for the ai based on the state of the board and the actuator is what takes actions on the board and finally you also have a move which is just a simple struct so it represents an ingame move where you swap a position towards a certain direction so for example swap the cell on zero zero with direction on right to swap with one zero so as i said all you really need to worry about is just implementing the abstract board everything else just interacts with that one so let's do just that over here on my scripts folder i'm going to create a new c sharp script name this my match 3 ml agents board and create a new game object to run it so just attach it and let's open so as i said this class will connect the machine learning side with your match 3 class so let's begin by just adding a field for that one so in my case my main one is called just match three and in this case i'm going to make it as a serialized field so i can easily set it in the editor so here in the editor i've got the field and just drag it on there okay now here we're going to add our using so we're going to add using unity.mlagents.extensions.match3 and instead of extending just modern behavior we're going to extend our abstract board okay now we need to implement all of this you can use visual studio to really help you out so just implement the abstract class so just with this default implementation let's just hit save and go back into the editor okay the code compiles and now we can see the public fields on the abstract board so we've got the rows columns special types and cell types so these are poly films so if you want you can set them directly over here in the editor or in my case the way that i set up my mastery game is all of that data is on a scriptable object so i'm going to grab it and set it directly in my code by the way if you find the video helpful please hit the like button it's a tiny thing but it really does help thanks so in my particular implementation i have this simple scriptable object that defines every single level and in there i've got a list of all the gem types that are possible as well as the width and height and so on again depending on how you set up your match 3 game this is going to be different but it's going to be roughly the same thing so in here i just make a private void awake and on awake i'm going to set all those fields so first up these the columns which in my case i named it width and height next up is the cell types this is the number of colors or shapes that you have in your level so in my case each level object has a list of all the gems and then the final thing you need to set is the number of special types so for example if you've got some special gems that cause some explosions or destruction online or something so anything that is different from the base cell types that's what you would input in here in my case i made two different level types so one of them is hitting the score and the other one is destroying some class nodes so for my normal score type i don't have any special types and on my glass levels i do have the glass as a special cell type so in my case if my level is of type score so there's nothing special so i just have a zero and if not then it's going to be a glass level so it is going to be one on the special type again if you have multiple special types then obviously you would put a different number okay so that's the basics we just set up all of our public fields now down here we see all the functions that we actually need to implement and if you want some help on how these should be implemented you can just go into the main abstract board class and over here you've got tons of comments to tell you exactly what each of them should do so for example over here on the get cell type this one returns the color or shape or whatever type of the piece at a given row and cone so this will be an int that will be between zero and the number of types that you gave so for example if you've got a match three with let's say just squares and circles then you would put on the number of cell types you would put two so you got squares and circles two types and in here if it was a square then you would return zero and if it was a circle you'd return one so you convert your types into simple integer values so over here the way that i implemented things so i asked my custom match free class to give me the gem type and then i simply return an integer that refers to that gem type okay that's pretty much it for the get sound type then for the special type as it says here this is pretty much exactly the same thing but regarding special types so in my case the only special type is if it is in case in class or not so in my case i can ask my class if a specific position is in case in the last if so return one if not return zero next up for the is move valid so this one checks if a particular move is valid for the game meaning that it tests if this move would result in a match if so it is valid and can be swapped and you can inspect the struct on the move to see how it is set up so you've got essentially a row and cone then you've got a direction for the swap so for example zero zero swapping to the right and you would test that so again i'm going to implement it in my particular case okay so in my match 3 class i've got a function to ask if two grid positions can be swapped so we start x and y compared with an n x and y that's if that can be swapped so i go into the move and the move also has a really nice function that returns the other cell so again for example if the move was zero zero swap to the right then calling other cell would give you the position one zero so just ask that do that and there you go that one is implement and finally we have the make move function so this one is supposed to actually make the move so you can see over here on the abstract it instructs the game to make the actual given move and then returns through if the move was made however look at this note which is that during training a move that was invalid may still be requested so if it happens you need to handle that so let's implement this all right so that's it pretty much the same logic as for asking if the move is valid and if it is then i can do this move so i just swap those positions if not then i can do it okay so that's pretty much it with this we have our abstract board fully implemented so now this class acts as a link between the builtin sensor and actuator and our custom mastery class so speaking of that let's add those two over here on our ml agents we currently have our board now in order to run machine learning we need an agent so let's add the standard just search for the agent component and there you go there's the standard agent and it automatically adds the behavior parameters so here give it a name so just just something like match three agent then we're also going to add the builtin components so let's add the match 3 sensor component and also the actuator so match 3 actuator component again these are from the official extensions we didn't touch these at all and now this sensor and this actuator is going to work in conjunction with the agent and all of them are going to tall to our custom match three board which in turn interfaces with the rest of our code with our custom classes alright so we're almost ready for training one more thing is needed for the agent which is to request a decision now usually we would add here the decision requester script so this one is great for constantly requesting decisions however this game is turn based so we should manually request decisions the way the game works is the board is ready and it waits for the player to make a move then the algorithm looks for all the matches spawns some more gems and finally goes back to waiting for the player so we only want to take an action and request a decision when the board is on that state so in my case i have a class that fires off some events so when it is waiting for the user so let's listen to this event to request a decision so just go there and subscribe to that event when the event happens we go into the agent and request decision so let's grab our agent and the agent class is in the normal ml agents okay we've got the standard builtin agent class and then here we just go into the agent and request a decision okay that's it the decision is taken care of now we need one more very important thing which is adding some rewards now in my match three game i have two goal types one is based on score and the other one based on destroying all the class in a level if it is score based then we can give it a reward every time the sum is destroyed just like the score and if it is a glass level then we give it a reward only every time the glass is destroyed then with regards to rewards we also need to handle multiple episodes so for the score going we can set a limited number of moves and then when the moves are over we end the episode and for the class the episode ends when the class is on gone okay so let's see that now again when i implemented my custom mastery class i made a whole bunch of very useful events so for the score i can listen to this event when a jam grid position is destroyed and for the glass i got this one when the glass is destroyed so thanks to how i set up this class with some really nice events it's going to be super simple to add so when a gem grid position is destroyed if it is a score goal type if so then just go into the agent now the reward same thing over here one can let's destroy it if it is then we add roar and naturally the rewards need to be in the same format as your actual play rewards so if you have something like a bonus score for matching four in a row then you would also apply a bonus reward for that here i'm only adding the same reward for every gem that is destroyed just because this demo is very simple and now if it is a glasgow we also want the ai to learn to destroy the glass in as few turns as possible so let's also give it a negative reward on every move so when a move is used if we are on the last type then we're giving it a negative reward for the score type we don't need that since the score will always have a fixed number of moves so that one by default it will already try to achieve the maximum score within the same moves so with this we have all of our rewards nicely designed the next thing is handling the episode end now again i also got another very useful event so this one is when out of moves so very simple when there are no more moves we just listen to that event and end the episode we just go into the agent and call and episode then in order to play all over again a very simple way is just to reload the current scene so here just using the standard scene manager to load the current scene so we do that when we run our moves and then also when we have a win which is going to happen on the last levels all right so that should do it again how easy this is to implement is going to depend on how you implemented your original metric class in my case i already made all these very useful events so adding this one on top was extremely easy now before we train we should test with heuristics to make sure that everything is indeed working now for handling heuristics is actually extremely simple the builtin match 3 actuator already has a really nice toggle to force heuristics so to use it we just really need to take this and now it will be using the default heuristics so we should be able to test okay we can now test so just make sure everything is set up exalt like this so we made our board we implemented all these films are set dynamically so we don't need to set them in here then we've got our normal behavior parameters actually here we can set the space size to zero since all of the observations are handled by the sensor component okay everything else looks pretty good so we got the agent the center the actuator and we are forcing heuristics okay so we can now finally hit play and test and when you do you might see this very weird error it's something to do with the action mask this is a weird error related to how the sensor and the actuator initialize if you do see this error then a simple solution is just load up a different scene doesn't matter which one so just go to a different scene and go back into your scene and without touching anything if you run now it should be working and if right away everything is indeed working i'm not touching anything and the code is automatically using heuristics to find a random valid move now let's just verify that the level is resetting correctly so just wait until it runs out of moves so just one more move zero and if there you go as you saw it automatically finished level and you reload the current one all right so everything is good and we can now start training now for training again don't forget go up here and disable force heuristic and now let's run training normally here is the config file i will be using this is included in the official github repo my only change here was really just putting the summary frequency to 100 just for now just for testing and also changing the behavior name to match the one on the behavior parameters component and here's my command line so just use the config and run training again if you're not familiar with these commands go watch the getting start video in there i cover in detail all of this the config the commands and so on so with this we're ready to start training and there you go we're listening and yep training is now running so you can see everything is constantly going through the moves constantly you'll lose and so on alright so we see everything training everything going and we can start to see our results all right so training is working that's awesome now one thing though which is like this we're only training one instance of the game this is going to be quite a bit slow so ideally we always want to run training in parallel so let's do it just like it did when training the flippy bird agent which is to make a proper build and use that for training the first thing we need is to make a build so let's go into our build settings make sure you include the scene in the build then you can also set it as a server build which will not waste resources on rendering so just go ahead and make a regular build just make sure that it starts playing automatically okay i've got my standard build here we can even double click to make sure that everything is working and there it is running without any visuals okay so here's our command using the same config going into the environment parameter going inside of our path running our executable then for the number of environments so this will depend on your machine in my case eight is my maximum then the same run id and in this case resume again i covered training using builds in detail in the flappy bird video so go watch that if you want to learn more so if we just go ahead and run this and yep there it is we've got all of our instances running and yep they are all training we can verify by looking in the task manager and yep over here we see we have our command line with all of our eight instances all right so that's really it now our ai is indeed training with eight instances in parallel so that's left is just don't let it train for a little bit alright so i have a brain that i trained for about one hour and it's already very good here are the graphs in tensorboard so the one thing is that each brain needs to be trained separately so i've got a brain that was trained for the score goal and another one here that was trained for the glasgow so as you can see this one learned quite quickly actually and the glass ai did take a bit longer i trained it in total for four hours it had a strange crash right down the middle but as you can see just continuously getting improvement for the training scenarios like you saw the score goal has the unlimited number of moves they always got 100 moves and they try to reach as much score as possible so that is why the episode length is always the same because it's always 100 moves and the score is constantly increasing and for the glass goal what i did was made some code to place 10 random cells in casing the glass and then also gave it a negative reward for every move so it learned to destroy as quickly as possible and as you can see over here on the episode length yeah constantly going down all right so that's the results for training now let's run the ai's and see first here is the score ai so let's see how much score it gets okay got a total of twelve thousand nine hundred let's run again okay got ten thousand five hundred and now it got 17 000. all right now i'm going to try to play myself so here i am let's see if i can beat it okay i got 8 600. and 6900 and 8700 now i'm definitely not a pro match 3 player or anything but you can see how in just one hour of training the eye is already doing much better than me so now let's swap it out for the one with the glass brain here's the ai making its moves and it got it with 91 moves left now let's see how i do all right look at that i actually beat the ai on the second one and with that we have made an ai that use machine learning to play a match 3 game now as i mentioned in the beginning the huge benefit when compared with classic ai is that we don't need to change much every time we add a new feature for example i add an extra feature that causes an explosion whenever i match four in a row so here if i swap this one i'm going to match four in a row and all of these are going to explode so swap and if there you go all of them go on so with that i implement the brand new mechanic and now if i was working with classic ai i would have to explicitly add that new logic onto my bot however here when working with machine learning i really don't have to do anything all of the core components are exactly the same so i just have to go and run training some more and the ai will learn that if it matches four in a row it won't cause an explosion that gives it more points you can either run training some more completely from scratch or you can use the parameter initialize from to continue training from the previous model which will make it learn the new behavior very quickly so that's the awesome power of machine learning and you can see how useful it is when you've got a game that is in constant development alright awesome now as you saw all i needed to do was implement the abstract board and everything worked perfectly with my custom mastery class so if you have your own match 3 game it's very easy to implement this so go ahead and give it a try all right hope that's useful check out these videos to learn some more thanks to these awesome patreon supporters for making these videos possible thank you for watching and i'll see you next time