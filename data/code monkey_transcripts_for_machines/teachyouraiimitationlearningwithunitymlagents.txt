hello and welcome i'm your code monkey and here let's check out the awesome power of imitation learning using unity ml agents first if you're not familiar with ml agents that is unity's machine learning ai toolkit i cover the detailed getting start guide that goes through the whole installation process and how to use it so go watch that video if you haven't already and check the full machine learning playlist in the description ml agent supports two types of learning reinforcement learning and imitation learning now imitation learning is how you can teach your ai directly how to behave in order to achieve a certain goal meaning that instead of trying to work by just randomly testing actions it will instead try to imitate what the player did and build upon it so think of it as if you were trying to play a game in one method you just randomly push every button on the controller until something happens and in another method you have someone who knows how to play teach you what the buttons do and how to push them in the correct order to get the reward now let's first think about the limitations when using reinforcement learning and then we can see how imitation learning is an awesome very powerful tool in the getting started video i cover the most basic type of learning just reinforcement learning where the agent learns how to do something based on the rewards that it gets now that method works great when you have a relatively simple scenario for example in that video we made a simple agent and it wants to touch the goal it's pretty simple so it can easily complete the task it spawns in a random position and moves towards the goal so that one works out great but over here i have another more complex demo i'm currently controlling the character using heuristics so the goal is to get into this button so i can move the character go in there then i press a button on my keyboard to push the actual button and as soon as i do a food pallet get spawned so now i need to go there and touch it and there you go i went now for you assuming that you are a human being this is a pretty simple task even if i don't give you the instructions you can probably figure out after a few seconds but for an ai that randomly pushes buttons until it gets a reward then this scenario is extremely complex just think in order for the ai to complete the whole task first it needs to trigger the right random actions to get it to the button then it needs to again randomly push the button and then again needs to trigger the right random combination of actions that gets it to the food pellet so as you can see that's a ton of very specific random actions that need to happen in a very specific sequence so the odds of that happening based on pure luck alone are extremely tiny so essentially you'd have better luck just getting the ai to play the lottery so that's where imitation learning comes in instead of the ai trying random actions until something happens we teach it how it should complete the task and the i learned from that and just like with reinforcement learning using ml agents to achieve this is quite simple again if you haven't seen the getting started video go and watch that in there i go through all the basics on getting started and logic for how it all works in order to do imitation learning it is pretty much the same thing that we saw for reinforcement learning so over here i have my scene and i can control the character using heuristics so the agent class is already nicely implemented let's look at it so i've got my environment and inside i've got the agent and here it is the various behavior parameters so very simple stuff and let's inspect the food agent script so here is the script and again remember how reinforcement learning works which is first the ai takes some observations of its environment then it takes a decision it makes an action and sees if it gets a reward that's the reinforcement learning cycle over here i have my food agent class and as you can see the code is pretty simple so if you watch the other video then all of this should be quite familiar first up here we have the on episode begin function so this is where we set up the scene with some randomness so that the ai doesn't learn how to solve just one specific set of positions so we randomize the player position and then on the food button script when we reset the button we're also randomizing the position so both the player and the button get random positions that's all we do on the on episode begin then we have our collect observations function so here in terms of observations first i'm giving it the state of the button so if the button can be used then the machine learning algorithm receives a 1 and if not it receives a 0. then i'm also giving it the direction towards the food button then another observation for the current state of the food so if it has been spawned or not and if the food has been spawned then i give it the direction towards the food and if not just two zeros so those are all the observations we just have over here one two three four five and six floats then down here for the actions i am using discrete actions to move the character and here they have some very simple very straightforward actions so just don't move move left move right move back or move forward so it's a very basic movement controller over here modifying the rigid body velocity and then another action for the is use button down so when this one is set to one then that is the agent using the use button and when that happens then it simply looks for objects around the agent and finds a button to push so if it can't find a button it tries to push that button so i covered this simple way of pushing buttons in the waste open doors video so those are all the actions and then for the rewards over here we have a reward when it successfully uses the button and then down here when we consume the food we also get another reward and lastly over here on the on action received on every action i'm also giving it a negative reward in order to essentially encourage the agent to finish as quickly as possible now one important thing is that i only added this negative reward to training after it was already succeeding in achieving the task so i didn't start with this one by default essentially in the beginning you want to help your ai to learn and then later on you can focus on actually optimizing okay so here is the script as you can see it's pretty small pretty simple first let's actually look at what happens if we try training our ai using just reinforcement learning and by the way here's a quick tip that someone mentioned in the comments on the previous video if you go into the folder where you have your project you can just go up here into the actual path and in here you type cmd and when you do it opens up the command prompt directly onto that folder so very useful tip now here let's try doing the normal training okay so there it is training is currently running and you can see it's happening exactly as you would expected so the agent is just trying random actions which caused it to randomly move around so again remember in reinforcement learning it's very important to get a reward and in this case the agent is only getting a reward when it pushes the button so when trying these random actions the agent needs to be unlucky enough in order to push the right actions to move it towards the button and then actually push the button so achieving that first part is actually somewhat doable so it might get lucky and achieve that but even if it does achieve doing that then it won't learn to go towards the button and push it but then it's going to have a lot of trouble to go towards the pellet after pushing the button now again you could technically leave it like this and through sheer chance alone then maybe in a million steps you would get lucky and complete the whole task but the odds of that happening are really slim so this is just basically reinforcement learning it tries random actions and hopes that it achieves something so here it already got lucky and hit the button so now it learned to go towards the button and push it but again achieving the whole task is going to be very difficult so now let's give this ai some help and show it how this task should be completed and by the way if you find the video helpful consider subscribing and hitting the like button it really helps out the channel now as i said that one is very simple all we need to do is go into our agent and let me actually go inside the prefab so i modify all the agents so here i'm in the prefab and select the agent and then i just have to go down here and going to add another component go inside ml agents and in here we're going to add a demonstration recorder then here we see some fields so first of all we've got a toggle to enable or disable recording so just go ahead toggle that so we start recording then for the number of steps this is in case you want to unlimit how many steps you record but if you just want to continue recording until you stop the game then just leave it at zero then we've got a demonstration name so let's name this our food agent demo and then directory where you want to save it so let's just name it demos alright so that's on the setup for the demonstration and now hey record is very simple just make sure that the agent is over here set the heuristic okay here is the calling and all i have to do is just run the scene as normal so here i am and now my actions are being recorded so essentially the ai is now looking at everything that i do all the actions i take and all of the observation values as i take them now all i have to do is really just teach it correctly so i guess that means that if i wanted to be mean to the poor ai i would just ram into a wall nonstop and now the poor ai would learn just to slam into a wall now that's probably not very useful so let's actually teach it how to achieve the task so here i just move towards the button i press the keyboard button to trigger the action and now go towards the palette and consume it and now again go into that one press the button and so on and so on and essentially this way the agent the ai is actually looking at me looking at how i achieve this analyzing all the actions that i'm taking and all the various observations so that's pretty much all it takes to record the demo you just complete this as many times as you can essentially the more that i give it the more the agent will learn and then in order to stop recording you just simply exit play mode okay recording is done and if we go into our project files we can see over here we have a folder called demos and then inside we have our food agent demo so just go ahead copy this one inside our assets so there it is and here in our project files we can see our demo and if we select it we can look in the inspector and see the various stats so you can see how many steps it recorded how many episodes what was the main reward what is the size of the observations and the various actions so there's this demo that i just made where i trained for a tiny bit now really very optimally and then over here i have another demo and in this one i train more properly so you can see the main reward almost close to two which is essentially one for that one and one for hitting the pellet so again the more data you give it and the better the data the better the ad will actually learn so now the next step is just to tell the ai to use this demo to learn from and for that we need to go into the config file so here i set it up exactly like i covered on the getting started video so i've got a folder for my configs and inside i've got my foodagen.yaml and here is the config with all of the hyper parameters and now in order to use imitation learning we go down here inside the reward signals and we're going to add another section and this one we're going to name it gale gale stands for generative adversarial imitation learning meaning that the ai won't try to beat the demo that you give it so at a high level how it works is by creating a second learning algorithm called the discriminator and the goal of that one is to figure out if a certain action came from the agent or from the demo so essentially over time our agent will learn how to behave more like the demo in order to trick the discriminator and again you can combine this with extrinsic rewards which essentially means that it works on top of reinforcement learning so after it learns how to behave like the demo it will continue improving until it becomes essentially superhuman so we add the scale section and then here we have a whole bunch of parameters you can check the docs to see all the various parameters and what they do the main ones that we need are the strength so this is how much the demo will impact how the agent behaves so if you want it to act exactly like the demo you give it 1.0 but that's probably a bit too much we still want the agent to learn to get better than the demo so let's start off at 0.5 and then the other parameter that we absolutely need is the demo underscore path and this is just the path towards the demo so here in the project folder we've got the demos and inside we've got the food agent demo so this is the one that i prepared previously so let's use this one since it has more values so just paste this pattern here that's it so essentially all it takes is adding these parameters and then all of a sudden you just added imitation learning now there's actually two types of imitation learning that you can use so there's gale here and there's another one called bc or behavioral cloning so that one goes outside of the reward signal so nothing here but rather down here this one is named behavioral cloning and inside we've also got these two so we have a strength let's also put it at 0.5 and then again a demo path now gail like i said works by trying to trick a discriminator into pretending that the actions came from the demo whereas bc simply tries to copy exactly what you did now the limitations of bc is that it can never get better than the demos so in order to get the best results you really just combine all three so first using bc it learns to act exactly like you then when combined with gale it learns to act similarly to you while achieving the same goal and when combined with extrinsic rewards it continues improving upon those two and that's how you get superhuman learning then essentially the trick is just to play around with all these parameters so at the start we want the agent to learn from the demos so we can put both of these with a pretty high strength but then we want the agent to go beyond the demo so after it learns the basics then we can reduce this to something like point one so it gets more impacted by the actual extrinsic rewards okay so now it's time to check out our ai nc learning using imitation warning now before we do some mass learning let's go inside our prefab and in here let's make sure that we disable recording on demonstrations so just untick this and let's set the behavior type back into default so that it trains and now let's run the same logic using our configuration.yemo and food agent let's name it imitation okay so let's run and here let's also enable all of them so we've got mass training and hit on play and if there it is the agent is now learning to play using our demos as a demonstration so you can see some of them already managed to hit and grab the food palette here we go one two three four five five of them managed to get the palette and two more and this one actually completed the whole task so as you can see this one is already doing quite a lot better than our previous training which was just trying random actions so quite a handful of them have already learned to press the button and go towards the palette look at that one almost went perfectly so all of the logic is working and our model is currently being built now we can go and look at tensorboard to visualize in learning so here it is and we can view the graphs and we can see that it's already working so in the beginning as it was trying just pretty much random things like this it wasn't getting anything so reward of minus one and then as it started to behave more and more like the demos you can see it's skyrocketed the reward right away and over here the episode length so essentially it's learning how to achieve the task quicker and quicker so after just a little bit of time we can clearly see the results so most of the agents have already learned how to do that complex task so they go towards the button they press the button then they go towards the food palette so let's stop training and let's go inside the results to grab our brain model here it is and if there's the agent using our model in order to achieve the tasks so he goes towards the button pushes the button and then goes towards the food pellet so look at that isn't that awesome at first the agent couldn't do anything it would just randomly move around and now thanks to our demonstration we have taught the agent how to achieve this relatively complex task so it goes towards the button pushes the button then goes towards the food palette here i have another brain that i trained for quite a bit longer and as you can see this one is quite a lot faster at achieving the goal so it goes directly towards the button doesn't even hesitate as soon as it gets inside the button it triggers the button and then goes straight towards the food pellet and again we can still see the magic of machine learning which is remember that we didn't write any code telling the agent how to move or how to press a button the agent learn all those actions by itself with the help of the human player teaching it how to play so here we have imitation learning it's a massively powerful tool and something that will greatly help you when training your agents in more and more complex scenarios as long as you give it enough data in your demo you can teach your ai to solve pretty much any problem so stay tuned for more machine learning videos where i will be applying this to even more complex scenarios you can check the full machine learning playlist linked in the description as always you can download the project files and utilities from unitycodemonkey.com this video is made possible thanks to these awesome supporters go to patreon.com unitycodemonkey to get some perks and help keep the videos free for everyone if you found the video helpful consider liking and subscribing post any questions you have in comments and i'll see you next time