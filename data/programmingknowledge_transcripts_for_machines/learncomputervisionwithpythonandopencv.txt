hi this video course is on learning computer vision with Python and OpenCV I hope you are really excited about this course I'm definitely sure at the end of this course you will gain enormous knowledge on computer vision and you will have a tool box with several image processing techniques ready this is Catherine completing my master's degree in computer vision I'm currently working as a data scientist in Texas USA I'm interested in medical imagery researching and robotics you can find me in my LinkedIn before getting started with open CV let's see the overview of this course in section 1 we will provide some insights and installation procedures of open CV Python which work great for image processing techniques and computer vision in section 2 we give the inside of working with images in frequency domain and helps in finding the edges in the image using image gradients and segmenting the image in section 3 we detect features from images and use it for detecting the objects in images for example in this section we will detect faces in the images using features captured from several positive or negative images in section 4 we will learn about getting started with videos and do the background subtraction and calculate the optical flow of the object in the video using different methods and finally track the object in the video using mean shift and cam shape basic Python programming numpy and matplotlib all the prerequisites of this course let's get scattered the different morphological operations are erosion dilation opening closing morphological gradient tophat black hat and structuring elements the first one is erosion the pixels in the original image are considered as one only if the pixels under 2d convolutional kernel is one pixel near the boundaries are eroded based on the kernel size it is useful for removing white noises or detaching two connected objects the function is C V dot erode I have a spoiler alert for you we're going to see one more example on this morphological operations in image segmentation using watershed algorithm let's look into the code for erosion so here we have used CV dot erode when after erosion this is they eroded image and this erode method remote all the white noises in the input image the second one is dilation it is the opposite of illusion the result an image pixel element will be one if at least one pixel under 2d convolutional curl is one this in turn increases the white region of the image or increases the size of the foreground object a nice removal dilation is performed after erosion so for dilation we use the method called CV dot dilate let's look into the code here we use CB 2 to dilate what it exactly does is it increases the white region of the image so this is the input image and this is the dilated one later looks so different the third one is opening opening is otherwise known as erosion followed by dilation it removes the noise in the image so we use the function C V dot morphology X with a parameter CB dot mara underscore open let's look into the code so here in the code we use smartphone GX with the parameter more underscore open so how it exactly works is erosion followed by dilation so this is the input image this is the opening image the fourth one is closing closing is otherwise known as opposite of opening so here dilation followed by erosion so we use the open Seavey's method CV dot morphology X with math underscore closed as the parameter so like I said Mark Foley underscore X and Mark Fonda's are close so how it is different from opening years like in the closing image you can see more of white region and damage which means first we've performed the erosion operation and then we go for the dilation one v honest morphological gradient morphological gradient is nothing but the difference between the dilation and erosion of the image the resulting image will appear as the outline of the image let's look into the code so here we have morphology X that is like they've been using it for a long well I guess and with the parameter C B 2 dot morph underscore gradient is the thing so here is the input image and here is the difference between dilation and erosion operation in the image next one is top hat top hat is otherwise known as difference between the opening of an image and the original image let's look into the code ok so here we use morph underscore top hat parameter for morphology X method so here is the output what's happening here really like it calculates the difference between opening up an image in the original image the next one is black hat black hat is otherwise known as the difference between closing of an input image and the input image and we have a parameter more underscored black hat let's check the code so how black head works is like it calculates the closing of the image and then you have the input image so finally finding the difference between closing of the input image and the original image that's known as the black head operation so the last one is structuring element so getting structuring element function from OpenCV gives you the desired shape and size of the kernel so we can get more funders correct we can get more fun tasks or ellipse or cross or whatever the function you want like rect in the sense like it will give you the rect shape kernel generally in certain images the pixel values have skewed only on a certain range for example brighter images will have almost all the pixel intensities of brighter values that is around the range of 240 to 255 on the contrary an ideal image will have pixel intensity values from all regions of the image so I think this might have given you a good intuition about the pixel intensity distribution in images so in this case meaning the transformation function that takes the input pixels and returns the equalized output pixels so we're gonna use this function numpy dot histogram so for using that we need to flatten the image first let's look into the code now so here we use numpy dot histogram and I'm giving the flattened image as the input for a histogram so from the given example it is understood that pixels lie in the brighter region so we need to have a full spectrum to transform the image into a good one that's what histogram Equalization does so in this lumpy array usage we have a master rate for the mastery all operations are performed on the non master elements explaining mastery is beyond the scope of this video this method gives you a lookup table which helps him mapping the input pixels to the output pixels we can just apply transform on the image the practical use case of histogram equalization is in face recognition before feeding the face images for training histogram equalization is applied even if the image was a darker one equalization almost get the same result as that of a brighter image hence Equalization is used to make all the regions of the image with a better lighting condition the next one is histogram Equalization with OpenCV we can achieve the histogram equalization in a similar way some issues with histogram equalization ZAR that histogram considers the global contrast of the image so if we have very bright object in the image by applying equalization to the image we'll make the image lose the information the brighter region so for open CV based histogram equalization we use equalized hist let's look into the code now so I perform equalize historian here so this is the input image and this is the equalist histogram so if you try to plot the histogram you can find that the pixel intensity distribution will be in all regions so like a discussed before we can solve this problem using adaptive histogram Equalization some issues with histogram equalization or histograms consider the global contrast of the image so if you have a bright object in the image by applying equalization to the image will make the image lose information in the brighter area so we can solve this problem using adaptive histogram Equalization here we divide the image into tiles with a default size of 8 by 8 and OpenCV histogram equalization is applied on each of these blocks as usual if there is any noise in the image histogram equalization will amplify the noise to solve this problem again we can apply contrast limiting by default fall to use the contrast limit and open series if any histogram bin is above 40 those pixels are clipped and distributed uniformly to other bins prayer histogram Equalization after Equalization to remove these artifacts and tile borders bilinear interpolation is applied yes background subtraction is a major preprocessing step for the video the first method is so we need to extract the moving foreground from the static background it's gonna be really easy if the image of the background is available the first method is background subtractor emoji this is a Gaussian mixture based background subtraction or a segmentation algorithm it used a method to model each background pixel by a mixture of K Gaussian distributions K value ranged from 3 to 5 the weights of the mixer represent the time stamp that each color stay in the video the probable colors are the media background colors which stay in the video longer and static for achieving this we need to create a background subtractor object using Create background subtractor emotion it has the parameters like number of Gaussian mixtures length of history M threshold etc you can play around with these parameters in the video let's look into the code so here in the code we are going to use the same user in both video sample let me run the code okay here is the thing the background is subtracted from the video the second method is background subtract emoji this is a Gaussian mixture based background subtraction or a segmentation algorithm the most important feature here is that it selects the appropriate number of gaussian mixture for each pixel in the video also it provides adaptability for varying scenes and illumination let's look into the code in background subtractor emoji they have different parameters in emoji we have an option of detecting shadow in the video if Didache shadow is equal to true then it detects and marks the shadow in the video shadows are marked in gray color one more important thing is it decreases the speed of the background subtraction let me run this code so it looks like better than emoji the last background subtractor method is background subtractor GMG this algorithm make use of statistical estimation of the image and per pixel bayesian segmentation but default in OpenCV it uses 120 frames for modeling the background and deploys basing inference for the probabilistic foreground estimation new observations are given more weights than the old to differentiate the illumination morphological operations like opening and closing which we discussed in the section 2 are used to remove the noise you can try to implement this yourself as a homework today