in this video we'll talk about making a simple python optical character recognition script where we use uh pi test rack uh api over the google interest rate ocr engine to actually read text from images programmatically so in this video we will talk about what is ocr what are the applications of optical character recognition how can we actually build an ocr script where we can actually read image read text from images so let's get started so first let's have a very brief introduction about what ocr is so humans can understand the contents of an image simply by looking at it we perceive the text on the image as text and can read it so computers don't work the same way they need something more complete in an organized way to understand that so this is where optical character recognition comes into the picture whether it's recognition of car plates from a camera or handwritten documents that should be converted into additional copy this technique is very very very useful so in this video we will delve into the depth of optical character ignition and its application areas we'll also build a simple script and python that will help us detect characters from images and you can also build on top of this simple python script and build a web application out of it so what is ocr so optical character recognition involves detection of text content on images and translation of those images to encode a text that the computer can understand easily so how is this achieved uh so to us as i said uh text an image is easily discernable and we are always able to detect characters and read the text but for computers it's only a series of dots or pixels so the image is first scan and the text and the graphics uh elements are converted into something called as a bitmap which is basically a matrix of black and white dots then the image is preprocessed where the brightness and the contrast of them are enhanced to improve accuracy of process now the image split results identifying the areas of interest such as where the images or text are and this helps curve the extraction process the areas containing text can now be broken down into further lines worlds and characters and now the ocr engine or the software is able to match the characters through comparison and various ai algorithms the final result is the text in the image that we're given now uh be aware that the process may not be 100 accurate and it might need some human intervention to correct some elements that were not scanned correctly the error correction part can also be achieved using a dictionary or even an np natural language processing so let's see where we use ocr so ocr is very commonly used in airports to automate the process of pass protocol mission extraction from information out of it the other applications include automation of data entry processes detection and recognition of carbon outputs so in this video we'll use python tessraft or simply by tesseract library which is a wrapper for google's tesseract or cr engine so i chose to make this video with pydescript because it's completely open source and it's being developed and maintained by a giant that is google so now first we need to download by tesseract or install it so that we can start working with it so to install pi tesseract you can go to this website uh and just do a simple pip install python so let's do the next thing which we need to do is have opencv in our computer to work with images using python so for that we do a pip install opencv this might take some time since opencv is a very very big software but since i already have it it was done in like a few seconds so next thing is for let's start creating our script a python script and start writing the code this should take about a few seconds to build almost there now first before we jump on to writing our script first actually let's see which image will be actually be reading from or how do we which image do we actually choose to extract the characters from so i have this image.png here so basically we'll be actually reading the characters from this image so this image has a few words so we try to write a python script which can actually read all of this from the image directly or using pi tessraft or the tesseract of crg so let's start first we make an ocr.py file now we need to import a few things for suppose we need to import cv2 and the next thing actually we don't need numpy for now the next thing which we need is import by yeah so first uh let's actually read the image that we have so using again uh opencv so we have image equal to and now let's actually write our code in a much readable format and actually fragment the parts of our function that we need to write so let's define a function called as ocr and this is going to be dealing with the image and actually run our entire api and give us back the text from the image so basically text equal to by tesseract dot image to spring and so as you can see it's pretty easy and straightforward to actually use pi tesseract where we just have to make a function called where the method is image to strength passing the image parameter which again returns a text which we return back to our standard output so now it is not so straightforward to actually write nocr using python this might actually give us the results but as i said the results are not 100 accurate we need to do some preprocessing of our own to get the result that we want so let's do that processing now the first thing which we need to do is convert the image to grayscale so let's write the function for that image parameter and we return series so color okay next thing which we need to do is uh remove the noise from the image so some images might be distorted and might have if you have some pixels which are not the way they're supposed to be so for that we actually remove some noise in the image to make it a bit more sharp let's see how we do that nice again we're leaving functions all of these the code is much more readable again let's give it a comment so that we know what the function is something called as thresholding so we need to have a threshold basically which states that if the pixel value is about uh it's above the threshold then the pixel is black or white and if it's below the threshold then again it's either black or white it's the opposite of what it is above the threshold so in this way we have a very concrete black and white image and because that it is very easy for pythagoras to predict or to give us out the characters from the image so again let's comment it first folding function the shoulder image and this is a bit long function called let me just copy it and then get it here so again we have a threshold we threshold this again depending on structured binary from the threshold also you can read more about these two functions uh in description below there is information in the description about all of this what i'm doing and now that we have a few functions which can help allow us to actually you know preprocess the image and enhance our image properly let's write the code to actually call these functions image equal to get grayscale and g first we convert this to grayscale and the next thing which we need to do is threshold image equal to thresholding image and finally now that we have thresholded it i don't know so the next thing which we need to do is remove the noise or excess noise that the image might have nice ing and yeah we're good to go so now that we have uh done our preprocessed or image using a very simple opencv techniques which is just you know converting it to greyscale removing the noise and just thresholding it the last part here is to actually call our ocr code so let's call our ocr code and pass the enhanced image here and once when we print it hopefully we should get this rtr this is the output where the output says a pipeline approach to category condition so let's just check the code once again and make sure that everything here is right looks about right and now we can run our code and see whether we have the output that we actually mean ocr and yeah as you can see we have the exact output which the image had which was basically a python approach to character recognition and we were able to extract that information from the image using the python test rank api so let's just go through uh what we have done here uh you know which just converts or uses the api to convert image to string but before that we had done a bit of pin processing on our image so we covered it to grayscale thresholded it and then remove the noise and after the image has been preprocessed we then pass that image to the ocr code and then we get our desired output which is as you can see a python approach to that reaction so uh that is all that is it for the tutorial for pythag there will be much more interesting and complicated tutorials about pipeline in the future but for now that is it thank you for watching i'll see you in the next video bye