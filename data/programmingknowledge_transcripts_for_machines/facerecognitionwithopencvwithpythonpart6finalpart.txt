hi guys my name is this is the part number six of this project playlist and it's been quite late after predict the path number five so i just changed my ide because uh previously i was having spider id that that comes from anaconda and now i have id of pyjama so it doesn't affect our code and so let's start it so like in the previous video we have seen that like uh all the things like base data collection video camera on like how to how to do that base recognition okay all of that and now like we have to do like the last practical part of it like we have to recognize our face after after loading and loading the data of the faces right like i will open my webcam and i will upload my data like i will start the webcam and my camera feed will constantly and consecutively uh load my data okay and after that like my facial data would be stored in a numpy array and in prediction i will use that numpy array for in my k n algorithm to predict my new face okay so but okay so basic overview that like in your family just record the faces of four or five people and after that in the data collection record that and while the data recognition just one person coming the camera or multiple persons and a label will be come at around your face and a box will come i will show you that later okay so till then just see here so this is our face organization code okay so like we have done uh this place data collection and like everything we have done till in the later in the earlier classes and this is a hard casket classifier which we have used for detecting the facial components and now like let us see our face recognition file so basically like we have like now like we have discussed kane and gotham in the earlier class like how our base is detected in the bunch of many phases okay so like this is my canon algorithm i have not used a library function rather than i have quoted it from scratch okay like i will show you later like i also told you to study this scaling code by yourself so basically it is nothing just calculating the equilibrium distance and just calculating that which face is the nearest phase to the point of convergence like two of a new phase how many previous places are near to us okay so like like that thing is done here like i have also given comments and just you can read that okay and like i will share this code i will share the repository so that you can read the code and understand it and run it in your computer okay and as of now let me just unhide the scale code okay so now let me just unhide it okay so i have just minimized my canon code so let us see now like what further things i've done in this in this part so like initially like while we while i have to recognize my face so before that like basic steps has to be done as we have done in previous classes like okay so like we have to first open the camera like when we open the camera then only we can like put our face in front of it right so first we open our camera by cb2 dot video capture zero by this we are opening our webcam like this opencv function video capture and by this you open our webcam and like with c and i have stored my webcam in this cap variable so cap will contain my webcam okay my video field basically and after that like i have called my classifier that is hardcaster classifier and the function to call our classifier is cascade classifier okay and there are multiple classifiers like aspect class frontal phase classifier is only used for like uh directing over faces and there are multiple classifiers like which are which are used for detection the number rate of the car or a person is the gender of a person or many things so there are like a lot of classifiers which have already been made so we have used hardcast classifier to do to classify a particular part of the faces okay and after that after that just see those data set paths so initial like in previous video we have seen that whenever we are we are capturing our face then we are storing that face in a particular data file okay so uh just see here face data collection here we have stored our face um i think here just see here like we have stored our face in this data set path okay and this data set path is basically this folder now like when i show this folder so just see here i think this is a folder okay just see this okay so this is a folder that is like my like this is my folder basically which contains my all the files python files and this is my face data set folder in which all the faces like whatever the name i have given in the data collection is being written here in the dot npy format so if i open this like face data then you can see that uh when i was printing it then i was printing in such a way like dot format data set path plus file name plus dot npy okay so you can see that like it is my data set path is space data and data set name and uh file name is this like this is my name and this is the file name and dot np by say extension okay so like this my store data and now i have to use this data so like in basic organization i have uh i will be using my this facial data for the recognition part okay and this is the normal areas by which we are just calculating our facial daylight with where we are storing the data and label are the the name of the data like what is the label like currently and class i like i have made two new variables here class id and names so class id will be basically labels for every given file okay and names are like we are mapping a particular name with a particular data file okay and now let us see like how to do data preparation okay so like just see this line just see this loop for fx in os dot os dot list directory data set path so basically os is a another library in python which is used to for interaction with our operating system os basically means operating system okay so here you can see that like i have also imported this os file os library basically and now i'm using that so by this os dot list dire it means list directory and data set path so this this line is basically looping in by this folder okay this is my folder face data set and here my uh like this loop is i this line is iterating over this uh folder okay so every file like every file which is present here will be in the effects like i will be iterating over every file and like in this line fx dot with end with it is just finding that which file ends with this extension dot npy so basically if i made some new file layer like if i made a new folder here suppose a new folder and suppose i make a word doc here okay so like i made a new folder and a word document dot word doc so basically if these folders are present in my file so i have to just uh find the dot mpy files okay so with if fx dot ends with dot mpy i am finding just only dot np wifi is where my data are stored okay where the different faces data are stored i'm just finding those files okay and like just see names names bracket class ids go to fx colon minus 4 so i hope that you remember the slicing operator we have discussed in previous class also like what is the slicing operator so basically you see this we are we are taking all the num we are taking all the characters uh except the last four okay so last order basically this dot npy are the last four indices right and everything before dot npy is our name so basically this names class id contains our name basically okay and here we are just loading our data and appending this particular name and data item in my face data array okay so phase data is this so we are just appending every data data in this phase data area okay and now you see that now we are making a particular target variable like like suppose we have five persons person number one two zero five and these five percent are the family members okay and now like we have to make a particular area a particular scaled down array with that five percent okay so just see that like we have to meet different target errors for that so initially my class id is zero so let's just see this line so basically like we have target variables for different phases like we have stored our facial data and now we are just simplifying that data into target variables okay so target are nothing just a simple array okay so basically what we are doing is like initially like we are having classes like initial class is zero and after that like we are will be implement incrementing our class id with every iteration so a particular class id is associated with every phase data okay initially my class id is zero and now just say this like i have got my data item and this i'm just taking the shape of the data item like the length of my data items data items are basically the number of times our phase has been stored okay so like i'm just calculating the length of the data item and like converting that into an array of once so i i'll be forming an area of once with the length of the data item okay the size will be length of the rate item and i am multiplying it by class id so my class id is zero so when zero is multiplied with then one uh np dot once it will become an area of zeros okay so this will be my target number one after that like i will increase my class id i'll increment it i'll store that target in the labels area and i will just move to the next iteration after that i will go at my second phase okay and what i will do is like i will get another data item i will tell you the size of the data item because i'm having a different person now and i will convert i will make a np array of once and the size of that array will be data item size okay and i will multiply that by class id so whenever an area of once is multiplied with class id which is one so it will become the same area again so that will be my target number two and similarly when i class id are being incremented so basically like when class id equal to when two is multiplied by area of once then it will become an area of two okay the basic difference is that the size of this these all the target arrays are different okay based on the particular faces the size of errors are different and the number on there is our difference okay so that's how like we are just modifying the facial data into target variables and storing all the data in this labels so labels is also an area we are storing all the different phase data and labels now and now we are just printing that data like whatever the face data we have what the base labels we have all that simple stuff and just combining that into np like np or concatenate based data and phase labels space data is the phase data and phase labels are the labels of the faces associated with that okay and now i just see that like we have printed that stuff and now it is my font this line doesn't care as of now and now just see that like like this this line okay so now let's see that like so now like we have like stored our facial data like we have extracted our data from the data set and we have stored that data okay now like we have to implement ever like we have to call our gain function and we have to make a box around our face so what will happen is that when you store your face data okay and like one part is storing our face data in face data dot py file and now like when we are recognizing it like open your camera like play this file your camera will be open and then you will show your face in front of the camera a box will become around your face and your name will be written above that box okay suppose uh if i show you this we just just see this suppose like we having a face like this and like what what will happen is like when i open my webcam suppose this is my webcam okay this this whole screen is my webcam and this is my face like i'm having neck also and like so okay like rest of the body and a face so basically whatever got some will do is like when you open up the camera then a colored box will be covered on our face which will be like this which will cover only our face part okay like okay so a squared box will be formed around our face and our name will become at the top okay so our from our like our algorithm will do that so like this is our webcam and this is me or anything or you and a particular green color box will be covered on this and this is due to this classifier which is like uh defining our face basically and our name will be written over that let me just show you that code so basically like like we are just doing the same thing again which we have seen earlier also like we will start a loop an infinite loop which will be recording our camera so we will start our camera by cap dot read and this red and frame will basically we having our camera variables like webcam variables return is basically like telling us that whether the camera is on or off okay the frame is basically our main camera opening which we will be using okay so first like we have just converted our image to a grayscale image okay like whatever the video will we are having we have just converted that into a grayscale video and after that like we are done same thing like we have just detect multiscale and these are the scaling factor and the number of neighbors like we have seen all this part in earlier video also okay just get over here so this spaces will basically contain our coordinates of the faces like x y w and h so basically uh if i change the plane so this this this corner like top left corner will contain the will having the point number x and y sorry i don't have the mouse so i'm talking like this so x and y are the coordinates and this is our width and this is our height basically okay so basically our this function will give us the x by width and height so that that all will be stored in in the face area okay and now like we are just starting a loop okay so like in the new loop we are having a face and with a face we are having the coordinates and these coordinates are stored are got from the space okay so this space is basically the one phase on which we are iterating and everything this is same just we are just cutting the part of the camera frame and just converting that to 100 cross 100 frame size and now just say this out is equal to k n we are calling our function this c just concentrate here we are calling our function k in and now like train train set and face section flatten so face section dot plating so basically training set is our training set which we have which we are carrying over from the past time and phase section dot platinum means like we have defined this earlier also like we are having a face section just here we are having a face section basically the camera frame which is just uh uh calibrating our face so we are just plotting that to convert that into a area okay of one column in multiple rows we are just starting that because in canon our parameter should be a flattened array only area of one column okay so with train set we have that we have our new face just we are just parting passing the two parameters and this will give us the output output will be that face like training set we have trained and space section is the section we got here so it will basically guess the output that which frame we are having currently so trains that we got from data phase data okay all the phase data we have so it will just iterate over every data and just apply our k n algorithm on that okay which is having a training set and a test set okay on on the basis of that it will give us the prediction which is this and it will tell us that which point it belongs to okay it's like if we have this basically like this is a stuff like if you're having a phase in between so it will just tell us that which face does our face belong to from this rest of the five faces basically okay and now like we have done that like we got the output face from here and now we we have to make a box on the face and a text on the face basically okay so cv2 dot rectangle dot rectangle is a function which is used to make a shape by opencv so what we are doing is just we are passing a frame the coordinates the top left coordinates and the bottom right coordinates okay top left x y and bottom right are explicitly y plus h we are passing the coordinates okay and it will make a face round it will make a rectangle in these coordinates and this is the color and this is the width width of the box color is 255 25 this is basically bgr color okay blue green red okay like if i do zero here and if i do g zero here so bgr means b g and r so if my b and g are zero and my r is 255 it will make a box of a red color okay and if i make this like uh if i make this 25 here it will make a green color box okay this is just a color color format and now like to put a text like here like we write a function co2.put text and it will just uh put a text here and this is the font of the text and this is the and this is the coordinates where i have to put my text and this is my color of the text like bgr format b is 255 so my text will be of blue color okay and this is a width okay and similarly like that we are just putting everything and now like we are just displaying our face okay like we are just showing our camera feed and all of that okay and after that everything just peer make a function like if i press a key q so my function will be end there and i can close my webcam and my webcam will not be closed by anything except pressing q okay and now like after all everything we just will just destroy the window and close the program that's all okay like this is a project of face cognition and i hope that like this is a very beginner level project in machine learning okay it's like i hope that this will this will be clear to all of you and just write the let's just give the comment below that how like like um how much you like this playlist of this project okay and okay so let's end this video now okay bye