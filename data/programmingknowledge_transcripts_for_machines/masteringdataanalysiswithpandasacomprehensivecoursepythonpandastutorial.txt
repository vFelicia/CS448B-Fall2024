hi guys welcome back to our new course on pandas this is gonna be an introductory video so let's get started so pandas is a python Library used for working with data sets it has functions for the following task first of all we have data analysis so data analysis is the practice of working with data to glean useful information which can then be used to make informed decisions so in data analysis basically we try to find out patterns from data so we extract meaningful information and we use that information in future to make meaningful and informed decisions the second is cleansing data cleansing or data cleaning is the process of detecting and correcting corrupt or inaccurate records from a record set table or a database and it refers to identifying incomplete incorrect inaccurate or irrelevant parts of the data and then replacing modifying or deleting the dirty or course data so in cleansing what we do is we correct the wrongly process data for example when you are making a data set there must be some values missing in a record that may not be available so we just need to clean them for example we have a row with empty values so we have to replace that row because we can't work with raw data data needs to be in a meaningful form to extract patterns from the data and the last part is data exploration it is very similar to initial data analysis whereby a data analyst uses visual exploration to understand what is in a data set and then characteristics of theta rather than the traditional data management systems so in data analysis we try to use the functions to find out patterns like the mean the median or something like that but in data exploration we draw colorful plots or charts to analyze the data the process of analysis and exploration are usually performed together armed together known as Eda or explorate free data analysis so it includes the data Exploration with the help of charts or plots as well as with the help of functions so it is called as Eda or exploratory data analysis whenever we have any project the first part is to perform the ede or the exploratory data analysis and then Keening because if we know what is the problem in data then only we can key in the data so these are three important functions that are facilitated through pandas or with the help of functions that are available in the module pandas of python now let's move on to our next question why even use pandas so pandas has a lot of other functionalities as well we'll go through some of them first one is analysis of big data so what is Big Data Big Data refers to the data sets that are too large or complex to be to be dealt with by traditional data processing application software the size of big data is very large and the computational power required is very high so big data can't be analyzed on your systems with the help of traditional software we need newer software to analyze big data so pandas can help with analysis of Big Data as well the second is pandas can clean messy data sets and make them readable and relevant so already discussed it can help in cleansing or cleaning of data the third one is it has a lot of use in data science as already discussed data science is a branch of computer science where we study how to store use and analyze data for deriving information from it so pandas has a bigger role to play in the field of data science so what is difference between data and information data refers to Raw facts so it's usually in unprocessed form while information has proper context it means that it is in a process form and we can directly extract patterns from information now let's move on to our next topic that is what else can pandas do so what are some additional functionalities offered by pandas so first one is calculation of correlation among different keys or columns or features so what is correlation in statistics correlation or dependence is any statistical relationship whether causal or not between two random variables or bivariate data so in simple word it means that how will one variable will be affected when the other one is changed the second one is calculation of average values from the data set calculation of the minimum and the maximum values of a column in a data set deletion of fruits that are not relevant or continual values so this comes under data cleansing the second and third points come under the data analysis and correlation is a very important aspect because whenever we do feature engineering we have to do correlation analysis to find out which features are correlated and what is the extent of correlation and we neglect the features which have a direct correlation or a perfect correlation because it doesn't make sense as the both the features are giving us the same information so why bother to take multiple features if one feature is sufficient so in today's lecture we covered the basics of pandas and the basic functionalities of this module offered by python hi guys welcome back to our course on pandas in our last lecture I introduce you to the python module pandas and today I'm going to teach you how to get started with pandas that is how to install import and to some basic operations with thunder so let's get started so first of all let's discuss the installation of pandas so installation of pandas if you already have the PIP package as well as the python installed on your system so generally we prefer to do all the installations with either the PIP installer package or the condom so either it's pip install pandas or conda install pandas so if you have Python and pip package already installed then installation of pandas is very easy so you just need to write the command pip install pandas so install it using the command that is pep install pandas so now I'll run it so it says requirement already satisfied because I've already installed but it may take some time in your system because you would be running it in the command line also uh the Anaconda package comes with the preinstalled pandas module so if you're using jupyter notebook and you have the whole Anaconda package then you don't need to install it explicitly it comes already installed with Anaconda package so if this fails in your command line and if you are using some other IDE you can use a distribution like Anaconda spider Etc that comes preinstalled with pandas now let's import the pandas module so we just need to write import so just simply write import pandas so we have imported pandas successfully but most of the type we import our modules as an alias because we can't write a big word every time we are using some functions so we just import with a short term or an alias so import pandas as PD and PD is the Alias here now let's check the version so how to check what version are you using you just simply need to write print PD dot underscore underscore version underscore underscore so it says 1.4.2 I'm using notebooks so I don't need to write print explicitly but if you're using some other IDE then this will not work you have to write print PD dots underscore underscore version underscore underscore as whole if I just write PD dot version it works here but it won't work on any other IDE it works for Notebook environment only now we'll create a data frame so data frame is a very important part of pandas module because this is mostly used in projects so data frame we'll discuss it in later in detail that what is the data frame and how it works how to add rows or columns to data frame what is difference between data frame and a normal table so right now I'm just creating a data frame so let the name be my data set and I'm using a dictionary to create a data frame so there are a lot of methods to create a data frame you can pass less numpy arrays or dictionaries to create data frames so I'm using a dictionary here I have to give values as key value pairs so my keys are cards and values and my values are BMW skoda as one list and one and two as another list now I'll just write print my data set so I'm going to print this dictionary first and then I'm going to create a data frame so my VAR or any data frame name is equal to PD dot data frame please note that data frame is key sensitive so first alphabet is capital my gaps log has some problems so it's PD dot data frame and pass the dictionary so dictionary name is my data set and shift enter to run so it's giving an error because I've not added a comma in the elements so now it will work so this is our dictionary and this is our data frame so you can see the difference so in today's lecture I taught you how to get started with pandas hi guys welcome back to our course on pandas in today's lecture we are going to cover the series data type in pandas so let's get started so the first question is what is a series so we know that pandas is usually preferred for data analysis so we know that Anders is primarily used for analysis of data pandas is a module which is primarily used for analysis of data and it has two major data types the first one being a pandas CDs and the other one being a data free so pandas supports two main data types first one being series data type and the other one being data Frame data type usually we use data frames because a table or in data is in form of rows and columns but series is very important biggest data frame is nothing but a bunch of series clustered together so now our original question is what is a series so we know that pandas has two main data types series and data frame and what is a series so series is nothing but like a column in a table so Panda series is like a column in a table and when you combine a lot of different columns it becomes a table and in this case a data frame so Panda series is like a column in a table and it is a one dimensional array holding data off any type so Panda series is just like a 1D array but now you must be wondering then what is the difference between a 1D array and a panda series we'll get on to that topic first let us see that which data types can be used to create a panda Series so we can convert a python list a numpy array or a dictionary into a series so first of all we'll try to make a series from a python list so first of all I'm going to import pandas as PD and import numpy as NP now I'll not use anything from numpy but maybe in between I may need to use it so I'm importing numpy as well and I have created a python list that is my list let me just create it in a new cell yeah I've created a list and now I need to create a series so I'll write a is equal to PD dot series and SS capital and I need to pass my list that is my list only so data is equal to my list I'll just print and this is the pandas series now let me just create a series from numpy array so first of all I need to create a numpy array and I have already discussed how to create a numpy array in the numpy module so you can refer that module if you don't know how to create a numpy array so now I'll just write the same syntax and I just need to pass the numpy array instead of list I'll print it again so I got the same result now we covered the topics of creating a series from a numpy array as well as a python list so we covered these two topics now let's move on to the topic of creating a series from a dictionary or a python dictionary so you know that in dictionary we have the entries as key value pairs but first we'll try to understand the difference between an array and a series and then we'll proceed to create a series from a dictionary and understand the difference that how it is different from creating a series from a list or a so first let's try to understand the difference between a series and an array so in an array we have numeric indexes so to refer to the first element we'll use the zeros index to refer to the second element we'll use the index 1. and in general to refer to the K plus one element we need to use the kth index so a series doesn't necessarily have numeric indexes it can have access labels meaning that it can be indexed by a label instead of numeric values so instead of 0 1 2 I can use Alpha Beta gamma a b c or anything I like or any word like ABC for 10 x y z for 20 def for 30. so a series can have access labels meaning that it can be indexed by a label instead of numeric value but by default it has a numeric indexing it means that if I don't pass a value for the labels the default label will be a numeric value like 0 1 2 and so on so now we'll create a series using a dictionary so now I'll create a series using a dictionary and we'll see what is different here so first of all I need to create a dictionary so let there be dictionary with the name e and it has element Anna and let's add one more element after we give the values for this key so let Anna has the value 10 and Jasper has the value 20 and Nikita has the value 30 so Anna Jasper and Nikita are the keys while 10 20 and 30 are the values so now create a series so w is equal to PD dot CDs and I'll pass this dictionary and I'll print it so Anna Jasper and Nikita here act as the labels for the series and 20 10 20 30 are the values so in today's lecture we covered the concept of pandas series that will be all for today hi guys welcome back to our course on pandas today we are going to continue our discussion on pandas series so let's get started in our last video we covered how to create a panda series from a list and an array as well as what is the difference between a series and an array so we'll continue our discussion on labels and indexing today so now our task is to take the data and label values as separate lists and create a panda series in our last lecture we use a dictionary for the values as well as the labels because the keys can act as label values and the values can act as the entries so now our task is to take the data and label values as separate list and create a pandas series so first of all we are going to import partners so import pandas as PD and import numpy as NP now we'll take two less one for the data and one for the label so first of all let's take labels as a b comma BC on CD so we have defined the list for the labels now we have to define the list for the data so let's data Z equal to Let It Be numeric so 1 comma 2 comma 3. now we'll just write the series name or Q is equal to PD dot series and will pass two parameters first one being the data so data is equal to data Z and the second one being the index so index is equal to labeled so in last case we just passed a dictionary and automatically the index or the labels and data was assigned but in this case we have to pass data and index so here we can see that it doesn't have a numeric index it has index as the value of labels that we have passed now let's see what if we don't pass the index values so it's not a brainer if we don't pass index values they will be taken as the default numeric values starting from zeros so it will be 0 1 2 and so on now let me just print the capital Q so it's 0 1 and 2. so if you don't pass the index it automatically will take numerical values of numeric values now let's move on let me just give you an assignment now your assignment is to take a list and a numpy array as an input and create a series please do all the assignments it helpful and it will help you learn more now let's move on to choosing an index to access a particular value so we'll use an index to access a value let me just access the value 2 here so I can write capital Q so to access the value 2 in capital Q first so I'll just write capital Q off 1. I'll just run this cell and I got to and to access to from small q I can write q and in bracket I have to specify the label that is BC so I got to as result so in today's lecture we continued our discussion on labels on indexing hi guys welcome back to our course on pandas in today's lecture we are going to cover some operations on pandas Series so let's get started so we are going to cover some basic operations such as sum and difference so operations on CDs first of all let me declare or Define two series so that I can perform operations on them so let series 1 or scr1 is equal to PD dot series and let me just pass a list and labels so I have to pass the labels as a list so PD dot series list and the list of labels as index similarly I have to declare the second series so let the elements p2345 and the index be a little different this time so let it be B c d and E so the indexes are not same or the labels are not same let me just import pandas as PD don't forget to do this sometimes I do forget because I think that it's continuation of previous notebook but I'm making a new notebook every time so I have to declare it or import again now let's just perform the additions so scr1 Plus acr2 so I'll just run this cell and I got the sum it shows not a number for label e and label e because there are no values corresponding to these enables in the other list for example label a is only in series 1 and there is no label a in series 2 so their sum is not a number similarly for the label e also we can use the add method to perform the sum so we can also use the add method to perform the sum or for addition now I'll demonstrate the use of add method so I just have to write scr1 dot add scr 2 in the bracket I'll run this cell will get the same result now we should observe that whether it causes the change in series 1 or not so I'll just print the series 1 scr1 so no change so add method doesn't cause any change in the original series it just performs the addition and returns a new series so no change in series one now let's see what's the difference between addition using add method and the normal add operator so in this case we can also pass the default fill value so we observed that there was no nothing corresponding to label a in series 2 but we can give a default value in this case so the label a will be filled by 0 in series 2. so someone plus 0 will give us 1 and not not a number so this is the difference we can give the default field value if there is no corresponding label in the other series similarly we can perform the subtraction using the subtract operator the minus operator as well as using the sub method so this is your assignment that you have to perform subtraction using the minus operator and Dot sub method and demonstrate the code and the output as well from today's lecture we covered some basic operations related to pandas series hi guys welcome back to our course on pandas in our last lecture we concluded our discussion on series and today we are going to start data frames so let's get started so our first question is what are data frames so data frames are the workhouse of pandas so they are directly inspired by our programming language and then nothing but a bunch of series objects put together so series is one dimension we just cluster together a bunch of series and it becomes a data offering so data frames are the workhouse of pandas that directly inspired by the r programming language and we can think of data frame as a bunch of series objects put together because series is one dimension and when you combine a group or a bunch of Series so it becomes a tabular structure that is a data frame now let's see how to create a data frame so first of all we have to import numpy and pandas by Alias so import numpy as NP unimport Partners as PD now we'll run the cell also in this case I am going to use the rant n method of numpy to create a 2d array which I'll will pass to data frames so I I'll import that also from numpy dot random input run in I'll create a data frame with the name DF so DF is equal to PD dot data frame and in this case we have to pass a 2d array so instead of passing a hole to the array I'll just write run in 5 comma 4 because this will return me a 2d array and I have to pass a list of index as well as a list of columns because a data frame has indexes as well as column values or keys so I'll just write a b c d e dot split because this will return me a list I can either write split and I can pass comma or I can just give normal spaces so a b c d e and by default the split is along the blank or the white space similarly for the columns I'll pass w x y z and Dot split because this will also return me a list of four elements and 4 into 5 is 20 which is the dimension of the data so this is the resultant data frame now I'll try to access a row directly to access a row or an index in a series I can write DF and in bracket pass the index or the label so DFA this will work when I use it in a series but will it work in a data free let's check so DF of a where a is the label this is giving me an error so this helps us to deduce the fact that we can't directly access a row using a label in case of a data frame so this gives us an error we'll discuss the use of dot Loc and Dot iloc later for selecting row offer data free so we'll discuss these topics in upcoming videos but there is one more Point here we can't access the rows directly but we can select the columns directly so DF of eggs X where X is the column label will give me the column values so I'll just write DF of X where X is the column label and it returns me a series because data frame is nothing but a bunch of series put together now let's select multiple columns to multiple columns we have to pass a list of columns so you need to pass a list of columns so X comma y or Y comma Z or anything so there's an error in syntax let me just Rectify it and then I'll run so this is the correct syntax and this is the result please note that you have to pass a list of column labels and not just labels separated by commas now let's prove that data frame is just a bunch of series objects so to prove that data frame is just a bunch of series you can use the type method and select a column so if you can prove that every column of a data frame is the CDs then it's proven that data frame is just a bunch of series objects combined so I'll just write type and in bracket I'll pass DF and I'll pass DS W column so it gives me pandas.co.series.series so it's a series object so in today's lecture I introduce you to the data Frame data type of pandas hi guys welcome back to our course on pandas today we'll continue our discussion on data frames and I'll teach you how to add a column to a data frame or how to remove a column from a data frame so let's get started so our topic is adding and removing columns adding and removing columns to Slash from a data frame so first of all we are going to create a data frame so our first step is to create a data frame so I'll first do the necessary Imports so import pandas as PD import numpy as NP and from numpy dot random I need to do one more import before I can create a data frame let me just write the instruction for the data frame first then I'll add that command so DF is equal to PD dot data frame Rand in 4 comma 4 will create a matrix of Dimension 4 cross 4 and we'll pass it to the data frame along with we have to pass the index so we'll pass ABCD dot split it will return a list containing four values and similarly we'll pass the columns w x y z and also We'll add dot split because it will also return a list containing four values now I'll run it but I have to do the necessary import first so from numpy Dot random import Rand and because run n requires this import or you can use numpy dot random dot Rand and instead of only Rand in so it will also work so now it's giving an edit because so word columns is not spelled correctly so let me just change it yeah now I have created a data frame successfully now just print it so this is our 4 cross 4 data frame now I'll try to add a new column to the data frame with the name ZN so DF of c n or DF bracket square bracket and the column name or the name of the new column is equal to then I have to pass the values because every column has four values I have to pass four values now let's display the modified data frame so here we can see that a new column has been added successfully initially we had W X Y Z now we have w x y z and z in so we we have added a new column successfully now let's remove the column so generally we use a method known as drop to remove a column so I'll write TF dot drop and I'll pass the column name and also the axis because whenever we deal with columns we are dealing with axis equal to one if we don't pass this axis equal to 1 it will give you an error so this is the modified data frame when ZN has been removed but it will not make changes in the original data frame it just returns a new data frame so is it actually deleted no it's not when you display DF you still have Z in so it's false in place by default what is in place let me illustrate in place true or in place false while performing an operation means that do you want to make changes to the original data frame or not if in place is false then no changes are made to the initial data frame and when you where you want to make changes you have to pass in place is equal to true now when I'll make this change it will remove it permanently it's giving an error because the name is the n not CE yeah now it has been removed permanently so when you specify in place is equal to true it makes changes to the initial data frame only so in today's lecture we covered how to create new columns and how to delete columns from a data frame hi guys welcome back to our course on pandas in today's lecture we are going to continue our discussion on data frames and I'll teach you how to select rows of a data frame so let's get started so today's topic is selection of rows offer data frame so this is the topic first let me just import so import pandas as PD import numpy as NP and from numpy dot random so from numpy dot random import run n we are using this to create an array a 2d array you can directly pass a 2d array but that will just make the code a little bit complicated not complicated but it won't look very clean so that's why we are creating a 2d array with help of Rand in method so let me just create a data frame and I have to pass index value as well as the column values so let the index be e and B and the column B C and D so I have to pass these as lists and I have a 2 cross 2 Matrix that will create a two cross two data frame with the index a b and column values C and D so I have created a data frame so this is our result in data frame now let's just try to select a column first so we have selected the column C so we can conclude that we can select a column directly from a data frame now let's try to select a row let it be a so d f of e so this is giving us an error so we can conclude that we'll get an error while trying to select a row directly so error while trying to select a row directly also all the necessary notebook links will be given this time so you can just refer to the notebooks if you are not able to implement something I'll share a GitHub link so selecting of rows is therefore different from selection of columns or from selecting columns so selection of rows and selection of columns are done by different methods and selection of rows can be done using two methods first one is dot loc method and in this we have to pass the label so dot loc and we have to pass the label or label is passed and the other method is iloc method and in this case index is passed so there are two methods for selection of rows first method is dot loc and the other method is dot iloc in the first one label is passed and then the second one index is passed let me just write df.loc a so here we can directly pass the label and we'll get the row and in iloc method we have to pass the index so the index of e is 0 so it gives us the first row similarly we can select the second row using locb or using iloc one now let's see how to select a single cell because we have selected rows we have selected columns but now we want to select a single cell so I can write DF Dot Loc and I have to pass e comma fee so it selects the first row and the first column or the first cell now let's select the value 2.424 so what is the code that you're going to write to select this particular cell so it is the second row and the second column or the column D and the row P so d f b comma d but we have to write d f Dot Loc because we are passing the labels so we have to write Loc or we can write DF Dot iloc one comma 1. so it is first index column wise as well as row wise because 0 and 1 and 0 and 1 so first now let's select subset of a data frame so in this case we are going to select the rows A and B but only one of the columns so I'll write df.loc and I'll pass both the rows and only one column oh it gives me an error because the mixing is not allowed you can't mix if you are using dot loc then you have to use all the labels only you can't use indexes now let's try using this this also gives us an error because if you are passing a single element you don't need to pass it as a list also it won't work if you pass two of the elements as less in both the cases so this is the wrong syntax also if you do mixing of any kind that is also wrong so this also gives an error now let's see what happens if I pass both the row values instead of arrow and a column value so there was an error but now I passed a row value and a column value so it's correct also now I'm going to pass a list as the row value and only one column value so this is the result so that's the correct method also note that mixing of labels and indexes is not allowed or not supported so in today's lecture we covered selection of rows of a data free hi guys welcome back to our course on pandas in today's lecture we are going to continue and hopefully conclude our discussion on data frames and today we'll discuss conditional selection in data frames so let's get started so the topic for today is conditional selection so conditional selection is an important feature of pandas in which we select cells or sub data frames or subsets of data frames or rows or columns using bracket notations in a way which is very similar to numpy so the use of bracket notation is very important also we know that a conditional operator always returns a true or a false value because every condition that we are checking is either true or false so it makes sense that a conditional operator or any conditional operator returns a true or a false value now let's demonstrate these Concepts using code first of all let me just import all the necessary modules or functions so from num by dot random import ran in we are using rant n for creating a 2d array and then passing it to create a data frame so let's first create a data frame and then I'll demonstrate the concept of conditional selection so we are writing the statement to create a data frame Let It Be 3 cross 3 data frame so I have to write Rand in 3 cross 3 or 3 comma 3 because we don't write cross here we write 3 comma 3 and I am going to pass the index values as let it be a comma B comma C so the index values are a comma B comma C and we have to pass this as a list or I can also write ABC with space dot split because that also Returns the list or I can write directly and let the column values p d e and f now I've created a data frame so this is our data frame as visible on the screen now what if we want to select under a given condition so DF greater than 1. and let's execute the statement so it gives us true and false values so all the values which are greater than 1 corresponding to those we get true otherwise we get false now what if we want the values which are greater than 1 and not just true or false we actually want to print the values so we'll write DS and in square bracket not in this round bracket in square bracket we'll write d f and d s greater than 1. so it will print the value which is greater than 1 so that is 1.24 and so on and it will return not a number for all the other entries now what if we want to check a particular column only so we'll write DF and we'll write in square bracket DF of d greater than 0. so all the rows in which the value of column D is greater than 0 will be displayed that's all the rows so we don't see any difference now let's change it to 1. so now only first row is displayed because only in first row the value of column D is greater than 1 that is 1.24 now what if we want a particular cell or I should not frame it like this I should frame it like to select particular rows and particular columns so it can be a cell or it can be a subset of the data frame so we'll write DF DF of D greater than 1 and a so it is giving me an error because I have to pass a column value so in this case we got the result so it is streamed like this what if we want to a particular column so we are selecting a particular column and a particular row or a set of columns and rows so it's either a cell or a sub data frame so there's a little ambiguity here so please take care of that so in today's lecture we covered conditional selection in data frames so we conclude the topic of data frames hi guys welcome back to our course on numpy in our last lecture we concluded our discussion on data frames and today's lecture we are going to see how to read and view data using the functions offered by the pandas module of python so let's get started so today's topic is reading and viewing data from CSV and Json files so these are two important or the two major file formats in which data is available so we have two data sets here first is the iris data set and the Json version will download the two versions of the iris data set the first is the Json version and the second is the CSV version so let me make sure that it isn't the same directory as our notebook is going to be otherwise it will give us an error when we'll try to read data from these files so it is ids.csv and Iris dot Json this data set is publicly available on both the versions can be downloaded from Kiki now let's move back to our notebook that is reading and viewing data from CSV and Json files so first we are going to import pandas as PD and now we'll create a data frame so DF is equal to PD dot read CSV please note that read CSV is the function which is used to read CSV files and extract data frames from the CSP files now we'll just print the data frame so it gives us the first five entries and the last five entries let me just write DF and execute it so it's in a better format so it contains 150 rows and six columns but what if we want to display all the rules like all 150 rows I want to display then I'll convert it to string using the two string method so I'll write DF dot to underscore string function so it will give me the whole data set so this is the data set and all the 153 entries have been displayed now let me just print the first five entries of the data set so I'll write DF dot head so head method here displays the first five entries similarly the tail method displays the last five entries by default and this can be changed by passing the parameters so it displays the last five entries of the data frame now we can have some basic info by using the info method so it tells us about The Columns of the data set and the normal count in the column so all the 150 entries in the data set are not null when we check if we call them so this data set is probably clean also note that the names of all the columns can be extracted using the keys method so we'll write DF dot keys and we'll execute so we got all the column names as a list now as already discussed we can pass arguments To The Head and the tail function we want to change the number of entries so here if I want to display the first 15 entries I have to pass 15 in the head similarly if I want to display the last 15 entries I have to write DF dot tail and in bracket as to pass 15. so I have displayed the first 15 as well as the last 15 entries now let's see how to read Json files so for that we have a function called as read Json so I'll write PD dot read Json so I have to write pd.3 Json and I have to pass the filing so it is iris.json so Iris dot Chi Zone so this is the theme data set just to format is different also note that Json files are generally used to deal with big data all the other functions will remain same like the head tail info everything everything will remain just the same just note that the format is different so the function to read will be different but the data set will be dealt with the same functions so in today's lecture we covered how to read and view data from csb and Json hi guys welcome back to our course on pandas in today's lecture we are going to do correlation analysis using the function offered by pandas module of python so let's get started so as already discussed and the introductory lecture in statistics correlation or dependence is any statistical relationship whether causal or not between two random variables or pivariate data so in simpler words it tells us how to different columns or different features or different keys in a data frame or a data set are related to each other so correlation in simpler words is used to find relationship among the features or among the columns or among the keys so this is more of a formal definition correlation or dependence is any statistical relationship whether causal or not between two random variables or by varied data we can see that correlation is used to find relationship among the features now a great aspect of the pandas module is the curve method or the correlation method in short we say core or core or anything it doesn't matter until you write the correct thing when you are coding so a great aspect of pandas module is the core method so it can calculate the correlation between each column of the data set so the core method calculates the relationship between each column of the data set now I'll demonstrate the use of core method so first of all let me just do the necessary import so import pandas as PD now I'm going to extract a data frame from a CSV file so PD dot read CSV and let the file name be Iris dot CSV this is the same file that we discussed in our previous lecture now I just need to write DF Dot code and it will return me a new table or we can say a data frame with the correlation values you can read more about the correlation analysis in statistics but let me just tell you in brief how to read this table so the core method ignores the column which are not numeric so it had six columns I think one was about the species so it was not included in this table because the core method ignores the column which are not numeric and the result of core method is a table consisting of numeric values also if You observe carefully you'll notice that all the values in this table vary between 1 and plus 1. so the negative or the minus values denote a negative correlation so if one variable increases the other one will decrease so this is the meaning of the negative correlation and the positive values are plus denotes a positive correlation it means that if one variable will increase the other will increase as well now our next question is what is a good correlation so when we have a numeric value of 0.6 or minus 0.6 that denotes a good correlation either positive or negative like positive 0.6 will denote that it has a good positive correlation and a negative value will indicate that it has a good negative correlation another important thing to note is the presence of a perfect correlation so if you are having a correlation value of plus 1 it denotes a perfect correlation and note that every feature is perfectly correlated to itself for example petal length is perfectly correlated to Petal length it's not important that to have a perfect correlation we observe the correlational same features we can have perfect correlation in different features as well but if the features are same then they must be perfectly correlated now let's see the correlation in form of a heat map we'll discuss more about heat maps and other plots in the map plotlet and c bond module I'm going to give you a brief intro only so we are going to observe this correlation and form of a heat map for that I need to import c bond as SNS and mat.lib Dot pipelot as PLT also note that if you don't have these modules installed in your system you can just skip because I'm going to teach this in future playlists as well I'll write SNS Dot heat map and I'll pass the table or the data frame that is DF Dot core so I'll write df.com so it gives me a heat map note that light value means a positive correlation and darker color means a negative correlation let me just print the correlation values as well and change this color combination to much of something cool warm and a not is equal to true now I have the correlation values as well as a different color for better visibility so today's lecture was all about correlation analysis using pandas also we'll discuss more about plotting in future playlists hi guys welcome back to your course on pandas in today's lecture I'm going to introduce you to the concept of data cleaning in pandas it is one of the most important stages in data preprocessing so let's get started so today's topic is data cleansing or more popularly known as data keyning so data cleaning means fixing bad data in our data set and bad data could be of many types so we'll discuss what can and cannot be considered as bad data so you have a clearer picture in your mind that what comprises of bad data so bad data could be data in wrong format empty cells let me just make a new cell for all this just wait a second so bad data could be data in wrong format empty cells wrong data duplicates that you have the same entries many times so all this comprises of bad data and we need to clean or we need to remove this kind of data from the data set or data frame so first of all we'll discuss how to deal with empty cells so first of all let me just import pandas as PD so I'm going to import pandas as PD and I'll read a data frame so DF is equal to read CSV and I'll pass Iris dot CSV now let me just sorry it's PD dot read so let me just display the first five entries of the data set so you can see that data is already clean so I need to add some other columns so that it is not clean anymore and then I'll demonstrate how can we actually fix the data set so like it would be DF of additional data is equal to not a number or this gives me an error because any n can't directly be used with python so there's a number function for it we'll discuss it later for now let it be none so I'll change it to none just give me one second yeah so let me just change it to none so it's still the same data set but we have added an additional column that is none so all the entries are none so you can observe that these columns makes absolutely no sense if it were present or not so this is kind of an example of bad cells now this column contains only none values so the right choice would be to remove this entire column which has none values now there's also method to remove the rules that contain not a number of values or null values so there's a little ambiguity here this difference between none and not a number or any n here so new DS is equal to DF dot drop any this will remove all the rows containing none values so in the new data frame is empty because every true contains a none or any n value so it will remove all the rows because of that column so this method is not a perfect choice here we should remove the column itself other than removing all the rows containing none or in in values so if I display the head of the new data frame it is also empty so hi guys welcome back to our course on pandas in our last lecture we started the topic data cleaning and I demonstrated how to remove a column and how to remove rows with none or not a number values today we'll see how to replace the null values with the mean or median and other simple methods of data keyning so let's get started so this is continuation of the previous video I'm just gonna make this data a little more dirty by adding an additional column which has empty values now I'm gonna replace the empty values by a number so this is one of the methods of data cleaning so replace the empty values by a number so we'll write DF dot fill any and we'll just provide that number by which we want to fill the none values this is to be used if all the rows have a value in common like they have one two three in common or we are adding a city for a particular set of people who live in same city so all people will have the city value as same so this is to be used only when all the rows share a same value now I'm going to add two more columns in which the values are none so that I can demonstrate a few more concepts of data cleaning now you must have observed that we failed additional data column with value one two three but when I displayed the data set again the changes were not committed so to commit the changes we always need to specify in place as true so I'll write fill any or fill the none or the null values or the NN values in the column A add 1 and in base is true so that when I display the data set again the changes have been committed now I'll just drop one of the columns because I have a lot of columns with none value that I may not require so one of the simple method as Illustrated before is to just drop the column so this is a very long and documented error and there is an error because I have forgot to mention the access always remember that when you are dropping a column you have to pass the axis equal to one and then you have to execute it so now I'll just run this cell again so I'll run the cell again and it works perfectly now so I'll display the data set again so the empty column add with no values has been removed now I'll teach you how to replace the rows which have none values with the mean of other values in that column because the rows have null values some of the rows might have null or none or any in values for a column in our case the column is absolutely empty so let me just fill some of the values in a column and then I'll tell you how to fill all the other values in the column using mean median Etc so let me just change the column values for some of the rows so you can see that I have replaced one value of this column additional data with three and I have also accidentally change the value of another column to 4 but it won't matter let me just correct it and select the right column yeah now I have replaced two of the values by three and four now I'll replace all the other none or null or not a number of values in this column with the mean of these two values so X is equal to DF additional mean or additional data dot mean so X is the mean head and I'll write d f and the column name is additional data and I'll write fill dot fill n a and I'll pass X which is the mean in place is equal to true now I'll display the data frames so all the other values have been replaced with mean of these values now I've left with just one column which has all the none values let me just drop it simply so I'll write DF dot drop and pass the column name X is equal to 1 and in place is equal to true now the data is key in again also I'll demonstrate some of other ways to handle null data in a specific lecture which will be dedicated to handling of null values so in today's lecture we conclude our discussion on data cleaning hi guys welcome back to our course on pandas in today's lecture I'm going to teach you how to visualize data using inbuilt functions of pandas so let's get started so I am going to cover the use of plot method to drop plots using pandas so the title is pandas for plotting and an ID only I'm not going to discuss it in detail I'm just giving you an idea so pandas uses the plot method to create plots also to visualize the plots we can use Pi plot which a sub module of the matplot library so I'm using notebook so I don't need to use this Pi plot or I don't need to import the pipelot but if you're using some other IDE it is vital it's important it's absolutely compulsory otherwise you won't be able to visualize the plots so first of all I am going to import pandas as PD and I will also import matplotlib Dot pipelot as pld so our first job now is to read the CSV file and extract the data frame or the data set from the CSV file I'll use the same Iris data set so I'll write PD dot Tweed CSV and it will pass the name iris.csv now I'll display some entries so this is our data set or our data frame now let me just draw a scatter plot we'll discuss two plots first is a scatter plot and the other one is the histogram so DF Dot Plot kind is equal to scatter and I have to pass the X and Y values because in a scatter plot we plot points and we have to pass the x coordinate as well as the y coordinate so let the x coordinate be petal length in centimeter and the y coordinate B length in centimeter so scatter plot can also be used for correlation analysis so we can see that how petal length and supple length are correlated using a scatter plot so it is also important so see as petal length increases after three the simple length also increases there is some correlation although it is not a very good correlation because for the values from 1 and 2 the plot is kind of messy but after three it shows a positive correlation although it doesn't seem a very good correlation we are using notebooks so we don't need to write PLT dot show but it will be required if you use some other IDE for executing this code now let's move on to our next plot so let's draw a histogram now so histogram is kind of a frequency plot so we have a variable and its frequency so let the variable be simple length in centimeters and the yaxis will give the frequency of that particular sepuland that how many flowers have that particular length of sepals so I'll write simple length centimeters and I'll write Dot Plot kind is equal to hist or histogram so this is our histogram so in today's lecture we covered how to draw plots using pandas and the data visualization abilities of pandas that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas in today's lecture I am going to discuss the merging of data frames in pandas so let's get started so the merge function is used for merging of data sets and pandas or we can see that the merge function facilitates the merging of data sets so there are three terms here merging joining and concatenating so we'll also try to understand the difference between these three so the first is merging and it is done by the merge function so the function merge allows us to merge data frames together using similar logic as merging SQL tables together so this merging is same as joins in SQL if you can recall the inner join outer join left join right join that is same as this merging so the merge function allows us to merge data frames together using a similar logic as merging the SQL tables together if you haven't studied joining an SQL I request you to find some good video on SQL joins and go through it now I'll create a data frame in this case I'm going to create two data frames left and right then I am going to demonstrate inner join or the inner merge outer merge same as SQL joins inner outer left and right let me just create two data frames real quick this gave me an error because I forgot to import pandas as PD so this is our left data frame or the data frame one in a similar manner let's create the second data frame we just change some values in the original data frame and that's it so create two data frames first and then try to perform different time soft merging and merging is similar as SQL joint so there are generally four kinds of merging and also note that for merging we require keys that is very important so this is our right data set and we have one more data set that is left these are the two data sets now I'll write PD dot merge and I'll pass both the data sets that is left and right final pass on equal to key one comma key to submerging is performed on keys that is very important so this is the inner merging or inner SQL join so please take care of this that merging is same as SQL joins and is performed on keys so this is the inner join if we want to perform the outer join then we have to specify how is equal to Outer and we have to also specify on q1 comma key2 so that was in a join and this is outer join similarly to perform right and left join we just need to specify how is equal to left or right so in a similar manner we can perform left and right join also for more information please refer SQL joints so in today's lecture we covered merging of data sets in pandas that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas today I'm going to discuss the joining of data sets or data frames with the help of functions offered by pandas so let's get started so the topic for today is joining so joining is a convenient method for combining The Columns of two potentially differently index data frames into a single result data frame so we have two different data frames and we are combining the columns of two data frames which have different indexes and we get one data frame as a result so this is the official definition now let's try to understand the difference between joining and merging so joining is performed on indexes and merging is performed on keys so this is one and only major difference between joining and merging of data sets or data frames and panels we are concerned with indexes so now I'll demonstrate how joining works but let me just complete this statement so joining is same as merging but performed on indexes instead of keys K1 and K2 so the keys of the dictionary are a and b and a contains the value as well as 8 0 a 1 and E2 and the key B contain the value in a list b0 P1 and B2 and the index contains so in a similar manner will create a second data frame whose name is right and will make some changes in the columns as well as the index also I forgot to import pandas as PD so I got an edit but I've corrected it so this is our left data frame and in a similar manner I'll create the second data frame so let me just copy and paste whole thing and I'll change the name and I also change the key values as well so it's c c not C1 and C2 or C not C2 C3 or whatever you want to have it doesn't actually matter so the keys in this case are C and D containing lists as c0 C2 C3 and d0 D2 D3 and the index values now pay attention that joining is done on indexes rather than keys so now I'll write left dot join and I'll pass right so this is the inner join similarly we can exhibit the outer join I'll just need to write left dot join and I'll pass right and I'll pass how is equal to outer so this is the result of the outer join in a similar manner we can perform left and right jaw so this is the result of left join and the result of right join so in today's lecture we discuss joining of data frame in pandas that's all about joining that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas today I'm going to cover the concatenation of data frames in pandas so let's get started so the topic for today is concatenation so concatenation basically means gluing together data frames also note that Dimensions should match along the axis we are concatenating on so it is different from joining what we are basically doing is we are just gluing two data frames together and please take care of Dimensions while concatenating so let me just complete this sentence Dimensions should match along the axis we are concatenating on also to perform concatenation we have a special method so the use of concat method is done fourth concatenation so he used PD dot concat method and pass the list of data frames you want to concatenate so let me just create a data frame real quick and I also need to do the necessary import that is pandas but let me just first Define the First Data frame so let me move on uh so by mistake I went back now have to do it all over again so let me just do it again quickly so I have to import pandas as PD and I'll run this cell again and the cell again so now I'll just display the First Data frame and in a similar manner I'll create the second data frame so df2 this time and the columns will remain the same The Columns will be the same a b c and d but the indexes will vary so the index is should be in continuation here when I'll am concatenate along the axis 0. the only thing that we need to keep in mind while concatenation is the indexes and the values if you don't have access to values or indexes so the result of concatenation can be a little messy when you concatenate along the higher axis but we are concatenating on axis 0 right now so for the First Data frame the Nexus are 0 1 2 and 3 and for the second data frame I'll specify the indexes as four five six and seven so I'll make the necessary changes let me make some changes in the data as well the data can be redundant also but to make it look better I'm just making some changes in data as well but we can have redundant data we just need to change the indexes so let the indexes be 4 5 6 and 7. now I'll just run this cell and I'll display the second data frame that is in continuation of the First Data frame now write PD Dot concat and I'll pass both the data frames so this gave me an error because always remember that you have to pass the data frames in form of a list so please don't forget indentation or the documentation because different methods or functions take different kind of references or arguments so make sure to pass a list of data free now let's concatenate along the axis 1. so in this case we have to specify access is equal to one rest of the procedure is same so I'll write PD Dot concat and I'll pass the list of data frames as well as I'll specify the axis is equal to 1. so we have concatenated along the columns or along the axis 1. so we have concatenated along the columns also note that we got a lot of null or nnn values so make sure you have all the necessary values for concatenation if you are doing concatenation along the axis 1. so make sure you have all the values for concatenation otherwise it will give n a n or null in the results so in today's lecture we covered the concatenation of data frames and pandas that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas in today's lecture I'm going to teach you how to combine multiple conditions using selection and how to extract information about unique elements from a data frame so let's get started so today's topic is selection and information on unique elements first of all our job is to create a data frame so create a data frame first so I'm going to import pandas as PD and I'll create a data frame so DF is equal to PD dot data frame so in this case I am not going to use the Run n method I'm just simply passing the column wise values in form of a dictionary so in a similar manner you have to create a data frame with three columns so this is our third column and executed so we have created a data frame and this is the resultant data frame now under selection so we select from data frame using criteria from multiple columns so we'll combine multiple conditions using operator such as and and or so we can select from a data frame using right area from multiple columns so basically here we are combining multiple conditions using and operator so I'll write new data frame is equal to data frame and in bracket I'll specify the conditions 1 so DF column 1 greater than 2 and other condition so I'll write add DF column 2 equal to equal to triple four or four hundred forty four I'll execute this I'll display so it is giving me an empty data frame yeah this is because our initially data frame should have three columns so there's something wrong in our Declaration of a data frame so let's check because it should have three column here we have two column oh I have not given the correct name to the third column Let It Be column three now let's execute execute this again now we have three columns now this condition will work so we have a row here so this row had column 2 equal to equal to 444 and the column 1 was greater than 2. so this is similar to the conditional selection we discussed earlier only difference is we are combining several conditions now we'll see how to get information on unique values column so first we'll try to identify all the unique elements of a column and obtain them in form of a list so for that purpose we have to use the unique method so I'll write DF and the target column Dot unique so column 2 has three unique values 444 555 and 666. in a similar manner we can calculate the count of unique elements of a column so for that I have to write DF Target column Dot n unique and I'll execute it so it has three unique elements first one gives us the unique element and the second one gives us the count of the unique elements or the total number of unique ellipse now our next objective is to calculate how many times the unique values appear in a column so what is frequency of each unique value so for that we have a method called as value counts so here triple four occurred two times triple five occurred one time and triple six awkward only one time so in today's lecture we covered unique elements and conditional selection that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to your course on pandas in today's lecture I'm going to demonstrate the use of apply method of pandas so let's get started so the apply method is used for applying functions on columns so we can select a particular column apply a function on all the values of that column and store the result somewhere else like in a new column or in a new list somewhere so apply method is used to broadcast a function to the columns that is every value of that particular column will be treated with the function that is passed in the apply method so first of all let us read a data frame so let's feed a data frame first then I am going to import pandas as PD so now I'll write DF is equal to PD Dot read CSV and I'll pass the file name that is Iris dot CSV I'll display some of the rows of the data frame so this is basically our data frame now let's create a new column that stores the length of species name so the last column is the species and we have to count the number of characters in the species name for every row so create a new column that stores the length of species name so the procedure is very simple we have to create a new column so DF of new column name or anything let it be Lin species or dense species name is equal to DF of species because we are applying this function on the column species and we are applying the function that is length so this needs not to be in commas or removing so dot apply length now I'll display the data frame and it has a new column that is length of species name and you can count it manually also it's one two three four five six seven eight nine ten eleven and for the last true it is 14. now let's create a function that takes a number and Returns the number multiplied by 2. so create a function that takes a number and Returns the number multiplied by 2 and our second job is that using apply method so using apply method create a new column Dot contains the doubled cepulant so we have to create a function that takes a number and returns a number multiplied by two and we have to apply it to the column that is supplement centimeter so I'm creating a function first so this is the function Let its name be times 2 and it returns number multiplied by two now d s of sample length 2 art supplement doubled is equal to DF supplement centimeter dot apply times 2. I'll execute it and now we have a new version of the data frame containing an additional column that contains the double length so apply method can be used to broadcast inbuilt or user defined functions so it can be used to broadcast in build functions as well and user defined functions as well also we can use a combination of apply method as well as the Lambda function so today's lecture was all about the application of apply method in pandas that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas in today's lecture we'll discuss some methods functions or operations of pandas to get information about data frames so let's get started short topic is basic operations or functions so we'll discuss some methods or functions of pandas to get information about the data frames and these functions are very useful during data analysis so use of methods last functions of pandas to get info about data frames so I'll import pandas as PD then I'll read a data frame from the iris file as usual so DF is equal to PD dot read CSV and I'll pass Iris dot CSV and this is our data frame now I'll just get some basic info about this data frame using DF dot info so this is the application of info method or function so it gives us the information about the column names the number of null values and their count to this we have already discussed in a previous lecture now let's move on so how to get the names of all the keys of a data frame for that we can write DF dot keys and it will display a list of all the keys moving on to the description we can write DF dot describe so it will tell us the count the mean the standard deviation the minimum and the maximum value and the quartile distribution of each and every column provided that it is a numeric column like for the species it's showing nothing so that is missing here so DF dot describe can give us the description of each and every column another method to fetch all the keys is using DF dot columns so it also returns us a list of all the column names it is similar to DF dot keys so this is cmf DF dot Keys function now we also have a function to fetch all the indexes so it will not return a list of indexes but rather it Returns the start value the stop value and the step size in today's lecture we covered some functions to get information on data frames that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas in today's lecture we are going to cover the topics of sorting and ordering using pandas so let's get started so topic for today is sorting and ordering so sorting and ordering first I'm going to import pandas as PD so import pandas as PD our next job is to read a CSP file on extract the data set from the file so read a CSV file and extract a data frame for that I am going to write DF or the variable or anything is equal to PD dot read CSV and the name of the file is Iris dot CSV so this is our data frame so let's sort in ascending order by simple length so sorting in ascending order by sepulence so here we have sorting as well as ordering so order is ascending on the variable is simple length so now I'm going to write d f Dot sort underscore values function and it takes a parameter that is by in which we have to specify the column name so we want to sort by supplement so I'll pass supplements centimeter and it will return me the sorted data frame also note that it does not cause any change in the original data frame see there's no change in the original data frame so we can say that by default sorting is not in place so in place is false by default if we want permanent changes we have to specify the in place as true now let's sort by Petland so the syntax will be same DF dot sort values Pi is equal to Petal and centimeter so this is quite easy to do so let's sort by petal and now and write DF dot sort values and by is equal to Petal length centimeters and I'll run it so this also returns a data frame but does not cause any change in the original data frame until and unless we specified in place as true so that's all about sorting and ordering the values or the entries in a data frame that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas in today's lecture I am going to demonstrate the use of tail keyword for deletion of columns from a data frame so let's get started let me just create a new notebook first and rename it so let me just change the name to Dell keyword so the topic for today is Dell keyword and it's used for dropping The Columns of a data frame so Dell keyword can be used for removing a column earlier I demonstrated the use of drop method for removal of a column now I'll teach you how to remove a column using the Dell keyword so let me just import pandas as PD and let me just read a CSV file and extract the data frame from that particular file so this is our data frame let me just create a new column real quick so let's add a column so DF of blank blank is equal to none or anything so it's giving an error because it can't be directly used we have to write numpy Dot N A N I think so because it is in numpy and not in Python NN is not a data type supported by python so let it be blank or white space or anything and let me just display the data frames now I have a column with the blank values or empty values now let me just conventionally remove this column so conventionally we used the drop method so I'll write DF dot drop and I'll pass the column name axis is equal to one so this is the conventional method and it does not cause any change in the original data set unless you specify in place as true so no change in the original data frame until and unless we specify in place true so it won't commit any changes until you specify in place as true so pass DFT drop the column name axis is equal to 1 and in place is equal to true so now it has been removed now let's see how to use the Dell keyword to achieve the same result so let me just add the column once again so DF of Planck is equal to none this time and display the data set so this is the extra column with none values now I'll just simply write Del DS and the column name in square bracket and it has been deleted from the original data set as well we don't need to specify in place true or something like that so deleted successfully without passing additional parameters like access or specifying the in place as true so in today's lecture we covered the use of tail keyword for removing columns from a data frame that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas in today's lecture we'll learn how to deal with not a number or nonvalues in a data set we have already discussed some of it in the data cleaning portion of this playlist but we'll cover this topic in a finer detail today so let's get started so our topic is dealing with Nan values in a data set so that's the topic for today so first job is always to create or import a data set will create a data set instead of importing it let the data frame name be df1 in this case and we'll pass a dictionary here to create a data frame so let me just do it quickly so it has two columns that is a and b elements of column A are gonna be a 0 a 1 and A2 while the elements of column B are gonna be b0 B1 and B2 so B 0 comma B1 and B2 and our index gonna be 0 1 and 2. so I have to pass the index the index is equal to list 0 comma 1 comma 2. now I'm gonna run this thing there's an error I forgot to import let's import import panels as PD as PD and df1 is equal to PD dot data frame so this is our first data frame now similarly create a second data frame just change some of the values so second data frame can be created in a similar manner by changing a few values what we are actually gonna do is we are waiting two data frames and we are gonna concatenate it along the axis one so that we have some of the values as nen that's how we are gonna achieve some alien values we can also directly insert some of the Nan values using numpy dot Nan but here to make it a little more complex I'm using concatenation so I've concatenated both the data sets or the data frames along the axis one so now I have one two three four five six six into two twelve twelve and in values now our first job is to check for null values or any n values in this case so checking for null values so we can check for null values by is null method or function so I'll write Q dot is null and all the null values will return true while other values will return false so we'll get a sort of data frame as a result and the entries corresponding to the null values will be true and corresponding to not null values will be false now we can see how to drop all the rows with null values so I had already discussed this just write me Q dot drop any so all the rows have been deleted because all the rows contain null value so drop n a removes the rows with null values this we have already discussed in data cleaning but I thought it would be great if I explain it in detail here so by default drop any or drop null is false in place so it won't cause any change and the original data set unless you specify in place is equal to true now we Are Gonna Fill the null values for that we have fill any method and I'm gonna pass whatever number or string I want null values to be replaced with now all the null values will be replaced with the string fill so here we can see the result now moving on so if we want to assign any n value to some variable directly we can't do it using the python functions or the python Concepts we have to go for numpy so I'm gonna import and I'm by as NP and I'm gonna write Q of Nu is equal to NP Dot N A N this is how we assign an in value to a row or a column you can't directly write Q Nu is equal to Indian it won't work so now you know how to directly assign a row red n in value so in today's lecture we covered how to deal with null or NN values in a data frame that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas in today's lecture I'm going to teach you about pivot tables so let's get started so what is a pivot table so pivot table it's nothing but a multiindex table so earlier we had just only one index or label here we can have multiple and we can sort them so we are basically trying to create a multiindex table from a normal data frame this is what we are gonna do in this video so pivot table simplifies the presentation of data in a data frame where we have redundant a pivot valid for a particular let me just important so let's now I'm going to first create a dictionary in order and then we will create so let the dictionary b a b c and d respectively so A and B have redundant so A and B will act as the multiple indexes so let the elements of a b so bar redundant and elements p 1 and 2 for the column B also redundant so we have created a dictionary now let's create a data frame so DF is equal to PD dot data frame and I'll pass the dictionary so this is the resultant data frame now I have to create a pivot table so let's create a pivot table so in order to create a pivot table I have to write DF dot pivot table within underscore separation and I'll pass values is equal to D because it represents the data index or the multiindex is represented by a and b and let's represent the columns by C so the columns is equal to Phi so the columns I X and Y now this is the resultant data frame or pivot table or a pivot data frame so in today's lecture I covered how to create a pivot table from a normal data frame hence we have created a pivot table successfully that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you hi guys welcome back to our course on pandas this is gonna be the last Theory lecture I'm gonna teach you how to read data from HTML files so let's get started so today's topic is reading data from HTML files so we have to install HTML lib lxml and beautiful soup before we can actually read data from HTML files so these are the commands for installation that is conda install lxml conda install HTML lib 5 or HTML5 lib and conda install beautiful soup 4. so I have installed after installation you have to restart the restart notebook so just close it close your browser open the Anaconda navigate again and launch the notebook again so I have launched the notebook successfully now I just need to look for that particular file search in desktop so I'll just go to the file was reading HTML Dot ipin now I just need to import pandas aspd so import pandas as PD and then I just need to write DS is equal to PD Dot read HTML it's similar to reading from CSV or Json I just need to change read underscore HTML and I have to pass the link of the file and you can process and manipulate the data frame in the similar way as we manipulated any other data frame so this is gonna be your assignment you have to look for an HTML file that contains a database and you have to extract that database from the HTML file that will be all for today this video is brought to you by programming knowledge please like comment share subscribe and hit the Bell button for updates and stay tuned with us for next lecture thank you